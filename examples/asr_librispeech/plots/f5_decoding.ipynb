{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load speech and language embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model_path = '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/examples/asr_librispeech/plots/embeddings/ami_phoneme_wavlm_llama32_1b_linear_peft.pt'\n",
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: speech_embeddings, Shape: torch.Size([2, 36, 5120])\n",
      "Key: language_embeddings, Shape: torch.Size([2, 36, 2048])\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'model' is your dictionary\n",
    "for key in model.keys():\n",
    "    print(f\"Key: {key}, Shape: {model[key].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load find ckpt path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_20227_loss_0.6369916200637817/model.pt'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Directory path where the folders are located\n",
    "dir_path = '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_wavlm_llama32_1b_linear_peft'\n",
    "\n",
    "# Get all directories starting with 'asr_epoch_'\n",
    "folders = [f for f in os.listdir(dir_path) if f.startswith('asr_epoch_')]\n",
    "\n",
    "# Sort folders by the numeric value of the loss (7th part of the folder name)\n",
    "sorted_folders = sorted(folders, key=lambda x: float(x.split('_')[6]))\n",
    "\n",
    "# The folder with the lowest loss value\n",
    "lowest_loss_folder = sorted_folders[0]\n",
    "\n",
    "# Construct the full path\n",
    "full_path = os.path.join(dir_path, lowest_loss_folder)\n",
    "\n",
    "# Define the model file path\n",
    "checkpoint_path = os.path.join(full_path, 'model.pt')\n",
    "checkpoint_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_20227_loss_0.6369916200637817/model.pt\n",
      "The loaded model is not a dictionary. Printing the object type:\n",
      "<class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Check if the model file exists and inspect its contents\n",
    "if os.path.exists(checkpoint):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')  # Load the model file\n",
    "    print(f\"Model loaded successfully from {checkpoint_path}\")\n",
    "    \n",
    "    # Check if the loaded object is a dictionary (common for PyTorch checkpoints)\n",
    "    if isinstance(model, dict):\n",
    "        print(\"Keys in the model checkpoint:\")\n",
    "        for key in model.keys():\n",
    "            print(f\"- {key}\")\n",
    "    else:\n",
    "        print(\"The loaded model is not a dictionary. Printing the object type:\")\n",
    "        print(type(model))\n",
    "else:\n",
    "    print(\"Model file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct',\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "            '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight': tensor([[ 2.5326e-02,  2.8484e-02,  1.3398e-03,  ...,  3.1131e-03,\n",
       "          -1.0659e-02,  1.6014e-03],\n",
       "         [ 2.0980e-03,  6.1089e-05,  2.3090e-02,  ...,  4.0515e-02,\n",
       "          -2.5970e-03, -6.9620e-03],\n",
       "         [ 1.5990e-02,  3.0519e-02,  1.9506e-02,  ...,  4.0012e-02,\n",
       "          -1.6976e-02, -3.2935e-02],\n",
       "         ...,\n",
       "         [ 1.7744e-02,  2.5626e-02,  2.6607e-02,  ...,  6.8131e-03,\n",
       "          -6.7438e-03,  2.4509e-03],\n",
       "         [-2.5725e-02, -1.8041e-02,  9.6223e-03,  ..., -2.9973e-02,\n",
       "           5.1318e-03, -9.5922e-03],\n",
       "         [ 3.2651e-02,  2.1047e-02,  2.2146e-02,  ...,  1.8839e-02,\n",
       "          -3.1481e-02, -4.7576e-03]]),\n",
       " 'llm.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight': tensor([[-0.0169, -0.0162,  0.0109,  ..., -0.0257,  0.0238, -0.0166],\n",
       "         [ 0.0159,  0.0135, -0.0033,  ...,  0.0059, -0.0145,  0.0089],\n",
       "         [ 0.0096,  0.0111,  0.0029,  ...,  0.0141, -0.0212,  0.0085],\n",
       "         ...,\n",
       "         [-0.0008,  0.0255, -0.0369,  ..., -0.0399, -0.0334,  0.0109],\n",
       "         [-0.0066,  0.0081, -0.0331,  ..., -0.0411, -0.0218,  0.0002],\n",
       "         [-0.0002, -0.0267,  0.0322,  ...,  0.0390,  0.0284,  0.0010]]),\n",
       " 'llm.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight': tensor([[ 0.0015, -0.0245, -0.0204,  ...,  0.0142,  0.0184,  0.0102],\n",
       "         [ 0.0026,  0.0201,  0.0054,  ...,  0.0140, -0.0052,  0.0186],\n",
       "         [ 0.0072,  0.0008,  0.0044,  ...,  0.0068,  0.0059, -0.0176],\n",
       "         ...,\n",
       "         [ 0.0099, -0.0076,  0.0136,  ..., -0.0004,  0.0036,  0.0206],\n",
       "         [ 0.0078, -0.0206, -0.0052,  ..., -0.0039,  0.0077, -0.0146],\n",
       "         [ 0.0447,  0.0202, -0.0105,  ..., -0.0021, -0.0177,  0.0238]]),\n",
       " 'llm.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight': tensor([[ 0.0035, -0.0232,  0.0222,  ..., -0.0029, -0.0065,  0.0343],\n",
       "         [-0.0007,  0.0070, -0.0077,  ..., -0.0064,  0.0095, -0.0052],\n",
       "         [-0.0256,  0.0279,  0.0010,  ..., -0.0230,  0.0089, -0.0040],\n",
       "         ...,\n",
       "         [ 0.0233,  0.0028, -0.0105,  ...,  0.0007,  0.0151,  0.0054],\n",
       "         [-0.0018,  0.0060,  0.0074,  ..., -0.0076, -0.0040, -0.0039],\n",
       "         [-0.0179, -0.0035,  0.0238,  ..., -0.0043, -0.0120,  0.0016]]),\n",
       " 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight': tensor([[ 1.2890e-03, -7.7198e-04, -2.3521e-02,  ...,  1.5971e-02,\n",
       "           1.3355e-02,  1.6961e-03],\n",
       "         [-2.0474e-02,  6.5047e-03,  1.3624e-02,  ...,  4.2420e-03,\n",
       "          -1.0595e-03,  1.0701e-02],\n",
       "         [-1.1492e-02, -2.4931e-02, -1.8501e-02,  ...,  8.8005e-03,\n",
       "          -4.7521e-03,  1.8807e-03],\n",
       "         ...,\n",
       "         [-4.1018e-03,  1.8767e-03, -2.2548e-02,  ...,  8.9578e-03,\n",
       "           1.2638e-02,  1.1356e-02],\n",
       "         [ 3.1177e-02, -1.2078e-02,  9.5743e-03,  ...,  3.3860e-02,\n",
       "          -2.7144e-03,  2.6597e-03],\n",
       "         [-1.1006e-03,  1.9178e-02, -2.2369e-02,  ...,  4.8215e-03,\n",
       "           1.9860e-05,  4.2237e-02]]),\n",
       " 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0052, -0.0055,  0.0060,  ..., -0.0075,  0.0080,  0.0033],\n",
       "         [ 0.0095, -0.0268,  0.0125,  ...,  0.0030,  0.0044,  0.0057],\n",
       "         [ 0.0114, -0.0054,  0.0137,  ...,  0.0011, -0.0030,  0.0065],\n",
       "         ...,\n",
       "         [ 0.0056, -0.0086,  0.0050,  ...,  0.0075,  0.0051, -0.0091],\n",
       "         [-0.0108,  0.0131, -0.0084,  ..., -0.0119, -0.0011, -0.0113],\n",
       "         [ 0.0016,  0.0103,  0.0005,  ...,  0.0006,  0.0088,  0.0024]]),\n",
       " 'llm.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight': tensor([[ 0.0051,  0.0218,  0.0050,  ..., -0.0160,  0.0105,  0.0019],\n",
       "         [ 0.0072,  0.0054, -0.0202,  ...,  0.0038, -0.0156,  0.0328],\n",
       "         [-0.0062,  0.0137, -0.0027,  ...,  0.0177, -0.0040, -0.0007],\n",
       "         ...,\n",
       "         [-0.0058, -0.0036, -0.0093,  ...,  0.0082, -0.0027,  0.0185],\n",
       "         [-0.0016,  0.0102, -0.0070,  ...,  0.0136, -0.0083,  0.0034],\n",
       "         [ 0.0034,  0.0071, -0.0091,  ...,  0.0070, -0.0014,  0.0163]]),\n",
       " 'llm.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight': tensor([[ 0.0022, -0.0002,  0.0045,  ..., -0.0075,  0.0132, -0.0105],\n",
       "         [ 0.0084,  0.0129,  0.0008,  ..., -0.0128, -0.0074,  0.0036],\n",
       "         [-0.0007,  0.0089, -0.0132,  ...,  0.0128,  0.0005,  0.0071],\n",
       "         ...,\n",
       "         [ 0.0093, -0.0106, -0.0046,  ..., -0.0268,  0.0039,  0.0057],\n",
       "         [ 0.0055,  0.0280,  0.0154,  ..., -0.0064, -0.0072,  0.0184],\n",
       "         [ 0.0140,  0.0233, -0.0220,  ..., -0.0115, -0.0065,  0.0278]]),\n",
       " 'llm.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight': tensor([[-0.0499,  0.0280, -0.0040,  ..., -0.0263, -0.0058,  0.0054],\n",
       "         [-0.0061,  0.0260, -0.0087,  ...,  0.0150,  0.0118,  0.0020],\n",
       "         [ 0.0197, -0.0066,  0.0138,  ...,  0.0025,  0.0042,  0.0035],\n",
       "         ...,\n",
       "         [-0.0028,  0.0103,  0.0491,  ..., -0.0085,  0.0149, -0.0036],\n",
       "         [-0.0318, -0.0199, -0.0208,  ..., -0.0020,  0.0115,  0.0124],\n",
       "         [-0.0243, -0.0225, -0.0230,  ..., -0.0103, -0.0158, -0.0069]]),\n",
       " 'llm.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight': tensor([[-0.0169,  0.0105, -0.0155,  ...,  0.0208,  0.0006, -0.0270],\n",
       "         [ 0.0082,  0.0182, -0.0319,  ...,  0.0064, -0.0044,  0.0058],\n",
       "         [ 0.0060, -0.0108, -0.0139,  ...,  0.0227,  0.0027, -0.0153],\n",
       "         ...,\n",
       "         [ 0.0039,  0.0011, -0.0023,  ...,  0.0193, -0.0193,  0.0012],\n",
       "         [ 0.0061,  0.0274, -0.0307,  ..., -0.0007, -0.0013,  0.0041],\n",
       "         [-0.0088, -0.0162, -0.0205,  ..., -0.0015,  0.0115, -0.0013]]),\n",
       " 'llm.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight': tensor([[-0.0164,  0.0029, -0.0189,  ..., -0.0319,  0.0212, -0.0053],\n",
       "         [-0.0074, -0.0107,  0.0074,  ..., -0.0040,  0.0043,  0.0201],\n",
       "         [-0.0340,  0.0309,  0.0204,  ...,  0.0231,  0.0203,  0.0154],\n",
       "         ...,\n",
       "         [ 0.0144,  0.0349,  0.0242,  ..., -0.0051, -0.0252, -0.0062],\n",
       "         [-0.0134,  0.0108, -0.0101,  ...,  0.0217,  0.0297,  0.0325],\n",
       "         [ 0.0049, -0.0270, -0.0115,  ..., -0.0069, -0.0139, -0.0160]]),\n",
       " 'llm.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight': tensor([[ 1.5690e-02, -6.4135e-03, -3.6356e-02,  ..., -7.2229e-03,\n",
       "           4.4403e-03, -7.7652e-03],\n",
       "         [ 6.4300e-03,  2.2908e-02, -6.6268e-04,  ...,  2.5060e-02,\n",
       "           1.1217e-02, -2.4810e-03],\n",
       "         [ 1.5130e-02, -3.1020e-03,  1.2996e-02,  ...,  2.5552e-02,\n",
       "           2.1965e-02, -2.1635e-02],\n",
       "         ...,\n",
       "         [-2.9105e-02,  7.6887e-03,  8.8001e-03,  ...,  2.0132e-02,\n",
       "           1.3533e-02, -3.1539e-03],\n",
       "         [ 5.7505e-04, -2.9247e-02, -2.5658e-02,  ...,  1.0104e-02,\n",
       "          -1.1479e-02,  3.1324e-02],\n",
       "         [-1.3748e-02, -1.0539e-02,  2.4330e-05,  ...,  5.9253e-03,\n",
       "           1.3193e-02, -7.2387e-03]]),\n",
       " 'llm.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight': tensor([[-0.0111,  0.0148,  0.0073,  ..., -0.0113,  0.0143,  0.0298],\n",
       "         [-0.0098, -0.0131,  0.0041,  ...,  0.0258, -0.0121,  0.0115],\n",
       "         [-0.0070, -0.0158, -0.0176,  ..., -0.0068, -0.0023, -0.0022],\n",
       "         ...,\n",
       "         [ 0.0099, -0.0147,  0.0032,  ..., -0.0177, -0.0163, -0.0189],\n",
       "         [-0.0040, -0.0050, -0.0132,  ...,  0.0062,  0.0169,  0.0316],\n",
       "         [ 0.0174,  0.0083,  0.0162,  ...,  0.0152, -0.0122, -0.0020]]),\n",
       " 'llm.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight': tensor([[ 2.1434e-03, -1.2648e-03,  2.2371e-02,  ..., -1.1723e-03,\n",
       "          -1.6079e-02, -1.3238e-02],\n",
       "         [-8.8259e-03, -2.6293e-02, -6.3860e-03,  ...,  2.2429e-02,\n",
       "          -2.7712e-03, -1.9125e-02],\n",
       "         [-2.2992e-03, -1.9214e-03,  2.5687e-02,  ..., -8.2553e-03,\n",
       "           2.1013e-03,  3.7967e-03],\n",
       "         ...,\n",
       "         [-1.8953e-04, -1.3511e-02, -1.3815e-02,  ...,  7.6910e-03,\n",
       "           5.0879e-04, -2.3388e-03],\n",
       "         [ 2.8105e-02,  5.5559e-03, -2.5383e-02,  ..., -1.3021e-02,\n",
       "           9.2824e-03, -5.2595e-03],\n",
       "         [-1.0774e-02,  1.2146e-03,  1.2744e-02,  ..., -2.4350e-03,\n",
       "          -1.8013e-06,  4.5848e-03]]),\n",
       " 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0264, -0.0114, -0.0051,  ..., -0.0463, -0.0032, -0.0012],\n",
       "         [ 0.0042, -0.0342, -0.0053,  ..., -0.0129, -0.0012, -0.0267],\n",
       "         [-0.0112, -0.0040, -0.0022,  ..., -0.0457, -0.0016, -0.0033],\n",
       "         ...,\n",
       "         [ 0.0212,  0.0100,  0.0130,  ...,  0.0180,  0.0074,  0.0174],\n",
       "         [ 0.0102, -0.0088, -0.0041,  ..., -0.0243,  0.0150,  0.0111],\n",
       "         [-0.0171,  0.0066, -0.0080,  ..., -0.0022,  0.0135, -0.0078]]),\n",
       " 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0019, -0.0011, -0.0186,  ..., -0.0088,  0.0274, -0.0174],\n",
       "         [ 0.0207,  0.0224,  0.0049,  ..., -0.0042, -0.0035,  0.0085],\n",
       "         [ 0.0012,  0.0112,  0.0435,  ..., -0.0013, -0.0253,  0.0039],\n",
       "         ...,\n",
       "         [ 0.0119,  0.0025,  0.0094,  ..., -0.0165,  0.0070,  0.0197],\n",
       "         [ 0.0103, -0.0074,  0.0239,  ..., -0.0098,  0.0178, -0.0030],\n",
       "         [-0.0032,  0.0045,  0.0014,  ..., -0.0082, -0.0028, -0.0083]]),\n",
       " 'llm.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight': tensor([[-0.0085, -0.0017,  0.0100,  ..., -0.0380, -0.0105,  0.0116],\n",
       "         [-0.0177, -0.0010,  0.0298,  ...,  0.0117,  0.0212,  0.0096],\n",
       "         [ 0.0426, -0.0355,  0.0148,  ..., -0.0116,  0.0105,  0.0019],\n",
       "         ...,\n",
       "         [-0.0120, -0.0248,  0.0220,  ...,  0.0097, -0.0117, -0.0172],\n",
       "         [ 0.0176,  0.0105, -0.0490,  ...,  0.0412, -0.0190,  0.0053],\n",
       "         [ 0.0241,  0.0103,  0.0106,  ...,  0.0148,  0.0117, -0.0085]]),\n",
       " 'llm.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight': tensor([[ 0.0084,  0.0018, -0.0182,  ...,  0.0055,  0.0041, -0.0065],\n",
       "         [-0.0026,  0.0005,  0.0140,  ..., -0.0005, -0.0111,  0.0006],\n",
       "         [ 0.0066,  0.0171,  0.0068,  ..., -0.0027,  0.0022, -0.0040],\n",
       "         ...,\n",
       "         [ 0.0064,  0.0216,  0.0016,  ...,  0.0060, -0.0333,  0.0407],\n",
       "         [-0.0160, -0.0148,  0.0257,  ...,  0.0100,  0.0054,  0.0069],\n",
       "         [ 0.0057, -0.0010, -0.0036,  ...,  0.0011,  0.0104,  0.0008]]),\n",
       " 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0214,  0.0033,  0.0346,  ...,  0.0288,  0.0042,  0.0029],\n",
       "         [-0.0087,  0.0115, -0.0085,  ...,  0.0002, -0.0093,  0.0005],\n",
       "         [ 0.0072,  0.0105,  0.0166,  ..., -0.0389,  0.0125,  0.0133],\n",
       "         ...,\n",
       "         [-0.0048,  0.0033,  0.0070,  ..., -0.0247, -0.0234, -0.0158],\n",
       "         [-0.0103, -0.0096,  0.0063,  ...,  0.0057,  0.0196,  0.0129],\n",
       "         [-0.0205, -0.0253,  0.0035,  ..., -0.0246, -0.0259, -0.0105]]),\n",
       " 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0041, -0.0088, -0.0157,  ...,  0.0119, -0.0112, -0.0065],\n",
       "         [ 0.0033, -0.0014, -0.0048,  ..., -0.0035,  0.0019,  0.0048],\n",
       "         [ 0.0050,  0.0049, -0.0102,  ...,  0.0111,  0.0218,  0.0135],\n",
       "         ...,\n",
       "         [-0.0010,  0.0084, -0.0013,  ...,  0.0053,  0.0110,  0.0179],\n",
       "         [-0.0043,  0.0004,  0.0115,  ...,  0.0030,  0.0080, -0.0060],\n",
       "         [ 0.0099,  0.0038, -0.0073,  ...,  0.0025, -0.0036,  0.0045]]),\n",
       " 'llm.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight': tensor([[-0.0141,  0.0076, -0.0250,  ..., -0.0279, -0.0114,  0.0169],\n",
       "         [-0.0262, -0.0137, -0.0101,  ..., -0.0044,  0.0105, -0.0069],\n",
       "         [ 0.0052, -0.0015, -0.0115,  ..., -0.0127,  0.0131,  0.0008],\n",
       "         ...,\n",
       "         [ 0.0213,  0.0094, -0.0015,  ...,  0.0303,  0.0197,  0.0060],\n",
       "         [-0.0190,  0.0152,  0.0234,  ...,  0.0225, -0.0060,  0.0005],\n",
       "         [-0.0115,  0.0015,  0.0066,  ...,  0.0054,  0.0150,  0.0071]]),\n",
       " 'llm.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight': tensor([[-0.0105,  0.0079,  0.0050,  ..., -0.0241, -0.0288, -0.0019],\n",
       "         [-0.0073, -0.0037, -0.0021,  ...,  0.0220,  0.0025,  0.0004],\n",
       "         [ 0.0025,  0.0117,  0.0138,  ...,  0.0102,  0.0002, -0.0112],\n",
       "         ...,\n",
       "         [ 0.0003, -0.0148,  0.0042,  ...,  0.0079,  0.0272,  0.0084],\n",
       "         [ 0.0113,  0.0079,  0.0089,  ..., -0.0284, -0.0044, -0.0148],\n",
       "         [ 0.0039, -0.0101,  0.0135,  ...,  0.0093, -0.0043, -0.0122]]),\n",
       " 'llm.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight': tensor([[-0.0306,  0.0259,  0.0089,  ..., -0.0158,  0.0087, -0.0210],\n",
       "         [-0.0093,  0.0315,  0.0028,  ...,  0.0120,  0.0166,  0.0062],\n",
       "         [-0.0306, -0.0022, -0.0052,  ..., -0.0169, -0.0347,  0.0179],\n",
       "         ...,\n",
       "         [-0.0105, -0.0036, -0.0077,  ...,  0.0125, -0.0044,  0.0336],\n",
       "         [-0.0270,  0.0388, -0.0012,  ..., -0.0231,  0.0266,  0.0034],\n",
       "         [-0.0100,  0.0125,  0.0430,  ...,  0.0095,  0.0052, -0.0235]]),\n",
       " 'llm.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight': tensor([[ 0.0114,  0.0026, -0.0106,  ..., -0.0122,  0.0023,  0.0036],\n",
       "         [-0.0090,  0.0114, -0.0063,  ...,  0.0138, -0.0051,  0.0172],\n",
       "         [ 0.0159, -0.0028, -0.0167,  ...,  0.0021, -0.0031,  0.0137],\n",
       "         ...,\n",
       "         [-0.0166,  0.0223,  0.0056,  ..., -0.0134, -0.0174, -0.0308],\n",
       "         [-0.0155,  0.0112, -0.0269,  ..., -0.0123,  0.0081, -0.0044],\n",
       "         [ 0.0230, -0.0045,  0.0017,  ..., -0.0189,  0.0012,  0.0164]]),\n",
       " 'llm.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight': tensor([[ 0.0032, -0.0092, -0.0106,  ...,  0.0236, -0.0221,  0.0127],\n",
       "         [-0.0187,  0.0168, -0.0059,  ...,  0.0097, -0.0087,  0.0145],\n",
       "         [-0.0318,  0.0028,  0.0161,  ...,  0.0174, -0.0038,  0.0166],\n",
       "         ...,\n",
       "         [-0.0009, -0.0028,  0.0267,  ..., -0.0022,  0.0316, -0.0101],\n",
       "         [-0.0236,  0.0085, -0.0126,  ...,  0.0251, -0.0416,  0.0296],\n",
       "         [-0.0052,  0.0144,  0.0124,  ..., -0.0112,  0.0204, -0.0055]]),\n",
       " 'llm.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight': tensor([[ 0.0011,  0.0026, -0.0029,  ..., -0.0252,  0.0215, -0.0012],\n",
       "         [-0.0012,  0.0272,  0.0058,  ..., -0.0084,  0.0226, -0.0011],\n",
       "         [ 0.0016, -0.0169,  0.0198,  ...,  0.0122, -0.0067,  0.0041],\n",
       "         ...,\n",
       "         [ 0.0106, -0.0227, -0.0253,  ...,  0.0012,  0.0011,  0.0164],\n",
       "         [-0.0139,  0.0169, -0.0056,  ...,  0.0113,  0.0079,  0.0065],\n",
       "         [ 0.0119,  0.0004,  0.0016,  ..., -0.0034,  0.0186, -0.0058]]),\n",
       " 'llm.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight': tensor([[ 0.0070,  0.0084, -0.0097,  ..., -0.0033,  0.0246, -0.0017],\n",
       "         [-0.0185, -0.0169,  0.0099,  ...,  0.0136, -0.0013,  0.0174],\n",
       "         [-0.0200,  0.0193, -0.0045,  ..., -0.0099, -0.0340,  0.0011],\n",
       "         ...,\n",
       "         [ 0.0011, -0.0052, -0.0024,  ...,  0.0313, -0.0060,  0.0022],\n",
       "         [-0.0045,  0.0216,  0.0070,  ..., -0.0026, -0.0329, -0.0034],\n",
       "         [-0.0053, -0.0255, -0.0179,  ..., -0.0020,  0.0504,  0.0275]]),\n",
       " 'llm.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight': tensor([[-0.0004,  0.0021,  0.0036,  ..., -0.0053, -0.0076, -0.0020],\n",
       "         [-0.0019,  0.0030,  0.0255,  ...,  0.0076,  0.0079,  0.0076],\n",
       "         [ 0.0130, -0.0016, -0.0075,  ..., -0.0153, -0.0168,  0.0046],\n",
       "         ...,\n",
       "         [-0.0002, -0.0109, -0.0002,  ..., -0.0212,  0.0038, -0.0045],\n",
       "         [ 0.0093, -0.0151, -0.0105,  ..., -0.0151, -0.0034, -0.0137],\n",
       "         [-0.0023,  0.0026, -0.0114,  ...,  0.0004, -0.0258,  0.0143]]),\n",
       " 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0135, -0.0016,  0.0352,  ..., -0.0271,  0.0030, -0.0029],\n",
       "         [ 0.0374,  0.0052,  0.0057,  ..., -0.0194,  0.0170,  0.0103],\n",
       "         [-0.0066, -0.0035,  0.0199,  ...,  0.0086,  0.0091,  0.0062],\n",
       "         ...,\n",
       "         [ 0.0193,  0.0107, -0.0379,  ..., -0.0231, -0.0198,  0.0203],\n",
       "         [-0.0003,  0.0138,  0.0005,  ...,  0.0034,  0.0210, -0.0033],\n",
       "         [-0.0208,  0.0012,  0.0304,  ...,  0.0266, -0.0004, -0.0217]]),\n",
       " 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0287, -0.0217,  0.0153,  ..., -0.0232,  0.0050, -0.0295],\n",
       "         [ 0.0101, -0.0033,  0.0082,  ...,  0.0055, -0.0163, -0.0008],\n",
       "         [ 0.0081, -0.0071, -0.0002,  ..., -0.0096,  0.0106, -0.0097],\n",
       "         ...,\n",
       "         [-0.0157,  0.0010, -0.0017,  ...,  0.0046, -0.0254, -0.0120],\n",
       "         [ 0.0051, -0.0139,  0.0374,  ..., -0.0263, -0.0288, -0.0371],\n",
       "         [-0.0466,  0.0185, -0.0269,  ...,  0.0233, -0.0017,  0.0257]]),\n",
       " 'llm.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight': tensor([[-0.0128,  0.0165, -0.0212,  ...,  0.0108, -0.0186,  0.0201],\n",
       "         [-0.0152, -0.0426,  0.0069,  ...,  0.0396,  0.0042,  0.0144],\n",
       "         [-0.0330,  0.0049,  0.0132,  ..., -0.0111,  0.0014,  0.0201],\n",
       "         ...,\n",
       "         [-0.0121, -0.0278,  0.0016,  ...,  0.0069, -0.0076,  0.0159],\n",
       "         [ 0.0209,  0.0018, -0.0165,  ...,  0.0112, -0.0324,  0.0211],\n",
       "         [-0.0014,  0.0352,  0.0095,  ..., -0.0226,  0.0241, -0.0224]]),\n",
       " 'llm.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight': tensor([[-0.0125,  0.0028,  0.0065,  ..., -0.0258, -0.0056,  0.0071],\n",
       "         [-0.0020, -0.0059,  0.0059,  ..., -0.0008, -0.0095, -0.0024],\n",
       "         [ 0.0008, -0.0037, -0.0187,  ...,  0.0090, -0.0133, -0.0062],\n",
       "         ...,\n",
       "         [-0.0229, -0.0232,  0.0039,  ...,  0.0165, -0.0122, -0.0059],\n",
       "         [-0.0173, -0.0321,  0.0092,  ..., -0.0250, -0.0215, -0.0167],\n",
       "         [-0.0061, -0.0182, -0.0152,  ..., -0.0330, -0.0089,  0.0132]]),\n",
       " 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0003,  0.0056,  0.0262,  ..., -0.0261,  0.0293, -0.0065],\n",
       "         [-0.0255,  0.0174,  0.0180,  ..., -0.0231, -0.0126,  0.0168],\n",
       "         [ 0.0042, -0.0243,  0.0083,  ..., -0.0201, -0.0090,  0.0024],\n",
       "         ...,\n",
       "         [-0.0006,  0.0093, -0.0457,  ...,  0.0071, -0.0040,  0.0133],\n",
       "         [ 0.0203, -0.0027, -0.0266,  ...,  0.0052,  0.0005,  0.0167],\n",
       "         [-0.0109, -0.0318,  0.0067,  ...,  0.0317, -0.0037,  0.0125]]),\n",
       " 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0138,  0.0055, -0.0007,  ..., -0.0094,  0.0148, -0.0117],\n",
       "         [ 0.0051,  0.0086, -0.0005,  ..., -0.0161, -0.0050, -0.0069],\n",
       "         [ 0.0045, -0.0239,  0.0006,  ...,  0.0080,  0.0010,  0.0021],\n",
       "         ...,\n",
       "         [ 0.0077,  0.0015, -0.0061,  ...,  0.0098, -0.0152, -0.0002],\n",
       "         [-0.0105,  0.0002, -0.0039,  ...,  0.0016, -0.0046, -0.0026],\n",
       "         [-0.0145,  0.0050,  0.0013,  ...,  0.0088,  0.0122, -0.0059]]),\n",
       " 'llm.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight': tensor([[-2.7803e-03,  1.5424e-02, -3.3876e-04,  ..., -1.8716e-03,\n",
       "           1.4413e-03, -4.8271e-03],\n",
       "         [-6.8210e-06,  6.0872e-03, -2.5749e-02,  ...,  1.8281e-03,\n",
       "           1.3747e-02, -4.9810e-03],\n",
       "         [-1.5459e-02,  7.4024e-03,  9.9365e-03,  ..., -4.3168e-03,\n",
       "          -3.1711e-02,  1.6223e-03],\n",
       "         ...,\n",
       "         [ 5.7506e-03, -2.6920e-02,  1.3035e-02,  ...,  6.8124e-03,\n",
       "           3.8603e-02,  6.6465e-03],\n",
       "         [ 7.2161e-03,  4.2639e-03,  4.8731e-03,  ...,  2.1208e-03,\n",
       "          -1.7954e-02, -1.0946e-02],\n",
       "         [ 8.0286e-03, -1.7761e-02, -9.0986e-03,  ..., -1.1975e-02,\n",
       "           1.6133e-02, -3.9698e-03]]),\n",
       " 'llm.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight': tensor([[ 0.0157, -0.0034, -0.0058,  ..., -0.0006,  0.0038,  0.0056],\n",
       "         [-0.0006,  0.0062, -0.0056,  ...,  0.0055,  0.0082, -0.0030],\n",
       "         [-0.0081, -0.0094, -0.0057,  ..., -0.0056, -0.0086, -0.0093],\n",
       "         ...,\n",
       "         [ 0.0172,  0.0062,  0.0102,  ..., -0.0047,  0.0015,  0.0214],\n",
       "         [ 0.0007, -0.0147,  0.0137,  ..., -0.0226, -0.0009,  0.0106],\n",
       "         [ 0.0181,  0.0093,  0.0079,  ...,  0.0129,  0.0019,  0.0102]]),\n",
       " 'llm.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight': tensor([[-0.0260, -0.0180, -0.0099,  ...,  0.0434, -0.0092,  0.0211],\n",
       "         [ 0.0022, -0.0026,  0.0035,  ...,  0.0229,  0.0225,  0.0180],\n",
       "         [ 0.0159, -0.0116, -0.0058,  ...,  0.0171, -0.0286,  0.0224],\n",
       "         ...,\n",
       "         [ 0.0115,  0.0051, -0.0098,  ...,  0.0023, -0.0336,  0.0013],\n",
       "         [-0.0090, -0.0021,  0.0080,  ...,  0.0272, -0.0095, -0.0033],\n",
       "         [ 0.0081, -0.0120,  0.0122,  ..., -0.0089,  0.0077, -0.0026]]),\n",
       " 'llm.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight': tensor([[-0.0023, -0.0004,  0.0027,  ..., -0.0081, -0.0238, -0.0167],\n",
       "         [ 0.0452,  0.0098,  0.0071,  ..., -0.0385,  0.0114,  0.0275],\n",
       "         [ 0.0135, -0.0050,  0.0173,  ..., -0.0086,  0.0060,  0.0174],\n",
       "         ...,\n",
       "         [ 0.0158, -0.0028,  0.0027,  ..., -0.0149,  0.0282,  0.0189],\n",
       "         [-0.0075, -0.0027, -0.0217,  ..., -0.0115, -0.0071,  0.0068],\n",
       "         [-0.0071,  0.0099, -0.0162,  ..., -0.0430, -0.0077,  0.0004]]),\n",
       " 'llm.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight': tensor([[ 0.0014, -0.0049,  0.0167,  ..., -0.0128, -0.0174, -0.0049],\n",
       "         [-0.0242,  0.0024, -0.0163,  ...,  0.0129,  0.0183,  0.0009],\n",
       "         [-0.0236, -0.0158,  0.0006,  ...,  0.0072,  0.0022,  0.0002],\n",
       "         ...,\n",
       "         [ 0.0008,  0.0204,  0.0068,  ...,  0.0036,  0.0118, -0.0014],\n",
       "         [ 0.0022,  0.0133, -0.0064,  ...,  0.0032,  0.0153,  0.0146],\n",
       "         [ 0.0021, -0.0021,  0.0066,  ...,  0.0157,  0.0104, -0.0044]]),\n",
       " 'llm.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight': tensor([[ 0.0033,  0.0201, -0.0358,  ...,  0.0105, -0.0263,  0.0117],\n",
       "         [ 0.0103,  0.0180, -0.0003,  ...,  0.0105,  0.0100,  0.0010],\n",
       "         [ 0.0053, -0.0048,  0.0018,  ...,  0.0156, -0.0092,  0.0182],\n",
       "         ...,\n",
       "         [-0.0025,  0.0089, -0.0195,  ..., -0.0267,  0.0060, -0.0350],\n",
       "         [ 0.0029, -0.0032,  0.0157,  ...,  0.0096,  0.0073, -0.0130],\n",
       "         [ 0.0244, -0.0103,  0.0085,  ...,  0.0082, -0.0119, -0.0246]]),\n",
       " 'llm.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight': tensor([[ 0.0038, -0.0102, -0.0254,  ...,  0.0166,  0.0091,  0.0213],\n",
       "         [ 0.0042, -0.0002, -0.0041,  ...,  0.0111, -0.0008,  0.0084],\n",
       "         [-0.0128,  0.0027, -0.0009,  ..., -0.0064,  0.0031, -0.0070],\n",
       "         ...,\n",
       "         [ 0.0014, -0.0069, -0.0018,  ..., -0.0157, -0.0035,  0.0168],\n",
       "         [-0.0039, -0.0148, -0.0083,  ...,  0.0157, -0.0080,  0.0104],\n",
       "         [ 0.0150, -0.0003,  0.0063,  ...,  0.0077,  0.0228, -0.0081]]),\n",
       " 'llm.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight': tensor([[ 2.8963e-03, -1.3317e-03, -1.1795e-02,  ..., -2.3351e-03,\n",
       "           1.5605e-02,  8.2164e-04],\n",
       "         [ 2.1793e-02,  9.6811e-03, -4.0888e-03,  ...,  1.6853e-03,\n",
       "           8.3821e-04, -1.6719e-02],\n",
       "         [ 8.4715e-03,  8.1067e-04, -4.4808e-05,  ..., -1.5029e-02,\n",
       "          -7.7239e-03,  2.9354e-04],\n",
       "         ...,\n",
       "         [-1.3419e-02, -7.0400e-03, -1.6188e-02,  ...,  2.8463e-02,\n",
       "           8.3236e-03, -3.8535e-03],\n",
       "         [ 5.4565e-03,  8.0180e-03, -1.6553e-02,  ...,  3.2578e-03,\n",
       "          -3.8836e-03,  1.8393e-02],\n",
       "         [-1.5832e-02,  1.0176e-02, -7.5620e-04,  ..., -1.2022e-02,\n",
       "          -2.6293e-02, -2.0071e-03]]),\n",
       " 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight': tensor([[ 8.8139e-03, -2.7268e-02, -2.6462e-02,  ..., -9.2968e-03,\n",
       "           4.4384e-03, -4.8692e-02],\n",
       "         [-4.0940e-03, -3.6398e-03, -1.3347e-02,  ..., -8.2621e-03,\n",
       "           8.9316e-03,  1.4868e-02],\n",
       "         [ 1.5038e-02,  7.5416e-03,  2.2075e-02,  ...,  2.2060e-03,\n",
       "           7.2928e-03,  2.0823e-02],\n",
       "         ...,\n",
       "         [ 6.5350e-04, -3.2897e-02, -4.2843e-03,  ...,  3.5855e-02,\n",
       "          -1.8940e-02, -4.2754e-03],\n",
       "         [-9.6945e-03, -2.5020e-02,  1.0664e-03,  ...,  1.0178e-02,\n",
       "          -7.0917e-05, -2.0127e-02],\n",
       "         [-3.3731e-02,  2.6671e-02,  2.2913e-02,  ...,  1.3267e-02,\n",
       "          -1.7484e-03, -3.2024e-02]]),\n",
       " 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight': tensor([[ 1.5538e-02,  1.8370e-02,  7.9839e-03,  ..., -2.2985e-02,\n",
       "           1.3127e-02,  1.8595e-02],\n",
       "         [ 1.4128e-02,  5.4187e-03,  2.0250e-02,  ..., -3.7428e-03,\n",
       "           2.5369e-02,  1.8596e-02],\n",
       "         [ 8.7443e-03, -1.0273e-04,  6.6188e-03,  ...,  1.8364e-02,\n",
       "           7.9372e-03,  3.3870e-03],\n",
       "         ...,\n",
       "         [ 1.4135e-02,  2.0674e-02, -8.3823e-03,  ..., -9.9950e-03,\n",
       "           1.0300e-02,  1.8931e-02],\n",
       "         [ 2.0782e-05,  8.9214e-03,  1.0841e-03,  ...,  5.9271e-03,\n",
       "           4.2895e-03, -1.5808e-03],\n",
       "         [-2.7136e-03, -1.9902e-02,  7.5599e-03,  ...,  2.9499e-03,\n",
       "          -4.6971e-03, -5.4925e-03]]),\n",
       " 'llm.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight': tensor([[-0.0195,  0.0018, -0.0060,  ...,  0.0048,  0.0043, -0.0295],\n",
       "         [-0.0004,  0.0390, -0.0117,  ..., -0.0022, -0.0024, -0.0254],\n",
       "         [ 0.0112, -0.0066, -0.0024,  ..., -0.0319, -0.0205,  0.0059],\n",
       "         ...,\n",
       "         [ 0.0282, -0.0030, -0.0264,  ...,  0.0011,  0.0092, -0.0141],\n",
       "         [ 0.0083,  0.0226,  0.0128,  ...,  0.0306, -0.0065,  0.0081],\n",
       "         [-0.0085,  0.0048,  0.0389,  ...,  0.0117, -0.0043, -0.0004]]),\n",
       " 'llm.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight': tensor([[-0.0064, -0.0052,  0.0020,  ..., -0.0122,  0.0116,  0.0105],\n",
       "         [ 0.0276,  0.0095, -0.0036,  ...,  0.0009, -0.0027,  0.0092],\n",
       "         [ 0.0248, -0.0019,  0.0044,  ..., -0.0071,  0.0087,  0.0110],\n",
       "         ...,\n",
       "         [-0.0025,  0.0096, -0.0124,  ..., -0.0065,  0.0109,  0.0195],\n",
       "         [-0.0036,  0.0011,  0.0041,  ...,  0.0093, -0.0003, -0.0105],\n",
       "         [ 0.0081,  0.0083,  0.0024,  ..., -0.0031,  0.0252,  0.0256]]),\n",
       " 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight': tensor([[-4.3577e-03,  1.1782e-03,  2.1953e-02,  ...,  9.2822e-03,\n",
       "           1.9855e-02, -4.0308e-02],\n",
       "         [-1.6126e-02, -1.1104e-02,  5.5809e-03,  ..., -1.8534e-02,\n",
       "          -5.1484e-03, -2.5781e-02],\n",
       "         [ 6.8569e-03,  2.1398e-03,  4.0273e-03,  ..., -8.7831e-03,\n",
       "           1.8969e-02, -1.0017e-02],\n",
       "         ...,\n",
       "         [ 1.3264e-02, -2.3151e-04, -1.7678e-03,  ..., -6.9168e-03,\n",
       "           4.6976e-03, -2.1559e-02],\n",
       "         [ 7.4320e-03, -1.5855e-02,  1.6273e-03,  ...,  1.5665e-02,\n",
       "           2.6662e-02,  1.2021e-02],\n",
       "         [ 1.1448e-02, -7.9038e-05, -2.1878e-02,  ..., -1.2973e-02,\n",
       "          -9.9892e-03,  2.8496e-02]]),\n",
       " 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0093,  0.0040, -0.0057,  ...,  0.0047,  0.0123, -0.0057],\n",
       "         [ 0.0092, -0.0067, -0.0103,  ...,  0.0029, -0.0012, -0.0126],\n",
       "         [-0.0145, -0.0082, -0.0028,  ...,  0.0025, -0.0056, -0.0086],\n",
       "         ...,\n",
       "         [ 0.0035, -0.0117,  0.0050,  ..., -0.0026,  0.0142, -0.0047],\n",
       "         [-0.0005, -0.0138, -0.0086,  ..., -0.0140, -0.0066, -0.0145],\n",
       "         [-0.0020,  0.0066, -0.0027,  ...,  0.0030,  0.0128, -0.0207]]),\n",
       " 'llm.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight': tensor([[ 0.0162,  0.0226, -0.0090,  ...,  0.0147, -0.0241, -0.0145],\n",
       "         [-0.0149, -0.0213,  0.0035,  ..., -0.0080, -0.0054,  0.0177],\n",
       "         [-0.0034, -0.0163,  0.0030,  ..., -0.0034,  0.0055,  0.0234],\n",
       "         ...,\n",
       "         [-0.0027,  0.0124, -0.0189,  ..., -0.0038, -0.0044,  0.0248],\n",
       "         [ 0.0113, -0.0245, -0.0124,  ...,  0.0004,  0.0069, -0.0189],\n",
       "         [ 0.0079,  0.0210, -0.0281,  ..., -0.0133, -0.0048, -0.0093]]),\n",
       " 'llm.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight': tensor([[ 1.1726e-02,  1.0692e-02,  8.5817e-03,  ..., -8.2081e-03,\n",
       "          -1.0796e-02, -1.2146e-03],\n",
       "         [ 3.7418e-05, -1.4160e-02,  7.3811e-03,  ..., -7.5839e-03,\n",
       "          -4.9552e-03, -1.7752e-02],\n",
       "         [-2.0385e-03, -4.8169e-03,  1.1736e-02,  ...,  4.0919e-03,\n",
       "          -5.2743e-03, -2.7379e-03],\n",
       "         ...,\n",
       "         [ 1.6678e-02,  1.3111e-02,  1.9262e-02,  ...,  1.3963e-03,\n",
       "          -1.2244e-02,  6.5417e-03],\n",
       "         [ 1.7193e-02,  8.6207e-04, -1.1716e-02,  ..., -6.9021e-03,\n",
       "          -2.4335e-02,  1.0850e-02],\n",
       "         [ 1.3103e-02,  9.9804e-03, -4.8468e-03,  ..., -2.3930e-02,\n",
       "           1.3247e-02,  1.3398e-02]]),\n",
       " 'llm.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight': tensor([[ 0.0177,  0.0190,  0.0229,  ...,  0.0210, -0.0314, -0.0044],\n",
       "         [ 0.0257,  0.0275,  0.0194,  ...,  0.0130, -0.0212, -0.0060],\n",
       "         [ 0.0124, -0.0253,  0.0144,  ...,  0.0132, -0.0086, -0.0014],\n",
       "         ...,\n",
       "         [-0.0014,  0.0275,  0.0336,  ..., -0.0047,  0.0018,  0.0010],\n",
       "         [-0.0045,  0.0068, -0.0330,  ...,  0.0103,  0.0105, -0.0014],\n",
       "         [ 0.0154,  0.0172,  0.0051,  ...,  0.0114, -0.0209,  0.0146]]),\n",
       " 'llm.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight': tensor([[ 0.0031, -0.0003,  0.0060,  ...,  0.0068, -0.0117,  0.0150],\n",
       "         [ 0.0052,  0.0043,  0.0188,  ..., -0.0038, -0.0243, -0.0010],\n",
       "         [ 0.0163,  0.0102, -0.0167,  ..., -0.0029, -0.0056,  0.0054],\n",
       "         ...,\n",
       "         [-0.0030, -0.0008, -0.0152,  ...,  0.0087,  0.0037,  0.0141],\n",
       "         [ 0.0227,  0.0103,  0.0226,  ...,  0.0095,  0.0016,  0.0102],\n",
       "         [-0.0004,  0.0131,  0.0122,  ...,  0.0208,  0.0053, -0.0173]]),\n",
       " 'llm.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight': tensor([[ 0.0039,  0.0045, -0.0026,  ..., -0.0168,  0.0246, -0.0043],\n",
       "         [ 0.0214, -0.0230, -0.0346,  ..., -0.0220, -0.0004, -0.0050],\n",
       "         [ 0.0199,  0.0063,  0.0196,  ..., -0.0152, -0.0192, -0.0011],\n",
       "         ...,\n",
       "         [ 0.0210, -0.0209,  0.0253,  ...,  0.0156,  0.0020,  0.0107],\n",
       "         [ 0.0201,  0.0066,  0.0018,  ...,  0.0128, -0.0094, -0.0265],\n",
       "         [ 0.0079, -0.0139, -0.0154,  ...,  0.0200,  0.0185, -0.0007]]),\n",
       " 'llm.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight': tensor([[ 0.0091,  0.0124, -0.0329,  ...,  0.0058, -0.0464, -0.0008],\n",
       "         [-0.0176,  0.0004,  0.0092,  ..., -0.0023,  0.0041,  0.0130],\n",
       "         [-0.0028,  0.0078, -0.0037,  ..., -0.0070,  0.0332,  0.0173],\n",
       "         ...,\n",
       "         [-0.0158, -0.0071,  0.0090,  ..., -0.0103,  0.0259, -0.0072],\n",
       "         [ 0.0168, -0.0361,  0.0070,  ..., -0.0291,  0.0128, -0.0002],\n",
       "         [ 0.0043, -0.0099, -0.0133,  ...,  0.0096,  0.0140,  0.0032]]),\n",
       " 'llm.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight': tensor([[-0.0006, -0.0084, -0.0086,  ..., -0.0092,  0.0159, -0.0257],\n",
       "         [-0.0097,  0.0029,  0.0002,  ...,  0.0002,  0.0316,  0.0003],\n",
       "         [-0.0150, -0.0037, -0.0310,  ...,  0.0078,  0.0038,  0.0043],\n",
       "         ...,\n",
       "         [-0.0058,  0.0054,  0.0118,  ...,  0.0049, -0.0152, -0.0003],\n",
       "         [ 0.0119,  0.0018,  0.0049,  ..., -0.0058, -0.0007, -0.0299],\n",
       "         [ 0.0214,  0.0084,  0.0004,  ...,  0.0058, -0.0172, -0.0192]]),\n",
       " 'llm.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight': tensor([[-0.0074, -0.0033, -0.0248,  ...,  0.0014, -0.0248,  0.0026],\n",
       "         [ 0.0076, -0.0155, -0.0010,  ..., -0.0016, -0.0091,  0.0177],\n",
       "         [-0.0177, -0.0174,  0.0003,  ...,  0.0075, -0.0088,  0.0078],\n",
       "         ...,\n",
       "         [ 0.0281, -0.0089, -0.0013,  ...,  0.0117,  0.0078,  0.0221],\n",
       "         [-0.0018,  0.0035,  0.0152,  ..., -0.0061,  0.0102, -0.0100],\n",
       "         [ 0.0230, -0.0017, -0.0148,  ...,  0.0209,  0.0216, -0.0099]]),\n",
       " 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0280,  0.0058,  0.0055,  ...,  0.0188, -0.0167,  0.0369],\n",
       "         [-0.0491,  0.0116,  0.0019,  ..., -0.0041,  0.0194, -0.0189],\n",
       "         [ 0.0055, -0.0123,  0.0213,  ..., -0.0024,  0.0124, -0.0288],\n",
       "         ...,\n",
       "         [ 0.0289, -0.0295,  0.0051,  ..., -0.0094,  0.0030, -0.0168],\n",
       "         [-0.0252,  0.0067,  0.0195,  ...,  0.0043, -0.0135, -0.0030],\n",
       "         [-0.0084,  0.0096, -0.0202,  ..., -0.0153, -0.0249, -0.0443]]),\n",
       " 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight': tensor([[-0.0130, -0.0029, -0.0003,  ...,  0.0169, -0.0225, -0.0064],\n",
       "         [ 0.0046,  0.0142, -0.0122,  ..., -0.0022,  0.0171, -0.0009],\n",
       "         [-0.0012,  0.0052, -0.0049,  ...,  0.0101,  0.0091,  0.0107],\n",
       "         ...,\n",
       "         [ 0.0003,  0.0079,  0.0015,  ...,  0.0022,  0.0211, -0.0155],\n",
       "         [ 0.0109,  0.0136, -0.0055,  ..., -0.0162, -0.0081, -0.0092],\n",
       "         [-0.0063,  0.0004,  0.0104,  ...,  0.0097, -0.0083,  0.0145]]),\n",
       " 'llm.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight': tensor([[ 0.0338, -0.0118, -0.0020,  ..., -0.0306, -0.0043, -0.0145],\n",
       "         [-0.0299, -0.0393, -0.0223,  ...,  0.0151, -0.0146,  0.0003],\n",
       "         [ 0.0089,  0.0199,  0.0318,  ...,  0.0127,  0.0148, -0.0139],\n",
       "         ...,\n",
       "         [-0.0130, -0.0308,  0.0204,  ..., -0.0003,  0.0053, -0.0116],\n",
       "         [ 0.0246,  0.0339, -0.0080,  ...,  0.0240,  0.0218,  0.0086],\n",
       "         [-0.0236, -0.0289,  0.0323,  ...,  0.0069,  0.0181,  0.0065]]),\n",
       " 'llm.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight': tensor([[ 1.1839e-02,  1.2627e-02,  5.0785e-03,  ..., -1.2757e-02,\n",
       "           2.6300e-02,  1.2432e-02],\n",
       "         [ 2.8718e-03, -2.9566e-02,  2.0423e-02,  ..., -1.4883e-02,\n",
       "           3.1971e-03, -2.4834e-02],\n",
       "         [ 3.4935e-03, -2.9984e-03, -9.0460e-03,  ..., -1.3391e-03,\n",
       "          -1.0094e-02, -1.4853e-02],\n",
       "         ...,\n",
       "         [ 1.6808e-03,  7.1381e-05,  2.3260e-03,  ...,  1.4020e-02,\n",
       "           8.1488e-03,  3.9929e-03],\n",
       "         [ 1.6042e-02, -3.5768e-03, -2.3487e-03,  ...,  2.3800e-02,\n",
       "           1.3284e-03,  2.7181e-03],\n",
       "         [ 2.3897e-02,  6.7264e-05,  9.3014e-03,  ..., -9.9032e-03,\n",
       "           1.3797e-02, -5.4736e-03]]),\n",
       " 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0018,  0.0166,  0.0115,  ..., -0.0106,  0.0047,  0.0136],\n",
       "         [-0.0083, -0.0102,  0.0307,  ...,  0.0122,  0.0165,  0.0086],\n",
       "         [ 0.0135, -0.0088,  0.0231,  ...,  0.0088, -0.0117,  0.0079],\n",
       "         ...,\n",
       "         [ 0.0146, -0.0211,  0.0161,  ..., -0.0103, -0.0039, -0.0373],\n",
       "         [-0.0136,  0.0102, -0.0128,  ...,  0.0106, -0.0086,  0.0236],\n",
       "         [-0.0143, -0.0178,  0.0043,  ...,  0.0274, -0.0158,  0.0098]]),\n",
       " 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0075,  0.0238,  0.0112,  ...,  0.0055, -0.0099,  0.0174],\n",
       "         [ 0.0148, -0.0056, -0.0097,  ...,  0.0089,  0.0095,  0.0053],\n",
       "         [-0.0014, -0.0230, -0.0050,  ..., -0.0024,  0.0136, -0.0022],\n",
       "         ...,\n",
       "         [-0.0029,  0.0041,  0.0165,  ..., -0.0241,  0.0006,  0.0049],\n",
       "         [-0.0063,  0.0002,  0.0090,  ..., -0.0148, -0.0129,  0.0119],\n",
       "         [-0.0047, -0.0045,  0.0004,  ...,  0.0043,  0.0080, -0.0064]]),\n",
       " 'llm.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight': tensor([[ 0.0319,  0.0091, -0.0091,  ...,  0.0171,  0.0374,  0.0039],\n",
       "         [ 0.0001,  0.0106,  0.0230,  ...,  0.0153,  0.0164,  0.0433],\n",
       "         [-0.0184, -0.0041,  0.0073,  ..., -0.0074, -0.0049, -0.0118],\n",
       "         ...,\n",
       "         [ 0.0185, -0.0275, -0.0147,  ...,  0.0303, -0.0324, -0.0104],\n",
       "         [ 0.0088,  0.0282, -0.0027,  ...,  0.0088,  0.0138,  0.0054],\n",
       "         [-0.0187, -0.0034,  0.0254,  ...,  0.0194,  0.0111, -0.0122]]),\n",
       " 'llm.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight': tensor([[-0.0085,  0.0093, -0.0103,  ...,  0.0272, -0.0111,  0.0176],\n",
       "         [-0.0207, -0.0278,  0.0220,  ...,  0.0140, -0.0247, -0.0131],\n",
       "         [-0.0043,  0.0105,  0.0014,  ..., -0.0037,  0.0014,  0.0088],\n",
       "         ...,\n",
       "         [-0.0122,  0.0198,  0.0191,  ..., -0.0151,  0.0062,  0.0052],\n",
       "         [ 0.0016, -0.0127,  0.0180,  ...,  0.0070,  0.0104, -0.0136],\n",
       "         [ 0.0066,  0.0010,  0.0104,  ...,  0.0015, -0.0073, -0.0071]]),\n",
       " 'llm.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight': tensor([[ 0.0070,  0.0084,  0.0288,  ...,  0.0231,  0.0108, -0.0078],\n",
       "         [ 0.0106, -0.0162,  0.0106,  ...,  0.0079, -0.0086, -0.0210],\n",
       "         [ 0.0073, -0.0071, -0.0347,  ..., -0.0006, -0.0324, -0.0213],\n",
       "         ...,\n",
       "         [-0.0218,  0.0138,  0.0484,  ...,  0.0029,  0.0064,  0.0447],\n",
       "         [-0.0288,  0.0240,  0.0337,  ..., -0.0003, -0.0016,  0.0314],\n",
       "         [-0.0234,  0.0077, -0.0137,  ...,  0.0091,  0.0124, -0.0148]]),\n",
       " 'llm.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight': tensor([[ 0.0281,  0.0123, -0.0207,  ...,  0.0023,  0.0170, -0.0182],\n",
       "         [ 0.0096,  0.0004, -0.0337,  ...,  0.0158,  0.0111,  0.0004],\n",
       "         [ 0.0049,  0.0183, -0.0293,  ...,  0.0027,  0.0018, -0.0056],\n",
       "         ...,\n",
       "         [ 0.0131,  0.0143,  0.0179,  ...,  0.0137,  0.0173, -0.0170],\n",
       "         [-0.0031,  0.0260,  0.0348,  ..., -0.0108,  0.0030,  0.0038],\n",
       "         [ 0.0084, -0.0273, -0.0045,  ...,  0.0238,  0.0183, -0.0133]]),\n",
       " 'llm.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight': tensor([[-0.0085,  0.0048,  0.0065,  ...,  0.0155, -0.0188,  0.0143],\n",
       "         [ 0.0257, -0.0083,  0.0057,  ...,  0.0280, -0.0090, -0.0030],\n",
       "         [ 0.0003, -0.0110, -0.0329,  ..., -0.0241,  0.0076,  0.0110],\n",
       "         ...,\n",
       "         [-0.0137,  0.0015,  0.0161,  ...,  0.0021,  0.0051, -0.0151],\n",
       "         [-0.0060, -0.0045, -0.0225,  ...,  0.0128, -0.0057, -0.0057],\n",
       "         [-0.0053,  0.0146, -0.0006,  ..., -0.0045, -0.0015, -0.0308]]),\n",
       " 'llm.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight': tensor([[-1.8466e-02,  1.6516e-02,  1.2195e-03,  ..., -2.9461e-03,\n",
       "          -1.8335e-02,  2.0719e-02],\n",
       "         [ 3.2644e-03, -9.2254e-03,  2.1660e-02,  ..., -2.9726e-03,\n",
       "           2.6959e-02,  1.4170e-02],\n",
       "         [-7.6854e-03,  8.0572e-03,  6.6801e-04,  ...,  2.1858e-02,\n",
       "           1.3405e-02, -6.1887e-03],\n",
       "         ...,\n",
       "         [-1.5925e-02,  1.5640e-02, -1.5998e-02,  ..., -8.2976e-03,\n",
       "          -4.3274e-03, -6.1230e-03],\n",
       "         [ 2.1747e-02,  1.4263e-03, -3.6723e-03,  ..., -2.4235e-02,\n",
       "          -7.6308e-03, -1.3262e-03],\n",
       "         [-5.8465e-03, -8.9680e-05,  1.8796e-02,  ...,  6.1713e-04,\n",
       "          -2.7852e-02, -1.1292e-02]]),\n",
       " 'llm.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight': tensor([[ 0.0021, -0.0160, -0.0091,  ..., -0.0035,  0.0040, -0.0059],\n",
       "         [ 0.0151, -0.0048,  0.0211,  ..., -0.0159, -0.0149,  0.0355],\n",
       "         [ 0.0083, -0.0143, -0.0023,  ..., -0.0002, -0.0028,  0.0100],\n",
       "         ...,\n",
       "         [-0.0177, -0.0080, -0.0032,  ...,  0.0024,  0.0404, -0.0080],\n",
       "         [-0.0038,  0.0072,  0.0053,  ..., -0.0029, -0.0093, -0.0137],\n",
       "         [-0.0104,  0.0059, -0.0029,  ...,  0.0085,  0.0075, -0.0088]]),\n",
       " 'llm.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight': tensor([[-0.0065,  0.0108, -0.0106,  ...,  0.0069,  0.0051, -0.0040],\n",
       "         [ 0.0057, -0.0134, -0.0159,  ..., -0.0163, -0.0051,  0.0022],\n",
       "         [-0.0011, -0.0031,  0.0083,  ...,  0.0023,  0.0125,  0.0103],\n",
       "         ...,\n",
       "         [ 0.0027, -0.0054, -0.0188,  ...,  0.0051, -0.0259, -0.0241],\n",
       "         [ 0.0059, -0.0032, -0.0172,  ...,  0.0096, -0.0038, -0.0210],\n",
       "         [-0.0080, -0.0117,  0.0130,  ...,  0.0123,  0.0187,  0.0090]]),\n",
       " 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0098,  0.0059, -0.0148,  ..., -0.0002, -0.0025, -0.0227],\n",
       "         [-0.0110,  0.0073,  0.0291,  ...,  0.0028, -0.0238, -0.0009],\n",
       "         [-0.0282,  0.0425,  0.0362,  ...,  0.0243, -0.0173,  0.0070],\n",
       "         ...,\n",
       "         [ 0.0078,  0.0248, -0.0154,  ...,  0.0218, -0.0128,  0.0397],\n",
       "         [ 0.0103,  0.0073, -0.0231,  ..., -0.0049,  0.0124, -0.0261],\n",
       "         [-0.0250,  0.0333,  0.0229,  ...,  0.0137, -0.0216,  0.0058]]),\n",
       " 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0089, -0.0061, -0.0012,  ...,  0.0068,  0.0005, -0.0252],\n",
       "         [ 0.0130, -0.0106, -0.0032,  ..., -0.0164,  0.0132,  0.0003],\n",
       "         [-0.0174,  0.0150,  0.0288,  ...,  0.0076, -0.0138,  0.0262],\n",
       "         ...,\n",
       "         [-0.0215,  0.0174,  0.0167,  ...,  0.0215, -0.0065,  0.0053],\n",
       "         [-0.0077,  0.0072,  0.0099,  ...,  0.0088, -0.0046,  0.0023],\n",
       "         [-0.0095,  0.0110, -0.0195,  ...,  0.0214, -0.0036, -0.0025]]),\n",
       " 'llm.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight': tensor([[-0.0020,  0.0193,  0.0202,  ...,  0.0103, -0.0418,  0.0195],\n",
       "         [ 0.0398,  0.0193,  0.0028,  ..., -0.0071, -0.0522, -0.0010],\n",
       "         [ 0.0039, -0.0154,  0.0245,  ...,  0.0053, -0.0079,  0.0312],\n",
       "         ...,\n",
       "         [-0.0152,  0.0081,  0.0079,  ...,  0.0124,  0.0087,  0.0110],\n",
       "         [-0.0002,  0.0183, -0.0035,  ...,  0.0195,  0.0196, -0.0033],\n",
       "         [ 0.0140, -0.0446,  0.0188,  ..., -0.0094,  0.0434, -0.0086]]),\n",
       " 'llm.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight': tensor([[-0.0020, -0.0019,  0.0151,  ...,  0.0014, -0.0074, -0.0019],\n",
       "         [ 0.0011, -0.0142, -0.0005,  ..., -0.0049, -0.0005, -0.0053],\n",
       "         [-0.0003, -0.0197, -0.0060,  ..., -0.0112,  0.0067, -0.0087],\n",
       "         ...,\n",
       "         [-0.0115,  0.0021, -0.0093,  ...,  0.0223,  0.0170,  0.0097],\n",
       "         [ 0.0060,  0.0022,  0.0021,  ...,  0.0209,  0.0485,  0.0375],\n",
       "         [ 0.0398,  0.0360,  0.0484,  ..., -0.0164, -0.0093, -0.0226]]),\n",
       " 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0208, -0.0132,  0.0024,  ...,  0.0047, -0.0033, -0.0023],\n",
       "         [-0.0024, -0.0056, -0.0082,  ...,  0.0065, -0.0078, -0.0058],\n",
       "         [-0.0045, -0.0103, -0.0093,  ...,  0.0143, -0.0171,  0.0213],\n",
       "         ...,\n",
       "         [-0.0214,  0.0272,  0.0060,  ...,  0.0088, -0.0023,  0.0165],\n",
       "         [-0.0002, -0.0174, -0.0171,  ..., -0.0108,  0.0067, -0.0213],\n",
       "         [ 0.0189,  0.0036,  0.0211,  ..., -0.0158,  0.0277, -0.0155]]),\n",
       " 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0126, -0.0157,  0.0187,  ..., -0.0355, -0.0037,  0.0248],\n",
       "         [-0.0130,  0.0066, -0.0046,  ..., -0.0075,  0.0090,  0.0069],\n",
       "         [-0.0137,  0.0198, -0.0129,  ..., -0.0006, -0.0180, -0.0132],\n",
       "         ...,\n",
       "         [-0.0025,  0.0027,  0.0104,  ..., -0.0140,  0.0005,  0.0154],\n",
       "         [ 0.0065,  0.0077, -0.0087,  ...,  0.0092,  0.0064,  0.0044],\n",
       "         [ 0.0074, -0.0115,  0.0168,  ..., -0.0129, -0.0049,  0.0085]]),\n",
       " 'llm.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight': tensor([[-0.0016, -0.0103, -0.0194,  ...,  0.0104,  0.0126, -0.0002],\n",
       "         [-0.0144,  0.0054, -0.0031,  ...,  0.0184, -0.0141,  0.0321],\n",
       "         [-0.0008,  0.0164,  0.0029,  ...,  0.0107,  0.0061,  0.0082],\n",
       "         ...,\n",
       "         [-0.0219,  0.0089,  0.0162,  ..., -0.0011,  0.0017,  0.0021],\n",
       "         [-0.0102,  0.0158, -0.0089,  ...,  0.0199,  0.0075,  0.0181],\n",
       "         [ 0.0303, -0.0216,  0.0051,  ..., -0.0253,  0.0024,  0.0026]]),\n",
       " 'llm.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight': tensor([[ 0.0097,  0.0014,  0.0238,  ...,  0.0130, -0.0032,  0.0059],\n",
       "         [-0.0074,  0.0122, -0.0041,  ...,  0.0161,  0.0047, -0.0034],\n",
       "         [-0.0215, -0.0042,  0.0014,  ...,  0.0158, -0.0013,  0.0075],\n",
       "         ...,\n",
       "         [ 0.0102,  0.0010, -0.0054,  ...,  0.0110, -0.0042,  0.0027],\n",
       "         [ 0.0088,  0.0048, -0.0046,  ..., -0.0005,  0.0060,  0.0157],\n",
       "         [-0.0085, -0.0099,  0.0106,  ...,  0.0029,  0.0070, -0.0037]]),\n",
       " 'llm.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight': tensor([[ 0.0277, -0.0183,  0.0225,  ..., -0.0300, -0.0059,  0.0288],\n",
       "         [ 0.0412,  0.0182, -0.0340,  ..., -0.0006, -0.0114,  0.0212],\n",
       "         [-0.0259,  0.0004, -0.0218,  ...,  0.0371,  0.0242,  0.0217],\n",
       "         ...,\n",
       "         [-0.0045,  0.0078,  0.0325,  ..., -0.0023,  0.0131,  0.0143],\n",
       "         [ 0.0104,  0.0175,  0.0164,  ...,  0.0257, -0.0024,  0.0141],\n",
       "         [-0.0031,  0.0299,  0.0169,  ...,  0.0135,  0.0265,  0.0269]]),\n",
       " 'llm.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight': tensor([[-7.6634e-03,  4.7082e-03,  2.6903e-02,  ...,  3.4671e-02,\n",
       "          -2.1199e-03, -8.8932e-03],\n",
       "         [ 7.2828e-04,  2.1485e-02,  1.6150e-02,  ...,  2.5043e-02,\n",
       "          -1.8172e-03, -1.8365e-02],\n",
       "         [ 1.3839e-02,  2.5956e-02, -1.4406e-02,  ..., -2.0840e-02,\n",
       "           4.4426e-04,  2.4473e-02],\n",
       "         ...,\n",
       "         [-2.5677e-02,  3.4495e-03, -1.3540e-02,  ...,  1.3054e-02,\n",
       "           8.2858e-03, -5.9412e-03],\n",
       "         [-8.3200e-03, -1.1343e-02,  5.1791e-03,  ..., -4.0249e-03,\n",
       "          -7.3944e-03,  2.8160e-05],\n",
       "         [ 7.6615e-03, -8.8250e-04, -5.4770e-03,  ...,  9.5058e-03,\n",
       "           8.3832e-03,  7.2094e-03]]),\n",
       " 'llm.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight': tensor([[-0.0164, -0.0087,  0.0054,  ..., -0.0252, -0.0199,  0.0014],\n",
       "         [ 0.0108,  0.0029,  0.0158,  ..., -0.0258, -0.0208,  0.0087],\n",
       "         [ 0.0261,  0.0067, -0.0121,  ..., -0.0268, -0.0176, -0.0169],\n",
       "         ...,\n",
       "         [-0.0217, -0.0055,  0.0181,  ..., -0.0007, -0.0031,  0.0211],\n",
       "         [ 0.0117,  0.0145,  0.0132,  ..., -0.0061,  0.0274,  0.0259],\n",
       "         [-0.0133, -0.0255, -0.0034,  ..., -0.0232, -0.0020, -0.0014]]),\n",
       " 'llm.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight': tensor([[-0.0074,  0.0131, -0.0003,  ...,  0.0185,  0.0050,  0.0039],\n",
       "         [ 0.0114,  0.0059, -0.0119,  ...,  0.0034, -0.0047, -0.0064],\n",
       "         [-0.0036,  0.0051,  0.0098,  ...,  0.0328,  0.0232,  0.0020],\n",
       "         ...,\n",
       "         [-0.0033,  0.0076,  0.0021,  ..., -0.0021, -0.0084,  0.0028],\n",
       "         [-0.0131,  0.0080, -0.0036,  ..., -0.0064,  0.0056, -0.0255],\n",
       "         [ 0.0143, -0.0192, -0.0479,  ...,  0.0179, -0.0030, -0.0058]]),\n",
       " 'llm.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight': tensor([[-0.0275,  0.0012,  0.0383,  ..., -0.0236, -0.0074,  0.0092],\n",
       "         [ 0.0101, -0.0126, -0.0056,  ...,  0.0081,  0.0228,  0.0067],\n",
       "         [ 0.0064, -0.0097, -0.0213,  ..., -0.0107, -0.0214, -0.0095],\n",
       "         ...,\n",
       "         [ 0.0017,  0.0172, -0.0155,  ..., -0.0145, -0.0041, -0.0116],\n",
       "         [ 0.0125,  0.0138,  0.0022,  ..., -0.0029, -0.0019, -0.0252],\n",
       "         [ 0.0080,  0.0006,  0.0058,  ...,  0.0061, -0.0081,  0.0136]]),\n",
       " 'llm.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight': tensor([[-0.0012, -0.0064,  0.0137,  ...,  0.0074,  0.0145, -0.0240],\n",
       "         [-0.0028, -0.0161,  0.0226,  ..., -0.0082,  0.0050, -0.0152],\n",
       "         [-0.0006, -0.0051, -0.0138,  ...,  0.0091,  0.0091, -0.0037],\n",
       "         ...,\n",
       "         [ 0.0127, -0.0019, -0.0051,  ...,  0.0026,  0.0150, -0.0045],\n",
       "         [ 0.0049, -0.0095,  0.0036,  ...,  0.0232,  0.0035, -0.0011],\n",
       "         [ 0.0014, -0.0080, -0.0138,  ..., -0.0081,  0.0031, -0.0173]]),\n",
       " 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0149,  0.0100, -0.0036,  ...,  0.0014,  0.0021, -0.0175],\n",
       "         [-0.0218,  0.0028, -0.0196,  ...,  0.0064,  0.0042,  0.0173],\n",
       "         [-0.0024, -0.0034,  0.0075,  ..., -0.0272, -0.0221, -0.0292],\n",
       "         ...,\n",
       "         [-0.0343,  0.0141, -0.0327,  ..., -0.0058,  0.0061,  0.0012],\n",
       "         [-0.0258,  0.0014, -0.0128,  ...,  0.0209,  0.0140,  0.0072],\n",
       "         [ 0.0044,  0.0026,  0.0063,  ...,  0.0125, -0.0265, -0.0096]]),\n",
       " 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0190, -0.0308,  0.0385,  ...,  0.0149, -0.0409,  0.0067],\n",
       "         [-0.0212,  0.0154, -0.0261,  ...,  0.0026,  0.0170, -0.0085],\n",
       "         [ 0.0181,  0.0050, -0.0018,  ..., -0.0237,  0.0006,  0.0114],\n",
       "         ...,\n",
       "         [ 0.0176, -0.0037,  0.0260,  ..., -0.0302, -0.0014, -0.0161],\n",
       "         [-0.0028,  0.0150,  0.0021,  ..., -0.0155,  0.0203,  0.0009],\n",
       "         [-0.0013,  0.0133, -0.0098,  ...,  0.0069,  0.0255, -0.0063]]),\n",
       " 'llm.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight': tensor([[ 0.0104,  0.0091, -0.0421,  ..., -0.0010,  0.0202,  0.0099],\n",
       "         [-0.0063,  0.0412, -0.0242,  ...,  0.0005, -0.0112,  0.0206],\n",
       "         [ 0.0155, -0.0404, -0.0084,  ...,  0.0026,  0.0080, -0.0062],\n",
       "         ...,\n",
       "         [ 0.0403,  0.0050, -0.0134,  ...,  0.0086,  0.0515,  0.0303],\n",
       "         [ 0.0172,  0.0224,  0.0240,  ..., -0.0246,  0.0148, -0.0083],\n",
       "         [-0.0194,  0.0255,  0.0005,  ...,  0.0221, -0.0238, -0.0214]]),\n",
       " 'llm.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight': tensor([[-0.0013,  0.0653, -0.0140,  ..., -0.0376,  0.0130,  0.0116],\n",
       "         [ 0.0143,  0.0177, -0.0064,  ...,  0.0189, -0.0086, -0.0068],\n",
       "         [ 0.0065, -0.0371,  0.0161,  ...,  0.0480, -0.0107, -0.0227],\n",
       "         ...,\n",
       "         [ 0.0286,  0.0017,  0.0012,  ...,  0.0174, -0.0033, -0.0035],\n",
       "         [ 0.0054,  0.0033,  0.0129,  ...,  0.0115,  0.0036, -0.0182],\n",
       "         [-0.0081, -0.0078, -0.0038,  ..., -0.0068, -0.0051,  0.0128]]),\n",
       " 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0159, -0.0079,  0.0145,  ..., -0.0052, -0.0174,  0.0014],\n",
       "         [-0.0061, -0.0085,  0.0224,  ..., -0.0294,  0.0054,  0.0100],\n",
       "         [-0.0166, -0.0276, -0.0275,  ...,  0.0021,  0.0048,  0.0157],\n",
       "         ...,\n",
       "         [-0.0031,  0.0108,  0.0163,  ...,  0.0472, -0.0031, -0.0194],\n",
       "         [ 0.0169, -0.0112, -0.0112,  ..., -0.0273,  0.0069, -0.0281],\n",
       "         [ 0.0064, -0.0219, -0.0002,  ...,  0.0252, -0.0424,  0.0200]]),\n",
       " 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0135,  0.0073, -0.0157,  ...,  0.0015,  0.0074, -0.0129],\n",
       "         [ 0.0237, -0.0138,  0.0082,  ...,  0.0159,  0.0024,  0.0100],\n",
       "         [-0.0169,  0.0040, -0.0066,  ...,  0.0082,  0.0153, -0.0125],\n",
       "         ...,\n",
       "         [-0.0249,  0.0193, -0.0037,  ...,  0.0125,  0.0273,  0.0053],\n",
       "         [-0.0061, -0.0165, -0.0136,  ..., -0.0188, -0.0018,  0.0101],\n",
       "         [-0.0043,  0.0145,  0.0114,  ..., -0.0103,  0.0007,  0.0026]]),\n",
       " 'llm.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight': tensor([[ 0.0473, -0.0015, -0.0153,  ..., -0.0073, -0.0087,  0.0024],\n",
       "         [ 0.0062,  0.0208, -0.0012,  ...,  0.0142, -0.0044,  0.0324],\n",
       "         [ 0.0079,  0.0160,  0.0170,  ..., -0.0154, -0.0005, -0.0129],\n",
       "         ...,\n",
       "         [-0.0322,  0.0119,  0.0178,  ...,  0.0013, -0.0194, -0.0175],\n",
       "         [-0.0149,  0.0333,  0.0116,  ...,  0.0092,  0.0055,  0.0174],\n",
       "         [-0.0329,  0.0182, -0.0129,  ...,  0.0021, -0.0027,  0.0036]]),\n",
       " 'llm.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight': tensor([[ 0.0040,  0.0134, -0.0060,  ...,  0.0022,  0.0127,  0.0185],\n",
       "         [ 0.0037, -0.0109,  0.0014,  ..., -0.0214,  0.0199,  0.0070],\n",
       "         [-0.0067, -0.0167,  0.0157,  ...,  0.0109, -0.0034, -0.0153],\n",
       "         ...,\n",
       "         [-0.0138,  0.0230, -0.0214,  ..., -0.0142,  0.0020,  0.0246],\n",
       "         [ 0.0018, -0.0113, -0.0091,  ...,  0.0001, -0.0074, -0.0080],\n",
       "         [ 0.0042, -0.0040,  0.0310,  ..., -0.0182,  0.0049, -0.0041]]),\n",
       " 'llm.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight': tensor([[-0.0052, -0.0190,  0.0075,  ..., -0.0046,  0.0162,  0.0152],\n",
       "         [ 0.0152,  0.0007,  0.0302,  ..., -0.0091,  0.0096, -0.0178],\n",
       "         [ 0.0089,  0.0163,  0.0637,  ..., -0.0203,  0.0077,  0.0147],\n",
       "         ...,\n",
       "         [-0.0157,  0.0219,  0.0119,  ..., -0.0127, -0.0262, -0.0096],\n",
       "         [-0.0251, -0.0065, -0.0193,  ...,  0.0174,  0.0109,  0.0091],\n",
       "         [ 0.0154, -0.0285, -0.0147,  ...,  0.0313, -0.0084,  0.0122]]),\n",
       " 'llm.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight': tensor([[-3.4149e-02, -3.9088e-02, -3.2573e-02,  ...,  2.2733e-02,\n",
       "          -1.9034e-02,  1.4267e-02],\n",
       "         [-4.5159e-03,  5.8046e-03, -1.5562e-03,  ..., -6.1524e-03,\n",
       "           2.0456e-02,  2.1707e-02],\n",
       "         [-1.3807e-02, -2.3728e-03,  6.4445e-04,  ..., -2.0560e-02,\n",
       "           8.4985e-03,  2.5920e-03],\n",
       "         ...,\n",
       "         [ 2.2946e-02, -1.0852e-02, -6.7839e-03,  ...,  2.3889e-02,\n",
       "          -4.0669e-03,  2.4028e-02],\n",
       "         [-3.9570e-03,  5.3407e-03, -7.1481e-05,  ..., -5.2724e-03,\n",
       "           5.2631e-03,  3.9212e-03],\n",
       "         [ 3.6678e-02,  3.8640e-02,  3.6027e-02,  ..., -2.8744e-02,\n",
       "           3.5384e-02,  6.2690e-03]]),\n",
       " 'llm.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight': tensor([[ 0.0241,  0.0008,  0.0057,  ..., -0.0035, -0.0055,  0.0220],\n",
       "         [ 0.0205, -0.0051, -0.0260,  ...,  0.0261, -0.0061, -0.0160],\n",
       "         [ 0.0028,  0.0197, -0.0350,  ..., -0.0027,  0.0207,  0.0081],\n",
       "         ...,\n",
       "         [ 0.0253, -0.0123, -0.0103,  ..., -0.0043, -0.0052, -0.0081],\n",
       "         [ 0.0255,  0.0050, -0.0189,  ..., -0.0276, -0.0036, -0.0002],\n",
       "         [-0.0003, -0.0093, -0.0243,  ...,  0.0163,  0.0308, -0.0084]]),\n",
       " 'llm.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight': tensor([[ 2.1387e-02,  7.3709e-03, -3.7826e-04,  ..., -1.9466e-02,\n",
       "          -1.6198e-02,  1.7774e-03],\n",
       "         [-1.1939e-02, -1.1154e-02,  6.2392e-03,  ...,  8.4227e-03,\n",
       "           5.6816e-03,  6.3113e-03],\n",
       "         [ 5.9941e-03,  4.5820e-03,  1.6138e-02,  ..., -4.6760e-03,\n",
       "          -2.7295e-02, -1.5203e-02],\n",
       "         ...,\n",
       "         [ 7.1494e-03,  7.7078e-03,  9.5203e-03,  ...,  1.1833e-02,\n",
       "           1.6362e-02,  1.6649e-02],\n",
       "         [-1.0768e-02,  8.1351e-05,  9.3818e-03,  ...,  1.5205e-02,\n",
       "           4.2823e-03,  1.0413e-02],\n",
       "         [ 2.0459e-02,  3.5155e-03,  6.7268e-03,  ..., -2.0695e-03,\n",
       "           1.6856e-04, -4.0865e-03]]),\n",
       " 'llm.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight': tensor([[ 0.0065, -0.0017,  0.0256,  ...,  0.0010,  0.0150,  0.0068],\n",
       "         [ 0.0040,  0.0134,  0.0041,  ..., -0.0165,  0.0175,  0.0065],\n",
       "         [ 0.0249, -0.0110,  0.0199,  ...,  0.0339, -0.0072, -0.0021],\n",
       "         ...,\n",
       "         [-0.0247, -0.0021,  0.0099,  ..., -0.0157,  0.0235, -0.0037],\n",
       "         [ 0.0235,  0.0131,  0.0136,  ..., -0.0048, -0.0139, -0.0114],\n",
       "         [ 0.0163,  0.0106,  0.0007,  ..., -0.0125, -0.0028, -0.0012]]),\n",
       " 'llm.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight': tensor([[-0.0198, -0.0162, -0.0091,  ..., -0.0014, -0.0019, -0.0210],\n",
       "         [-0.0236,  0.0079, -0.0132,  ..., -0.0179, -0.0245, -0.0093],\n",
       "         [ 0.0089, -0.0087,  0.0080,  ...,  0.0160, -0.0043,  0.0009],\n",
       "         ...,\n",
       "         [-0.0025,  0.0018, -0.0098,  ..., -0.0058, -0.0129,  0.0120],\n",
       "         [ 0.0068,  0.0008, -0.0016,  ..., -0.0095,  0.0063, -0.0054],\n",
       "         [-0.0072,  0.0045, -0.0020,  ..., -0.0145, -0.0086, -0.0021]]),\n",
       " 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0174, -0.0047,  0.0026,  ..., -0.0234,  0.0066,  0.0039],\n",
       "         [ 0.0134,  0.0106,  0.0026,  ...,  0.0307, -0.0041,  0.0284],\n",
       "         [-0.0341,  0.0042,  0.0096,  ...,  0.0155,  0.0309,  0.0107],\n",
       "         ...,\n",
       "         [-0.0009,  0.0070,  0.0041,  ..., -0.0281, -0.0019, -0.0219],\n",
       "         [ 0.0136, -0.0043,  0.0084,  ...,  0.0145, -0.0228, -0.0062],\n",
       "         [-0.0156, -0.0207, -0.0384,  ...,  0.0034, -0.0024,  0.0461]]),\n",
       " 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0106,  0.0257,  0.0108,  ..., -0.0018,  0.0156,  0.0094],\n",
       "         [ 0.0003, -0.0312,  0.0141,  ..., -0.0091, -0.0048, -0.0053],\n",
       "         [ 0.0096, -0.0031, -0.0121,  ...,  0.0027,  0.0165,  0.0260],\n",
       "         ...,\n",
       "         [ 0.0007, -0.0147, -0.0074,  ...,  0.0061,  0.0061,  0.0082],\n",
       "         [ 0.0056, -0.0029,  0.0046,  ..., -0.0059,  0.0054,  0.0148],\n",
       "         [ 0.0004, -0.0045, -0.0030,  ..., -0.0045, -0.0035,  0.0131]]),\n",
       " 'llm.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight': tensor([[-1.4671e-02, -3.8321e-03,  3.2903e-03,  ..., -1.4183e-02,\n",
       "           2.4672e-02,  1.9775e-02],\n",
       "         [-1.3645e-02, -5.9574e-03,  1.6670e-02,  ..., -1.9976e-02,\n",
       "           1.7889e-02, -6.6852e-03],\n",
       "         [-1.8482e-02,  5.5592e-03, -2.8426e-02,  ..., -6.8309e-04,\n",
       "          -2.7378e-02,  3.2406e-03],\n",
       "         ...,\n",
       "         [ 1.8950e-02, -1.9126e-03, -7.7874e-03,  ..., -1.0488e-02,\n",
       "          -2.6480e-02,  3.8204e-03],\n",
       "         [-9.8430e-05,  1.3756e-02, -2.3124e-02,  ..., -3.4432e-02,\n",
       "          -1.2683e-02, -5.9312e-03],\n",
       "         [-4.6559e-03, -7.6521e-03, -1.4393e-02,  ...,  3.3070e-02,\n",
       "          -1.8331e-02,  2.0699e-02]]),\n",
       " 'llm.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight': tensor([[-0.0125,  0.0064, -0.0061,  ...,  0.0050, -0.0138, -0.0048],\n",
       "         [ 0.0318,  0.0103, -0.0081,  ..., -0.0034, -0.0251,  0.0022],\n",
       "         [ 0.0265, -0.0130,  0.0220,  ..., -0.0159,  0.0047,  0.0094],\n",
       "         ...,\n",
       "         [ 0.0008,  0.0086, -0.0013,  ...,  0.0085, -0.0059, -0.0081],\n",
       "         [ 0.0101, -0.0075,  0.0082,  ..., -0.0101, -0.0094,  0.0113],\n",
       "         [-0.0002,  0.0015,  0.0013,  ..., -0.0018, -0.0031, -0.0012]]),\n",
       " 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0367, -0.0035,  0.0027,  ...,  0.0016, -0.0171,  0.0225],\n",
       "         [-0.0015, -0.0141,  0.0103,  ..., -0.0218, -0.0049, -0.0274],\n",
       "         [-0.0077, -0.0151,  0.0120,  ..., -0.0076,  0.0123, -0.0350],\n",
       "         ...,\n",
       "         [-0.0050, -0.0075,  0.0179,  ..., -0.0102,  0.0079,  0.0236],\n",
       "         [-0.0151,  0.0200,  0.0263,  ...,  0.0209,  0.0043,  0.0186],\n",
       "         [-0.0159, -0.0102,  0.0126,  ...,  0.0127,  0.0124, -0.0008]]),\n",
       " 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0014,  0.0108,  0.0032,  ..., -0.0074, -0.0023,  0.0058],\n",
       "         [-0.0105,  0.0118,  0.0232,  ..., -0.0100, -0.0155,  0.0139],\n",
       "         [ 0.0056, -0.0068, -0.0173,  ..., -0.0058, -0.0093,  0.0098],\n",
       "         ...,\n",
       "         [ 0.0011,  0.0010,  0.0166,  ...,  0.0064, -0.0089, -0.0152],\n",
       "         [ 0.0021,  0.0191, -0.0106,  ...,  0.0114,  0.0012,  0.0144],\n",
       "         [-0.0042, -0.0070,  0.0039,  ..., -0.0048,  0.0100,  0.0011]]),\n",
       " 'llm.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight': tensor([[ 0.0103,  0.0035,  0.0115,  ..., -0.0149,  0.0198, -0.0148],\n",
       "         [ 0.0095,  0.0108,  0.0082,  ..., -0.0081, -0.0020, -0.0041],\n",
       "         [ 0.0024,  0.0016,  0.0022,  ..., -0.0182, -0.0150,  0.0390],\n",
       "         ...,\n",
       "         [-0.0283,  0.0151,  0.0169,  ..., -0.0004, -0.0064,  0.0009],\n",
       "         [-0.0057, -0.0216, -0.0127,  ..., -0.0196, -0.0039,  0.0130],\n",
       "         [ 0.0007,  0.0229, -0.0027,  ..., -0.0249, -0.0083, -0.0054]]),\n",
       " 'llm.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight': tensor([[-0.0074,  0.0157,  0.0122,  ...,  0.0172,  0.0083, -0.0011],\n",
       "         [ 0.0261, -0.0167, -0.0115,  ...,  0.0054,  0.0197, -0.0014],\n",
       "         [ 0.0028, -0.0006,  0.0039,  ..., -0.0042,  0.0032, -0.0038],\n",
       "         ...,\n",
       "         [-0.0003,  0.0124, -0.0021,  ...,  0.0039,  0.0126, -0.0102],\n",
       "         [ 0.0012, -0.0046,  0.0022,  ...,  0.0063,  0.0006, -0.0110],\n",
       "         [-0.0039, -0.0191, -0.0091,  ...,  0.0043, -0.0111,  0.0069]]),\n",
       " 'llm.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight': tensor([[ 0.0081,  0.0057, -0.0059,  ...,  0.0130,  0.0112,  0.0119],\n",
       "         [ 0.0100,  0.0177, -0.0280,  ...,  0.0300, -0.0018,  0.0165],\n",
       "         [-0.0241, -0.0156, -0.0066,  ..., -0.0354,  0.0070, -0.0259],\n",
       "         ...,\n",
       "         [-0.0269,  0.0256, -0.0239,  ...,  0.0092,  0.0356, -0.0279],\n",
       "         [-0.0196, -0.0238, -0.0197,  ..., -0.0157,  0.0322,  0.0083],\n",
       "         [ 0.0103,  0.0286, -0.0202,  ..., -0.0154,  0.0197, -0.0081]]),\n",
       " 'llm.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight': tensor([[-0.0108,  0.0115, -0.0028,  ...,  0.0129,  0.0159,  0.0354],\n",
       "         [-0.0053, -0.0128, -0.0004,  ..., -0.0114, -0.0015, -0.0079],\n",
       "         [-0.0275,  0.0147,  0.0136,  ..., -0.0064, -0.0023,  0.0075],\n",
       "         ...,\n",
       "         [-0.0085,  0.0119, -0.0108,  ...,  0.0335, -0.0112,  0.0200],\n",
       "         [ 0.0058, -0.0019,  0.0081,  ..., -0.0168,  0.0030,  0.0083],\n",
       "         [ 0.0130,  0.0199,  0.0071,  ...,  0.0166, -0.0236,  0.0039]]),\n",
       " 'llm.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight': tensor([[ 0.0092,  0.0031,  0.0299,  ...,  0.0011, -0.0021, -0.0129],\n",
       "         [ 0.0013,  0.0101, -0.0103,  ...,  0.0014,  0.0332, -0.0223],\n",
       "         [ 0.0147,  0.0098,  0.0052,  ..., -0.0093,  0.0241,  0.0115],\n",
       "         ...,\n",
       "         [-0.0142,  0.0271,  0.0134,  ..., -0.0377, -0.0057,  0.0124],\n",
       "         [-0.0085, -0.0134,  0.0064,  ...,  0.0262,  0.0047, -0.0096],\n",
       "         [-0.0041, -0.0313, -0.0303,  ...,  0.0037, -0.0176,  0.0292]]),\n",
       " 'llm.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight': tensor([[ 0.0059,  0.0261,  0.0253,  ..., -0.0220,  0.0347, -0.0009],\n",
       "         [-0.0105,  0.0032,  0.0030,  ...,  0.0161,  0.0120,  0.0475],\n",
       "         [-0.0218, -0.0221, -0.0018,  ..., -0.0104,  0.0279,  0.0264],\n",
       "         ...,\n",
       "         [ 0.0256,  0.0272,  0.0315,  ...,  0.0139,  0.0116, -0.0275],\n",
       "         [ 0.0003, -0.0030, -0.0051,  ..., -0.0052,  0.0026, -0.0050],\n",
       "         [ 0.0249,  0.0261,  0.0213,  ..., -0.0035,  0.0010, -0.0121]]),\n",
       " 'llm.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight': tensor([[-0.0115, -0.0021, -0.0064,  ...,  0.0081,  0.0200, -0.0289],\n",
       "         [-0.0092,  0.0016, -0.0105,  ...,  0.0079, -0.0040,  0.0020],\n",
       "         [-0.0046, -0.0127, -0.0150,  ..., -0.0045,  0.0035, -0.0007],\n",
       "         ...,\n",
       "         [-0.0027, -0.0011,  0.0006,  ...,  0.0072,  0.0140,  0.0006],\n",
       "         [-0.0076,  0.0064,  0.0016,  ...,  0.0014,  0.0202,  0.0028],\n",
       "         [ 0.0052,  0.0007,  0.0040,  ..., -0.0010,  0.0111, -0.0158]]),\n",
       " 'llm.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight': tensor([[-0.0052,  0.0079,  0.0123,  ..., -0.0074, -0.0197, -0.0128],\n",
       "         [-0.0129,  0.0091,  0.0009,  ..., -0.0066, -0.0211, -0.0091],\n",
       "         [ 0.0110,  0.0002,  0.0011,  ..., -0.0144, -0.0104, -0.0091],\n",
       "         ...,\n",
       "         [-0.0035,  0.0074,  0.0129,  ...,  0.0069,  0.0008, -0.0096],\n",
       "         [-0.0152,  0.0039, -0.0017,  ..., -0.0276, -0.0153, -0.0039],\n",
       "         [-0.0042, -0.0103, -0.0174,  ...,  0.0103,  0.0077, -0.0082]]),\n",
       " 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0189, -0.0052,  0.0044,  ...,  0.0094,  0.0013,  0.0255],\n",
       "         [ 0.0178, -0.0066, -0.0222,  ..., -0.0077,  0.0494, -0.0325],\n",
       "         [ 0.0008, -0.0297,  0.0124,  ..., -0.0085, -0.0116,  0.0175],\n",
       "         ...,\n",
       "         [ 0.0126, -0.0359,  0.0175,  ..., -0.0127,  0.0129,  0.0174],\n",
       "         [-0.0116,  0.0055,  0.0017,  ..., -0.0437,  0.0039,  0.0187],\n",
       "         [ 0.0158,  0.0269, -0.0107,  ..., -0.0248,  0.0210, -0.0233]]),\n",
       " 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight': tensor([[-0.0079, -0.0046, -0.0175,  ..., -0.0103, -0.0403, -0.0063],\n",
       "         [ 0.0265, -0.0025,  0.0384,  ...,  0.0048,  0.0119, -0.0187],\n",
       "         [-0.0017,  0.0165, -0.0061,  ...,  0.0100, -0.0018,  0.0053],\n",
       "         ...,\n",
       "         [-0.0097, -0.0056, -0.0292,  ..., -0.0045, -0.0244, -0.0068],\n",
       "         [-0.0145,  0.0060,  0.0122,  ...,  0.0148, -0.0228,  0.0130],\n",
       "         [-0.0183,  0.0315, -0.0154,  ...,  0.0207, -0.0050,  0.0245]]),\n",
       " 'llm.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight': tensor([[-0.0133, -0.0172, -0.0220,  ..., -0.0078, -0.0158,  0.0106],\n",
       "         [-0.0185, -0.0103, -0.0143,  ...,  0.0079,  0.0349,  0.0094],\n",
       "         [-0.0031, -0.0104, -0.0080,  ...,  0.0089,  0.0066,  0.0161],\n",
       "         ...,\n",
       "         [ 0.0281, -0.0113, -0.0070,  ..., -0.0077, -0.0059, -0.0291],\n",
       "         [ 0.0079,  0.0148,  0.0045,  ..., -0.0145, -0.0037, -0.0262],\n",
       "         [-0.0283, -0.0003,  0.0116,  ...,  0.0136, -0.0015,  0.0116]]),\n",
       " 'llm.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight': tensor([[ 0.0107, -0.0049, -0.0003,  ..., -0.0112, -0.0240,  0.0054],\n",
       "         [-0.0066, -0.0125,  0.0109,  ...,  0.0019,  0.0036, -0.0030],\n",
       "         [ 0.0207, -0.0072,  0.0142,  ..., -0.0364, -0.0357,  0.0393],\n",
       "         ...,\n",
       "         [ 0.0116, -0.0054,  0.0097,  ...,  0.0019,  0.0008,  0.0016],\n",
       "         [-0.0206, -0.0018, -0.0074,  ...,  0.0075,  0.0074, -0.0171],\n",
       "         [-0.0075,  0.0093, -0.0154,  ...,  0.0001,  0.0153,  0.0065]]),\n",
       " 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0132, -0.0366, -0.0435,  ..., -0.0294, -0.0187,  0.0023],\n",
       "         [ 0.0031, -0.0172, -0.0064,  ...,  0.0373, -0.0046, -0.0006],\n",
       "         [ 0.0314, -0.0166, -0.0178,  ..., -0.0077,  0.0052,  0.0228],\n",
       "         ...,\n",
       "         [-0.0092, -0.0366, -0.0276,  ...,  0.0098,  0.0168, -0.0193],\n",
       "         [-0.0066, -0.0128,  0.0241,  ..., -0.0083, -0.0127,  0.0148],\n",
       "         [-0.0029, -0.0071,  0.0014,  ...,  0.0003, -0.0119,  0.0280]]),\n",
       " 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0167,  0.0157, -0.0067,  ..., -0.0036, -0.0039,  0.0010],\n",
       "         [-0.0057, -0.0121, -0.0002,  ..., -0.0216,  0.0041, -0.0157],\n",
       "         [ 0.0030,  0.0068,  0.0042,  ...,  0.0061,  0.0043, -0.0022],\n",
       "         ...,\n",
       "         [ 0.0013, -0.0156,  0.0102,  ...,  0.0141, -0.0107,  0.0018],\n",
       "         [-0.0029, -0.0030,  0.0104,  ..., -0.0151,  0.0025,  0.0016],\n",
       "         [-0.0019,  0.0093,  0.0067,  ..., -0.0030, -0.0077,  0.0065]]),\n",
       " 'llm.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight': tensor([[-0.0076,  0.0053,  0.0032,  ..., -0.0055, -0.0129, -0.0146],\n",
       "         [-0.0219,  0.0121,  0.0107,  ..., -0.0225,  0.0019,  0.0061],\n",
       "         [ 0.0058,  0.0058,  0.0044,  ...,  0.0003, -0.0042,  0.0006],\n",
       "         ...,\n",
       "         [ 0.0158, -0.0205,  0.0091,  ..., -0.0202,  0.0059,  0.0126],\n",
       "         [ 0.0021, -0.0019, -0.0064,  ..., -0.0144, -0.0056, -0.0062],\n",
       "         [ 0.0165, -0.0018,  0.0049,  ..., -0.0132,  0.0071,  0.0032]]),\n",
       " 'llm.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight': tensor([[ 0.0074, -0.0128, -0.0044,  ...,  0.0016,  0.0109,  0.0064],\n",
       "         [-0.0120,  0.0051, -0.0057,  ...,  0.0015, -0.0046,  0.0217],\n",
       "         [ 0.0100, -0.0060, -0.0033,  ..., -0.0070,  0.0136,  0.0082],\n",
       "         ...,\n",
       "         [-0.0063,  0.0045,  0.0100,  ...,  0.0168,  0.0052, -0.0231],\n",
       "         [-0.0059,  0.0004,  0.0019,  ...,  0.0169, -0.0094, -0.0079],\n",
       "         [-0.0007,  0.0040,  0.0098,  ...,  0.0153, -0.0072, -0.0086]]),\n",
       " 'llm.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight': tensor([[-0.0309,  0.0024, -0.0417,  ..., -0.0069,  0.0150, -0.0005],\n",
       "         [-0.0025,  0.0087,  0.0127,  ..., -0.0319, -0.0106, -0.0105],\n",
       "         [-0.0032,  0.0254, -0.0244,  ..., -0.0089,  0.0270,  0.0037],\n",
       "         ...,\n",
       "         [-0.0059, -0.0132, -0.0156,  ..., -0.0311, -0.0069,  0.0316],\n",
       "         [ 0.0434, -0.0131,  0.0090,  ..., -0.0023, -0.0182, -0.0249],\n",
       "         [-0.0121, -0.0090, -0.0426,  ..., -0.0007, -0.0090,  0.0401]]),\n",
       " 'llm.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight': tensor([[ 0.0084, -0.0095,  0.0303,  ...,  0.0009,  0.0178, -0.0141],\n",
       "         [ 0.0171,  0.0501,  0.0227,  ..., -0.0068,  0.0256,  0.0122],\n",
       "         [-0.0060,  0.0065,  0.0070,  ..., -0.0034, -0.0355,  0.0280],\n",
       "         ...,\n",
       "         [ 0.0016,  0.0087,  0.0092,  ...,  0.0102,  0.0032,  0.0002],\n",
       "         [-0.0013,  0.0008, -0.0044,  ...,  0.0086,  0.0029, -0.0130],\n",
       "         [ 0.0019,  0.0015, -0.0008,  ...,  0.0101,  0.0071,  0.0024]]),\n",
       " 'llm.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight': tensor([[-0.0460, -0.0317, -0.0258,  ..., -0.0031,  0.0065, -0.0137],\n",
       "         [-0.0196, -0.0058, -0.0125,  ..., -0.0044, -0.0011,  0.0074],\n",
       "         [-0.0145,  0.0541, -0.0081,  ..., -0.0035, -0.0044,  0.0262],\n",
       "         ...,\n",
       "         [ 0.0142, -0.0020,  0.0164,  ...,  0.0128, -0.0038,  0.0109],\n",
       "         [ 0.0154,  0.0074, -0.0113,  ...,  0.0120, -0.0035,  0.0066],\n",
       "         [-0.0126, -0.0132, -0.0239,  ...,  0.0041, -0.0134, -0.0017]]),\n",
       " 'llm.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight': tensor([[ 0.0080,  0.0035,  0.0144,  ...,  0.0170,  0.0003, -0.0133],\n",
       "         [-0.0161,  0.0182, -0.0082,  ...,  0.0014,  0.0020,  0.0172],\n",
       "         [-0.0137,  0.0126, -0.0130,  ..., -0.0245,  0.0110, -0.0156],\n",
       "         ...,\n",
       "         [-0.0092,  0.0058,  0.0086,  ...,  0.0070, -0.0214, -0.0108],\n",
       "         [-0.0011, -0.0013,  0.0058,  ..., -0.0157,  0.0025,  0.0110],\n",
       "         [ 0.0012, -0.0103,  0.0074,  ...,  0.0173,  0.0025,  0.0157]]),\n",
       " 'llm.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight': tensor([[ 0.0057, -0.0232,  0.0013,  ..., -0.0134,  0.0253,  0.0026],\n",
       "         [-0.0102, -0.0073, -0.0065,  ...,  0.0055, -0.0056, -0.0099],\n",
       "         [ 0.0003,  0.0042, -0.0148,  ..., -0.0128,  0.0130,  0.0142],\n",
       "         ...,\n",
       "         [ 0.0077, -0.0059, -0.0019,  ...,  0.0054, -0.0050,  0.0092],\n",
       "         [-0.0018,  0.0019, -0.0090,  ...,  0.0217, -0.0282,  0.0150],\n",
       "         [-0.0269, -0.0358,  0.0101,  ...,  0.0093, -0.0256,  0.0193]]),\n",
       " 'llm.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight': tensor([[-0.0122,  0.0041, -0.0089,  ...,  0.0093,  0.0294, -0.0142],\n",
       "         [ 0.0102, -0.0004,  0.0080,  ..., -0.0044, -0.0072,  0.0037],\n",
       "         [ 0.0213,  0.0044, -0.0086,  ...,  0.0071,  0.0089,  0.0078],\n",
       "         ...,\n",
       "         [-0.0197, -0.0038,  0.0247,  ..., -0.0113,  0.0219, -0.0017],\n",
       "         [ 0.0056, -0.0013, -0.0060,  ...,  0.0093,  0.0021,  0.0114],\n",
       "         [ 0.0020,  0.0045, -0.0074,  ..., -0.0055, -0.0240,  0.0046]]),\n",
       " 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0072,  0.0256, -0.0022,  ...,  0.0160, -0.0052, -0.0304],\n",
       "         [ 0.0200,  0.0020,  0.0223,  ...,  0.0140,  0.0043,  0.0016],\n",
       "         [ 0.0060, -0.0165, -0.0014,  ..., -0.0076,  0.0130, -0.0186],\n",
       "         ...,\n",
       "         [ 0.0411, -0.0308, -0.0299,  ..., -0.0219, -0.0071, -0.0020],\n",
       "         [-0.0405,  0.0324,  0.0199,  ..., -0.0092, -0.0054, -0.0396],\n",
       "         [-0.0117, -0.0108, -0.0222,  ...,  0.0192,  0.0198, -0.0013]]),\n",
       " 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0143,  0.0076,  0.0324,  ...,  0.0263, -0.0296,  0.0420],\n",
       "         [-0.0177,  0.0398, -0.0214,  ...,  0.0262, -0.0149, -0.0158],\n",
       "         [-0.0126, -0.0150,  0.0130,  ..., -0.0216,  0.0162, -0.0051],\n",
       "         ...,\n",
       "         [-0.0013,  0.0131,  0.0002,  ...,  0.0034,  0.0039, -0.0072],\n",
       "         [-0.0144,  0.0089, -0.0243,  ...,  0.0059,  0.0072, -0.0256],\n",
       "         [-0.0068, -0.0169,  0.0039,  ..., -0.0146,  0.0037,  0.0037]]),\n",
       " 'llm.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight': tensor([[ 0.0077, -0.0056,  0.0042,  ...,  0.0035,  0.0151, -0.0223],\n",
       "         [ 0.0215,  0.0102,  0.0015,  ...,  0.0118,  0.0195, -0.0005],\n",
       "         [-0.0389,  0.0400,  0.0104,  ..., -0.0129,  0.0130, -0.0232],\n",
       "         ...,\n",
       "         [ 0.0013, -0.0048,  0.0218,  ...,  0.0224,  0.0139, -0.0096],\n",
       "         [ 0.0020,  0.0103, -0.0106,  ...,  0.0043, -0.0345, -0.0222],\n",
       "         [ 0.0229, -0.0270,  0.0047,  ..., -0.0280,  0.0256,  0.0144]]),\n",
       " 'llm.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight': tensor([[-2.6065e-02,  2.9780e-02,  4.5187e-02,  ..., -3.8275e-02,\n",
       "           4.7056e-02, -5.0982e-02],\n",
       "         [ 1.9344e-02, -1.1774e-02, -9.1599e-03,  ..., -1.9523e-02,\n",
       "          -8.1278e-03, -4.2433e-03],\n",
       "         [-1.4077e-02,  4.5960e-03, -1.5109e-02,  ...,  2.0773e-02,\n",
       "          -1.9586e-02,  1.1227e-02],\n",
       "         ...,\n",
       "         [ 1.0110e-02, -1.0989e-02,  2.9026e-03,  ..., -1.3117e-02,\n",
       "           1.7258e-02, -1.7223e-02],\n",
       "         [ 2.8444e-04, -2.5670e-02,  1.4805e-02,  ..., -1.0774e-02,\n",
       "           2.5431e-02, -1.9815e-02],\n",
       "         [ 7.9277e-05, -2.4374e-03, -1.8427e-02,  ..., -6.4629e-03,\n",
       "          -6.4336e-03, -1.5836e-03]]),\n",
       " 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0008, -0.0230,  0.0200,  ..., -0.0171, -0.0080,  0.0004],\n",
       "         [ 0.0312,  0.0017, -0.0496,  ...,  0.0019, -0.0140,  0.0051],\n",
       "         [-0.0169, -0.0255, -0.0021,  ...,  0.0178, -0.0269,  0.0248],\n",
       "         ...,\n",
       "         [ 0.0354,  0.0086,  0.0186,  ...,  0.0098,  0.0086,  0.0073],\n",
       "         [-0.0040, -0.0133,  0.0384,  ..., -0.0340, -0.0137, -0.0102],\n",
       "         [-0.0175, -0.0154, -0.0608,  ...,  0.0091,  0.0001,  0.0106]]),\n",
       " 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0180, -0.0044,  0.0059,  ...,  0.0026,  0.0111,  0.0313],\n",
       "         [-0.0083,  0.0122, -0.0277,  ...,  0.0090,  0.0075, -0.0025],\n",
       "         [-0.0097,  0.0093, -0.0046,  ...,  0.0063,  0.0224,  0.0077],\n",
       "         ...,\n",
       "         [ 0.0122, -0.0190, -0.0037,  ..., -0.0249, -0.0139,  0.0005],\n",
       "         [-0.0111,  0.0104, -0.0046,  ..., -0.0059, -0.0127,  0.0111],\n",
       "         [ 0.0118, -0.0120,  0.0024,  ...,  0.0020, -0.0031, -0.0133]]),\n",
       " 'llm.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight': tensor([[-1.9528e-02, -1.2025e-02,  3.1285e-03,  ...,  1.1966e-03,\n",
       "           7.9796e-03,  4.8820e-03],\n",
       "         [-2.9880e-02, -1.7833e-02, -7.8769e-03,  ...,  2.4830e-02,\n",
       "           4.7902e-03,  9.2595e-03],\n",
       "         [-2.5491e-02,  1.1504e-02, -4.8343e-03,  ..., -1.3631e-02,\n",
       "          -1.1404e-02,  1.4652e-02],\n",
       "         ...,\n",
       "         [ 8.6148e-03, -1.7759e-02,  1.9229e-04,  ..., -4.1004e-03,\n",
       "           2.7412e-02, -1.2245e-02],\n",
       "         [-9.0571e-03,  8.0920e-03,  1.2678e-02,  ...,  1.5087e-02,\n",
       "           3.1600e-02,  2.8747e-02],\n",
       "         [ 2.5553e-05, -6.6187e-03,  1.6459e-02,  ...,  1.0755e-02,\n",
       "          -1.9684e-02, -3.2760e-02]]),\n",
       " 'llm.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight': tensor([[ 0.0039, -0.0052, -0.0029,  ...,  0.0056,  0.0110,  0.0031],\n",
       "         [-0.0113, -0.0019,  0.0156,  ..., -0.0235, -0.0048,  0.0051],\n",
       "         [-0.0128, -0.0104, -0.0081,  ..., -0.0120,  0.0210,  0.0041],\n",
       "         ...,\n",
       "         [ 0.0158,  0.0032,  0.0106,  ..., -0.0026, -0.0050, -0.0098],\n",
       "         [-0.0087, -0.0117,  0.0014,  ..., -0.0050, -0.0131,  0.0021],\n",
       "         [-0.0034,  0.0143, -0.0066,  ..., -0.0074,  0.0111, -0.0052]]),\n",
       " 'llm.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight': tensor([[-0.0338,  0.0309,  0.0051,  ..., -0.0094, -0.0140, -0.0137],\n",
       "         [ 0.0201, -0.0263, -0.0217,  ..., -0.0044, -0.0090,  0.0050],\n",
       "         [ 0.0056,  0.0197,  0.0048,  ..., -0.0126, -0.0096, -0.0018],\n",
       "         ...,\n",
       "         [ 0.0119,  0.0147, -0.0269,  ..., -0.0072, -0.0109, -0.0249],\n",
       "         [ 0.0208,  0.0236,  0.0177,  ..., -0.0211, -0.0093, -0.0126],\n",
       "         [-0.0167, -0.0144, -0.0376,  ...,  0.0079, -0.0342,  0.0056]]),\n",
       " 'llm.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight': tensor([[-0.0219,  0.0137, -0.0010,  ...,  0.0195, -0.0121,  0.0157],\n",
       "         [ 0.0180, -0.0113,  0.0005,  ..., -0.0071,  0.0006,  0.0107],\n",
       "         [ 0.0055,  0.0290, -0.0039,  ..., -0.0455,  0.0057, -0.0400],\n",
       "         ...,\n",
       "         [-0.0026, -0.0117, -0.0119,  ..., -0.0088, -0.0143, -0.0090],\n",
       "         [-0.0080, -0.0071,  0.0165,  ...,  0.0146, -0.0127,  0.0109],\n",
       "         [ 0.0054, -0.0152,  0.0279,  ...,  0.0044, -0.0025,  0.0108]]),\n",
       " 'llm.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight': tensor([[-0.0043, -0.0222,  0.0169,  ..., -0.0240,  0.0122,  0.0112],\n",
       "         [-0.0278, -0.0096,  0.0207,  ...,  0.0050,  0.0077,  0.0204],\n",
       "         [-0.0142,  0.0100, -0.0253,  ...,  0.0058,  0.0114, -0.0036],\n",
       "         ...,\n",
       "         [-0.0251, -0.0103, -0.0168,  ...,  0.0434, -0.0418,  0.0194],\n",
       "         [-0.0264, -0.0233, -0.0165,  ...,  0.0254, -0.0013, -0.0030],\n",
       "         [-0.0124, -0.0039, -0.0208,  ..., -0.0210, -0.0035,  0.0112]]),\n",
       " 'llm.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight': tensor([[-2.4488e-02, -2.8193e-04, -2.5342e-02,  ..., -1.5047e-02,\n",
       "          -2.4575e-03,  1.3471e-02],\n",
       "         [ 6.1837e-03,  1.7191e-03,  1.1319e-02,  ..., -6.3980e-03,\n",
       "          -2.5271e-03,  4.2053e-03],\n",
       "         [-5.0358e-03,  8.9793e-03,  8.3983e-03,  ..., -2.3617e-02,\n",
       "          -1.2543e-02,  6.5829e-03],\n",
       "         ...,\n",
       "         [-4.8532e-03, -2.1302e-02,  2.7472e-02,  ..., -1.3240e-02,\n",
       "          -6.9805e-03,  4.4883e-04],\n",
       "         [-1.6779e-02,  7.5406e-03,  2.7506e-02,  ..., -5.6322e-03,\n",
       "          -1.7276e-03,  2.0180e-02],\n",
       "         [-2.5603e-02, -1.9737e-03, -3.0582e-03,  ..., -6.0768e-04,\n",
       "          -7.2893e-05,  1.0081e-02]]),\n",
       " 'llm.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight': tensor([[-0.0081,  0.0038, -0.0051,  ...,  0.0044,  0.0245,  0.0105],\n",
       "         [ 0.0131,  0.0038, -0.0098,  ..., -0.0037, -0.0014,  0.0195],\n",
       "         [ 0.0011,  0.0216, -0.0050,  ..., -0.0099,  0.0201, -0.0066],\n",
       "         ...,\n",
       "         [ 0.0093,  0.0050, -0.0047,  ..., -0.0159, -0.0061, -0.0020],\n",
       "         [-0.0230, -0.0091,  0.0071,  ..., -0.0002,  0.0018,  0.0145],\n",
       "         [-0.0068, -0.0056,  0.0165,  ..., -0.0046,  0.0141,  0.0131]]),\n",
       " 'llm.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight': tensor([[ 0.0044, -0.0044,  0.0108,  ..., -0.0159, -0.0131,  0.0067],\n",
       "         [ 0.0004,  0.0044, -0.0116,  ..., -0.0022,  0.0045,  0.0071],\n",
       "         [-0.0146, -0.0012, -0.0092,  ...,  0.0090,  0.0254, -0.0070],\n",
       "         ...,\n",
       "         [-0.0012,  0.0014,  0.0215,  ..., -0.0031, -0.0086,  0.0083],\n",
       "         [ 0.0050,  0.0016, -0.0150,  ...,  0.0043,  0.0113,  0.0156],\n",
       "         [ 0.0125,  0.0087,  0.0130,  ..., -0.0042,  0.0058,  0.0168]]),\n",
       " 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight': tensor([[-1.2138e-02,  3.7495e-03, -4.9712e-04,  ...,  4.4860e-02,\n",
       "          -1.0474e-02, -1.1152e-02],\n",
       "         [ 2.5972e-02, -4.2682e-03, -8.7710e-03,  ..., -1.5480e-03,\n",
       "          -5.7585e-02, -8.5813e-03],\n",
       "         [ 2.5369e-02,  1.0729e-02, -3.0082e-02,  ..., -2.1478e-02,\n",
       "          -2.0326e-02, -3.2084e-03],\n",
       "         ...,\n",
       "         [-3.2054e-03, -1.9104e-02,  5.1035e-05,  ..., -3.2520e-02,\n",
       "           8.1287e-03,  1.4617e-02],\n",
       "         [-2.6767e-03,  1.1715e-02,  6.4023e-03,  ..., -7.1876e-03,\n",
       "          -1.0040e-03, -8.5344e-03],\n",
       "         [ 4.0429e-03, -4.5141e-03, -2.9868e-02,  ..., -3.0953e-02,\n",
       "           7.7634e-03, -1.1488e-02]]),\n",
       " 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0066, -0.0260,  0.0001,  ..., -0.0159,  0.0005, -0.0263],\n",
       "         [ 0.0424, -0.0112, -0.0188,  ..., -0.0213,  0.0181, -0.0212],\n",
       "         [-0.0179,  0.0127,  0.0052,  ...,  0.0284, -0.0103,  0.0373],\n",
       "         ...,\n",
       "         [-0.0264,  0.0333, -0.0060,  ...,  0.0025,  0.0171, -0.0014],\n",
       "         [ 0.0135,  0.0094, -0.0103,  ...,  0.0174, -0.0043,  0.0054],\n",
       "         [ 0.0112,  0.0518, -0.0356,  ...,  0.0362, -0.0384, -0.0074]]),\n",
       " 'llm.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight': tensor([[ 0.0012,  0.0248, -0.0426,  ..., -0.0169, -0.0033,  0.0155],\n",
       "         [-0.0222,  0.0087,  0.0134,  ...,  0.0124, -0.0211,  0.0109],\n",
       "         [-0.0088,  0.0044,  0.0426,  ..., -0.0353, -0.0287, -0.0220],\n",
       "         ...,\n",
       "         [ 0.0067,  0.0325, -0.0279,  ...,  0.0098, -0.0027,  0.0116],\n",
       "         [-0.0080,  0.0022,  0.0167,  ...,  0.0230, -0.0111, -0.0026],\n",
       "         [ 0.0067, -0.0371, -0.0021,  ..., -0.0352, -0.0214, -0.0294]]),\n",
       " 'llm.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight': tensor([[-0.0021, -0.0237,  0.0083,  ..., -0.0344, -0.0227,  0.0296],\n",
       "         [-0.0001, -0.0143,  0.0077,  ...,  0.0036, -0.0162, -0.0047],\n",
       "         [ 0.0207,  0.0156,  0.0173,  ..., -0.0089,  0.0145,  0.0134],\n",
       "         ...,\n",
       "         [-0.0215,  0.0002,  0.0050,  ...,  0.0049, -0.0029, -0.0101],\n",
       "         [-0.0031,  0.0132,  0.0046,  ...,  0.0172,  0.0048, -0.0142],\n",
       "         [ 0.0035,  0.0108, -0.0035,  ..., -0.0031, -0.0159, -0.0234]]),\n",
       " 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0228,  0.0079, -0.0138,  ...,  0.0036, -0.0121,  0.0155],\n",
       "         [ 0.0160, -0.0053, -0.0044,  ..., -0.0238,  0.0050,  0.0190],\n",
       "         [ 0.0073, -0.0139, -0.0126,  ...,  0.0188, -0.0252, -0.0105],\n",
       "         ...,\n",
       "         [-0.0377,  0.0194, -0.0113,  ...,  0.0015,  0.0248,  0.0236],\n",
       "         [ 0.0242, -0.0275, -0.0046,  ..., -0.0208,  0.0267,  0.0107],\n",
       "         [-0.0135,  0.0232, -0.0163,  ...,  0.0240, -0.0201,  0.0307]]),\n",
       " 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0005, -0.0096,  0.0047,  ...,  0.0115,  0.0033,  0.0063],\n",
       "         [ 0.0097,  0.0040, -0.0008,  ..., -0.0108, -0.0103,  0.0068],\n",
       "         [-0.0110,  0.0184, -0.0021,  ..., -0.0075, -0.0064, -0.0039],\n",
       "         ...,\n",
       "         [-0.0011,  0.0147, -0.0110,  ..., -0.0097,  0.0106,  0.0015],\n",
       "         [-0.0202, -0.0154,  0.0042,  ...,  0.0029, -0.0036, -0.0160],\n",
       "         [ 0.0132,  0.0040,  0.0147,  ...,  0.0044,  0.0064,  0.0108]]),\n",
       " 'llm.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight': tensor([[ 0.0021, -0.0109, -0.0138,  ..., -0.0092,  0.0190,  0.0099],\n",
       "         [ 0.0002,  0.0141,  0.0033,  ...,  0.0130, -0.0056,  0.0007],\n",
       "         [ 0.0168,  0.0274, -0.0213,  ..., -0.0058,  0.0187, -0.0031],\n",
       "         ...,\n",
       "         [ 0.0137,  0.0003, -0.0237,  ...,  0.0183, -0.0268,  0.0274],\n",
       "         [ 0.0199, -0.0032, -0.0099,  ...,  0.0282, -0.0393, -0.0098],\n",
       "         [-0.0022, -0.0121,  0.0204,  ...,  0.0107, -0.0048,  0.0133]]),\n",
       " 'llm.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight': tensor([[-0.0067,  0.0067,  0.0144,  ...,  0.0167, -0.0194, -0.0092],\n",
       "         [-0.0213, -0.0099,  0.0128,  ..., -0.0201,  0.0035,  0.0190],\n",
       "         [-0.0094, -0.0105, -0.0042,  ..., -0.0043,  0.0207,  0.0018],\n",
       "         ...,\n",
       "         [-0.0165,  0.0228,  0.0179,  ..., -0.0064, -0.0073, -0.0180],\n",
       "         [-0.0139,  0.0166, -0.0092,  ...,  0.0084,  0.0238,  0.0097],\n",
       "         [-0.0221,  0.0240,  0.0166,  ...,  0.0110, -0.0112, -0.0069]]),\n",
       " 'llm.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight': tensor([[-0.0109,  0.0016,  0.0071,  ..., -0.0251, -0.0270,  0.0220],\n",
       "         [-0.0293, -0.0478, -0.0126,  ...,  0.0064,  0.0427,  0.0069],\n",
       "         [-0.0025, -0.0128,  0.0010,  ..., -0.0196, -0.0290, -0.0307],\n",
       "         ...,\n",
       "         [-0.0005, -0.0034, -0.0113,  ...,  0.0055,  0.0019, -0.0146],\n",
       "         [-0.0132, -0.0103, -0.0253,  ...,  0.0223, -0.0234, -0.0046],\n",
       "         [ 0.0361, -0.0175,  0.0335,  ..., -0.0150, -0.0118,  0.0138]]),\n",
       " 'llm.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight': tensor([[-1.3741e-02,  1.5848e-02,  4.1018e-03,  ..., -1.1063e-02,\n",
       "           1.7367e-02,  1.5076e-02],\n",
       "         [ 3.4364e-03,  1.5318e-03, -1.2334e-02,  ..., -1.0800e-02,\n",
       "           5.0831e-03, -1.4179e-02],\n",
       "         [ 1.9022e-02,  4.2294e-02,  1.3874e-02,  ..., -8.8525e-03,\n",
       "           1.4188e-02, -2.3197e-03],\n",
       "         ...,\n",
       "         [ 2.5759e-02, -1.1956e-02,  8.1995e-04,  ...,  1.8125e-02,\n",
       "          -2.9010e-02, -2.4779e-02],\n",
       "         [ 1.8326e-02, -1.3239e-02,  3.4902e-03,  ...,  3.0448e-03,\n",
       "           9.7479e-06, -2.8098e-03],\n",
       "         [ 1.9683e-02,  6.1500e-03,  3.4091e-05,  ...,  2.6191e-02,\n",
       "          -1.4037e-02,  9.8486e-03]]),\n",
       " 'llm.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight': tensor([[-0.0014, -0.0216,  0.0085,  ..., -0.0200, -0.0207,  0.0067],\n",
       "         [ 0.0059,  0.0212,  0.0111,  ..., -0.0218,  0.0278,  0.0127],\n",
       "         [ 0.0172,  0.0075,  0.0107,  ...,  0.0218, -0.0021,  0.0034],\n",
       "         ...,\n",
       "         [ 0.0102,  0.0130, -0.0394,  ..., -0.0322, -0.0041,  0.0025],\n",
       "         [-0.0082, -0.0039, -0.0086,  ...,  0.0159,  0.0003, -0.0177],\n",
       "         [ 0.0265, -0.0313, -0.0179,  ..., -0.0237,  0.0080,  0.0084]]),\n",
       " 'llm.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight': tensor([[ 0.0031,  0.0201, -0.0219,  ...,  0.0081,  0.0099, -0.0087],\n",
       "         [-0.0011,  0.0099, -0.0129,  ..., -0.0128, -0.0007, -0.0236],\n",
       "         [ 0.0115, -0.0309,  0.0148,  ...,  0.0129, -0.0040, -0.0030],\n",
       "         ...,\n",
       "         [ 0.0004, -0.0101, -0.0050,  ..., -0.0094,  0.0140,  0.0143],\n",
       "         [-0.0007, -0.0020, -0.0070,  ...,  0.0067,  0.0101, -0.0085],\n",
       "         [ 0.0016,  0.0210,  0.0233,  ...,  0.0339,  0.0171,  0.0071]]),\n",
       " 'llm.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight': tensor([[ 0.0062,  0.0097,  0.0021,  ..., -0.0081, -0.0010, -0.0341],\n",
       "         [ 0.0187, -0.0130, -0.0013,  ...,  0.0018, -0.0100,  0.0191],\n",
       "         [-0.0026,  0.0045, -0.0027,  ..., -0.0130, -0.0048, -0.0084],\n",
       "         ...,\n",
       "         [ 0.0014,  0.0068, -0.0004,  ..., -0.0275, -0.0126,  0.0211],\n",
       "         [-0.0071, -0.0035,  0.0291,  ...,  0.0004,  0.0031,  0.0126],\n",
       "         [-0.0026, -0.0174, -0.0262,  ...,  0.0057, -0.0023,  0.0169]]),\n",
       " 'llm.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight': tensor([[ 1.0082e-02, -2.7587e-03, -8.6464e-03,  ..., -1.1143e-02,\n",
       "           2.1204e-02,  1.1227e-02],\n",
       "         [-9.3499e-03, -1.0300e-02,  1.5444e-02,  ...,  1.8548e-02,\n",
       "           3.1854e-03, -5.0252e-04],\n",
       "         [ 8.9605e-04, -7.5186e-03, -2.3535e-02,  ..., -1.4641e-02,\n",
       "           1.7033e-02,  1.2269e-02],\n",
       "         ...,\n",
       "         [-3.1641e-06,  2.6697e-02,  1.9047e-02,  ..., -4.3680e-03,\n",
       "          -2.0641e-03, -7.4486e-03],\n",
       "         [ 4.0485e-03,  1.0751e-02, -1.3640e-02,  ...,  1.1581e-02,\n",
       "          -1.7073e-04, -3.8953e-03],\n",
       "         [-1.1590e-02, -4.7286e-03, -2.4507e-03,  ..., -1.0382e-02,\n",
       "           1.2214e-04, -6.1724e-03]]),\n",
       " 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight': tensor([[-0.0077, -0.0110, -0.0098,  ...,  0.0260,  0.0042,  0.0456],\n",
       "         [-0.0454,  0.0295, -0.0236,  ...,  0.0274,  0.0061,  0.0130],\n",
       "         [ 0.0031,  0.0177, -0.0269,  ..., -0.0122, -0.0156, -0.0318],\n",
       "         ...,\n",
       "         [-0.0063,  0.0166, -0.0205,  ...,  0.0116,  0.0076,  0.0145],\n",
       "         [-0.0430,  0.0304,  0.0038,  ..., -0.0097, -0.0351, -0.0200],\n",
       "         [-0.0057, -0.0055, -0.0103,  ...,  0.0080,  0.0022,  0.0023]]),\n",
       " 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight': tensor([[ 6.0314e-03,  5.7812e-03, -3.6937e-03,  ...,  2.4154e-02,\n",
       "          -1.7922e-02, -1.8174e-02],\n",
       "         [ 2.6153e-03,  2.0093e-02,  1.0198e-02,  ...,  4.0381e-02,\n",
       "          -3.9610e-02, -1.0305e-03],\n",
       "         [ 2.0263e-02,  3.2883e-02, -1.1196e-02,  ...,  3.3843e-02,\n",
       "          -1.0907e-02, -8.3654e-03],\n",
       "         ...,\n",
       "         [-1.0199e-02, -2.5511e-02,  3.7921e-03,  ..., -3.9672e-02,\n",
       "           3.1036e-02,  1.4759e-02],\n",
       "         [ 1.6189e-04,  1.2868e-04,  6.9444e-05,  ...,  2.3603e-03,\n",
       "          -9.1989e-04, -5.2210e-03],\n",
       "         [ 1.3106e-02,  1.7857e-02, -1.4559e-02,  ...,  4.3714e-03,\n",
       "           2.8152e-03, -2.7195e-03]]),\n",
       " 'llm.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight': tensor([[ 0.0062,  0.0075, -0.0173,  ..., -0.0072, -0.0257,  0.0134],\n",
       "         [ 0.0166, -0.0081, -0.0058,  ...,  0.0402,  0.0135,  0.0350],\n",
       "         [-0.0119, -0.0062,  0.0128,  ...,  0.0138,  0.0281,  0.0151],\n",
       "         ...,\n",
       "         [-0.0257,  0.0001,  0.0259,  ..., -0.0171,  0.0175,  0.0072],\n",
       "         [ 0.0312, -0.0200, -0.0191,  ...,  0.0256, -0.0223,  0.0105],\n",
       "         [-0.0063,  0.0190, -0.0079,  ..., -0.0239, -0.0063, -0.0206]]),\n",
       " 'llm.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight': tensor([[ 3.5047e-03, -1.3075e-03, -1.7867e-04,  ...,  3.7135e-03,\n",
       "           3.0662e-03, -8.6790e-03],\n",
       "         [-5.7552e-03, -1.2589e-02, -2.2067e-02,  ..., -3.8460e-02,\n",
       "           1.8512e-02,  2.6705e-02],\n",
       "         [-1.6494e-02, -5.8121e-03, -1.9510e-02,  ..., -2.0071e-02,\n",
       "           1.9391e-02, -1.3187e-03],\n",
       "         ...,\n",
       "         [-1.8613e-02, -1.6908e-02, -2.6535e-03,  ...,  1.2665e-02,\n",
       "           1.5403e-02,  2.9664e-02],\n",
       "         [-1.4639e-03, -8.2815e-05, -3.0746e-04,  ..., -1.0930e-02,\n",
       "          -5.4887e-03, -8.4435e-03],\n",
       "         [ 2.5977e-03,  1.0300e-02,  3.5901e-03,  ..., -8.4034e-03,\n",
       "           6.6691e-03, -1.1770e-02]]),\n",
       " 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0049, -0.0261,  0.0375,  ...,  0.0116, -0.0148, -0.0052],\n",
       "         [-0.0030, -0.0194,  0.0276,  ..., -0.0017,  0.0027, -0.0110],\n",
       "         [-0.0133, -0.0012, -0.0033,  ...,  0.0073,  0.0097,  0.0008],\n",
       "         ...,\n",
       "         [-0.0118,  0.0002,  0.0341,  ...,  0.0020, -0.0436,  0.0232],\n",
       "         [-0.0012,  0.0259,  0.0122,  ..., -0.0395,  0.0128,  0.0067],\n",
       "         [ 0.0289, -0.0038, -0.0119,  ...,  0.0161, -0.0174, -0.0182]]),\n",
       " 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight': tensor([[-1.9593e-03, -3.0661e-03,  1.6908e-02,  ...,  1.2645e-02,\n",
       "           2.1197e-02,  1.6816e-03],\n",
       "         [-1.1845e-02, -6.4952e-03,  1.7361e-02,  ...,  1.1129e-02,\n",
       "           1.3711e-02, -2.7266e-03],\n",
       "         [ 1.3135e-02, -7.5698e-03,  1.5518e-03,  ...,  3.7357e-03,\n",
       "          -1.8980e-02, -1.8689e-03],\n",
       "         ...,\n",
       "         [ 8.9992e-03,  4.0974e-03, -4.7704e-03,  ..., -1.2078e-02,\n",
       "           2.1023e-03,  1.7845e-05],\n",
       "         [ 4.0811e-03,  1.0912e-02,  1.3346e-02,  ...,  4.9110e-03,\n",
       "          -2.8649e-04,  8.1979e-03],\n",
       "         [ 1.1107e-02,  1.1361e-02, -1.1719e-02,  ...,  1.7056e-02,\n",
       "           1.4835e-03, -2.6769e-03]]),\n",
       " 'llm.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight': tensor([[-1.5942e-02,  1.6658e-02,  6.1925e-03,  ..., -4.9005e-03,\n",
       "           5.1630e-03, -1.2629e-02],\n",
       "         [ 7.8793e-03,  1.1896e-02,  8.2521e-03,  ...,  5.4219e-02,\n",
       "           2.2746e-02,  2.5697e-02],\n",
       "         [-8.0908e-03,  1.9008e-02, -3.6051e-03,  ...,  2.6007e-02,\n",
       "          -1.7656e-02, -2.2783e-02],\n",
       "         ...,\n",
       "         [ 2.2236e-02, -1.7502e-02,  2.4564e-02,  ...,  6.6103e-03,\n",
       "          -1.8907e-02, -1.0378e-02],\n",
       "         [ 1.3488e-05, -3.0267e-02,  2.5171e-02,  ..., -3.0085e-02,\n",
       "           1.8543e-02,  5.4719e-03],\n",
       "         [-9.9983e-03,  2.7663e-02, -1.8498e-02,  ..., -1.3591e-02,\n",
       "          -5.8715e-03,  1.9307e-02]]),\n",
       " 'llm.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight': tensor([[-1.3608e-02,  1.5146e-02,  4.3295e-03,  ...,  3.3964e-03,\n",
       "           1.8513e-02,  4.9633e-03],\n",
       "         [ 3.3300e-03,  1.5339e-02,  1.3332e-02,  ..., -1.0985e-02,\n",
       "          -5.1262e-03,  1.0617e-02],\n",
       "         [ 5.5561e-03,  1.2816e-03, -4.1078e-05,  ..., -1.0816e-02,\n",
       "          -6.0260e-03,  3.8976e-03],\n",
       "         ...,\n",
       "         [-2.6224e-02, -1.1312e-02,  3.0707e-03,  ...,  4.8627e-03,\n",
       "          -8.8761e-03, -1.5288e-02],\n",
       "         [-1.4525e-02,  6.8113e-03,  1.2586e-02,  ..., -3.2027e-03,\n",
       "          -1.9526e-02,  1.6391e-02],\n",
       "         [ 1.4821e-02, -4.6450e-03, -7.8485e-03,  ...,  1.4658e-02,\n",
       "           1.9099e-02,  6.0719e-03]]),\n",
       " 'llm.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight': tensor([[ 0.0319, -0.0249, -0.0095,  ...,  0.0154,  0.0123, -0.0139],\n",
       "         [-0.0062, -0.0220, -0.0239,  ..., -0.0019,  0.0186,  0.0306],\n",
       "         [ 0.0510,  0.0031,  0.0331,  ...,  0.0234, -0.0007, -0.0083],\n",
       "         ...,\n",
       "         [-0.0100, -0.0106, -0.0213,  ...,  0.0350,  0.0326, -0.0135],\n",
       "         [ 0.0184,  0.0020,  0.0027,  ..., -0.0133, -0.0098, -0.0473],\n",
       "         [-0.0141, -0.0010, -0.0230,  ..., -0.0179, -0.0027, -0.0047]]),\n",
       " 'llm.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight': tensor([[-0.0041, -0.0175, -0.0146,  ...,  0.0146, -0.0208,  0.0179],\n",
       "         [-0.0264,  0.0213, -0.0097,  ...,  0.0015, -0.0048,  0.0025],\n",
       "         [ 0.0071, -0.0081, -0.0127,  ...,  0.0069, -0.0126, -0.0244],\n",
       "         ...,\n",
       "         [ 0.0023,  0.0037,  0.0047,  ..., -0.0072,  0.0180, -0.0129],\n",
       "         [ 0.0073,  0.0091,  0.0066,  ..., -0.0104, -0.0227, -0.0050],\n",
       "         [-0.0042, -0.0002,  0.0002,  ..., -0.0258,  0.0055,  0.0245]]),\n",
       " 'llm.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight': tensor([[-0.0132,  0.0077,  0.0243,  ..., -0.0097, -0.0135,  0.0116],\n",
       "         [-0.0015,  0.0123,  0.0157,  ...,  0.0150, -0.0022, -0.0277],\n",
       "         [ 0.0383, -0.0197, -0.0098,  ...,  0.0133, -0.0093,  0.0190],\n",
       "         ...,\n",
       "         [-0.0440, -0.0176,  0.0031,  ...,  0.0259,  0.0046, -0.0238],\n",
       "         [ 0.0010, -0.0059, -0.0094,  ...,  0.0007,  0.0044,  0.0258],\n",
       "         [ 0.0033, -0.0157,  0.0136,  ..., -0.0009, -0.0087,  0.0204]]),\n",
       " 'llm.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight': tensor([[-0.0173, -0.0009,  0.0114,  ...,  0.0055, -0.0008,  0.0032],\n",
       "         [-0.0019, -0.0205,  0.0020,  ...,  0.0053,  0.0052,  0.0148],\n",
       "         [ 0.0105,  0.0134,  0.0030,  ..., -0.0187, -0.0063,  0.0026],\n",
       "         ...,\n",
       "         [-0.0284,  0.0199, -0.0092,  ...,  0.0126,  0.0081,  0.0121],\n",
       "         [ 0.0049,  0.0056,  0.0125,  ...,  0.0196, -0.0003,  0.0025],\n",
       "         [ 0.0148, -0.0214,  0.0035,  ..., -0.0097,  0.0103, -0.0122]]),\n",
       " 'llm.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight': tensor([[ 0.0378,  0.0071, -0.0260,  ...,  0.0190,  0.0129, -0.0160],\n",
       "         [-0.0110, -0.0024,  0.0009,  ...,  0.0159,  0.0204, -0.0052],\n",
       "         [ 0.0066,  0.0155,  0.0157,  ..., -0.0160, -0.0106,  0.0049],\n",
       "         ...,\n",
       "         [ 0.0153, -0.0023, -0.0208,  ..., -0.0065,  0.0122, -0.0027],\n",
       "         [-0.0024, -0.0195,  0.0053,  ...,  0.0205, -0.0261, -0.0092],\n",
       "         [-0.0028, -0.0031, -0.0040,  ...,  0.0127, -0.0032,  0.0192]]),\n",
       " 'llm.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight': tensor([[-0.0026, -0.0103, -0.0155,  ...,  0.0138,  0.0104, -0.0242],\n",
       "         [-0.0063, -0.0279, -0.0057,  ..., -0.0072,  0.0195,  0.0014],\n",
       "         [-0.0113,  0.0243,  0.0036,  ..., -0.0031,  0.0141,  0.0096],\n",
       "         ...,\n",
       "         [-0.0031, -0.0157, -0.0164,  ...,  0.0129, -0.0116, -0.0162],\n",
       "         [ 0.0131,  0.0315,  0.0148,  ..., -0.0046, -0.0067, -0.0037],\n",
       "         [ 0.0061, -0.0178,  0.0163,  ...,  0.0030,  0.0173, -0.0153]]),\n",
       " 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0047,  0.0277,  0.0035,  ..., -0.0184, -0.0231,  0.0205],\n",
       "         [-0.0048,  0.0155,  0.0065,  ...,  0.0140, -0.0131,  0.0245],\n",
       "         [-0.0197, -0.0044, -0.0377,  ..., -0.0069, -0.0110, -0.0157],\n",
       "         ...,\n",
       "         [ 0.0038, -0.0224, -0.0107,  ..., -0.0084,  0.0225,  0.0404],\n",
       "         [ 0.0059,  0.0210,  0.0360,  ...,  0.0166, -0.0255, -0.0061],\n",
       "         [ 0.0007, -0.0236, -0.0202,  ...,  0.0111, -0.0351, -0.0026]]),\n",
       " 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0192, -0.0435,  0.0416,  ..., -0.0194,  0.0426,  0.0330],\n",
       "         [-0.0118,  0.0031,  0.0262,  ...,  0.0185,  0.0001,  0.0066],\n",
       "         [-0.0152, -0.0050, -0.0143,  ...,  0.0060,  0.0201,  0.0106],\n",
       "         ...,\n",
       "         [-0.0066, -0.0102,  0.0008,  ..., -0.0131,  0.0190,  0.0175],\n",
       "         [ 0.0063,  0.0212, -0.0005,  ...,  0.0157, -0.0178, -0.0189],\n",
       "         [ 0.0044,  0.0141, -0.0072,  ..., -0.0028, -0.0019, -0.0202]]),\n",
       " 'llm.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight': tensor([[-0.0273, -0.0104,  0.0035,  ...,  0.0099, -0.0132,  0.0155],\n",
       "         [ 0.0050,  0.0163,  0.0215,  ..., -0.0225, -0.0620,  0.0168],\n",
       "         [ 0.0290,  0.0166,  0.0007,  ..., -0.0116, -0.0425, -0.0092],\n",
       "         ...,\n",
       "         [-0.0222,  0.0156,  0.0097,  ...,  0.0091, -0.0046, -0.0143],\n",
       "         [ 0.0310, -0.0036,  0.0246,  ...,  0.0043,  0.0008,  0.0225],\n",
       "         [ 0.0170,  0.0117,  0.0343,  ..., -0.0493, -0.0239,  0.0037]]),\n",
       " 'llm.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight': tensor([[ 0.0234,  0.0053,  0.0363,  ..., -0.0142, -0.0252, -0.0257],\n",
       "         [-0.0165,  0.0200, -0.0008,  ...,  0.0186, -0.0148,  0.0347],\n",
       "         [-0.0152, -0.0095, -0.0292,  ...,  0.0440, -0.0057,  0.0223],\n",
       "         ...,\n",
       "         [-0.0023,  0.0005, -0.0050,  ...,  0.0106, -0.0030,  0.0081],\n",
       "         [-0.0079, -0.0042,  0.0024,  ...,  0.0084, -0.0003, -0.0038],\n",
       "         [ 0.0053, -0.0237, -0.0185,  ..., -0.0007, -0.0321, -0.0211]]),\n",
       " 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0183, -0.0147, -0.0181,  ..., -0.0211,  0.0401,  0.0359],\n",
       "         [ 0.0216,  0.0095,  0.0095,  ..., -0.0273, -0.0180, -0.0111],\n",
       "         [-0.0405, -0.0169, -0.0060,  ...,  0.0091,  0.0153, -0.0217],\n",
       "         ...,\n",
       "         [ 0.0014, -0.0086, -0.0330,  ...,  0.0062, -0.0065, -0.0026],\n",
       "         [ 0.0050, -0.0178, -0.0098,  ..., -0.0227,  0.0423, -0.0091],\n",
       "         [-0.0152, -0.0029, -0.0006,  ...,  0.0236,  0.0095,  0.0148]]),\n",
       " 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0047, -0.0199,  0.0024,  ..., -0.0192,  0.0128, -0.0387],\n",
       "         [-0.0084, -0.0034, -0.0059,  ...,  0.0010, -0.0008, -0.0044],\n",
       "         [ 0.0119, -0.0050,  0.0044,  ...,  0.0160, -0.0067,  0.0129],\n",
       "         ...,\n",
       "         [-0.0073, -0.0035, -0.0004,  ...,  0.0111,  0.0139,  0.0036],\n",
       "         [ 0.0016,  0.0163,  0.0046,  ..., -0.0061,  0.0070,  0.0047],\n",
       "         [ 0.0061, -0.0012,  0.0006,  ...,  0.0159, -0.0049, -0.0237]]),\n",
       " 'llm.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight': tensor([[ 0.0349,  0.0026,  0.0086,  ..., -0.0160, -0.0023, -0.0087],\n",
       "         [-0.0175,  0.0251,  0.0016,  ...,  0.0046,  0.0213, -0.0173],\n",
       "         [ 0.0021,  0.0205,  0.0029,  ...,  0.0307,  0.0179,  0.0095],\n",
       "         ...,\n",
       "         [-0.0011, -0.0143,  0.0136,  ...,  0.0263,  0.0159, -0.0074],\n",
       "         [-0.0175,  0.0089, -0.0156,  ..., -0.0283, -0.0079,  0.0154],\n",
       "         [ 0.0146, -0.0078,  0.0107,  ..., -0.0132, -0.0293,  0.0016]]),\n",
       " 'llm.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight': tensor([[-0.0018, -0.0208, -0.0171,  ..., -0.0108,  0.0148,  0.0078],\n",
       "         [-0.0025, -0.0064, -0.0005,  ..., -0.0088,  0.0037, -0.0014],\n",
       "         [ 0.0063,  0.0054,  0.0032,  ...,  0.0060, -0.0289,  0.0069],\n",
       "         ...,\n",
       "         [-0.0019,  0.0102,  0.0093,  ...,  0.0328, -0.0199, -0.0069],\n",
       "         [-0.0036, -0.0102, -0.0125,  ...,  0.0002,  0.0071, -0.0059],\n",
       "         [ 0.0031, -0.0006, -0.0051,  ...,  0.0095, -0.0174, -0.0060]]),\n",
       " 'llm.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight': tensor([[ 0.0187, -0.0026,  0.0337,  ..., -0.0064,  0.0176,  0.0026],\n",
       "         [ 0.0084, -0.0052, -0.0200,  ...,  0.0082, -0.0131,  0.0018],\n",
       "         [-0.0032, -0.0401, -0.0137,  ..., -0.0262, -0.0318, -0.0461],\n",
       "         ...,\n",
       "         [ 0.0027, -0.0069, -0.0043,  ..., -0.0066, -0.0001, -0.0287],\n",
       "         [-0.0055,  0.0071,  0.0031,  ...,  0.0194,  0.0173, -0.0260],\n",
       "         [ 0.0322,  0.0148,  0.0156,  ...,  0.0373, -0.0365,  0.0057]]),\n",
       " 'llm.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight': tensor([[-0.0068,  0.0030,  0.0153,  ...,  0.0115, -0.0010,  0.0095],\n",
       "         [ 0.0037,  0.0033, -0.0107,  ...,  0.0107,  0.0029, -0.0011],\n",
       "         [-0.0061, -0.0229,  0.0427,  ...,  0.0107, -0.0139, -0.0107],\n",
       "         ...,\n",
       "         [ 0.0011,  0.0106, -0.0029,  ..., -0.0055, -0.0118,  0.0086],\n",
       "         [-0.0190,  0.0125, -0.0149,  ..., -0.0064,  0.0084, -0.0026],\n",
       "         [ 0.0072, -0.0402,  0.0035,  ..., -0.0445,  0.0085, -0.0147]]),\n",
       " 'llm.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight': tensor([[ 0.0034,  0.0038,  0.0263,  ..., -0.0171, -0.0124,  0.0224],\n",
       "         [ 0.0008, -0.0156,  0.0064,  ..., -0.0177,  0.0325,  0.0289],\n",
       "         [ 0.0050,  0.0047,  0.0305,  ..., -0.0050, -0.0293, -0.0010],\n",
       "         ...,\n",
       "         [-0.0016,  0.0215, -0.0018,  ..., -0.0239,  0.0072,  0.0100],\n",
       "         [-0.0164, -0.0271,  0.0367,  ..., -0.0076, -0.0068, -0.0055],\n",
       "         [ 0.0095, -0.0259,  0.0073,  ...,  0.0187, -0.0393,  0.0108]]),\n",
       " 'llm.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight': tensor([[ 0.0177,  0.0040, -0.0234,  ..., -0.0104, -0.0090, -0.0070],\n",
       "         [-0.0018, -0.0162, -0.0151,  ..., -0.0045, -0.0198,  0.0200],\n",
       "         [-0.0167,  0.0141, -0.0021,  ..., -0.0388, -0.0065, -0.0102],\n",
       "         ...,\n",
       "         [-0.0067,  0.0241, -0.0035,  ..., -0.0250, -0.0396,  0.0111],\n",
       "         [ 0.0404,  0.0097,  0.0106,  ..., -0.0025, -0.0140,  0.0376],\n",
       "         [ 0.0149, -0.0031,  0.0087,  ..., -0.0139, -0.0029,  0.0141]]),\n",
       " 'llm.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight': tensor([[-6.5909e-05, -8.1959e-03, -1.9043e-02,  ..., -5.3827e-03,\n",
       "           1.0331e-02,  1.0676e-02],\n",
       "         [-1.4706e-02,  1.8395e-02, -9.3051e-03,  ...,  1.0213e-02,\n",
       "          -1.0403e-02,  5.1475e-02],\n",
       "         [ 4.1439e-03, -2.3789e-02,  4.0936e-03,  ..., -7.1540e-03,\n",
       "          -1.8869e-02, -9.3353e-03],\n",
       "         ...,\n",
       "         [-1.1995e-02, -3.2253e-03, -1.3563e-02,  ...,  1.5927e-02,\n",
       "          -5.6427e-03, -1.0559e-02],\n",
       "         [-1.2176e-03, -1.1940e-02, -1.6110e-03,  ...,  1.3760e-03,\n",
       "           9.9210e-03,  1.5717e-03],\n",
       "         [-9.8625e-03, -5.1305e-04,  3.9857e-03,  ..., -4.3401e-02,\n",
       "          -1.8514e-03,  7.9486e-03]]),\n",
       " 'llm.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight': tensor([[-0.0138,  0.0287, -0.0088,  ...,  0.0081,  0.0026, -0.0158],\n",
       "         [ 0.0137, -0.0145, -0.0255,  ...,  0.0088,  0.0036, -0.0078],\n",
       "         [ 0.0165, -0.0121,  0.0089,  ...,  0.0024,  0.0080,  0.0193],\n",
       "         ...,\n",
       "         [-0.0028, -0.0128, -0.0020,  ...,  0.0030,  0.0067,  0.0170],\n",
       "         [-0.0009, -0.0017,  0.0138,  ..., -0.0027,  0.0029, -0.0055],\n",
       "         [ 0.0027, -0.0257,  0.0290,  ...,  0.0004, -0.0103, -0.0251]]),\n",
       " 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0139, -0.0309, -0.0068,  ...,  0.0032, -0.0353,  0.0057],\n",
       "         [-0.0268,  0.0486,  0.0225,  ...,  0.0232,  0.0092,  0.0460],\n",
       "         [ 0.0069,  0.0087, -0.0135,  ..., -0.0304,  0.0080,  0.0067],\n",
       "         ...,\n",
       "         [ 0.0013, -0.0042, -0.0003,  ...,  0.0035,  0.0124, -0.0250],\n",
       "         [-0.0189, -0.0163,  0.0040,  ..., -0.0289,  0.0142,  0.0107],\n",
       "         [-0.0114,  0.0199,  0.0008,  ...,  0.0043,  0.0060,  0.0189]]),\n",
       " 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight': tensor([[-0.0063, -0.0228,  0.0010,  ..., -0.0040, -0.0123,  0.0060],\n",
       "         [-0.0160, -0.0080, -0.0174,  ..., -0.0188,  0.0096, -0.0193],\n",
       "         [ 0.0450, -0.0012,  0.0375,  ...,  0.0512, -0.0428,  0.0606],\n",
       "         ...,\n",
       "         [ 0.0231,  0.0102,  0.0034,  ...,  0.0081, -0.0080,  0.0044],\n",
       "         [ 0.0071,  0.0108,  0.0101,  ...,  0.0018,  0.0010, -0.0066],\n",
       "         [ 0.0124,  0.0069, -0.0094,  ..., -0.0026, -0.0031, -0.0014]]),\n",
       " 'llm.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight': tensor([[-2.2297e-02, -1.0659e-02,  5.1775e-03,  ...,  1.5142e-02,\n",
       "           3.0238e-02, -1.5329e-02],\n",
       "         [-1.2842e-03,  2.6647e-02, -1.5146e-03,  ...,  1.0881e-02,\n",
       "           1.8656e-02, -2.7792e-03],\n",
       "         [-1.7645e-02,  4.1068e-02,  1.4447e-02,  ...,  9.7757e-03,\n",
       "           5.5558e-03,  3.3157e-02],\n",
       "         ...,\n",
       "         [-5.2438e-04,  2.0584e-03, -1.6697e-02,  ...,  1.6948e-02,\n",
       "          -2.6781e-02,  4.3865e-03],\n",
       "         [ 5.0269e-03, -3.4675e-02,  2.4041e-02,  ..., -6.1779e-05,\n",
       "          -3.1046e-03, -2.4311e-02],\n",
       "         [ 1.9104e-02,  1.2069e-02,  2.8374e-02,  ...,  2.4259e-02,\n",
       "          -1.8774e-02,  2.4220e-02]]),\n",
       " 'llm.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight': tensor([[ 0.0120, -0.0168,  0.0052,  ..., -0.0383,  0.0475, -0.0127],\n",
       "         [-0.0131,  0.0076,  0.0080,  ...,  0.0287, -0.0126,  0.0085],\n",
       "         [ 0.0129, -0.0088, -0.0027,  ..., -0.0071,  0.0187, -0.0207],\n",
       "         ...,\n",
       "         [ 0.0050, -0.0004,  0.0057,  ...,  0.0105, -0.0028, -0.0074],\n",
       "         [-0.0026, -0.0128, -0.0092,  ...,  0.0047, -0.0092, -0.0010],\n",
       "         [-0.0023,  0.0096,  0.0089,  ..., -0.0007,  0.0036, -0.0035]]),\n",
       " 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight': tensor([[ 0.0164, -0.0235,  0.0392,  ...,  0.0165, -0.0163, -0.0244],\n",
       "         [ 0.0082, -0.0026, -0.0476,  ...,  0.0096,  0.0319, -0.0189],\n",
       "         [ 0.0006,  0.0034,  0.0374,  ...,  0.0196, -0.0172,  0.0377],\n",
       "         ...,\n",
       "         [-0.0089,  0.0034, -0.0083,  ..., -0.0244,  0.0054,  0.0180],\n",
       "         [-0.0101, -0.0148, -0.0341,  ..., -0.0028,  0.0032,  0.0490],\n",
       "         [-0.0064, -0.0261,  0.0131,  ..., -0.0040, -0.0006,  0.0102]]),\n",
       " 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight': tensor([[-0.0006,  0.0150, -0.0205,  ..., -0.0091, -0.0080, -0.0158],\n",
       "         [-0.0004,  0.0080,  0.0027,  ..., -0.0031, -0.0132, -0.0117],\n",
       "         [ 0.0383, -0.0015,  0.0086,  ...,  0.0021, -0.0007, -0.0076],\n",
       "         ...,\n",
       "         [ 0.0115,  0.0108,  0.0020,  ..., -0.0031, -0.0001,  0.0044],\n",
       "         [-0.0090, -0.0067, -0.0085,  ...,  0.0108, -0.0036, -0.0030],\n",
       "         [ 0.0112,  0.0103, -0.0017,  ..., -0.0225,  0.0064, -0.0078]]),\n",
       " 'llm.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight': tensor([[-0.0194, -0.0286,  0.0042,  ...,  0.0171, -0.0137, -0.0064],\n",
       "         [-0.0177, -0.0073, -0.0217,  ..., -0.0115, -0.0018,  0.0163],\n",
       "         [ 0.0066, -0.0242,  0.0056,  ..., -0.0037, -0.0214, -0.0069],\n",
       "         ...,\n",
       "         [-0.0148,  0.0367,  0.0240,  ..., -0.0101,  0.0005,  0.0188],\n",
       "         [-0.0045, -0.0043, -0.0101,  ..., -0.0058,  0.0029, -0.0276],\n",
       "         [ 0.0187, -0.0025, -0.0174,  ...,  0.0027,  0.0379, -0.0082]]),\n",
       " 'llm.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight': tensor([[-4.0098e-02,  3.3578e-02, -1.7398e-02,  ..., -6.6897e-03,\n",
       "          -4.1744e-03,  2.3518e-02],\n",
       "         [-6.8172e-03,  9.6515e-03,  4.5282e-04,  ..., -9.5008e-03,\n",
       "           1.2329e-02, -9.8977e-03],\n",
       "         [-2.2733e-03, -5.7589e-03, -3.1332e-03,  ...,  4.3417e-03,\n",
       "           8.5182e-03,  6.7657e-03],\n",
       "         ...,\n",
       "         [-1.2124e-02, -1.3180e-02, -1.2813e-03,  ...,  5.9248e-03,\n",
       "           9.8816e-07, -2.0335e-02],\n",
       "         [ 1.4698e-02, -1.5220e-02, -1.6256e-03,  ..., -1.4016e-02,\n",
       "           4.6216e-03,  1.0831e-02],\n",
       "         [ 6.5082e-03, -1.6103e-02,  2.9463e-03,  ...,  2.0709e-02,\n",
       "          -1.3430e-02, -8.8661e-03]]),\n",
       " 'llm.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight': tensor([[-0.0146, -0.0135, -0.0224,  ...,  0.0110, -0.0234,  0.0267],\n",
       "         [-0.0284,  0.0127,  0.0159,  ..., -0.0327,  0.0044, -0.0166],\n",
       "         [ 0.0025,  0.0259,  0.0160,  ...,  0.0223,  0.0052, -0.0229],\n",
       "         ...,\n",
       "         [-0.0225,  0.0348,  0.0345,  ...,  0.0232,  0.0011,  0.0183],\n",
       "         [ 0.0011, -0.0433,  0.0250,  ..., -0.0475,  0.0123, -0.0270],\n",
       "         [ 0.0134,  0.0110,  0.0197,  ..., -0.0238,  0.0158,  0.0167]]),\n",
       " 'llm.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight': tensor([[-0.0092,  0.0068,  0.0153,  ...,  0.0178, -0.0178,  0.0090],\n",
       "         [ 0.0108,  0.0119, -0.0031,  ..., -0.0002, -0.0103, -0.0036],\n",
       "         [-0.0075, -0.0091,  0.0043,  ..., -0.0035, -0.0026,  0.0037],\n",
       "         ...,\n",
       "         [ 0.0251, -0.0032, -0.0046,  ..., -0.0299,  0.0108,  0.0042],\n",
       "         [-0.0059,  0.0180, -0.0152,  ..., -0.0078,  0.0008, -0.0071],\n",
       "         [ 0.0206, -0.0187, -0.0185,  ...,  0.0164, -0.0088, -0.0118]]),\n",
       " 'llm.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight': tensor([[ 0.0017,  0.0280,  0.0367,  ..., -0.0299,  0.0007, -0.0282],\n",
       "         [ 0.0101, -0.0082, -0.0237,  ...,  0.0231, -0.0110,  0.0137],\n",
       "         [-0.0240,  0.0052,  0.0009,  ...,  0.0364,  0.0004, -0.0112],\n",
       "         ...,\n",
       "         [-0.0136,  0.0091, -0.0053,  ...,  0.0149, -0.0172,  0.0156],\n",
       "         [-0.0072,  0.0047, -0.0088,  ..., -0.0161, -0.0171,  0.0233],\n",
       "         [ 0.0016,  0.0289,  0.0003,  ...,  0.0123, -0.0019, -0.0076]]),\n",
       " 'llm.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight': tensor([[-0.0073, -0.0048, -0.0336,  ...,  0.0602, -0.0181,  0.0069],\n",
       "         [-0.0070, -0.0341, -0.0076,  ..., -0.0191, -0.0312,  0.0287],\n",
       "         [-0.0255,  0.0172, -0.0209,  ...,  0.0259, -0.0045,  0.0215],\n",
       "         ...,\n",
       "         [ 0.0084, -0.0131, -0.0186,  ...,  0.0255, -0.0002, -0.0252],\n",
       "         [-0.0461,  0.0195, -0.0225,  ..., -0.0003, -0.0403, -0.0075],\n",
       "         [-0.0052, -0.0010,  0.0010,  ...,  0.0122,  0.0131,  0.0070]]),\n",
       " 'llm.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight': tensor([[ 0.0035,  0.0262, -0.0060,  ..., -0.0123, -0.0087,  0.0121],\n",
       "         [-0.0066,  0.0196, -0.0277,  ..., -0.0070, -0.0041, -0.0169],\n",
       "         [-0.0131,  0.0015, -0.0119,  ...,  0.0010,  0.0082, -0.0018],\n",
       "         ...,\n",
       "         [-0.0042, -0.0045,  0.0123,  ...,  0.0136,  0.0090, -0.0098],\n",
       "         [-0.0072, -0.0524,  0.0505,  ...,  0.0138, -0.0075, -0.0256],\n",
       "         [-0.0123,  0.0278,  0.0146,  ..., -0.0050, -0.0125, -0.0244]]),\n",
       " 'llm.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight': tensor([[ 1.1262e-03,  1.0857e-02,  1.2628e-02,  ..., -3.4408e-04,\n",
       "           1.2567e-02, -1.1745e-03],\n",
       "         [-3.1920e-03, -1.2338e-02, -2.2681e-03,  ..., -6.7106e-03,\n",
       "          -1.3397e-02, -1.0439e-02],\n",
       "         [-3.1282e-03, -6.1839e-03,  1.0540e-02,  ...,  1.6958e-02,\n",
       "          -1.5479e-02,  5.4726e-03],\n",
       "         ...,\n",
       "         [-6.5174e-03, -2.1420e-02, -6.3364e-03,  ..., -7.5169e-03,\n",
       "          -3.3841e-03, -1.9317e-02],\n",
       "         [-2.2988e-02,  2.7149e-03, -1.6525e-02,  ..., -5.3556e-03,\n",
       "           6.7795e-03, -1.0948e-02],\n",
       "         [-5.3650e-03,  1.4135e-02,  1.1001e-03,  ..., -2.2424e-02,\n",
       "          -2.7166e-05,  4.1928e-03]]),\n",
       " 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight': tensor([[ 0.0113,  0.0255,  0.0178,  ..., -0.0120,  0.0185, -0.0215],\n",
       "         [ 0.0469, -0.0085,  0.0310,  ..., -0.0031, -0.0230,  0.0243],\n",
       "         [-0.0110,  0.0192, -0.0183,  ...,  0.0141, -0.0009,  0.0045],\n",
       "         ...,\n",
       "         [ 0.0254,  0.0064, -0.0452,  ...,  0.0014,  0.0075,  0.0290],\n",
       "         [ 0.0051,  0.0066, -0.0285,  ...,  0.0122,  0.0157,  0.0015],\n",
       "         [ 0.0041, -0.0094, -0.0017,  ...,  0.0011,  0.0108, -0.0075]]),\n",
       " 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0016,  0.0250, -0.0104,  ..., -0.0118, -0.0025,  0.0036],\n",
       "         [ 0.0139,  0.0458, -0.0193,  ...,  0.0113,  0.0042, -0.0223],\n",
       "         [-0.0064, -0.0173, -0.0221,  ..., -0.0065, -0.0003,  0.0018],\n",
       "         ...,\n",
       "         [ 0.0074,  0.0033, -0.0077,  ...,  0.0121,  0.0043,  0.0062],\n",
       "         [ 0.0101,  0.0074,  0.0048,  ...,  0.0042,  0.0059, -0.0015],\n",
       "         [ 0.0165, -0.0003,  0.0172,  ...,  0.0058,  0.0188, -0.0165]]),\n",
       " 'llm.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight': tensor([[-0.0032,  0.0178,  0.0255,  ..., -0.0042, -0.0116, -0.0143],\n",
       "         [ 0.0217,  0.0370,  0.0234,  ...,  0.0015,  0.0320, -0.0165],\n",
       "         [-0.0258, -0.0106, -0.0146,  ..., -0.0026, -0.0323, -0.0162],\n",
       "         ...,\n",
       "         [-0.0088,  0.0346,  0.0445,  ...,  0.0230,  0.0208, -0.0018],\n",
       "         [ 0.0029,  0.0268,  0.0293,  ...,  0.0036,  0.0049,  0.0168],\n",
       "         [ 0.0005, -0.0209,  0.0002,  ..., -0.0044,  0.0143,  0.0077]]),\n",
       " 'llm.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight': tensor([[ 0.0133, -0.0084, -0.0160,  ...,  0.0113,  0.0020, -0.0194],\n",
       "         [-0.0010, -0.0009,  0.0132,  ..., -0.0021, -0.0120, -0.0113],\n",
       "         [ 0.0160, -0.0257, -0.0273,  ...,  0.0465,  0.0332, -0.0252],\n",
       "         ...,\n",
       "         [ 0.0024,  0.0016,  0.0215,  ..., -0.0094, -0.0212,  0.0326],\n",
       "         [ 0.0242,  0.0178, -0.0135,  ...,  0.0057, -0.0081, -0.0004],\n",
       "         [-0.0056, -0.0003, -0.0028,  ..., -0.0069, -0.0055, -0.0169]]),\n",
       " 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0074, -0.0289, -0.0037,  ...,  0.0032, -0.0032,  0.0106],\n",
       "         [ 0.0129,  0.0089, -0.0143,  ...,  0.0200,  0.0026, -0.0187],\n",
       "         [-0.0059,  0.0167,  0.0081,  ..., -0.0004, -0.0163,  0.0096],\n",
       "         ...,\n",
       "         [-0.0235, -0.0095, -0.0366,  ..., -0.0073,  0.0345, -0.0050],\n",
       "         [ 0.0079,  0.0250, -0.0195,  ...,  0.0058,  0.0079,  0.0119],\n",
       "         [-0.0142,  0.0053, -0.0174,  ...,  0.0010,  0.0124, -0.0247]]),\n",
       " 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight': tensor([[-3.0715e-03,  1.4510e-02,  1.9485e-02,  ..., -5.8089e-03,\n",
       "           3.9152e-04, -6.1708e-03],\n",
       "         [ 4.4213e-03,  1.1430e-02, -1.1510e-02,  ..., -2.9947e-03,\n",
       "          -3.8244e-03,  2.9474e-03],\n",
       "         [ 4.4276e-03, -1.5368e-02,  2.1465e-02,  ..., -1.2156e-05,\n",
       "          -1.3460e-02,  1.3401e-02],\n",
       "         ...,\n",
       "         [ 3.0321e-02, -2.3038e-02, -8.4299e-03,  ..., -1.4426e-02,\n",
       "          -1.2534e-02,  4.2105e-03],\n",
       "         [ 2.4925e-03,  2.2035e-03,  1.0315e-02,  ...,  7.8323e-03,\n",
       "           9.1478e-03,  9.2790e-03],\n",
       "         [-9.7290e-04,  1.0333e-02,  2.2659e-03,  ...,  1.3543e-02,\n",
       "          -3.5595e-03, -6.5222e-03]]),\n",
       " 'llm.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight': tensor([[ 6.2362e-03,  7.5321e-05,  3.9339e-02,  ...,  2.8106e-02,\n",
       "           3.9150e-03,  1.7492e-02],\n",
       "         [-1.6776e-02,  3.7716e-02,  1.9473e-02,  ..., -3.0129e-02,\n",
       "           3.7252e-03,  1.7785e-02],\n",
       "         [ 3.3590e-03,  1.8590e-02, -7.7291e-03,  ...,  1.4942e-02,\n",
       "           1.0653e-02,  5.7740e-03],\n",
       "         ...,\n",
       "         [-1.7543e-02, -1.9570e-02,  1.1505e-02,  ...,  1.2891e-02,\n",
       "          -4.9461e-03, -1.2370e-02],\n",
       "         [ 1.9552e-04, -3.3237e-02, -9.1419e-03,  ..., -5.1832e-03,\n",
       "          -1.1733e-02, -6.5114e-03],\n",
       "         [ 2.5602e-02,  1.4829e-02, -3.1746e-02,  ..., -1.2557e-02,\n",
       "           2.9316e-02, -2.6056e-03]]),\n",
       " 'llm.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight': tensor([[-0.0021,  0.0123, -0.0296,  ..., -0.0083, -0.0035, -0.0173],\n",
       "         [ 0.0262,  0.0078,  0.0252,  ..., -0.0079, -0.0189, -0.0007],\n",
       "         [ 0.0215,  0.0128,  0.0032,  ...,  0.0196, -0.0025, -0.0041],\n",
       "         ...,\n",
       "         [ 0.0052,  0.0043,  0.0162,  ..., -0.0026, -0.0038,  0.0078],\n",
       "         [-0.0002, -0.0063,  0.0118,  ...,  0.0097, -0.0009, -0.0073],\n",
       "         [ 0.0143,  0.0098,  0.0279,  ..., -0.0119, -0.0191,  0.0292]]),\n",
       " 'llm.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight': tensor([[-0.0146,  0.0030, -0.0305,  ..., -0.0227,  0.0230, -0.0073],\n",
       "         [-0.0070,  0.0320, -0.0303,  ..., -0.0059, -0.0196, -0.0190],\n",
       "         [-0.0522, -0.0056,  0.0016,  ...,  0.0261,  0.0307,  0.0092],\n",
       "         ...,\n",
       "         [ 0.0061,  0.0124,  0.0239,  ...,  0.0069, -0.0094,  0.0077],\n",
       "         [-0.0263,  0.0142,  0.0176,  ..., -0.0135,  0.0055,  0.0144],\n",
       "         [-0.0005,  0.0450, -0.0235,  ..., -0.0178,  0.0066, -0.0114]]),\n",
       " 'llm.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight': tensor([[ 0.0089,  0.0155, -0.0042,  ..., -0.0048, -0.0140,  0.0282],\n",
       "         [-0.0221, -0.0147,  0.0012,  ...,  0.0067, -0.0058,  0.0064],\n",
       "         [ 0.0162,  0.0232, -0.0145,  ...,  0.0085, -0.0173,  0.0199],\n",
       "         ...,\n",
       "         [-0.0034, -0.0030,  0.0134,  ...,  0.0128,  0.0070,  0.0141],\n",
       "         [-0.0252,  0.0286, -0.0050,  ...,  0.0028, -0.0122, -0.0172],\n",
       "         [ 0.0116,  0.0139, -0.0028,  ..., -0.0282,  0.0254,  0.0096]]),\n",
       " 'llm.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight': tensor([[-0.0141,  0.0047,  0.0064,  ..., -0.0160,  0.0027,  0.0101],\n",
       "         [ 0.0085,  0.0046,  0.0083,  ..., -0.0141, -0.0075, -0.0015],\n",
       "         [ 0.0157,  0.0312,  0.0006,  ...,  0.0123,  0.0110,  0.0002],\n",
       "         ...,\n",
       "         [ 0.0070,  0.0298,  0.0050,  ...,  0.0096,  0.0400, -0.0010],\n",
       "         [-0.0132,  0.0237, -0.0118,  ..., -0.0068, -0.0218, -0.0041],\n",
       "         [-0.0075, -0.0084,  0.0423,  ...,  0.0141,  0.0105,  0.0145]]),\n",
       " 'llm.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight': tensor([[-0.0169,  0.0101,  0.0245,  ..., -0.0120,  0.0249,  0.0003],\n",
       "         [ 0.0014, -0.0239,  0.0217,  ...,  0.0139,  0.0136,  0.0154],\n",
       "         [-0.0255, -0.0298,  0.0185,  ...,  0.0079,  0.0404,  0.0066],\n",
       "         ...,\n",
       "         [ 0.0061,  0.0103,  0.0062,  ...,  0.0246,  0.0003, -0.0098],\n",
       "         [ 0.0252,  0.0208,  0.0050,  ..., -0.0177, -0.0174, -0.0144],\n",
       "         [-0.0060,  0.0007, -0.0064,  ...,  0.0298,  0.0058,  0.0120]]),\n",
       " 'llm.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight': tensor([[ 0.0016, -0.0168, -0.0089,  ...,  0.0391,  0.0157, -0.0189],\n",
       "         [ 0.0152, -0.0050,  0.0022,  ..., -0.0392,  0.0036,  0.0108],\n",
       "         [ 0.0117,  0.0111,  0.0363,  ..., -0.0188, -0.0235,  0.0177],\n",
       "         ...,\n",
       "         [ 0.0047, -0.0039,  0.0047,  ...,  0.0017,  0.0020, -0.0124],\n",
       "         [ 0.0251,  0.0026,  0.0149,  ...,  0.0089, -0.0154, -0.0079],\n",
       "         [-0.0107,  0.0015,  0.0137,  ...,  0.0206,  0.0066, -0.0215]]),\n",
       " 'llm.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight': tensor([[ 0.0085,  0.0114,  0.0040,  ...,  0.0160, -0.0153,  0.0171],\n",
       "         [ 0.0185, -0.0261,  0.0175,  ...,  0.0012, -0.0071, -0.0147],\n",
       "         [-0.0318,  0.0028,  0.0123,  ..., -0.0213,  0.0275, -0.0200],\n",
       "         ...,\n",
       "         [ 0.0288,  0.0035, -0.0070,  ..., -0.0061,  0.0051,  0.0003],\n",
       "         [-0.0028,  0.0068, -0.0058,  ...,  0.0006,  0.0113, -0.0097],\n",
       "         [ 0.0027, -0.0125, -0.0140,  ..., -0.0090,  0.0081, -0.0055]]),\n",
       " 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight': tensor([[-2.0488e-02, -2.3002e-02, -2.1202e-02,  ..., -1.1002e-02,\n",
       "          -2.2923e-02, -2.3555e-03],\n",
       "         [-2.4301e-03,  4.7801e-03, -2.7110e-02,  ..., -2.5857e-02,\n",
       "          -1.9879e-03,  2.8223e-02],\n",
       "         [-3.0606e-02,  3.8879e-02, -2.1335e-02,  ..., -3.0218e-03,\n",
       "          -3.3818e-03,  1.8962e-02],\n",
       "         ...,\n",
       "         [-2.3406e-03, -6.1321e-03,  4.4060e-02,  ..., -6.4623e-03,\n",
       "          -1.4575e-05, -2.8345e-02],\n",
       "         [ 7.0937e-03,  3.2046e-02, -1.8678e-02,  ...,  1.5979e-02,\n",
       "          -1.6840e-02,  3.4151e-03],\n",
       "         [-2.4091e-02, -2.2418e-02, -3.1675e-03,  ..., -5.7582e-03,\n",
       "           2.9228e-03,  3.0128e-02]]),\n",
       " 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight': tensor([[ 0.0447,  0.0357,  0.0194,  ..., -0.0096, -0.0456, -0.0043],\n",
       "         [ 0.0346,  0.0205, -0.0066,  ..., -0.0018, -0.0255,  0.0019],\n",
       "         [ 0.0256,  0.0311, -0.0146,  ..., -0.0180, -0.0276,  0.0031],\n",
       "         ...,\n",
       "         [-0.0025, -0.0088,  0.0014,  ...,  0.0037,  0.0096,  0.0162],\n",
       "         [ 0.0041,  0.0226,  0.0226,  ..., -0.0119, -0.0136, -0.0119],\n",
       "         [-0.0052, -0.0189,  0.0260,  ..., -0.0126,  0.0260, -0.0037]]),\n",
       " 'llm.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight': tensor([[ 0.0401,  0.0069, -0.0266,  ...,  0.0075, -0.0051, -0.0014],\n",
       "         [ 0.0136,  0.0302, -0.0096,  ..., -0.0304, -0.0116, -0.0007],\n",
       "         [-0.0185, -0.0158, -0.0036,  ...,  0.0037, -0.0273, -0.0092],\n",
       "         ...,\n",
       "         [-0.0241, -0.0125, -0.0024,  ..., -0.0109, -0.0135,  0.0019],\n",
       "         [-0.0276,  0.0043, -0.0134,  ...,  0.0414, -0.0153,  0.0052],\n",
       "         [-0.0004,  0.0210, -0.0293,  ...,  0.0207,  0.0003,  0.0003]]),\n",
       " 'llm.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight': tensor([[-0.0164, -0.0023, -0.0084,  ..., -0.0011,  0.0007, -0.0045],\n",
       "         [ 0.0238,  0.0124, -0.0102,  ...,  0.0095, -0.0101, -0.0019],\n",
       "         [ 0.0158,  0.0012, -0.0029,  ...,  0.0085,  0.0042,  0.0140],\n",
       "         ...,\n",
       "         [ 0.0021, -0.0191, -0.0067,  ..., -0.0047, -0.0062, -0.0185],\n",
       "         [ 0.0099,  0.0081, -0.0096,  ..., -0.0138, -0.0097, -0.0035],\n",
       "         [ 0.0137,  0.0176, -0.0068,  ...,  0.0276, -0.0039,  0.0023]]),\n",
       " 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight': tensor([[-0.0155,  0.0183,  0.0179,  ...,  0.0077,  0.0325,  0.0030],\n",
       "         [ 0.0152,  0.0167, -0.0008,  ..., -0.0236, -0.0004, -0.0051],\n",
       "         [-0.0017, -0.0108, -0.0054,  ...,  0.0109, -0.0065,  0.0251],\n",
       "         ...,\n",
       "         [-0.0109,  0.0106, -0.0043,  ...,  0.0296,  0.0052,  0.0342],\n",
       "         [-0.0047, -0.0138,  0.0047,  ..., -0.0078, -0.0280, -0.0127],\n",
       "         [-0.0203, -0.0106,  0.0079,  ...,  0.0019,  0.0137,  0.0402]]),\n",
       " 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight': tensor([[ 0.0061,  0.0040,  0.0113,  ..., -0.0028, -0.0075,  0.0130],\n",
       "         [-0.0027,  0.0045, -0.0262,  ..., -0.0145,  0.0182, -0.0110],\n",
       "         [ 0.0027,  0.0054, -0.0065,  ..., -0.0150,  0.0002, -0.0111],\n",
       "         ...,\n",
       "         [-0.0044,  0.0041,  0.0036,  ...,  0.0064,  0.0147,  0.0016],\n",
       "         [ 0.0038,  0.0146, -0.0053,  ..., -0.0152,  0.0051, -0.0029],\n",
       "         [ 0.0107,  0.0221, -0.0093,  ..., -0.0160, -0.0043, -0.0151]]),\n",
       " 'llm.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight': tensor([[-0.0040, -0.0153, -0.0158,  ..., -0.0187, -0.0011, -0.0336],\n",
       "         [ 0.0120, -0.0067, -0.0220,  ..., -0.0294, -0.0131,  0.0208],\n",
       "         [-0.0052,  0.0132, -0.0187,  ...,  0.0092, -0.0281,  0.0190],\n",
       "         ...,\n",
       "         [ 0.0195, -0.0015, -0.0164,  ..., -0.0194, -0.0283, -0.0265],\n",
       "         [-0.0077,  0.0116,  0.0146,  ..., -0.0289, -0.0195,  0.0287],\n",
       "         [-0.0047, -0.0138,  0.0076,  ..., -0.0059,  0.0208,  0.0292]]),\n",
       " 'llm.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight': tensor([[-0.0082,  0.0056,  0.0021,  ...,  0.0181,  0.0062, -0.0209],\n",
       "         [-0.0059, -0.0062, -0.0056,  ...,  0.0252, -0.0087,  0.0081],\n",
       "         [ 0.0021, -0.0248,  0.0118,  ..., -0.0155, -0.0231,  0.0148],\n",
       "         ...,\n",
       "         [-0.0113,  0.0043, -0.0032,  ..., -0.0309, -0.0223,  0.0050],\n",
       "         [-0.0097, -0.0055, -0.0210,  ...,  0.0211,  0.0107,  0.0170],\n",
       "         [ 0.0108, -0.0052, -0.0066,  ..., -0.0123, -0.0132, -0.0112]]),\n",
       " 'llm.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight': tensor([[ 0.0294,  0.0141,  0.0012,  ...,  0.0343,  0.0170,  0.0082],\n",
       "         [-0.0148,  0.0327, -0.0057,  ...,  0.0103,  0.0073, -0.0031],\n",
       "         [-0.0236, -0.0188, -0.0016,  ..., -0.0272, -0.0205, -0.0005],\n",
       "         ...,\n",
       "         [-0.0040,  0.0067, -0.0407,  ...,  0.0033,  0.0015, -0.0021],\n",
       "         [ 0.0040, -0.0161,  0.0164,  ..., -0.0248, -0.0137, -0.0261],\n",
       "         [ 0.0074, -0.0117,  0.0022,  ..., -0.0264, -0.0057,  0.0301]]),\n",
       " 'llm.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight': tensor([[ 1.3115e-02, -7.0239e-03,  1.9277e-02,  ..., -1.0122e-02,\n",
       "           2.0085e-02, -1.3976e-04],\n",
       "         [ 1.0201e-02, -7.0661e-03, -4.0217e-03,  ..., -1.0052e-02,\n",
       "           2.5007e-03,  7.0586e-03],\n",
       "         [-2.7843e-02, -2.1361e-02,  1.5694e-02,  ..., -1.9971e-03,\n",
       "           2.3076e-03,  1.7053e-02],\n",
       "         ...,\n",
       "         [ 9.2268e-03, -4.4982e-03, -1.3371e-02,  ...,  9.9213e-05,\n",
       "          -1.4956e-02,  6.8857e-03],\n",
       "         [ 9.2780e-03,  2.0722e-02,  8.7385e-03,  ...,  1.8212e-02,\n",
       "          -1.1143e-03,  6.2680e-03],\n",
       "         [ 1.2330e-02,  7.3771e-03,  2.6456e-02,  ..., -3.0126e-02,\n",
       "           1.0273e-02, -2.3085e-03]]),\n",
       " 'llm.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight': tensor([[-0.0151,  0.0260, -0.0010,  ..., -0.0149, -0.0303, -0.0135],\n",
       "         [-0.0384, -0.0221, -0.0320,  ...,  0.0067,  0.0270, -0.0122],\n",
       "         [-0.0240, -0.0215,  0.0234,  ...,  0.0168, -0.0076, -0.0236],\n",
       "         ...,\n",
       "         [-0.0245, -0.0311,  0.0419,  ..., -0.0124,  0.0390, -0.0011],\n",
       "         [-0.0282,  0.0216,  0.0069,  ...,  0.0192,  0.0201,  0.0160],\n",
       "         [-0.0120, -0.0273, -0.0193,  ...,  0.0331,  0.0096, -0.0270]]),\n",
       " 'llm.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight': tensor([[ 0.0104,  0.0060,  0.0172,  ...,  0.0027, -0.0131, -0.0081],\n",
       "         [-0.0041,  0.0087, -0.0027,  ...,  0.0098,  0.0115, -0.0195],\n",
       "         [-0.0443, -0.0029, -0.0326,  ..., -0.0247,  0.0132, -0.0175],\n",
       "         ...,\n",
       "         [ 0.0233,  0.0296, -0.0102,  ...,  0.0080,  0.0309, -0.0085],\n",
       "         [ 0.0386,  0.0158,  0.0057,  ..., -0.0064,  0.0148,  0.0190],\n",
       "         [ 0.0051,  0.0029,  0.0423,  ...,  0.0004, -0.0243, -0.0427]]),\n",
       " 'llm.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight': tensor([[ 0.0139, -0.0428, -0.0185,  ...,  0.0104,  0.0205,  0.0239],\n",
       "         [ 0.0079,  0.0125,  0.0052,  ..., -0.0136, -0.0046,  0.0221],\n",
       "         [ 0.0112, -0.0468,  0.0248,  ...,  0.0131, -0.0090, -0.0148],\n",
       "         ...,\n",
       "         [-0.0122, -0.0006, -0.0349,  ...,  0.0048, -0.0114, -0.0014],\n",
       "         [-0.0110,  0.0140,  0.0292,  ...,  0.0061, -0.0022, -0.0102],\n",
       "         [-0.0021, -0.0187, -0.0058,  ..., -0.0440,  0.0006,  0.0164]]),\n",
       " 'llm.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight': tensor([[-6.4829e-03, -1.8348e-02,  2.7542e-02,  ...,  2.2512e-02,\n",
       "          -2.4174e-02, -1.2947e-02],\n",
       "         [ 6.0937e-05,  2.4827e-02, -8.9653e-03,  ..., -3.7183e-03,\n",
       "           3.8783e-03,  1.2429e-02],\n",
       "         [-5.8433e-03, -1.7520e-03,  7.7474e-03,  ..., -5.5953e-03,\n",
       "          -2.8317e-02,  8.6336e-04],\n",
       "         ...,\n",
       "         [ 1.5204e-03, -1.4594e-02, -2.3148e-02,  ...,  3.5210e-03,\n",
       "           1.4600e-02, -6.0747e-03],\n",
       "         [ 1.1256e-02,  1.6739e-02, -1.1980e-02,  ...,  7.5191e-03,\n",
       "           3.5314e-03, -5.1425e-03],\n",
       "         [ 1.9559e-03,  1.5333e-02, -1.5058e-02,  ..., -8.7778e-03,\n",
       "           9.5532e-04,  1.6740e-02]])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_checkpoint = {k: v for k, v in checkpoint.items() if 'llm.' in k}\n",
    "llm_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token_id=128009\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['model.embed_tokens.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.mlp.down_proj.weight', 'model.layers.0.input_layernorm.weight', 'model.layers.0.post_attention_layernorm.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.input_layernorm.weight', 'model.layers.1.post_attention_layernorm.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.input_layernorm.weight', 'model.layers.2.post_attention_layernorm.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.input_layernorm.weight', 'model.layers.3.post_attention_layernorm.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.input_layernorm.weight', 'model.layers.4.post_attention_layernorm.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.input_layernorm.weight', 'model.layers.5.post_attention_layernorm.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.input_layernorm.weight', 'model.layers.6.post_attention_layernorm.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.input_layernorm.weight', 'model.layers.7.post_attention_layernorm.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.input_layernorm.weight', 'model.layers.8.post_attention_layernorm.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.input_layernorm.weight', 'model.layers.9.post_attention_layernorm.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.input_layernorm.weight', 'model.layers.10.post_attention_layernorm.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.input_layernorm.weight', 'model.layers.11.post_attention_layernorm.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.input_layernorm.weight', 'model.layers.12.post_attention_layernorm.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.input_layernorm.weight', 'model.layers.13.post_attention_layernorm.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.input_layernorm.weight', 'model.layers.14.post_attention_layernorm.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.input_layernorm.weight', 'model.layers.15.post_attention_layernorm.weight', 'model.norm.weight', 'lm_head.weight'], unexpected_keys=['llm.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'llm.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(llm_checkpoint, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "full_path is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/full_path/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1221\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1325\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1823\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1822\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1823\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1825\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1722\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1722\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1645\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1645\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1654\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:372\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 372\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:396\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    395\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:352\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    344\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m     )\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-679aea24-2e99b2fa3286c3a22e87c3b9;86e1c90e-6c62-4abc-9386-e7b783da084c)\n\nRepository Not Found for url: https://huggingface.co/full_path/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load a pretrained LLM and tokenizer\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_path\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your specific LLM model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Assume we have a learned speech embedding (output of the projector)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# In practice, this would come from your speech embedding model\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:487\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m--> 487\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/transformers/utils/hub.py:426\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: full_path is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Load a pretrained LLM and tokenizer\n",
    "model_name = \"full_path\"  # Replace with your specific LLM model\n",
    "llm = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Assume we have a learned speech embedding (output of the projector)\n",
    "# In practice, this would come from your speech embedding model\n",
    "learned_speech_embedding = torch.randn(1, llm.config.hidden_size)\n",
    "print(learned_speech_embedding)\n",
    "\n",
    "# Get the LLM's token embeddings\n",
    "llm_embeddings = llm.get_input_embeddings().weight\n",
    "\n",
    "# Compute cosine similarity between the learned embedding and all token embeddings\n",
    "similarities = F.cosine_similarity(learned_speech_embedding, llm_embeddings, dim=1)\n",
    "\n",
    "# Find the index of the most similar token\n",
    "closest_token_idx = similarities.argmax().item()\n",
    "\n",
    "# Get the actual token (not decoded text) from the tokenizer's vocabulary\n",
    "closest_token = tokenizer.convert_ids_to_tokens([closest_token_idx])[0]\n",
    "\n",
    "print(f\"Most similar token: {closest_token}\")\n",
    "print(f\"Token ID: {closest_token_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Load a custom LLaMA 3.2 1B model and tokenizer from a checkpoint\n",
    "model_name = \"path_to_llama_model\"  # Replace with the local path or model hub path for LLaMA 3.2 1B\n",
    "llm = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Assume we have a learned speech embedding (output of the projector)\n",
    "# In practice, this would come from your speech embedding model\n",
    "learned_speech_embedding = torch.randn(1, llm.config.hidden_size)\n",
    "print(learned_speech_embedding)\n",
    "\n",
    "# Get the LLaMA model's token embeddings\n",
    "llm_embeddings = llm.get_input_embeddings().weight\n",
    "\n",
    "# Compute cosine similarity between the learned embedding and all token embeddings\n",
    "similarities = F.cosine_similarity(learned_speech_embedding, llm_embeddings, dim=1)\n",
    "\n",
    "# Find the index of the most similar token\n",
    "closest_token_idx = similarities.argmax().item()\n",
    "\n",
    "# Get the actual token (not decoded text) from the tokenizer's vocabulary\n",
    "closest_token = tokenizer.convert_ids_to_tokens([closest_token_idx])[0]\n",
    "\n",
    "print(f\"Most similar token: {closest_token}\")\n",
    "print(f\"Token ID: {closest_token_idx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
