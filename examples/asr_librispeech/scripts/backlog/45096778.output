/work/van-speech-nlp/jindaznb/slamenv/bin/python
Configuration:
Task: all
Prompt Flag: 
Config File: wavlm-mono
Epochs: 2
Batch Size: 4
Data Folder: ami_phoneme_only
Use PEFT: true
LLM Name: llama32_1b
Freeze Encoder: true
speech encoder name: wavlm
speech encoder path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt
speech encoder2 name: 
speech encoder2 path: 
llm_path: 
use_peft: true
use_fp16: 
Final identifier: ami_phoneme_only_wavlm_llama32_1b_linear_peft
Latest file: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_4165_loss_0.5406042337417603/model.pt
ckpt_folder: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_4165_loss_0.5406042337417603
Resume epoch: 2
Resume step: 4165
[2024-11-14 09:02:01][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 4165, 'resume_epoch': 2, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-11-14 09:02:01][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-11-14 09:02:01][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-11-14 09:02:01][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'ami_phoneme_only_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-11-14_09-02-00.txt', 'log_interval': 5}
[2024-11-14 09:02:23][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-11-14 09:02:29][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-11-14 09:02:29][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-11-14 09:02:29][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-11-14 09:02:29][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-11-14 09:02:38][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-14 09:02:38][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-11-14 09:02:38][slam_llm.models.slam_model][INFO] - setup peft...
trainable params: 5,636,096 || all params: 1,241,450,496 || trainable%: 0.4539928106807088
[2024-11-14 09:02:38][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-14 09:02:38][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-11-14 09:02:38][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-11-14 09:02:38][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-11-14 09:02:38][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_4165_loss_0.5406042337417603/model.pt
[2024-11-14 09:02:38][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-11-14 09:02:38][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-11-14 09:02:41][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_phoneme_only/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_phoneme_only/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-11-14 09:02:43][root][INFO] - --> Training Set Length = 66681
[2024-11-14 09:02:43][root][INFO] - --> Validation Set Length = 8348
[2024-11-14 09:02:43][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-14 09:02:43][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-14 09:02:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:48][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-11-14 09:02:49][root][INFO] - Training Epoch: 2/2, step 4165/16670 completed (loss: 0.2844129204750061, acc: 0.9178082346916199)
[2024-11-14 09:02:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:49][root][INFO] - Training Epoch: 2/2, step 4166/16670 completed (loss: 0.14568820595741272, acc: 0.9616307020187378)
[2024-11-14 09:02:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:50][root][INFO] - Training Epoch: 2/2, step 4167/16670 completed (loss: 0.23451976478099823, acc: 0.9322034120559692)
[2024-11-14 09:02:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:50][root][INFO] - Training Epoch: 2/2, step 4168/16670 completed (loss: 0.0395376943051815, acc: 0.9829787015914917)
[2024-11-14 09:02:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:51][root][INFO] - Training Epoch: 2/2, step 4169/16670 completed (loss: 0.21539311110973358, acc: 0.9473684430122375)
[2024-11-14 09:02:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:51][root][INFO] - Training Epoch: 2/2, step 4170/16670 completed (loss: 0.11873074620962143, acc: 0.9559471607208252)
[2024-11-14 09:02:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:51][root][INFO] - Training Epoch: 2/2, step 4171/16670 completed (loss: 0.07737438380718231, acc: 0.9800000190734863)
[2024-11-14 09:02:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:52][root][INFO] - Training Epoch: 2/2, step 4172/16670 completed (loss: 0.07194089889526367, acc: 0.9905660152435303)
[2024-11-14 09:02:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:52][root][INFO] - Training Epoch: 2/2, step 4173/16670 completed (loss: 0.14796586334705353, acc: 0.9535714387893677)
[2024-11-14 09:02:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:52][root][INFO] - Training Epoch: 2/2, step 4174/16670 completed (loss: 0.11135925352573395, acc: 0.9644268751144409)
[2024-11-14 09:02:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:53][root][INFO] - Training Epoch: 2/2, step 4175/16670 completed (loss: 0.2539350390434265, acc: 0.9342105388641357)
[2024-11-14 09:02:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:53][root][INFO] - Training Epoch: 2/2, step 4176/16670 completed (loss: 0.18677417933940887, acc: 0.9560975432395935)
[2024-11-14 09:02:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:54][root][INFO] - Training Epoch: 2/2, step 4177/16670 completed (loss: 0.07828604429960251, acc: 0.9731343388557434)
[2024-11-14 09:02:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:54][root][INFO] - Training Epoch: 2/2, step 4178/16670 completed (loss: 0.07641959190368652, acc: 0.9763033390045166)
[2024-11-14 09:02:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:54][root][INFO] - Training Epoch: 2/2, step 4179/16670 completed (loss: 0.13347052037715912, acc: 0.9658119678497314)
[2024-11-14 09:02:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:55][root][INFO] - Training Epoch: 2/2, step 4180/16670 completed (loss: 0.15169993042945862, acc: 0.9513677954673767)
[2024-11-14 09:02:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:55][root][INFO] - Training Epoch: 2/2, step 4181/16670 completed (loss: 0.2788730561733246, acc: 0.9589040875434875)
[2024-11-14 09:02:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:55][root][INFO] - Training Epoch: 2/2, step 4182/16670 completed (loss: 0.11731129139661789, acc: 0.9638554453849792)
[2024-11-14 09:02:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:56][root][INFO] - Training Epoch: 2/2, step 4183/16670 completed (loss: 0.11197305470705032, acc: 0.9550561904907227)
[2024-11-14 09:02:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:56][root][INFO] - Training Epoch: 2/2, step 4184/16670 completed (loss: 0.08147378265857697, acc: 0.9776358008384705)
[2024-11-14 09:02:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:57][root][INFO] - Training Epoch: 2/2, step 4185/16670 completed (loss: 0.15229962766170502, acc: 0.9601989984512329)
[2024-11-14 09:02:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:57][root][INFO] - Training Epoch: 2/2, step 4186/16670 completed (loss: 0.18186485767364502, acc: 0.9569892287254333)
[2024-11-14 09:02:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:57][root][INFO] - Training Epoch: 2/2, step 4187/16670 completed (loss: 0.18606874346733093, acc: 0.9473684430122375)
[2024-11-14 09:02:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:58][root][INFO] - Training Epoch: 2/2, step 4188/16670 completed (loss: 0.19410134851932526, acc: 0.9311594367027283)
[2024-11-14 09:02:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:58][root][INFO] - Training Epoch: 2/2, step 4189/16670 completed (loss: 0.2376493364572525, acc: 0.9473684430122375)
[2024-11-14 09:02:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:59][root][INFO] - Training Epoch: 2/2, step 4190/16670 completed (loss: 0.1424378752708435, acc: 0.9554139971733093)
[2024-11-14 09:02:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:59][root][INFO] - Training Epoch: 2/2, step 4191/16670 completed (loss: 0.28403252363204956, acc: 0.9122806787490845)
[2024-11-14 09:02:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:02:59][root][INFO] - Training Epoch: 2/2, step 4192/16670 completed (loss: 0.09134916961193085, acc: 0.967391312122345)
[2024-11-14 09:02:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:00][root][INFO] - Training Epoch: 2/2, step 4193/16670 completed (loss: 0.1334477961063385, acc: 0.9665551781654358)
[2024-11-14 09:03:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:00][root][INFO] - Training Epoch: 2/2, step 4194/16670 completed (loss: 0.11487677693367004, acc: 0.9661017060279846)
[2024-11-14 09:03:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:00][root][INFO] - Training Epoch: 2/2, step 4195/16670 completed (loss: 0.09568856656551361, acc: 0.970695972442627)
[2024-11-14 09:03:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:01][root][INFO] - Training Epoch: 2/2, step 4196/16670 completed (loss: 0.16417652368545532, acc: 0.9622641801834106)
[2024-11-14 09:03:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:01][root][INFO] - Training Epoch: 2/2, step 4197/16670 completed (loss: 0.1519578993320465, acc: 0.9473684430122375)
[2024-11-14 09:03:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:02][root][INFO] - Training Epoch: 2/2, step 4198/16670 completed (loss: 0.06429194658994675, acc: 0.9836956262588501)
[2024-11-14 09:03:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:02][root][INFO] - Training Epoch: 2/2, step 4199/16670 completed (loss: 0.17574948072433472, acc: 0.9503546357154846)
[2024-11-14 09:03:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:02][root][INFO] - Training Epoch: 2/2, step 4200/16670 completed (loss: 0.23237484693527222, acc: 0.9156118035316467)
[2024-11-14 09:03:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:03][root][INFO] - Training Epoch: 2/2, step 4201/16670 completed (loss: 0.20672744512557983, acc: 0.9382715821266174)
[2024-11-14 09:03:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:03][root][INFO] - Training Epoch: 2/2, step 4202/16670 completed (loss: 0.15746067464351654, acc: 0.957446813583374)
[2024-11-14 09:03:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:03][root][INFO] - Training Epoch: 2/2, step 4203/16670 completed (loss: 0.06010442599654198, acc: 0.9875518679618835)
[2024-11-14 09:03:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:04][root][INFO] - Training Epoch: 2/2, step 4204/16670 completed (loss: 0.24049855768680573, acc: 0.9365671873092651)
[2024-11-14 09:03:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:04][root][INFO] - Training Epoch: 2/2, step 4205/16670 completed (loss: 0.07385099679231644, acc: 0.9819004535675049)
[2024-11-14 09:03:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:05][root][INFO] - Training Epoch: 2/2, step 4206/16670 completed (loss: 0.1429968774318695, acc: 0.9493243098258972)
[2024-11-14 09:03:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:05][root][INFO] - Training Epoch: 2/2, step 4207/16670 completed (loss: 0.17648786306381226, acc: 0.9395973086357117)
[2024-11-14 09:03:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:05][root][INFO] - Training Epoch: 2/2, step 4208/16670 completed (loss: 0.10776195675134659, acc: 0.9576719403266907)
[2024-11-14 09:03:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:06][root][INFO] - Training Epoch: 2/2, step 4209/16670 completed (loss: 0.10029713809490204, acc: 0.9816513657569885)
[2024-11-14 09:03:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:06][root][INFO] - Training Epoch: 2/2, step 4210/16670 completed (loss: 0.14537636935710907, acc: 0.9552238583564758)
[2024-11-14 09:03:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:06][root][INFO] - Training Epoch: 2/2, step 4211/16670 completed (loss: 0.17526713013648987, acc: 0.9554656147956848)
[2024-11-14 09:03:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:07][root][INFO] - Training Epoch: 2/2, step 4212/16670 completed (loss: 0.16129817068576813, acc: 0.9487179517745972)
[2024-11-14 09:03:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:07][root][INFO] - Training Epoch: 2/2, step 4213/16670 completed (loss: 0.13321170210838318, acc: 0.960698664188385)
[2024-11-14 09:03:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:07][root][INFO] - Training Epoch: 2/2, step 4214/16670 completed (loss: 0.09505343437194824, acc: 0.9751861095428467)
[2024-11-14 09:03:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:08][root][INFO] - Training Epoch: 2/2, step 4215/16670 completed (loss: 0.09783367812633514, acc: 0.9751037359237671)
[2024-11-14 09:03:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:08][root][INFO] - Training Epoch: 2/2, step 4216/16670 completed (loss: 0.121079221367836, acc: 0.9722222089767456)
[2024-11-14 09:03:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:08][root][INFO] - Training Epoch: 2/2, step 4217/16670 completed (loss: 0.09685051441192627, acc: 0.9720930457115173)
[2024-11-14 09:03:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:09][root][INFO] - Training Epoch: 2/2, step 4218/16670 completed (loss: 0.20695269107818604, acc: 0.9449999928474426)
[2024-11-14 09:03:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:09][root][INFO] - Training Epoch: 2/2, step 4219/16670 completed (loss: 0.08848223090171814, acc: 0.9726027250289917)
[2024-11-14 09:03:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:09][root][INFO] - Training Epoch: 2/2, step 4220/16670 completed (loss: 0.11448120325803757, acc: 0.9563318490982056)
[2024-11-14 09:03:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:10][root][INFO] - Training Epoch: 2/2, step 4221/16670 completed (loss: 0.07246363162994385, acc: 0.9777777791023254)
[2024-11-14 09:03:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:10][root][INFO] - Training Epoch: 2/2, step 4222/16670 completed (loss: 0.2675715386867523, acc: 0.9197080135345459)
[2024-11-14 09:03:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:11][root][INFO] - Training Epoch: 2/2, step 4223/16670 completed (loss: 0.13090214133262634, acc: 0.9628571271896362)
[2024-11-14 09:03:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:11][root][INFO] - Training Epoch: 2/2, step 4224/16670 completed (loss: 0.10722536593675613, acc: 0.9722222089767456)
[2024-11-14 09:03:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:11][root][INFO] - Training Epoch: 2/2, step 4225/16670 completed (loss: 0.07402613013982773, acc: 0.9791666865348816)
[2024-11-14 09:03:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:12][root][INFO] - Training Epoch: 2/2, step 4226/16670 completed (loss: 0.08581865578889847, acc: 0.9760956168174744)
[2024-11-14 09:03:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:12][root][INFO] - Training Epoch: 2/2, step 4227/16670 completed (loss: 0.11702477186918259, acc: 0.9728260636329651)
[2024-11-14 09:03:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:13][root][INFO] - Training Epoch: 2/2, step 4228/16670 completed (loss: 0.22505606710910797, acc: 0.9401993155479431)
[2024-11-14 09:03:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:13][root][INFO] - Training Epoch: 2/2, step 4229/16670 completed (loss: 0.08637630939483643, acc: 0.9840425252914429)
[2024-11-14 09:03:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:13][root][INFO] - Training Epoch: 2/2, step 4230/16670 completed (loss: 0.09552304446697235, acc: 0.9727272987365723)
[2024-11-14 09:03:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:14][root][INFO] - Training Epoch: 2/2, step 4231/16670 completed (loss: 0.12290085852146149, acc: 0.9651162624359131)
[2024-11-14 09:03:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:14][root][INFO] - Training Epoch: 2/2, step 4232/16670 completed (loss: 0.15599995851516724, acc: 0.9624999761581421)
[2024-11-14 09:03:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:14][root][INFO] - Training Epoch: 2/2, step 4233/16670 completed (loss: 0.17489127814769745, acc: 0.9493087530136108)
[2024-11-14 09:03:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:15][root][INFO] - Training Epoch: 2/2, step 4234/16670 completed (loss: 0.08658431470394135, acc: 0.9661017060279846)
[2024-11-14 09:03:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:15][root][INFO] - Training Epoch: 2/2, step 4235/16670 completed (loss: 0.21179720759391785, acc: 0.9433962106704712)
[2024-11-14 09:03:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:16][root][INFO] - Training Epoch: 2/2, step 4236/16670 completed (loss: 0.07995761930942535, acc: 0.9698629975318909)
[2024-11-14 09:03:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:16][root][INFO] - Training Epoch: 2/2, step 4237/16670 completed (loss: 0.19166840612888336, acc: 0.9482758641242981)
[2024-11-14 09:03:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:16][root][INFO] - Training Epoch: 2/2, step 4238/16670 completed (loss: 0.11135076731443405, acc: 0.973372757434845)
[2024-11-14 09:03:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:17][root][INFO] - Training Epoch: 2/2, step 4239/16670 completed (loss: 0.09876832365989685, acc: 0.9675675630569458)
[2024-11-14 09:03:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:17][root][INFO] - Training Epoch: 2/2, step 4240/16670 completed (loss: 0.16352570056915283, acc: 0.9613259434700012)
[2024-11-14 09:03:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:17][root][INFO] - Training Epoch: 2/2, step 4241/16670 completed (loss: 0.21013279259204865, acc: 0.9353612065315247)
[2024-11-14 09:03:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:18][root][INFO] - Training Epoch: 2/2, step 4242/16670 completed (loss: 0.07259227335453033, acc: 0.988950252532959)
[2024-11-14 09:03:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:18][root][INFO] - Training Epoch: 2/2, step 4243/16670 completed (loss: 0.010224923491477966, acc: 1.0)
[2024-11-14 09:03:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:19][root][INFO] - Training Epoch: 2/2, step 4244/16670 completed (loss: 0.09377851337194443, acc: 0.9585062265396118)
[2024-11-14 09:03:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:19][root][INFO] - Training Epoch: 2/2, step 4245/16670 completed (loss: 0.14137667417526245, acc: 0.9563318490982056)
[2024-11-14 09:03:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:19][root][INFO] - Training Epoch: 2/2, step 4246/16670 completed (loss: 0.11913445591926575, acc: 0.9672897458076477)
[2024-11-14 09:03:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:20][root][INFO] - Training Epoch: 2/2, step 4247/16670 completed (loss: 0.07741667330265045, acc: 0.9777777791023254)
[2024-11-14 09:03:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:20][root][INFO] - Training Epoch: 2/2, step 4248/16670 completed (loss: 0.11045213043689728, acc: 0.9578059315681458)
[2024-11-14 09:03:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:21][root][INFO] - Training Epoch: 2/2, step 4249/16670 completed (loss: 0.1340787559747696, acc: 0.953667938709259)
[2024-11-14 09:03:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:21][root][INFO] - Training Epoch: 2/2, step 4250/16670 completed (loss: 0.04656035453081131, acc: 0.9801980257034302)
[2024-11-14 09:03:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:21][root][INFO] - Training Epoch: 2/2, step 4251/16670 completed (loss: 0.07062536478042603, acc: 0.9784482717514038)
[2024-11-14 09:03:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:22][root][INFO] - Training Epoch: 2/2, step 4252/16670 completed (loss: 0.23421351611614227, acc: 0.9369369149208069)
[2024-11-14 09:03:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:22][root][INFO] - Training Epoch: 2/2, step 4253/16670 completed (loss: 0.1308916211128235, acc: 0.9533898234367371)
[2024-11-14 09:03:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:23][root][INFO] - Training Epoch: 2/2, step 4254/16670 completed (loss: 0.2222917526960373, acc: 0.9482758641242981)
[2024-11-14 09:03:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:23][root][INFO] - Training Epoch: 2/2, step 4255/16670 completed (loss: 0.14600995182991028, acc: 0.9614148139953613)
[2024-11-14 09:03:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:23][root][INFO] - Training Epoch: 2/2, step 4256/16670 completed (loss: 0.07427562028169632, acc: 0.9753086566925049)
[2024-11-14 09:03:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:24][root][INFO] - Training Epoch: 2/2, step 4257/16670 completed (loss: 0.13097858428955078, acc: 0.974452555179596)
[2024-11-14 09:03:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:24][root][INFO] - Training Epoch: 2/2, step 4258/16670 completed (loss: 0.04341084510087967, acc: 0.9967319965362549)
[2024-11-14 09:03:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:25][root][INFO] - Training Epoch: 2/2, step 4259/16670 completed (loss: 0.1512220948934555, acc: 0.9595588445663452)
[2024-11-14 09:03:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:25][root][INFO] - Training Epoch: 2/2, step 4260/16670 completed (loss: 0.054855868220329285, acc: 0.9844961166381836)
[2024-11-14 09:03:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:25][root][INFO] - Training Epoch: 2/2, step 4261/16670 completed (loss: 0.11259129643440247, acc: 0.9751037359237671)
[2024-11-14 09:03:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:26][root][INFO] - Training Epoch: 2/2, step 4262/16670 completed (loss: 0.180127814412117, acc: 0.953125)
[2024-11-14 09:03:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:26][root][INFO] - Training Epoch: 2/2, step 4263/16670 completed (loss: 0.09007883816957474, acc: 0.9785714149475098)
[2024-11-14 09:03:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:27][root][INFO] - Training Epoch: 2/2, step 4264/16670 completed (loss: 0.15048567950725555, acc: 0.9618528485298157)
[2024-11-14 09:03:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:27][root][INFO] - Training Epoch: 2/2, step 4265/16670 completed (loss: 0.1273643672466278, acc: 0.9624413251876831)
[2024-11-14 09:03:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:27][root][INFO] - Training Epoch: 2/2, step 4266/16670 completed (loss: 0.050075940787792206, acc: 0.9776358008384705)
[2024-11-14 09:03:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:28][root][INFO] - Training Epoch: 2/2, step 4267/16670 completed (loss: 0.059824198484420776, acc: 0.9819004535675049)
[2024-11-14 09:03:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:28][root][INFO] - Training Epoch: 2/2, step 4268/16670 completed (loss: 0.09077319502830505, acc: 0.977011501789093)
[2024-11-14 09:03:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:29][root][INFO] - Training Epoch: 2/2, step 4269/16670 completed (loss: 0.15283313393592834, acc: 0.9618644118309021)
[2024-11-14 09:03:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:29][root][INFO] - Training Epoch: 2/2, step 4270/16670 completed (loss: 0.09437102824449539, acc: 0.9747899174690247)
[2024-11-14 09:03:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:29][root][INFO] - Training Epoch: 2/2, step 4271/16670 completed (loss: 0.1790696233510971, acc: 0.9465240836143494)
[2024-11-14 09:03:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:30][root][INFO] - Training Epoch: 2/2, step 4272/16670 completed (loss: 0.11160973459482193, acc: 0.9644970297813416)
[2024-11-14 09:03:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:30][root][INFO] - Training Epoch: 2/2, step 4273/16670 completed (loss: 0.1181039810180664, acc: 0.9719298481941223)
[2024-11-14 09:03:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:30][root][INFO] - Training Epoch: 2/2, step 4274/16670 completed (loss: 0.10959579050540924, acc: 0.9636363387107849)
[2024-11-14 09:03:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:31][root][INFO] - Training Epoch: 2/2, step 4275/16670 completed (loss: 0.05211396887898445, acc: 0.9836734533309937)
[2024-11-14 09:03:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:31][root][INFO] - Training Epoch: 2/2, step 4276/16670 completed (loss: 0.06020672991871834, acc: 0.9849624037742615)
[2024-11-14 09:03:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:31][root][INFO] - Training Epoch: 2/2, step 4277/16670 completed (loss: 0.11852408945560455, acc: 0.9659090638160706)
[2024-11-14 09:03:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:32][root][INFO] - Training Epoch: 2/2, step 4278/16670 completed (loss: 0.1569463461637497, acc: 0.9520000219345093)
[2024-11-14 09:03:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:32][root][INFO] - Training Epoch: 2/2, step 4279/16670 completed (loss: 0.07119038701057434, acc: 0.9679715037345886)
[2024-11-14 09:03:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:33][root][INFO] - Training Epoch: 2/2, step 4280/16670 completed (loss: 0.03970303386449814, acc: 0.991631805896759)
[2024-11-14 09:03:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:33][root][INFO] - Training Epoch: 2/2, step 4281/16670 completed (loss: 0.09317776560783386, acc: 0.9793814420700073)
[2024-11-14 09:03:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:33][root][INFO] - Training Epoch: 2/2, step 4282/16670 completed (loss: 0.1445532590150833, acc: 0.9772727489471436)
[2024-11-14 09:03:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:34][root][INFO] - Training Epoch: 2/2, step 4283/16670 completed (loss: 0.1195477545261383, acc: 0.9760765433311462)
[2024-11-14 09:03:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:34][root][INFO] - Training Epoch: 2/2, step 4284/16670 completed (loss: 0.16509784758090973, acc: 0.95652174949646)
[2024-11-14 09:03:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:34][root][INFO] - Training Epoch: 2/2, step 4285/16670 completed (loss: 0.10144206136465073, acc: 0.9740259647369385)
[2024-11-14 09:03:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:35][root][INFO] - Training Epoch: 2/2, step 4286/16670 completed (loss: 0.09858852624893188, acc: 0.9712041616439819)
[2024-11-14 09:03:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:35][root][INFO] - Training Epoch: 2/2, step 4287/16670 completed (loss: 0.17925699055194855, acc: 0.9448819160461426)
[2024-11-14 09:03:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:36][root][INFO] - Training Epoch: 2/2, step 4288/16670 completed (loss: 0.07031267136335373, acc: 0.9843260049819946)
[2024-11-14 09:03:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:36][root][INFO] - Training Epoch: 2/2, step 4289/16670 completed (loss: 0.08770778775215149, acc: 0.9734848737716675)
[2024-11-14 09:03:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:36][root][INFO] - Training Epoch: 2/2, step 4290/16670 completed (loss: 0.06893099844455719, acc: 0.9845201373100281)
[2024-11-14 09:03:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:37][root][INFO] - Training Epoch: 2/2, step 4291/16670 completed (loss: 0.18600191175937653, acc: 0.9457013607025146)
[2024-11-14 09:03:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:37][root][INFO] - Training Epoch: 2/2, step 4292/16670 completed (loss: 0.18624304234981537, acc: 0.9609755873680115)
[2024-11-14 09:03:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:37][root][INFO] - Training Epoch: 2/2, step 4293/16670 completed (loss: 0.15249350666999817, acc: 0.9552845358848572)
[2024-11-14 09:03:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:38][root][INFO] - Training Epoch: 2/2, step 4294/16670 completed (loss: 0.0741899311542511, acc: 0.980988621711731)
[2024-11-14 09:03:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:38][root][INFO] - Training Epoch: 2/2, step 4295/16670 completed (loss: 0.17912226915359497, acc: 0.9604862928390503)
[2024-11-14 09:03:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:39][root][INFO] - Training Epoch: 2/2, step 4296/16670 completed (loss: 0.12711961567401886, acc: 0.9566786885261536)
[2024-11-14 09:03:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:39][root][INFO] - Training Epoch: 2/2, step 4297/16670 completed (loss: 0.11982651799917221, acc: 0.9780219793319702)
[2024-11-14 09:03:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:39][root][INFO] - Training Epoch: 2/2, step 4298/16670 completed (loss: 0.22168532013893127, acc: 0.9568345546722412)
[2024-11-14 09:03:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:40][root][INFO] - Training Epoch: 2/2, step 4299/16670 completed (loss: 0.13808849453926086, acc: 0.9576271176338196)
[2024-11-14 09:03:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:40][root][INFO] - Training Epoch: 2/2, step 4300/16670 completed (loss: 0.08662763237953186, acc: 0.9793510437011719)
[2024-11-14 09:03:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:40][root][INFO] - Training Epoch: 2/2, step 4301/16670 completed (loss: 0.10350857675075531, acc: 0.978787899017334)
[2024-11-14 09:03:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:41][root][INFO] - Training Epoch: 2/2, step 4302/16670 completed (loss: 0.22848238050937653, acc: 0.94140625)
[2024-11-14 09:03:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:41][root][INFO] - Training Epoch: 2/2, step 4303/16670 completed (loss: 0.09351536631584167, acc: 0.9736841917037964)
[2024-11-14 09:03:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:41][root][INFO] - Training Epoch: 2/2, step 4304/16670 completed (loss: 0.16542811691761017, acc: 0.9636363387107849)
[2024-11-14 09:03:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:42][root][INFO] - Training Epoch: 2/2, step 4305/16670 completed (loss: 0.06499303877353668, acc: 0.977477490901947)
[2024-11-14 09:03:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:42][root][INFO] - Training Epoch: 2/2, step 4306/16670 completed (loss: 0.0669640526175499, acc: 0.9871794581413269)
[2024-11-14 09:03:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:42][root][INFO] - Training Epoch: 2/2, step 4307/16670 completed (loss: 0.11952975392341614, acc: 0.971563994884491)
[2024-11-14 09:03:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:43][root][INFO] - Training Epoch: 2/2, step 4308/16670 completed (loss: 0.14686967432498932, acc: 0.9667773842811584)
[2024-11-14 09:03:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:43][root][INFO] - Training Epoch: 2/2, step 4309/16670 completed (loss: 0.16873528063297272, acc: 0.9638009071350098)
[2024-11-14 09:03:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:43][root][INFO] - Training Epoch: 2/2, step 4310/16670 completed (loss: 0.14958684146404266, acc: 0.9588477611541748)
[2024-11-14 09:03:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:44][root][INFO] - Training Epoch: 2/2, step 4311/16670 completed (loss: 0.05650024116039276, acc: 0.9861111044883728)
[2024-11-14 09:03:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:44][root][INFO] - Training Epoch: 2/2, step 4312/16670 completed (loss: 0.10380668193101883, acc: 0.9635854363441467)
[2024-11-14 09:03:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:44][root][INFO] - Training Epoch: 2/2, step 4313/16670 completed (loss: 0.11990399658679962, acc: 0.9590643048286438)
[2024-11-14 09:03:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:45][root][INFO] - Training Epoch: 2/2, step 4314/16670 completed (loss: 0.11632528901100159, acc: 0.9561403393745422)
[2024-11-14 09:03:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:45][root][INFO] - Training Epoch: 2/2, step 4315/16670 completed (loss: 0.3472428023815155, acc: 0.9210526347160339)
[2024-11-14 09:03:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:45][root][INFO] - Training Epoch: 2/2, step 4316/16670 completed (loss: 0.16922970116138458, acc: 0.9367815852165222)
[2024-11-14 09:03:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:46][root][INFO] - Training Epoch: 2/2, step 4317/16670 completed (loss: 0.09480930864810944, acc: 0.9815950989723206)
[2024-11-14 09:03:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:46][root][INFO] - Training Epoch: 2/2, step 4318/16670 completed (loss: 0.07441393285989761, acc: 0.9799330830574036)
[2024-11-14 09:03:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:46][root][INFO] - Training Epoch: 2/2, step 4319/16670 completed (loss: 0.1315845549106598, acc: 0.9695817232131958)
[2024-11-14 09:03:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:47][root][INFO] - Training Epoch: 2/2, step 4320/16670 completed (loss: 0.059767067432403564, acc: 0.9861751198768616)
[2024-11-14 09:03:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:47][root][INFO] - Training Epoch: 2/2, step 4321/16670 completed (loss: 0.07750684767961502, acc: 0.9698113203048706)
[2024-11-14 09:03:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:47][root][INFO] - Training Epoch: 2/2, step 4322/16670 completed (loss: 0.0885000079870224, acc: 0.976190447807312)
[2024-11-14 09:03:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:48][root][INFO] - Training Epoch: 2/2, step 4323/16670 completed (loss: 0.14988836646080017, acc: 0.9657142758369446)
[2024-11-14 09:03:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:48][root][INFO] - Training Epoch: 2/2, step 4324/16670 completed (loss: 0.05995981767773628, acc: 0.9818181991577148)
[2024-11-14 09:03:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:48][root][INFO] - Training Epoch: 2/2, step 4325/16670 completed (loss: 0.12899459898471832, acc: 0.9754902124404907)
[2024-11-14 09:03:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:49][root][INFO] - Training Epoch: 2/2, step 4326/16670 completed (loss: 0.04594388231635094, acc: 0.984000027179718)
[2024-11-14 09:03:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:49][root][INFO] - Training Epoch: 2/2, step 4327/16670 completed (loss: 0.12869252264499664, acc: 0.9635922312736511)
[2024-11-14 09:03:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:49][root][INFO] - Training Epoch: 2/2, step 4328/16670 completed (loss: 0.15741488337516785, acc: 0.9581748843193054)
[2024-11-14 09:03:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:50][root][INFO] - Training Epoch: 2/2, step 4329/16670 completed (loss: 0.2238273322582245, acc: 0.9440559148788452)
[2024-11-14 09:03:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:50][root][INFO] - Training Epoch: 2/2, step 4330/16670 completed (loss: 0.0613168329000473, acc: 0.9846153855323792)
[2024-11-14 09:03:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:51][root][INFO] - Training Epoch: 2/2, step 4331/16670 completed (loss: 0.10162022709846497, acc: 0.9624060392379761)
[2024-11-14 09:03:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:51][root][INFO] - Training Epoch: 2/2, step 4332/16670 completed (loss: 0.17902565002441406, acc: 0.9477611780166626)
[2024-11-14 09:03:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:51][root][INFO] - Training Epoch: 2/2, step 4333/16670 completed (loss: 0.05004146322607994, acc: 0.9891892075538635)
[2024-11-14 09:03:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:52][root][INFO] - Training Epoch: 2/2, step 4334/16670 completed (loss: 0.1513873040676117, acc: 0.9634146094322205)
[2024-11-14 09:03:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:52][root][INFO] - Training Epoch: 2/2, step 4335/16670 completed (loss: 0.16728654503822327, acc: 0.9533678889274597)
[2024-11-14 09:03:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:52][root][INFO] - Training Epoch: 2/2, step 4336/16670 completed (loss: 0.09829212725162506, acc: 0.9797297120094299)
[2024-11-14 09:03:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:53][root][INFO] - Training Epoch: 2/2, step 4337/16670 completed (loss: 0.12185036391019821, acc: 0.9568345546722412)
[2024-11-14 09:03:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:53][root][INFO] - Training Epoch: 2/2, step 4338/16670 completed (loss: 0.08066552877426147, acc: 0.9644669890403748)
[2024-11-14 09:03:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:53][root][INFO] - Training Epoch: 2/2, step 4339/16670 completed (loss: 0.08807124942541122, acc: 0.982758641242981)
[2024-11-14 09:03:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:54][root][INFO] - Training Epoch: 2/2, step 4340/16670 completed (loss: 0.22158178687095642, acc: 0.9408866763114929)
[2024-11-14 09:03:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:54][root][INFO] - Training Epoch: 2/2, step 4341/16670 completed (loss: 0.03964867442846298, acc: 0.9870129823684692)
[2024-11-14 09:03:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:54][root][INFO] - Training Epoch: 2/2, step 4342/16670 completed (loss: 0.08104798942804337, acc: 0.9897435903549194)
[2024-11-14 09:03:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:55][root][INFO] - Training Epoch: 2/2, step 4343/16670 completed (loss: 0.31519365310668945, acc: 0.9090909361839294)
[2024-11-14 09:03:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:55][root][INFO] - Training Epoch: 2/2, step 4344/16670 completed (loss: 0.12190742045640945, acc: 0.9624999761581421)
[2024-11-14 09:03:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:55][root][INFO] - Training Epoch: 2/2, step 4345/16670 completed (loss: 0.06408218294382095, acc: 0.9808428883552551)
[2024-11-14 09:03:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:56][root][INFO] - Training Epoch: 2/2, step 4346/16670 completed (loss: 0.14170211553573608, acc: 0.9627329111099243)
[2024-11-14 09:03:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:56][root][INFO] - Training Epoch: 2/2, step 4347/16670 completed (loss: 0.1868516504764557, acc: 0.954023003578186)
[2024-11-14 09:03:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:56][root][INFO] - Training Epoch: 2/2, step 4348/16670 completed (loss: 0.09799424558877945, acc: 0.9746835231781006)
[2024-11-14 09:03:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:57][root][INFO] - Training Epoch: 2/2, step 4349/16670 completed (loss: 0.03463734686374664, acc: 0.9942196607589722)
[2024-11-14 09:03:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:57][root][INFO] - Training Epoch: 2/2, step 4350/16670 completed (loss: 0.030892005190253258, acc: 1.0)
[2024-11-14 09:03:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:57][root][INFO] - Training Epoch: 2/2, step 4351/16670 completed (loss: 0.06624369323253632, acc: 0.9851484894752502)
[2024-11-14 09:03:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:58][root][INFO] - Training Epoch: 2/2, step 4352/16670 completed (loss: 0.1332775354385376, acc: 0.9681978821754456)
[2024-11-14 09:03:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:58][root][INFO] - Training Epoch: 2/2, step 4353/16670 completed (loss: 0.06939680129289627, acc: 0.9825174808502197)
[2024-11-14 09:03:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:59][root][INFO] - Training Epoch: 2/2, step 4354/16670 completed (loss: 0.10254629701375961, acc: 0.9756097793579102)
[2024-11-14 09:03:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:59][root][INFO] - Training Epoch: 2/2, step 4355/16670 completed (loss: 0.145823135972023, acc: 0.9541547298431396)
[2024-11-14 09:03:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:03:59][root][INFO] - Training Epoch: 2/2, step 4356/16670 completed (loss: 0.07617666572332382, acc: 0.9796954393386841)
[2024-11-14 09:03:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:00][root][INFO] - Training Epoch: 2/2, step 4357/16670 completed (loss: 0.11905216425657272, acc: 0.9639639854431152)
[2024-11-14 09:04:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:00][root][INFO] - Training Epoch: 2/2, step 4358/16670 completed (loss: 0.08488447964191437, acc: 0.9700854420661926)
[2024-11-14 09:04:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:00][root][INFO] - Training Epoch: 2/2, step 4359/16670 completed (loss: 0.10999207198619843, acc: 0.9664804339408875)
[2024-11-14 09:04:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:01][root][INFO] - Training Epoch: 2/2, step 4360/16670 completed (loss: 0.07726190239191055, acc: 0.9790209531784058)
[2024-11-14 09:04:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:01][root][INFO] - Training Epoch: 2/2, step 4361/16670 completed (loss: 0.20448538661003113, acc: 0.9409090876579285)
[2024-11-14 09:04:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:01][root][INFO] - Training Epoch: 2/2, step 4362/16670 completed (loss: 0.06800238788127899, acc: 0.987500011920929)
[2024-11-14 09:04:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:02][root][INFO] - Training Epoch: 2/2, step 4363/16670 completed (loss: 0.07909028977155685, acc: 0.97826087474823)
[2024-11-14 09:04:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:02][root][INFO] - Training Epoch: 2/2, step 4364/16670 completed (loss: 0.1001260057091713, acc: 0.9659090638160706)
[2024-11-14 09:04:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:02][root][INFO] - Training Epoch: 2/2, step 4365/16670 completed (loss: 0.1336069107055664, acc: 0.9588607549667358)
[2024-11-14 09:04:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:03][root][INFO] - Training Epoch: 2/2, step 4366/16670 completed (loss: 0.06684014946222305, acc: 0.9748201370239258)
[2024-11-14 09:04:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:03][root][INFO] - Training Epoch: 2/2, step 4367/16670 completed (loss: 0.16202786564826965, acc: 0.9538905024528503)
[2024-11-14 09:04:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:03][root][INFO] - Training Epoch: 2/2, step 4368/16670 completed (loss: 0.20926892757415771, acc: 0.9385474920272827)
[2024-11-14 09:04:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:04][root][INFO] - Training Epoch: 2/2, step 4369/16670 completed (loss: 0.13526056706905365, acc: 0.9716312289237976)
[2024-11-14 09:04:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:04][root][INFO] - Training Epoch: 2/2, step 4370/16670 completed (loss: 0.1291295439004898, acc: 0.9441624283790588)
[2024-11-14 09:04:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:04][root][INFO] - Training Epoch: 2/2, step 4371/16670 completed (loss: 0.08793220669031143, acc: 0.9676375389099121)
[2024-11-14 09:04:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:05][root][INFO] - Training Epoch: 2/2, step 4372/16670 completed (loss: 0.19680394232273102, acc: 0.9423868060112)
[2024-11-14 09:04:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:05][root][INFO] - Training Epoch: 2/2, step 4373/16670 completed (loss: 0.07716846466064453, acc: 0.9791666865348816)
[2024-11-14 09:04:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:05][root][INFO] - Training Epoch: 2/2, step 4374/16670 completed (loss: 0.08166886121034622, acc: 0.9790940880775452)
[2024-11-14 09:04:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:06][root][INFO] - Training Epoch: 2/2, step 4375/16670 completed (loss: 0.06399933248758316, acc: 0.9722222089767456)
[2024-11-14 09:04:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:06][root][INFO] - Training Epoch: 2/2, step 4376/16670 completed (loss: 0.1615917682647705, acc: 0.9636963605880737)
[2024-11-14 09:04:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:06][root][INFO] - Training Epoch: 2/2, step 4377/16670 completed (loss: 0.07238483428955078, acc: 0.9820144176483154)
[2024-11-14 09:04:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:07][root][INFO] - Training Epoch: 2/2, step 4378/16670 completed (loss: 0.08184793591499329, acc: 0.9664804339408875)
[2024-11-14 09:04:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:07][root][INFO] - Training Epoch: 2/2, step 4379/16670 completed (loss: 0.054374128580093384, acc: 0.9875518679618835)
[2024-11-14 09:04:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:07][root][INFO] - Training Epoch: 2/2, step 4380/16670 completed (loss: 0.19922852516174316, acc: 0.9663865566253662)
[2024-11-14 09:04:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:08][root][INFO] - Training Epoch: 2/2, step 4381/16670 completed (loss: 0.14096258580684662, acc: 0.9527272582054138)
[2024-11-14 09:04:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:08][root][INFO] - Training Epoch: 2/2, step 4382/16670 completed (loss: 0.16558310389518738, acc: 0.9444444179534912)
[2024-11-14 09:04:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:08][root][INFO] - Training Epoch: 2/2, step 4383/16670 completed (loss: 0.0681292861700058, acc: 0.9683544039726257)
[2024-11-14 09:04:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:09][root][INFO] - Training Epoch: 2/2, step 4384/16670 completed (loss: 0.13503329455852509, acc: 0.9508196711540222)
[2024-11-14 09:04:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:09][root][INFO] - Training Epoch: 2/2, step 4385/16670 completed (loss: 0.10024427622556686, acc: 0.9841897487640381)
[2024-11-14 09:04:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:09][root][INFO] - Training Epoch: 2/2, step 4386/16670 completed (loss: 0.08371663838624954, acc: 0.9683698415756226)
[2024-11-14 09:04:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:10][root][INFO] - Training Epoch: 2/2, step 4387/16670 completed (loss: 0.2859914302825928, acc: 0.9275861978530884)
[2024-11-14 09:04:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:10][root][INFO] - Training Epoch: 2/2, step 4388/16670 completed (loss: 0.11732713133096695, acc: 0.9710982441902161)
[2024-11-14 09:04:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:10][root][INFO] - Training Epoch: 2/2, step 4389/16670 completed (loss: 0.13950839638710022, acc: 0.9685534834861755)
[2024-11-14 09:04:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:11][root][INFO] - Training Epoch: 2/2, step 4390/16670 completed (loss: 0.0216776542365551, acc: 0.9956331849098206)
[2024-11-14 09:04:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:11][root][INFO] - Training Epoch: 2/2, step 4391/16670 completed (loss: 0.22298943996429443, acc: 0.937269389629364)
[2024-11-14 09:04:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:12][root][INFO] - Training Epoch: 2/2, step 4392/16670 completed (loss: 0.05673515051603317, acc: 0.9894737005233765)
[2024-11-14 09:04:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:12][root][INFO] - Training Epoch: 2/2, step 4393/16670 completed (loss: 0.23510313034057617, acc: 0.9375)
[2024-11-14 09:04:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:12][root][INFO] - Training Epoch: 2/2, step 4394/16670 completed (loss: 0.14355960488319397, acc: 0.9655172228813171)
[2024-11-14 09:04:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:13][root][INFO] - Training Epoch: 2/2, step 4395/16670 completed (loss: 0.03362288698554039, acc: 0.9903846383094788)
[2024-11-14 09:04:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:13][root][INFO] - Training Epoch: 2/2, step 4396/16670 completed (loss: 0.07383982092142105, acc: 0.9755101799964905)
[2024-11-14 09:04:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:13][root][INFO] - Training Epoch: 2/2, step 4397/16670 completed (loss: 0.11323320120573044, acc: 0.9692307710647583)
[2024-11-14 09:04:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:14][root][INFO] - Training Epoch: 2/2, step 4398/16670 completed (loss: 0.07681288570165634, acc: 0.9803921580314636)
[2024-11-14 09:04:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:14][root][INFO] - Training Epoch: 2/2, step 4399/16670 completed (loss: 0.08301413804292679, acc: 0.9740740656852722)
[2024-11-14 09:04:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:14][root][INFO] - Training Epoch: 2/2, step 4400/16670 completed (loss: 0.16807027161121368, acc: 0.9434782862663269)
[2024-11-14 09:04:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:15][root][INFO] - Training Epoch: 2/2, step 4401/16670 completed (loss: 0.16238631308078766, acc: 0.9527559280395508)
[2024-11-14 09:04:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:15][root][INFO] - Training Epoch: 2/2, step 4402/16670 completed (loss: 0.037343721836805344, acc: 0.9868420958518982)
[2024-11-14 09:04:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:15][root][INFO] - Training Epoch: 2/2, step 4403/16670 completed (loss: 0.07927253097295761, acc: 0.9819004535675049)
[2024-11-14 09:04:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:16][root][INFO] - Training Epoch: 2/2, step 4404/16670 completed (loss: 0.012438087724149227, acc: 0.9943181872367859)
[2024-11-14 09:04:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:16][root][INFO] - Training Epoch: 2/2, step 4405/16670 completed (loss: 0.1588384360074997, acc: 0.9679012298583984)
[2024-11-14 09:04:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:17][root][INFO] - Training Epoch: 2/2, step 4406/16670 completed (loss: 0.18926642835140228, acc: 0.9352940917015076)
[2024-11-14 09:04:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:17][root][INFO] - Training Epoch: 2/2, step 4407/16670 completed (loss: 0.09200208634138107, acc: 0.9725610017776489)
[2024-11-14 09:04:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:17][root][INFO] - Training Epoch: 2/2, step 4408/16670 completed (loss: 0.13801562786102295, acc: 0.9567723274230957)
[2024-11-14 09:04:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:18][root][INFO] - Training Epoch: 2/2, step 4409/16670 completed (loss: 0.08260513842105865, acc: 0.9769230484962463)
[2024-11-14 09:04:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:18][root][INFO] - Training Epoch: 2/2, step 4410/16670 completed (loss: 0.04506145045161247, acc: 0.9949238300323486)
[2024-11-14 09:04:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:18][root][INFO] - Training Epoch: 2/2, step 4411/16670 completed (loss: 0.06554372608661652, acc: 0.9804878234863281)
[2024-11-14 09:04:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:19][root][INFO] - Training Epoch: 2/2, step 4412/16670 completed (loss: 0.044774867594242096, acc: 0.9860627055168152)
[2024-11-14 09:04:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:19][root][INFO] - Training Epoch: 2/2, step 4413/16670 completed (loss: 0.14708077907562256, acc: 0.9539473652839661)
[2024-11-14 09:04:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:19][root][INFO] - Training Epoch: 2/2, step 4414/16670 completed (loss: 0.18271416425704956, acc: 0.936170220375061)
[2024-11-14 09:04:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:20][root][INFO] - Training Epoch: 2/2, step 4415/16670 completed (loss: 0.1617852747440338, acc: 0.9628099203109741)
[2024-11-14 09:04:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:20][root][INFO] - Training Epoch: 2/2, step 4416/16670 completed (loss: 0.021105356514453888, acc: 0.9949748516082764)
[2024-11-14 09:04:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:20][root][INFO] - Training Epoch: 2/2, step 4417/16670 completed (loss: 0.1135672926902771, acc: 0.9755101799964905)
[2024-11-14 09:04:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:21][root][INFO] - Training Epoch: 2/2, step 4418/16670 completed (loss: 0.09045369178056717, acc: 0.970588207244873)
[2024-11-14 09:04:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:21][root][INFO] - Training Epoch: 2/2, step 4419/16670 completed (loss: 0.045721668750047684, acc: 0.991428554058075)
[2024-11-14 09:04:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:22][root][INFO] - Training Epoch: 2/2, step 4420/16670 completed (loss: 0.08154942840337753, acc: 0.9894179701805115)
[2024-11-14 09:04:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:22][root][INFO] - Training Epoch: 2/2, step 4421/16670 completed (loss: 0.10656283795833588, acc: 0.9622641801834106)
[2024-11-14 09:04:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:22][root][INFO] - Training Epoch: 2/2, step 4422/16670 completed (loss: 0.06712540239095688, acc: 0.9817351698875427)
[2024-11-14 09:04:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:23][root][INFO] - Training Epoch: 2/2, step 4423/16670 completed (loss: 0.1069546639919281, acc: 0.9692307710647583)
[2024-11-14 09:04:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:23][root][INFO] - Training Epoch: 2/2, step 4424/16670 completed (loss: 0.016639837995171547, acc: 0.9932432174682617)
[2024-11-14 09:04:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:23][root][INFO] - Training Epoch: 2/2, step 4425/16670 completed (loss: 0.11133064329624176, acc: 0.9790576100349426)
[2024-11-14 09:04:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:24][root][INFO] - Training Epoch: 2/2, step 4426/16670 completed (loss: 0.02081059105694294, acc: 1.0)
[2024-11-14 09:04:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:24][root][INFO] - Training Epoch: 2/2, step 4427/16670 completed (loss: 0.02858395129442215, acc: 0.9963503479957581)
[2024-11-14 09:04:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:24][root][INFO] - Training Epoch: 2/2, step 4428/16670 completed (loss: 0.1115071028470993, acc: 0.9726027250289917)
[2024-11-14 09:04:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:25][root][INFO] - Training Epoch: 2/2, step 4429/16670 completed (loss: 0.04404887557029724, acc: 0.9876543283462524)
[2024-11-14 09:04:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:25][root][INFO] - Training Epoch: 2/2, step 4430/16670 completed (loss: 0.05318703129887581, acc: 0.987500011920929)
[2024-11-14 09:04:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:26][root][INFO] - Training Epoch: 2/2, step 4431/16670 completed (loss: 0.11357760429382324, acc: 0.9726027250289917)
[2024-11-14 09:04:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:26][root][INFO] - Training Epoch: 2/2, step 4432/16670 completed (loss: 0.10442189872264862, acc: 0.9785714149475098)
[2024-11-14 09:04:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:26][root][INFO] - Training Epoch: 2/2, step 4433/16670 completed (loss: 0.1409018188714981, acc: 0.9684210419654846)
[2024-11-14 09:04:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:27][root][INFO] - Training Epoch: 2/2, step 4434/16670 completed (loss: 0.11390896886587143, acc: 0.9682539701461792)
[2024-11-14 09:04:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:27][root][INFO] - Training Epoch: 2/2, step 4435/16670 completed (loss: 0.018243223428726196, acc: 0.9944444298744202)
[2024-11-14 09:04:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:27][root][INFO] - Training Epoch: 2/2, step 4436/16670 completed (loss: 0.09451945126056671, acc: 0.9802955389022827)
[2024-11-14 09:04:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:28][root][INFO] - Training Epoch: 2/2, step 4437/16670 completed (loss: 0.12642335891723633, acc: 0.965753436088562)
[2024-11-14 09:04:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:28][root][INFO] - Training Epoch: 2/2, step 4438/16670 completed (loss: 0.11275023967027664, acc: 0.9576923251152039)
[2024-11-14 09:04:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:28][root][INFO] - Training Epoch: 2/2, step 4439/16670 completed (loss: 0.07051628828048706, acc: 0.9746192693710327)
[2024-11-14 09:04:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:29][root][INFO] - Training Epoch: 2/2, step 4440/16670 completed (loss: 0.18872201442718506, acc: 0.9518716335296631)
[2024-11-14 09:04:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:29][root][INFO] - Training Epoch: 2/2, step 4441/16670 completed (loss: 0.0710485577583313, acc: 0.9838709831237793)
[2024-11-14 09:04:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:29][root][INFO] - Training Epoch: 2/2, step 4442/16670 completed (loss: 0.03476714342832565, acc: 0.9868420958518982)
[2024-11-14 09:04:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:30][root][INFO] - Training Epoch: 2/2, step 4443/16670 completed (loss: 0.11524977535009384, acc: 0.9737827777862549)
[2024-11-14 09:04:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:30][root][INFO] - Training Epoch: 2/2, step 4444/16670 completed (loss: 0.019375093281269073, acc: 0.9911110997200012)
[2024-11-14 09:04:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:30][root][INFO] - Training Epoch: 2/2, step 4445/16670 completed (loss: 0.0991348922252655, acc: 0.9715302586555481)
[2024-11-14 09:04:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:31][root][INFO] - Training Epoch: 2/2, step 4446/16670 completed (loss: 0.08596139401197433, acc: 0.9748110771179199)
[2024-11-14 09:04:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:31][root][INFO] - Training Epoch: 2/2, step 4447/16670 completed (loss: 0.09797108918428421, acc: 0.976190447807312)
[2024-11-14 09:04:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:32][root][INFO] - Training Epoch: 2/2, step 4448/16670 completed (loss: 0.0636902004480362, acc: 0.9872204661369324)
[2024-11-14 09:04:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:32][root][INFO] - Training Epoch: 2/2, step 4449/16670 completed (loss: 0.04771212115883827, acc: 0.984000027179718)
[2024-11-14 09:04:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:32][root][INFO] - Training Epoch: 2/2, step 4450/16670 completed (loss: 0.18102270364761353, acc: 0.9553903341293335)
[2024-11-14 09:04:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:33][root][INFO] - Training Epoch: 2/2, step 4451/16670 completed (loss: 0.07144492864608765, acc: 0.9836065769195557)
[2024-11-14 09:04:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:33][root][INFO] - Training Epoch: 2/2, step 4452/16670 completed (loss: 0.13184083998203278, acc: 0.9681817889213562)
[2024-11-14 09:04:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:33][root][INFO] - Training Epoch: 2/2, step 4453/16670 completed (loss: 0.07565067708492279, acc: 0.9734042286872864)
[2024-11-14 09:04:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:34][root][INFO] - Training Epoch: 2/2, step 4454/16670 completed (loss: 0.09694098681211472, acc: 0.96875)
[2024-11-14 09:04:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:34][root][INFO] - Training Epoch: 2/2, step 4455/16670 completed (loss: 0.07961112260818481, acc: 0.9835391044616699)
[2024-11-14 09:04:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:35][root][INFO] - Training Epoch: 2/2, step 4456/16670 completed (loss: 0.0860670953989029, acc: 0.9719626307487488)
[2024-11-14 09:04:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:35][root][INFO] - Training Epoch: 2/2, step 4457/16670 completed (loss: 0.07993759214878082, acc: 0.969924807548523)
[2024-11-14 09:04:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:35][root][INFO] - Training Epoch: 2/2, step 4458/16670 completed (loss: 0.1593516319990158, acc: 0.9620853066444397)
[2024-11-14 09:04:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:36][root][INFO] - Training Epoch: 2/2, step 4459/16670 completed (loss: 0.06198060140013695, acc: 0.9891696572303772)
[2024-11-14 09:04:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:36][root][INFO] - Training Epoch: 2/2, step 4460/16670 completed (loss: 0.10464122146368027, acc: 0.9768211841583252)
[2024-11-14 09:04:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:36][root][INFO] - Training Epoch: 2/2, step 4461/16670 completed (loss: 0.07730317115783691, acc: 0.9847328066825867)
[2024-11-14 09:04:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:37][root][INFO] - Training Epoch: 2/2, step 4462/16670 completed (loss: 0.22267590463161469, acc: 0.9428571462631226)
[2024-11-14 09:04:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:37][root][INFO] - Training Epoch: 2/2, step 4463/16670 completed (loss: 0.0634523406624794, acc: 0.9836734533309937)
[2024-11-14 09:04:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:37][root][INFO] - Training Epoch: 2/2, step 4464/16670 completed (loss: 0.10847543925046921, acc: 0.9677419066429138)
[2024-11-14 09:04:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:38][root][INFO] - Training Epoch: 2/2, step 4465/16670 completed (loss: 0.06123168766498566, acc: 0.9817351698875427)
[2024-11-14 09:04:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:38][root][INFO] - Training Epoch: 2/2, step 4466/16670 completed (loss: 0.09725197404623032, acc: 0.9724137783050537)
[2024-11-14 09:04:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:38][root][INFO] - Training Epoch: 2/2, step 4467/16670 completed (loss: 0.050757914781570435, acc: 0.9868420958518982)
[2024-11-14 09:04:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:39][root][INFO] - Training Epoch: 2/2, step 4468/16670 completed (loss: 0.11886662989854813, acc: 0.9696969985961914)
[2024-11-14 09:04:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:39][root][INFO] - Training Epoch: 2/2, step 4469/16670 completed (loss: 0.1830197125673294, acc: 0.9498208165168762)
[2024-11-14 09:04:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:39][root][INFO] - Training Epoch: 2/2, step 4470/16670 completed (loss: 0.08863431960344315, acc: 0.9677419066429138)
[2024-11-14 09:04:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:40][root][INFO] - Training Epoch: 2/2, step 4471/16670 completed (loss: 0.06784379482269287, acc: 0.9813664555549622)
[2024-11-14 09:04:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:40][root][INFO] - Training Epoch: 2/2, step 4472/16670 completed (loss: 0.1741631031036377, acc: 0.9707112908363342)
[2024-11-14 09:04:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:40][root][INFO] - Training Epoch: 2/2, step 4473/16670 completed (loss: 0.07587975263595581, acc: 0.9806094169616699)
[2024-11-14 09:04:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:41][root][INFO] - Training Epoch: 2/2, step 4474/16670 completed (loss: 0.04615176469087601, acc: 0.9866666793823242)
[2024-11-14 09:04:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:41][root][INFO] - Training Epoch: 2/2, step 4475/16670 completed (loss: 0.11201798915863037, acc: 0.9616724848747253)
[2024-11-14 09:04:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:42][root][INFO] - Training Epoch: 2/2, step 4476/16670 completed (loss: 0.13205236196517944, acc: 0.961685836315155)
[2024-11-14 09:04:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:42][root][INFO] - Training Epoch: 2/2, step 4477/16670 completed (loss: 0.056790269911289215, acc: 0.9885057210922241)
[2024-11-14 09:04:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:42][root][INFO] - Training Epoch: 2/2, step 4478/16670 completed (loss: 0.04547906294465065, acc: 0.9857142567634583)
[2024-11-14 09:04:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:43][root][INFO] - Training Epoch: 2/2, step 4479/16670 completed (loss: 0.09271284937858582, acc: 0.9750778675079346)
[2024-11-14 09:04:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:43][root][INFO] - Training Epoch: 2/2, step 4480/16670 completed (loss: 0.18941017985343933, acc: 0.9532710313796997)
[2024-11-14 09:04:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:44][root][INFO] - Training Epoch: 2/2, step 4481/16670 completed (loss: 0.17218220233917236, acc: 0.9489361643791199)
[2024-11-14 09:04:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:44][root][INFO] - Training Epoch: 2/2, step 4482/16670 completed (loss: 0.056786831468343735, acc: 0.9832636117935181)
[2024-11-14 09:04:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:44][root][INFO] - Training Epoch: 2/2, step 4483/16670 completed (loss: 0.10562741756439209, acc: 0.9591836929321289)
[2024-11-14 09:04:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:45][root][INFO] - Training Epoch: 2/2, step 4484/16670 completed (loss: 0.030204476788640022, acc: 0.9880478382110596)
[2024-11-14 09:04:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:45][root][INFO] - Training Epoch: 2/2, step 4485/16670 completed (loss: 0.10794281214475632, acc: 0.9490740895271301)
[2024-11-14 09:04:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:45][root][INFO] - Training Epoch: 2/2, step 4486/16670 completed (loss: 0.11938980221748352, acc: 0.9722222089767456)
[2024-11-14 09:04:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:46][root][INFO] - Training Epoch: 2/2, step 4487/16670 completed (loss: 0.051788974553346634, acc: 0.9864864945411682)
[2024-11-14 09:04:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:46][root][INFO] - Training Epoch: 2/2, step 4488/16670 completed (loss: 0.10514399409294128, acc: 0.9684542417526245)
[2024-11-14 09:04:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:46][root][INFO] - Training Epoch: 2/2, step 4489/16670 completed (loss: 0.13653095066547394, acc: 0.9599999785423279)
[2024-11-14 09:04:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:47][root][INFO] - Training Epoch: 2/2, step 4490/16670 completed (loss: 0.05543902516365051, acc: 0.9849246144294739)
[2024-11-14 09:04:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:47][root][INFO] - Training Epoch: 2/2, step 4491/16670 completed (loss: 0.05165217071771622, acc: 0.9848024249076843)
[2024-11-14 09:04:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:47][root][INFO] - Training Epoch: 2/2, step 4492/16670 completed (loss: 0.18468494713306427, acc: 0.9411764740943909)
[2024-11-14 09:04:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:48][root][INFO] - Training Epoch: 2/2, step 4493/16670 completed (loss: 0.2290266901254654, acc: 0.928909957408905)
[2024-11-14 09:04:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:48][root][INFO] - Training Epoch: 2/2, step 4494/16670 completed (loss: 0.09861423820257187, acc: 0.9795918464660645)
[2024-11-14 09:04:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:48][root][INFO] - Training Epoch: 2/2, step 4495/16670 completed (loss: 0.15818579494953156, acc: 0.9562682509422302)
[2024-11-14 09:04:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:49][root][INFO] - Training Epoch: 2/2, step 4496/16670 completed (loss: 0.13301680982112885, acc: 0.9580838084220886)
[2024-11-14 09:04:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:49][root][INFO] - Training Epoch: 2/2, step 4497/16670 completed (loss: 0.04824204742908478, acc: 0.9809523820877075)
[2024-11-14 09:04:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:49][root][INFO] - Training Epoch: 2/2, step 4498/16670 completed (loss: 0.06573929637670517, acc: 0.9722222089767456)
[2024-11-14 09:04:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:50][root][INFO] - Training Epoch: 2/2, step 4499/16670 completed (loss: 0.08226962387561798, acc: 0.9819004535675049)
[2024-11-14 09:04:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:50][root][INFO] - Training Epoch: 2/2, step 4500/16670 completed (loss: 0.03269670903682709, acc: 0.9901315569877625)
[2024-11-14 09:04:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:51][root][INFO] - Training Epoch: 2/2, step 4501/16670 completed (loss: 0.05137697234749794, acc: 0.9862385392189026)
[2024-11-14 09:04:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:51][root][INFO] - Training Epoch: 2/2, step 4502/16670 completed (loss: 0.16581472754478455, acc: 0.9617834687232971)
[2024-11-14 09:04:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:51][root][INFO] - Training Epoch: 2/2, step 4503/16670 completed (loss: 0.17534828186035156, acc: 0.9673202633857727)
[2024-11-14 09:04:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:52][root][INFO] - Training Epoch: 2/2, step 4504/16670 completed (loss: 0.15256734192371368, acc: 0.9529411792755127)
[2024-11-14 09:04:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:52][root][INFO] - Training Epoch: 2/2, step 4505/16670 completed (loss: 0.03850363567471504, acc: 0.9898989796638489)
[2024-11-14 09:04:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:52][root][INFO] - Training Epoch: 2/2, step 4506/16670 completed (loss: 0.08363297581672668, acc: 0.976580798625946)
[2024-11-14 09:04:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:53][root][INFO] - Training Epoch: 2/2, step 4507/16670 completed (loss: 0.050821222364902496, acc: 0.9842519760131836)
[2024-11-14 09:04:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:53][root][INFO] - Training Epoch: 2/2, step 4508/16670 completed (loss: 0.06324730813503265, acc: 0.9793814420700073)
[2024-11-14 09:04:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:53][root][INFO] - Training Epoch: 2/2, step 4509/16670 completed (loss: 0.07110586762428284, acc: 0.9707602262496948)
[2024-11-14 09:04:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:54][root][INFO] - Training Epoch: 2/2, step 4510/16670 completed (loss: 0.10597265511751175, acc: 0.976047933101654)
[2024-11-14 09:04:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:54][root][INFO] - Training Epoch: 2/2, step 4511/16670 completed (loss: 0.08725323528051376, acc: 0.9760000109672546)
[2024-11-14 09:04:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:54][root][INFO] - Training Epoch: 2/2, step 4512/16670 completed (loss: 0.1293850839138031, acc: 0.9642857313156128)
[2024-11-14 09:04:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:55][root][INFO] - Training Epoch: 2/2, step 4513/16670 completed (loss: 0.11575156450271606, acc: 0.9711934328079224)
[2024-11-14 09:04:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:55][root][INFO] - Training Epoch: 2/2, step 4514/16670 completed (loss: 0.26478445529937744, acc: 0.931034505367279)
[2024-11-14 09:04:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:55][root][INFO] - Training Epoch: 2/2, step 4515/16670 completed (loss: 0.032163191586732864, acc: 0.9853372573852539)
[2024-11-14 09:04:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:56][root][INFO] - Training Epoch: 2/2, step 4516/16670 completed (loss: 0.08821593225002289, acc: 0.9746835231781006)
[2024-11-14 09:04:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:56][root][INFO] - Training Epoch: 2/2, step 4517/16670 completed (loss: 0.057443052530288696, acc: 0.9837398529052734)
[2024-11-14 09:04:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:56][root][INFO] - Training Epoch: 2/2, step 4518/16670 completed (loss: 0.10117117315530777, acc: 0.9736841917037964)
[2024-11-14 09:04:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:57][root][INFO] - Training Epoch: 2/2, step 4519/16670 completed (loss: 0.1661868691444397, acc: 0.9594594836235046)
[2024-11-14 09:04:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:57][root][INFO] - Training Epoch: 2/2, step 4520/16670 completed (loss: 0.07035614550113678, acc: 0.9888476133346558)
[2024-11-14 09:04:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:58][root][INFO] - Training Epoch: 2/2, step 4521/16670 completed (loss: 0.10765544325113297, acc: 0.97826087474823)
[2024-11-14 09:04:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:58][root][INFO] - Training Epoch: 2/2, step 4522/16670 completed (loss: 0.22126659750938416, acc: 0.940625011920929)
[2024-11-14 09:04:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:58][root][INFO] - Training Epoch: 2/2, step 4523/16670 completed (loss: 0.10565061122179031, acc: 0.9701195359230042)
[2024-11-14 09:04:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:59][root][INFO] - Training Epoch: 2/2, step 4524/16670 completed (loss: 0.056385330855846405, acc: 0.9836065769195557)
[2024-11-14 09:04:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:59][root][INFO] - Training Epoch: 2/2, step 4525/16670 completed (loss: 0.08995204418897629, acc: 0.969072163105011)
[2024-11-14 09:04:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:04:59][root][INFO] - Training Epoch: 2/2, step 4526/16670 completed (loss: 0.1436612606048584, acc: 0.9664804339408875)
[2024-11-14 09:05:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:00][root][INFO] - Training Epoch: 2/2, step 4527/16670 completed (loss: 0.1340518742799759, acc: 0.9629629850387573)
[2024-11-14 09:05:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:00][root][INFO] - Training Epoch: 2/2, step 4528/16670 completed (loss: 0.04097672924399376, acc: 0.9956140518188477)
[2024-11-14 09:05:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:01][root][INFO] - Training Epoch: 2/2, step 4529/16670 completed (loss: 0.14455536007881165, acc: 0.9607843160629272)
[2024-11-14 09:05:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:01][root][INFO] - Training Epoch: 2/2, step 4530/16670 completed (loss: 0.07720623910427094, acc: 0.9757084846496582)
[2024-11-14 09:05:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:01][root][INFO] - Training Epoch: 2/2, step 4531/16670 completed (loss: 0.06057431921362877, acc: 0.9825174808502197)
[2024-11-14 09:05:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:02][root][INFO] - Training Epoch: 2/2, step 4532/16670 completed (loss: 0.1276800036430359, acc: 0.9623655676841736)
[2024-11-14 09:05:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:02][root][INFO] - Training Epoch: 2/2, step 4533/16670 completed (loss: 0.0498368926346302, acc: 0.9866071343421936)
[2024-11-14 09:05:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:03][root][INFO] - Training Epoch: 2/2, step 4534/16670 completed (loss: 0.11005690693855286, acc: 0.9791666865348816)
[2024-11-14 09:05:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:03][root][INFO] - Training Epoch: 2/2, step 4535/16670 completed (loss: 0.07125651836395264, acc: 0.9670329689979553)
[2024-11-14 09:05:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:03][root][INFO] - Training Epoch: 2/2, step 4536/16670 completed (loss: 0.15942834317684174, acc: 0.9713375568389893)
[2024-11-14 09:05:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:04][root][INFO] - Training Epoch: 2/2, step 4537/16670 completed (loss: 0.09980716556310654, acc: 0.9838056564331055)
[2024-11-14 09:05:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:04][root][INFO] - Training Epoch: 2/2, step 4538/16670 completed (loss: 0.08591985702514648, acc: 0.9762611389160156)
[2024-11-14 09:05:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:04][root][INFO] - Training Epoch: 2/2, step 4539/16670 completed (loss: 0.07003666460514069, acc: 0.9774919748306274)
[2024-11-14 09:05:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:05][root][INFO] - Training Epoch: 2/2, step 4540/16670 completed (loss: 0.08326268196105957, acc: 0.9753845930099487)
[2024-11-14 09:05:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:05][root][INFO] - Training Epoch: 2/2, step 4541/16670 completed (loss: 0.11049700528383255, acc: 0.9698795080184937)
[2024-11-14 09:05:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:06][root][INFO] - Training Epoch: 2/2, step 4542/16670 completed (loss: 0.06727325916290283, acc: 0.9861111044883728)
[2024-11-14 09:05:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:06][root][INFO] - Training Epoch: 2/2, step 4543/16670 completed (loss: 0.20194491744041443, acc: 0.9537814855575562)
[2024-11-14 09:05:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:06][root][INFO] - Training Epoch: 2/2, step 4544/16670 completed (loss: 0.09400849789381027, acc: 0.9802955389022827)
[2024-11-14 09:05:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:07][root][INFO] - Training Epoch: 2/2, step 4545/16670 completed (loss: 0.1969144195318222, acc: 0.9714285731315613)
[2024-11-14 09:05:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:07][root][INFO] - Training Epoch: 2/2, step 4546/16670 completed (loss: 0.20159301161766052, acc: 0.9457626938819885)
[2024-11-14 09:05:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:08][root][INFO] - Training Epoch: 2/2, step 4547/16670 completed (loss: 0.06793167442083359, acc: 0.9754098653793335)
[2024-11-14 09:05:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:08][root][INFO] - Training Epoch: 2/2, step 4548/16670 completed (loss: 0.09500575810670853, acc: 0.9829545617103577)
[2024-11-14 09:05:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:08][root][INFO] - Training Epoch: 2/2, step 4549/16670 completed (loss: 0.08795671164989471, acc: 0.9757575988769531)
[2024-11-14 09:05:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:09][root][INFO] - Training Epoch: 2/2, step 4550/16670 completed (loss: 0.0522390641272068, acc: 0.9913793206214905)
[2024-11-14 09:05:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:09][root][INFO] - Training Epoch: 2/2, step 4551/16670 completed (loss: 0.12615010142326355, acc: 0.9653846025466919)
[2024-11-14 09:05:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:09][root][INFO] - Training Epoch: 2/2, step 4552/16670 completed (loss: 0.051023218780756, acc: 0.9872340559959412)
[2024-11-14 09:05:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:10][root][INFO] - Training Epoch: 2/2, step 4553/16670 completed (loss: 0.14788305759429932, acc: 0.9629629850387573)
[2024-11-14 09:05:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:10][root][INFO] - Training Epoch: 2/2, step 4554/16670 completed (loss: 0.12921065092086792, acc: 0.971061110496521)
[2024-11-14 09:05:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:10][root][INFO] - Training Epoch: 2/2, step 4555/16670 completed (loss: 0.06125073507428169, acc: 0.9920634627342224)
[2024-11-14 09:05:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:11][root][INFO] - Training Epoch: 2/2, step 4556/16670 completed (loss: 0.024576179683208466, acc: 0.992094874382019)
[2024-11-14 09:05:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:11][root][INFO] - Training Epoch: 2/2, step 4557/16670 completed (loss: 0.07783035933971405, acc: 0.9803921580314636)
[2024-11-14 09:05:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:11][root][INFO] - Training Epoch: 2/2, step 4558/16670 completed (loss: 0.19717662036418915, acc: 0.9595959782600403)
[2024-11-14 09:05:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:12][root][INFO] - Training Epoch: 2/2, step 4559/16670 completed (loss: 0.23329411447048187, acc: 0.9144144058227539)
[2024-11-14 09:05:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:12][root][INFO] - Training Epoch: 2/2, step 4560/16670 completed (loss: 0.07538287341594696, acc: 0.983146071434021)
[2024-11-14 09:05:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:13][root][INFO] - Training Epoch: 2/2, step 4561/16670 completed (loss: 0.05204813927412033, acc: 0.989159882068634)
[2024-11-14 09:05:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:13][root][INFO] - Training Epoch: 2/2, step 4562/16670 completed (loss: 0.1159372329711914, acc: 0.9635416865348816)
[2024-11-14 09:05:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:13][root][INFO] - Training Epoch: 2/2, step 4563/16670 completed (loss: 0.061814043670892715, acc: 0.9868420958518982)
[2024-11-14 09:05:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:14][root][INFO] - Training Epoch: 2/2, step 4564/16670 completed (loss: 0.0806155651807785, acc: 0.9750000238418579)
[2024-11-14 09:05:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:14][root][INFO] - Training Epoch: 2/2, step 4565/16670 completed (loss: 0.10458748042583466, acc: 0.9836065769195557)
[2024-11-14 09:05:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:14][root][INFO] - Training Epoch: 2/2, step 4566/16670 completed (loss: 0.061330243945121765, acc: 0.9854227304458618)
[2024-11-14 09:05:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:15][root][INFO] - Training Epoch: 2/2, step 4567/16670 completed (loss: 0.11871256679296494, acc: 0.9730769395828247)
[2024-11-14 09:05:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:15][root][INFO] - Training Epoch: 2/2, step 4568/16670 completed (loss: 0.019274666905403137, acc: 0.9950248599052429)
[2024-11-14 09:05:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:15][root][INFO] - Training Epoch: 2/2, step 4569/16670 completed (loss: 0.11779562383890152, acc: 0.9608433842658997)
[2024-11-14 09:05:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:16][root][INFO] - Training Epoch: 2/2, step 4570/16670 completed (loss: 0.09493255615234375, acc: 0.9741697311401367)
[2024-11-14 09:05:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:16][root][INFO] - Training Epoch: 2/2, step 4571/16670 completed (loss: 0.05175524204969406, acc: 0.9855072498321533)
[2024-11-14 09:05:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:16][root][INFO] - Training Epoch: 2/2, step 4572/16670 completed (loss: 0.11115719377994537, acc: 0.9603524208068848)
[2024-11-14 09:05:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:17][root][INFO] - Training Epoch: 2/2, step 4573/16670 completed (loss: 0.09479466080665588, acc: 0.9684684872627258)
[2024-11-14 09:05:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:17][root][INFO] - Training Epoch: 2/2, step 4574/16670 completed (loss: 0.1442183256149292, acc: 0.9683908224105835)
[2024-11-14 09:05:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:18][root][INFO] - Training Epoch: 2/2, step 4575/16670 completed (loss: 0.057352740317583084, acc: 0.9806201457977295)
[2024-11-14 09:05:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:18][root][INFO] - Training Epoch: 2/2, step 4576/16670 completed (loss: 0.10980650782585144, acc: 0.9786666631698608)
[2024-11-14 09:05:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:18][root][INFO] - Training Epoch: 2/2, step 4577/16670 completed (loss: 0.1079523116350174, acc: 0.962382435798645)
[2024-11-14 09:05:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:19][root][INFO] - Training Epoch: 2/2, step 4578/16670 completed (loss: 0.10250162333250046, acc: 0.9711191058158875)
[2024-11-14 09:05:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:19][root][INFO] - Training Epoch: 2/2, step 4579/16670 completed (loss: 0.23752354085445404, acc: 0.949999988079071)
[2024-11-14 09:05:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:19][root][INFO] - Training Epoch: 2/2, step 4580/16670 completed (loss: 0.015159519389271736, acc: 1.0)
[2024-11-14 09:05:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:20][root][INFO] - Training Epoch: 2/2, step 4581/16670 completed (loss: 0.0085288779810071, acc: 1.0)
[2024-11-14 09:05:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:20][root][INFO] - Training Epoch: 2/2, step 4582/16670 completed (loss: 0.06811729818582535, acc: 0.9757785201072693)
[2024-11-14 09:05:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:21][root][INFO] - Training Epoch: 2/2, step 4583/16670 completed (loss: 0.07151393592357635, acc: 0.981203019618988)
[2024-11-14 09:05:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:21][root][INFO] - Training Epoch: 2/2, step 4584/16670 completed (loss: 0.048711877316236496, acc: 0.9880478382110596)
[2024-11-14 09:05:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:21][root][INFO] - Training Epoch: 2/2, step 4585/16670 completed (loss: 0.07523851841688156, acc: 0.9757785201072693)
[2024-11-14 09:05:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:22][root][INFO] - Training Epoch: 2/2, step 4586/16670 completed (loss: 0.11980515718460083, acc: 0.9384058117866516)
[2024-11-14 09:05:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:22][root][INFO] - Training Epoch: 2/2, step 4587/16670 completed (loss: 0.03970925509929657, acc: 0.9851852059364319)
[2024-11-14 09:05:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:22][root][INFO] - Training Epoch: 2/2, step 4588/16670 completed (loss: 0.05460639297962189, acc: 0.9886363744735718)
[2024-11-14 09:05:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:23][root][INFO] - Training Epoch: 2/2, step 4589/16670 completed (loss: 0.1243329718708992, acc: 0.9645669460296631)
[2024-11-14 09:05:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:23][root][INFO] - Training Epoch: 2/2, step 4590/16670 completed (loss: 0.13059276342391968, acc: 0.9703390002250671)
[2024-11-14 09:05:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:24][root][INFO] - Training Epoch: 2/2, step 4591/16670 completed (loss: 0.1411471664905548, acc: 0.9638242721557617)
[2024-11-14 09:05:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:24][root][INFO] - Training Epoch: 2/2, step 4592/16670 completed (loss: 0.08891734480857849, acc: 0.9715302586555481)
[2024-11-14 09:05:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:24][root][INFO] - Training Epoch: 2/2, step 4593/16670 completed (loss: 0.12447010725736618, acc: 0.966360867023468)
[2024-11-14 09:05:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:25][root][INFO] - Training Epoch: 2/2, step 4594/16670 completed (loss: 0.13850876688957214, acc: 0.9713261723518372)
[2024-11-14 09:05:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:25][root][INFO] - Training Epoch: 2/2, step 4595/16670 completed (loss: 0.11394478380680084, acc: 0.9685314893722534)
[2024-11-14 09:05:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:26][root][INFO] - Training Epoch: 2/2, step 4596/16670 completed (loss: 0.10157758742570877, acc: 0.9728813767433167)
[2024-11-14 09:05:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:26][root][INFO] - Training Epoch: 2/2, step 4597/16670 completed (loss: 0.1264946609735489, acc: 0.9745222926139832)
[2024-11-14 09:05:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:26][root][INFO] - Training Epoch: 2/2, step 4598/16670 completed (loss: 0.07190588861703873, acc: 0.9843260049819946)
[2024-11-14 09:05:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:27][root][INFO] - Training Epoch: 2/2, step 4599/16670 completed (loss: 0.09279279410839081, acc: 0.9820359349250793)
[2024-11-14 09:05:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:27][root][INFO] - Training Epoch: 2/2, step 4600/16670 completed (loss: 0.06876453757286072, acc: 0.9820144176483154)
[2024-11-14 09:05:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:27][root][INFO] - Training Epoch: 2/2, step 4601/16670 completed (loss: 0.1790623813867569, acc: 0.9516128897666931)
[2024-11-14 09:05:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:28][root][INFO] - Training Epoch: 2/2, step 4602/16670 completed (loss: 0.12452837824821472, acc: 0.9636363387107849)
[2024-11-14 09:05:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:28][root][INFO] - Training Epoch: 2/2, step 4603/16670 completed (loss: 0.036428648978471756, acc: 0.9880239367485046)
[2024-11-14 09:05:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:29][root][INFO] - Training Epoch: 2/2, step 4604/16670 completed (loss: 0.015254057943820953, acc: 1.0)
[2024-11-14 09:05:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:29][root][INFO] - Training Epoch: 2/2, step 4605/16670 completed (loss: 0.06936319172382355, acc: 0.9823529124259949)
[2024-11-14 09:05:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:29][root][INFO] - Training Epoch: 2/2, step 4606/16670 completed (loss: 0.05401845648884773, acc: 0.9874607920646667)
[2024-11-14 09:05:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:30][root][INFO] - Training Epoch: 2/2, step 4607/16670 completed (loss: 0.19535763561725616, acc: 0.9642857313156128)
[2024-11-14 09:05:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:30][root][INFO] - Training Epoch: 2/2, step 4608/16670 completed (loss: 0.03791198879480362, acc: 0.9870689511299133)
[2024-11-14 09:05:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:30][root][INFO] - Training Epoch: 2/2, step 4609/16670 completed (loss: 0.18576715886592865, acc: 0.9677419066429138)
[2024-11-14 09:05:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:31][root][INFO] - Training Epoch: 2/2, step 4610/16670 completed (loss: 0.15242010354995728, acc: 0.9670329689979553)
[2024-11-14 09:05:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:31][root][INFO] - Training Epoch: 2/2, step 4611/16670 completed (loss: 0.0774378776550293, acc: 0.9749373197555542)
[2024-11-14 09:05:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:32][root][INFO] - Training Epoch: 2/2, step 4612/16670 completed (loss: 0.23088061809539795, acc: 0.9304812550544739)
[2024-11-14 09:05:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:32][root][INFO] - Training Epoch: 2/2, step 4613/16670 completed (loss: 0.04481138288974762, acc: 0.98591548204422)
[2024-11-14 09:05:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:32][root][INFO] - Training Epoch: 2/2, step 4614/16670 completed (loss: 0.1918465793132782, acc: 0.9306930899620056)
[2024-11-14 09:05:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:33][root][INFO] - Training Epoch: 2/2, step 4615/16670 completed (loss: 0.20077697932720184, acc: 0.9405940771102905)
[2024-11-14 09:05:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:33][root][INFO] - Training Epoch: 2/2, step 4616/16670 completed (loss: 0.09003221243619919, acc: 0.9736841917037964)
[2024-11-14 09:05:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:33][root][INFO] - Training Epoch: 2/2, step 4617/16670 completed (loss: 0.16534002125263214, acc: 0.9377990365028381)
[2024-11-14 09:05:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:34][root][INFO] - Training Epoch: 2/2, step 4618/16670 completed (loss: 0.06987985223531723, acc: 0.9830508232116699)
[2024-11-14 09:05:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:34][root][INFO] - Training Epoch: 2/2, step 4619/16670 completed (loss: 0.10868535190820694, acc: 0.9700000286102295)
[2024-11-14 09:05:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:34][root][INFO] - Training Epoch: 2/2, step 4620/16670 completed (loss: 0.021728094667196274, acc: 0.994350254535675)
[2024-11-14 09:05:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:35][root][INFO] - Training Epoch: 2/2, step 4621/16670 completed (loss: 0.11854300647974014, acc: 0.9855072498321533)
[2024-11-14 09:05:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:35][root][INFO] - Training Epoch: 2/2, step 4622/16670 completed (loss: 0.14233192801475525, acc: 0.958730161190033)
[2024-11-14 09:05:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:36][root][INFO] - Training Epoch: 2/2, step 4623/16670 completed (loss: 0.10081002861261368, acc: 0.960698664188385)
[2024-11-14 09:05:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:36][root][INFO] - Training Epoch: 2/2, step 4624/16670 completed (loss: 0.10321076959371567, acc: 0.9578313231468201)
[2024-11-14 09:05:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:36][root][INFO] - Training Epoch: 2/2, step 4625/16670 completed (loss: 0.10086628049612045, acc: 0.9641255736351013)
[2024-11-14 09:05:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:37][root][INFO] - Training Epoch: 2/2, step 4626/16670 completed (loss: 0.1423659324645996, acc: 0.9396985173225403)
[2024-11-14 09:05:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:37][root][INFO] - Training Epoch: 2/2, step 4627/16670 completed (loss: 0.03251500427722931, acc: 0.9919354915618896)
[2024-11-14 09:05:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:37][root][INFO] - Training Epoch: 2/2, step 4628/16670 completed (loss: 0.16151441633701324, acc: 0.9645669460296631)
[2024-11-14 09:05:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:38][root][INFO] - Training Epoch: 2/2, step 4629/16670 completed (loss: 0.10284540802240372, acc: 0.983146071434021)
[2024-11-14 09:05:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:38][root][INFO] - Training Epoch: 2/2, step 4630/16670 completed (loss: 0.04010585695505142, acc: 0.993630588054657)
[2024-11-14 09:05:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:38][root][INFO] - Training Epoch: 2/2, step 4631/16670 completed (loss: 0.10981574654579163, acc: 0.9596773982048035)
[2024-11-14 09:05:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:39][root][INFO] - Training Epoch: 2/2, step 4632/16670 completed (loss: 0.05494614690542221, acc: 0.9838709831237793)
[2024-11-14 09:05:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:39][root][INFO] - Training Epoch: 2/2, step 4633/16670 completed (loss: 0.05173885077238083, acc: 0.9873949289321899)
[2024-11-14 09:05:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:39][root][INFO] - Training Epoch: 2/2, step 4634/16670 completed (loss: 0.07018085569143295, acc: 0.977011501789093)
[2024-11-14 09:05:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:40][root][INFO] - Training Epoch: 2/2, step 4635/16670 completed (loss: 0.07624322921037674, acc: 0.9790209531784058)
[2024-11-14 09:05:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:40][root][INFO] - Training Epoch: 2/2, step 4636/16670 completed (loss: 0.13322687149047852, acc: 0.9610389471054077)
[2024-11-14 09:05:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:40][root][INFO] - Training Epoch: 2/2, step 4637/16670 completed (loss: 0.1983088254928589, acc: 0.9420289993286133)
[2024-11-14 09:05:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:41][root][INFO] - Training Epoch: 2/2, step 4638/16670 completed (loss: 0.11461801081895828, acc: 0.9672544002532959)
[2024-11-14 09:05:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:41][root][INFO] - Training Epoch: 2/2, step 4639/16670 completed (loss: 0.05535774305462837, acc: 0.9789473414421082)
[2024-11-14 09:05:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:42][root][INFO] - Training Epoch: 2/2, step 4640/16670 completed (loss: 0.06133636087179184, acc: 0.9850746393203735)
[2024-11-14 09:05:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:42][root][INFO] - Training Epoch: 2/2, step 4641/16670 completed (loss: 0.11128639429807663, acc: 0.9746835231781006)
[2024-11-14 09:05:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:42][root][INFO] - Training Epoch: 2/2, step 4642/16670 completed (loss: 0.02765476331114769, acc: 0.99245285987854)
[2024-11-14 09:05:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:43][root][INFO] - Training Epoch: 2/2, step 4643/16670 completed (loss: 0.040493194013834, acc: 0.9894179701805115)
[2024-11-14 09:05:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:43][root][INFO] - Training Epoch: 2/2, step 4644/16670 completed (loss: 0.3891773223876953, acc: 0.9307692050933838)
[2024-11-14 09:05:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:43][root][INFO] - Training Epoch: 2/2, step 4645/16670 completed (loss: 0.06369327008724213, acc: 0.9725274443626404)
[2024-11-14 09:05:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:44][root][INFO] - Training Epoch: 2/2, step 4646/16670 completed (loss: 0.08148742467164993, acc: 0.9748427867889404)
[2024-11-14 09:05:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:44][root][INFO] - Training Epoch: 2/2, step 4647/16670 completed (loss: 0.18386927247047424, acc: 0.9611650705337524)
[2024-11-14 09:05:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:44][root][INFO] - Training Epoch: 2/2, step 4648/16670 completed (loss: 0.11477749049663544, acc: 0.96875)
[2024-11-14 09:05:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:45][root][INFO] - Training Epoch: 2/2, step 4649/16670 completed (loss: 0.05808175355195999, acc: 0.9858155846595764)
[2024-11-14 09:05:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:45][root][INFO] - Training Epoch: 2/2, step 4650/16670 completed (loss: 0.06887934356927872, acc: 0.985029935836792)
[2024-11-14 09:05:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:46][root][INFO] - Training Epoch: 2/2, step 4651/16670 completed (loss: 0.13332010805606842, acc: 0.9491525292396545)
[2024-11-14 09:05:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:46][root][INFO] - Training Epoch: 2/2, step 4652/16670 completed (loss: 0.06703612953424454, acc: 0.9813953638076782)
[2024-11-14 09:05:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:46][root][INFO] - Training Epoch: 2/2, step 4653/16670 completed (loss: 0.029305724427103996, acc: 0.9923076629638672)
[2024-11-14 09:05:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:47][root][INFO] - Training Epoch: 2/2, step 4654/16670 completed (loss: 0.04470984265208244, acc: 0.9906976819038391)
[2024-11-14 09:05:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:47][root][INFO] - Training Epoch: 2/2, step 4655/16670 completed (loss: 0.05544896423816681, acc: 0.9693251252174377)
[2024-11-14 09:05:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:47][root][INFO] - Training Epoch: 2/2, step 4656/16670 completed (loss: 0.19207042455673218, acc: 0.9515151381492615)
[2024-11-14 09:05:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:48][root][INFO] - Training Epoch: 2/2, step 4657/16670 completed (loss: 0.07951641827821732, acc: 0.9841772317886353)
[2024-11-14 09:05:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:48][root][INFO] - Training Epoch: 2/2, step 4658/16670 completed (loss: 0.1570490598678589, acc: 0.9729729890823364)
[2024-11-14 09:05:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:48][root][INFO] - Training Epoch: 2/2, step 4659/16670 completed (loss: 0.20433087646961212, acc: 0.9491525292396545)
[2024-11-14 09:05:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:49][root][INFO] - Training Epoch: 2/2, step 4660/16670 completed (loss: 0.08392303436994553, acc: 0.9880478382110596)
[2024-11-14 09:05:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:49][root][INFO] - Training Epoch: 2/2, step 4661/16670 completed (loss: 0.028396809473633766, acc: 0.9848484992980957)
[2024-11-14 09:05:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:49][root][INFO] - Training Epoch: 2/2, step 4662/16670 completed (loss: 0.2731662392616272, acc: 0.9125475287437439)
[2024-11-14 09:05:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:50][root][INFO] - Training Epoch: 2/2, step 4663/16670 completed (loss: 0.15421360731124878, acc: 0.9613259434700012)
[2024-11-14 09:05:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:50][root][INFO] - Training Epoch: 2/2, step 4664/16670 completed (loss: 0.017445292323827744, acc: 0.9940119981765747)
[2024-11-14 09:05:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:51][root][INFO] - Training Epoch: 2/2, step 4665/16670 completed (loss: 0.13845963776111603, acc: 0.9681528806686401)
[2024-11-14 09:05:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:51][root][INFO] - Training Epoch: 2/2, step 4666/16670 completed (loss: 0.07874565571546555, acc: 0.9807692170143127)
[2024-11-14 09:05:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:51][root][INFO] - Training Epoch: 2/2, step 4667/16670 completed (loss: 0.07409944385290146, acc: 0.9781659245491028)
[2024-11-14 09:05:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:52][root][INFO] - Training Epoch: 2/2, step 4668/16670 completed (loss: 0.10074833780527115, acc: 0.9578543901443481)
[2024-11-14 09:05:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:52][root][INFO] - Training Epoch: 2/2, step 4669/16670 completed (loss: 0.05682748928666115, acc: 0.9841772317886353)
[2024-11-14 09:05:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:52][root][INFO] - Training Epoch: 2/2, step 4670/16670 completed (loss: 0.05511520430445671, acc: 0.984375)
[2024-11-14 09:05:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:53][root][INFO] - Training Epoch: 2/2, step 4671/16670 completed (loss: 0.11615727841854095, acc: 0.9606481194496155)
[2024-11-14 09:05:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:53][root][INFO] - Training Epoch: 2/2, step 4672/16670 completed (loss: 0.040785565972328186, acc: 0.985981285572052)
[2024-11-14 09:05:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:53][root][INFO] - Training Epoch: 2/2, step 4673/16670 completed (loss: 0.10151778906583786, acc: 0.9709302186965942)
[2024-11-14 09:05:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:54][root][INFO] - Training Epoch: 2/2, step 4674/16670 completed (loss: 0.061743125319480896, acc: 0.9786324501037598)
[2024-11-14 09:05:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:54][root][INFO] - Training Epoch: 2/2, step 4675/16670 completed (loss: 0.03841767460107803, acc: 0.9896373152732849)
[2024-11-14 09:05:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:54][root][INFO] - Training Epoch: 2/2, step 4676/16670 completed (loss: 0.11361780762672424, acc: 0.9509202241897583)
[2024-11-14 09:05:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:55][root][INFO] - Training Epoch: 2/2, step 4677/16670 completed (loss: 0.024298308417201042, acc: 0.9915611743927002)
[2024-11-14 09:05:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:55][root][INFO] - Training Epoch: 2/2, step 4678/16670 completed (loss: 0.07832934707403183, acc: 0.9801980257034302)
[2024-11-14 09:05:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:55][root][INFO] - Training Epoch: 2/2, step 4679/16670 completed (loss: 0.1694541871547699, acc: 0.9425837397575378)
[2024-11-14 09:05:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:55][root][INFO] - Training Epoch: 2/2, step 4680/16670 completed (loss: 0.13912265002727509, acc: 0.9542483687400818)
[2024-11-14 09:05:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:56][root][INFO] - Training Epoch: 2/2, step 4681/16670 completed (loss: 0.12937495112419128, acc: 0.9711934328079224)
[2024-11-14 09:05:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:56][root][INFO] - Training Epoch: 2/2, step 4682/16670 completed (loss: 0.1052405834197998, acc: 0.9865771532058716)
[2024-11-14 09:05:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:56][root][INFO] - Training Epoch: 2/2, step 4683/16670 completed (loss: 0.07147358357906342, acc: 0.9829931855201721)
[2024-11-14 09:05:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:57][root][INFO] - Training Epoch: 2/2, step 4684/16670 completed (loss: 0.19812218844890594, acc: 0.9407407641410828)
[2024-11-14 09:05:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:57][root][INFO] - Training Epoch: 2/2, step 4685/16670 completed (loss: 0.08538920432329178, acc: 0.9743589758872986)
[2024-11-14 09:05:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:58][root][INFO] - Training Epoch: 2/2, step 4686/16670 completed (loss: 0.21658582985401154, acc: 0.9408283829689026)
[2024-11-14 09:05:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:58][root][INFO] - Training Epoch: 2/2, step 4687/16670 completed (loss: 0.11346418410539627, acc: 0.9729729890823364)
[2024-11-14 09:05:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:58][root][INFO] - Training Epoch: 2/2, step 4688/16670 completed (loss: 0.06981608271598816, acc: 0.9767441749572754)
[2024-11-14 09:05:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:59][root][INFO] - Training Epoch: 2/2, step 4689/16670 completed (loss: 0.2042541354894638, acc: 0.9346405267715454)
[2024-11-14 09:05:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:59][root][INFO] - Training Epoch: 2/2, step 4690/16670 completed (loss: 0.1663029044866562, acc: 0.960698664188385)
[2024-11-14 09:05:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:05:59][root][INFO] - Training Epoch: 2/2, step 4691/16670 completed (loss: 0.11823800206184387, acc: 0.9705014824867249)
[2024-11-14 09:06:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:00][root][INFO] - Training Epoch: 2/2, step 4692/16670 completed (loss: 0.04231591895222664, acc: 0.9845361113548279)
[2024-11-14 09:06:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:00][root][INFO] - Training Epoch: 2/2, step 4693/16670 completed (loss: 0.0976828932762146, acc: 0.978787899017334)
[2024-11-14 09:06:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:00][root][INFO] - Training Epoch: 2/2, step 4694/16670 completed (loss: 0.016303153708577156, acc: 1.0)
[2024-11-14 09:06:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:01][root][INFO] - Training Epoch: 2/2, step 4695/16670 completed (loss: 0.0830279216170311, acc: 0.9728096723556519)
[2024-11-14 09:06:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:01][root][INFO] - Training Epoch: 2/2, step 4696/16670 completed (loss: 0.1242983341217041, acc: 0.9481481313705444)
[2024-11-14 09:06:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:02][root][INFO] - Training Epoch: 2/2, step 4697/16670 completed (loss: 0.030479589477181435, acc: 0.9961089491844177)
[2024-11-14 09:06:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:02][root][INFO] - Training Epoch: 2/2, step 4698/16670 completed (loss: 0.11609404534101486, acc: 0.96875)
[2024-11-14 09:06:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:02][root][INFO] - Training Epoch: 2/2, step 4699/16670 completed (loss: 0.15763846039772034, acc: 0.9526315927505493)
[2024-11-14 09:06:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:02][root][INFO] - Training Epoch: 2/2, step 4700/16670 completed (loss: 0.059433307498693466, acc: 0.9878048896789551)
[2024-11-14 09:06:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:03][root][INFO] - Training Epoch: 2/2, step 4701/16670 completed (loss: 0.06443264335393906, acc: 0.9793388247489929)
[2024-11-14 09:06:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:03][root][INFO] - Training Epoch: 2/2, step 4702/16670 completed (loss: 0.09555895626544952, acc: 0.9655172228813171)
[2024-11-14 09:06:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:04][root][INFO] - Training Epoch: 2/2, step 4703/16670 completed (loss: 0.06180435046553612, acc: 0.9850746393203735)
[2024-11-14 09:06:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:04][root][INFO] - Training Epoch: 2/2, step 4704/16670 completed (loss: 0.1371322125196457, acc: 0.9653179049491882)
[2024-11-14 09:06:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:04][root][INFO] - Training Epoch: 2/2, step 4705/16670 completed (loss: 0.0789707750082016, acc: 0.9729729890823364)
[2024-11-14 09:06:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:05][root][INFO] - Training Epoch: 2/2, step 4706/16670 completed (loss: 0.10599867254495621, acc: 0.9751552939414978)
[2024-11-14 09:06:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:05][root][INFO] - Training Epoch: 2/2, step 4707/16670 completed (loss: 0.07969798147678375, acc: 0.9745762944221497)
[2024-11-14 09:06:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:05][root][INFO] - Training Epoch: 2/2, step 4708/16670 completed (loss: 0.1614246368408203, acc: 0.9477351903915405)
[2024-11-14 09:06:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:06][root][INFO] - Training Epoch: 2/2, step 4709/16670 completed (loss: 0.06433718651533127, acc: 0.9818181991577148)
[2024-11-14 09:06:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:06][root][INFO] - Training Epoch: 2/2, step 4710/16670 completed (loss: 0.11634854972362518, acc: 0.9576271176338196)
[2024-11-14 09:06:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:06][root][INFO] - Training Epoch: 2/2, step 4711/16670 completed (loss: 0.16829998791217804, acc: 0.962199330329895)
[2024-11-14 09:06:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:07][root][INFO] - Training Epoch: 2/2, step 4712/16670 completed (loss: 0.019548283889889717, acc: 0.9956140518188477)
[2024-11-14 09:06:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:07][root][INFO] - Training Epoch: 2/2, step 4713/16670 completed (loss: 0.03816494345664978, acc: 0.9815384745597839)
[2024-11-14 09:06:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:07][root][INFO] - Training Epoch: 2/2, step 4714/16670 completed (loss: 0.05378706753253937, acc: 0.9841772317886353)
[2024-11-14 09:06:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:08][root][INFO] - Training Epoch: 2/2, step 4715/16670 completed (loss: 0.09968201071023941, acc: 0.9795918464660645)
[2024-11-14 09:06:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:08][root][INFO] - Training Epoch: 2/2, step 4716/16670 completed (loss: 0.1557389348745346, acc: 0.9548611044883728)
[2024-11-14 09:06:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:09][root][INFO] - Training Epoch: 2/2, step 4717/16670 completed (loss: 0.23697000741958618, acc: 0.9276595711708069)
[2024-11-14 09:06:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:09][root][INFO] - Training Epoch: 2/2, step 4718/16670 completed (loss: 0.27324530482292175, acc: 0.9318181872367859)
[2024-11-14 09:06:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:09][root][INFO] - Training Epoch: 2/2, step 4719/16670 completed (loss: 0.16514696180820465, acc: 0.961240291595459)
[2024-11-14 09:06:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:10][root][INFO] - Training Epoch: 2/2, step 4720/16670 completed (loss: 0.17478537559509277, acc: 0.9508196711540222)
[2024-11-14 09:06:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:10][root][INFO] - Training Epoch: 2/2, step 4721/16670 completed (loss: 0.06544069200754166, acc: 0.9811320900917053)
[2024-11-14 09:06:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:10][root][INFO] - Training Epoch: 2/2, step 4722/16670 completed (loss: 0.05057568848133087, acc: 0.9883268475532532)
[2024-11-14 09:06:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:11][root][INFO] - Training Epoch: 2/2, step 4723/16670 completed (loss: 0.06875798851251602, acc: 0.9800664186477661)
[2024-11-14 09:06:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:11][root][INFO] - Training Epoch: 2/2, step 4724/16670 completed (loss: 0.018360871821641922, acc: 0.9931972622871399)
[2024-11-14 09:06:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:12][root][INFO] - Training Epoch: 2/2, step 4725/16670 completed (loss: 0.07571940124034882, acc: 0.9683544039726257)
[2024-11-14 09:06:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:12][root][INFO] - Training Epoch: 2/2, step 4726/16670 completed (loss: 0.047885604202747345, acc: 0.9872881174087524)
[2024-11-14 09:06:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:12][root][INFO] - Training Epoch: 2/2, step 4727/16670 completed (loss: 0.03672251105308533, acc: 0.9936102032661438)
[2024-11-14 09:06:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:13][root][INFO] - Training Epoch: 2/2, step 4728/16670 completed (loss: 0.08908464014530182, acc: 0.9735099077224731)
[2024-11-14 09:06:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:13][root][INFO] - Training Epoch: 2/2, step 4729/16670 completed (loss: 0.08955550193786621, acc: 0.9733333587646484)
[2024-11-14 09:06:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:13][root][INFO] - Training Epoch: 2/2, step 4730/16670 completed (loss: 0.05222896486520767, acc: 0.9788135886192322)
[2024-11-14 09:06:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:14][root][INFO] - Training Epoch: 2/2, step 4731/16670 completed (loss: 0.08840001374483109, acc: 0.9739776849746704)
[2024-11-14 09:06:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:14][root][INFO] - Training Epoch: 2/2, step 4732/16670 completed (loss: 0.04364908114075661, acc: 0.98828125)
[2024-11-14 09:06:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:15][root][INFO] - Training Epoch: 2/2, step 4733/16670 completed (loss: 0.10598677396774292, acc: 0.9745762944221497)
[2024-11-14 09:06:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:15][root][INFO] - Training Epoch: 2/2, step 4734/16670 completed (loss: 0.1699654757976532, acc: 0.938144326210022)
[2024-11-14 09:06:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:15][root][INFO] - Training Epoch: 2/2, step 4735/16670 completed (loss: 0.08338794857263565, acc: 0.9758307933807373)
[2024-11-14 09:06:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:16][root][INFO] - Training Epoch: 2/2, step 4736/16670 completed (loss: 0.06295912712812424, acc: 0.9785407781600952)
[2024-11-14 09:06:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:16][root][INFO] - Training Epoch: 2/2, step 4737/16670 completed (loss: 0.027956625446677208, acc: 0.9936708807945251)
[2024-11-14 09:06:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:16][root][INFO] - Training Epoch: 2/2, step 4738/16670 completed (loss: 0.16398124396800995, acc: 0.9525691866874695)
[2024-11-14 09:06:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:17][root][INFO] - Training Epoch: 2/2, step 4739/16670 completed (loss: 0.1159069687128067, acc: 0.9811320900917053)
[2024-11-14 09:06:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:17][root][INFO] - Training Epoch: 2/2, step 4740/16670 completed (loss: 0.20577357709407806, acc: 0.9518072009086609)
[2024-11-14 09:06:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:18][root][INFO] - Training Epoch: 2/2, step 4741/16670 completed (loss: 0.02160935290157795, acc: 0.9906542301177979)
[2024-11-14 09:06:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:18][root][INFO] - Training Epoch: 2/2, step 4742/16670 completed (loss: 0.1033293604850769, acc: 0.9803921580314636)
[2024-11-14 09:06:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:18][root][INFO] - Training Epoch: 2/2, step 4743/16670 completed (loss: 0.31508147716522217, acc: 0.8876404762268066)
[2024-11-14 09:06:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:19][root][INFO] - Training Epoch: 2/2, step 4744/16670 completed (loss: 0.15984471142292023, acc: 0.9475409984588623)
[2024-11-14 09:06:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:19][root][INFO] - Training Epoch: 2/2, step 4745/16670 completed (loss: 0.06835373491048813, acc: 0.97826087474823)
[2024-11-14 09:06:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:20][root][INFO] - Training Epoch: 2/2, step 4746/16670 completed (loss: 0.07017377018928528, acc: 0.9836065769195557)
[2024-11-14 09:06:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:20][root][INFO] - Training Epoch: 2/2, step 4747/16670 completed (loss: 0.060874614864587784, acc: 0.9838709831237793)
[2024-11-14 09:06:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:20][root][INFO] - Training Epoch: 2/2, step 4748/16670 completed (loss: 0.11840265244245529, acc: 0.9695122241973877)
[2024-11-14 09:06:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:21][root][INFO] - Training Epoch: 2/2, step 4749/16670 completed (loss: 0.13574020564556122, acc: 0.9695122241973877)
[2024-11-14 09:06:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:21][root][INFO] - Training Epoch: 2/2, step 4750/16670 completed (loss: 0.0863354504108429, acc: 0.9757575988769531)
[2024-11-14 09:06:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:21][root][INFO] - Training Epoch: 2/2, step 4751/16670 completed (loss: 0.08247663825750351, acc: 0.9696969985961914)
[2024-11-14 09:06:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:22][root][INFO] - Training Epoch: 2/2, step 4752/16670 completed (loss: 0.06737975031137466, acc: 0.9824561476707458)
[2024-11-14 09:06:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:22][root][INFO] - Training Epoch: 2/2, step 4753/16670 completed (loss: 0.04752904176712036, acc: 0.9855595827102661)
[2024-11-14 09:06:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:23][root][INFO] - Training Epoch: 2/2, step 4754/16670 completed (loss: 0.04088659957051277, acc: 0.990338146686554)
[2024-11-14 09:06:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:23][root][INFO] - Training Epoch: 2/2, step 4755/16670 completed (loss: 0.11851777881383896, acc: 0.9671052694320679)
[2024-11-14 09:06:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:23][root][INFO] - Training Epoch: 2/2, step 4756/16670 completed (loss: 0.24734868109226227, acc: 0.9444444179534912)
[2024-11-14 09:06:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:24][root][INFO] - Training Epoch: 2/2, step 4757/16670 completed (loss: 0.06455665826797485, acc: 0.9828571677207947)
[2024-11-14 09:06:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:24][root][INFO] - Training Epoch: 2/2, step 4758/16670 completed (loss: 0.1250816136598587, acc: 0.9672130942344666)
[2024-11-14 09:06:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:25][root][INFO] - Training Epoch: 2/2, step 4759/16670 completed (loss: 0.09684567153453827, acc: 0.9746835231781006)
[2024-11-14 09:06:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:25][root][INFO] - Training Epoch: 2/2, step 4760/16670 completed (loss: 0.09585292637348175, acc: 0.9855769276618958)
[2024-11-14 09:06:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:25][root][INFO] - Training Epoch: 2/2, step 4761/16670 completed (loss: 0.09233647584915161, acc: 0.9814814925193787)
[2024-11-14 09:06:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:26][root][INFO] - Training Epoch: 2/2, step 4762/16670 completed (loss: 0.12656809389591217, acc: 0.9795082211494446)
[2024-11-14 09:06:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:26][root][INFO] - Training Epoch: 2/2, step 4763/16670 completed (loss: 0.15998899936676025, acc: 0.9527897238731384)
[2024-11-14 09:06:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:27][root][INFO] - Training Epoch: 2/2, step 4764/16670 completed (loss: 0.104317307472229, acc: 0.9696969985961914)
[2024-11-14 09:06:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:27][root][INFO] - Training Epoch: 2/2, step 4765/16670 completed (loss: 0.06843508780002594, acc: 0.9814814925193787)
[2024-11-14 09:06:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:27][root][INFO] - Training Epoch: 2/2, step 4766/16670 completed (loss: 0.05783779174089432, acc: 0.9942857027053833)
[2024-11-14 09:06:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:28][root][INFO] - Training Epoch: 2/2, step 4767/16670 completed (loss: 0.21400754153728485, acc: 0.9375)
[2024-11-14 09:06:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:28][root][INFO] - Training Epoch: 2/2, step 4768/16670 completed (loss: 0.12401005625724792, acc: 0.9648241400718689)
[2024-11-14 09:06:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:28][root][INFO] - Training Epoch: 2/2, step 4769/16670 completed (loss: 0.16648028790950775, acc: 0.9613733887672424)
[2024-11-14 09:06:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:29][root][INFO] - Training Epoch: 2/2, step 4770/16670 completed (loss: 0.1294155716896057, acc: 0.9672726988792419)
[2024-11-14 09:06:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:29][root][INFO] - Training Epoch: 2/2, step 4771/16670 completed (loss: 0.13609111309051514, acc: 0.960869550704956)
[2024-11-14 09:06:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:30][root][INFO] - Training Epoch: 2/2, step 4772/16670 completed (loss: 0.16924543678760529, acc: 0.9568345546722412)
[2024-11-14 09:06:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:30][root][INFO] - Training Epoch: 2/2, step 4773/16670 completed (loss: 0.05469566583633423, acc: 0.9824561476707458)
[2024-11-14 09:06:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:30][root][INFO] - Training Epoch: 2/2, step 4774/16670 completed (loss: 0.1865180879831314, acc: 0.9462810158729553)
[2024-11-14 09:06:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:31][root][INFO] - Training Epoch: 2/2, step 4775/16670 completed (loss: 0.0952385663986206, acc: 0.9716981053352356)
[2024-11-14 09:06:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:31][root][INFO] - Training Epoch: 2/2, step 4776/16670 completed (loss: 0.1088126078248024, acc: 0.9648241400718689)
[2024-11-14 09:06:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:31][root][INFO] - Training Epoch: 2/2, step 4777/16670 completed (loss: 0.12919338047504425, acc: 0.9656357169151306)
[2024-11-14 09:06:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:32][root][INFO] - Training Epoch: 2/2, step 4778/16670 completed (loss: 0.13855180144309998, acc: 0.9599999785423279)
[2024-11-14 09:06:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:32][root][INFO] - Training Epoch: 2/2, step 4779/16670 completed (loss: 0.09948381781578064, acc: 0.9800570011138916)
[2024-11-14 09:06:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:33][root][INFO] - Training Epoch: 2/2, step 4780/16670 completed (loss: 0.04627889767289162, acc: 0.98591548204422)
[2024-11-14 09:06:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:33][root][INFO] - Training Epoch: 2/2, step 4781/16670 completed (loss: 0.07086041569709778, acc: 0.9828571677207947)
[2024-11-14 09:06:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:33][root][INFO] - Training Epoch: 2/2, step 4782/16670 completed (loss: 0.0607006698846817, acc: 0.9831932783126831)
[2024-11-14 09:06:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:34][root][INFO] - Training Epoch: 2/2, step 4783/16670 completed (loss: 0.15717053413391113, acc: 0.9591078162193298)
[2024-11-14 09:06:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:34][root][INFO] - Training Epoch: 2/2, step 4784/16670 completed (loss: 0.19616824388504028, acc: 0.9495798349380493)
[2024-11-14 09:06:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:34][root][INFO] - Training Epoch: 2/2, step 4785/16670 completed (loss: 0.162847638130188, acc: 0.9618320465087891)
[2024-11-14 09:06:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:35][root][INFO] - Training Epoch: 2/2, step 4786/16670 completed (loss: 0.10025506466627121, acc: 0.9745222926139832)
[2024-11-14 09:06:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:35][root][INFO] - Training Epoch: 2/2, step 4787/16670 completed (loss: 0.14721305668354034, acc: 0.9595959782600403)
[2024-11-14 09:06:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:36][root][INFO] - Training Epoch: 2/2, step 4788/16670 completed (loss: 0.10768026113510132, acc: 0.9726027250289917)
[2024-11-14 09:06:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:36][root][INFO] - Training Epoch: 2/2, step 4789/16670 completed (loss: 0.06311476230621338, acc: 0.9747474789619446)
[2024-11-14 09:06:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:36][root][INFO] - Training Epoch: 2/2, step 4790/16670 completed (loss: 0.0894191786646843, acc: 0.9754098653793335)
[2024-11-14 09:06:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:37][root][INFO] - Training Epoch: 2/2, step 4791/16670 completed (loss: 0.10696884244680405, acc: 0.9741100072860718)
[2024-11-14 09:06:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:37][root][INFO] - Training Epoch: 2/2, step 4792/16670 completed (loss: 0.12437234073877335, acc: 0.9629629850387573)
[2024-11-14 09:06:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:37][root][INFO] - Training Epoch: 2/2, step 4793/16670 completed (loss: 0.05096256732940674, acc: 0.9750000238418579)
[2024-11-14 09:06:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:38][root][INFO] - Training Epoch: 2/2, step 4794/16670 completed (loss: 0.07706034928560257, acc: 0.9702127575874329)
[2024-11-14 09:06:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:38][root][INFO] - Training Epoch: 2/2, step 4795/16670 completed (loss: 0.13653331995010376, acc: 0.96875)
[2024-11-14 09:06:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:38][root][INFO] - Training Epoch: 2/2, step 4796/16670 completed (loss: 0.06505253165960312, acc: 0.9734042286872864)
[2024-11-14 09:06:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:39][root][INFO] - Training Epoch: 2/2, step 4797/16670 completed (loss: 0.08681763708591461, acc: 0.9773755669593811)
[2024-11-14 09:06:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:39][root][INFO] - Training Epoch: 2/2, step 4798/16670 completed (loss: 0.07520498335361481, acc: 0.9795918464660645)
[2024-11-14 09:06:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:40][root][INFO] - Training Epoch: 2/2, step 4799/16670 completed (loss: 0.22305531799793243, acc: 0.9259259104728699)
[2024-11-14 09:06:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:40][root][INFO] - Training Epoch: 2/2, step 4800/16670 completed (loss: 0.09146080166101456, acc: 0.9808306694030762)
[2024-11-14 09:06:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:40][root][INFO] - Training Epoch: 2/2, step 4801/16670 completed (loss: 0.08652740716934204, acc: 0.9744681119918823)
[2024-11-14 09:06:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:41][root][INFO] - Training Epoch: 2/2, step 4802/16670 completed (loss: 0.13998150825500488, acc: 0.9591836929321289)
[2024-11-14 09:06:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:41][root][INFO] - Training Epoch: 2/2, step 4803/16670 completed (loss: 0.07331742346286774, acc: 0.9767441749572754)
[2024-11-14 09:06:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:41][root][INFO] - Training Epoch: 2/2, step 4804/16670 completed (loss: 0.15182803571224213, acc: 0.971731424331665)
[2024-11-14 09:06:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:42][root][INFO] - Training Epoch: 2/2, step 4805/16670 completed (loss: 0.23977337777614594, acc: 0.944615364074707)
[2024-11-14 09:06:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:42][root][INFO] - Training Epoch: 2/2, step 4806/16670 completed (loss: 0.05118640884757042, acc: 0.9875518679618835)
[2024-11-14 09:06:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:43][root][INFO] - Training Epoch: 2/2, step 4807/16670 completed (loss: 0.1436629593372345, acc: 0.9668246507644653)
[2024-11-14 09:06:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:43][root][INFO] - Training Epoch: 2/2, step 4808/16670 completed (loss: 0.12593962252140045, acc: 0.9700374603271484)
[2024-11-14 09:06:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:43][root][INFO] - Training Epoch: 2/2, step 4809/16670 completed (loss: 0.15648828446865082, acc: 0.9438202381134033)
[2024-11-14 09:06:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:44][root][INFO] - Training Epoch: 2/2, step 4810/16670 completed (loss: 0.03875259682536125, acc: 0.9875776171684265)
[2024-11-14 09:06:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:44][root][INFO] - Training Epoch: 2/2, step 4811/16670 completed (loss: 0.07934965938329697, acc: 0.9810426831245422)
[2024-11-14 09:06:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:44][root][INFO] - Training Epoch: 2/2, step 4812/16670 completed (loss: 0.19393837451934814, acc: 0.9402984976768494)
[2024-11-14 09:06:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:45][root][INFO] - Training Epoch: 2/2, step 4813/16670 completed (loss: 0.04177290201187134, acc: 0.9885495901107788)
[2024-11-14 09:06:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:45][root][INFO] - Training Epoch: 2/2, step 4814/16670 completed (loss: 0.09370583295822144, acc: 0.9826989769935608)
[2024-11-14 09:06:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:46][root][INFO] - Training Epoch: 2/2, step 4815/16670 completed (loss: 0.07894585281610489, acc: 0.9864406585693359)
[2024-11-14 09:06:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:46][root][INFO] - Training Epoch: 2/2, step 4816/16670 completed (loss: 0.18217548727989197, acc: 0.9542483687400818)
[2024-11-14 09:06:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:46][root][INFO] - Training Epoch: 2/2, step 4817/16670 completed (loss: 0.1376606673002243, acc: 0.9578947424888611)
[2024-11-14 09:06:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:47][root][INFO] - Training Epoch: 2/2, step 4818/16670 completed (loss: 0.041679445654153824, acc: 0.9895104765892029)
[2024-11-14 09:06:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:47][root][INFO] - Training Epoch: 2/2, step 4819/16670 completed (loss: 0.03196925297379494, acc: 0.991150438785553)
[2024-11-14 09:06:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:47][root][INFO] - Training Epoch: 2/2, step 4820/16670 completed (loss: 0.20945097506046295, acc: 0.9482758641242981)
[2024-11-14 09:06:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:48][root][INFO] - Training Epoch: 2/2, step 4821/16670 completed (loss: 0.06605121493339539, acc: 0.9780701994895935)
[2024-11-14 09:06:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:48][root][INFO] - Training Epoch: 2/2, step 4822/16670 completed (loss: 0.177003875374794, acc: 0.9607142806053162)
[2024-11-14 09:06:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:49][root][INFO] - Training Epoch: 2/2, step 4823/16670 completed (loss: 0.08241261541843414, acc: 0.9807692170143127)
[2024-11-14 09:06:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:49][root][INFO] - Training Epoch: 2/2, step 4824/16670 completed (loss: 0.013182935304939747, acc: 1.0)
[2024-11-14 09:06:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:49][root][INFO] - Training Epoch: 2/2, step 4825/16670 completed (loss: 0.09865312278270721, acc: 0.9689119458198547)
[2024-11-14 09:06:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:50][root][INFO] - Training Epoch: 2/2, step 4826/16670 completed (loss: 0.05006716772913933, acc: 0.9864864945411682)
[2024-11-14 09:06:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:50][root][INFO] - Training Epoch: 2/2, step 4827/16670 completed (loss: 0.10819027572870255, acc: 0.9747474789619446)
[2024-11-14 09:06:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:50][root][INFO] - Training Epoch: 2/2, step 4828/16670 completed (loss: 0.08845984190702438, acc: 0.9780564308166504)
[2024-11-14 09:06:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:51][root][INFO] - Training Epoch: 2/2, step 4829/16670 completed (loss: 0.0446191169321537, acc: 0.9882006049156189)
[2024-11-14 09:06:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:51][root][INFO] - Training Epoch: 2/2, step 4830/16670 completed (loss: 0.241150364279747, acc: 0.9261363744735718)
[2024-11-14 09:06:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:52][root][INFO] - Training Epoch: 2/2, step 4831/16670 completed (loss: 0.12556521594524384, acc: 0.9613526463508606)
[2024-11-14 09:06:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:52][root][INFO] - Training Epoch: 2/2, step 4832/16670 completed (loss: 0.14672760665416718, acc: 0.9693877696990967)
[2024-11-14 09:06:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:52][root][INFO] - Training Epoch: 2/2, step 4833/16670 completed (loss: 0.06285801529884338, acc: 0.9826086759567261)
[2024-11-14 09:06:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:53][root][INFO] - Training Epoch: 2/2, step 4834/16670 completed (loss: 0.038868896663188934, acc: 0.984375)
[2024-11-14 09:06:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:53][root][INFO] - Training Epoch: 2/2, step 4835/16670 completed (loss: 0.039272490888834, acc: 0.9958333373069763)
[2024-11-14 09:06:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:53][root][INFO] - Training Epoch: 2/2, step 4836/16670 completed (loss: 0.13377508521080017, acc: 0.96517413854599)
[2024-11-14 09:06:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:54][root][INFO] - Training Epoch: 2/2, step 4837/16670 completed (loss: 0.0566130094230175, acc: 0.9831932783126831)
[2024-11-14 09:06:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:54][root][INFO] - Training Epoch: 2/2, step 4838/16670 completed (loss: 0.05304040014743805, acc: 0.9880478382110596)
[2024-11-14 09:06:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:54][root][INFO] - Training Epoch: 2/2, step 4839/16670 completed (loss: 0.07214533537626266, acc: 0.9851852059364319)
[2024-11-14 09:06:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:55][root][INFO] - Training Epoch: 2/2, step 4840/16670 completed (loss: 0.07963760942220688, acc: 0.9780219793319702)
[2024-11-14 09:06:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:55][root][INFO] - Training Epoch: 2/2, step 4841/16670 completed (loss: 0.1072859987616539, acc: 0.9496855139732361)
[2024-11-14 09:06:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:55][root][INFO] - Training Epoch: 2/2, step 4842/16670 completed (loss: 0.08100823312997818, acc: 0.98525071144104)
[2024-11-14 09:06:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:56][root][INFO] - Training Epoch: 2/2, step 4843/16670 completed (loss: 0.03502872586250305, acc: 0.9879518151283264)
[2024-11-14 09:06:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:56][root][INFO] - Training Epoch: 2/2, step 4844/16670 completed (loss: 0.046073608100414276, acc: 0.9855072498321533)
[2024-11-14 09:06:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:56][root][INFO] - Training Epoch: 2/2, step 4845/16670 completed (loss: 0.08009402453899384, acc: 0.9719298481941223)
[2024-11-14 09:06:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:57][root][INFO] - Training Epoch: 2/2, step 4846/16670 completed (loss: 0.07461077719926834, acc: 0.9763157963752747)
[2024-11-14 09:06:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:57][root][INFO] - Training Epoch: 2/2, step 4847/16670 completed (loss: 0.09986579418182373, acc: 0.9654255509376526)
[2024-11-14 09:06:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:58][root][INFO] - Training Epoch: 2/2, step 4848/16670 completed (loss: 0.183064267039299, acc: 0.948113203048706)
[2024-11-14 09:06:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:58][root][INFO] - Training Epoch: 2/2, step 4849/16670 completed (loss: 0.09014780074357986, acc: 0.9762845635414124)
[2024-11-14 09:06:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:58][root][INFO] - Training Epoch: 2/2, step 4850/16670 completed (loss: 0.06963566690683365, acc: 0.9913294911384583)
[2024-11-14 09:06:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:59][root][INFO] - Training Epoch: 2/2, step 4851/16670 completed (loss: 0.03690129518508911, acc: 0.9902912378311157)
[2024-11-14 09:06:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:59][root][INFO] - Training Epoch: 2/2, step 4852/16670 completed (loss: 0.1057555079460144, acc: 0.9629629850387573)
[2024-11-14 09:06:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:06:59][root][INFO] - Training Epoch: 2/2, step 4853/16670 completed (loss: 0.055213216692209244, acc: 0.9904305934906006)
[2024-11-14 09:06:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:00][root][INFO] - Training Epoch: 2/2, step 4854/16670 completed (loss: 0.043154340237379074, acc: 0.9822221994400024)
[2024-11-14 09:07:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:00][root][INFO] - Training Epoch: 2/2, step 4855/16670 completed (loss: 0.060773465782403946, acc: 0.9771987199783325)
[2024-11-14 09:07:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:00][root][INFO] - Training Epoch: 2/2, step 4856/16670 completed (loss: 0.03385559841990471, acc: 0.9904761910438538)
[2024-11-14 09:07:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:01][root][INFO] - Training Epoch: 2/2, step 4857/16670 completed (loss: 0.06859812140464783, acc: 0.9894366264343262)
[2024-11-14 09:07:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:01][root][INFO] - Training Epoch: 2/2, step 4858/16670 completed (loss: 0.07006088644266129, acc: 0.9765396118164062)
[2024-11-14 09:07:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:01][root][INFO] - Training Epoch: 2/2, step 4859/16670 completed (loss: 0.07098400592803955, acc: 0.98591548204422)
[2024-11-14 09:07:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:02][root][INFO] - Training Epoch: 2/2, step 4860/16670 completed (loss: 0.05396166816353798, acc: 0.9772727489471436)
[2024-11-14 09:07:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:02][root][INFO] - Training Epoch: 2/2, step 4861/16670 completed (loss: 0.014751022681593895, acc: 1.0)
[2024-11-14 09:07:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:03][root][INFO] - Training Epoch: 2/2, step 4862/16670 completed (loss: 0.046049606055021286, acc: 0.9947090148925781)
[2024-11-14 09:07:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:03][root][INFO] - Training Epoch: 2/2, step 4863/16670 completed (loss: 0.06511268764734268, acc: 0.9796748161315918)
[2024-11-14 09:07:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:03][root][INFO] - Training Epoch: 2/2, step 4864/16670 completed (loss: 0.03591131046414375, acc: 0.9958677887916565)
[2024-11-14 09:07:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:04][root][INFO] - Training Epoch: 2/2, step 4865/16670 completed (loss: 0.16252553462982178, acc: 0.9626865386962891)
[2024-11-14 09:07:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:04][root][INFO] - Training Epoch: 2/2, step 4866/16670 completed (loss: 0.10498779267072678, acc: 0.9702970385551453)
[2024-11-14 09:07:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:04][root][INFO] - Training Epoch: 2/2, step 4867/16670 completed (loss: 0.06282472610473633, acc: 0.9863945841789246)
[2024-11-14 09:07:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:05][root][INFO] - Training Epoch: 2/2, step 4868/16670 completed (loss: 0.08013653010129929, acc: 0.9702127575874329)
[2024-11-14 09:07:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:05][root][INFO] - Training Epoch: 2/2, step 4869/16670 completed (loss: 0.06536728143692017, acc: 0.9826839566230774)
[2024-11-14 09:07:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:05][root][INFO] - Training Epoch: 2/2, step 4870/16670 completed (loss: 0.03148697689175606, acc: 0.982807993888855)
[2024-11-14 09:07:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:06][root][INFO] - Training Epoch: 2/2, step 4871/16670 completed (loss: 0.12297043204307556, acc: 0.9629629850387573)
[2024-11-14 09:07:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:06][root][INFO] - Training Epoch: 2/2, step 4872/16670 completed (loss: 0.06252976506948471, acc: 0.984674334526062)
[2024-11-14 09:07:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:06][root][INFO] - Training Epoch: 2/2, step 4873/16670 completed (loss: 0.07109035551548004, acc: 0.9775280952453613)
[2024-11-14 09:07:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:07][root][INFO] - Training Epoch: 2/2, step 4874/16670 completed (loss: 0.08085305243730545, acc: 0.9738805890083313)
[2024-11-14 09:07:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:07][root][INFO] - Training Epoch: 2/2, step 4875/16670 completed (loss: 0.1554507613182068, acc: 0.9728506803512573)
[2024-11-14 09:07:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:07][root][INFO] - Training Epoch: 2/2, step 4876/16670 completed (loss: 0.059277601540088654, acc: 0.9824561476707458)
[2024-11-14 09:07:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:08][root][INFO] - Training Epoch: 2/2, step 4877/16670 completed (loss: 0.048683490604162216, acc: 0.9953703880310059)
[2024-11-14 09:07:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:08][root][INFO] - Training Epoch: 2/2, step 4878/16670 completed (loss: 0.04551596939563751, acc: 1.0)
[2024-11-14 09:07:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:08][root][INFO] - Training Epoch: 2/2, step 4879/16670 completed (loss: 0.04799489304423332, acc: 0.9799330830574036)
[2024-11-14 09:07:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:09][root][INFO] - Training Epoch: 2/2, step 4880/16670 completed (loss: 0.08041026443243027, acc: 0.9738903641700745)
[2024-11-14 09:07:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:09][root][INFO] - Training Epoch: 2/2, step 4881/16670 completed (loss: 0.17800159752368927, acc: 0.9489361643791199)
[2024-11-14 09:07:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:10][root][INFO] - Training Epoch: 2/2, step 4882/16670 completed (loss: 0.15692196786403656, acc: 0.9623287916183472)
[2024-11-14 09:07:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:10][root][INFO] - Training Epoch: 2/2, step 4883/16670 completed (loss: 0.06933744251728058, acc: 0.9784172773361206)
[2024-11-14 09:07:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:10][root][INFO] - Training Epoch: 2/2, step 4884/16670 completed (loss: 0.08866389095783234, acc: 0.969348669052124)
[2024-11-14 09:07:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:11][root][INFO] - Training Epoch: 2/2, step 4885/16670 completed (loss: 0.07635309547185898, acc: 0.9774436354637146)
[2024-11-14 09:07:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:11][root][INFO] - Training Epoch: 2/2, step 4886/16670 completed (loss: 0.10060586780309677, acc: 0.9742646813392639)
[2024-11-14 09:07:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:11][root][INFO] - Training Epoch: 2/2, step 4887/16670 completed (loss: 0.058639269322156906, acc: 0.9817517995834351)
[2024-11-14 09:07:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:12][root][INFO] - Training Epoch: 2/2, step 4888/16670 completed (loss: 0.055974122136831284, acc: 0.9900000095367432)
[2024-11-14 09:07:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:12][root][INFO] - Training Epoch: 2/2, step 4889/16670 completed (loss: 0.17262719571590424, acc: 0.9552238583564758)
[2024-11-14 09:07:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:12][root][INFO] - Training Epoch: 2/2, step 4890/16670 completed (loss: 0.1470184326171875, acc: 0.9502074718475342)
[2024-11-14 09:07:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:13][root][INFO] - Training Epoch: 2/2, step 4891/16670 completed (loss: 0.13272276520729065, acc: 0.96875)
[2024-11-14 09:07:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:13][root][INFO] - Training Epoch: 2/2, step 4892/16670 completed (loss: 0.1059306263923645, acc: 0.9663299918174744)
[2024-11-14 09:07:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:14][root][INFO] - Training Epoch: 2/2, step 4893/16670 completed (loss: 0.02181732840836048, acc: 0.9907692074775696)
[2024-11-14 09:07:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:14][root][INFO] - Training Epoch: 2/2, step 4894/16670 completed (loss: 0.1466926485300064, acc: 0.9713114500045776)
[2024-11-14 09:07:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:14][root][INFO] - Training Epoch: 2/2, step 4895/16670 completed (loss: 0.0904703214764595, acc: 0.9754385948181152)
[2024-11-14 09:07:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:15][root][INFO] - Training Epoch: 2/2, step 4896/16670 completed (loss: 0.1366773545742035, acc: 0.9665071964263916)
[2024-11-14 09:07:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:15][root][INFO] - Training Epoch: 2/2, step 4897/16670 completed (loss: 0.06773828715085983, acc: 0.976047933101654)
[2024-11-14 09:07:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:16][root][INFO] - Training Epoch: 2/2, step 4898/16670 completed (loss: 0.08160578459501266, acc: 0.9747474789619446)
[2024-11-14 09:07:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:16][root][INFO] - Training Epoch: 2/2, step 4899/16670 completed (loss: 0.19532553851604462, acc: 0.9411764740943909)
[2024-11-14 09:07:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:16][root][INFO] - Training Epoch: 2/2, step 4900/16670 completed (loss: 0.10807972401380539, acc: 0.967391312122345)
[2024-11-14 09:07:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:17][root][INFO] - Training Epoch: 2/2, step 4901/16670 completed (loss: 0.06964246183633804, acc: 0.9822485446929932)
[2024-11-14 09:07:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:17][root][INFO] - Training Epoch: 2/2, step 4902/16670 completed (loss: 0.08391652256250381, acc: 0.9675675630569458)
[2024-11-14 09:07:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:17][root][INFO] - Training Epoch: 2/2, step 4903/16670 completed (loss: 0.08901704847812653, acc: 0.981566846370697)
[2024-11-14 09:07:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:18][root][INFO] - Training Epoch: 2/2, step 4904/16670 completed (loss: 0.06458190083503723, acc: 0.9726443886756897)
[2024-11-14 09:07:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:18][root][INFO] - Training Epoch: 2/2, step 4905/16670 completed (loss: 0.1856708824634552, acc: 0.9642857313156128)
[2024-11-14 09:07:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:18][root][INFO] - Training Epoch: 2/2, step 4906/16670 completed (loss: 0.07813223451375961, acc: 0.9784946441650391)
[2024-11-14 09:07:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:19][root][INFO] - Training Epoch: 2/2, step 4907/16670 completed (loss: 0.12733930349349976, acc: 0.9738219976425171)
[2024-11-14 09:07:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:19][root][INFO] - Training Epoch: 2/2, step 4908/16670 completed (loss: 0.08365662395954132, acc: 0.9791666865348816)
[2024-11-14 09:07:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:19][root][INFO] - Training Epoch: 2/2, step 4909/16670 completed (loss: 0.06292393058538437, acc: 0.9787985682487488)
[2024-11-14 09:07:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:20][root][INFO] - Training Epoch: 2/2, step 4910/16670 completed (loss: 0.046704474836587906, acc: 0.9890710115432739)
[2024-11-14 09:07:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:20][root][INFO] - Training Epoch: 2/2, step 4911/16670 completed (loss: 0.07134176045656204, acc: 0.9847328066825867)
[2024-11-14 09:07:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:20][root][INFO] - Training Epoch: 2/2, step 4912/16670 completed (loss: 0.1020376980304718, acc: 0.9596773982048035)
[2024-11-14 09:07:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:21][root][INFO] - Training Epoch: 2/2, step 4913/16670 completed (loss: 0.031364526599645615, acc: 0.9909502267837524)
[2024-11-14 09:07:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:21][root][INFO] - Training Epoch: 2/2, step 4914/16670 completed (loss: 0.07179834693670273, acc: 0.9814814925193787)
[2024-11-14 09:07:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:21][root][INFO] - Training Epoch: 2/2, step 4915/16670 completed (loss: 0.12454339116811752, acc: 0.959854006767273)
[2024-11-14 09:07:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:22][root][INFO] - Training Epoch: 2/2, step 4916/16670 completed (loss: 0.1116945743560791, acc: 0.9763033390045166)
[2024-11-14 09:07:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:22][root][INFO] - Training Epoch: 2/2, step 4917/16670 completed (loss: 0.44370409846305847, acc: 0.9047619104385376)
[2024-11-14 09:07:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:22][root][INFO] - Training Epoch: 2/2, step 4918/16670 completed (loss: 0.024854343384504318, acc: 0.9944751262664795)
[2024-11-14 09:07:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:23][root][INFO] - Training Epoch: 2/2, step 4919/16670 completed (loss: 0.09572936594486237, acc: 0.9665551781654358)
[2024-11-14 09:07:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:23][root][INFO] - Training Epoch: 2/2, step 4920/16670 completed (loss: 0.12740814685821533, acc: 0.9713261723518372)
[2024-11-14 09:07:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:23][root][INFO] - Training Epoch: 2/2, step 4921/16670 completed (loss: 0.054100845009088516, acc: 0.9839141964912415)
[2024-11-14 09:07:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:24][root][INFO] - Training Epoch: 2/2, step 4922/16670 completed (loss: 0.288019061088562, acc: 0.9527027010917664)
[2024-11-14 09:07:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:24][root][INFO] - Training Epoch: 2/2, step 4923/16670 completed (loss: 0.10649574548006058, acc: 0.973607063293457)
[2024-11-14 09:07:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:24][root][INFO] - Training Epoch: 2/2, step 4924/16670 completed (loss: 0.24052223563194275, acc: 0.936274528503418)
[2024-11-14 09:07:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:25][root][INFO] - Training Epoch: 2/2, step 4925/16670 completed (loss: 0.0289311446249485, acc: 0.9935897588729858)
[2024-11-14 09:07:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:25][root][INFO] - Training Epoch: 2/2, step 4926/16670 completed (loss: 0.0707913190126419, acc: 0.9738805890083313)
[2024-11-14 09:07:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:26][root][INFO] - Training Epoch: 2/2, step 4927/16670 completed (loss: 0.046038780361413956, acc: 0.9883720874786377)
[2024-11-14 09:07:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:26][root][INFO] - Training Epoch: 2/2, step 4928/16670 completed (loss: 0.05848360434174538, acc: 0.9843137264251709)
[2024-11-14 09:07:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:26][root][INFO] - Training Epoch: 2/2, step 4929/16670 completed (loss: 0.08660513907670975, acc: 0.9791666865348816)
[2024-11-14 09:07:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:27][root][INFO] - Training Epoch: 2/2, step 4930/16670 completed (loss: 0.06970653682947159, acc: 0.9874476790428162)
[2024-11-14 09:07:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:27][root][INFO] - Training Epoch: 2/2, step 4931/16670 completed (loss: 0.11919918656349182, acc: 0.9696969985961914)
[2024-11-14 09:07:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:27][root][INFO] - Training Epoch: 2/2, step 4932/16670 completed (loss: 0.04464526101946831, acc: 0.9852398633956909)
[2024-11-14 09:07:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:28][root][INFO] - Training Epoch: 2/2, step 4933/16670 completed (loss: 0.09923204034566879, acc: 0.9746192693710327)
[2024-11-14 09:07:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:28][root][INFO] - Training Epoch: 2/2, step 4934/16670 completed (loss: 0.08820176869630814, acc: 0.9872881174087524)
[2024-11-14 09:07:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:29][root][INFO] - Training Epoch: 2/2, step 4935/16670 completed (loss: 0.0576321966946125, acc: 0.9780701994895935)
[2024-11-14 09:07:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:29][root][INFO] - Training Epoch: 2/2, step 4936/16670 completed (loss: 0.22074031829833984, acc: 0.949999988079071)
[2024-11-14 09:07:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:29][root][INFO] - Training Epoch: 2/2, step 4937/16670 completed (loss: 0.21594424545764923, acc: 0.9365079402923584)
[2024-11-14 09:07:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:30][root][INFO] - Training Epoch: 2/2, step 4938/16670 completed (loss: 0.25502464175224304, acc: 0.9298245906829834)
[2024-11-14 09:07:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:30][root][INFO] - Training Epoch: 2/2, step 4939/16670 completed (loss: 0.3875735104084015, acc: 0.9189189076423645)
[2024-11-14 09:07:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:30][root][INFO] - Training Epoch: 2/2, step 4940/16670 completed (loss: 0.07237868010997772, acc: 1.0)
[2024-11-14 09:07:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:31][root][INFO] - Training Epoch: 2/2, step 4941/16670 completed (loss: 0.20328252017498016, acc: 0.9347826242446899)
[2024-11-14 09:07:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:31][root][INFO] - Training Epoch: 2/2, step 4942/16670 completed (loss: 0.3349466621875763, acc: 0.9215686321258545)
[2024-11-14 09:07:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:32][root][INFO] - Training Epoch: 2/2, step 4943/16670 completed (loss: 0.23792311549186707, acc: 0.9589040875434875)
[2024-11-14 09:07:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:32][root][INFO] - Training Epoch: 2/2, step 4944/16670 completed (loss: 0.31505128741264343, acc: 0.9264705777168274)
[2024-11-14 09:07:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:32][root][INFO] - Training Epoch: 2/2, step 4945/16670 completed (loss: 0.237931028008461, acc: 0.9599999785423279)
[2024-11-14 09:07:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:33][root][INFO] - Training Epoch: 2/2, step 4946/16670 completed (loss: 0.0682588666677475, acc: 0.9841269850730896)
[2024-11-14 09:07:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:33][root][INFO] - Training Epoch: 2/2, step 4947/16670 completed (loss: 0.19876708090305328, acc: 0.9714285731315613)
[2024-11-14 09:07:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:33][root][INFO] - Training Epoch: 2/2, step 4948/16670 completed (loss: 0.16482070088386536, acc: 0.976190447807312)
[2024-11-14 09:07:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:34][root][INFO] - Training Epoch: 2/2, step 4949/16670 completed (loss: 0.14756545424461365, acc: 0.9516128897666931)
[2024-11-14 09:07:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:34][root][INFO] - Training Epoch: 2/2, step 4950/16670 completed (loss: 0.21602042019367218, acc: 0.9583333134651184)
[2024-11-14 09:07:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:34][root][INFO] - Training Epoch: 2/2, step 4951/16670 completed (loss: 0.3262038826942444, acc: 0.8627451062202454)
[2024-11-14 09:07:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:35][root][INFO] - Training Epoch: 2/2, step 4952/16670 completed (loss: 0.23634007573127747, acc: 0.9090909361839294)
[2024-11-14 09:07:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:35][root][INFO] - Training Epoch: 2/2, step 4953/16670 completed (loss: 0.40648189187049866, acc: 0.9406779408454895)
[2024-11-14 09:07:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:35][root][INFO] - Training Epoch: 2/2, step 4954/16670 completed (loss: 0.17574305832386017, acc: 0.931034505367279)
[2024-11-14 09:07:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:36][root][INFO] - Training Epoch: 2/2, step 4955/16670 completed (loss: 0.0653952807188034, acc: 0.9846153855323792)
[2024-11-14 09:07:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:36][root][INFO] - Training Epoch: 2/2, step 4956/16670 completed (loss: 0.427036315202713, acc: 0.9189189076423645)
[2024-11-14 09:07:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:36][root][INFO] - Training Epoch: 2/2, step 4957/16670 completed (loss: 0.175042986869812, acc: 0.96875)
[2024-11-14 09:07:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:37][root][INFO] - Training Epoch: 2/2, step 4958/16670 completed (loss: 0.15924248099327087, acc: 0.9512194991111755)
[2024-11-14 09:07:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:37][root][INFO] - Training Epoch: 2/2, step 4959/16670 completed (loss: 0.16886088252067566, acc: 0.9636363387107849)
[2024-11-14 09:07:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:37][root][INFO] - Training Epoch: 2/2, step 4960/16670 completed (loss: 0.3159016966819763, acc: 0.9333333373069763)
[2024-11-14 09:07:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:38][root][INFO] - Training Epoch: 2/2, step 4961/16670 completed (loss: 0.13880951702594757, acc: 0.9607843160629272)
[2024-11-14 09:07:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:38][root][INFO] - Training Epoch: 2/2, step 4962/16670 completed (loss: 0.19834502041339874, acc: 0.9402984976768494)
[2024-11-14 09:07:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:38][root][INFO] - Training Epoch: 2/2, step 4963/16670 completed (loss: 0.5279772877693176, acc: 0.868852436542511)
[2024-11-14 09:07:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:39][root][INFO] - Training Epoch: 2/2, step 4964/16670 completed (loss: 0.23749740421772003, acc: 0.9464285969734192)
[2024-11-14 09:07:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:39][root][INFO] - Training Epoch: 2/2, step 4965/16670 completed (loss: 0.3160041272640228, acc: 0.8983050584793091)
[2024-11-14 09:07:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:40][root][INFO] - Training Epoch: 2/2, step 4966/16670 completed (loss: 0.31156042218208313, acc: 0.9512194991111755)
[2024-11-14 09:07:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:40][root][INFO] - Training Epoch: 2/2, step 4967/16670 completed (loss: 0.13887827098369598, acc: 0.9605262875556946)
[2024-11-14 09:07:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:40][root][INFO] - Training Epoch: 2/2, step 4968/16670 completed (loss: 0.3708941638469696, acc: 0.9344262480735779)
[2024-11-14 09:07:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:41][root][INFO] - Training Epoch: 2/2, step 4969/16670 completed (loss: 0.4482521116733551, acc: 0.9322034120559692)
[2024-11-14 09:07:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:41][root][INFO] - Training Epoch: 2/2, step 4970/16670 completed (loss: 0.03825865685939789, acc: 1.0)
[2024-11-14 09:07:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:42][root][INFO] - Training Epoch: 2/2, step 4971/16670 completed (loss: 0.07274739444255829, acc: 0.9791666865348816)
[2024-11-14 09:07:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:42][root][INFO] - Training Epoch: 2/2, step 4972/16670 completed (loss: 0.26019635796546936, acc: 0.9074074029922485)
[2024-11-14 09:07:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:42][root][INFO] - Training Epoch: 2/2, step 4973/16670 completed (loss: 0.1007782369852066, acc: 0.9807692170143127)
[2024-11-14 09:07:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:43][root][INFO] - Training Epoch: 2/2, step 4974/16670 completed (loss: 0.1901765763759613, acc: 0.9701492786407471)
[2024-11-14 09:07:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:43][root][INFO] - Training Epoch: 2/2, step 4975/16670 completed (loss: 0.24044665694236755, acc: 0.9464285969734192)
[2024-11-14 09:07:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:43][root][INFO] - Training Epoch: 2/2, step 4976/16670 completed (loss: 0.023774174973368645, acc: 1.0)
[2024-11-14 09:07:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:44][root][INFO] - Training Epoch: 2/2, step 4977/16670 completed (loss: 0.4027368128299713, acc: 0.9411764740943909)
[2024-11-14 09:07:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:44][root][INFO] - Training Epoch: 2/2, step 4978/16670 completed (loss: 0.031308673322200775, acc: 1.0)
[2024-11-14 09:07:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:44][root][INFO] - Training Epoch: 2/2, step 4979/16670 completed (loss: 0.19766239821910858, acc: 0.9838709831237793)
[2024-11-14 09:07:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:45][root][INFO] - Training Epoch: 2/2, step 4980/16670 completed (loss: 0.22252900898456573, acc: 0.9534883499145508)
[2024-11-14 09:07:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:45][root][INFO] - Training Epoch: 2/2, step 4981/16670 completed (loss: 0.05569920316338539, acc: 1.0)
[2024-11-14 09:07:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:46][root][INFO] - Training Epoch: 2/2, step 4982/16670 completed (loss: 0.12616650760173798, acc: 0.9545454382896423)
[2024-11-14 09:07:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:46][root][INFO] - Training Epoch: 2/2, step 4983/16670 completed (loss: 0.20551533997058868, acc: 0.9152542352676392)
[2024-11-14 09:07:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:46][root][INFO] - Training Epoch: 2/2, step 4984/16670 completed (loss: 0.03432367742061615, acc: 1.0)
[2024-11-14 09:07:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:47][root][INFO] - Training Epoch: 2/2, step 4985/16670 completed (loss: 0.6212121844291687, acc: 0.9200000166893005)
[2024-11-14 09:07:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:47][root][INFO] - Training Epoch: 2/2, step 4986/16670 completed (loss: 0.05474886670708656, acc: 1.0)
[2024-11-14 09:07:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:47][root][INFO] - Training Epoch: 2/2, step 4987/16670 completed (loss: 0.5220522284507751, acc: 0.9344262480735779)
[2024-11-14 09:07:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:48][root][INFO] - Training Epoch: 2/2, step 4988/16670 completed (loss: 0.48113173246383667, acc: 0.875)
[2024-11-14 09:07:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:48][root][INFO] - Training Epoch: 2/2, step 4989/16670 completed (loss: 0.2818986475467682, acc: 0.9285714030265808)
[2024-11-14 09:07:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:48][root][INFO] - Training Epoch: 2/2, step 4990/16670 completed (loss: 0.08736840635538101, acc: 0.978723406791687)
[2024-11-14 09:07:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:49][root][INFO] - Training Epoch: 2/2, step 4991/16670 completed (loss: 0.2269638031721115, acc: 0.9365079402923584)
[2024-11-14 09:07:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:49][root][INFO] - Training Epoch: 2/2, step 4992/16670 completed (loss: 0.20432884991168976, acc: 0.8985507488250732)
[2024-11-14 09:07:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:49][root][INFO] - Training Epoch: 2/2, step 4993/16670 completed (loss: 0.07972380518913269, acc: 0.9692307710647583)
[2024-11-14 09:07:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:50][root][INFO] - Training Epoch: 2/2, step 4994/16670 completed (loss: 0.2574908137321472, acc: 0.9245283007621765)
[2024-11-14 09:07:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:50][root][INFO] - Training Epoch: 2/2, step 4995/16670 completed (loss: 0.39214661717414856, acc: 0.9047619104385376)
[2024-11-14 09:07:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:50][root][INFO] - Training Epoch: 2/2, step 4996/16670 completed (loss: 0.3455891013145447, acc: 0.9130434989929199)
[2024-11-14 09:07:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:51][root][INFO] - Training Epoch: 2/2, step 4997/16670 completed (loss: 0.3086628317832947, acc: 0.9726027250289917)
[2024-11-14 09:07:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:51][root][INFO] - Training Epoch: 2/2, step 4998/16670 completed (loss: 0.16486604511737823, acc: 0.9756097793579102)
[2024-11-14 09:07:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:52][root][INFO] - Training Epoch: 2/2, step 4999/16670 completed (loss: 0.24737711250782013, acc: 0.9298245906829834)
[2024-11-14 09:07:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:52][root][INFO] - Training Epoch: 2/2, step 5000/16670 completed (loss: 0.1393681913614273, acc: 0.9444444179534912)
[2024-11-14 09:07:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:52][root][INFO] - Training Epoch: 2/2, step 5001/16670 completed (loss: 0.09466789662837982, acc: 0.9836065769195557)
[2024-11-14 09:07:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:53][root][INFO] - Training Epoch: 2/2, step 5002/16670 completed (loss: 0.11002399772405624, acc: 0.9714285731315613)
[2024-11-14 09:07:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:53][root][INFO] - Training Epoch: 2/2, step 5003/16670 completed (loss: 0.1529681533575058, acc: 0.9666666388511658)
[2024-11-14 09:07:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:53][root][INFO] - Training Epoch: 2/2, step 5004/16670 completed (loss: 0.34291398525238037, acc: 0.9402984976768494)
[2024-11-14 09:07:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:54][root][INFO] - Training Epoch: 2/2, step 5005/16670 completed (loss: 0.16192415356636047, acc: 0.9591836929321289)
[2024-11-14 09:07:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:54][root][INFO] - Training Epoch: 2/2, step 5006/16670 completed (loss: 0.3028882145881653, acc: 0.925000011920929)
[2024-11-14 09:07:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:55][root][INFO] - Training Epoch: 2/2, step 5007/16670 completed (loss: 0.35044199228286743, acc: 0.9210526347160339)
[2024-11-14 09:07:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:55][root][INFO] - Training Epoch: 2/2, step 5008/16670 completed (loss: 0.17292188107967377, acc: 0.9230769276618958)
[2024-11-14 09:07:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:55][root][INFO] - Training Epoch: 2/2, step 5009/16670 completed (loss: 0.16575585305690765, acc: 0.9855072498321533)
[2024-11-14 09:07:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:56][root][INFO] - Training Epoch: 2/2, step 5010/16670 completed (loss: 0.5357822775840759, acc: 0.9016393423080444)
[2024-11-14 09:07:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:56][root][INFO] - Training Epoch: 2/2, step 5011/16670 completed (loss: 0.2087666541337967, acc: 0.9285714030265808)
[2024-11-14 09:07:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:56][root][INFO] - Training Epoch: 2/2, step 5012/16670 completed (loss: 0.15439529716968536, acc: 0.9583333134651184)
[2024-11-14 09:07:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:57][root][INFO] - Training Epoch: 2/2, step 5013/16670 completed (loss: 0.22362378239631653, acc: 0.9387755393981934)
[2024-11-14 09:07:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:57][root][INFO] - Training Epoch: 2/2, step 5014/16670 completed (loss: 0.11600218713283539, acc: 0.9583333134651184)
[2024-11-14 09:07:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:57][root][INFO] - Training Epoch: 2/2, step 5015/16670 completed (loss: 0.25015532970428467, acc: 0.9661017060279846)
[2024-11-14 09:07:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:58][root][INFO] - Training Epoch: 2/2, step 5016/16670 completed (loss: 0.4334026277065277, acc: 0.9375)
[2024-11-14 09:07:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:58][root][INFO] - Training Epoch: 2/2, step 5017/16670 completed (loss: 0.06157878041267395, acc: 1.0)
[2024-11-14 09:07:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:58][root][INFO] - Training Epoch: 2/2, step 5018/16670 completed (loss: 0.08563362061977386, acc: 0.9824561476707458)
[2024-11-14 09:07:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:59][root][INFO] - Training Epoch: 2/2, step 5019/16670 completed (loss: 0.0922536626458168, acc: 0.9803921580314636)
[2024-11-14 09:07:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:07:59][root][INFO] - Training Epoch: 2/2, step 5020/16670 completed (loss: 0.07523589581251144, acc: 1.0)
[2024-11-14 09:07:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:00][root][INFO] - Training Epoch: 2/2, step 5021/16670 completed (loss: 0.05729367583990097, acc: 1.0)
[2024-11-14 09:08:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:00][root][INFO] - Training Epoch: 2/2, step 5022/16670 completed (loss: 0.11176396161317825, acc: 0.9821428656578064)
[2024-11-14 09:08:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:00][root][INFO] - Training Epoch: 2/2, step 5023/16670 completed (loss: 0.0662609338760376, acc: 0.9746835231781006)
[2024-11-14 09:08:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:00][root][INFO] - Training Epoch: 2/2, step 5024/16670 completed (loss: 0.06767818331718445, acc: 1.0)
[2024-11-14 09:08:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:01][root][INFO] - Training Epoch: 2/2, step 5025/16670 completed (loss: 0.4023381471633911, acc: 0.9245283007621765)
[2024-11-14 09:08:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:01][root][INFO] - Training Epoch: 2/2, step 5026/16670 completed (loss: 0.0974297970533371, acc: 0.9726027250289917)
[2024-11-14 09:08:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:01][root][INFO] - Training Epoch: 2/2, step 5027/16670 completed (loss: 0.08851657062768936, acc: 0.9692307710647583)
[2024-11-14 09:08:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:02][root][INFO] - Training Epoch: 2/2, step 5028/16670 completed (loss: 0.3675212562084198, acc: 0.9090909361839294)
[2024-11-14 09:08:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:02][root][INFO] - Training Epoch: 2/2, step 5029/16670 completed (loss: 0.028507037088274956, acc: 1.0)
[2024-11-14 09:08:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:02][root][INFO] - Training Epoch: 2/2, step 5030/16670 completed (loss: 0.12794795632362366, acc: 0.9666666388511658)
[2024-11-14 09:08:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:03][root][INFO] - Training Epoch: 2/2, step 5031/16670 completed (loss: 0.050558071583509445, acc: 1.0)
[2024-11-14 09:08:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:03][root][INFO] - Training Epoch: 2/2, step 5032/16670 completed (loss: 0.16920562088489532, acc: 0.9333333373069763)
[2024-11-14 09:08:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:04][root][INFO] - Training Epoch: 2/2, step 5033/16670 completed (loss: 0.18443377315998077, acc: 0.9433962106704712)
[2024-11-14 09:08:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:04][root][INFO] - Training Epoch: 2/2, step 5034/16670 completed (loss: 0.1077510342001915, acc: 0.9841269850730896)
[2024-11-14 09:08:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:04][root][INFO] - Training Epoch: 2/2, step 5035/16670 completed (loss: 0.3272223174571991, acc: 0.930232584476471)
[2024-11-14 09:08:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:05][root][INFO] - Training Epoch: 2/2, step 5036/16670 completed (loss: 0.1139114499092102, acc: 0.9491525292396545)
[2024-11-14 09:08:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:05][root][INFO] - Training Epoch: 2/2, step 5037/16670 completed (loss: 0.12961889803409576, acc: 0.9636363387107849)
[2024-11-14 09:08:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:05][root][INFO] - Training Epoch: 2/2, step 5038/16670 completed (loss: 0.050153106451034546, acc: 1.0)
[2024-11-14 09:08:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:06][root][INFO] - Training Epoch: 2/2, step 5039/16670 completed (loss: 0.2228536307811737, acc: 0.9642857313156128)
[2024-11-14 09:08:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:06][root][INFO] - Training Epoch: 2/2, step 5040/16670 completed (loss: 0.0381818525493145, acc: 1.0)
[2024-11-14 09:08:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:06][root][INFO] - Training Epoch: 2/2, step 5041/16670 completed (loss: 0.027043435722589493, acc: 1.0)
[2024-11-14 09:08:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:07][root][INFO] - Training Epoch: 2/2, step 5042/16670 completed (loss: 0.12771722674369812, acc: 0.9750000238418579)
[2024-11-14 09:08:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:07][root][INFO] - Training Epoch: 2/2, step 5043/16670 completed (loss: 0.07289683818817139, acc: 0.9852941036224365)
[2024-11-14 09:08:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:07][root][INFO] - Training Epoch: 2/2, step 5044/16670 completed (loss: 0.49747180938720703, acc: 0.9264705777168274)
[2024-11-14 09:08:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:08][root][INFO] - Training Epoch: 2/2, step 5045/16670 completed (loss: 0.09715579450130463, acc: 0.9777777791023254)
[2024-11-14 09:08:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:08][root][INFO] - Training Epoch: 2/2, step 5046/16670 completed (loss: 0.11843331903219223, acc: 0.9696969985961914)
[2024-11-14 09:08:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:09][root][INFO] - Training Epoch: 2/2, step 5047/16670 completed (loss: 0.14921168982982635, acc: 0.9245283007621765)
[2024-11-14 09:08:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:09][root][INFO] - Training Epoch: 2/2, step 5048/16670 completed (loss: 0.28230708837509155, acc: 0.9076923131942749)
[2024-11-14 09:08:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:09][root][INFO] - Training Epoch: 2/2, step 5049/16670 completed (loss: 0.18718142807483673, acc: 0.9387755393981934)
[2024-11-14 09:08:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:09][root][INFO] - Training Epoch: 2/2, step 5050/16670 completed (loss: 0.4163428246974945, acc: 0.9166666865348816)
[2024-11-14 09:08:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:10][root][INFO] - Training Epoch: 2/2, step 5051/16670 completed (loss: 0.21954114735126495, acc: 0.9473684430122375)
[2024-11-14 09:08:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:10][root][INFO] - Training Epoch: 2/2, step 5052/16670 completed (loss: 0.20660100877285004, acc: 0.8809523582458496)
[2024-11-14 09:08:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:10][root][INFO] - Training Epoch: 2/2, step 5053/16670 completed (loss: 0.15479470789432526, acc: 0.9411764740943909)
[2024-11-14 09:08:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:11][root][INFO] - Training Epoch: 2/2, step 5054/16670 completed (loss: 0.23374658823013306, acc: 0.9444444179534912)
[2024-11-14 09:08:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:11][root][INFO] - Training Epoch: 2/2, step 5055/16670 completed (loss: 0.05660751089453697, acc: 0.9821428656578064)
[2024-11-14 09:08:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:11][root][INFO] - Training Epoch: 2/2, step 5056/16670 completed (loss: 0.03378841280937195, acc: 1.0)
[2024-11-14 09:08:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:12][root][INFO] - Training Epoch: 2/2, step 5057/16670 completed (loss: 0.2520029544830322, acc: 0.9285714030265808)
[2024-11-14 09:08:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:12][root][INFO] - Training Epoch: 2/2, step 5058/16670 completed (loss: 0.03338385000824928, acc: 1.0)
[2024-11-14 09:08:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:12][root][INFO] - Training Epoch: 2/2, step 5059/16670 completed (loss: 0.3352572023868561, acc: 0.8809523582458496)
[2024-11-14 09:08:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:13][root][INFO] - Training Epoch: 2/2, step 5060/16670 completed (loss: 0.3482307195663452, acc: 0.8823529481887817)
[2024-11-14 09:08:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:13][root][INFO] - Training Epoch: 2/2, step 5061/16670 completed (loss: 0.03504229336977005, acc: 1.0)
[2024-11-14 09:08:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:13][root][INFO] - Training Epoch: 2/2, step 5062/16670 completed (loss: 0.22406116127967834, acc: 0.9418604373931885)
[2024-11-14 09:08:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:14][root][INFO] - Training Epoch: 2/2, step 5063/16670 completed (loss: 0.18039438128471375, acc: 0.918367326259613)
[2024-11-14 09:08:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:14][root][INFO] - Training Epoch: 2/2, step 5064/16670 completed (loss: 0.07707478851079941, acc: 0.9836065769195557)
[2024-11-14 09:08:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:15][root][INFO] - Training Epoch: 2/2, step 5065/16670 completed (loss: 0.2597803473472595, acc: 0.942307710647583)
[2024-11-14 09:08:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:15][root][INFO] - Training Epoch: 2/2, step 5066/16670 completed (loss: 0.1756165474653244, acc: 0.9382715821266174)
[2024-11-14 09:08:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:15][root][INFO] - Training Epoch: 2/2, step 5067/16670 completed (loss: 0.5530237555503845, acc: 0.9193548560142517)
[2024-11-14 09:08:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:16][root][INFO] - Training Epoch: 2/2, step 5068/16670 completed (loss: 0.18687480688095093, acc: 0.9433962106704712)
[2024-11-14 09:08:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:16][root][INFO] - Training Epoch: 2/2, step 5069/16670 completed (loss: 0.1831630915403366, acc: 0.9285714030265808)
[2024-11-14 09:08:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:16][root][INFO] - Training Epoch: 2/2, step 5070/16670 completed (loss: 0.21354489028453827, acc: 0.9436619877815247)
[2024-11-14 09:08:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:17][root][INFO] - Training Epoch: 2/2, step 5071/16670 completed (loss: 0.3148598074913025, acc: 0.9014084339141846)
[2024-11-14 09:08:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:17][root][INFO] - Training Epoch: 2/2, step 5072/16670 completed (loss: 0.47173118591308594, acc: 0.9117646813392639)
[2024-11-14 09:08:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:18][root][INFO] - Training Epoch: 2/2, step 5073/16670 completed (loss: 0.49288544058799744, acc: 0.9411764740943909)
[2024-11-14 09:08:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:18][root][INFO] - Training Epoch: 2/2, step 5074/16670 completed (loss: 0.4795106053352356, acc: 0.9534883499145508)
[2024-11-14 09:08:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:18][root][INFO] - Training Epoch: 2/2, step 5075/16670 completed (loss: 0.1653912216424942, acc: 0.9074074029922485)
[2024-11-14 09:08:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:19][root][INFO] - Training Epoch: 2/2, step 5076/16670 completed (loss: 0.11423344165086746, acc: 0.9729729890823364)
[2024-11-14 09:08:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:19][root][INFO] - Training Epoch: 2/2, step 5077/16670 completed (loss: 0.039136335253715515, acc: 0.9885057210922241)
[2024-11-14 09:08:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:19][root][INFO] - Training Epoch: 2/2, step 5078/16670 completed (loss: 0.2621176540851593, acc: 0.9622641801834106)
[2024-11-14 09:08:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:20][root][INFO] - Training Epoch: 2/2, step 5079/16670 completed (loss: 0.029386717826128006, acc: 1.0)
[2024-11-14 09:08:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:20][root][INFO] - Training Epoch: 2/2, step 5080/16670 completed (loss: 0.16038574278354645, acc: 0.9538461565971375)
[2024-11-14 09:08:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:20][root][INFO] - Training Epoch: 2/2, step 5081/16670 completed (loss: 0.2463465929031372, acc: 0.9411764740943909)
[2024-11-14 09:08:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:21][root][INFO] - Training Epoch: 2/2, step 5082/16670 completed (loss: 0.24201171100139618, acc: 0.9411764740943909)
[2024-11-14 09:08:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:21][root][INFO] - Training Epoch: 2/2, step 5083/16670 completed (loss: 0.07863514125347137, acc: 1.0)
[2024-11-14 09:08:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:22][root][INFO] - Training Epoch: 2/2, step 5084/16670 completed (loss: 0.1688777208328247, acc: 0.9599999785423279)
[2024-11-14 09:08:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:22][root][INFO] - Training Epoch: 2/2, step 5085/16670 completed (loss: 0.6562384963035583, acc: 0.875)
[2024-11-14 09:08:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:22][root][INFO] - Training Epoch: 2/2, step 5086/16670 completed (loss: 0.42660456895828247, acc: 0.875)
[2024-11-14 09:08:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:23][root][INFO] - Training Epoch: 2/2, step 5087/16670 completed (loss: 0.055530622601509094, acc: 0.9807692170143127)
[2024-11-14 09:08:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:23][root][INFO] - Training Epoch: 2/2, step 5088/16670 completed (loss: 0.21584846079349518, acc: 0.9534883499145508)
[2024-11-14 09:08:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:23][root][INFO] - Training Epoch: 2/2, step 5089/16670 completed (loss: 0.29467394948005676, acc: 0.8852459192276001)
[2024-11-14 09:08:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:24][root][INFO] - Training Epoch: 2/2, step 5090/16670 completed (loss: 0.47370445728302, acc: 0.8260869383811951)
[2024-11-14 09:08:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:24][root][INFO] - Training Epoch: 2/2, step 5091/16670 completed (loss: 0.05540645122528076, acc: 1.0)
[2024-11-14 09:08:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:24][root][INFO] - Training Epoch: 2/2, step 5092/16670 completed (loss: 0.07389145344495773, acc: 1.0)
[2024-11-14 09:08:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:25][root][INFO] - Training Epoch: 2/2, step 5093/16670 completed (loss: 0.15773501992225647, acc: 0.982758641242981)
[2024-11-14 09:08:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:25][root][INFO] - Training Epoch: 2/2, step 5094/16670 completed (loss: 0.2903594970703125, acc: 0.9111111164093018)
[2024-11-14 09:08:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:26][root][INFO] - Training Epoch: 2/2, step 5095/16670 completed (loss: 0.026124674826860428, acc: 1.0)
[2024-11-14 09:08:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:26][root][INFO] - Training Epoch: 2/2, step 5096/16670 completed (loss: 0.08568120002746582, acc: 0.9850746393203735)
[2024-11-14 09:08:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:26][root][INFO] - Training Epoch: 2/2, step 5097/16670 completed (loss: 0.14646509289741516, acc: 0.939393937587738)
[2024-11-14 09:08:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:27][root][INFO] - Training Epoch: 2/2, step 5098/16670 completed (loss: 0.035074662417173386, acc: 1.0)
[2024-11-14 09:08:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:27][root][INFO] - Training Epoch: 2/2, step 5099/16670 completed (loss: 0.7233670353889465, acc: 0.8809523582458496)
[2024-11-14 09:08:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:27][root][INFO] - Training Epoch: 2/2, step 5100/16670 completed (loss: 0.20726360380649567, acc: 0.8799999952316284)
[2024-11-14 09:08:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:28][root][INFO] - Training Epoch: 2/2, step 5101/16670 completed (loss: 0.003924401942640543, acc: 1.0)
[2024-11-14 09:08:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:28][root][INFO] - Training Epoch: 2/2, step 5102/16670 completed (loss: 0.06635452806949615, acc: 0.9836065769195557)
[2024-11-14 09:08:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:28][root][INFO] - Training Epoch: 2/2, step 5103/16670 completed (loss: 0.11507616937160492, acc: 0.9696969985961914)
[2024-11-14 09:08:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:29][root][INFO] - Training Epoch: 2/2, step 5104/16670 completed (loss: 0.12703727185726166, acc: 0.9772727489471436)
[2024-11-14 09:08:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:29][root][INFO] - Training Epoch: 2/2, step 5105/16670 completed (loss: 0.008217948488891125, acc: 1.0)
[2024-11-14 09:08:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:30][root][INFO] - Training Epoch: 2/2, step 5106/16670 completed (loss: 0.02775081805884838, acc: 1.0)
[2024-11-14 09:08:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:30][root][INFO] - Training Epoch: 2/2, step 5107/16670 completed (loss: 0.21980802714824677, acc: 0.9428571462631226)
[2024-11-14 09:08:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:30][root][INFO] - Training Epoch: 2/2, step 5108/16670 completed (loss: 0.2974097728729248, acc: 0.9186046719551086)
[2024-11-14 09:08:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:31][root][INFO] - Training Epoch: 2/2, step 5109/16670 completed (loss: 0.1529388725757599, acc: 0.9777777791023254)
[2024-11-14 09:08:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:31][root][INFO] - Training Epoch: 2/2, step 5110/16670 completed (loss: 0.3621731400489807, acc: 0.970588207244873)
[2024-11-14 09:08:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:31][root][INFO] - Training Epoch: 2/2, step 5111/16670 completed (loss: 0.11864827573299408, acc: 0.976190447807312)
[2024-11-14 09:08:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:32][root][INFO] - Training Epoch: 2/2, step 5112/16670 completed (loss: 0.3896288275718689, acc: 0.9230769276618958)
[2024-11-14 09:08:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:32][root][INFO] - Training Epoch: 2/2, step 5113/16670 completed (loss: 0.05280919373035431, acc: 1.0)
[2024-11-14 09:08:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:32][root][INFO] - Training Epoch: 2/2, step 5114/16670 completed (loss: 0.458457350730896, acc: 0.8769230842590332)
[2024-11-14 09:08:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:33][root][INFO] - Training Epoch: 2/2, step 5115/16670 completed (loss: 0.1036534458398819, acc: 0.9764705896377563)
[2024-11-14 09:08:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:33][root][INFO] - Training Epoch: 2/2, step 5116/16670 completed (loss: 0.20629651844501495, acc: 0.9459459185600281)
[2024-11-14 09:08:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:33][root][INFO] - Training Epoch: 2/2, step 5117/16670 completed (loss: 0.23405194282531738, acc: 0.9166666865348816)
[2024-11-14 09:08:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:34][root][INFO] - Training Epoch: 2/2, step 5118/16670 completed (loss: 0.07163894176483154, acc: 0.9714285731315613)
[2024-11-14 09:08:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:34][root][INFO] - Training Epoch: 2/2, step 5119/16670 completed (loss: 0.12744154036045074, acc: 0.9629629850387573)
[2024-11-14 09:08:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:35][root][INFO] - Training Epoch: 2/2, step 5120/16670 completed (loss: 0.059815991669893265, acc: 1.0)
[2024-11-14 09:08:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:35][root][INFO] - Training Epoch: 2/2, step 5121/16670 completed (loss: 0.4664546251296997, acc: 0.8837209343910217)
[2024-11-14 09:08:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:35][root][INFO] - Training Epoch: 2/2, step 5122/16670 completed (loss: 0.2112433761358261, acc: 0.920634925365448)
[2024-11-14 09:08:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:35][root][INFO] - Training Epoch: 2/2, step 5123/16670 completed (loss: 0.2224888950586319, acc: 0.9615384340286255)
[2024-11-14 09:08:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:36][root][INFO] - Training Epoch: 2/2, step 5124/16670 completed (loss: 0.05231421813368797, acc: 1.0)
[2024-11-14 09:08:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:36][root][INFO] - Training Epoch: 2/2, step 5125/16670 completed (loss: 0.2908881902694702, acc: 0.9318181872367859)
[2024-11-14 09:08:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:37][root][INFO] - Training Epoch: 2/2, step 5126/16670 completed (loss: 0.4432901442050934, acc: 0.9178082346916199)
[2024-11-14 09:08:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:37][root][INFO] - Training Epoch: 2/2, step 5127/16670 completed (loss: 0.37481629848480225, acc: 0.9298245906829834)
[2024-11-14 09:08:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:37][root][INFO] - Training Epoch: 2/2, step 5128/16670 completed (loss: 0.4052158296108246, acc: 0.9137930870056152)
[2024-11-14 09:08:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:38][root][INFO] - Training Epoch: 2/2, step 5129/16670 completed (loss: 0.24696597456932068, acc: 0.9425287246704102)
[2024-11-14 09:08:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:38][root][INFO] - Training Epoch: 2/2, step 5130/16670 completed (loss: 0.5703822374343872, acc: 0.837837815284729)
[2024-11-14 09:08:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:38][root][INFO] - Training Epoch: 2/2, step 5131/16670 completed (loss: 0.41741153597831726, acc: 0.8863636255264282)
[2024-11-14 09:08:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:39][root][INFO] - Training Epoch: 2/2, step 5132/16670 completed (loss: 0.36417537927627563, acc: 0.8805969953536987)
[2024-11-14 09:08:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:39][root][INFO] - Training Epoch: 2/2, step 5133/16670 completed (loss: 0.05103672295808792, acc: 0.9777777791023254)
[2024-11-14 09:08:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:39][root][INFO] - Training Epoch: 2/2, step 5134/16670 completed (loss: 0.13267718255519867, acc: 0.9814814925193787)
[2024-11-14 09:08:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:40][root][INFO] - Training Epoch: 2/2, step 5135/16670 completed (loss: 0.12783664464950562, acc: 0.982758641242981)
[2024-11-14 09:08:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:40][root][INFO] - Training Epoch: 2/2, step 5136/16670 completed (loss: 0.08160490542650223, acc: 0.9756097793579102)
[2024-11-14 09:08:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:40][root][INFO] - Training Epoch: 2/2, step 5137/16670 completed (loss: 0.16401535272598267, acc: 0.9444444179534912)
[2024-11-14 09:08:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:41][root][INFO] - Training Epoch: 2/2, step 5138/16670 completed (loss: 0.09705482423305511, acc: 0.9777777791023254)
[2024-11-14 09:08:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:41][root][INFO] - Training Epoch: 2/2, step 5139/16670 completed (loss: 0.18075773119926453, acc: 0.9615384340286255)
[2024-11-14 09:08:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:41][root][INFO] - Training Epoch: 2/2, step 5140/16670 completed (loss: 0.38479265570640564, acc: 0.8771929740905762)
[2024-11-14 09:08:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:42][root][INFO] - Training Epoch: 2/2, step 5141/16670 completed (loss: 0.28745004534721375, acc: 0.8846153616905212)
[2024-11-14 09:08:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:42][root][INFO] - Training Epoch: 2/2, step 5142/16670 completed (loss: 0.13365787267684937, acc: 0.9615384340286255)
[2024-11-14 09:08:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:42][root][INFO] - Training Epoch: 2/2, step 5143/16670 completed (loss: 0.09649933874607086, acc: 0.9800000190734863)
[2024-11-14 09:08:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:43][root][INFO] - Training Epoch: 2/2, step 5144/16670 completed (loss: 0.24885620176792145, acc: 0.9245283007621765)
[2024-11-14 09:08:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:43][root][INFO] - Training Epoch: 2/2, step 5145/16670 completed (loss: 0.3152138888835907, acc: 0.9558823704719543)
[2024-11-14 09:08:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:44][root][INFO] - Training Epoch: 2/2, step 5146/16670 completed (loss: 0.19977280497550964, acc: 0.9428571462631226)
[2024-11-14 09:08:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:44][root][INFO] - Training Epoch: 2/2, step 5147/16670 completed (loss: 0.25112608075141907, acc: 0.9538461565971375)
[2024-11-14 09:08:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:44][root][INFO] - Training Epoch: 2/2, step 5148/16670 completed (loss: 0.07508137077093124, acc: 0.970588207244873)
[2024-11-14 09:08:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:45][root][INFO] - Training Epoch: 2/2, step 5149/16670 completed (loss: 0.10332110524177551, acc: 0.978723406791687)
[2024-11-14 09:08:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:45][root][INFO] - Training Epoch: 2/2, step 5150/16670 completed (loss: 0.26589298248291016, acc: 0.978723406791687)
[2024-11-14 09:08:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:45][root][INFO] - Training Epoch: 2/2, step 5151/16670 completed (loss: 0.4698641300201416, acc: 0.9583333134651184)
[2024-11-14 09:08:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:46][root][INFO] - Training Epoch: 2/2, step 5152/16670 completed (loss: 0.2920863628387451, acc: 0.9137930870056152)
[2024-11-14 09:08:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:46][root][INFO] - Training Epoch: 2/2, step 5153/16670 completed (loss: 0.26936963200569153, acc: 0.89552241563797)
[2024-11-14 09:08:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:46][root][INFO] - Training Epoch: 2/2, step 5154/16670 completed (loss: 0.6319712996482849, acc: 0.930232584476471)
[2024-11-14 09:08:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:47][root][INFO] - Training Epoch: 2/2, step 5155/16670 completed (loss: 0.24768158793449402, acc: 0.9454545378684998)
[2024-11-14 09:08:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:47][root][INFO] - Training Epoch: 2/2, step 5156/16670 completed (loss: 0.34125009179115295, acc: 0.9512194991111755)
[2024-11-14 09:08:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:47][root][INFO] - Training Epoch: 2/2, step 5157/16670 completed (loss: 0.239247664809227, acc: 0.9454545378684998)
[2024-11-14 09:08:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:48][root][INFO] - Training Epoch: 2/2, step 5158/16670 completed (loss: 0.45613089203834534, acc: 0.8965517282485962)
[2024-11-14 09:08:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:48][root][INFO] - Training Epoch: 2/2, step 5159/16670 completed (loss: 0.39433667063713074, acc: 0.8765432238578796)
[2024-11-14 09:08:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:48][root][INFO] - Training Epoch: 2/2, step 5160/16670 completed (loss: 0.22730085253715515, acc: 0.9333333373069763)
[2024-11-14 09:08:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:49][root][INFO] - Training Epoch: 2/2, step 5161/16670 completed (loss: 0.20081114768981934, acc: 0.9487179517745972)
[2024-11-14 09:08:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:49][root][INFO] - Training Epoch: 2/2, step 5162/16670 completed (loss: 0.46950235962867737, acc: 0.9285714030265808)
[2024-11-14 09:08:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:49][root][INFO] - Training Epoch: 2/2, step 5163/16670 completed (loss: 0.1830909103155136, acc: 0.9666666388511658)
[2024-11-14 09:08:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:50][root][INFO] - Training Epoch: 2/2, step 5164/16670 completed (loss: 0.42807790637016296, acc: 0.8846153616905212)
[2024-11-14 09:08:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:50][root][INFO] - Training Epoch: 2/2, step 5165/16670 completed (loss: 0.5045948028564453, acc: 0.8169013857841492)
[2024-11-14 09:08:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:50][root][INFO] - Training Epoch: 2/2, step 5166/16670 completed (loss: 0.08605828136205673, acc: 0.9846153855323792)
[2024-11-14 09:08:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:51][root][INFO] - Training Epoch: 2/2, step 5167/16670 completed (loss: 0.13287603855133057, acc: 0.9655172228813171)
[2024-11-14 09:08:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:51][root][INFO] - Training Epoch: 2/2, step 5168/16670 completed (loss: 0.4618862271308899, acc: 0.9193548560142517)
[2024-11-14 09:08:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:51][root][INFO] - Training Epoch: 2/2, step 5169/16670 completed (loss: 0.47532182931900024, acc: 0.8510638475418091)
[2024-11-14 09:08:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:52][root][INFO] - Training Epoch: 2/2, step 5170/16670 completed (loss: 0.2536624073982239, acc: 0.8913043737411499)
[2024-11-14 09:08:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:52][root][INFO] - Training Epoch: 2/2, step 5171/16670 completed (loss: 0.2065151333808899, acc: 0.9253731369972229)
[2024-11-14 09:08:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:53][root][INFO] - Training Epoch: 2/2, step 5172/16670 completed (loss: 0.5073581337928772, acc: 0.8793103694915771)
[2024-11-14 09:08:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:53][root][INFO] - Training Epoch: 2/2, step 5173/16670 completed (loss: 0.26311051845550537, acc: 0.9545454382896423)
[2024-11-14 09:08:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:53][root][INFO] - Training Epoch: 2/2, step 5174/16670 completed (loss: 0.33930444717407227, acc: 0.9166666865348816)
[2024-11-14 09:08:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:54][root][INFO] - Training Epoch: 2/2, step 5175/16670 completed (loss: 0.3528493046760559, acc: 0.8611111044883728)
[2024-11-14 09:08:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:54][root][INFO] - Training Epoch: 2/2, step 5176/16670 completed (loss: 0.07097774744033813, acc: 0.976190447807312)
[2024-11-14 09:08:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:54][root][INFO] - Training Epoch: 2/2, step 5177/16670 completed (loss: 0.44480812549591064, acc: 0.8888888955116272)
[2024-11-14 09:08:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:55][root][INFO] - Training Epoch: 2/2, step 5178/16670 completed (loss: 0.19894585013389587, acc: 0.9318181872367859)
[2024-11-14 09:08:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:55][root][INFO] - Training Epoch: 2/2, step 5179/16670 completed (loss: 0.4393436312675476, acc: 0.9032257795333862)
[2024-11-14 09:08:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:55][root][INFO] - Training Epoch: 2/2, step 5180/16670 completed (loss: 0.32730817794799805, acc: 0.8840579986572266)
[2024-11-14 09:08:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:56][root][INFO] - Training Epoch: 2/2, step 5181/16670 completed (loss: 0.32143911719322205, acc: 0.9523809552192688)
[2024-11-14 09:08:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:56][root][INFO] - Training Epoch: 2/2, step 5182/16670 completed (loss: 0.9773935079574585, acc: 0.8799999952316284)
[2024-11-14 09:08:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:56][root][INFO] - Training Epoch: 2/2, step 5183/16670 completed (loss: 0.4895409643650055, acc: 0.8918918967247009)
[2024-11-14 09:08:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:57][root][INFO] - Training Epoch: 2/2, step 5184/16670 completed (loss: 0.5430073142051697, acc: 0.8918918967247009)
[2024-11-14 09:08:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:57][root][INFO] - Training Epoch: 2/2, step 5185/16670 completed (loss: 0.3292752206325531, acc: 0.875)
[2024-11-14 09:08:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:57][root][INFO] - Training Epoch: 2/2, step 5186/16670 completed (loss: 0.5323721170425415, acc: 0.8548387289047241)
[2024-11-14 09:08:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:58][root][INFO] - Training Epoch: 2/2, step 5187/16670 completed (loss: 0.24775472283363342, acc: 0.9193548560142517)
[2024-11-14 09:08:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:58][root][INFO] - Training Epoch: 2/2, step 5188/16670 completed (loss: 0.6762487888336182, acc: 0.84375)
[2024-11-14 09:08:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:58][root][INFO] - Training Epoch: 2/2, step 5189/16670 completed (loss: 0.3258107900619507, acc: 0.9253731369972229)
[2024-11-14 09:08:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:59][root][INFO] - Training Epoch: 2/2, step 5190/16670 completed (loss: 0.3485734462738037, acc: 0.9047619104385376)
[2024-11-14 09:08:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:08:59][root][INFO] - Training Epoch: 2/2, step 5191/16670 completed (loss: 0.38148173689842224, acc: 0.9166666865348816)
[2024-11-14 09:08:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:00][root][INFO] - Training Epoch: 2/2, step 5192/16670 completed (loss: 0.21324218809604645, acc: 0.9538461565971375)
[2024-11-14 09:09:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:00][root][INFO] - Training Epoch: 2/2, step 5193/16670 completed (loss: 0.18077489733695984, acc: 0.942307710647583)
[2024-11-14 09:09:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:00][root][INFO] - Training Epoch: 2/2, step 5194/16670 completed (loss: 0.4685690999031067, acc: 0.9069767594337463)
[2024-11-14 09:09:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:00][root][INFO] - Training Epoch: 2/2, step 5195/16670 completed (loss: 0.36151084303855896, acc: 0.9069767594337463)
[2024-11-14 09:09:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:01][root][INFO] - Training Epoch: 2/2, step 5196/16670 completed (loss: 0.14730557799339294, acc: 1.0)
[2024-11-14 09:09:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:01][root][INFO] - Training Epoch: 2/2, step 5197/16670 completed (loss: 0.43209055066108704, acc: 0.892307698726654)
[2024-11-14 09:09:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:02][root][INFO] - Training Epoch: 2/2, step 5198/16670 completed (loss: 0.6451826095581055, acc: 0.9069767594337463)
[2024-11-14 09:09:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:02][root][INFO] - Training Epoch: 2/2, step 5199/16670 completed (loss: 0.2923480272293091, acc: 0.9411764740943909)
[2024-11-14 09:09:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:02][root][INFO] - Training Epoch: 2/2, step 5200/16670 completed (loss: 0.5241634249687195, acc: 0.8947368264198303)
[2024-11-14 09:09:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:03][root][INFO] - Training Epoch: 2/2, step 5201/16670 completed (loss: 0.239939883351326, acc: 0.9428571462631226)
[2024-11-14 09:09:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:03][root][INFO] - Training Epoch: 2/2, step 5202/16670 completed (loss: 0.697664201259613, acc: 0.8863636255264282)
[2024-11-14 09:09:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:03][root][INFO] - Training Epoch: 2/2, step 5203/16670 completed (loss: 0.14034131169319153, acc: 0.9487179517745972)
[2024-11-14 09:09:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:04][root][INFO] - Training Epoch: 2/2, step 5204/16670 completed (loss: 0.11383384466171265, acc: 1.0)
[2024-11-14 09:09:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:04][root][INFO] - Training Epoch: 2/2, step 5205/16670 completed (loss: 0.2511211931705475, acc: 0.9365079402923584)
[2024-11-14 09:09:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:04][root][INFO] - Training Epoch: 2/2, step 5206/16670 completed (loss: 0.5569776296615601, acc: 0.9130434989929199)
[2024-11-14 09:09:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:05][root][INFO] - Training Epoch: 2/2, step 5207/16670 completed (loss: 0.32215288281440735, acc: 0.8867924809455872)
[2024-11-14 09:09:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:05][root][INFO] - Training Epoch: 2/2, step 5208/16670 completed (loss: 0.3416942059993744, acc: 0.9178082346916199)
[2024-11-14 09:09:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:05][root][INFO] - Training Epoch: 2/2, step 5209/16670 completed (loss: 0.2919713854789734, acc: 0.9636363387107849)
[2024-11-14 09:09:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:06][root][INFO] - Training Epoch: 2/2, step 5210/16670 completed (loss: 0.5804605484008789, acc: 0.8571428656578064)
[2024-11-14 09:09:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:06][root][INFO] - Training Epoch: 2/2, step 5211/16670 completed (loss: 0.13091622292995453, acc: 0.9821428656578064)
[2024-11-14 09:09:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:06][root][INFO] - Training Epoch: 2/2, step 5212/16670 completed (loss: 0.24315224587917328, acc: 0.9210526347160339)
[2024-11-14 09:09:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:07][root][INFO] - Training Epoch: 2/2, step 5213/16670 completed (loss: 0.3376728296279907, acc: 0.8703703880310059)
[2024-11-14 09:09:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:07][root][INFO] - Training Epoch: 2/2, step 5214/16670 completed (loss: 0.03810678422451019, acc: 1.0)
[2024-11-14 09:09:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:07][root][INFO] - Training Epoch: 2/2, step 5215/16670 completed (loss: 0.1344950646162033, acc: 1.0)
[2024-11-14 09:09:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:08][root][INFO] - Training Epoch: 2/2, step 5216/16670 completed (loss: 0.11549480259418488, acc: 0.957446813583374)
[2024-11-14 09:09:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:08][root][INFO] - Training Epoch: 2/2, step 5217/16670 completed (loss: 0.3752717077732086, acc: 0.9041095972061157)
[2024-11-14 09:09:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:08][root][INFO] - Training Epoch: 2/2, step 5218/16670 completed (loss: 0.6159014701843262, acc: 0.7368420958518982)
[2024-11-14 09:09:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:09][root][INFO] - Training Epoch: 2/2, step 5219/16670 completed (loss: 0.2820828855037689, acc: 0.918367326259613)
[2024-11-14 09:09:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:09][root][INFO] - Training Epoch: 2/2, step 5220/16670 completed (loss: 0.34293171763420105, acc: 0.9230769276618958)
[2024-11-14 09:09:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:09][root][INFO] - Training Epoch: 2/2, step 5221/16670 completed (loss: 0.4242112934589386, acc: 0.8985507488250732)
[2024-11-14 09:09:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:10][root][INFO] - Training Epoch: 2/2, step 5222/16670 completed (loss: 0.10538379848003387, acc: 1.0)
[2024-11-14 09:09:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:10][root][INFO] - Training Epoch: 2/2, step 5223/16670 completed (loss: 0.14713679254055023, acc: 0.9487179517745972)
[2024-11-14 09:09:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:10][root][INFO] - Training Epoch: 2/2, step 5224/16670 completed (loss: 0.23974302411079407, acc: 0.9333333373069763)
[2024-11-14 09:09:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:11][root][INFO] - Training Epoch: 2/2, step 5225/16670 completed (loss: 0.14517270028591156, acc: 0.9583333134651184)
[2024-11-14 09:09:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:11][root][INFO] - Training Epoch: 2/2, step 5226/16670 completed (loss: 1.0007511377334595, acc: 0.7567567825317383)
[2024-11-14 09:09:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:11][root][INFO] - Training Epoch: 2/2, step 5227/16670 completed (loss: 0.3251769244670868, acc: 0.9347826242446899)
[2024-11-14 09:09:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:12][root][INFO] - Training Epoch: 2/2, step 5228/16670 completed (loss: 0.17271792888641357, acc: 0.9047619104385376)
[2024-11-14 09:09:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:12][root][INFO] - Training Epoch: 2/2, step 5229/16670 completed (loss: 0.26601704955101013, acc: 0.9285714030265808)
[2024-11-14 09:09:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:12][root][INFO] - Training Epoch: 2/2, step 5230/16670 completed (loss: 0.06799384951591492, acc: 0.9666666388511658)
[2024-11-14 09:09:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:13][root][INFO] - Training Epoch: 2/2, step 5231/16670 completed (loss: 0.42622390389442444, acc: 0.8961039185523987)
[2024-11-14 09:09:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:13][root][INFO] - Training Epoch: 2/2, step 5232/16670 completed (loss: 0.5152729153633118, acc: 0.8666666746139526)
[2024-11-14 09:09:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:14][root][INFO] - Training Epoch: 2/2, step 5233/16670 completed (loss: 0.11663857847452164, acc: 0.9777777791023254)
[2024-11-14 09:09:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:14][root][INFO] - Training Epoch: 2/2, step 5234/16670 completed (loss: 0.45931175351142883, acc: 0.875)
[2024-11-14 09:09:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:14][root][INFO] - Training Epoch: 2/2, step 5235/16670 completed (loss: 0.3028187155723572, acc: 0.8888888955116272)
[2024-11-14 09:09:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:15][root][INFO] - Training Epoch: 2/2, step 5236/16670 completed (loss: 0.24917812645435333, acc: 0.9428571462631226)
[2024-11-14 09:09:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:15][root][INFO] - Training Epoch: 2/2, step 5237/16670 completed (loss: 0.15198175609111786, acc: 0.978723406791687)
[2024-11-14 09:09:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:15][root][INFO] - Training Epoch: 2/2, step 5238/16670 completed (loss: 0.08878882229328156, acc: 1.0)
[2024-11-14 09:09:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:16][root][INFO] - Training Epoch: 2/2, step 5239/16670 completed (loss: 0.07589114457368851, acc: 0.957446813583374)
[2024-11-14 09:09:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:16][root][INFO] - Training Epoch: 2/2, step 5240/16670 completed (loss: 0.5330538153648376, acc: 0.8888888955116272)
[2024-11-14 09:09:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:16][root][INFO] - Training Epoch: 2/2, step 5241/16670 completed (loss: 0.13601219654083252, acc: 0.9714285731315613)
[2024-11-14 09:09:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:17][root][INFO] - Training Epoch: 2/2, step 5242/16670 completed (loss: 0.18313126266002655, acc: 0.9090909361839294)
[2024-11-14 09:09:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:17][root][INFO] - Training Epoch: 2/2, step 5243/16670 completed (loss: 0.301203191280365, acc: 0.9354838728904724)
[2024-11-14 09:09:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:17][root][INFO] - Training Epoch: 2/2, step 5244/16670 completed (loss: 0.6321131587028503, acc: 0.9117646813392639)
[2024-11-14 09:09:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:18][root][INFO] - Training Epoch: 2/2, step 5245/16670 completed (loss: 0.1907329559326172, acc: 0.9375)
[2024-11-14 09:09:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:18][root][INFO] - Training Epoch: 2/2, step 5246/16670 completed (loss: 0.03830990567803383, acc: 1.0)
[2024-11-14 09:09:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:18][root][INFO] - Training Epoch: 2/2, step 5247/16670 completed (loss: 0.3392433226108551, acc: 0.8999999761581421)
[2024-11-14 09:09:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:19][root][INFO] - Training Epoch: 2/2, step 5248/16670 completed (loss: 0.15499092638492584, acc: 0.9230769276618958)
[2024-11-14 09:09:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:19][root][INFO] - Training Epoch: 2/2, step 5249/16670 completed (loss: 0.36052408814430237, acc: 0.8571428656578064)
[2024-11-14 09:09:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:19][root][INFO] - Training Epoch: 2/2, step 5250/16670 completed (loss: 0.31026798486709595, acc: 0.9137930870056152)
[2024-11-14 09:09:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:20][root][INFO] - Training Epoch: 2/2, step 5251/16670 completed (loss: 0.10638196766376495, acc: 0.9534883499145508)
[2024-11-14 09:09:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:20][root][INFO] - Training Epoch: 2/2, step 5252/16670 completed (loss: 0.16868902742862701, acc: 0.9615384340286255)
[2024-11-14 09:09:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:20][root][INFO] - Training Epoch: 2/2, step 5253/16670 completed (loss: 0.45836272835731506, acc: 0.9333333373069763)
[2024-11-14 09:09:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:21][root][INFO] - Training Epoch: 2/2, step 5254/16670 completed (loss: 0.6337922811508179, acc: 0.8799999952316284)
[2024-11-14 09:09:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:21][root][INFO] - Training Epoch: 2/2, step 5255/16670 completed (loss: 0.04558033123612404, acc: 1.0)
[2024-11-14 09:09:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:21][root][INFO] - Training Epoch: 2/2, step 5256/16670 completed (loss: 0.28199607133865356, acc: 0.9411764740943909)
[2024-11-14 09:09:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:22][root][INFO] - Training Epoch: 2/2, step 5257/16670 completed (loss: 0.2465258538722992, acc: 0.9285714030265808)
[2024-11-14 09:09:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:22][root][INFO] - Training Epoch: 2/2, step 5258/16670 completed (loss: 0.1618763655424118, acc: 0.9615384340286255)
[2024-11-14 09:09:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:23][root][INFO] - Training Epoch: 2/2, step 5259/16670 completed (loss: 0.39358633756637573, acc: 0.9272727370262146)
[2024-11-14 09:09:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:23][root][INFO] - Training Epoch: 2/2, step 5260/16670 completed (loss: 0.3235872983932495, acc: 0.8947368264198303)
[2024-11-14 09:09:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:23][root][INFO] - Training Epoch: 2/2, step 5261/16670 completed (loss: 0.6767480373382568, acc: 0.84375)
[2024-11-14 09:09:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:24][root][INFO] - Training Epoch: 2/2, step 5262/16670 completed (loss: 0.8151206374168396, acc: 0.8644067645072937)
[2024-11-14 09:09:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:24][root][INFO] - Training Epoch: 2/2, step 5263/16670 completed (loss: 0.23649811744689941, acc: 0.9387755393981934)
[2024-11-14 09:09:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:24][root][INFO] - Training Epoch: 2/2, step 5264/16670 completed (loss: 0.30798476934432983, acc: 0.9047619104385376)
[2024-11-14 09:09:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:25][root][INFO] - Training Epoch: 2/2, step 5265/16670 completed (loss: 0.1620597243309021, acc: 0.9677419066429138)
[2024-11-14 09:09:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:25][root][INFO] - Training Epoch: 2/2, step 5266/16670 completed (loss: 0.3254654109477997, acc: 0.9433962106704712)
[2024-11-14 09:09:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:25][root][INFO] - Training Epoch: 2/2, step 5267/16670 completed (loss: 0.16557426750659943, acc: 0.9387755393981934)
[2024-11-14 09:09:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:26][root][INFO] - Training Epoch: 2/2, step 5268/16670 completed (loss: 0.10963527113199234, acc: 0.9722222089767456)
[2024-11-14 09:09:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:26][root][INFO] - Training Epoch: 2/2, step 5269/16670 completed (loss: 0.15379953384399414, acc: 0.9384615421295166)
[2024-11-14 09:09:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:26][root][INFO] - Training Epoch: 2/2, step 5270/16670 completed (loss: 0.6142076253890991, acc: 0.8269230723381042)
[2024-11-14 09:09:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:27][root][INFO] - Training Epoch: 2/2, step 5271/16670 completed (loss: 0.49772340059280396, acc: 0.9130434989929199)
[2024-11-14 09:09:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:27][root][INFO] - Training Epoch: 2/2, step 5272/16670 completed (loss: 0.049750033766031265, acc: 1.0)
[2024-11-14 09:09:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:28][root][INFO] - Training Epoch: 2/2, step 5273/16670 completed (loss: 0.07793087512254715, acc: 1.0)
[2024-11-14 09:09:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:28][root][INFO] - Training Epoch: 2/2, step 5274/16670 completed (loss: 0.21833868324756622, acc: 0.953125)
[2024-11-14 09:09:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:28][root][INFO] - Training Epoch: 2/2, step 5275/16670 completed (loss: 0.1599624902009964, acc: 0.942307710647583)
[2024-11-14 09:09:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:29][root][INFO] - Training Epoch: 2/2, step 5276/16670 completed (loss: 0.6895779967308044, acc: 0.8571428656578064)
[2024-11-14 09:09:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:29][root][INFO] - Training Epoch: 2/2, step 5277/16670 completed (loss: 0.7548618316650391, acc: 0.828125)
[2024-11-14 09:09:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:29][root][INFO] - Training Epoch: 2/2, step 5278/16670 completed (loss: 0.2880150079727173, acc: 0.9384615421295166)
[2024-11-14 09:09:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:30][root][INFO] - Training Epoch: 2/2, step 5279/16670 completed (loss: 0.41231483221054077, acc: 0.9069767594337463)
[2024-11-14 09:09:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:30][root][INFO] - Training Epoch: 2/2, step 5280/16670 completed (loss: 0.0868060514330864, acc: 0.9743589758872986)
[2024-11-14 09:09:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:30][root][INFO] - Training Epoch: 2/2, step 5281/16670 completed (loss: 0.21182313561439514, acc: 0.9242424368858337)
[2024-11-14 09:09:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:31][root][INFO] - Training Epoch: 2/2, step 5282/16670 completed (loss: 0.1839350312948227, acc: 0.9333333373069763)
[2024-11-14 09:09:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:31][root][INFO] - Training Epoch: 2/2, step 5283/16670 completed (loss: 0.3269830048084259, acc: 0.9137930870056152)
[2024-11-14 09:09:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:31][root][INFO] - Training Epoch: 2/2, step 5284/16670 completed (loss: 0.639740526676178, acc: 0.8846153616905212)
[2024-11-14 09:09:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:32][root][INFO] - Training Epoch: 2/2, step 5285/16670 completed (loss: 0.11592400074005127, acc: 0.98591548204422)
[2024-11-14 09:09:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:32][root][INFO] - Training Epoch: 2/2, step 5286/16670 completed (loss: 0.18751150369644165, acc: 0.9677419066429138)
[2024-11-14 09:09:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:33][root][INFO] - Training Epoch: 2/2, step 5287/16670 completed (loss: 0.2759113609790802, acc: 0.9354838728904724)
[2024-11-14 09:09:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:33][root][INFO] - Training Epoch: 2/2, step 5288/16670 completed (loss: 0.42613133788108826, acc: 0.8507462739944458)
[2024-11-14 09:09:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:33][root][INFO] - Training Epoch: 2/2, step 5289/16670 completed (loss: 0.27755123376846313, acc: 0.8723404407501221)
[2024-11-14 09:09:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:34][root][INFO] - Training Epoch: 2/2, step 5290/16670 completed (loss: 0.1907765120267868, acc: 0.9230769276618958)
[2024-11-14 09:09:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:34][root][INFO] - Training Epoch: 2/2, step 5291/16670 completed (loss: 0.05920223519206047, acc: 1.0)
[2024-11-14 09:09:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:34][root][INFO] - Training Epoch: 2/2, step 5292/16670 completed (loss: 0.16634562611579895, acc: 0.9674267172813416)
[2024-11-14 09:09:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:35][root][INFO] - Training Epoch: 2/2, step 5293/16670 completed (loss: 0.039644092321395874, acc: 0.9809523820877075)
[2024-11-14 09:09:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:35][root][INFO] - Training Epoch: 2/2, step 5294/16670 completed (loss: 0.2166493982076645, acc: 0.936170220375061)
[2024-11-14 09:09:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:35][root][INFO] - Training Epoch: 2/2, step 5295/16670 completed (loss: 0.2278728038072586, acc: 0.9423868060112)
[2024-11-14 09:09:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:36][root][INFO] - Training Epoch: 2/2, step 5296/16670 completed (loss: 0.21307677030563354, acc: 0.9439252614974976)
[2024-11-14 09:09:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:36][root][INFO] - Training Epoch: 2/2, step 5297/16670 completed (loss: 0.23041792213916779, acc: 0.9340659379959106)
[2024-11-14 09:09:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:36][root][INFO] - Training Epoch: 2/2, step 5298/16670 completed (loss: 0.040366970002651215, acc: 1.0)
[2024-11-14 09:09:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:37][root][INFO] - Training Epoch: 2/2, step 5299/16670 completed (loss: 0.15841196477413177, acc: 0.9677419066429138)
[2024-11-14 09:09:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:37][root][INFO] - Training Epoch: 2/2, step 5300/16670 completed (loss: 0.23278117179870605, acc: 0.9360730648040771)
[2024-11-14 09:09:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:38][root][INFO] - Training Epoch: 2/2, step 5301/16670 completed (loss: 0.06872376799583435, acc: 0.9759036302566528)
[2024-11-14 09:09:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:38][root][INFO] - Training Epoch: 2/2, step 5302/16670 completed (loss: 0.10677766799926758, acc: 0.9680851101875305)
[2024-11-14 09:09:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:38][root][INFO] - Training Epoch: 2/2, step 5303/16670 completed (loss: 0.03478708490729332, acc: 0.9845361113548279)
[2024-11-14 09:09:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:39][root][INFO] - Training Epoch: 2/2, step 5304/16670 completed (loss: 0.18815161287784576, acc: 0.9556962251663208)
[2024-11-14 09:09:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:39][root][INFO] - Training Epoch: 2/2, step 5305/16670 completed (loss: 0.1746293008327484, acc: 0.9398906826972961)
[2024-11-14 09:09:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:40][root][INFO] - Training Epoch: 2/2, step 5306/16670 completed (loss: 0.253820538520813, acc: 0.9117646813392639)
[2024-11-14 09:09:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:40][root][INFO] - Training Epoch: 2/2, step 5307/16670 completed (loss: 0.38618579506874084, acc: 0.9047619104385376)
[2024-11-14 09:09:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:40][root][INFO] - Training Epoch: 2/2, step 5308/16670 completed (loss: 0.09584890305995941, acc: 0.9621848464012146)
[2024-11-14 09:09:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:41][root][INFO] - Training Epoch: 2/2, step 5309/16670 completed (loss: 0.2720943093299866, acc: 0.9308176040649414)
[2024-11-14 09:09:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:41][root][INFO] - Training Epoch: 2/2, step 5310/16670 completed (loss: 0.08659177273511887, acc: 0.9712460041046143)
[2024-11-14 09:09:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:41][root][INFO] - Training Epoch: 2/2, step 5311/16670 completed (loss: 0.08322930335998535, acc: 0.9774011373519897)
[2024-11-14 09:09:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:42][root][INFO] - Training Epoch: 2/2, step 5312/16670 completed (loss: 0.07341793924570084, acc: 0.982300877571106)
[2024-11-14 09:09:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:42][root][INFO] - Training Epoch: 2/2, step 5313/16670 completed (loss: 0.06707902252674103, acc: 0.9750000238418579)
[2024-11-14 09:09:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:42][root][INFO] - Training Epoch: 2/2, step 5314/16670 completed (loss: 0.20995374023914337, acc: 0.9414634108543396)
[2024-11-14 09:09:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:43][root][INFO] - Training Epoch: 2/2, step 5315/16670 completed (loss: 0.13025006651878357, acc: 0.9597315192222595)
[2024-11-14 09:09:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:43][root][INFO] - Training Epoch: 2/2, step 5316/16670 completed (loss: 0.04903452843427658, acc: 0.9904305934906006)
[2024-11-14 09:09:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:43][root][INFO] - Training Epoch: 2/2, step 5317/16670 completed (loss: 0.31160691380500793, acc: 0.927480936050415)
[2024-11-14 09:09:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:44][root][INFO] - Training Epoch: 2/2, step 5318/16670 completed (loss: 0.15589825809001923, acc: 0.9528796076774597)
[2024-11-14 09:09:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:44][root][INFO] - Training Epoch: 2/2, step 5319/16670 completed (loss: 0.16035838425159454, acc: 0.9589743614196777)
[2024-11-14 09:09:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:45][root][INFO] - Training Epoch: 2/2, step 5320/16670 completed (loss: 0.10307256877422333, acc: 0.9585798978805542)
[2024-11-14 09:09:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:45][root][INFO] - Training Epoch: 2/2, step 5321/16670 completed (loss: 0.19067025184631348, acc: 0.9322034120559692)
[2024-11-14 09:09:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:45][root][INFO] - Training Epoch: 2/2, step 5322/16670 completed (loss: 0.10795022547245026, acc: 0.9663865566253662)
[2024-11-14 09:09:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:46][root][INFO] - Training Epoch: 2/2, step 5323/16670 completed (loss: 0.1157088428735733, acc: 0.9671361446380615)
[2024-11-14 09:09:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:46][root][INFO] - Training Epoch: 2/2, step 5324/16670 completed (loss: 0.12853136658668518, acc: 0.949999988079071)
[2024-11-14 09:09:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:46][root][INFO] - Training Epoch: 2/2, step 5325/16670 completed (loss: 0.2725169062614441, acc: 0.9363057613372803)
[2024-11-14 09:09:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:47][root][INFO] - Training Epoch: 2/2, step 5326/16670 completed (loss: 0.17178712785243988, acc: 0.9547511339187622)
[2024-11-14 09:09:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:47][root][INFO] - Training Epoch: 2/2, step 5327/16670 completed (loss: 0.1174212321639061, acc: 0.9613259434700012)
[2024-11-14 09:09:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:48][root][INFO] - Training Epoch: 2/2, step 5328/16670 completed (loss: 0.18304136395454407, acc: 0.9444444179534912)
[2024-11-14 09:09:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:48][root][INFO] - Training Epoch: 2/2, step 5329/16670 completed (loss: 0.11027734726667404, acc: 0.9727891087532043)
[2024-11-14 09:09:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:48][root][INFO] - Training Epoch: 2/2, step 5330/16670 completed (loss: 0.22236239910125732, acc: 0.9470198750495911)
[2024-11-14 09:09:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:49][root][INFO] - Training Epoch: 2/2, step 5331/16670 completed (loss: 0.1842641830444336, acc: 0.9446640610694885)
[2024-11-14 09:09:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:49][root][INFO] - Training Epoch: 2/2, step 5332/16670 completed (loss: 0.1451205611228943, acc: 0.9610894918441772)
[2024-11-14 09:09:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:49][root][INFO] - Training Epoch: 2/2, step 5333/16670 completed (loss: 0.3257540464401245, acc: 0.9227941036224365)
[2024-11-14 09:09:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:50][root][INFO] - Training Epoch: 2/2, step 5334/16670 completed (loss: 0.1647990196943283, acc: 0.963302731513977)
[2024-11-14 09:09:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:50][root][INFO] - Training Epoch: 2/2, step 5335/16670 completed (loss: 0.2108680009841919, acc: 0.960698664188385)
[2024-11-14 09:09:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:50][root][INFO] - Training Epoch: 2/2, step 5336/16670 completed (loss: 0.28248298168182373, acc: 0.932584285736084)
[2024-11-14 09:09:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:51][root][INFO] - Training Epoch: 2/2, step 5337/16670 completed (loss: 0.17921142280101776, acc: 0.9470198750495911)
[2024-11-14 09:09:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:51][root][INFO] - Training Epoch: 2/2, step 5338/16670 completed (loss: 0.13061325252056122, acc: 0.9506726264953613)
[2024-11-14 09:09:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:51][root][INFO] - Training Epoch: 2/2, step 5339/16670 completed (loss: 0.053251639008522034, acc: 0.9885057210922241)
[2024-11-14 09:09:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:52][root][INFO] - Training Epoch: 2/2, step 5340/16670 completed (loss: 0.14478133618831635, acc: 0.9599999785423279)
[2024-11-14 09:09:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:52][root][INFO] - Training Epoch: 2/2, step 5341/16670 completed (loss: 0.2184525728225708, acc: 0.9312169551849365)
[2024-11-14 09:09:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:52][root][INFO] - Training Epoch: 2/2, step 5342/16670 completed (loss: 0.06915276497602463, acc: 0.9758453965187073)
[2024-11-14 09:09:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:53][root][INFO] - Training Epoch: 2/2, step 5343/16670 completed (loss: 0.19773711264133453, acc: 0.9526627063751221)
[2024-11-14 09:09:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:53][root][INFO] - Training Epoch: 2/2, step 5344/16670 completed (loss: 0.1211501806974411, acc: 0.9707602262496948)
[2024-11-14 09:09:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:53][root][INFO] - Training Epoch: 2/2, step 5345/16670 completed (loss: 0.10241535305976868, acc: 0.9677419066429138)
[2024-11-14 09:09:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:54][root][INFO] - Training Epoch: 2/2, step 5346/16670 completed (loss: 0.09998980164527893, acc: 0.9694656729698181)
[2024-11-14 09:09:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:54][root][INFO] - Training Epoch: 2/2, step 5347/16670 completed (loss: 0.2140420824289322, acc: 0.9189189076423645)
[2024-11-14 09:09:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:54][root][INFO] - Training Epoch: 2/2, step 5348/16670 completed (loss: 0.1335809826850891, acc: 0.9590643048286438)
[2024-11-14 09:09:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:55][root][INFO] - Training Epoch: 2/2, step 5349/16670 completed (loss: 0.23435917496681213, acc: 0.9465240836143494)
[2024-11-14 09:09:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:55][root][INFO] - Training Epoch: 2/2, step 5350/16670 completed (loss: 0.10143180191516876, acc: 0.9711934328079224)
[2024-11-14 09:09:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:56][root][INFO] - Training Epoch: 2/2, step 5351/16670 completed (loss: 0.061317507177591324, acc: 0.9902912378311157)
[2024-11-14 09:09:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:56][root][INFO] - Training Epoch: 2/2, step 5352/16670 completed (loss: 0.051158253103494644, acc: 0.988095223903656)
[2024-11-14 09:09:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:56][root][INFO] - Training Epoch: 2/2, step 5353/16670 completed (loss: 0.2011798471212387, acc: 0.9359999895095825)
[2024-11-14 09:09:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:57][root][INFO] - Training Epoch: 2/2, step 5354/16670 completed (loss: 0.09578149765729904, acc: 0.96517413854599)
[2024-11-14 09:09:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:57][root][INFO] - Training Epoch: 2/2, step 5355/16670 completed (loss: 0.1396605372428894, acc: 0.9509803652763367)
[2024-11-14 09:09:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:57][root][INFO] - Training Epoch: 2/2, step 5356/16670 completed (loss: 0.07937832921743393, acc: 0.970588207244873)
[2024-11-14 09:09:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:58][root][INFO] - Training Epoch: 2/2, step 5357/16670 completed (loss: 0.12354826927185059, acc: 0.9622641801834106)
[2024-11-14 09:09:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:58][root][INFO] - Training Epoch: 2/2, step 5358/16670 completed (loss: 0.07141483575105667, acc: 0.9893617033958435)
[2024-11-14 09:09:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:58][root][INFO] - Training Epoch: 2/2, step 5359/16670 completed (loss: 0.26921364665031433, acc: 0.9300411343574524)
[2024-11-14 09:09:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:59][root][INFO] - Training Epoch: 2/2, step 5360/16670 completed (loss: 0.2184734046459198, acc: 0.9691358208656311)
[2024-11-14 09:09:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:59][root][INFO] - Training Epoch: 2/2, step 5361/16670 completed (loss: 0.26799872517585754, acc: 0.935251772403717)
[2024-11-14 09:09:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:09:59][root][INFO] - Training Epoch: 2/2, step 5362/16670 completed (loss: 0.2060958743095398, acc: 0.9431818127632141)
[2024-11-14 09:09:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:00][root][INFO] - Training Epoch: 2/2, step 5363/16670 completed (loss: 0.08890928328037262, acc: 0.9906103014945984)
[2024-11-14 09:10:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:00][root][INFO] - Training Epoch: 2/2, step 5364/16670 completed (loss: 0.10987414419651031, acc: 0.9634146094322205)
[2024-11-14 09:10:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:00][root][INFO] - Training Epoch: 2/2, step 5365/16670 completed (loss: 0.1651892215013504, acc: 0.9643835425376892)
[2024-11-14 09:10:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:01][root][INFO] - Training Epoch: 2/2, step 5366/16670 completed (loss: 0.16952396929264069, acc: 0.9649805426597595)
[2024-11-14 09:10:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:01][root][INFO] - Training Epoch: 2/2, step 5367/16670 completed (loss: 0.08697815239429474, acc: 0.9746835231781006)
[2024-11-14 09:10:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:01][root][INFO] - Training Epoch: 2/2, step 5368/16670 completed (loss: 0.14169158041477203, acc: 0.9457831382751465)
[2024-11-14 09:10:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:02][root][INFO] - Training Epoch: 2/2, step 5369/16670 completed (loss: 0.023353872820734978, acc: 0.9917355179786682)
[2024-11-14 09:10:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:02][root][INFO] - Training Epoch: 2/2, step 5370/16670 completed (loss: 0.14961613714694977, acc: 0.9665071964263916)
[2024-11-14 09:10:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:03][root][INFO] - Training Epoch: 2/2, step 5371/16670 completed (loss: 0.1657286435365677, acc: 0.9459459185600281)
[2024-11-14 09:10:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:03][root][INFO] - Training Epoch: 2/2, step 5372/16670 completed (loss: 0.1782349944114685, acc: 0.970370352268219)
[2024-11-14 09:10:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:03][root][INFO] - Training Epoch: 2/2, step 5373/16670 completed (loss: 0.10157157480716705, acc: 0.9762611389160156)
[2024-11-14 09:10:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:04][root][INFO] - Training Epoch: 2/2, step 5374/16670 completed (loss: 0.086700938642025, acc: 0.97826087474823)
[2024-11-14 09:10:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:04][root][INFO] - Training Epoch: 2/2, step 5375/16670 completed (loss: 0.08936964720487595, acc: 0.984000027179718)
[2024-11-14 09:10:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:05][root][INFO] - Training Epoch: 2/2, step 5376/16670 completed (loss: 0.07181629538536072, acc: 0.9700374603271484)
[2024-11-14 09:10:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:05][root][INFO] - Training Epoch: 2/2, step 5377/16670 completed (loss: 0.1283450424671173, acc: 0.9545454382896423)
[2024-11-14 09:10:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:05][root][INFO] - Training Epoch: 2/2, step 5378/16670 completed (loss: 0.24330995976924896, acc: 0.9371980428695679)
[2024-11-14 09:10:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:06][root][INFO] - Training Epoch: 2/2, step 5379/16670 completed (loss: 0.049622055143117905, acc: 0.9693877696990967)
[2024-11-14 09:10:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:06][root][INFO] - Training Epoch: 2/2, step 5380/16670 completed (loss: 0.15994460880756378, acc: 0.9475409984588623)
[2024-11-14 09:10:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:06][root][INFO] - Training Epoch: 2/2, step 5381/16670 completed (loss: 0.08121833205223083, acc: 0.9871794581413269)
[2024-11-14 09:10:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:07][root][INFO] - Training Epoch: 2/2, step 5382/16670 completed (loss: 0.0684705451130867, acc: 0.9795918464660645)
[2024-11-14 09:10:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:07][root][INFO] - Training Epoch: 2/2, step 5383/16670 completed (loss: 0.12573570013046265, acc: 0.9601989984512329)
[2024-11-14 09:10:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:08][root][INFO] - Training Epoch: 2/2, step 5384/16670 completed (loss: 0.08934848755598068, acc: 0.9698113203048706)
[2024-11-14 09:10:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:08][root][INFO] - Training Epoch: 2/2, step 5385/16670 completed (loss: 0.13449786603450775, acc: 0.9534883499145508)
[2024-11-14 09:10:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:08][root][INFO] - Training Epoch: 2/2, step 5386/16670 completed (loss: 0.03736705332994461, acc: 0.9871794581413269)
[2024-11-14 09:10:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:09][root][INFO] - Training Epoch: 2/2, step 5387/16670 completed (loss: 0.11287782341241837, acc: 0.9702970385551453)
[2024-11-14 09:10:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:09][root][INFO] - Training Epoch: 2/2, step 5388/16670 completed (loss: 0.2632206678390503, acc: 0.942148745059967)
[2024-11-14 09:10:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:09][root][INFO] - Training Epoch: 2/2, step 5389/16670 completed (loss: 0.14058086276054382, acc: 0.9528619647026062)
[2024-11-14 09:10:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:10][root][INFO] - Training Epoch: 2/2, step 5390/16670 completed (loss: 0.18747298419475555, acc: 0.9544159770011902)
[2024-11-14 09:10:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:10][root][INFO] - Training Epoch: 2/2, step 5391/16670 completed (loss: 0.23610305786132812, acc: 0.9477611780166626)
[2024-11-14 09:10:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:10][root][INFO] - Training Epoch: 2/2, step 5392/16670 completed (loss: 0.12816593050956726, acc: 0.9561643600463867)
[2024-11-14 09:10:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:11][root][INFO] - Training Epoch: 2/2, step 5393/16670 completed (loss: 0.06077023223042488, acc: 0.9775280952453613)
[2024-11-14 09:10:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:11][root][INFO] - Training Epoch: 2/2, step 5394/16670 completed (loss: 0.10890594869852066, acc: 0.9646643400192261)
[2024-11-14 09:10:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:12][root][INFO] - Training Epoch: 2/2, step 5395/16670 completed (loss: 0.016140952706336975, acc: 1.0)
[2024-11-14 09:10:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:12][root][INFO] - Training Epoch: 2/2, step 5396/16670 completed (loss: 0.1701248586177826, acc: 0.95652174949646)
[2024-11-14 09:10:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:12][root][INFO] - Training Epoch: 2/2, step 5397/16670 completed (loss: 0.0941300094127655, acc: 0.9712643623352051)
[2024-11-14 09:10:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:13][root][INFO] - Training Epoch: 2/2, step 5398/16670 completed (loss: 0.18108077347278595, acc: 0.9508196711540222)
[2024-11-14 09:10:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:13][root][INFO] - Training Epoch: 2/2, step 5399/16670 completed (loss: 0.0914478749036789, acc: 0.9677419066429138)
[2024-11-14 09:10:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:13][root][INFO] - Training Epoch: 2/2, step 5400/16670 completed (loss: 0.03394278138875961, acc: 0.9916666746139526)
[2024-11-14 09:10:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:14][root][INFO] - Training Epoch: 2/2, step 5401/16670 completed (loss: 0.12665382027626038, acc: 0.9670782089233398)
[2024-11-14 09:10:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:14][root][INFO] - Training Epoch: 2/2, step 5402/16670 completed (loss: 0.06477665156126022, acc: 0.9781022071838379)
[2024-11-14 09:10:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:14][root][INFO] - Training Epoch: 2/2, step 5403/16670 completed (loss: 0.14749866724014282, acc: 0.9573863744735718)
[2024-11-14 09:10:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:15][root][INFO] - Training Epoch: 2/2, step 5404/16670 completed (loss: 0.1107422411441803, acc: 0.9670782089233398)
[2024-11-14 09:10:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:15][root][INFO] - Training Epoch: 2/2, step 5405/16670 completed (loss: 0.27731817960739136, acc: 0.9009901285171509)
[2024-11-14 09:10:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:16][root][INFO] - Training Epoch: 2/2, step 5406/16670 completed (loss: 0.047079578042030334, acc: 0.9822695255279541)
[2024-11-14 09:10:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:16][root][INFO] - Training Epoch: 2/2, step 5407/16670 completed (loss: 0.17253923416137695, acc: 0.9638242721557617)
[2024-11-14 09:10:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:16][root][INFO] - Training Epoch: 2/2, step 5408/16670 completed (loss: 0.11555251479148865, acc: 0.9751243591308594)
[2024-11-14 09:10:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:17][root][INFO] - Training Epoch: 2/2, step 5409/16670 completed (loss: 0.1436595916748047, acc: 0.9832776188850403)
[2024-11-14 09:10:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:17][root][INFO] - Training Epoch: 2/2, step 5410/16670 completed (loss: 0.13007768988609314, acc: 0.9710144996643066)
[2024-11-14 09:10:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:17][root][INFO] - Training Epoch: 2/2, step 5411/16670 completed (loss: 0.15662136673927307, acc: 0.9509202241897583)
[2024-11-14 09:10:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:18][root][INFO] - Training Epoch: 2/2, step 5412/16670 completed (loss: 0.24474170804023743, acc: 0.9316770434379578)
[2024-11-14 09:10:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:18][root][INFO] - Training Epoch: 2/2, step 5413/16670 completed (loss: 0.2531573474407196, acc: 0.9306930899620056)
[2024-11-14 09:10:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:19][root][INFO] - Training Epoch: 2/2, step 5414/16670 completed (loss: 0.13712777197360992, acc: 0.9680851101875305)
[2024-11-14 09:10:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:19][root][INFO] - Training Epoch: 2/2, step 5415/16670 completed (loss: 0.13271069526672363, acc: 0.9624060392379761)
[2024-11-14 09:10:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:19][root][INFO] - Training Epoch: 2/2, step 5416/16670 completed (loss: 0.05297870188951492, acc: 0.9809264540672302)
[2024-11-14 09:10:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:20][root][INFO] - Training Epoch: 2/2, step 5417/16670 completed (loss: 0.04588382691144943, acc: 0.9903846383094788)
[2024-11-14 09:10:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:20][root][INFO] - Training Epoch: 2/2, step 5418/16670 completed (loss: 0.1749584972858429, acc: 0.9448819160461426)
[2024-11-14 09:10:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:20][root][INFO] - Training Epoch: 2/2, step 5419/16670 completed (loss: 0.07738978415727615, acc: 0.9856459498405457)
[2024-11-14 09:10:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:21][root][INFO] - Training Epoch: 2/2, step 5420/16670 completed (loss: 0.07839783281087875, acc: 0.9739952683448792)
[2024-11-14 09:10:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:21][root][INFO] - Training Epoch: 2/2, step 5421/16670 completed (loss: 0.09914378076791763, acc: 0.96875)
[2024-11-14 09:10:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:21][root][INFO] - Training Epoch: 2/2, step 5422/16670 completed (loss: 0.07526512444019318, acc: 0.981249988079071)
[2024-11-14 09:10:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:22][root][INFO] - Training Epoch: 2/2, step 5423/16670 completed (loss: 0.09627849608659744, acc: 0.9768211841583252)
[2024-11-14 09:10:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:22][root][INFO] - Training Epoch: 2/2, step 5424/16670 completed (loss: 0.11837565898895264, acc: 0.9660193920135498)
[2024-11-14 09:10:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:22][root][INFO] - Training Epoch: 2/2, step 5425/16670 completed (loss: 0.15124846994876862, acc: 0.9578947424888611)
[2024-11-14 09:10:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:23][root][INFO] - Training Epoch: 2/2, step 5426/16670 completed (loss: 0.023029182106256485, acc: 0.9955947399139404)
[2024-11-14 09:10:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:23][root][INFO] - Training Epoch: 2/2, step 5427/16670 completed (loss: 0.10154146701097488, acc: 0.9796609878540039)
[2024-11-14 09:10:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:23][root][INFO] - Training Epoch: 2/2, step 5428/16670 completed (loss: 0.4337294399738312, acc: 0.8607594966888428)
[2024-11-14 09:10:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:24][root][INFO] - Training Epoch: 2/2, step 5429/16670 completed (loss: 0.08248808979988098, acc: 0.9726443886756897)
[2024-11-14 09:10:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:24][root][INFO] - Training Epoch: 2/2, step 5430/16670 completed (loss: 0.05858229100704193, acc: 0.9855072498321533)
[2024-11-14 09:10:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:25][root][INFO] - Training Epoch: 2/2, step 5431/16670 completed (loss: 0.1690962314605713, acc: 0.9636363387107849)
[2024-11-14 09:10:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:25][root][INFO] - Training Epoch: 2/2, step 5432/16670 completed (loss: 0.07265515625476837, acc: 0.9866666793823242)
[2024-11-14 09:10:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:25][root][INFO] - Training Epoch: 2/2, step 5433/16670 completed (loss: 0.10368507355451584, acc: 0.9659090638160706)
[2024-11-14 09:10:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:26][root][INFO] - Training Epoch: 2/2, step 5434/16670 completed (loss: 0.12475979328155518, acc: 0.9671361446380615)
[2024-11-14 09:10:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:26][root][INFO] - Training Epoch: 2/2, step 5435/16670 completed (loss: 0.10144191235303879, acc: 0.977477490901947)
[2024-11-14 09:10:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:26][root][INFO] - Training Epoch: 2/2, step 5436/16670 completed (loss: 0.12380699813365936, acc: 0.9518716335296631)
[2024-11-14 09:10:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:27][root][INFO] - Training Epoch: 2/2, step 5437/16670 completed (loss: 0.08440172672271729, acc: 0.9748201370239258)
[2024-11-14 09:10:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:27][root][INFO] - Training Epoch: 2/2, step 5438/16670 completed (loss: 0.09973927587270737, acc: 0.9664429426193237)
[2024-11-14 09:10:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:27][root][INFO] - Training Epoch: 2/2, step 5439/16670 completed (loss: 0.12154167890548706, acc: 0.9642857313156128)
[2024-11-14 09:10:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:28][root][INFO] - Training Epoch: 2/2, step 5440/16670 completed (loss: 0.13170477747917175, acc: 0.9604519605636597)
[2024-11-14 09:10:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:28][root][INFO] - Training Epoch: 2/2, step 5441/16670 completed (loss: 0.11963745951652527, acc: 0.9824561476707458)
[2024-11-14 09:10:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:29][root][INFO] - Training Epoch: 2/2, step 5442/16670 completed (loss: 0.07819655537605286, acc: 0.9770992398262024)
[2024-11-14 09:10:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:29][root][INFO] - Training Epoch: 2/2, step 5443/16670 completed (loss: 0.026994021609425545, acc: 0.9931972622871399)
[2024-11-14 09:10:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:29][root][INFO] - Training Epoch: 2/2, step 5444/16670 completed (loss: 0.14765410125255585, acc: 0.9623655676841736)
[2024-11-14 09:10:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:30][root][INFO] - Training Epoch: 2/2, step 5445/16670 completed (loss: 0.23448459804058075, acc: 0.9410112500190735)
[2024-11-14 09:10:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:30][root][INFO] - Training Epoch: 2/2, step 5446/16670 completed (loss: 0.08999386429786682, acc: 0.9763779640197754)
[2024-11-14 09:10:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:31][root][INFO] - Training Epoch: 2/2, step 5447/16670 completed (loss: 0.042392171919345856, acc: 0.9906976819038391)
[2024-11-14 09:10:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:31][root][INFO] - Training Epoch: 2/2, step 5448/16670 completed (loss: 0.1434144526720047, acc: 0.9658384919166565)
[2024-11-14 09:10:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:31][root][INFO] - Training Epoch: 2/2, step 5449/16670 completed (loss: 0.11977268755435944, acc: 0.9670782089233398)
[2024-11-14 09:10:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:31][root][INFO] - Training Epoch: 2/2, step 5450/16670 completed (loss: 0.11647876352071762, acc: 0.9523809552192688)
[2024-11-14 09:10:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:32][root][INFO] - Training Epoch: 2/2, step 5451/16670 completed (loss: 0.1948113590478897, acc: 0.9736841917037964)
[2024-11-14 09:10:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:32][root][INFO] - Training Epoch: 2/2, step 5452/16670 completed (loss: 0.062728151679039, acc: 0.9810426831245422)
[2024-11-14 09:10:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:32][root][INFO] - Training Epoch: 2/2, step 5453/16670 completed (loss: 0.209028422832489, acc: 0.9652777910232544)
[2024-11-14 09:10:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:33][root][INFO] - Training Epoch: 2/2, step 5454/16670 completed (loss: 0.094903863966465, acc: 0.967391312122345)
[2024-11-14 09:10:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:33][root][INFO] - Training Epoch: 2/2, step 5455/16670 completed (loss: 0.2691226601600647, acc: 0.9038461446762085)
[2024-11-14 09:10:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:33][root][INFO] - Training Epoch: 2/2, step 5456/16670 completed (loss: 0.04206053912639618, acc: 0.9810126423835754)
[2024-11-14 09:10:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:34][root][INFO] - Training Epoch: 2/2, step 5457/16670 completed (loss: 0.05354658141732216, acc: 0.9854369163513184)
[2024-11-14 09:10:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:34][root][INFO] - Training Epoch: 2/2, step 5458/16670 completed (loss: 0.04921551048755646, acc: 0.9795918464660645)
[2024-11-14 09:10:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:35][root][INFO] - Training Epoch: 2/2, step 5459/16670 completed (loss: 0.06287732720375061, acc: 0.9806201457977295)
[2024-11-14 09:10:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:35][root][INFO] - Training Epoch: 2/2, step 5460/16670 completed (loss: 0.11419771611690521, acc: 0.9613526463508606)
[2024-11-14 09:10:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:35][root][INFO] - Training Epoch: 2/2, step 5461/16670 completed (loss: 0.11907467991113663, acc: 0.9715909361839294)
[2024-11-14 09:10:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:36][root][INFO] - Training Epoch: 2/2, step 5462/16670 completed (loss: 0.06772866100072861, acc: 0.9877049326896667)
[2024-11-14 09:10:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:36][root][INFO] - Training Epoch: 2/2, step 5463/16670 completed (loss: 0.0710940808057785, acc: 0.9840764403343201)
[2024-11-14 09:10:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:36][root][INFO] - Training Epoch: 2/2, step 5464/16670 completed (loss: 0.024072719737887383, acc: 1.0)
[2024-11-14 09:10:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:37][root][INFO] - Training Epoch: 2/2, step 5465/16670 completed (loss: 0.11200406402349472, acc: 0.97826087474823)
[2024-11-14 09:10:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:37][root][INFO] - Training Epoch: 2/2, step 5466/16670 completed (loss: 0.28163978457450867, acc: 0.925000011920929)
[2024-11-14 09:10:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:37][root][INFO] - Training Epoch: 2/2, step 5467/16670 completed (loss: 0.03707807883620262, acc: 0.9925373196601868)
[2024-11-14 09:10:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:38][root][INFO] - Training Epoch: 2/2, step 5468/16670 completed (loss: 0.050935644656419754, acc: 0.9863013625144958)
[2024-11-14 09:10:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:38][root][INFO] - Training Epoch: 2/2, step 5469/16670 completed (loss: 0.07985031604766846, acc: 0.9700374603271484)
[2024-11-14 09:10:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:39][root][INFO] - Training Epoch: 2/2, step 5470/16670 completed (loss: 0.07495111972093582, acc: 0.9663461446762085)
[2024-11-14 09:10:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:39][root][INFO] - Training Epoch: 2/2, step 5471/16670 completed (loss: 0.0634036585688591, acc: 0.9803921580314636)
[2024-11-14 09:10:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:39][root][INFO] - Training Epoch: 2/2, step 5472/16670 completed (loss: 0.08433026820421219, acc: 0.9779735803604126)
[2024-11-14 09:10:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:39][root][INFO] - Training Epoch: 2/2, step 5473/16670 completed (loss: 0.08491811901330948, acc: 0.9846153855323792)
[2024-11-14 09:10:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:40][root][INFO] - Training Epoch: 2/2, step 5474/16670 completed (loss: 0.10976587980985641, acc: 0.9728260636329651)
[2024-11-14 09:10:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:40][root][INFO] - Training Epoch: 2/2, step 5475/16670 completed (loss: 0.05516735836863518, acc: 0.9866666793823242)
[2024-11-14 09:10:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:41][root][INFO] - Training Epoch: 2/2, step 5476/16670 completed (loss: 0.02977265790104866, acc: 1.0)
[2024-11-14 09:10:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:41][root][INFO] - Training Epoch: 2/2, step 5477/16670 completed (loss: 0.07775726169347763, acc: 0.9698492288589478)
[2024-11-14 09:10:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:41][root][INFO] - Training Epoch: 2/2, step 5478/16670 completed (loss: 0.05854608863592148, acc: 0.9730941653251648)
[2024-11-14 09:10:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:42][root][INFO] - Training Epoch: 2/2, step 5479/16670 completed (loss: 0.08966942876577377, acc: 0.9860627055168152)
[2024-11-14 09:10:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:42][root][INFO] - Training Epoch: 2/2, step 5480/16670 completed (loss: 0.09685138612985611, acc: 0.9758453965187073)
[2024-11-14 09:10:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:42][root][INFO] - Training Epoch: 2/2, step 5481/16670 completed (loss: 0.19401831924915314, acc: 0.9419087171554565)
[2024-11-14 09:10:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:43][root][INFO] - Training Epoch: 2/2, step 5482/16670 completed (loss: 0.07430284470319748, acc: 0.9737827777862549)
[2024-11-14 09:10:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:43][root][INFO] - Training Epoch: 2/2, step 5483/16670 completed (loss: 0.09540481865406036, acc: 0.9694915413856506)
[2024-11-14 09:10:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:43][root][INFO] - Training Epoch: 2/2, step 5484/16670 completed (loss: 0.03165141120553017, acc: 0.9880239367485046)
[2024-11-14 09:10:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:44][root][INFO] - Training Epoch: 2/2, step 5485/16670 completed (loss: 0.03146115317940712, acc: 0.9906103014945984)
[2024-11-14 09:10:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:44][root][INFO] - Training Epoch: 2/2, step 5486/16670 completed (loss: 0.1448351889848709, acc: 0.9589040875434875)
[2024-11-14 09:10:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:44][root][INFO] - Training Epoch: 2/2, step 5487/16670 completed (loss: 0.12304282188415527, acc: 0.9714285731315613)
[2024-11-14 09:10:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:45][root][INFO] - Training Epoch: 2/2, step 5488/16670 completed (loss: 0.0537245012819767, acc: 0.9837586879730225)
[2024-11-14 09:10:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:45][root][INFO] - Training Epoch: 2/2, step 5489/16670 completed (loss: 0.10077273100614548, acc: 0.9705014824867249)
[2024-11-14 09:10:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:46][root][INFO] - Training Epoch: 2/2, step 5490/16670 completed (loss: 0.013890081085264683, acc: 0.9957982897758484)
[2024-11-14 09:10:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:46][root][INFO] - Training Epoch: 2/2, step 5491/16670 completed (loss: 0.08409156650304794, acc: 0.9837837815284729)
[2024-11-14 09:10:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:46][root][INFO] - Training Epoch: 2/2, step 5492/16670 completed (loss: 0.16391758620738983, acc: 0.9502487778663635)
[2024-11-14 09:10:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:47][root][INFO] - Training Epoch: 2/2, step 5493/16670 completed (loss: 0.06921808421611786, acc: 0.9745762944221497)
[2024-11-14 09:10:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:47][root][INFO] - Training Epoch: 2/2, step 5494/16670 completed (loss: 0.0858750194311142, acc: 0.9726027250289917)
[2024-11-14 09:10:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:47][root][INFO] - Training Epoch: 2/2, step 5495/16670 completed (loss: 0.15659204125404358, acc: 0.9560975432395935)
[2024-11-14 09:10:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:48][root][INFO] - Training Epoch: 2/2, step 5496/16670 completed (loss: 0.22041785717010498, acc: 0.9354838728904724)
[2024-11-14 09:10:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:48][root][INFO] - Training Epoch: 2/2, step 5497/16670 completed (loss: 0.03195217251777649, acc: 0.9876543283462524)
[2024-11-14 09:10:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:48][root][INFO] - Training Epoch: 2/2, step 5498/16670 completed (loss: 0.06946742534637451, acc: 0.9806763529777527)
[2024-11-14 09:10:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:49][root][INFO] - Training Epoch: 2/2, step 5499/16670 completed (loss: 0.0629194974899292, acc: 0.9704142212867737)
[2024-11-14 09:10:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:49][root][INFO] - Training Epoch: 2/2, step 5500/16670 completed (loss: 0.08889556676149368, acc: 0.9641434550285339)
[2024-11-14 09:10:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:49][root][INFO] - Training Epoch: 2/2, step 5501/16670 completed (loss: 0.22686068713665009, acc: 0.9469964504241943)
[2024-11-14 09:10:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:50][root][INFO] - Training Epoch: 2/2, step 5502/16670 completed (loss: 0.027625609189271927, acc: 0.9839743375778198)
[2024-11-14 09:10:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:50][root][INFO] - Training Epoch: 2/2, step 5503/16670 completed (loss: 0.10603319853544235, acc: 0.9728260636329651)
[2024-11-14 09:10:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:51][root][INFO] - Training Epoch: 2/2, step 5504/16670 completed (loss: 0.11192473024129868, acc: 0.9631901979446411)
[2024-11-14 09:10:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:51][root][INFO] - Training Epoch: 2/2, step 5505/16670 completed (loss: 0.01632479950785637, acc: 0.9962546825408936)
[2024-11-14 09:10:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:51][root][INFO] - Training Epoch: 2/2, step 5506/16670 completed (loss: 0.08216060698032379, acc: 0.9740740656852722)
[2024-11-14 09:10:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:51][root][INFO] - Training Epoch: 2/2, step 5507/16670 completed (loss: 0.13308875262737274, acc: 0.970802903175354)
[2024-11-14 09:10:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:52][root][INFO] - Training Epoch: 2/2, step 5508/16670 completed (loss: 0.07825787365436554, acc: 0.9772727489471436)
[2024-11-14 09:10:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:52][root][INFO] - Training Epoch: 2/2, step 5509/16670 completed (loss: 0.07762502878904343, acc: 0.9759036302566528)
[2024-11-14 09:10:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:52][root][INFO] - Training Epoch: 2/2, step 5510/16670 completed (loss: 0.12270339578390121, acc: 0.969565212726593)
[2024-11-14 09:10:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:53][root][INFO] - Training Epoch: 2/2, step 5511/16670 completed (loss: 0.1402921825647354, acc: 0.9750000238418579)
[2024-11-14 09:10:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:53][root][INFO] - Training Epoch: 2/2, step 5512/16670 completed (loss: 0.061886079609394073, acc: 0.9793510437011719)
[2024-11-14 09:10:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:53][root][INFO] - Training Epoch: 2/2, step 5513/16670 completed (loss: 0.09327146410942078, acc: 0.974554717540741)
[2024-11-14 09:10:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:54][root][INFO] - Training Epoch: 2/2, step 5514/16670 completed (loss: 0.07589089870452881, acc: 0.976190447807312)
[2024-11-14 09:10:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:54][root][INFO] - Training Epoch: 2/2, step 5515/16670 completed (loss: 0.13496960699558258, acc: 0.9626168012619019)
[2024-11-14 09:10:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:54][root][INFO] - Training Epoch: 2/2, step 5516/16670 completed (loss: 0.1713944673538208, acc: 0.9595141410827637)
[2024-11-14 09:10:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:55][root][INFO] - Training Epoch: 2/2, step 5517/16670 completed (loss: 0.14997610449790955, acc: 0.9678714871406555)
[2024-11-14 09:10:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:55][root][INFO] - Training Epoch: 2/2, step 5518/16670 completed (loss: 0.1686398833990097, acc: 0.9599999785423279)
[2024-11-14 09:10:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:55][root][INFO] - Training Epoch: 2/2, step 5519/16670 completed (loss: 0.13006579875946045, acc: 0.9632652997970581)
[2024-11-14 09:10:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:56][root][INFO] - Training Epoch: 2/2, step 5520/16670 completed (loss: 0.17468231916427612, acc: 0.9561403393745422)
[2024-11-14 09:10:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:56][root][INFO] - Training Epoch: 2/2, step 5521/16670 completed (loss: 0.05740708112716675, acc: 0.9806763529777527)
[2024-11-14 09:10:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:56][root][INFO] - Training Epoch: 2/2, step 5522/16670 completed (loss: 0.04960677772760391, acc: 0.9861111044883728)
[2024-11-14 09:10:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:57][root][INFO] - Training Epoch: 2/2, step 5523/16670 completed (loss: 0.10564122349023819, acc: 0.9696969985961914)
[2024-11-14 09:10:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:57][root][INFO] - Training Epoch: 2/2, step 5524/16670 completed (loss: 0.2496543675661087, acc: 0.9358974099159241)
[2024-11-14 09:10:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:57][root][INFO] - Training Epoch: 2/2, step 5525/16670 completed (loss: 0.05941399931907654, acc: 0.9810606241226196)
[2024-11-14 09:10:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:58][root][INFO] - Training Epoch: 2/2, step 5526/16670 completed (loss: 0.046862393617630005, acc: 0.9844357967376709)
[2024-11-14 09:10:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:58][root][INFO] - Training Epoch: 2/2, step 5527/16670 completed (loss: 0.07945173233747482, acc: 0.9672130942344666)
[2024-11-14 09:10:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:58][root][INFO] - Training Epoch: 2/2, step 5528/16670 completed (loss: 0.15928064286708832, acc: 0.9572192430496216)
[2024-11-14 09:10:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:59][root][INFO] - Training Epoch: 2/2, step 5529/16670 completed (loss: 0.03166402876377106, acc: 1.0)
[2024-11-14 09:10:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:59][root][INFO] - Training Epoch: 2/2, step 5530/16670 completed (loss: 0.10302602499723434, acc: 0.966183602809906)
[2024-11-14 09:10:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:59][root][INFO] - Training Epoch: 2/2, step 5531/16670 completed (loss: 0.027956491336226463, acc: 0.9946523904800415)
[2024-11-14 09:10:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:10:59][root][INFO] - Training Epoch: 2/2, step 5532/16670 completed (loss: 0.06573565304279327, acc: 0.9750000238418579)
[2024-11-14 09:11:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:00][root][INFO] - Training Epoch: 2/2, step 5533/16670 completed (loss: 0.06668250262737274, acc: 0.978723406791687)
[2024-11-14 09:11:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:00][root][INFO] - Training Epoch: 2/2, step 5534/16670 completed (loss: 0.06034405902028084, acc: 0.9828571677207947)
[2024-11-14 09:11:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:00][root][INFO] - Training Epoch: 2/2, step 5535/16670 completed (loss: 0.05482872202992439, acc: 0.9881656765937805)
[2024-11-14 09:11:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:01][root][INFO] - Training Epoch: 2/2, step 5536/16670 completed (loss: 0.08165207505226135, acc: 0.9710144996643066)
[2024-11-14 09:11:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:01][root][INFO] - Training Epoch: 2/2, step 5537/16670 completed (loss: 0.03949257731437683, acc: 0.9883720874786377)
[2024-11-14 09:11:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:01][root][INFO] - Training Epoch: 2/2, step 5538/16670 completed (loss: 0.023797646164894104, acc: 0.9951691031455994)
[2024-11-14 09:11:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:02][root][INFO] - Training Epoch: 2/2, step 5539/16670 completed (loss: 0.1705058068037033, acc: 0.9610389471054077)
[2024-11-14 09:11:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:02][root][INFO] - Training Epoch: 2/2, step 5540/16670 completed (loss: 0.05423634871840477, acc: 0.9795918464660645)
[2024-11-14 09:11:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:02][root][INFO] - Training Epoch: 2/2, step 5541/16670 completed (loss: 0.13913603127002716, acc: 0.9599999785423279)
[2024-11-14 09:11:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:03][root][INFO] - Training Epoch: 2/2, step 5542/16670 completed (loss: 0.09189565479755402, acc: 0.9726027250289917)
[2024-11-14 09:11:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:03][root][INFO] - Training Epoch: 2/2, step 5543/16670 completed (loss: 0.08426675200462341, acc: 0.9847715497016907)
[2024-11-14 09:11:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:03][root][INFO] - Training Epoch: 2/2, step 5544/16670 completed (loss: 0.018675198778510094, acc: 0.9899328947067261)
[2024-11-14 09:11:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:04][root][INFO] - Training Epoch: 2/2, step 5545/16670 completed (loss: 0.021193768829107285, acc: 0.9936708807945251)
[2024-11-14 09:11:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:04][root][INFO] - Training Epoch: 2/2, step 5546/16670 completed (loss: 0.07507763803005219, acc: 0.9855769276618958)
[2024-11-14 09:11:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:04][root][INFO] - Training Epoch: 2/2, step 5547/16670 completed (loss: 0.048625051975250244, acc: 0.9824561476707458)
[2024-11-14 09:11:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:05][root][INFO] - Training Epoch: 2/2, step 5548/16670 completed (loss: 0.2803714871406555, acc: 0.9136363863945007)
[2024-11-14 09:11:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:05][root][INFO] - Training Epoch: 2/2, step 5549/16670 completed (loss: 0.025510430335998535, acc: 0.9964538812637329)
[2024-11-14 09:11:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:05][root][INFO] - Training Epoch: 2/2, step 5550/16670 completed (loss: 0.05969807505607605, acc: 0.9814814925193787)
[2024-11-14 09:11:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:06][root][INFO] - Training Epoch: 2/2, step 5551/16670 completed (loss: 0.09404414147138596, acc: 0.9776119589805603)
[2024-11-14 09:11:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:06][root][INFO] - Training Epoch: 2/2, step 5552/16670 completed (loss: 0.20717380940914154, acc: 0.9549180269241333)
[2024-11-14 09:11:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:06][root][INFO] - Training Epoch: 2/2, step 5553/16670 completed (loss: 0.1885274350643158, acc: 0.9395973086357117)
[2024-11-14 09:11:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:07][root][INFO] - Training Epoch: 2/2, step 5554/16670 completed (loss: 0.12394656985998154, acc: 0.9710144996643066)
[2024-11-14 09:11:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:07][root][INFO] - Training Epoch: 2/2, step 5555/16670 completed (loss: 0.03632095456123352, acc: 0.9813664555549622)
[2024-11-14 09:11:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:08][root][INFO] - Training Epoch: 2/2, step 5556/16670 completed (loss: 0.2664061486721039, acc: 0.9388646483421326)
[2024-11-14 09:11:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:08][root][INFO] - Training Epoch: 2/2, step 5557/16670 completed (loss: 0.06477166712284088, acc: 0.9805194735527039)
[2024-11-14 09:11:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:08][root][INFO] - Training Epoch: 2/2, step 5558/16670 completed (loss: 0.07993913441896439, acc: 0.9750000238418579)
[2024-11-14 09:11:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:09][root][INFO] - Training Epoch: 2/2, step 5559/16670 completed (loss: 0.058394912630319595, acc: 0.9813953638076782)
[2024-11-14 09:11:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:09][root][INFO] - Training Epoch: 2/2, step 5560/16670 completed (loss: 0.1604740172624588, acc: 0.949367105960846)
[2024-11-14 09:11:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:09][root][INFO] - Training Epoch: 2/2, step 5561/16670 completed (loss: 0.0556039996445179, acc: 0.9862385392189026)
[2024-11-14 09:11:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:10][root][INFO] - Training Epoch: 2/2, step 5562/16670 completed (loss: 0.20160888135433197, acc: 0.9333333373069763)
[2024-11-14 09:11:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:10][root][INFO] - Training Epoch: 2/2, step 5563/16670 completed (loss: 0.0398329496383667, acc: 0.977011501789093)
[2024-11-14 09:11:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:10][root][INFO] - Training Epoch: 2/2, step 5564/16670 completed (loss: 0.0848151296377182, acc: 0.9775280952453613)
[2024-11-14 09:11:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:11][root][INFO] - Training Epoch: 2/2, step 5565/16670 completed (loss: 0.03051760047674179, acc: 0.9942528605461121)
[2024-11-14 09:11:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:11][root][INFO] - Training Epoch: 2/2, step 5566/16670 completed (loss: 0.1668182909488678, acc: 0.9548386931419373)
[2024-11-14 09:11:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:11][root][INFO] - Training Epoch: 2/2, step 5567/16670 completed (loss: 0.1134861409664154, acc: 0.957446813583374)
[2024-11-14 09:11:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:12][root][INFO] - Training Epoch: 2/2, step 5568/16670 completed (loss: 0.07170690596103668, acc: 0.9819494485855103)
[2024-11-14 09:11:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:12][root][INFO] - Training Epoch: 2/2, step 5569/16670 completed (loss: 0.05545799061655998, acc: 0.9862068891525269)
[2024-11-14 09:11:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:12][root][INFO] - Training Epoch: 2/2, step 5570/16670 completed (loss: 0.19687826931476593, acc: 0.9572649598121643)
[2024-11-14 09:11:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:13][root][INFO] - Training Epoch: 2/2, step 5571/16670 completed (loss: 0.161091610789299, acc: 0.940397322177887)
[2024-11-14 09:11:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:13][root][INFO] - Training Epoch: 2/2, step 5572/16670 completed (loss: 0.1058453693985939, acc: 0.9775910377502441)
[2024-11-14 09:11:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:14][root][INFO] - Training Epoch: 2/2, step 5573/16670 completed (loss: 0.10903453826904297, acc: 0.9721361994743347)
[2024-11-14 09:11:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:14][root][INFO] - Training Epoch: 2/2, step 5574/16670 completed (loss: 0.09418845921754837, acc: 0.9675324559211731)
[2024-11-14 09:11:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:14][root][INFO] - Training Epoch: 2/2, step 5575/16670 completed (loss: 0.05358876287937164, acc: 0.9778597950935364)
[2024-11-14 09:11:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:15][root][INFO] - Training Epoch: 2/2, step 5576/16670 completed (loss: 0.05960121005773544, acc: 0.9810426831245422)
[2024-11-14 09:11:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:15][root][INFO] - Training Epoch: 2/2, step 5577/16670 completed (loss: 0.11269336938858032, acc: 0.973372757434845)
[2024-11-14 09:11:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:15][root][INFO] - Training Epoch: 2/2, step 5578/16670 completed (loss: 0.06176795810461044, acc: 0.9846153855323792)
[2024-11-14 09:11:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:16][root][INFO] - Training Epoch: 2/2, step 5579/16670 completed (loss: 0.2058117389678955, acc: 0.9327731132507324)
[2024-11-14 09:11:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:16][root][INFO] - Training Epoch: 2/2, step 5580/16670 completed (loss: 0.060260988771915436, acc: 0.9924242496490479)
[2024-11-14 09:11:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:16][root][INFO] - Training Epoch: 2/2, step 5581/16670 completed (loss: 0.1654655635356903, acc: 0.9665071964263916)
[2024-11-14 09:11:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:17][root][INFO] - Training Epoch: 2/2, step 5582/16670 completed (loss: 0.09143269807100296, acc: 0.9713656306266785)
[2024-11-14 09:11:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:17][root][INFO] - Training Epoch: 2/2, step 5583/16670 completed (loss: 0.06747238337993622, acc: 0.9879518151283264)
[2024-11-14 09:11:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:18][root][INFO] - Training Epoch: 2/2, step 5584/16670 completed (loss: 0.0851355567574501, acc: 0.9791666865348816)
[2024-11-14 09:11:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:18][root][INFO] - Training Epoch: 2/2, step 5585/16670 completed (loss: 0.022694848477840424, acc: 0.9929078221321106)
[2024-11-14 09:11:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:18][root][INFO] - Training Epoch: 2/2, step 5586/16670 completed (loss: 0.12374014407396317, acc: 0.9578059315681458)
[2024-11-14 09:11:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:19][root][INFO] - Training Epoch: 2/2, step 5587/16670 completed (loss: 0.21656280755996704, acc: 0.9267241358757019)
[2024-11-14 09:11:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:19][root][INFO] - Training Epoch: 2/2, step 5588/16670 completed (loss: 0.06869839876890182, acc: 0.9785932898521423)
[2024-11-14 09:11:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:19][root][INFO] - Training Epoch: 2/2, step 5589/16670 completed (loss: 0.09778816998004913, acc: 0.9762470126152039)
[2024-11-14 09:11:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:20][root][INFO] - Training Epoch: 2/2, step 5590/16670 completed (loss: 0.17218929529190063, acc: 0.939130425453186)
[2024-11-14 09:11:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:20][root][INFO] - Training Epoch: 2/2, step 5591/16670 completed (loss: 0.05775490775704384, acc: 0.9834983348846436)
[2024-11-14 09:11:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:20][root][INFO] - Training Epoch: 2/2, step 5592/16670 completed (loss: 0.18196289241313934, acc: 0.9591836929321289)
[2024-11-14 09:11:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:21][root][INFO] - Training Epoch: 2/2, step 5593/16670 completed (loss: 0.061673883348703384, acc: 0.9775280952453613)
[2024-11-14 09:11:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:21][root][INFO] - Training Epoch: 2/2, step 5594/16670 completed (loss: 0.18700988590717316, acc: 0.9477611780166626)
[2024-11-14 09:11:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:22][root][INFO] - Training Epoch: 2/2, step 5595/16670 completed (loss: 0.15327410399913788, acc: 0.9718309640884399)
[2024-11-14 09:11:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:22][root][INFO] - Training Epoch: 2/2, step 5596/16670 completed (loss: 0.05799798294901848, acc: 0.9838056564331055)
[2024-11-14 09:11:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:22][root][INFO] - Training Epoch: 2/2, step 5597/16670 completed (loss: 0.09499740600585938, acc: 0.9660193920135498)
[2024-11-14 09:11:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:23][root][INFO] - Training Epoch: 2/2, step 5598/16670 completed (loss: 0.14834260940551758, acc: 0.9646017551422119)
[2024-11-14 09:11:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:23][root][INFO] - Training Epoch: 2/2, step 5599/16670 completed (loss: 0.12646041810512543, acc: 0.9631578922271729)
[2024-11-14 09:11:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:23][root][INFO] - Training Epoch: 2/2, step 5600/16670 completed (loss: 0.13681469857692719, acc: 0.9547738432884216)
[2024-11-14 09:11:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:24][root][INFO] - Training Epoch: 2/2, step 5601/16670 completed (loss: 0.04457904398441315, acc: 0.97826087474823)
[2024-11-14 09:11:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:24][root][INFO] - Training Epoch: 2/2, step 5602/16670 completed (loss: 0.20158547163009644, acc: 0.9504950642585754)
[2024-11-14 09:11:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:25][root][INFO] - Training Epoch: 2/2, step 5603/16670 completed (loss: 0.03793290629982948, acc: 0.9914529919624329)
[2024-11-14 09:11:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:25][root][INFO] - Training Epoch: 2/2, step 5604/16670 completed (loss: 0.4222608804702759, acc: 0.8999999761581421)
[2024-11-14 09:11:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:25][root][INFO] - Training Epoch: 2/2, step 5605/16670 completed (loss: 0.0711941123008728, acc: 0.9790576100349426)
[2024-11-14 09:11:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:26][root][INFO] - Training Epoch: 2/2, step 5606/16670 completed (loss: 0.2942649722099304, acc: 0.9385964870452881)
[2024-11-14 09:11:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:26][root][INFO] - Training Epoch: 2/2, step 5607/16670 completed (loss: 0.10281068086624146, acc: 0.9754601120948792)
[2024-11-14 09:11:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:26][root][INFO] - Training Epoch: 2/2, step 5608/16670 completed (loss: 0.14484655857086182, acc: 0.9570552110671997)
[2024-11-14 09:11:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:27][root][INFO] - Training Epoch: 2/2, step 5609/16670 completed (loss: 0.19564096629619598, acc: 0.9496855139732361)
[2024-11-14 09:11:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:27][root][INFO] - Training Epoch: 2/2, step 5610/16670 completed (loss: 0.11297185719013214, acc: 0.9591836929321289)
[2024-11-14 09:11:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:27][root][INFO] - Training Epoch: 2/2, step 5611/16670 completed (loss: 0.10335945338010788, acc: 0.9655172228813171)
[2024-11-14 09:11:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:28][root][INFO] - Training Epoch: 2/2, step 5612/16670 completed (loss: 0.04343072324991226, acc: 0.9864864945411682)
[2024-11-14 09:11:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:28][root][INFO] - Training Epoch: 2/2, step 5613/16670 completed (loss: 0.23964548110961914, acc: 0.9430379867553711)
[2024-11-14 09:11:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:28][root][INFO] - Training Epoch: 2/2, step 5614/16670 completed (loss: 0.041966721415519714, acc: 0.9906976819038391)
[2024-11-14 09:11:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:29][root][INFO] - Training Epoch: 2/2, step 5615/16670 completed (loss: 0.13514749705791473, acc: 0.9605262875556946)
[2024-11-14 09:11:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:29][root][INFO] - Training Epoch: 2/2, step 5616/16670 completed (loss: 0.15653732419013977, acc: 0.9390243887901306)
[2024-11-14 09:11:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:29][root][INFO] - Training Epoch: 2/2, step 5617/16670 completed (loss: 0.16131573915481567, acc: 0.95652174949646)
[2024-11-14 09:11:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:30][root][INFO] - Training Epoch: 2/2, step 5618/16670 completed (loss: 0.29394668340682983, acc: 0.931034505367279)
[2024-11-14 09:11:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:30][root][INFO] - Training Epoch: 2/2, step 5619/16670 completed (loss: 0.21054154634475708, acc: 0.9424460530281067)
[2024-11-14 09:11:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:31][root][INFO] - Training Epoch: 2/2, step 5620/16670 completed (loss: 0.22320201992988586, acc: 0.9190475940704346)
[2024-11-14 09:11:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:31][root][INFO] - Training Epoch: 2/2, step 5621/16670 completed (loss: 0.2849651277065277, acc: 0.930232584476471)
[2024-11-14 09:11:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:31][root][INFO] - Training Epoch: 2/2, step 5622/16670 completed (loss: 0.07511094212532043, acc: 0.9919354915618896)
[2024-11-14 09:11:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:32][root][INFO] - Training Epoch: 2/2, step 5623/16670 completed (loss: 0.16142022609710693, acc: 0.9561403393745422)
[2024-11-14 09:11:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:32][root][INFO] - Training Epoch: 2/2, step 5624/16670 completed (loss: 0.10703682899475098, acc: 0.9792746305465698)
[2024-11-14 09:11:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:32][root][INFO] - Training Epoch: 2/2, step 5625/16670 completed (loss: 0.2119758427143097, acc: 0.9239130616188049)
[2024-11-14 09:11:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:33][root][INFO] - Training Epoch: 2/2, step 5626/16670 completed (loss: 0.23135624825954437, acc: 0.9371428489685059)
[2024-11-14 09:11:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:33][root][INFO] - Training Epoch: 2/2, step 5627/16670 completed (loss: 0.08796991407871246, acc: 0.9652174115180969)
[2024-11-14 09:11:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:33][root][INFO] - Training Epoch: 2/2, step 5628/16670 completed (loss: 0.09333722293376923, acc: 0.9677419066429138)
[2024-11-14 09:11:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:34][root][INFO] - Training Epoch: 2/2, step 5629/16670 completed (loss: 0.04748893156647682, acc: 0.9801980257034302)
[2024-11-14 09:11:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:34][root][INFO] - Training Epoch: 2/2, step 5630/16670 completed (loss: 0.20910382270812988, acc: 0.9487179517745972)
[2024-11-14 09:11:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:34][root][INFO] - Training Epoch: 2/2, step 5631/16670 completed (loss: 0.040784403681755066, acc: 0.9833333492279053)
[2024-11-14 09:11:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:35][root][INFO] - Training Epoch: 2/2, step 5632/16670 completed (loss: 0.07892707735300064, acc: 0.9852941036224365)
[2024-11-14 09:11:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:35][root][INFO] - Training Epoch: 2/2, step 5633/16670 completed (loss: 0.12173455953598022, acc: 0.9593495726585388)
[2024-11-14 09:11:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:36][root][INFO] - Training Epoch: 2/2, step 5634/16670 completed (loss: 0.2542061507701874, acc: 0.9496123790740967)
[2024-11-14 09:11:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:36][root][INFO] - Training Epoch: 2/2, step 5635/16670 completed (loss: 0.06322905421257019, acc: 0.9866071343421936)
[2024-11-14 09:11:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:36][root][INFO] - Training Epoch: 2/2, step 5636/16670 completed (loss: 0.07226835191249847, acc: 0.9800000190734863)
[2024-11-14 09:11:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:37][root][INFO] - Training Epoch: 2/2, step 5637/16670 completed (loss: 0.27171143889427185, acc: 0.9470198750495911)
[2024-11-14 09:11:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:37][root][INFO] - Training Epoch: 2/2, step 5638/16670 completed (loss: 0.16310851275920868, acc: 0.9537037014961243)
[2024-11-14 09:11:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:37][root][INFO] - Training Epoch: 2/2, step 5639/16670 completed (loss: 0.04325247183442116, acc: 0.991525411605835)
[2024-11-14 09:11:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:38][root][INFO] - Training Epoch: 2/2, step 5640/16670 completed (loss: 0.15599623322486877, acc: 0.9711538553237915)
[2024-11-14 09:11:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:38][root][INFO] - Training Epoch: 2/2, step 5641/16670 completed (loss: 0.17567816376686096, acc: 0.9588235020637512)
[2024-11-14 09:11:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:39][root][INFO] - Training Epoch: 2/2, step 5642/16670 completed (loss: 0.054699040949344635, acc: 0.9888888597488403)
[2024-11-14 09:11:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:39][root][INFO] - Training Epoch: 2/2, step 5643/16670 completed (loss: 0.12086790800094604, acc: 0.9756097793579102)
[2024-11-14 09:11:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:39][root][INFO] - Training Epoch: 2/2, step 5644/16670 completed (loss: 0.0368722528219223, acc: 0.976190447807312)
[2024-11-14 09:11:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:40][root][INFO] - Training Epoch: 2/2, step 5645/16670 completed (loss: 0.12219499051570892, acc: 0.9537814855575562)
[2024-11-14 09:11:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:40][root][INFO] - Training Epoch: 2/2, step 5646/16670 completed (loss: 0.1226542666554451, acc: 0.9634146094322205)
[2024-11-14 09:11:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:40][root][INFO] - Training Epoch: 2/2, step 5647/16670 completed (loss: 0.1618572622537613, acc: 0.9729729890823364)
[2024-11-14 09:11:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:41][root][INFO] - Training Epoch: 2/2, step 5648/16670 completed (loss: 0.1429906040430069, acc: 0.9547738432884216)
[2024-11-14 09:11:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:41][root][INFO] - Training Epoch: 2/2, step 5649/16670 completed (loss: 0.18362534046173096, acc: 0.9716312289237976)
[2024-11-14 09:11:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:41][root][INFO] - Training Epoch: 2/2, step 5650/16670 completed (loss: 0.09788820892572403, acc: 0.960629940032959)
[2024-11-14 09:11:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:42][root][INFO] - Training Epoch: 2/2, step 5651/16670 completed (loss: 0.2161211371421814, acc: 0.9439252614974976)
[2024-11-14 09:11:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:42][root][INFO] - Training Epoch: 2/2, step 5652/16670 completed (loss: 0.227822944521904, acc: 0.9175257682800293)
[2024-11-14 09:11:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:42][root][INFO] - Training Epoch: 2/2, step 5653/16670 completed (loss: 0.06937766820192337, acc: 0.9698492288589478)
[2024-11-14 09:11:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:43][root][INFO] - Training Epoch: 2/2, step 5654/16670 completed (loss: 0.22903169691562653, acc: 0.9340659379959106)
[2024-11-14 09:11:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:43][root][INFO] - Training Epoch: 2/2, step 5655/16670 completed (loss: 0.11818746477365494, acc: 0.9756097793579102)
[2024-11-14 09:11:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:43][root][INFO] - Training Epoch: 2/2, step 5656/16670 completed (loss: 0.24350540339946747, acc: 0.942105233669281)
[2024-11-14 09:11:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:44][root][INFO] - Training Epoch: 2/2, step 5657/16670 completed (loss: 0.026927590370178223, acc: 1.0)
[2024-11-14 09:11:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:44][root][INFO] - Training Epoch: 2/2, step 5658/16670 completed (loss: 0.06413852423429489, acc: 0.9828571677207947)
[2024-11-14 09:11:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:45][root][INFO] - Training Epoch: 2/2, step 5659/16670 completed (loss: 0.08322477340698242, acc: 0.9656862616539001)
[2024-11-14 09:11:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:45][root][INFO] - Training Epoch: 2/2, step 5660/16670 completed (loss: 0.14115995168685913, acc: 0.957446813583374)
[2024-11-14 09:11:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:45][root][INFO] - Training Epoch: 2/2, step 5661/16670 completed (loss: 0.10668620467185974, acc: 0.9741935729980469)
[2024-11-14 09:11:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:46][root][INFO] - Training Epoch: 2/2, step 5662/16670 completed (loss: 0.11647479236125946, acc: 0.9731543660163879)
[2024-11-14 09:11:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:46][root][INFO] - Training Epoch: 2/2, step 5663/16670 completed (loss: 0.02549225091934204, acc: 0.9921875)
[2024-11-14 09:11:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:46][root][INFO] - Training Epoch: 2/2, step 5664/16670 completed (loss: 0.11475475132465363, acc: 0.970588207244873)
[2024-11-14 09:11:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:47][root][INFO] - Training Epoch: 2/2, step 5665/16670 completed (loss: 0.042694106698036194, acc: 0.9772727489471436)
[2024-11-14 09:11:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:47][root][INFO] - Training Epoch: 2/2, step 5666/16670 completed (loss: 0.09315028041601181, acc: 0.971875011920929)
[2024-11-14 09:11:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:47][root][INFO] - Training Epoch: 2/2, step 5667/16670 completed (loss: 0.18551410734653473, acc: 0.9577465057373047)
[2024-11-14 09:11:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:48][root][INFO] - Training Epoch: 2/2, step 5668/16670 completed (loss: 0.12136644124984741, acc: 0.9605262875556946)
[2024-11-14 09:11:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:48][root][INFO] - Training Epoch: 2/2, step 5669/16670 completed (loss: 0.07324181497097015, acc: 1.0)
[2024-11-14 09:11:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:49][root][INFO] - Training Epoch: 2/2, step 5670/16670 completed (loss: 0.21286699175834656, acc: 0.939393937587738)
[2024-11-14 09:11:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:49][root][INFO] - Training Epoch: 2/2, step 5671/16670 completed (loss: 0.3468523621559143, acc: 0.9316770434379578)
[2024-11-14 09:11:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:49][root][INFO] - Training Epoch: 2/2, step 5672/16670 completed (loss: 0.1781550645828247, acc: 0.9663865566253662)
[2024-11-14 09:11:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:50][root][INFO] - Training Epoch: 2/2, step 5673/16670 completed (loss: 0.07334348559379578, acc: 0.9662446975708008)
[2024-11-14 09:11:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:50][root][INFO] - Training Epoch: 2/2, step 5674/16670 completed (loss: 0.2291063666343689, acc: 0.9515151381492615)
[2024-11-14 09:11:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:50][root][INFO] - Training Epoch: 2/2, step 5675/16670 completed (loss: 0.27064403891563416, acc: 0.9408283829689026)
[2024-11-14 09:11:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:51][root][INFO] - Training Epoch: 2/2, step 5676/16670 completed (loss: 0.15110152959823608, acc: 0.9519650936126709)
[2024-11-14 09:11:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:51][root][INFO] - Training Epoch: 2/2, step 5677/16670 completed (loss: 0.1824439913034439, acc: 0.9488189220428467)
[2024-11-14 09:11:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:51][root][INFO] - Training Epoch: 2/2, step 5678/16670 completed (loss: 0.15459463000297546, acc: 0.9507042169570923)
[2024-11-14 09:11:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:52][root][INFO] - Training Epoch: 2/2, step 5679/16670 completed (loss: 0.10425077378749847, acc: 0.9679487347602844)
[2024-11-14 09:11:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:52][root][INFO] - Training Epoch: 2/2, step 5680/16670 completed (loss: 0.0653700977563858, acc: 0.9830508232116699)
[2024-11-14 09:11:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:53][root][INFO] - Training Epoch: 2/2, step 5681/16670 completed (loss: 0.12483092397451401, acc: 0.9692307710647583)
[2024-11-14 09:11:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:53][root][INFO] - Training Epoch: 2/2, step 5682/16670 completed (loss: 0.08942089229822159, acc: 0.9647887349128723)
[2024-11-14 09:11:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:53][root][INFO] - Training Epoch: 2/2, step 5683/16670 completed (loss: 0.05168984830379486, acc: 0.9781022071838379)
[2024-11-14 09:11:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:54][root][INFO] - Training Epoch: 2/2, step 5684/16670 completed (loss: 0.12665677070617676, acc: 0.9537572264671326)
[2024-11-14 09:11:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:54][root][INFO] - Training Epoch: 2/2, step 5685/16670 completed (loss: 0.10363121330738068, acc: 0.9627118706703186)
[2024-11-14 09:11:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:54][root][INFO] - Training Epoch: 2/2, step 5686/16670 completed (loss: 0.2836974561214447, acc: 0.9150943160057068)
[2024-11-14 09:11:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:55][root][INFO] - Training Epoch: 2/2, step 5687/16670 completed (loss: 0.13788026571273804, acc: 0.9722222089767456)
[2024-11-14 09:11:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:55][root][INFO] - Training Epoch: 2/2, step 5688/16670 completed (loss: 0.1819954812526703, acc: 0.9306122660636902)
[2024-11-14 09:11:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:55][root][INFO] - Training Epoch: 2/2, step 5689/16670 completed (loss: 0.10215503722429276, acc: 0.9773585200309753)
[2024-11-14 09:11:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:56][root][INFO] - Training Epoch: 2/2, step 5690/16670 completed (loss: 0.11141228675842285, acc: 0.9689922332763672)
[2024-11-14 09:11:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:56][root][INFO] - Training Epoch: 2/2, step 5691/16670 completed (loss: 0.22734618186950684, acc: 0.9102563858032227)
[2024-11-14 09:11:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:57][root][INFO] - Training Epoch: 2/2, step 5692/16670 completed (loss: 0.19928386807441711, acc: 0.931034505367279)
[2024-11-14 09:11:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:57][root][INFO] - Training Epoch: 2/2, step 5693/16670 completed (loss: 0.0800417959690094, acc: 0.9847328066825867)
[2024-11-14 09:11:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:57][root][INFO] - Training Epoch: 2/2, step 5694/16670 completed (loss: 0.1502431333065033, acc: 0.9444444179534912)
[2024-11-14 09:11:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:58][root][INFO] - Training Epoch: 2/2, step 5695/16670 completed (loss: 0.293888121843338, acc: 0.914893627166748)
[2024-11-14 09:11:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:58][root][INFO] - Training Epoch: 2/2, step 5696/16670 completed (loss: 0.12924669682979584, acc: 0.9674418568611145)
[2024-11-14 09:11:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:58][root][INFO] - Training Epoch: 2/2, step 5697/16670 completed (loss: 0.11733177304267883, acc: 0.9781022071838379)
[2024-11-14 09:11:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:59][root][INFO] - Training Epoch: 2/2, step 5698/16670 completed (loss: 0.12463711947202682, acc: 0.9591836929321289)
[2024-11-14 09:11:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:59][root][INFO] - Training Epoch: 2/2, step 5699/16670 completed (loss: 0.209639310836792, acc: 0.9454545378684998)
[2024-11-14 09:11:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:11:59][root][INFO] - Training Epoch: 2/2, step 5700/16670 completed (loss: 0.11363478004932404, acc: 0.963350772857666)
[2024-11-14 09:11:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:00][root][INFO] - Training Epoch: 2/2, step 5701/16670 completed (loss: 0.11415248364210129, acc: 0.9797979593276978)
[2024-11-14 09:12:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:00][root][INFO] - Training Epoch: 2/2, step 5702/16670 completed (loss: 0.054136209189891815, acc: 0.9905660152435303)
[2024-11-14 09:12:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:00][root][INFO] - Training Epoch: 2/2, step 5703/16670 completed (loss: 0.09912008047103882, acc: 0.9670329689979553)
[2024-11-14 09:12:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:01][root][INFO] - Training Epoch: 2/2, step 5704/16670 completed (loss: 0.13904531300067902, acc: 0.9638009071350098)
[2024-11-14 09:12:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:01][root][INFO] - Training Epoch: 2/2, step 5705/16670 completed (loss: 0.0802234336733818, acc: 0.9750000238418579)
[2024-11-14 09:12:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:01][root][INFO] - Training Epoch: 2/2, step 5706/16670 completed (loss: 0.057667579501867294, acc: 0.9906542301177979)
[2024-11-14 09:12:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:02][root][INFO] - Training Epoch: 2/2, step 5707/16670 completed (loss: 0.06661558151245117, acc: 0.9769230484962463)
[2024-11-14 09:12:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:02][root][INFO] - Training Epoch: 2/2, step 5708/16670 completed (loss: 0.1297563910484314, acc: 0.9618320465087891)
[2024-11-14 09:12:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:02][root][INFO] - Training Epoch: 2/2, step 5709/16670 completed (loss: 0.12477842718362808, acc: 0.9617486596107483)
[2024-11-14 09:12:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:03][root][INFO] - Training Epoch: 2/2, step 5710/16670 completed (loss: 0.18043740093708038, acc: 0.9518716335296631)
[2024-11-14 09:12:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:03][root][INFO] - Training Epoch: 2/2, step 5711/16670 completed (loss: 0.21477293968200684, acc: 0.9473684430122375)
[2024-11-14 09:12:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:04][root][INFO] - Training Epoch: 2/2, step 5712/16670 completed (loss: 0.25561437010765076, acc: 0.9189189076423645)
[2024-11-14 09:12:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:04][root][INFO] - Training Epoch: 2/2, step 5713/16670 completed (loss: 0.12935207784175873, acc: 0.9618055820465088)
[2024-11-14 09:12:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:04][root][INFO] - Training Epoch: 2/2, step 5714/16670 completed (loss: 0.07010485976934433, acc: 0.9696969985961914)
[2024-11-14 09:12:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:05][root][INFO] - Training Epoch: 2/2, step 5715/16670 completed (loss: 0.15438857674598694, acc: 0.9402984976768494)
[2024-11-14 09:12:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:05][root][INFO] - Training Epoch: 2/2, step 5716/16670 completed (loss: 0.3493548035621643, acc: 0.9305555820465088)
[2024-11-14 09:12:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:05][root][INFO] - Training Epoch: 2/2, step 5717/16670 completed (loss: 0.3080446422100067, acc: 0.9202454090118408)
[2024-11-14 09:12:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:06][root][INFO] - Training Epoch: 2/2, step 5718/16670 completed (loss: 0.07689595222473145, acc: 0.9858657121658325)
[2024-11-14 09:12:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:06][root][INFO] - Training Epoch: 2/2, step 5719/16670 completed (loss: 0.23874834179878235, acc: 0.949999988079071)
[2024-11-14 09:12:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:06][root][INFO] - Training Epoch: 2/2, step 5720/16670 completed (loss: 0.242273211479187, acc: 0.920634925365448)
[2024-11-14 09:12:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:07][root][INFO] - Training Epoch: 2/2, step 5721/16670 completed (loss: 0.15167979896068573, acc: 0.9509202241897583)
[2024-11-14 09:12:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:07][root][INFO] - Training Epoch: 2/2, step 5722/16670 completed (loss: 0.039644353091716766, acc: 0.9868420958518982)
[2024-11-14 09:12:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:07][root][INFO] - Training Epoch: 2/2, step 5723/16670 completed (loss: 0.2022547721862793, acc: 0.9263157844543457)
[2024-11-14 09:12:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:08][root][INFO] - Training Epoch: 2/2, step 5724/16670 completed (loss: 0.057487912476062775, acc: 0.9727272987365723)
[2024-11-14 09:12:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:08][root][INFO] - Training Epoch: 2/2, step 5725/16670 completed (loss: 0.19655460119247437, acc: 0.9572649598121643)
[2024-11-14 09:12:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:09][root][INFO] - Training Epoch: 2/2, step 5726/16670 completed (loss: 0.1986134797334671, acc: 0.9328358173370361)
[2024-11-14 09:12:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:09][root][INFO] - Training Epoch: 2/2, step 5727/16670 completed (loss: 0.08280571550130844, acc: 0.9750000238418579)
[2024-11-14 09:12:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:09][root][INFO] - Training Epoch: 2/2, step 5728/16670 completed (loss: 0.2338763177394867, acc: 0.9465649127960205)
[2024-11-14 09:12:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:10][root][INFO] - Training Epoch: 2/2, step 5729/16670 completed (loss: 0.24796679615974426, acc: 0.932330846786499)
[2024-11-14 09:12:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:10][root][INFO] - Training Epoch: 2/2, step 5730/16670 completed (loss: 0.19848698377609253, acc: 0.9588235020637512)
[2024-11-14 09:12:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:10][root][INFO] - Training Epoch: 2/2, step 5731/16670 completed (loss: 0.09083415567874908, acc: 0.9871794581413269)
[2024-11-14 09:12:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:11][root][INFO] - Training Epoch: 2/2, step 5732/16670 completed (loss: 0.33827292919158936, acc: 0.9259259104728699)
[2024-11-14 09:12:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:11][root][INFO] - Training Epoch: 2/2, step 5733/16670 completed (loss: 0.13727706670761108, acc: 0.9487179517745972)
[2024-11-14 09:12:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:11][root][INFO] - Training Epoch: 2/2, step 5734/16670 completed (loss: 0.23613178730010986, acc: 0.931506872177124)
[2024-11-14 09:12:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:12][root][INFO] - Training Epoch: 2/2, step 5735/16670 completed (loss: 0.02535068616271019, acc: 0.9932885766029358)
[2024-11-14 09:12:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:12][root][INFO] - Training Epoch: 2/2, step 5736/16670 completed (loss: 0.11777942627668381, acc: 0.9666666388511658)
[2024-11-14 09:12:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:13][root][INFO] - Training Epoch: 2/2, step 5737/16670 completed (loss: 0.031824566423892975, acc: 0.9936708807945251)
[2024-11-14 09:12:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:13][root][INFO] - Training Epoch: 2/2, step 5738/16670 completed (loss: 0.1856684684753418, acc: 0.9593908786773682)
[2024-11-14 09:12:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:13][root][INFO] - Training Epoch: 2/2, step 5739/16670 completed (loss: 0.027165686711668968, acc: 0.9954751133918762)
[2024-11-14 09:12:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:14][root][INFO] - Training Epoch: 2/2, step 5740/16670 completed (loss: 0.11347340047359467, acc: 0.9469026327133179)
[2024-11-14 09:12:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:14][root][INFO] - Training Epoch: 2/2, step 5741/16670 completed (loss: 0.0452360138297081, acc: 0.982758641242981)
[2024-11-14 09:12:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:14][root][INFO] - Training Epoch: 2/2, step 5742/16670 completed (loss: 0.2550866901874542, acc: 0.9447236061096191)
[2024-11-14 09:12:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:15][root][INFO] - Training Epoch: 2/2, step 5743/16670 completed (loss: 0.12328027933835983, acc: 0.9641255736351013)
[2024-11-14 09:12:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:15][root][INFO] - Training Epoch: 2/2, step 5744/16670 completed (loss: 0.20562782883644104, acc: 0.9578947424888611)
[2024-11-14 09:12:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:15][root][INFO] - Training Epoch: 2/2, step 5745/16670 completed (loss: 0.1089763343334198, acc: 0.9666666388511658)
[2024-11-14 09:12:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:16][root][INFO] - Training Epoch: 2/2, step 5746/16670 completed (loss: 0.05232669413089752, acc: 0.989130437374115)
[2024-11-14 09:12:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:16][root][INFO] - Training Epoch: 2/2, step 5747/16670 completed (loss: 0.036029938608407974, acc: 0.988095223903656)
[2024-11-14 09:12:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:17][root][INFO] - Training Epoch: 2/2, step 5748/16670 completed (loss: 0.18187998235225677, acc: 0.9655172228813171)
[2024-11-14 09:12:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:17][root][INFO] - Training Epoch: 2/2, step 5749/16670 completed (loss: 0.12073460966348648, acc: 0.9477611780166626)
[2024-11-14 09:12:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:17][root][INFO] - Training Epoch: 2/2, step 5750/16670 completed (loss: 0.09790319204330444, acc: 0.97826087474823)
[2024-11-14 09:12:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:18][root][INFO] - Training Epoch: 2/2, step 5751/16670 completed (loss: 0.10555258393287659, acc: 0.9682539701461792)
[2024-11-14 09:12:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:18][root][INFO] - Training Epoch: 2/2, step 5752/16670 completed (loss: 0.14086726307868958, acc: 0.9626556038856506)
[2024-11-14 09:12:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:18][root][INFO] - Training Epoch: 2/2, step 5753/16670 completed (loss: 0.03251899033784866, acc: 0.9893617033958435)
[2024-11-14 09:12:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:19][root][INFO] - Training Epoch: 2/2, step 5754/16670 completed (loss: 0.11468431353569031, acc: 0.9569377899169922)
[2024-11-14 09:12:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:19][root][INFO] - Training Epoch: 2/2, step 5755/16670 completed (loss: 0.07032113522291183, acc: 0.970370352268219)
[2024-11-14 09:12:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:20][root][INFO] - Training Epoch: 2/2, step 5756/16670 completed (loss: 0.11882339417934418, acc: 0.9720670580863953)
[2024-11-14 09:12:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:20][root][INFO] - Training Epoch: 2/2, step 5757/16670 completed (loss: 0.1832614690065384, acc: 0.9506173133850098)
[2024-11-14 09:12:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:20][root][INFO] - Training Epoch: 2/2, step 5758/16670 completed (loss: 0.03422253951430321, acc: 0.9823529124259949)
[2024-11-14 09:12:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:21][root][INFO] - Training Epoch: 2/2, step 5759/16670 completed (loss: 0.22572118043899536, acc: 0.9365079402923584)
[2024-11-14 09:12:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:21][root][INFO] - Training Epoch: 2/2, step 5760/16670 completed (loss: 0.022310664877295494, acc: 1.0)
[2024-11-14 09:12:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:21][root][INFO] - Training Epoch: 2/2, step 5761/16670 completed (loss: 0.26529157161712646, acc: 0.9104477763175964)
[2024-11-14 09:12:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:22][root][INFO] - Training Epoch: 2/2, step 5762/16670 completed (loss: 0.027163613587617874, acc: 1.0)
[2024-11-14 09:12:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:22][root][INFO] - Training Epoch: 2/2, step 5763/16670 completed (loss: 0.11792407184839249, acc: 0.9664429426193237)
[2024-11-14 09:12:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:22][root][INFO] - Training Epoch: 2/2, step 5764/16670 completed (loss: 0.11260868608951569, acc: 0.9679999947547913)
[2024-11-14 09:12:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:23][root][INFO] - Training Epoch: 2/2, step 5765/16670 completed (loss: 0.07263223081827164, acc: 0.977011501789093)
[2024-11-14 09:12:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:23][root][INFO] - Training Epoch: 2/2, step 5766/16670 completed (loss: 0.10308517515659332, acc: 0.9646017551422119)
[2024-11-14 09:12:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:23][root][INFO] - Training Epoch: 2/2, step 5767/16670 completed (loss: 0.18096107244491577, acc: 0.9695122241973877)
[2024-11-14 09:12:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:24][root][INFO] - Training Epoch: 2/2, step 5768/16670 completed (loss: 0.05915098637342453, acc: 0.9805194735527039)
[2024-11-14 09:12:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:24][root][INFO] - Training Epoch: 2/2, step 5769/16670 completed (loss: 0.10858527570962906, acc: 0.96875)
[2024-11-14 09:12:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:24][root][INFO] - Training Epoch: 2/2, step 5770/16670 completed (loss: 0.25596415996551514, acc: 0.9496855139732361)
[2024-11-14 09:12:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:25][root][INFO] - Training Epoch: 2/2, step 5771/16670 completed (loss: 0.0742102786898613, acc: 0.9814814925193787)
[2024-11-14 09:12:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:25][root][INFO] - Training Epoch: 2/2, step 5772/16670 completed (loss: 0.07295391708612442, acc: 0.9729729890823364)
[2024-11-14 09:12:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:26][root][INFO] - Training Epoch: 2/2, step 5773/16670 completed (loss: 0.1285131871700287, acc: 0.9642857313156128)
[2024-11-14 09:12:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:26][root][INFO] - Training Epoch: 2/2, step 5774/16670 completed (loss: 0.05918380990624428, acc: 0.9879518151283264)
[2024-11-14 09:12:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:26][root][INFO] - Training Epoch: 2/2, step 5775/16670 completed (loss: 0.0700828805565834, acc: 0.9777777791023254)
[2024-11-14 09:12:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:27][root][INFO] - Training Epoch: 2/2, step 5776/16670 completed (loss: 0.14463335275650024, acc: 0.9589743614196777)
[2024-11-14 09:12:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:27][root][INFO] - Training Epoch: 2/2, step 5777/16670 completed (loss: 0.3093017041683197, acc: 0.9064327478408813)
[2024-11-14 09:12:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:28][root][INFO] - Training Epoch: 2/2, step 5778/16670 completed (loss: 0.07283275574445724, acc: 0.9718875288963318)
[2024-11-14 09:12:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:28][root][INFO] - Training Epoch: 2/2, step 5779/16670 completed (loss: 0.19454379379749298, acc: 0.9591836929321289)
[2024-11-14 09:12:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:28][root][INFO] - Training Epoch: 2/2, step 5780/16670 completed (loss: 0.18324707448482513, acc: 0.9596412777900696)
[2024-11-14 09:12:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:29][root][INFO] - Training Epoch: 2/2, step 5781/16670 completed (loss: 0.28272247314453125, acc: 0.9379844665527344)
[2024-11-14 09:12:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:29][root][INFO] - Training Epoch: 2/2, step 5782/16670 completed (loss: 0.15388508141040802, acc: 0.9411764740943909)
[2024-11-14 09:12:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:29][root][INFO] - Training Epoch: 2/2, step 5783/16670 completed (loss: 0.055888187140226364, acc: 0.9779411554336548)
[2024-11-14 09:12:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:30][root][INFO] - Training Epoch: 2/2, step 5784/16670 completed (loss: 0.13740748167037964, acc: 0.9416666626930237)
[2024-11-14 09:12:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:30][root][INFO] - Training Epoch: 2/2, step 5785/16670 completed (loss: 0.07375060021877289, acc: 0.9906542301177979)
[2024-11-14 09:12:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:31][root][INFO] - Training Epoch: 2/2, step 5786/16670 completed (loss: 0.07521961629390717, acc: 0.9711538553237915)
[2024-11-14 09:12:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:31][root][INFO] - Training Epoch: 2/2, step 5787/16670 completed (loss: 0.08006294071674347, acc: 0.9772727489471436)
[2024-11-14 09:12:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:31][root][INFO] - Training Epoch: 2/2, step 5788/16670 completed (loss: 0.15586884319782257, acc: 0.96875)
[2024-11-14 09:12:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:32][root][INFO] - Training Epoch: 2/2, step 5789/16670 completed (loss: 0.0571383535861969, acc: 0.9810426831245422)
[2024-11-14 09:12:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:32][root][INFO] - Training Epoch: 2/2, step 5790/16670 completed (loss: 0.1752266138792038, acc: 0.949999988079071)
[2024-11-14 09:12:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:32][root][INFO] - Training Epoch: 2/2, step 5791/16670 completed (loss: 0.24204322695732117, acc: 0.9496402740478516)
[2024-11-14 09:12:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:33][root][INFO] - Training Epoch: 2/2, step 5792/16670 completed (loss: 0.046009957790374756, acc: 0.9873417615890503)
[2024-11-14 09:12:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:33][root][INFO] - Training Epoch: 2/2, step 5793/16670 completed (loss: 0.09295409917831421, acc: 0.9661017060279846)
[2024-11-14 09:12:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:33][root][INFO] - Training Epoch: 2/2, step 5794/16670 completed (loss: 0.07840517163276672, acc: 0.96875)
[2024-11-14 09:12:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:34][root][INFO] - Training Epoch: 2/2, step 5795/16670 completed (loss: 0.049922652542591095, acc: 0.9937888383865356)
[2024-11-14 09:12:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:34][root][INFO] - Training Epoch: 2/2, step 5796/16670 completed (loss: 0.12558704614639282, acc: 0.9670329689979553)
[2024-11-14 09:12:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:34][root][INFO] - Training Epoch: 2/2, step 5797/16670 completed (loss: 0.11813188344240189, acc: 0.9710144996643066)
[2024-11-14 09:12:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:35][root][INFO] - Training Epoch: 2/2, step 5798/16670 completed (loss: 0.07669416815042496, acc: 0.980079710483551)
[2024-11-14 09:12:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:35][root][INFO] - Training Epoch: 2/2, step 5799/16670 completed (loss: 0.09641975909471512, acc: 0.96875)
[2024-11-14 09:12:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:35][root][INFO] - Training Epoch: 2/2, step 5800/16670 completed (loss: 0.15689826011657715, acc: 0.9602649211883545)
[2024-11-14 09:12:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:36][root][INFO] - Training Epoch: 2/2, step 5801/16670 completed (loss: 0.07567154616117477, acc: 0.9786096215248108)
[2024-11-14 09:12:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:36][root][INFO] - Training Epoch: 2/2, step 5802/16670 completed (loss: 0.10242273658514023, acc: 0.9795918464660645)
[2024-11-14 09:12:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:36][root][INFO] - Training Epoch: 2/2, step 5803/16670 completed (loss: 0.1279406100511551, acc: 0.9693877696990967)
[2024-11-14 09:12:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:37][root][INFO] - Training Epoch: 2/2, step 5804/16670 completed (loss: 0.084308922290802, acc: 0.9914529919624329)
[2024-11-14 09:12:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:37][root][INFO] - Training Epoch: 2/2, step 5805/16670 completed (loss: 0.043495774269104004, acc: 0.9937499761581421)
[2024-11-14 09:12:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:37][root][INFO] - Training Epoch: 2/2, step 5806/16670 completed (loss: 0.06600477546453476, acc: 0.9864864945411682)
[2024-11-14 09:12:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:38][root][INFO] - Training Epoch: 2/2, step 5807/16670 completed (loss: 0.20533472299575806, acc: 0.9378530979156494)
[2024-11-14 09:12:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:38][root][INFO] - Training Epoch: 2/2, step 5808/16670 completed (loss: 0.10721734166145325, acc: 0.9754902124404907)
[2024-11-14 09:12:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:38][root][INFO] - Training Epoch: 2/2, step 5809/16670 completed (loss: 0.22024907171726227, acc: 0.9450549483299255)
[2024-11-14 09:12:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:39][root][INFO] - Training Epoch: 2/2, step 5810/16670 completed (loss: 0.17276857793331146, acc: 0.9488636255264282)
[2024-11-14 09:12:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:39][root][INFO] - Training Epoch: 2/2, step 5811/16670 completed (loss: 0.07593132555484772, acc: 0.9822485446929932)
[2024-11-14 09:12:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:39][root][INFO] - Training Epoch: 2/2, step 5812/16670 completed (loss: 0.12701515853405, acc: 0.9677419066429138)
[2024-11-14 09:12:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:40][root][INFO] - Training Epoch: 2/2, step 5813/16670 completed (loss: 0.3646211624145508, acc: 0.8785046935081482)
[2024-11-14 09:12:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:40][root][INFO] - Training Epoch: 2/2, step 5814/16670 completed (loss: 0.07378168404102325, acc: 0.9733333587646484)
[2024-11-14 09:12:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:40][root][INFO] - Training Epoch: 2/2, step 5815/16670 completed (loss: 0.047813571989536285, acc: 0.9842519760131836)
[2024-11-14 09:12:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:41][root][INFO] - Training Epoch: 2/2, step 5816/16670 completed (loss: 0.15926256775856018, acc: 0.9549999833106995)
[2024-11-14 09:12:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:41][root][INFO] - Training Epoch: 2/2, step 5817/16670 completed (loss: 0.15219339728355408, acc: 0.9599999785423279)
[2024-11-14 09:12:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:41][root][INFO] - Training Epoch: 2/2, step 5818/16670 completed (loss: 0.2116917073726654, acc: 0.949999988079071)
[2024-11-14 09:12:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:42][root][INFO] - Training Epoch: 2/2, step 5819/16670 completed (loss: 0.18443819880485535, acc: 0.9534883499145508)
[2024-11-14 09:12:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:42][root][INFO] - Training Epoch: 2/2, step 5820/16670 completed (loss: 0.023155972361564636, acc: 0.9922480583190918)
[2024-11-14 09:12:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:42][root][INFO] - Training Epoch: 2/2, step 5821/16670 completed (loss: 0.08998768776655197, acc: 0.9722222089767456)
[2024-11-14 09:12:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:43][root][INFO] - Training Epoch: 2/2, step 5822/16670 completed (loss: 0.17963755130767822, acc: 0.9629629850387573)
[2024-11-14 09:12:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:43][root][INFO] - Training Epoch: 2/2, step 5823/16670 completed (loss: 0.13913099467754364, acc: 0.951724112033844)
[2024-11-14 09:12:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:44][root][INFO] - Training Epoch: 2/2, step 5824/16670 completed (loss: 0.07899507135152817, acc: 0.9821428656578064)
[2024-11-14 09:12:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:44][root][INFO] - Training Epoch: 2/2, step 5825/16670 completed (loss: 0.359026700258255, acc: 0.9118942618370056)
[2024-11-14 09:12:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:44][root][INFO] - Training Epoch: 2/2, step 5826/16670 completed (loss: 0.08119523525238037, acc: 0.9848484992980957)
[2024-11-14 09:12:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:45][root][INFO] - Training Epoch: 2/2, step 5827/16670 completed (loss: 0.030240317806601524, acc: 0.9924242496490479)
[2024-11-14 09:12:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:45][root][INFO] - Training Epoch: 2/2, step 5828/16670 completed (loss: 0.0885859951376915, acc: 0.9850000143051147)
[2024-11-14 09:12:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:45][root][INFO] - Training Epoch: 2/2, step 5829/16670 completed (loss: 0.1973627507686615, acc: 0.9430894255638123)
[2024-11-14 09:12:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:46][root][INFO] - Training Epoch: 2/2, step 5830/16670 completed (loss: 0.14778797328472137, acc: 0.9567307829856873)
[2024-11-14 09:12:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:46][root][INFO] - Training Epoch: 2/2, step 5831/16670 completed (loss: 0.3519660234451294, acc: 0.9137930870056152)
[2024-11-14 09:12:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:46][root][INFO] - Training Epoch: 2/2, step 5832/16670 completed (loss: 0.19973303377628326, acc: 0.9436619877815247)
[2024-11-14 09:12:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:47][root][INFO] - Training Epoch: 2/2, step 5833/16670 completed (loss: 0.16358424723148346, acc: 0.9379310607910156)
[2024-11-14 09:12:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:47][root][INFO] - Training Epoch: 2/2, step 5834/16670 completed (loss: 0.25632983446121216, acc: 0.9655172228813171)
[2024-11-14 09:12:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:47][root][INFO] - Training Epoch: 2/2, step 5835/16670 completed (loss: 0.09407990425825119, acc: 0.9717742204666138)
[2024-11-14 09:12:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:48][root][INFO] - Training Epoch: 2/2, step 5836/16670 completed (loss: 0.43124037981033325, acc: 0.8931623697280884)
[2024-11-14 09:12:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:48][root][INFO] - Training Epoch: 2/2, step 5837/16670 completed (loss: 0.05457963049411774, acc: 0.9795918464660645)
[2024-11-14 09:12:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:48][root][INFO] - Training Epoch: 2/2, step 5838/16670 completed (loss: 0.33428898453712463, acc: 0.9176470637321472)
[2024-11-14 09:12:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:49][root][INFO] - Training Epoch: 2/2, step 5839/16670 completed (loss: 0.07352910190820694, acc: 0.9789473414421082)
[2024-11-14 09:12:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:49][root][INFO] - Training Epoch: 2/2, step 5840/16670 completed (loss: 0.16019997000694275, acc: 0.9615384340286255)
[2024-11-14 09:12:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:49][root][INFO] - Training Epoch: 2/2, step 5841/16670 completed (loss: 0.14027036726474762, acc: 0.9539473652839661)
[2024-11-14 09:12:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:50][root][INFO] - Training Epoch: 2/2, step 5842/16670 completed (loss: 0.07202638685703278, acc: 0.9711538553237915)
[2024-11-14 09:12:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:50][root][INFO] - Training Epoch: 2/2, step 5843/16670 completed (loss: 0.1422690898180008, acc: 0.9428571462631226)
[2024-11-14 09:12:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:50][root][INFO] - Training Epoch: 2/2, step 5844/16670 completed (loss: 0.09769095480442047, acc: 0.9743589758872986)
[2024-11-14 09:12:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:51][root][INFO] - Training Epoch: 2/2, step 5845/16670 completed (loss: 0.10689181834459305, acc: 0.9708737730979919)
[2024-11-14 09:12:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:51][root][INFO] - Training Epoch: 2/2, step 5846/16670 completed (loss: 0.12621243298053741, acc: 0.9626168012619019)
[2024-11-14 09:12:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:51][root][INFO] - Training Epoch: 2/2, step 5847/16670 completed (loss: 0.07049299776554108, acc: 0.9664429426193237)
[2024-11-14 09:12:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:52][root][INFO] - Training Epoch: 2/2, step 5848/16670 completed (loss: 0.26802194118499756, acc: 0.9295774698257446)
[2024-11-14 09:12:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:52][root][INFO] - Training Epoch: 2/2, step 5849/16670 completed (loss: 0.3146212100982666, acc: 0.9171974658966064)
[2024-11-14 09:12:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:52][root][INFO] - Training Epoch: 2/2, step 5850/16670 completed (loss: 0.06150604784488678, acc: 0.9885057210922241)
[2024-11-14 09:12:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:53][root][INFO] - Training Epoch: 2/2, step 5851/16670 completed (loss: 0.30223166942596436, acc: 0.9354838728904724)
[2024-11-14 09:12:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:53][root][INFO] - Training Epoch: 2/2, step 5852/16670 completed (loss: 0.1658087968826294, acc: 0.949367105960846)
[2024-11-14 09:12:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:53][root][INFO] - Training Epoch: 2/2, step 5853/16670 completed (loss: 0.14171051979064941, acc: 0.9873417615890503)
[2024-11-14 09:12:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:54][root][INFO] - Training Epoch: 2/2, step 5854/16670 completed (loss: 0.08359084278345108, acc: 0.9674796462059021)
[2024-11-14 09:12:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:54][root][INFO] - Training Epoch: 2/2, step 5855/16670 completed (loss: 0.210590660572052, acc: 0.9411764740943909)
[2024-11-14 09:12:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:54][root][INFO] - Training Epoch: 2/2, step 5856/16670 completed (loss: 0.18151845037937164, acc: 0.9406392574310303)
[2024-11-14 09:12:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:55][root][INFO] - Training Epoch: 2/2, step 5857/16670 completed (loss: 0.11225404590368271, acc: 0.9670782089233398)
[2024-11-14 09:12:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:55][root][INFO] - Training Epoch: 2/2, step 5858/16670 completed (loss: 0.026375988498330116, acc: 1.0)
[2024-11-14 09:12:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:55][root][INFO] - Training Epoch: 2/2, step 5859/16670 completed (loss: 0.047699734568595886, acc: 0.9846153855323792)
[2024-11-14 09:12:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:56][root][INFO] - Training Epoch: 2/2, step 5860/16670 completed (loss: 0.04280776157975197, acc: 0.9918032884597778)
[2024-11-14 09:12:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:56][root][INFO] - Training Epoch: 2/2, step 5861/16670 completed (loss: 0.11291857063770294, acc: 0.9655172228813171)
[2024-11-14 09:12:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:56][root][INFO] - Training Epoch: 2/2, step 5862/16670 completed (loss: 0.25445428490638733, acc: 0.9415584206581116)
[2024-11-14 09:12:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:57][root][INFO] - Training Epoch: 2/2, step 5863/16670 completed (loss: 0.09413677453994751, acc: 0.988095223903656)
[2024-11-14 09:12:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:57][root][INFO] - Training Epoch: 2/2, step 5864/16670 completed (loss: 0.06454984843730927, acc: 0.9789473414421082)
[2024-11-14 09:12:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:57][root][INFO] - Training Epoch: 2/2, step 5865/16670 completed (loss: 0.23495496809482574, acc: 0.963350772857666)
[2024-11-14 09:12:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:57][root][INFO] - Training Epoch: 2/2, step 5866/16670 completed (loss: 0.06630952656269073, acc: 0.9756097793579102)
[2024-11-14 09:12:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:58][root][INFO] - Training Epoch: 2/2, step 5867/16670 completed (loss: 0.16405528783798218, acc: 0.9444444179534912)
[2024-11-14 09:12:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:58][root][INFO] - Training Epoch: 2/2, step 5868/16670 completed (loss: 0.08084578067064285, acc: 0.9685039520263672)
[2024-11-14 09:12:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:58][root][INFO] - Training Epoch: 2/2, step 5869/16670 completed (loss: 0.11897177249193192, acc: 0.9622641801834106)
[2024-11-14 09:12:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:59][root][INFO] - Training Epoch: 2/2, step 5870/16670 completed (loss: 0.0784277692437172, acc: 0.9775784611701965)
[2024-11-14 09:12:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:59][root][INFO] - Training Epoch: 2/2, step 5871/16670 completed (loss: 0.2009364366531372, acc: 0.9610389471054077)
[2024-11-14 09:12:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:12:59][root][INFO] - Training Epoch: 2/2, step 5872/16670 completed (loss: 0.04272003471851349, acc: 0.9925925731658936)
[2024-11-14 09:13:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:00][root][INFO] - Training Epoch: 2/2, step 5873/16670 completed (loss: 0.006942882668226957, acc: 1.0)
[2024-11-14 09:13:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:00][root][INFO] - Training Epoch: 2/2, step 5874/16670 completed (loss: 0.15345746278762817, acc: 0.9583333134651184)
[2024-11-14 09:13:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:00][root][INFO] - Training Epoch: 2/2, step 5875/16670 completed (loss: 0.13744710385799408, acc: 0.9626865386962891)
[2024-11-14 09:13:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:01][root][INFO] - Training Epoch: 2/2, step 5876/16670 completed (loss: 0.17623929679393768, acc: 0.9372549057006836)
[2024-11-14 09:13:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:01][root][INFO] - Training Epoch: 2/2, step 5877/16670 completed (loss: 0.11800573021173477, acc: 0.96875)
[2024-11-14 09:13:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:01][root][INFO] - Training Epoch: 2/2, step 5878/16670 completed (loss: 0.1321392059326172, acc: 0.9805825352668762)
[2024-11-14 09:13:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:02][root][INFO] - Training Epoch: 2/2, step 5879/16670 completed (loss: 0.139678493142128, acc: 0.9433962106704712)
[2024-11-14 09:13:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:02][root][INFO] - Training Epoch: 2/2, step 5880/16670 completed (loss: 0.2341725379228592, acc: 0.9253731369972229)
[2024-11-14 09:13:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:02][root][INFO] - Training Epoch: 2/2, step 5881/16670 completed (loss: 0.19276459515094757, acc: 0.9289617538452148)
[2024-11-14 09:13:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:03][root][INFO] - Training Epoch: 2/2, step 5882/16670 completed (loss: 0.214151069521904, acc: 0.9571428298950195)
[2024-11-14 09:13:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:03][root][INFO] - Training Epoch: 2/2, step 5883/16670 completed (loss: 0.3112970292568207, acc: 0.9275362491607666)
[2024-11-14 09:13:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:03][root][INFO] - Training Epoch: 2/2, step 5884/16670 completed (loss: 0.058151453733444214, acc: 0.9818181991577148)
[2024-11-14 09:13:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:04][root][INFO] - Training Epoch: 2/2, step 5885/16670 completed (loss: 0.45292529463768005, acc: 0.9056603908538818)
[2024-11-14 09:13:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:04][root][INFO] - Training Epoch: 2/2, step 5886/16670 completed (loss: 0.14085300266742706, acc: 0.9666666388511658)
[2024-11-14 09:13:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:04][root][INFO] - Training Epoch: 2/2, step 5887/16670 completed (loss: 0.07231734693050385, acc: 0.9902912378311157)
[2024-11-14 09:13:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:05][root][INFO] - Training Epoch: 2/2, step 5888/16670 completed (loss: 0.06125105172395706, acc: 0.988095223903656)
[2024-11-14 09:13:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:05][root][INFO] - Training Epoch: 2/2, step 5889/16670 completed (loss: 0.16507959365844727, acc: 0.9652174115180969)
[2024-11-14 09:13:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:06][root][INFO] - Training Epoch: 2/2, step 5890/16670 completed (loss: 0.06829487532377243, acc: 0.9830508232116699)
[2024-11-14 09:13:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:06][root][INFO] - Training Epoch: 2/2, step 5891/16670 completed (loss: 0.13070328533649445, acc: 0.9821428656578064)
[2024-11-14 09:13:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:06][root][INFO] - Training Epoch: 2/2, step 5892/16670 completed (loss: 0.10818207263946533, acc: 0.9646464586257935)
[2024-11-14 09:13:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:07][root][INFO] - Training Epoch: 2/2, step 5893/16670 completed (loss: 0.35304006934165955, acc: 0.9102563858032227)
[2024-11-14 09:13:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:07][root][INFO] - Training Epoch: 2/2, step 5894/16670 completed (loss: 0.0570119246840477, acc: 0.9860140085220337)
[2024-11-14 09:13:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:07][root][INFO] - Training Epoch: 2/2, step 5895/16670 completed (loss: 0.20865370333194733, acc: 0.9568965435028076)
[2024-11-14 09:13:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:08][root][INFO] - Training Epoch: 2/2, step 5896/16670 completed (loss: 0.19754092395305634, acc: 0.939393937587738)
[2024-11-14 09:13:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:08][root][INFO] - Training Epoch: 2/2, step 5897/16670 completed (loss: 0.13313210010528564, acc: 0.9767441749572754)
[2024-11-14 09:13:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:08][root][INFO] - Training Epoch: 2/2, step 5898/16670 completed (loss: 0.17473793029785156, acc: 0.9152542352676392)
[2024-11-14 09:13:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:09][root][INFO] - Training Epoch: 2/2, step 5899/16670 completed (loss: 0.13058529794216156, acc: 0.9464285969734192)
[2024-11-14 09:13:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:09][root][INFO] - Training Epoch: 2/2, step 5900/16670 completed (loss: 0.13667571544647217, acc: 0.9727272987365723)
[2024-11-14 09:13:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:09][root][INFO] - Training Epoch: 2/2, step 5901/16670 completed (loss: 0.10322604328393936, acc: 0.9577465057373047)
[2024-11-14 09:13:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:10][root][INFO] - Training Epoch: 2/2, step 5902/16670 completed (loss: 0.13358990848064423, acc: 0.9520000219345093)
[2024-11-14 09:13:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:10][root][INFO] - Training Epoch: 2/2, step 5903/16670 completed (loss: 0.14499908685684204, acc: 0.961904764175415)
[2024-11-14 09:13:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:10][root][INFO] - Training Epoch: 2/2, step 5904/16670 completed (loss: 0.14604488015174866, acc: 0.9716981053352356)
[2024-11-14 09:13:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:11][root][INFO] - Training Epoch: 2/2, step 5905/16670 completed (loss: 0.12028612941503525, acc: 0.9818181991577148)
[2024-11-14 09:13:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:11][root][INFO] - Training Epoch: 2/2, step 5906/16670 completed (loss: 0.08395492285490036, acc: 0.9806451797485352)
[2024-11-14 09:13:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:11][root][INFO] - Training Epoch: 2/2, step 5907/16670 completed (loss: 0.12156058847904205, acc: 0.9780219793319702)
[2024-11-14 09:13:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:12][root][INFO] - Training Epoch: 2/2, step 5908/16670 completed (loss: 0.28038525581359863, acc: 0.9230769276618958)
[2024-11-14 09:13:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:12][root][INFO] - Training Epoch: 2/2, step 5909/16670 completed (loss: 0.11722692847251892, acc: 0.9745762944221497)
[2024-11-14 09:13:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:13][root][INFO] - Training Epoch: 2/2, step 5910/16670 completed (loss: 0.1812966763973236, acc: 0.9482758641242981)
[2024-11-14 09:13:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:13][root][INFO] - Training Epoch: 2/2, step 5911/16670 completed (loss: 0.18176282942295074, acc: 0.9772727489471436)
[2024-11-14 09:13:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:13][root][INFO] - Training Epoch: 2/2, step 5912/16670 completed (loss: 0.1711028665304184, acc: 0.9560439586639404)
[2024-11-14 09:13:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:14][root][INFO] - Training Epoch: 2/2, step 5913/16670 completed (loss: 0.1317676454782486, acc: 0.96517413854599)
[2024-11-14 09:13:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:14][root][INFO] - Training Epoch: 2/2, step 5914/16670 completed (loss: 0.08389948308467865, acc: 0.965753436088562)
[2024-11-14 09:13:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:14][root][INFO] - Training Epoch: 2/2, step 5915/16670 completed (loss: 0.376537024974823, acc: 0.8925619721412659)
[2024-11-14 09:13:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:15][root][INFO] - Training Epoch: 2/2, step 5916/16670 completed (loss: 0.12582744657993317, acc: 0.9746835231781006)
[2024-11-14 09:13:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:15][root][INFO] - Training Epoch: 2/2, step 5917/16670 completed (loss: 0.23871231079101562, acc: 0.9338235259056091)
[2024-11-14 09:13:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:15][root][INFO] - Training Epoch: 2/2, step 5918/16670 completed (loss: 0.13556228578090668, acc: 0.9636363387107849)
[2024-11-14 09:13:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:16][root][INFO] - Training Epoch: 2/2, step 5919/16670 completed (loss: 0.08365924656391144, acc: 0.9661017060279846)
[2024-11-14 09:13:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:16][root][INFO] - Training Epoch: 2/2, step 5920/16670 completed (loss: 0.10270936787128448, acc: 0.9764150977134705)
[2024-11-14 09:13:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:16][root][INFO] - Training Epoch: 2/2, step 5921/16670 completed (loss: 0.2519690990447998, acc: 0.929729700088501)
[2024-11-14 09:13:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:17][root][INFO] - Training Epoch: 2/2, step 5922/16670 completed (loss: 0.08360279351472855, acc: 0.9760765433311462)
[2024-11-14 09:13:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:17][root][INFO] - Training Epoch: 2/2, step 5923/16670 completed (loss: 0.12739253044128418, acc: 0.9624060392379761)
[2024-11-14 09:13:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:17][root][INFO] - Training Epoch: 2/2, step 5924/16670 completed (loss: 0.05990559980273247, acc: 0.982300877571106)
[2024-11-14 09:13:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:18][root][INFO] - Training Epoch: 2/2, step 5925/16670 completed (loss: 0.16860520839691162, acc: 0.9718309640884399)
[2024-11-14 09:13:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:18][root][INFO] - Training Epoch: 2/2, step 5926/16670 completed (loss: 0.06462278962135315, acc: 0.978723406791687)
[2024-11-14 09:13:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:19][root][INFO] - Training Epoch: 2/2, step 5927/16670 completed (loss: 0.13788828253746033, acc: 0.9591836929321289)
[2024-11-14 09:13:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:19][root][INFO] - Training Epoch: 2/2, step 5928/16670 completed (loss: 0.3487360179424286, acc: 0.9066666960716248)
[2024-11-14 09:13:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:19][root][INFO] - Training Epoch: 2/2, step 5929/16670 completed (loss: 0.14703263342380524, acc: 0.9444444179534912)
[2024-11-14 09:13:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:20][root][INFO] - Training Epoch: 2/2, step 5930/16670 completed (loss: 0.13988034427165985, acc: 0.931034505367279)
[2024-11-14 09:13:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:20][root][INFO] - Training Epoch: 2/2, step 5931/16670 completed (loss: 0.16508328914642334, acc: 0.9491525292396545)
[2024-11-14 09:13:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:20][root][INFO] - Training Epoch: 2/2, step 5932/16670 completed (loss: 0.14538443088531494, acc: 0.9558823704719543)
[2024-11-14 09:13:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:21][root][INFO] - Training Epoch: 2/2, step 5933/16670 completed (loss: 0.07443340867757797, acc: 0.9708737730979919)
[2024-11-14 09:13:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:21][root][INFO] - Training Epoch: 2/2, step 5934/16670 completed (loss: 0.24690023064613342, acc: 0.9333333373069763)
[2024-11-14 09:13:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:21][root][INFO] - Training Epoch: 2/2, step 5935/16670 completed (loss: 0.02682315744459629, acc: 0.9941860437393188)
[2024-11-14 09:13:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:22][root][INFO] - Training Epoch: 2/2, step 5936/16670 completed (loss: 0.25295552611351013, acc: 0.9473684430122375)
[2024-11-14 09:13:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:22][root][INFO] - Training Epoch: 2/2, step 5937/16670 completed (loss: 0.16166529059410095, acc: 0.9642857313156128)
[2024-11-14 09:13:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:23][root][INFO] - Training Epoch: 2/2, step 5938/16670 completed (loss: 0.15706150233745575, acc: 0.9444444179534912)
[2024-11-14 09:13:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:23][root][INFO] - Training Epoch: 2/2, step 5939/16670 completed (loss: 0.12424014508724213, acc: 0.9661017060279846)
[2024-11-14 09:13:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:23][root][INFO] - Training Epoch: 2/2, step 5940/16670 completed (loss: 0.25637200474739075, acc: 0.9387755393981934)
[2024-11-14 09:13:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:24][root][INFO] - Training Epoch: 2/2, step 5941/16670 completed (loss: 0.07954621315002441, acc: 0.9696969985961914)
[2024-11-14 09:13:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:24][root][INFO] - Training Epoch: 2/2, step 5942/16670 completed (loss: 0.10393059998750687, acc: 0.9745762944221497)
[2024-11-14 09:13:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:24][root][INFO] - Training Epoch: 2/2, step 5943/16670 completed (loss: 0.16064517199993134, acc: 0.9553571343421936)
[2024-11-14 09:13:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:25][root][INFO] - Training Epoch: 2/2, step 5944/16670 completed (loss: 0.27576392889022827, acc: 0.9105691313743591)
[2024-11-14 09:13:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:25][root][INFO] - Training Epoch: 2/2, step 5945/16670 completed (loss: 0.17086417973041534, acc: 0.9647058844566345)
[2024-11-14 09:13:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:25][root][INFO] - Training Epoch: 2/2, step 5946/16670 completed (loss: 0.13333657383918762, acc: 0.9520547986030579)
[2024-11-14 09:13:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:26][root][INFO] - Training Epoch: 2/2, step 5947/16670 completed (loss: 0.10334683954715729, acc: 0.9756097793579102)
[2024-11-14 09:13:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:26][root][INFO] - Training Epoch: 2/2, step 5948/16670 completed (loss: 0.08936531841754913, acc: 0.9629629850387573)
[2024-11-14 09:13:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:26][root][INFO] - Training Epoch: 2/2, step 5949/16670 completed (loss: 0.22087810933589935, acc: 0.9491525292396545)
[2024-11-14 09:13:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:27][root][INFO] - Training Epoch: 2/2, step 5950/16670 completed (loss: 0.10162530839443207, acc: 0.9807692170143127)
[2024-11-14 09:13:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:27][root][INFO] - Training Epoch: 2/2, step 5951/16670 completed (loss: 0.11948654055595398, acc: 0.9817073345184326)
[2024-11-14 09:13:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:27][root][INFO] - Training Epoch: 2/2, step 5952/16670 completed (loss: 0.10054067522287369, acc: 0.9529411792755127)
[2024-11-14 09:13:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:28][root][INFO] - Training Epoch: 2/2, step 5953/16670 completed (loss: 0.22692567110061646, acc: 0.9514563083648682)
[2024-11-14 09:13:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:28][root][INFO] - Training Epoch: 2/2, step 5954/16670 completed (loss: 0.03287393972277641, acc: 0.9901960492134094)
[2024-11-14 09:13:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:28][root][INFO] - Training Epoch: 2/2, step 5955/16670 completed (loss: 0.15337985754013062, acc: 0.9622641801834106)
[2024-11-14 09:13:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:29][root][INFO] - Training Epoch: 2/2, step 5956/16670 completed (loss: 0.27101200819015503, acc: 0.9482758641242981)
[2024-11-14 09:13:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:29][root][INFO] - Training Epoch: 2/2, step 5957/16670 completed (loss: 0.16440428793430328, acc: 0.9444444179534912)
[2024-11-14 09:13:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:29][root][INFO] - Training Epoch: 2/2, step 5958/16670 completed (loss: 0.226701021194458, acc: 0.9289940595626831)
[2024-11-14 09:13:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:29][root][INFO] - Training Epoch: 2/2, step 5959/16670 completed (loss: 0.20346392691135406, acc: 0.942307710647583)
[2024-11-14 09:13:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:30][root][INFO] - Training Epoch: 2/2, step 5960/16670 completed (loss: 0.0805739238858223, acc: 0.9708737730979919)
[2024-11-14 09:13:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:30][root][INFO] - Training Epoch: 2/2, step 5961/16670 completed (loss: 0.03619803860783577, acc: 0.9924812316894531)
[2024-11-14 09:13:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:30][root][INFO] - Training Epoch: 2/2, step 5962/16670 completed (loss: 0.2980084717273712, acc: 0.9122806787490845)
[2024-11-14 09:13:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:31][root][INFO] - Training Epoch: 2/2, step 5963/16670 completed (loss: 0.1542903035879135, acc: 0.9444444179534912)
[2024-11-14 09:13:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:31][root][INFO] - Training Epoch: 2/2, step 5964/16670 completed (loss: 0.08202851563692093, acc: 0.9736841917037964)
[2024-11-14 09:13:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:31][root][INFO] - Training Epoch: 2/2, step 5965/16670 completed (loss: 0.23881544172763824, acc: 0.9322034120559692)
[2024-11-14 09:13:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:32][root][INFO] - Training Epoch: 2/2, step 5966/16670 completed (loss: 0.09019149839878082, acc: 0.9807692170143127)
[2024-11-14 09:13:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:32][root][INFO] - Training Epoch: 2/2, step 5967/16670 completed (loss: 0.16875146329402924, acc: 0.9339622855186462)
[2024-11-14 09:13:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:32][root][INFO] - Training Epoch: 2/2, step 5968/16670 completed (loss: 0.12353228777647018, acc: 0.963302731513977)
[2024-11-14 09:13:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:33][root][INFO] - Training Epoch: 2/2, step 5969/16670 completed (loss: 0.13311734795570374, acc: 0.9797570705413818)
[2024-11-14 09:13:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:33][root][INFO] - Training Epoch: 2/2, step 5970/16670 completed (loss: 0.22631242871284485, acc: 0.948113203048706)
[2024-11-14 09:13:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:33][root][INFO] - Training Epoch: 2/2, step 5971/16670 completed (loss: 0.08667731285095215, acc: 0.965753436088562)
[2024-11-14 09:13:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:34][root][INFO] - Training Epoch: 2/2, step 5972/16670 completed (loss: 0.09176205098628998, acc: 0.9763779640197754)
[2024-11-14 09:13:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:34][root][INFO] - Training Epoch: 2/2, step 5973/16670 completed (loss: 0.21299636363983154, acc: 0.9743589758872986)
[2024-11-14 09:13:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:34][root][INFO] - Training Epoch: 2/2, step 5974/16670 completed (loss: 0.24059560894966125, acc: 0.932330846786499)
[2024-11-14 09:13:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:35][root][INFO] - Training Epoch: 2/2, step 5975/16670 completed (loss: 0.3355201184749603, acc: 0.930232584476471)
[2024-11-14 09:13:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:35][root][INFO] - Training Epoch: 2/2, step 5976/16670 completed (loss: 0.23357398808002472, acc: 0.9349315166473389)
[2024-11-14 09:13:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:35][root][INFO] - Training Epoch: 2/2, step 5977/16670 completed (loss: 0.05268241837620735, acc: 0.9841269850730896)
[2024-11-14 09:13:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:36][root][INFO] - Training Epoch: 2/2, step 5978/16670 completed (loss: 0.27071917057037354, acc: 0.9370629191398621)
[2024-11-14 09:13:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:36][root][INFO] - Training Epoch: 2/2, step 5979/16670 completed (loss: 0.1634148508310318, acc: 0.921875)
[2024-11-14 09:13:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:36][root][INFO] - Training Epoch: 2/2, step 5980/16670 completed (loss: 0.1365813910961151, acc: 0.9432623982429504)
[2024-11-14 09:13:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:37][root][INFO] - Training Epoch: 2/2, step 5981/16670 completed (loss: 0.22594065964221954, acc: 0.9387755393981934)
[2024-11-14 09:13:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:37][root][INFO] - Training Epoch: 2/2, step 5982/16670 completed (loss: 0.2056610882282257, acc: 0.9473684430122375)
[2024-11-14 09:13:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:37][root][INFO] - Training Epoch: 2/2, step 5983/16670 completed (loss: 0.056133776903152466, acc: 0.9819819927215576)
[2024-11-14 09:13:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:37][root][INFO] - Training Epoch: 2/2, step 5984/16670 completed (loss: 0.19208186864852905, acc: 0.9772727489471436)
[2024-11-14 09:13:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:38][root][INFO] - Training Epoch: 2/2, step 5985/16670 completed (loss: 0.15253399312496185, acc: 0.94017094373703)
[2024-11-14 09:13:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:38][root][INFO] - Training Epoch: 2/2, step 5986/16670 completed (loss: 0.15810024738311768, acc: 0.976190447807312)
[2024-11-14 09:13:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:38][root][INFO] - Training Epoch: 2/2, step 5987/16670 completed (loss: 0.051130782812833786, acc: 0.9868420958518982)
[2024-11-14 09:13:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:39][root][INFO] - Training Epoch: 2/2, step 5988/16670 completed (loss: 0.18542198836803436, acc: 0.8999999761581421)
[2024-11-14 09:13:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:39][root][INFO] - Training Epoch: 2/2, step 5989/16670 completed (loss: 0.3295651376247406, acc: 0.9304812550544739)
[2024-11-14 09:13:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:39][root][INFO] - Training Epoch: 2/2, step 5990/16670 completed (loss: 0.22128963470458984, acc: 0.9261363744735718)
[2024-11-14 09:13:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:40][root][INFO] - Training Epoch: 2/2, step 5991/16670 completed (loss: 0.0694851353764534, acc: 0.9795918464660645)
[2024-11-14 09:13:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:40][root][INFO] - Training Epoch: 2/2, step 5992/16670 completed (loss: 0.1385629028081894, acc: 0.9692307710647583)
[2024-11-14 09:13:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:40][root][INFO] - Training Epoch: 2/2, step 5993/16670 completed (loss: 0.02509600669145584, acc: 1.0)
[2024-11-14 09:13:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:41][root][INFO] - Training Epoch: 2/2, step 5994/16670 completed (loss: 0.13266558945178986, acc: 0.9722222089767456)
[2024-11-14 09:13:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:41][root][INFO] - Training Epoch: 2/2, step 5995/16670 completed (loss: 0.1903582215309143, acc: 0.9322034120559692)
[2024-11-14 09:13:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:41][root][INFO] - Training Epoch: 2/2, step 5996/16670 completed (loss: 0.1897129863500595, acc: 0.9469026327133179)
[2024-11-14 09:13:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:42][root][INFO] - Training Epoch: 2/2, step 5997/16670 completed (loss: 0.18909066915512085, acc: 0.9371428489685059)
[2024-11-14 09:13:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:42][root][INFO] - Training Epoch: 2/2, step 5998/16670 completed (loss: 0.08293349295854568, acc: 0.9798657894134521)
[2024-11-14 09:13:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:42][root][INFO] - Training Epoch: 2/2, step 5999/16670 completed (loss: 0.06840801239013672, acc: 0.967391312122345)
[2024-11-14 09:13:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:43][root][INFO] - Training Epoch: 2/2, step 6000/16670 completed (loss: 0.1471756249666214, acc: 0.9512194991111755)
[2024-11-14 09:13:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:43][root][INFO] - Training Epoch: 2/2, step 6001/16670 completed (loss: 0.16272440552711487, acc: 0.9479166865348816)
[2024-11-14 09:13:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:43][root][INFO] - Training Epoch: 2/2, step 6002/16670 completed (loss: 0.14177510142326355, acc: 0.9646017551422119)
[2024-11-14 09:13:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:44][root][INFO] - Training Epoch: 2/2, step 6003/16670 completed (loss: 0.39842450618743896, acc: 0.8405796885490417)
[2024-11-14 09:13:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:44][root][INFO] - Training Epoch: 2/2, step 6004/16670 completed (loss: 0.15769191086292267, acc: 0.9525862336158752)
[2024-11-14 09:13:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:44][root][INFO] - Training Epoch: 2/2, step 6005/16670 completed (loss: 0.3340391218662262, acc: 0.9036144614219666)
[2024-11-14 09:13:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:45][root][INFO] - Training Epoch: 2/2, step 6006/16670 completed (loss: 0.05352091044187546, acc: 0.9855072498321533)
[2024-11-14 09:13:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:45][root][INFO] - Training Epoch: 2/2, step 6007/16670 completed (loss: 0.19924931228160858, acc: 0.9347826242446899)
[2024-11-14 09:13:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:45][root][INFO] - Training Epoch: 2/2, step 6008/16670 completed (loss: 0.09977462142705917, acc: 0.9704433679580688)
[2024-11-14 09:13:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:46][root][INFO] - Training Epoch: 2/2, step 6009/16670 completed (loss: 0.027842972427606583, acc: 1.0)
[2024-11-14 09:13:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:46][root][INFO] - Training Epoch: 2/2, step 6010/16670 completed (loss: 0.25873494148254395, acc: 0.95652174949646)
[2024-11-14 09:13:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:46][root][INFO] - Training Epoch: 2/2, step 6011/16670 completed (loss: 0.24209024012088776, acc: 0.939130425453186)
[2024-11-14 09:13:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:47][root][INFO] - Training Epoch: 2/2, step 6012/16670 completed (loss: 0.14532458782196045, acc: 0.9444444179534912)
[2024-11-14 09:13:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:47][root][INFO] - Training Epoch: 2/2, step 6013/16670 completed (loss: 0.1362026482820511, acc: 0.9617224931716919)
[2024-11-14 09:13:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:47][root][INFO] - Training Epoch: 2/2, step 6014/16670 completed (loss: 0.18111592531204224, acc: 0.939393937587738)
[2024-11-14 09:13:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:48][root][INFO] - Training Epoch: 2/2, step 6015/16670 completed (loss: 0.12526607513427734, acc: 0.9464285969734192)
[2024-11-14 09:13:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:48][root][INFO] - Training Epoch: 2/2, step 6016/16670 completed (loss: 0.17662313580513, acc: 0.9484536051750183)
[2024-11-14 09:13:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:48][root][INFO] - Training Epoch: 2/2, step 6017/16670 completed (loss: 0.05607904866337776, acc: 0.9802631735801697)
[2024-11-14 09:13:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:49][root][INFO] - Training Epoch: 2/2, step 6018/16670 completed (loss: 0.16471968591213226, acc: 0.9428571462631226)
[2024-11-14 09:13:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:49][root][INFO] - Training Epoch: 2/2, step 6019/16670 completed (loss: 0.17871299386024475, acc: 0.9408283829689026)
[2024-11-14 09:13:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:49][root][INFO] - Training Epoch: 2/2, step 6020/16670 completed (loss: 0.09966202080249786, acc: 0.9850746393203735)
[2024-11-14 09:13:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:50][root][INFO] - Training Epoch: 2/2, step 6021/16670 completed (loss: 0.23068147897720337, acc: 0.9090909361839294)
[2024-11-14 09:13:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:50][root][INFO] - Training Epoch: 2/2, step 6022/16670 completed (loss: 0.13462600111961365, acc: 0.9605262875556946)
[2024-11-14 09:13:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:50][root][INFO] - Training Epoch: 2/2, step 6023/16670 completed (loss: 0.30426499247550964, acc: 0.9306930899620056)
[2024-11-14 09:13:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:51][root][INFO] - Training Epoch: 2/2, step 6024/16670 completed (loss: 0.06130219250917435, acc: 0.9851852059364319)
[2024-11-14 09:13:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:51][root][INFO] - Training Epoch: 2/2, step 6025/16670 completed (loss: 0.15193139016628265, acc: 0.9569892287254333)
[2024-11-14 09:13:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:51][root][INFO] - Training Epoch: 2/2, step 6026/16670 completed (loss: 0.28122684359550476, acc: 0.907975435256958)
[2024-11-14 09:13:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:51][root][INFO] - Training Epoch: 2/2, step 6027/16670 completed (loss: 0.173642098903656, acc: 0.949999988079071)
[2024-11-14 09:13:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:52][root][INFO] - Training Epoch: 2/2, step 6028/16670 completed (loss: 0.1758696734905243, acc: 0.9547738432884216)
[2024-11-14 09:13:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:52][root][INFO] - Training Epoch: 2/2, step 6029/16670 completed (loss: 0.05343225225806236, acc: 0.9904761910438538)
[2024-11-14 09:13:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:52][root][INFO] - Training Epoch: 2/2, step 6030/16670 completed (loss: 0.0596507228910923, acc: 0.9878048896789551)
[2024-11-14 09:13:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:53][root][INFO] - Training Epoch: 2/2, step 6031/16670 completed (loss: 0.06620576977729797, acc: 0.9748427867889404)
[2024-11-14 09:13:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:53][root][INFO] - Training Epoch: 2/2, step 6032/16670 completed (loss: 0.12666110694408417, acc: 0.9555555582046509)
[2024-11-14 09:13:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:53][root][INFO] - Training Epoch: 2/2, step 6033/16670 completed (loss: 0.3051176369190216, acc: 0.8974359035491943)
[2024-11-14 09:13:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:54][root][INFO] - Training Epoch: 2/2, step 6034/16670 completed (loss: 0.025644520297646523, acc: 1.0)
[2024-11-14 09:13:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:54][root][INFO] - Training Epoch: 2/2, step 6035/16670 completed (loss: 0.08604931831359863, acc: 0.9642857313156128)
[2024-11-14 09:13:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:54][root][INFO] - Training Epoch: 2/2, step 6036/16670 completed (loss: 0.13463108241558075, acc: 0.9560439586639404)
[2024-11-14 09:13:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:54][root][INFO] - Training Epoch: 2/2, step 6037/16670 completed (loss: 0.009289511479437351, acc: 1.0)
[2024-11-14 09:13:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:55][root][INFO] - Training Epoch: 2/2, step 6038/16670 completed (loss: 0.22586122155189514, acc: 0.90625)
[2024-11-14 09:13:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:55][root][INFO] - Training Epoch: 2/2, step 6039/16670 completed (loss: 0.10481423884630203, acc: 0.9790209531784058)
[2024-11-14 09:13:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:55][root][INFO] - Training Epoch: 2/2, step 6040/16670 completed (loss: 0.10169710963964462, acc: 0.9769585132598877)
[2024-11-14 09:13:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:56][root][INFO] - Training Epoch: 2/2, step 6041/16670 completed (loss: 0.18223321437835693, acc: 0.944915235042572)
[2024-11-14 09:13:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:56][root][INFO] - Training Epoch: 2/2, step 6042/16670 completed (loss: 0.16843661665916443, acc: 0.9607843160629272)
[2024-11-14 09:13:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:56][root][INFO] - Training Epoch: 2/2, step 6043/16670 completed (loss: 0.19008868932724, acc: 0.9622641801834106)
[2024-11-14 09:13:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:57][root][INFO] - Training Epoch: 2/2, step 6044/16670 completed (loss: 0.22441305220127106, acc: 0.9285714030265808)
[2024-11-14 09:13:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:57][root][INFO] - Training Epoch: 2/2, step 6045/16670 completed (loss: 0.2712046504020691, acc: 0.9350649118423462)
[2024-11-14 09:13:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:57][root][INFO] - Training Epoch: 2/2, step 6046/16670 completed (loss: 0.08894350379705429, acc: 0.9831932783126831)
[2024-11-14 09:13:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:58][root][INFO] - Training Epoch: 2/2, step 6047/16670 completed (loss: 0.173589289188385, acc: 0.9567567706108093)
[2024-11-14 09:13:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:58][root][INFO] - Training Epoch: 2/2, step 6048/16670 completed (loss: 0.167521134018898, acc: 0.96875)
[2024-11-14 09:13:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:58][root][INFO] - Training Epoch: 2/2, step 6049/16670 completed (loss: 0.1985832005739212, acc: 0.9477124214172363)
[2024-11-14 09:13:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:59][root][INFO] - Training Epoch: 2/2, step 6050/16670 completed (loss: 0.07551971822977066, acc: 0.970588207244873)
[2024-11-14 09:13:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:59][root][INFO] - Training Epoch: 2/2, step 6051/16670 completed (loss: 0.20342664420604706, acc: 0.9649122953414917)
[2024-11-14 09:13:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:13:59][root][INFO] - Training Epoch: 2/2, step 6052/16670 completed (loss: 0.06017576903104782, acc: 0.9795918464660645)
[2024-11-14 09:13:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:00][root][INFO] - Training Epoch: 2/2, step 6053/16670 completed (loss: 0.20879286527633667, acc: 0.9357798099517822)
[2024-11-14 09:14:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:00][root][INFO] - Training Epoch: 2/2, step 6054/16670 completed (loss: 0.5221973657608032, acc: 0.849056601524353)
[2024-11-14 09:14:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:00][root][INFO] - Training Epoch: 2/2, step 6055/16670 completed (loss: 0.40090128779411316, acc: 0.9061371684074402)
[2024-11-14 09:14:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:01][root][INFO] - Training Epoch: 2/2, step 6056/16670 completed (loss: 0.08436048775911331, acc: 0.9712918400764465)
[2024-11-14 09:14:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:01][root][INFO] - Training Epoch: 2/2, step 6057/16670 completed (loss: 0.15250270068645477, acc: 0.9689440727233887)
[2024-11-14 09:14:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:01][root][INFO] - Training Epoch: 2/2, step 6058/16670 completed (loss: 0.08947522938251495, acc: 0.9680851101875305)
[2024-11-14 09:14:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:01][root][INFO] - Training Epoch: 2/2, step 6059/16670 completed (loss: 0.15773141384124756, acc: 0.9577465057373047)
[2024-11-14 09:14:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:02][root][INFO] - Training Epoch: 2/2, step 6060/16670 completed (loss: 0.3093404173851013, acc: 0.914893627166748)
[2024-11-14 09:14:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:02][root][INFO] - Training Epoch: 2/2, step 6061/16670 completed (loss: 0.19885557889938354, acc: 0.9378238320350647)
[2024-11-14 09:14:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:02][root][INFO] - Training Epoch: 2/2, step 6062/16670 completed (loss: 0.2057148963212967, acc: 0.9354838728904724)
[2024-11-14 09:14:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:03][root][INFO] - Training Epoch: 2/2, step 6063/16670 completed (loss: 0.2956024706363678, acc: 0.9198113083839417)
[2024-11-14 09:14:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:03][root][INFO] - Training Epoch: 2/2, step 6064/16670 completed (loss: 0.12219317257404327, acc: 0.9704142212867737)
[2024-11-14 09:14:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:03][root][INFO] - Training Epoch: 2/2, step 6065/16670 completed (loss: 0.41981709003448486, acc: 0.8426966071128845)
[2024-11-14 09:14:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:04][root][INFO] - Training Epoch: 2/2, step 6066/16670 completed (loss: 0.3033384382724762, acc: 0.9222519993782043)
[2024-11-14 09:14:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:04][root][INFO] - Training Epoch: 2/2, step 6067/16670 completed (loss: 0.4165741503238678, acc: 0.8996139168739319)
[2024-11-14 09:14:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:04][root][INFO] - Training Epoch: 2/2, step 6068/16670 completed (loss: 0.1351647973060608, acc: 0.9604316353797913)
[2024-11-14 09:14:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:05][root][INFO] - Training Epoch: 2/2, step 6069/16670 completed (loss: 0.28964850306510925, acc: 0.9328858852386475)
[2024-11-14 09:14:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:05][root][INFO] - Training Epoch: 2/2, step 6070/16670 completed (loss: 0.2898455262184143, acc: 0.9132652878761292)
[2024-11-14 09:14:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:05][root][INFO] - Training Epoch: 2/2, step 6071/16670 completed (loss: 0.26752427220344543, acc: 0.9127516746520996)
[2024-11-14 09:14:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:06][root][INFO] - Training Epoch: 2/2, step 6072/16670 completed (loss: 0.16674409806728363, acc: 0.9346405267715454)
[2024-11-14 09:14:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:06][root][INFO] - Training Epoch: 2/2, step 6073/16670 completed (loss: 0.3972736597061157, acc: 0.8951964974403381)
[2024-11-14 09:14:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:06][root][INFO] - Training Epoch: 2/2, step 6074/16670 completed (loss: 0.11518584936857224, acc: 0.9515151381492615)
[2024-11-14 09:14:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:07][root][INFO] - Training Epoch: 2/2, step 6075/16670 completed (loss: 0.18530049920082092, acc: 0.9605911374092102)
[2024-11-14 09:14:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:07][root][INFO] - Training Epoch: 2/2, step 6076/16670 completed (loss: 0.059067606925964355, acc: 0.9729729890823364)
[2024-11-14 09:14:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:07][root][INFO] - Training Epoch: 2/2, step 6077/16670 completed (loss: 0.20514485239982605, acc: 0.9262672662734985)
[2024-11-14 09:14:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:08][root][INFO] - Training Epoch: 2/2, step 6078/16670 completed (loss: 0.380262166261673, acc: 0.899328887462616)
[2024-11-14 09:14:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:08][root][INFO] - Training Epoch: 2/2, step 6079/16670 completed (loss: 0.3139384984970093, acc: 0.9069767594337463)
[2024-11-14 09:14:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:08][root][INFO] - Training Epoch: 2/2, step 6080/16670 completed (loss: 0.15056933462619781, acc: 0.9535865187644958)
[2024-11-14 09:14:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:09][root][INFO] - Training Epoch: 2/2, step 6081/16670 completed (loss: 0.31676754355430603, acc: 0.9666666388511658)
[2024-11-14 09:14:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:09][root][INFO] - Training Epoch: 2/2, step 6082/16670 completed (loss: 0.7387317419052124, acc: 0.8620689511299133)
[2024-11-14 09:14:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:09][root][INFO] - Training Epoch: 2/2, step 6083/16670 completed (loss: 0.054163478314876556, acc: 1.0)
[2024-11-14 09:14:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:10][root][INFO] - Training Epoch: 2/2, step 6084/16670 completed (loss: 0.30046507716178894, acc: 0.9069767594337463)
[2024-11-14 09:14:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:10][root][INFO] - Training Epoch: 2/2, step 6085/16670 completed (loss: 0.6555522680282593, acc: 0.8409090638160706)
[2024-11-14 09:14:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:10][root][INFO] - Training Epoch: 2/2, step 6086/16670 completed (loss: 0.48243075609207153, acc: 0.8837209343910217)
[2024-11-14 09:14:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:11][root][INFO] - Training Epoch: 2/2, step 6087/16670 completed (loss: 0.3451407551765442, acc: 0.9491525292396545)
[2024-11-14 09:14:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:11][root][INFO] - Training Epoch: 2/2, step 6088/16670 completed (loss: 0.5022920966148376, acc: 0.931034505367279)
[2024-11-14 09:14:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:11][root][INFO] - Training Epoch: 2/2, step 6089/16670 completed (loss: 0.060827068984508514, acc: 1.0)
[2024-11-14 09:14:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:12][root][INFO] - Training Epoch: 2/2, step 6090/16670 completed (loss: 0.21534523367881775, acc: 0.9152542352676392)
[2024-11-14 09:14:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:12][root][INFO] - Training Epoch: 2/2, step 6091/16670 completed (loss: 0.4077795743942261, acc: 0.8524590134620667)
[2024-11-14 09:14:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:12][root][INFO] - Training Epoch: 2/2, step 6092/16670 completed (loss: 0.4254835844039917, acc: 0.8823529481887817)
[2024-11-14 09:14:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:13][root][INFO] - Training Epoch: 2/2, step 6093/16670 completed (loss: 0.47729089856147766, acc: 0.8857142925262451)
[2024-11-14 09:14:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:13][root][INFO] - Training Epoch: 2/2, step 6094/16670 completed (loss: 0.07280915975570679, acc: 1.0)
[2024-11-14 09:14:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:13][root][INFO] - Training Epoch: 2/2, step 6095/16670 completed (loss: 0.4628712832927704, acc: 0.9024389982223511)
[2024-11-14 09:14:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:14][root][INFO] - Training Epoch: 2/2, step 6096/16670 completed (loss: 0.3637520968914032, acc: 0.9464285969734192)
[2024-11-14 09:14:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:14][root][INFO] - Training Epoch: 2/2, step 6097/16670 completed (loss: 0.3366685211658478, acc: 0.9200000166893005)
[2024-11-14 09:14:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:14][root][INFO] - Training Epoch: 2/2, step 6098/16670 completed (loss: 0.48867031931877136, acc: 0.9069767594337463)
[2024-11-14 09:14:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:15][root][INFO] - Training Epoch: 2/2, step 6099/16670 completed (loss: 0.37481775879859924, acc: 0.8095238208770752)
[2024-11-14 09:14:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:15][root][INFO] - Training Epoch: 2/2, step 6100/16670 completed (loss: 0.4935089945793152, acc: 0.8461538553237915)
[2024-11-14 09:14:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:15][root][INFO] - Training Epoch: 2/2, step 6101/16670 completed (loss: 0.1167444959282875, acc: 0.9750000238418579)
[2024-11-14 09:14:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:16][root][INFO] - Training Epoch: 2/2, step 6102/16670 completed (loss: 0.06544745713472366, acc: 0.9814814925193787)
[2024-11-14 09:14:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:16][root][INFO] - Training Epoch: 2/2, step 6103/16670 completed (loss: 0.08752452582120895, acc: 0.9803921580314636)
[2024-11-14 09:14:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:16][root][INFO] - Training Epoch: 2/2, step 6104/16670 completed (loss: 0.14882130920886993, acc: 0.9523809552192688)
[2024-11-14 09:14:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:17][root][INFO] - Training Epoch: 2/2, step 6105/16670 completed (loss: 0.19199465215206146, acc: 0.9677419066429138)
[2024-11-14 09:14:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:17][root][INFO] - Training Epoch: 2/2, step 6106/16670 completed (loss: 0.23827145993709564, acc: 0.9344262480735779)
[2024-11-14 09:14:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:17][root][INFO] - Training Epoch: 2/2, step 6107/16670 completed (loss: 0.08462211489677429, acc: 0.970588207244873)
[2024-11-14 09:14:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:18][root][INFO] - Training Epoch: 2/2, step 6108/16670 completed (loss: 0.42811039090156555, acc: 0.8979591727256775)
[2024-11-14 09:14:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:18][root][INFO] - Training Epoch: 2/2, step 6109/16670 completed (loss: 0.09482826292514801, acc: 0.9655172228813171)
[2024-11-14 09:14:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:18][root][INFO] - Training Epoch: 2/2, step 6110/16670 completed (loss: 0.7245495319366455, acc: 0.7872340679168701)
[2024-11-14 09:14:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:19][root][INFO] - Training Epoch: 2/2, step 6111/16670 completed (loss: 0.34212610125541687, acc: 0.892307698726654)
[2024-11-14 09:14:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:19][root][INFO] - Training Epoch: 2/2, step 6112/16670 completed (loss: 0.43213513493537903, acc: 0.9268292784690857)
[2024-11-14 09:14:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:19][root][INFO] - Training Epoch: 2/2, step 6113/16670 completed (loss: 0.5466684699058533, acc: 0.875)
[2024-11-14 09:14:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:20][root][INFO] - Training Epoch: 2/2, step 6114/16670 completed (loss: 0.33373183012008667, acc: 0.9230769276618958)
[2024-11-14 09:14:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:20][root][INFO] - Training Epoch: 2/2, step 6115/16670 completed (loss: 0.5112353563308716, acc: 0.8730158805847168)
[2024-11-14 09:14:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:20][root][INFO] - Training Epoch: 2/2, step 6116/16670 completed (loss: 0.3641098439693451, acc: 0.9523809552192688)
[2024-11-14 09:14:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:21][root][INFO] - Training Epoch: 2/2, step 6117/16670 completed (loss: 0.08497659862041473, acc: 0.9718309640884399)
[2024-11-14 09:14:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:21][root][INFO] - Training Epoch: 2/2, step 6118/16670 completed (loss: 0.13020573556423187, acc: 0.9666666388511658)
[2024-11-14 09:14:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:21][root][INFO] - Training Epoch: 2/2, step 6119/16670 completed (loss: 0.11995099484920502, acc: 0.9756097793579102)
[2024-11-14 09:14:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:22][root][INFO] - Training Epoch: 2/2, step 6120/16670 completed (loss: 0.42832714319229126, acc: 0.918367326259613)
[2024-11-14 09:14:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:22][root][INFO] - Training Epoch: 2/2, step 6121/16670 completed (loss: 0.2985042333602905, acc: 0.9298245906829834)
[2024-11-14 09:14:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:22][root][INFO] - Training Epoch: 2/2, step 6122/16670 completed (loss: 0.49656349420547485, acc: 0.8666666746139526)
[2024-11-14 09:14:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:23][root][INFO] - Training Epoch: 2/2, step 6123/16670 completed (loss: 0.04933980107307434, acc: 1.0)
[2024-11-14 09:14:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:23][root][INFO] - Training Epoch: 2/2, step 6124/16670 completed (loss: 0.3081788718700409, acc: 0.9074074029922485)
[2024-11-14 09:14:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:23][root][INFO] - Training Epoch: 2/2, step 6125/16670 completed (loss: 0.5213019847869873, acc: 0.8611111044883728)
[2024-11-14 09:14:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:24][root][INFO] - Training Epoch: 2/2, step 6126/16670 completed (loss: 0.14074696600437164, acc: 0.9655172228813171)
[2024-11-14 09:14:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:24][root][INFO] - Training Epoch: 2/2, step 6127/16670 completed (loss: 0.23412004113197327, acc: 0.9189189076423645)
[2024-11-14 09:14:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:24][root][INFO] - Training Epoch: 2/2, step 6128/16670 completed (loss: 0.3359374403953552, acc: 0.9365079402923584)
[2024-11-14 09:14:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:25][root][INFO] - Training Epoch: 2/2, step 6129/16670 completed (loss: 0.12263253331184387, acc: 0.9811320900917053)
[2024-11-14 09:14:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:25][root][INFO] - Training Epoch: 2/2, step 6130/16670 completed (loss: 0.20765568315982819, acc: 0.9583333134651184)
[2024-11-14 09:14:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:25][root][INFO] - Training Epoch: 2/2, step 6131/16670 completed (loss: 0.2634017765522003, acc: 0.8979591727256775)
[2024-11-14 09:14:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:26][root][INFO] - Training Epoch: 2/2, step 6132/16670 completed (loss: 0.49122926592826843, acc: 0.9137930870056152)
[2024-11-14 09:14:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:26][root][INFO] - Training Epoch: 2/2, step 6133/16670 completed (loss: 0.16351214051246643, acc: 0.9818181991577148)
[2024-11-14 09:14:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:26][root][INFO] - Training Epoch: 2/2, step 6134/16670 completed (loss: 0.849147617816925, acc: 0.8133333325386047)
[2024-11-14 09:14:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:27][root][INFO] - Training Epoch: 2/2, step 6135/16670 completed (loss: 0.21109050512313843, acc: 0.931034505367279)
[2024-11-14 09:14:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:27][root][INFO] - Training Epoch: 2/2, step 6136/16670 completed (loss: 0.2945822477340698, acc: 0.9594594836235046)
[2024-11-14 09:14:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:28][root][INFO] - Training Epoch: 2/2, step 6137/16670 completed (loss: 0.5292268395423889, acc: 0.8888888955116272)
[2024-11-14 09:14:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:28][root][INFO] - Training Epoch: 2/2, step 6138/16670 completed (loss: 0.5179173350334167, acc: 0.8837209343910217)
[2024-11-14 09:14:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:28][root][INFO] - Training Epoch: 2/2, step 6139/16670 completed (loss: 0.22340422868728638, acc: 0.9666666388511658)
[2024-11-14 09:14:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:28][root][INFO] - Training Epoch: 2/2, step 6140/16670 completed (loss: 0.2925218939781189, acc: 0.9436619877815247)
[2024-11-14 09:14:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:29][root][INFO] - Training Epoch: 2/2, step 6141/16670 completed (loss: 0.39111965894699097, acc: 0.8775510191917419)
[2024-11-14 09:14:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:29][root][INFO] - Training Epoch: 2/2, step 6142/16670 completed (loss: 0.3243776857852936, acc: 0.9324324131011963)
[2024-11-14 09:14:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:29][root][INFO] - Training Epoch: 2/2, step 6143/16670 completed (loss: 0.0562874861061573, acc: 1.0)
[2024-11-14 09:14:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:30][root][INFO] - Training Epoch: 2/2, step 6144/16670 completed (loss: 0.33338233828544617, acc: 0.9090909361839294)
[2024-11-14 09:14:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:30][root][INFO] - Training Epoch: 2/2, step 6145/16670 completed (loss: 0.354903906583786, acc: 0.9318181872367859)
[2024-11-14 09:14:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:30][root][INFO] - Training Epoch: 2/2, step 6146/16670 completed (loss: 0.5954921841621399, acc: 0.9016393423080444)
[2024-11-14 09:14:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:31][root][INFO] - Training Epoch: 2/2, step 6147/16670 completed (loss: 0.2823626399040222, acc: 0.9558823704719543)
[2024-11-14 09:14:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:31][root][INFO] - Training Epoch: 2/2, step 6148/16670 completed (loss: 0.7683694958686829, acc: 0.8679245114326477)
[2024-11-14 09:14:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:31][root][INFO] - Training Epoch: 2/2, step 6149/16670 completed (loss: 0.10888855159282684, acc: 0.9818181991577148)
[2024-11-14 09:14:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:32][root][INFO] - Training Epoch: 2/2, step 6150/16670 completed (loss: 0.3334706425666809, acc: 0.9180327653884888)
[2024-11-14 09:14:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:32][root][INFO] - Training Epoch: 2/2, step 6151/16670 completed (loss: 0.11600693315267563, acc: 0.95652174949646)
[2024-11-14 09:14:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:32][root][INFO] - Training Epoch: 2/2, step 6152/16670 completed (loss: 0.22102601826190948, acc: 0.9577465057373047)
[2024-11-14 09:14:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:33][root][INFO] - Training Epoch: 2/2, step 6153/16670 completed (loss: 1.1059517860412598, acc: 0.7397260069847107)
[2024-11-14 09:14:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:33][root][INFO] - Training Epoch: 2/2, step 6154/16670 completed (loss: 0.5896323323249817, acc: 0.8474576473236084)
[2024-11-14 09:14:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:34][root][INFO] - Training Epoch: 2/2, step 6155/16670 completed (loss: 0.3884493410587311, acc: 0.9111111164093018)
[2024-11-14 09:14:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:34][root][INFO] - Training Epoch: 2/2, step 6156/16670 completed (loss: 0.27456554770469666, acc: 0.9210526347160339)
[2024-11-14 09:14:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:34][root][INFO] - Training Epoch: 2/2, step 6157/16670 completed (loss: 0.2861793339252472, acc: 0.9090909361839294)
[2024-11-14 09:14:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:35][root][INFO] - Training Epoch: 2/2, step 6158/16670 completed (loss: 0.13871325552463531, acc: 0.970588207244873)
[2024-11-14 09:14:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:35][root][INFO] - Training Epoch: 2/2, step 6159/16670 completed (loss: 0.43360885977745056, acc: 0.8695651888847351)
[2024-11-14 09:14:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:35][root][INFO] - Training Epoch: 2/2, step 6160/16670 completed (loss: 0.7805172801017761, acc: 0.8333333134651184)
[2024-11-14 09:14:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:35][root][INFO] - Training Epoch: 2/2, step 6161/16670 completed (loss: 0.29949426651000977, acc: 0.9454545378684998)
[2024-11-14 09:14:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:36][root][INFO] - Training Epoch: 2/2, step 6162/16670 completed (loss: 0.3677002489566803, acc: 0.9222221970558167)
[2024-11-14 09:14:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:36][root][INFO] - Training Epoch: 2/2, step 6163/16670 completed (loss: 0.4455285668373108, acc: 0.8888888955116272)
[2024-11-14 09:14:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:37][root][INFO] - Training Epoch: 2/2, step 6164/16670 completed (loss: 0.5247558951377869, acc: 0.9245283007621765)
[2024-11-14 09:14:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:37][root][INFO] - Training Epoch: 2/2, step 6165/16670 completed (loss: 0.22957158088684082, acc: 0.9696969985961914)
[2024-11-14 09:14:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:37][root][INFO] - Training Epoch: 2/2, step 6166/16670 completed (loss: 0.331706702709198, acc: 0.939393937587738)
[2024-11-14 09:14:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:38][root][INFO] - Training Epoch: 2/2, step 6167/16670 completed (loss: 0.25361835956573486, acc: 0.9411764740943909)
[2024-11-14 09:14:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:38][root][INFO] - Training Epoch: 2/2, step 6168/16670 completed (loss: 0.3586508631706238, acc: 0.925000011920929)
[2024-11-14 09:14:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:38][root][INFO] - Training Epoch: 2/2, step 6169/16670 completed (loss: 0.05682488903403282, acc: 1.0)
[2024-11-14 09:14:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:39][root][INFO] - Training Epoch: 2/2, step 6170/16670 completed (loss: 0.40257105231285095, acc: 0.9130434989929199)
[2024-11-14 09:14:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:39][root][INFO] - Training Epoch: 2/2, step 6171/16670 completed (loss: 0.4029168486595154, acc: 0.9230769276618958)
[2024-11-14 09:14:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:39][root][INFO] - Training Epoch: 2/2, step 6172/16670 completed (loss: 0.5190408229827881, acc: 0.8227847814559937)
[2024-11-14 09:14:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:40][root][INFO] - Training Epoch: 2/2, step 6173/16670 completed (loss: 0.44355538487434387, acc: 0.8571428656578064)
[2024-11-14 09:14:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:40][root][INFO] - Training Epoch: 2/2, step 6174/16670 completed (loss: 0.6606944799423218, acc: 0.8648648858070374)
[2024-11-14 09:14:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:40][root][INFO] - Training Epoch: 2/2, step 6175/16670 completed (loss: 0.24773478507995605, acc: 0.8999999761581421)
[2024-11-14 09:14:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:41][root][INFO] - Training Epoch: 2/2, step 6176/16670 completed (loss: 0.3091687858104706, acc: 0.9104477763175964)
[2024-11-14 09:14:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:41][root][INFO] - Training Epoch: 2/2, step 6177/16670 completed (loss: 0.329943984746933, acc: 0.9452054500579834)
[2024-11-14 09:14:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:42][root][INFO] - Training Epoch: 2/2, step 6178/16670 completed (loss: 0.1401459127664566, acc: 0.9583333134651184)
[2024-11-14 09:14:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:42][root][INFO] - Training Epoch: 2/2, step 6179/16670 completed (loss: 0.30242958664894104, acc: 0.9074074029922485)
[2024-11-14 09:14:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:42][root][INFO] - Training Epoch: 2/2, step 6180/16670 completed (loss: 0.5278094410896301, acc: 0.9056603908538818)
[2024-11-14 09:14:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:43][root][INFO] - Training Epoch: 2/2, step 6181/16670 completed (loss: 0.759576678276062, acc: 0.824999988079071)
[2024-11-14 09:14:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:43][root][INFO] - Training Epoch: 2/2, step 6182/16670 completed (loss: 0.27567896246910095, acc: 0.9268292784690857)
[2024-11-14 09:14:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:43][root][INFO] - Training Epoch: 2/2, step 6183/16670 completed (loss: 0.7140780687332153, acc: 0.7931034564971924)
[2024-11-14 09:14:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:44][root][INFO] - Training Epoch: 2/2, step 6184/16670 completed (loss: 0.053432147949934006, acc: 1.0)
[2024-11-14 09:14:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:44][root][INFO] - Training Epoch: 2/2, step 6185/16670 completed (loss: 0.6174049377441406, acc: 0.8279569745063782)
[2024-11-14 09:14:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:44][root][INFO] - Training Epoch: 2/2, step 6186/16670 completed (loss: 0.6758543252944946, acc: 0.8139534592628479)
[2024-11-14 09:14:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:45][root][INFO] - Training Epoch: 2/2, step 6187/16670 completed (loss: 0.13211600482463837, acc: 0.9333333373069763)
[2024-11-14 09:14:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:45][root][INFO] - Training Epoch: 2/2, step 6188/16670 completed (loss: 0.7686768770217896, acc: 0.835616409778595)
[2024-11-14 09:14:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:46][root][INFO] - Training Epoch: 2/2, step 6189/16670 completed (loss: 0.5068886876106262, acc: 0.920634925365448)
[2024-11-14 09:14:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:46][root][INFO] - Training Epoch: 2/2, step 6190/16670 completed (loss: 0.4248923361301422, acc: 0.9146341681480408)
[2024-11-14 09:14:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:46][root][INFO] - Training Epoch: 2/2, step 6191/16670 completed (loss: 0.5995190739631653, acc: 0.8857142925262451)
[2024-11-14 09:14:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:47][root][INFO] - Training Epoch: 2/2, step 6192/16670 completed (loss: 0.38985419273376465, acc: 0.9347826242446899)
[2024-11-14 09:14:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:47][root][INFO] - Training Epoch: 2/2, step 6193/16670 completed (loss: 0.16284899413585663, acc: 0.9538461565971375)
[2024-11-14 09:14:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:47][root][INFO] - Training Epoch: 2/2, step 6194/16670 completed (loss: 0.21627183258533478, acc: 0.9245283007621765)
[2024-11-14 09:14:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:48][root][INFO] - Training Epoch: 2/2, step 6195/16670 completed (loss: 0.39289572834968567, acc: 0.8970588445663452)
[2024-11-14 09:14:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:48][root][INFO] - Training Epoch: 2/2, step 6196/16670 completed (loss: 0.17460238933563232, acc: 0.9404761791229248)
[2024-11-14 09:14:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:48][root][INFO] - Training Epoch: 2/2, step 6197/16670 completed (loss: 0.2741197943687439, acc: 0.9019607901573181)
[2024-11-14 09:14:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:49][root][INFO] - Training Epoch: 2/2, step 6198/16670 completed (loss: 0.2534632086753845, acc: 0.9272727370262146)
[2024-11-14 09:14:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:49][root][INFO] - Training Epoch: 2/2, step 6199/16670 completed (loss: 0.19676615297794342, acc: 0.9491525292396545)
[2024-11-14 09:14:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:49][root][INFO] - Training Epoch: 2/2, step 6200/16670 completed (loss: 0.19656576216220856, acc: 1.0)
[2024-11-14 09:14:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:50][root][INFO] - Training Epoch: 2/2, step 6201/16670 completed (loss: 0.06337124854326248, acc: 0.9750000238418579)
[2024-11-14 09:14:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:50][root][INFO] - Training Epoch: 2/2, step 6202/16670 completed (loss: 0.7529320120811462, acc: 0.9069767594337463)
[2024-11-14 09:14:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:50][root][INFO] - Training Epoch: 2/2, step 6203/16670 completed (loss: 0.5129875540733337, acc: 0.9152542352676392)
[2024-11-14 09:14:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:51][root][INFO] - Training Epoch: 2/2, step 6204/16670 completed (loss: 0.18182137608528137, acc: 0.9655172228813171)
[2024-11-14 09:14:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:51][root][INFO] - Training Epoch: 2/2, step 6205/16670 completed (loss: 0.594479501247406, acc: 0.8571428656578064)
[2024-11-14 09:14:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:51][root][INFO] - Training Epoch: 2/2, step 6206/16670 completed (loss: 0.3271400034427643, acc: 0.9240506291389465)
[2024-11-14 09:14:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:52][root][INFO] - Training Epoch: 2/2, step 6207/16670 completed (loss: 0.30666619539260864, acc: 0.8888888955116272)
[2024-11-14 09:14:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:52][root][INFO] - Training Epoch: 2/2, step 6208/16670 completed (loss: 0.2871198058128357, acc: 0.9210526347160339)
[2024-11-14 09:14:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:52][root][INFO] - Training Epoch: 2/2, step 6209/16670 completed (loss: 0.41089195013046265, acc: 0.8999999761581421)
[2024-11-14 09:14:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:53][root][INFO] - Training Epoch: 2/2, step 6210/16670 completed (loss: 0.14157605171203613, acc: 0.9636363387107849)
[2024-11-14 09:14:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:53][root][INFO] - Training Epoch: 2/2, step 6211/16670 completed (loss: 0.20297332108020782, acc: 0.95652174949646)
[2024-11-14 09:14:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:53][root][INFO] - Training Epoch: 2/2, step 6212/16670 completed (loss: 0.3328477442264557, acc: 0.9230769276618958)
[2024-11-14 09:14:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:54][root][INFO] - Training Epoch: 2/2, step 6213/16670 completed (loss: 0.7125019431114197, acc: 0.8279569745063782)
[2024-11-14 09:14:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:54][root][INFO] - Training Epoch: 2/2, step 6214/16670 completed (loss: 0.9796443581581116, acc: 0.7692307829856873)
[2024-11-14 09:14:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:54][root][INFO] - Training Epoch: 2/2, step 6215/16670 completed (loss: 0.4394172728061676, acc: 0.8636363744735718)
[2024-11-14 09:14:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:55][root][INFO] - Training Epoch: 2/2, step 6216/16670 completed (loss: 0.5515016913414001, acc: 0.9230769276618958)
[2024-11-14 09:14:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:55][root][INFO] - Training Epoch: 2/2, step 6217/16670 completed (loss: 0.21161390841007233, acc: 0.9285714030265808)
[2024-11-14 09:14:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:55][root][INFO] - Training Epoch: 2/2, step 6218/16670 completed (loss: 0.49066048860549927, acc: 0.859649121761322)
[2024-11-14 09:14:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:56][root][INFO] - Training Epoch: 2/2, step 6219/16670 completed (loss: 0.2527824342250824, acc: 0.8983050584793091)
[2024-11-14 09:14:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:56][root][INFO] - Training Epoch: 2/2, step 6220/16670 completed (loss: 0.700888991355896, acc: 0.8947368264198303)
[2024-11-14 09:14:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:56][root][INFO] - Training Epoch: 2/2, step 6221/16670 completed (loss: 0.09567689150571823, acc: 0.9230769276618958)
[2024-11-14 09:14:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:57][root][INFO] - Training Epoch: 2/2, step 6222/16670 completed (loss: 0.5859447717666626, acc: 0.8571428656578064)
[2024-11-14 09:14:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:57][root][INFO] - Training Epoch: 2/2, step 6223/16670 completed (loss: 0.18011149764060974, acc: 0.9411764740943909)
[2024-11-14 09:14:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:57][root][INFO] - Training Epoch: 2/2, step 6224/16670 completed (loss: 0.18451355397701263, acc: 0.936170220375061)
[2024-11-14 09:14:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:58][root][INFO] - Training Epoch: 2/2, step 6225/16670 completed (loss: 0.22281748056411743, acc: 0.9295774698257446)
[2024-11-14 09:14:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:58][root][INFO] - Training Epoch: 2/2, step 6226/16670 completed (loss: 0.45038965344429016, acc: 0.898876428604126)
[2024-11-14 09:14:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:58][root][INFO] - Training Epoch: 2/2, step 6227/16670 completed (loss: 0.6653336882591248, acc: 0.8550724387168884)
[2024-11-14 09:14:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:59][root][INFO] - Training Epoch: 2/2, step 6228/16670 completed (loss: 0.6730612516403198, acc: 0.828125)
[2024-11-14 09:14:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:59][root][INFO] - Training Epoch: 2/2, step 6229/16670 completed (loss: 0.2158040851354599, acc: 0.9375)
[2024-11-14 09:14:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:14:59][root][INFO] - Training Epoch: 2/2, step 6230/16670 completed (loss: 0.27386674284935, acc: 0.9215686321258545)
[2024-11-14 09:14:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:00][root][INFO] - Training Epoch: 2/2, step 6231/16670 completed (loss: 0.2686269283294678, acc: 0.9344262480735779)
[2024-11-14 09:15:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:00][root][INFO] - Training Epoch: 2/2, step 6232/16670 completed (loss: 0.20731322467327118, acc: 0.9649122953414917)
[2024-11-14 09:15:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:00][root][INFO] - Training Epoch: 2/2, step 6233/16670 completed (loss: 0.13244503736495972, acc: 0.96875)
[2024-11-14 09:15:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:01][root][INFO] - Training Epoch: 2/2, step 6234/16670 completed (loss: 0.2685762941837311, acc: 0.9411764740943909)
[2024-11-14 09:15:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:01][root][INFO] - Training Epoch: 2/2, step 6235/16670 completed (loss: 0.6723331212997437, acc: 0.8604651093482971)
[2024-11-14 09:15:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:01][root][INFO] - Training Epoch: 2/2, step 6236/16670 completed (loss: 0.3737972378730774, acc: 0.8965517282485962)
[2024-11-14 09:15:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:01][root][INFO] - Training Epoch: 2/2, step 6237/16670 completed (loss: 0.021919691935181618, acc: 1.0)
[2024-11-14 09:15:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:02][root][INFO] - Training Epoch: 2/2, step 6238/16670 completed (loss: 0.3334302008152008, acc: 0.9122806787490845)
[2024-11-14 09:15:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:02][root][INFO] - Training Epoch: 2/2, step 6239/16670 completed (loss: 0.746938943862915, acc: 0.8656716346740723)
[2024-11-14 09:15:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:02][root][INFO] - Training Epoch: 2/2, step 6240/16670 completed (loss: 0.10943829268217087, acc: 0.9473684430122375)
[2024-11-14 09:15:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:03][root][INFO] - Training Epoch: 2/2, step 6241/16670 completed (loss: 0.35306409001350403, acc: 0.9375)
[2024-11-14 09:15:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:03][root][INFO] - Training Epoch: 2/2, step 6242/16670 completed (loss: 0.2527919113636017, acc: 0.9222221970558167)
[2024-11-14 09:15:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:03][root][INFO] - Training Epoch: 2/2, step 6243/16670 completed (loss: 0.37892311811447144, acc: 0.8823529481887817)
[2024-11-14 09:15:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:04][root][INFO] - Training Epoch: 2/2, step 6244/16670 completed (loss: 0.2250427007675171, acc: 0.9285714030265808)
[2024-11-14 09:15:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:04][root][INFO] - Training Epoch: 2/2, step 6245/16670 completed (loss: 0.12060706317424774, acc: 0.9800000190734863)
[2024-11-14 09:15:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:04][root][INFO] - Training Epoch: 2/2, step 6246/16670 completed (loss: 0.6067179441452026, acc: 0.8780487775802612)
[2024-11-14 09:15:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:05][root][INFO] - Training Epoch: 2/2, step 6247/16670 completed (loss: 0.20925407111644745, acc: 0.9722222089767456)
[2024-11-14 09:15:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:05][root][INFO] - Training Epoch: 2/2, step 6248/16670 completed (loss: 0.5192853212356567, acc: 0.841269850730896)
[2024-11-14 09:15:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:05][root][INFO] - Training Epoch: 2/2, step 6249/16670 completed (loss: 0.3765379786491394, acc: 0.9090909361839294)
[2024-11-14 09:15:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:06][root][INFO] - Training Epoch: 2/2, step 6250/16670 completed (loss: 0.8380415439605713, acc: 0.8169013857841492)
[2024-11-14 09:15:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:06][root][INFO] - Training Epoch: 2/2, step 6251/16670 completed (loss: 0.5381878018379211, acc: 0.8723404407501221)
[2024-11-14 09:15:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:06][root][INFO] - Training Epoch: 2/2, step 6252/16670 completed (loss: 0.44000816345214844, acc: 0.8367347121238708)
[2024-11-14 09:15:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:07][root][INFO] - Training Epoch: 2/2, step 6253/16670 completed (loss: 0.5300058722496033, acc: 0.8888888955116272)
[2024-11-14 09:15:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:07][root][INFO] - Training Epoch: 2/2, step 6254/16670 completed (loss: 0.5141935348510742, acc: 0.8245614171028137)
[2024-11-14 09:15:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:07][root][INFO] - Training Epoch: 2/2, step 6255/16670 completed (loss: 0.17523476481437683, acc: 0.9454545378684998)
[2024-11-14 09:15:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:08][root][INFO] - Training Epoch: 2/2, step 6256/16670 completed (loss: 0.29932358860969543, acc: 0.931034505367279)
[2024-11-14 09:15:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:08][root][INFO] - Training Epoch: 2/2, step 6257/16670 completed (loss: 0.42454084753990173, acc: 0.918367326259613)
[2024-11-14 09:15:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:08][root][INFO] - Training Epoch: 2/2, step 6258/16670 completed (loss: 0.218622088432312, acc: 0.9811320900917053)
[2024-11-14 09:15:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:09][root][INFO] - Training Epoch: 2/2, step 6259/16670 completed (loss: 0.3317943215370178, acc: 0.9090909361839294)
[2024-11-14 09:15:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:09][root][INFO] - Training Epoch: 2/2, step 6260/16670 completed (loss: 0.10056126862764359, acc: 0.9714285731315613)
[2024-11-14 09:15:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:09][root][INFO] - Training Epoch: 2/2, step 6261/16670 completed (loss: 0.3895558714866638, acc: 0.8461538553237915)
[2024-11-14 09:15:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:10][root][INFO] - Training Epoch: 2/2, step 6262/16670 completed (loss: 0.053754933178424835, acc: 0.9696969985961914)
[2024-11-14 09:15:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:10][root][INFO] - Training Epoch: 2/2, step 6263/16670 completed (loss: 0.45766666531562805, acc: 0.8888888955116272)
[2024-11-14 09:15:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:10][root][INFO] - Training Epoch: 2/2, step 6264/16670 completed (loss: 0.04658540338277817, acc: 1.0)
[2024-11-14 09:15:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:11][root][INFO] - Training Epoch: 2/2, step 6265/16670 completed (loss: 0.0934123545885086, acc: 1.0)
[2024-11-14 09:15:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:11][root][INFO] - Training Epoch: 2/2, step 6266/16670 completed (loss: 0.35172975063323975, acc: 0.9076923131942749)
[2024-11-14 09:15:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:11][root][INFO] - Training Epoch: 2/2, step 6267/16670 completed (loss: 0.82608962059021, acc: 0.7804877758026123)
[2024-11-14 09:15:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:12][root][INFO] - Training Epoch: 2/2, step 6268/16670 completed (loss: 0.15530075132846832, acc: 0.9545454382896423)
[2024-11-14 09:15:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:12][root][INFO] - Training Epoch: 2/2, step 6269/16670 completed (loss: 0.5562710762023926, acc: 0.8571428656578064)
[2024-11-14 09:15:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:12][root][INFO] - Training Epoch: 2/2, step 6270/16670 completed (loss: 0.30407071113586426, acc: 0.9156626462936401)
[2024-11-14 09:15:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:13][root][INFO] - Training Epoch: 2/2, step 6271/16670 completed (loss: 0.29341375827789307, acc: 0.8888888955116272)
[2024-11-14 09:15:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:13][root][INFO] - Training Epoch: 2/2, step 6272/16670 completed (loss: 0.34486663341522217, acc: 0.8695651888847351)
[2024-11-14 09:15:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:13][root][INFO] - Training Epoch: 2/2, step 6273/16670 completed (loss: 0.21684010326862335, acc: 0.8918918967247009)
[2024-11-14 09:15:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:14][root][INFO] - Training Epoch: 2/2, step 6274/16670 completed (loss: 0.24385936558246613, acc: 0.9714285731315613)
[2024-11-14 09:15:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:14][root][INFO] - Training Epoch: 2/2, step 6275/16670 completed (loss: 0.4334355592727661, acc: 0.891566276550293)
[2024-11-14 09:15:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:14][root][INFO] - Training Epoch: 2/2, step 6276/16670 completed (loss: 0.4809449315071106, acc: 0.8985507488250732)
[2024-11-14 09:15:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:15][root][INFO] - Training Epoch: 2/2, step 6277/16670 completed (loss: 0.2722588777542114, acc: 0.9074074029922485)
[2024-11-14 09:15:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:15][root][INFO] - Training Epoch: 2/2, step 6278/16670 completed (loss: 0.41467922925949097, acc: 0.9268292784690857)
[2024-11-14 09:15:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:16][root][INFO] - Training Epoch: 2/2, step 6279/16670 completed (loss: 0.5740683674812317, acc: 0.8387096524238586)
[2024-11-14 09:15:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:16][root][INFO] - Training Epoch: 2/2, step 6280/16670 completed (loss: 1.082668423652649, acc: 0.800000011920929)
[2024-11-14 09:15:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:16][root][INFO] - Training Epoch: 2/2, step 6281/16670 completed (loss: 0.6935454607009888, acc: 0.7692307829856873)
[2024-11-14 09:15:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:17][root][INFO] - Training Epoch: 2/2, step 6282/16670 completed (loss: 0.9791836738586426, acc: 0.7777777910232544)
[2024-11-14 09:15:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:17][root][INFO] - Training Epoch: 2/2, step 6283/16670 completed (loss: 0.35206425189971924, acc: 0.8888888955116272)
[2024-11-14 09:15:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:17][root][INFO] - Training Epoch: 2/2, step 6284/16670 completed (loss: 0.280265212059021, acc: 0.8999999761581421)
[2024-11-14 09:15:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:18][root][INFO] - Training Epoch: 2/2, step 6285/16670 completed (loss: 0.2333608865737915, acc: 0.9534883499145508)
[2024-11-14 09:15:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:18][root][INFO] - Training Epoch: 2/2, step 6286/16670 completed (loss: 0.2412595897912979, acc: 0.95652174949646)
[2024-11-14 09:15:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:19][root][INFO] - Training Epoch: 2/2, step 6287/16670 completed (loss: 0.5354713201522827, acc: 0.8039215803146362)
[2024-11-14 09:15:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:19][root][INFO] - Training Epoch: 2/2, step 6288/16670 completed (loss: 0.3323887288570404, acc: 0.9056603908538818)
[2024-11-14 09:15:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:19][root][INFO] - Training Epoch: 2/2, step 6289/16670 completed (loss: 0.7351641654968262, acc: 0.8205128312110901)
[2024-11-14 09:15:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:20][root][INFO] - Training Epoch: 2/2, step 6290/16670 completed (loss: 0.5288817882537842, acc: 0.8730158805847168)
[2024-11-14 09:15:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:20][root][INFO] - Training Epoch: 2/2, step 6291/16670 completed (loss: 0.5277814269065857, acc: 0.8983050584793091)
[2024-11-14 09:15:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:20][root][INFO] - Training Epoch: 2/2, step 6292/16670 completed (loss: 0.05149976164102554, acc: 1.0)
[2024-11-14 09:15:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:21][root][INFO] - Training Epoch: 2/2, step 6293/16670 completed (loss: 0.6668026447296143, acc: 0.8589743375778198)
[2024-11-14 09:15:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:21][root][INFO] - Training Epoch: 2/2, step 6294/16670 completed (loss: 0.1907142549753189, acc: 0.9491525292396545)
[2024-11-14 09:15:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:22][root][INFO] - Training Epoch: 2/2, step 6295/16670 completed (loss: 0.7166966199874878, acc: 0.8539325594902039)
[2024-11-14 09:15:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:22][root][INFO] - Training Epoch: 2/2, step 6296/16670 completed (loss: 0.02405381202697754, acc: 1.0)
[2024-11-14 09:15:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:22][root][INFO] - Training Epoch: 2/2, step 6297/16670 completed (loss: 0.5244235992431641, acc: 0.8615384697914124)
[2024-11-14 09:15:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:23][root][INFO] - Training Epoch: 2/2, step 6298/16670 completed (loss: 0.38021302223205566, acc: 0.8809523582458496)
[2024-11-14 09:15:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:23][root][INFO] - Training Epoch: 2/2, step 6299/16670 completed (loss: 0.5409746766090393, acc: 0.8545454740524292)
[2024-11-14 09:15:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:23][root][INFO] - Training Epoch: 2/2, step 6300/16670 completed (loss: 0.7282564640045166, acc: 0.8144329786300659)
[2024-11-14 09:15:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:24][root][INFO] - Training Epoch: 2/2, step 6301/16670 completed (loss: 0.3106204867362976, acc: 0.9200000166893005)
[2024-11-14 09:15:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:24][root][INFO] - Training Epoch: 2/2, step 6302/16670 completed (loss: 0.3582594096660614, acc: 0.9156626462936401)
[2024-11-14 09:15:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:24][root][INFO] - Training Epoch: 2/2, step 6303/16670 completed (loss: 1.2099491357803345, acc: 0.7763158082962036)
[2024-11-14 09:15:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:25][root][INFO] - Training Epoch: 2/2, step 6304/16670 completed (loss: 0.2977050244808197, acc: 0.9107142686843872)
[2024-11-14 09:15:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:25][root][INFO] - Training Epoch: 2/2, step 6305/16670 completed (loss: 0.0755167007446289, acc: 0.9714285731315613)
[2024-11-14 09:15:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:25][root][INFO] - Training Epoch: 2/2, step 6306/16670 completed (loss: 0.8743629455566406, acc: 0.761904776096344)
[2024-11-14 09:15:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:26][root][INFO] - Training Epoch: 2/2, step 6307/16670 completed (loss: 0.45004990696907043, acc: 0.9411764740943909)
[2024-11-14 09:15:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:26][root][INFO] - Training Epoch: 2/2, step 6308/16670 completed (loss: 0.6087191104888916, acc: 0.8472222089767456)
[2024-11-14 09:15:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:27][root][INFO] - Training Epoch: 2/2, step 6309/16670 completed (loss: 0.7009981274604797, acc: 0.8679245114326477)
[2024-11-14 09:15:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:27][root][INFO] - Training Epoch: 2/2, step 6310/16670 completed (loss: 0.1212756484746933, acc: 0.96875)
[2024-11-14 09:15:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:27][root][INFO] - Training Epoch: 2/2, step 6311/16670 completed (loss: 0.6198528409004211, acc: 0.8552631735801697)
[2024-11-14 09:15:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:28][root][INFO] - Training Epoch: 2/2, step 6312/16670 completed (loss: 0.384438157081604, acc: 0.8999999761581421)
[2024-11-14 09:15:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:28][root][INFO] - Training Epoch: 2/2, step 6313/16670 completed (loss: 0.5683148503303528, acc: 0.843137264251709)
[2024-11-14 09:15:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:28][root][INFO] - Training Epoch: 2/2, step 6314/16670 completed (loss: 0.8732532262802124, acc: 0.8181818127632141)
[2024-11-14 09:15:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:29][root][INFO] - Training Epoch: 2/2, step 6315/16670 completed (loss: 0.4710632264614105, acc: 0.8823529481887817)
[2024-11-14 09:15:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:29][root][INFO] - Training Epoch: 2/2, step 6316/16670 completed (loss: 0.7517977952957153, acc: 0.8241758346557617)
[2024-11-14 09:15:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:30][root][INFO] - Training Epoch: 2/2, step 6317/16670 completed (loss: 0.0699896290898323, acc: 0.9772727489471436)
[2024-11-14 09:15:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:30][root][INFO] - Training Epoch: 2/2, step 6318/16670 completed (loss: 0.28258413076400757, acc: 0.9629629850387573)
[2024-11-14 09:15:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:30][root][INFO] - Training Epoch: 2/2, step 6319/16670 completed (loss: 0.44927120208740234, acc: 0.875)
[2024-11-14 09:15:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:31][root][INFO] - Training Epoch: 2/2, step 6320/16670 completed (loss: 0.6639921069145203, acc: 0.84375)
[2024-11-14 09:15:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:31][root][INFO] - Training Epoch: 2/2, step 6321/16670 completed (loss: 0.3875497877597809, acc: 0.9090909361839294)
[2024-11-14 09:15:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:31][root][INFO] - Training Epoch: 2/2, step 6322/16670 completed (loss: 0.36052802205085754, acc: 0.9024389982223511)
[2024-11-14 09:15:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:32][root][INFO] - Training Epoch: 2/2, step 6323/16670 completed (loss: 0.972027063369751, acc: 0.8333333134651184)
[2024-11-14 09:15:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:32][root][INFO] - Training Epoch: 2/2, step 6324/16670 completed (loss: 0.25466659665107727, acc: 0.9230769276618958)
[2024-11-14 09:15:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:32][root][INFO] - Training Epoch: 2/2, step 6325/16670 completed (loss: 0.2278565615415573, acc: 0.936170220375061)
[2024-11-14 09:15:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:33][root][INFO] - Training Epoch: 2/2, step 6326/16670 completed (loss: 0.668661892414093, acc: 0.8666666746139526)
[2024-11-14 09:15:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:33][root][INFO] - Training Epoch: 2/2, step 6327/16670 completed (loss: 0.6127995252609253, acc: 0.8627451062202454)
[2024-11-14 09:15:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:33][root][INFO] - Training Epoch: 2/2, step 6328/16670 completed (loss: 0.5152701139450073, acc: 0.8734177350997925)
[2024-11-14 09:15:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:33][root][INFO] - Training Epoch: 2/2, step 6329/16670 completed (loss: 0.22711032629013062, acc: 0.9756097793579102)
[2024-11-14 09:15:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:34][root][INFO] - Training Epoch: 2/2, step 6330/16670 completed (loss: 0.3489129841327667, acc: 0.949999988079071)
[2024-11-14 09:15:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:34][root][INFO] - Training Epoch: 2/2, step 6331/16670 completed (loss: 0.33358919620513916, acc: 0.9473684430122375)
[2024-11-14 09:15:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:34][root][INFO] - Training Epoch: 2/2, step 6332/16670 completed (loss: 0.40141189098358154, acc: 0.8695651888847351)
[2024-11-14 09:15:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:35][root][INFO] - Training Epoch: 2/2, step 6333/16670 completed (loss: 0.3645436763763428, acc: 0.9512194991111755)
[2024-11-14 09:15:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:35][root][INFO] - Training Epoch: 2/2, step 6334/16670 completed (loss: 0.19731053709983826, acc: 0.9622641801834106)
[2024-11-14 09:15:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:35][root][INFO] - Training Epoch: 2/2, step 6335/16670 completed (loss: 0.19828028976917267, acc: 0.9649122953414917)
[2024-11-14 09:15:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:36][root][INFO] - Training Epoch: 2/2, step 6336/16670 completed (loss: 0.8358205556869507, acc: 0.8085106611251831)
[2024-11-14 09:15:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:36][root][INFO] - Training Epoch: 2/2, step 6337/16670 completed (loss: 0.1829337775707245, acc: 0.9375)
[2024-11-14 09:15:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:36][root][INFO] - Training Epoch: 2/2, step 6338/16670 completed (loss: 0.29355013370513916, acc: 0.89552241563797)
[2024-11-14 09:15:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:37][root][INFO] - Training Epoch: 2/2, step 6339/16670 completed (loss: 0.37699612975120544, acc: 0.8965517282485962)
[2024-11-14 09:15:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:37][root][INFO] - Training Epoch: 2/2, step 6340/16670 completed (loss: 1.2889306545257568, acc: 0.7971014380455017)
[2024-11-14 09:15:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:38][root][INFO] - Training Epoch: 2/2, step 6341/16670 completed (loss: 0.19678129255771637, acc: 0.9756097793579102)
[2024-11-14 09:15:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:38][root][INFO] - Training Epoch: 2/2, step 6342/16670 completed (loss: 0.35412946343421936, acc: 0.9245283007621765)
[2024-11-14 09:15:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:38][root][INFO] - Training Epoch: 2/2, step 6343/16670 completed (loss: 0.5634647011756897, acc: 0.8307692408561707)
[2024-11-14 09:15:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:38][root][INFO] - Training Epoch: 2/2, step 6344/16670 completed (loss: 0.2581522762775421, acc: 0.9365079402923584)
[2024-11-14 09:15:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:39][root][INFO] - Training Epoch: 2/2, step 6345/16670 completed (loss: 0.15327467024326324, acc: 0.9545454382896423)
[2024-11-14 09:15:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:39][root][INFO] - Training Epoch: 2/2, step 6346/16670 completed (loss: 0.15246784687042236, acc: 0.9777777791023254)
[2024-11-14 09:15:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:39][root][INFO] - Training Epoch: 2/2, step 6347/16670 completed (loss: 0.6332709789276123, acc: 0.8299999833106995)
[2024-11-14 09:15:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:40][root][INFO] - Training Epoch: 2/2, step 6348/16670 completed (loss: 0.23828241229057312, acc: 0.9154929518699646)
[2024-11-14 09:15:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:40][root][INFO] - Training Epoch: 2/2, step 6349/16670 completed (loss: 0.21857701241970062, acc: 0.9242424368858337)
[2024-11-14 09:15:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:40][root][INFO] - Training Epoch: 2/2, step 6350/16670 completed (loss: 0.6405518054962158, acc: 0.8181818127632141)
[2024-11-14 09:15:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:41][root][INFO] - Training Epoch: 2/2, step 6351/16670 completed (loss: 0.8648102879524231, acc: 0.8382353186607361)
[2024-11-14 09:15:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:41][root][INFO] - Training Epoch: 2/2, step 6352/16670 completed (loss: 0.24376976490020752, acc: 0.90625)
[2024-11-14 09:15:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:41][root][INFO] - Training Epoch: 2/2, step 6353/16670 completed (loss: 0.5585634112358093, acc: 0.8651685118675232)
[2024-11-14 09:15:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:42][root][INFO] - Training Epoch: 2/2, step 6354/16670 completed (loss: 0.8628959655761719, acc: 0.8374999761581421)
[2024-11-14 09:15:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:42][root][INFO] - Training Epoch: 2/2, step 6355/16670 completed (loss: 0.6237737536430359, acc: 0.8205128312110901)
[2024-11-14 09:15:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:42][root][INFO] - Training Epoch: 2/2, step 6356/16670 completed (loss: 0.4578702747821808, acc: 0.8636363744735718)
[2024-11-14 09:15:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:43][root][INFO] - Training Epoch: 2/2, step 6357/16670 completed (loss: 0.8355588912963867, acc: 0.75)
[2024-11-14 09:15:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:43][root][INFO] - Training Epoch: 2/2, step 6358/16670 completed (loss: 0.5197194218635559, acc: 0.8888888955116272)
[2024-11-14 09:15:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:44][root][INFO] - Training Epoch: 2/2, step 6359/16670 completed (loss: 0.26980945467948914, acc: 0.9411764740943909)
[2024-11-14 09:15:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:44][root][INFO] - Training Epoch: 2/2, step 6360/16670 completed (loss: 0.39840972423553467, acc: 0.8888888955116272)
[2024-11-14 09:15:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:44][root][INFO] - Training Epoch: 2/2, step 6361/16670 completed (loss: 0.38801831007003784, acc: 0.84375)
[2024-11-14 09:15:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:45][root][INFO] - Training Epoch: 2/2, step 6362/16670 completed (loss: 0.2017916738986969, acc: 0.9285714030265808)
[2024-11-14 09:15:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:45][root][INFO] - Training Epoch: 2/2, step 6363/16670 completed (loss: 0.16986536979675293, acc: 0.969072163105011)
[2024-11-14 09:15:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:45][root][INFO] - Training Epoch: 2/2, step 6364/16670 completed (loss: 0.3452160954475403, acc: 0.9333333373069763)
[2024-11-14 09:15:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:46][root][INFO] - Training Epoch: 2/2, step 6365/16670 completed (loss: 0.20303945243358612, acc: 0.9399999976158142)
[2024-11-14 09:15:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:46][root][INFO] - Training Epoch: 2/2, step 6366/16670 completed (loss: 0.18555961549282074, acc: 0.9583333134651184)
[2024-11-14 09:15:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:46][root][INFO] - Training Epoch: 2/2, step 6367/16670 completed (loss: 0.495796799659729, acc: 0.8809523582458496)
[2024-11-14 09:15:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:47][root][INFO] - Training Epoch: 2/2, step 6368/16670 completed (loss: 0.4705934226512909, acc: 0.8666666746139526)
[2024-11-14 09:15:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:47][root][INFO] - Training Epoch: 2/2, step 6369/16670 completed (loss: 0.6246072053909302, acc: 0.8645833134651184)
[2024-11-14 09:15:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:48][root][INFO] - Training Epoch: 2/2, step 6370/16670 completed (loss: 0.2816722095012665, acc: 0.8409090638160706)
[2024-11-14 09:15:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:48][root][INFO] - Training Epoch: 2/2, step 6371/16670 completed (loss: 0.17210792005062103, acc: 0.9807692170143127)
[2024-11-14 09:15:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:48][root][INFO] - Training Epoch: 2/2, step 6372/16670 completed (loss: 0.08721307665109634, acc: 1.0)
[2024-11-14 09:15:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:49][root][INFO] - Training Epoch: 2/2, step 6373/16670 completed (loss: 0.12491144239902496, acc: 0.9750000238418579)
[2024-11-14 09:15:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:49][root][INFO] - Training Epoch: 2/2, step 6374/16670 completed (loss: 0.5095095038414001, acc: 0.8513513803482056)
[2024-11-14 09:15:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:49][root][INFO] - Training Epoch: 2/2, step 6375/16670 completed (loss: 0.14197982847690582, acc: 0.9772727489471436)
[2024-11-14 09:15:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:50][root][INFO] - Training Epoch: 2/2, step 6376/16670 completed (loss: 0.6068366765975952, acc: 0.8421052694320679)
[2024-11-14 09:15:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:50][root][INFO] - Training Epoch: 2/2, step 6377/16670 completed (loss: 0.26536452770233154, acc: 0.9354838728904724)
[2024-11-14 09:15:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:50][root][INFO] - Training Epoch: 2/2, step 6378/16670 completed (loss: 0.1952858418226242, acc: 0.918367326259613)
[2024-11-14 09:15:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:51][root][INFO] - Training Epoch: 2/2, step 6379/16670 completed (loss: 0.10299394279718399, acc: 0.9772727489471436)
[2024-11-14 09:15:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:51][root][INFO] - Training Epoch: 2/2, step 6380/16670 completed (loss: 0.40685009956359863, acc: 0.930232584476471)
[2024-11-14 09:15:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:51][root][INFO] - Training Epoch: 2/2, step 6381/16670 completed (loss: 0.8479262590408325, acc: 0.8382353186607361)
[2024-11-14 09:15:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:52][root][INFO] - Training Epoch: 2/2, step 6382/16670 completed (loss: 0.2264300435781479, acc: 0.9433962106704712)
[2024-11-14 09:15:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:52][root][INFO] - Training Epoch: 2/2, step 6383/16670 completed (loss: 0.49159494042396545, acc: 0.8709677457809448)
[2024-11-14 09:15:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:52][root][INFO] - Training Epoch: 2/2, step 6384/16670 completed (loss: 0.14504852890968323, acc: 0.9583333134651184)
[2024-11-14 09:15:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:53][root][INFO] - Training Epoch: 2/2, step 6385/16670 completed (loss: 0.2988094091415405, acc: 0.9459459185600281)
[2024-11-14 09:15:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:53][root][INFO] - Training Epoch: 2/2, step 6386/16670 completed (loss: 0.26675355434417725, acc: 0.8799999952316284)
[2024-11-14 09:15:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:54][root][INFO] - Training Epoch: 2/2, step 6387/16670 completed (loss: 0.06686029583215714, acc: 0.9846153855323792)
[2024-11-14 09:15:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:54][root][INFO] - Training Epoch: 2/2, step 6388/16670 completed (loss: 0.7978795170783997, acc: 0.8571428656578064)
[2024-11-14 09:15:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:54][root][INFO] - Training Epoch: 2/2, step 6389/16670 completed (loss: 0.4713963270187378, acc: 0.9200000166893005)
[2024-11-14 09:15:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:55][root][INFO] - Training Epoch: 2/2, step 6390/16670 completed (loss: 0.42444536089897156, acc: 0.8793103694915771)
[2024-11-14 09:15:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:55][root][INFO] - Training Epoch: 2/2, step 6391/16670 completed (loss: 0.6135227084159851, acc: 0.8275862336158752)
[2024-11-14 09:15:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:55][root][INFO] - Training Epoch: 2/2, step 6392/16670 completed (loss: 0.2510325610637665, acc: 0.9333333373069763)
[2024-11-14 09:15:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:56][root][INFO] - Training Epoch: 2/2, step 6393/16670 completed (loss: 0.12873665988445282, acc: 0.9696969985961914)
[2024-11-14 09:15:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:56][root][INFO] - Training Epoch: 2/2, step 6394/16670 completed (loss: 0.35404694080352783, acc: 0.9264705777168274)
[2024-11-14 09:15:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:56][root][INFO] - Training Epoch: 2/2, step 6395/16670 completed (loss: 0.3501628041267395, acc: 0.9069767594337463)
[2024-11-14 09:15:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:57][root][INFO] - Training Epoch: 2/2, step 6396/16670 completed (loss: 0.3867974877357483, acc: 0.8823529481887817)
[2024-11-14 09:15:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:57][root][INFO] - Training Epoch: 2/2, step 6397/16670 completed (loss: 0.6569633483886719, acc: 0.8448275923728943)
[2024-11-14 09:15:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:57][root][INFO] - Training Epoch: 2/2, step 6398/16670 completed (loss: 0.2735629081726074, acc: 0.9076923131942749)
[2024-11-14 09:15:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:58][root][INFO] - Training Epoch: 2/2, step 6399/16670 completed (loss: 0.6368000507354736, acc: 0.8666666746139526)
[2024-11-14 09:15:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:58][root][INFO] - Training Epoch: 2/2, step 6400/16670 completed (loss: 0.10203739255666733, acc: 0.9692307710647583)
[2024-11-14 09:15:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:59][root][INFO] - Training Epoch: 2/2, step 6401/16670 completed (loss: 0.3309049904346466, acc: 0.8833333253860474)
[2024-11-14 09:15:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:59][root][INFO] - Training Epoch: 2/2, step 6402/16670 completed (loss: 0.7707974314689636, acc: 0.8474576473236084)
[2024-11-14 09:15:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:15:59][root][INFO] - Training Epoch: 2/2, step 6403/16670 completed (loss: 0.3209165632724762, acc: 0.9259259104728699)
[2024-11-14 09:15:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:00][root][INFO] - Training Epoch: 2/2, step 6404/16670 completed (loss: 0.9329153299331665, acc: 0.7586206793785095)
[2024-11-14 09:16:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:00][root][INFO] - Training Epoch: 2/2, step 6405/16670 completed (loss: 0.48018983006477356, acc: 0.8860759735107422)
[2024-11-14 09:16:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:00][root][INFO] - Training Epoch: 2/2, step 6406/16670 completed (loss: 0.2020636349916458, acc: 0.9622641801834106)
[2024-11-14 09:16:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:01][root][INFO] - Training Epoch: 2/2, step 6407/16670 completed (loss: 0.7981457114219666, acc: 0.8428571224212646)
[2024-11-14 09:16:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:01][root][INFO] - Training Epoch: 2/2, step 6408/16670 completed (loss: 0.7319661378860474, acc: 0.800000011920929)
[2024-11-14 09:16:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:01][root][INFO] - Training Epoch: 2/2, step 6409/16670 completed (loss: 0.3529275953769684, acc: 0.930232584476471)
[2024-11-14 09:16:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:02][root][INFO] - Training Epoch: 2/2, step 6410/16670 completed (loss: 0.33358052372932434, acc: 0.9032257795333862)
[2024-11-14 09:16:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:02][root][INFO] - Training Epoch: 2/2, step 6411/16670 completed (loss: 0.3133016526699066, acc: 0.895348846912384)
[2024-11-14 09:16:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:03][root][INFO] - Training Epoch: 2/2, step 6412/16670 completed (loss: 0.18546336889266968, acc: 0.9615384340286255)
[2024-11-14 09:16:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:03][root][INFO] - Training Epoch: 2/2, step 6413/16670 completed (loss: 0.3785896599292755, acc: 0.8500000238418579)
[2024-11-14 09:16:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:03][root][INFO] - Training Epoch: 2/2, step 6414/16670 completed (loss: 0.15614663064479828, acc: 0.9736841917037964)
[2024-11-14 09:16:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:04][root][INFO] - Training Epoch: 2/2, step 6415/16670 completed (loss: 0.7910295724868774, acc: 0.8918918967247009)
[2024-11-14 09:16:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:04][root][INFO] - Training Epoch: 2/2, step 6416/16670 completed (loss: 0.6914345622062683, acc: 0.8181818127632141)
[2024-11-14 09:16:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:04][root][INFO] - Training Epoch: 2/2, step 6417/16670 completed (loss: 0.11598071455955505, acc: 0.9682539701461792)
[2024-11-14 09:16:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:05][root][INFO] - Training Epoch: 2/2, step 6418/16670 completed (loss: 0.062117356806993484, acc: 0.9803921580314636)
[2024-11-14 09:16:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:05][root][INFO] - Training Epoch: 2/2, step 6419/16670 completed (loss: 0.16643038392066956, acc: 0.976190447807312)
[2024-11-14 09:16:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:05][root][INFO] - Training Epoch: 2/2, step 6420/16670 completed (loss: 0.18557292222976685, acc: 0.9264705777168274)
[2024-11-14 09:16:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:06][root][INFO] - Training Epoch: 2/2, step 6421/16670 completed (loss: 0.13709431886672974, acc: 0.9666666388511658)
[2024-11-14 09:16:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:06][root][INFO] - Training Epoch: 2/2, step 6422/16670 completed (loss: 0.28695061802864075, acc: 0.9074074029922485)
[2024-11-14 09:16:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:06][root][INFO] - Training Epoch: 2/2, step 6423/16670 completed (loss: 0.17011506855487823, acc: 0.9523809552192688)
[2024-11-14 09:16:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:07][root][INFO] - Training Epoch: 2/2, step 6424/16670 completed (loss: 0.19200833141803741, acc: 0.9347826242446899)
[2024-11-14 09:16:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:07][root][INFO] - Training Epoch: 2/2, step 6425/16670 completed (loss: 0.18157526850700378, acc: 0.9756097793579102)
[2024-11-14 09:16:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:07][root][INFO] - Training Epoch: 2/2, step 6426/16670 completed (loss: 0.04265965521335602, acc: 1.0)
[2024-11-14 09:16:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:07][root][INFO] - Training Epoch: 2/2, step 6427/16670 completed (loss: 0.7242315411567688, acc: 0.78125)
[2024-11-14 09:16:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:08][root][INFO] - Training Epoch: 2/2, step 6428/16670 completed (loss: 0.3982984125614166, acc: 0.9041095972061157)
[2024-11-14 09:16:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:08][root][INFO] - Training Epoch: 2/2, step 6429/16670 completed (loss: 0.47474396228790283, acc: 0.8958333134651184)
[2024-11-14 09:16:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:08][root][INFO] - Training Epoch: 2/2, step 6430/16670 completed (loss: 0.6845831871032715, acc: 0.8541666865348816)
[2024-11-14 09:16:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:09][root][INFO] - Training Epoch: 2/2, step 6431/16670 completed (loss: 0.11158798635005951, acc: 0.9756097793579102)
[2024-11-14 09:16:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:09][root][INFO] - Training Epoch: 2/2, step 6432/16670 completed (loss: 0.17429593205451965, acc: 0.9607843160629272)
[2024-11-14 09:16:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:09][root][INFO] - Training Epoch: 2/2, step 6433/16670 completed (loss: 0.660749614238739, acc: 0.8918918967247009)
[2024-11-14 09:16:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:10][root][INFO] - Training Epoch: 2/2, step 6434/16670 completed (loss: 0.1708531230688095, acc: 0.9599999785423279)
[2024-11-14 09:16:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:10][root][INFO] - Training Epoch: 2/2, step 6435/16670 completed (loss: 0.593270480632782, acc: 0.8541666865348816)
[2024-11-14 09:16:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:11][root][INFO] - Training Epoch: 2/2, step 6436/16670 completed (loss: 0.49602410197257996, acc: 0.8840579986572266)
[2024-11-14 09:16:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:11][root][INFO] - Training Epoch: 2/2, step 6437/16670 completed (loss: 0.3075641393661499, acc: 0.953125)
[2024-11-14 09:16:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:11][root][INFO] - Training Epoch: 2/2, step 6438/16670 completed (loss: 0.7707380652427673, acc: 0.8846153616905212)
[2024-11-14 09:16:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:12][root][INFO] - Training Epoch: 2/2, step 6439/16670 completed (loss: 0.046831969171762466, acc: 0.9750000238418579)
[2024-11-14 09:16:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:12][root][INFO] - Training Epoch: 2/2, step 6440/16670 completed (loss: 0.2721322774887085, acc: 0.9599999785423279)
[2024-11-14 09:16:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:12][root][INFO] - Training Epoch: 2/2, step 6441/16670 completed (loss: 0.24468418955802917, acc: 0.9756097793579102)
[2024-11-14 09:16:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:13][root][INFO] - Training Epoch: 2/2, step 6442/16670 completed (loss: 0.04284291714429855, acc: 0.9729729890823364)
[2024-11-14 09:16:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:13][root][INFO] - Training Epoch: 2/2, step 6443/16670 completed (loss: 0.7269819974899292, acc: 0.7954545617103577)
[2024-11-14 09:16:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:13][root][INFO] - Training Epoch: 2/2, step 6444/16670 completed (loss: 0.8675388693809509, acc: 0.8205128312110901)
[2024-11-14 09:16:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:14][root][INFO] - Training Epoch: 2/2, step 6445/16670 completed (loss: 0.27177608013153076, acc: 0.9333333373069763)
[2024-11-14 09:16:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:14][root][INFO] - Training Epoch: 2/2, step 6446/16670 completed (loss: 0.298020601272583, acc: 0.9122806787490845)
[2024-11-14 09:16:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:14][root][INFO] - Training Epoch: 2/2, step 6447/16670 completed (loss: 0.05885079875588417, acc: 0.9864864945411682)
[2024-11-14 09:16:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:15][root][INFO] - Training Epoch: 2/2, step 6448/16670 completed (loss: 0.2645498812198639, acc: 0.9444444179534912)
[2024-11-14 09:16:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:15][root][INFO] - Training Epoch: 2/2, step 6449/16670 completed (loss: 0.4631444215774536, acc: 0.9135802388191223)
[2024-11-14 09:16:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:15][root][INFO] - Training Epoch: 2/2, step 6450/16670 completed (loss: 0.22824762761592865, acc: 0.9069767594337463)
[2024-11-14 09:16:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:16][root][INFO] - Training Epoch: 2/2, step 6451/16670 completed (loss: 0.22590957581996918, acc: 0.9411764740943909)
[2024-11-14 09:16:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:16][root][INFO] - Training Epoch: 2/2, step 6452/16670 completed (loss: 0.047951169312000275, acc: 1.0)
[2024-11-14 09:16:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:16][root][INFO] - Training Epoch: 2/2, step 6453/16670 completed (loss: 0.1877257376909256, acc: 0.9107142686843872)
[2024-11-14 09:16:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:17][root][INFO] - Training Epoch: 2/2, step 6454/16670 completed (loss: 0.079645536839962, acc: 1.0)
[2024-11-14 09:16:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:17][root][INFO] - Training Epoch: 2/2, step 6455/16670 completed (loss: 0.44094860553741455, acc: 0.8645833134651184)
[2024-11-14 09:16:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:17][root][INFO] - Training Epoch: 2/2, step 6456/16670 completed (loss: 0.12338997423648834, acc: 0.970588207244873)
[2024-11-14 09:16:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:18][root][INFO] - Training Epoch: 2/2, step 6457/16670 completed (loss: 0.468132346868515, acc: 0.875)
[2024-11-14 09:16:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:18][root][INFO] - Training Epoch: 2/2, step 6458/16670 completed (loss: 0.15768058598041534, acc: 0.9740259647369385)
[2024-11-14 09:16:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:18][root][INFO] - Training Epoch: 2/2, step 6459/16670 completed (loss: 0.031339775770902634, acc: 1.0)
[2024-11-14 09:16:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:19][root][INFO] - Training Epoch: 2/2, step 6460/16670 completed (loss: 0.1134093701839447, acc: 0.9607843160629272)
[2024-11-14 09:16:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:19][root][INFO] - Training Epoch: 2/2, step 6461/16670 completed (loss: 0.04437820985913277, acc: 1.0)
[2024-11-14 09:16:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:19][root][INFO] - Training Epoch: 2/2, step 6462/16670 completed (loss: 0.05272210016846657, acc: 0.970588207244873)
[2024-11-14 09:16:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:20][root][INFO] - Training Epoch: 2/2, step 6463/16670 completed (loss: 0.10476751625537872, acc: 0.9599999785423279)
[2024-11-14 09:16:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:20][root][INFO] - Training Epoch: 2/2, step 6464/16670 completed (loss: 0.23526214063167572, acc: 0.9420289993286133)
[2024-11-14 09:16:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:20][root][INFO] - Training Epoch: 2/2, step 6465/16670 completed (loss: 0.05244314670562744, acc: 1.0)
[2024-11-14 09:16:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:21][root][INFO] - Training Epoch: 2/2, step 6466/16670 completed (loss: 0.20191732048988342, acc: 0.9390243887901306)
[2024-11-14 09:16:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:21][root][INFO] - Training Epoch: 2/2, step 6467/16670 completed (loss: 0.23112209141254425, acc: 0.9599999785423279)
[2024-11-14 09:16:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:21][root][INFO] - Training Epoch: 2/2, step 6468/16670 completed (loss: 0.3045606017112732, acc: 0.9137930870056152)
[2024-11-14 09:16:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:22][root][INFO] - Training Epoch: 2/2, step 6469/16670 completed (loss: 0.21348980069160461, acc: 0.9555555582046509)
[2024-11-14 09:16:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:22][root][INFO] - Training Epoch: 2/2, step 6470/16670 completed (loss: 0.8718323707580566, acc: 0.8392857313156128)
[2024-11-14 09:16:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:22][root][INFO] - Training Epoch: 2/2, step 6471/16670 completed (loss: 1.4172091484069824, acc: 0.6481481194496155)
[2024-11-14 09:16:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:23][root][INFO] - Training Epoch: 2/2, step 6472/16670 completed (loss: 0.4594435691833496, acc: 0.9428571462631226)
[2024-11-14 09:16:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:23][root][INFO] - Training Epoch: 2/2, step 6473/16670 completed (loss: 0.13777735829353333, acc: 0.9583333134651184)
[2024-11-14 09:16:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:23][root][INFO] - Training Epoch: 2/2, step 6474/16670 completed (loss: 0.12517231702804565, acc: 0.9615384340286255)
[2024-11-14 09:16:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:23][root][INFO] - Training Epoch: 2/2, step 6475/16670 completed (loss: 0.09430769830942154, acc: 0.96875)
[2024-11-14 09:16:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:24][root][INFO] - Training Epoch: 2/2, step 6476/16670 completed (loss: 0.08885327726602554, acc: 1.0)
[2024-11-14 09:16:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:24][root][INFO] - Training Epoch: 2/2, step 6477/16670 completed (loss: 0.36828356981277466, acc: 0.9275362491607666)
[2024-11-14 09:16:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:24][root][INFO] - Training Epoch: 2/2, step 6478/16670 completed (loss: 0.21891559660434723, acc: 0.949999988079071)
[2024-11-14 09:16:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:25][root][INFO] - Training Epoch: 2/2, step 6479/16670 completed (loss: 0.13806401193141937, acc: 0.939393937587738)
[2024-11-14 09:16:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:25][root][INFO] - Training Epoch: 2/2, step 6480/16670 completed (loss: 0.18585407733917236, acc: 0.9523809552192688)
[2024-11-14 09:16:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:25][root][INFO] - Training Epoch: 2/2, step 6481/16670 completed (loss: 0.062156785279512405, acc: 1.0)
[2024-11-14 09:16:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:26][root][INFO] - Training Epoch: 2/2, step 6482/16670 completed (loss: 0.5064203143119812, acc: 0.8500000238418579)
[2024-11-14 09:16:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:26][root][INFO] - Training Epoch: 2/2, step 6483/16670 completed (loss: 0.2716158628463745, acc: 0.9090909361839294)
[2024-11-14 09:16:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:26][root][INFO] - Training Epoch: 2/2, step 6484/16670 completed (loss: 0.1403551697731018, acc: 0.9682539701461792)
[2024-11-14 09:16:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:27][root][INFO] - Training Epoch: 2/2, step 6485/16670 completed (loss: 0.5030648112297058, acc: 0.9200000166893005)
[2024-11-14 09:16:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:27][root][INFO] - Training Epoch: 2/2, step 6486/16670 completed (loss: 0.19751805067062378, acc: 0.9577465057373047)
[2024-11-14 09:16:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:27][root][INFO] - Training Epoch: 2/2, step 6487/16670 completed (loss: 0.12642554938793182, acc: 0.949999988079071)
[2024-11-14 09:16:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:28][root][INFO] - Training Epoch: 2/2, step 6488/16670 completed (loss: 0.11446699500083923, acc: 0.9571428298950195)
[2024-11-14 09:16:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:28][root][INFO] - Training Epoch: 2/2, step 6489/16670 completed (loss: 0.31545111536979675, acc: 0.8787878751754761)
[2024-11-14 09:16:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:29][root][INFO] - Training Epoch: 2/2, step 6490/16670 completed (loss: 0.1083298772573471, acc: 0.970588207244873)
[2024-11-14 09:16:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:29][root][INFO] - Training Epoch: 2/2, step 6491/16670 completed (loss: 0.08024649322032928, acc: 0.9855072498321533)
[2024-11-14 09:16:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:29][root][INFO] - Training Epoch: 2/2, step 6492/16670 completed (loss: 0.15259669721126556, acc: 0.9591836929321289)
[2024-11-14 09:16:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:30][root][INFO] - Training Epoch: 2/2, step 6493/16670 completed (loss: 0.30864188075065613, acc: 0.9375)
[2024-11-14 09:16:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:30][root][INFO] - Training Epoch: 2/2, step 6494/16670 completed (loss: 0.06466618180274963, acc: 0.9696969985961914)
[2024-11-14 09:16:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:31][root][INFO] - Training Epoch: 2/2, step 6495/16670 completed (loss: 0.29048120975494385, acc: 0.8833333253860474)
[2024-11-14 09:16:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:31][root][INFO] - Training Epoch: 2/2, step 6496/16670 completed (loss: 0.2976419925689697, acc: 0.9180327653884888)
[2024-11-14 09:16:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:31][root][INFO] - Training Epoch: 2/2, step 6497/16670 completed (loss: 0.23736637830734253, acc: 0.9649122953414917)
[2024-11-14 09:16:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:32][root][INFO] - Training Epoch: 2/2, step 6498/16670 completed (loss: 0.14443248510360718, acc: 0.9838709831237793)
[2024-11-14 09:16:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:32][root][INFO] - Training Epoch: 2/2, step 6499/16670 completed (loss: 0.47619011998176575, acc: 0.8205128312110901)
[2024-11-14 09:16:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:32][root][INFO] - Training Epoch: 2/2, step 6500/16670 completed (loss: 0.2603914439678192, acc: 0.9367088675498962)
[2024-11-14 09:16:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:33][root][INFO] - Training Epoch: 2/2, step 6501/16670 completed (loss: 0.17308351397514343, acc: 0.9615384340286255)
[2024-11-14 09:16:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:33][root][INFO] - Training Epoch: 2/2, step 6502/16670 completed (loss: 0.08430218696594238, acc: 1.0)
[2024-11-14 09:16:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:33][root][INFO] - Training Epoch: 2/2, step 6503/16670 completed (loss: 0.09437701851129532, acc: 0.9599999785423279)
[2024-11-14 09:16:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:34][root][INFO] - Training Epoch: 2/2, step 6504/16670 completed (loss: 0.5414245128631592, acc: 0.8571428656578064)
[2024-11-14 09:16:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:34][root][INFO] - Training Epoch: 2/2, step 6505/16670 completed (loss: 0.160823255777359, acc: 0.9390243887901306)
[2024-11-14 09:16:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:34][root][INFO] - Training Epoch: 2/2, step 6506/16670 completed (loss: 0.17103658616542816, acc: 0.9605262875556946)
[2024-11-14 09:16:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:35][root][INFO] - Training Epoch: 2/2, step 6507/16670 completed (loss: 0.032190438359975815, acc: 1.0)
[2024-11-14 09:16:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:35][root][INFO] - Training Epoch: 2/2, step 6508/16670 completed (loss: 0.10841767489910126, acc: 0.9750000238418579)
[2024-11-14 09:16:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:35][root][INFO] - Training Epoch: 2/2, step 6509/16670 completed (loss: 0.2793673872947693, acc: 0.9375)
[2024-11-14 09:16:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:36][root][INFO] - Training Epoch: 2/2, step 6510/16670 completed (loss: 0.07899625599384308, acc: 0.97826087474823)
[2024-11-14 09:16:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:36][root][INFO] - Training Epoch: 2/2, step 6511/16670 completed (loss: 0.3769851326942444, acc: 0.9152542352676392)
[2024-11-14 09:16:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:36][root][INFO] - Training Epoch: 2/2, step 6512/16670 completed (loss: 0.19142788648605347, acc: 0.931506872177124)
[2024-11-14 09:16:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:37][root][INFO] - Training Epoch: 2/2, step 6513/16670 completed (loss: 0.29323387145996094, acc: 0.90625)
[2024-11-14 09:16:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:37][root][INFO] - Training Epoch: 2/2, step 6514/16670 completed (loss: 0.060859788209199905, acc: 0.9791666865348816)
[2024-11-14 09:16:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:38][root][INFO] - Training Epoch: 2/2, step 6515/16670 completed (loss: 0.43093839287757874, acc: 0.8723404407501221)
[2024-11-14 09:16:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:38][root][INFO] - Training Epoch: 2/2, step 6516/16670 completed (loss: 0.17688363790512085, acc: 0.9599999785423279)
[2024-11-14 09:16:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:38][root][INFO] - Training Epoch: 2/2, step 6517/16670 completed (loss: 0.1126379445195198, acc: 0.9777777791023254)
[2024-11-14 09:16:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:39][root][INFO] - Training Epoch: 2/2, step 6518/16670 completed (loss: 0.08516708761453629, acc: 0.9818181991577148)
[2024-11-14 09:16:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:39][root][INFO] - Training Epoch: 2/2, step 6519/16670 completed (loss: 0.36713579297065735, acc: 0.8723404407501221)
[2024-11-14 09:16:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:39][root][INFO] - Training Epoch: 2/2, step 6520/16670 completed (loss: 0.22853195667266846, acc: 0.9487179517745972)
[2024-11-14 09:16:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:40][root][INFO] - Training Epoch: 2/2, step 6521/16670 completed (loss: 0.25202542543411255, acc: 0.9464285969734192)
[2024-11-14 09:16:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:40][root][INFO] - Training Epoch: 2/2, step 6522/16670 completed (loss: 0.11675454676151276, acc: 0.9259259104728699)
[2024-11-14 09:16:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:40][root][INFO] - Training Epoch: 2/2, step 6523/16670 completed (loss: 0.29023244976997375, acc: 0.9367088675498962)
[2024-11-14 09:16:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:41][root][INFO] - Training Epoch: 2/2, step 6524/16670 completed (loss: 0.09023302048444748, acc: 0.9756097793579102)
[2024-11-14 09:16:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:41][root][INFO] - Training Epoch: 2/2, step 6525/16670 completed (loss: 0.5702202916145325, acc: 0.8965517282485962)
[2024-11-14 09:16:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:41][root][INFO] - Training Epoch: 2/2, step 6526/16670 completed (loss: 0.22295375168323517, acc: 0.8913043737411499)
[2024-11-14 09:16:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:42][root][INFO] - Training Epoch: 2/2, step 6527/16670 completed (loss: 0.10550972074270248, acc: 0.9807692170143127)
[2024-11-14 09:16:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:42][root][INFO] - Training Epoch: 2/2, step 6528/16670 completed (loss: 0.1671994924545288, acc: 0.9487179517745972)
[2024-11-14 09:16:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:42][root][INFO] - Training Epoch: 2/2, step 6529/16670 completed (loss: 0.20144318044185638, acc: 0.95652174949646)
[2024-11-14 09:16:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:43][root][INFO] - Training Epoch: 2/2, step 6530/16670 completed (loss: 0.007022552192211151, acc: 1.0)
[2024-11-14 09:16:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:43][root][INFO] - Training Epoch: 2/2, step 6531/16670 completed (loss: 0.20870114862918854, acc: 0.9454545378684998)
[2024-11-14 09:16:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:43][root][INFO] - Training Epoch: 2/2, step 6532/16670 completed (loss: 0.028276680037379265, acc: 1.0)
[2024-11-14 09:16:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:44][root][INFO] - Training Epoch: 2/2, step 6533/16670 completed (loss: 0.23146632313728333, acc: 0.9464285969734192)
[2024-11-14 09:16:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:44][root][INFO] - Training Epoch: 2/2, step 6534/16670 completed (loss: 0.1873939037322998, acc: 0.9272727370262146)
[2024-11-14 09:16:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:44][root][INFO] - Training Epoch: 2/2, step 6535/16670 completed (loss: 0.08436321467161179, acc: 1.0)
[2024-11-14 09:16:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:45][root][INFO] - Training Epoch: 2/2, step 6536/16670 completed (loss: 0.2721424400806427, acc: 0.9433962106704712)
[2024-11-14 09:16:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:45][root][INFO] - Training Epoch: 2/2, step 6537/16670 completed (loss: 0.442624032497406, acc: 0.8837209343910217)
[2024-11-14 09:16:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:45][root][INFO] - Training Epoch: 2/2, step 6538/16670 completed (loss: 0.28000709414482117, acc: 0.9411764740943909)
[2024-11-14 09:16:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:46][root][INFO] - Training Epoch: 2/2, step 6539/16670 completed (loss: 0.3497382402420044, acc: 0.9166666865348816)
[2024-11-14 09:16:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:46][root][INFO] - Training Epoch: 2/2, step 6540/16670 completed (loss: 0.4265885055065155, acc: 0.8947368264198303)
[2024-11-14 09:16:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:46][root][INFO] - Training Epoch: 2/2, step 6541/16670 completed (loss: 0.17783121764659882, acc: 0.9411764740943909)
[2024-11-14 09:16:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:47][root][INFO] - Training Epoch: 2/2, step 6542/16670 completed (loss: 0.3664810359477997, acc: 0.8974359035491943)
[2024-11-14 09:16:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:47][root][INFO] - Training Epoch: 2/2, step 6543/16670 completed (loss: 0.056652702391147614, acc: 1.0)
[2024-11-14 09:16:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:47][root][INFO] - Training Epoch: 2/2, step 6544/16670 completed (loss: 0.14951802790164948, acc: 0.9375)
[2024-11-14 09:16:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:48][root][INFO] - Training Epoch: 2/2, step 6545/16670 completed (loss: 0.3221021294593811, acc: 0.9344262480735779)
[2024-11-14 09:16:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:48][root][INFO] - Training Epoch: 2/2, step 6546/16670 completed (loss: 0.2513597905635834, acc: 0.9642857313156128)
[2024-11-14 09:16:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:48][root][INFO] - Training Epoch: 2/2, step 6547/16670 completed (loss: 0.3245641887187958, acc: 0.9324324131011963)
[2024-11-14 09:16:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:49][root][INFO] - Training Epoch: 2/2, step 6548/16670 completed (loss: 0.13339988887310028, acc: 0.9772727489471436)
[2024-11-14 09:16:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:49][root][INFO] - Training Epoch: 2/2, step 6549/16670 completed (loss: 0.24714291095733643, acc: 0.9473684430122375)
[2024-11-14 09:16:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:49][root][INFO] - Training Epoch: 2/2, step 6550/16670 completed (loss: 0.9088879823684692, acc: 0.7543859481811523)
[2024-11-14 09:16:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:50][root][INFO] - Training Epoch: 2/2, step 6551/16670 completed (loss: 0.09514939785003662, acc: 0.9594594836235046)
[2024-11-14 09:16:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:50][root][INFO] - Training Epoch: 2/2, step 6552/16670 completed (loss: 0.38010111451148987, acc: 0.921875)
[2024-11-14 09:16:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:50][root][INFO] - Training Epoch: 2/2, step 6553/16670 completed (loss: 0.27609574794769287, acc: 0.925000011920929)
[2024-11-14 09:16:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:51][root][INFO] - Training Epoch: 2/2, step 6554/16670 completed (loss: 0.1490149050951004, acc: 0.9677419066429138)
[2024-11-14 09:16:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:51][root][INFO] - Training Epoch: 2/2, step 6555/16670 completed (loss: 0.09147627651691437, acc: 0.9800000190734863)
[2024-11-14 09:16:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:51][root][INFO] - Training Epoch: 2/2, step 6556/16670 completed (loss: 0.24686460196971893, acc: 0.9166666865348816)
[2024-11-14 09:16:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:52][root][INFO] - Training Epoch: 2/2, step 6557/16670 completed (loss: 0.008734376169741154, acc: 1.0)
[2024-11-14 09:16:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:52][root][INFO] - Training Epoch: 2/2, step 6558/16670 completed (loss: 0.023797012865543365, acc: 1.0)
[2024-11-14 09:16:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:52][root][INFO] - Training Epoch: 2/2, step 6559/16670 completed (loss: 0.22943659126758575, acc: 0.925000011920929)
[2024-11-14 09:16:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:53][root][INFO] - Training Epoch: 2/2, step 6560/16670 completed (loss: 0.020941587164998055, acc: 1.0)
[2024-11-14 09:16:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:53][root][INFO] - Training Epoch: 2/2, step 6561/16670 completed (loss: 0.427646279335022, acc: 0.936170220375061)
[2024-11-14 09:16:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:53][root][INFO] - Training Epoch: 2/2, step 6562/16670 completed (loss: 0.07379668205976486, acc: 1.0)
[2024-11-14 09:16:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:54][root][INFO] - Training Epoch: 2/2, step 6563/16670 completed (loss: 0.32743707299232483, acc: 0.887499988079071)
[2024-11-14 09:16:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:54][root][INFO] - Training Epoch: 2/2, step 6564/16670 completed (loss: 0.8589507937431335, acc: 0.9019607901573181)
[2024-11-14 09:16:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:54][root][INFO] - Training Epoch: 2/2, step 6565/16670 completed (loss: 0.08440735191106796, acc: 0.970588207244873)
[2024-11-14 09:16:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:55][root][INFO] - Training Epoch: 2/2, step 6566/16670 completed (loss: 0.10538036376237869, acc: 0.9772727489471436)
[2024-11-14 09:16:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:55][root][INFO] - Training Epoch: 2/2, step 6567/16670 completed (loss: 0.502604067325592, acc: 0.8999999761581421)
[2024-11-14 09:16:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:55][root][INFO] - Training Epoch: 2/2, step 6568/16670 completed (loss: 0.13972613215446472, acc: 0.96875)
[2024-11-14 09:16:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:56][root][INFO] - Training Epoch: 2/2, step 6569/16670 completed (loss: 0.06062934175133705, acc: 0.9791666865348816)
[2024-11-14 09:16:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:56][root][INFO] - Training Epoch: 2/2, step 6570/16670 completed (loss: 0.014517875388264656, acc: 1.0)
[2024-11-14 09:16:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:56][root][INFO] - Training Epoch: 2/2, step 6571/16670 completed (loss: 0.15930373966693878, acc: 0.9622641801834106)
[2024-11-14 09:16:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:57][root][INFO] - Training Epoch: 2/2, step 6572/16670 completed (loss: 0.08375506848096848, acc: 0.976190447807312)
[2024-11-14 09:16:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:57][root][INFO] - Training Epoch: 2/2, step 6573/16670 completed (loss: 0.3650100529193878, acc: 0.9166666865348816)
[2024-11-14 09:16:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:57][root][INFO] - Training Epoch: 2/2, step 6574/16670 completed (loss: 0.2219628393650055, acc: 0.949999988079071)
[2024-11-14 09:16:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:58][root][INFO] - Training Epoch: 2/2, step 6575/16670 completed (loss: 0.10146266967058182, acc: 0.976190447807312)
[2024-11-14 09:16:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:58][root][INFO] - Training Epoch: 2/2, step 6576/16670 completed (loss: 0.15222422778606415, acc: 0.9558823704719543)
[2024-11-14 09:16:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:58][root][INFO] - Training Epoch: 2/2, step 6577/16670 completed (loss: 0.7801977396011353, acc: 0.7647058963775635)
[2024-11-14 09:16:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:59][root][INFO] - Training Epoch: 2/2, step 6578/16670 completed (loss: 0.10494188964366913, acc: 0.9729729890823364)
[2024-11-14 09:16:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:59][root][INFO] - Training Epoch: 2/2, step 6579/16670 completed (loss: 0.4917822778224945, acc: 0.9166666865348816)
[2024-11-14 09:16:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:16:59][root][INFO] - Training Epoch: 2/2, step 6580/16670 completed (loss: 0.6215161085128784, acc: 0.849056601524353)
[2024-11-14 09:16:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:00][root][INFO] - Training Epoch: 2/2, step 6581/16670 completed (loss: 0.37840554118156433, acc: 0.8461538553237915)
[2024-11-14 09:17:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:00][root][INFO] - Training Epoch: 2/2, step 6582/16670 completed (loss: 0.13702742755413055, acc: 0.9661017060279846)
[2024-11-14 09:17:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:00][root][INFO] - Training Epoch: 2/2, step 6583/16670 completed (loss: 0.07204657047986984, acc: 0.9607843160629272)
[2024-11-14 09:17:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:01][root][INFO] - Training Epoch: 2/2, step 6584/16670 completed (loss: 0.37096261978149414, acc: 0.9204545617103577)
[2024-11-14 09:17:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:01][root][INFO] - Training Epoch: 2/2, step 6585/16670 completed (loss: 0.062308575958013535, acc: 0.9736841917037964)
[2024-11-14 09:17:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:01][root][INFO] - Training Epoch: 2/2, step 6586/16670 completed (loss: 0.5213289856910706, acc: 0.9166666865348816)
[2024-11-14 09:17:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:02][root][INFO] - Training Epoch: 2/2, step 6587/16670 completed (loss: 0.4879174828529358, acc: 0.8928571343421936)
[2024-11-14 09:17:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:02][root][INFO] - Training Epoch: 2/2, step 6588/16670 completed (loss: 0.4172128736972809, acc: 0.9342105388641357)
[2024-11-14 09:17:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:02][root][INFO] - Training Epoch: 2/2, step 6589/16670 completed (loss: 0.19186915457248688, acc: 0.9629629850387573)
[2024-11-14 09:17:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:03][root][INFO] - Training Epoch: 2/2, step 6590/16670 completed (loss: 0.419439435005188, acc: 0.8787878751754761)
[2024-11-14 09:17:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:03][root][INFO] - Training Epoch: 2/2, step 6591/16670 completed (loss: 0.6956592202186584, acc: 0.9245283007621765)
[2024-11-14 09:17:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:03][root][INFO] - Training Epoch: 2/2, step 6592/16670 completed (loss: 0.29320427775382996, acc: 0.9166666865348816)
[2024-11-14 09:17:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:04][root][INFO] - Training Epoch: 2/2, step 6593/16670 completed (loss: 0.06600348651409149, acc: 0.9642857313156128)
[2024-11-14 09:17:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:04][root][INFO] - Training Epoch: 2/2, step 6594/16670 completed (loss: 0.21320591866970062, acc: 0.9152542352676392)
[2024-11-14 09:17:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:04][root][INFO] - Training Epoch: 2/2, step 6595/16670 completed (loss: 0.2227000594139099, acc: 0.9538461565971375)
[2024-11-14 09:17:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:05][root][INFO] - Training Epoch: 2/2, step 6596/16670 completed (loss: 0.10325463861227036, acc: 0.9622641801834106)
[2024-11-14 09:17:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:05][root][INFO] - Training Epoch: 2/2, step 6597/16670 completed (loss: 0.22333155572414398, acc: 0.9594594836235046)
[2024-11-14 09:17:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:06][root][INFO] - Training Epoch: 2/2, step 6598/16670 completed (loss: 0.01950475387275219, acc: 1.0)
[2024-11-14 09:17:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:06][root][INFO] - Training Epoch: 2/2, step 6599/16670 completed (loss: 0.18609336018562317, acc: 0.9512194991111755)
[2024-11-14 09:17:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:06][root][INFO] - Training Epoch: 2/2, step 6600/16670 completed (loss: 0.5076067447662354, acc: 0.8888888955116272)
[2024-11-14 09:17:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:07][root][INFO] - Training Epoch: 2/2, step 6601/16670 completed (loss: 0.13954435288906097, acc: 0.9655172228813171)
[2024-11-14 09:17:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:07][root][INFO] - Training Epoch: 2/2, step 6602/16670 completed (loss: 0.27806296944618225, acc: 0.9268292784690857)
[2024-11-14 09:17:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:07][root][INFO] - Training Epoch: 2/2, step 6603/16670 completed (loss: 0.534617006778717, acc: 0.8676470518112183)
[2024-11-14 09:17:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:08][root][INFO] - Training Epoch: 2/2, step 6604/16670 completed (loss: 0.5999188423156738, acc: 0.8641975522041321)
[2024-11-14 09:17:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:08][root][INFO] - Training Epoch: 2/2, step 6605/16670 completed (loss: 0.39724719524383545, acc: 0.930232584476471)
[2024-11-14 09:17:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:08][root][INFO] - Training Epoch: 2/2, step 6606/16670 completed (loss: 0.10804224759340286, acc: 0.9545454382896423)
[2024-11-14 09:17:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:09][root][INFO] - Training Epoch: 2/2, step 6607/16670 completed (loss: 0.12215124815702438, acc: 0.97826087474823)
[2024-11-14 09:17:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:09][root][INFO] - Training Epoch: 2/2, step 6608/16670 completed (loss: 0.5129852890968323, acc: 0.8888888955116272)
[2024-11-14 09:17:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:09][root][INFO] - Training Epoch: 2/2, step 6609/16670 completed (loss: 0.4360228180885315, acc: 0.9047619104385376)
[2024-11-14 09:17:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:10][root][INFO] - Training Epoch: 2/2, step 6610/16670 completed (loss: 0.2212846875190735, acc: 0.9436619877815247)
[2024-11-14 09:17:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:10][root][INFO] - Training Epoch: 2/2, step 6611/16670 completed (loss: 0.16576886177062988, acc: 0.936170220375061)
[2024-11-14 09:17:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:10][root][INFO] - Training Epoch: 2/2, step 6612/16670 completed (loss: 0.2641080915927887, acc: 0.9433962106704712)
[2024-11-14 09:17:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:11][root][INFO] - Training Epoch: 2/2, step 6613/16670 completed (loss: 0.12507364153862, acc: 0.9591836929321289)
[2024-11-14 09:17:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:11][root][INFO] - Training Epoch: 2/2, step 6614/16670 completed (loss: 0.20025424659252167, acc: 0.9594594836235046)
[2024-11-14 09:17:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:11][root][INFO] - Training Epoch: 2/2, step 6615/16670 completed (loss: 0.19209519028663635, acc: 0.96875)
[2024-11-14 09:17:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:12][root][INFO] - Training Epoch: 2/2, step 6616/16670 completed (loss: 0.07878399640321732, acc: 0.9791666865348816)
[2024-11-14 09:17:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:12][root][INFO] - Training Epoch: 2/2, step 6617/16670 completed (loss: 0.021756285801529884, acc: 1.0)
[2024-11-14 09:17:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:12][root][INFO] - Training Epoch: 2/2, step 6618/16670 completed (loss: 0.3379558026790619, acc: 0.9583333134651184)
[2024-11-14 09:17:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:13][root][INFO] - Training Epoch: 2/2, step 6619/16670 completed (loss: 0.158106729388237, acc: 0.9523809552192688)
[2024-11-14 09:17:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:13][root][INFO] - Training Epoch: 2/2, step 6620/16670 completed (loss: 0.15589752793312073, acc: 0.9649122953414917)
[2024-11-14 09:17:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:13][root][INFO] - Training Epoch: 2/2, step 6621/16670 completed (loss: 0.01215022150427103, acc: 1.0)
[2024-11-14 09:17:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:14][root][INFO] - Training Epoch: 2/2, step 6622/16670 completed (loss: 0.3350540101528168, acc: 0.9107142686843872)
[2024-11-14 09:17:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:14][root][INFO] - Training Epoch: 2/2, step 6623/16670 completed (loss: 0.572672426700592, acc: 0.9019607901573181)
[2024-11-14 09:17:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:14][root][INFO] - Training Epoch: 2/2, step 6624/16670 completed (loss: 0.13446316123008728, acc: 0.9710144996643066)
[2024-11-14 09:17:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:15][root][INFO] - Training Epoch: 2/2, step 6625/16670 completed (loss: 0.29847630858421326, acc: 0.9342105388641357)
[2024-11-14 09:17:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:15][root][INFO] - Training Epoch: 2/2, step 6626/16670 completed (loss: 0.12231185287237167, acc: 0.9649122953414917)
[2024-11-14 09:17:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:15][root][INFO] - Training Epoch: 2/2, step 6627/16670 completed (loss: 0.18760201334953308, acc: 0.9189189076423645)
[2024-11-14 09:17:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:16][root][INFO] - Training Epoch: 2/2, step 6628/16670 completed (loss: 0.5319816470146179, acc: 0.8666666746139526)
[2024-11-14 09:17:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:16][root][INFO] - Training Epoch: 2/2, step 6629/16670 completed (loss: 0.5289695858955383, acc: 0.9750000238418579)
[2024-11-14 09:17:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:16][root][INFO] - Training Epoch: 2/2, step 6630/16670 completed (loss: 0.036855343729257584, acc: 1.0)
[2024-11-14 09:17:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:17][root][INFO] - Training Epoch: 2/2, step 6631/16670 completed (loss: 0.25786828994750977, acc: 0.9189189076423645)
[2024-11-14 09:17:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:17][root][INFO] - Training Epoch: 2/2, step 6632/16670 completed (loss: 0.24258966743946075, acc: 0.9402984976768494)
[2024-11-14 09:17:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:17][root][INFO] - Training Epoch: 2/2, step 6633/16670 completed (loss: 0.08528554439544678, acc: 0.9743589758872986)
[2024-11-14 09:17:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:18][root][INFO] - Training Epoch: 2/2, step 6634/16670 completed (loss: 0.3776812255382538, acc: 0.9047619104385376)
[2024-11-14 09:17:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:18][root][INFO] - Training Epoch: 2/2, step 6635/16670 completed (loss: 0.6201057434082031, acc: 0.8108108043670654)
[2024-11-14 09:17:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:18][root][INFO] - Training Epoch: 2/2, step 6636/16670 completed (loss: 0.19794414937496185, acc: 0.9166666865348816)
[2024-11-14 09:17:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:19][root][INFO] - Training Epoch: 2/2, step 6637/16670 completed (loss: 0.15113314986228943, acc: 0.95652174949646)
[2024-11-14 09:17:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:19][root][INFO] - Training Epoch: 2/2, step 6638/16670 completed (loss: 0.4453466832637787, acc: 0.8765432238578796)
[2024-11-14 09:17:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:19][root][INFO] - Training Epoch: 2/2, step 6639/16670 completed (loss: 0.07993088662624359, acc: 0.9795918464660645)
[2024-11-14 09:17:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:19][root][INFO] - Training Epoch: 2/2, step 6640/16670 completed (loss: 0.020923534408211708, acc: 1.0)
[2024-11-14 09:17:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:20][root][INFO] - Training Epoch: 2/2, step 6641/16670 completed (loss: 0.35080546140670776, acc: 0.9428571462631226)
[2024-11-14 09:17:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:20][root][INFO] - Training Epoch: 2/2, step 6642/16670 completed (loss: 0.16439443826675415, acc: 0.9384615421295166)
[2024-11-14 09:17:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:20][root][INFO] - Training Epoch: 2/2, step 6643/16670 completed (loss: 0.20375080406665802, acc: 0.9399999976158142)
[2024-11-14 09:17:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:21][root][INFO] - Training Epoch: 2/2, step 6644/16670 completed (loss: 0.10610991716384888, acc: 0.9777777791023254)
[2024-11-14 09:17:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:21][root][INFO] - Training Epoch: 2/2, step 6645/16670 completed (loss: 0.45243918895721436, acc: 0.8823529481887817)
[2024-11-14 09:17:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:21][root][INFO] - Training Epoch: 2/2, step 6646/16670 completed (loss: 0.2200058400630951, acc: 0.9464285969734192)
[2024-11-14 09:17:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:22][root][INFO] - Training Epoch: 2/2, step 6647/16670 completed (loss: 0.4100866913795471, acc: 0.9200000166893005)
[2024-11-14 09:17:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:22][root][INFO] - Training Epoch: 2/2, step 6648/16670 completed (loss: 0.14581193029880524, acc: 0.9322034120559692)
[2024-11-14 09:17:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:22][root][INFO] - Training Epoch: 2/2, step 6649/16670 completed (loss: 0.2828817069530487, acc: 0.9189189076423645)
[2024-11-14 09:17:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:23][root][INFO] - Training Epoch: 2/2, step 6650/16670 completed (loss: 0.24421384930610657, acc: 0.9402984976768494)
[2024-11-14 09:17:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:23][root][INFO] - Training Epoch: 2/2, step 6651/16670 completed (loss: 0.15749038755893707, acc: 0.9111111164093018)
[2024-11-14 09:17:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:23][root][INFO] - Training Epoch: 2/2, step 6652/16670 completed (loss: 0.09326133131980896, acc: 0.9545454382896423)
[2024-11-14 09:17:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:24][root][INFO] - Training Epoch: 2/2, step 6653/16670 completed (loss: 0.32507649064064026, acc: 0.8703703880310059)
[2024-11-14 09:17:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:24][root][INFO] - Training Epoch: 2/2, step 6654/16670 completed (loss: 0.21664617955684662, acc: 0.9333333373069763)
[2024-11-14 09:17:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:24][root][INFO] - Training Epoch: 2/2, step 6655/16670 completed (loss: 0.49099117517471313, acc: 0.8805969953536987)
[2024-11-14 09:17:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:25][root][INFO] - Training Epoch: 2/2, step 6656/16670 completed (loss: 0.04310448095202446, acc: 1.0)
[2024-11-14 09:17:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:25][root][INFO] - Training Epoch: 2/2, step 6657/16670 completed (loss: 0.023057933896780014, acc: 1.0)
[2024-11-14 09:17:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:25][root][INFO] - Training Epoch: 2/2, step 6658/16670 completed (loss: 0.016925062984228134, acc: 1.0)
[2024-11-14 09:17:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:26][root][INFO] - Training Epoch: 2/2, step 6659/16670 completed (loss: 0.5886692404747009, acc: 0.8500000238418579)
[2024-11-14 09:17:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:26][root][INFO] - Training Epoch: 2/2, step 6660/16670 completed (loss: 0.09832131862640381, acc: 0.957446813583374)
[2024-11-14 09:17:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:26][root][INFO] - Training Epoch: 2/2, step 6661/16670 completed (loss: 0.07069385796785355, acc: 1.0)
[2024-11-14 09:17:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:27][root][INFO] - Training Epoch: 2/2, step 6662/16670 completed (loss: 0.029376160353422165, acc: 1.0)
[2024-11-14 09:17:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:27][root][INFO] - Training Epoch: 2/2, step 6663/16670 completed (loss: 0.024969859048724174, acc: 1.0)
[2024-11-14 09:17:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:27][root][INFO] - Training Epoch: 2/2, step 6664/16670 completed (loss: 0.45001041889190674, acc: 0.8620689511299133)
[2024-11-14 09:17:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:28][root][INFO] - Training Epoch: 2/2, step 6665/16670 completed (loss: 0.2788045108318329, acc: 0.9452054500579834)
[2024-11-14 09:17:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:28][root][INFO] - Training Epoch: 2/2, step 6666/16670 completed (loss: 0.24479401111602783, acc: 0.9473684430122375)
[2024-11-14 09:17:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:29][root][INFO] - Training Epoch: 2/2, step 6667/16670 completed (loss: 0.22860443592071533, acc: 0.9512194991111755)
[2024-11-14 09:17:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:29][root][INFO] - Training Epoch: 2/2, step 6668/16670 completed (loss: 0.25691908597946167, acc: 0.9677419066429138)
[2024-11-14 09:17:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:29][root][INFO] - Training Epoch: 2/2, step 6669/16670 completed (loss: 0.5360368490219116, acc: 0.892307698726654)
[2024-11-14 09:17:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:29][root][INFO] - Training Epoch: 2/2, step 6670/16670 completed (loss: 0.19061064720153809, acc: 0.9750000238418579)
[2024-11-14 09:17:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:30][root][INFO] - Training Epoch: 2/2, step 6671/16670 completed (loss: 0.30459627509117126, acc: 0.8876404762268066)
[2024-11-14 09:17:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:30][root][INFO] - Training Epoch: 2/2, step 6672/16670 completed (loss: 0.44137755036354065, acc: 0.8813559412956238)
[2024-11-14 09:17:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:31][root][INFO] - Training Epoch: 2/2, step 6673/16670 completed (loss: 0.2340836375951767, acc: 0.9655172228813171)
[2024-11-14 09:17:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:31][root][INFO] - Training Epoch: 2/2, step 6674/16670 completed (loss: 0.33502569794654846, acc: 0.9333333373069763)
[2024-11-14 09:17:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:31][root][INFO] - Training Epoch: 2/2, step 6675/16670 completed (loss: 0.15437740087509155, acc: 0.976190447807312)
[2024-11-14 09:17:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:32][root][INFO] - Training Epoch: 2/2, step 6676/16670 completed (loss: 0.10066746920347214, acc: 0.930232584476471)
[2024-11-14 09:17:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:32][root][INFO] - Training Epoch: 2/2, step 6677/16670 completed (loss: 0.14755110442638397, acc: 0.9824561476707458)
[2024-11-14 09:17:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:32][root][INFO] - Training Epoch: 2/2, step 6678/16670 completed (loss: 0.02886272594332695, acc: 1.0)
[2024-11-14 09:17:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:33][root][INFO] - Training Epoch: 2/2, step 6679/16670 completed (loss: 0.11069107055664062, acc: 0.9807692170143127)
[2024-11-14 09:17:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:33][root][INFO] - Training Epoch: 2/2, step 6680/16670 completed (loss: 0.22196069359779358, acc: 0.9473684430122375)
[2024-11-14 09:17:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:33][root][INFO] - Training Epoch: 2/2, step 6681/16670 completed (loss: 0.20508931577205658, acc: 0.9516128897666931)
[2024-11-14 09:17:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:34][root][INFO] - Training Epoch: 2/2, step 6682/16670 completed (loss: 0.015685753896832466, acc: 1.0)
[2024-11-14 09:17:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:34][root][INFO] - Training Epoch: 2/2, step 6683/16670 completed (loss: 0.16863834857940674, acc: 0.9215686321258545)
[2024-11-14 09:17:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:34][root][INFO] - Training Epoch: 2/2, step 6684/16670 completed (loss: 0.6445469856262207, acc: 0.8524590134620667)
[2024-11-14 09:17:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:35][root][INFO] - Training Epoch: 2/2, step 6685/16670 completed (loss: 0.5435543656349182, acc: 0.8775510191917419)
[2024-11-14 09:17:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:35][root][INFO] - Training Epoch: 2/2, step 6686/16670 completed (loss: 0.38843730092048645, acc: 0.9545454382896423)
[2024-11-14 09:17:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:35][root][INFO] - Training Epoch: 2/2, step 6687/16670 completed (loss: 0.03598984330892563, acc: 1.0)
[2024-11-14 09:17:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:36][root][INFO] - Training Epoch: 2/2, step 6688/16670 completed (loss: 0.5188854336738586, acc: 0.8870967626571655)
[2024-11-14 09:17:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:36][root][INFO] - Training Epoch: 2/2, step 6689/16670 completed (loss: 0.3911791145801544, acc: 0.9365079402923584)
[2024-11-14 09:17:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:37][root][INFO] - Training Epoch: 2/2, step 6690/16670 completed (loss: 0.39010900259017944, acc: 0.9042553305625916)
[2024-11-14 09:17:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:37][root][INFO] - Training Epoch: 2/2, step 6691/16670 completed (loss: 0.20422841608524323, acc: 0.9345794320106506)
[2024-11-14 09:17:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:37][root][INFO] - Training Epoch: 2/2, step 6692/16670 completed (loss: 0.4061773121356964, acc: 0.8974359035491943)
[2024-11-14 09:17:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:38][root][INFO] - Training Epoch: 2/2, step 6693/16670 completed (loss: 0.2765338122844696, acc: 0.925000011920929)
[2024-11-14 09:17:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:38][root][INFO] - Training Epoch: 2/2, step 6694/16670 completed (loss: 0.033077068626880646, acc: 1.0)
[2024-11-14 09:17:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:38][root][INFO] - Training Epoch: 2/2, step 6695/16670 completed (loss: 0.27965620160102844, acc: 0.9230769276618958)
[2024-11-14 09:17:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:39][root][INFO] - Training Epoch: 2/2, step 6696/16670 completed (loss: 0.7341335415840149, acc: 0.8518518805503845)
[2024-11-14 09:17:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:39][root][INFO] - Training Epoch: 2/2, step 6697/16670 completed (loss: 0.09122253209352493, acc: 0.9803921580314636)
[2024-11-14 09:17:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:39][root][INFO] - Training Epoch: 2/2, step 6698/16670 completed (loss: 0.0823604092001915, acc: 0.9777777791023254)
[2024-11-14 09:17:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:40][root][INFO] - Training Epoch: 2/2, step 6699/16670 completed (loss: 0.041118308901786804, acc: 1.0)
[2024-11-14 09:17:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:40][root][INFO] - Training Epoch: 2/2, step 6700/16670 completed (loss: 0.05033636838197708, acc: 1.0)
[2024-11-14 09:17:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:40][root][INFO] - Training Epoch: 2/2, step 6701/16670 completed (loss: 0.39687129855155945, acc: 0.8823529481887817)
[2024-11-14 09:17:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:41][root][INFO] - Training Epoch: 2/2, step 6702/16670 completed (loss: 0.20134586095809937, acc: 0.8947368264198303)
[2024-11-14 09:17:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:41][root][INFO] - Training Epoch: 2/2, step 6703/16670 completed (loss: 0.31319963932037354, acc: 0.9512194991111755)
[2024-11-14 09:17:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:41][root][INFO] - Training Epoch: 2/2, step 6704/16670 completed (loss: 0.4437008202075958, acc: 0.8636363744735718)
[2024-11-14 09:17:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:42][root][INFO] - Training Epoch: 2/2, step 6705/16670 completed (loss: 0.2272927314043045, acc: 0.9240506291389465)
[2024-11-14 09:17:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:42][root][INFO] - Training Epoch: 2/2, step 6706/16670 completed (loss: 0.12059443444013596, acc: 0.9682539701461792)
[2024-11-14 09:17:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:42][root][INFO] - Training Epoch: 2/2, step 6707/16670 completed (loss: 0.1415896713733673, acc: 0.9454545378684998)
[2024-11-14 09:17:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:43][root][INFO] - Training Epoch: 2/2, step 6708/16670 completed (loss: 0.04415556788444519, acc: 1.0)
[2024-11-14 09:17:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:43][root][INFO] - Training Epoch: 2/2, step 6709/16670 completed (loss: 0.40389934182167053, acc: 0.9047619104385376)
[2024-11-14 09:17:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:43][root][INFO] - Training Epoch: 2/2, step 6710/16670 completed (loss: 0.05753644183278084, acc: 1.0)
[2024-11-14 09:17:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:44][root][INFO] - Training Epoch: 2/2, step 6711/16670 completed (loss: 0.05813290551304817, acc: 1.0)
[2024-11-14 09:17:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:44][root][INFO] - Training Epoch: 2/2, step 6712/16670 completed (loss: 0.14122553169727325, acc: 0.9607843160629272)
[2024-11-14 09:17:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:44][root][INFO] - Training Epoch: 2/2, step 6713/16670 completed (loss: 0.3099546432495117, acc: 0.9242424368858337)
[2024-11-14 09:17:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:45][root][INFO] - Training Epoch: 2/2, step 6714/16670 completed (loss: 0.21276813745498657, acc: 0.9305555820465088)
[2024-11-14 09:17:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:45][root][INFO] - Training Epoch: 2/2, step 6715/16670 completed (loss: 0.1646297574043274, acc: 0.9428571462631226)
[2024-11-14 09:17:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:45][root][INFO] - Training Epoch: 2/2, step 6716/16670 completed (loss: 0.14477358758449554, acc: 0.9857142567634583)
[2024-11-14 09:17:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:46][root][INFO] - Training Epoch: 2/2, step 6717/16670 completed (loss: 0.02999000810086727, acc: 1.0)
[2024-11-14 09:17:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:46][root][INFO] - Training Epoch: 2/2, step 6718/16670 completed (loss: 0.523324728012085, acc: 0.8275862336158752)
[2024-11-14 09:17:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:46][root][INFO] - Training Epoch: 2/2, step 6719/16670 completed (loss: 0.21878276765346527, acc: 0.9518072009086609)
[2024-11-14 09:17:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:47][root][INFO] - Training Epoch: 2/2, step 6720/16670 completed (loss: 0.19430392980575562, acc: 0.9117646813392639)
[2024-11-14 09:17:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:47][root][INFO] - Training Epoch: 2/2, step 6721/16670 completed (loss: 0.4214366376399994, acc: 0.8965517282485962)
[2024-11-14 09:17:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:47][root][INFO] - Training Epoch: 2/2, step 6722/16670 completed (loss: 0.4436102509498596, acc: 0.8974359035491943)
[2024-11-14 09:17:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:48][root][INFO] - Training Epoch: 2/2, step 6723/16670 completed (loss: 0.20249758660793304, acc: 0.931034505367279)
[2024-11-14 09:17:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:48][root][INFO] - Training Epoch: 2/2, step 6724/16670 completed (loss: 0.49992817640304565, acc: 0.9156626462936401)
[2024-11-14 09:17:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:48][root][INFO] - Training Epoch: 2/2, step 6725/16670 completed (loss: 0.19180428981781006, acc: 0.9444444179534912)
[2024-11-14 09:17:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:49][root][INFO] - Training Epoch: 2/2, step 6726/16670 completed (loss: 0.3812737464904785, acc: 0.8863636255264282)
[2024-11-14 09:17:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:49][root][INFO] - Training Epoch: 2/2, step 6727/16670 completed (loss: 0.05742086097598076, acc: 0.9811320900917053)
[2024-11-14 09:17:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:49][root][INFO] - Training Epoch: 2/2, step 6728/16670 completed (loss: 0.20152616500854492, acc: 0.9402984976768494)
[2024-11-14 09:17:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:50][root][INFO] - Training Epoch: 2/2, step 6729/16670 completed (loss: 0.13334910571575165, acc: 0.9200000166893005)
[2024-11-14 09:17:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:50][root][INFO] - Training Epoch: 2/2, step 6730/16670 completed (loss: 0.1647486537694931, acc: 0.939393937587738)
[2024-11-14 09:17:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:50][root][INFO] - Training Epoch: 2/2, step 6731/16670 completed (loss: 0.19219852983951569, acc: 0.9803921580314636)
[2024-11-14 09:17:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:51][root][INFO] - Training Epoch: 2/2, step 6732/16670 completed (loss: 0.23477225005626678, acc: 0.9545454382896423)
[2024-11-14 09:17:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:51][root][INFO] - Training Epoch: 2/2, step 6733/16670 completed (loss: 0.1358492225408554, acc: 0.9642857313156128)
[2024-11-14 09:17:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:51][root][INFO] - Training Epoch: 2/2, step 6734/16670 completed (loss: 0.4353472888469696, acc: 0.8867924809455872)
[2024-11-14 09:17:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:52][root][INFO] - Training Epoch: 2/2, step 6735/16670 completed (loss: 0.3194476366043091, acc: 0.9298245906829834)
[2024-11-14 09:17:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:52][root][INFO] - Training Epoch: 2/2, step 6736/16670 completed (loss: 0.1928280144929886, acc: 0.939393937587738)
[2024-11-14 09:17:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:52][root][INFO] - Training Epoch: 2/2, step 6737/16670 completed (loss: 0.11403484642505646, acc: 0.9701492786407471)
[2024-11-14 09:17:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:52][root][INFO] - Training Epoch: 2/2, step 6738/16670 completed (loss: 0.128147691488266, acc: 0.9750000238418579)
[2024-11-14 09:17:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:53][root][INFO] - Training Epoch: 2/2, step 6739/16670 completed (loss: 0.22880208492279053, acc: 0.9387755393981934)
[2024-11-14 09:17:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:53][root][INFO] - Training Epoch: 2/2, step 6740/16670 completed (loss: 0.1021619513630867, acc: 0.9821428656578064)
[2024-11-14 09:17:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:53][root][INFO] - Training Epoch: 2/2, step 6741/16670 completed (loss: 0.2702522277832031, acc: 0.9473684430122375)
[2024-11-14 09:17:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:54][root][INFO] - Training Epoch: 2/2, step 6742/16670 completed (loss: 0.3290885388851166, acc: 0.9350649118423462)
[2024-11-14 09:17:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:54][root][INFO] - Training Epoch: 2/2, step 6743/16670 completed (loss: 0.41358664631843567, acc: 0.8823529481887817)
[2024-11-14 09:17:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:54][root][INFO] - Training Epoch: 2/2, step 6744/16670 completed (loss: 0.0891244113445282, acc: 0.9838709831237793)
[2024-11-14 09:17:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:55][root][INFO] - Training Epoch: 2/2, step 6745/16670 completed (loss: 0.16749510169029236, acc: 0.9756097793579102)
[2024-11-14 09:17:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:55][root][INFO] - Training Epoch: 2/2, step 6746/16670 completed (loss: 0.2933746576309204, acc: 0.9375)
[2024-11-14 09:17:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:55][root][INFO] - Training Epoch: 2/2, step 6747/16670 completed (loss: 0.04425771161913872, acc: 0.978723406791687)
[2024-11-14 09:17:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:56][root][INFO] - Training Epoch: 2/2, step 6748/16670 completed (loss: 0.19773255288600922, acc: 0.953125)
[2024-11-14 09:17:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:56][root][INFO] - Training Epoch: 2/2, step 6749/16670 completed (loss: 0.061435356736183167, acc: 0.9814814925193787)
[2024-11-14 09:17:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:56][root][INFO] - Training Epoch: 2/2, step 6750/16670 completed (loss: 0.3304128050804138, acc: 0.9019607901573181)
[2024-11-14 09:17:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:57][root][INFO] - Training Epoch: 2/2, step 6751/16670 completed (loss: 0.3581068813800812, acc: 0.9024389982223511)
[2024-11-14 09:17:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:57][root][INFO] - Training Epoch: 2/2, step 6752/16670 completed (loss: 0.5289820432662964, acc: 0.9090909361839294)
[2024-11-14 09:17:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:57][root][INFO] - Training Epoch: 2/2, step 6753/16670 completed (loss: 0.15899987518787384, acc: 0.957446813583374)
[2024-11-14 09:17:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:57][root][INFO] - Training Epoch: 2/2, step 6754/16670 completed (loss: 0.25385355949401855, acc: 0.9130434989929199)
[2024-11-14 09:17:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:58][root][INFO] - Training Epoch: 2/2, step 6755/16670 completed (loss: 0.19410419464111328, acc: 0.9436619877815247)
[2024-11-14 09:17:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:58][root][INFO] - Training Epoch: 2/2, step 6756/16670 completed (loss: 0.5110530853271484, acc: 0.9130434989929199)
[2024-11-14 09:17:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:59][root][INFO] - Training Epoch: 2/2, step 6757/16670 completed (loss: 0.25346484780311584, acc: 0.9399999976158142)
[2024-11-14 09:17:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:59][root][INFO] - Training Epoch: 2/2, step 6758/16670 completed (loss: 0.03133818507194519, acc: 1.0)
[2024-11-14 09:17:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:59][root][INFO] - Training Epoch: 2/2, step 6759/16670 completed (loss: 0.17843933403491974, acc: 0.9411764740943909)
[2024-11-14 09:17:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:17:59][root][INFO] - Training Epoch: 2/2, step 6760/16670 completed (loss: 0.3297756612300873, acc: 0.921875)
[2024-11-14 09:17:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:00][root][INFO] - Training Epoch: 2/2, step 6761/16670 completed (loss: 0.07575815916061401, acc: 0.9767441749572754)
[2024-11-14 09:18:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:00][root][INFO] - Training Epoch: 2/2, step 6762/16670 completed (loss: 0.2630249857902527, acc: 0.9142857193946838)
[2024-11-14 09:18:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:00][root][INFO] - Training Epoch: 2/2, step 6763/16670 completed (loss: 0.5694829821586609, acc: 0.8787878751754761)
[2024-11-14 09:18:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:01][root][INFO] - Training Epoch: 2/2, step 6764/16670 completed (loss: 0.14345300197601318, acc: 0.96875)
[2024-11-14 09:18:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:01][root][INFO] - Training Epoch: 2/2, step 6765/16670 completed (loss: 0.31832486391067505, acc: 0.9230769276618958)
[2024-11-14 09:18:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:01][root][INFO] - Training Epoch: 2/2, step 6766/16670 completed (loss: 0.5889892578125, acc: 0.8840579986572266)
[2024-11-14 09:18:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:02][root][INFO] - Training Epoch: 2/2, step 6767/16670 completed (loss: 0.21995629370212555, acc: 0.9552238583564758)
[2024-11-14 09:18:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:02][root][INFO] - Training Epoch: 2/2, step 6768/16670 completed (loss: 0.1678476780653, acc: 0.936170220375061)
[2024-11-14 09:18:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:02][root][INFO] - Training Epoch: 2/2, step 6769/16670 completed (loss: 0.3146800398826599, acc: 0.9743589758872986)
[2024-11-14 09:18:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:03][root][INFO] - Training Epoch: 2/2, step 6770/16670 completed (loss: 0.10958857834339142, acc: 0.9696969985961914)
[2024-11-14 09:18:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:03][root][INFO] - Training Epoch: 2/2, step 6771/16670 completed (loss: 0.42024096846580505, acc: 0.875)
[2024-11-14 09:18:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:03][root][INFO] - Training Epoch: 2/2, step 6772/16670 completed (loss: 0.3063024580478668, acc: 0.9200000166893005)
[2024-11-14 09:18:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:04][root][INFO] - Training Epoch: 2/2, step 6773/16670 completed (loss: 0.09511474519968033, acc: 0.9629629850387573)
[2024-11-14 09:18:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:04][root][INFO] - Training Epoch: 2/2, step 6774/16670 completed (loss: 0.3913038671016693, acc: 0.9142857193946838)
[2024-11-14 09:18:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:04][root][INFO] - Training Epoch: 2/2, step 6775/16670 completed (loss: 0.15901362895965576, acc: 0.9795918464660645)
[2024-11-14 09:18:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:05][root][INFO] - Training Epoch: 2/2, step 6776/16670 completed (loss: 0.5216400623321533, acc: 0.90625)
[2024-11-14 09:18:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:05][root][INFO] - Training Epoch: 2/2, step 6777/16670 completed (loss: 0.3573662042617798, acc: 0.90625)
[2024-11-14 09:18:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:06][root][INFO] - Training Epoch: 2/2, step 6778/16670 completed (loss: 0.1633196622133255, acc: 0.9387755393981934)
[2024-11-14 09:18:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:06][root][INFO] - Training Epoch: 2/2, step 6779/16670 completed (loss: 0.5115997195243835, acc: 0.8518518805503845)
[2024-11-14 09:18:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:06][root][INFO] - Training Epoch: 2/2, step 6780/16670 completed (loss: 0.3155175447463989, acc: 0.9027777910232544)
[2024-11-14 09:18:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:07][root][INFO] - Training Epoch: 2/2, step 6781/16670 completed (loss: 0.20277783274650574, acc: 0.9268292784690857)
[2024-11-14 09:18:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:07][root][INFO] - Training Epoch: 2/2, step 6782/16670 completed (loss: 0.09731604158878326, acc: 0.9729729890823364)
[2024-11-14 09:18:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:07][root][INFO] - Training Epoch: 2/2, step 6783/16670 completed (loss: 0.03541234880685806, acc: 1.0)
[2024-11-14 09:18:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:08][root][INFO] - Training Epoch: 2/2, step 6784/16670 completed (loss: 0.12905897200107574, acc: 0.9555555582046509)
[2024-11-14 09:18:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:08][root][INFO] - Training Epoch: 2/2, step 6785/16670 completed (loss: 0.6141988039016724, acc: 0.8999999761581421)
[2024-11-14 09:18:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:08][root][INFO] - Training Epoch: 2/2, step 6786/16670 completed (loss: 0.2506062686443329, acc: 0.9122806787490845)
[2024-11-14 09:18:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:09][root][INFO] - Training Epoch: 2/2, step 6787/16670 completed (loss: 0.13961641490459442, acc: 0.9795918464660645)
[2024-11-14 09:18:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:09][root][INFO] - Training Epoch: 2/2, step 6788/16670 completed (loss: 0.09880492836236954, acc: 0.9729729890823364)
[2024-11-14 09:18:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:09][root][INFO] - Training Epoch: 2/2, step 6789/16670 completed (loss: 0.20003367960453033, acc: 0.9411764740943909)
[2024-11-14 09:18:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:10][root][INFO] - Training Epoch: 2/2, step 6790/16670 completed (loss: 0.029405374079942703, acc: 1.0)
[2024-11-14 09:18:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:10][root][INFO] - Training Epoch: 2/2, step 6791/16670 completed (loss: 0.29141610860824585, acc: 0.9047619104385376)
[2024-11-14 09:18:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:10][root][INFO] - Training Epoch: 2/2, step 6792/16670 completed (loss: 0.6912633180618286, acc: 0.8983050584793091)
[2024-11-14 09:18:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:11][root][INFO] - Training Epoch: 2/2, step 6793/16670 completed (loss: 0.5634572505950928, acc: 0.9090909361839294)
[2024-11-14 09:18:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:11][root][INFO] - Training Epoch: 2/2, step 6794/16670 completed (loss: 0.24276643991470337, acc: 0.9166666865348816)
[2024-11-14 09:18:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:12][root][INFO] - Training Epoch: 2/2, step 6795/16670 completed (loss: 0.20601102709770203, acc: 0.9512194991111755)
[2024-11-14 09:18:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:12][root][INFO] - Training Epoch: 2/2, step 6796/16670 completed (loss: 0.3322323262691498, acc: 0.9200000166893005)
[2024-11-14 09:18:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:12][root][INFO] - Training Epoch: 2/2, step 6797/16670 completed (loss: 0.23770099878311157, acc: 0.9420289993286133)
[2024-11-14 09:18:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:13][root][INFO] - Training Epoch: 2/2, step 6798/16670 completed (loss: 0.14240655303001404, acc: 0.9523809552192688)
[2024-11-14 09:18:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:13][root][INFO] - Training Epoch: 2/2, step 6799/16670 completed (loss: 0.498188316822052, acc: 0.9090909361839294)
[2024-11-14 09:18:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:13][root][INFO] - Training Epoch: 2/2, step 6800/16670 completed (loss: 0.5067777633666992, acc: 0.914893627166748)
[2024-11-14 09:18:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:14][root][INFO] - Training Epoch: 2/2, step 6801/16670 completed (loss: 0.1297781616449356, acc: 0.9830508232116699)
[2024-11-14 09:18:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:14][root][INFO] - Training Epoch: 2/2, step 6802/16670 completed (loss: 0.19316214323043823, acc: 0.9661017060279846)
[2024-11-14 09:18:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:14][root][INFO] - Training Epoch: 2/2, step 6803/16670 completed (loss: 0.1447092741727829, acc: 0.9803921580314636)
[2024-11-14 09:18:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:15][root][INFO] - Training Epoch: 2/2, step 6804/16670 completed (loss: 0.1663268655538559, acc: 0.953125)
[2024-11-14 09:18:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:15][root][INFO] - Training Epoch: 2/2, step 6805/16670 completed (loss: 0.3231762945652008, acc: 0.8974359035491943)
[2024-11-14 09:18:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:15][root][INFO] - Training Epoch: 2/2, step 6806/16670 completed (loss: 0.5232064127922058, acc: 0.8888888955116272)
[2024-11-14 09:18:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:16][root][INFO] - Training Epoch: 2/2, step 6807/16670 completed (loss: 0.03934333473443985, acc: 1.0)
[2024-11-14 09:18:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:16][root][INFO] - Training Epoch: 2/2, step 6808/16670 completed (loss: 0.43915411829948425, acc: 0.8999999761581421)
[2024-11-14 09:18:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:17][root][INFO] - Training Epoch: 2/2, step 6809/16670 completed (loss: 0.3921092748641968, acc: 0.9090909361839294)
[2024-11-14 09:18:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:17][root][INFO] - Training Epoch: 2/2, step 6810/16670 completed (loss: 0.2696777284145355, acc: 0.9298245906829834)
[2024-11-14 09:18:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:17][root][INFO] - Training Epoch: 2/2, step 6811/16670 completed (loss: 0.3280882239341736, acc: 0.9137930870056152)
[2024-11-14 09:18:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:18][root][INFO] - Training Epoch: 2/2, step 6812/16670 completed (loss: 0.33541804552078247, acc: 0.9459459185600281)
[2024-11-14 09:18:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:18][root][INFO] - Training Epoch: 2/2, step 6813/16670 completed (loss: 0.48057395219802856, acc: 0.9230769276618958)
[2024-11-14 09:18:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:18][root][INFO] - Training Epoch: 2/2, step 6814/16670 completed (loss: 0.1627025604248047, acc: 0.9714285731315613)
[2024-11-14 09:18:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:19][root][INFO] - Training Epoch: 2/2, step 6815/16670 completed (loss: 0.15743598341941833, acc: 0.9714285731315613)
[2024-11-14 09:18:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:19][root][INFO] - Training Epoch: 2/2, step 6816/16670 completed (loss: 0.4412407875061035, acc: 0.9166666865348816)
[2024-11-14 09:18:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:19][root][INFO] - Training Epoch: 2/2, step 6817/16670 completed (loss: 0.10683358460664749, acc: 0.9666666388511658)
[2024-11-14 09:18:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:20][root][INFO] - Training Epoch: 2/2, step 6818/16670 completed (loss: 0.5403855443000793, acc: 0.8679245114326477)
[2024-11-14 09:18:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:20][root][INFO] - Training Epoch: 2/2, step 6819/16670 completed (loss: 0.03656281903386116, acc: 1.0)
[2024-11-14 09:18:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:20][root][INFO] - Training Epoch: 2/2, step 6820/16670 completed (loss: 0.1467628926038742, acc: 0.976190447807312)
[2024-11-14 09:18:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:21][root][INFO] - Training Epoch: 2/2, step 6821/16670 completed (loss: 0.39753231406211853, acc: 0.9428571462631226)
[2024-11-14 09:18:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:21][root][INFO] - Training Epoch: 2/2, step 6822/16670 completed (loss: 0.09645649045705795, acc: 0.9444444179534912)
[2024-11-14 09:18:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:22][root][INFO] - Training Epoch: 2/2, step 6823/16670 completed (loss: 0.5420935153961182, acc: 0.8472222089767456)
[2024-11-14 09:18:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:22][root][INFO] - Training Epoch: 2/2, step 6824/16670 completed (loss: 0.5837424993515015, acc: 0.8947368264198303)
[2024-11-14 09:18:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:22][root][INFO] - Training Epoch: 2/2, step 6825/16670 completed (loss: 0.2639791667461395, acc: 0.9193548560142517)
[2024-11-14 09:18:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:23][root][INFO] - Training Epoch: 2/2, step 6826/16670 completed (loss: 0.23493456840515137, acc: 0.9512194991111755)
[2024-11-14 09:18:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:23][root][INFO] - Training Epoch: 2/2, step 6827/16670 completed (loss: 0.10540782660245895, acc: 0.9807692170143127)
[2024-11-14 09:18:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:23][root][INFO] - Training Epoch: 2/2, step 6828/16670 completed (loss: 0.08814632147550583, acc: 0.9710144996643066)
[2024-11-14 09:18:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:24][root][INFO] - Training Epoch: 2/2, step 6829/16670 completed (loss: 0.011076869443058968, acc: 1.0)
[2024-11-14 09:18:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:24][root][INFO] - Training Epoch: 2/2, step 6830/16670 completed (loss: 0.2929375171661377, acc: 0.9375)
[2024-11-14 09:18:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:24][root][INFO] - Training Epoch: 2/2, step 6831/16670 completed (loss: 0.40735065937042236, acc: 0.9178082346916199)
[2024-11-14 09:18:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:25][root][INFO] - Training Epoch: 2/2, step 6832/16670 completed (loss: 0.2404758185148239, acc: 0.970588207244873)
[2024-11-14 09:18:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:25][root][INFO] - Training Epoch: 2/2, step 6833/16670 completed (loss: 0.15408144891262054, acc: 0.978723406791687)
[2024-11-14 09:18:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:25][root][INFO] - Training Epoch: 2/2, step 6834/16670 completed (loss: 0.1186625063419342, acc: 0.96875)
[2024-11-14 09:18:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:26][root][INFO] - Training Epoch: 2/2, step 6835/16670 completed (loss: 0.41318610310554504, acc: 0.9253731369972229)
[2024-11-14 09:18:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:26][root][INFO] - Training Epoch: 2/2, step 6836/16670 completed (loss: 0.006445521023124456, acc: 1.0)
[2024-11-14 09:18:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:27][root][INFO] - Training Epoch: 2/2, step 6837/16670 completed (loss: 0.2399125099182129, acc: 0.9473684430122375)
[2024-11-14 09:18:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:27][root][INFO] - Training Epoch: 2/2, step 6838/16670 completed (loss: 0.0672198161482811, acc: 0.9863013625144958)
[2024-11-14 09:18:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:27][root][INFO] - Training Epoch: 2/2, step 6839/16670 completed (loss: 0.40209904313087463, acc: 0.875)
[2024-11-14 09:18:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:28][root][INFO] - Training Epoch: 2/2, step 6840/16670 completed (loss: 0.2330256849527359, acc: 0.96875)
[2024-11-14 09:18:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:28][root][INFO] - Training Epoch: 2/2, step 6841/16670 completed (loss: 0.17225392162799835, acc: 0.9464285969734192)
[2024-11-14 09:18:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:28][root][INFO] - Training Epoch: 2/2, step 6842/16670 completed (loss: 0.32305610179901123, acc: 0.9333333373069763)
[2024-11-14 09:18:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:29][root][INFO] - Training Epoch: 2/2, step 6843/16670 completed (loss: 0.23361803591251373, acc: 0.8977272510528564)
[2024-11-14 09:18:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:29][root][INFO] - Training Epoch: 2/2, step 6844/16670 completed (loss: 0.32103341817855835, acc: 0.9069767594337463)
[2024-11-14 09:18:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:29][root][INFO] - Training Epoch: 2/2, step 6845/16670 completed (loss: 0.0649356096982956, acc: 0.9801980257034302)
[2024-11-14 09:18:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:30][root][INFO] - Training Epoch: 2/2, step 6846/16670 completed (loss: 0.47863009572029114, acc: 0.8571428656578064)
[2024-11-14 09:18:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:30][root][INFO] - Training Epoch: 2/2, step 6847/16670 completed (loss: 0.3181725740432739, acc: 0.9016393423080444)
[2024-11-14 09:18:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:30][root][INFO] - Training Epoch: 2/2, step 6848/16670 completed (loss: 0.21283407509326935, acc: 0.9375)
[2024-11-14 09:18:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:31][root][INFO] - Training Epoch: 2/2, step 6849/16670 completed (loss: 0.20741117000579834, acc: 0.9444444179534912)
[2024-11-14 09:18:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:31][root][INFO] - Training Epoch: 2/2, step 6850/16670 completed (loss: 0.06048491969704628, acc: 0.9855072498321533)
[2024-11-14 09:18:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:31][root][INFO] - Training Epoch: 2/2, step 6851/16670 completed (loss: 0.03389957919716835, acc: 1.0)
[2024-11-14 09:18:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:32][root][INFO] - Training Epoch: 2/2, step 6852/16670 completed (loss: 0.5742672085762024, acc: 0.8602150678634644)
[2024-11-14 09:18:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:32][root][INFO] - Training Epoch: 2/2, step 6853/16670 completed (loss: 0.19414998590946198, acc: 0.9512194991111755)
[2024-11-14 09:18:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:32][root][INFO] - Training Epoch: 2/2, step 6854/16670 completed (loss: 0.12238729745149612, acc: 0.9200000166893005)
[2024-11-14 09:18:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:33][root][INFO] - Training Epoch: 2/2, step 6855/16670 completed (loss: 0.15053895115852356, acc: 0.9473684430122375)
[2024-11-14 09:18:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:33][root][INFO] - Training Epoch: 2/2, step 6856/16670 completed (loss: 0.1679334193468094, acc: 0.9642857313156128)
[2024-11-14 09:18:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:34][root][INFO] - Training Epoch: 2/2, step 6857/16670 completed (loss: 0.11077013611793518, acc: 0.9466666579246521)
[2024-11-14 09:18:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:34][root][INFO] - Training Epoch: 2/2, step 6858/16670 completed (loss: 0.18427829444408417, acc: 0.9402984976768494)
[2024-11-14 09:18:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:34][root][INFO] - Training Epoch: 2/2, step 6859/16670 completed (loss: 0.22007685899734497, acc: 0.953125)
[2024-11-14 09:18:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:35][root][INFO] - Training Epoch: 2/2, step 6860/16670 completed (loss: 0.2556939423084259, acc: 0.931034505367279)
[2024-11-14 09:18:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:35][root][INFO] - Training Epoch: 2/2, step 6861/16670 completed (loss: 0.37377873063087463, acc: 0.9102563858032227)
[2024-11-14 09:18:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:35][root][INFO] - Training Epoch: 2/2, step 6862/16670 completed (loss: 0.16601914167404175, acc: 0.9444444179534912)
[2024-11-14 09:18:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:36][root][INFO] - Training Epoch: 2/2, step 6863/16670 completed (loss: 0.30121052265167236, acc: 0.9024389982223511)
[2024-11-14 09:18:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:36][root][INFO] - Training Epoch: 2/2, step 6864/16670 completed (loss: 0.4906558096408844, acc: 0.9318181872367859)
[2024-11-14 09:18:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:36][root][INFO] - Training Epoch: 2/2, step 6865/16670 completed (loss: 0.2553727924823761, acc: 0.9137930870056152)
[2024-11-14 09:18:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:37][root][INFO] - Training Epoch: 2/2, step 6866/16670 completed (loss: 0.4209420680999756, acc: 0.8913043737411499)
[2024-11-14 09:18:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:37][root][INFO] - Training Epoch: 2/2, step 6867/16670 completed (loss: 0.32767730951309204, acc: 0.9264705777168274)
[2024-11-14 09:18:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:38][root][INFO] - Training Epoch: 2/2, step 6868/16670 completed (loss: 0.10889960825443268, acc: 0.977011501789093)
[2024-11-14 09:18:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:38][root][INFO] - Training Epoch: 2/2, step 6869/16670 completed (loss: 0.19374720752239227, acc: 0.9259259104728699)
[2024-11-14 09:18:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:38][root][INFO] - Training Epoch: 2/2, step 6870/16670 completed (loss: 0.39660534262657166, acc: 0.8965517282485962)
[2024-11-14 09:18:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:39][root][INFO] - Training Epoch: 2/2, step 6871/16670 completed (loss: 0.3931518793106079, acc: 0.8703703880310059)
[2024-11-14 09:18:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:39][root][INFO] - Training Epoch: 2/2, step 6872/16670 completed (loss: 0.29143431782722473, acc: 0.8857142925262451)
[2024-11-14 09:18:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:39][root][INFO] - Training Epoch: 2/2, step 6873/16670 completed (loss: 0.35406845808029175, acc: 0.9494949579238892)
[2024-11-14 09:18:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:40][root][INFO] - Training Epoch: 2/2, step 6874/16670 completed (loss: 0.23646366596221924, acc: 0.9285714030265808)
[2024-11-14 09:18:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:40][root][INFO] - Training Epoch: 2/2, step 6875/16670 completed (loss: 0.1618044674396515, acc: 0.931506872177124)
[2024-11-14 09:18:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:41][root][INFO] - Training Epoch: 2/2, step 6876/16670 completed (loss: 0.09991773962974548, acc: 0.9873417615890503)
[2024-11-14 09:18:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:41][root][INFO] - Training Epoch: 2/2, step 6877/16670 completed (loss: 0.19679762423038483, acc: 0.9726027250289917)
[2024-11-14 09:18:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:41][root][INFO] - Training Epoch: 2/2, step 6878/16670 completed (loss: 0.17167142033576965, acc: 0.954023003578186)
[2024-11-14 09:18:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:42][root][INFO] - Training Epoch: 2/2, step 6879/16670 completed (loss: 0.21361038088798523, acc: 0.8999999761581421)
[2024-11-14 09:18:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:42][root][INFO] - Training Epoch: 2/2, step 6880/16670 completed (loss: 0.3737749755382538, acc: 0.9210526347160339)
[2024-11-14 09:18:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:42][root][INFO] - Training Epoch: 2/2, step 6881/16670 completed (loss: 0.300571471452713, acc: 0.9032257795333862)
[2024-11-14 09:18:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:43][root][INFO] - Training Epoch: 2/2, step 6882/16670 completed (loss: 0.1543566882610321, acc: 0.9545454382896423)
[2024-11-14 09:18:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:43][root][INFO] - Training Epoch: 2/2, step 6883/16670 completed (loss: 0.14749029278755188, acc: 0.9516128897666931)
[2024-11-14 09:18:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:44][root][INFO] - Training Epoch: 2/2, step 6884/16670 completed (loss: 0.16237236559391022, acc: 0.930232584476471)
[2024-11-14 09:18:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:44][root][INFO] - Training Epoch: 2/2, step 6885/16670 completed (loss: 0.3829249143600464, acc: 0.9240506291389465)
[2024-11-14 09:18:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:44][root][INFO] - Training Epoch: 2/2, step 6886/16670 completed (loss: 0.09117385745048523, acc: 0.9615384340286255)
[2024-11-14 09:18:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:45][root][INFO] - Training Epoch: 2/2, step 6887/16670 completed (loss: 0.17663127183914185, acc: 0.9615384340286255)
[2024-11-14 09:18:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:45][root][INFO] - Training Epoch: 2/2, step 6888/16670 completed (loss: 0.10127760469913483, acc: 0.9726027250289917)
[2024-11-14 09:18:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:45][root][INFO] - Training Epoch: 2/2, step 6889/16670 completed (loss: 0.33841222524642944, acc: 0.942307710647583)
[2024-11-14 09:18:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:46][root][INFO] - Training Epoch: 2/2, step 6890/16670 completed (loss: 0.02657146006822586, acc: 1.0)
[2024-11-14 09:18:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:46][root][INFO] - Training Epoch: 2/2, step 6891/16670 completed (loss: 0.11159788817167282, acc: 0.9756097793579102)
[2024-11-14 09:18:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:46][root][INFO] - Training Epoch: 2/2, step 6892/16670 completed (loss: 0.5318692922592163, acc: 0.942307710647583)
[2024-11-14 09:18:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:47][root][INFO] - Training Epoch: 2/2, step 6893/16670 completed (loss: 0.0788995623588562, acc: 0.9878048896789551)
[2024-11-14 09:18:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:47][root][INFO] - Training Epoch: 2/2, step 6894/16670 completed (loss: 0.2177760750055313, acc: 0.9230769276618958)
[2024-11-14 09:18:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:48][root][INFO] - Training Epoch: 2/2, step 6895/16670 completed (loss: 0.17749598622322083, acc: 0.9624999761581421)
[2024-11-14 09:18:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:48][root][INFO] - Training Epoch: 2/2, step 6896/16670 completed (loss: 0.14168892800807953, acc: 0.9272727370262146)
[2024-11-14 09:18:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:48][root][INFO] - Training Epoch: 2/2, step 6897/16670 completed (loss: 0.14365383982658386, acc: 0.9666666388511658)
[2024-11-14 09:18:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:49][root][INFO] - Training Epoch: 2/2, step 6898/16670 completed (loss: 0.42213577032089233, acc: 0.8974359035491943)
[2024-11-14 09:18:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:49][root][INFO] - Training Epoch: 2/2, step 6899/16670 completed (loss: 0.04271514713764191, acc: 1.0)
[2024-11-14 09:18:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:49][root][INFO] - Training Epoch: 2/2, step 6900/16670 completed (loss: 0.2175041139125824, acc: 0.9487179517745972)
[2024-11-14 09:18:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:50][root][INFO] - Training Epoch: 2/2, step 6901/16670 completed (loss: 0.13507355749607086, acc: 0.9545454382896423)
[2024-11-14 09:18:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:50][root][INFO] - Training Epoch: 2/2, step 6902/16670 completed (loss: 0.30542510747909546, acc: 0.9295774698257446)
[2024-11-14 09:18:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:51][root][INFO] - Training Epoch: 2/2, step 6903/16670 completed (loss: 0.3865452706813812, acc: 0.9220778942108154)
[2024-11-14 09:18:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:51][root][INFO] - Training Epoch: 2/2, step 6904/16670 completed (loss: 0.1641332507133484, acc: 0.9473684430122375)
[2024-11-14 09:18:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:51][root][INFO] - Training Epoch: 2/2, step 6905/16670 completed (loss: 0.07421553879976273, acc: 0.9821428656578064)
[2024-11-14 09:18:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:52][root][INFO] - Training Epoch: 2/2, step 6906/16670 completed (loss: 0.17058105766773224, acc: 0.97826087474823)
[2024-11-14 09:18:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:52][root][INFO] - Training Epoch: 2/2, step 6907/16670 completed (loss: 0.22289332747459412, acc: 0.9253731369972229)
[2024-11-14 09:18:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:52][root][INFO] - Training Epoch: 2/2, step 6908/16670 completed (loss: 0.38505449891090393, acc: 0.925000011920929)
[2024-11-14 09:18:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:53][root][INFO] - Training Epoch: 2/2, step 6909/16670 completed (loss: 0.13763955235481262, acc: 0.9375)
[2024-11-14 09:18:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:53][root][INFO] - Training Epoch: 2/2, step 6910/16670 completed (loss: 0.2329014390707016, acc: 0.9117646813392639)
[2024-11-14 09:18:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:53][root][INFO] - Training Epoch: 2/2, step 6911/16670 completed (loss: 0.41517120599746704, acc: 0.949999988079071)
[2024-11-14 09:18:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:54][root][INFO] - Training Epoch: 2/2, step 6912/16670 completed (loss: 0.4577992260456085, acc: 0.9295774698257446)
[2024-11-14 09:18:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:54][root][INFO] - Training Epoch: 2/2, step 6913/16670 completed (loss: 0.29222458600997925, acc: 0.9285714030265808)
[2024-11-14 09:18:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:54][root][INFO] - Training Epoch: 2/2, step 6914/16670 completed (loss: 0.08019676804542542, acc: 0.9795918464660645)
[2024-11-14 09:18:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:55][root][INFO] - Training Epoch: 2/2, step 6915/16670 completed (loss: 0.0928712785243988, acc: 0.9852941036224365)
[2024-11-14 09:18:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:55][root][INFO] - Training Epoch: 2/2, step 6916/16670 completed (loss: 0.37354880571365356, acc: 0.9300000071525574)
[2024-11-14 09:18:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:55][root][INFO] - Training Epoch: 2/2, step 6917/16670 completed (loss: 0.074006088078022, acc: 1.0)
[2024-11-14 09:18:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:56][root][INFO] - Training Epoch: 2/2, step 6918/16670 completed (loss: 0.12872308492660522, acc: 0.9622641801834106)
[2024-11-14 09:18:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:56][root][INFO] - Training Epoch: 2/2, step 6919/16670 completed (loss: 0.06326007843017578, acc: 0.9836065769195557)
[2024-11-14 09:18:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:56][root][INFO] - Training Epoch: 2/2, step 6920/16670 completed (loss: 0.22195106744766235, acc: 0.9459459185600281)
[2024-11-14 09:18:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:57][root][INFO] - Training Epoch: 2/2, step 6921/16670 completed (loss: 0.26345735788345337, acc: 0.9428571462631226)
[2024-11-14 09:18:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:57][root][INFO] - Training Epoch: 2/2, step 6922/16670 completed (loss: 0.04336245357990265, acc: 1.0)
[2024-11-14 09:18:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:57][root][INFO] - Training Epoch: 2/2, step 6923/16670 completed (loss: 0.3136831820011139, acc: 0.9166666865348816)
[2024-11-14 09:18:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:58][root][INFO] - Training Epoch: 2/2, step 6924/16670 completed (loss: 0.2311207354068756, acc: 0.9534883499145508)
[2024-11-14 09:18:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:58][root][INFO] - Training Epoch: 2/2, step 6925/16670 completed (loss: 0.12245946377515793, acc: 0.9846153855323792)
[2024-11-14 09:18:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:58][root][INFO] - Training Epoch: 2/2, step 6926/16670 completed (loss: 0.04642307385802269, acc: 1.0)
[2024-11-14 09:18:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:59][root][INFO] - Training Epoch: 2/2, step 6927/16670 completed (loss: 0.02033771201968193, acc: 1.0)
[2024-11-14 09:18:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:59][root][INFO] - Training Epoch: 2/2, step 6928/16670 completed (loss: 0.267912358045578, acc: 0.9642857313156128)
[2024-11-14 09:18:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:18:59][root][INFO] - Training Epoch: 2/2, step 6929/16670 completed (loss: 0.10376126319169998, acc: 0.9803921580314636)
[2024-11-14 09:18:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:00][root][INFO] - Training Epoch: 2/2, step 6930/16670 completed (loss: 0.04197396710515022, acc: 1.0)
[2024-11-14 09:19:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:00][root][INFO] - Training Epoch: 2/2, step 6931/16670 completed (loss: 0.2506556510925293, acc: 0.9651162624359131)
[2024-11-14 09:19:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:00][root][INFO] - Training Epoch: 2/2, step 6932/16670 completed (loss: 0.3343104124069214, acc: 0.9555555582046509)
[2024-11-14 09:19:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:01][root][INFO] - Training Epoch: 2/2, step 6933/16670 completed (loss: 0.10440731793642044, acc: 0.9607843160629272)
[2024-11-14 09:19:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:01][root][INFO] - Training Epoch: 2/2, step 6934/16670 completed (loss: 0.16705326735973358, acc: 0.9545454382896423)
[2024-11-14 09:19:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:02][root][INFO] - Training Epoch: 2/2, step 6935/16670 completed (loss: 0.20597565174102783, acc: 0.9599999785423279)
[2024-11-14 09:19:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:02][root][INFO] - Training Epoch: 2/2, step 6936/16670 completed (loss: 0.036007657647132874, acc: 0.9814814925193787)
[2024-11-14 09:19:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:02][root][INFO] - Training Epoch: 2/2, step 6937/16670 completed (loss: 0.21547508239746094, acc: 0.9722222089767456)
[2024-11-14 09:19:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:03][root][INFO] - Training Epoch: 2/2, step 6938/16670 completed (loss: 0.16253817081451416, acc: 0.9830508232116699)
[2024-11-14 09:19:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:03][root][INFO] - Training Epoch: 2/2, step 6939/16670 completed (loss: 0.17240940034389496, acc: 0.9350649118423462)
[2024-11-14 09:19:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:03][root][INFO] - Training Epoch: 2/2, step 6940/16670 completed (loss: 0.1691059172153473, acc: 0.9487179517745972)
[2024-11-14 09:19:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:04][root][INFO] - Training Epoch: 2/2, step 6941/16670 completed (loss: 0.23142720758914948, acc: 0.9354838728904724)
[2024-11-14 09:19:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:04][root][INFO] - Training Epoch: 2/2, step 6942/16670 completed (loss: 0.05292043834924698, acc: 1.0)
[2024-11-14 09:19:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:04][root][INFO] - Training Epoch: 2/2, step 6943/16670 completed (loss: 0.1277441382408142, acc: 0.9672130942344666)
[2024-11-14 09:19:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:05][root][INFO] - Training Epoch: 2/2, step 6944/16670 completed (loss: 0.2873975932598114, acc: 0.9642857313156128)
[2024-11-14 09:19:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:05][root][INFO] - Training Epoch: 2/2, step 6945/16670 completed (loss: 0.22739191353321075, acc: 0.9242424368858337)
[2024-11-14 09:19:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:05][root][INFO] - Training Epoch: 2/2, step 6946/16670 completed (loss: 0.22867590188980103, acc: 0.9578947424888611)
[2024-11-14 09:19:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:06][root][INFO] - Training Epoch: 2/2, step 6947/16670 completed (loss: 0.10025294870138168, acc: 0.9807692170143127)
[2024-11-14 09:19:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:06][root][INFO] - Training Epoch: 2/2, step 6948/16670 completed (loss: 1.047644019126892, acc: 0.8181818127632141)
[2024-11-14 09:19:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:06][root][INFO] - Training Epoch: 2/2, step 6949/16670 completed (loss: 0.03184257820248604, acc: 1.0)
[2024-11-14 09:19:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:07][root][INFO] - Training Epoch: 2/2, step 6950/16670 completed (loss: 0.35896024107933044, acc: 0.8870967626571655)
[2024-11-14 09:19:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:07][root][INFO] - Training Epoch: 2/2, step 6951/16670 completed (loss: 0.5460485816001892, acc: 0.8641975522041321)
[2024-11-14 09:19:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:08][root][INFO] - Training Epoch: 2/2, step 6952/16670 completed (loss: 0.6367936730384827, acc: 0.8958333134651184)
[2024-11-14 09:19:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:08][root][INFO] - Training Epoch: 2/2, step 6953/16670 completed (loss: 0.673448920249939, acc: 0.8222222328186035)
[2024-11-14 09:19:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:08][root][INFO] - Training Epoch: 2/2, step 6954/16670 completed (loss: 0.2867160141468048, acc: 0.920634925365448)
[2024-11-14 09:19:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:09][root][INFO] - Training Epoch: 2/2, step 6955/16670 completed (loss: 0.07766828685998917, acc: 0.9583333134651184)
[2024-11-14 09:19:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:09][root][INFO] - Training Epoch: 2/2, step 6956/16670 completed (loss: 0.3416091501712799, acc: 0.8823529481887817)
[2024-11-14 09:19:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:09][root][INFO] - Training Epoch: 2/2, step 6957/16670 completed (loss: 0.3169253170490265, acc: 0.8958333134651184)
[2024-11-14 09:19:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:10][root][INFO] - Training Epoch: 2/2, step 6958/16670 completed (loss: 0.201540008187294, acc: 0.9464285969734192)
[2024-11-14 09:19:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:10][root][INFO] - Training Epoch: 2/2, step 6959/16670 completed (loss: 0.17000780999660492, acc: 0.9387755393981934)
[2024-11-14 09:19:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:10][root][INFO] - Training Epoch: 2/2, step 6960/16670 completed (loss: 0.19284726679325104, acc: 0.949999988079071)
[2024-11-14 09:19:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:11][root][INFO] - Training Epoch: 2/2, step 6961/16670 completed (loss: 0.588462233543396, acc: 0.8588235378265381)
[2024-11-14 09:19:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:11][root][INFO] - Training Epoch: 2/2, step 6962/16670 completed (loss: 0.1948358118534088, acc: 0.9454545378684998)
[2024-11-14 09:19:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:11][root][INFO] - Training Epoch: 2/2, step 6963/16670 completed (loss: 0.16496337950229645, acc: 0.9431818127632141)
[2024-11-14 09:19:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:12][root][INFO] - Training Epoch: 2/2, step 6964/16670 completed (loss: 0.3101593255996704, acc: 0.9292035102844238)
[2024-11-14 09:19:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:12][root][INFO] - Training Epoch: 2/2, step 6965/16670 completed (loss: 0.16549643874168396, acc: 0.9750000238418579)
[2024-11-14 09:19:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:12][root][INFO] - Training Epoch: 2/2, step 6966/16670 completed (loss: 0.031001154333353043, acc: 1.0)
[2024-11-14 09:19:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:13][root][INFO] - Training Epoch: 2/2, step 6967/16670 completed (loss: 0.10576886683702469, acc: 0.9607843160629272)
[2024-11-14 09:19:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:13][root][INFO] - Training Epoch: 2/2, step 6968/16670 completed (loss: 0.3475913107395172, acc: 0.8888888955116272)
[2024-11-14 09:19:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:13][root][INFO] - Training Epoch: 2/2, step 6969/16670 completed (loss: 0.2567600607872009, acc: 0.9615384340286255)
[2024-11-14 09:19:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:14][root][INFO] - Training Epoch: 2/2, step 6970/16670 completed (loss: 0.13396435976028442, acc: 0.9638554453849792)
[2024-11-14 09:19:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:14][root][INFO] - Training Epoch: 2/2, step 6971/16670 completed (loss: 0.2938719093799591, acc: 0.9318181872367859)
[2024-11-14 09:19:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:14][root][INFO] - Training Epoch: 2/2, step 6972/16670 completed (loss: 0.47353771328926086, acc: 0.9047619104385376)
[2024-11-14 09:19:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:15][root][INFO] - Training Epoch: 2/2, step 6973/16670 completed (loss: 0.15684106945991516, acc: 0.9545454382896423)
[2024-11-14 09:19:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:15][root][INFO] - Training Epoch: 2/2, step 6974/16670 completed (loss: 0.4593597650527954, acc: 0.8734177350997925)
[2024-11-14 09:19:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:15][root][INFO] - Training Epoch: 2/2, step 6975/16670 completed (loss: 0.30727848410606384, acc: 0.9545454382896423)
[2024-11-14 09:19:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:16][root][INFO] - Training Epoch: 2/2, step 6976/16670 completed (loss: 0.38913336396217346, acc: 0.9137930870056152)
[2024-11-14 09:19:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:16][root][INFO] - Training Epoch: 2/2, step 6977/16670 completed (loss: 0.288342148065567, acc: 0.8823529481887817)
[2024-11-14 09:19:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:16][root][INFO] - Training Epoch: 2/2, step 6978/16670 completed (loss: 0.21290740370750427, acc: 0.9333333373069763)
[2024-11-14 09:19:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:17][root][INFO] - Training Epoch: 2/2, step 6979/16670 completed (loss: 0.22200563549995422, acc: 0.9259259104728699)
[2024-11-14 09:19:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:17][root][INFO] - Training Epoch: 2/2, step 6980/16670 completed (loss: 0.09306692332029343, acc: 0.9824561476707458)
[2024-11-14 09:19:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:17][root][INFO] - Training Epoch: 2/2, step 6981/16670 completed (loss: 0.20990799367427826, acc: 0.8974359035491943)
[2024-11-14 09:19:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:18][root][INFO] - Training Epoch: 2/2, step 6982/16670 completed (loss: 0.21077746152877808, acc: 0.938144326210022)
[2024-11-14 09:19:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:18][root][INFO] - Training Epoch: 2/2, step 6983/16670 completed (loss: 0.2571406364440918, acc: 0.930232584476471)
[2024-11-14 09:19:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:18][root][INFO] - Training Epoch: 2/2, step 6984/16670 completed (loss: 0.3443835377693176, acc: 0.9104477763175964)
[2024-11-14 09:19:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:19][root][INFO] - Training Epoch: 2/2, step 6985/16670 completed (loss: 0.24581138789653778, acc: 0.9622641801834106)
[2024-11-14 09:19:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:19][root][INFO] - Training Epoch: 2/2, step 6986/16670 completed (loss: 0.3679042160511017, acc: 0.9152542352676392)
[2024-11-14 09:19:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:19][root][INFO] - Training Epoch: 2/2, step 6987/16670 completed (loss: 0.23971232771873474, acc: 0.9508196711540222)
[2024-11-14 09:19:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:19][root][INFO] - Training Epoch: 2/2, step 6988/16670 completed (loss: 0.2904605567455292, acc: 0.9222221970558167)
[2024-11-14 09:19:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:20][root][INFO] - Training Epoch: 2/2, step 6989/16670 completed (loss: 0.1924559473991394, acc: 0.9661017060279846)
[2024-11-14 09:19:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:20][root][INFO] - Training Epoch: 2/2, step 6990/16670 completed (loss: 0.1861380934715271, acc: 0.954023003578186)
[2024-11-14 09:19:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:20][root][INFO] - Training Epoch: 2/2, step 6991/16670 completed (loss: 0.24701949954032898, acc: 0.9464285969734192)
[2024-11-14 09:19:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:21][root][INFO] - Training Epoch: 2/2, step 6992/16670 completed (loss: 0.33289527893066406, acc: 0.9047619104385376)
[2024-11-14 09:19:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:21][root][INFO] - Training Epoch: 2/2, step 6993/16670 completed (loss: 0.15632817149162292, acc: 0.9516128897666931)
[2024-11-14 09:19:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:21][root][INFO] - Training Epoch: 2/2, step 6994/16670 completed (loss: 0.37664535641670227, acc: 0.8717948794364929)
[2024-11-14 09:19:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:22][root][INFO] - Training Epoch: 2/2, step 6995/16670 completed (loss: 0.11477991938591003, acc: 0.9418604373931885)
[2024-11-14 09:19:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:22][root][INFO] - Training Epoch: 2/2, step 6996/16670 completed (loss: 0.02650526911020279, acc: 1.0)
[2024-11-14 09:19:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:22][root][INFO] - Training Epoch: 2/2, step 6997/16670 completed (loss: 0.31019356846809387, acc: 0.9464285969734192)
[2024-11-14 09:19:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:23][root][INFO] - Training Epoch: 2/2, step 6998/16670 completed (loss: 0.3897271156311035, acc: 0.9166666865348816)
[2024-11-14 09:19:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:23][root][INFO] - Training Epoch: 2/2, step 6999/16670 completed (loss: 0.11226073652505875, acc: 1.0)
[2024-11-14 09:19:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:23][root][INFO] - Training Epoch: 2/2, step 7000/16670 completed (loss: 0.3664133846759796, acc: 0.8846153616905212)
[2024-11-14 09:19:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:24][root][INFO] - Training Epoch: 2/2, step 7001/16670 completed (loss: 0.1391240358352661, acc: 0.9722222089767456)
[2024-11-14 09:19:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:24][root][INFO] - Training Epoch: 2/2, step 7002/16670 completed (loss: 0.2099495232105255, acc: 0.9491525292396545)
[2024-11-14 09:19:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:24][root][INFO] - Training Epoch: 2/2, step 7003/16670 completed (loss: 0.23913900554180145, acc: 0.9285714030265808)
[2024-11-14 09:19:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:25][root][INFO] - Training Epoch: 2/2, step 7004/16670 completed (loss: 0.06459800153970718, acc: 1.0)
[2024-11-14 09:19:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:25][root][INFO] - Training Epoch: 2/2, step 7005/16670 completed (loss: 0.2673744261264801, acc: 0.9019607901573181)
[2024-11-14 09:19:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:25][root][INFO] - Training Epoch: 2/2, step 7006/16670 completed (loss: 0.3594801425933838, acc: 0.8791208863258362)
[2024-11-14 09:19:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:26][root][INFO] - Training Epoch: 2/2, step 7007/16670 completed (loss: 0.07873845845460892, acc: 0.9666666388511658)
[2024-11-14 09:19:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:26][root][INFO] - Training Epoch: 2/2, step 7008/16670 completed (loss: 0.3628746569156647, acc: 0.9230769276618958)
[2024-11-14 09:19:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:26][root][INFO] - Training Epoch: 2/2, step 7009/16670 completed (loss: 0.20545893907546997, acc: 0.9365079402923584)
[2024-11-14 09:19:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:27][root][INFO] - Training Epoch: 2/2, step 7010/16670 completed (loss: 0.48518577218055725, acc: 0.8674699068069458)
[2024-11-14 09:19:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:27][root][INFO] - Training Epoch: 2/2, step 7011/16670 completed (loss: 0.24865944683551788, acc: 0.90625)
[2024-11-14 09:19:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:27][root][INFO] - Training Epoch: 2/2, step 7012/16670 completed (loss: 0.38199564814567566, acc: 0.892307698726654)
[2024-11-14 09:19:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:28][root][INFO] - Training Epoch: 2/2, step 7013/16670 completed (loss: 0.11978904902935028, acc: 0.9743589758872986)
[2024-11-14 09:19:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:28][root][INFO] - Training Epoch: 2/2, step 7014/16670 completed (loss: 0.09727975726127625, acc: 0.9777777791023254)
[2024-11-14 09:19:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:28][root][INFO] - Training Epoch: 2/2, step 7015/16670 completed (loss: 0.4436110258102417, acc: 0.9166666865348816)
[2024-11-14 09:19:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:29][root][INFO] - Training Epoch: 2/2, step 7016/16670 completed (loss: 0.27243441343307495, acc: 0.9444444179534912)
[2024-11-14 09:19:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:29][root][INFO] - Training Epoch: 2/2, step 7017/16670 completed (loss: 0.4204181730747223, acc: 0.8888888955116272)
[2024-11-14 09:19:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:29][root][INFO] - Training Epoch: 2/2, step 7018/16670 completed (loss: 0.11134632676839828, acc: 0.9589040875434875)
[2024-11-14 09:19:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:30][root][INFO] - Training Epoch: 2/2, step 7019/16670 completed (loss: 0.0882972776889801, acc: 0.9714285731315613)
[2024-11-14 09:19:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:30][root][INFO] - Training Epoch: 2/2, step 7020/16670 completed (loss: 0.09675532579421997, acc: 0.9684210419654846)
[2024-11-14 09:19:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:30][root][INFO] - Training Epoch: 2/2, step 7021/16670 completed (loss: 0.28772374987602234, acc: 0.9538461565971375)
[2024-11-14 09:19:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:31][root][INFO] - Training Epoch: 2/2, step 7022/16670 completed (loss: 0.24017153680324554, acc: 0.9078947305679321)
[2024-11-14 09:19:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:31][root][INFO] - Training Epoch: 2/2, step 7023/16670 completed (loss: 0.17498038709163666, acc: 0.9607843160629272)
[2024-11-14 09:19:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:31][root][INFO] - Training Epoch: 2/2, step 7024/16670 completed (loss: 0.1798921376466751, acc: 0.9516128897666931)
[2024-11-14 09:19:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:32][root][INFO] - Training Epoch: 2/2, step 7025/16670 completed (loss: 0.2240302711725235, acc: 0.9672130942344666)
[2024-11-14 09:19:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:32][root][INFO] - Training Epoch: 2/2, step 7026/16670 completed (loss: 0.3051677346229553, acc: 0.9146341681480408)
[2024-11-14 09:19:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:32][root][INFO] - Training Epoch: 2/2, step 7027/16670 completed (loss: 0.3678736090660095, acc: 0.9452054500579834)
[2024-11-14 09:19:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:33][root][INFO] - Training Epoch: 2/2, step 7028/16670 completed (loss: 0.0920640155673027, acc: 0.9642857313156128)
[2024-11-14 09:19:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:33][root][INFO] - Training Epoch: 2/2, step 7029/16670 completed (loss: 0.3981689512729645, acc: 0.893203854560852)
[2024-11-14 09:19:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:33][root][INFO] - Training Epoch: 2/2, step 7030/16670 completed (loss: 0.27872350811958313, acc: 0.9791666865348816)
[2024-11-14 09:19:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:34][root][INFO] - Training Epoch: 2/2, step 7031/16670 completed (loss: 0.5700103044509888, acc: 0.9295774698257446)
[2024-11-14 09:19:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:34][root][INFO] - Training Epoch: 2/2, step 7032/16670 completed (loss: 0.046217769384384155, acc: 1.0)
[2024-11-14 09:19:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:34][root][INFO] - Training Epoch: 2/2, step 7033/16670 completed (loss: 0.29913952946662903, acc: 0.9200000166893005)
[2024-11-14 09:19:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:35][root][INFO] - Training Epoch: 2/2, step 7034/16670 completed (loss: 0.2506604790687561, acc: 0.9672130942344666)
[2024-11-14 09:19:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:35][root][INFO] - Training Epoch: 2/2, step 7035/16670 completed (loss: 0.34676605463027954, acc: 0.949999988079071)
[2024-11-14 09:19:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:35][root][INFO] - Training Epoch: 2/2, step 7036/16670 completed (loss: 0.037403982132673264, acc: 1.0)
[2024-11-14 09:19:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:36][root][INFO] - Training Epoch: 2/2, step 7037/16670 completed (loss: 0.26026061177253723, acc: 0.9649122953414917)
[2024-11-14 09:19:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:36][root][INFO] - Training Epoch: 2/2, step 7038/16670 completed (loss: 0.28835591673851013, acc: 0.9189189076423645)
[2024-11-14 09:19:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:36][root][INFO] - Training Epoch: 2/2, step 7039/16670 completed (loss: 0.19121932983398438, acc: 0.9560439586639404)
[2024-11-14 09:19:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:37][root][INFO] - Training Epoch: 2/2, step 7040/16670 completed (loss: 0.03367920592427254, acc: 1.0)
[2024-11-14 09:19:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:37][root][INFO] - Training Epoch: 2/2, step 7041/16670 completed (loss: 0.10152339935302734, acc: 0.9545454382896423)
[2024-11-14 09:19:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:37][root][INFO] - Training Epoch: 2/2, step 7042/16670 completed (loss: 0.0327155739068985, acc: 1.0)
[2024-11-14 09:19:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:37][root][INFO] - Training Epoch: 2/2, step 7043/16670 completed (loss: 0.15060272812843323, acc: 0.9534883499145508)
[2024-11-14 09:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:38][root][INFO] - Training Epoch: 2/2, step 7044/16670 completed (loss: 0.18582293391227722, acc: 0.9516128897666931)
[2024-11-14 09:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:38][root][INFO] - Training Epoch: 2/2, step 7045/16670 completed (loss: 0.5208777189254761, acc: 0.887499988079071)
[2024-11-14 09:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:38][root][INFO] - Training Epoch: 2/2, step 7046/16670 completed (loss: 0.16285963356494904, acc: 0.9365079402923584)
[2024-11-14 09:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:39][root][INFO] - Training Epoch: 2/2, step 7047/16670 completed (loss: 0.0754837617278099, acc: 0.9661017060279846)
[2024-11-14 09:19:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:39][root][INFO] - Training Epoch: 2/2, step 7048/16670 completed (loss: 0.2076471596956253, acc: 0.9464285969734192)
[2024-11-14 09:19:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:39][root][INFO] - Training Epoch: 2/2, step 7049/16670 completed (loss: 0.1454905867576599, acc: 0.9777777791023254)
[2024-11-14 09:19:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:40][root][INFO] - Training Epoch: 2/2, step 7050/16670 completed (loss: 0.34832537174224854, acc: 0.8902438879013062)
[2024-11-14 09:19:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:40][root][INFO] - Training Epoch: 2/2, step 7051/16670 completed (loss: 0.08176732808351517, acc: 0.9743589758872986)
[2024-11-14 09:19:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:40][root][INFO] - Training Epoch: 2/2, step 7052/16670 completed (loss: 0.25499841570854187, acc: 0.9166666865348816)
[2024-11-14 09:19:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:41][root][INFO] - Training Epoch: 2/2, step 7053/16670 completed (loss: 0.10759836435317993, acc: 0.970588207244873)
[2024-11-14 09:19:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:41][root][INFO] - Training Epoch: 2/2, step 7054/16670 completed (loss: 0.11974454671144485, acc: 0.9245283007621765)
[2024-11-14 09:19:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:41][root][INFO] - Training Epoch: 2/2, step 7055/16670 completed (loss: 0.2017505168914795, acc: 0.9444444179534912)
[2024-11-14 09:19:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:42][root][INFO] - Training Epoch: 2/2, step 7056/16670 completed (loss: 0.12354429811239243, acc: 0.9722222089767456)
[2024-11-14 09:19:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:42][root][INFO] - Training Epoch: 2/2, step 7057/16670 completed (loss: 0.44487839937210083, acc: 0.9041095972061157)
[2024-11-14 09:19:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:42][root][INFO] - Training Epoch: 2/2, step 7058/16670 completed (loss: 0.16048890352249146, acc: 0.9518072009086609)
[2024-11-14 09:19:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:43][root][INFO] - Training Epoch: 2/2, step 7059/16670 completed (loss: 0.21258167922496796, acc: 0.9420289993286133)
[2024-11-14 09:19:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:43][root][INFO] - Training Epoch: 2/2, step 7060/16670 completed (loss: 0.028403982520103455, acc: 1.0)
[2024-11-14 09:19:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:43][root][INFO] - Training Epoch: 2/2, step 7061/16670 completed (loss: 0.24470597505569458, acc: 0.98591548204422)
[2024-11-14 09:19:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:44][root][INFO] - Training Epoch: 2/2, step 7062/16670 completed (loss: 0.4685976505279541, acc: 0.8823529481887817)
[2024-11-14 09:19:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:44][root][INFO] - Training Epoch: 2/2, step 7063/16670 completed (loss: 0.1324884444475174, acc: 0.9651162624359131)
[2024-11-14 09:19:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:45][root][INFO] - Training Epoch: 2/2, step 7064/16670 completed (loss: 0.5134673714637756, acc: 0.8974359035491943)
[2024-11-14 09:19:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:45][root][INFO] - Training Epoch: 2/2, step 7065/16670 completed (loss: 0.089117132127285, acc: 0.9701492786407471)
[2024-11-14 09:19:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:45][root][INFO] - Training Epoch: 2/2, step 7066/16670 completed (loss: 0.1924055963754654, acc: 0.9130434989929199)
[2024-11-14 09:19:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:46][root][INFO] - Training Epoch: 2/2, step 7067/16670 completed (loss: 0.04020508751273155, acc: 0.9803921580314636)
[2024-11-14 09:19:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:46][root][INFO] - Training Epoch: 2/2, step 7068/16670 completed (loss: 0.24765940010547638, acc: 0.9534883499145508)
[2024-11-14 09:19:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:46][root][INFO] - Training Epoch: 2/2, step 7069/16670 completed (loss: 0.12283974885940552, acc: 0.9399999976158142)
[2024-11-14 09:19:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:47][root][INFO] - Training Epoch: 2/2, step 7070/16670 completed (loss: 0.48032212257385254, acc: 0.8983050584793091)
[2024-11-14 09:19:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:47][root][INFO] - Training Epoch: 2/2, step 7071/16670 completed (loss: 0.0928119346499443, acc: 0.9655172228813171)
[2024-11-14 09:19:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:48][root][INFO] - Training Epoch: 2/2, step 7072/16670 completed (loss: 0.39461979269981384, acc: 0.9333333373069763)
[2024-11-14 09:19:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:48][root][INFO] - Training Epoch: 2/2, step 7073/16670 completed (loss: 0.340872198343277, acc: 0.8666666746139526)
[2024-11-14 09:19:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:48][root][INFO] - Training Epoch: 2/2, step 7074/16670 completed (loss: 0.21865063905715942, acc: 0.9090909361839294)
[2024-11-14 09:19:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:49][root][INFO] - Training Epoch: 2/2, step 7075/16670 completed (loss: 0.1459500640630722, acc: 0.9545454382896423)
[2024-11-14 09:19:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:49][root][INFO] - Training Epoch: 2/2, step 7076/16670 completed (loss: 0.38360896706581116, acc: 0.9036144614219666)
[2024-11-14 09:19:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:49][root][INFO] - Training Epoch: 2/2, step 7077/16670 completed (loss: 0.3664756417274475, acc: 0.9275362491607666)
[2024-11-14 09:19:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:50][root][INFO] - Training Epoch: 2/2, step 7078/16670 completed (loss: 0.3483542203903198, acc: 0.8846153616905212)
[2024-11-14 09:19:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:50][root][INFO] - Training Epoch: 2/2, step 7079/16670 completed (loss: 0.5330266952514648, acc: 0.8837209343910217)
[2024-11-14 09:19:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:50][root][INFO] - Training Epoch: 2/2, step 7080/16670 completed (loss: 0.10558509826660156, acc: 0.9610389471054077)
[2024-11-14 09:19:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:51][root][INFO] - Training Epoch: 2/2, step 7081/16670 completed (loss: 0.08399299532175064, acc: 1.0)
[2024-11-14 09:19:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:51][root][INFO] - Training Epoch: 2/2, step 7082/16670 completed (loss: 0.13176724314689636, acc: 0.9459459185600281)
[2024-11-14 09:19:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:51][root][INFO] - Training Epoch: 2/2, step 7083/16670 completed (loss: 0.17682026326656342, acc: 0.9666666388511658)
[2024-11-14 09:19:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:52][root][INFO] - Training Epoch: 2/2, step 7084/16670 completed (loss: 0.20260384678840637, acc: 0.931034505367279)
[2024-11-14 09:19:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:52][root][INFO] - Training Epoch: 2/2, step 7085/16670 completed (loss: 0.5271520018577576, acc: 0.8999999761581421)
[2024-11-14 09:19:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:52][root][INFO] - Training Epoch: 2/2, step 7086/16670 completed (loss: 0.20061077177524567, acc: 0.9333333373069763)
[2024-11-14 09:19:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:53][root][INFO] - Training Epoch: 2/2, step 7087/16670 completed (loss: 0.3021991550922394, acc: 0.9166666865348816)
[2024-11-14 09:19:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:53][root][INFO] - Training Epoch: 2/2, step 7088/16670 completed (loss: 0.13053876161575317, acc: 0.9615384340286255)
[2024-11-14 09:19:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:53][root][INFO] - Training Epoch: 2/2, step 7089/16670 completed (loss: 0.10998963564634323, acc: 0.9767441749572754)
[2024-11-14 09:19:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:54][root][INFO] - Training Epoch: 2/2, step 7090/16670 completed (loss: 0.12165357172489166, acc: 0.9870129823684692)
[2024-11-14 09:19:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:54][root][INFO] - Training Epoch: 2/2, step 7091/16670 completed (loss: 0.1809474378824234, acc: 0.9666666388511658)
[2024-11-14 09:19:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:54][root][INFO] - Training Epoch: 2/2, step 7092/16670 completed (loss: 0.29807373881340027, acc: 0.9322034120559692)
[2024-11-14 09:19:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:55][root][INFO] - Training Epoch: 2/2, step 7093/16670 completed (loss: 0.5254212021827698, acc: 0.921875)
[2024-11-14 09:19:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:55][root][INFO] - Training Epoch: 2/2, step 7094/16670 completed (loss: 0.02018195204436779, acc: 1.0)
[2024-11-14 09:19:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:55][root][INFO] - Training Epoch: 2/2, step 7095/16670 completed (loss: 0.33093467354774475, acc: 0.9322034120559692)
[2024-11-14 09:19:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:56][root][INFO] - Training Epoch: 2/2, step 7096/16670 completed (loss: 0.03003407083451748, acc: 1.0)
[2024-11-14 09:19:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:56][root][INFO] - Training Epoch: 2/2, step 7097/16670 completed (loss: 0.528803825378418, acc: 0.8679245114326477)
[2024-11-14 09:19:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:56][root][INFO] - Training Epoch: 2/2, step 7098/16670 completed (loss: 0.17086677253246307, acc: 0.9452054500579834)
[2024-11-14 09:19:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:57][root][INFO] - Training Epoch: 2/2, step 7099/16670 completed (loss: 0.14703942835330963, acc: 0.9818181991577148)
[2024-11-14 09:19:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:57][root][INFO] - Training Epoch: 2/2, step 7100/16670 completed (loss: 0.1640143245458603, acc: 0.949999988079071)
[2024-11-14 09:19:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:57][root][INFO] - Training Epoch: 2/2, step 7101/16670 completed (loss: 0.5324894189834595, acc: 0.849056601524353)
[2024-11-14 09:19:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:58][root][INFO] - Training Epoch: 2/2, step 7102/16670 completed (loss: 0.09450212121009827, acc: 0.9733333587646484)
[2024-11-14 09:19:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:58][root][INFO] - Training Epoch: 2/2, step 7103/16670 completed (loss: 0.06352812796831131, acc: 0.9599999785423279)
[2024-11-14 09:19:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:58][root][INFO] - Training Epoch: 2/2, step 7104/16670 completed (loss: 0.12185673415660858, acc: 0.939393937587738)
[2024-11-14 09:19:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:59][root][INFO] - Training Epoch: 2/2, step 7105/16670 completed (loss: 0.1599324494600296, acc: 0.9622641801834106)
[2024-11-14 09:19:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:59][root][INFO] - Training Epoch: 2/2, step 7106/16670 completed (loss: 0.08343084901571274, acc: 0.9710144996643066)
[2024-11-14 09:19:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:19:59][root][INFO] - Training Epoch: 2/2, step 7107/16670 completed (loss: 0.05074417218565941, acc: 1.0)
[2024-11-14 09:19:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:00][root][INFO] - Training Epoch: 2/2, step 7108/16670 completed (loss: 0.5158740878105164, acc: 0.8620689511299133)
[2024-11-14 09:20:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:00][root][INFO] - Training Epoch: 2/2, step 7109/16670 completed (loss: 0.06832063943147659, acc: 0.9750000238418579)
[2024-11-14 09:20:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:00][root][INFO] - Training Epoch: 2/2, step 7110/16670 completed (loss: 0.2399565577507019, acc: 0.9402984976768494)
[2024-11-14 09:20:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:01][root][INFO] - Training Epoch: 2/2, step 7111/16670 completed (loss: 0.47222819924354553, acc: 0.8933333158493042)
[2024-11-14 09:20:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:01][root][INFO] - Training Epoch: 2/2, step 7112/16670 completed (loss: 0.25134965777397156, acc: 0.9824561476707458)
[2024-11-14 09:20:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:01][root][INFO] - Training Epoch: 2/2, step 7113/16670 completed (loss: 0.38265833258628845, acc: 0.8709677457809448)
[2024-11-14 09:20:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:02][root][INFO] - Training Epoch: 2/2, step 7114/16670 completed (loss: 0.14266791939735413, acc: 0.925000011920929)
[2024-11-14 09:20:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:02][root][INFO] - Training Epoch: 2/2, step 7115/16670 completed (loss: 0.4823536276817322, acc: 0.8777777552604675)
[2024-11-14 09:20:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:02][root][INFO] - Training Epoch: 2/2, step 7116/16670 completed (loss: 0.07815089821815491, acc: 0.9722222089767456)
[2024-11-14 09:20:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:03][root][INFO] - Training Epoch: 2/2, step 7117/16670 completed (loss: 0.30907052755355835, acc: 0.9555555582046509)
[2024-11-14 09:20:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:03][root][INFO] - Training Epoch: 2/2, step 7118/16670 completed (loss: 0.06685621291399002, acc: 1.0)
[2024-11-14 09:20:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:03][root][INFO] - Training Epoch: 2/2, step 7119/16670 completed (loss: 0.13115116953849792, acc: 0.9512194991111755)
[2024-11-14 09:20:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:03][root][INFO] - Training Epoch: 2/2, step 7120/16670 completed (loss: 0.3149246275424957, acc: 0.887499988079071)
[2024-11-14 09:20:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:04][root][INFO] - Training Epoch: 2/2, step 7121/16670 completed (loss: 0.34925755858421326, acc: 0.9200000166893005)
[2024-11-14 09:20:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:04][root][INFO] - Training Epoch: 2/2, step 7122/16670 completed (loss: 0.27994608879089355, acc: 0.9152542352676392)
[2024-11-14 09:20:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:05][root][INFO] - Training Epoch: 2/2, step 7123/16670 completed (loss: 0.0306555163115263, acc: 0.9714285731315613)
[2024-11-14 09:20:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:05][root][INFO] - Training Epoch: 2/2, step 7124/16670 completed (loss: 0.1985621452331543, acc: 0.9375)
[2024-11-14 09:20:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:05][root][INFO] - Training Epoch: 2/2, step 7125/16670 completed (loss: 0.20564931631088257, acc: 0.9726027250289917)
[2024-11-14 09:20:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:06][root][INFO] - Training Epoch: 2/2, step 7126/16670 completed (loss: 0.3434726595878601, acc: 0.8589743375778198)
[2024-11-14 09:20:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:06][root][INFO] - Training Epoch: 2/2, step 7127/16670 completed (loss: 0.04393910989165306, acc: 1.0)
[2024-11-14 09:20:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:06][root][INFO] - Training Epoch: 2/2, step 7128/16670 completed (loss: 0.22977393865585327, acc: 0.9298245906829834)
[2024-11-14 09:20:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:07][root][INFO] - Training Epoch: 2/2, step 7129/16670 completed (loss: 0.160215362906456, acc: 0.9583333134651184)
[2024-11-14 09:20:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:07][root][INFO] - Training Epoch: 2/2, step 7130/16670 completed (loss: 0.684670627117157, acc: 0.8399999737739563)
[2024-11-14 09:20:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:08][root][INFO] - Training Epoch: 2/2, step 7131/16670 completed (loss: 0.03765050694346428, acc: 1.0)
[2024-11-14 09:20:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:08][root][INFO] - Training Epoch: 2/2, step 7132/16670 completed (loss: 0.2871762812137604, acc: 0.921875)
[2024-11-14 09:20:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:08][root][INFO] - Training Epoch: 2/2, step 7133/16670 completed (loss: 0.0905199944972992, acc: 0.9861111044883728)
[2024-11-14 09:20:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:09][root][INFO] - Training Epoch: 2/2, step 7134/16670 completed (loss: 0.1343376189470291, acc: 0.9607843160629272)
[2024-11-14 09:20:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:09][root][INFO] - Training Epoch: 2/2, step 7135/16670 completed (loss: 0.07651134580373764, acc: 1.0)
[2024-11-14 09:20:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:09][root][INFO] - Training Epoch: 2/2, step 7136/16670 completed (loss: 0.0331774540245533, acc: 1.0)
[2024-11-14 09:20:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:10][root][INFO] - Training Epoch: 2/2, step 7137/16670 completed (loss: 0.45924803614616394, acc: 0.8999999761581421)
[2024-11-14 09:20:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:10][root][INFO] - Training Epoch: 2/2, step 7138/16670 completed (loss: 0.45250004529953003, acc: 0.8695651888847351)
[2024-11-14 09:20:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:10][root][INFO] - Training Epoch: 2/2, step 7139/16670 completed (loss: 0.5317379236221313, acc: 0.9230769276618958)
[2024-11-14 09:20:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:11][root][INFO] - Training Epoch: 2/2, step 7140/16670 completed (loss: 0.22614909708499908, acc: 0.9130434989929199)
[2024-11-14 09:20:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:11][root][INFO] - Training Epoch: 2/2, step 7141/16670 completed (loss: 0.11124154180288315, acc: 0.9642857313156128)
[2024-11-14 09:20:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:11][root][INFO] - Training Epoch: 2/2, step 7142/16670 completed (loss: 0.17907489836215973, acc: 0.9444444179534912)
[2024-11-14 09:20:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:12][root][INFO] - Training Epoch: 2/2, step 7143/16670 completed (loss: 0.11150086671113968, acc: 1.0)
[2024-11-14 09:20:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:12][root][INFO] - Training Epoch: 2/2, step 7144/16670 completed (loss: 0.27868396043777466, acc: 0.930232584476471)
[2024-11-14 09:20:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:13][root][INFO] - Training Epoch: 2/2, step 7145/16670 completed (loss: 0.06371117383241653, acc: 1.0)
[2024-11-14 09:20:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:13][root][INFO] - Training Epoch: 2/2, step 7146/16670 completed (loss: 0.35634467005729675, acc: 0.9285714030265808)
[2024-11-14 09:20:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:13][root][INFO] - Training Epoch: 2/2, step 7147/16670 completed (loss: 0.28727781772613525, acc: 0.8947368264198303)
[2024-11-14 09:20:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:14][root][INFO] - Training Epoch: 2/2, step 7148/16670 completed (loss: 0.09019250422716141, acc: 0.9736841917037964)
[2024-11-14 09:20:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:14][root][INFO] - Training Epoch: 2/2, step 7149/16670 completed (loss: 0.3504239320755005, acc: 0.9306930899620056)
[2024-11-14 09:20:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:14][root][INFO] - Training Epoch: 2/2, step 7150/16670 completed (loss: 0.023693209514021873, acc: 1.0)
[2024-11-14 09:20:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:15][root][INFO] - Training Epoch: 2/2, step 7151/16670 completed (loss: 0.2853478193283081, acc: 0.8823529481887817)
[2024-11-14 09:20:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:15][root][INFO] - Training Epoch: 2/2, step 7152/16670 completed (loss: 0.1281290501356125, acc: 0.9736841917037964)
[2024-11-14 09:20:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:15][root][INFO] - Training Epoch: 2/2, step 7153/16670 completed (loss: 0.020678000524640083, acc: 1.0)
[2024-11-14 09:20:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:16][root][INFO] - Training Epoch: 2/2, step 7154/16670 completed (loss: 0.19410361349582672, acc: 0.9545454382896423)
[2024-11-14 09:20:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:16][root][INFO] - Training Epoch: 2/2, step 7155/16670 completed (loss: 0.15060169994831085, acc: 0.9523809552192688)
[2024-11-14 09:20:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:17][root][INFO] - Training Epoch: 2/2, step 7156/16670 completed (loss: 0.488656222820282, acc: 0.8450704216957092)
[2024-11-14 09:20:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:17][root][INFO] - Training Epoch: 2/2, step 7157/16670 completed (loss: 0.7366297841072083, acc: 0.8709677457809448)
[2024-11-14 09:20:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:17][root][INFO] - Training Epoch: 2/2, step 7158/16670 completed (loss: 0.35272011160850525, acc: 0.9259259104728699)
[2024-11-14 09:20:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:17][root][INFO] - Training Epoch: 2/2, step 7159/16670 completed (loss: 0.07280093431472778, acc: 0.9795918464660645)
[2024-11-14 09:20:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:18][root][INFO] - Training Epoch: 2/2, step 7160/16670 completed (loss: 0.24227288365364075, acc: 0.976190447807312)
[2024-11-14 09:20:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:18][root][INFO] - Training Epoch: 2/2, step 7161/16670 completed (loss: 0.04391951113939285, acc: 0.9807692170143127)
[2024-11-14 09:20:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:18][root][INFO] - Training Epoch: 2/2, step 7162/16670 completed (loss: 0.12618477642536163, acc: 0.9642857313156128)
[2024-11-14 09:20:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:19][root][INFO] - Training Epoch: 2/2, step 7163/16670 completed (loss: 0.27990958094596863, acc: 0.9272727370262146)
[2024-11-14 09:20:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:19][root][INFO] - Training Epoch: 2/2, step 7164/16670 completed (loss: 0.13479620218276978, acc: 0.9555555582046509)
[2024-11-14 09:20:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:19][root][INFO] - Training Epoch: 2/2, step 7165/16670 completed (loss: 0.21932353079319, acc: 0.9473684430122375)
[2024-11-14 09:20:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:20][root][INFO] - Training Epoch: 2/2, step 7166/16670 completed (loss: 0.2477494329214096, acc: 0.9285714030265808)
[2024-11-14 09:20:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:20][root][INFO] - Training Epoch: 2/2, step 7167/16670 completed (loss: 0.05957649275660515, acc: 1.0)
[2024-11-14 09:20:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:21][root][INFO] - Training Epoch: 2/2, step 7168/16670 completed (loss: 0.26384228467941284, acc: 0.9375)
[2024-11-14 09:20:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:21][root][INFO] - Training Epoch: 2/2, step 7169/16670 completed (loss: 0.12246347963809967, acc: 0.9666666388511658)
[2024-11-14 09:20:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:21][root][INFO] - Training Epoch: 2/2, step 7170/16670 completed (loss: 0.166113942861557, acc: 0.9399999976158142)
[2024-11-14 09:20:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:22][root][INFO] - Training Epoch: 2/2, step 7171/16670 completed (loss: 0.13835103809833527, acc: 0.9756097793579102)
[2024-11-14 09:20:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:22][root][INFO] - Training Epoch: 2/2, step 7172/16670 completed (loss: 0.4686630964279175, acc: 0.8888888955116272)
[2024-11-14 09:20:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:22][root][INFO] - Training Epoch: 2/2, step 7173/16670 completed (loss: 0.2172185778617859, acc: 0.9024389982223511)
[2024-11-14 09:20:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:23][root][INFO] - Training Epoch: 2/2, step 7174/16670 completed (loss: 0.21138852834701538, acc: 0.9516128897666931)
[2024-11-14 09:20:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:23][root][INFO] - Training Epoch: 2/2, step 7175/16670 completed (loss: 0.1348886340856552, acc: 0.9482758641242981)
[2024-11-14 09:20:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:23][root][INFO] - Training Epoch: 2/2, step 7176/16670 completed (loss: 0.5400373339653015, acc: 0.8421052694320679)
[2024-11-14 09:20:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:24][root][INFO] - Training Epoch: 2/2, step 7177/16670 completed (loss: 0.3752676248550415, acc: 0.8969072103500366)
[2024-11-14 09:20:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:24][root][INFO] - Training Epoch: 2/2, step 7178/16670 completed (loss: 0.6234991550445557, acc: 0.8108108043670654)
[2024-11-14 09:20:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:24][root][INFO] - Training Epoch: 2/2, step 7179/16670 completed (loss: 0.12773868441581726, acc: 1.0)
[2024-11-14 09:20:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:25][root][INFO] - Training Epoch: 2/2, step 7180/16670 completed (loss: 0.20384526252746582, acc: 0.9615384340286255)
[2024-11-14 09:20:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:25][root][INFO] - Training Epoch: 2/2, step 7181/16670 completed (loss: 0.3163929879665375, acc: 0.9090909361839294)
[2024-11-14 09:20:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:25][root][INFO] - Training Epoch: 2/2, step 7182/16670 completed (loss: 0.5290495157241821, acc: 0.9024389982223511)
[2024-11-14 09:20:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:26][root][INFO] - Training Epoch: 2/2, step 7183/16670 completed (loss: 0.3530997335910797, acc: 0.9272727370262146)
[2024-11-14 09:20:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:26][root][INFO] - Training Epoch: 2/2, step 7184/16670 completed (loss: 0.0633760392665863, acc: 1.0)
[2024-11-14 09:20:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:26][root][INFO] - Training Epoch: 2/2, step 7185/16670 completed (loss: 0.1758553385734558, acc: 0.9285714030265808)
[2024-11-14 09:20:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:27][root][INFO] - Training Epoch: 2/2, step 7186/16670 completed (loss: 0.17838121950626373, acc: 0.9552238583564758)
[2024-11-14 09:20:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:27][root][INFO] - Training Epoch: 2/2, step 7187/16670 completed (loss: 0.22547392547130585, acc: 0.9264705777168274)
[2024-11-14 09:20:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:27][root][INFO] - Training Epoch: 2/2, step 7188/16670 completed (loss: 0.2461155503988266, acc: 0.96875)
[2024-11-14 09:20:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:28][root][INFO] - Training Epoch: 2/2, step 7189/16670 completed (loss: 0.03772030025720596, acc: 1.0)
[2024-11-14 09:20:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:28][root][INFO] - Training Epoch: 2/2, step 7190/16670 completed (loss: 0.1559491753578186, acc: 0.957446813583374)
[2024-11-14 09:20:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:29][root][INFO] - Training Epoch: 2/2, step 7191/16670 completed (loss: 0.13231708109378815, acc: 0.95652174949646)
[2024-11-14 09:20:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:29][root][INFO] - Training Epoch: 2/2, step 7192/16670 completed (loss: 0.20497451722621918, acc: 0.9523809552192688)
[2024-11-14 09:20:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:29][root][INFO] - Training Epoch: 2/2, step 7193/16670 completed (loss: 0.08695776760578156, acc: 0.9807692170143127)
[2024-11-14 09:20:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:30][root][INFO] - Training Epoch: 2/2, step 7194/16670 completed (loss: 0.2499414086341858, acc: 0.9411764740943909)
[2024-11-14 09:20:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:30][root][INFO] - Training Epoch: 2/2, step 7195/16670 completed (loss: 0.29323112964630127, acc: 0.9166666865348816)
[2024-11-14 09:20:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:30][root][INFO] - Training Epoch: 2/2, step 7196/16670 completed (loss: 0.2728738486766815, acc: 0.8947368264198303)
[2024-11-14 09:20:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:31][root][INFO] - Training Epoch: 2/2, step 7197/16670 completed (loss: 0.28631606698036194, acc: 0.921875)
[2024-11-14 09:20:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:31][root][INFO] - Training Epoch: 2/2, step 7198/16670 completed (loss: 0.40889567136764526, acc: 0.930232584476471)
[2024-11-14 09:20:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:31][root][INFO] - Training Epoch: 2/2, step 7199/16670 completed (loss: 0.12311296164989471, acc: 0.9672130942344666)
[2024-11-14 09:20:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:32][root][INFO] - Training Epoch: 2/2, step 7200/16670 completed (loss: 0.11177901923656464, acc: 0.9677419066429138)
[2024-11-14 09:20:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:32][root][INFO] - Training Epoch: 2/2, step 7201/16670 completed (loss: 0.21444281935691833, acc: 0.8888888955116272)
[2024-11-14 09:20:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:32][root][INFO] - Training Epoch: 2/2, step 7202/16670 completed (loss: 0.1964389979839325, acc: 0.9032257795333862)
[2024-11-14 09:20:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:33][root][INFO] - Training Epoch: 2/2, step 7203/16670 completed (loss: 0.41693779826164246, acc: 0.9193548560142517)
[2024-11-14 09:20:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:33][root][INFO] - Training Epoch: 2/2, step 7204/16670 completed (loss: 0.599113941192627, acc: 0.8823529481887817)
[2024-11-14 09:20:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:33][root][INFO] - Training Epoch: 2/2, step 7205/16670 completed (loss: 0.2845099866390228, acc: 0.9259259104728699)
[2024-11-14 09:20:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:34][root][INFO] - Training Epoch: 2/2, step 7206/16670 completed (loss: 0.12543220818042755, acc: 0.982758641242981)
[2024-11-14 09:20:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:34][root][INFO] - Training Epoch: 2/2, step 7207/16670 completed (loss: 0.5392698049545288, acc: 0.8536585569381714)
[2024-11-14 09:20:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:35][root][INFO] - Training Epoch: 2/2, step 7208/16670 completed (loss: 0.3987491726875305, acc: 0.9130434989929199)
[2024-11-14 09:20:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:35][root][INFO] - Training Epoch: 2/2, step 7209/16670 completed (loss: 0.18660496175289154, acc: 0.9534883499145508)
[2024-11-14 09:20:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:35][root][INFO] - Training Epoch: 2/2, step 7210/16670 completed (loss: 0.07502792775630951, acc: 1.0)
[2024-11-14 09:20:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:36][root][INFO] - Training Epoch: 2/2, step 7211/16670 completed (loss: 0.33772945404052734, acc: 0.8888888955116272)
[2024-11-14 09:20:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:36][root][INFO] - Training Epoch: 2/2, step 7212/16670 completed (loss: 0.7618666887283325, acc: 0.8095238208770752)
[2024-11-14 09:20:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:36][root][INFO] - Training Epoch: 2/2, step 7213/16670 completed (loss: 0.33840087056159973, acc: 0.9285714030265808)
[2024-11-14 09:20:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:37][root][INFO] - Training Epoch: 2/2, step 7214/16670 completed (loss: 0.11370658129453659, acc: 0.9464285969734192)
[2024-11-14 09:20:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:37][root][INFO] - Training Epoch: 2/2, step 7215/16670 completed (loss: 0.4016972780227661, acc: 0.8709677457809448)
[2024-11-14 09:20:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:38][root][INFO] - Training Epoch: 2/2, step 7216/16670 completed (loss: 0.6763767600059509, acc: 0.9189189076423645)
[2024-11-14 09:20:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:38][root][INFO] - Training Epoch: 2/2, step 7217/16670 completed (loss: 0.13304390013217926, acc: 0.9791666865348816)
[2024-11-14 09:20:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:38][root][INFO] - Training Epoch: 2/2, step 7218/16670 completed (loss: 0.1487170159816742, acc: 0.95652174949646)
[2024-11-14 09:20:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:39][root][INFO] - Training Epoch: 2/2, step 7219/16670 completed (loss: 0.1300077736377716, acc: 0.9722222089767456)
[2024-11-14 09:20:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:39][root][INFO] - Training Epoch: 2/2, step 7220/16670 completed (loss: 0.34852728247642517, acc: 0.8928571343421936)
[2024-11-14 09:20:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:39][root][INFO] - Training Epoch: 2/2, step 7221/16670 completed (loss: 0.3379495143890381, acc: 0.9420289993286133)
[2024-11-14 09:20:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:40][root][INFO] - Training Epoch: 2/2, step 7222/16670 completed (loss: 0.38386642932891846, acc: 0.9038461446762085)
[2024-11-14 09:20:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:40][root][INFO] - Training Epoch: 2/2, step 7223/16670 completed (loss: 0.41697558760643005, acc: 0.8529411554336548)
[2024-11-14 09:20:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:41][root][INFO] - Training Epoch: 2/2, step 7224/16670 completed (loss: 0.20932620763778687, acc: 0.9333333373069763)
[2024-11-14 09:20:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:41][root][INFO] - Training Epoch: 2/2, step 7225/16670 completed (loss: 0.437967985868454, acc: 0.8888888955116272)
[2024-11-14 09:20:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:41][root][INFO] - Training Epoch: 2/2, step 7226/16670 completed (loss: 0.18492308259010315, acc: 0.9655172228813171)
[2024-11-14 09:20:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:42][root][INFO] - Training Epoch: 2/2, step 7227/16670 completed (loss: 0.21324892342090607, acc: 0.9420289993286133)
[2024-11-14 09:20:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:42][root][INFO] - Training Epoch: 2/2, step 7228/16670 completed (loss: 0.13594083487987518, acc: 0.9655172228813171)
[2024-11-14 09:20:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:42][root][INFO] - Training Epoch: 2/2, step 7229/16670 completed (loss: 0.277523010969162, acc: 0.9210526347160339)
[2024-11-14 09:20:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:43][root][INFO] - Training Epoch: 2/2, step 7230/16670 completed (loss: 0.02695527859032154, acc: 1.0)
[2024-11-14 09:20:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:43][root][INFO] - Training Epoch: 2/2, step 7231/16670 completed (loss: 0.14694485068321228, acc: 0.942307710647583)
[2024-11-14 09:20:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:43][root][INFO] - Training Epoch: 2/2, step 7232/16670 completed (loss: 0.30813437700271606, acc: 0.9080459475517273)
[2024-11-14 09:20:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:44][root][INFO] - Training Epoch: 2/2, step 7233/16670 completed (loss: 0.3892662525177002, acc: 0.875)
[2024-11-14 09:20:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:44][root][INFO] - Training Epoch: 2/2, step 7234/16670 completed (loss: 0.4376073181629181, acc: 0.8571428656578064)
[2024-11-14 09:20:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:45][root][INFO] - Training Epoch: 2/2, step 7235/16670 completed (loss: 0.1972953975200653, acc: 0.9591836929321289)
[2024-11-14 09:20:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:45][root][INFO] - Training Epoch: 2/2, step 7236/16670 completed (loss: 0.705177903175354, acc: 0.8235294222831726)
[2024-11-14 09:20:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:45][root][INFO] - Training Epoch: 2/2, step 7237/16670 completed (loss: 0.4192560911178589, acc: 0.945652186870575)
[2024-11-14 09:20:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:46][root][INFO] - Training Epoch: 2/2, step 7238/16670 completed (loss: 0.3491142690181732, acc: 0.9090909361839294)
[2024-11-14 09:20:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:46][root][INFO] - Training Epoch: 2/2, step 7239/16670 completed (loss: 0.03920682147145271, acc: 1.0)
[2024-11-14 09:20:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:46][root][INFO] - Training Epoch: 2/2, step 7240/16670 completed (loss: 0.3690514862537384, acc: 0.9189189076423645)
[2024-11-14 09:20:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:47][root][INFO] - Training Epoch: 2/2, step 7241/16670 completed (loss: 0.536851704120636, acc: 0.8857142925262451)
[2024-11-14 09:20:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:47][root][INFO] - Training Epoch: 2/2, step 7242/16670 completed (loss: 0.4482395052909851, acc: 0.8947368264198303)
[2024-11-14 09:20:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:47][root][INFO] - Training Epoch: 2/2, step 7243/16670 completed (loss: 0.4697018265724182, acc: 0.8983050584793091)
[2024-11-14 09:20:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:48][root][INFO] - Training Epoch: 2/2, step 7244/16670 completed (loss: 0.7242043614387512, acc: 0.8307692408561707)
[2024-11-14 09:20:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:48][root][INFO] - Training Epoch: 2/2, step 7245/16670 completed (loss: 1.0662870407104492, acc: 0.7058823704719543)
[2024-11-14 09:20:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:49][root][INFO] - Training Epoch: 2/2, step 7246/16670 completed (loss: 0.2576139271259308, acc: 0.9074074029922485)
[2024-11-14 09:20:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:49][root][INFO] - Training Epoch: 2/2, step 7247/16670 completed (loss: 0.17349864542484283, acc: 0.9473684430122375)
[2024-11-14 09:20:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:49][root][INFO] - Training Epoch: 2/2, step 7248/16670 completed (loss: 0.3320142328739166, acc: 0.9454545378684998)
[2024-11-14 09:20:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:50][root][INFO] - Training Epoch: 2/2, step 7249/16670 completed (loss: 0.42251870036125183, acc: 0.9032257795333862)
[2024-11-14 09:20:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:50][root][INFO] - Training Epoch: 2/2, step 7250/16670 completed (loss: 0.24254368245601654, acc: 0.9516128897666931)
[2024-11-14 09:20:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:50][root][INFO] - Training Epoch: 2/2, step 7251/16670 completed (loss: 0.18833044171333313, acc: 0.9750000238418579)
[2024-11-14 09:20:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:51][root][INFO] - Training Epoch: 2/2, step 7252/16670 completed (loss: 0.37827566266059875, acc: 0.9487179517745972)
[2024-11-14 09:20:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:51][root][INFO] - Training Epoch: 2/2, step 7253/16670 completed (loss: 0.11507099866867065, acc: 0.9714285731315613)
[2024-11-14 09:20:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:51][root][INFO] - Training Epoch: 2/2, step 7254/16670 completed (loss: 0.4575575888156891, acc: 0.8974359035491943)
[2024-11-14 09:20:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:52][root][INFO] - Training Epoch: 2/2, step 7255/16670 completed (loss: 0.2109874039888382, acc: 0.9523809552192688)
[2024-11-14 09:20:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:52][root][INFO] - Training Epoch: 2/2, step 7256/16670 completed (loss: 0.26466789841651917, acc: 0.9189189076423645)
[2024-11-14 09:20:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:53][root][INFO] - Training Epoch: 2/2, step 7257/16670 completed (loss: 0.2443343997001648, acc: 0.9382022619247437)
[2024-11-14 09:20:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:53][root][INFO] - Training Epoch: 2/2, step 7258/16670 completed (loss: 0.2629318833351135, acc: 0.9120234847068787)
[2024-11-14 09:20:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:53][root][INFO] - Training Epoch: 2/2, step 7259/16670 completed (loss: 0.2652583122253418, acc: 0.9289340376853943)
[2024-11-14 09:20:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:54][root][INFO] - Training Epoch: 2/2, step 7260/16670 completed (loss: 0.1885656714439392, acc: 0.935943067073822)
[2024-11-14 09:20:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:54][root][INFO] - Training Epoch: 2/2, step 7261/16670 completed (loss: 0.18810153007507324, acc: 0.9479768872261047)
[2024-11-14 09:20:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:54][root][INFO] - Training Epoch: 2/2, step 7262/16670 completed (loss: 0.1703367531299591, acc: 0.9547038078308105)
[2024-11-14 09:20:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:55][root][INFO] - Training Epoch: 2/2, step 7263/16670 completed (loss: 0.1995280385017395, acc: 0.9317269325256348)
[2024-11-14 09:20:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:55][root][INFO] - Training Epoch: 2/2, step 7264/16670 completed (loss: 0.36021357774734497, acc: 0.9101123809814453)
[2024-11-14 09:20:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:55][root][INFO] - Training Epoch: 2/2, step 7265/16670 completed (loss: 0.14281749725341797, acc: 0.9583333134651184)
[2024-11-14 09:20:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:56][root][INFO] - Training Epoch: 2/2, step 7266/16670 completed (loss: 0.21036361157894135, acc: 0.9505300521850586)
[2024-11-14 09:20:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:56][root][INFO] - Training Epoch: 2/2, step 7267/16670 completed (loss: 0.07801001518964767, acc: 0.9770992398262024)
[2024-11-14 09:20:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:57][root][INFO] - Training Epoch: 2/2, step 7268/16670 completed (loss: 0.40102970600128174, acc: 0.8559321761131287)
[2024-11-14 09:20:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:57][root][INFO] - Training Epoch: 2/2, step 7269/16670 completed (loss: 0.036162734031677246, acc: 0.9935897588729858)
[2024-11-14 09:20:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:57][root][INFO] - Training Epoch: 2/2, step 7270/16670 completed (loss: 0.1436624377965927, acc: 0.9738805890083313)
[2024-11-14 09:20:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:58][root][INFO] - Training Epoch: 2/2, step 7271/16670 completed (loss: 0.0406658910214901, acc: 0.9855072498321533)
[2024-11-14 09:20:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:58][root][INFO] - Training Epoch: 2/2, step 7272/16670 completed (loss: 0.16794362664222717, acc: 0.9456868767738342)
[2024-11-14 09:20:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:58][root][INFO] - Training Epoch: 2/2, step 7273/16670 completed (loss: 0.12912927567958832, acc: 0.9689922332763672)
[2024-11-14 09:20:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:59][root][INFO] - Training Epoch: 2/2, step 7274/16670 completed (loss: 0.18591012060642242, acc: 0.9513888955116272)
[2024-11-14 09:20:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:59][root][INFO] - Training Epoch: 2/2, step 7275/16670 completed (loss: 0.07978756725788116, acc: 0.9832776188850403)
[2024-11-14 09:20:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:59][root][INFO] - Training Epoch: 2/2, step 7276/16670 completed (loss: 0.15379109978675842, acc: 0.9660493731498718)
[2024-11-14 09:20:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:20:59][root][INFO] - Training Epoch: 2/2, step 7277/16670 completed (loss: 0.245888352394104, acc: 0.9307359457015991)
[2024-11-14 09:21:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:00][root][INFO] - Training Epoch: 2/2, step 7278/16670 completed (loss: 0.11821983754634857, acc: 0.9599999785423279)
[2024-11-14 09:21:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:00][root][INFO] - Training Epoch: 2/2, step 7279/16670 completed (loss: 0.15423966944217682, acc: 0.9579831957817078)
[2024-11-14 09:21:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:00][root][INFO] - Training Epoch: 2/2, step 7280/16670 completed (loss: 0.1831420511007309, acc: 0.9446640610694885)
[2024-11-14 09:21:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:01][root][INFO] - Training Epoch: 2/2, step 7281/16670 completed (loss: 0.1344672292470932, acc: 0.954407274723053)
[2024-11-14 09:21:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:01][root][INFO] - Training Epoch: 2/2, step 7282/16670 completed (loss: 0.17143775522708893, acc: 0.9493087530136108)
[2024-11-14 09:21:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:02][root][INFO] - Training Epoch: 2/2, step 7283/16670 completed (loss: 0.14394207298755646, acc: 0.9613526463508606)
[2024-11-14 09:21:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:02][root][INFO] - Training Epoch: 2/2, step 7284/16670 completed (loss: 0.2007547914981842, acc: 0.944915235042572)
[2024-11-14 09:21:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:02][root][INFO] - Training Epoch: 2/2, step 7285/16670 completed (loss: 0.17236541211605072, acc: 0.9562841653823853)
[2024-11-14 09:21:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:03][root][INFO] - Training Epoch: 2/2, step 7286/16670 completed (loss: 0.09044066071510315, acc: 0.9774919748306274)
[2024-11-14 09:21:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:03][root][INFO] - Training Epoch: 2/2, step 7287/16670 completed (loss: 0.1544678509235382, acc: 0.9584569931030273)
[2024-11-14 09:21:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:04][root][INFO] - Training Epoch: 2/2, step 7288/16670 completed (loss: 0.09220044314861298, acc: 0.9627659320831299)
[2024-11-14 09:21:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:04][root][INFO] - Training Epoch: 2/2, step 7289/16670 completed (loss: 0.15693862736225128, acc: 0.9638009071350098)
[2024-11-14 09:21:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:04][root][INFO] - Training Epoch: 2/2, step 7290/16670 completed (loss: 0.10236161202192307, acc: 0.9716312289237976)
[2024-11-14 09:21:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:05][root][INFO] - Training Epoch: 2/2, step 7291/16670 completed (loss: 0.4063427448272705, acc: 0.8918918967247009)
[2024-11-14 09:21:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:05][root][INFO] - Training Epoch: 2/2, step 7292/16670 completed (loss: 0.07633542269468307, acc: 0.9766536951065063)
[2024-11-14 09:21:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:05][root][INFO] - Training Epoch: 2/2, step 7293/16670 completed (loss: 0.0844089686870575, acc: 0.9682539701461792)
[2024-11-14 09:21:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:06][root][INFO] - Training Epoch: 2/2, step 7294/16670 completed (loss: 0.028246840462088585, acc: 0.9898648858070374)
[2024-11-14 09:21:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:06][root][INFO] - Training Epoch: 2/2, step 7295/16670 completed (loss: 0.04734836146235466, acc: 0.9863945841789246)
[2024-11-14 09:21:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:07][root][INFO] - Training Epoch: 2/2, step 7296/16670 completed (loss: 0.30736178159713745, acc: 0.916201114654541)
[2024-11-14 09:21:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:07][root][INFO] - Training Epoch: 2/2, step 7297/16670 completed (loss: 0.13084754347801208, acc: 0.9655963182449341)
[2024-11-14 09:21:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:07][root][INFO] - Training Epoch: 2/2, step 7298/16670 completed (loss: 0.2482803463935852, acc: 0.9081632494926453)
[2024-11-14 09:21:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:08][root][INFO] - Training Epoch: 2/2, step 7299/16670 completed (loss: 0.10069158673286438, acc: 0.9811320900917053)
[2024-11-14 09:21:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:08][root][INFO] - Training Epoch: 2/2, step 7300/16670 completed (loss: 0.1303299218416214, acc: 0.9609375)
[2024-11-14 09:21:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:08][root][INFO] - Training Epoch: 2/2, step 7301/16670 completed (loss: 0.0688282698392868, acc: 0.9789915680885315)
[2024-11-14 09:21:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:09][root][INFO] - Training Epoch: 2/2, step 7302/16670 completed (loss: 0.04813101887702942, acc: 0.9893048405647278)
[2024-11-14 09:21:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:09][root][INFO] - Training Epoch: 2/2, step 7303/16670 completed (loss: 0.1853753924369812, acc: 0.934883713722229)
[2024-11-14 09:21:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:10][root][INFO] - Training Epoch: 2/2, step 7304/16670 completed (loss: 0.23411118984222412, acc: 0.929618775844574)
[2024-11-14 09:21:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:10][root][INFO] - Training Epoch: 2/2, step 7305/16670 completed (loss: 0.12806540727615356, acc: 0.9646302461624146)
[2024-11-14 09:21:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:10][root][INFO] - Training Epoch: 2/2, step 7306/16670 completed (loss: 0.1252872496843338, acc: 0.9737827777862549)
[2024-11-14 09:21:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:10][root][INFO] - Training Epoch: 2/2, step 7307/16670 completed (loss: 0.30476564168930054, acc: 0.9277108311653137)
[2024-11-14 09:21:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:11][root][INFO] - Training Epoch: 2/2, step 7308/16670 completed (loss: 0.24765188992023468, acc: 0.9178571701049805)
[2024-11-14 09:21:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:11][root][INFO] - Training Epoch: 2/2, step 7309/16670 completed (loss: 0.07656336575746536, acc: 0.9814126491546631)
[2024-11-14 09:21:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:12][root][INFO] - Training Epoch: 2/2, step 7310/16670 completed (loss: 0.17231321334838867, acc: 0.9661654233932495)
[2024-11-14 09:21:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:12][root][INFO] - Training Epoch: 2/2, step 7311/16670 completed (loss: 0.0876188650727272, acc: 0.9513888955116272)
[2024-11-14 09:21:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:12][root][INFO] - Training Epoch: 2/2, step 7312/16670 completed (loss: 0.19296297430992126, acc: 0.9404255151748657)
[2024-11-14 09:21:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:13][root][INFO] - Training Epoch: 2/2, step 7313/16670 completed (loss: 0.2330053299665451, acc: 0.9377431869506836)
[2024-11-14 09:21:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:13][root][INFO] - Training Epoch: 2/2, step 7314/16670 completed (loss: 0.15973125398159027, acc: 0.9624999761581421)
[2024-11-14 09:21:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:13][root][INFO] - Training Epoch: 2/2, step 7315/16670 completed (loss: 0.22103333473205566, acc: 0.9428571462631226)
[2024-11-14 09:21:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:14][root][INFO] - Training Epoch: 2/2, step 7316/16670 completed (loss: 0.031472936272621155, acc: 1.0)
[2024-11-14 09:21:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:14][root][INFO] - Training Epoch: 2/2, step 7317/16670 completed (loss: 0.27756938338279724, acc: 0.9341563582420349)
[2024-11-14 09:21:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:14][root][INFO] - Training Epoch: 2/2, step 7318/16670 completed (loss: 0.08366788923740387, acc: 0.9843137264251709)
[2024-11-14 09:21:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:15][root][INFO] - Training Epoch: 2/2, step 7319/16670 completed (loss: 0.1623179018497467, acc: 0.954692542552948)
[2024-11-14 09:21:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:15][root][INFO] - Training Epoch: 2/2, step 7320/16670 completed (loss: 0.09207407385110855, acc: 0.9749103784561157)
[2024-11-14 09:21:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:16][root][INFO] - Training Epoch: 2/2, step 7321/16670 completed (loss: 0.042169153690338135, acc: 0.9896193742752075)
[2024-11-14 09:21:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:16][root][INFO] - Training Epoch: 2/2, step 7322/16670 completed (loss: 0.0617094486951828, acc: 0.9759759902954102)
[2024-11-14 09:21:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:16][root][INFO] - Training Epoch: 2/2, step 7323/16670 completed (loss: 0.13993972539901733, acc: 0.9541666507720947)
[2024-11-14 09:21:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:17][root][INFO] - Training Epoch: 2/2, step 7324/16670 completed (loss: 0.19201602041721344, acc: 0.9465649127960205)
[2024-11-14 09:21:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:17][root][INFO] - Training Epoch: 2/2, step 7325/16670 completed (loss: 0.12075630575418472, acc: 0.9539170265197754)
[2024-11-14 09:21:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:18][root][INFO] - Training Epoch: 2/2, step 7326/16670 completed (loss: 0.1161022037267685, acc: 0.980079710483551)
[2024-11-14 09:21:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:18][root][INFO] - Training Epoch: 2/2, step 7327/16670 completed (loss: 0.23041003942489624, acc: 0.9236640930175781)
[2024-11-14 09:21:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:18][root][INFO] - Training Epoch: 2/2, step 7328/16670 completed (loss: 0.16434301435947418, acc: 0.9433333277702332)
[2024-11-14 09:21:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:19][root][INFO] - Training Epoch: 2/2, step 7329/16670 completed (loss: 0.07086290419101715, acc: 0.9778597950935364)
[2024-11-14 09:21:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:19][root][INFO] - Training Epoch: 2/2, step 7330/16670 completed (loss: 0.07100613415241241, acc: 0.976190447807312)
[2024-11-14 09:21:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:19][root][INFO] - Training Epoch: 2/2, step 7331/16670 completed (loss: 0.17934422194957733, acc: 0.9481707215309143)
[2024-11-14 09:21:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:20][root][INFO] - Training Epoch: 2/2, step 7332/16670 completed (loss: 0.09505008906126022, acc: 0.9709677696228027)
[2024-11-14 09:21:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:20][root][INFO] - Training Epoch: 2/2, step 7333/16670 completed (loss: 0.11757321655750275, acc: 0.9477611780166626)
[2024-11-14 09:21:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:21][root][INFO] - Training Epoch: 2/2, step 7334/16670 completed (loss: 0.17170065641403198, acc: 0.9583333134651184)
[2024-11-14 09:21:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:21][root][INFO] - Training Epoch: 2/2, step 7335/16670 completed (loss: 0.15695901215076447, acc: 0.9541666507720947)
[2024-11-14 09:21:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:21][root][INFO] - Training Epoch: 2/2, step 7336/16670 completed (loss: 0.05905847251415253, acc: 0.9905660152435303)
[2024-11-14 09:21:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:22][root][INFO] - Training Epoch: 2/2, step 7337/16670 completed (loss: 0.09753646701574326, acc: 0.9648648500442505)
[2024-11-14 09:21:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:22][root][INFO] - Training Epoch: 2/2, step 7338/16670 completed (loss: 0.18210917711257935, acc: 0.9673202633857727)
[2024-11-14 09:21:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:22][root][INFO] - Training Epoch: 2/2, step 7339/16670 completed (loss: 0.17334066331386566, acc: 0.9344262480735779)
[2024-11-14 09:21:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:23][root][INFO] - Training Epoch: 2/2, step 7340/16670 completed (loss: 0.29609084129333496, acc: 0.9285714030265808)
[2024-11-14 09:21:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:23][root][INFO] - Training Epoch: 2/2, step 7341/16670 completed (loss: 0.09439273923635483, acc: 0.9842519760131836)
[2024-11-14 09:21:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:24][root][INFO] - Training Epoch: 2/2, step 7342/16670 completed (loss: 0.07471325993537903, acc: 0.9881656765937805)
[2024-11-14 09:21:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:24][root][INFO] - Training Epoch: 2/2, step 7343/16670 completed (loss: 0.09403567761182785, acc: 0.9631901979446411)
[2024-11-14 09:21:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:24][root][INFO] - Training Epoch: 2/2, step 7344/16670 completed (loss: 0.04745223745703697, acc: 0.9829931855201721)
[2024-11-14 09:21:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:25][root][INFO] - Training Epoch: 2/2, step 7345/16670 completed (loss: 0.13090896606445312, acc: 0.9624999761581421)
[2024-11-14 09:21:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:25][root][INFO] - Training Epoch: 2/2, step 7346/16670 completed (loss: 0.15939967334270477, acc: 0.9411764740943909)
[2024-11-14 09:21:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:25][root][INFO] - Training Epoch: 2/2, step 7347/16670 completed (loss: 0.15278823673725128, acc: 0.9563491940498352)
[2024-11-14 09:21:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:26][root][INFO] - Training Epoch: 2/2, step 7348/16670 completed (loss: 0.15328779816627502, acc: 0.9557521939277649)
[2024-11-14 09:21:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:26][root][INFO] - Training Epoch: 2/2, step 7349/16670 completed (loss: 0.15899048745632172, acc: 0.9543859362602234)
[2024-11-14 09:21:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:26][root][INFO] - Training Epoch: 2/2, step 7350/16670 completed (loss: 0.13565599918365479, acc: 0.9644013047218323)
[2024-11-14 09:21:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:27][root][INFO] - Training Epoch: 2/2, step 7351/16670 completed (loss: 0.17628921568393707, acc: 0.9452054500579834)
[2024-11-14 09:21:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:27][root][INFO] - Training Epoch: 2/2, step 7352/16670 completed (loss: 0.1027320995926857, acc: 0.9726027250289917)
[2024-11-14 09:21:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:27][root][INFO] - Training Epoch: 2/2, step 7353/16670 completed (loss: 0.2448958307504654, acc: 0.9294871687889099)
[2024-11-14 09:21:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:28][root][INFO] - Training Epoch: 2/2, step 7354/16670 completed (loss: 0.11186292767524719, acc: 0.9666666388511658)
[2024-11-14 09:21:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:28][root][INFO] - Training Epoch: 2/2, step 7355/16670 completed (loss: 0.19829022884368896, acc: 0.9653679728507996)
[2024-11-14 09:21:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:28][root][INFO] - Training Epoch: 2/2, step 7356/16670 completed (loss: 0.1247463971376419, acc: 0.9627329111099243)
[2024-11-14 09:21:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:29][root][INFO] - Training Epoch: 2/2, step 7357/16670 completed (loss: 0.16127793490886688, acc: 0.9581151604652405)
[2024-11-14 09:21:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:29][root][INFO] - Training Epoch: 2/2, step 7358/16670 completed (loss: 0.11006777733564377, acc: 0.9649805426597595)
[2024-11-14 09:21:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:29][root][INFO] - Training Epoch: 2/2, step 7359/16670 completed (loss: 0.17152802646160126, acc: 0.9647576808929443)
[2024-11-14 09:21:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:30][root][INFO] - Training Epoch: 2/2, step 7360/16670 completed (loss: 0.27208879590034485, acc: 0.9345794320106506)
[2024-11-14 09:21:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:30][root][INFO] - Training Epoch: 2/2, step 7361/16670 completed (loss: 0.15860581398010254, acc: 0.9435028433799744)
[2024-11-14 09:21:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:30][root][INFO] - Training Epoch: 2/2, step 7362/16670 completed (loss: 0.17186281085014343, acc: 0.9590908885002136)
[2024-11-14 09:21:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:31][root][INFO] - Training Epoch: 2/2, step 7363/16670 completed (loss: 0.08575726300477982, acc: 0.9545454382896423)
[2024-11-14 09:21:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:31][root][INFO] - Training Epoch: 2/2, step 7364/16670 completed (loss: 0.15738920867443085, acc: 0.9658384919166565)
[2024-11-14 09:21:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:31][root][INFO] - Training Epoch: 2/2, step 7365/16670 completed (loss: 0.10456326603889465, acc: 0.9721115827560425)
[2024-11-14 09:21:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:32][root][INFO] - Training Epoch: 2/2, step 7366/16670 completed (loss: 0.15884095430374146, acc: 0.945026159286499)
[2024-11-14 09:21:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:32][root][INFO] - Training Epoch: 2/2, step 7367/16670 completed (loss: 0.08807124942541122, acc: 0.9735449552536011)
[2024-11-14 09:21:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:32][root][INFO] - Training Epoch: 2/2, step 7368/16670 completed (loss: 0.25669974088668823, acc: 0.9321428537368774)
[2024-11-14 09:21:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:33][root][INFO] - Training Epoch: 2/2, step 7369/16670 completed (loss: 0.08998547494411469, acc: 0.962837815284729)
[2024-11-14 09:21:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:33][root][INFO] - Training Epoch: 2/2, step 7370/16670 completed (loss: 0.19583295285701752, acc: 0.9494949579238892)
[2024-11-14 09:21:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:33][root][INFO] - Training Epoch: 2/2, step 7371/16670 completed (loss: 0.07056904584169388, acc: 0.9724770784378052)
[2024-11-14 09:21:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:34][root][INFO] - Training Epoch: 2/2, step 7372/16670 completed (loss: 0.1737680435180664, acc: 0.9558823704719543)
[2024-11-14 09:21:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:34][root][INFO] - Training Epoch: 2/2, step 7373/16670 completed (loss: 0.19314691424369812, acc: 0.9506173133850098)
[2024-11-14 09:21:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:34][root][INFO] - Training Epoch: 2/2, step 7374/16670 completed (loss: 0.11087417602539062, acc: 0.971563994884491)
[2024-11-14 09:21:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:35][root][INFO] - Training Epoch: 2/2, step 7375/16670 completed (loss: 0.30734920501708984, acc: 0.9459459185600281)
[2024-11-14 09:21:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:35][root][INFO] - Training Epoch: 2/2, step 7376/16670 completed (loss: 0.11996437609195709, acc: 0.9694322943687439)
[2024-11-14 09:21:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:35][root][INFO] - Training Epoch: 2/2, step 7377/16670 completed (loss: 0.0850479006767273, acc: 0.9733333587646484)
[2024-11-14 09:21:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:36][root][INFO] - Training Epoch: 2/2, step 7378/16670 completed (loss: 0.3520719110965729, acc: 0.9011406898498535)
[2024-11-14 09:21:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:36][root][INFO] - Training Epoch: 2/2, step 7379/16670 completed (loss: 0.08651243150234222, acc: 0.9810126423835754)
[2024-11-14 09:21:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:36][root][INFO] - Training Epoch: 2/2, step 7380/16670 completed (loss: 0.06713633984327316, acc: 0.9847908616065979)
[2024-11-14 09:21:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:37][root][INFO] - Training Epoch: 2/2, step 7381/16670 completed (loss: 0.14127564430236816, acc: 0.9578059315681458)
[2024-11-14 09:21:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:37][root][INFO] - Training Epoch: 2/2, step 7382/16670 completed (loss: 0.25574204325675964, acc: 0.9386503100395203)
[2024-11-14 09:21:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:37][root][INFO] - Training Epoch: 2/2, step 7383/16670 completed (loss: 0.07743716239929199, acc: 0.9867841601371765)
[2024-11-14 09:21:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:38][root][INFO] - Training Epoch: 2/2, step 7384/16670 completed (loss: 0.05761534720659256, acc: 0.9871794581413269)
[2024-11-14 09:21:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:38][root][INFO] - Training Epoch: 2/2, step 7385/16670 completed (loss: 0.1539217233657837, acc: 0.9615384340286255)
[2024-11-14 09:21:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:38][root][INFO] - Training Epoch: 2/2, step 7386/16670 completed (loss: 0.08935357630252838, acc: 0.9616613388061523)
[2024-11-14 09:21:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:39][root][INFO] - Training Epoch: 2/2, step 7387/16670 completed (loss: 0.2550267279148102, acc: 0.9411764740943909)
[2024-11-14 09:21:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:39][root][INFO] - Training Epoch: 2/2, step 7388/16670 completed (loss: 0.21849530935287476, acc: 0.9214659929275513)
[2024-11-14 09:21:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:39][root][INFO] - Training Epoch: 2/2, step 7389/16670 completed (loss: 0.15810956060886383, acc: 0.9842932224273682)
[2024-11-14 09:21:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:40][root][INFO] - Training Epoch: 2/2, step 7390/16670 completed (loss: 0.0973111167550087, acc: 0.9674267172813416)
[2024-11-14 09:21:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:40][root][INFO] - Training Epoch: 2/2, step 7391/16670 completed (loss: 0.1889744997024536, acc: 0.9423868060112)
[2024-11-14 09:21:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:40][root][INFO] - Training Epoch: 2/2, step 7392/16670 completed (loss: 0.1735832691192627, acc: 0.9559228420257568)
[2024-11-14 09:21:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:41][root][INFO] - Training Epoch: 2/2, step 7393/16670 completed (loss: 0.10172697901725769, acc: 0.9764705896377563)
[2024-11-14 09:21:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:41][root][INFO] - Training Epoch: 2/2, step 7394/16670 completed (loss: 0.14795401692390442, acc: 0.9627329111099243)
[2024-11-14 09:21:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:41][root][INFO] - Training Epoch: 2/2, step 7395/16670 completed (loss: 0.0630808174610138, acc: 0.9785714149475098)
[2024-11-14 09:21:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:42][root][INFO] - Training Epoch: 2/2, step 7396/16670 completed (loss: 0.18141953647136688, acc: 0.9576719403266907)
[2024-11-14 09:21:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:42][root][INFO] - Training Epoch: 2/2, step 7397/16670 completed (loss: 0.1922731250524521, acc: 0.9575471878051758)
[2024-11-14 09:21:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:42][root][INFO] - Training Epoch: 2/2, step 7398/16670 completed (loss: 0.12411119788885117, acc: 0.9616438150405884)
[2024-11-14 09:21:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:43][root][INFO] - Training Epoch: 2/2, step 7399/16670 completed (loss: 0.1368071585893631, acc: 0.9562841653823853)
[2024-11-14 09:21:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:43][root][INFO] - Training Epoch: 2/2, step 7400/16670 completed (loss: 0.12225555628538132, acc: 0.9642857313156128)
[2024-11-14 09:21:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:43][root][INFO] - Training Epoch: 2/2, step 7401/16670 completed (loss: 0.16764624416828156, acc: 0.9533073902130127)
[2024-11-14 09:21:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:44][root][INFO] - Training Epoch: 2/2, step 7402/16670 completed (loss: 0.028104707598686218, acc: 0.9948979616165161)
[2024-11-14 09:21:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:44][root][INFO] - Training Epoch: 2/2, step 7403/16670 completed (loss: 0.13303379714488983, acc: 0.9729729890823364)
[2024-11-14 09:21:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:44][root][INFO] - Training Epoch: 2/2, step 7404/16670 completed (loss: 0.07623913139104843, acc: 0.977142870426178)
[2024-11-14 09:21:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:45][root][INFO] - Training Epoch: 2/2, step 7405/16670 completed (loss: 0.15169881284236908, acc: 0.954023003578186)
[2024-11-14 09:21:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:45][root][INFO] - Training Epoch: 2/2, step 7406/16670 completed (loss: 0.08847939968109131, acc: 0.9810426831245422)
[2024-11-14 09:21:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:45][root][INFO] - Training Epoch: 2/2, step 7407/16670 completed (loss: 0.10163137316703796, acc: 0.9873417615890503)
[2024-11-14 09:21:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:46][root][INFO] - Training Epoch: 2/2, step 7408/16670 completed (loss: 0.16293713450431824, acc: 0.9512894153594971)
[2024-11-14 09:21:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:46][root][INFO] - Training Epoch: 2/2, step 7409/16670 completed (loss: 0.04993380233645439, acc: 0.9885057210922241)
[2024-11-14 09:21:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:46][root][INFO] - Training Epoch: 2/2, step 7410/16670 completed (loss: 0.05384006351232529, acc: 0.9848484992980957)
[2024-11-14 09:21:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:46][root][INFO] - Training Epoch: 2/2, step 7411/16670 completed (loss: 0.09705845266580582, acc: 0.9731543660163879)
[2024-11-14 09:21:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:47][root][INFO] - Training Epoch: 2/2, step 7412/16670 completed (loss: 0.10874169319868088, acc: 0.9800000190734863)
[2024-11-14 09:21:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:47][root][INFO] - Training Epoch: 2/2, step 7413/16670 completed (loss: 0.04253694415092468, acc: 0.991304337978363)
[2024-11-14 09:21:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:47][root][INFO] - Training Epoch: 2/2, step 7414/16670 completed (loss: 0.03088584914803505, acc: 0.9893617033958435)
[2024-11-14 09:21:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:48][root][INFO] - Training Epoch: 2/2, step 7415/16670 completed (loss: 0.15511316061019897, acc: 0.9694656729698181)
[2024-11-14 09:21:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:48][root][INFO] - Training Epoch: 2/2, step 7416/16670 completed (loss: 0.18429036438465118, acc: 0.9459459185600281)
[2024-11-14 09:21:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:48][root][INFO] - Training Epoch: 2/2, step 7417/16670 completed (loss: 0.12577873468399048, acc: 0.9640287756919861)
[2024-11-14 09:21:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:49][root][INFO] - Training Epoch: 2/2, step 7418/16670 completed (loss: 0.1525670439004898, acc: 0.9509803652763367)
[2024-11-14 09:21:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:49][root][INFO] - Training Epoch: 2/2, step 7419/16670 completed (loss: 0.1361943930387497, acc: 0.9642857313156128)
[2024-11-14 09:21:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:49][root][INFO] - Training Epoch: 2/2, step 7420/16670 completed (loss: 0.03184220939874649, acc: 0.9937888383865356)
[2024-11-14 09:21:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:50][root][INFO] - Training Epoch: 2/2, step 7421/16670 completed (loss: 0.07471156865358353, acc: 0.9721115827560425)
[2024-11-14 09:21:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:50][root][INFO] - Training Epoch: 2/2, step 7422/16670 completed (loss: 0.04059021919965744, acc: 0.9820895791053772)
[2024-11-14 09:21:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:50][root][INFO] - Training Epoch: 2/2, step 7423/16670 completed (loss: 0.08306600153446198, acc: 0.9818181991577148)
[2024-11-14 09:21:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:51][root][INFO] - Training Epoch: 2/2, step 7424/16670 completed (loss: 0.09440572559833527, acc: 0.9714285731315613)
[2024-11-14 09:21:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:51][root][INFO] - Training Epoch: 2/2, step 7425/16670 completed (loss: 0.21026843786239624, acc: 0.9463087320327759)
[2024-11-14 09:21:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:51][root][INFO] - Training Epoch: 2/2, step 7426/16670 completed (loss: 0.08644551038742065, acc: 0.9789473414421082)
[2024-11-14 09:21:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:52][root][INFO] - Training Epoch: 2/2, step 7427/16670 completed (loss: 0.0614837147295475, acc: 0.9868995547294617)
[2024-11-14 09:21:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:52][root][INFO] - Training Epoch: 2/2, step 7428/16670 completed (loss: 0.09116150438785553, acc: 0.9691358208656311)
[2024-11-14 09:21:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:52][root][INFO] - Training Epoch: 2/2, step 7429/16670 completed (loss: 0.16391609609127045, acc: 0.9660193920135498)
[2024-11-14 09:21:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:53][root][INFO] - Training Epoch: 2/2, step 7430/16670 completed (loss: 0.13088826835155487, acc: 0.9779005646705627)
[2024-11-14 09:21:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:53][root][INFO] - Training Epoch: 2/2, step 7431/16670 completed (loss: 0.04970316216349602, acc: 0.9871794581413269)
[2024-11-14 09:21:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:53][root][INFO] - Training Epoch: 2/2, step 7432/16670 completed (loss: 0.15297551453113556, acc: 0.9628099203109741)
[2024-11-14 09:21:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:54][root][INFO] - Training Epoch: 2/2, step 7433/16670 completed (loss: 0.1466805785894394, acc: 0.9587156176567078)
[2024-11-14 09:21:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:54][root][INFO] - Training Epoch: 2/2, step 7434/16670 completed (loss: 0.06659629940986633, acc: 0.9727272987365723)
[2024-11-14 09:21:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:54][root][INFO] - Training Epoch: 2/2, step 7435/16670 completed (loss: 0.0843416377902031, acc: 0.9750000238418579)
[2024-11-14 09:21:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:55][root][INFO] - Training Epoch: 2/2, step 7436/16670 completed (loss: 0.0893435850739479, acc: 0.9642857313156128)
[2024-11-14 09:21:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:55][root][INFO] - Training Epoch: 2/2, step 7437/16670 completed (loss: 0.20081835985183716, acc: 0.9314516186714172)
[2024-11-14 09:21:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:55][root][INFO] - Training Epoch: 2/2, step 7438/16670 completed (loss: 0.04419415071606636, acc: 0.9956331849098206)
[2024-11-14 09:21:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:56][root][INFO] - Training Epoch: 2/2, step 7439/16670 completed (loss: 0.08802498877048492, acc: 0.9615384340286255)
[2024-11-14 09:21:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:56][root][INFO] - Training Epoch: 2/2, step 7440/16670 completed (loss: 0.15921495854854584, acc: 0.9588235020637512)
[2024-11-14 09:21:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:57][root][INFO] - Training Epoch: 2/2, step 7441/16670 completed (loss: 0.10555607825517654, acc: 0.9694189429283142)
[2024-11-14 09:21:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:57][root][INFO] - Training Epoch: 2/2, step 7442/16670 completed (loss: 0.06548876315355301, acc: 0.9789473414421082)
[2024-11-14 09:21:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:57][root][INFO] - Training Epoch: 2/2, step 7443/16670 completed (loss: 0.13270850479602814, acc: 0.9528301954269409)
[2024-11-14 09:21:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:58][root][INFO] - Training Epoch: 2/2, step 7444/16670 completed (loss: 0.12408053874969482, acc: 0.9468085169792175)
[2024-11-14 09:21:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:58][root][INFO] - Training Epoch: 2/2, step 7445/16670 completed (loss: 0.058905452489852905, acc: 0.9883268475532532)
[2024-11-14 09:21:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:59][root][INFO] - Training Epoch: 2/2, step 7446/16670 completed (loss: 0.10618295520544052, acc: 0.9666666388511658)
[2024-11-14 09:21:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:59][root][INFO] - Training Epoch: 2/2, step 7447/16670 completed (loss: 0.14500202238559723, acc: 0.9670329689979553)
[2024-11-14 09:21:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:21:59][root][INFO] - Training Epoch: 2/2, step 7448/16670 completed (loss: 0.04158318415284157, acc: 0.9811320900917053)
[2024-11-14 09:21:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:00][root][INFO] - Training Epoch: 2/2, step 7449/16670 completed (loss: 0.143229141831398, acc: 0.9489796161651611)
[2024-11-14 09:22:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:00][root][INFO] - Training Epoch: 2/2, step 7450/16670 completed (loss: 0.23813915252685547, acc: 0.9263157844543457)
[2024-11-14 09:22:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:01][root][INFO] - Training Epoch: 2/2, step 7451/16670 completed (loss: 0.08176542818546295, acc: 0.9781659245491028)
[2024-11-14 09:22:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:01][root][INFO] - Training Epoch: 2/2, step 7452/16670 completed (loss: 0.0702190101146698, acc: 0.9854545593261719)
[2024-11-14 09:22:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:01][root][INFO] - Training Epoch: 2/2, step 7453/16670 completed (loss: 0.09348293393850327, acc: 0.976047933101654)
[2024-11-14 09:22:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:02][root][INFO] - Training Epoch: 2/2, step 7454/16670 completed (loss: 0.173400416970253, acc: 0.9318181872367859)
[2024-11-14 09:22:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:02][root][INFO] - Training Epoch: 2/2, step 7455/16670 completed (loss: 0.0526384674012661, acc: 0.9858356714248657)
[2024-11-14 09:22:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:02][root][INFO] - Training Epoch: 2/2, step 7456/16670 completed (loss: 0.12838037312030792, acc: 0.9601770043373108)
[2024-11-14 09:22:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:03][root][INFO] - Training Epoch: 2/2, step 7457/16670 completed (loss: 0.07365356385707855, acc: 0.9785932898521423)
[2024-11-14 09:22:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:03][root][INFO] - Training Epoch: 2/2, step 7458/16670 completed (loss: 0.14036114513874054, acc: 0.9610389471054077)
[2024-11-14 09:22:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:04][root][INFO] - Training Epoch: 2/2, step 7459/16670 completed (loss: 0.10728199034929276, acc: 0.9656862616539001)
[2024-11-14 09:22:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:04][root][INFO] - Training Epoch: 2/2, step 7460/16670 completed (loss: 0.06040893867611885, acc: 0.97826087474823)
[2024-11-14 09:22:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:04][root][INFO] - Training Epoch: 2/2, step 7461/16670 completed (loss: 0.07596898078918457, acc: 0.9770641922950745)
[2024-11-14 09:22:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:05][root][INFO] - Training Epoch: 2/2, step 7462/16670 completed (loss: 0.16417573392391205, acc: 0.9528301954269409)
[2024-11-14 09:22:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:05][root][INFO] - Training Epoch: 2/2, step 7463/16670 completed (loss: 0.09622104465961456, acc: 0.9752475023269653)
[2024-11-14 09:22:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:05][root][INFO] - Training Epoch: 2/2, step 7464/16670 completed (loss: 0.09354555606842041, acc: 0.98591548204422)
[2024-11-14 09:22:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:06][root][INFO] - Training Epoch: 2/2, step 7465/16670 completed (loss: 0.0920887142419815, acc: 0.9783197641372681)
[2024-11-14 09:22:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:06][root][INFO] - Training Epoch: 2/2, step 7466/16670 completed (loss: 0.10773468017578125, acc: 0.9666666388511658)
[2024-11-14 09:22:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:07][root][INFO] - Training Epoch: 2/2, step 7467/16670 completed (loss: 0.096934475004673, acc: 0.9790209531784058)
[2024-11-14 09:22:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:07][root][INFO] - Training Epoch: 2/2, step 7468/16670 completed (loss: 0.07166745513677597, acc: 0.9798387289047241)
[2024-11-14 09:22:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:07][root][INFO] - Training Epoch: 2/2, step 7469/16670 completed (loss: 0.16036982834339142, acc: 0.9685039520263672)
[2024-11-14 09:22:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:08][root][INFO] - Training Epoch: 2/2, step 7470/16670 completed (loss: 0.16051267087459564, acc: 0.9615384340286255)
[2024-11-14 09:22:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:08][root][INFO] - Training Epoch: 2/2, step 7471/16670 completed (loss: 0.1481667459011078, acc: 0.9470587968826294)
[2024-11-14 09:22:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:08][root][INFO] - Training Epoch: 2/2, step 7472/16670 completed (loss: 0.13139662146568298, acc: 0.9554139971733093)
[2024-11-14 09:22:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:09][root][INFO] - Training Epoch: 2/2, step 7473/16670 completed (loss: 0.2248390167951584, acc: 0.914893627166748)
[2024-11-14 09:22:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:09][root][INFO] - Training Epoch: 2/2, step 7474/16670 completed (loss: 0.09962431341409683, acc: 0.9593908786773682)
[2024-11-14 09:22:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:10][root][INFO] - Training Epoch: 2/2, step 7475/16670 completed (loss: 0.05497857928276062, acc: 0.9865471124649048)
[2024-11-14 09:22:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:10][root][INFO] - Training Epoch: 2/2, step 7476/16670 completed (loss: 0.11097104847431183, acc: 0.9593023061752319)
[2024-11-14 09:22:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:10][root][INFO] - Training Epoch: 2/2, step 7477/16670 completed (loss: 0.2247830182313919, acc: 0.9528796076774597)
[2024-11-14 09:22:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:11][root][INFO] - Training Epoch: 2/2, step 7478/16670 completed (loss: 0.031002210453152657, acc: 0.9893617033958435)
[2024-11-14 09:22:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:11][root][INFO] - Training Epoch: 2/2, step 7479/16670 completed (loss: 0.15108835697174072, acc: 0.949999988079071)
[2024-11-14 09:22:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:11][root][INFO] - Training Epoch: 2/2, step 7480/16670 completed (loss: 0.1758985072374344, acc: 0.9551569223403931)
[2024-11-14 09:22:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:11][root][INFO] - Training Epoch: 2/2, step 7481/16670 completed (loss: 0.11700073629617691, acc: 0.9696969985961914)
[2024-11-14 09:22:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:12][root][INFO] - Training Epoch: 2/2, step 7482/16670 completed (loss: 0.07733385264873505, acc: 0.9696969985961914)
[2024-11-14 09:22:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:12][root][INFO] - Training Epoch: 2/2, step 7483/16670 completed (loss: 0.19664403796195984, acc: 0.9454545378684998)
[2024-11-14 09:22:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:12][root][INFO] - Training Epoch: 2/2, step 7484/16670 completed (loss: 0.04752781614661217, acc: 0.9896907210350037)
[2024-11-14 09:22:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:13][root][INFO] - Training Epoch: 2/2, step 7485/16670 completed (loss: 0.0646044984459877, acc: 0.9813664555549622)
[2024-11-14 09:22:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:13][root][INFO] - Training Epoch: 2/2, step 7486/16670 completed (loss: 0.13466796278953552, acc: 0.9609375)
[2024-11-14 09:22:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:13][root][INFO] - Training Epoch: 2/2, step 7487/16670 completed (loss: 0.14013786613941193, acc: 0.9617021083831787)
[2024-11-14 09:22:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:14][root][INFO] - Training Epoch: 2/2, step 7488/16670 completed (loss: 0.04243333265185356, acc: 0.9943820238113403)
[2024-11-14 09:22:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:14][root][INFO] - Training Epoch: 2/2, step 7489/16670 completed (loss: 0.15776897966861725, acc: 0.9426751732826233)
[2024-11-14 09:22:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:14][root][INFO] - Training Epoch: 2/2, step 7490/16670 completed (loss: 0.20342573523521423, acc: 0.9378238320350647)
[2024-11-14 09:22:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:15][root][INFO] - Training Epoch: 2/2, step 7491/16670 completed (loss: 0.1639164686203003, acc: 0.9333333373069763)
[2024-11-14 09:22:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:15][root][INFO] - Training Epoch: 2/2, step 7492/16670 completed (loss: 0.20812033116817474, acc: 0.9175257682800293)
[2024-11-14 09:22:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:15][root][INFO] - Training Epoch: 2/2, step 7493/16670 completed (loss: 0.1449744552373886, acc: 0.969924807548523)
[2024-11-14 09:22:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:16][root][INFO] - Training Epoch: 2/2, step 7494/16670 completed (loss: 0.1637994945049286, acc: 0.9543147087097168)
[2024-11-14 09:22:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:16][root][INFO] - Training Epoch: 2/2, step 7495/16670 completed (loss: 0.13529813289642334, acc: 0.9674418568611145)
[2024-11-14 09:22:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:16][root][INFO] - Training Epoch: 2/2, step 7496/16670 completed (loss: 0.09497229009866714, acc: 0.9612902998924255)
[2024-11-14 09:22:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:17][root][INFO] - Training Epoch: 2/2, step 7497/16670 completed (loss: 0.14931128919124603, acc: 0.9604519605636597)
[2024-11-14 09:22:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:17][root][INFO] - Training Epoch: 2/2, step 7498/16670 completed (loss: 0.08199524879455566, acc: 0.9794520735740662)
[2024-11-14 09:22:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:17][root][INFO] - Training Epoch: 2/2, step 7499/16670 completed (loss: 0.07289214432239532, acc: 0.9756097793579102)
[2024-11-14 09:22:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:18][root][INFO] - Training Epoch: 2/2, step 7500/16670 completed (loss: 0.07517125457525253, acc: 0.9744681119918823)
[2024-11-14 09:22:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:18][root][INFO] - Training Epoch: 2/2, step 7501/16670 completed (loss: 0.01756853424012661, acc: 1.0)
[2024-11-14 09:22:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:18][root][INFO] - Training Epoch: 2/2, step 7502/16670 completed (loss: 0.06371035426855087, acc: 0.9747474789619446)
[2024-11-14 09:22:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:19][root][INFO] - Training Epoch: 2/2, step 7503/16670 completed (loss: 0.12125855684280396, acc: 0.9670329689979553)
[2024-11-14 09:22:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:19][root][INFO] - Training Epoch: 2/2, step 7504/16670 completed (loss: 0.086237832903862, acc: 0.9838709831237793)
[2024-11-14 09:22:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:19][root][INFO] - Training Epoch: 2/2, step 7505/16670 completed (loss: 0.25588059425354004, acc: 0.9350000023841858)
[2024-11-14 09:22:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:20][root][INFO] - Training Epoch: 2/2, step 7506/16670 completed (loss: 0.17672836780548096, acc: 0.9629629850387573)
[2024-11-14 09:22:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:20][root][INFO] - Training Epoch: 2/2, step 7507/16670 completed (loss: 0.24240362644195557, acc: 0.9171270728111267)
[2024-11-14 09:22:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:20][root][INFO] - Training Epoch: 2/2, step 7508/16670 completed (loss: 0.06357967108488083, acc: 0.9929078221321106)
[2024-11-14 09:22:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:21][root][INFO] - Training Epoch: 2/2, step 7509/16670 completed (loss: 0.1189948245882988, acc: 0.9473684430122375)
[2024-11-14 09:22:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:21][root][INFO] - Training Epoch: 2/2, step 7510/16670 completed (loss: 0.13275451958179474, acc: 0.9593023061752319)
[2024-11-14 09:22:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:21][root][INFO] - Training Epoch: 2/2, step 7511/16670 completed (loss: 0.17702113091945648, acc: 0.9519230723381042)
[2024-11-14 09:22:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:22][root][INFO] - Training Epoch: 2/2, step 7512/16670 completed (loss: 0.12742087244987488, acc: 0.9661538600921631)
[2024-11-14 09:22:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:22][root][INFO] - Training Epoch: 2/2, step 7513/16670 completed (loss: 0.10620887577533722, acc: 0.9734848737716675)
[2024-11-14 09:22:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:23][root][INFO] - Training Epoch: 2/2, step 7514/16670 completed (loss: 0.17646116018295288, acc: 0.9372937083244324)
[2024-11-14 09:22:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:23][root][INFO] - Training Epoch: 2/2, step 7515/16670 completed (loss: 0.10949435085058212, acc: 0.971731424331665)
[2024-11-14 09:22:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:23][root][INFO] - Training Epoch: 2/2, step 7516/16670 completed (loss: 0.1692415475845337, acc: 0.961240291595459)
[2024-11-14 09:22:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:24][root][INFO] - Training Epoch: 2/2, step 7517/16670 completed (loss: 0.06566376984119415, acc: 0.9715302586555481)
[2024-11-14 09:22:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:24][root][INFO] - Training Epoch: 2/2, step 7518/16670 completed (loss: 0.13104255497455597, acc: 0.9683544039726257)
[2024-11-14 09:22:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:24][root][INFO] - Training Epoch: 2/2, step 7519/16670 completed (loss: 0.07441480457782745, acc: 0.9831932783126831)
[2024-11-14 09:22:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:25][root][INFO] - Training Epoch: 2/2, step 7520/16670 completed (loss: 0.16268371045589447, acc: 0.9545454382896423)
[2024-11-14 09:22:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:25][root][INFO] - Training Epoch: 2/2, step 7521/16670 completed (loss: 0.06790784746408463, acc: 0.9780219793319702)
[2024-11-14 09:22:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:25][root][INFO] - Training Epoch: 2/2, step 7522/16670 completed (loss: 0.23381924629211426, acc: 0.95652174949646)
[2024-11-14 09:22:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:26][root][INFO] - Training Epoch: 2/2, step 7523/16670 completed (loss: 0.16798196732997894, acc: 0.9550561904907227)
[2024-11-14 09:22:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:26][root][INFO] - Training Epoch: 2/2, step 7524/16670 completed (loss: 0.29314181208610535, acc: 0.9200000166893005)
[2024-11-14 09:22:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:26][root][INFO] - Training Epoch: 2/2, step 7525/16670 completed (loss: 0.3410854637622833, acc: 0.9205297827720642)
[2024-11-14 09:22:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:27][root][INFO] - Training Epoch: 2/2, step 7526/16670 completed (loss: 0.05340082570910454, acc: 0.9781659245491028)
[2024-11-14 09:22:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:27][root][INFO] - Training Epoch: 2/2, step 7527/16670 completed (loss: 0.15154710412025452, acc: 0.95652174949646)
[2024-11-14 09:22:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:27][root][INFO] - Training Epoch: 2/2, step 7528/16670 completed (loss: 0.11287999898195267, acc: 0.9718309640884399)
[2024-11-14 09:22:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:28][root][INFO] - Training Epoch: 2/2, step 7529/16670 completed (loss: 0.1230616569519043, acc: 0.9795918464660645)
[2024-11-14 09:22:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:28][root][INFO] - Training Epoch: 2/2, step 7530/16670 completed (loss: 0.09587039053440094, acc: 0.9800994992256165)
[2024-11-14 09:22:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:29][root][INFO] - Training Epoch: 2/2, step 7531/16670 completed (loss: 0.09367548674345016, acc: 0.9558823704719543)
[2024-11-14 09:22:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:29][root][INFO] - Training Epoch: 2/2, step 7532/16670 completed (loss: 0.07845708727836609, acc: 0.9780219793319702)
[2024-11-14 09:22:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:29][root][INFO] - Training Epoch: 2/2, step 7533/16670 completed (loss: 0.09126971662044525, acc: 0.9805194735527039)
[2024-11-14 09:22:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:30][root][INFO] - Training Epoch: 2/2, step 7534/16670 completed (loss: 0.024498116225004196, acc: 0.9913793206214905)
[2024-11-14 09:22:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:30][root][INFO] - Training Epoch: 2/2, step 7535/16670 completed (loss: 0.1613837629556656, acc: 0.9473684430122375)
[2024-11-14 09:22:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:30][root][INFO] - Training Epoch: 2/2, step 7536/16670 completed (loss: 0.38469812273979187, acc: 0.9090909361839294)
[2024-11-14 09:22:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:31][root][INFO] - Training Epoch: 2/2, step 7537/16670 completed (loss: 0.027042627334594727, acc: 1.0)
[2024-11-14 09:22:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:31][root][INFO] - Training Epoch: 2/2, step 7538/16670 completed (loss: 0.14696520566940308, acc: 0.936170220375061)
[2024-11-14 09:22:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:32][root][INFO] - Training Epoch: 2/2, step 7539/16670 completed (loss: 0.13359223306179047, acc: 0.9685863852500916)
[2024-11-14 09:22:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:32][root][INFO] - Training Epoch: 2/2, step 7540/16670 completed (loss: 0.031805407255887985, acc: 0.9904761910438538)
[2024-11-14 09:22:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:32][root][INFO] - Training Epoch: 2/2, step 7541/16670 completed (loss: 0.15649506449699402, acc: 0.9470899701118469)
[2024-11-14 09:22:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:33][root][INFO] - Training Epoch: 2/2, step 7542/16670 completed (loss: 0.17768104374408722, acc: 0.9380530714988708)
[2024-11-14 09:22:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:33][root][INFO] - Training Epoch: 2/2, step 7543/16670 completed (loss: 0.11098118126392365, acc: 0.9595959782600403)
[2024-11-14 09:22:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:33][root][INFO] - Training Epoch: 2/2, step 7544/16670 completed (loss: 0.10918112099170685, acc: 0.977011501789093)
[2024-11-14 09:22:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:34][root][INFO] - Training Epoch: 2/2, step 7545/16670 completed (loss: 0.19024696946144104, acc: 0.9805825352668762)
[2024-11-14 09:22:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:34][root][INFO] - Training Epoch: 2/2, step 7546/16670 completed (loss: 0.090205617249012, acc: 0.9738219976425171)
[2024-11-14 09:22:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:35][root][INFO] - Training Epoch: 2/2, step 7547/16670 completed (loss: 0.08269054442644119, acc: 0.9862068891525269)
[2024-11-14 09:22:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:35][root][INFO] - Training Epoch: 2/2, step 7548/16670 completed (loss: 0.15920716524124146, acc: 0.9632107019424438)
[2024-11-14 09:22:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:35][root][INFO] - Training Epoch: 2/2, step 7549/16670 completed (loss: 0.12768305838108063, acc: 0.957446813583374)
[2024-11-14 09:22:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:36][root][INFO] - Training Epoch: 2/2, step 7550/16670 completed (loss: 0.11295975744724274, acc: 0.9679999947547913)
[2024-11-14 09:22:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:36][root][INFO] - Training Epoch: 2/2, step 7551/16670 completed (loss: 0.08901821076869965, acc: 0.970588207244873)
[2024-11-14 09:22:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:36][root][INFO] - Training Epoch: 2/2, step 7552/16670 completed (loss: 0.0681738629937172, acc: 0.9795918464660645)
[2024-11-14 09:22:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:37][root][INFO] - Training Epoch: 2/2, step 7553/16670 completed (loss: 0.244733989238739, acc: 0.9285714030265808)
[2024-11-14 09:22:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:37][root][INFO] - Training Epoch: 2/2, step 7554/16670 completed (loss: 0.09108290076255798, acc: 0.9769585132598877)
[2024-11-14 09:22:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:37][root][INFO] - Training Epoch: 2/2, step 7555/16670 completed (loss: 0.07164478302001953, acc: 0.9842105507850647)
[2024-11-14 09:22:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:38][root][INFO] - Training Epoch: 2/2, step 7556/16670 completed (loss: 0.11180789768695831, acc: 0.969111979007721)
[2024-11-14 09:22:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:38][root][INFO] - Training Epoch: 2/2, step 7557/16670 completed (loss: 0.08207990974187851, acc: 0.9745762944221497)
[2024-11-14 09:22:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:39][root][INFO] - Training Epoch: 2/2, step 7558/16670 completed (loss: 0.14812034368515015, acc: 0.966292142868042)
[2024-11-14 09:22:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:39][root][INFO] - Training Epoch: 2/2, step 7559/16670 completed (loss: 0.04513004794716835, acc: 0.9722222089767456)
[2024-11-14 09:22:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:39][root][INFO] - Training Epoch: 2/2, step 7560/16670 completed (loss: 0.13938011229038239, acc: 0.9686098694801331)
[2024-11-14 09:22:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:40][root][INFO] - Training Epoch: 2/2, step 7561/16670 completed (loss: 0.30719640851020813, acc: 0.913241982460022)
[2024-11-14 09:22:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:40][root][INFO] - Training Epoch: 2/2, step 7562/16670 completed (loss: 0.22701150178909302, acc: 0.9409282803535461)
[2024-11-14 09:22:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:40][root][INFO] - Training Epoch: 2/2, step 7563/16670 completed (loss: 0.08795760571956635, acc: 0.9880239367485046)
[2024-11-14 09:22:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:41][root][INFO] - Training Epoch: 2/2, step 7564/16670 completed (loss: 0.08506760746240616, acc: 0.9750000238418579)
[2024-11-14 09:22:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:41][root][INFO] - Training Epoch: 2/2, step 7565/16670 completed (loss: 0.16843697428703308, acc: 0.9541984796524048)
[2024-11-14 09:22:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:41][root][INFO] - Training Epoch: 2/2, step 7566/16670 completed (loss: 0.04446496069431305, acc: 0.9915611743927002)
[2024-11-14 09:22:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:42][root][INFO] - Training Epoch: 2/2, step 7567/16670 completed (loss: 0.09739450365304947, acc: 0.9698795080184937)
[2024-11-14 09:22:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:42][root][INFO] - Training Epoch: 2/2, step 7568/16670 completed (loss: 0.2687262296676636, acc: 0.9202454090118408)
[2024-11-14 09:22:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:43][root][INFO] - Training Epoch: 2/2, step 7569/16670 completed (loss: 0.23819243907928467, acc: 0.9407114386558533)
[2024-11-14 09:22:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:43][root][INFO] - Training Epoch: 2/2, step 7570/16670 completed (loss: 0.10095473378896713, acc: 0.9754601120948792)
[2024-11-14 09:22:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:43][root][INFO] - Training Epoch: 2/2, step 7571/16670 completed (loss: 0.07288490235805511, acc: 0.9800994992256165)
[2024-11-14 09:22:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:44][root][INFO] - Training Epoch: 2/2, step 7572/16670 completed (loss: 0.08946117758750916, acc: 0.9774436354637146)
[2024-11-14 09:22:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:44][root][INFO] - Training Epoch: 2/2, step 7573/16670 completed (loss: 0.21842528879642487, acc: 0.9469026327133179)
[2024-11-14 09:22:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:44][root][INFO] - Training Epoch: 2/2, step 7574/16670 completed (loss: 0.11908340454101562, acc: 0.9508670568466187)
[2024-11-14 09:22:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:45][root][INFO] - Training Epoch: 2/2, step 7575/16670 completed (loss: 0.06877051293849945, acc: 0.9873949289321899)
[2024-11-14 09:22:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:45][root][INFO] - Training Epoch: 2/2, step 7576/16670 completed (loss: 0.2049691081047058, acc: 0.9304635524749756)
[2024-11-14 09:22:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:45][root][INFO] - Training Epoch: 2/2, step 7577/16670 completed (loss: 0.12752987444400787, acc: 0.9726027250289917)
[2024-11-14 09:22:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:46][root][INFO] - Training Epoch: 2/2, step 7578/16670 completed (loss: 0.17331504821777344, acc: 0.9503546357154846)
[2024-11-14 09:22:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:46][root][INFO] - Training Epoch: 2/2, step 7579/16670 completed (loss: 0.12980066239833832, acc: 0.9637305736541748)
[2024-11-14 09:22:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:47][root][INFO] - Training Epoch: 2/2, step 7580/16670 completed (loss: 0.19182629883289337, acc: 0.9557822942733765)
[2024-11-14 09:22:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:47][root][INFO] - Training Epoch: 2/2, step 7581/16670 completed (loss: 0.11611068248748779, acc: 0.9784172773361206)
[2024-11-14 09:22:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:47][root][INFO] - Training Epoch: 2/2, step 7582/16670 completed (loss: 0.10934216529130936, acc: 0.9745762944221497)
[2024-11-14 09:22:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:48][root][INFO] - Training Epoch: 2/2, step 7583/16670 completed (loss: 0.13680078089237213, acc: 0.9548872113227844)
[2024-11-14 09:22:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:48][root][INFO] - Training Epoch: 2/2, step 7584/16670 completed (loss: 0.17377956211566925, acc: 0.9595959782600403)
[2024-11-14 09:22:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:48][root][INFO] - Training Epoch: 2/2, step 7585/16670 completed (loss: 0.0971146896481514, acc: 0.9774436354637146)
[2024-11-14 09:22:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:49][root][INFO] - Training Epoch: 2/2, step 7586/16670 completed (loss: 0.02861623279750347, acc: 0.9937106966972351)
[2024-11-14 09:22:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:49][root][INFO] - Training Epoch: 2/2, step 7587/16670 completed (loss: 0.03166444972157478, acc: 0.9947090148925781)
[2024-11-14 09:22:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:50][root][INFO] - Training Epoch: 2/2, step 7588/16670 completed (loss: 0.07548417896032333, acc: 0.9793814420700073)
[2024-11-14 09:22:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:50][root][INFO] - Training Epoch: 2/2, step 7589/16670 completed (loss: 0.3192649781703949, acc: 0.9200000166893005)
[2024-11-14 09:22:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:50][root][INFO] - Training Epoch: 2/2, step 7590/16670 completed (loss: 0.08252044022083282, acc: 0.9642857313156128)
[2024-11-14 09:22:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:51][root][INFO] - Training Epoch: 2/2, step 7591/16670 completed (loss: 0.07531096786260605, acc: 0.9777777791023254)
[2024-11-14 09:22:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:51][root][INFO] - Training Epoch: 2/2, step 7592/16670 completed (loss: 0.08109227567911148, acc: 0.9639639854431152)
[2024-11-14 09:22:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:52][root][INFO] - Training Epoch: 2/2, step 7593/16670 completed (loss: 0.2554031014442444, acc: 0.9120879173278809)
[2024-11-14 09:22:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:52][root][INFO] - Training Epoch: 2/2, step 7594/16670 completed (loss: 0.16266022622585297, acc: 0.9578313231468201)
[2024-11-14 09:22:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:52][root][INFO] - Training Epoch: 2/2, step 7595/16670 completed (loss: 0.1975095123052597, acc: 0.9677419066429138)
[2024-11-14 09:22:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:53][root][INFO] - Training Epoch: 2/2, step 7596/16670 completed (loss: 0.10501988977193832, acc: 0.9691358208656311)
[2024-11-14 09:22:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:53][root][INFO] - Training Epoch: 2/2, step 7597/16670 completed (loss: 0.24045871198177338, acc: 0.9329608678817749)
[2024-11-14 09:22:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:54][root][INFO] - Training Epoch: 2/2, step 7598/16670 completed (loss: 0.15137013792991638, acc: 0.9644444584846497)
[2024-11-14 09:22:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:54][root][INFO] - Training Epoch: 2/2, step 7599/16670 completed (loss: 0.08314313739538193, acc: 0.9626865386962891)
[2024-11-14 09:22:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:54][root][INFO] - Training Epoch: 2/2, step 7600/16670 completed (loss: 0.11525628715753555, acc: 0.9653465151786804)
[2024-11-14 09:22:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:55][root][INFO] - Training Epoch: 2/2, step 7601/16670 completed (loss: 0.0522615909576416, acc: 0.987261176109314)
[2024-11-14 09:22:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:55][root][INFO] - Training Epoch: 2/2, step 7602/16670 completed (loss: 0.1324138045310974, acc: 0.949999988079071)
[2024-11-14 09:22:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:55][root][INFO] - Training Epoch: 2/2, step 7603/16670 completed (loss: 0.10765519738197327, acc: 0.9723183512687683)
[2024-11-14 09:22:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:55][root][INFO] - Training Epoch: 2/2, step 7604/16670 completed (loss: 0.06017623469233513, acc: 0.9867841601371765)
[2024-11-14 09:22:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:56][root][INFO] - Training Epoch: 2/2, step 7605/16670 completed (loss: 0.22922898828983307, acc: 0.930232584476471)
[2024-11-14 09:22:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:56][root][INFO] - Training Epoch: 2/2, step 7606/16670 completed (loss: 0.10482557862997055, acc: 0.9739583134651184)
[2024-11-14 09:22:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:57][root][INFO] - Training Epoch: 2/2, step 7607/16670 completed (loss: 0.05555567145347595, acc: 0.976190447807312)
[2024-11-14 09:22:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:57][root][INFO] - Training Epoch: 2/2, step 7608/16670 completed (loss: 0.0933884009718895, acc: 0.9826589822769165)
[2024-11-14 09:22:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:57][root][INFO] - Training Epoch: 2/2, step 7609/16670 completed (loss: 0.22182759642601013, acc: 0.9516128897666931)
[2024-11-14 09:22:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:57][root][INFO] - Training Epoch: 2/2, step 7610/16670 completed (loss: 0.06228869408369064, acc: 0.9820627570152283)
[2024-11-14 09:22:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:58][root][INFO] - Training Epoch: 2/2, step 7611/16670 completed (loss: 0.10679484158754349, acc: 0.9672897458076477)
[2024-11-14 09:22:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:58][root][INFO] - Training Epoch: 2/2, step 7612/16670 completed (loss: 0.13596831262111664, acc: 0.9652777910232544)
[2024-11-14 09:22:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:58][root][INFO] - Training Epoch: 2/2, step 7613/16670 completed (loss: 0.2957771420478821, acc: 0.9239130616188049)
[2024-11-14 09:22:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:59][root][INFO] - Training Epoch: 2/2, step 7614/16670 completed (loss: 0.13977383077144623, acc: 0.9539749026298523)
[2024-11-14 09:22:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:59][root][INFO] - Training Epoch: 2/2, step 7615/16670 completed (loss: 0.07178161293268204, acc: 0.9781249761581421)
[2024-11-14 09:22:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:22:59][root][INFO] - Training Epoch: 2/2, step 7616/16670 completed (loss: 0.019625093787908554, acc: 0.9954128265380859)
[2024-11-14 09:22:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:00][root][INFO] - Training Epoch: 2/2, step 7617/16670 completed (loss: 0.1540910005569458, acc: 0.954356849193573)
[2024-11-14 09:23:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:00][root][INFO] - Training Epoch: 2/2, step 7618/16670 completed (loss: 0.17645953595638275, acc: 0.9318181872367859)
[2024-11-14 09:23:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:00][root][INFO] - Training Epoch: 2/2, step 7619/16670 completed (loss: 0.013413171283900738, acc: 1.0)
[2024-11-14 09:23:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:01][root][INFO] - Training Epoch: 2/2, step 7620/16670 completed (loss: 0.06429854780435562, acc: 0.9902912378311157)
[2024-11-14 09:23:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:01][root][INFO] - Training Epoch: 2/2, step 7621/16670 completed (loss: 0.03847828507423401, acc: 0.9875776171684265)
[2024-11-14 09:23:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:01][root][INFO] - Training Epoch: 2/2, step 7622/16670 completed (loss: 0.2070349156856537, acc: 0.9425287246704102)
[2024-11-14 09:23:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:02][root][INFO] - Training Epoch: 2/2, step 7623/16670 completed (loss: 0.1975301057100296, acc: 0.9510489702224731)
[2024-11-14 09:23:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:02][root][INFO] - Training Epoch: 2/2, step 7624/16670 completed (loss: 0.21328023076057434, acc: 0.932692289352417)
[2024-11-14 09:23:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:02][root][INFO] - Training Epoch: 2/2, step 7625/16670 completed (loss: 0.20814955234527588, acc: 0.9516907930374146)
[2024-11-14 09:23:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:03][root][INFO] - Training Epoch: 2/2, step 7626/16670 completed (loss: 0.10006681829690933, acc: 0.9709302186965942)
[2024-11-14 09:23:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:03][root][INFO] - Training Epoch: 2/2, step 7627/16670 completed (loss: 0.04086023569107056, acc: 0.9878048896789551)
[2024-11-14 09:23:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:03][root][INFO] - Training Epoch: 2/2, step 7628/16670 completed (loss: 0.16094645857810974, acc: 0.9594095945358276)
[2024-11-14 09:23:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:04][root][INFO] - Training Epoch: 2/2, step 7629/16670 completed (loss: 0.21633735299110413, acc: 0.9436619877815247)
[2024-11-14 09:23:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:04][root][INFO] - Training Epoch: 2/2, step 7630/16670 completed (loss: 0.21292905509471893, acc: 0.9319728016853333)
[2024-11-14 09:23:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:04][root][INFO] - Training Epoch: 2/2, step 7631/16670 completed (loss: 0.13422517478466034, acc: 0.9523809552192688)
[2024-11-14 09:23:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:05][root][INFO] - Training Epoch: 2/2, step 7632/16670 completed (loss: 0.13991519808769226, acc: 0.9545454382896423)
[2024-11-14 09:23:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:05][root][INFO] - Training Epoch: 2/2, step 7633/16670 completed (loss: 0.22081159055233002, acc: 0.9578059315681458)
[2024-11-14 09:23:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:05][root][INFO] - Training Epoch: 2/2, step 7634/16670 completed (loss: 0.11070530861616135, acc: 0.9733333587646484)
[2024-11-14 09:23:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:05][root][INFO] - Training Epoch: 2/2, step 7635/16670 completed (loss: 0.19251428544521332, acc: 0.9567901492118835)
[2024-11-14 09:23:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:06][root][INFO] - Training Epoch: 2/2, step 7636/16670 completed (loss: 0.12562035024166107, acc: 0.95652174949646)
[2024-11-14 09:23:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:06][root][INFO] - Training Epoch: 2/2, step 7637/16670 completed (loss: 0.07739541679620743, acc: 0.970588207244873)
[2024-11-14 09:23:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:06][root][INFO] - Training Epoch: 2/2, step 7638/16670 completed (loss: 0.09859078377485275, acc: 0.9803149700164795)
[2024-11-14 09:23:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:07][root][INFO] - Training Epoch: 2/2, step 7639/16670 completed (loss: 0.059669651091098785, acc: 0.9766082167625427)
[2024-11-14 09:23:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:07][root][INFO] - Training Epoch: 2/2, step 7640/16670 completed (loss: 0.13313981890678406, acc: 0.9575757384300232)
[2024-11-14 09:23:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:07][root][INFO] - Training Epoch: 2/2, step 7641/16670 completed (loss: 0.12485617399215698, acc: 0.9666666388511658)
[2024-11-14 09:23:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:08][root][INFO] - Training Epoch: 2/2, step 7642/16670 completed (loss: 0.28143468499183655, acc: 0.9166666865348816)
[2024-11-14 09:23:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:08][root][INFO] - Training Epoch: 2/2, step 7643/16670 completed (loss: 0.16276441514492035, acc: 0.9661538600921631)
[2024-11-14 09:23:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:08][root][INFO] - Training Epoch: 2/2, step 7644/16670 completed (loss: 0.18828561902046204, acc: 0.9629629850387573)
[2024-11-14 09:23:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:09][root][INFO] - Training Epoch: 2/2, step 7645/16670 completed (loss: 0.27235570549964905, acc: 0.9312499761581421)
[2024-11-14 09:23:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:09][root][INFO] - Training Epoch: 2/2, step 7646/16670 completed (loss: 0.04413365200161934, acc: 0.9801980257034302)
[2024-11-14 09:23:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:09][root][INFO] - Training Epoch: 2/2, step 7647/16670 completed (loss: 0.09373780339956284, acc: 0.9795082211494446)
[2024-11-14 09:23:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:10][root][INFO] - Training Epoch: 2/2, step 7648/16670 completed (loss: 0.15698681771755219, acc: 0.9563758373260498)
[2024-11-14 09:23:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:10][root][INFO] - Training Epoch: 2/2, step 7649/16670 completed (loss: 0.031982652842998505, acc: 0.9920634627342224)
[2024-11-14 09:23:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:10][root][INFO] - Training Epoch: 2/2, step 7650/16670 completed (loss: 0.0461815670132637, acc: 0.9879518151283264)
[2024-11-14 09:23:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:11][root][INFO] - Training Epoch: 2/2, step 7651/16670 completed (loss: 0.13017146289348602, acc: 0.9529411792755127)
[2024-11-14 09:23:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:11][root][INFO] - Training Epoch: 2/2, step 7652/16670 completed (loss: 0.1779688596725464, acc: 0.9569892287254333)
[2024-11-14 09:23:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:11][root][INFO] - Training Epoch: 2/2, step 7653/16670 completed (loss: 0.13774998486042023, acc: 0.9675675630569458)
[2024-11-14 09:23:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:12][root][INFO] - Training Epoch: 2/2, step 7654/16670 completed (loss: 0.14503909647464752, acc: 0.95703125)
[2024-11-14 09:23:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:12][root][INFO] - Training Epoch: 2/2, step 7655/16670 completed (loss: 0.12626895308494568, acc: 0.9575289487838745)
[2024-11-14 09:23:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:12][root][INFO] - Training Epoch: 2/2, step 7656/16670 completed (loss: 0.025779105722904205, acc: 0.9896373152732849)
[2024-11-14 09:23:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:13][root][INFO] - Training Epoch: 2/2, step 7657/16670 completed (loss: 0.055045049637556076, acc: 0.9885057210922241)
[2024-11-14 09:23:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:13][root][INFO] - Training Epoch: 2/2, step 7658/16670 completed (loss: 0.08627763390541077, acc: 0.9710144996643066)
[2024-11-14 09:23:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:13][root][INFO] - Training Epoch: 2/2, step 7659/16670 completed (loss: 0.09803980588912964, acc: 0.9639175534248352)
[2024-11-14 09:23:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:14][root][INFO] - Training Epoch: 2/2, step 7660/16670 completed (loss: 0.13020722568035126, acc: 0.9740932583808899)
[2024-11-14 09:23:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:14][root][INFO] - Training Epoch: 2/2, step 7661/16670 completed (loss: 0.17424339056015015, acc: 0.9358974099159241)
[2024-11-14 09:23:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:14][root][INFO] - Training Epoch: 2/2, step 7662/16670 completed (loss: 0.04924483597278595, acc: 0.9813084006309509)
[2024-11-14 09:23:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:15][root][INFO] - Training Epoch: 2/2, step 7663/16670 completed (loss: 0.10752619057893753, acc: 0.9731800556182861)
[2024-11-14 09:23:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:15][root][INFO] - Training Epoch: 2/2, step 7664/16670 completed (loss: 0.1797323077917099, acc: 0.9642857313156128)
[2024-11-14 09:23:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:15][root][INFO] - Training Epoch: 2/2, step 7665/16670 completed (loss: 0.09427659958600998, acc: 0.9811320900917053)
[2024-11-14 09:23:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:16][root][INFO] - Training Epoch: 2/2, step 7666/16670 completed (loss: 0.16097357869148254, acc: 0.9365079402923584)
[2024-11-14 09:23:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:16][root][INFO] - Training Epoch: 2/2, step 7667/16670 completed (loss: 0.06097059324383736, acc: 0.9736841917037964)
[2024-11-14 09:23:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:16][root][INFO] - Training Epoch: 2/2, step 7668/16670 completed (loss: 0.15686985850334167, acc: 0.9622641801834106)
[2024-11-14 09:23:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:17][root][INFO] - Training Epoch: 2/2, step 7669/16670 completed (loss: 0.22456669807434082, acc: 0.9555555582046509)
[2024-11-14 09:23:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:17][root][INFO] - Training Epoch: 2/2, step 7670/16670 completed (loss: 0.03974059969186783, acc: 0.9879999756813049)
[2024-11-14 09:23:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:17][root][INFO] - Training Epoch: 2/2, step 7671/16670 completed (loss: 0.12225502729415894, acc: 0.9635627269744873)
[2024-11-14 09:23:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:17][root][INFO] - Training Epoch: 2/2, step 7672/16670 completed (loss: 0.1084429994225502, acc: 0.9689119458198547)
[2024-11-14 09:23:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:18][root][INFO] - Training Epoch: 2/2, step 7673/16670 completed (loss: 0.09477817267179489, acc: 0.9767441749572754)
[2024-11-14 09:23:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:18][root][INFO] - Training Epoch: 2/2, step 7674/16670 completed (loss: 0.05444132164120674, acc: 0.9727272987365723)
[2024-11-14 09:23:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:18][root][INFO] - Training Epoch: 2/2, step 7675/16670 completed (loss: 0.13519245386123657, acc: 0.966183602809906)
[2024-11-14 09:23:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:19][root][INFO] - Training Epoch: 2/2, step 7676/16670 completed (loss: 0.19868138432502747, acc: 0.9528301954269409)
[2024-11-14 09:23:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:19][root][INFO] - Training Epoch: 2/2, step 7677/16670 completed (loss: 0.11429467797279358, acc: 0.9611650705337524)
[2024-11-14 09:23:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:19][root][INFO] - Training Epoch: 2/2, step 7678/16670 completed (loss: 0.06520246714353561, acc: 0.9855769276618958)
[2024-11-14 09:23:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:20][root][INFO] - Training Epoch: 2/2, step 7679/16670 completed (loss: 0.14748775959014893, acc: 0.9623655676841736)
[2024-11-14 09:23:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:20][root][INFO] - Training Epoch: 2/2, step 7680/16670 completed (loss: 0.07434096932411194, acc: 0.9784482717514038)
[2024-11-14 09:23:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:20][root][INFO] - Training Epoch: 2/2, step 7681/16670 completed (loss: 0.08625324815511703, acc: 0.9780219793319702)
[2024-11-14 09:23:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:21][root][INFO] - Training Epoch: 2/2, step 7682/16670 completed (loss: 0.1276465356349945, acc: 0.966183602809906)
[2024-11-14 09:23:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:21][root][INFO] - Training Epoch: 2/2, step 7683/16670 completed (loss: 0.07749776542186737, acc: 0.9751243591308594)
[2024-11-14 09:23:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:21][root][INFO] - Training Epoch: 2/2, step 7684/16670 completed (loss: 0.07725870609283447, acc: 0.9781420826911926)
[2024-11-14 09:23:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:22][root][INFO] - Training Epoch: 2/2, step 7685/16670 completed (loss: 0.1827828735113144, acc: 0.9459459185600281)
[2024-11-14 09:23:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:22][root][INFO] - Training Epoch: 2/2, step 7686/16670 completed (loss: 0.07394351810216904, acc: 0.9655172228813171)
[2024-11-14 09:23:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:22][root][INFO] - Training Epoch: 2/2, step 7687/16670 completed (loss: 0.07381283491849899, acc: 0.9652777910232544)
[2024-11-14 09:23:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:23][root][INFO] - Training Epoch: 2/2, step 7688/16670 completed (loss: 0.13867981731891632, acc: 0.9648241400718689)
[2024-11-14 09:23:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:23][root][INFO] - Training Epoch: 2/2, step 7689/16670 completed (loss: 0.07840781658887863, acc: 0.984375)
[2024-11-14 09:23:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:23][root][INFO] - Training Epoch: 2/2, step 7690/16670 completed (loss: 0.07661104202270508, acc: 0.978723406791687)
[2024-11-14 09:23:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:23][root][INFO] - Training Epoch: 2/2, step 7691/16670 completed (loss: 0.14030645787715912, acc: 0.9599999785423279)
[2024-11-14 09:23:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:24][root][INFO] - Training Epoch: 2/2, step 7692/16670 completed (loss: 0.08822736889123917, acc: 0.9732142686843872)
[2024-11-14 09:23:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:24][root][INFO] - Training Epoch: 2/2, step 7693/16670 completed (loss: 0.0347505621612072, acc: 0.9863013625144958)
[2024-11-14 09:23:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:25][root][INFO] - Training Epoch: 2/2, step 7694/16670 completed (loss: 0.08882247656583786, acc: 0.970588207244873)
[2024-11-14 09:23:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:25][root][INFO] - Training Epoch: 2/2, step 7695/16670 completed (loss: 0.08775021135807037, acc: 0.9615384340286255)
[2024-11-14 09:23:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:25][root][INFO] - Training Epoch: 2/2, step 7696/16670 completed (loss: 0.08241458982229233, acc: 0.9714285731315613)
[2024-11-14 09:23:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:25][root][INFO] - Training Epoch: 2/2, step 7697/16670 completed (loss: 0.04173949733376503, acc: 0.9888888597488403)
[2024-11-14 09:23:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:26][root][INFO] - Training Epoch: 2/2, step 7698/16670 completed (loss: 0.09455892443656921, acc: 0.9739130139350891)
[2024-11-14 09:23:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:26][root][INFO] - Training Epoch: 2/2, step 7699/16670 completed (loss: 0.23287835717201233, acc: 0.9336283206939697)
[2024-11-14 09:23:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:26][root][INFO] - Training Epoch: 2/2, step 7700/16670 completed (loss: 0.05354107543826103, acc: 0.9793814420700073)
[2024-11-14 09:23:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:27][root][INFO] - Training Epoch: 2/2, step 7701/16670 completed (loss: 0.06780899316072464, acc: 0.9746835231781006)
[2024-11-14 09:23:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:27][root][INFO] - Training Epoch: 2/2, step 7702/16670 completed (loss: 0.07729896903038025, acc: 0.9728682041168213)
[2024-11-14 09:23:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:28][root][INFO] - Training Epoch: 2/2, step 7703/16670 completed (loss: 0.31557485461235046, acc: 0.925000011920929)
[2024-11-14 09:23:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:28][root][INFO] - Training Epoch: 2/2, step 7704/16670 completed (loss: 0.0929906889796257, acc: 0.9756097793579102)
[2024-11-14 09:23:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:28][root][INFO] - Training Epoch: 2/2, step 7705/16670 completed (loss: 0.3080819845199585, acc: 0.90625)
[2024-11-14 09:23:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:29][root][INFO] - Training Epoch: 2/2, step 7706/16670 completed (loss: 0.09461020678281784, acc: 0.9666666388511658)
[2024-11-14 09:23:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:29][root][INFO] - Training Epoch: 2/2, step 7707/16670 completed (loss: 0.11446122080087662, acc: 0.965753436088562)
[2024-11-14 09:23:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:29][root][INFO] - Training Epoch: 2/2, step 7708/16670 completed (loss: 0.1821308135986328, acc: 0.9495798349380493)
[2024-11-14 09:23:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:30][root][INFO] - Training Epoch: 2/2, step 7709/16670 completed (loss: 0.1456611603498459, acc: 0.9523809552192688)
[2024-11-14 09:23:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:30][root][INFO] - Training Epoch: 2/2, step 7710/16670 completed (loss: 0.04981290549039841, acc: 0.991304337978363)
[2024-11-14 09:23:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:30][root][INFO] - Training Epoch: 2/2, step 7711/16670 completed (loss: 0.12440527230501175, acc: 0.9523809552192688)
[2024-11-14 09:23:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:31][root][INFO] - Training Epoch: 2/2, step 7712/16670 completed (loss: 0.04405505955219269, acc: 0.9854369163513184)
[2024-11-14 09:23:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:31][root][INFO] - Training Epoch: 2/2, step 7713/16670 completed (loss: 0.2115248441696167, acc: 0.9411764740943909)
[2024-11-14 09:23:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:32][root][INFO] - Training Epoch: 2/2, step 7714/16670 completed (loss: 0.3427174687385559, acc: 0.8925619721412659)
[2024-11-14 09:23:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:32][root][INFO] - Training Epoch: 2/2, step 7715/16670 completed (loss: 0.08937536925077438, acc: 0.9734513163566589)
[2024-11-14 09:23:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:32][root][INFO] - Training Epoch: 2/2, step 7716/16670 completed (loss: 0.1348343938589096, acc: 0.9778761267662048)
[2024-11-14 09:23:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:33][root][INFO] - Training Epoch: 2/2, step 7717/16670 completed (loss: 0.06313104182481766, acc: 0.976190447807312)
[2024-11-14 09:23:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:33][root][INFO] - Training Epoch: 2/2, step 7718/16670 completed (loss: 0.020244698971509933, acc: 0.9927007555961609)
[2024-11-14 09:23:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:33][root][INFO] - Training Epoch: 2/2, step 7719/16670 completed (loss: 0.02267961949110031, acc: 0.9935483932495117)
[2024-11-14 09:23:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:34][root][INFO] - Training Epoch: 2/2, step 7720/16670 completed (loss: 0.0857827365398407, acc: 0.970588207244873)
[2024-11-14 09:23:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:34][root][INFO] - Training Epoch: 2/2, step 7721/16670 completed (loss: 0.11250460147857666, acc: 0.9772727489471436)
[2024-11-14 09:23:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:34][root][INFO] - Training Epoch: 2/2, step 7722/16670 completed (loss: 0.10899785161018372, acc: 0.9773585200309753)
[2024-11-14 09:23:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:35][root][INFO] - Training Epoch: 2/2, step 7723/16670 completed (loss: 0.15414594113826752, acc: 0.9464285969734192)
[2024-11-14 09:23:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:35][root][INFO] - Training Epoch: 2/2, step 7724/16670 completed (loss: 0.13810516893863678, acc: 0.969072163105011)
[2024-11-14 09:23:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:35][root][INFO] - Training Epoch: 2/2, step 7725/16670 completed (loss: 0.09948588907718658, acc: 0.9655172228813171)
[2024-11-14 09:23:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:36][root][INFO] - Training Epoch: 2/2, step 7726/16670 completed (loss: 0.29780277609825134, acc: 0.9090909361839294)
[2024-11-14 09:23:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:36][root][INFO] - Training Epoch: 2/2, step 7727/16670 completed (loss: 0.12814322113990784, acc: 0.9520547986030579)
[2024-11-14 09:23:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:36][root][INFO] - Training Epoch: 2/2, step 7728/16670 completed (loss: 0.1901988387107849, acc: 0.9496402740478516)
[2024-11-14 09:23:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:37][root][INFO] - Training Epoch: 2/2, step 7729/16670 completed (loss: 0.08696768432855606, acc: 0.9838709831237793)
[2024-11-14 09:23:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:37][root][INFO] - Training Epoch: 2/2, step 7730/16670 completed (loss: 0.07236813008785248, acc: 0.9892473220825195)
[2024-11-14 09:23:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:38][root][INFO] - Training Epoch: 2/2, step 7731/16670 completed (loss: 0.03928235545754433, acc: 1.0)
[2024-11-14 09:23:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:38][root][INFO] - Training Epoch: 2/2, step 7732/16670 completed (loss: 0.07439308613538742, acc: 0.9752475023269653)
[2024-11-14 09:23:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:38][root][INFO] - Training Epoch: 2/2, step 7733/16670 completed (loss: 0.062153007835149765, acc: 0.9698275923728943)
[2024-11-14 09:23:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:39][root][INFO] - Training Epoch: 2/2, step 7734/16670 completed (loss: 0.19573278725147247, acc: 0.9472140669822693)
[2024-11-14 09:23:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:39][root][INFO] - Training Epoch: 2/2, step 7735/16670 completed (loss: 0.05320897698402405, acc: 0.9890109896659851)
[2024-11-14 09:23:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:39][root][INFO] - Training Epoch: 2/2, step 7736/16670 completed (loss: 0.0470866821706295, acc: 0.9823788404464722)
[2024-11-14 09:23:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:40][root][INFO] - Training Epoch: 2/2, step 7737/16670 completed (loss: 0.16306619346141815, acc: 0.9672130942344666)
[2024-11-14 09:23:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:40][root][INFO] - Training Epoch: 2/2, step 7738/16670 completed (loss: 0.0727967619895935, acc: 0.97826087474823)
[2024-11-14 09:23:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:41][root][INFO] - Training Epoch: 2/2, step 7739/16670 completed (loss: 0.12025246769189835, acc: 0.9709543585777283)
[2024-11-14 09:23:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:41][root][INFO] - Training Epoch: 2/2, step 7740/16670 completed (loss: 0.18941253423690796, acc: 0.9595959782600403)
[2024-11-14 09:23:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:41][root][INFO] - Training Epoch: 2/2, step 7741/16670 completed (loss: 0.17205461859703064, acc: 0.9523809552192688)
[2024-11-14 09:23:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:42][root][INFO] - Training Epoch: 2/2, step 7742/16670 completed (loss: 0.02274642512202263, acc: 0.9932885766029358)
[2024-11-14 09:23:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:42][root][INFO] - Training Epoch: 2/2, step 7743/16670 completed (loss: 0.1362263709306717, acc: 0.9632107019424438)
[2024-11-14 09:23:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:42][root][INFO] - Training Epoch: 2/2, step 7744/16670 completed (loss: 0.16438543796539307, acc: 0.9785714149475098)
[2024-11-14 09:23:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:43][root][INFO] - Training Epoch: 2/2, step 7745/16670 completed (loss: 0.08452519029378891, acc: 0.9717513918876648)
[2024-11-14 09:23:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:43][root][INFO] - Training Epoch: 2/2, step 7746/16670 completed (loss: 0.1734892576932907, acc: 0.9496855139732361)
[2024-11-14 09:23:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:43][root][INFO] - Training Epoch: 2/2, step 7747/16670 completed (loss: 0.022272678092122078, acc: 0.9927536249160767)
[2024-11-14 09:23:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:44][root][INFO] - Training Epoch: 2/2, step 7748/16670 completed (loss: 0.021486623212695122, acc: 0.9922480583190918)
[2024-11-14 09:23:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:44][root][INFO] - Training Epoch: 2/2, step 7749/16670 completed (loss: 0.12097080051898956, acc: 0.9683544039726257)
[2024-11-14 09:23:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:45][root][INFO] - Training Epoch: 2/2, step 7750/16670 completed (loss: 0.10001030564308167, acc: 0.976047933101654)
[2024-11-14 09:23:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:45][root][INFO] - Training Epoch: 2/2, step 7751/16670 completed (loss: 0.02713749185204506, acc: 1.0)
[2024-11-14 09:23:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:45][root][INFO] - Training Epoch: 2/2, step 7752/16670 completed (loss: 0.11985229700803757, acc: 0.9552238583564758)
[2024-11-14 09:23:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:46][root][INFO] - Training Epoch: 2/2, step 7753/16670 completed (loss: 0.07701750844717026, acc: 0.9636363387107849)
[2024-11-14 09:23:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:46][root][INFO] - Training Epoch: 2/2, step 7754/16670 completed (loss: 0.016087593510746956, acc: 1.0)
[2024-11-14 09:23:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:46][root][INFO] - Training Epoch: 2/2, step 7755/16670 completed (loss: 0.15763357281684875, acc: 0.9539170265197754)
[2024-11-14 09:23:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:46][root][INFO] - Training Epoch: 2/2, step 7756/16670 completed (loss: 0.07920686900615692, acc: 0.975683867931366)
[2024-11-14 09:23:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:47][root][INFO] - Training Epoch: 2/2, step 7757/16670 completed (loss: 0.08767496794462204, acc: 0.9809160232543945)
[2024-11-14 09:23:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:47][root][INFO] - Training Epoch: 2/2, step 7758/16670 completed (loss: 0.06902220845222473, acc: 0.9829059839248657)
[2024-11-14 09:23:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:48][root][INFO] - Training Epoch: 2/2, step 7759/16670 completed (loss: 0.0673983246088028, acc: 0.9795918464660645)
[2024-11-14 09:23:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:48][root][INFO] - Training Epoch: 2/2, step 7760/16670 completed (loss: 0.12457364797592163, acc: 0.9731543660163879)
[2024-11-14 09:23:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:48][root][INFO] - Training Epoch: 2/2, step 7761/16670 completed (loss: 0.126756951212883, acc: 0.9735449552536011)
[2024-11-14 09:23:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:49][root][INFO] - Training Epoch: 2/2, step 7762/16670 completed (loss: 0.25081580877304077, acc: 0.9152542352676392)
[2024-11-14 09:23:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:49][root][INFO] - Training Epoch: 2/2, step 7763/16670 completed (loss: 0.059125933796167374, acc: 0.9826589822769165)
[2024-11-14 09:23:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:49][root][INFO] - Training Epoch: 2/2, step 7764/16670 completed (loss: 0.01837519370019436, acc: 1.0)
[2024-11-14 09:23:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:50][root][INFO] - Training Epoch: 2/2, step 7765/16670 completed (loss: 0.10019464045763016, acc: 0.9753845930099487)
[2024-11-14 09:23:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:50][root][INFO] - Training Epoch: 2/2, step 7766/16670 completed (loss: 0.3483545780181885, acc: 0.9137930870056152)
[2024-11-14 09:23:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:50][root][INFO] - Training Epoch: 2/2, step 7767/16670 completed (loss: 0.08403155952692032, acc: 0.9931034445762634)
[2024-11-14 09:23:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:51][root][INFO] - Training Epoch: 2/2, step 7768/16670 completed (loss: 0.26082804799079895, acc: 0.9371069073677063)
[2024-11-14 09:23:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:51][root][INFO] - Training Epoch: 2/2, step 7769/16670 completed (loss: 0.20842455327510834, acc: 0.9462365508079529)
[2024-11-14 09:23:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:51][root][INFO] - Training Epoch: 2/2, step 7770/16670 completed (loss: 0.26720914244651794, acc: 0.9433962106704712)
[2024-11-14 09:23:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:52][root][INFO] - Training Epoch: 2/2, step 7771/16670 completed (loss: 0.12674085795879364, acc: 0.9513888955116272)
[2024-11-14 09:23:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:52][root][INFO] - Training Epoch: 2/2, step 7772/16670 completed (loss: 0.07675595581531525, acc: 0.9800000190734863)
[2024-11-14 09:23:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:53][root][INFO] - Training Epoch: 2/2, step 7773/16670 completed (loss: 0.02182788774371147, acc: 0.9924812316894531)
[2024-11-14 09:23:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:53][root][INFO] - Training Epoch: 2/2, step 7774/16670 completed (loss: 0.09165681153535843, acc: 0.9691358208656311)
[2024-11-14 09:23:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:54][root][INFO] - Training Epoch: 2/2, step 7775/16670 completed (loss: 0.1638004034757614, acc: 0.9593908786773682)
[2024-11-14 09:23:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:54][root][INFO] - Training Epoch: 2/2, step 7776/16670 completed (loss: 0.10334465652704239, acc: 0.9685534834861755)
[2024-11-14 09:23:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:54][root][INFO] - Training Epoch: 2/2, step 7777/16670 completed (loss: 0.1192299872636795, acc: 0.9694322943687439)
[2024-11-14 09:23:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:55][root][INFO] - Training Epoch: 2/2, step 7778/16670 completed (loss: 0.14166764914989471, acc: 0.9473684430122375)
[2024-11-14 09:23:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:55][root][INFO] - Training Epoch: 2/2, step 7779/16670 completed (loss: 0.29017174243927, acc: 0.9523809552192688)
[2024-11-14 09:23:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:55][root][INFO] - Training Epoch: 2/2, step 7780/16670 completed (loss: 0.1316230148077011, acc: 0.9545454382896423)
[2024-11-14 09:23:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:56][root][INFO] - Training Epoch: 2/2, step 7781/16670 completed (loss: 0.29129594564437866, acc: 0.9347826242446899)
[2024-11-14 09:23:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:56][root][INFO] - Training Epoch: 2/2, step 7782/16670 completed (loss: 0.31544435024261475, acc: 0.9210526347160339)
[2024-11-14 09:23:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:56][root][INFO] - Training Epoch: 2/2, step 7783/16670 completed (loss: 0.20947960019111633, acc: 0.9344262480735779)
[2024-11-14 09:23:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:57][root][INFO] - Training Epoch: 2/2, step 7784/16670 completed (loss: 0.164006769657135, acc: 0.9655172228813171)
[2024-11-14 09:23:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:57][root][INFO] - Training Epoch: 2/2, step 7785/16670 completed (loss: 0.19296795129776, acc: 0.9655172228813171)
[2024-11-14 09:23:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:57][root][INFO] - Training Epoch: 2/2, step 7786/16670 completed (loss: 0.24144449830055237, acc: 0.9433962106704712)
[2024-11-14 09:23:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:58][root][INFO] - Training Epoch: 2/2, step 7787/16670 completed (loss: 0.10778118669986725, acc: 0.9743589758872986)
[2024-11-14 09:23:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:58][root][INFO] - Training Epoch: 2/2, step 7788/16670 completed (loss: 0.06430298835039139, acc: 1.0)
[2024-11-14 09:23:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:58][root][INFO] - Training Epoch: 2/2, step 7789/16670 completed (loss: 0.1310185194015503, acc: 0.9729729890823364)
[2024-11-14 09:23:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:59][root][INFO] - Training Epoch: 2/2, step 7790/16670 completed (loss: 0.38144609332084656, acc: 0.8837209343910217)
[2024-11-14 09:23:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:59][root][INFO] - Training Epoch: 2/2, step 7791/16670 completed (loss: 0.2614096999168396, acc: 0.9318181872367859)
[2024-11-14 09:23:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:23:59][root][INFO] - Training Epoch: 2/2, step 7792/16670 completed (loss: 0.10409274697303772, acc: 0.9714285731315613)
[2024-11-14 09:24:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:00][root][INFO] - Training Epoch: 2/2, step 7793/16670 completed (loss: 0.07659298181533813, acc: 0.9795918464660645)
[2024-11-14 09:24:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:00][root][INFO] - Training Epoch: 2/2, step 7794/16670 completed (loss: 0.13453495502471924, acc: 0.9636363387107849)
[2024-11-14 09:24:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:01][root][INFO] - Training Epoch: 2/2, step 7795/16670 completed (loss: 0.22668038308620453, acc: 0.9245283007621765)
[2024-11-14 09:24:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:01][root][INFO] - Training Epoch: 2/2, step 7796/16670 completed (loss: 0.16678816080093384, acc: 0.9772727489471436)
[2024-11-14 09:24:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:01][root][INFO] - Training Epoch: 2/2, step 7797/16670 completed (loss: 0.13896967470645905, acc: 0.9375)
[2024-11-14 09:24:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:02][root][INFO] - Training Epoch: 2/2, step 7798/16670 completed (loss: 0.4911215305328369, acc: 0.9056603908538818)
[2024-11-14 09:24:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:02][root][INFO] - Training Epoch: 2/2, step 7799/16670 completed (loss: 0.13624101877212524, acc: 0.9722222089767456)
[2024-11-14 09:24:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:02][root][INFO] - Training Epoch: 2/2, step 7800/16670 completed (loss: 0.3179537355899811, acc: 0.9375)
[2024-11-14 09:24:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:03][root][INFO] - Training Epoch: 2/2, step 7801/16670 completed (loss: 0.19082693755626678, acc: 0.976190447807312)
[2024-11-14 09:24:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:03][root][INFO] - Training Epoch: 2/2, step 7802/16670 completed (loss: 0.3695908188819885, acc: 0.9577465057373047)
[2024-11-14 09:24:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:03][root][INFO] - Training Epoch: 2/2, step 7803/16670 completed (loss: 0.244185209274292, acc: 0.9384615421295166)
[2024-11-14 09:24:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:04][root][INFO] - Training Epoch: 2/2, step 7804/16670 completed (loss: 0.1604601889848709, acc: 0.9285714030265808)
[2024-11-14 09:24:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:04][root][INFO] - Training Epoch: 2/2, step 7805/16670 completed (loss: 0.2891058027744293, acc: 0.95652174949646)
[2024-11-14 09:24:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:04][root][INFO] - Training Epoch: 2/2, step 7806/16670 completed (loss: 0.4418254494667053, acc: 0.8571428656578064)
[2024-11-14 09:24:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:05][root][INFO] - Training Epoch: 2/2, step 7807/16670 completed (loss: 0.08281974494457245, acc: 0.9677419066429138)
[2024-11-14 09:24:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:05][root][INFO] - Training Epoch: 2/2, step 7808/16670 completed (loss: 0.08558416366577148, acc: 0.9599999785423279)
[2024-11-14 09:24:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:05][root][INFO] - Training Epoch: 2/2, step 7809/16670 completed (loss: 0.13029451668262482, acc: 0.970588207244873)
[2024-11-14 09:24:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:06][root][INFO] - Training Epoch: 2/2, step 7810/16670 completed (loss: 0.41187524795532227, acc: 0.8666666746139526)
[2024-11-14 09:24:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:06][root][INFO] - Training Epoch: 2/2, step 7811/16670 completed (loss: 0.10497993230819702, acc: 0.9714285731315613)
[2024-11-14 09:24:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:06][root][INFO] - Training Epoch: 2/2, step 7812/16670 completed (loss: 0.1302325278520584, acc: 0.9512194991111755)
[2024-11-14 09:24:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:07][root][INFO] - Training Epoch: 2/2, step 7813/16670 completed (loss: 0.24464479088783264, acc: 0.9272727370262146)
[2024-11-14 09:24:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:07][root][INFO] - Training Epoch: 2/2, step 7814/16670 completed (loss: 0.18841540813446045, acc: 0.9342105388641357)
[2024-11-14 09:24:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:08][root][INFO] - Training Epoch: 2/2, step 7815/16670 completed (loss: 0.2466644048690796, acc: 0.9591836929321289)
[2024-11-14 09:24:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:08][root][INFO] - Training Epoch: 2/2, step 7816/16670 completed (loss: 0.2746201753616333, acc: 0.9444444179534912)
[2024-11-14 09:24:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:08][root][INFO] - Training Epoch: 2/2, step 7817/16670 completed (loss: 0.2031308114528656, acc: 0.9512194991111755)
[2024-11-14 09:24:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:09][root][INFO] - Training Epoch: 2/2, step 7818/16670 completed (loss: 0.06702572107315063, acc: 0.9777777791023254)
[2024-11-14 09:24:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:09][root][INFO] - Training Epoch: 2/2, step 7819/16670 completed (loss: 0.3093431293964386, acc: 0.9047619104385376)
[2024-11-14 09:24:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:09][root][INFO] - Training Epoch: 2/2, step 7820/16670 completed (loss: 0.15365999937057495, acc: 0.9666666388511658)
[2024-11-14 09:24:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:10][root][INFO] - Training Epoch: 2/2, step 7821/16670 completed (loss: 0.2930440604686737, acc: 0.9200000166893005)
[2024-11-14 09:24:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:10][root][INFO] - Training Epoch: 2/2, step 7822/16670 completed (loss: 0.48828569054603577, acc: 0.8913043737411499)
[2024-11-14 09:24:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:10][root][INFO] - Training Epoch: 2/2, step 7823/16670 completed (loss: 0.24208003282546997, acc: 0.9714285731315613)
[2024-11-14 09:24:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:11][root][INFO] - Training Epoch: 2/2, step 7824/16670 completed (loss: 0.6178911328315735, acc: 0.8979591727256775)
[2024-11-14 09:24:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:11][root][INFO] - Training Epoch: 2/2, step 7825/16670 completed (loss: 0.11781414598226547, acc: 0.9750000238418579)
[2024-11-14 09:24:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:11][root][INFO] - Training Epoch: 2/2, step 7826/16670 completed (loss: 0.1561565101146698, acc: 0.9268292784690857)
[2024-11-14 09:24:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:12][root][INFO] - Training Epoch: 2/2, step 7827/16670 completed (loss: 0.24323078989982605, acc: 0.9298245906829834)
[2024-11-14 09:24:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:12][root][INFO] - Training Epoch: 2/2, step 7828/16670 completed (loss: 0.16597332060337067, acc: 0.95652174949646)
[2024-11-14 09:24:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:12][root][INFO] - Training Epoch: 2/2, step 7829/16670 completed (loss: 0.10815238952636719, acc: 0.95652174949646)
[2024-11-14 09:24:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:13][root][INFO] - Training Epoch: 2/2, step 7830/16670 completed (loss: 0.2639807164669037, acc: 0.9166666865348816)
[2024-11-14 09:24:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:13][root][INFO] - Training Epoch: 2/2, step 7831/16670 completed (loss: 0.1533442884683609, acc: 0.9696969985961914)
[2024-11-14 09:24:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:13][root][INFO] - Training Epoch: 2/2, step 7832/16670 completed (loss: 0.33376654982566833, acc: 0.9200000166893005)
[2024-11-14 09:24:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:14][root][INFO] - Training Epoch: 2/2, step 7833/16670 completed (loss: 0.2571409344673157, acc: 0.939393937587738)
[2024-11-14 09:24:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:14][root][INFO] - Training Epoch: 2/2, step 7834/16670 completed (loss: 0.05052907392382622, acc: 1.0)
[2024-11-14 09:24:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:14][root][INFO] - Training Epoch: 2/2, step 7835/16670 completed (loss: 0.46864208579063416, acc: 0.875)
[2024-11-14 09:24:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:15][root][INFO] - Training Epoch: 2/2, step 7836/16670 completed (loss: 0.1961366981267929, acc: 0.9166666865348816)
[2024-11-14 09:24:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:15][root][INFO] - Training Epoch: 2/2, step 7837/16670 completed (loss: 0.35945838689804077, acc: 0.824999988079071)
[2024-11-14 09:24:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:16][root][INFO] - Training Epoch: 2/2, step 7838/16670 completed (loss: 0.06412255764007568, acc: 0.9807692170143127)
[2024-11-14 09:24:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:16][root][INFO] - Training Epoch: 2/2, step 7839/16670 completed (loss: 0.4133223295211792, acc: 0.8600000143051147)
[2024-11-14 09:24:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:16][root][INFO] - Training Epoch: 2/2, step 7840/16670 completed (loss: 0.1948366016149521, acc: 0.9375)
[2024-11-14 09:24:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:17][root][INFO] - Training Epoch: 2/2, step 7841/16670 completed (loss: 0.3864365518093109, acc: 0.8421052694320679)
[2024-11-14 09:24:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:17][root][INFO] - Training Epoch: 2/2, step 7842/16670 completed (loss: 0.5043838620185852, acc: 0.875)
[2024-11-14 09:24:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:17][root][INFO] - Training Epoch: 2/2, step 7843/16670 completed (loss: 0.05367743968963623, acc: 1.0)
[2024-11-14 09:24:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:18][root][INFO] - Training Epoch: 2/2, step 7844/16670 completed (loss: 0.44333887100219727, acc: 0.8461538553237915)
[2024-11-14 09:24:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:18][root][INFO] - Training Epoch: 2/2, step 7845/16670 completed (loss: 0.1794986128807068, acc: 0.9347826242446899)
[2024-11-14 09:24:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:18][root][INFO] - Training Epoch: 2/2, step 7846/16670 completed (loss: 0.20968720316886902, acc: 0.9487179517745972)
[2024-11-14 09:24:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:19][root][INFO] - Training Epoch: 2/2, step 7847/16670 completed (loss: 0.1481778621673584, acc: 0.9534883499145508)
[2024-11-14 09:24:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:19][root][INFO] - Training Epoch: 2/2, step 7848/16670 completed (loss: 0.29023051261901855, acc: 0.931506872177124)
[2024-11-14 09:24:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:19][root][INFO] - Training Epoch: 2/2, step 7849/16670 completed (loss: 0.09088695794343948, acc: 1.0)
[2024-11-14 09:24:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:20][root][INFO] - Training Epoch: 2/2, step 7850/16670 completed (loss: 0.3732335567474365, acc: 0.9375)
[2024-11-14 09:24:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:20][root][INFO] - Training Epoch: 2/2, step 7851/16670 completed (loss: 0.08086007088422775, acc: 0.9791666865348816)
[2024-11-14 09:24:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:21][root][INFO] - Training Epoch: 2/2, step 7852/16670 completed (loss: 0.4944898784160614, acc: 0.9107142686843872)
[2024-11-14 09:24:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:21][root][INFO] - Training Epoch: 2/2, step 7853/16670 completed (loss: 0.310436487197876, acc: 0.8965517282485962)
[2024-11-14 09:24:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:21][root][INFO] - Training Epoch: 2/2, step 7854/16670 completed (loss: 0.022372504696249962, acc: 1.0)
[2024-11-14 09:24:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:22][root][INFO] - Training Epoch: 2/2, step 7855/16670 completed (loss: 0.13890226185321808, acc: 0.9591836929321289)
[2024-11-14 09:24:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:22][root][INFO] - Training Epoch: 2/2, step 7856/16670 completed (loss: 0.34143224358558655, acc: 0.9107142686843872)
[2024-11-14 09:24:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:22][root][INFO] - Training Epoch: 2/2, step 7857/16670 completed (loss: 0.17390207946300507, acc: 0.9811320900917053)
[2024-11-14 09:24:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:23][root][INFO] - Training Epoch: 2/2, step 7858/16670 completed (loss: 0.6092969179153442, acc: 0.9074074029922485)
[2024-11-14 09:24:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:23][root][INFO] - Training Epoch: 2/2, step 7859/16670 completed (loss: 0.4464372992515564, acc: 0.9230769276618958)
[2024-11-14 09:24:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:23][root][INFO] - Training Epoch: 2/2, step 7860/16670 completed (loss: 0.06618354469537735, acc: 1.0)
[2024-11-14 09:24:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:24][root][INFO] - Training Epoch: 2/2, step 7861/16670 completed (loss: 0.1895342767238617, acc: 0.9333333373069763)
[2024-11-14 09:24:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:24][root][INFO] - Training Epoch: 2/2, step 7862/16670 completed (loss: 0.15018920600414276, acc: 0.95652174949646)
[2024-11-14 09:24:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:24][root][INFO] - Training Epoch: 2/2, step 7863/16670 completed (loss: 0.5388437509536743, acc: 0.9152542352676392)
[2024-11-14 09:24:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:25][root][INFO] - Training Epoch: 2/2, step 7864/16670 completed (loss: 0.09050501883029938, acc: 1.0)
[2024-11-14 09:24:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:25][root][INFO] - Training Epoch: 2/2, step 7865/16670 completed (loss: 0.6083763837814331, acc: 0.8196721076965332)
[2024-11-14 09:24:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:25][root][INFO] - Training Epoch: 2/2, step 7866/16670 completed (loss: 0.19128791987895966, acc: 1.0)
[2024-11-14 09:24:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:26][root][INFO] - Training Epoch: 2/2, step 7867/16670 completed (loss: 0.3568313717842102, acc: 0.930232584476471)
[2024-11-14 09:24:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:26][root][INFO] - Training Epoch: 2/2, step 7868/16670 completed (loss: 0.18042238056659698, acc: 0.949999988079071)
[2024-11-14 09:24:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:26][root][INFO] - Training Epoch: 2/2, step 7869/16670 completed (loss: 0.11229222267866135, acc: 0.9661017060279846)
[2024-11-14 09:24:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:27][root][INFO] - Training Epoch: 2/2, step 7870/16670 completed (loss: 0.41785046458244324, acc: 0.9111111164093018)
[2024-11-14 09:24:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:27][root][INFO] - Training Epoch: 2/2, step 7871/16670 completed (loss: 0.28129130601882935, acc: 0.9180327653884888)
[2024-11-14 09:24:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:27][root][INFO] - Training Epoch: 2/2, step 7872/16670 completed (loss: 0.1471269279718399, acc: 0.9682539701461792)
[2024-11-14 09:24:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:28][root][INFO] - Training Epoch: 2/2, step 7873/16670 completed (loss: 0.08954776078462601, acc: 0.9750000238418579)
[2024-11-14 09:24:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:28][root][INFO] - Training Epoch: 2/2, step 7874/16670 completed (loss: 0.12560710310935974, acc: 0.9642857313156128)
[2024-11-14 09:24:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:28][root][INFO] - Training Epoch: 2/2, step 7875/16670 completed (loss: 0.17198176681995392, acc: 0.957446813583374)
[2024-11-14 09:24:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:29][root][INFO] - Training Epoch: 2/2, step 7876/16670 completed (loss: 0.6498258709907532, acc: 0.8421052694320679)
[2024-11-14 09:24:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:29][root][INFO] - Training Epoch: 2/2, step 7877/16670 completed (loss: 0.1366952508687973, acc: 0.9642857313156128)
[2024-11-14 09:24:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:29][root][INFO] - Training Epoch: 2/2, step 7878/16670 completed (loss: 0.6431901454925537, acc: 0.8769230842590332)
[2024-11-14 09:24:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:30][root][INFO] - Training Epoch: 2/2, step 7879/16670 completed (loss: 0.15018384158611298, acc: 0.9642857313156128)
[2024-11-14 09:24:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:30][root][INFO] - Training Epoch: 2/2, step 7880/16670 completed (loss: 0.22614148259162903, acc: 0.949999988079071)
[2024-11-14 09:24:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:31][root][INFO] - Training Epoch: 2/2, step 7881/16670 completed (loss: 0.050427649170160294, acc: 1.0)
[2024-11-14 09:24:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:31][root][INFO] - Training Epoch: 2/2, step 7882/16670 completed (loss: 0.45463284850120544, acc: 0.925000011920929)
[2024-11-14 09:24:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:31][root][INFO] - Training Epoch: 2/2, step 7883/16670 completed (loss: 0.16564436256885529, acc: 0.9583333134651184)
[2024-11-14 09:24:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:32][root][INFO] - Training Epoch: 2/2, step 7884/16670 completed (loss: 0.5956943035125732, acc: 0.84375)
[2024-11-14 09:24:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:32][root][INFO] - Training Epoch: 2/2, step 7885/16670 completed (loss: 0.19673749804496765, acc: 0.925000011920929)
[2024-11-14 09:24:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:32][root][INFO] - Training Epoch: 2/2, step 7886/16670 completed (loss: 0.09091765433549881, acc: 0.9750000238418579)
[2024-11-14 09:24:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:33][root][INFO] - Training Epoch: 2/2, step 7887/16670 completed (loss: 0.21507258713245392, acc: 0.9104477763175964)
[2024-11-14 09:24:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:33][root][INFO] - Training Epoch: 2/2, step 7888/16670 completed (loss: 0.1916109025478363, acc: 0.9642857313156128)
[2024-11-14 09:24:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:33][root][INFO] - Training Epoch: 2/2, step 7889/16670 completed (loss: 0.12501393258571625, acc: 0.9655172228813171)
[2024-11-14 09:24:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:33][root][INFO] - Training Epoch: 2/2, step 7890/16670 completed (loss: 0.3035019040107727, acc: 0.9268292784690857)
[2024-11-14 09:24:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:34][root][INFO] - Training Epoch: 2/2, step 7891/16670 completed (loss: 0.08233285695314407, acc: 1.0)
[2024-11-14 09:24:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:34][root][INFO] - Training Epoch: 2/2, step 7892/16670 completed (loss: 0.16949394345283508, acc: 0.930232584476471)
[2024-11-14 09:24:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:34][root][INFO] - Training Epoch: 2/2, step 7893/16670 completed (loss: 0.23686841130256653, acc: 0.9411764740943909)
[2024-11-14 09:24:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:35][root][INFO] - Training Epoch: 2/2, step 7894/16670 completed (loss: 0.32483378052711487, acc: 0.9084967374801636)
[2024-11-14 09:24:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:35][root][INFO] - Training Epoch: 2/2, step 7895/16670 completed (loss: 0.16109509766101837, acc: 0.9473684430122375)
[2024-11-14 09:24:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:36][root][INFO] - Training Epoch: 2/2, step 7896/16670 completed (loss: 0.26057571172714233, acc: 0.9230769276618958)
[2024-11-14 09:24:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:36][root][INFO] - Training Epoch: 2/2, step 7897/16670 completed (loss: 0.2545381486415863, acc: 0.9420289993286133)
[2024-11-14 09:24:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:36][root][INFO] - Training Epoch: 2/2, step 7898/16670 completed (loss: 0.3608807325363159, acc: 0.931034505367279)
[2024-11-14 09:24:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:37][root][INFO] - Training Epoch: 2/2, step 7899/16670 completed (loss: 0.1664666384458542, acc: 0.9428571462631226)
[2024-11-14 09:24:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:37][root][INFO] - Training Epoch: 2/2, step 7900/16670 completed (loss: 0.3850915729999542, acc: 0.8999999761581421)
[2024-11-14 09:24:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:37][root][INFO] - Training Epoch: 2/2, step 7901/16670 completed (loss: 0.14384771883487701, acc: 0.9590643048286438)
[2024-11-14 09:24:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:38][root][INFO] - Training Epoch: 2/2, step 7902/16670 completed (loss: 0.235687255859375, acc: 0.915032684803009)
[2024-11-14 09:24:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:38][root][INFO] - Training Epoch: 2/2, step 7903/16670 completed (loss: 0.18566066026687622, acc: 0.9545454382896423)
[2024-11-14 09:24:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:39][root][INFO] - Training Epoch: 2/2, step 7904/16670 completed (loss: 0.1746656745672226, acc: 0.9660193920135498)
[2024-11-14 09:24:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:39][root][INFO] - Training Epoch: 2/2, step 7905/16670 completed (loss: 0.038399793207645416, acc: 0.9871794581413269)
[2024-11-14 09:24:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:39][root][INFO] - Training Epoch: 2/2, step 7906/16670 completed (loss: 0.1938008815050125, acc: 0.9448275566101074)
[2024-11-14 09:24:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:40][root][INFO] - Training Epoch: 2/2, step 7907/16670 completed (loss: 0.12057579308748245, acc: 0.9675675630569458)
[2024-11-14 09:24:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:40][root][INFO] - Training Epoch: 2/2, step 7908/16670 completed (loss: 0.13544981181621552, acc: 0.9682539701461792)
[2024-11-14 09:24:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:40][root][INFO] - Training Epoch: 2/2, step 7909/16670 completed (loss: 0.12938563525676727, acc: 0.969072163105011)
[2024-11-14 09:24:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:41][root][INFO] - Training Epoch: 2/2, step 7910/16670 completed (loss: 0.1237666979432106, acc: 0.9733333587646484)
[2024-11-14 09:24:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:41][root][INFO] - Training Epoch: 2/2, step 7911/16670 completed (loss: 0.11436915397644043, acc: 0.9671052694320679)
[2024-11-14 09:24:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:42][root][INFO] - Training Epoch: 2/2, step 7912/16670 completed (loss: 0.12083857506513596, acc: 0.9726775884628296)
[2024-11-14 09:24:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:42][root][INFO] - Training Epoch: 2/2, step 7913/16670 completed (loss: 0.05878658965229988, acc: 0.9895833134651184)
[2024-11-14 09:24:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:42][root][INFO] - Training Epoch: 2/2, step 7914/16670 completed (loss: 0.12058768421411514, acc: 0.9716981053352356)
[2024-11-14 09:24:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:43][root][INFO] - Training Epoch: 2/2, step 7915/16670 completed (loss: 0.2072296440601349, acc: 0.9619771838188171)
[2024-11-14 09:24:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:43][root][INFO] - Training Epoch: 2/2, step 7916/16670 completed (loss: 0.054546818137168884, acc: 0.9845361113548279)
[2024-11-14 09:24:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:43][root][INFO] - Training Epoch: 2/2, step 7917/16670 completed (loss: 0.2766599655151367, acc: 0.9339622855186462)
[2024-11-14 09:24:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:44][root][INFO] - Training Epoch: 2/2, step 7918/16670 completed (loss: 0.16562706232070923, acc: 0.9508196711540222)
[2024-11-14 09:24:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:44][root][INFO] - Training Epoch: 2/2, step 7919/16670 completed (loss: 0.150736466050148, acc: 0.964102566242218)
[2024-11-14 09:24:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:44][root][INFO] - Training Epoch: 2/2, step 7920/16670 completed (loss: 0.11458276212215424, acc: 0.9624999761581421)
[2024-11-14 09:24:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:45][root][INFO] - Training Epoch: 2/2, step 7921/16670 completed (loss: 0.11705251783132553, acc: 0.9631578922271729)
[2024-11-14 09:24:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:45][root][INFO] - Training Epoch: 2/2, step 7922/16670 completed (loss: 0.11275412887334824, acc: 0.9685534834861755)
[2024-11-14 09:24:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:46][root][INFO] - Training Epoch: 2/2, step 7923/16670 completed (loss: 0.16733922064304352, acc: 0.9615384340286255)
[2024-11-14 09:24:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:46][root][INFO] - Training Epoch: 2/2, step 7924/16670 completed (loss: 0.12801618874073029, acc: 0.9511111378669739)
[2024-11-14 09:24:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:46][root][INFO] - Training Epoch: 2/2, step 7925/16670 completed (loss: 0.09423069655895233, acc: 0.9624060392379761)
[2024-11-14 09:24:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:47][root][INFO] - Training Epoch: 2/2, step 7926/16670 completed (loss: 0.300118625164032, acc: 0.907975435256958)
[2024-11-14 09:24:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:47][root][INFO] - Training Epoch: 2/2, step 7927/16670 completed (loss: 0.12142691761255264, acc: 0.95652174949646)
[2024-11-14 09:24:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:47][root][INFO] - Training Epoch: 2/2, step 7928/16670 completed (loss: 0.250332236289978, acc: 0.9217391014099121)
[2024-11-14 09:24:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:48][root][INFO] - Training Epoch: 2/2, step 7929/16670 completed (loss: 0.09058020263910294, acc: 0.9803921580314636)
[2024-11-14 09:24:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:48][root][INFO] - Training Epoch: 2/2, step 7930/16670 completed (loss: 0.1592317521572113, acc: 0.9579831957817078)
[2024-11-14 09:24:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:48][root][INFO] - Training Epoch: 2/2, step 7931/16670 completed (loss: 0.13186100125312805, acc: 0.9684210419654846)
[2024-11-14 09:24:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:49][root][INFO] - Training Epoch: 2/2, step 7932/16670 completed (loss: 0.10674279183149338, acc: 0.9744898080825806)
[2024-11-14 09:24:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:49][root][INFO] - Training Epoch: 2/2, step 7933/16670 completed (loss: 0.0648118183016777, acc: 0.9794520735740662)
[2024-11-14 09:24:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:50][root][INFO] - Training Epoch: 2/2, step 7934/16670 completed (loss: 0.1932474970817566, acc: 0.9438775777816772)
[2024-11-14 09:24:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:50][root][INFO] - Training Epoch: 2/2, step 7935/16670 completed (loss: 0.07023539394140244, acc: 0.9615384340286255)
[2024-11-14 09:24:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:50][root][INFO] - Training Epoch: 2/2, step 7936/16670 completed (loss: 0.14843155443668365, acc: 0.9624060392379761)
[2024-11-14 09:24:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:51][root][INFO] - Training Epoch: 2/2, step 7937/16670 completed (loss: 0.05367541313171387, acc: 0.9818181991577148)
[2024-11-14 09:24:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:51][root][INFO] - Training Epoch: 2/2, step 7938/16670 completed (loss: 0.21538382768630981, acc: 0.9452054500579834)
[2024-11-14 09:24:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:52][root][INFO] - Training Epoch: 2/2, step 7939/16670 completed (loss: 0.0777079239487648, acc: 0.9776951670646667)
[2024-11-14 09:24:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:52][root][INFO] - Training Epoch: 2/2, step 7940/16670 completed (loss: 0.15948624908924103, acc: 0.9701492786407471)
[2024-11-14 09:24:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:52][root][INFO] - Training Epoch: 2/2, step 7941/16670 completed (loss: 0.17816655337810516, acc: 0.9674796462059021)
[2024-11-14 09:24:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:53][root][INFO] - Training Epoch: 2/2, step 7942/16670 completed (loss: 0.1896243542432785, acc: 0.9562841653823853)
[2024-11-14 09:24:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:53][root][INFO] - Training Epoch: 2/2, step 7943/16670 completed (loss: 0.3157888948917389, acc: 0.9259259104728699)
[2024-11-14 09:24:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:53][root][INFO] - Training Epoch: 2/2, step 7944/16670 completed (loss: 0.10304567962884903, acc: 0.95652174949646)
[2024-11-14 09:24:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:54][root][INFO] - Training Epoch: 2/2, step 7945/16670 completed (loss: 0.13989757001399994, acc: 0.9586777091026306)
[2024-11-14 09:24:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:54][root][INFO] - Training Epoch: 2/2, step 7946/16670 completed (loss: 0.29245173931121826, acc: 0.8630136847496033)
[2024-11-14 09:24:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:54][root][INFO] - Training Epoch: 2/2, step 7947/16670 completed (loss: 0.05584491416811943, acc: 1.0)
[2024-11-14 09:24:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:55][root][INFO] - Training Epoch: 2/2, step 7948/16670 completed (loss: 0.19839994609355927, acc: 0.984375)
[2024-11-14 09:24:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:55][root][INFO] - Training Epoch: 2/2, step 7949/16670 completed (loss: 0.12785646319389343, acc: 0.9676113128662109)
[2024-11-14 09:24:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:55][root][INFO] - Training Epoch: 2/2, step 7950/16670 completed (loss: 0.15811054408550262, acc: 0.9548386931419373)
[2024-11-14 09:24:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:56][root][INFO] - Training Epoch: 2/2, step 7951/16670 completed (loss: 0.05469561740756035, acc: 0.9849246144294739)
[2024-11-14 09:24:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:56][root][INFO] - Training Epoch: 2/2, step 7952/16670 completed (loss: 0.13621877133846283, acc: 0.9568345546722412)
[2024-11-14 09:24:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:57][root][INFO] - Training Epoch: 2/2, step 7953/16670 completed (loss: 0.14846189320087433, acc: 0.9572192430496216)
[2024-11-14 09:24:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:57][root][INFO] - Training Epoch: 2/2, step 7954/16670 completed (loss: 0.1219744011759758, acc: 0.9512194991111755)
[2024-11-14 09:24:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:57][root][INFO] - Training Epoch: 2/2, step 7955/16670 completed (loss: 0.24401135742664337, acc: 0.9504132270812988)
[2024-11-14 09:24:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:58][root][INFO] - Training Epoch: 2/2, step 7956/16670 completed (loss: 0.1116601899266243, acc: 0.9419354796409607)
[2024-11-14 09:24:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:58][root][INFO] - Training Epoch: 2/2, step 7957/16670 completed (loss: 0.08625246584415436, acc: 0.97826087474823)
[2024-11-14 09:24:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:58][root][INFO] - Training Epoch: 2/2, step 7958/16670 completed (loss: 0.18978169560432434, acc: 0.9345238208770752)
[2024-11-14 09:24:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:59][root][INFO] - Training Epoch: 2/2, step 7959/16670 completed (loss: 0.1607442945241928, acc: 0.9642857313156128)
[2024-11-14 09:24:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:59][root][INFO] - Training Epoch: 2/2, step 7960/16670 completed (loss: 0.006648261100053787, acc: 1.0)
[2024-11-14 09:24:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:24:59][root][INFO] - Training Epoch: 2/2, step 7961/16670 completed (loss: 0.32896438241004944, acc: 0.9044585824012756)
[2024-11-14 09:24:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:00][root][INFO] - Training Epoch: 2/2, step 7962/16670 completed (loss: 0.11321667581796646, acc: 0.9765258431434631)
[2024-11-14 09:25:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:00][root][INFO] - Training Epoch: 2/2, step 7963/16670 completed (loss: 0.14234307408332825, acc: 0.9506173133850098)
[2024-11-14 09:25:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:00][root][INFO] - Training Epoch: 2/2, step 7964/16670 completed (loss: 0.19140397012233734, acc: 0.9615384340286255)
[2024-11-14 09:25:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:01][root][INFO] - Training Epoch: 2/2, step 7965/16670 completed (loss: 0.15755513310432434, acc: 0.9714285731315613)
[2024-11-14 09:25:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:01][root][INFO] - Training Epoch: 2/2, step 7966/16670 completed (loss: 0.13523736596107483, acc: 0.9492385983467102)
[2024-11-14 09:25:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:02][root][INFO] - Training Epoch: 2/2, step 7967/16670 completed (loss: 0.1019757091999054, acc: 0.96875)
[2024-11-14 09:25:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:02][root][INFO] - Training Epoch: 2/2, step 7968/16670 completed (loss: 0.15600968897342682, acc: 0.9405940771102905)
[2024-11-14 09:25:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:02][root][INFO] - Training Epoch: 2/2, step 7969/16670 completed (loss: 0.10443128645420074, acc: 0.969298243522644)
[2024-11-14 09:25:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:03][root][INFO] - Training Epoch: 2/2, step 7970/16670 completed (loss: 0.06888987123966217, acc: 0.9747292399406433)
[2024-11-14 09:25:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:03][root][INFO] - Training Epoch: 2/2, step 7971/16670 completed (loss: 0.23689168691635132, acc: 0.9324324131011963)
[2024-11-14 09:25:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:03][root][INFO] - Training Epoch: 2/2, step 7972/16670 completed (loss: 0.1035599410533905, acc: 0.9655172228813171)
[2024-11-14 09:25:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:04][root][INFO] - Training Epoch: 2/2, step 7973/16670 completed (loss: 0.15617406368255615, acc: 0.9395973086357117)
[2024-11-14 09:25:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:04][root][INFO] - Training Epoch: 2/2, step 7974/16670 completed (loss: 0.059826456010341644, acc: 0.9788732528686523)
[2024-11-14 09:25:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:04][root][INFO] - Training Epoch: 2/2, step 7975/16670 completed (loss: 0.21293796598911285, acc: 0.9518072009086609)
[2024-11-14 09:25:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:05][root][INFO] - Training Epoch: 2/2, step 7976/16670 completed (loss: 0.194792702794075, acc: 0.9454545378684998)
[2024-11-14 09:25:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:05][root][INFO] - Training Epoch: 2/2, step 7977/16670 completed (loss: 0.11179015785455704, acc: 0.9580838084220886)
[2024-11-14 09:25:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:05][root][INFO] - Training Epoch: 2/2, step 7978/16670 completed (loss: 0.12043338268995285, acc: 0.9631578922271729)
[2024-11-14 09:25:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:06][root][INFO] - Training Epoch: 2/2, step 7979/16670 completed (loss: 0.13327427208423615, acc: 0.9852941036224365)
[2024-11-14 09:25:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:06][root][INFO] - Training Epoch: 2/2, step 7980/16670 completed (loss: 0.11862814426422119, acc: 0.969348669052124)
[2024-11-14 09:25:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:06][root][INFO] - Training Epoch: 2/2, step 7981/16670 completed (loss: 0.03664076700806618, acc: 0.9886363744735718)
[2024-11-14 09:25:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:07][root][INFO] - Training Epoch: 2/2, step 7982/16670 completed (loss: 0.06799425184726715, acc: 0.9798387289047241)
[2024-11-14 09:25:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:07][root][INFO] - Training Epoch: 2/2, step 7983/16670 completed (loss: 0.07950040698051453, acc: 0.9658119678497314)
[2024-11-14 09:25:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:07][root][INFO] - Training Epoch: 2/2, step 7984/16670 completed (loss: 0.11700929701328278, acc: 0.977011501789093)
[2024-11-14 09:25:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:08][root][INFO] - Training Epoch: 2/2, step 7985/16670 completed (loss: 0.1708078235387802, acc: 0.9533073902130127)
[2024-11-14 09:25:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:08][root][INFO] - Training Epoch: 2/2, step 7986/16670 completed (loss: 0.14695218205451965, acc: 0.957446813583374)
[2024-11-14 09:25:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:09][root][INFO] - Training Epoch: 2/2, step 7987/16670 completed (loss: 0.030790435150265694, acc: 0.9928057789802551)
[2024-11-14 09:25:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:09][root][INFO] - Training Epoch: 2/2, step 7988/16670 completed (loss: 0.0718260258436203, acc: 0.9683098793029785)
[2024-11-14 09:25:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:09][root][INFO] - Training Epoch: 2/2, step 7989/16670 completed (loss: 0.19446587562561035, acc: 0.9318181872367859)
[2024-11-14 09:25:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:09][root][INFO] - Training Epoch: 2/2, step 7990/16670 completed (loss: 0.06479626893997192, acc: 0.9830508232116699)
[2024-11-14 09:25:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:10][root][INFO] - Training Epoch: 2/2, step 7991/16670 completed (loss: 0.04113210737705231, acc: 0.9773755669593811)
[2024-11-14 09:25:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:10][root][INFO] - Training Epoch: 2/2, step 7992/16670 completed (loss: 0.11746789515018463, acc: 0.9645161032676697)
[2024-11-14 09:25:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:10][root][INFO] - Training Epoch: 2/2, step 7993/16670 completed (loss: 0.07953004539012909, acc: 0.9732620120048523)
[2024-11-14 09:25:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:11][root][INFO] - Training Epoch: 2/2, step 7994/16670 completed (loss: 0.22457793354988098, acc: 0.9130434989929199)
[2024-11-14 09:25:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:11][root][INFO] - Training Epoch: 2/2, step 7995/16670 completed (loss: 0.10767072439193726, acc: 0.9634146094322205)
[2024-11-14 09:25:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:11][root][INFO] - Training Epoch: 2/2, step 7996/16670 completed (loss: 0.0328054316341877, acc: 0.9922178983688354)
[2024-11-14 09:25:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:12][root][INFO] - Training Epoch: 2/2, step 7997/16670 completed (loss: 0.02861127071082592, acc: 0.990338146686554)
[2024-11-14 09:25:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:12][root][INFO] - Training Epoch: 2/2, step 7998/16670 completed (loss: 0.029409974813461304, acc: 0.9937888383865356)
[2024-11-14 09:25:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:12][root][INFO] - Training Epoch: 2/2, step 7999/16670 completed (loss: 0.05839896947145462, acc: 0.9810426831245422)
[2024-11-14 09:25:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:13][root][INFO] - Training Epoch: 2/2, step 8000/16670 completed (loss: 0.14931556582450867, acc: 0.9599999785423279)
[2024-11-14 09:25:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:13][root][INFO] - Training Epoch: 2/2, step 8001/16670 completed (loss: 0.05960281193256378, acc: 0.9831932783126831)
[2024-11-14 09:25:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:13][root][INFO] - Training Epoch: 2/2, step 8002/16670 completed (loss: 0.04341146722435951, acc: 0.9909090995788574)
[2024-11-14 09:25:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:14][root][INFO] - Training Epoch: 2/2, step 8003/16670 completed (loss: 0.04152714088559151, acc: 0.97826087474823)
[2024-11-14 09:25:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:14][root][INFO] - Training Epoch: 2/2, step 8004/16670 completed (loss: 0.10240613669157028, acc: 0.9675925970077515)
[2024-11-14 09:25:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:14][root][INFO] - Training Epoch: 2/2, step 8005/16670 completed (loss: 0.13889163732528687, acc: 0.9513274431228638)
[2024-11-14 09:25:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:15][root][INFO] - Training Epoch: 2/2, step 8006/16670 completed (loss: 0.051011014729738235, acc: 0.9941520690917969)
[2024-11-14 09:25:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:15][root][INFO] - Training Epoch: 2/2, step 8007/16670 completed (loss: 0.012622459791600704, acc: 1.0)
[2024-11-14 09:25:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:15][root][INFO] - Training Epoch: 2/2, step 8008/16670 completed (loss: 0.12745638191699982, acc: 0.969298243522644)
[2024-11-14 09:25:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:16][root][INFO] - Training Epoch: 2/2, step 8009/16670 completed (loss: 0.013274664990603924, acc: 1.0)
[2024-11-14 09:25:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:16][root][INFO] - Training Epoch: 2/2, step 8010/16670 completed (loss: 0.051134154200553894, acc: 0.9743589758872986)
[2024-11-14 09:25:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:16][root][INFO] - Training Epoch: 2/2, step 8011/16670 completed (loss: 0.025401955470442772, acc: 0.9955947399139404)
[2024-11-14 09:25:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:17][root][INFO] - Training Epoch: 2/2, step 8012/16670 completed (loss: 0.16175627708435059, acc: 0.9482758641242981)
[2024-11-14 09:25:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:17][root][INFO] - Training Epoch: 2/2, step 8013/16670 completed (loss: 0.04495370760560036, acc: 0.9919354915618896)
[2024-11-14 09:25:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:17][root][INFO] - Training Epoch: 2/2, step 8014/16670 completed (loss: 0.07946933060884476, acc: 0.9832636117935181)
[2024-11-14 09:25:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:18][root][INFO] - Training Epoch: 2/2, step 8015/16670 completed (loss: 0.1400960236787796, acc: 0.9700374603271484)
[2024-11-14 09:25:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:18][root][INFO] - Training Epoch: 2/2, step 8016/16670 completed (loss: 0.027996141463518143, acc: 0.9942857027053833)
[2024-11-14 09:25:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:18][root][INFO] - Training Epoch: 2/2, step 8017/16670 completed (loss: 0.09717398136854172, acc: 0.9665272235870361)
[2024-11-14 09:25:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:19][root][INFO] - Training Epoch: 2/2, step 8018/16670 completed (loss: 0.02540886588394642, acc: 0.9906542301177979)
[2024-11-14 09:25:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:19][root][INFO] - Training Epoch: 2/2, step 8019/16670 completed (loss: 0.1275564432144165, acc: 0.9720930457115173)
[2024-11-14 09:25:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:19][root][INFO] - Training Epoch: 2/2, step 8020/16670 completed (loss: 0.030970731750130653, acc: 0.9922178983688354)
[2024-11-14 09:25:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:20][root][INFO] - Training Epoch: 2/2, step 8021/16670 completed (loss: 0.04881598800420761, acc: 0.9801324605941772)
[2024-11-14 09:25:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:20][root][INFO] - Training Epoch: 2/2, step 8022/16670 completed (loss: 0.04002155736088753, acc: 1.0)
[2024-11-14 09:25:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:20][root][INFO] - Training Epoch: 2/2, step 8023/16670 completed (loss: 0.07674884051084518, acc: 0.970059871673584)
[2024-11-14 09:25:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:21][root][INFO] - Training Epoch: 2/2, step 8024/16670 completed (loss: 0.12299428880214691, acc: 0.9609755873680115)
[2024-11-14 09:25:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:21][root][INFO] - Training Epoch: 2/2, step 8025/16670 completed (loss: 0.11574842780828476, acc: 0.9731543660163879)
[2024-11-14 09:25:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:21][root][INFO] - Training Epoch: 2/2, step 8026/16670 completed (loss: 0.18949027359485626, acc: 0.9435897469520569)
[2024-11-14 09:25:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:22][root][INFO] - Training Epoch: 2/2, step 8027/16670 completed (loss: 0.06828856468200684, acc: 0.9685534834861755)
[2024-11-14 09:25:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:22][root][INFO] - Training Epoch: 2/2, step 8028/16670 completed (loss: 0.17390897870063782, acc: 0.9672130942344666)
[2024-11-14 09:25:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:22][root][INFO] - Training Epoch: 2/2, step 8029/16670 completed (loss: 0.05951957032084465, acc: 0.9811320900917053)
[2024-11-14 09:25:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:23][root][INFO] - Training Epoch: 2/2, step 8030/16670 completed (loss: 0.18628956377506256, acc: 0.9490445852279663)
[2024-11-14 09:25:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:23][root][INFO] - Training Epoch: 2/2, step 8031/16670 completed (loss: 0.2503143846988678, acc: 0.9557521939277649)
[2024-11-14 09:25:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:23][root][INFO] - Training Epoch: 2/2, step 8032/16670 completed (loss: 0.11793484538793564, acc: 0.9672130942344666)
[2024-11-14 09:25:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:24][root][INFO] - Training Epoch: 2/2, step 8033/16670 completed (loss: 0.02949424833059311, acc: 0.9947090148925781)
[2024-11-14 09:25:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:24][root][INFO] - Training Epoch: 2/2, step 8034/16670 completed (loss: 0.14463259279727936, acc: 0.918367326259613)
[2024-11-14 09:25:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:24][root][INFO] - Training Epoch: 2/2, step 8035/16670 completed (loss: 0.1182689219713211, acc: 0.9653846025466919)
[2024-11-14 09:25:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:25][root][INFO] - Training Epoch: 2/2, step 8036/16670 completed (loss: 0.07731257379055023, acc: 0.9661017060279846)
[2024-11-14 09:25:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:25][root][INFO] - Training Epoch: 2/2, step 8037/16670 completed (loss: 0.1666555553674698, acc: 0.9533898234367371)
[2024-11-14 09:25:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:25][root][INFO] - Training Epoch: 2/2, step 8038/16670 completed (loss: 0.057574693113565445, acc: 0.9846625924110413)
[2024-11-14 09:25:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:26][root][INFO] - Training Epoch: 2/2, step 8039/16670 completed (loss: 0.03261498361825943, acc: 1.0)
[2024-11-14 09:25:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:26][root][INFO] - Training Epoch: 2/2, step 8040/16670 completed (loss: 0.08664558827877045, acc: 0.9900497794151306)
[2024-11-14 09:25:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:26][root][INFO] - Training Epoch: 2/2, step 8041/16670 completed (loss: 0.04385588690638542, acc: 0.9904761910438538)
[2024-11-14 09:25:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:27][root][INFO] - Training Epoch: 2/2, step 8042/16670 completed (loss: 0.059845417737960815, acc: 0.9912663698196411)
[2024-11-14 09:25:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:27][root][INFO] - Training Epoch: 2/2, step 8043/16670 completed (loss: 0.11936745792627335, acc: 0.9795918464660645)
[2024-11-14 09:25:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:27][root][INFO] - Training Epoch: 2/2, step 8044/16670 completed (loss: 0.0814242959022522, acc: 0.96875)
[2024-11-14 09:25:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:28][root][INFO] - Training Epoch: 2/2, step 8045/16670 completed (loss: 0.1844651699066162, acc: 0.9567567706108093)
[2024-11-14 09:25:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:28][root][INFO] - Training Epoch: 2/2, step 8046/16670 completed (loss: 0.05926176533102989, acc: 0.9750000238418579)
[2024-11-14 09:25:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:28][root][INFO] - Training Epoch: 2/2, step 8047/16670 completed (loss: 0.07134666293859482, acc: 0.9848484992980957)
[2024-11-14 09:25:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:29][root][INFO] - Training Epoch: 2/2, step 8048/16670 completed (loss: 0.1120159924030304, acc: 0.9740740656852722)
[2024-11-14 09:25:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:29][root][INFO] - Training Epoch: 2/2, step 8049/16670 completed (loss: 0.11987172812223434, acc: 0.9650349617004395)
[2024-11-14 09:25:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:30][root][INFO] - Training Epoch: 2/2, step 8050/16670 completed (loss: 0.030856331810355186, acc: 0.9928057789802551)
[2024-11-14 09:25:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:30][root][INFO] - Training Epoch: 2/2, step 8051/16670 completed (loss: 0.06654467433691025, acc: 0.982332170009613)
[2024-11-14 09:25:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:30][root][INFO] - Training Epoch: 2/2, step 8052/16670 completed (loss: 0.08433843404054642, acc: 0.9717868566513062)
[2024-11-14 09:25:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:31][root][INFO] - Training Epoch: 2/2, step 8053/16670 completed (loss: 0.1109820306301117, acc: 0.9516128897666931)
[2024-11-14 09:25:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:31][root][INFO] - Training Epoch: 2/2, step 8054/16670 completed (loss: 0.24034176766872406, acc: 0.9344262480735779)
[2024-11-14 09:25:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:31][root][INFO] - Training Epoch: 2/2, step 8055/16670 completed (loss: 0.24174784123897552, acc: 0.931034505367279)
[2024-11-14 09:25:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:32][root][INFO] - Training Epoch: 2/2, step 8056/16670 completed (loss: 0.4422856271266937, acc: 0.8947368264198303)
[2024-11-14 09:25:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:32][root][INFO] - Training Epoch: 2/2, step 8057/16670 completed (loss: 0.13770166039466858, acc: 0.9800000190734863)
[2024-11-14 09:25:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:32][root][INFO] - Training Epoch: 2/2, step 8058/16670 completed (loss: 0.17831304669380188, acc: 0.96875)
[2024-11-14 09:25:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:33][root][INFO] - Training Epoch: 2/2, step 8059/16670 completed (loss: 0.26055479049682617, acc: 0.9074074029922485)
[2024-11-14 09:25:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:33][root][INFO] - Training Epoch: 2/2, step 8060/16670 completed (loss: 0.3120437562465668, acc: 0.9166666865348816)
[2024-11-14 09:25:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:34][root][INFO] - Training Epoch: 2/2, step 8061/16670 completed (loss: 0.07206559926271439, acc: 0.9838709831237793)
[2024-11-14 09:25:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:34][root][INFO] - Training Epoch: 2/2, step 8062/16670 completed (loss: 0.25779077410697937, acc: 0.9454545378684998)
[2024-11-14 09:25:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:34][root][INFO] - Training Epoch: 2/2, step 8063/16670 completed (loss: 0.0994902104139328, acc: 0.9672130942344666)
[2024-11-14 09:25:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:35][root][INFO] - Training Epoch: 2/2, step 8064/16670 completed (loss: 0.05018577352166176, acc: 0.9736841917037964)
[2024-11-14 09:25:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:35][root][INFO] - Training Epoch: 2/2, step 8065/16670 completed (loss: 0.24984484910964966, acc: 0.9253731369972229)
[2024-11-14 09:25:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:35][root][INFO] - Training Epoch: 2/2, step 8066/16670 completed (loss: 0.09361086040735245, acc: 0.9836065769195557)
[2024-11-14 09:25:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:36][root][INFO] - Training Epoch: 2/2, step 8067/16670 completed (loss: 0.23162081837654114, acc: 0.9605262875556946)
[2024-11-14 09:25:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:36][root][INFO] - Training Epoch: 2/2, step 8068/16670 completed (loss: 0.2102028876543045, acc: 0.9193548560142517)
[2024-11-14 09:25:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:36][root][INFO] - Training Epoch: 2/2, step 8069/16670 completed (loss: 0.30286142230033875, acc: 0.9166666865348816)
[2024-11-14 09:25:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:37][root][INFO] - Training Epoch: 2/2, step 8070/16670 completed (loss: 0.3199974000453949, acc: 0.9347826242446899)
[2024-11-14 09:25:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:37][root][INFO] - Training Epoch: 2/2, step 8071/16670 completed (loss: 0.2611040472984314, acc: 0.9215686321258545)
[2024-11-14 09:25:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:37][root][INFO] - Training Epoch: 2/2, step 8072/16670 completed (loss: 0.22094304859638214, acc: 0.9591836929321289)
[2024-11-14 09:25:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:38][root][INFO] - Training Epoch: 2/2, step 8073/16670 completed (loss: 0.5232778191566467, acc: 0.8474576473236084)
[2024-11-14 09:25:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:38][root][INFO] - Training Epoch: 2/2, step 8074/16670 completed (loss: 0.11747531592845917, acc: 0.95652174949646)
[2024-11-14 09:25:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:38][root][INFO] - Training Epoch: 2/2, step 8075/16670 completed (loss: 0.4068354368209839, acc: 0.9333333373069763)
[2024-11-14 09:25:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:39][root][INFO] - Training Epoch: 2/2, step 8076/16670 completed (loss: 0.08240076154470444, acc: 0.9857142567634583)
[2024-11-14 09:25:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:39][root][INFO] - Training Epoch: 2/2, step 8077/16670 completed (loss: 0.02685825154185295, acc: 1.0)
[2024-11-14 09:25:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:39][root][INFO] - Training Epoch: 2/2, step 8078/16670 completed (loss: 0.17079132795333862, acc: 0.936170220375061)
[2024-11-14 09:25:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:40][root][INFO] - Training Epoch: 2/2, step 8079/16670 completed (loss: 0.3108169734477997, acc: 0.9365079402923584)
[2024-11-14 09:25:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:40][root][INFO] - Training Epoch: 2/2, step 8080/16670 completed (loss: 0.031230131164193153, acc: 1.0)
[2024-11-14 09:25:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:41][root][INFO] - Training Epoch: 2/2, step 8081/16670 completed (loss: 0.30266129970550537, acc: 0.9200000166893005)
[2024-11-14 09:25:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:41][root][INFO] - Training Epoch: 2/2, step 8082/16670 completed (loss: 0.21052081882953644, acc: 0.9268292784690857)
[2024-11-14 09:25:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:41][root][INFO] - Training Epoch: 2/2, step 8083/16670 completed (loss: 0.0774613469839096, acc: 0.9677419066429138)
[2024-11-14 09:25:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:42][root][INFO] - Training Epoch: 2/2, step 8084/16670 completed (loss: 0.046225983649492264, acc: 1.0)
[2024-11-14 09:25:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:42][root][INFO] - Training Epoch: 2/2, step 8085/16670 completed (loss: 0.060932885855436325, acc: 0.9750000238418579)
[2024-11-14 09:25:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:42][root][INFO] - Training Epoch: 2/2, step 8086/16670 completed (loss: 0.27191847562789917, acc: 0.9791666865348816)
[2024-11-14 09:25:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:43][root][INFO] - Training Epoch: 2/2, step 8087/16670 completed (loss: 0.07342232018709183, acc: 0.97826087474823)
[2024-11-14 09:25:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:43][root][INFO] - Training Epoch: 2/2, step 8088/16670 completed (loss: 0.2185455560684204, acc: 0.90625)
[2024-11-14 09:25:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:43][root][INFO] - Training Epoch: 2/2, step 8089/16670 completed (loss: 0.2863974869251251, acc: 0.9259259104728699)
[2024-11-14 09:25:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:44][root][INFO] - Training Epoch: 2/2, step 8090/16670 completed (loss: 0.2136240154504776, acc: 0.957446813583374)
[2024-11-14 09:25:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:44][root][INFO] - Training Epoch: 2/2, step 8091/16670 completed (loss: 0.166142076253891, acc: 0.9666666388511658)
[2024-11-14 09:25:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:44][root][INFO] - Training Epoch: 2/2, step 8092/16670 completed (loss: 0.5422970056533813, acc: 0.949999988079071)
[2024-11-14 09:25:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:45][root][INFO] - Training Epoch: 2/2, step 8093/16670 completed (loss: 0.0813552662730217, acc: 0.9655172228813171)
[2024-11-14 09:25:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:45][root][INFO] - Training Epoch: 2/2, step 8094/16670 completed (loss: 0.18121758103370667, acc: 0.9545454382896423)
[2024-11-14 09:25:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:46][root][INFO] - Training Epoch: 2/2, step 8095/16670 completed (loss: 0.0138528598472476, acc: 1.0)
[2024-11-14 09:25:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:46][root][INFO] - Training Epoch: 2/2, step 8096/16670 completed (loss: 0.04143097251653671, acc: 1.0)
[2024-11-14 09:25:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:46][root][INFO] - Training Epoch: 2/2, step 8097/16670 completed (loss: 0.02461065724492073, acc: 1.0)
[2024-11-14 09:25:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:47][root][INFO] - Training Epoch: 2/2, step 8098/16670 completed (loss: 0.1116984412074089, acc: 0.9692307710647583)
[2024-11-14 09:25:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:47][root][INFO] - Training Epoch: 2/2, step 8099/16670 completed (loss: 0.23493970930576324, acc: 0.9444444179534912)
[2024-11-14 09:25:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:47][root][INFO] - Training Epoch: 2/2, step 8100/16670 completed (loss: 0.3976210653781891, acc: 0.8823529481887817)
[2024-11-14 09:25:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:48][root][INFO] - Training Epoch: 2/2, step 8101/16670 completed (loss: 0.07211146503686905, acc: 0.9800000190734863)
[2024-11-14 09:25:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:48][root][INFO] - Training Epoch: 2/2, step 8102/16670 completed (loss: 0.2532942593097687, acc: 0.9318181872367859)
[2024-11-14 09:25:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:48][root][INFO] - Training Epoch: 2/2, step 8103/16670 completed (loss: 0.0892784371972084, acc: 0.9811320900917053)
[2024-11-14 09:25:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:49][root][INFO] - Training Epoch: 2/2, step 8104/16670 completed (loss: 0.3097521960735321, acc: 0.8823529481887817)
[2024-11-14 09:25:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:49][root][INFO] - Training Epoch: 2/2, step 8105/16670 completed (loss: 0.20974887907505035, acc: 0.9459459185600281)
[2024-11-14 09:25:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:49][root][INFO] - Training Epoch: 2/2, step 8106/16670 completed (loss: 0.058455511927604675, acc: 1.0)
[2024-11-14 09:25:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:50][root][INFO] - Training Epoch: 2/2, step 8107/16670 completed (loss: 0.12182248383760452, acc: 0.9473684430122375)
[2024-11-14 09:25:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:50][root][INFO] - Training Epoch: 2/2, step 8108/16670 completed (loss: 0.22502079606056213, acc: 0.9347826242446899)
[2024-11-14 09:25:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:50][root][INFO] - Training Epoch: 2/2, step 8109/16670 completed (loss: 0.29139918088912964, acc: 0.9272727370262146)
[2024-11-14 09:25:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:51][root][INFO] - Training Epoch: 2/2, step 8110/16670 completed (loss: 0.23495617508888245, acc: 0.936170220375061)
[2024-11-14 09:25:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:51][root][INFO] - Training Epoch: 2/2, step 8111/16670 completed (loss: 0.08685395866632462, acc: 0.982758641242981)
[2024-11-14 09:25:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:51][root][INFO] - Training Epoch: 2/2, step 8112/16670 completed (loss: 0.2567603886127472, acc: 0.8913043737411499)
[2024-11-14 09:25:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:52][root][INFO] - Training Epoch: 2/2, step 8113/16670 completed (loss: 0.3001951277256012, acc: 0.930232584476471)
[2024-11-14 09:25:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:52][root][INFO] - Training Epoch: 2/2, step 8114/16670 completed (loss: 0.23421353101730347, acc: 0.9354838728904724)
[2024-11-14 09:25:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:52][root][INFO] - Training Epoch: 2/2, step 8115/16670 completed (loss: 0.11346189677715302, acc: 0.9661017060279846)
[2024-11-14 09:25:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:53][root][INFO] - Training Epoch: 2/2, step 8116/16670 completed (loss: 0.06043535843491554, acc: 0.96875)
[2024-11-14 09:25:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:53][root][INFO] - Training Epoch: 2/2, step 8117/16670 completed (loss: 0.0915604755282402, acc: 0.9890109896659851)
[2024-11-14 09:25:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:53][root][INFO] - Training Epoch: 2/2, step 8118/16670 completed (loss: 0.11529558897018433, acc: 0.970588207244873)
[2024-11-14 09:25:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:54][root][INFO] - Training Epoch: 2/2, step 8119/16670 completed (loss: 0.3193517327308655, acc: 0.920634925365448)
[2024-11-14 09:25:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:54][root][INFO] - Training Epoch: 2/2, step 8120/16670 completed (loss: 0.242891326546669, acc: 0.9137930870056152)
[2024-11-14 09:25:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:54][root][INFO] - Training Epoch: 2/2, step 8121/16670 completed (loss: 0.22561059892177582, acc: 0.9444444179534912)
[2024-11-14 09:25:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:55][root][INFO] - Training Epoch: 2/2, step 8122/16670 completed (loss: 0.2962283194065094, acc: 0.8999999761581421)
[2024-11-14 09:25:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:55][root][INFO] - Training Epoch: 2/2, step 8123/16670 completed (loss: 0.10691464692354202, acc: 0.9622641801834106)
[2024-11-14 09:25:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:55][root][INFO] - Training Epoch: 2/2, step 8124/16670 completed (loss: 0.31624796986579895, acc: 0.9375)
[2024-11-14 09:25:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:56][root][INFO] - Training Epoch: 2/2, step 8125/16670 completed (loss: 0.14462295174598694, acc: 0.9629629850387573)
[2024-11-14 09:25:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:56][root][INFO] - Training Epoch: 2/2, step 8126/16670 completed (loss: 0.5888015627861023, acc: 0.8928571343421936)
[2024-11-14 09:25:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:56][root][INFO] - Training Epoch: 2/2, step 8127/16670 completed (loss: 0.17792163789272308, acc: 0.9375)
[2024-11-14 09:25:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:57][root][INFO] - Training Epoch: 2/2, step 8128/16670 completed (loss: 0.2318304032087326, acc: 0.949367105960846)
[2024-11-14 09:25:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:57][root][INFO] - Training Epoch: 2/2, step 8129/16670 completed (loss: 0.02146749570965767, acc: 1.0)
[2024-11-14 09:25:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:57][root][INFO] - Training Epoch: 2/2, step 8130/16670 completed (loss: 0.16221414506435394, acc: 0.978723406791687)
[2024-11-14 09:25:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:58][root][INFO] - Training Epoch: 2/2, step 8131/16670 completed (loss: 0.1834004670381546, acc: 0.970588207244873)
[2024-11-14 09:25:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:58][root][INFO] - Training Epoch: 2/2, step 8132/16670 completed (loss: 0.138564795255661, acc: 0.9800000190734863)
[2024-11-14 09:25:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:58][root][INFO] - Training Epoch: 2/2, step 8133/16670 completed (loss: 0.017352258786559105, acc: 1.0)
[2024-11-14 09:25:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:59][root][INFO] - Training Epoch: 2/2, step 8134/16670 completed (loss: 0.10972413420677185, acc: 0.9696969985961914)
[2024-11-14 09:25:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:59][root][INFO] - Training Epoch: 2/2, step 8135/16670 completed (loss: 0.2736798822879791, acc: 0.8947368264198303)
[2024-11-14 09:25:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:25:59][root][INFO] - Training Epoch: 2/2, step 8136/16670 completed (loss: 0.32038456201553345, acc: 0.9354838728904724)
[2024-11-14 09:25:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:00][root][INFO] - Training Epoch: 2/2, step 8137/16670 completed (loss: 0.12824486196041107, acc: 0.9795918464660645)
[2024-11-14 09:26:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:00][root][INFO] - Training Epoch: 2/2, step 8138/16670 completed (loss: 0.3293011486530304, acc: 0.8529411554336548)
[2024-11-14 09:26:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:00][root][INFO] - Training Epoch: 2/2, step 8139/16670 completed (loss: 0.5852423310279846, acc: 0.8846153616905212)
[2024-11-14 09:26:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:01][root][INFO] - Training Epoch: 2/2, step 8140/16670 completed (loss: 0.3312666714191437, acc: 0.8958333134651184)
[2024-11-14 09:26:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:01][root][INFO] - Training Epoch: 2/2, step 8141/16670 completed (loss: 0.1708669513463974, acc: 0.9545454382896423)
[2024-11-14 09:26:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:01][root][INFO] - Training Epoch: 2/2, step 8142/16670 completed (loss: 0.4298027753829956, acc: 0.90625)
[2024-11-14 09:26:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:02][root][INFO] - Training Epoch: 2/2, step 8143/16670 completed (loss: 0.130013108253479, acc: 0.954023003578186)
[2024-11-14 09:26:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:02][root][INFO] - Training Epoch: 2/2, step 8144/16670 completed (loss: 0.22081740200519562, acc: 0.976190447807312)
[2024-11-14 09:26:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:02][root][INFO] - Training Epoch: 2/2, step 8145/16670 completed (loss: 0.48923400044441223, acc: 0.9032257795333862)
[2024-11-14 09:26:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:03][root][INFO] - Training Epoch: 2/2, step 8146/16670 completed (loss: 0.6492763757705688, acc: 0.8409090638160706)
[2024-11-14 09:26:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:03][root][INFO] - Training Epoch: 2/2, step 8147/16670 completed (loss: 0.26183369755744934, acc: 0.8965517282485962)
[2024-11-14 09:26:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:03][root][INFO] - Training Epoch: 2/2, step 8148/16670 completed (loss: 0.25872910022735596, acc: 0.9137930870056152)
[2024-11-14 09:26:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:04][root][INFO] - Training Epoch: 2/2, step 8149/16670 completed (loss: 0.06406517326831818, acc: 0.9677419066429138)
[2024-11-14 09:26:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:04][root][INFO] - Training Epoch: 2/2, step 8150/16670 completed (loss: 0.1485801339149475, acc: 0.9599999785423279)
[2024-11-14 09:26:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:04][root][INFO] - Training Epoch: 2/2, step 8151/16670 completed (loss: 0.6743590831756592, acc: 0.796875)
[2024-11-14 09:26:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:04][root][INFO] - Training Epoch: 2/2, step 8152/16670 completed (loss: 0.17207776010036469, acc: 0.936170220375061)
[2024-11-14 09:26:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:05][root][INFO] - Training Epoch: 2/2, step 8153/16670 completed (loss: 0.5867174863815308, acc: 0.8135592937469482)
[2024-11-14 09:26:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:05][root][INFO] - Training Epoch: 2/2, step 8154/16670 completed (loss: 0.6393977403640747, acc: 0.875)
[2024-11-14 09:26:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:05][root][INFO] - Training Epoch: 2/2, step 8155/16670 completed (loss: 0.2696671485900879, acc: 0.9285714030265808)
[2024-11-14 09:26:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:06][root][INFO] - Training Epoch: 2/2, step 8156/16670 completed (loss: 0.19401811063289642, acc: 0.9375)
[2024-11-14 09:26:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:06][root][INFO] - Training Epoch: 2/2, step 8157/16670 completed (loss: 0.19651733338832855, acc: 0.9624999761581421)
[2024-11-14 09:26:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:06][root][INFO] - Training Epoch: 2/2, step 8158/16670 completed (loss: 0.6022459268569946, acc: 0.8653846383094788)
[2024-11-14 09:26:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:07][root][INFO] - Training Epoch: 2/2, step 8159/16670 completed (loss: 0.3200969398021698, acc: 0.9428571462631226)
[2024-11-14 09:26:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:07][root][INFO] - Training Epoch: 2/2, step 8160/16670 completed (loss: 0.27109238505363464, acc: 0.9180327653884888)
[2024-11-14 09:26:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:07][root][INFO] - Training Epoch: 2/2, step 8161/16670 completed (loss: 0.1664295494556427, acc: 0.9545454382896423)
[2024-11-14 09:26:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:08][root][INFO] - Training Epoch: 2/2, step 8162/16670 completed (loss: 0.18348409235477448, acc: 0.9333333373069763)
[2024-11-14 09:26:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:08][root][INFO] - Training Epoch: 2/2, step 8163/16670 completed (loss: 0.40964993834495544, acc: 0.8510638475418091)
[2024-11-14 09:26:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:09][root][INFO] - Training Epoch: 2/2, step 8164/16670 completed (loss: 0.10431845486164093, acc: 0.9538461565971375)
[2024-11-14 09:26:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:09][root][INFO] - Training Epoch: 2/2, step 8165/16670 completed (loss: 0.15315397083759308, acc: 0.9622641801834106)
[2024-11-14 09:26:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:09][root][INFO] - Training Epoch: 2/2, step 8166/16670 completed (loss: 0.17478518187999725, acc: 0.8974359035491943)
[2024-11-14 09:26:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:10][root][INFO] - Training Epoch: 2/2, step 8167/16670 completed (loss: 0.28541791439056396, acc: 0.957446813583374)
[2024-11-14 09:26:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:10][root][INFO] - Training Epoch: 2/2, step 8168/16670 completed (loss: 0.6705228090286255, acc: 0.8732394576072693)
[2024-11-14 09:26:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:10][root][INFO] - Training Epoch: 2/2, step 8169/16670 completed (loss: 0.1026662066578865, acc: 0.9538461565971375)
[2024-11-14 09:26:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:11][root][INFO] - Training Epoch: 2/2, step 8170/16670 completed (loss: 0.3645873963832855, acc: 0.9154929518699646)
[2024-11-14 09:26:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:11][root][INFO] - Training Epoch: 2/2, step 8171/16670 completed (loss: 0.031747765839099884, acc: 1.0)
[2024-11-14 09:26:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:11][root][INFO] - Training Epoch: 2/2, step 8172/16670 completed (loss: 0.5557702779769897, acc: 0.9066666960716248)
[2024-11-14 09:26:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:12][root][INFO] - Training Epoch: 2/2, step 8173/16670 completed (loss: 0.41449201107025146, acc: 0.8805969953536987)
[2024-11-14 09:26:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:12][root][INFO] - Training Epoch: 2/2, step 8174/16670 completed (loss: 0.6635428667068481, acc: 0.8656716346740723)
[2024-11-14 09:26:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:12][root][INFO] - Training Epoch: 2/2, step 8175/16670 completed (loss: 0.05575724318623543, acc: 1.0)
[2024-11-14 09:26:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:13][root][INFO] - Training Epoch: 2/2, step 8176/16670 completed (loss: 0.3778402805328369, acc: 0.9076923131942749)
[2024-11-14 09:26:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:13][root][INFO] - Training Epoch: 2/2, step 8177/16670 completed (loss: 0.12127166241407394, acc: 0.9767441749572754)
[2024-11-14 09:26:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:13][root][INFO] - Training Epoch: 2/2, step 8178/16670 completed (loss: 0.43312951922416687, acc: 0.8936170339584351)
[2024-11-14 09:26:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:14][root][INFO] - Training Epoch: 2/2, step 8179/16670 completed (loss: 0.25697633624076843, acc: 0.9523809552192688)
[2024-11-14 09:26:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:14][root][INFO] - Training Epoch: 2/2, step 8180/16670 completed (loss: 0.4982115626335144, acc: 0.9122806787490845)
[2024-11-14 09:26:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:14][root][INFO] - Training Epoch: 2/2, step 8181/16670 completed (loss: 0.4322551488876343, acc: 0.8518518805503845)
[2024-11-14 09:26:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:15][root][INFO] - Training Epoch: 2/2, step 8182/16670 completed (loss: 0.04490109905600548, acc: 1.0)
[2024-11-14 09:26:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:15][root][INFO] - Training Epoch: 2/2, step 8183/16670 completed (loss: 0.2151704877614975, acc: 0.9545454382896423)
[2024-11-14 09:26:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:16][root][INFO] - Training Epoch: 2/2, step 8184/16670 completed (loss: 0.09150154888629913, acc: 1.0)
[2024-11-14 09:26:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:16][root][INFO] - Training Epoch: 2/2, step 8185/16670 completed (loss: 0.355533242225647, acc: 0.9032257795333862)
[2024-11-14 09:26:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:16][root][INFO] - Training Epoch: 2/2, step 8186/16670 completed (loss: 0.2345474809408188, acc: 0.9569892287254333)
[2024-11-14 09:26:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:17][root][INFO] - Training Epoch: 2/2, step 8187/16670 completed (loss: 0.4759172201156616, acc: 0.8965517282485962)
[2024-11-14 09:26:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:17][root][INFO] - Training Epoch: 2/2, step 8188/16670 completed (loss: 0.09406272321939468, acc: 0.9629629850387573)
[2024-11-14 09:26:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:17][root][INFO] - Training Epoch: 2/2, step 8189/16670 completed (loss: 0.2183356136083603, acc: 0.9583333134651184)
[2024-11-14 09:26:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:18][root][INFO] - Training Epoch: 2/2, step 8190/16670 completed (loss: 0.051095716655254364, acc: 0.982758641242981)
[2024-11-14 09:26:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:18][root][INFO] - Training Epoch: 2/2, step 8191/16670 completed (loss: 0.24111704528331757, acc: 0.9605262875556946)
[2024-11-14 09:26:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:18][root][INFO] - Training Epoch: 2/2, step 8192/16670 completed (loss: 0.2365015745162964, acc: 0.9245283007621765)
[2024-11-14 09:26:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:19][root][INFO] - Training Epoch: 2/2, step 8193/16670 completed (loss: 0.2991759181022644, acc: 0.9350649118423462)
[2024-11-14 09:26:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:19][root][INFO] - Training Epoch: 2/2, step 8194/16670 completed (loss: 0.2955760657787323, acc: 0.925000011920929)
[2024-11-14 09:26:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:19][root][INFO] - Training Epoch: 2/2, step 8195/16670 completed (loss: 0.032620418816804886, acc: 1.0)
[2024-11-14 09:26:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:20][root][INFO] - Training Epoch: 2/2, step 8196/16670 completed (loss: 0.6023551225662231, acc: 0.8867924809455872)
[2024-11-14 09:26:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:20][root][INFO] - Training Epoch: 2/2, step 8197/16670 completed (loss: 0.33348944783210754, acc: 0.8695651888847351)
[2024-11-14 09:26:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:21][root][INFO] - Training Epoch: 2/2, step 8198/16670 completed (loss: 0.13154301047325134, acc: 0.9534883499145508)
[2024-11-14 09:26:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:21][root][INFO] - Training Epoch: 2/2, step 8199/16670 completed (loss: 0.024001671001315117, acc: 1.0)
[2024-11-14 09:26:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:21][root][INFO] - Training Epoch: 2/2, step 8200/16670 completed (loss: 0.14804066717624664, acc: 0.9855072498321533)
[2024-11-14 09:26:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:22][root][INFO] - Training Epoch: 2/2, step 8201/16670 completed (loss: 0.28783103823661804, acc: 0.9516128897666931)
[2024-11-14 09:26:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:22][root][INFO] - Training Epoch: 2/2, step 8202/16670 completed (loss: 0.05775265768170357, acc: 1.0)
[2024-11-14 09:26:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:22][root][INFO] - Training Epoch: 2/2, step 8203/16670 completed (loss: 0.22038134932518005, acc: 0.9322034120559692)
[2024-11-14 09:26:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:23][root][INFO] - Training Epoch: 2/2, step 8204/16670 completed (loss: 0.43413302302360535, acc: 0.9210526347160339)
[2024-11-14 09:26:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:23][root][INFO] - Training Epoch: 2/2, step 8205/16670 completed (loss: 0.12374772876501083, acc: 0.9710144996643066)
[2024-11-14 09:26:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:23][root][INFO] - Training Epoch: 2/2, step 8206/16670 completed (loss: 0.08472811430692673, acc: 0.9583333134651184)
[2024-11-14 09:26:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:24][root][INFO] - Training Epoch: 2/2, step 8207/16670 completed (loss: 0.41483741998672485, acc: 0.949999988079071)
[2024-11-14 09:26:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:24][root][INFO] - Training Epoch: 2/2, step 8208/16670 completed (loss: 0.4008311927318573, acc: 0.8873239159584045)
[2024-11-14 09:26:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:24][root][INFO] - Training Epoch: 2/2, step 8209/16670 completed (loss: 0.5857120752334595, acc: 0.8936170339584351)
[2024-11-14 09:26:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:25][root][INFO] - Training Epoch: 2/2, step 8210/16670 completed (loss: 0.25011393427848816, acc: 0.9333333373069763)
[2024-11-14 09:26:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:25][root][INFO] - Training Epoch: 2/2, step 8211/16670 completed (loss: 0.4013114273548126, acc: 0.9411764740943909)
[2024-11-14 09:26:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:25][root][INFO] - Training Epoch: 2/2, step 8212/16670 completed (loss: 0.17276166379451752, acc: 0.9726027250289917)
[2024-11-14 09:26:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:26][root][INFO] - Training Epoch: 2/2, step 8213/16670 completed (loss: 0.10104463994503021, acc: 0.9722222089767456)
[2024-11-14 09:26:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:26][root][INFO] - Training Epoch: 2/2, step 8214/16670 completed (loss: 0.14273706078529358, acc: 0.936170220375061)
[2024-11-14 09:26:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:27][root][INFO] - Training Epoch: 2/2, step 8215/16670 completed (loss: 0.43314871191978455, acc: 0.9074074029922485)
[2024-11-14 09:26:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:27][root][INFO] - Training Epoch: 2/2, step 8216/16670 completed (loss: 0.28909170627593994, acc: 0.9166666865348816)
[2024-11-14 09:26:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:27][root][INFO] - Training Epoch: 2/2, step 8217/16670 completed (loss: 0.27622222900390625, acc: 0.9402984976768494)
[2024-11-14 09:26:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:27][root][INFO] - Training Epoch: 2/2, step 8218/16670 completed (loss: 0.33232903480529785, acc: 0.9166666865348816)
[2024-11-14 09:26:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:28][root][INFO] - Training Epoch: 2/2, step 8219/16670 completed (loss: 0.5598443150520325, acc: 0.8695651888847351)
[2024-11-14 09:26:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:28][root][INFO] - Training Epoch: 2/2, step 8220/16670 completed (loss: 0.2889697849750519, acc: 0.8979591727256775)
[2024-11-14 09:26:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:29][root][INFO] - Training Epoch: 2/2, step 8221/16670 completed (loss: 0.24072925746440887, acc: 0.9142857193946838)
[2024-11-14 09:26:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:29][root][INFO] - Training Epoch: 2/2, step 8222/16670 completed (loss: 0.08508408069610596, acc: 0.9795918464660645)
[2024-11-14 09:26:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:29][root][INFO] - Training Epoch: 2/2, step 8223/16670 completed (loss: 0.0704619511961937, acc: 0.9729729890823364)
[2024-11-14 09:26:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:30][root][INFO] - Training Epoch: 2/2, step 8224/16670 completed (loss: 0.1358141452074051, acc: 1.0)
[2024-11-14 09:26:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:30][root][INFO] - Training Epoch: 2/2, step 8225/16670 completed (loss: 0.27295610308647156, acc: 0.925000011920929)
[2024-11-14 09:26:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:30][root][INFO] - Training Epoch: 2/2, step 8226/16670 completed (loss: 0.07014737278223038, acc: 0.970588207244873)
[2024-11-14 09:26:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:31][root][INFO] - Training Epoch: 2/2, step 8227/16670 completed (loss: 0.280060350894928, acc: 0.9074074029922485)
[2024-11-14 09:26:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:31][root][INFO] - Training Epoch: 2/2, step 8228/16670 completed (loss: 0.3135973811149597, acc: 0.9454545378684998)
[2024-11-14 09:26:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:31][root][INFO] - Training Epoch: 2/2, step 8229/16670 completed (loss: 0.124836765229702, acc: 0.9672130942344666)
[2024-11-14 09:26:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:32][root][INFO] - Training Epoch: 2/2, step 8230/16670 completed (loss: 0.24772369861602783, acc: 0.9125000238418579)
[2024-11-14 09:26:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:32][root][INFO] - Training Epoch: 2/2, step 8231/16670 completed (loss: 0.1527899205684662, acc: 0.9692307710647583)
[2024-11-14 09:26:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:33][root][INFO] - Training Epoch: 2/2, step 8232/16670 completed (loss: 0.17775847017765045, acc: 0.9696969985961914)
[2024-11-14 09:26:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:33][root][INFO] - Training Epoch: 2/2, step 8233/16670 completed (loss: 0.24312563240528107, acc: 0.9558823704719543)
[2024-11-14 09:26:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:33][root][INFO] - Training Epoch: 2/2, step 8234/16670 completed (loss: 0.20761331915855408, acc: 0.9259259104728699)
[2024-11-14 09:26:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:34][root][INFO] - Training Epoch: 2/2, step 8235/16670 completed (loss: 0.048486292362213135, acc: 1.0)
[2024-11-14 09:26:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:34][root][INFO] - Training Epoch: 2/2, step 8236/16670 completed (loss: 0.11754085123538971, acc: 0.938144326210022)
[2024-11-14 09:26:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:34][root][INFO] - Training Epoch: 2/2, step 8237/16670 completed (loss: 0.018184956163167953, acc: 1.0)
[2024-11-14 09:26:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:35][root][INFO] - Training Epoch: 2/2, step 8238/16670 completed (loss: 0.028384028002619743, acc: 1.0)
[2024-11-14 09:26:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:35][root][INFO] - Training Epoch: 2/2, step 8239/16670 completed (loss: 0.013742581941187382, acc: 1.0)
[2024-11-14 09:26:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:35][root][INFO] - Training Epoch: 2/2, step 8240/16670 completed (loss: 0.2530886232852936, acc: 0.9534883499145508)
[2024-11-14 09:26:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:36][root][INFO] - Training Epoch: 2/2, step 8241/16670 completed (loss: 0.7738266587257385, acc: 0.8787878751754761)
[2024-11-14 09:26:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:36][root][INFO] - Training Epoch: 2/2, step 8242/16670 completed (loss: 0.2821041941642761, acc: 0.931034505367279)
[2024-11-14 09:26:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:36][root][INFO] - Training Epoch: 2/2, step 8243/16670 completed (loss: 0.2521640956401825, acc: 0.9629629850387573)
[2024-11-14 09:26:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:37][root][INFO] - Training Epoch: 2/2, step 8244/16670 completed (loss: 0.15796418488025665, acc: 0.9811320900917053)
[2024-11-14 09:26:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:37][root][INFO] - Training Epoch: 2/2, step 8245/16670 completed (loss: 0.30584925413131714, acc: 0.9454545378684998)
[2024-11-14 09:26:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:37][root][INFO] - Training Epoch: 2/2, step 8246/16670 completed (loss: 0.4396194815635681, acc: 0.8902438879013062)
[2024-11-14 09:26:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:38][root][INFO] - Training Epoch: 2/2, step 8247/16670 completed (loss: 0.25891849398612976, acc: 0.931034505367279)
[2024-11-14 09:26:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:38][root][INFO] - Training Epoch: 2/2, step 8248/16670 completed (loss: 0.28766006231307983, acc: 0.8712871074676514)
[2024-11-14 09:26:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:38][root][INFO] - Training Epoch: 2/2, step 8249/16670 completed (loss: 0.19031691551208496, acc: 0.9555555582046509)
[2024-11-14 09:26:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:39][root][INFO] - Training Epoch: 2/2, step 8250/16670 completed (loss: 0.5580409169197083, acc: 0.75)
[2024-11-14 09:26:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:39][root][INFO] - Training Epoch: 2/2, step 8251/16670 completed (loss: 0.24563850462436676, acc: 0.949999988079071)
[2024-11-14 09:26:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:39][root][INFO] - Training Epoch: 2/2, step 8252/16670 completed (loss: 0.10807459056377411, acc: 0.9516128897666931)
[2024-11-14 09:26:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:40][root][INFO] - Training Epoch: 2/2, step 8253/16670 completed (loss: 0.4010423719882965, acc: 0.9230769276618958)
[2024-11-14 09:26:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:40][root][INFO] - Training Epoch: 2/2, step 8254/16670 completed (loss: 0.43598517775535583, acc: 0.9107142686843872)
[2024-11-14 09:26:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:40][root][INFO] - Training Epoch: 2/2, step 8255/16670 completed (loss: 0.09609952569007874, acc: 0.9807692170143127)
[2024-11-14 09:26:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:41][root][INFO] - Training Epoch: 2/2, step 8256/16670 completed (loss: 0.32767099142074585, acc: 0.9259259104728699)
[2024-11-14 09:26:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:41][root][INFO] - Training Epoch: 2/2, step 8257/16670 completed (loss: 0.21636144816875458, acc: 0.9464285969734192)
[2024-11-14 09:26:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:41][root][INFO] - Training Epoch: 2/2, step 8258/16670 completed (loss: 0.159037247300148, acc: 0.9615384340286255)
[2024-11-14 09:26:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:42][root][INFO] - Training Epoch: 2/2, step 8259/16670 completed (loss: 0.049616001546382904, acc: 1.0)
[2024-11-14 09:26:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:42][root][INFO] - Training Epoch: 2/2, step 8260/16670 completed (loss: 0.2779589593410492, acc: 0.8863636255264282)
[2024-11-14 09:26:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:43][root][INFO] - Training Epoch: 2/2, step 8261/16670 completed (loss: 0.340317040681839, acc: 0.9259259104728699)
[2024-11-14 09:26:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:43][root][INFO] - Training Epoch: 2/2, step 8262/16670 completed (loss: 0.032957032322883606, acc: 1.0)
[2024-11-14 09:26:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:43][root][INFO] - Training Epoch: 2/2, step 8263/16670 completed (loss: 0.0669998899102211, acc: 1.0)
[2024-11-14 09:26:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:44][root][INFO] - Training Epoch: 2/2, step 8264/16670 completed (loss: 0.21575962007045746, acc: 0.9599999785423279)
[2024-11-14 09:26:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:44][root][INFO] - Training Epoch: 2/2, step 8265/16670 completed (loss: 0.09355555474758148, acc: 0.9743589758872986)
[2024-11-14 09:26:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:44][root][INFO] - Training Epoch: 2/2, step 8266/16670 completed (loss: 0.17382943630218506, acc: 0.931034505367279)
[2024-11-14 09:26:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:45][root][INFO] - Training Epoch: 2/2, step 8267/16670 completed (loss: 0.32152456045150757, acc: 0.9545454382896423)
[2024-11-14 09:26:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:45][root][INFO] - Training Epoch: 2/2, step 8268/16670 completed (loss: 0.38696226477622986, acc: 0.9285714030265808)
[2024-11-14 09:26:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:45][root][INFO] - Training Epoch: 2/2, step 8269/16670 completed (loss: 0.05287642776966095, acc: 1.0)
[2024-11-14 09:26:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:46][root][INFO] - Training Epoch: 2/2, step 8270/16670 completed (loss: 0.21834833920001984, acc: 0.9375)
[2024-11-14 09:26:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:46][root][INFO] - Training Epoch: 2/2, step 8271/16670 completed (loss: 0.12818101048469543, acc: 0.9722222089767456)
[2024-11-14 09:26:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:47][root][INFO] - Training Epoch: 2/2, step 8272/16670 completed (loss: 0.23215992748737335, acc: 0.9473684430122375)
[2024-11-14 09:26:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:47][root][INFO] - Training Epoch: 2/2, step 8273/16670 completed (loss: 0.32400384545326233, acc: 0.9375)
[2024-11-14 09:26:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:47][root][INFO] - Training Epoch: 2/2, step 8274/16670 completed (loss: 0.28741130232810974, acc: 0.9111111164093018)
[2024-11-14 09:26:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:48][root][INFO] - Training Epoch: 2/2, step 8275/16670 completed (loss: 0.30965539813041687, acc: 0.9264705777168274)
[2024-11-14 09:26:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:48][root][INFO] - Training Epoch: 2/2, step 8276/16670 completed (loss: 0.09495963901281357, acc: 0.9636363387107849)
[2024-11-14 09:26:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:48][root][INFO] - Training Epoch: 2/2, step 8277/16670 completed (loss: 0.30802014470100403, acc: 0.9473684430122375)
[2024-11-14 09:26:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:49][root][INFO] - Training Epoch: 2/2, step 8278/16670 completed (loss: 0.4409372806549072, acc: 0.8823529481887817)
[2024-11-14 09:26:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:49][root][INFO] - Training Epoch: 2/2, step 8279/16670 completed (loss: 0.2977217733860016, acc: 0.9107142686843872)
[2024-11-14 09:26:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:50][root][INFO] - Training Epoch: 2/2, step 8280/16670 completed (loss: 0.22187770903110504, acc: 0.9375)
[2024-11-14 09:26:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:50][root][INFO] - Training Epoch: 2/2, step 8281/16670 completed (loss: 0.47239798307418823, acc: 0.8529411554336548)
[2024-11-14 09:26:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:50][root][INFO] - Training Epoch: 2/2, step 8282/16670 completed (loss: 0.19168774783611298, acc: 0.9375)
[2024-11-14 09:26:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:51][root][INFO] - Training Epoch: 2/2, step 8283/16670 completed (loss: 0.42430105805397034, acc: 0.9375)
[2024-11-14 09:26:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:51][root][INFO] - Training Epoch: 2/2, step 8284/16670 completed (loss: 0.0893154889345169, acc: 0.9714285731315613)
[2024-11-14 09:26:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:51][root][INFO] - Training Epoch: 2/2, step 8285/16670 completed (loss: 0.07993783801794052, acc: 0.970588207244873)
[2024-11-14 09:26:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:52][root][INFO] - Training Epoch: 2/2, step 8286/16670 completed (loss: 0.284732460975647, acc: 0.9375)
[2024-11-14 09:26:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:52][root][INFO] - Training Epoch: 2/2, step 8287/16670 completed (loss: 0.48681825399398804, acc: 0.8571428656578064)
[2024-11-14 09:26:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:52][root][INFO] - Training Epoch: 2/2, step 8288/16670 completed (loss: 0.04591159150004387, acc: 1.0)
[2024-11-14 09:26:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:53][root][INFO] - Training Epoch: 2/2, step 8289/16670 completed (loss: 0.4012582004070282, acc: 0.9200000166893005)
[2024-11-14 09:26:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:53][root][INFO] - Training Epoch: 2/2, step 8290/16670 completed (loss: 0.3492978811264038, acc: 0.9411764740943909)
[2024-11-14 09:26:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:54][root][INFO] - Training Epoch: 2/2, step 8291/16670 completed (loss: 0.467791885137558, acc: 0.8928571343421936)
[2024-11-14 09:26:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:54][root][INFO] - Training Epoch: 2/2, step 8292/16670 completed (loss: 0.5641827583312988, acc: 0.8852459192276001)
[2024-11-14 09:26:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:54][root][INFO] - Training Epoch: 2/2, step 8293/16670 completed (loss: 0.5561591386795044, acc: 0.9268292784690857)
[2024-11-14 09:26:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:55][root][INFO] - Training Epoch: 2/2, step 8294/16670 completed (loss: 0.6995276212692261, acc: 0.8125)
[2024-11-14 09:26:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:55][root][INFO] - Training Epoch: 2/2, step 8295/16670 completed (loss: 0.08573108166456223, acc: 0.9807692170143127)
[2024-11-14 09:26:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:55][root][INFO] - Training Epoch: 2/2, step 8296/16670 completed (loss: 0.19393087923526764, acc: 0.9722222089767456)
[2024-11-14 09:26:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:56][root][INFO] - Training Epoch: 2/2, step 8297/16670 completed (loss: 0.19455181062221527, acc: 0.9777777791023254)
[2024-11-14 09:26:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:56][root][INFO] - Training Epoch: 2/2, step 8298/16670 completed (loss: 0.32431700825691223, acc: 0.931034505367279)
[2024-11-14 09:26:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:56][root][INFO] - Training Epoch: 2/2, step 8299/16670 completed (loss: 0.18944180011749268, acc: 0.9428571462631226)
[2024-11-14 09:26:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:57][root][INFO] - Training Epoch: 2/2, step 8300/16670 completed (loss: 0.28009021282196045, acc: 0.9142857193946838)
[2024-11-14 09:26:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:57][root][INFO] - Training Epoch: 2/2, step 8301/16670 completed (loss: 0.09315986931324005, acc: 0.949999988079071)
[2024-11-14 09:26:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:57][root][INFO] - Training Epoch: 2/2, step 8302/16670 completed (loss: 0.06293924152851105, acc: 1.0)
[2024-11-14 09:26:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:58][root][INFO] - Training Epoch: 2/2, step 8303/16670 completed (loss: 0.3629688620567322, acc: 0.9189189076423645)
[2024-11-14 09:26:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:58][root][INFO] - Training Epoch: 2/2, step 8304/16670 completed (loss: 0.17325446009635925, acc: 0.9750000238418579)
[2024-11-14 09:26:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:58][root][INFO] - Training Epoch: 2/2, step 8305/16670 completed (loss: 0.15948842465877533, acc: 0.949999988079071)
[2024-11-14 09:26:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:59][root][INFO] - Training Epoch: 2/2, step 8306/16670 completed (loss: 0.05957585200667381, acc: 1.0)
[2024-11-14 09:26:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:59][root][INFO] - Training Epoch: 2/2, step 8307/16670 completed (loss: 0.21575815975666046, acc: 0.9259259104728699)
[2024-11-14 09:26:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:26:59][root][INFO] - Training Epoch: 2/2, step 8308/16670 completed (loss: 0.12628179788589478, acc: 0.9655172228813171)
[2024-11-14 09:27:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:00][root][INFO] - Training Epoch: 2/2, step 8309/16670 completed (loss: 0.12360917031764984, acc: 0.9130434989929199)
[2024-11-14 09:27:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:00][root][INFO] - Training Epoch: 2/2, step 8310/16670 completed (loss: 0.48095977306365967, acc: 0.8604651093482971)
[2024-11-14 09:27:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:00][root][INFO] - Training Epoch: 2/2, step 8311/16670 completed (loss: 0.1460917592048645, acc: 0.9545454382896423)
[2024-11-14 09:27:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:01][root][INFO] - Training Epoch: 2/2, step 8312/16670 completed (loss: 0.25551608204841614, acc: 0.9090909361839294)
[2024-11-14 09:27:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:01][root][INFO] - Training Epoch: 2/2, step 8313/16670 completed (loss: 0.3237476944923401, acc: 0.9615384340286255)
[2024-11-14 09:27:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:01][root][INFO] - Training Epoch: 2/2, step 8314/16670 completed (loss: 0.19510211050510406, acc: 0.8837209343910217)
[2024-11-14 09:27:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:02][root][INFO] - Training Epoch: 2/2, step 8315/16670 completed (loss: 0.15214741230010986, acc: 0.918367326259613)
[2024-11-14 09:27:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:02][root][INFO] - Training Epoch: 2/2, step 8316/16670 completed (loss: 0.5859197974205017, acc: 0.8936170339584351)
[2024-11-14 09:27:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:02][root][INFO] - Training Epoch: 2/2, step 8317/16670 completed (loss: 0.8133232593536377, acc: 0.8125)
[2024-11-14 09:27:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:03][root][INFO] - Training Epoch: 2/2, step 8318/16670 completed (loss: 0.5135505795478821, acc: 0.8653846383094788)
[2024-11-14 09:27:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:03][root][INFO] - Training Epoch: 2/2, step 8319/16670 completed (loss: 0.2744482457637787, acc: 0.9375)
[2024-11-14 09:27:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:03][root][INFO] - Training Epoch: 2/2, step 8320/16670 completed (loss: 0.5726481080055237, acc: 0.9038461446762085)
[2024-11-14 09:27:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:04][root][INFO] - Training Epoch: 2/2, step 8321/16670 completed (loss: 0.1903480589389801, acc: 0.925000011920929)
[2024-11-14 09:27:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:04][root][INFO] - Training Epoch: 2/2, step 8322/16670 completed (loss: 0.1739872843027115, acc: 0.9629629850387573)
[2024-11-14 09:27:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:04][root][INFO] - Training Epoch: 2/2, step 8323/16670 completed (loss: 0.13431178033351898, acc: 0.95652174949646)
[2024-11-14 09:27:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:05][root][INFO] - Training Epoch: 2/2, step 8324/16670 completed (loss: 0.3881355822086334, acc: 0.8666666746139526)
[2024-11-14 09:27:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:05][root][INFO] - Training Epoch: 2/2, step 8325/16670 completed (loss: 0.03508537635207176, acc: 1.0)
[2024-11-14 09:27:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:06][root][INFO] - Training Epoch: 2/2, step 8326/16670 completed (loss: 0.10042380541563034, acc: 0.9677419066429138)
[2024-11-14 09:27:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:06][root][INFO] - Training Epoch: 2/2, step 8327/16670 completed (loss: 1.7681983709335327, acc: 0.6818181872367859)
[2024-11-14 09:27:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:06][root][INFO] - Training Epoch: 2/2, step 8328/16670 completed (loss: 0.2208356112241745, acc: 0.9696969985961914)
[2024-11-14 09:27:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:07][root][INFO] - Training Epoch: 2/2, step 8329/16670 completed (loss: 0.42410939931869507, acc: 0.9333333373069763)
[2024-11-14 09:27:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:07][root][INFO] - Training Epoch: 2/2, step 8330/16670 completed (loss: 0.2691080570220947, acc: 0.9259259104728699)
[2024-11-14 09:27:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:07][root][INFO] - Training Epoch: 2/2, step 8331/16670 completed (loss: 0.2206275761127472, acc: 0.9615384340286255)
[2024-11-14 09:27:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:27:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:28:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:29:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:30:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:31:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:32:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:33:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:34:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:35:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:36:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:37:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:45][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.8349, device='cuda:0') eval_epoch_loss=tensor(0.6070, device='cuda:0') eval_epoch_acc=tensor(0.8690, device='cuda:0')
[2024-11-14 09:38:45][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-14 09:38:45][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-14 09:38:46][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_8332_loss_0.6070092916488647/model.pt
[2024-11-14 09:38:46][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft directory
[2024-11-14 09:38:46][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.6070092916488647
[2024-11-14 09:38:46][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.8689873218536377
[2024-11-14 09:38:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:46][root][INFO] - Training Epoch: 2/2, step 8332/16670 completed (loss: 0.016295455396175385, acc: 1.0)
[2024-11-14 09:38:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:46][root][INFO] - Training Epoch: 2/2, step 8333/16670 completed (loss: 0.23259200155735016, acc: 0.9130434989929199)
[2024-11-14 09:38:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:47][root][INFO] - Training Epoch: 2/2, step 8334/16670 completed (loss: 0.13548396527767181, acc: 0.95652174949646)
[2024-11-14 09:38:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:47][root][INFO] - Training Epoch: 2/2, step 8335/16670 completed (loss: 0.4148239195346832, acc: 0.9264705777168274)
[2024-11-14 09:38:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:47][root][INFO] - Training Epoch: 2/2, step 8336/16670 completed (loss: 0.2819124162197113, acc: 0.9166666865348816)
[2024-11-14 09:38:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:48][root][INFO] - Training Epoch: 2/2, step 8337/16670 completed (loss: 0.4539014995098114, acc: 0.8918918967247009)
[2024-11-14 09:38:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:48][root][INFO] - Training Epoch: 2/2, step 8338/16670 completed (loss: 0.24675267934799194, acc: 0.9545454382896423)
[2024-11-14 09:38:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:48][root][INFO] - Training Epoch: 2/2, step 8339/16670 completed (loss: 0.09310899674892426, acc: 0.9523809552192688)
[2024-11-14 09:38:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:49][root][INFO] - Training Epoch: 2/2, step 8340/16670 completed (loss: 0.1279432326555252, acc: 1.0)
[2024-11-14 09:38:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:49][root][INFO] - Training Epoch: 2/2, step 8341/16670 completed (loss: 0.4537448585033417, acc: 0.9166666865348816)
[2024-11-14 09:38:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:49][root][INFO] - Training Epoch: 2/2, step 8342/16670 completed (loss: 0.32572701573371887, acc: 0.9464285969734192)
[2024-11-14 09:38:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:49][root][INFO] - Training Epoch: 2/2, step 8343/16670 completed (loss: 0.6211550831794739, acc: 0.8644067645072937)
[2024-11-14 09:38:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:50][root][INFO] - Training Epoch: 2/2, step 8344/16670 completed (loss: 0.36319848895072937, acc: 0.9117646813392639)
[2024-11-14 09:38:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:50][root][INFO] - Training Epoch: 2/2, step 8345/16670 completed (loss: 0.14880692958831787, acc: 0.95652174949646)
[2024-11-14 09:38:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:50][root][INFO] - Training Epoch: 2/2, step 8346/16670 completed (loss: 0.0465356670320034, acc: 1.0)
[2024-11-14 09:38:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:51][root][INFO] - Training Epoch: 2/2, step 8347/16670 completed (loss: 0.3194943964481354, acc: 0.9038461446762085)
[2024-11-14 09:38:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:51][root][INFO] - Training Epoch: 2/2, step 8348/16670 completed (loss: 0.38164451718330383, acc: 0.8333333134651184)
[2024-11-14 09:38:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:51][root][INFO] - Training Epoch: 2/2, step 8349/16670 completed (loss: 0.3869818449020386, acc: 0.9444444179534912)
[2024-11-14 09:38:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:52][root][INFO] - Training Epoch: 2/2, step 8350/16670 completed (loss: 0.5714738965034485, acc: 0.8510638475418091)
[2024-11-14 09:38:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:52][root][INFO] - Training Epoch: 2/2, step 8351/16670 completed (loss: 0.26459169387817383, acc: 0.9402984976768494)
[2024-11-14 09:38:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:53][root][INFO] - Training Epoch: 2/2, step 8352/16670 completed (loss: 0.23551316559314728, acc: 0.9459459185600281)
[2024-11-14 09:38:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:53][root][INFO] - Training Epoch: 2/2, step 8353/16670 completed (loss: 0.05578874796628952, acc: 1.0)
[2024-11-14 09:38:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:53][root][INFO] - Training Epoch: 2/2, step 8354/16670 completed (loss: 0.4604586362838745, acc: 0.9036144614219666)
[2024-11-14 09:38:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:54][root][INFO] - Training Epoch: 2/2, step 8355/16670 completed (loss: 0.14044784009456635, acc: 0.9411764740943909)
[2024-11-14 09:38:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:54][root][INFO] - Training Epoch: 2/2, step 8356/16670 completed (loss: 0.6614716649055481, acc: 0.8636363744735718)
[2024-11-14 09:38:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:54][root][INFO] - Training Epoch: 2/2, step 8357/16670 completed (loss: 0.5369449257850647, acc: 0.8979591727256775)
[2024-11-14 09:38:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:55][root][INFO] - Training Epoch: 2/2, step 8358/16670 completed (loss: 0.16575612127780914, acc: 0.9333333373069763)
[2024-11-14 09:38:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:55][root][INFO] - Training Epoch: 2/2, step 8359/16670 completed (loss: 0.09404803067445755, acc: 0.9750000238418579)
[2024-11-14 09:38:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:55][root][INFO] - Training Epoch: 2/2, step 8360/16670 completed (loss: 0.1850195825099945, acc: 0.9230769276618958)
[2024-11-14 09:38:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:56][root][INFO] - Training Epoch: 2/2, step 8361/16670 completed (loss: 0.17112034559249878, acc: 0.9411764740943909)
[2024-11-14 09:38:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:56][root][INFO] - Training Epoch: 2/2, step 8362/16670 completed (loss: 0.7763366103172302, acc: 0.8275862336158752)
[2024-11-14 09:38:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:56][root][INFO] - Training Epoch: 2/2, step 8363/16670 completed (loss: 0.5092248320579529, acc: 0.8913043737411499)
[2024-11-14 09:38:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:57][root][INFO] - Training Epoch: 2/2, step 8364/16670 completed (loss: 0.16974802315235138, acc: 0.9428571462631226)
[2024-11-14 09:38:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:57][root][INFO] - Training Epoch: 2/2, step 8365/16670 completed (loss: 0.4368079602718353, acc: 0.9130434989929199)
[2024-11-14 09:38:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:57][root][INFO] - Training Epoch: 2/2, step 8366/16670 completed (loss: 0.7778109312057495, acc: 0.800000011920929)
[2024-11-14 09:38:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:58][root][INFO] - Training Epoch: 2/2, step 8367/16670 completed (loss: 0.03204551711678505, acc: 1.0)
[2024-11-14 09:38:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:58][root][INFO] - Training Epoch: 2/2, step 8368/16670 completed (loss: 0.19145141541957855, acc: 0.9402984976768494)
[2024-11-14 09:38:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:58][root][INFO] - Training Epoch: 2/2, step 8369/16670 completed (loss: 0.1634874790906906, acc: 0.9545454382896423)
[2024-11-14 09:38:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:59][root][INFO] - Training Epoch: 2/2, step 8370/16670 completed (loss: 1.1956170797348022, acc: 0.8148148059844971)
[2024-11-14 09:38:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:59][root][INFO] - Training Epoch: 2/2, step 8371/16670 completed (loss: 0.052936919033527374, acc: 1.0)
[2024-11-14 09:38:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:38:59][root][INFO] - Training Epoch: 2/2, step 8372/16670 completed (loss: 0.1546480357646942, acc: 0.96875)
[2024-11-14 09:39:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:00][root][INFO] - Training Epoch: 2/2, step 8373/16670 completed (loss: 0.3273719251155853, acc: 0.8999999761581421)
[2024-11-14 09:39:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:00][root][INFO] - Training Epoch: 2/2, step 8374/16670 completed (loss: 0.269639253616333, acc: 0.9032257795333862)
[2024-11-14 09:39:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:01][root][INFO] - Training Epoch: 2/2, step 8375/16670 completed (loss: 0.4250170588493347, acc: 0.8666666746139526)
[2024-11-14 09:39:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:01][root][INFO] - Training Epoch: 2/2, step 8376/16670 completed (loss: 0.18409273028373718, acc: 0.9750000238418579)
[2024-11-14 09:39:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:01][root][INFO] - Training Epoch: 2/2, step 8377/16670 completed (loss: 0.32498493790626526, acc: 0.8852459192276001)
[2024-11-14 09:39:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:02][root][INFO] - Training Epoch: 2/2, step 8378/16670 completed (loss: 0.358766108751297, acc: 0.9142857193946838)
[2024-11-14 09:39:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:02][root][INFO] - Training Epoch: 2/2, step 8379/16670 completed (loss: 0.3490748107433319, acc: 0.8500000238418579)
[2024-11-14 09:39:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:02][root][INFO] - Training Epoch: 2/2, step 8380/16670 completed (loss: 0.34705621004104614, acc: 0.8974359035491943)
[2024-11-14 09:39:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:03][root][INFO] - Training Epoch: 2/2, step 8381/16670 completed (loss: 0.14133602380752563, acc: 0.9615384340286255)
[2024-11-14 09:39:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:03][root][INFO] - Training Epoch: 2/2, step 8382/16670 completed (loss: 0.49804186820983887, acc: 0.9534883499145508)
[2024-11-14 09:39:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:03][root][INFO] - Training Epoch: 2/2, step 8383/16670 completed (loss: 0.11469205468893051, acc: 0.9583333134651184)
[2024-11-14 09:39:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:03][root][INFO] - Training Epoch: 2/2, step 8384/16670 completed (loss: 0.803765058517456, acc: 0.8484848737716675)
[2024-11-14 09:39:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:04][root][INFO] - Training Epoch: 2/2, step 8385/16670 completed (loss: 0.7184348106384277, acc: 0.9047619104385376)
[2024-11-14 09:39:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:04][root][INFO] - Training Epoch: 2/2, step 8386/16670 completed (loss: 0.5501087307929993, acc: 0.8421052694320679)
[2024-11-14 09:39:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:04][root][INFO] - Training Epoch: 2/2, step 8387/16670 completed (loss: 0.7554904818534851, acc: 0.8533333539962769)
[2024-11-14 09:39:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:05][root][INFO] - Training Epoch: 2/2, step 8388/16670 completed (loss: 0.3638954162597656, acc: 0.8999999761581421)
[2024-11-14 09:39:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:05][root][INFO] - Training Epoch: 2/2, step 8389/16670 completed (loss: 0.02698608860373497, acc: 1.0)
[2024-11-14 09:39:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:06][root][INFO] - Training Epoch: 2/2, step 8390/16670 completed (loss: 0.1809997260570526, acc: 0.9729729890823364)
[2024-11-14 09:39:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:06][root][INFO] - Training Epoch: 2/2, step 8391/16670 completed (loss: 1.047533631324768, acc: 0.7333333492279053)
[2024-11-14 09:39:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:06][root][INFO] - Training Epoch: 2/2, step 8392/16670 completed (loss: 0.25433167815208435, acc: 0.9215686321258545)
[2024-11-14 09:39:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:06][root][INFO] - Training Epoch: 2/2, step 8393/16670 completed (loss: 0.4078333079814911, acc: 0.8983050584793091)
[2024-11-14 09:39:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:07][root][INFO] - Training Epoch: 2/2, step 8394/16670 completed (loss: 0.6483431458473206, acc: 0.8260869383811951)
[2024-11-14 09:39:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:07][root][INFO] - Training Epoch: 2/2, step 8395/16670 completed (loss: 0.2136891484260559, acc: 0.936170220375061)
[2024-11-14 09:39:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:07][root][INFO] - Training Epoch: 2/2, step 8396/16670 completed (loss: 0.6621111035346985, acc: 0.8636363744735718)
[2024-11-14 09:39:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:08][root][INFO] - Training Epoch: 2/2, step 8397/16670 completed (loss: 0.5895164608955383, acc: 0.9069767594337463)
[2024-11-14 09:39:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:08][root][INFO] - Training Epoch: 2/2, step 8398/16670 completed (loss: 0.3453506827354431, acc: 0.9387755393981934)
[2024-11-14 09:39:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:08][root][INFO] - Training Epoch: 2/2, step 8399/16670 completed (loss: 0.3655726909637451, acc: 0.9333333373069763)
[2024-11-14 09:39:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:09][root][INFO] - Training Epoch: 2/2, step 8400/16670 completed (loss: 0.43497246503829956, acc: 0.920634925365448)
[2024-11-14 09:39:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:09][root][INFO] - Training Epoch: 2/2, step 8401/16670 completed (loss: 0.12770028412342072, acc: 0.9666666388511658)
[2024-11-14 09:39:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:09][root][INFO] - Training Epoch: 2/2, step 8402/16670 completed (loss: 0.19305332005023956, acc: 0.9152542352676392)
[2024-11-14 09:39:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:10][root][INFO] - Training Epoch: 2/2, step 8403/16670 completed (loss: 0.9331932663917542, acc: 0.8125)
[2024-11-14 09:39:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:10][root][INFO] - Training Epoch: 2/2, step 8404/16670 completed (loss: 0.1943286955356598, acc: 0.9855072498321533)
[2024-11-14 09:39:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:11][root][INFO] - Training Epoch: 2/2, step 8405/16670 completed (loss: 0.4825458824634552, acc: 0.8493150472640991)
[2024-11-14 09:39:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:11][root][INFO] - Training Epoch: 2/2, step 8406/16670 completed (loss: 0.07248614728450775, acc: 0.9937499761581421)
[2024-11-14 09:39:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:11][root][INFO] - Training Epoch: 2/2, step 8407/16670 completed (loss: 0.2532398998737335, acc: 0.9368420839309692)
[2024-11-14 09:39:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:12][root][INFO] - Training Epoch: 2/2, step 8408/16670 completed (loss: 0.12613989412784576, acc: 0.976190447807312)
[2024-11-14 09:39:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:12][root][INFO] - Training Epoch: 2/2, step 8409/16670 completed (loss: 0.3300055265426636, acc: 0.910179615020752)
[2024-11-14 09:39:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:12][root][INFO] - Training Epoch: 2/2, step 8410/16670 completed (loss: 0.18019266426563263, acc: 0.9615384340286255)
[2024-11-14 09:39:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:13][root][INFO] - Training Epoch: 2/2, step 8411/16670 completed (loss: 0.19454415142536163, acc: 0.9583333134651184)
[2024-11-14 09:39:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:13][root][INFO] - Training Epoch: 2/2, step 8412/16670 completed (loss: 0.47658616304397583, acc: 0.8897058963775635)
[2024-11-14 09:39:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:13][root][INFO] - Training Epoch: 2/2, step 8413/16670 completed (loss: 0.20343121886253357, acc: 0.9568965435028076)
[2024-11-14 09:39:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:14][root][INFO] - Training Epoch: 2/2, step 8414/16670 completed (loss: 0.2511146068572998, acc: 0.929729700088501)
[2024-11-14 09:39:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:14][root][INFO] - Training Epoch: 2/2, step 8415/16670 completed (loss: 0.21830423176288605, acc: 0.9130434989929199)
[2024-11-14 09:39:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:14][root][INFO] - Training Epoch: 2/2, step 8416/16670 completed (loss: 0.25738346576690674, acc: 0.9360465407371521)
[2024-11-14 09:39:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:15][root][INFO] - Training Epoch: 2/2, step 8417/16670 completed (loss: 0.4304387867450714, acc: 0.907216489315033)
[2024-11-14 09:39:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:15][root][INFO] - Training Epoch: 2/2, step 8418/16670 completed (loss: 0.06423383206129074, acc: 0.9783549904823303)
[2024-11-14 09:39:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:15][root][INFO] - Training Epoch: 2/2, step 8419/16670 completed (loss: 0.355418860912323, acc: 0.9225806593894958)
[2024-11-14 09:39:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:16][root][INFO] - Training Epoch: 2/2, step 8420/16670 completed (loss: 0.1545911729335785, acc: 0.9378882050514221)
[2024-11-14 09:39:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:16][root][INFO] - Training Epoch: 2/2, step 8421/16670 completed (loss: 0.10738687962293625, acc: 0.9629629850387573)
[2024-11-14 09:39:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:16][root][INFO] - Training Epoch: 2/2, step 8422/16670 completed (loss: 0.2101275622844696, acc: 0.9519230723381042)
[2024-11-14 09:39:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:17][root][INFO] - Training Epoch: 2/2, step 8423/16670 completed (loss: 0.1354530304670334, acc: 0.9556313753128052)
[2024-11-14 09:39:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:17][root][INFO] - Training Epoch: 2/2, step 8424/16670 completed (loss: 0.18219102919101715, acc: 0.9605911374092102)
[2024-11-14 09:39:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:17][root][INFO] - Training Epoch: 2/2, step 8425/16670 completed (loss: 0.22656846046447754, acc: 0.934959352016449)
[2024-11-14 09:39:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:18][root][INFO] - Training Epoch: 2/2, step 8426/16670 completed (loss: 0.15246614813804626, acc: 0.9825581312179565)
[2024-11-14 09:39:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:18][root][INFO] - Training Epoch: 2/2, step 8427/16670 completed (loss: 0.24094125628471375, acc: 0.9548386931419373)
[2024-11-14 09:39:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:18][root][INFO] - Training Epoch: 2/2, step 8428/16670 completed (loss: 0.02766645886003971, acc: 1.0)
[2024-11-14 09:39:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:19][root][INFO] - Training Epoch: 2/2, step 8429/16670 completed (loss: 0.17428894340991974, acc: 0.9620689749717712)
[2024-11-14 09:39:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:19][root][INFO] - Training Epoch: 2/2, step 8430/16670 completed (loss: 0.1586228907108307, acc: 0.9670329689979553)
[2024-11-14 09:39:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:19][root][INFO] - Training Epoch: 2/2, step 8431/16670 completed (loss: 0.22752195596694946, acc: 0.9257143139839172)
[2024-11-14 09:39:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:20][root][INFO] - Training Epoch: 2/2, step 8432/16670 completed (loss: 0.3180825114250183, acc: 0.9215686321258545)
[2024-11-14 09:39:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:20][root][INFO] - Training Epoch: 2/2, step 8433/16670 completed (loss: 0.14142294228076935, acc: 0.9681817889213562)
[2024-11-14 09:39:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:20][root][INFO] - Training Epoch: 2/2, step 8434/16670 completed (loss: 0.11764663457870483, acc: 0.9713375568389893)
[2024-11-14 09:39:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:21][root][INFO] - Training Epoch: 2/2, step 8435/16670 completed (loss: 0.0346979983150959, acc: 0.9932885766029358)
[2024-11-14 09:39:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:21][root][INFO] - Training Epoch: 2/2, step 8436/16670 completed (loss: 0.15359564125537872, acc: 0.9405940771102905)
[2024-11-14 09:39:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:21][root][INFO] - Training Epoch: 2/2, step 8437/16670 completed (loss: 0.10217060893774033, acc: 0.9865771532058716)
[2024-11-14 09:39:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:22][root][INFO] - Training Epoch: 2/2, step 8438/16670 completed (loss: 0.12988600134849548, acc: 0.9689440727233887)
[2024-11-14 09:39:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:22][root][INFO] - Training Epoch: 2/2, step 8439/16670 completed (loss: 0.07942168414592743, acc: 0.983146071434021)
[2024-11-14 09:39:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:22][root][INFO] - Training Epoch: 2/2, step 8440/16670 completed (loss: 0.06282578408718109, acc: 0.9795918464660645)
[2024-11-14 09:39:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:23][root][INFO] - Training Epoch: 2/2, step 8441/16670 completed (loss: 0.15165206789970398, acc: 0.9320388436317444)
[2024-11-14 09:39:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:23][root][INFO] - Training Epoch: 2/2, step 8442/16670 completed (loss: 0.1265794038772583, acc: 0.9750000238418579)
[2024-11-14 09:39:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:23][root][INFO] - Training Epoch: 2/2, step 8443/16670 completed (loss: 0.1746373176574707, acc: 0.948051929473877)
[2024-11-14 09:39:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:24][root][INFO] - Training Epoch: 2/2, step 8444/16670 completed (loss: 0.20056216418743134, acc: 0.9534883499145508)
[2024-11-14 09:39:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:24][root][INFO] - Training Epoch: 2/2, step 8445/16670 completed (loss: 0.3626183271408081, acc: 0.9330143332481384)
[2024-11-14 09:39:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:24][root][INFO] - Training Epoch: 2/2, step 8446/16670 completed (loss: 0.17946548759937286, acc: 0.9428571462631226)
[2024-11-14 09:39:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:25][root][INFO] - Training Epoch: 2/2, step 8447/16670 completed (loss: 0.1798115223646164, acc: 0.9604519605636597)
[2024-11-14 09:39:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:25][root][INFO] - Training Epoch: 2/2, step 8448/16670 completed (loss: 0.2631913423538208, acc: 0.9438202381134033)
[2024-11-14 09:39:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:25][root][INFO] - Training Epoch: 2/2, step 8449/16670 completed (loss: 0.2559413015842438, acc: 0.914893627166748)
[2024-11-14 09:39:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:26][root][INFO] - Training Epoch: 2/2, step 8450/16670 completed (loss: 0.09620603173971176, acc: 0.9693877696990967)
[2024-11-14 09:39:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:26][root][INFO] - Training Epoch: 2/2, step 8451/16670 completed (loss: 0.2025124877691269, acc: 0.9377431869506836)
[2024-11-14 09:39:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:26][root][INFO] - Training Epoch: 2/2, step 8452/16670 completed (loss: 0.2144176959991455, acc: 0.93359375)
[2024-11-14 09:39:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:27][root][INFO] - Training Epoch: 2/2, step 8453/16670 completed (loss: 0.12020714581012726, acc: 0.9735682606697083)
[2024-11-14 09:39:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:27][root][INFO] - Training Epoch: 2/2, step 8454/16670 completed (loss: 0.19904905557632446, acc: 0.9605911374092102)
[2024-11-14 09:39:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:28][root][INFO] - Training Epoch: 2/2, step 8455/16670 completed (loss: 0.22101128101348877, acc: 0.9446494579315186)
[2024-11-14 09:39:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:28][root][INFO] - Training Epoch: 2/2, step 8456/16670 completed (loss: 0.12605027854442596, acc: 0.9532710313796997)
[2024-11-14 09:39:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:28][root][INFO] - Training Epoch: 2/2, step 8457/16670 completed (loss: 0.1559303104877472, acc: 0.9313725233078003)
[2024-11-14 09:39:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:29][root][INFO] - Training Epoch: 2/2, step 8458/16670 completed (loss: 0.348411500453949, acc: 0.9103448390960693)
[2024-11-14 09:39:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:29][root][INFO] - Training Epoch: 2/2, step 8459/16670 completed (loss: 0.2447277009487152, acc: 0.9456067085266113)
[2024-11-14 09:39:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:29][root][INFO] - Training Epoch: 2/2, step 8460/16670 completed (loss: 0.31498846411705017, acc: 0.8928571343421936)
[2024-11-14 09:39:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:30][root][INFO] - Training Epoch: 2/2, step 8461/16670 completed (loss: 0.15549781918525696, acc: 0.9578947424888611)
[2024-11-14 09:39:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:30][root][INFO] - Training Epoch: 2/2, step 8462/16670 completed (loss: 0.4710961878299713, acc: 0.862500011920929)
[2024-11-14 09:39:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:30][root][INFO] - Training Epoch: 2/2, step 8463/16670 completed (loss: 0.05274955928325653, acc: 0.9823529124259949)
[2024-11-14 09:39:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:31][root][INFO] - Training Epoch: 2/2, step 8464/16670 completed (loss: 0.16564740240573883, acc: 0.9430894255638123)
[2024-11-14 09:39:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:31][root][INFO] - Training Epoch: 2/2, step 8465/16670 completed (loss: 0.3016507923603058, acc: 0.9059829115867615)
[2024-11-14 09:39:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:31][root][INFO] - Training Epoch: 2/2, step 8466/16670 completed (loss: 0.2077750861644745, acc: 0.955974817276001)
[2024-11-14 09:39:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:32][root][INFO] - Training Epoch: 2/2, step 8467/16670 completed (loss: 0.22435612976551056, acc: 0.9185185432434082)
[2024-11-14 09:39:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:32][root][INFO] - Training Epoch: 2/2, step 8468/16670 completed (loss: 0.14771221578121185, acc: 0.9428571462631226)
[2024-11-14 09:39:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:32][root][INFO] - Training Epoch: 2/2, step 8469/16670 completed (loss: 0.07497003674507141, acc: 0.9793281555175781)
[2024-11-14 09:39:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:33][root][INFO] - Training Epoch: 2/2, step 8470/16670 completed (loss: 0.18634389340877533, acc: 0.9489796161651611)
[2024-11-14 09:39:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:33][root][INFO] - Training Epoch: 2/2, step 8471/16670 completed (loss: 0.08043301105499268, acc: 0.9825581312179565)
[2024-11-14 09:39:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:33][root][INFO] - Training Epoch: 2/2, step 8472/16670 completed (loss: 0.1574224829673767, acc: 0.949367105960846)
[2024-11-14 09:39:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:34][root][INFO] - Training Epoch: 2/2, step 8473/16670 completed (loss: 0.1180686503648758, acc: 0.9753086566925049)
[2024-11-14 09:39:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:34][root][INFO] - Training Epoch: 2/2, step 8474/16670 completed (loss: 0.18624526262283325, acc: 0.9419087171554565)
[2024-11-14 09:39:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:34][root][INFO] - Training Epoch: 2/2, step 8475/16670 completed (loss: 0.1471039056777954, acc: 0.9464285969734192)
[2024-11-14 09:39:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:35][root][INFO] - Training Epoch: 2/2, step 8476/16670 completed (loss: 0.18411606550216675, acc: 0.9579831957817078)
[2024-11-14 09:39:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:35][root][INFO] - Training Epoch: 2/2, step 8477/16670 completed (loss: 0.17687341570854187, acc: 0.9382022619247437)
[2024-11-14 09:39:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:35][root][INFO] - Training Epoch: 2/2, step 8478/16670 completed (loss: 0.25329363346099854, acc: 0.9193548560142517)
[2024-11-14 09:39:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:36][root][INFO] - Training Epoch: 2/2, step 8479/16670 completed (loss: 0.1426083743572235, acc: 0.9658119678497314)
[2024-11-14 09:39:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:36][root][INFO] - Training Epoch: 2/2, step 8480/16670 completed (loss: 0.23619496822357178, acc: 0.9328621625900269)
[2024-11-14 09:39:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:36][root][INFO] - Training Epoch: 2/2, step 8481/16670 completed (loss: 0.1476462483406067, acc: 0.9649122953414917)
[2024-11-14 09:39:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:37][root][INFO] - Training Epoch: 2/2, step 8482/16670 completed (loss: 0.24139580130577087, acc: 0.933920681476593)
[2024-11-14 09:39:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:37][root][INFO] - Training Epoch: 2/2, step 8483/16670 completed (loss: 0.11136343330144882, acc: 0.9473684430122375)
[2024-11-14 09:39:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:38][root][INFO] - Training Epoch: 2/2, step 8484/16670 completed (loss: 0.07425622642040253, acc: 0.9810126423835754)
[2024-11-14 09:39:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:38][root][INFO] - Training Epoch: 2/2, step 8485/16670 completed (loss: 0.15356218814849854, acc: 0.9586777091026306)
[2024-11-14 09:39:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:38][root][INFO] - Training Epoch: 2/2, step 8486/16670 completed (loss: 0.13860994577407837, acc: 0.9677419066429138)
[2024-11-14 09:39:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:39][root][INFO] - Training Epoch: 2/2, step 8487/16670 completed (loss: 0.2966095805168152, acc: 0.936170220375061)
[2024-11-14 09:39:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:39][root][INFO] - Training Epoch: 2/2, step 8488/16670 completed (loss: 0.12545576691627502, acc: 0.9569377899169922)
[2024-11-14 09:39:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:39][root][INFO] - Training Epoch: 2/2, step 8489/16670 completed (loss: 0.32641541957855225, acc: 0.9210526347160339)
[2024-11-14 09:39:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:40][root][INFO] - Training Epoch: 2/2, step 8490/16670 completed (loss: 0.2058805376291275, acc: 0.9333333373069763)
[2024-11-14 09:39:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:40][root][INFO] - Training Epoch: 2/2, step 8491/16670 completed (loss: 0.2662525475025177, acc: 0.9276315569877625)
[2024-11-14 09:39:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:40][root][INFO] - Training Epoch: 2/2, step 8492/16670 completed (loss: 0.11152157187461853, acc: 0.9576271176338196)
[2024-11-14 09:39:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:41][root][INFO] - Training Epoch: 2/2, step 8493/16670 completed (loss: 0.12562309205532074, acc: 0.9589040875434875)
[2024-11-14 09:39:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:41][root][INFO] - Training Epoch: 2/2, step 8494/16670 completed (loss: 0.23868328332901, acc: 0.9278846383094788)
[2024-11-14 09:39:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:41][root][INFO] - Training Epoch: 2/2, step 8495/16670 completed (loss: 0.24854712188243866, acc: 0.9431818127632141)
[2024-11-14 09:39:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:42][root][INFO] - Training Epoch: 2/2, step 8496/16670 completed (loss: 0.17382311820983887, acc: 0.9458333253860474)
[2024-11-14 09:39:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:42][root][INFO] - Training Epoch: 2/2, step 8497/16670 completed (loss: 0.16378243267536163, acc: 0.9357143044471741)
[2024-11-14 09:39:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:43][root][INFO] - Training Epoch: 2/2, step 8498/16670 completed (loss: 0.13976430892944336, acc: 0.961904764175415)
[2024-11-14 09:39:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:43][root][INFO] - Training Epoch: 2/2, step 8499/16670 completed (loss: 0.36753395199775696, acc: 0.898876428604126)
[2024-11-14 09:39:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:43][root][INFO] - Training Epoch: 2/2, step 8500/16670 completed (loss: 0.6219801306724548, acc: 0.8181818127632141)
[2024-11-14 09:39:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:44][root][INFO] - Training Epoch: 2/2, step 8501/16670 completed (loss: 0.3663523495197296, acc: 0.918367326259613)
[2024-11-14 09:39:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:44][root][INFO] - Training Epoch: 2/2, step 8502/16670 completed (loss: 1.1104649305343628, acc: 0.7307692170143127)
[2024-11-14 09:39:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:44][root][INFO] - Training Epoch: 2/2, step 8503/16670 completed (loss: 0.7593241930007935, acc: 0.8243243098258972)
[2024-11-14 09:39:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:45][root][INFO] - Training Epoch: 2/2, step 8504/16670 completed (loss: 0.8815041184425354, acc: 0.800000011920929)
[2024-11-14 09:39:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:45][root][INFO] - Training Epoch: 2/2, step 8505/16670 completed (loss: 0.4804340600967407, acc: 0.8545454740524292)
[2024-11-14 09:39:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:45][root][INFO] - Training Epoch: 2/2, step 8506/16670 completed (loss: 0.15606269240379333, acc: 0.9534883499145508)
[2024-11-14 09:39:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:46][root][INFO] - Training Epoch: 2/2, step 8507/16670 completed (loss: 0.3838813304901123, acc: 0.9399999976158142)
[2024-11-14 09:39:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:46][root][INFO] - Training Epoch: 2/2, step 8508/16670 completed (loss: 0.6506496071815491, acc: 0.8653846383094788)
[2024-11-14 09:39:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:46][root][INFO] - Training Epoch: 2/2, step 8509/16670 completed (loss: 0.40774425864219666, acc: 0.8888888955116272)
[2024-11-14 09:39:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:47][root][INFO] - Training Epoch: 2/2, step 8510/16670 completed (loss: 0.28795334696769714, acc: 0.914893627166748)
[2024-11-14 09:39:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:47][root][INFO] - Training Epoch: 2/2, step 8511/16670 completed (loss: 0.7561701536178589, acc: 0.8627451062202454)
[2024-11-14 09:39:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:47][root][INFO] - Training Epoch: 2/2, step 8512/16670 completed (loss: 0.6038557291030884, acc: 0.8604651093482971)
[2024-11-14 09:39:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:48][root][INFO] - Training Epoch: 2/2, step 8513/16670 completed (loss: 0.17525407671928406, acc: 0.9482758641242981)
[2024-11-14 09:39:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:48][root][INFO] - Training Epoch: 2/2, step 8514/16670 completed (loss: 0.6844180226325989, acc: 0.8285714387893677)
[2024-11-14 09:39:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:48][root][INFO] - Training Epoch: 2/2, step 8515/16670 completed (loss: 0.6273307204246521, acc: 0.8666666746139526)
[2024-11-14 09:39:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:49][root][INFO] - Training Epoch: 2/2, step 8516/16670 completed (loss: 0.5886898040771484, acc: 0.8857142925262451)
[2024-11-14 09:39:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:49][root][INFO] - Training Epoch: 2/2, step 8517/16670 completed (loss: 0.4067658483982086, acc: 0.9247311949729919)
[2024-11-14 09:39:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:50][root][INFO] - Training Epoch: 2/2, step 8518/16670 completed (loss: 0.4993780255317688, acc: 0.8787878751754761)
[2024-11-14 09:39:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:50][root][INFO] - Training Epoch: 2/2, step 8519/16670 completed (loss: 0.6271046996116638, acc: 0.875)
[2024-11-14 09:39:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:50][root][INFO] - Training Epoch: 2/2, step 8520/16670 completed (loss: 0.8305390477180481, acc: 0.8333333134651184)
[2024-11-14 09:39:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:50][root][INFO] - Training Epoch: 2/2, step 8521/16670 completed (loss: 0.504780113697052, acc: 0.8805969953536987)
[2024-11-14 09:39:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:51][root][INFO] - Training Epoch: 2/2, step 8522/16670 completed (loss: 0.9000046253204346, acc: 0.7659574747085571)
[2024-11-14 09:39:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:51][root][INFO] - Training Epoch: 2/2, step 8523/16670 completed (loss: 0.26567137241363525, acc: 0.9411764740943909)
[2024-11-14 09:39:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:52][root][INFO] - Training Epoch: 2/2, step 8524/16670 completed (loss: 0.7641410231590271, acc: 0.8823529481887817)
[2024-11-14 09:39:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:52][root][INFO] - Training Epoch: 2/2, step 8525/16670 completed (loss: 0.5911681652069092, acc: 0.8666666746139526)
[2024-11-14 09:39:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:52][root][INFO] - Training Epoch: 2/2, step 8526/16670 completed (loss: 0.47423213720321655, acc: 0.8620689511299133)
[2024-11-14 09:39:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:53][root][INFO] - Training Epoch: 2/2, step 8527/16670 completed (loss: 0.3960527181625366, acc: 0.8936170339584351)
[2024-11-14 09:39:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:53][root][INFO] - Training Epoch: 2/2, step 8528/16670 completed (loss: 0.4500897228717804, acc: 0.8888888955116272)
[2024-11-14 09:39:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:53][root][INFO] - Training Epoch: 2/2, step 8529/16670 completed (loss: 0.38627007603645325, acc: 0.939393937587738)
[2024-11-14 09:39:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:53][root][INFO] - Training Epoch: 2/2, step 8530/16670 completed (loss: 0.21868246793746948, acc: 0.9433962106704712)
[2024-11-14 09:39:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:54][root][INFO] - Training Epoch: 2/2, step 8531/16670 completed (loss: 0.25370341539382935, acc: 0.9399999976158142)
[2024-11-14 09:39:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:54][root][INFO] - Training Epoch: 2/2, step 8532/16670 completed (loss: 0.7745258808135986, acc: 0.824999988079071)
[2024-11-14 09:39:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:54][root][INFO] - Training Epoch: 2/2, step 8533/16670 completed (loss: 0.627716064453125, acc: 0.8676470518112183)
[2024-11-14 09:39:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:55][root][INFO] - Training Epoch: 2/2, step 8534/16670 completed (loss: 1.2035231590270996, acc: 0.738095223903656)
[2024-11-14 09:39:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:55][root][INFO] - Training Epoch: 2/2, step 8535/16670 completed (loss: 0.5313734412193298, acc: 0.8541666865348816)
[2024-11-14 09:39:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:55][root][INFO] - Training Epoch: 2/2, step 8536/16670 completed (loss: 0.24854563176631927, acc: 0.9591836929321289)
[2024-11-14 09:39:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:56][root][INFO] - Training Epoch: 2/2, step 8537/16670 completed (loss: 0.26474902033805847, acc: 0.9104477763175964)
[2024-11-14 09:39:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:56][root][INFO] - Training Epoch: 2/2, step 8538/16670 completed (loss: 0.26647478342056274, acc: 0.9444444179534912)
[2024-11-14 09:39:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:56][root][INFO] - Training Epoch: 2/2, step 8539/16670 completed (loss: 0.6040363907814026, acc: 0.8658536672592163)
[2024-11-14 09:39:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:57][root][INFO] - Training Epoch: 2/2, step 8540/16670 completed (loss: 0.605875551700592, acc: 0.8727272748947144)
[2024-11-14 09:39:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:57][root][INFO] - Training Epoch: 2/2, step 8541/16670 completed (loss: 0.802540123462677, acc: 0.9074074029922485)
[2024-11-14 09:39:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:57][root][INFO] - Training Epoch: 2/2, step 8542/16670 completed (loss: 0.2787325084209442, acc: 0.9538461565971375)
[2024-11-14 09:39:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:58][root][INFO] - Training Epoch: 2/2, step 8543/16670 completed (loss: 0.4825257360935211, acc: 0.8636363744735718)
[2024-11-14 09:39:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:58][root][INFO] - Training Epoch: 2/2, step 8544/16670 completed (loss: 0.5824738144874573, acc: 0.8709677457809448)
[2024-11-14 09:39:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:59][root][INFO] - Training Epoch: 2/2, step 8545/16670 completed (loss: 0.4436561167240143, acc: 0.9210526347160339)
[2024-11-14 09:39:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:59][root][INFO] - Training Epoch: 2/2, step 8546/16670 completed (loss: 0.16777853667736053, acc: 0.9607843160629272)
[2024-11-14 09:39:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:39:59][root][INFO] - Training Epoch: 2/2, step 8547/16670 completed (loss: 0.45001906156539917, acc: 0.8799999952316284)
[2024-11-14 09:39:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:00][root][INFO] - Training Epoch: 2/2, step 8548/16670 completed (loss: 1.261763095855713, acc: 0.6896551847457886)
[2024-11-14 09:40:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:00][root][INFO] - Training Epoch: 2/2, step 8549/16670 completed (loss: 0.18816757202148438, acc: 0.9756097793579102)
[2024-11-14 09:40:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:00][root][INFO] - Training Epoch: 2/2, step 8550/16670 completed (loss: 0.6317223310470581, acc: 0.8055555820465088)
[2024-11-14 09:40:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:01][root][INFO] - Training Epoch: 2/2, step 8551/16670 completed (loss: 0.2813397943973541, acc: 0.9245283007621765)
[2024-11-14 09:40:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:01][root][INFO] - Training Epoch: 2/2, step 8552/16670 completed (loss: 0.16468371450901031, acc: 0.9726027250289917)
[2024-11-14 09:40:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:01][root][INFO] - Training Epoch: 2/2, step 8553/16670 completed (loss: 0.1382748782634735, acc: 0.9615384340286255)
[2024-11-14 09:40:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:02][root][INFO] - Training Epoch: 2/2, step 8554/16670 completed (loss: 0.569514274597168, acc: 0.8918918967247009)
[2024-11-14 09:40:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:02][root][INFO] - Training Epoch: 2/2, step 8555/16670 completed (loss: 0.8653762340545654, acc: 0.8611111044883728)
[2024-11-14 09:40:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:02][root][INFO] - Training Epoch: 2/2, step 8556/16670 completed (loss: 0.14920276403427124, acc: 0.9629629850387573)
[2024-11-14 09:40:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:03][root][INFO] - Training Epoch: 2/2, step 8557/16670 completed (loss: 0.2102471888065338, acc: 0.9701492786407471)
[2024-11-14 09:40:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:03][root][INFO] - Training Epoch: 2/2, step 8558/16670 completed (loss: 0.4657433032989502, acc: 0.9032257795333862)
[2024-11-14 09:40:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:04][root][INFO] - Training Epoch: 2/2, step 8559/16670 completed (loss: 0.6472270488739014, acc: 0.8387096524238586)
[2024-11-14 09:40:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:04][root][INFO] - Training Epoch: 2/2, step 8560/16670 completed (loss: 0.662745475769043, acc: 0.8928571343421936)
[2024-11-14 09:40:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:04][root][INFO] - Training Epoch: 2/2, step 8561/16670 completed (loss: 0.634635329246521, acc: 0.8615384697914124)
[2024-11-14 09:40:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:05][root][INFO] - Training Epoch: 2/2, step 8562/16670 completed (loss: 0.34153494238853455, acc: 0.8846153616905212)
[2024-11-14 09:40:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:05][root][INFO] - Training Epoch: 2/2, step 8563/16670 completed (loss: 0.41620200872421265, acc: 0.9210526347160339)
[2024-11-14 09:40:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:05][root][INFO] - Training Epoch: 2/2, step 8564/16670 completed (loss: 0.42238911986351013, acc: 0.9433962106704712)
[2024-11-14 09:40:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:06][root][INFO] - Training Epoch: 2/2, step 8565/16670 completed (loss: 0.8009933829307556, acc: 0.8666666746139526)
[2024-11-14 09:40:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:06][root][INFO] - Training Epoch: 2/2, step 8566/16670 completed (loss: 0.7239030599594116, acc: 0.7857142686843872)
[2024-11-14 09:40:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:06][root][INFO] - Training Epoch: 2/2, step 8567/16670 completed (loss: 0.4554055333137512, acc: 0.9130434989929199)
[2024-11-14 09:40:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:06][root][INFO] - Training Epoch: 2/2, step 8568/16670 completed (loss: 0.628361165523529, acc: 0.8199999928474426)
[2024-11-14 09:40:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:07][root][INFO] - Training Epoch: 2/2, step 8569/16670 completed (loss: 0.5767625570297241, acc: 0.8461538553237915)
[2024-11-14 09:40:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:07][root][INFO] - Training Epoch: 2/2, step 8570/16670 completed (loss: 0.12325911968946457, acc: 0.9722222089767456)
[2024-11-14 09:40:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:07][root][INFO] - Training Epoch: 2/2, step 8571/16670 completed (loss: 0.488494336605072, acc: 0.8999999761581421)
[2024-11-14 09:40:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:08][root][INFO] - Training Epoch: 2/2, step 8572/16670 completed (loss: 0.42341554164886475, acc: 0.9166666865348816)
[2024-11-14 09:40:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:08][root][INFO] - Training Epoch: 2/2, step 8573/16670 completed (loss: 0.6866083145141602, acc: 0.843137264251709)
[2024-11-14 09:40:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:08][root][INFO] - Training Epoch: 2/2, step 8574/16670 completed (loss: 0.138956680893898, acc: 0.9824561476707458)
[2024-11-14 09:40:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:09][root][INFO] - Training Epoch: 2/2, step 8575/16670 completed (loss: 0.42109158635139465, acc: 0.9268292784690857)
[2024-11-14 09:40:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:09][root][INFO] - Training Epoch: 2/2, step 8576/16670 completed (loss: 0.04769119992852211, acc: 1.0)
[2024-11-14 09:40:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:09][root][INFO] - Training Epoch: 2/2, step 8577/16670 completed (loss: 0.30194422602653503, acc: 0.8961039185523987)
[2024-11-14 09:40:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:10][root][INFO] - Training Epoch: 2/2, step 8578/16670 completed (loss: 0.42723336815834045, acc: 0.8867924809455872)
[2024-11-14 09:40:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:10][root][INFO] - Training Epoch: 2/2, step 8579/16670 completed (loss: 0.41002601385116577, acc: 0.8852459192276001)
[2024-11-14 09:40:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:10][root][INFO] - Training Epoch: 2/2, step 8580/16670 completed (loss: 0.38279563188552856, acc: 0.859649121761322)
[2024-11-14 09:40:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:11][root][INFO] - Training Epoch: 2/2, step 8581/16670 completed (loss: 0.629004716873169, acc: 0.8979591727256775)
[2024-11-14 09:40:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:11][root][INFO] - Training Epoch: 2/2, step 8582/16670 completed (loss: 0.26750651001930237, acc: 0.9473684430122375)
[2024-11-14 09:40:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:11][root][INFO] - Training Epoch: 2/2, step 8583/16670 completed (loss: 0.14721061289310455, acc: 1.0)
[2024-11-14 09:40:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:12][root][INFO] - Training Epoch: 2/2, step 8584/16670 completed (loss: 0.35869860649108887, acc: 0.920634925365448)
[2024-11-14 09:40:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:12][root][INFO] - Training Epoch: 2/2, step 8585/16670 completed (loss: 0.4546934962272644, acc: 0.9200000166893005)
[2024-11-14 09:40:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:12][root][INFO] - Training Epoch: 2/2, step 8586/16670 completed (loss: 0.05171717330813408, acc: 0.978723406791687)
[2024-11-14 09:40:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:13][root][INFO] - Training Epoch: 2/2, step 8587/16670 completed (loss: 0.46772781014442444, acc: 0.8809523582458496)
[2024-11-14 09:40:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:13][root][INFO] - Training Epoch: 2/2, step 8588/16670 completed (loss: 0.5074961185455322, acc: 0.8653846383094788)
[2024-11-14 09:40:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:13][root][INFO] - Training Epoch: 2/2, step 8589/16670 completed (loss: 0.49735215306282043, acc: 0.8888888955116272)
[2024-11-14 09:40:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:14][root][INFO] - Training Epoch: 2/2, step 8590/16670 completed (loss: 0.508826732635498, acc: 0.8409090638160706)
[2024-11-14 09:40:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:14][root][INFO] - Training Epoch: 2/2, step 8591/16670 completed (loss: 0.9656965732574463, acc: 0.875)
[2024-11-14 09:40:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:14][root][INFO] - Training Epoch: 2/2, step 8592/16670 completed (loss: 0.11692085862159729, acc: 0.9696969985961914)
[2024-11-14 09:40:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:15][root][INFO] - Training Epoch: 2/2, step 8593/16670 completed (loss: 0.15614551305770874, acc: 0.9599999785423279)
[2024-11-14 09:40:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:15][root][INFO] - Training Epoch: 2/2, step 8594/16670 completed (loss: 0.21715961396694183, acc: 0.9615384340286255)
[2024-11-14 09:40:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:16][root][INFO] - Training Epoch: 2/2, step 8595/16670 completed (loss: 0.4332984983921051, acc: 0.9473684430122375)
[2024-11-14 09:40:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:16][root][INFO] - Training Epoch: 2/2, step 8596/16670 completed (loss: 0.42513710260391235, acc: 0.8333333134651184)
[2024-11-14 09:40:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:16][root][INFO] - Training Epoch: 2/2, step 8597/16670 completed (loss: 0.6404213309288025, acc: 0.774193525314331)
[2024-11-14 09:40:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:16][root][INFO] - Training Epoch: 2/2, step 8598/16670 completed (loss: 0.3508237302303314, acc: 0.90625)
[2024-11-14 09:40:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:17][root][INFO] - Training Epoch: 2/2, step 8599/16670 completed (loss: 0.79507976770401, acc: 0.8219178318977356)
[2024-11-14 09:40:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:17][root][INFO] - Training Epoch: 2/2, step 8600/16670 completed (loss: 0.22466102242469788, acc: 0.9375)
[2024-11-14 09:40:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:17][root][INFO] - Training Epoch: 2/2, step 8601/16670 completed (loss: 0.44633325934410095, acc: 0.8717948794364929)
[2024-11-14 09:40:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:18][root][INFO] - Training Epoch: 2/2, step 8602/16670 completed (loss: 0.4672035872936249, acc: 0.9230769276618958)
[2024-11-14 09:40:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:18][root][INFO] - Training Epoch: 2/2, step 8603/16670 completed (loss: 1.0062487125396729, acc: 0.7592592835426331)
[2024-11-14 09:40:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:18][root][INFO] - Training Epoch: 2/2, step 8604/16670 completed (loss: 0.33195585012435913, acc: 0.9090909361839294)
[2024-11-14 09:40:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:19][root][INFO] - Training Epoch: 2/2, step 8605/16670 completed (loss: 0.44240373373031616, acc: 0.8961039185523987)
[2024-11-14 09:40:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:19][root][INFO] - Training Epoch: 2/2, step 8606/16670 completed (loss: 0.4215683937072754, acc: 0.892307698726654)
[2024-11-14 09:40:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:19][root][INFO] - Training Epoch: 2/2, step 8607/16670 completed (loss: 0.4687316119670868, acc: 0.8723404407501221)
[2024-11-14 09:40:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:20][root][INFO] - Training Epoch: 2/2, step 8608/16670 completed (loss: 0.17616985738277435, acc: 0.9750000238418579)
[2024-11-14 09:40:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:20][root][INFO] - Training Epoch: 2/2, step 8609/16670 completed (loss: 0.3939799964427948, acc: 0.9130434989929199)
[2024-11-14 09:40:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:21][root][INFO] - Training Epoch: 2/2, step 8610/16670 completed (loss: 0.09010825306177139, acc: 0.978723406791687)
[2024-11-14 09:40:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:21][root][INFO] - Training Epoch: 2/2, step 8611/16670 completed (loss: 0.139079749584198, acc: 0.9629629850387573)
[2024-11-14 09:40:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:21][root][INFO] - Training Epoch: 2/2, step 8612/16670 completed (loss: 0.4265839457511902, acc: 0.8873239159584045)
[2024-11-14 09:40:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:22][root][INFO] - Training Epoch: 2/2, step 8613/16670 completed (loss: 0.12605014443397522, acc: 0.9824561476707458)
[2024-11-14 09:40:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:22][root][INFO] - Training Epoch: 2/2, step 8614/16670 completed (loss: 0.226104736328125, acc: 0.9642857313156128)
[2024-11-14 09:40:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:22][root][INFO] - Training Epoch: 2/2, step 8615/16670 completed (loss: 0.22702407836914062, acc: 0.9166666865348816)
[2024-11-14 09:40:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:23][root][INFO] - Training Epoch: 2/2, step 8616/16670 completed (loss: 0.5316828489303589, acc: 0.8641975522041321)
[2024-11-14 09:40:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:23][root][INFO] - Training Epoch: 2/2, step 8617/16670 completed (loss: 0.3839265704154968, acc: 0.9354838728904724)
[2024-11-14 09:40:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:23][root][INFO] - Training Epoch: 2/2, step 8618/16670 completed (loss: 0.1405886858701706, acc: 0.9268292784690857)
[2024-11-14 09:40:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:24][root][INFO] - Training Epoch: 2/2, step 8619/16670 completed (loss: 0.5411553978919983, acc: 0.8787878751754761)
[2024-11-14 09:40:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:24][root][INFO] - Training Epoch: 2/2, step 8620/16670 completed (loss: 0.5145952105522156, acc: 0.8970588445663452)
[2024-11-14 09:40:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:24][root][INFO] - Training Epoch: 2/2, step 8621/16670 completed (loss: 0.5431036353111267, acc: 0.8636363744735718)
[2024-11-14 09:40:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:25][root][INFO] - Training Epoch: 2/2, step 8622/16670 completed (loss: 0.24447572231292725, acc: 0.9322034120559692)
[2024-11-14 09:40:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:25][root][INFO] - Training Epoch: 2/2, step 8623/16670 completed (loss: 0.4932405352592468, acc: 0.925000011920929)
[2024-11-14 09:40:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:25][root][INFO] - Training Epoch: 2/2, step 8624/16670 completed (loss: 0.19961851835250854, acc: 0.9756097793579102)
[2024-11-14 09:40:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:25][root][INFO] - Training Epoch: 2/2, step 8625/16670 completed (loss: 0.15480726957321167, acc: 0.95652174949646)
[2024-11-14 09:40:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:26][root][INFO] - Training Epoch: 2/2, step 8626/16670 completed (loss: 0.22778664529323578, acc: 0.9591836929321289)
[2024-11-14 09:40:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:26][root][INFO] - Training Epoch: 2/2, step 8627/16670 completed (loss: 0.7396146655082703, acc: 0.8545454740524292)
[2024-11-14 09:40:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:26][root][INFO] - Training Epoch: 2/2, step 8628/16670 completed (loss: 0.31727465987205505, acc: 0.9277108311653137)
[2024-11-14 09:40:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:27][root][INFO] - Training Epoch: 2/2, step 8629/16670 completed (loss: 0.35668379068374634, acc: 0.9047619104385376)
[2024-11-14 09:40:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:27][root][INFO] - Training Epoch: 2/2, step 8630/16670 completed (loss: 0.33136260509490967, acc: 0.8999999761581421)
[2024-11-14 09:40:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:27][root][INFO] - Training Epoch: 2/2, step 8631/16670 completed (loss: 0.4347294569015503, acc: 0.9054054021835327)
[2024-11-14 09:40:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:28][root][INFO] - Training Epoch: 2/2, step 8632/16670 completed (loss: 0.5561153292655945, acc: 0.8545454740524292)
[2024-11-14 09:40:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:28][root][INFO] - Training Epoch: 2/2, step 8633/16670 completed (loss: 0.5399783253669739, acc: 0.837837815284729)
[2024-11-14 09:40:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:28][root][INFO] - Training Epoch: 2/2, step 8634/16670 completed (loss: 0.41500723361968994, acc: 0.9340659379959106)
[2024-11-14 09:40:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:29][root][INFO] - Training Epoch: 2/2, step 8635/16670 completed (loss: 0.4166613817214966, acc: 0.8823529481887817)
[2024-11-14 09:40:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:29][root][INFO] - Training Epoch: 2/2, step 8636/16670 completed (loss: 0.31934085488319397, acc: 0.9090909361839294)
[2024-11-14 09:40:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:29][root][INFO] - Training Epoch: 2/2, step 8637/16670 completed (loss: 0.4269827902317047, acc: 0.9230769276618958)
[2024-11-14 09:40:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:30][root][INFO] - Training Epoch: 2/2, step 8638/16670 completed (loss: 0.4998170733451843, acc: 0.9104477763175964)
[2024-11-14 09:40:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:30][root][INFO] - Training Epoch: 2/2, step 8639/16670 completed (loss: 0.4544111490249634, acc: 0.9333333373069763)
[2024-11-14 09:40:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:30][root][INFO] - Training Epoch: 2/2, step 8640/16670 completed (loss: 0.4457453787326813, acc: 0.8904109597206116)
[2024-11-14 09:40:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:31][root][INFO] - Training Epoch: 2/2, step 8641/16670 completed (loss: 0.14958052337169647, acc: 0.9836065769195557)
[2024-11-14 09:40:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:31][root][INFO] - Training Epoch: 2/2, step 8642/16670 completed (loss: 0.15142273902893066, acc: 0.9523809552192688)
[2024-11-14 09:40:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:31][root][INFO] - Training Epoch: 2/2, step 8643/16670 completed (loss: 0.2708759009838104, acc: 0.9402984976768494)
[2024-11-14 09:40:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:32][root][INFO] - Training Epoch: 2/2, step 8644/16670 completed (loss: 0.0590708963572979, acc: 1.0)
[2024-11-14 09:40:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:32][root][INFO] - Training Epoch: 2/2, step 8645/16670 completed (loss: 0.5889073610305786, acc: 0.8409090638160706)
[2024-11-14 09:40:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:32][root][INFO] - Training Epoch: 2/2, step 8646/16670 completed (loss: 0.533676028251648, acc: 0.8909090757369995)
[2024-11-14 09:40:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:33][root][INFO] - Training Epoch: 2/2, step 8647/16670 completed (loss: 0.8133088946342468, acc: 0.8235294222831726)
[2024-11-14 09:40:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:33][root][INFO] - Training Epoch: 2/2, step 8648/16670 completed (loss: 0.297293096780777, acc: 0.9215686321258545)
[2024-11-14 09:40:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:33][root][INFO] - Training Epoch: 2/2, step 8649/16670 completed (loss: 0.5415868759155273, acc: 0.9090909361839294)
[2024-11-14 09:40:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:34][root][INFO] - Training Epoch: 2/2, step 8650/16670 completed (loss: 0.7298502326011658, acc: 0.8214285969734192)
[2024-11-14 09:40:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:34][root][INFO] - Training Epoch: 2/2, step 8651/16670 completed (loss: 0.19416482746601105, acc: 0.9024389982223511)
[2024-11-14 09:40:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:34][root][INFO] - Training Epoch: 2/2, step 8652/16670 completed (loss: 0.3749338388442993, acc: 0.8999999761581421)
[2024-11-14 09:40:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:35][root][INFO] - Training Epoch: 2/2, step 8653/16670 completed (loss: 0.11819229274988174, acc: 0.9795918464660645)
[2024-11-14 09:40:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:35][root][INFO] - Training Epoch: 2/2, step 8654/16670 completed (loss: 0.3328385055065155, acc: 0.9076923131942749)
[2024-11-14 09:40:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:35][root][INFO] - Training Epoch: 2/2, step 8655/16670 completed (loss: 0.27551063895225525, acc: 0.9387755393981934)
[2024-11-14 09:40:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:35][root][INFO] - Training Epoch: 2/2, step 8656/16670 completed (loss: 0.29907336831092834, acc: 0.9019607901573181)
[2024-11-14 09:40:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:36][root][INFO] - Training Epoch: 2/2, step 8657/16670 completed (loss: 0.4078103005886078, acc: 0.9230769276618958)
[2024-11-14 09:40:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:36][root][INFO] - Training Epoch: 2/2, step 8658/16670 completed (loss: 0.6378649473190308, acc: 0.8846153616905212)
[2024-11-14 09:40:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:36][root][INFO] - Training Epoch: 2/2, step 8659/16670 completed (loss: 0.17960742115974426, acc: 0.9433962106704712)
[2024-11-14 09:40:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:37][root][INFO] - Training Epoch: 2/2, step 8660/16670 completed (loss: 0.7861825823783875, acc: 0.8863636255264282)
[2024-11-14 09:40:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:37][root][INFO] - Training Epoch: 2/2, step 8661/16670 completed (loss: 0.57965487241745, acc: 0.9021739363670349)
[2024-11-14 09:40:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:37][root][INFO] - Training Epoch: 2/2, step 8662/16670 completed (loss: 0.18597599864006042, acc: 0.9491525292396545)
[2024-11-14 09:40:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:38][root][INFO] - Training Epoch: 2/2, step 8663/16670 completed (loss: 0.40461158752441406, acc: 0.8571428656578064)
[2024-11-14 09:40:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:38][root][INFO] - Training Epoch: 2/2, step 8664/16670 completed (loss: 0.09373590350151062, acc: 0.9848484992980957)
[2024-11-14 09:40:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:38][root][INFO] - Training Epoch: 2/2, step 8665/16670 completed (loss: 0.5723958015441895, acc: 0.800000011920929)
[2024-11-14 09:40:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:39][root][INFO] - Training Epoch: 2/2, step 8666/16670 completed (loss: 0.46732690930366516, acc: 0.8965517282485962)
[2024-11-14 09:40:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:39][root][INFO] - Training Epoch: 2/2, step 8667/16670 completed (loss: 0.42224475741386414, acc: 0.9036144614219666)
[2024-11-14 09:40:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:39][root][INFO] - Training Epoch: 2/2, step 8668/16670 completed (loss: 0.44870755076408386, acc: 0.9137930870056152)
[2024-11-14 09:40:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:40][root][INFO] - Training Epoch: 2/2, step 8669/16670 completed (loss: 0.625377893447876, acc: 0.8999999761581421)
[2024-11-14 09:40:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:40][root][INFO] - Training Epoch: 2/2, step 8670/16670 completed (loss: 0.15165621042251587, acc: 0.9534883499145508)
[2024-11-14 09:40:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:40][root][INFO] - Training Epoch: 2/2, step 8671/16670 completed (loss: 0.624249279499054, acc: 0.8372092843055725)
[2024-11-14 09:40:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:41][root][INFO] - Training Epoch: 2/2, step 8672/16670 completed (loss: 0.23122714459896088, acc: 0.9384615421295166)
[2024-11-14 09:40:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:41][root][INFO] - Training Epoch: 2/2, step 8673/16670 completed (loss: 0.5356069207191467, acc: 0.898876428604126)
[2024-11-14 09:40:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:41][root][INFO] - Training Epoch: 2/2, step 8674/16670 completed (loss: 0.1017712727189064, acc: 0.9759036302566528)
[2024-11-14 09:40:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:42][root][INFO] - Training Epoch: 2/2, step 8675/16670 completed (loss: 0.6697100400924683, acc: 0.8235294222831726)
[2024-11-14 09:40:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:42][root][INFO] - Training Epoch: 2/2, step 8676/16670 completed (loss: 0.4938645660877228, acc: 0.875)
[2024-11-14 09:40:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:42][root][INFO] - Training Epoch: 2/2, step 8677/16670 completed (loss: 0.4257110059261322, acc: 0.8928571343421936)
[2024-11-14 09:40:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:43][root][INFO] - Training Epoch: 2/2, step 8678/16670 completed (loss: 0.6765744686126709, acc: 0.8196721076965332)
[2024-11-14 09:40:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:43][root][INFO] - Training Epoch: 2/2, step 8679/16670 completed (loss: 0.08630472421646118, acc: 0.9818181991577148)
[2024-11-14 09:40:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:43][root][INFO] - Training Epoch: 2/2, step 8680/16670 completed (loss: 0.1805851310491562, acc: 0.9545454382896423)
[2024-11-14 09:40:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:44][root][INFO] - Training Epoch: 2/2, step 8681/16670 completed (loss: 0.21440106630325317, acc: 0.9333333373069763)
[2024-11-14 09:40:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:44][root][INFO] - Training Epoch: 2/2, step 8682/16670 completed (loss: 0.41021353006362915, acc: 0.9642857313156128)
[2024-11-14 09:40:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:44][root][INFO] - Training Epoch: 2/2, step 8683/16670 completed (loss: 0.387940913438797, acc: 0.8863636255264282)
[2024-11-14 09:40:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:45][root][INFO] - Training Epoch: 2/2, step 8684/16670 completed (loss: 0.31462329626083374, acc: 0.8965517282485962)
[2024-11-14 09:40:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:45][root][INFO] - Training Epoch: 2/2, step 8685/16670 completed (loss: 0.626330554485321, acc: 0.8947368264198303)
[2024-11-14 09:40:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:45][root][INFO] - Training Epoch: 2/2, step 8686/16670 completed (loss: 0.4598654508590698, acc: 0.8837209343910217)
[2024-11-14 09:40:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:46][root][INFO] - Training Epoch: 2/2, step 8687/16670 completed (loss: 0.5182291269302368, acc: 0.8928571343421936)
[2024-11-14 09:40:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:46][root][INFO] - Training Epoch: 2/2, step 8688/16670 completed (loss: 0.3505555987358093, acc: 0.8909090757369995)
[2024-11-14 09:40:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:46][root][INFO] - Training Epoch: 2/2, step 8689/16670 completed (loss: 0.45078718662261963, acc: 0.90625)
[2024-11-14 09:40:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:47][root][INFO] - Training Epoch: 2/2, step 8690/16670 completed (loss: 0.3851221799850464, acc: 0.9142857193946838)
[2024-11-14 09:40:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:47][root][INFO] - Training Epoch: 2/2, step 8691/16670 completed (loss: 0.5533865690231323, acc: 0.8703703880310059)
[2024-11-14 09:40:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:47][root][INFO] - Training Epoch: 2/2, step 8692/16670 completed (loss: 0.47782373428344727, acc: 0.875)
[2024-11-14 09:40:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:48][root][INFO] - Training Epoch: 2/2, step 8693/16670 completed (loss: 0.12489330768585205, acc: 0.9534883499145508)
[2024-11-14 09:40:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:48][root][INFO] - Training Epoch: 2/2, step 8694/16670 completed (loss: 0.6789066791534424, acc: 0.84375)
[2024-11-14 09:40:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:48][root][INFO] - Training Epoch: 2/2, step 8695/16670 completed (loss: 0.41121402382850647, acc: 0.8999999761581421)
[2024-11-14 09:40:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:49][root][INFO] - Training Epoch: 2/2, step 8696/16670 completed (loss: 0.5368592739105225, acc: 0.930232584476471)
[2024-11-14 09:40:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:49][root][INFO] - Training Epoch: 2/2, step 8697/16670 completed (loss: 0.8984524011611938, acc: 0.7936508059501648)
[2024-11-14 09:40:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:49][root][INFO] - Training Epoch: 2/2, step 8698/16670 completed (loss: 0.3098938763141632, acc: 0.875)
[2024-11-14 09:40:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:50][root][INFO] - Training Epoch: 2/2, step 8699/16670 completed (loss: 0.17842014133930206, acc: 0.9428571462631226)
[2024-11-14 09:40:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:50][root][INFO] - Training Epoch: 2/2, step 8700/16670 completed (loss: 0.629695475101471, acc: 0.8939393758773804)
[2024-11-14 09:40:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:50][root][INFO] - Training Epoch: 2/2, step 8701/16670 completed (loss: 0.8549336194992065, acc: 0.8837209343910217)
[2024-11-14 09:40:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:51][root][INFO] - Training Epoch: 2/2, step 8702/16670 completed (loss: 0.6263803243637085, acc: 0.8823529481887817)
[2024-11-14 09:40:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:51][root][INFO] - Training Epoch: 2/2, step 8703/16670 completed (loss: 0.8072543144226074, acc: 0.8199999928474426)
[2024-11-14 09:40:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:51][root][INFO] - Training Epoch: 2/2, step 8704/16670 completed (loss: 0.2787246108055115, acc: 0.8918918967247009)
[2024-11-14 09:40:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:52][root][INFO] - Training Epoch: 2/2, step 8705/16670 completed (loss: 0.2001274973154068, acc: 0.931034505367279)
[2024-11-14 09:40:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:52][root][INFO] - Training Epoch: 2/2, step 8706/16670 completed (loss: 0.23066848516464233, acc: 0.9599999785423279)
[2024-11-14 09:40:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:52][root][INFO] - Training Epoch: 2/2, step 8707/16670 completed (loss: 0.38603511452674866, acc: 0.8679245114326477)
[2024-11-14 09:40:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:53][root][INFO] - Training Epoch: 2/2, step 8708/16670 completed (loss: 0.13941752910614014, acc: 0.96875)
[2024-11-14 09:40:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:53][root][INFO] - Training Epoch: 2/2, step 8709/16670 completed (loss: 0.37334588170051575, acc: 0.9523809552192688)
[2024-11-14 09:40:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:53][root][INFO] - Training Epoch: 2/2, step 8710/16670 completed (loss: 0.28985732793807983, acc: 0.9210526347160339)
[2024-11-14 09:40:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:54][root][INFO] - Training Epoch: 2/2, step 8711/16670 completed (loss: 0.6754855513572693, acc: 0.7924528121948242)
[2024-11-14 09:40:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:54][root][INFO] - Training Epoch: 2/2, step 8712/16670 completed (loss: 0.10702984780073166, acc: 0.9642857313156128)
[2024-11-14 09:40:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:54][root][INFO] - Training Epoch: 2/2, step 8713/16670 completed (loss: 0.39529627561569214, acc: 0.9137930870056152)
[2024-11-14 09:40:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:55][root][INFO] - Training Epoch: 2/2, step 8714/16670 completed (loss: 0.5229166746139526, acc: 0.8666666746139526)
[2024-11-14 09:40:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:55][root][INFO] - Training Epoch: 2/2, step 8715/16670 completed (loss: 0.3178081810474396, acc: 0.9166666865348816)
[2024-11-14 09:40:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:55][root][INFO] - Training Epoch: 2/2, step 8716/16670 completed (loss: 0.47607654333114624, acc: 0.8695651888847351)
[2024-11-14 09:40:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:56][root][INFO] - Training Epoch: 2/2, step 8717/16670 completed (loss: 0.5611252784729004, acc: 0.8615384697914124)
[2024-11-14 09:40:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:56][root][INFO] - Training Epoch: 2/2, step 8718/16670 completed (loss: 0.5839402675628662, acc: 0.8387096524238586)
[2024-11-14 09:40:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:56][root][INFO] - Training Epoch: 2/2, step 8719/16670 completed (loss: 0.12292033433914185, acc: 0.9433962106704712)
[2024-11-14 09:40:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:57][root][INFO] - Training Epoch: 2/2, step 8720/16670 completed (loss: 0.2941524386405945, acc: 0.9743589758872986)
[2024-11-14 09:40:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:57][root][INFO] - Training Epoch: 2/2, step 8721/16670 completed (loss: 0.20383583009243011, acc: 0.9074074029922485)
[2024-11-14 09:40:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:57][root][INFO] - Training Epoch: 2/2, step 8722/16670 completed (loss: 0.4004530906677246, acc: 0.9090909361839294)
[2024-11-14 09:40:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:58][root][INFO] - Training Epoch: 2/2, step 8723/16670 completed (loss: 0.35386011004447937, acc: 0.930232584476471)
[2024-11-14 09:40:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:58][root][INFO] - Training Epoch: 2/2, step 8724/16670 completed (loss: 0.5585659146308899, acc: 0.8387096524238586)
[2024-11-14 09:40:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:58][root][INFO] - Training Epoch: 2/2, step 8725/16670 completed (loss: 0.06628666818141937, acc: 1.0)
[2024-11-14 09:40:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:58][root][INFO] - Training Epoch: 2/2, step 8726/16670 completed (loss: 0.05859002843499184, acc: 0.9756097793579102)
[2024-11-14 09:40:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:59][root][INFO] - Training Epoch: 2/2, step 8727/16670 completed (loss: 0.4863467216491699, acc: 0.8545454740524292)
[2024-11-14 09:40:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:59][root][INFO] - Training Epoch: 2/2, step 8728/16670 completed (loss: 0.4129014313220978, acc: 0.9130434989929199)
[2024-11-14 09:40:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:40:59][root][INFO] - Training Epoch: 2/2, step 8729/16670 completed (loss: 0.265818327665329, acc: 0.9615384340286255)
[2024-11-14 09:41:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:00][root][INFO] - Training Epoch: 2/2, step 8730/16670 completed (loss: 0.9790914058685303, acc: 0.800000011920929)
[2024-11-14 09:41:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:00][root][INFO] - Training Epoch: 2/2, step 8731/16670 completed (loss: 0.7024399042129517, acc: 0.800000011920929)
[2024-11-14 09:41:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:00][root][INFO] - Training Epoch: 2/2, step 8732/16670 completed (loss: 0.13869264721870422, acc: 0.9800000190734863)
[2024-11-14 09:41:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:01][root][INFO] - Training Epoch: 2/2, step 8733/16670 completed (loss: 0.91078120470047, acc: 0.7692307829856873)
[2024-11-14 09:41:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:01][root][INFO] - Training Epoch: 2/2, step 8734/16670 completed (loss: 0.6540678143501282, acc: 0.8333333134651184)
[2024-11-14 09:41:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:02][root][INFO] - Training Epoch: 2/2, step 8735/16670 completed (loss: 0.28933846950531006, acc: 0.9272727370262146)
[2024-11-14 09:41:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:02][root][INFO] - Training Epoch: 2/2, step 8736/16670 completed (loss: 1.232843041419983, acc: 0.75)
[2024-11-14 09:41:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:02][root][INFO] - Training Epoch: 2/2, step 8737/16670 completed (loss: 0.562555193901062, acc: 0.8500000238418579)
[2024-11-14 09:41:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:02][root][INFO] - Training Epoch: 2/2, step 8738/16670 completed (loss: 0.5208770036697388, acc: 0.8260869383811951)
[2024-11-14 09:41:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:03][root][INFO] - Training Epoch: 2/2, step 8739/16670 completed (loss: 0.3589605987071991, acc: 0.9122806787490845)
[2024-11-14 09:41:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:03][root][INFO] - Training Epoch: 2/2, step 8740/16670 completed (loss: 0.4418659210205078, acc: 0.8780487775802612)
[2024-11-14 09:41:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:04][root][INFO] - Training Epoch: 2/2, step 8741/16670 completed (loss: 0.37704554200172424, acc: 0.8571428656578064)
[2024-11-14 09:41:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:04][root][INFO] - Training Epoch: 2/2, step 8742/16670 completed (loss: 0.8861247301101685, acc: 0.800000011920929)
[2024-11-14 09:41:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:04][root][INFO] - Training Epoch: 2/2, step 8743/16670 completed (loss: 0.703413724899292, acc: 0.9090909361839294)
[2024-11-14 09:41:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:04][root][INFO] - Training Epoch: 2/2, step 8744/16670 completed (loss: 0.29167887568473816, acc: 0.9285714030265808)
[2024-11-14 09:41:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:05][root][INFO] - Training Epoch: 2/2, step 8745/16670 completed (loss: 0.1962880641222, acc: 0.9729729890823364)
[2024-11-14 09:41:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:05][root][INFO] - Training Epoch: 2/2, step 8746/16670 completed (loss: 0.35866889357566833, acc: 0.9166666865348816)
[2024-11-14 09:41:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:05][root][INFO] - Training Epoch: 2/2, step 8747/16670 completed (loss: 0.6771640181541443, acc: 0.804347813129425)
[2024-11-14 09:41:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:06][root][INFO] - Training Epoch: 2/2, step 8748/16670 completed (loss: 0.49648311734199524, acc: 0.8333333134651184)
[2024-11-14 09:41:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:06][root][INFO] - Training Epoch: 2/2, step 8749/16670 completed (loss: 0.5000385642051697, acc: 0.8653846383094788)
[2024-11-14 09:41:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:06][root][INFO] - Training Epoch: 2/2, step 8750/16670 completed (loss: 0.5417476296424866, acc: 0.9245283007621765)
[2024-11-14 09:41:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:07][root][INFO] - Training Epoch: 2/2, step 8751/16670 completed (loss: 0.9992707967758179, acc: 0.7674418687820435)
[2024-11-14 09:41:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:07][root][INFO] - Training Epoch: 2/2, step 8752/16670 completed (loss: 0.9699530005455017, acc: 0.7058823704719543)
[2024-11-14 09:41:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:07][root][INFO] - Training Epoch: 2/2, step 8753/16670 completed (loss: 0.27147018909454346, acc: 0.875)
[2024-11-14 09:41:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:08][root][INFO] - Training Epoch: 2/2, step 8754/16670 completed (loss: 0.38083794713020325, acc: 0.942307710647583)
[2024-11-14 09:41:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:08][root][INFO] - Training Epoch: 2/2, step 8755/16670 completed (loss: 1.0470730066299438, acc: 0.84375)
[2024-11-14 09:41:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:08][root][INFO] - Training Epoch: 2/2, step 8756/16670 completed (loss: 0.6516213417053223, acc: 0.9130434989929199)
[2024-11-14 09:41:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:09][root][INFO] - Training Epoch: 2/2, step 8757/16670 completed (loss: 0.24645665287971497, acc: 0.9523809552192688)
[2024-11-14 09:41:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:09][root][INFO] - Training Epoch: 2/2, step 8758/16670 completed (loss: 0.37054160237312317, acc: 0.8947368264198303)
[2024-11-14 09:41:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:09][root][INFO] - Training Epoch: 2/2, step 8759/16670 completed (loss: 0.4907597005367279, acc: 0.9111111164093018)
[2024-11-14 09:41:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:10][root][INFO] - Training Epoch: 2/2, step 8760/16670 completed (loss: 1.45286226272583, acc: 0.7179487347602844)
[2024-11-14 09:41:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:10][root][INFO] - Training Epoch: 2/2, step 8761/16670 completed (loss: 0.2787472903728485, acc: 0.8909090757369995)
[2024-11-14 09:41:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:10][root][INFO] - Training Epoch: 2/2, step 8762/16670 completed (loss: 0.5862647294998169, acc: 0.9032257795333862)
[2024-11-14 09:41:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:11][root][INFO] - Training Epoch: 2/2, step 8763/16670 completed (loss: 0.4948625862598419, acc: 0.8857142925262451)
[2024-11-14 09:41:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:11][root][INFO] - Training Epoch: 2/2, step 8764/16670 completed (loss: 0.5094457864761353, acc: 0.8701298832893372)
[2024-11-14 09:41:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:11][root][INFO] - Training Epoch: 2/2, step 8765/16670 completed (loss: 0.9509773850440979, acc: 0.8064516186714172)
[2024-11-14 09:41:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:12][root][INFO] - Training Epoch: 2/2, step 8766/16670 completed (loss: 0.5860695838928223, acc: 0.868852436542511)
[2024-11-14 09:41:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:12][root][INFO] - Training Epoch: 2/2, step 8767/16670 completed (loss: 0.32176685333251953, acc: 0.9220778942108154)
[2024-11-14 09:41:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:12][root][INFO] - Training Epoch: 2/2, step 8768/16670 completed (loss: 0.16975338757038116, acc: 0.942307710647583)
[2024-11-14 09:41:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:13][root][INFO] - Training Epoch: 2/2, step 8769/16670 completed (loss: 0.4366539418697357, acc: 0.949999988079071)
[2024-11-14 09:41:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:13][root][INFO] - Training Epoch: 2/2, step 8770/16670 completed (loss: 1.0371774435043335, acc: 0.7659574747085571)
[2024-11-14 09:41:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:13][root][INFO] - Training Epoch: 2/2, step 8771/16670 completed (loss: 0.7385339140892029, acc: 0.8194444179534912)
[2024-11-14 09:41:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:14][root][INFO] - Training Epoch: 2/2, step 8772/16670 completed (loss: 0.910471498966217, acc: 0.7962962985038757)
[2024-11-14 09:41:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:14][root][INFO] - Training Epoch: 2/2, step 8773/16670 completed (loss: 0.9448584914207458, acc: 0.800000011920929)
[2024-11-14 09:41:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:15][root][INFO] - Training Epoch: 2/2, step 8774/16670 completed (loss: 0.6275386214256287, acc: 0.875)
[2024-11-14 09:41:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:15][root][INFO] - Training Epoch: 2/2, step 8775/16670 completed (loss: 0.5455994606018066, acc: 0.90625)
[2024-11-14 09:41:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:15][root][INFO] - Training Epoch: 2/2, step 8776/16670 completed (loss: 0.42631837725639343, acc: 0.8918918967247009)
[2024-11-14 09:41:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:16][root][INFO] - Training Epoch: 2/2, step 8777/16670 completed (loss: 0.2066446840763092, acc: 0.9452054500579834)
[2024-11-14 09:41:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:16][root][INFO] - Training Epoch: 2/2, step 8778/16670 completed (loss: 0.32955050468444824, acc: 0.9152542352676392)
[2024-11-14 09:41:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:16][root][INFO] - Training Epoch: 2/2, step 8779/16670 completed (loss: 0.35873106122016907, acc: 0.918367326259613)
[2024-11-14 09:41:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:17][root][INFO] - Training Epoch: 2/2, step 8780/16670 completed (loss: 0.24862737953662872, acc: 0.9649122953414917)
[2024-11-14 09:41:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:17][root][INFO] - Training Epoch: 2/2, step 8781/16670 completed (loss: 0.3910205066204071, acc: 0.89552241563797)
[2024-11-14 09:41:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:17][root][INFO] - Training Epoch: 2/2, step 8782/16670 completed (loss: 0.6369278430938721, acc: 0.8113207817077637)
[2024-11-14 09:41:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:18][root][INFO] - Training Epoch: 2/2, step 8783/16670 completed (loss: 0.31082212924957275, acc: 0.9111111164093018)
[2024-11-14 09:41:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:18][root][INFO] - Training Epoch: 2/2, step 8784/16670 completed (loss: 0.49015942215919495, acc: 0.9454545378684998)
[2024-11-14 09:41:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:18][root][INFO] - Training Epoch: 2/2, step 8785/16670 completed (loss: 0.44406694173812866, acc: 0.9113923907279968)
[2024-11-14 09:41:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:19][root][INFO] - Training Epoch: 2/2, step 8786/16670 completed (loss: 0.3170885145664215, acc: 0.9259259104728699)
[2024-11-14 09:41:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:19][root][INFO] - Training Epoch: 2/2, step 8787/16670 completed (loss: 0.29892849922180176, acc: 0.966292142868042)
[2024-11-14 09:41:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:19][root][INFO] - Training Epoch: 2/2, step 8788/16670 completed (loss: 0.35472360253334045, acc: 0.9047619104385376)
[2024-11-14 09:41:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:20][root][INFO] - Training Epoch: 2/2, step 8789/16670 completed (loss: 0.43169453740119934, acc: 0.9038461446762085)
[2024-11-14 09:41:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:20][root][INFO] - Training Epoch: 2/2, step 8790/16670 completed (loss: 0.4458127021789551, acc: 0.925000011920929)
[2024-11-14 09:41:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:20][root][INFO] - Training Epoch: 2/2, step 8791/16670 completed (loss: 0.15899312496185303, acc: 0.9402984976768494)
[2024-11-14 09:41:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:21][root][INFO] - Training Epoch: 2/2, step 8792/16670 completed (loss: 0.7893359065055847, acc: 0.8717948794364929)
[2024-11-14 09:41:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:21][root][INFO] - Training Epoch: 2/2, step 8793/16670 completed (loss: 0.19746461510658264, acc: 0.9411764740943909)
[2024-11-14 09:41:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:21][root][INFO] - Training Epoch: 2/2, step 8794/16670 completed (loss: 0.12931862473487854, acc: 0.982758641242981)
[2024-11-14 09:41:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:21][root][INFO] - Training Epoch: 2/2, step 8795/16670 completed (loss: 0.3027489483356476, acc: 0.9444444179534912)
[2024-11-14 09:41:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:22][root][INFO] - Training Epoch: 2/2, step 8796/16670 completed (loss: 0.5293312668800354, acc: 0.9130434989929199)
[2024-11-14 09:41:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:22][root][INFO] - Training Epoch: 2/2, step 8797/16670 completed (loss: 0.5172399878501892, acc: 0.9111111164093018)
[2024-11-14 09:41:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:22][root][INFO] - Training Epoch: 2/2, step 8798/16670 completed (loss: 0.2194695919752121, acc: 0.936170220375061)
[2024-11-14 09:41:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:23][root][INFO] - Training Epoch: 2/2, step 8799/16670 completed (loss: 0.10733754932880402, acc: 0.9736841917037964)
[2024-11-14 09:41:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:23][root][INFO] - Training Epoch: 2/2, step 8800/16670 completed (loss: 1.0196881294250488, acc: 0.7674418687820435)
[2024-11-14 09:41:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:23][root][INFO] - Training Epoch: 2/2, step 8801/16670 completed (loss: 0.5818049907684326, acc: 0.8936170339584351)
[2024-11-14 09:41:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:24][root][INFO] - Training Epoch: 2/2, step 8802/16670 completed (loss: 0.1704406589269638, acc: 0.949999988079071)
[2024-11-14 09:41:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:24][root][INFO] - Training Epoch: 2/2, step 8803/16670 completed (loss: 0.11776985973119736, acc: 0.957446813583374)
[2024-11-14 09:41:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:25][root][INFO] - Training Epoch: 2/2, step 8804/16670 completed (loss: 0.10769003629684448, acc: 0.9852941036224365)
[2024-11-14 09:41:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:25][root][INFO] - Training Epoch: 2/2, step 8805/16670 completed (loss: 0.304313987493515, acc: 0.9411764740943909)
[2024-11-14 09:41:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:25][root][INFO] - Training Epoch: 2/2, step 8806/16670 completed (loss: 0.9833846688270569, acc: 0.75)
[2024-11-14 09:41:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:26][root][INFO] - Training Epoch: 2/2, step 8807/16670 completed (loss: 0.07761584967374802, acc: 0.9830508232116699)
[2024-11-14 09:41:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:26][root][INFO] - Training Epoch: 2/2, step 8808/16670 completed (loss: 0.8874291181564331, acc: 0.8181818127632141)
[2024-11-14 09:41:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:26][root][INFO] - Training Epoch: 2/2, step 8809/16670 completed (loss: 0.37043988704681396, acc: 0.914893627166748)
[2024-11-14 09:41:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:27][root][INFO] - Training Epoch: 2/2, step 8810/16670 completed (loss: 0.12061141431331635, acc: 0.9649122953414917)
[2024-11-14 09:41:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:27][root][INFO] - Training Epoch: 2/2, step 8811/16670 completed (loss: 0.4001259207725525, acc: 0.8690476417541504)
[2024-11-14 09:41:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:27][root][INFO] - Training Epoch: 2/2, step 8812/16670 completed (loss: 0.6560289263725281, acc: 0.8958333134651184)
[2024-11-14 09:41:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:28][root][INFO] - Training Epoch: 2/2, step 8813/16670 completed (loss: 0.2738305926322937, acc: 0.9545454382896423)
[2024-11-14 09:41:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:28][root][INFO] - Training Epoch: 2/2, step 8814/16670 completed (loss: 0.3424377739429474, acc: 0.9295774698257446)
[2024-11-14 09:41:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:28][root][INFO] - Training Epoch: 2/2, step 8815/16670 completed (loss: 0.3568113446235657, acc: 0.8901098966598511)
[2024-11-14 09:41:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:29][root][INFO] - Training Epoch: 2/2, step 8816/16670 completed (loss: 0.24745848774909973, acc: 0.9428571462631226)
[2024-11-14 09:41:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:29][root][INFO] - Training Epoch: 2/2, step 8817/16670 completed (loss: 0.46318715810775757, acc: 0.9268292784690857)
[2024-11-14 09:41:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:29][root][INFO] - Training Epoch: 2/2, step 8818/16670 completed (loss: 0.6478802561759949, acc: 0.8367347121238708)
[2024-11-14 09:41:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:30][root][INFO] - Training Epoch: 2/2, step 8819/16670 completed (loss: 0.5151306986808777, acc: 0.930232584476471)
[2024-11-14 09:41:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:30][root][INFO] - Training Epoch: 2/2, step 8820/16670 completed (loss: 0.15998980402946472, acc: 0.9555555582046509)
[2024-11-14 09:41:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:30][root][INFO] - Training Epoch: 2/2, step 8821/16670 completed (loss: 0.15544380247592926, acc: 0.9692307710647583)
[2024-11-14 09:41:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:31][root][INFO] - Training Epoch: 2/2, step 8822/16670 completed (loss: 0.07526249438524246, acc: 1.0)
[2024-11-14 09:41:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:31][root][INFO] - Training Epoch: 2/2, step 8823/16670 completed (loss: 0.18060509860515594, acc: 0.9670329689979553)
[2024-11-14 09:41:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:31][root][INFO] - Training Epoch: 2/2, step 8824/16670 completed (loss: 0.3210640549659729, acc: 0.942307710647583)
[2024-11-14 09:41:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:32][root][INFO] - Training Epoch: 2/2, step 8825/16670 completed (loss: 0.4255649745464325, acc: 0.8804348111152649)
[2024-11-14 09:41:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:32][root][INFO] - Training Epoch: 2/2, step 8826/16670 completed (loss: 0.5113982558250427, acc: 0.8536585569381714)
[2024-11-14 09:41:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:32][root][INFO] - Training Epoch: 2/2, step 8827/16670 completed (loss: 0.23606689274311066, acc: 0.9074074029922485)
[2024-11-14 09:41:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:33][root][INFO] - Training Epoch: 2/2, step 8828/16670 completed (loss: 0.6768021583557129, acc: 0.8813559412956238)
[2024-11-14 09:41:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:33][root][INFO] - Training Epoch: 2/2, step 8829/16670 completed (loss: 0.32749882340431213, acc: 0.9285714030265808)
[2024-11-14 09:41:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:33][root][INFO] - Training Epoch: 2/2, step 8830/16670 completed (loss: 0.5345954895019531, acc: 0.8421052694320679)
[2024-11-14 09:41:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:34][root][INFO] - Training Epoch: 2/2, step 8831/16670 completed (loss: 0.15291348099708557, acc: 0.9538461565971375)
[2024-11-14 09:41:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:34][root][INFO] - Training Epoch: 2/2, step 8832/16670 completed (loss: 0.38633590936660767, acc: 0.9230769276618958)
[2024-11-14 09:41:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:34][root][INFO] - Training Epoch: 2/2, step 8833/16670 completed (loss: 0.29490652680397034, acc: 0.9358974099159241)
[2024-11-14 09:41:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:35][root][INFO] - Training Epoch: 2/2, step 8834/16670 completed (loss: 1.0648614168167114, acc: 0.7818182110786438)
[2024-11-14 09:41:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:35][root][INFO] - Training Epoch: 2/2, step 8835/16670 completed (loss: 0.11952895671129227, acc: 0.9545454382896423)
[2024-11-14 09:41:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:35][root][INFO] - Training Epoch: 2/2, step 8836/16670 completed (loss: 0.3501526713371277, acc: 0.8965517282485962)
[2024-11-14 09:41:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:36][root][INFO] - Training Epoch: 2/2, step 8837/16670 completed (loss: 0.5419013500213623, acc: 0.9230769276618958)
[2024-11-14 09:41:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:36][root][INFO] - Training Epoch: 2/2, step 8838/16670 completed (loss: 0.1412692815065384, acc: 0.9523809552192688)
[2024-11-14 09:41:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:36][root][INFO] - Training Epoch: 2/2, step 8839/16670 completed (loss: 0.4210158586502075, acc: 0.9047619104385376)
[2024-11-14 09:41:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:37][root][INFO] - Training Epoch: 2/2, step 8840/16670 completed (loss: 0.35470354557037354, acc: 0.942307710647583)
[2024-11-14 09:41:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:37][root][INFO] - Training Epoch: 2/2, step 8841/16670 completed (loss: 0.09400276094675064, acc: 0.9836065769195557)
[2024-11-14 09:41:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:37][root][INFO] - Training Epoch: 2/2, step 8842/16670 completed (loss: 0.3435494899749756, acc: 0.9277108311653137)
[2024-11-14 09:41:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:38][root][INFO] - Training Epoch: 2/2, step 8843/16670 completed (loss: 0.09009812027215958, acc: 0.9666666388511658)
[2024-11-14 09:41:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:38][root][INFO] - Training Epoch: 2/2, step 8844/16670 completed (loss: 0.23412220180034637, acc: 0.9428571462631226)
[2024-11-14 09:41:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:38][root][INFO] - Training Epoch: 2/2, step 8845/16670 completed (loss: 0.2621166706085205, acc: 0.9365079402923584)
[2024-11-14 09:41:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:39][root][INFO] - Training Epoch: 2/2, step 8846/16670 completed (loss: 0.20968623459339142, acc: 0.957446813583374)
[2024-11-14 09:41:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:39][root][INFO] - Training Epoch: 2/2, step 8847/16670 completed (loss: 0.053282104432582855, acc: 1.0)
[2024-11-14 09:41:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:39][root][INFO] - Training Epoch: 2/2, step 8848/16670 completed (loss: 0.15898388624191284, acc: 0.948051929473877)
[2024-11-14 09:41:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:40][root][INFO] - Training Epoch: 2/2, step 8849/16670 completed (loss: 0.2795650064945221, acc: 0.9375)
[2024-11-14 09:41:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:40][root][INFO] - Training Epoch: 2/2, step 8850/16670 completed (loss: 0.3468056321144104, acc: 0.931034505367279)
[2024-11-14 09:41:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:40][root][INFO] - Training Epoch: 2/2, step 8851/16670 completed (loss: 0.26719826459884644, acc: 0.9305555820465088)
[2024-11-14 09:41:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:41][root][INFO] - Training Epoch: 2/2, step 8852/16670 completed (loss: 0.43813556432724, acc: 0.9152542352676392)
[2024-11-14 09:41:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:41][root][INFO] - Training Epoch: 2/2, step 8853/16670 completed (loss: 0.5853397846221924, acc: 0.8947368264198303)
[2024-11-14 09:41:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:41][root][INFO] - Training Epoch: 2/2, step 8854/16670 completed (loss: 0.5850003361701965, acc: 0.8888888955116272)
[2024-11-14 09:41:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:42][root][INFO] - Training Epoch: 2/2, step 8855/16670 completed (loss: 0.1292777806520462, acc: 0.9750000238418579)
[2024-11-14 09:41:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:42][root][INFO] - Training Epoch: 2/2, step 8856/16670 completed (loss: 0.1744934469461441, acc: 0.9666666388511658)
[2024-11-14 09:41:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:42][root][INFO] - Training Epoch: 2/2, step 8857/16670 completed (loss: 0.48242199420928955, acc: 0.9154929518699646)
[2024-11-14 09:41:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:43][root][INFO] - Training Epoch: 2/2, step 8858/16670 completed (loss: 0.28586190938949585, acc: 0.9125000238418579)
[2024-11-14 09:41:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:43][root][INFO] - Training Epoch: 2/2, step 8859/16670 completed (loss: 0.20509308576583862, acc: 0.9200000166893005)
[2024-11-14 09:41:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:43][root][INFO] - Training Epoch: 2/2, step 8860/16670 completed (loss: 0.199436217546463, acc: 0.9189189076423645)
[2024-11-14 09:41:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:44][root][INFO] - Training Epoch: 2/2, step 8861/16670 completed (loss: 0.39327695965766907, acc: 0.9166666865348816)
[2024-11-14 09:41:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:44][root][INFO] - Training Epoch: 2/2, step 8862/16670 completed (loss: 0.4297380745410919, acc: 0.9102563858032227)
[2024-11-14 09:41:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:44][root][INFO] - Training Epoch: 2/2, step 8863/16670 completed (loss: 0.130494624376297, acc: 0.9622641801834106)
[2024-11-14 09:41:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:45][root][INFO] - Training Epoch: 2/2, step 8864/16670 completed (loss: 0.42108091711997986, acc: 0.8888888955116272)
[2024-11-14 09:41:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:45][root][INFO] - Training Epoch: 2/2, step 8865/16670 completed (loss: 0.19003210961818695, acc: 0.9347826242446899)
[2024-11-14 09:41:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:45][root][INFO] - Training Epoch: 2/2, step 8866/16670 completed (loss: 0.062194108963012695, acc: 0.9807692170143127)
[2024-11-14 09:41:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:46][root][INFO] - Training Epoch: 2/2, step 8867/16670 completed (loss: 0.6099185943603516, acc: 0.8333333134651184)
[2024-11-14 09:41:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:46][root][INFO] - Training Epoch: 2/2, step 8868/16670 completed (loss: 0.07817612588405609, acc: 0.9870129823684692)
[2024-11-14 09:41:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:47][root][INFO] - Training Epoch: 2/2, step 8869/16670 completed (loss: 0.1513378620147705, acc: 0.9642857313156128)
[2024-11-14 09:41:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:47][root][INFO] - Training Epoch: 2/2, step 8870/16670 completed (loss: 0.21387331187725067, acc: 0.9298245906829834)
[2024-11-14 09:41:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:47][root][INFO] - Training Epoch: 2/2, step 8871/16670 completed (loss: 0.625307023525238, acc: 0.8909090757369995)
[2024-11-14 09:41:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:48][root][INFO] - Training Epoch: 2/2, step 8872/16670 completed (loss: 0.09273624420166016, acc: 0.9855072498321533)
[2024-11-14 09:41:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:48][root][INFO] - Training Epoch: 2/2, step 8873/16670 completed (loss: 1.1523444652557373, acc: 0.8387096524238586)
[2024-11-14 09:41:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:48][root][INFO] - Training Epoch: 2/2, step 8874/16670 completed (loss: 0.3452049791812897, acc: 0.9069767594337463)
[2024-11-14 09:41:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:48][root][INFO] - Training Epoch: 2/2, step 8875/16670 completed (loss: 0.2572163939476013, acc: 0.9142857193946838)
[2024-11-14 09:41:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:49][root][INFO] - Training Epoch: 2/2, step 8876/16670 completed (loss: 0.22325988113880157, acc: 0.9473684430122375)
[2024-11-14 09:41:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:49][root][INFO] - Training Epoch: 2/2, step 8877/16670 completed (loss: 0.6123951077461243, acc: 0.9032257795333862)
[2024-11-14 09:41:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:50][root][INFO] - Training Epoch: 2/2, step 8878/16670 completed (loss: 0.2522822618484497, acc: 0.9375)
[2024-11-14 09:41:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:50][root][INFO] - Training Epoch: 2/2, step 8879/16670 completed (loss: 0.2871823310852051, acc: 0.9189189076423645)
[2024-11-14 09:41:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:50][root][INFO] - Training Epoch: 2/2, step 8880/16670 completed (loss: 0.2581339180469513, acc: 0.9552238583564758)
[2024-11-14 09:41:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:50][root][INFO] - Training Epoch: 2/2, step 8881/16670 completed (loss: 0.6392199993133545, acc: 0.8947368264198303)
[2024-11-14 09:41:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:51][root][INFO] - Training Epoch: 2/2, step 8882/16670 completed (loss: 0.06705902516841888, acc: 1.0)
[2024-11-14 09:41:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:51][root][INFO] - Training Epoch: 2/2, step 8883/16670 completed (loss: 0.1489332765340805, acc: 0.9491525292396545)
[2024-11-14 09:41:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:51][root][INFO] - Training Epoch: 2/2, step 8884/16670 completed (loss: 0.12661360204219818, acc: 0.9541284441947937)
[2024-11-14 09:41:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:52][root][INFO] - Training Epoch: 2/2, step 8885/16670 completed (loss: 0.2700364887714386, acc: 0.9838709831237793)
[2024-11-14 09:41:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:52][root][INFO] - Training Epoch: 2/2, step 8886/16670 completed (loss: 0.26199817657470703, acc: 0.9295774698257446)
[2024-11-14 09:41:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:52][root][INFO] - Training Epoch: 2/2, step 8887/16670 completed (loss: 0.24164170026779175, acc: 0.9583333134651184)
[2024-11-14 09:41:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:53][root][INFO] - Training Epoch: 2/2, step 8888/16670 completed (loss: 0.32738903164863586, acc: 0.9545454382896423)
[2024-11-14 09:41:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:53][root][INFO] - Training Epoch: 2/2, step 8889/16670 completed (loss: 0.9619290232658386, acc: 0.800000011920929)
[2024-11-14 09:41:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:53][root][INFO] - Training Epoch: 2/2, step 8890/16670 completed (loss: 0.1810993105173111, acc: 0.95652174949646)
[2024-11-14 09:41:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:54][root][INFO] - Training Epoch: 2/2, step 8891/16670 completed (loss: 0.48929011821746826, acc: 0.8857142925262451)
[2024-11-14 09:41:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:54][root][INFO] - Training Epoch: 2/2, step 8892/16670 completed (loss: 0.3061961531639099, acc: 0.9512194991111755)
[2024-11-14 09:41:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:54][root][INFO] - Training Epoch: 2/2, step 8893/16670 completed (loss: 0.2084921896457672, acc: 0.9473684430122375)
[2024-11-14 09:41:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:55][root][INFO] - Training Epoch: 2/2, step 8894/16670 completed (loss: 0.16299232840538025, acc: 0.9411764740943909)
[2024-11-14 09:41:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:55][root][INFO] - Training Epoch: 2/2, step 8895/16670 completed (loss: 0.29050213098526, acc: 0.9178082346916199)
[2024-11-14 09:41:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:55][root][INFO] - Training Epoch: 2/2, step 8896/16670 completed (loss: 0.17605113983154297, acc: 0.9599999785423279)
[2024-11-14 09:41:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:56][root][INFO] - Training Epoch: 2/2, step 8897/16670 completed (loss: 0.46426400542259216, acc: 0.8909090757369995)
[2024-11-14 09:41:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:56][root][INFO] - Training Epoch: 2/2, step 8898/16670 completed (loss: 0.41118675470352173, acc: 0.9375)
[2024-11-14 09:41:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:57][root][INFO] - Training Epoch: 2/2, step 8899/16670 completed (loss: 0.5322822332382202, acc: 0.8999999761581421)
[2024-11-14 09:41:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:57][root][INFO] - Training Epoch: 2/2, step 8900/16670 completed (loss: 0.30670052766799927, acc: 0.9444444179534912)
[2024-11-14 09:41:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:57][root][INFO] - Training Epoch: 2/2, step 8901/16670 completed (loss: 0.28745782375335693, acc: 0.9365079402923584)
[2024-11-14 09:41:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:58][root][INFO] - Training Epoch: 2/2, step 8902/16670 completed (loss: 0.06049414724111557, acc: 0.9848484992980957)
[2024-11-14 09:41:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:58][root][INFO] - Training Epoch: 2/2, step 8903/16670 completed (loss: 0.036833833903074265, acc: 1.0)
[2024-11-14 09:41:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:58][root][INFO] - Training Epoch: 2/2, step 8904/16670 completed (loss: 0.11976959556341171, acc: 0.9473684430122375)
[2024-11-14 09:41:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:59][root][INFO] - Training Epoch: 2/2, step 8905/16670 completed (loss: 0.48438480496406555, acc: 0.8928571343421936)
[2024-11-14 09:41:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:59][root][INFO] - Training Epoch: 2/2, step 8906/16670 completed (loss: 0.5661084651947021, acc: 0.9032257795333862)
[2024-11-14 09:41:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:41:59][root][INFO] - Training Epoch: 2/2, step 8907/16670 completed (loss: 0.4123401641845703, acc: 0.9024389982223511)
[2024-11-14 09:41:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:00][root][INFO] - Training Epoch: 2/2, step 8908/16670 completed (loss: 0.21915408968925476, acc: 0.9482758641242981)
[2024-11-14 09:42:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:00][root][INFO] - Training Epoch: 2/2, step 8909/16670 completed (loss: 0.27758559584617615, acc: 0.954023003578186)
[2024-11-14 09:42:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:00][root][INFO] - Training Epoch: 2/2, step 8910/16670 completed (loss: 0.22453857958316803, acc: 0.9333333373069763)
[2024-11-14 09:42:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:01][root][INFO] - Training Epoch: 2/2, step 8911/16670 completed (loss: 0.3746548593044281, acc: 0.9090909361839294)
[2024-11-14 09:42:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:01][root][INFO] - Training Epoch: 2/2, step 8912/16670 completed (loss: 0.1615557074546814, acc: 0.9722222089767456)
[2024-11-14 09:42:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:01][root][INFO] - Training Epoch: 2/2, step 8913/16670 completed (loss: 0.32276129722595215, acc: 0.8904109597206116)
[2024-11-14 09:42:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:02][root][INFO] - Training Epoch: 2/2, step 8914/16670 completed (loss: 0.4292292892932892, acc: 0.9032257795333862)
[2024-11-14 09:42:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:02][root][INFO] - Training Epoch: 2/2, step 8915/16670 completed (loss: 0.8648125529289246, acc: 0.7857142686843872)
[2024-11-14 09:42:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:02][root][INFO] - Training Epoch: 2/2, step 8916/16670 completed (loss: 0.6816733479499817, acc: 0.895348846912384)
[2024-11-14 09:42:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:03][root][INFO] - Training Epoch: 2/2, step 8917/16670 completed (loss: 0.28376805782318115, acc: 0.9444444179534912)
[2024-11-14 09:42:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:03][root][INFO] - Training Epoch: 2/2, step 8918/16670 completed (loss: 0.11279911547899246, acc: 0.9666666388511658)
[2024-11-14 09:42:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:03][root][INFO] - Training Epoch: 2/2, step 8919/16670 completed (loss: 0.5791639089584351, acc: 0.8469387888908386)
[2024-11-14 09:42:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:04][root][INFO] - Training Epoch: 2/2, step 8920/16670 completed (loss: 0.44077062606811523, acc: 0.9230769276618958)
[2024-11-14 09:42:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:04][root][INFO] - Training Epoch: 2/2, step 8921/16670 completed (loss: 0.0390314944088459, acc: 1.0)
[2024-11-14 09:42:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:04][root][INFO] - Training Epoch: 2/2, step 8922/16670 completed (loss: 0.03325653821229935, acc: 1.0)
[2024-11-14 09:42:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:05][root][INFO] - Training Epoch: 2/2, step 8923/16670 completed (loss: 0.45914629101753235, acc: 0.8888888955116272)
[2024-11-14 09:42:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:05][root][INFO] - Training Epoch: 2/2, step 8924/16670 completed (loss: 0.5913889408111572, acc: 0.8846153616905212)
[2024-11-14 09:42:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:05][root][INFO] - Training Epoch: 2/2, step 8925/16670 completed (loss: 0.30072224140167236, acc: 0.9054054021835327)
[2024-11-14 09:42:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:05][root][INFO] - Training Epoch: 2/2, step 8926/16670 completed (loss: 0.14771586656570435, acc: 0.95652174949646)
[2024-11-14 09:42:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:06][root][INFO] - Training Epoch: 2/2, step 8927/16670 completed (loss: 0.03572189435362816, acc: 1.0)
[2024-11-14 09:42:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:06][root][INFO] - Training Epoch: 2/2, step 8928/16670 completed (loss: 0.05879431590437889, acc: 1.0)
[2024-11-14 09:42:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:06][root][INFO] - Training Epoch: 2/2, step 8929/16670 completed (loss: 0.30043452978134155, acc: 0.9056603908538818)
[2024-11-14 09:42:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:07][root][INFO] - Training Epoch: 2/2, step 8930/16670 completed (loss: 0.13801704347133636, acc: 0.9577465057373047)
[2024-11-14 09:42:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:07][root][INFO] - Training Epoch: 2/2, step 8931/16670 completed (loss: 0.3900800347328186, acc: 0.929411768913269)
[2024-11-14 09:42:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:08][root][INFO] - Training Epoch: 2/2, step 8932/16670 completed (loss: 0.34949830174446106, acc: 0.9259259104728699)
[2024-11-14 09:42:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:08][root][INFO] - Training Epoch: 2/2, step 8933/16670 completed (loss: 0.13649675250053406, acc: 0.970588207244873)
[2024-11-14 09:42:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:08][root][INFO] - Training Epoch: 2/2, step 8934/16670 completed (loss: 0.271793931722641, acc: 0.9682539701461792)
[2024-11-14 09:42:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:09][root][INFO] - Training Epoch: 2/2, step 8935/16670 completed (loss: 0.33722129464149475, acc: 0.9259259104728699)
[2024-11-14 09:42:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:09][root][INFO] - Training Epoch: 2/2, step 8936/16670 completed (loss: 0.26342782378196716, acc: 0.9272727370262146)
[2024-11-14 09:42:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:09][root][INFO] - Training Epoch: 2/2, step 8937/16670 completed (loss: 0.716640055179596, acc: 0.8309859037399292)
[2024-11-14 09:42:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:10][root][INFO] - Training Epoch: 2/2, step 8938/16670 completed (loss: 0.4505126178264618, acc: 0.8974359035491943)
[2024-11-14 09:42:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:10][root][INFO] - Training Epoch: 2/2, step 8939/16670 completed (loss: 0.15281184017658234, acc: 0.9726027250289917)
[2024-11-14 09:42:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:10][root][INFO] - Training Epoch: 2/2, step 8940/16670 completed (loss: 0.44153478741645813, acc: 0.8928571343421936)
[2024-11-14 09:42:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:10][root][INFO] - Training Epoch: 2/2, step 8941/16670 completed (loss: 0.1784811168909073, acc: 0.9428571462631226)
[2024-11-14 09:42:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:11][root][INFO] - Training Epoch: 2/2, step 8942/16670 completed (loss: 0.3674120604991913, acc: 0.9076923131942749)
[2024-11-14 09:42:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:11][root][INFO] - Training Epoch: 2/2, step 8943/16670 completed (loss: 0.4873862862586975, acc: 0.936170220375061)
[2024-11-14 09:42:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:12][root][INFO] - Training Epoch: 2/2, step 8944/16670 completed (loss: 0.7296937704086304, acc: 0.8243243098258972)
[2024-11-14 09:42:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:12][root][INFO] - Training Epoch: 2/2, step 8945/16670 completed (loss: 0.5444204807281494, acc: 0.8571428656578064)
[2024-11-14 09:42:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:12][root][INFO] - Training Epoch: 2/2, step 8946/16670 completed (loss: 1.076772928237915, acc: 0.8500000238418579)
[2024-11-14 09:42:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:13][root][INFO] - Training Epoch: 2/2, step 8947/16670 completed (loss: 0.26326748728752136, acc: 0.931034505367279)
[2024-11-14 09:42:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:13][root][INFO] - Training Epoch: 2/2, step 8948/16670 completed (loss: 0.06584882736206055, acc: 0.9661017060279846)
[2024-11-14 09:42:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:13][root][INFO] - Training Epoch: 2/2, step 8949/16670 completed (loss: 0.534690797328949, acc: 0.8260869383811951)
[2024-11-14 09:42:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:13][root][INFO] - Training Epoch: 2/2, step 8950/16670 completed (loss: 0.11607201397418976, acc: 0.95652174949646)
[2024-11-14 09:42:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:14][root][INFO] - Training Epoch: 2/2, step 8951/16670 completed (loss: 0.5696462392807007, acc: 0.8799999952316284)
[2024-11-14 09:42:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:14][root][INFO] - Training Epoch: 2/2, step 8952/16670 completed (loss: 0.5835142731666565, acc: 0.9259259104728699)
[2024-11-14 09:42:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:14][root][INFO] - Training Epoch: 2/2, step 8953/16670 completed (loss: 0.6602872610092163, acc: 0.8909090757369995)
[2024-11-14 09:42:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:15][root][INFO] - Training Epoch: 2/2, step 8954/16670 completed (loss: 0.2259199470281601, acc: 0.9230769276618958)
[2024-11-14 09:42:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:15][root][INFO] - Training Epoch: 2/2, step 8955/16670 completed (loss: 0.4532134234905243, acc: 0.8999999761581421)
[2024-11-14 09:42:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:15][root][INFO] - Training Epoch: 2/2, step 8956/16670 completed (loss: 0.7750913500785828, acc: 0.8780487775802612)
[2024-11-14 09:42:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:16][root][INFO] - Training Epoch: 2/2, step 8957/16670 completed (loss: 0.37664952874183655, acc: 0.9253731369972229)
[2024-11-14 09:42:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:16][root][INFO] - Training Epoch: 2/2, step 8958/16670 completed (loss: 0.10432577133178711, acc: 0.9534883499145508)
[2024-11-14 09:42:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:16][root][INFO] - Training Epoch: 2/2, step 8959/16670 completed (loss: 0.3149314522743225, acc: 0.8799999952316284)
[2024-11-14 09:42:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:17][root][INFO] - Training Epoch: 2/2, step 8960/16670 completed (loss: 0.3211964964866638, acc: 0.9333333373069763)
[2024-11-14 09:42:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:17][root][INFO] - Training Epoch: 2/2, step 8961/16670 completed (loss: 0.5758357048034668, acc: 0.841269850730896)
[2024-11-14 09:42:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:17][root][INFO] - Training Epoch: 2/2, step 8962/16670 completed (loss: 0.6058377623558044, acc: 0.892307698726654)
[2024-11-14 09:42:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:17][root][INFO] - Training Epoch: 2/2, step 8963/16670 completed (loss: 0.3051607310771942, acc: 0.9491525292396545)
[2024-11-14 09:42:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:18][root][INFO] - Training Epoch: 2/2, step 8964/16670 completed (loss: 0.6489447951316833, acc: 0.859375)
[2024-11-14 09:42:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:18][root][INFO] - Training Epoch: 2/2, step 8965/16670 completed (loss: 0.5372875928878784, acc: 0.8666666746139526)
[2024-11-14 09:42:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:18][root][INFO] - Training Epoch: 2/2, step 8966/16670 completed (loss: 0.07910136133432388, acc: 0.9655172228813171)
[2024-11-14 09:42:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:19][root][INFO] - Training Epoch: 2/2, step 8967/16670 completed (loss: 0.3116544485092163, acc: 0.8852459192276001)
[2024-11-14 09:42:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:19][root][INFO] - Training Epoch: 2/2, step 8968/16670 completed (loss: 0.5614909529685974, acc: 0.9152542352676392)
[2024-11-14 09:42:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:19][root][INFO] - Training Epoch: 2/2, step 8969/16670 completed (loss: 0.21100056171417236, acc: 0.9677419066429138)
[2024-11-14 09:42:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:20][root][INFO] - Training Epoch: 2/2, step 8970/16670 completed (loss: 0.06778603792190552, acc: 0.9821428656578064)
[2024-11-14 09:42:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:20][root][INFO] - Training Epoch: 2/2, step 8971/16670 completed (loss: 0.4480239450931549, acc: 0.9047619104385376)
[2024-11-14 09:42:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:20][root][INFO] - Training Epoch: 2/2, step 8972/16670 completed (loss: 0.434711217880249, acc: 0.875)
[2024-11-14 09:42:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:20][root][INFO] - Training Epoch: 2/2, step 8973/16670 completed (loss: 0.06050224229693413, acc: 0.9866666793823242)
[2024-11-14 09:42:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:21][root][INFO] - Training Epoch: 2/2, step 8974/16670 completed (loss: 0.03909947723150253, acc: 1.0)
[2024-11-14 09:42:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:21][root][INFO] - Training Epoch: 2/2, step 8975/16670 completed (loss: 0.16369546949863434, acc: 0.942307710647583)
[2024-11-14 09:42:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:22][root][INFO] - Training Epoch: 2/2, step 8976/16670 completed (loss: 0.43456754088401794, acc: 0.8727272748947144)
[2024-11-14 09:42:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:22][root][INFO] - Training Epoch: 2/2, step 8977/16670 completed (loss: 0.23738135397434235, acc: 0.9418604373931885)
[2024-11-14 09:42:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:22][root][INFO] - Training Epoch: 2/2, step 8978/16670 completed (loss: 0.6308510303497314, acc: 0.8611111044883728)
[2024-11-14 09:42:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:23][root][INFO] - Training Epoch: 2/2, step 8979/16670 completed (loss: 0.13591714203357697, acc: 0.9833333492279053)
[2024-11-14 09:42:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:23][root][INFO] - Training Epoch: 2/2, step 8980/16670 completed (loss: 0.7011657357215881, acc: 0.8461538553237915)
[2024-11-14 09:42:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:23][root][INFO] - Training Epoch: 2/2, step 8981/16670 completed (loss: 0.12535624206066132, acc: 0.9861111044883728)
[2024-11-14 09:42:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:24][root][INFO] - Training Epoch: 2/2, step 8982/16670 completed (loss: 0.23413710296154022, acc: 0.9629629850387573)
[2024-11-14 09:42:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:24][root][INFO] - Training Epoch: 2/2, step 8983/16670 completed (loss: 0.1328548789024353, acc: 0.9807692170143127)
[2024-11-14 09:42:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:24][root][INFO] - Training Epoch: 2/2, step 8984/16670 completed (loss: 0.3148950934410095, acc: 0.9253731369972229)
[2024-11-14 09:42:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:25][root][INFO] - Training Epoch: 2/2, step 8985/16670 completed (loss: 0.1852491945028305, acc: 0.9649122953414917)
[2024-11-14 09:42:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:25][root][INFO] - Training Epoch: 2/2, step 8986/16670 completed (loss: 0.24489222466945648, acc: 0.9358974099159241)
[2024-11-14 09:42:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:25][root][INFO] - Training Epoch: 2/2, step 8987/16670 completed (loss: 0.38085874915122986, acc: 0.8985507488250732)
[2024-11-14 09:42:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:26][root][INFO] - Training Epoch: 2/2, step 8988/16670 completed (loss: 0.37216997146606445, acc: 0.9189189076423645)
[2024-11-14 09:42:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:26][root][INFO] - Training Epoch: 2/2, step 8989/16670 completed (loss: 0.020312143489718437, acc: 1.0)
[2024-11-14 09:42:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:26][root][INFO] - Training Epoch: 2/2, step 8990/16670 completed (loss: 0.19171355664730072, acc: 0.9482758641242981)
[2024-11-14 09:42:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:27][root][INFO] - Training Epoch: 2/2, step 8991/16670 completed (loss: 0.24989382922649384, acc: 0.9215686321258545)
[2024-11-14 09:42:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:27][root][INFO] - Training Epoch: 2/2, step 8992/16670 completed (loss: 0.07125131040811539, acc: 0.9838709831237793)
[2024-11-14 09:42:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:27][root][INFO] - Training Epoch: 2/2, step 8993/16670 completed (loss: 0.33383116126060486, acc: 0.9122806787490845)
[2024-11-14 09:42:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:28][root][INFO] - Training Epoch: 2/2, step 8994/16670 completed (loss: 0.02286044880747795, acc: 1.0)
[2024-11-14 09:42:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:28][root][INFO] - Training Epoch: 2/2, step 8995/16670 completed (loss: 0.22076454758644104, acc: 0.9746835231781006)
[2024-11-14 09:42:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:28][root][INFO] - Training Epoch: 2/2, step 8996/16670 completed (loss: 0.19260847568511963, acc: 0.9558823704719543)
[2024-11-14 09:42:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:29][root][INFO] - Training Epoch: 2/2, step 8997/16670 completed (loss: 0.28935784101486206, acc: 0.8999999761581421)
[2024-11-14 09:42:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:29][root][INFO] - Training Epoch: 2/2, step 8998/16670 completed (loss: 0.4541592597961426, acc: 0.8888888955116272)
[2024-11-14 09:42:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:29][root][INFO] - Training Epoch: 2/2, step 8999/16670 completed (loss: 0.17502887547016144, acc: 0.9545454382896423)
[2024-11-14 09:42:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:30][root][INFO] - Training Epoch: 2/2, step 9000/16670 completed (loss: 0.7160156965255737, acc: 0.8510638475418091)
[2024-11-14 09:42:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:30][root][INFO] - Training Epoch: 2/2, step 9001/16670 completed (loss: 0.23217126727104187, acc: 0.942307710647583)
[2024-11-14 09:42:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:31][root][INFO] - Training Epoch: 2/2, step 9002/16670 completed (loss: 0.16305086016654968, acc: 0.949367105960846)
[2024-11-14 09:42:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:31][root][INFO] - Training Epoch: 2/2, step 9003/16670 completed (loss: 0.22284914553165436, acc: 0.9599999785423279)
[2024-11-14 09:42:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:31][root][INFO] - Training Epoch: 2/2, step 9004/16670 completed (loss: 0.47869551181793213, acc: 0.8999999761581421)
[2024-11-14 09:42:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:32][root][INFO] - Training Epoch: 2/2, step 9005/16670 completed (loss: 0.21532593667507172, acc: 0.918367326259613)
[2024-11-14 09:42:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:32][root][INFO] - Training Epoch: 2/2, step 9006/16670 completed (loss: 0.6800599098205566, acc: 0.8399999737739563)
[2024-11-14 09:42:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:32][root][INFO] - Training Epoch: 2/2, step 9007/16670 completed (loss: 0.31819233298301697, acc: 0.9285714030265808)
[2024-11-14 09:42:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:33][root][INFO] - Training Epoch: 2/2, step 9008/16670 completed (loss: 0.32003727555274963, acc: 0.8947368264198303)
[2024-11-14 09:42:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:33][root][INFO] - Training Epoch: 2/2, step 9009/16670 completed (loss: 0.2798772156238556, acc: 0.9729729890823364)
[2024-11-14 09:42:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:33][root][INFO] - Training Epoch: 2/2, step 9010/16670 completed (loss: 0.033235061913728714, acc: 1.0)
[2024-11-14 09:42:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:33][root][INFO] - Training Epoch: 2/2, step 9011/16670 completed (loss: 0.12256770581007004, acc: 0.957446813583374)
[2024-11-14 09:42:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:34][root][INFO] - Training Epoch: 2/2, step 9012/16670 completed (loss: 0.5004920363426208, acc: 0.9024389982223511)
[2024-11-14 09:42:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:34][root][INFO] - Training Epoch: 2/2, step 9013/16670 completed (loss: 0.17770332098007202, acc: 0.9624999761581421)
[2024-11-14 09:42:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:35][root][INFO] - Training Epoch: 2/2, step 9014/16670 completed (loss: 0.244407519698143, acc: 0.918367326259613)
[2024-11-14 09:42:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:35][root][INFO] - Training Epoch: 2/2, step 9015/16670 completed (loss: 0.30108606815338135, acc: 0.9090909361839294)
[2024-11-14 09:42:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:35][root][INFO] - Training Epoch: 2/2, step 9016/16670 completed (loss: 0.4070326089859009, acc: 0.8709677457809448)
[2024-11-14 09:42:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:36][root][INFO] - Training Epoch: 2/2, step 9017/16670 completed (loss: 0.7838318347930908, acc: 0.795918345451355)
[2024-11-14 09:42:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:36][root][INFO] - Training Epoch: 2/2, step 9018/16670 completed (loss: 0.33155471086502075, acc: 0.9324324131011963)
[2024-11-14 09:42:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:36][root][INFO] - Training Epoch: 2/2, step 9019/16670 completed (loss: 0.19433991611003876, acc: 0.95652174949646)
[2024-11-14 09:42:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:37][root][INFO] - Training Epoch: 2/2, step 9020/16670 completed (loss: 0.8941104412078857, acc: 0.8399999737739563)
[2024-11-14 09:42:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:37][root][INFO] - Training Epoch: 2/2, step 9021/16670 completed (loss: 0.11694937944412231, acc: 0.9555555582046509)
[2024-11-14 09:42:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:37][root][INFO] - Training Epoch: 2/2, step 9022/16670 completed (loss: 0.1948586255311966, acc: 0.9333333373069763)
[2024-11-14 09:42:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:38][root][INFO] - Training Epoch: 2/2, step 9023/16670 completed (loss: 0.17567068338394165, acc: 0.9620253443717957)
[2024-11-14 09:42:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:38][root][INFO] - Training Epoch: 2/2, step 9024/16670 completed (loss: 0.3920426070690155, acc: 0.9215686321258545)
[2024-11-14 09:42:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:38][root][INFO] - Training Epoch: 2/2, step 9025/16670 completed (loss: 0.24810904264450073, acc: 0.9210526347160339)
[2024-11-14 09:42:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:39][root][INFO] - Training Epoch: 2/2, step 9026/16670 completed (loss: 0.4081805348396301, acc: 0.9295774698257446)
[2024-11-14 09:42:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:39][root][INFO] - Training Epoch: 2/2, step 9027/16670 completed (loss: 0.18410304188728333, acc: 0.8999999761581421)
[2024-11-14 09:42:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:39][root][INFO] - Training Epoch: 2/2, step 9028/16670 completed (loss: 0.33256933093070984, acc: 0.9344262480735779)
[2024-11-14 09:42:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:40][root][INFO] - Training Epoch: 2/2, step 9029/16670 completed (loss: 0.8286766409873962, acc: 0.8461538553237915)
[2024-11-14 09:42:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:40][root][INFO] - Training Epoch: 2/2, step 9030/16670 completed (loss: 0.29600852727890015, acc: 0.9491525292396545)
[2024-11-14 09:42:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:40][root][INFO] - Training Epoch: 2/2, step 9031/16670 completed (loss: 0.4601634442806244, acc: 0.8888888955116272)
[2024-11-14 09:42:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:41][root][INFO] - Training Epoch: 2/2, step 9032/16670 completed (loss: 0.19783145189285278, acc: 0.9756097793579102)
[2024-11-14 09:42:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:41][root][INFO] - Training Epoch: 2/2, step 9033/16670 completed (loss: 0.24524402618408203, acc: 0.9189189076423645)
[2024-11-14 09:42:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:41][root][INFO] - Training Epoch: 2/2, step 9034/16670 completed (loss: 0.5699772834777832, acc: 0.8611111044883728)
[2024-11-14 09:42:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:42][root][INFO] - Training Epoch: 2/2, step 9035/16670 completed (loss: 0.5423188805580139, acc: 0.9230769276618958)
[2024-11-14 09:42:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:42][root][INFO] - Training Epoch: 2/2, step 9036/16670 completed (loss: 0.9878925681114197, acc: 0.8541666865348816)
[2024-11-14 09:42:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:42][root][INFO] - Training Epoch: 2/2, step 9037/16670 completed (loss: 0.060892876237630844, acc: 1.0)
[2024-11-14 09:42:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:43][root][INFO] - Training Epoch: 2/2, step 9038/16670 completed (loss: 0.5728216171264648, acc: 0.8723404407501221)
[2024-11-14 09:42:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:43][root][INFO] - Training Epoch: 2/2, step 9039/16670 completed (loss: 0.3183024525642395, acc: 0.9200000166893005)
[2024-11-14 09:42:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:44][root][INFO] - Training Epoch: 2/2, step 9040/16670 completed (loss: 0.3377906382083893, acc: 0.8571428656578064)
[2024-11-14 09:42:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:44][root][INFO] - Training Epoch: 2/2, step 9041/16670 completed (loss: 0.1343909054994583, acc: 0.976190447807312)
[2024-11-14 09:42:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:44][root][INFO] - Training Epoch: 2/2, step 9042/16670 completed (loss: 0.27096396684646606, acc: 0.9344262480735779)
[2024-11-14 09:42:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:45][root][INFO] - Training Epoch: 2/2, step 9043/16670 completed (loss: 0.2136581689119339, acc: 0.939393937587738)
[2024-11-14 09:42:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:45][root][INFO] - Training Epoch: 2/2, step 9044/16670 completed (loss: 0.11757770925760269, acc: 0.9583333134651184)
[2024-11-14 09:42:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:45][root][INFO] - Training Epoch: 2/2, step 9045/16670 completed (loss: 0.45772606134414673, acc: 0.8723404407501221)
[2024-11-14 09:42:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:46][root][INFO] - Training Epoch: 2/2, step 9046/16670 completed (loss: 0.0788053646683693, acc: 0.9743589758872986)
[2024-11-14 09:42:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:46][root][INFO] - Training Epoch: 2/2, step 9047/16670 completed (loss: 1.6644268035888672, acc: 0.7111111283302307)
[2024-11-14 09:42:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:46][root][INFO] - Training Epoch: 2/2, step 9048/16670 completed (loss: 0.21392348408699036, acc: 0.9677419066429138)
[2024-11-14 09:42:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:47][root][INFO] - Training Epoch: 2/2, step 9049/16670 completed (loss: 0.07297159731388092, acc: 0.9818181991577148)
[2024-11-14 09:42:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:47][root][INFO] - Training Epoch: 2/2, step 9050/16670 completed (loss: 0.09758444875478745, acc: 0.9636363387107849)
[2024-11-14 09:42:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:47][root][INFO] - Training Epoch: 2/2, step 9051/16670 completed (loss: 1.1580009460449219, acc: 0.7352941036224365)
[2024-11-14 09:42:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:48][root][INFO] - Training Epoch: 2/2, step 9052/16670 completed (loss: 0.1805775910615921, acc: 0.9523809552192688)
[2024-11-14 09:42:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:48][root][INFO] - Training Epoch: 2/2, step 9053/16670 completed (loss: 0.10077479481697083, acc: 0.9800000190734863)
[2024-11-14 09:42:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:48][root][INFO] - Training Epoch: 2/2, step 9054/16670 completed (loss: 0.8364217877388, acc: 0.8125)
[2024-11-14 09:42:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:49][root][INFO] - Training Epoch: 2/2, step 9055/16670 completed (loss: 0.6861624121665955, acc: 0.8888888955116272)
[2024-11-14 09:42:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:49][root][INFO] - Training Epoch: 2/2, step 9056/16670 completed (loss: 0.5607871413230896, acc: 0.9230769276618958)
[2024-11-14 09:42:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:49][root][INFO] - Training Epoch: 2/2, step 9057/16670 completed (loss: 1.0118422508239746, acc: 0.8095238208770752)
[2024-11-14 09:42:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:49][root][INFO] - Training Epoch: 2/2, step 9058/16670 completed (loss: 0.1485140174627304, acc: 0.9714285731315613)
[2024-11-14 09:42:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:50][root][INFO] - Training Epoch: 2/2, step 9059/16670 completed (loss: 0.3735997676849365, acc: 0.9019607901573181)
[2024-11-14 09:42:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:50][root][INFO] - Training Epoch: 2/2, step 9060/16670 completed (loss: 0.28771650791168213, acc: 0.9411764740943909)
[2024-11-14 09:42:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:50][root][INFO] - Training Epoch: 2/2, step 9061/16670 completed (loss: 1.0946626663208008, acc: 0.8064516186714172)
[2024-11-14 09:42:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:51][root][INFO] - Training Epoch: 2/2, step 9062/16670 completed (loss: 0.3536466658115387, acc: 0.8620689511299133)
[2024-11-14 09:42:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:51][root][INFO] - Training Epoch: 2/2, step 9063/16670 completed (loss: 0.8283377885818481, acc: 0.8367347121238708)
[2024-11-14 09:42:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:51][root][INFO] - Training Epoch: 2/2, step 9064/16670 completed (loss: 0.40080776810646057, acc: 0.9210526347160339)
[2024-11-14 09:42:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:52][root][INFO] - Training Epoch: 2/2, step 9065/16670 completed (loss: 0.4500000774860382, acc: 0.8823529481887817)
[2024-11-14 09:42:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:52][root][INFO] - Training Epoch: 2/2, step 9066/16670 completed (loss: 0.3348208963871002, acc: 0.9285714030265808)
[2024-11-14 09:42:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:53][root][INFO] - Training Epoch: 2/2, step 9067/16670 completed (loss: 0.10172884911298752, acc: 0.9777777791023254)
[2024-11-14 09:42:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:53][root][INFO] - Training Epoch: 2/2, step 9068/16670 completed (loss: 0.5065332055091858, acc: 0.9166666865348816)
[2024-11-14 09:42:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:53][root][INFO] - Training Epoch: 2/2, step 9069/16670 completed (loss: 0.7833579778671265, acc: 0.887499988079071)
[2024-11-14 09:42:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:54][root][INFO] - Training Epoch: 2/2, step 9070/16670 completed (loss: 0.205475851893425, acc: 0.939393937587738)
[2024-11-14 09:42:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:54][root][INFO] - Training Epoch: 2/2, step 9071/16670 completed (loss: 0.3224606513977051, acc: 0.9117646813392639)
[2024-11-14 09:42:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:54][root][INFO] - Training Epoch: 2/2, step 9072/16670 completed (loss: 0.26882171630859375, acc: 0.9452054500579834)
[2024-11-14 09:42:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:55][root][INFO] - Training Epoch: 2/2, step 9073/16670 completed (loss: 0.2638574242591858, acc: 0.9268292784690857)
[2024-11-14 09:42:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:55][root][INFO] - Training Epoch: 2/2, step 9074/16670 completed (loss: 1.0694319009780884, acc: 0.8260869383811951)
[2024-11-14 09:42:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:55][root][INFO] - Training Epoch: 2/2, step 9075/16670 completed (loss: 0.37909430265426636, acc: 0.9111111164093018)
[2024-11-14 09:42:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:56][root][INFO] - Training Epoch: 2/2, step 9076/16670 completed (loss: 0.7212476134300232, acc: 0.9375)
[2024-11-14 09:42:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:56][root][INFO] - Training Epoch: 2/2, step 9077/16670 completed (loss: 0.3086044192314148, acc: 0.8666666746139526)
[2024-11-14 09:42:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:56][root][INFO] - Training Epoch: 2/2, step 9078/16670 completed (loss: 0.47209635376930237, acc: 0.925000011920929)
[2024-11-14 09:42:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:57][root][INFO] - Training Epoch: 2/2, step 9079/16670 completed (loss: 0.32260650396347046, acc: 0.8985507488250732)
[2024-11-14 09:42:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:57][root][INFO] - Training Epoch: 2/2, step 9080/16670 completed (loss: 0.5629162192344666, acc: 0.8983050584793091)
[2024-11-14 09:42:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:57][root][INFO] - Training Epoch: 2/2, step 9081/16670 completed (loss: 0.3093356490135193, acc: 0.9365079402923584)
[2024-11-14 09:42:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:58][root][INFO] - Training Epoch: 2/2, step 9082/16670 completed (loss: 0.17599260807037354, acc: 0.9740259647369385)
[2024-11-14 09:42:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:58][root][INFO] - Training Epoch: 2/2, step 9083/16670 completed (loss: 0.14758585393428802, acc: 0.9444444179534912)
[2024-11-14 09:42:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:58][root][INFO] - Training Epoch: 2/2, step 9084/16670 completed (loss: 0.5032826066017151, acc: 0.8717948794364929)
[2024-11-14 09:42:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:59][root][INFO] - Training Epoch: 2/2, step 9085/16670 completed (loss: 0.2884797751903534, acc: 0.9285714030265808)
[2024-11-14 09:42:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:59][root][INFO] - Training Epoch: 2/2, step 9086/16670 completed (loss: 0.550412118434906, acc: 0.8461538553237915)
[2024-11-14 09:42:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:42:59][root][INFO] - Training Epoch: 2/2, step 9087/16670 completed (loss: 0.3165947496891022, acc: 0.9253731369972229)
[2024-11-14 09:43:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:00][root][INFO] - Training Epoch: 2/2, step 9088/16670 completed (loss: 0.29056501388549805, acc: 0.9615384340286255)
[2024-11-14 09:43:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:00][root][INFO] - Training Epoch: 2/2, step 9089/16670 completed (loss: 0.2788923680782318, acc: 0.9322034120559692)
[2024-11-14 09:43:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:00][root][INFO] - Training Epoch: 2/2, step 9090/16670 completed (loss: 0.22962641716003418, acc: 0.925000011920929)
[2024-11-14 09:43:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:01][root][INFO] - Training Epoch: 2/2, step 9091/16670 completed (loss: 0.26701125502586365, acc: 0.8815789222717285)
[2024-11-14 09:43:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:01][root][INFO] - Training Epoch: 2/2, step 9092/16670 completed (loss: 0.22223462164402008, acc: 0.9333333373069763)
[2024-11-14 09:43:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:01][root][INFO] - Training Epoch: 2/2, step 9093/16670 completed (loss: 0.30444633960723877, acc: 0.8636363744735718)
[2024-11-14 09:43:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:02][root][INFO] - Training Epoch: 2/2, step 9094/16670 completed (loss: 0.5993530750274658, acc: 0.8387096524238586)
[2024-11-14 09:43:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:02][root][INFO] - Training Epoch: 2/2, step 9095/16670 completed (loss: 0.2873571217060089, acc: 0.9594594836235046)
[2024-11-14 09:43:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:03][root][INFO] - Training Epoch: 2/2, step 9096/16670 completed (loss: 0.2636224627494812, acc: 0.949999988079071)
[2024-11-14 09:43:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:03][root][INFO] - Training Epoch: 2/2, step 9097/16670 completed (loss: 0.1596144437789917, acc: 0.930232584476471)
[2024-11-14 09:43:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:03][root][INFO] - Training Epoch: 2/2, step 9098/16670 completed (loss: 0.21840126812458038, acc: 0.9459459185600281)
[2024-11-14 09:43:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:03][root][INFO] - Training Epoch: 2/2, step 9099/16670 completed (loss: 0.15806175768375397, acc: 0.9367088675498962)
[2024-11-14 09:43:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:04][root][INFO] - Training Epoch: 2/2, step 9100/16670 completed (loss: 0.5585374236106873, acc: 0.9107142686843872)
[2024-11-14 09:43:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:04][root][INFO] - Training Epoch: 2/2, step 9101/16670 completed (loss: 0.05660952255129814, acc: 1.0)
[2024-11-14 09:43:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:04][root][INFO] - Training Epoch: 2/2, step 9102/16670 completed (loss: 0.16624337434768677, acc: 0.9411764740943909)
[2024-11-14 09:43:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:05][root][INFO] - Training Epoch: 2/2, step 9103/16670 completed (loss: 0.15406255424022675, acc: 0.9285714030265808)
[2024-11-14 09:43:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:05][root][INFO] - Training Epoch: 2/2, step 9104/16670 completed (loss: 0.3722696006298065, acc: 0.9230769276618958)
[2024-11-14 09:43:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:05][root][INFO] - Training Epoch: 2/2, step 9105/16670 completed (loss: 0.2148258537054062, acc: 0.9482758641242981)
[2024-11-14 09:43:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:06][root][INFO] - Training Epoch: 2/2, step 9106/16670 completed (loss: 0.4856613874435425, acc: 0.8478260636329651)
[2024-11-14 09:43:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:06][root][INFO] - Training Epoch: 2/2, step 9107/16670 completed (loss: 0.39043310284614563, acc: 0.9268292784690857)
[2024-11-14 09:43:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:06][root][INFO] - Training Epoch: 2/2, step 9108/16670 completed (loss: 0.4107529819011688, acc: 0.9333333373069763)
[2024-11-14 09:43:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:07][root][INFO] - Training Epoch: 2/2, step 9109/16670 completed (loss: 0.2597678303718567, acc: 0.9384615421295166)
[2024-11-14 09:43:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:07][root][INFO] - Training Epoch: 2/2, step 9110/16670 completed (loss: 0.10181145370006561, acc: 0.9803921580314636)
[2024-11-14 09:43:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:07][root][INFO] - Training Epoch: 2/2, step 9111/16670 completed (loss: 0.24344922602176666, acc: 0.9285714030265808)
[2024-11-14 09:43:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:08][root][INFO] - Training Epoch: 2/2, step 9112/16670 completed (loss: 0.8427098393440247, acc: 0.8620689511299133)
[2024-11-14 09:43:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:08][root][INFO] - Training Epoch: 2/2, step 9113/16670 completed (loss: 0.3985312581062317, acc: 0.936170220375061)
[2024-11-14 09:43:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:09][root][INFO] - Training Epoch: 2/2, step 9114/16670 completed (loss: 0.17585892975330353, acc: 0.9399999976158142)
[2024-11-14 09:43:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:09][root][INFO] - Training Epoch: 2/2, step 9115/16670 completed (loss: 0.39703434705734253, acc: 0.918367326259613)
[2024-11-14 09:43:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:09][root][INFO] - Training Epoch: 2/2, step 9116/16670 completed (loss: 0.14085103571414948, acc: 0.9642857313156128)
[2024-11-14 09:43:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:10][root][INFO] - Training Epoch: 2/2, step 9117/16670 completed (loss: 0.11253484338521957, acc: 0.9655172228813171)
[2024-11-14 09:43:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:10][root][INFO] - Training Epoch: 2/2, step 9118/16670 completed (loss: 0.4531800448894501, acc: 0.8947368264198303)
[2024-11-14 09:43:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:10][root][INFO] - Training Epoch: 2/2, step 9119/16670 completed (loss: 0.3486647307872772, acc: 0.9180327653884888)
[2024-11-14 09:43:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:11][root][INFO] - Training Epoch: 2/2, step 9120/16670 completed (loss: 0.49526381492614746, acc: 0.8305084705352783)
[2024-11-14 09:43:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:11][root][INFO] - Training Epoch: 2/2, step 9121/16670 completed (loss: 0.2595946788787842, acc: 0.8888888955116272)
[2024-11-14 09:43:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:11][root][INFO] - Training Epoch: 2/2, step 9122/16670 completed (loss: 1.1790052652359009, acc: 0.782608687877655)
[2024-11-14 09:43:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:12][root][INFO] - Training Epoch: 2/2, step 9123/16670 completed (loss: 0.48898056149482727, acc: 0.9259259104728699)
[2024-11-14 09:43:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:12][root][INFO] - Training Epoch: 2/2, step 9124/16670 completed (loss: 0.6985534429550171, acc: 0.8775510191917419)
[2024-11-14 09:43:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:12][root][INFO] - Training Epoch: 2/2, step 9125/16670 completed (loss: 0.3489155173301697, acc: 0.9016393423080444)
[2024-11-14 09:43:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:13][root][INFO] - Training Epoch: 2/2, step 9126/16670 completed (loss: 0.7411707639694214, acc: 0.8666666746139526)
[2024-11-14 09:43:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:13][root][INFO] - Training Epoch: 2/2, step 9127/16670 completed (loss: 0.3889411389827728, acc: 0.8548387289047241)
[2024-11-14 09:43:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:13][root][INFO] - Training Epoch: 2/2, step 9128/16670 completed (loss: 0.3646640479564667, acc: 0.9285714030265808)
[2024-11-14 09:43:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:14][root][INFO] - Training Epoch: 2/2, step 9129/16670 completed (loss: 0.7374941110610962, acc: 0.8709677457809448)
[2024-11-14 09:43:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:14][root][INFO] - Training Epoch: 2/2, step 9130/16670 completed (loss: 0.18753057718276978, acc: 0.9666666388511658)
[2024-11-14 09:43:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:14][root][INFO] - Training Epoch: 2/2, step 9131/16670 completed (loss: 0.4062791168689728, acc: 0.875)
[2024-11-14 09:43:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:15][root][INFO] - Training Epoch: 2/2, step 9132/16670 completed (loss: 0.1452091783285141, acc: 0.9701492786407471)
[2024-11-14 09:43:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:15][root][INFO] - Training Epoch: 2/2, step 9133/16670 completed (loss: 0.1497115045785904, acc: 0.9591836929321289)
[2024-11-14 09:43:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:15][root][INFO] - Training Epoch: 2/2, step 9134/16670 completed (loss: 0.18350748717784882, acc: 0.9512194991111755)
[2024-11-14 09:43:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:16][root][INFO] - Training Epoch: 2/2, step 9135/16670 completed (loss: 0.22679384052753448, acc: 0.9342105388641357)
[2024-11-14 09:43:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:16][root][INFO] - Training Epoch: 2/2, step 9136/16670 completed (loss: 0.8323522806167603, acc: 0.8363636136054993)
[2024-11-14 09:43:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:16][root][INFO] - Training Epoch: 2/2, step 9137/16670 completed (loss: 0.27055624127388, acc: 0.8958333134651184)
[2024-11-14 09:43:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:17][root][INFO] - Training Epoch: 2/2, step 9138/16670 completed (loss: 0.29541096091270447, acc: 0.9090909361839294)
[2024-11-14 09:43:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:17][root][INFO] - Training Epoch: 2/2, step 9139/16670 completed (loss: 0.1945590078830719, acc: 0.9350649118423462)
[2024-11-14 09:43:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:17][root][INFO] - Training Epoch: 2/2, step 9140/16670 completed (loss: 0.38060763478279114, acc: 0.8863636255264282)
[2024-11-14 09:43:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:18][root][INFO] - Training Epoch: 2/2, step 9141/16670 completed (loss: 0.36226704716682434, acc: 0.8709677457809448)
[2024-11-14 09:43:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:18][root][INFO] - Training Epoch: 2/2, step 9142/16670 completed (loss: 0.3669259250164032, acc: 0.9090909361839294)
[2024-11-14 09:43:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:18][root][INFO] - Training Epoch: 2/2, step 9143/16670 completed (loss: 0.41995394229888916, acc: 0.8909090757369995)
[2024-11-14 09:43:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:19][root][INFO] - Training Epoch: 2/2, step 9144/16670 completed (loss: 0.22919431328773499, acc: 0.9056603908538818)
[2024-11-14 09:43:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:19][root][INFO] - Training Epoch: 2/2, step 9145/16670 completed (loss: 0.11047454923391342, acc: 0.9870129823684692)
[2024-11-14 09:43:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:19][root][INFO] - Training Epoch: 2/2, step 9146/16670 completed (loss: 0.4386844336986542, acc: 0.8799999952316284)
[2024-11-14 09:43:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:20][root][INFO] - Training Epoch: 2/2, step 9147/16670 completed (loss: 0.43776583671569824, acc: 0.9069767594337463)
[2024-11-14 09:43:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:20][root][INFO] - Training Epoch: 2/2, step 9148/16670 completed (loss: 0.23878389596939087, acc: 0.9322034120559692)
[2024-11-14 09:43:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:20][root][INFO] - Training Epoch: 2/2, step 9149/16670 completed (loss: 0.18807654082775116, acc: 0.9375)
[2024-11-14 09:43:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:21][root][INFO] - Training Epoch: 2/2, step 9150/16670 completed (loss: 0.1517125517129898, acc: 0.9384615421295166)
[2024-11-14 09:43:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:21][root][INFO] - Training Epoch: 2/2, step 9151/16670 completed (loss: 0.16041630506515503, acc: 0.9473684430122375)
[2024-11-14 09:43:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:21][root][INFO] - Training Epoch: 2/2, step 9152/16670 completed (loss: 0.08038649708032608, acc: 1.0)
[2024-11-14 09:43:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:22][root][INFO] - Training Epoch: 2/2, step 9153/16670 completed (loss: 0.47526559233665466, acc: 0.8484848737716675)
[2024-11-14 09:43:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:22][root][INFO] - Training Epoch: 2/2, step 9154/16670 completed (loss: 0.34568387269973755, acc: 0.9107142686843872)
[2024-11-14 09:43:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:22][root][INFO] - Training Epoch: 2/2, step 9155/16670 completed (loss: 0.19439885020256042, acc: 0.9714285731315613)
[2024-11-14 09:43:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:23][root][INFO] - Training Epoch: 2/2, step 9156/16670 completed (loss: 0.5546290874481201, acc: 0.8985507488250732)
[2024-11-14 09:43:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:23][root][INFO] - Training Epoch: 2/2, step 9157/16670 completed (loss: 0.06281746178865433, acc: 0.9677419066429138)
[2024-11-14 09:43:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:23][root][INFO] - Training Epoch: 2/2, step 9158/16670 completed (loss: 0.3061809539794922, acc: 0.921875)
[2024-11-14 09:43:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:24][root][INFO] - Training Epoch: 2/2, step 9159/16670 completed (loss: 0.4302622377872467, acc: 0.9130434989929199)
[2024-11-14 09:43:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:24][root][INFO] - Training Epoch: 2/2, step 9160/16670 completed (loss: 0.5163736939430237, acc: 0.8636363744735718)
[2024-11-14 09:43:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:24][root][INFO] - Training Epoch: 2/2, step 9161/16670 completed (loss: 0.5007619857788086, acc: 0.9074074029922485)
[2024-11-14 09:43:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:25][root][INFO] - Training Epoch: 2/2, step 9162/16670 completed (loss: 0.25730693340301514, acc: 0.9347826242446899)
[2024-11-14 09:43:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:25][root][INFO] - Training Epoch: 2/2, step 9163/16670 completed (loss: 0.42851030826568604, acc: 0.931506872177124)
[2024-11-14 09:43:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:25][root][INFO] - Training Epoch: 2/2, step 9164/16670 completed (loss: 0.2923714220523834, acc: 0.90625)
[2024-11-14 09:43:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:26][root][INFO] - Training Epoch: 2/2, step 9165/16670 completed (loss: 0.9081792831420898, acc: 0.8301886916160583)
[2024-11-14 09:43:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:26][root][INFO] - Training Epoch: 2/2, step 9166/16670 completed (loss: 0.1719207912683487, acc: 0.9411764740943909)
[2024-11-14 09:43:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:26][root][INFO] - Training Epoch: 2/2, step 9167/16670 completed (loss: 0.09763285517692566, acc: 1.0)
[2024-11-14 09:43:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:27][root][INFO] - Training Epoch: 2/2, step 9168/16670 completed (loss: 0.2276402711868286, acc: 0.8947368264198303)
[2024-11-14 09:43:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:27][root][INFO] - Training Epoch: 2/2, step 9169/16670 completed (loss: 0.2790316641330719, acc: 0.9285714030265808)
[2024-11-14 09:43:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:28][root][INFO] - Training Epoch: 2/2, step 9170/16670 completed (loss: 0.21844159066677094, acc: 0.9466666579246521)
[2024-11-14 09:43:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:28][root][INFO] - Training Epoch: 2/2, step 9171/16670 completed (loss: 0.4601871371269226, acc: 0.9019607901573181)
[2024-11-14 09:43:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:28][root][INFO] - Training Epoch: 2/2, step 9172/16670 completed (loss: 0.13210158050060272, acc: 0.9710144996643066)
[2024-11-14 09:43:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:29][root][INFO] - Training Epoch: 2/2, step 9173/16670 completed (loss: 0.04486539959907532, acc: 1.0)
[2024-11-14 09:43:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:29][root][INFO] - Training Epoch: 2/2, step 9174/16670 completed (loss: 0.19425322115421295, acc: 0.9189189076423645)
[2024-11-14 09:43:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:29][root][INFO] - Training Epoch: 2/2, step 9175/16670 completed (loss: 0.37625929713249207, acc: 0.9324324131011963)
[2024-11-14 09:43:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:30][root][INFO] - Training Epoch: 2/2, step 9176/16670 completed (loss: 0.5467749834060669, acc: 0.8793103694915771)
[2024-11-14 09:43:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:30][root][INFO] - Training Epoch: 2/2, step 9177/16670 completed (loss: 0.27416160702705383, acc: 0.9545454382896423)
[2024-11-14 09:43:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:30][root][INFO] - Training Epoch: 2/2, step 9178/16670 completed (loss: 0.46209537982940674, acc: 0.930232584476471)
[2024-11-14 09:43:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:31][root][INFO] - Training Epoch: 2/2, step 9179/16670 completed (loss: 0.5346196293830872, acc: 0.8571428656578064)
[2024-11-14 09:43:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:31][root][INFO] - Training Epoch: 2/2, step 9180/16670 completed (loss: 0.4615984559059143, acc: 0.8157894611358643)
[2024-11-14 09:43:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:31][root][INFO] - Training Epoch: 2/2, step 9181/16670 completed (loss: 0.08564486354589462, acc: 1.0)
[2024-11-14 09:43:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:32][root][INFO] - Training Epoch: 2/2, step 9182/16670 completed (loss: 0.16451424360275269, acc: 0.9387755393981934)
[2024-11-14 09:43:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:32][root][INFO] - Training Epoch: 2/2, step 9183/16670 completed (loss: 0.3935982584953308, acc: 0.8620689511299133)
[2024-11-14 09:43:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:32][root][INFO] - Training Epoch: 2/2, step 9184/16670 completed (loss: 0.35357892513275146, acc: 0.9111111164093018)
[2024-11-14 09:43:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:33][root][INFO] - Training Epoch: 2/2, step 9185/16670 completed (loss: 0.1924956887960434, acc: 0.9200000166893005)
[2024-11-14 09:43:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:33][root][INFO] - Training Epoch: 2/2, step 9186/16670 completed (loss: 0.42632779479026794, acc: 0.9014084339141846)
[2024-11-14 09:43:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:34][root][INFO] - Training Epoch: 2/2, step 9187/16670 completed (loss: 0.3209003806114197, acc: 0.9041095972061157)
[2024-11-14 09:43:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:34][root][INFO] - Training Epoch: 2/2, step 9188/16670 completed (loss: 0.5649174451828003, acc: 0.8735632300376892)
[2024-11-14 09:43:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:34][root][INFO] - Training Epoch: 2/2, step 9189/16670 completed (loss: 0.1896362006664276, acc: 0.9692307710647583)
[2024-11-14 09:43:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:35][root][INFO] - Training Epoch: 2/2, step 9190/16670 completed (loss: 0.34768128395080566, acc: 0.9090909361839294)
[2024-11-14 09:43:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:35][root][INFO] - Training Epoch: 2/2, step 9191/16670 completed (loss: 0.18185730278491974, acc: 0.9200000166893005)
[2024-11-14 09:43:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:35][root][INFO] - Training Epoch: 2/2, step 9192/16670 completed (loss: 0.5170041918754578, acc: 0.9210526347160339)
[2024-11-14 09:43:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:36][root][INFO] - Training Epoch: 2/2, step 9193/16670 completed (loss: 0.4262021481990814, acc: 0.8653846383094788)
[2024-11-14 09:43:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:36][root][INFO] - Training Epoch: 2/2, step 9194/16670 completed (loss: 0.06640978157520294, acc: 1.0)
[2024-11-14 09:43:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:36][root][INFO] - Training Epoch: 2/2, step 9195/16670 completed (loss: 0.7151331305503845, acc: 0.8035714030265808)
[2024-11-14 09:43:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:37][root][INFO] - Training Epoch: 2/2, step 9196/16670 completed (loss: 0.9876588582992554, acc: 0.7555555701255798)
[2024-11-14 09:43:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:37][root][INFO] - Training Epoch: 2/2, step 9197/16670 completed (loss: 0.10050810128450394, acc: 0.9743589758872986)
[2024-11-14 09:43:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:37][root][INFO] - Training Epoch: 2/2, step 9198/16670 completed (loss: 0.1437934935092926, acc: 0.9599999785423279)
[2024-11-14 09:43:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:38][root][INFO] - Training Epoch: 2/2, step 9199/16670 completed (loss: 0.569995641708374, acc: 0.8888888955116272)
[2024-11-14 09:43:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:38][root][INFO] - Training Epoch: 2/2, step 9200/16670 completed (loss: 0.3546288013458252, acc: 0.9090909361839294)
[2024-11-14 09:43:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:38][root][INFO] - Training Epoch: 2/2, step 9201/16670 completed (loss: 0.4336850047111511, acc: 0.9354838728904724)
[2024-11-14 09:43:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:39][root][INFO] - Training Epoch: 2/2, step 9202/16670 completed (loss: 0.21789106726646423, acc: 0.931034505367279)
[2024-11-14 09:43:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:39][root][INFO] - Training Epoch: 2/2, step 9203/16670 completed (loss: 1.6519309282302856, acc: 0.6153846383094788)
[2024-11-14 09:43:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:39][root][INFO] - Training Epoch: 2/2, step 9204/16670 completed (loss: 0.3457043170928955, acc: 0.8928571343421936)
[2024-11-14 09:43:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:40][root][INFO] - Training Epoch: 2/2, step 9205/16670 completed (loss: 0.3138754963874817, acc: 0.8600000143051147)
[2024-11-14 09:43:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:40][root][INFO] - Training Epoch: 2/2, step 9206/16670 completed (loss: 0.8814122676849365, acc: 0.8360655903816223)
[2024-11-14 09:43:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:41][root][INFO] - Training Epoch: 2/2, step 9207/16670 completed (loss: 0.7092745304107666, acc: 0.8205128312110901)
[2024-11-14 09:43:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:41][root][INFO] - Training Epoch: 2/2, step 9208/16670 completed (loss: 0.517595112323761, acc: 0.8958333134651184)
[2024-11-14 09:43:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:41][root][INFO] - Training Epoch: 2/2, step 9209/16670 completed (loss: 0.3541156053543091, acc: 0.9024389982223511)
[2024-11-14 09:43:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:42][root][INFO] - Training Epoch: 2/2, step 9210/16670 completed (loss: 0.5425501465797424, acc: 0.9076923131942749)
[2024-11-14 09:43:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:42][root][INFO] - Training Epoch: 2/2, step 9211/16670 completed (loss: 0.14092883467674255, acc: 0.9375)
[2024-11-14 09:43:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:42][root][INFO] - Training Epoch: 2/2, step 9212/16670 completed (loss: 0.5471879839897156, acc: 0.8641975522041321)
[2024-11-14 09:43:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:43][root][INFO] - Training Epoch: 2/2, step 9213/16670 completed (loss: 0.5389046669006348, acc: 0.8909090757369995)
[2024-11-14 09:43:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:43][root][INFO] - Training Epoch: 2/2, step 9214/16670 completed (loss: 0.6740451455116272, acc: 0.8214285969734192)
[2024-11-14 09:43:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:43][root][INFO] - Training Epoch: 2/2, step 9215/16670 completed (loss: 0.3079072833061218, acc: 0.9122806787490845)
[2024-11-14 09:43:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:43][root][INFO] - Training Epoch: 2/2, step 9216/16670 completed (loss: 0.7899426817893982, acc: 0.837837815284729)
[2024-11-14 09:43:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:44][root][INFO] - Training Epoch: 2/2, step 9217/16670 completed (loss: 0.6500456929206848, acc: 0.8571428656578064)
[2024-11-14 09:43:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:44][root][INFO] - Training Epoch: 2/2, step 9218/16670 completed (loss: 0.7445729374885559, acc: 0.7931034564971924)
[2024-11-14 09:43:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:44][root][INFO] - Training Epoch: 2/2, step 9219/16670 completed (loss: 0.898088812828064, acc: 0.800000011920929)
[2024-11-14 09:43:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:45][root][INFO] - Training Epoch: 2/2, step 9220/16670 completed (loss: 0.2738499045372009, acc: 0.925000011920929)
[2024-11-14 09:43:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:45][root][INFO] - Training Epoch: 2/2, step 9221/16670 completed (loss: 0.6391578316688538, acc: 0.8222222328186035)
[2024-11-14 09:43:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:45][root][INFO] - Training Epoch: 2/2, step 9222/16670 completed (loss: 0.43477165699005127, acc: 0.9047619104385376)
[2024-11-14 09:43:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:46][root][INFO] - Training Epoch: 2/2, step 9223/16670 completed (loss: 0.5369962453842163, acc: 0.8873239159584045)
[2024-11-14 09:43:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:46][root][INFO] - Training Epoch: 2/2, step 9224/16670 completed (loss: 0.8519328832626343, acc: 0.8181818127632141)
[2024-11-14 09:43:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:46][root][INFO] - Training Epoch: 2/2, step 9225/16670 completed (loss: 0.5392048358917236, acc: 0.8644067645072937)
[2024-11-14 09:43:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:46][root][INFO] - Training Epoch: 2/2, step 9226/16670 completed (loss: 0.539933979511261, acc: 0.8780487775802612)
[2024-11-14 09:43:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:47][root][INFO] - Training Epoch: 2/2, step 9227/16670 completed (loss: 0.32860907912254333, acc: 0.9523809552192688)
[2024-11-14 09:43:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:47][root][INFO] - Training Epoch: 2/2, step 9228/16670 completed (loss: 0.15382102131843567, acc: 0.9750000238418579)
[2024-11-14 09:43:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:47][root][INFO] - Training Epoch: 2/2, step 9229/16670 completed (loss: 0.609707236289978, acc: 0.8823529481887817)
[2024-11-14 09:43:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:48][root][INFO] - Training Epoch: 2/2, step 9230/16670 completed (loss: 0.5266014933586121, acc: 0.8999999761581421)
[2024-11-14 09:43:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:48][root][INFO] - Training Epoch: 2/2, step 9231/16670 completed (loss: 0.8663330674171448, acc: 0.8541666865348816)
[2024-11-14 09:43:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:48][root][INFO] - Training Epoch: 2/2, step 9232/16670 completed (loss: 1.0278279781341553, acc: 0.8799999952316284)
[2024-11-14 09:43:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:49][root][INFO] - Training Epoch: 2/2, step 9233/16670 completed (loss: 0.10437683761119843, acc: 0.9824561476707458)
[2024-11-14 09:43:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:49][root][INFO] - Training Epoch: 2/2, step 9234/16670 completed (loss: 0.28926268219947815, acc: 0.9322034120559692)
[2024-11-14 09:43:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:49][root][INFO] - Training Epoch: 2/2, step 9235/16670 completed (loss: 0.5055500268936157, acc: 0.8444444537162781)
[2024-11-14 09:43:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:50][root][INFO] - Training Epoch: 2/2, step 9236/16670 completed (loss: 0.3268265724182129, acc: 0.8421052694320679)
[2024-11-14 09:43:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:50][root][INFO] - Training Epoch: 2/2, step 9237/16670 completed (loss: 0.6907480359077454, acc: 0.8510638475418091)
[2024-11-14 09:43:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:51][root][INFO] - Training Epoch: 2/2, step 9238/16670 completed (loss: 0.15799115598201752, acc: 0.9701492786407471)
[2024-11-14 09:43:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:51][root][INFO] - Training Epoch: 2/2, step 9239/16670 completed (loss: 0.5520684123039246, acc: 0.9074074029922485)
[2024-11-14 09:43:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:51][root][INFO] - Training Epoch: 2/2, step 9240/16670 completed (loss: 0.6222168803215027, acc: 0.8488371968269348)
[2024-11-14 09:43:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:52][root][INFO] - Training Epoch: 2/2, step 9241/16670 completed (loss: 0.5474920272827148, acc: 0.8666666746139526)
[2024-11-14 09:43:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:52][root][INFO] - Training Epoch: 2/2, step 9242/16670 completed (loss: 0.04218290001153946, acc: 1.0)
[2024-11-14 09:43:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:52][root][INFO] - Training Epoch: 2/2, step 9243/16670 completed (loss: 0.09388214349746704, acc: 0.9714285731315613)
[2024-11-14 09:43:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:53][root][INFO] - Training Epoch: 2/2, step 9244/16670 completed (loss: 0.5886811017990112, acc: 0.8461538553237915)
[2024-11-14 09:43:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:53][root][INFO] - Training Epoch: 2/2, step 9245/16670 completed (loss: 0.3390255868434906, acc: 0.9117646813392639)
[2024-11-14 09:43:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:53][root][INFO] - Training Epoch: 2/2, step 9246/16670 completed (loss: 0.2379423826932907, acc: 0.9189189076423645)
[2024-11-14 09:43:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:54][root][INFO] - Training Epoch: 2/2, step 9247/16670 completed (loss: 0.2555413842201233, acc: 0.90625)
[2024-11-14 09:43:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:54][root][INFO] - Training Epoch: 2/2, step 9248/16670 completed (loss: 0.23513229191303253, acc: 0.9107142686843872)
[2024-11-14 09:43:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:55][root][INFO] - Training Epoch: 2/2, step 9249/16670 completed (loss: 0.7294714450836182, acc: 0.9069767594337463)
[2024-11-14 09:43:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:55][root][INFO] - Training Epoch: 2/2, step 9250/16670 completed (loss: 0.3190610110759735, acc: 0.8947368264198303)
[2024-11-14 09:43:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:55][root][INFO] - Training Epoch: 2/2, step 9251/16670 completed (loss: 0.13267387449741364, acc: 0.97826087474823)
[2024-11-14 09:43:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:56][root][INFO] - Training Epoch: 2/2, step 9252/16670 completed (loss: 0.817074716091156, acc: 0.7966101765632629)
[2024-11-14 09:43:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:56][root][INFO] - Training Epoch: 2/2, step 9253/16670 completed (loss: 0.6029982566833496, acc: 0.8571428656578064)
[2024-11-14 09:43:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:56][root][INFO] - Training Epoch: 2/2, step 9254/16670 completed (loss: 0.15105688571929932, acc: 1.0)
[2024-11-14 09:43:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:57][root][INFO] - Training Epoch: 2/2, step 9255/16670 completed (loss: 0.5756613612174988, acc: 0.8333333134651184)
[2024-11-14 09:43:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:57][root][INFO] - Training Epoch: 2/2, step 9256/16670 completed (loss: 0.13110673427581787, acc: 0.9852941036224365)
[2024-11-14 09:43:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:58][root][INFO] - Training Epoch: 2/2, step 9257/16670 completed (loss: 0.38845932483673096, acc: 0.925000011920929)
[2024-11-14 09:43:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:58][root][INFO] - Training Epoch: 2/2, step 9258/16670 completed (loss: 0.30917030572891235, acc: 0.9230769276618958)
[2024-11-14 09:43:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:58][root][INFO] - Training Epoch: 2/2, step 9259/16670 completed (loss: 0.388287216424942, acc: 0.89552241563797)
[2024-11-14 09:43:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:59][root][INFO] - Training Epoch: 2/2, step 9260/16670 completed (loss: 0.4024306535720825, acc: 0.9230769276618958)
[2024-11-14 09:43:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:59][root][INFO] - Training Epoch: 2/2, step 9261/16670 completed (loss: 0.1281561404466629, acc: 0.9642857313156128)
[2024-11-14 09:43:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:43:59][root][INFO] - Training Epoch: 2/2, step 9262/16670 completed (loss: 1.2375339269638062, acc: 0.7749999761581421)
[2024-11-14 09:44:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:00][root][INFO] - Training Epoch: 2/2, step 9263/16670 completed (loss: 0.35773783922195435, acc: 0.90625)
[2024-11-14 09:44:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:00][root][INFO] - Training Epoch: 2/2, step 9264/16670 completed (loss: 0.5472211837768555, acc: 0.8428571224212646)
[2024-11-14 09:44:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:01][root][INFO] - Training Epoch: 2/2, step 9265/16670 completed (loss: 0.17359711229801178, acc: 0.9555555582046509)
[2024-11-14 09:44:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:01][root][INFO] - Training Epoch: 2/2, step 9266/16670 completed (loss: 0.45609530806541443, acc: 0.9295774698257446)
[2024-11-14 09:44:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:01][root][INFO] - Training Epoch: 2/2, step 9267/16670 completed (loss: 0.1997918039560318, acc: 0.957446813583374)
[2024-11-14 09:44:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:02][root][INFO] - Training Epoch: 2/2, step 9268/16670 completed (loss: 0.14950890839099884, acc: 0.9642857313156128)
[2024-11-14 09:44:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:02][root][INFO] - Training Epoch: 2/2, step 9269/16670 completed (loss: 0.15245728194713593, acc: 0.9795918464660645)
[2024-11-14 09:44:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:02][root][INFO] - Training Epoch: 2/2, step 9270/16670 completed (loss: 0.4101494252681732, acc: 0.8813559412956238)
[2024-11-14 09:44:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:03][root][INFO] - Training Epoch: 2/2, step 9271/16670 completed (loss: 0.34662964940071106, acc: 0.9139785170555115)
[2024-11-14 09:44:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:03][root][INFO] - Training Epoch: 2/2, step 9272/16670 completed (loss: 0.5801680684089661, acc: 0.8260869383811951)
[2024-11-14 09:44:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:03][root][INFO] - Training Epoch: 2/2, step 9273/16670 completed (loss: 0.09779928624629974, acc: 0.9750000238418579)
[2024-11-14 09:44:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:04][root][INFO] - Training Epoch: 2/2, step 9274/16670 completed (loss: 0.45722508430480957, acc: 0.8888888955116272)
[2024-11-14 09:44:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:04][root][INFO] - Training Epoch: 2/2, step 9275/16670 completed (loss: 0.06405967473983765, acc: 1.0)
[2024-11-14 09:44:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:04][root][INFO] - Training Epoch: 2/2, step 9276/16670 completed (loss: 0.4571196734905243, acc: 0.8732394576072693)
[2024-11-14 09:44:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:04][root][INFO] - Training Epoch: 2/2, step 9277/16670 completed (loss: 0.38772743940353394, acc: 0.9215686321258545)
[2024-11-14 09:44:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:05][root][INFO] - Training Epoch: 2/2, step 9278/16670 completed (loss: 0.4663732051849365, acc: 0.875)
[2024-11-14 09:44:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:05][root][INFO] - Training Epoch: 2/2, step 9279/16670 completed (loss: 0.39898771047592163, acc: 0.895348846912384)
[2024-11-14 09:44:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:06][root][INFO] - Training Epoch: 2/2, step 9280/16670 completed (loss: 0.48056668043136597, acc: 0.9245283007621765)
[2024-11-14 09:44:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:06][root][INFO] - Training Epoch: 2/2, step 9281/16670 completed (loss: 0.5442269444465637, acc: 0.9074074029922485)
[2024-11-14 09:44:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:06][root][INFO] - Training Epoch: 2/2, step 9282/16670 completed (loss: 0.36556440591812134, acc: 0.9354838728904724)
[2024-11-14 09:44:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:06][root][INFO] - Training Epoch: 2/2, step 9283/16670 completed (loss: 0.3467533588409424, acc: 0.9210526347160339)
[2024-11-14 09:44:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:07][root][INFO] - Training Epoch: 2/2, step 9284/16670 completed (loss: 0.2286267876625061, acc: 0.939393937587738)
[2024-11-14 09:44:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:07][root][INFO] - Training Epoch: 2/2, step 9285/16670 completed (loss: 0.15644775331020355, acc: 0.9666666388511658)
[2024-11-14 09:44:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:07][root][INFO] - Training Epoch: 2/2, step 9286/16670 completed (loss: 0.563511073589325, acc: 0.8734177350997925)
[2024-11-14 09:44:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:08][root][INFO] - Training Epoch: 2/2, step 9287/16670 completed (loss: 0.511436939239502, acc: 0.8787878751754761)
[2024-11-14 09:44:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:08][root][INFO] - Training Epoch: 2/2, step 9288/16670 completed (loss: 0.1286088079214096, acc: 0.9795918464660645)
[2024-11-14 09:44:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:09][root][INFO] - Training Epoch: 2/2, step 9289/16670 completed (loss: 0.5318070650100708, acc: 0.8823529481887817)
[2024-11-14 09:44:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:09][root][INFO] - Training Epoch: 2/2, step 9290/16670 completed (loss: 0.3508369028568268, acc: 0.9354838728904724)
[2024-11-14 09:44:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:09][root][INFO] - Training Epoch: 2/2, step 9291/16670 completed (loss: 0.3792083263397217, acc: 0.907216489315033)
[2024-11-14 09:44:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:10][root][INFO] - Training Epoch: 2/2, step 9292/16670 completed (loss: 0.7375585436820984, acc: 0.8876404762268066)
[2024-11-14 09:44:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:10][root][INFO] - Training Epoch: 2/2, step 9293/16670 completed (loss: 0.5398750305175781, acc: 0.8529411554336548)
[2024-11-14 09:44:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:10][root][INFO] - Training Epoch: 2/2, step 9294/16670 completed (loss: 0.40200650691986084, acc: 0.9027777910232544)
[2024-11-14 09:44:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:11][root][INFO] - Training Epoch: 2/2, step 9295/16670 completed (loss: 0.31809747219085693, acc: 0.9200000166893005)
[2024-11-14 09:44:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:11][root][INFO] - Training Epoch: 2/2, step 9296/16670 completed (loss: 0.13513679802417755, acc: 0.9655172228813171)
[2024-11-14 09:44:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:11][root][INFO] - Training Epoch: 2/2, step 9297/16670 completed (loss: 0.2563123404979706, acc: 0.9344262480735779)
[2024-11-14 09:44:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:12][root][INFO] - Training Epoch: 2/2, step 9298/16670 completed (loss: 0.6048308610916138, acc: 0.8700000047683716)
[2024-11-14 09:44:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:12][root][INFO] - Training Epoch: 2/2, step 9299/16670 completed (loss: 0.12375978380441666, acc: 0.9571428298950195)
[2024-11-14 09:44:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:12][root][INFO] - Training Epoch: 2/2, step 9300/16670 completed (loss: 0.5702399611473083, acc: 0.8571428656578064)
[2024-11-14 09:44:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:13][root][INFO] - Training Epoch: 2/2, step 9301/16670 completed (loss: 0.42934921383857727, acc: 0.9193548560142517)
[2024-11-14 09:44:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:13][root][INFO] - Training Epoch: 2/2, step 9302/16670 completed (loss: 0.06609120965003967, acc: 1.0)
[2024-11-14 09:44:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:13][root][INFO] - Training Epoch: 2/2, step 9303/16670 completed (loss: 0.10581790655851364, acc: 0.9746835231781006)
[2024-11-14 09:44:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:14][root][INFO] - Training Epoch: 2/2, step 9304/16670 completed (loss: 0.044903822243213654, acc: 1.0)
[2024-11-14 09:44:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:14][root][INFO] - Training Epoch: 2/2, step 9305/16670 completed (loss: 0.2531546354293823, acc: 0.9230769276618958)
[2024-11-14 09:44:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:14][root][INFO] - Training Epoch: 2/2, step 9306/16670 completed (loss: 0.5099598169326782, acc: 0.8461538553237915)
[2024-11-14 09:44:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:15][root][INFO] - Training Epoch: 2/2, step 9307/16670 completed (loss: 0.019994769245386124, acc: 1.0)
[2024-11-14 09:44:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:15][root][INFO] - Training Epoch: 2/2, step 9308/16670 completed (loss: 0.4715246260166168, acc: 0.8507462739944458)
[2024-11-14 09:44:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:15][root][INFO] - Training Epoch: 2/2, step 9309/16670 completed (loss: 0.3140462636947632, acc: 0.914893627166748)
[2024-11-14 09:44:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:16][root][INFO] - Training Epoch: 2/2, step 9310/16670 completed (loss: 0.42500585317611694, acc: 0.8679245114326477)
[2024-11-14 09:44:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:16][root][INFO] - Training Epoch: 2/2, step 9311/16670 completed (loss: 0.5977160930633545, acc: 0.9354838728904724)
[2024-11-14 09:44:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:16][root][INFO] - Training Epoch: 2/2, step 9312/16670 completed (loss: 0.3364596366882324, acc: 0.9019607901573181)
[2024-11-14 09:44:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:17][root][INFO] - Training Epoch: 2/2, step 9313/16670 completed (loss: 0.40128567814826965, acc: 0.9204545617103577)
[2024-11-14 09:44:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:17][root][INFO] - Training Epoch: 2/2, step 9314/16670 completed (loss: 0.11332625895738602, acc: 0.9649122953414917)
[2024-11-14 09:44:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:17][root][INFO] - Training Epoch: 2/2, step 9315/16670 completed (loss: 0.2646450102329254, acc: 0.939393937587738)
[2024-11-14 09:44:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:18][root][INFO] - Training Epoch: 2/2, step 9316/16670 completed (loss: 0.4267958998680115, acc: 0.9113923907279968)
[2024-11-14 09:44:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:18][root][INFO] - Training Epoch: 2/2, step 9317/16670 completed (loss: 0.3590366244316101, acc: 0.8965517282485962)
[2024-11-14 09:44:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:18][root][INFO] - Training Epoch: 2/2, step 9318/16670 completed (loss: 0.486320823431015, acc: 0.8518518805503845)
[2024-11-14 09:44:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:19][root][INFO] - Training Epoch: 2/2, step 9319/16670 completed (loss: 0.22493694722652435, acc: 0.9411764740943909)
[2024-11-14 09:44:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:19][root][INFO] - Training Epoch: 2/2, step 9320/16670 completed (loss: 0.5612428784370422, acc: 0.8260869383811951)
[2024-11-14 09:44:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:19][root][INFO] - Training Epoch: 2/2, step 9321/16670 completed (loss: 0.3956267535686493, acc: 0.9166666865348816)
[2024-11-14 09:44:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:20][root][INFO] - Training Epoch: 2/2, step 9322/16670 completed (loss: 0.4374288320541382, acc: 0.9508196711540222)
[2024-11-14 09:44:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:20][root][INFO] - Training Epoch: 2/2, step 9323/16670 completed (loss: 0.31804877519607544, acc: 0.9333333373069763)
[2024-11-14 09:44:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:21][root][INFO] - Training Epoch: 2/2, step 9324/16670 completed (loss: 0.8590276837348938, acc: 0.8108108043670654)
[2024-11-14 09:44:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:21][root][INFO] - Training Epoch: 2/2, step 9325/16670 completed (loss: 0.42189767956733704, acc: 0.9333333373069763)
[2024-11-14 09:44:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:21][root][INFO] - Training Epoch: 2/2, step 9326/16670 completed (loss: 0.43553176522254944, acc: 0.9047619104385376)
[2024-11-14 09:44:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:22][root][INFO] - Training Epoch: 2/2, step 9327/16670 completed (loss: 0.8064070343971252, acc: 0.8452380895614624)
[2024-11-14 09:44:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:22][root][INFO] - Training Epoch: 2/2, step 9328/16670 completed (loss: 0.12728019058704376, acc: 0.9855072498321533)
[2024-11-14 09:44:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:22][root][INFO] - Training Epoch: 2/2, step 9329/16670 completed (loss: 0.4835685193538666, acc: 0.8999999761581421)
[2024-11-14 09:44:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:23][root][INFO] - Training Epoch: 2/2, step 9330/16670 completed (loss: 0.5573564171791077, acc: 0.8974359035491943)
[2024-11-14 09:44:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:23][root][INFO] - Training Epoch: 2/2, step 9331/16670 completed (loss: 0.22426453232765198, acc: 0.931506872177124)
[2024-11-14 09:44:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:23][root][INFO] - Training Epoch: 2/2, step 9332/16670 completed (loss: 0.3040716350078583, acc: 0.9384615421295166)
[2024-11-14 09:44:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:24][root][INFO] - Training Epoch: 2/2, step 9333/16670 completed (loss: 0.11195620149374008, acc: 0.976190447807312)
[2024-11-14 09:44:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:24][root][INFO] - Training Epoch: 2/2, step 9334/16670 completed (loss: 0.24393218755722046, acc: 0.9166666865348816)
[2024-11-14 09:44:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:24][root][INFO] - Training Epoch: 2/2, step 9335/16670 completed (loss: 0.29584869742393494, acc: 0.8571428656578064)
[2024-11-14 09:44:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:25][root][INFO] - Training Epoch: 2/2, step 9336/16670 completed (loss: 0.3862968385219574, acc: 0.9142857193946838)
[2024-11-14 09:44:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:25][root][INFO] - Training Epoch: 2/2, step 9337/16670 completed (loss: 0.32484209537506104, acc: 0.9545454382896423)
[2024-11-14 09:44:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:25][root][INFO] - Training Epoch: 2/2, step 9338/16670 completed (loss: 0.24965959787368774, acc: 0.9298245906829834)
[2024-11-14 09:44:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:26][root][INFO] - Training Epoch: 2/2, step 9339/16670 completed (loss: 0.10670243203639984, acc: 1.0)
[2024-11-14 09:44:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:26][root][INFO] - Training Epoch: 2/2, step 9340/16670 completed (loss: 0.7148960828781128, acc: 0.8493150472640991)
[2024-11-14 09:44:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:26][root][INFO] - Training Epoch: 2/2, step 9341/16670 completed (loss: 0.0929829403758049, acc: 0.9800000190734863)
[2024-11-14 09:44:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:27][root][INFO] - Training Epoch: 2/2, step 9342/16670 completed (loss: 0.21362751722335815, acc: 0.9375)
[2024-11-14 09:44:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:27][root][INFO] - Training Epoch: 2/2, step 9343/16670 completed (loss: 0.4218582212924957, acc: 0.8850574493408203)
[2024-11-14 09:44:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:27][root][INFO] - Training Epoch: 2/2, step 9344/16670 completed (loss: 0.15667875111103058, acc: 0.9411764740943909)
[2024-11-14 09:44:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:28][root][INFO] - Training Epoch: 2/2, step 9345/16670 completed (loss: 0.22365278005599976, acc: 0.8999999761581421)
[2024-11-14 09:44:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:28][root][INFO] - Training Epoch: 2/2, step 9346/16670 completed (loss: 0.194933220744133, acc: 0.9431818127632141)
[2024-11-14 09:44:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:28][root][INFO] - Training Epoch: 2/2, step 9347/16670 completed (loss: 0.34513983130455017, acc: 0.9137930870056152)
[2024-11-14 09:44:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:29][root][INFO] - Training Epoch: 2/2, step 9348/16670 completed (loss: 0.26989367604255676, acc: 0.9047619104385376)
[2024-11-14 09:44:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:29][root][INFO] - Training Epoch: 2/2, step 9349/16670 completed (loss: 0.2874375879764557, acc: 0.9142857193946838)
[2024-11-14 09:44:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:29][root][INFO] - Training Epoch: 2/2, step 9350/16670 completed (loss: 0.2380983829498291, acc: 0.9178082346916199)
[2024-11-14 09:44:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:30][root][INFO] - Training Epoch: 2/2, step 9351/16670 completed (loss: 0.5054562091827393, acc: 0.8909090757369995)
[2024-11-14 09:44:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:30][root][INFO] - Training Epoch: 2/2, step 9352/16670 completed (loss: 0.3528658449649811, acc: 0.8958333134651184)
[2024-11-14 09:44:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:30][root][INFO] - Training Epoch: 2/2, step 9353/16670 completed (loss: 0.630419909954071, acc: 0.8804348111152649)
[2024-11-14 09:44:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:31][root][INFO] - Training Epoch: 2/2, step 9354/16670 completed (loss: 0.14084410667419434, acc: 0.9615384340286255)
[2024-11-14 09:44:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:31][root][INFO] - Training Epoch: 2/2, step 9355/16670 completed (loss: 0.4008086621761322, acc: 0.9130434989929199)
[2024-11-14 09:44:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:31][root][INFO] - Training Epoch: 2/2, step 9356/16670 completed (loss: 0.05168496072292328, acc: 1.0)
[2024-11-14 09:44:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:32][root][INFO] - Training Epoch: 2/2, step 9357/16670 completed (loss: 0.3601851761341095, acc: 0.9285714030265808)
[2024-11-14 09:44:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:32][root][INFO] - Training Epoch: 2/2, step 9358/16670 completed (loss: 0.3080516457557678, acc: 0.9285714030265808)
[2024-11-14 09:44:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:32][root][INFO] - Training Epoch: 2/2, step 9359/16670 completed (loss: 0.27180927991867065, acc: 0.9464285969734192)
[2024-11-14 09:44:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:33][root][INFO] - Training Epoch: 2/2, step 9360/16670 completed (loss: 0.47879651188850403, acc: 0.8607594966888428)
[2024-11-14 09:44:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:33][root][INFO] - Training Epoch: 2/2, step 9361/16670 completed (loss: 0.6242674589157104, acc: 0.8837209343910217)
[2024-11-14 09:44:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:33][root][INFO] - Training Epoch: 2/2, step 9362/16670 completed (loss: 0.06164504215121269, acc: 1.0)
[2024-11-14 09:44:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:34][root][INFO] - Training Epoch: 2/2, step 9363/16670 completed (loss: 0.09741653501987457, acc: 0.9672130942344666)
[2024-11-14 09:44:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:34][root][INFO] - Training Epoch: 2/2, step 9364/16670 completed (loss: 0.0996202677488327, acc: 0.9545454382896423)
[2024-11-14 09:44:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:34][root][INFO] - Training Epoch: 2/2, step 9365/16670 completed (loss: 0.19093933701515198, acc: 0.9545454382896423)
[2024-11-14 09:44:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:35][root][INFO] - Training Epoch: 2/2, step 9366/16670 completed (loss: 0.6747324466705322, acc: 0.8600000143051147)
[2024-11-14 09:44:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:35][root][INFO] - Training Epoch: 2/2, step 9367/16670 completed (loss: 0.17943039536476135, acc: 0.9418604373931885)
[2024-11-14 09:44:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:35][root][INFO] - Training Epoch: 2/2, step 9368/16670 completed (loss: 0.08795871585607529, acc: 0.9599999785423279)
[2024-11-14 09:44:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:36][root][INFO] - Training Epoch: 2/2, step 9369/16670 completed (loss: 0.12828703224658966, acc: 0.9736841917037964)
[2024-11-14 09:44:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:36][root][INFO] - Training Epoch: 2/2, step 9370/16670 completed (loss: 0.49898865818977356, acc: 0.8958333134651184)
[2024-11-14 09:44:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:36][root][INFO] - Training Epoch: 2/2, step 9371/16670 completed (loss: 0.21674807369709015, acc: 0.9607843160629272)
[2024-11-14 09:44:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:37][root][INFO] - Training Epoch: 2/2, step 9372/16670 completed (loss: 0.3108437657356262, acc: 0.9428571462631226)
[2024-11-14 09:44:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:37][root][INFO] - Training Epoch: 2/2, step 9373/16670 completed (loss: 0.26043179631233215, acc: 0.9454545378684998)
[2024-11-14 09:44:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:38][root][INFO] - Training Epoch: 2/2, step 9374/16670 completed (loss: 0.318561315536499, acc: 0.9368420839309692)
[2024-11-14 09:44:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:38][root][INFO] - Training Epoch: 2/2, step 9375/16670 completed (loss: 0.35713163018226624, acc: 0.9245283007621765)
[2024-11-14 09:44:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:38][root][INFO] - Training Epoch: 2/2, step 9376/16670 completed (loss: 0.1231384128332138, acc: 0.9384615421295166)
[2024-11-14 09:44:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:39][root][INFO] - Training Epoch: 2/2, step 9377/16670 completed (loss: 0.273956298828125, acc: 0.9117646813392639)
[2024-11-14 09:44:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:39][root][INFO] - Training Epoch: 2/2, step 9378/16670 completed (loss: 0.6175334453582764, acc: 0.8644067645072937)
[2024-11-14 09:44:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:39][root][INFO] - Training Epoch: 2/2, step 9379/16670 completed (loss: 0.44526660442352295, acc: 0.9104477763175964)
[2024-11-14 09:44:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:40][root][INFO] - Training Epoch: 2/2, step 9380/16670 completed (loss: 0.36187970638275146, acc: 0.9180327653884888)
[2024-11-14 09:44:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:40][root][INFO] - Training Epoch: 2/2, step 9381/16670 completed (loss: 0.48335015773773193, acc: 0.8780487775802612)
[2024-11-14 09:44:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:40][root][INFO] - Training Epoch: 2/2, step 9382/16670 completed (loss: 0.3856067657470703, acc: 0.9130434989929199)
[2024-11-14 09:44:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:41][root][INFO] - Training Epoch: 2/2, step 9383/16670 completed (loss: 0.25404223799705505, acc: 0.9268292784690857)
[2024-11-14 09:44:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:41][root][INFO] - Training Epoch: 2/2, step 9384/16670 completed (loss: 0.38673871755599976, acc: 0.9024389982223511)
[2024-11-14 09:44:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:41][root][INFO] - Training Epoch: 2/2, step 9385/16670 completed (loss: 0.3001337945461273, acc: 0.9024389982223511)
[2024-11-14 09:44:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:42][root][INFO] - Training Epoch: 2/2, step 9386/16670 completed (loss: 0.3704695999622345, acc: 0.8913043737411499)
[2024-11-14 09:44:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:42][root][INFO] - Training Epoch: 2/2, step 9387/16670 completed (loss: 0.2982688248157501, acc: 0.9130434989929199)
[2024-11-14 09:44:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:43][root][INFO] - Training Epoch: 2/2, step 9388/16670 completed (loss: 0.7313842177391052, acc: 0.699999988079071)
[2024-11-14 09:44:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:43][root][INFO] - Training Epoch: 2/2, step 9389/16670 completed (loss: 0.3128913938999176, acc: 0.9347826242446899)
[2024-11-14 09:44:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:43][root][INFO] - Training Epoch: 2/2, step 9390/16670 completed (loss: 0.26307249069213867, acc: 0.9459459185600281)
[2024-11-14 09:44:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:44][root][INFO] - Training Epoch: 2/2, step 9391/16670 completed (loss: 0.36435753107070923, acc: 0.8611111044883728)
[2024-11-14 09:44:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:44][root][INFO] - Training Epoch: 2/2, step 9392/16670 completed (loss: 0.45733508467674255, acc: 0.8985507488250732)
[2024-11-14 09:44:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:44][root][INFO] - Training Epoch: 2/2, step 9393/16670 completed (loss: 0.4362165927886963, acc: 0.9275362491607666)
[2024-11-14 09:44:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:45][root][INFO] - Training Epoch: 2/2, step 9394/16670 completed (loss: 0.722747802734375, acc: 0.7887324094772339)
[2024-11-14 09:44:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:45][root][INFO] - Training Epoch: 2/2, step 9395/16670 completed (loss: 0.24179720878601074, acc: 0.9750000238418579)
[2024-11-14 09:44:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:45][root][INFO] - Training Epoch: 2/2, step 9396/16670 completed (loss: 0.32431766390800476, acc: 0.8983050584793091)
[2024-11-14 09:44:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:46][root][INFO] - Training Epoch: 2/2, step 9397/16670 completed (loss: 0.45675572752952576, acc: 0.8799999952316284)
[2024-11-14 09:44:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:46][root][INFO] - Training Epoch: 2/2, step 9398/16670 completed (loss: 0.43957674503326416, acc: 0.837837815284729)
[2024-11-14 09:44:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:46][root][INFO] - Training Epoch: 2/2, step 9399/16670 completed (loss: 0.4695780873298645, acc: 0.8783783912658691)
[2024-11-14 09:44:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:47][root][INFO] - Training Epoch: 2/2, step 9400/16670 completed (loss: 0.37570008635520935, acc: 0.8999999761581421)
[2024-11-14 09:44:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:47][root][INFO] - Training Epoch: 2/2, step 9401/16670 completed (loss: 0.2679659128189087, acc: 0.914893627166748)
[2024-11-14 09:44:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:47][root][INFO] - Training Epoch: 2/2, step 9402/16670 completed (loss: 0.6648333668708801, acc: 0.8765432238578796)
[2024-11-14 09:44:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:48][root][INFO] - Training Epoch: 2/2, step 9403/16670 completed (loss: 0.1267824023962021, acc: 0.9729729890823364)
[2024-11-14 09:44:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:48][root][INFO] - Training Epoch: 2/2, step 9404/16670 completed (loss: 0.3841206133365631, acc: 0.892307698726654)
[2024-11-14 09:44:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:48][root][INFO] - Training Epoch: 2/2, step 9405/16670 completed (loss: 0.45181968808174133, acc: 0.8780487775802612)
[2024-11-14 09:44:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:49][root][INFO] - Training Epoch: 2/2, step 9406/16670 completed (loss: 0.7427924275398254, acc: 0.8548387289047241)
[2024-11-14 09:44:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:49][root][INFO] - Training Epoch: 2/2, step 9407/16670 completed (loss: 0.33710038661956787, acc: 0.9295774698257446)
[2024-11-14 09:44:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:49][root][INFO] - Training Epoch: 2/2, step 9408/16670 completed (loss: 0.32097306847572327, acc: 0.9166666865348816)
[2024-11-14 09:44:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:50][root][INFO] - Training Epoch: 2/2, step 9409/16670 completed (loss: 0.29854923486709595, acc: 0.9166666865348816)
[2024-11-14 09:44:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:50][root][INFO] - Training Epoch: 2/2, step 9410/16670 completed (loss: 0.7371723651885986, acc: 0.84375)
[2024-11-14 09:44:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:50][root][INFO] - Training Epoch: 2/2, step 9411/16670 completed (loss: 0.21794138848781586, acc: 0.9555555582046509)
[2024-11-14 09:44:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:51][root][INFO] - Training Epoch: 2/2, step 9412/16670 completed (loss: 0.3036479949951172, acc: 0.9130434989929199)
[2024-11-14 09:44:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:51][root][INFO] - Training Epoch: 2/2, step 9413/16670 completed (loss: 0.7750248908996582, acc: 0.8363636136054993)
[2024-11-14 09:44:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:51][root][INFO] - Training Epoch: 2/2, step 9414/16670 completed (loss: 0.3180333971977234, acc: 0.9333333373069763)
[2024-11-14 09:44:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:52][root][INFO] - Training Epoch: 2/2, step 9415/16670 completed (loss: 0.34931471943855286, acc: 0.8823529481887817)
[2024-11-14 09:44:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:52][root][INFO] - Training Epoch: 2/2, step 9416/16670 completed (loss: 0.6095815896987915, acc: 0.8732394576072693)
[2024-11-14 09:44:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:52][root][INFO] - Training Epoch: 2/2, step 9417/16670 completed (loss: 0.32427698373794556, acc: 0.9253731369972229)
[2024-11-14 09:44:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:53][root][INFO] - Training Epoch: 2/2, step 9418/16670 completed (loss: 0.29037198424339294, acc: 0.9032257795333862)
[2024-11-14 09:44:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:53][root][INFO] - Training Epoch: 2/2, step 9419/16670 completed (loss: 0.32529416680336, acc: 0.914893627166748)
[2024-11-14 09:44:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:53][root][INFO] - Training Epoch: 2/2, step 9420/16670 completed (loss: 0.3635692000389099, acc: 0.9240506291389465)
[2024-11-14 09:44:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:54][root][INFO] - Training Epoch: 2/2, step 9421/16670 completed (loss: 0.4064769446849823, acc: 0.8679245114326477)
[2024-11-14 09:44:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:54][root][INFO] - Training Epoch: 2/2, step 9422/16670 completed (loss: 0.31636524200439453, acc: 0.9259259104728699)
[2024-11-14 09:44:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:54][root][INFO] - Training Epoch: 2/2, step 9423/16670 completed (loss: 0.3260519802570343, acc: 0.9166666865348816)
[2024-11-14 09:44:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:55][root][INFO] - Training Epoch: 2/2, step 9424/16670 completed (loss: 0.406247079372406, acc: 0.8823529481887817)
[2024-11-14 09:44:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:55][root][INFO] - Training Epoch: 2/2, step 9425/16670 completed (loss: 0.16959092020988464, acc: 0.9523809552192688)
[2024-11-14 09:44:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:55][root][INFO] - Training Epoch: 2/2, step 9426/16670 completed (loss: 0.2611563801765442, acc: 0.8999999761581421)
[2024-11-14 09:44:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:56][root][INFO] - Training Epoch: 2/2, step 9427/16670 completed (loss: 0.5371190905570984, acc: 0.875)
[2024-11-14 09:44:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:56][root][INFO] - Training Epoch: 2/2, step 9428/16670 completed (loss: 0.11751183122396469, acc: 0.9583333134651184)
[2024-11-14 09:44:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:57][root][INFO] - Training Epoch: 2/2, step 9429/16670 completed (loss: 0.1883663535118103, acc: 0.9444444179534912)
[2024-11-14 09:44:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:57][root][INFO] - Training Epoch: 2/2, step 9430/16670 completed (loss: 0.5734302401542664, acc: 0.9166666865348816)
[2024-11-14 09:44:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:57][root][INFO] - Training Epoch: 2/2, step 9431/16670 completed (loss: 0.5974637866020203, acc: 0.8163265585899353)
[2024-11-14 09:44:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:58][root][INFO] - Training Epoch: 2/2, step 9432/16670 completed (loss: 0.03645076975226402, acc: 1.0)
[2024-11-14 09:44:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:58][root][INFO] - Training Epoch: 2/2, step 9433/16670 completed (loss: 0.44762566685676575, acc: 0.9137930870056152)
[2024-11-14 09:44:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:58][root][INFO] - Training Epoch: 2/2, step 9434/16670 completed (loss: 0.2884204387664795, acc: 0.8974359035491943)
[2024-11-14 09:44:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:59][root][INFO] - Training Epoch: 2/2, step 9435/16670 completed (loss: 0.12970849871635437, acc: 0.9459459185600281)
[2024-11-14 09:44:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:59][root][INFO] - Training Epoch: 2/2, step 9436/16670 completed (loss: 0.1523498296737671, acc: 0.9516128897666931)
[2024-11-14 09:44:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:44:59][root][INFO] - Training Epoch: 2/2, step 9437/16670 completed (loss: 0.2849266231060028, acc: 0.9152542352676392)
[2024-11-14 09:44:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:00][root][INFO] - Training Epoch: 2/2, step 9438/16670 completed (loss: 0.5604251623153687, acc: 0.8636363744735718)
[2024-11-14 09:45:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:00][root][INFO] - Training Epoch: 2/2, step 9439/16670 completed (loss: 0.4203871488571167, acc: 0.9166666865348816)
[2024-11-14 09:45:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:00][root][INFO] - Training Epoch: 2/2, step 9440/16670 completed (loss: 0.23044046759605408, acc: 0.942307710647583)
[2024-11-14 09:45:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:01][root][INFO] - Training Epoch: 2/2, step 9441/16670 completed (loss: 0.10908758640289307, acc: 0.9740259647369385)
[2024-11-14 09:45:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:01][root][INFO] - Training Epoch: 2/2, step 9442/16670 completed (loss: 0.08407673239707947, acc: 0.9772727489471436)
[2024-11-14 09:45:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:01][root][INFO] - Training Epoch: 2/2, step 9443/16670 completed (loss: 1.1685400009155273, acc: 0.761904776096344)
[2024-11-14 09:45:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:02][root][INFO] - Training Epoch: 2/2, step 9444/16670 completed (loss: 0.6193363070487976, acc: 0.8536585569381714)
[2024-11-14 09:45:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:02][root][INFO] - Training Epoch: 2/2, step 9445/16670 completed (loss: 0.2751857340335846, acc: 0.9259259104728699)
[2024-11-14 09:45:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:02][root][INFO] - Training Epoch: 2/2, step 9446/16670 completed (loss: 0.3110586702823639, acc: 0.9074074029922485)
[2024-11-14 09:45:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:03][root][INFO] - Training Epoch: 2/2, step 9447/16670 completed (loss: 0.35534995794296265, acc: 0.95652174949646)
[2024-11-14 09:45:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:03][root][INFO] - Training Epoch: 2/2, step 9448/16670 completed (loss: 0.2673098146915436, acc: 0.9117646813392639)
[2024-11-14 09:45:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:03][root][INFO] - Training Epoch: 2/2, step 9449/16670 completed (loss: 0.07763496786355972, acc: 0.9743589758872986)
[2024-11-14 09:45:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:04][root][INFO] - Training Epoch: 2/2, step 9450/16670 completed (loss: 0.20616547763347626, acc: 0.9459459185600281)
[2024-11-14 09:45:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:04][root][INFO] - Training Epoch: 2/2, step 9451/16670 completed (loss: 0.24226132035255432, acc: 0.9428571462631226)
[2024-11-14 09:45:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:04][root][INFO] - Training Epoch: 2/2, step 9452/16670 completed (loss: 0.39298611879348755, acc: 0.8999999761581421)
[2024-11-14 09:45:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:05][root][INFO] - Training Epoch: 2/2, step 9453/16670 completed (loss: 0.4069512188434601, acc: 0.8545454740524292)
[2024-11-14 09:45:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:05][root][INFO] - Training Epoch: 2/2, step 9454/16670 completed (loss: 0.27321913838386536, acc: 0.9599999785423279)
[2024-11-14 09:45:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:06][root][INFO] - Training Epoch: 2/2, step 9455/16670 completed (loss: 0.21707195043563843, acc: 0.930232584476471)
[2024-11-14 09:45:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:06][root][INFO] - Training Epoch: 2/2, step 9456/16670 completed (loss: 0.5369356870651245, acc: 0.9069767594337463)
[2024-11-14 09:45:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:06][root][INFO] - Training Epoch: 2/2, step 9457/16670 completed (loss: 0.5100299119949341, acc: 0.9166666865348816)
[2024-11-14 09:45:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:06][root][INFO] - Training Epoch: 2/2, step 9458/16670 completed (loss: 0.4839688539505005, acc: 0.8823529481887817)
[2024-11-14 09:45:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:07][root][INFO] - Training Epoch: 2/2, step 9459/16670 completed (loss: 0.09458949416875839, acc: 0.9444444179534912)
[2024-11-14 09:45:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:07][root][INFO] - Training Epoch: 2/2, step 9460/16670 completed (loss: 0.5151798725128174, acc: 0.8965517282485962)
[2024-11-14 09:45:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:07][root][INFO] - Training Epoch: 2/2, step 9461/16670 completed (loss: 0.5623411536216736, acc: 0.8461538553237915)
[2024-11-14 09:45:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:08][root][INFO] - Training Epoch: 2/2, step 9462/16670 completed (loss: 0.21031689643859863, acc: 0.9714285731315613)
[2024-11-14 09:45:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:08][root][INFO] - Training Epoch: 2/2, step 9463/16670 completed (loss: 0.3603757917881012, acc: 0.9090909361839294)
[2024-11-14 09:45:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:08][root][INFO] - Training Epoch: 2/2, step 9464/16670 completed (loss: 0.15147419273853302, acc: 0.9803921580314636)
[2024-11-14 09:45:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:09][root][INFO] - Training Epoch: 2/2, step 9465/16670 completed (loss: 0.018620409071445465, acc: 1.0)
[2024-11-14 09:45:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:09][root][INFO] - Training Epoch: 2/2, step 9466/16670 completed (loss: 0.2983240485191345, acc: 0.9038461446762085)
[2024-11-14 09:45:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:10][root][INFO] - Training Epoch: 2/2, step 9467/16670 completed (loss: 0.1726059913635254, acc: 0.9807692170143127)
[2024-11-14 09:45:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:10][root][INFO] - Training Epoch: 2/2, step 9468/16670 completed (loss: 0.3123939335346222, acc: 0.9464285969734192)
[2024-11-14 09:45:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:10][root][INFO] - Training Epoch: 2/2, step 9469/16670 completed (loss: 0.14462538063526154, acc: 0.9558823704719543)
[2024-11-14 09:45:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:11][root][INFO] - Training Epoch: 2/2, step 9470/16670 completed (loss: 0.29668664932250977, acc: 0.9523809552192688)
[2024-11-14 09:45:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:11][root][INFO] - Training Epoch: 2/2, step 9471/16670 completed (loss: 0.29777511954307556, acc: 0.9130434989929199)
[2024-11-14 09:45:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:11][root][INFO] - Training Epoch: 2/2, step 9472/16670 completed (loss: 0.5713449120521545, acc: 0.9027777910232544)
[2024-11-14 09:45:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:11][root][INFO] - Training Epoch: 2/2, step 9473/16670 completed (loss: 0.08204980939626694, acc: 0.9722222089767456)
[2024-11-14 09:45:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:12][root][INFO] - Training Epoch: 2/2, step 9474/16670 completed (loss: 0.03138607740402222, acc: 1.0)
[2024-11-14 09:45:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:12][root][INFO] - Training Epoch: 2/2, step 9475/16670 completed (loss: 0.3591163456439972, acc: 0.9259259104728699)
[2024-11-14 09:45:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:12][root][INFO] - Training Epoch: 2/2, step 9476/16670 completed (loss: 0.6927742958068848, acc: 0.8524590134620667)
[2024-11-14 09:45:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:13][root][INFO] - Training Epoch: 2/2, step 9477/16670 completed (loss: 0.5765871405601501, acc: 0.8965517282485962)
[2024-11-14 09:45:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:13][root][INFO] - Training Epoch: 2/2, step 9478/16670 completed (loss: 0.2508423328399658, acc: 0.9047619104385376)
[2024-11-14 09:45:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:13][root][INFO] - Training Epoch: 2/2, step 9479/16670 completed (loss: 0.5392783284187317, acc: 0.875)
[2024-11-14 09:45:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:14][root][INFO] - Training Epoch: 2/2, step 9480/16670 completed (loss: 0.3605239987373352, acc: 0.8965517282485962)
[2024-11-14 09:45:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:14][root][INFO] - Training Epoch: 2/2, step 9481/16670 completed (loss: 0.6986621618270874, acc: 0.9523809552192688)
[2024-11-14 09:45:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:14][root][INFO] - Training Epoch: 2/2, step 9482/16670 completed (loss: 0.6962822675704956, acc: 0.84375)
[2024-11-14 09:45:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:15][root][INFO] - Training Epoch: 2/2, step 9483/16670 completed (loss: 0.2387537956237793, acc: 0.9583333134651184)
[2024-11-14 09:45:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:15][root][INFO] - Training Epoch: 2/2, step 9484/16670 completed (loss: 0.4558584988117218, acc: 0.9027777910232544)
[2024-11-14 09:45:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:15][root][INFO] - Training Epoch: 2/2, step 9485/16670 completed (loss: 0.21075771749019623, acc: 0.9583333134651184)
[2024-11-14 09:45:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:16][root][INFO] - Training Epoch: 2/2, step 9486/16670 completed (loss: 0.3656518757343292, acc: 0.9583333134651184)
[2024-11-14 09:45:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:16][root][INFO] - Training Epoch: 2/2, step 9487/16670 completed (loss: 0.3084949553012848, acc: 0.9200000166893005)
[2024-11-14 09:45:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:16][root][INFO] - Training Epoch: 2/2, step 9488/16670 completed (loss: 0.19058653712272644, acc: 0.9629629850387573)
[2024-11-14 09:45:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:17][root][INFO] - Training Epoch: 2/2, step 9489/16670 completed (loss: 0.670462429523468, acc: 0.800000011920929)
[2024-11-14 09:45:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:17][root][INFO] - Training Epoch: 2/2, step 9490/16670 completed (loss: 0.36575838923454285, acc: 0.9166666865348816)
[2024-11-14 09:45:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:17][root][INFO] - Training Epoch: 2/2, step 9491/16670 completed (loss: 0.06749890744686127, acc: 1.0)
[2024-11-14 09:45:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:18][root][INFO] - Training Epoch: 2/2, step 9492/16670 completed (loss: 0.6146442890167236, acc: 0.8666666746139526)
[2024-11-14 09:45:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:18][root][INFO] - Training Epoch: 2/2, step 9493/16670 completed (loss: 0.15846355259418488, acc: 0.9545454382896423)
[2024-11-14 09:45:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:18][root][INFO] - Training Epoch: 2/2, step 9494/16670 completed (loss: 0.5360151529312134, acc: 0.8181818127632141)
[2024-11-14 09:45:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:19][root][INFO] - Training Epoch: 2/2, step 9495/16670 completed (loss: 0.4178411364555359, acc: 0.9056603908538818)
[2024-11-14 09:45:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:19][root][INFO] - Training Epoch: 2/2, step 9496/16670 completed (loss: 0.23737551271915436, acc: 0.9117646813392639)
[2024-11-14 09:45:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:19][root][INFO] - Training Epoch: 2/2, step 9497/16670 completed (loss: 0.10293176770210266, acc: 1.0)
[2024-11-14 09:45:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:20][root][INFO] - Training Epoch: 2/2, step 9498/16670 completed (loss: 0.6847115159034729, acc: 0.8918918967247009)
[2024-11-14 09:45:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:20][root][INFO] - Training Epoch: 2/2, step 9499/16670 completed (loss: 1.3214824199676514, acc: 0.739130437374115)
[2024-11-14 09:45:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:20][root][INFO] - Training Epoch: 2/2, step 9500/16670 completed (loss: 0.5446843504905701, acc: 0.8769230842590332)
[2024-11-14 09:45:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:21][root][INFO] - Training Epoch: 2/2, step 9501/16670 completed (loss: 0.467426598072052, acc: 0.9411764740943909)
[2024-11-14 09:45:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:21][root][INFO] - Training Epoch: 2/2, step 9502/16670 completed (loss: 0.3267587721347809, acc: 0.8717948794364929)
[2024-11-14 09:45:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:21][root][INFO] - Training Epoch: 2/2, step 9503/16670 completed (loss: 0.37727153301239014, acc: 0.8783783912658691)
[2024-11-14 09:45:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:22][root][INFO] - Training Epoch: 2/2, step 9504/16670 completed (loss: 0.23664285242557526, acc: 0.9347826242446899)
[2024-11-14 09:45:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:22][root][INFO] - Training Epoch: 2/2, step 9505/16670 completed (loss: 0.646202027797699, acc: 0.9069767594337463)
[2024-11-14 09:45:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:22][root][INFO] - Training Epoch: 2/2, step 9506/16670 completed (loss: 0.6562315821647644, acc: 0.8269230723381042)
[2024-11-14 09:45:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:23][root][INFO] - Training Epoch: 2/2, step 9507/16670 completed (loss: 0.24998727440834045, acc: 0.930232584476471)
[2024-11-14 09:45:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:23][root][INFO] - Training Epoch: 2/2, step 9508/16670 completed (loss: 0.35885900259017944, acc: 0.8852459192276001)
[2024-11-14 09:45:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:23][root][INFO] - Training Epoch: 2/2, step 9509/16670 completed (loss: 0.26566392183303833, acc: 0.9215686321258545)
[2024-11-14 09:45:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:24][root][INFO] - Training Epoch: 2/2, step 9510/16670 completed (loss: 0.6774793863296509, acc: 0.8536585569381714)
[2024-11-14 09:45:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:24][root][INFO] - Training Epoch: 2/2, step 9511/16670 completed (loss: 0.2247120887041092, acc: 0.9444444179534912)
[2024-11-14 09:45:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:25][root][INFO] - Training Epoch: 2/2, step 9512/16670 completed (loss: 0.6803849339485168, acc: 0.9268292784690857)
[2024-11-14 09:45:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:25][root][INFO] - Training Epoch: 2/2, step 9513/16670 completed (loss: 0.43011435866355896, acc: 0.89552241563797)
[2024-11-14 09:45:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:25][root][INFO] - Training Epoch: 2/2, step 9514/16670 completed (loss: 0.2513832449913025, acc: 0.9516128897666931)
[2024-11-14 09:45:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:26][root][INFO] - Training Epoch: 2/2, step 9515/16670 completed (loss: 0.4254606366157532, acc: 0.9137930870056152)
[2024-11-14 09:45:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:26][root][INFO] - Training Epoch: 2/2, step 9516/16670 completed (loss: 0.3930979073047638, acc: 0.9180327653884888)
[2024-11-14 09:45:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:26][root][INFO] - Training Epoch: 2/2, step 9517/16670 completed (loss: 0.2367580533027649, acc: 0.9387755393981934)
[2024-11-14 09:45:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:27][root][INFO] - Training Epoch: 2/2, step 9518/16670 completed (loss: 0.7722549438476562, acc: 0.8484848737716675)
[2024-11-14 09:45:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:27][root][INFO] - Training Epoch: 2/2, step 9519/16670 completed (loss: 0.5914109945297241, acc: 0.8823529481887817)
[2024-11-14 09:45:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:27][root][INFO] - Training Epoch: 2/2, step 9520/16670 completed (loss: 0.5891866087913513, acc: 0.8275862336158752)
[2024-11-14 09:45:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:28][root][INFO] - Training Epoch: 2/2, step 9521/16670 completed (loss: 0.4336836636066437, acc: 0.9047619104385376)
[2024-11-14 09:45:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:28][root][INFO] - Training Epoch: 2/2, step 9522/16670 completed (loss: 0.6594720482826233, acc: 0.8588235378265381)
[2024-11-14 09:45:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:28][root][INFO] - Training Epoch: 2/2, step 9523/16670 completed (loss: 0.8549190759658813, acc: 0.7710843086242676)
[2024-11-14 09:45:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:29][root][INFO] - Training Epoch: 2/2, step 9524/16670 completed (loss: 0.3605436086654663, acc: 0.9230769276618958)
[2024-11-14 09:45:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:29][root][INFO] - Training Epoch: 2/2, step 9525/16670 completed (loss: 0.2740098834037781, acc: 0.9285714030265808)
[2024-11-14 09:45:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:29][root][INFO] - Training Epoch: 2/2, step 9526/16670 completed (loss: 0.17919287085533142, acc: 0.9726027250289917)
[2024-11-14 09:45:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:30][root][INFO] - Training Epoch: 2/2, step 9527/16670 completed (loss: 0.4311904013156891, acc: 0.930232584476471)
[2024-11-14 09:45:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:30][root][INFO] - Training Epoch: 2/2, step 9528/16670 completed (loss: 0.8329158425331116, acc: 0.7647058963775635)
[2024-11-14 09:45:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:30][root][INFO] - Training Epoch: 2/2, step 9529/16670 completed (loss: 0.2714536786079407, acc: 0.9090909361839294)
[2024-11-14 09:45:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:31][root][INFO] - Training Epoch: 2/2, step 9530/16670 completed (loss: 0.14679300785064697, acc: 0.9508196711540222)
[2024-11-14 09:45:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:31][root][INFO] - Training Epoch: 2/2, step 9531/16670 completed (loss: 0.6077966690063477, acc: 0.8787878751754761)
[2024-11-14 09:45:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:31][root][INFO] - Training Epoch: 2/2, step 9532/16670 completed (loss: 0.6820888519287109, acc: 0.8571428656578064)
[2024-11-14 09:45:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:32][root][INFO] - Training Epoch: 2/2, step 9533/16670 completed (loss: 0.805992066860199, acc: 0.8181818127632141)
[2024-11-14 09:45:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:32][root][INFO] - Training Epoch: 2/2, step 9534/16670 completed (loss: 0.13391929864883423, acc: 0.978723406791687)
[2024-11-14 09:45:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:32][root][INFO] - Training Epoch: 2/2, step 9535/16670 completed (loss: 0.51529860496521, acc: 0.8717948794364929)
[2024-11-14 09:45:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:33][root][INFO] - Training Epoch: 2/2, step 9536/16670 completed (loss: 0.275611013174057, acc: 0.9523809552192688)
[2024-11-14 09:45:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:33][root][INFO] - Training Epoch: 2/2, step 9537/16670 completed (loss: 0.1767261028289795, acc: 0.9411764740943909)
[2024-11-14 09:45:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:34][root][INFO] - Training Epoch: 2/2, step 9538/16670 completed (loss: 0.4933388829231262, acc: 0.9534883499145508)
[2024-11-14 09:45:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:34][root][INFO] - Training Epoch: 2/2, step 9539/16670 completed (loss: 0.13914422690868378, acc: 0.9599999785423279)
[2024-11-14 09:45:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:34][root][INFO] - Training Epoch: 2/2, step 9540/16670 completed (loss: 0.17473243176937103, acc: 0.953125)
[2024-11-14 09:45:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:35][root][INFO] - Training Epoch: 2/2, step 9541/16670 completed (loss: 0.23271188139915466, acc: 0.970588207244873)
[2024-11-14 09:45:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:35][root][INFO] - Training Epoch: 2/2, step 9542/16670 completed (loss: 0.09991952031850815, acc: 0.9824561476707458)
[2024-11-14 09:45:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:35][root][INFO] - Training Epoch: 2/2, step 9543/16670 completed (loss: 0.4462312161922455, acc: 0.9444444179534912)
[2024-11-14 09:45:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:36][root][INFO] - Training Epoch: 2/2, step 9544/16670 completed (loss: 0.10517000406980515, acc: 0.9629629850387573)
[2024-11-14 09:45:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:36][root][INFO] - Training Epoch: 2/2, step 9545/16670 completed (loss: 0.10898251831531525, acc: 0.97826087474823)
[2024-11-14 09:45:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:37][root][INFO] - Training Epoch: 2/2, step 9546/16670 completed (loss: 0.2644573748111725, acc: 0.9523809552192688)
[2024-11-14 09:45:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:37][root][INFO] - Training Epoch: 2/2, step 9547/16670 completed (loss: 0.4355165958404541, acc: 0.8999999761581421)
[2024-11-14 09:45:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:37][root][INFO] - Training Epoch: 2/2, step 9548/16670 completed (loss: 0.6984429955482483, acc: 0.875)
[2024-11-14 09:45:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:38][root][INFO] - Training Epoch: 2/2, step 9549/16670 completed (loss: 0.39917030930519104, acc: 0.9090909361839294)
[2024-11-14 09:45:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:38][root][INFO] - Training Epoch: 2/2, step 9550/16670 completed (loss: 0.2181641012430191, acc: 0.9666666388511658)
[2024-11-14 09:45:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:38][root][INFO] - Training Epoch: 2/2, step 9551/16670 completed (loss: 0.3400040566921234, acc: 0.89552241563797)
[2024-11-14 09:45:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:39][root][INFO] - Training Epoch: 2/2, step 9552/16670 completed (loss: 0.3463286757469177, acc: 0.9047619104385376)
[2024-11-14 09:45:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:39][root][INFO] - Training Epoch: 2/2, step 9553/16670 completed (loss: 0.2854524850845337, acc: 0.9642857313156128)
[2024-11-14 09:45:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:39][root][INFO] - Training Epoch: 2/2, step 9554/16670 completed (loss: 0.4561850428581238, acc: 0.9024389982223511)
[2024-11-14 09:45:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:40][root][INFO] - Training Epoch: 2/2, step 9555/16670 completed (loss: 0.04684174060821533, acc: 0.9857142567634583)
[2024-11-14 09:45:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:40][root][INFO] - Training Epoch: 2/2, step 9556/16670 completed (loss: 0.5493024587631226, acc: 0.8399999737739563)
[2024-11-14 09:45:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:40][root][INFO] - Training Epoch: 2/2, step 9557/16670 completed (loss: 0.9532926082611084, acc: 0.8285714387893677)
[2024-11-14 09:45:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:41][root][INFO] - Training Epoch: 2/2, step 9558/16670 completed (loss: 0.172279953956604, acc: 0.9722222089767456)
[2024-11-14 09:45:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:41][root][INFO] - Training Epoch: 2/2, step 9559/16670 completed (loss: 0.47587108612060547, acc: 0.8965517282485962)
[2024-11-14 09:45:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:41][root][INFO] - Training Epoch: 2/2, step 9560/16670 completed (loss: 0.18129105865955353, acc: 0.970588207244873)
[2024-11-14 09:45:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:42][root][INFO] - Training Epoch: 2/2, step 9561/16670 completed (loss: 0.2758776545524597, acc: 0.9428571462631226)
[2024-11-14 09:45:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:42][root][INFO] - Training Epoch: 2/2, step 9562/16670 completed (loss: 0.221200093626976, acc: 0.9459459185600281)
[2024-11-14 09:45:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:42][root][INFO] - Training Epoch: 2/2, step 9563/16670 completed (loss: 0.44676801562309265, acc: 0.8928571343421936)
[2024-11-14 09:45:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:43][root][INFO] - Training Epoch: 2/2, step 9564/16670 completed (loss: 0.2584996521472931, acc: 0.9230769276618958)
[2024-11-14 09:45:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:43][root][INFO] - Training Epoch: 2/2, step 9565/16670 completed (loss: 0.3653101325035095, acc: 0.925000011920929)
[2024-11-14 09:45:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:43][root][INFO] - Training Epoch: 2/2, step 9566/16670 completed (loss: 0.11121568828821182, acc: 0.9636363387107849)
[2024-11-14 09:45:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:44][root][INFO] - Training Epoch: 2/2, step 9567/16670 completed (loss: 0.2577153146266937, acc: 0.939393937587738)
[2024-11-14 09:45:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:44][root][INFO] - Training Epoch: 2/2, step 9568/16670 completed (loss: 0.2794446349143982, acc: 0.9272727370262146)
[2024-11-14 09:45:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:44][root][INFO] - Training Epoch: 2/2, step 9569/16670 completed (loss: 0.29819709062576294, acc: 0.9285714030265808)
[2024-11-14 09:45:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:45][root][INFO] - Training Epoch: 2/2, step 9570/16670 completed (loss: 0.3724159896373749, acc: 0.9411764740943909)
[2024-11-14 09:45:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:45][root][INFO] - Training Epoch: 2/2, step 9571/16670 completed (loss: 0.4176451861858368, acc: 0.8888888955116272)
[2024-11-14 09:45:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:46][root][INFO] - Training Epoch: 2/2, step 9572/16670 completed (loss: 0.35187625885009766, acc: 0.9166666865348816)
[2024-11-14 09:45:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:46][root][INFO] - Training Epoch: 2/2, step 9573/16670 completed (loss: 0.16630269587039948, acc: 0.9629629850387573)
[2024-11-14 09:45:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:46][root][INFO] - Training Epoch: 2/2, step 9574/16670 completed (loss: 0.15101777017116547, acc: 0.9534883499145508)
[2024-11-14 09:45:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:47][root][INFO] - Training Epoch: 2/2, step 9575/16670 completed (loss: 0.25819334387779236, acc: 0.9583333134651184)
[2024-11-14 09:45:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:47][root][INFO] - Training Epoch: 2/2, step 9576/16670 completed (loss: 0.1448911875486374, acc: 0.9615384340286255)
[2024-11-14 09:45:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:47][root][INFO] - Training Epoch: 2/2, step 9577/16670 completed (loss: 0.2378873974084854, acc: 0.914893627166748)
[2024-11-14 09:45:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:48][root][INFO] - Training Epoch: 2/2, step 9578/16670 completed (loss: 0.126749649643898, acc: 0.9750000238418579)
[2024-11-14 09:45:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:48][root][INFO] - Training Epoch: 2/2, step 9579/16670 completed (loss: 0.7669962644577026, acc: 0.8367347121238708)
[2024-11-14 09:45:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:48][root][INFO] - Training Epoch: 2/2, step 9580/16670 completed (loss: 0.2535911202430725, acc: 0.9482758641242981)
[2024-11-14 09:45:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:49][root][INFO] - Training Epoch: 2/2, step 9581/16670 completed (loss: 0.11230461299419403, acc: 0.9487179517745972)
[2024-11-14 09:45:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:49][root][INFO] - Training Epoch: 2/2, step 9582/16670 completed (loss: 0.4707549512386322, acc: 0.9285714030265808)
[2024-11-14 09:45:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:49][root][INFO] - Training Epoch: 2/2, step 9583/16670 completed (loss: 0.3889559805393219, acc: 0.9387755393981934)
[2024-11-14 09:45:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:50][root][INFO] - Training Epoch: 2/2, step 9584/16670 completed (loss: 0.17484262585639954, acc: 0.9420289993286133)
[2024-11-14 09:45:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:50][root][INFO] - Training Epoch: 2/2, step 9585/16670 completed (loss: 0.23366102576255798, acc: 0.931034505367279)
[2024-11-14 09:45:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:50][root][INFO] - Training Epoch: 2/2, step 9586/16670 completed (loss: 0.07532297819852829, acc: 0.9861111044883728)
[2024-11-14 09:45:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:51][root][INFO] - Training Epoch: 2/2, step 9587/16670 completed (loss: 0.3407360017299652, acc: 0.9558823704719543)
[2024-11-14 09:45:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:51][root][INFO] - Training Epoch: 2/2, step 9588/16670 completed (loss: 0.29333606362342834, acc: 0.9298245906829834)
[2024-11-14 09:45:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:51][root][INFO] - Training Epoch: 2/2, step 9589/16670 completed (loss: 0.08337223529815674, acc: 0.9714285731315613)
[2024-11-14 09:45:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:52][root][INFO] - Training Epoch: 2/2, step 9590/16670 completed (loss: 0.19015240669250488, acc: 0.9714285731315613)
[2024-11-14 09:45:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:52][root][INFO] - Training Epoch: 2/2, step 9591/16670 completed (loss: 0.27497151494026184, acc: 0.9399999976158142)
[2024-11-14 09:45:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:52][root][INFO] - Training Epoch: 2/2, step 9592/16670 completed (loss: 0.30422690510749817, acc: 0.9347826242446899)
[2024-11-14 09:45:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:53][root][INFO] - Training Epoch: 2/2, step 9593/16670 completed (loss: 0.1262994259595871, acc: 0.9830508232116699)
[2024-11-14 09:45:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:53][root][INFO] - Training Epoch: 2/2, step 9594/16670 completed (loss: 0.06882865726947784, acc: 0.982758641242981)
[2024-11-14 09:45:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:53][root][INFO] - Training Epoch: 2/2, step 9595/16670 completed (loss: 0.2382378727197647, acc: 0.90625)
[2024-11-14 09:45:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:54][root][INFO] - Training Epoch: 2/2, step 9596/16670 completed (loss: 0.1417272537946701, acc: 0.9682539701461792)
[2024-11-14 09:45:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:54][root][INFO] - Training Epoch: 2/2, step 9597/16670 completed (loss: 0.6636238098144531, acc: 0.8367347121238708)
[2024-11-14 09:45:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:54][root][INFO] - Training Epoch: 2/2, step 9598/16670 completed (loss: 0.17169606685638428, acc: 0.9583333134651184)
[2024-11-14 09:45:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:55][root][INFO] - Training Epoch: 2/2, step 9599/16670 completed (loss: 0.32882240414619446, acc: 0.8928571343421936)
[2024-11-14 09:45:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:55][root][INFO] - Training Epoch: 2/2, step 9600/16670 completed (loss: 0.7641070485115051, acc: 0.8723404407501221)
[2024-11-14 09:45:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:55][root][INFO] - Training Epoch: 2/2, step 9601/16670 completed (loss: 0.38779377937316895, acc: 0.9322034120559692)
[2024-11-14 09:45:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:56][root][INFO] - Training Epoch: 2/2, step 9602/16670 completed (loss: 0.12494245171546936, acc: 0.9636363387107849)
[2024-11-14 09:45:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:56][root][INFO] - Training Epoch: 2/2, step 9603/16670 completed (loss: 0.23277992010116577, acc: 0.9333333373069763)
[2024-11-14 09:45:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:56][root][INFO] - Training Epoch: 2/2, step 9604/16670 completed (loss: 0.2978982627391815, acc: 0.8846153616905212)
[2024-11-14 09:45:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:57][root][INFO] - Training Epoch: 2/2, step 9605/16670 completed (loss: 0.04589616507291794, acc: 0.9811320900917053)
[2024-11-14 09:45:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:57][root][INFO] - Training Epoch: 2/2, step 9606/16670 completed (loss: 0.1317618191242218, acc: 0.9387755393981934)
[2024-11-14 09:45:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:57][root][INFO] - Training Epoch: 2/2, step 9607/16670 completed (loss: 0.17921589314937592, acc: 0.9512194991111755)
[2024-11-14 09:45:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:58][root][INFO] - Training Epoch: 2/2, step 9608/16670 completed (loss: 0.3426711857318878, acc: 0.936170220375061)
[2024-11-14 09:45:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:58][root][INFO] - Training Epoch: 2/2, step 9609/16670 completed (loss: 0.06101552024483681, acc: 0.9807692170143127)
[2024-11-14 09:45:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:59][root][INFO] - Training Epoch: 2/2, step 9610/16670 completed (loss: 0.2999032735824585, acc: 0.9066666960716248)
[2024-11-14 09:45:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:59][root][INFO] - Training Epoch: 2/2, step 9611/16670 completed (loss: 0.09548049420118332, acc: 0.9767441749572754)
[2024-11-14 09:45:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:45:59][root][INFO] - Training Epoch: 2/2, step 9612/16670 completed (loss: 0.16357217729091644, acc: 0.9772727489471436)
[2024-11-14 09:45:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:00][root][INFO] - Training Epoch: 2/2, step 9613/16670 completed (loss: 0.2891884744167328, acc: 0.9193548560142517)
[2024-11-14 09:46:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:00][root][INFO] - Training Epoch: 2/2, step 9614/16670 completed (loss: 0.19903400540351868, acc: 0.9615384340286255)
[2024-11-14 09:46:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:00][root][INFO] - Training Epoch: 2/2, step 9615/16670 completed (loss: 0.18622633814811707, acc: 0.9677419066429138)
[2024-11-14 09:46:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:01][root][INFO] - Training Epoch: 2/2, step 9616/16670 completed (loss: 0.2713620662689209, acc: 0.9607843160629272)
[2024-11-14 09:46:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:01][root][INFO] - Training Epoch: 2/2, step 9617/16670 completed (loss: 0.2736555337905884, acc: 0.9358974099159241)
[2024-11-14 09:46:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:01][root][INFO] - Training Epoch: 2/2, step 9618/16670 completed (loss: 0.21720032393932343, acc: 0.976190447807312)
[2024-11-14 09:46:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:02][root][INFO] - Training Epoch: 2/2, step 9619/16670 completed (loss: 0.13653022050857544, acc: 0.9487179517745972)
[2024-11-14 09:46:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:02][root][INFO] - Training Epoch: 2/2, step 9620/16670 completed (loss: 0.01487802155315876, acc: 1.0)
[2024-11-14 09:46:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:02][root][INFO] - Training Epoch: 2/2, step 9621/16670 completed (loss: 0.11680103093385696, acc: 0.9777777791023254)
[2024-11-14 09:46:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:03][root][INFO] - Training Epoch: 2/2, step 9622/16670 completed (loss: 0.34391090273857117, acc: 0.9428571462631226)
[2024-11-14 09:46:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:03][root][INFO] - Training Epoch: 2/2, step 9623/16670 completed (loss: 0.3930513560771942, acc: 0.9130434989929199)
[2024-11-14 09:46:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:03][root][INFO] - Training Epoch: 2/2, step 9624/16670 completed (loss: 0.3167867064476013, acc: 0.9047619104385376)
[2024-11-14 09:46:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:04][root][INFO] - Training Epoch: 2/2, step 9625/16670 completed (loss: 0.17513175308704376, acc: 0.9677419066429138)
[2024-11-14 09:46:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:04][root][INFO] - Training Epoch: 2/2, step 9626/16670 completed (loss: 0.34182414412498474, acc: 0.8799999952316284)
[2024-11-14 09:46:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:04][root][INFO] - Training Epoch: 2/2, step 9627/16670 completed (loss: 0.40189218521118164, acc: 0.892307698726654)
[2024-11-14 09:46:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:05][root][INFO] - Training Epoch: 2/2, step 9628/16670 completed (loss: 0.1301897168159485, acc: 0.9512194991111755)
[2024-11-14 09:46:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:05][root][INFO] - Training Epoch: 2/2, step 9629/16670 completed (loss: 0.4058295488357544, acc: 0.9629629850387573)
[2024-11-14 09:46:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:05][root][INFO] - Training Epoch: 2/2, step 9630/16670 completed (loss: 0.1442204713821411, acc: 0.9347826242446899)
[2024-11-14 09:46:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:06][root][INFO] - Training Epoch: 2/2, step 9631/16670 completed (loss: 0.025038521736860275, acc: 1.0)
[2024-11-14 09:46:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:06][root][INFO] - Training Epoch: 2/2, step 9632/16670 completed (loss: 0.442718505859375, acc: 0.9166666865348816)
[2024-11-14 09:46:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:07][root][INFO] - Training Epoch: 2/2, step 9633/16670 completed (loss: 0.1827206015586853, acc: 0.9615384340286255)
[2024-11-14 09:46:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:07][root][INFO] - Training Epoch: 2/2, step 9634/16670 completed (loss: 0.1040818989276886, acc: 0.9772727489471436)
[2024-11-14 09:46:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:07][root][INFO] - Training Epoch: 2/2, step 9635/16670 completed (loss: 0.26849204301834106, acc: 0.949999988079071)
[2024-11-14 09:46:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:08][root][INFO] - Training Epoch: 2/2, step 9636/16670 completed (loss: 0.30252987146377563, acc: 0.8999999761581421)
[2024-11-14 09:46:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:08][root][INFO] - Training Epoch: 2/2, step 9637/16670 completed (loss: 0.47202828526496887, acc: 0.8833333253860474)
[2024-11-14 09:46:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:08][root][INFO] - Training Epoch: 2/2, step 9638/16670 completed (loss: 0.04384118318557739, acc: 1.0)
[2024-11-14 09:46:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:09][root][INFO] - Training Epoch: 2/2, step 9639/16670 completed (loss: 0.5341655015945435, acc: 0.9047619104385376)
[2024-11-14 09:46:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:09][root][INFO] - Training Epoch: 2/2, step 9640/16670 completed (loss: 0.16946470737457275, acc: 0.9411764740943909)
[2024-11-14 09:46:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:09][root][INFO] - Training Epoch: 2/2, step 9641/16670 completed (loss: 0.2322717308998108, acc: 0.9729729890823364)
[2024-11-14 09:46:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:10][root][INFO] - Training Epoch: 2/2, step 9642/16670 completed (loss: 0.044535890221595764, acc: 0.9811320900917053)
[2024-11-14 09:46:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:10][root][INFO] - Training Epoch: 2/2, step 9643/16670 completed (loss: 0.6906493902206421, acc: 0.8461538553237915)
[2024-11-14 09:46:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:10][root][INFO] - Training Epoch: 2/2, step 9644/16670 completed (loss: 0.24465787410736084, acc: 0.9433962106704712)
[2024-11-14 09:46:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:11][root][INFO] - Training Epoch: 2/2, step 9645/16670 completed (loss: 0.21318842470645905, acc: 0.9629629850387573)
[2024-11-14 09:46:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:11][root][INFO] - Training Epoch: 2/2, step 9646/16670 completed (loss: 0.3714762330055237, acc: 0.8275862336158752)
[2024-11-14 09:46:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:11][root][INFO] - Training Epoch: 2/2, step 9647/16670 completed (loss: 0.6648014783859253, acc: 0.9019607901573181)
[2024-11-14 09:46:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:12][root][INFO] - Training Epoch: 2/2, step 9648/16670 completed (loss: 0.7276517748832703, acc: 0.8181818127632141)
[2024-11-14 09:46:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:12][root][INFO] - Training Epoch: 2/2, step 9649/16670 completed (loss: 0.19735990464687347, acc: 0.976190447807312)
[2024-11-14 09:46:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:12][root][INFO] - Training Epoch: 2/2, step 9650/16670 completed (loss: 0.23146243393421173, acc: 0.9166666865348816)
[2024-11-14 09:46:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:13][root][INFO] - Training Epoch: 2/2, step 9651/16670 completed (loss: 0.1776825487613678, acc: 0.9870129823684692)
[2024-11-14 09:46:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:13][root][INFO] - Training Epoch: 2/2, step 9652/16670 completed (loss: 0.5319521427154541, acc: 0.8928571343421936)
[2024-11-14 09:46:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:13][root][INFO] - Training Epoch: 2/2, step 9653/16670 completed (loss: 0.4451078176498413, acc: 0.8979591727256775)
[2024-11-14 09:46:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:14][root][INFO] - Training Epoch: 2/2, step 9654/16670 completed (loss: 0.3071601986885071, acc: 0.949999988079071)
[2024-11-14 09:46:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:14][root][INFO] - Training Epoch: 2/2, step 9655/16670 completed (loss: 0.3401728868484497, acc: 0.9615384340286255)
[2024-11-14 09:46:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:14][root][INFO] - Training Epoch: 2/2, step 9656/16670 completed (loss: 0.11410228908061981, acc: 0.95652174949646)
[2024-11-14 09:46:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:15][root][INFO] - Training Epoch: 2/2, step 9657/16670 completed (loss: 0.562451958656311, acc: 0.9036144614219666)
[2024-11-14 09:46:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:15][root][INFO] - Training Epoch: 2/2, step 9658/16670 completed (loss: 0.110090471804142, acc: 0.9571428298950195)
[2024-11-14 09:46:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:15][root][INFO] - Training Epoch: 2/2, step 9659/16670 completed (loss: 0.8859440684318542, acc: 0.8571428656578064)
[2024-11-14 09:46:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:16][root][INFO] - Training Epoch: 2/2, step 9660/16670 completed (loss: 0.21763423085212708, acc: 0.9166666865348816)
[2024-11-14 09:46:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:16][root][INFO] - Training Epoch: 2/2, step 9661/16670 completed (loss: 0.10459340363740921, acc: 0.9591836929321289)
[2024-11-14 09:46:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:16][root][INFO] - Training Epoch: 2/2, step 9662/16670 completed (loss: 0.5554877519607544, acc: 0.9230769276618958)
[2024-11-14 09:46:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:17][root][INFO] - Training Epoch: 2/2, step 9663/16670 completed (loss: 0.465722918510437, acc: 0.8987341523170471)
[2024-11-14 09:46:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:17][root][INFO] - Training Epoch: 2/2, step 9664/16670 completed (loss: 0.187614306807518, acc: 0.9333333373069763)
[2024-11-14 09:46:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:17][root][INFO] - Training Epoch: 2/2, step 9665/16670 completed (loss: 0.310161292552948, acc: 0.9111111164093018)
[2024-11-14 09:46:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:18][root][INFO] - Training Epoch: 2/2, step 9666/16670 completed (loss: 0.7444257140159607, acc: 0.8382353186607361)
[2024-11-14 09:46:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:18][root][INFO] - Training Epoch: 2/2, step 9667/16670 completed (loss: 0.11436811089515686, acc: 1.0)
[2024-11-14 09:46:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:18][root][INFO] - Training Epoch: 2/2, step 9668/16670 completed (loss: 0.08091019839048386, acc: 0.9791666865348816)
[2024-11-14 09:46:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:19][root][INFO] - Training Epoch: 2/2, step 9669/16670 completed (loss: 0.31812259554862976, acc: 0.8999999761581421)
[2024-11-14 09:46:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:19][root][INFO] - Training Epoch: 2/2, step 9670/16670 completed (loss: 0.22891999781131744, acc: 0.8888888955116272)
[2024-11-14 09:46:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:19][root][INFO] - Training Epoch: 2/2, step 9671/16670 completed (loss: 0.0988462045788765, acc: 0.9777777791023254)
[2024-11-14 09:46:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:20][root][INFO] - Training Epoch: 2/2, step 9672/16670 completed (loss: 0.4951174557209015, acc: 0.8545454740524292)
[2024-11-14 09:46:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:20][root][INFO] - Training Epoch: 2/2, step 9673/16670 completed (loss: 0.23008877038955688, acc: 0.95652174949646)
[2024-11-14 09:46:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:20][root][INFO] - Training Epoch: 2/2, step 9674/16670 completed (loss: 0.06307727843523026, acc: 0.9800000190734863)
[2024-11-14 09:46:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:21][root][INFO] - Training Epoch: 2/2, step 9675/16670 completed (loss: 0.20057496428489685, acc: 0.9482758641242981)
[2024-11-14 09:46:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:21][root][INFO] - Training Epoch: 2/2, step 9676/16670 completed (loss: 0.21243338286876678, acc: 0.9516128897666931)
[2024-11-14 09:46:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:21][root][INFO] - Training Epoch: 2/2, step 9677/16670 completed (loss: 0.35680118203163147, acc: 0.9583333134651184)
[2024-11-14 09:46:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:22][root][INFO] - Training Epoch: 2/2, step 9678/16670 completed (loss: 0.11712602525949478, acc: 0.9629629850387573)
[2024-11-14 09:46:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:22][root][INFO] - Training Epoch: 2/2, step 9679/16670 completed (loss: 0.44557979702949524, acc: 0.8933333158493042)
[2024-11-14 09:46:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:22][root][INFO] - Training Epoch: 2/2, step 9680/16670 completed (loss: 0.12094274163246155, acc: 0.9818181991577148)
[2024-11-14 09:46:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:23][root][INFO] - Training Epoch: 2/2, step 9681/16670 completed (loss: 0.4149097204208374, acc: 0.9193548560142517)
[2024-11-14 09:46:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:23][root][INFO] - Training Epoch: 2/2, step 9682/16670 completed (loss: 0.5019323229789734, acc: 0.8974359035491943)
[2024-11-14 09:46:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:23][root][INFO] - Training Epoch: 2/2, step 9683/16670 completed (loss: 0.1911698877811432, acc: 0.9090909361839294)
[2024-11-14 09:46:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:24][root][INFO] - Training Epoch: 2/2, step 9684/16670 completed (loss: 0.04067283868789673, acc: 1.0)
[2024-11-14 09:46:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:24][root][INFO] - Training Epoch: 2/2, step 9685/16670 completed (loss: 0.3603738248348236, acc: 0.9090909361839294)
[2024-11-14 09:46:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:24][root][INFO] - Training Epoch: 2/2, step 9686/16670 completed (loss: 0.08454640954732895, acc: 0.9743589758872986)
[2024-11-14 09:46:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:25][root][INFO] - Training Epoch: 2/2, step 9687/16670 completed (loss: 0.2699772119522095, acc: 0.9677419066429138)
[2024-11-14 09:46:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:25][root][INFO] - Training Epoch: 2/2, step 9688/16670 completed (loss: 0.12375441193580627, acc: 0.9672130942344666)
[2024-11-14 09:46:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:25][root][INFO] - Training Epoch: 2/2, step 9689/16670 completed (loss: 0.411756306886673, acc: 0.9111111164093018)
[2024-11-14 09:46:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:26][root][INFO] - Training Epoch: 2/2, step 9690/16670 completed (loss: 0.08240810036659241, acc: 0.9772727489471436)
[2024-11-14 09:46:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:26][root][INFO] - Training Epoch: 2/2, step 9691/16670 completed (loss: 0.025582026690244675, acc: 1.0)
[2024-11-14 09:46:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:26][root][INFO] - Training Epoch: 2/2, step 9692/16670 completed (loss: 0.1542784720659256, acc: 0.9594594836235046)
[2024-11-14 09:46:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:27][root][INFO] - Training Epoch: 2/2, step 9693/16670 completed (loss: 0.11327335238456726, acc: 0.9666666388511658)
[2024-11-14 09:46:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:27][root][INFO] - Training Epoch: 2/2, step 9694/16670 completed (loss: 0.33314359188079834, acc: 0.9433962106704712)
[2024-11-14 09:46:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:27][root][INFO] - Training Epoch: 2/2, step 9695/16670 completed (loss: 0.2767038941383362, acc: 0.9459459185600281)
[2024-11-14 09:46:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:28][root][INFO] - Training Epoch: 2/2, step 9696/16670 completed (loss: 0.45137301087379456, acc: 0.9090909361839294)
[2024-11-14 09:46:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:28][root][INFO] - Training Epoch: 2/2, step 9697/16670 completed (loss: 0.38558539748191833, acc: 0.9433962106704712)
[2024-11-14 09:46:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:28][root][INFO] - Training Epoch: 2/2, step 9698/16670 completed (loss: 0.20683488249778748, acc: 0.9756097793579102)
[2024-11-14 09:46:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:29][root][INFO] - Training Epoch: 2/2, step 9699/16670 completed (loss: 0.05175703018903732, acc: 1.0)
[2024-11-14 09:46:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:29][root][INFO] - Training Epoch: 2/2, step 9700/16670 completed (loss: 0.11442519724369049, acc: 0.9629629850387573)
[2024-11-14 09:46:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:29][root][INFO] - Training Epoch: 2/2, step 9701/16670 completed (loss: 0.34512919187545776, acc: 0.9295774698257446)
[2024-11-14 09:46:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:30][root][INFO] - Training Epoch: 2/2, step 9702/16670 completed (loss: 0.344939649105072, acc: 0.97826087474823)
[2024-11-14 09:46:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:30][root][INFO] - Training Epoch: 2/2, step 9703/16670 completed (loss: 0.2631935477256775, acc: 0.9411764740943909)
[2024-11-14 09:46:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:30][root][INFO] - Training Epoch: 2/2, step 9704/16670 completed (loss: 0.13292592763900757, acc: 0.9508196711540222)
[2024-11-14 09:46:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:31][root][INFO] - Training Epoch: 2/2, step 9705/16670 completed (loss: 0.1271086037158966, acc: 0.9487179517745972)
[2024-11-14 09:46:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:31][root][INFO] - Training Epoch: 2/2, step 9706/16670 completed (loss: 0.14970436692237854, acc: 0.9836065769195557)
[2024-11-14 09:46:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:31][root][INFO] - Training Epoch: 2/2, step 9707/16670 completed (loss: 0.22627784311771393, acc: 0.9152542352676392)
[2024-11-14 09:46:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:32][root][INFO] - Training Epoch: 2/2, step 9708/16670 completed (loss: 0.0897761881351471, acc: 0.9591836929321289)
[2024-11-14 09:46:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:32][root][INFO] - Training Epoch: 2/2, step 9709/16670 completed (loss: 0.38455289602279663, acc: 0.8653846383094788)
[2024-11-14 09:46:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:32][root][INFO] - Training Epoch: 2/2, step 9710/16670 completed (loss: 0.3126745820045471, acc: 0.8999999761581421)
[2024-11-14 09:46:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:33][root][INFO] - Training Epoch: 2/2, step 9711/16670 completed (loss: 0.17751635611057281, acc: 0.9677419066429138)
[2024-11-14 09:46:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:33][root][INFO] - Training Epoch: 2/2, step 9712/16670 completed (loss: 0.25546303391456604, acc: 0.9375)
[2024-11-14 09:46:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:33][root][INFO] - Training Epoch: 2/2, step 9713/16670 completed (loss: 0.39486750960350037, acc: 0.9166666865348816)
[2024-11-14 09:46:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:34][root][INFO] - Training Epoch: 2/2, step 9714/16670 completed (loss: 0.2917843461036682, acc: 0.9523809552192688)
[2024-11-14 09:46:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:34][root][INFO] - Training Epoch: 2/2, step 9715/16670 completed (loss: 0.1074848398566246, acc: 0.9821428656578064)
[2024-11-14 09:46:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:34][root][INFO] - Training Epoch: 2/2, step 9716/16670 completed (loss: 0.12533506751060486, acc: 0.9285714030265808)
[2024-11-14 09:46:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:35][root][INFO] - Training Epoch: 2/2, step 9717/16670 completed (loss: 0.35822954773902893, acc: 0.8852459192276001)
[2024-11-14 09:46:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:35][root][INFO] - Training Epoch: 2/2, step 9718/16670 completed (loss: 0.3067058026790619, acc: 0.9736841917037964)
[2024-11-14 09:46:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:36][root][INFO] - Training Epoch: 2/2, step 9719/16670 completed (loss: 0.22075143456459045, acc: 0.932584285736084)
[2024-11-14 09:46:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:36][root][INFO] - Training Epoch: 2/2, step 9720/16670 completed (loss: 0.09960515797138214, acc: 0.9777777791023254)
[2024-11-14 09:46:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:36][root][INFO] - Training Epoch: 2/2, step 9721/16670 completed (loss: 0.3135513961315155, acc: 0.9259259104728699)
[2024-11-14 09:46:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:37][root][INFO] - Training Epoch: 2/2, step 9722/16670 completed (loss: 0.16609697043895721, acc: 0.9459459185600281)
[2024-11-14 09:46:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:37][root][INFO] - Training Epoch: 2/2, step 9723/16670 completed (loss: 0.008397036232054234, acc: 1.0)
[2024-11-14 09:46:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:37][root][INFO] - Training Epoch: 2/2, step 9724/16670 completed (loss: 0.05796751379966736, acc: 0.984375)
[2024-11-14 09:46:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:37][root][INFO] - Training Epoch: 2/2, step 9725/16670 completed (loss: 0.2448197454214096, acc: 0.9591836929321289)
[2024-11-14 09:46:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:38][root][INFO] - Training Epoch: 2/2, step 9726/16670 completed (loss: 0.46799230575561523, acc: 0.8571428656578064)
[2024-11-14 09:46:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:38][root][INFO] - Training Epoch: 2/2, step 9727/16670 completed (loss: 0.12721207737922668, acc: 0.978723406791687)
[2024-11-14 09:46:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:38][root][INFO] - Training Epoch: 2/2, step 9728/16670 completed (loss: 0.19796012341976166, acc: 0.9610389471054077)
[2024-11-14 09:46:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:39][root][INFO] - Training Epoch: 2/2, step 9729/16670 completed (loss: 0.30183327198028564, acc: 0.9365079402923584)
[2024-11-14 09:46:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:39][root][INFO] - Training Epoch: 2/2, step 9730/16670 completed (loss: 0.37152960896492004, acc: 0.9342105388641357)
[2024-11-14 09:46:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:39][root][INFO] - Training Epoch: 2/2, step 9731/16670 completed (loss: 0.3399374485015869, acc: 0.95652174949646)
[2024-11-14 09:46:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:40][root][INFO] - Training Epoch: 2/2, step 9732/16670 completed (loss: 0.1900453418493271, acc: 0.9468085169792175)
[2024-11-14 09:46:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:40][root][INFO] - Training Epoch: 2/2, step 9733/16670 completed (loss: 0.48299577832221985, acc: 0.8717948794364929)
[2024-11-14 09:46:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:40][root][INFO] - Training Epoch: 2/2, step 9734/16670 completed (loss: 0.41882723569869995, acc: 0.8809523582458496)
[2024-11-14 09:46:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:41][root][INFO] - Training Epoch: 2/2, step 9735/16670 completed (loss: 0.15199917554855347, acc: 0.9607843160629272)
[2024-11-14 09:46:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:41][root][INFO] - Training Epoch: 2/2, step 9736/16670 completed (loss: 0.28054895997047424, acc: 0.9090909361839294)
[2024-11-14 09:46:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:41][root][INFO] - Training Epoch: 2/2, step 9737/16670 completed (loss: 0.15514956414699554, acc: 0.9558823704719543)
[2024-11-14 09:46:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:42][root][INFO] - Training Epoch: 2/2, step 9738/16670 completed (loss: 0.08638724684715271, acc: 1.0)
[2024-11-14 09:46:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:42][root][INFO] - Training Epoch: 2/2, step 9739/16670 completed (loss: 0.15201693773269653, acc: 0.957446813583374)
[2024-11-14 09:46:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:42][root][INFO] - Training Epoch: 2/2, step 9740/16670 completed (loss: 0.18781325221061707, acc: 0.9591836929321289)
[2024-11-14 09:46:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:43][root][INFO] - Training Epoch: 2/2, step 9741/16670 completed (loss: 0.615953803062439, acc: 0.9032257795333862)
[2024-11-14 09:46:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:43][root][INFO] - Training Epoch: 2/2, step 9742/16670 completed (loss: 0.17089955508708954, acc: 0.949999988079071)
[2024-11-14 09:46:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:43][root][INFO] - Training Epoch: 2/2, step 9743/16670 completed (loss: 0.5862696766853333, acc: 0.8679245114326477)
[2024-11-14 09:46:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:44][root][INFO] - Training Epoch: 2/2, step 9744/16670 completed (loss: 0.5158677101135254, acc: 0.9636363387107849)
[2024-11-14 09:46:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:44][root][INFO] - Training Epoch: 2/2, step 9745/16670 completed (loss: 0.28945398330688477, acc: 0.9387755393981934)
[2024-11-14 09:46:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:44][root][INFO] - Training Epoch: 2/2, step 9746/16670 completed (loss: 0.4480148255825043, acc: 0.8888888955116272)
[2024-11-14 09:46:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:44][root][INFO] - Training Epoch: 2/2, step 9747/16670 completed (loss: 0.3711085617542267, acc: 0.9305555820465088)
[2024-11-14 09:46:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:45][root][INFO] - Training Epoch: 2/2, step 9748/16670 completed (loss: 0.2824191153049469, acc: 0.949999988079071)
[2024-11-14 09:46:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:45][root][INFO] - Training Epoch: 2/2, step 9749/16670 completed (loss: 0.2083064317703247, acc: 0.97826087474823)
[2024-11-14 09:46:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:45][root][INFO] - Training Epoch: 2/2, step 9750/16670 completed (loss: 0.6019172072410583, acc: 0.9032257795333862)
[2024-11-14 09:46:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:46][root][INFO] - Training Epoch: 2/2, step 9751/16670 completed (loss: 0.8364681005477905, acc: 0.8181818127632141)
[2024-11-14 09:46:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:46][root][INFO] - Training Epoch: 2/2, step 9752/16670 completed (loss: 0.05794857069849968, acc: 1.0)
[2024-11-14 09:46:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:46][root][INFO] - Training Epoch: 2/2, step 9753/16670 completed (loss: 0.19433274865150452, acc: 0.9493087530136108)
[2024-11-14 09:46:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:47][root][INFO] - Training Epoch: 2/2, step 9754/16670 completed (loss: 0.10985083132982254, acc: 0.9541984796524048)
[2024-11-14 09:46:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:47][root][INFO] - Training Epoch: 2/2, step 9755/16670 completed (loss: 0.15610401332378387, acc: 0.9607843160629272)
[2024-11-14 09:46:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:47][root][INFO] - Training Epoch: 2/2, step 9756/16670 completed (loss: 0.08741676807403564, acc: 0.9870129823684692)
[2024-11-14 09:46:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:48][root][INFO] - Training Epoch: 2/2, step 9757/16670 completed (loss: 0.10170584917068481, acc: 0.9674796462059021)
[2024-11-14 09:46:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:48][root][INFO] - Training Epoch: 2/2, step 9758/16670 completed (loss: 0.11587358266115189, acc: 0.9645161032676697)
[2024-11-14 09:46:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:48][root][INFO] - Training Epoch: 2/2, step 9759/16670 completed (loss: 0.16629983484745026, acc: 0.957317054271698)
[2024-11-14 09:46:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:49][root][INFO] - Training Epoch: 2/2, step 9760/16670 completed (loss: 0.11558058857917786, acc: 0.9667773842811584)
[2024-11-14 09:46:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:49][root][INFO] - Training Epoch: 2/2, step 9761/16670 completed (loss: 0.1600593626499176, acc: 0.9585987329483032)
[2024-11-14 09:46:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:49][root][INFO] - Training Epoch: 2/2, step 9762/16670 completed (loss: 0.27329394221305847, acc: 0.927756667137146)
[2024-11-14 09:46:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:50][root][INFO] - Training Epoch: 2/2, step 9763/16670 completed (loss: 0.034712281078100204, acc: 1.0)
[2024-11-14 09:46:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:50][root][INFO] - Training Epoch: 2/2, step 9764/16670 completed (loss: 0.12162061780691147, acc: 0.9706666469573975)
[2024-11-14 09:46:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:50][root][INFO] - Training Epoch: 2/2, step 9765/16670 completed (loss: 0.24792040884494781, acc: 0.931034505367279)
[2024-11-14 09:46:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:50][root][INFO] - Training Epoch: 2/2, step 9766/16670 completed (loss: 0.11148309707641602, acc: 0.9586206674575806)
[2024-11-14 09:46:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:51][root][INFO] - Training Epoch: 2/2, step 9767/16670 completed (loss: 0.17396435141563416, acc: 0.9464285969734192)
[2024-11-14 09:46:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:51][root][INFO] - Training Epoch: 2/2, step 9768/16670 completed (loss: 0.16405996680259705, acc: 0.9724770784378052)
[2024-11-14 09:46:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:51][root][INFO] - Training Epoch: 2/2, step 9769/16670 completed (loss: 0.16890545189380646, acc: 0.9587628841400146)
[2024-11-14 09:46:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:52][root][INFO] - Training Epoch: 2/2, step 9770/16670 completed (loss: 0.2772316336631775, acc: 0.9325153231620789)
[2024-11-14 09:46:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:52][root][INFO] - Training Epoch: 2/2, step 9771/16670 completed (loss: 0.23693959414958954, acc: 0.9411764740943909)
[2024-11-14 09:46:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:52][root][INFO] - Training Epoch: 2/2, step 9772/16670 completed (loss: 0.06915271282196045, acc: 0.9733333587646484)
[2024-11-14 09:46:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:53][root][INFO] - Training Epoch: 2/2, step 9773/16670 completed (loss: 0.1575116366147995, acc: 0.9428571462631226)
[2024-11-14 09:46:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:53][root][INFO] - Training Epoch: 2/2, step 9774/16670 completed (loss: 0.23678892850875854, acc: 0.9240506291389465)
[2024-11-14 09:46:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:53][root][INFO] - Training Epoch: 2/2, step 9775/16670 completed (loss: 0.2594965696334839, acc: 0.9438202381134033)
[2024-11-14 09:46:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:54][root][INFO] - Training Epoch: 2/2, step 9776/16670 completed (loss: 0.14848501980304718, acc: 0.95652174949646)
[2024-11-14 09:46:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:54][root][INFO] - Training Epoch: 2/2, step 9777/16670 completed (loss: 0.09009797871112823, acc: 0.9637305736541748)
[2024-11-14 09:46:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:54][root][INFO] - Training Epoch: 2/2, step 9778/16670 completed (loss: 0.23616862297058105, acc: 0.9328358173370361)
[2024-11-14 09:46:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:54][root][INFO] - Training Epoch: 2/2, step 9779/16670 completed (loss: 0.061999138444662094, acc: 0.9887640476226807)
[2024-11-14 09:46:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:55][root][INFO] - Training Epoch: 2/2, step 9780/16670 completed (loss: 0.13545750081539154, acc: 0.9473684430122375)
[2024-11-14 09:46:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:55][root][INFO] - Training Epoch: 2/2, step 9781/16670 completed (loss: 0.18708328902721405, acc: 0.9629629850387573)
[2024-11-14 09:46:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:55][root][INFO] - Training Epoch: 2/2, step 9782/16670 completed (loss: 0.3944683372974396, acc: 0.9166666865348816)
[2024-11-14 09:46:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:56][root][INFO] - Training Epoch: 2/2, step 9783/16670 completed (loss: 0.10700232535600662, acc: 0.9704142212867737)
[2024-11-14 09:46:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:56][root][INFO] - Training Epoch: 2/2, step 9784/16670 completed (loss: 0.05965878814458847, acc: 0.9814814925193787)
[2024-11-14 09:46:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:56][root][INFO] - Training Epoch: 2/2, step 9785/16670 completed (loss: 0.20449165999889374, acc: 0.9534883499145508)
[2024-11-14 09:46:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:57][root][INFO] - Training Epoch: 2/2, step 9786/16670 completed (loss: 0.2783989906311035, acc: 0.9301075339317322)
[2024-11-14 09:46:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:57][root][INFO] - Training Epoch: 2/2, step 9787/16670 completed (loss: 0.09214305877685547, acc: 0.9788732528686523)
[2024-11-14 09:46:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:57][root][INFO] - Training Epoch: 2/2, step 9788/16670 completed (loss: 0.3037274479866028, acc: 0.9108911156654358)
[2024-11-14 09:46:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:58][root][INFO] - Training Epoch: 2/2, step 9789/16670 completed (loss: 0.10662725567817688, acc: 0.9788732528686523)
[2024-11-14 09:46:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:58][root][INFO] - Training Epoch: 2/2, step 9790/16670 completed (loss: 0.0846208930015564, acc: 0.9829545617103577)
[2024-11-14 09:46:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:58][root][INFO] - Training Epoch: 2/2, step 9791/16670 completed (loss: 0.2157507836818695, acc: 0.9438202381134033)
[2024-11-14 09:46:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:59][root][INFO] - Training Epoch: 2/2, step 9792/16670 completed (loss: 0.28473028540611267, acc: 0.9203540086746216)
[2024-11-14 09:46:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:59][root][INFO] - Training Epoch: 2/2, step 9793/16670 completed (loss: 0.1491231471300125, acc: 0.9512194991111755)
[2024-11-14 09:46:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:46:59][root][INFO] - Training Epoch: 2/2, step 9794/16670 completed (loss: 0.212894469499588, acc: 0.9629629850387573)
[2024-11-14 09:46:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:00][root][INFO] - Training Epoch: 2/2, step 9795/16670 completed (loss: 0.21748478710651398, acc: 0.930232584476471)
[2024-11-14 09:47:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:00][root][INFO] - Training Epoch: 2/2, step 9796/16670 completed (loss: 0.16256561875343323, acc: 0.9696969985961914)
[2024-11-14 09:47:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:00][root][INFO] - Training Epoch: 2/2, step 9797/16670 completed (loss: 0.45505207777023315, acc: 0.8928571343421936)
[2024-11-14 09:47:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:01][root][INFO] - Training Epoch: 2/2, step 9798/16670 completed (loss: 0.40853649377822876, acc: 0.9032257795333862)
[2024-11-14 09:47:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:01][root][INFO] - Training Epoch: 2/2, step 9799/16670 completed (loss: 0.21805629134178162, acc: 0.95652174949646)
[2024-11-14 09:47:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:01][root][INFO] - Training Epoch: 2/2, step 9800/16670 completed (loss: 0.12002731114625931, acc: 0.9583333134651184)
[2024-11-14 09:47:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:02][root][INFO] - Training Epoch: 2/2, step 9801/16670 completed (loss: 0.7816839814186096, acc: 0.8653846383094788)
[2024-11-14 09:47:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:02][root][INFO] - Training Epoch: 2/2, step 9802/16670 completed (loss: 0.5531870126724243, acc: 0.8627451062202454)
[2024-11-14 09:47:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:02][root][INFO] - Training Epoch: 2/2, step 9803/16670 completed (loss: 0.32725289463996887, acc: 0.8947368264198303)
[2024-11-14 09:47:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:03][root][INFO] - Training Epoch: 2/2, step 9804/16670 completed (loss: 0.3058357834815979, acc: 0.8999999761581421)
[2024-11-14 09:47:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:03][root][INFO] - Training Epoch: 2/2, step 9805/16670 completed (loss: 0.3212348520755768, acc: 0.9117646813392639)
[2024-11-14 09:47:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:03][root][INFO] - Training Epoch: 2/2, step 9806/16670 completed (loss: 0.6084796190261841, acc: 0.8421052694320679)
[2024-11-14 09:47:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:03][root][INFO] - Training Epoch: 2/2, step 9807/16670 completed (loss: 0.4590643048286438, acc: 0.8833333253860474)
[2024-11-14 09:47:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:04][root][INFO] - Training Epoch: 2/2, step 9808/16670 completed (loss: 0.29765328764915466, acc: 0.9259259104728699)
[2024-11-14 09:47:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:04][root][INFO] - Training Epoch: 2/2, step 9809/16670 completed (loss: 0.20804144442081451, acc: 0.9599999785423279)
[2024-11-14 09:47:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:04][root][INFO] - Training Epoch: 2/2, step 9810/16670 completed (loss: 0.23706643283367157, acc: 0.9587628841400146)
[2024-11-14 09:47:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:05][root][INFO] - Training Epoch: 2/2, step 9811/16670 completed (loss: 0.07117730379104614, acc: 0.9862068891525269)
[2024-11-14 09:47:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:05][root][INFO] - Training Epoch: 2/2, step 9812/16670 completed (loss: 0.05756981298327446, acc: 0.9831932783126831)
[2024-11-14 09:47:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:05][root][INFO] - Training Epoch: 2/2, step 9813/16670 completed (loss: 0.167470321059227, acc: 0.960869550704956)
[2024-11-14 09:47:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:06][root][INFO] - Training Epoch: 2/2, step 9814/16670 completed (loss: 0.1663319170475006, acc: 0.9637681245803833)
[2024-11-14 09:47:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:06][root][INFO] - Training Epoch: 2/2, step 9815/16670 completed (loss: 0.4632982015609741, acc: 0.8590604066848755)
[2024-11-14 09:47:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:06][root][INFO] - Training Epoch: 2/2, step 9816/16670 completed (loss: 0.19841092824935913, acc: 0.9722222089767456)
[2024-11-14 09:47:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:07][root][INFO] - Training Epoch: 2/2, step 9817/16670 completed (loss: 0.25457799434661865, acc: 0.9239130616188049)
[2024-11-14 09:47:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:07][root][INFO] - Training Epoch: 2/2, step 9818/16670 completed (loss: 0.12420150637626648, acc: 0.9512194991111755)
[2024-11-14 09:47:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:07][root][INFO] - Training Epoch: 2/2, step 9819/16670 completed (loss: 0.08315277099609375, acc: 0.9826086759567261)
[2024-11-14 09:47:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:07][root][INFO] - Training Epoch: 2/2, step 9820/16670 completed (loss: 0.09927603602409363, acc: 0.9640718698501587)
[2024-11-14 09:47:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:08][root][INFO] - Training Epoch: 2/2, step 9821/16670 completed (loss: 0.08959267288446426, acc: 0.9710144996643066)
[2024-11-14 09:47:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:08][root][INFO] - Training Epoch: 2/2, step 9822/16670 completed (loss: 0.21053460240364075, acc: 0.9342105388641357)
[2024-11-14 09:47:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:08][root][INFO] - Training Epoch: 2/2, step 9823/16670 completed (loss: 0.2641404867172241, acc: 0.921875)
[2024-11-14 09:47:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:09][root][INFO] - Training Epoch: 2/2, step 9824/16670 completed (loss: 0.3296824097633362, acc: 0.9081632494926453)
[2024-11-14 09:47:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:09][root][INFO] - Training Epoch: 2/2, step 9825/16670 completed (loss: 0.07499103993177414, acc: 0.963302731513977)
[2024-11-14 09:47:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:09][root][INFO] - Training Epoch: 2/2, step 9826/16670 completed (loss: 0.051274336874485016, acc: 0.9864864945411682)
[2024-11-14 09:47:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:10][root][INFO] - Training Epoch: 2/2, step 9827/16670 completed (loss: 0.049499232321977615, acc: 0.9828571677207947)
[2024-11-14 09:47:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:10][root][INFO] - Training Epoch: 2/2, step 9828/16670 completed (loss: 0.13541501760482788, acc: 0.9797570705413818)
[2024-11-14 09:47:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:10][root][INFO] - Training Epoch: 2/2, step 9829/16670 completed (loss: 0.017058005556464195, acc: 1.0)
[2024-11-14 09:47:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:11][root][INFO] - Training Epoch: 2/2, step 9830/16670 completed (loss: 0.15351806581020355, acc: 0.9716981053352356)
[2024-11-14 09:47:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:11][root][INFO] - Training Epoch: 2/2, step 9831/16670 completed (loss: 0.13434912264347076, acc: 0.9684210419654846)
[2024-11-14 09:47:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:11][root][INFO] - Training Epoch: 2/2, step 9832/16670 completed (loss: 0.3942609131336212, acc: 0.9318181872367859)
[2024-11-14 09:47:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:11][root][INFO] - Training Epoch: 2/2, step 9833/16670 completed (loss: 0.6029713153839111, acc: 0.84375)
[2024-11-14 09:47:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:12][root][INFO] - Training Epoch: 2/2, step 9834/16670 completed (loss: 0.14925481379032135, acc: 0.930232584476471)
[2024-11-14 09:47:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:12][root][INFO] - Training Epoch: 2/2, step 9835/16670 completed (loss: 0.3299529552459717, acc: 0.9411764740943909)
[2024-11-14 09:47:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:12][root][INFO] - Training Epoch: 2/2, step 9836/16670 completed (loss: 0.09835528582334518, acc: 0.97826087474823)
[2024-11-14 09:47:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:13][root][INFO] - Training Epoch: 2/2, step 9837/16670 completed (loss: 0.09150430560112, acc: 0.9666666388511658)
[2024-11-14 09:47:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:13][root][INFO] - Training Epoch: 2/2, step 9838/16670 completed (loss: 0.42325782775878906, acc: 0.9166666865348816)
[2024-11-14 09:47:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:13][root][INFO] - Training Epoch: 2/2, step 9839/16670 completed (loss: 0.23415778577327728, acc: 0.9772727489471436)
[2024-11-14 09:47:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:14][root][INFO] - Training Epoch: 2/2, step 9840/16670 completed (loss: 0.19778257608413696, acc: 0.9444444179534912)
[2024-11-14 09:47:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:14][root][INFO] - Training Epoch: 2/2, step 9841/16670 completed (loss: 0.30232831835746765, acc: 0.9433962106704712)
[2024-11-14 09:47:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:14][root][INFO] - Training Epoch: 2/2, step 9842/16670 completed (loss: 0.24400025606155396, acc: 0.9534883499145508)
[2024-11-14 09:47:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:15][root][INFO] - Training Epoch: 2/2, step 9843/16670 completed (loss: 0.7049390077590942, acc: 0.8166666626930237)
[2024-11-14 09:47:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:15][root][INFO] - Training Epoch: 2/2, step 9844/16670 completed (loss: 0.3308064937591553, acc: 0.9066666960716248)
[2024-11-14 09:47:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:15][root][INFO] - Training Epoch: 2/2, step 9845/16670 completed (loss: 0.4416468143463135, acc: 0.8793103694915771)
[2024-11-14 09:47:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:16][root][INFO] - Training Epoch: 2/2, step 9846/16670 completed (loss: 0.3931303918361664, acc: 0.8805969953536987)
[2024-11-14 09:47:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:16][root][INFO] - Training Epoch: 2/2, step 9847/16670 completed (loss: 0.43473124504089355, acc: 0.8888888955116272)
[2024-11-14 09:47:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:16][root][INFO] - Training Epoch: 2/2, step 9848/16670 completed (loss: 0.172664076089859, acc: 0.9487179517745972)
[2024-11-14 09:47:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:17][root][INFO] - Training Epoch: 2/2, step 9849/16670 completed (loss: 0.27938851714134216, acc: 0.9389312863349915)
[2024-11-14 09:47:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:17][root][INFO] - Training Epoch: 2/2, step 9850/16670 completed (loss: 0.4207008183002472, acc: 0.9042553305625916)
[2024-11-14 09:47:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:17][root][INFO] - Training Epoch: 2/2, step 9851/16670 completed (loss: 0.6991771459579468, acc: 0.8382353186607361)
[2024-11-14 09:47:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:18][root][INFO] - Training Epoch: 2/2, step 9852/16670 completed (loss: 0.4567345380783081, acc: 0.8636363744735718)
[2024-11-14 09:47:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:18][root][INFO] - Training Epoch: 2/2, step 9853/16670 completed (loss: 0.5950950384140015, acc: 0.800000011920929)
[2024-11-14 09:47:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:18][root][INFO] - Training Epoch: 2/2, step 9854/16670 completed (loss: 0.6815292239189148, acc: 0.8360655903816223)
[2024-11-14 09:47:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:19][root][INFO] - Training Epoch: 2/2, step 9855/16670 completed (loss: 0.490590900182724, acc: 0.8974359035491943)
[2024-11-14 09:47:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:19][root][INFO] - Training Epoch: 2/2, step 9856/16670 completed (loss: 0.3271615505218506, acc: 0.9259259104728699)
[2024-11-14 09:47:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:19][root][INFO] - Training Epoch: 2/2, step 9857/16670 completed (loss: 0.07048460841178894, acc: 0.9772727489471436)
[2024-11-14 09:47:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:20][root][INFO] - Training Epoch: 2/2, step 9858/16670 completed (loss: 1.0669840574264526, acc: 0.738095223903656)
[2024-11-14 09:47:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:20][root][INFO] - Training Epoch: 2/2, step 9859/16670 completed (loss: 0.6153488755226135, acc: 0.9166666865348816)
[2024-11-14 09:47:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:20][root][INFO] - Training Epoch: 2/2, step 9860/16670 completed (loss: 0.5016173720359802, acc: 0.8939393758773804)
[2024-11-14 09:47:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:21][root][INFO] - Training Epoch: 2/2, step 9861/16670 completed (loss: 0.6892651915550232, acc: 0.8311688303947449)
[2024-11-14 09:47:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:21][root][INFO] - Training Epoch: 2/2, step 9862/16670 completed (loss: 0.6151681542396545, acc: 0.8703703880310059)
[2024-11-14 09:47:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:22][root][INFO] - Training Epoch: 2/2, step 9863/16670 completed (loss: 0.4043373167514801, acc: 0.8591549396514893)
[2024-11-14 09:47:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:22][root][INFO] - Training Epoch: 2/2, step 9864/16670 completed (loss: 1.0526198148727417, acc: 0.7400000095367432)
[2024-11-14 09:47:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:22][root][INFO] - Training Epoch: 2/2, step 9865/16670 completed (loss: 0.23042604327201843, acc: 0.9464285969734192)
[2024-11-14 09:47:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:23][root][INFO] - Training Epoch: 2/2, step 9866/16670 completed (loss: 0.40849530696868896, acc: 0.8709677457809448)
[2024-11-14 09:47:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:23][root][INFO] - Training Epoch: 2/2, step 9867/16670 completed (loss: 0.5517745018005371, acc: 0.8533333539962769)
[2024-11-14 09:47:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:23][root][INFO] - Training Epoch: 2/2, step 9868/16670 completed (loss: 0.2874697148799896, acc: 0.8974359035491943)
[2024-11-14 09:47:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:24][root][INFO] - Training Epoch: 2/2, step 9869/16670 completed (loss: 0.770237147808075, acc: 0.8108108043670654)
[2024-11-14 09:47:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:24][root][INFO] - Training Epoch: 2/2, step 9870/16670 completed (loss: 0.24560245871543884, acc: 0.9347826242446899)
[2024-11-14 09:47:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:24][root][INFO] - Training Epoch: 2/2, step 9871/16670 completed (loss: 0.503302276134491, acc: 0.9142857193946838)
[2024-11-14 09:47:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:25][root][INFO] - Training Epoch: 2/2, step 9872/16670 completed (loss: 0.6356266736984253, acc: 0.8888888955116272)
[2024-11-14 09:47:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:25][root][INFO] - Training Epoch: 2/2, step 9873/16670 completed (loss: 0.7657427787780762, acc: 0.841269850730896)
[2024-11-14 09:47:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:25][root][INFO] - Training Epoch: 2/2, step 9874/16670 completed (loss: 0.4822976589202881, acc: 0.8235294222831726)
[2024-11-14 09:47:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:26][root][INFO] - Training Epoch: 2/2, step 9875/16670 completed (loss: 0.376859575510025, acc: 0.9135802388191223)
[2024-11-14 09:47:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:26][root][INFO] - Training Epoch: 2/2, step 9876/16670 completed (loss: 0.2977098524570465, acc: 0.8823529481887817)
[2024-11-14 09:47:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:26][root][INFO] - Training Epoch: 2/2, step 9877/16670 completed (loss: 1.038175106048584, acc: 0.7446808218955994)
[2024-11-14 09:47:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:27][root][INFO] - Training Epoch: 2/2, step 9878/16670 completed (loss: 0.6334095001220703, acc: 0.8157894611358643)
[2024-11-14 09:47:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:27][root][INFO] - Training Epoch: 2/2, step 9879/16670 completed (loss: 0.0759173110127449, acc: 0.9743589758872986)
[2024-11-14 09:47:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:27][root][INFO] - Training Epoch: 2/2, step 9880/16670 completed (loss: 0.8279591202735901, acc: 0.8507462739944458)
[2024-11-14 09:47:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:28][root][INFO] - Training Epoch: 2/2, step 9881/16670 completed (loss: 0.9791306853294373, acc: 0.78125)
[2024-11-14 09:47:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:28][root][INFO] - Training Epoch: 2/2, step 9882/16670 completed (loss: 0.24889667332172394, acc: 0.9743589758872986)
[2024-11-14 09:47:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:28][root][INFO] - Training Epoch: 2/2, step 9883/16670 completed (loss: 0.5852152109146118, acc: 0.8181818127632141)
[2024-11-14 09:47:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:29][root][INFO] - Training Epoch: 2/2, step 9884/16670 completed (loss: 0.3129914402961731, acc: 0.9117646813392639)
[2024-11-14 09:47:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:29][root][INFO] - Training Epoch: 2/2, step 9885/16670 completed (loss: 1.1877540349960327, acc: 0.7843137383460999)
[2024-11-14 09:47:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:29][root][INFO] - Training Epoch: 2/2, step 9886/16670 completed (loss: 0.4918196499347687, acc: 0.8472222089767456)
[2024-11-14 09:47:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:30][root][INFO] - Training Epoch: 2/2, step 9887/16670 completed (loss: 0.3763432502746582, acc: 0.8846153616905212)
[2024-11-14 09:47:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:30][root][INFO] - Training Epoch: 2/2, step 9888/16670 completed (loss: 0.7629246115684509, acc: 0.8478260636329651)
[2024-11-14 09:47:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:30][root][INFO] - Training Epoch: 2/2, step 9889/16670 completed (loss: 0.42145395278930664, acc: 0.9272727370262146)
[2024-11-14 09:47:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:30][root][INFO] - Training Epoch: 2/2, step 9890/16670 completed (loss: 0.8336752653121948, acc: 0.8026315569877625)
[2024-11-14 09:47:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:31][root][INFO] - Training Epoch: 2/2, step 9891/16670 completed (loss: 0.7610015869140625, acc: 0.7704917788505554)
[2024-11-14 09:47:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:31][root][INFO] - Training Epoch: 2/2, step 9892/16670 completed (loss: 0.1942880004644394, acc: 0.9791666865348816)
[2024-11-14 09:47:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:31][root][INFO] - Training Epoch: 2/2, step 9893/16670 completed (loss: 0.4042340815067291, acc: 0.868852436542511)
[2024-11-14 09:47:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:32][root][INFO] - Training Epoch: 2/2, step 9894/16670 completed (loss: 0.6251049041748047, acc: 0.8787878751754761)
[2024-11-14 09:47:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:32][root][INFO] - Training Epoch: 2/2, step 9895/16670 completed (loss: 0.5526204705238342, acc: 0.8863636255264282)
[2024-11-14 09:47:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:32][root][INFO] - Training Epoch: 2/2, step 9896/16670 completed (loss: 0.688848078250885, acc: 0.8870967626571655)
[2024-11-14 09:47:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:33][root][INFO] - Training Epoch: 2/2, step 9897/16670 completed (loss: 0.42152684926986694, acc: 0.8727272748947144)
[2024-11-14 09:47:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:33][root][INFO] - Training Epoch: 2/2, step 9898/16670 completed (loss: 0.2070261836051941, acc: 0.9342105388641357)
[2024-11-14 09:47:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:34][root][INFO] - Training Epoch: 2/2, step 9899/16670 completed (loss: 0.4680944085121155, acc: 0.8703703880310059)
[2024-11-14 09:47:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:34][root][INFO] - Training Epoch: 2/2, step 9900/16670 completed (loss: 0.5121345520019531, acc: 0.9189189076423645)
[2024-11-14 09:47:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:34][root][INFO] - Training Epoch: 2/2, step 9901/16670 completed (loss: 0.28756842017173767, acc: 0.8709677457809448)
[2024-11-14 09:47:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:35][root][INFO] - Training Epoch: 2/2, step 9902/16670 completed (loss: 0.6764503717422485, acc: 0.8602150678634644)
[2024-11-14 09:47:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:35][root][INFO] - Training Epoch: 2/2, step 9903/16670 completed (loss: 0.5117325186729431, acc: 0.8983050584793091)
[2024-11-14 09:47:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:35][root][INFO] - Training Epoch: 2/2, step 9904/16670 completed (loss: 0.47087740898132324, acc: 0.8235294222831726)
[2024-11-14 09:47:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:35][root][INFO] - Training Epoch: 2/2, step 9905/16670 completed (loss: 0.9932242035865784, acc: 0.6875)
[2024-11-14 09:47:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:36][root][INFO] - Training Epoch: 2/2, step 9906/16670 completed (loss: 0.8537541031837463, acc: 0.8382353186607361)
[2024-11-14 09:47:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:36][root][INFO] - Training Epoch: 2/2, step 9907/16670 completed (loss: 0.5418680906295776, acc: 0.8913043737411499)
[2024-11-14 09:47:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:36][root][INFO] - Training Epoch: 2/2, step 9908/16670 completed (loss: 0.4209716320037842, acc: 0.9142857193946838)
[2024-11-14 09:47:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:37][root][INFO] - Training Epoch: 2/2, step 9909/16670 completed (loss: 0.303338885307312, acc: 0.9074074029922485)
[2024-11-14 09:47:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:37][root][INFO] - Training Epoch: 2/2, step 9910/16670 completed (loss: 0.3451433479785919, acc: 0.9473684430122375)
[2024-11-14 09:47:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:38][root][INFO] - Training Epoch: 2/2, step 9911/16670 completed (loss: 0.9624640345573425, acc: 0.8055555820465088)
[2024-11-14 09:47:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:38][root][INFO] - Training Epoch: 2/2, step 9912/16670 completed (loss: 0.8127045631408691, acc: 0.7647058963775635)
[2024-11-14 09:47:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:38][root][INFO] - Training Epoch: 2/2, step 9913/16670 completed (loss: 0.037258900701999664, acc: 1.0)
[2024-11-14 09:47:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:39][root][INFO] - Training Epoch: 2/2, step 9914/16670 completed (loss: 0.5568788051605225, acc: 0.8409090638160706)
[2024-11-14 09:47:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:39][root][INFO] - Training Epoch: 2/2, step 9915/16670 completed (loss: 0.3838207721710205, acc: 0.868852436542511)
[2024-11-14 09:47:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:39][root][INFO] - Training Epoch: 2/2, step 9916/16670 completed (loss: 0.1609504669904709, acc: 0.9696969985961914)
[2024-11-14 09:47:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:40][root][INFO] - Training Epoch: 2/2, step 9917/16670 completed (loss: 0.5112231373786926, acc: 0.9080459475517273)
[2024-11-14 09:47:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:40][root][INFO] - Training Epoch: 2/2, step 9918/16670 completed (loss: 0.7105101346969604, acc: 0.8333333134651184)
[2024-11-14 09:47:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:41][root][INFO] - Training Epoch: 2/2, step 9919/16670 completed (loss: 0.28924307227134705, acc: 0.9459459185600281)
[2024-11-14 09:47:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:41][root][INFO] - Training Epoch: 2/2, step 9920/16670 completed (loss: 0.8323502540588379, acc: 0.7941176295280457)
[2024-11-14 09:47:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:41][root][INFO] - Training Epoch: 2/2, step 9921/16670 completed (loss: 0.6601048111915588, acc: 0.7894737124443054)
[2024-11-14 09:47:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:42][root][INFO] - Training Epoch: 2/2, step 9922/16670 completed (loss: 0.3218463659286499, acc: 0.8846153616905212)
[2024-11-14 09:47:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:42][root][INFO] - Training Epoch: 2/2, step 9923/16670 completed (loss: 0.15890665352344513, acc: 0.9444444179534912)
[2024-11-14 09:47:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:42][root][INFO] - Training Epoch: 2/2, step 9924/16670 completed (loss: 0.37818533182144165, acc: 0.9152542352676392)
[2024-11-14 09:47:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:43][root][INFO] - Training Epoch: 2/2, step 9925/16670 completed (loss: 0.5299350619316101, acc: 0.8823529481887817)
[2024-11-14 09:47:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:43][root][INFO] - Training Epoch: 2/2, step 9926/16670 completed (loss: 0.2263650745153427, acc: 0.9545454382896423)
[2024-11-14 09:47:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:43][root][INFO] - Training Epoch: 2/2, step 9927/16670 completed (loss: 0.7114464640617371, acc: 0.8352941274642944)
[2024-11-14 09:47:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:44][root][INFO] - Training Epoch: 2/2, step 9928/16670 completed (loss: 0.08619555085897446, acc: 0.9767441749572754)
[2024-11-14 09:47:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:44][root][INFO] - Training Epoch: 2/2, step 9929/16670 completed (loss: 0.8237729072570801, acc: 0.7916666865348816)
[2024-11-14 09:47:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:44][root][INFO] - Training Epoch: 2/2, step 9930/16670 completed (loss: 0.2952902615070343, acc: 0.921875)
[2024-11-14 09:47:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:45][root][INFO] - Training Epoch: 2/2, step 9931/16670 completed (loss: 0.28036949038505554, acc: 0.9200000166893005)
[2024-11-14 09:47:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:45][root][INFO] - Training Epoch: 2/2, step 9932/16670 completed (loss: 0.3198595345020294, acc: 0.9090909361839294)
[2024-11-14 09:47:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:46][root][INFO] - Training Epoch: 2/2, step 9933/16670 completed (loss: 0.622768223285675, acc: 0.8409090638160706)
[2024-11-14 09:47:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:46][root][INFO] - Training Epoch: 2/2, step 9934/16670 completed (loss: 0.28616058826446533, acc: 0.9027777910232544)
[2024-11-14 09:47:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:46][root][INFO] - Training Epoch: 2/2, step 9935/16670 completed (loss: 0.5243770480155945, acc: 0.8933333158493042)
[2024-11-14 09:47:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:47][root][INFO] - Training Epoch: 2/2, step 9936/16670 completed (loss: 0.4544907510280609, acc: 0.8799999952316284)
[2024-11-14 09:47:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:47][root][INFO] - Training Epoch: 2/2, step 9937/16670 completed (loss: 0.3673359453678131, acc: 0.9122806787490845)
[2024-11-14 09:47:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:47][root][INFO] - Training Epoch: 2/2, step 9938/16670 completed (loss: 0.6104754209518433, acc: 0.8484848737716675)
[2024-11-14 09:47:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:48][root][INFO] - Training Epoch: 2/2, step 9939/16670 completed (loss: 0.45232611894607544, acc: 0.8865979313850403)
[2024-11-14 09:47:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:48][root][INFO] - Training Epoch: 2/2, step 9940/16670 completed (loss: 0.6955658793449402, acc: 0.8414633870124817)
[2024-11-14 09:47:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:48][root][INFO] - Training Epoch: 2/2, step 9941/16670 completed (loss: 0.3429730534553528, acc: 0.931034505367279)
[2024-11-14 09:47:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:49][root][INFO] - Training Epoch: 2/2, step 9942/16670 completed (loss: 0.2504384517669678, acc: 0.8863636255264282)
[2024-11-14 09:47:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:49][root][INFO] - Training Epoch: 2/2, step 9943/16670 completed (loss: 0.32262668013572693, acc: 0.9295774698257446)
[2024-11-14 09:47:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:49][root][INFO] - Training Epoch: 2/2, step 9944/16670 completed (loss: 0.5757843852043152, acc: 0.841269850730896)
[2024-11-14 09:47:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:50][root][INFO] - Training Epoch: 2/2, step 9945/16670 completed (loss: 0.7807672619819641, acc: 0.8192771077156067)
[2024-11-14 09:47:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:50][root][INFO] - Training Epoch: 2/2, step 9946/16670 completed (loss: 0.42434555292129517, acc: 0.9333333373069763)
[2024-11-14 09:47:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:50][root][INFO] - Training Epoch: 2/2, step 9947/16670 completed (loss: 0.4959219694137573, acc: 0.8507462739944458)
[2024-11-14 09:47:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:51][root][INFO] - Training Epoch: 2/2, step 9948/16670 completed (loss: 0.6820163726806641, acc: 0.8674699068069458)
[2024-11-14 09:47:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:51][root][INFO] - Training Epoch: 2/2, step 9949/16670 completed (loss: 0.42788270115852356, acc: 0.8309859037399292)
[2024-11-14 09:47:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:51][root][INFO] - Training Epoch: 2/2, step 9950/16670 completed (loss: 0.24840375781059265, acc: 0.9466666579246521)
[2024-11-14 09:47:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:52][root][INFO] - Training Epoch: 2/2, step 9951/16670 completed (loss: 0.2707640528678894, acc: 0.9259259104728699)
[2024-11-14 09:47:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:52][root][INFO] - Training Epoch: 2/2, step 9952/16670 completed (loss: 0.17290934920310974, acc: 0.9642857313156128)
[2024-11-14 09:47:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:52][root][INFO] - Training Epoch: 2/2, step 9953/16670 completed (loss: 0.3042981028556824, acc: 0.9272727370262146)
[2024-11-14 09:47:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:53][root][INFO] - Training Epoch: 2/2, step 9954/16670 completed (loss: 0.44065767526626587, acc: 0.8297872543334961)
[2024-11-14 09:47:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:53][root][INFO] - Training Epoch: 2/2, step 9955/16670 completed (loss: 0.48017746210098267, acc: 0.8904109597206116)
[2024-11-14 09:47:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:54][root][INFO] - Training Epoch: 2/2, step 9956/16670 completed (loss: 0.39704209566116333, acc: 0.9275362491607666)
[2024-11-14 09:47:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:54][root][INFO] - Training Epoch: 2/2, step 9957/16670 completed (loss: 0.7158779501914978, acc: 0.8307692408561707)
[2024-11-14 09:47:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:54][root][INFO] - Training Epoch: 2/2, step 9958/16670 completed (loss: 0.5954046845436096, acc: 0.9090909361839294)
[2024-11-14 09:47:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:55][root][INFO] - Training Epoch: 2/2, step 9959/16670 completed (loss: 0.695281982421875, acc: 0.875)
[2024-11-14 09:47:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:55][root][INFO] - Training Epoch: 2/2, step 9960/16670 completed (loss: 0.403379887342453, acc: 0.9230769276618958)
[2024-11-14 09:47:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:55][root][INFO] - Training Epoch: 2/2, step 9961/16670 completed (loss: 0.6552747488021851, acc: 0.8085106611251831)
[2024-11-14 09:47:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:56][root][INFO] - Training Epoch: 2/2, step 9962/16670 completed (loss: 0.5262770652770996, acc: 0.8961039185523987)
[2024-11-14 09:47:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:56][root][INFO] - Training Epoch: 2/2, step 9963/16670 completed (loss: 0.43082207441329956, acc: 0.8969072103500366)
[2024-11-14 09:47:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:56][root][INFO] - Training Epoch: 2/2, step 9964/16670 completed (loss: 0.316986083984375, acc: 0.9090909361839294)
[2024-11-14 09:47:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:57][root][INFO] - Training Epoch: 2/2, step 9965/16670 completed (loss: 0.5365003347396851, acc: 0.9019607901573181)
[2024-11-14 09:47:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:57][root][INFO] - Training Epoch: 2/2, step 9966/16670 completed (loss: 0.6759504079818726, acc: 0.8493150472640991)
[2024-11-14 09:47:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:57][root][INFO] - Training Epoch: 2/2, step 9967/16670 completed (loss: 0.5508462190628052, acc: 0.8260869383811951)
[2024-11-14 09:47:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:58][root][INFO] - Training Epoch: 2/2, step 9968/16670 completed (loss: 0.5835118293762207, acc: 0.8615384697914124)
[2024-11-14 09:47:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:58][root][INFO] - Training Epoch: 2/2, step 9969/16670 completed (loss: 0.7483662962913513, acc: 0.8695651888847351)
[2024-11-14 09:47:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:58][root][INFO] - Training Epoch: 2/2, step 9970/16670 completed (loss: 0.37995395064353943, acc: 0.8571428656578064)
[2024-11-14 09:47:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:59][root][INFO] - Training Epoch: 2/2, step 9971/16670 completed (loss: 0.20314693450927734, acc: 0.9464285969734192)
[2024-11-14 09:47:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:47:59][root][INFO] - Training Epoch: 2/2, step 9972/16670 completed (loss: 0.5825502872467041, acc: 0.8611111044883728)
[2024-11-14 09:47:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:00][root][INFO] - Training Epoch: 2/2, step 9973/16670 completed (loss: 0.5077630877494812, acc: 0.9354838728904724)
[2024-11-14 09:48:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:00][root][INFO] - Training Epoch: 2/2, step 9974/16670 completed (loss: 1.049121379852295, acc: 0.675000011920929)
[2024-11-14 09:48:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:00][root][INFO] - Training Epoch: 2/2, step 9975/16670 completed (loss: 0.9281324744224548, acc: 0.800000011920929)
[2024-11-14 09:48:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:01][root][INFO] - Training Epoch: 2/2, step 9976/16670 completed (loss: 0.6413543224334717, acc: 0.8243243098258972)
[2024-11-14 09:48:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:01][root][INFO] - Training Epoch: 2/2, step 9977/16670 completed (loss: 0.21170513331890106, acc: 0.9545454382896423)
[2024-11-14 09:48:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:01][root][INFO] - Training Epoch: 2/2, step 9978/16670 completed (loss: 0.5360313057899475, acc: 0.875)
[2024-11-14 09:48:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:02][root][INFO] - Training Epoch: 2/2, step 9979/16670 completed (loss: 0.9009882211685181, acc: 0.7749999761581421)
[2024-11-14 09:48:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:02][root][INFO] - Training Epoch: 2/2, step 9980/16670 completed (loss: 0.5830735564231873, acc: 0.9027777910232544)
[2024-11-14 09:48:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:02][root][INFO] - Training Epoch: 2/2, step 9981/16670 completed (loss: 0.29458436369895935, acc: 0.9259259104728699)
[2024-11-14 09:48:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:03][root][INFO] - Training Epoch: 2/2, step 9982/16670 completed (loss: 0.16303017735481262, acc: 0.9523809552192688)
[2024-11-14 09:48:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:03][root][INFO] - Training Epoch: 2/2, step 9983/16670 completed (loss: 0.41631025075912476, acc: 0.8961039185523987)
[2024-11-14 09:48:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:03][root][INFO] - Training Epoch: 2/2, step 9984/16670 completed (loss: 0.09138553589582443, acc: 0.9811320900917053)
[2024-11-14 09:48:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:04][root][INFO] - Training Epoch: 2/2, step 9985/16670 completed (loss: 0.6508994102478027, acc: 0.875)
[2024-11-14 09:48:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:04][root][INFO] - Training Epoch: 2/2, step 9986/16670 completed (loss: 0.22408545017242432, acc: 0.9692307710647583)
[2024-11-14 09:48:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:04][root][INFO] - Training Epoch: 2/2, step 9987/16670 completed (loss: 0.5601702332496643, acc: 0.8888888955116272)
[2024-11-14 09:48:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:05][root][INFO] - Training Epoch: 2/2, step 9988/16670 completed (loss: 0.9561405777931213, acc: 0.75)
[2024-11-14 09:48:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:05][root][INFO] - Training Epoch: 2/2, step 9989/16670 completed (loss: 0.5269063115119934, acc: 0.8703703880310059)
[2024-11-14 09:48:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:05][root][INFO] - Training Epoch: 2/2, step 9990/16670 completed (loss: 0.4035412073135376, acc: 0.8809523582458496)
[2024-11-14 09:48:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:06][root][INFO] - Training Epoch: 2/2, step 9991/16670 completed (loss: 0.5074763894081116, acc: 0.8793103694915771)
[2024-11-14 09:48:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:06][root][INFO] - Training Epoch: 2/2, step 9992/16670 completed (loss: 0.36495739221572876, acc: 0.8947368264198303)
[2024-11-14 09:48:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:06][root][INFO] - Training Epoch: 2/2, step 9993/16670 completed (loss: 0.6004862189292908, acc: 0.8518518805503845)
[2024-11-14 09:48:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:07][root][INFO] - Training Epoch: 2/2, step 9994/16670 completed (loss: 0.9320912957191467, acc: 0.800000011920929)
[2024-11-14 09:48:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:07][root][INFO] - Training Epoch: 2/2, step 9995/16670 completed (loss: 0.4038192629814148, acc: 0.8799999952316284)
[2024-11-14 09:48:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:08][root][INFO] - Training Epoch: 2/2, step 9996/16670 completed (loss: 0.23686446249485016, acc: 0.9242424368858337)
[2024-11-14 09:48:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:08][root][INFO] - Training Epoch: 2/2, step 9997/16670 completed (loss: 0.838768482208252, acc: 0.7941176295280457)
[2024-11-14 09:48:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:08][root][INFO] - Training Epoch: 2/2, step 9998/16670 completed (loss: 0.4715456962585449, acc: 0.8918918967247009)
[2024-11-14 09:48:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:09][root][INFO] - Training Epoch: 2/2, step 9999/16670 completed (loss: 0.2895442843437195, acc: 0.9245283007621765)
[2024-11-14 09:48:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:09][root][INFO] - Training Epoch: 2/2, step 10000/16670 completed (loss: 0.3613217771053314, acc: 0.8888888955116272)
[2024-11-14 09:48:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:09][root][INFO] - Training Epoch: 2/2, step 10001/16670 completed (loss: 0.42732560634613037, acc: 0.8791208863258362)
[2024-11-14 09:48:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:10][root][INFO] - Training Epoch: 2/2, step 10002/16670 completed (loss: 0.7189872860908508, acc: 0.7647058963775635)
[2024-11-14 09:48:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:10][root][INFO] - Training Epoch: 2/2, step 10003/16670 completed (loss: 0.3177153468132019, acc: 0.9189189076423645)
[2024-11-14 09:48:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:10][root][INFO] - Training Epoch: 2/2, step 10004/16670 completed (loss: 0.3017003536224365, acc: 0.9117646813392639)
[2024-11-14 09:48:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:10][root][INFO] - Training Epoch: 2/2, step 10005/16670 completed (loss: 0.048768118023872375, acc: 1.0)
[2024-11-14 09:48:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:11][root][INFO] - Training Epoch: 2/2, step 10006/16670 completed (loss: 0.22502964735031128, acc: 0.9210526347160339)
[2024-11-14 09:48:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:11][root][INFO] - Training Epoch: 2/2, step 10007/16670 completed (loss: 0.5985432267189026, acc: 0.8541666865348816)
[2024-11-14 09:48:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:11][root][INFO] - Training Epoch: 2/2, step 10008/16670 completed (loss: 0.5594537854194641, acc: 0.8461538553237915)
[2024-11-14 09:48:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:12][root][INFO] - Training Epoch: 2/2, step 10009/16670 completed (loss: 0.4262102246284485, acc: 0.8793103694915771)
[2024-11-14 09:48:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:12][root][INFO] - Training Epoch: 2/2, step 10010/16670 completed (loss: 0.5353020429611206, acc: 0.8395061492919922)
[2024-11-14 09:48:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:12][root][INFO] - Training Epoch: 2/2, step 10011/16670 completed (loss: 0.12901245057582855, acc: 0.9545454382896423)
[2024-11-14 09:48:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:13][root][INFO] - Training Epoch: 2/2, step 10012/16670 completed (loss: 0.5657640695571899, acc: 0.890625)
[2024-11-14 09:48:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:13][root][INFO] - Training Epoch: 2/2, step 10013/16670 completed (loss: 0.28556814789772034, acc: 0.8421052694320679)
[2024-11-14 09:48:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:13][root][INFO] - Training Epoch: 2/2, step 10014/16670 completed (loss: 0.23620294034481049, acc: 0.9411764740943909)
[2024-11-14 09:48:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:14][root][INFO] - Training Epoch: 2/2, step 10015/16670 completed (loss: 0.6326969861984253, acc: 0.8717948794364929)
[2024-11-14 09:48:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:14][root][INFO] - Training Epoch: 2/2, step 10016/16670 completed (loss: 0.5125110149383545, acc: 0.8840579986572266)
[2024-11-14 09:48:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:14][root][INFO] - Training Epoch: 2/2, step 10017/16670 completed (loss: 0.6174548268318176, acc: 0.875)
[2024-11-14 09:48:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:15][root][INFO] - Training Epoch: 2/2, step 10018/16670 completed (loss: 0.5062174201011658, acc: 0.8674699068069458)
[2024-11-14 09:48:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:15][root][INFO] - Training Epoch: 2/2, step 10019/16670 completed (loss: 0.1993149369955063, acc: 0.8928571343421936)
[2024-11-14 09:48:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:15][root][INFO] - Training Epoch: 2/2, step 10020/16670 completed (loss: 0.7393143773078918, acc: 0.8354430198669434)
[2024-11-14 09:48:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:15][root][INFO] - Training Epoch: 2/2, step 10021/16670 completed (loss: 0.22885018587112427, acc: 0.9512194991111755)
[2024-11-14 09:48:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:16][root][INFO] - Training Epoch: 2/2, step 10022/16670 completed (loss: 0.9465479254722595, acc: 0.7317073345184326)
[2024-11-14 09:48:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:16][root][INFO] - Training Epoch: 2/2, step 10023/16670 completed (loss: 0.36352822184562683, acc: 0.8936170339584351)
[2024-11-14 09:48:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:16][root][INFO] - Training Epoch: 2/2, step 10024/16670 completed (loss: 0.13515304028987885, acc: 0.9428571462631226)
[2024-11-14 09:48:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:17][root][INFO] - Training Epoch: 2/2, step 10025/16670 completed (loss: 0.24145649373531342, acc: 0.9107142686843872)
[2024-11-14 09:48:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:17][root][INFO] - Training Epoch: 2/2, step 10026/16670 completed (loss: 0.24178403615951538, acc: 0.9090909361839294)
[2024-11-14 09:48:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:17][root][INFO] - Training Epoch: 2/2, step 10027/16670 completed (loss: 0.43484213948249817, acc: 0.9130434989929199)
[2024-11-14 09:48:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:18][root][INFO] - Training Epoch: 2/2, step 10028/16670 completed (loss: 0.324307918548584, acc: 0.8999999761581421)
[2024-11-14 09:48:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:18][root][INFO] - Training Epoch: 2/2, step 10029/16670 completed (loss: 0.4503321945667267, acc: 0.9156626462936401)
[2024-11-14 09:48:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:18][root][INFO] - Training Epoch: 2/2, step 10030/16670 completed (loss: 0.2892235815525055, acc: 0.9122806787490845)
[2024-11-14 09:48:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:19][root][INFO] - Training Epoch: 2/2, step 10031/16670 completed (loss: 0.37275296449661255, acc: 0.9195402264595032)
[2024-11-14 09:48:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:19][root][INFO] - Training Epoch: 2/2, step 10032/16670 completed (loss: 0.16261307895183563, acc: 0.9558823704719543)
[2024-11-14 09:48:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:19][root][INFO] - Training Epoch: 2/2, step 10033/16670 completed (loss: 0.10453222692012787, acc: 0.9807692170143127)
[2024-11-14 09:48:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:19][root][INFO] - Training Epoch: 2/2, step 10034/16670 completed (loss: 0.5579745173454285, acc: 0.8115941882133484)
[2024-11-14 09:48:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:20][root][INFO] - Training Epoch: 2/2, step 10035/16670 completed (loss: 1.0117156505584717, acc: 0.796875)
[2024-11-14 09:48:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:20][root][INFO] - Training Epoch: 2/2, step 10036/16670 completed (loss: 0.9715228080749512, acc: 0.8148148059844971)
[2024-11-14 09:48:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:20][root][INFO] - Training Epoch: 2/2, step 10037/16670 completed (loss: 0.4214789569377899, acc: 0.8732394576072693)
[2024-11-14 09:48:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:21][root][INFO] - Training Epoch: 2/2, step 10038/16670 completed (loss: 0.33474016189575195, acc: 0.9066666960716248)
[2024-11-14 09:48:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:21][root][INFO] - Training Epoch: 2/2, step 10039/16670 completed (loss: 0.33572903275489807, acc: 0.9259259104728699)
[2024-11-14 09:48:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:21][root][INFO] - Training Epoch: 2/2, step 10040/16670 completed (loss: 0.7768750786781311, acc: 0.8181818127632141)
[2024-11-14 09:48:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:22][root][INFO] - Training Epoch: 2/2, step 10041/16670 completed (loss: 0.7705074548721313, acc: 0.8837209343910217)
[2024-11-14 09:48:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:22][root][INFO] - Training Epoch: 2/2, step 10042/16670 completed (loss: 0.3784671127796173, acc: 0.8857142925262451)
[2024-11-14 09:48:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:22][root][INFO] - Training Epoch: 2/2, step 10043/16670 completed (loss: 0.17817223072052002, acc: 0.9210526347160339)
[2024-11-14 09:48:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:22][root][INFO] - Training Epoch: 2/2, step 10044/16670 completed (loss: 0.8531426191329956, acc: 0.7551020383834839)
[2024-11-14 09:48:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:23][root][INFO] - Training Epoch: 2/2, step 10045/16670 completed (loss: 0.5777918696403503, acc: 0.8169013857841492)
[2024-11-14 09:48:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:23][root][INFO] - Training Epoch: 2/2, step 10046/16670 completed (loss: 0.3786363899707794, acc: 0.8983050584793091)
[2024-11-14 09:48:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:23][root][INFO] - Training Epoch: 2/2, step 10047/16670 completed (loss: 0.47020232677459717, acc: 0.8799999952316284)
[2024-11-14 09:48:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:24][root][INFO] - Training Epoch: 2/2, step 10048/16670 completed (loss: 0.521014928817749, acc: 0.9090909361839294)
[2024-11-14 09:48:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:24][root][INFO] - Training Epoch: 2/2, step 10049/16670 completed (loss: 0.37607353925704956, acc: 0.90625)
[2024-11-14 09:48:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:24][root][INFO] - Training Epoch: 2/2, step 10050/16670 completed (loss: 0.1249866858124733, acc: 0.949999988079071)
[2024-11-14 09:48:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:25][root][INFO] - Training Epoch: 2/2, step 10051/16670 completed (loss: 0.361197292804718, acc: 0.9012345671653748)
[2024-11-14 09:48:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:25][root][INFO] - Training Epoch: 2/2, step 10052/16670 completed (loss: 0.20188499987125397, acc: 0.9487179517745972)
[2024-11-14 09:48:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:25][root][INFO] - Training Epoch: 2/2, step 10053/16670 completed (loss: 0.4812264144420624, acc: 0.8852459192276001)
[2024-11-14 09:48:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:26][root][INFO] - Training Epoch: 2/2, step 10054/16670 completed (loss: 0.5692289471626282, acc: 0.8815789222717285)
[2024-11-14 09:48:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:26][root][INFO] - Training Epoch: 2/2, step 10055/16670 completed (loss: 0.636881411075592, acc: 0.8620689511299133)
[2024-11-14 09:48:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:26][root][INFO] - Training Epoch: 2/2, step 10056/16670 completed (loss: 0.4805123209953308, acc: 0.8823529481887817)
[2024-11-14 09:48:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:27][root][INFO] - Training Epoch: 2/2, step 10057/16670 completed (loss: 0.05909624695777893, acc: 1.0)
[2024-11-14 09:48:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:27][root][INFO] - Training Epoch: 2/2, step 10058/16670 completed (loss: 0.12857306003570557, acc: 0.9230769276618958)
[2024-11-14 09:48:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:27][root][INFO] - Training Epoch: 2/2, step 10059/16670 completed (loss: 0.2505825161933899, acc: 0.9272727370262146)
[2024-11-14 09:48:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:28][root][INFO] - Training Epoch: 2/2, step 10060/16670 completed (loss: 1.0467936992645264, acc: 0.686274528503418)
[2024-11-14 09:48:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:28][root][INFO] - Training Epoch: 2/2, step 10061/16670 completed (loss: 0.5021269917488098, acc: 0.8857142925262451)
[2024-11-14 09:48:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:28][root][INFO] - Training Epoch: 2/2, step 10062/16670 completed (loss: 0.0539713092148304, acc: 1.0)
[2024-11-14 09:48:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:28][root][INFO] - Training Epoch: 2/2, step 10063/16670 completed (loss: 0.4690147042274475, acc: 0.918367326259613)
[2024-11-14 09:48:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:29][root][INFO] - Training Epoch: 2/2, step 10064/16670 completed (loss: 0.2731051445007324, acc: 0.9487179517745972)
[2024-11-14 09:48:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:29][root][INFO] - Training Epoch: 2/2, step 10065/16670 completed (loss: 0.8685730695724487, acc: 0.800000011920929)
[2024-11-14 09:48:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:29][root][INFO] - Training Epoch: 2/2, step 10066/16670 completed (loss: 0.06960777938365936, acc: 0.9803921580314636)
[2024-11-14 09:48:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:30][root][INFO] - Training Epoch: 2/2, step 10067/16670 completed (loss: 1.0633893013000488, acc: 0.790123462677002)
[2024-11-14 09:48:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:30][root][INFO] - Training Epoch: 2/2, step 10068/16670 completed (loss: 0.8236304521560669, acc: 0.8367347121238708)
[2024-11-14 09:48:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:30][root][INFO] - Training Epoch: 2/2, step 10069/16670 completed (loss: 0.5463614463806152, acc: 0.8823529481887817)
[2024-11-14 09:48:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:31][root][INFO] - Training Epoch: 2/2, step 10070/16670 completed (loss: 0.6129282116889954, acc: 0.8421052694320679)
[2024-11-14 09:48:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:31][root][INFO] - Training Epoch: 2/2, step 10071/16670 completed (loss: 0.1314922273159027, acc: 0.9459459185600281)
[2024-11-14 09:48:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:31][root][INFO] - Training Epoch: 2/2, step 10072/16670 completed (loss: 0.15391439199447632, acc: 0.9591836929321289)
[2024-11-14 09:48:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:32][root][INFO] - Training Epoch: 2/2, step 10073/16670 completed (loss: 0.3178595006465912, acc: 0.8999999761581421)
[2024-11-14 09:48:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:32][root][INFO] - Training Epoch: 2/2, step 10074/16670 completed (loss: 0.5641890168190002, acc: 0.8658536672592163)
[2024-11-14 09:48:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:32][root][INFO] - Training Epoch: 2/2, step 10075/16670 completed (loss: 0.5132433176040649, acc: 0.8653846383094788)
[2024-11-14 09:48:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:33][root][INFO] - Training Epoch: 2/2, step 10076/16670 completed (loss: 0.9316598773002625, acc: 0.8500000238418579)
[2024-11-14 09:48:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:33][root][INFO] - Training Epoch: 2/2, step 10077/16670 completed (loss: 0.7859143614768982, acc: 0.7719298005104065)
[2024-11-14 09:48:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:33][root][INFO] - Training Epoch: 2/2, step 10078/16670 completed (loss: 0.4004923403263092, acc: 0.9285714030265808)
[2024-11-14 09:48:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:33][root][INFO] - Training Epoch: 2/2, step 10079/16670 completed (loss: 0.31115689873695374, acc: 0.936170220375061)
[2024-11-14 09:48:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:34][root][INFO] - Training Epoch: 2/2, step 10080/16670 completed (loss: 0.266648530960083, acc: 0.9444444179534912)
[2024-11-14 09:48:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:34][root][INFO] - Training Epoch: 2/2, step 10081/16670 completed (loss: 0.47508716583251953, acc: 0.8235294222831726)
[2024-11-14 09:48:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:34][root][INFO] - Training Epoch: 2/2, step 10082/16670 completed (loss: 0.789989173412323, acc: 0.7887324094772339)
[2024-11-14 09:48:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:35][root][INFO] - Training Epoch: 2/2, step 10083/16670 completed (loss: 0.2539820671081543, acc: 0.9433962106704712)
[2024-11-14 09:48:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:35][root][INFO] - Training Epoch: 2/2, step 10084/16670 completed (loss: 0.7783090472221375, acc: 0.8799999952316284)
[2024-11-14 09:48:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:36][root][INFO] - Training Epoch: 2/2, step 10085/16670 completed (loss: 1.1636245250701904, acc: 0.7441860437393188)
[2024-11-14 09:48:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:36][root][INFO] - Training Epoch: 2/2, step 10086/16670 completed (loss: 0.3027271032333374, acc: 0.9032257795333862)
[2024-11-14 09:48:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:36][root][INFO] - Training Epoch: 2/2, step 10087/16670 completed (loss: 0.4439781606197357, acc: 0.8536585569381714)
[2024-11-14 09:48:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:37][root][INFO] - Training Epoch: 2/2, step 10088/16670 completed (loss: 0.22581252455711365, acc: 0.9333333373069763)
[2024-11-14 09:48:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:37][root][INFO] - Training Epoch: 2/2, step 10089/16670 completed (loss: 0.6531547904014587, acc: 0.8367347121238708)
[2024-11-14 09:48:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:37][root][INFO] - Training Epoch: 2/2, step 10090/16670 completed (loss: 0.8157852292060852, acc: 0.8478260636329651)
[2024-11-14 09:48:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:38][root][INFO] - Training Epoch: 2/2, step 10091/16670 completed (loss: 0.33187511563301086, acc: 0.9189189076423645)
[2024-11-14 09:48:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:38][root][INFO] - Training Epoch: 2/2, step 10092/16670 completed (loss: 0.6125725507736206, acc: 0.8936170339584351)
[2024-11-14 09:48:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:38][root][INFO] - Training Epoch: 2/2, step 10093/16670 completed (loss: 0.2826102674007416, acc: 0.90625)
[2024-11-14 09:48:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:39][root][INFO] - Training Epoch: 2/2, step 10094/16670 completed (loss: 0.4152967929840088, acc: 0.8524590134620667)
[2024-11-14 09:48:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:39][root][INFO] - Training Epoch: 2/2, step 10095/16670 completed (loss: 0.40664663910865784, acc: 0.8947368264198303)
[2024-11-14 09:48:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:39][root][INFO] - Training Epoch: 2/2, step 10096/16670 completed (loss: 0.1737794727087021, acc: 0.9534883499145508)
[2024-11-14 09:48:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:39][root][INFO] - Training Epoch: 2/2, step 10097/16670 completed (loss: 0.4376576542854309, acc: 0.8857142925262451)
[2024-11-14 09:48:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:40][root][INFO] - Training Epoch: 2/2, step 10098/16670 completed (loss: 0.35028785467147827, acc: 0.9027777910232544)
[2024-11-14 09:48:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:40][root][INFO] - Training Epoch: 2/2, step 10099/16670 completed (loss: 0.5233882069587708, acc: 0.8727272748947144)
[2024-11-14 09:48:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:40][root][INFO] - Training Epoch: 2/2, step 10100/16670 completed (loss: 0.2829801142215729, acc: 0.9375)
[2024-11-14 09:48:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:41][root][INFO] - Training Epoch: 2/2, step 10101/16670 completed (loss: 0.16201238334178925, acc: 0.9736841917037964)
[2024-11-14 09:48:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:41][root][INFO] - Training Epoch: 2/2, step 10102/16670 completed (loss: 1.1494898796081543, acc: 0.7916666865348816)
[2024-11-14 09:48:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:41][root][INFO] - Training Epoch: 2/2, step 10103/16670 completed (loss: 0.5612044930458069, acc: 0.8103448152542114)
[2024-11-14 09:48:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:42][root][INFO] - Training Epoch: 2/2, step 10104/16670 completed (loss: 0.4068661034107208, acc: 0.8999999761581421)
[2024-11-14 09:48:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:42][root][INFO] - Training Epoch: 2/2, step 10105/16670 completed (loss: 0.4128836691379547, acc: 0.8611111044883728)
[2024-11-14 09:48:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:43][root][INFO] - Training Epoch: 2/2, step 10106/16670 completed (loss: 0.36765575408935547, acc: 0.8928571343421936)
[2024-11-14 09:48:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:43][root][INFO] - Training Epoch: 2/2, step 10107/16670 completed (loss: 0.9537254571914673, acc: 0.75)
[2024-11-14 09:48:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:43][root][INFO] - Training Epoch: 2/2, step 10108/16670 completed (loss: 0.7735100984573364, acc: 0.7941176295280457)
[2024-11-14 09:48:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:44][root][INFO] - Training Epoch: 2/2, step 10109/16670 completed (loss: 0.3677060902118683, acc: 0.9047619104385376)
[2024-11-14 09:48:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:44][root][INFO] - Training Epoch: 2/2, step 10110/16670 completed (loss: 0.20441992580890656, acc: 0.9428571462631226)
[2024-11-14 09:48:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:44][root][INFO] - Training Epoch: 2/2, step 10111/16670 completed (loss: 0.5191777348518372, acc: 0.8695651888847351)
[2024-11-14 09:48:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:45][root][INFO] - Training Epoch: 2/2, step 10112/16670 completed (loss: 0.13438907265663147, acc: 0.9615384340286255)
[2024-11-14 09:48:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:45][root][INFO] - Training Epoch: 2/2, step 10113/16670 completed (loss: 0.7801187634468079, acc: 0.875)
[2024-11-14 09:48:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:45][root][INFO] - Training Epoch: 2/2, step 10114/16670 completed (loss: 0.44731131196022034, acc: 0.9523809552192688)
[2024-11-14 09:48:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:46][root][INFO] - Training Epoch: 2/2, step 10115/16670 completed (loss: 0.5874709486961365, acc: 0.8444444537162781)
[2024-11-14 09:48:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:46][root][INFO] - Training Epoch: 2/2, step 10116/16670 completed (loss: 0.27019214630126953, acc: 0.9295774698257446)
[2024-11-14 09:48:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:46][root][INFO] - Training Epoch: 2/2, step 10117/16670 completed (loss: 0.5603915452957153, acc: 0.8169013857841492)
[2024-11-14 09:48:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:47][root][INFO] - Training Epoch: 2/2, step 10118/16670 completed (loss: 0.5184696316719055, acc: 0.8571428656578064)
[2024-11-14 09:48:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:47][root][INFO] - Training Epoch: 2/2, step 10119/16670 completed (loss: 0.403182715177536, acc: 0.8823529481887817)
[2024-11-14 09:48:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:47][root][INFO] - Training Epoch: 2/2, step 10120/16670 completed (loss: 0.3974126875400543, acc: 0.9200000166893005)
[2024-11-14 09:48:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:48][root][INFO] - Training Epoch: 2/2, step 10121/16670 completed (loss: 0.21310889720916748, acc: 0.9677419066429138)
[2024-11-14 09:48:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:48][root][INFO] - Training Epoch: 2/2, step 10122/16670 completed (loss: 0.15397481620311737, acc: 0.9642857313156128)
[2024-11-14 09:48:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:49][root][INFO] - Training Epoch: 2/2, step 10123/16670 completed (loss: 0.22593116760253906, acc: 0.9411764740943909)
[2024-11-14 09:48:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:49][root][INFO] - Training Epoch: 2/2, step 10124/16670 completed (loss: 0.4879550337791443, acc: 0.9038461446762085)
[2024-11-14 09:48:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:49][root][INFO] - Training Epoch: 2/2, step 10125/16670 completed (loss: 0.724601686000824, acc: 0.868852436542511)
[2024-11-14 09:48:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:50][root][INFO] - Training Epoch: 2/2, step 10126/16670 completed (loss: 0.056668877601623535, acc: 0.9696969985961914)
[2024-11-14 09:48:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:50][root][INFO] - Training Epoch: 2/2, step 10127/16670 completed (loss: 0.8361369967460632, acc: 0.8372092843055725)
[2024-11-14 09:48:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:50][root][INFO] - Training Epoch: 2/2, step 10128/16670 completed (loss: 0.31435123085975647, acc: 0.9491525292396545)
[2024-11-14 09:48:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:51][root][INFO] - Training Epoch: 2/2, step 10129/16670 completed (loss: 0.17045795917510986, acc: 0.9365079402923584)
[2024-11-14 09:48:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:51][root][INFO] - Training Epoch: 2/2, step 10130/16670 completed (loss: 0.30975833535194397, acc: 0.96875)
[2024-11-14 09:48:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:51][root][INFO] - Training Epoch: 2/2, step 10131/16670 completed (loss: 0.6276659965515137, acc: 0.8620689511299133)
[2024-11-14 09:48:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:52][root][INFO] - Training Epoch: 2/2, step 10132/16670 completed (loss: 0.056229911744594574, acc: 1.0)
[2024-11-14 09:48:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:52][root][INFO] - Training Epoch: 2/2, step 10133/16670 completed (loss: 0.8134960532188416, acc: 0.8648648858070374)
[2024-11-14 09:48:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:52][root][INFO] - Training Epoch: 2/2, step 10134/16670 completed (loss: 0.08735136687755585, acc: 0.9482758641242981)
[2024-11-14 09:48:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:53][root][INFO] - Training Epoch: 2/2, step 10135/16670 completed (loss: 0.39452648162841797, acc: 0.9384615421295166)
[2024-11-14 09:48:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:53][root][INFO] - Training Epoch: 2/2, step 10136/16670 completed (loss: 0.9047626852989197, acc: 0.8888888955116272)
[2024-11-14 09:48:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:53][root][INFO] - Training Epoch: 2/2, step 10137/16670 completed (loss: 0.3619074821472168, acc: 0.8939393758773804)
[2024-11-14 09:48:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:54][root][INFO] - Training Epoch: 2/2, step 10138/16670 completed (loss: 0.33275723457336426, acc: 0.9512194991111755)
[2024-11-14 09:48:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:54][root][INFO] - Training Epoch: 2/2, step 10139/16670 completed (loss: 0.1939692348241806, acc: 0.9032257795333862)
[2024-11-14 09:48:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:54][root][INFO] - Training Epoch: 2/2, step 10140/16670 completed (loss: 0.21000425517559052, acc: 0.9166666865348816)
[2024-11-14 09:48:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:55][root][INFO] - Training Epoch: 2/2, step 10141/16670 completed (loss: 0.2788102328777313, acc: 0.9285714030265808)
[2024-11-14 09:48:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:55][root][INFO] - Training Epoch: 2/2, step 10142/16670 completed (loss: 0.33781617879867554, acc: 0.9230769276618958)
[2024-11-14 09:48:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:55][root][INFO] - Training Epoch: 2/2, step 10143/16670 completed (loss: 0.2798016667366028, acc: 0.9387755393981934)
[2024-11-14 09:48:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:56][root][INFO] - Training Epoch: 2/2, step 10144/16670 completed (loss: 0.3232044577598572, acc: 0.9523809552192688)
[2024-11-14 09:48:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:56][root][INFO] - Training Epoch: 2/2, step 10145/16670 completed (loss: 0.8287002444267273, acc: 0.800000011920929)
[2024-11-14 09:48:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:56][root][INFO] - Training Epoch: 2/2, step 10146/16670 completed (loss: 0.1721925437450409, acc: 0.9305555820465088)
[2024-11-14 09:48:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:57][root][INFO] - Training Epoch: 2/2, step 10147/16670 completed (loss: 0.49387413263320923, acc: 0.8611111044883728)
[2024-11-14 09:48:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:57][root][INFO] - Training Epoch: 2/2, step 10148/16670 completed (loss: 0.3726128935813904, acc: 0.875)
[2024-11-14 09:48:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:57][root][INFO] - Training Epoch: 2/2, step 10149/16670 completed (loss: 0.2198127657175064, acc: 0.9444444179534912)
[2024-11-14 09:48:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:58][root][INFO] - Training Epoch: 2/2, step 10150/16670 completed (loss: 0.3993416130542755, acc: 0.8695651888847351)
[2024-11-14 09:48:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:58][root][INFO] - Training Epoch: 2/2, step 10151/16670 completed (loss: 0.7750899791717529, acc: 0.8529411554336548)
[2024-11-14 09:48:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:58][root][INFO] - Training Epoch: 2/2, step 10152/16670 completed (loss: 0.4027564227581024, acc: 0.9322034120559692)
[2024-11-14 09:48:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:59][root][INFO] - Training Epoch: 2/2, step 10153/16670 completed (loss: 0.47480931878089905, acc: 0.925000011920929)
[2024-11-14 09:48:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:59][root][INFO] - Training Epoch: 2/2, step 10154/16670 completed (loss: 0.4313873052597046, acc: 0.8714285492897034)
[2024-11-14 09:48:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:48:59][root][INFO] - Training Epoch: 2/2, step 10155/16670 completed (loss: 0.3610054552555084, acc: 0.9215686321258545)
[2024-11-14 09:48:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:00][root][INFO] - Training Epoch: 2/2, step 10156/16670 completed (loss: 0.40808573365211487, acc: 0.9090909361839294)
[2024-11-14 09:49:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:00][root][INFO] - Training Epoch: 2/2, step 10157/16670 completed (loss: 0.2556198239326477, acc: 0.9090909361839294)
[2024-11-14 09:49:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:00][root][INFO] - Training Epoch: 2/2, step 10158/16670 completed (loss: 0.3171251714229584, acc: 0.8947368264198303)
[2024-11-14 09:49:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:01][root][INFO] - Training Epoch: 2/2, step 10159/16670 completed (loss: 0.265266090631485, acc: 0.8913043737411499)
[2024-11-14 09:49:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:01][root][INFO] - Training Epoch: 2/2, step 10160/16670 completed (loss: 0.5640512704849243, acc: 0.8205128312110901)
[2024-11-14 09:49:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:01][root][INFO] - Training Epoch: 2/2, step 10161/16670 completed (loss: 0.3833308815956116, acc: 0.8918918967247009)
[2024-11-14 09:49:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:02][root][INFO] - Training Epoch: 2/2, step 10162/16670 completed (loss: 0.14623279869556427, acc: 0.9655172228813171)
[2024-11-14 09:49:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:02][root][INFO] - Training Epoch: 2/2, step 10163/16670 completed (loss: 0.170774444937706, acc: 0.9444444179534912)
[2024-11-14 09:49:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:02][root][INFO] - Training Epoch: 2/2, step 10164/16670 completed (loss: 0.08643930405378342, acc: 1.0)
[2024-11-14 09:49:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:02][root][INFO] - Training Epoch: 2/2, step 10165/16670 completed (loss: 0.27835655212402344, acc: 0.90625)
[2024-11-14 09:49:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:03][root][INFO] - Training Epoch: 2/2, step 10166/16670 completed (loss: 0.18166202306747437, acc: 0.9399999976158142)
[2024-11-14 09:49:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:03][root][INFO] - Training Epoch: 2/2, step 10167/16670 completed (loss: 0.2578868567943573, acc: 0.9333333373069763)
[2024-11-14 09:49:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:03][root][INFO] - Training Epoch: 2/2, step 10168/16670 completed (loss: 0.11728720366954803, acc: 0.9622641801834106)
[2024-11-14 09:49:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:04][root][INFO] - Training Epoch: 2/2, step 10169/16670 completed (loss: 0.24429775774478912, acc: 0.9230769276618958)
[2024-11-14 09:49:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:04][root][INFO] - Training Epoch: 2/2, step 10170/16670 completed (loss: 0.5628409385681152, acc: 0.9012345671653748)
[2024-11-14 09:49:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:04][root][INFO] - Training Epoch: 2/2, step 10171/16670 completed (loss: 0.0870591476559639, acc: 0.9692307710647583)
[2024-11-14 09:49:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:05][root][INFO] - Training Epoch: 2/2, step 10172/16670 completed (loss: 0.4807422161102295, acc: 0.8545454740524292)
[2024-11-14 09:49:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:05][root][INFO] - Training Epoch: 2/2, step 10173/16670 completed (loss: 0.691352367401123, acc: 0.9019607901573181)
[2024-11-14 09:49:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:05][root][INFO] - Training Epoch: 2/2, step 10174/16670 completed (loss: 0.19965536892414093, acc: 0.9622641801834106)
[2024-11-14 09:49:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:06][root][INFO] - Training Epoch: 2/2, step 10175/16670 completed (loss: 0.12601207196712494, acc: 0.9655172228813171)
[2024-11-14 09:49:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:06][root][INFO] - Training Epoch: 2/2, step 10176/16670 completed (loss: 0.05460147559642792, acc: 0.9722222089767456)
[2024-11-14 09:49:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:06][root][INFO] - Training Epoch: 2/2, step 10177/16670 completed (loss: 0.19611482322216034, acc: 0.9166666865348816)
[2024-11-14 09:49:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:06][root][INFO] - Training Epoch: 2/2, step 10178/16670 completed (loss: 0.27424702048301697, acc: 0.9487179517745972)
[2024-11-14 09:49:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:07][root][INFO] - Training Epoch: 2/2, step 10179/16670 completed (loss: 0.13427481055259705, acc: 0.95652174949646)
[2024-11-14 09:49:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:07][root][INFO] - Training Epoch: 2/2, step 10180/16670 completed (loss: 0.4002815783023834, acc: 0.9130434989929199)
[2024-11-14 09:49:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:07][root][INFO] - Training Epoch: 2/2, step 10181/16670 completed (loss: 0.23175665736198425, acc: 0.9696969985961914)
[2024-11-14 09:49:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:08][root][INFO] - Training Epoch: 2/2, step 10182/16670 completed (loss: 0.10679769515991211, acc: 0.9411764740943909)
[2024-11-14 09:49:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:08][root][INFO] - Training Epoch: 2/2, step 10183/16670 completed (loss: 0.07713624089956284, acc: 0.9777777791023254)
[2024-11-14 09:49:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:08][root][INFO] - Training Epoch: 2/2, step 10184/16670 completed (loss: 0.24965712428092957, acc: 0.9629629850387573)
[2024-11-14 09:49:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:09][root][INFO] - Training Epoch: 2/2, step 10185/16670 completed (loss: 0.16833710670471191, acc: 0.9622641801834106)
[2024-11-14 09:49:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:09][root][INFO] - Training Epoch: 2/2, step 10186/16670 completed (loss: 0.1659584641456604, acc: 0.9428571462631226)
[2024-11-14 09:49:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:09][root][INFO] - Training Epoch: 2/2, step 10187/16670 completed (loss: 0.5518842339515686, acc: 0.9090909361839294)
[2024-11-14 09:49:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:09][root][INFO] - Training Epoch: 2/2, step 10188/16670 completed (loss: 0.07267460227012634, acc: 0.9772727489471436)
[2024-11-14 09:49:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:10][root][INFO] - Training Epoch: 2/2, step 10189/16670 completed (loss: 0.6744322776794434, acc: 0.9069767594337463)
[2024-11-14 09:49:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:10][root][INFO] - Training Epoch: 2/2, step 10190/16670 completed (loss: 0.5339607000350952, acc: 0.875)
[2024-11-14 09:49:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:10][root][INFO] - Training Epoch: 2/2, step 10191/16670 completed (loss: 0.11659522354602814, acc: 0.95652174949646)
[2024-11-14 09:49:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:11][root][INFO] - Training Epoch: 2/2, step 10192/16670 completed (loss: 0.39312314987182617, acc: 0.930232584476471)
[2024-11-14 09:49:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:11][root][INFO] - Training Epoch: 2/2, step 10193/16670 completed (loss: 0.15540477633476257, acc: 0.9583333134651184)
[2024-11-14 09:49:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:12][root][INFO] - Training Epoch: 2/2, step 10194/16670 completed (loss: 0.06218183785676956, acc: 0.9863013625144958)
[2024-11-14 09:49:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:12][root][INFO] - Training Epoch: 2/2, step 10195/16670 completed (loss: 0.20895017683506012, acc: 0.9756097793579102)
[2024-11-14 09:49:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:12][root][INFO] - Training Epoch: 2/2, step 10196/16670 completed (loss: 0.11490987986326218, acc: 0.9777777791023254)
[2024-11-14 09:49:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:13][root][INFO] - Training Epoch: 2/2, step 10197/16670 completed (loss: 0.16124780476093292, acc: 0.9333333373069763)
[2024-11-14 09:49:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:13][root][INFO] - Training Epoch: 2/2, step 10198/16670 completed (loss: 0.1763094812631607, acc: 0.9444444179534912)
[2024-11-14 09:49:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:13][root][INFO] - Training Epoch: 2/2, step 10199/16670 completed (loss: 0.27413129806518555, acc: 0.9729729890823364)
[2024-11-14 09:49:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:14][root][INFO] - Training Epoch: 2/2, step 10200/16670 completed (loss: 0.41184622049331665, acc: 0.8571428656578064)
[2024-11-14 09:49:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:14][root][INFO] - Training Epoch: 2/2, step 10201/16670 completed (loss: 0.10422290861606598, acc: 0.9347826242446899)
[2024-11-14 09:49:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:14][root][INFO] - Training Epoch: 2/2, step 10202/16670 completed (loss: 0.1774895191192627, acc: 0.9777777791023254)
[2024-11-14 09:49:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:14][root][INFO] - Training Epoch: 2/2, step 10203/16670 completed (loss: 0.23267926275730133, acc: 0.9538461565971375)
[2024-11-14 09:49:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:15][root][INFO] - Training Epoch: 2/2, step 10204/16670 completed (loss: 0.06225366145372391, acc: 0.9850746393203735)
[2024-11-14 09:49:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:15][root][INFO] - Training Epoch: 2/2, step 10205/16670 completed (loss: 0.05161408707499504, acc: 0.9838709831237793)
[2024-11-14 09:49:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:15][root][INFO] - Training Epoch: 2/2, step 10206/16670 completed (loss: 0.3588975667953491, acc: 0.8846153616905212)
[2024-11-14 09:49:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:16][root][INFO] - Training Epoch: 2/2, step 10207/16670 completed (loss: 0.02347075752913952, acc: 1.0)
[2024-11-14 09:49:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:16][root][INFO] - Training Epoch: 2/2, step 10208/16670 completed (loss: 0.21636849641799927, acc: 0.9512194991111755)
[2024-11-14 09:49:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:16][root][INFO] - Training Epoch: 2/2, step 10209/16670 completed (loss: 0.18673400580883026, acc: 0.9594594836235046)
[2024-11-14 09:49:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:17][root][INFO] - Training Epoch: 2/2, step 10210/16670 completed (loss: 0.09451474249362946, acc: 0.9655172228813171)
[2024-11-14 09:49:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:17][root][INFO] - Training Epoch: 2/2, step 10211/16670 completed (loss: 0.09547892957925797, acc: 0.9666666388511658)
[2024-11-14 09:49:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:17][root][INFO] - Training Epoch: 2/2, step 10212/16670 completed (loss: 0.07346948981285095, acc: 0.97826087474823)
[2024-11-14 09:49:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:18][root][INFO] - Training Epoch: 2/2, step 10213/16670 completed (loss: 0.28964927792549133, acc: 0.9512194991111755)
[2024-11-14 09:49:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:18][root][INFO] - Training Epoch: 2/2, step 10214/16670 completed (loss: 0.10219510644674301, acc: 0.9444444179534912)
[2024-11-14 09:49:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:18][root][INFO] - Training Epoch: 2/2, step 10215/16670 completed (loss: 0.016533423215150833, acc: 1.0)
[2024-11-14 09:49:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:18][root][INFO] - Training Epoch: 2/2, step 10216/16670 completed (loss: 0.3120472729206085, acc: 0.8999999761581421)
[2024-11-14 09:49:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:19][root][INFO] - Training Epoch: 2/2, step 10217/16670 completed (loss: 0.672555148601532, acc: 0.8478260636329651)
[2024-11-14 09:49:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:19][root][INFO] - Training Epoch: 2/2, step 10218/16670 completed (loss: 0.4831204414367676, acc: 0.8857142925262451)
[2024-11-14 09:49:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:19][root][INFO] - Training Epoch: 2/2, step 10219/16670 completed (loss: 0.35764360427856445, acc: 0.9365079402923584)
[2024-11-14 09:49:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:20][root][INFO] - Training Epoch: 2/2, step 10220/16670 completed (loss: 0.31160661578178406, acc: 0.9200000166893005)
[2024-11-14 09:49:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:20][root][INFO] - Training Epoch: 2/2, step 10221/16670 completed (loss: 0.07007373869419098, acc: 0.9682539701461792)
[2024-11-14 09:49:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:20][root][INFO] - Training Epoch: 2/2, step 10222/16670 completed (loss: 0.05285779759287834, acc: 0.9861111044883728)
[2024-11-14 09:49:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:21][root][INFO] - Training Epoch: 2/2, step 10223/16670 completed (loss: 0.19241423904895782, acc: 0.9322034120559692)
[2024-11-14 09:49:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:21][root][INFO] - Training Epoch: 2/2, step 10224/16670 completed (loss: 0.2619990110397339, acc: 0.9523809552192688)
[2024-11-14 09:49:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:21][root][INFO] - Training Epoch: 2/2, step 10225/16670 completed (loss: 0.2131740003824234, acc: 0.9318181872367859)
[2024-11-14 09:49:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:22][root][INFO] - Training Epoch: 2/2, step 10226/16670 completed (loss: 0.5043745040893555, acc: 0.9122806787490845)
[2024-11-14 09:49:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:22][root][INFO] - Training Epoch: 2/2, step 10227/16670 completed (loss: 0.2635262906551361, acc: 0.9491525292396545)
[2024-11-14 09:49:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:23][root][INFO] - Training Epoch: 2/2, step 10228/16670 completed (loss: 0.18534570932388306, acc: 0.9756097793579102)
[2024-11-14 09:49:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:23][root][INFO] - Training Epoch: 2/2, step 10229/16670 completed (loss: 0.4174783527851105, acc: 0.9230769276618958)
[2024-11-14 09:49:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:23][root][INFO] - Training Epoch: 2/2, step 10230/16670 completed (loss: 0.49104568362236023, acc: 0.892307698726654)
[2024-11-14 09:49:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:24][root][INFO] - Training Epoch: 2/2, step 10231/16670 completed (loss: 0.34258323907852173, acc: 0.949999988079071)
[2024-11-14 09:49:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:24][root][INFO] - Training Epoch: 2/2, step 10232/16670 completed (loss: 0.394440621137619, acc: 0.9295774698257446)
[2024-11-14 09:49:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:24][root][INFO] - Training Epoch: 2/2, step 10233/16670 completed (loss: 0.05960217863321304, acc: 1.0)
[2024-11-14 09:49:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:25][root][INFO] - Training Epoch: 2/2, step 10234/16670 completed (loss: 0.021839888766407967, acc: 1.0)
[2024-11-14 09:49:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:25][root][INFO] - Training Epoch: 2/2, step 10235/16670 completed (loss: 0.07316960394382477, acc: 0.9736841917037964)
[2024-11-14 09:49:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:25][root][INFO] - Training Epoch: 2/2, step 10236/16670 completed (loss: 0.603477418422699, acc: 0.875)
[2024-11-14 09:49:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:26][root][INFO] - Training Epoch: 2/2, step 10237/16670 completed (loss: 0.4165290892124176, acc: 0.8684210777282715)
[2024-11-14 09:49:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:26][root][INFO] - Training Epoch: 2/2, step 10238/16670 completed (loss: 0.10329867899417877, acc: 0.9743589758872986)
[2024-11-14 09:49:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:26][root][INFO] - Training Epoch: 2/2, step 10239/16670 completed (loss: 0.04769795387983322, acc: 1.0)
[2024-11-14 09:49:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:27][root][INFO] - Training Epoch: 2/2, step 10240/16670 completed (loss: 0.34730982780456543, acc: 0.9242424368858337)
[2024-11-14 09:49:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:27][root][INFO] - Training Epoch: 2/2, step 10241/16670 completed (loss: 0.07248374074697495, acc: 0.9841269850730896)
[2024-11-14 09:49:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:28][root][INFO] - Training Epoch: 2/2, step 10242/16670 completed (loss: 0.13799986243247986, acc: 0.9622641801834106)
[2024-11-14 09:49:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:28][root][INFO] - Training Epoch: 2/2, step 10243/16670 completed (loss: 0.06062716245651245, acc: 1.0)
[2024-11-14 09:49:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:28][root][INFO] - Training Epoch: 2/2, step 10244/16670 completed (loss: 0.11212990432977676, acc: 0.9821428656578064)
[2024-11-14 09:49:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:29][root][INFO] - Training Epoch: 2/2, step 10245/16670 completed (loss: 0.10294055938720703, acc: 0.9795918464660645)
[2024-11-14 09:49:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:29][root][INFO] - Training Epoch: 2/2, step 10246/16670 completed (loss: 0.08629745244979858, acc: 0.9622641801834106)
[2024-11-14 09:49:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:29][root][INFO] - Training Epoch: 2/2, step 10247/16670 completed (loss: 0.3849644362926483, acc: 0.970588207244873)
[2024-11-14 09:49:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:30][root][INFO] - Training Epoch: 2/2, step 10248/16670 completed (loss: 0.04088188335299492, acc: 0.982758641242981)
[2024-11-14 09:49:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:30][root][INFO] - Training Epoch: 2/2, step 10249/16670 completed (loss: 0.14371870458126068, acc: 0.9629629850387573)
[2024-11-14 09:49:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:30][root][INFO] - Training Epoch: 2/2, step 10250/16670 completed (loss: 0.19609299302101135, acc: 0.97826087474823)
[2024-11-14 09:49:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:31][root][INFO] - Training Epoch: 2/2, step 10251/16670 completed (loss: 0.26711374521255493, acc: 0.9444444179534912)
[2024-11-14 09:49:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:31][root][INFO] - Training Epoch: 2/2, step 10252/16670 completed (loss: 0.22316612303256989, acc: 0.9577465057373047)
[2024-11-14 09:49:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:31][root][INFO] - Training Epoch: 2/2, step 10253/16670 completed (loss: 0.12027992308139801, acc: 0.9666666388511658)
[2024-11-14 09:49:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:32][root][INFO] - Training Epoch: 2/2, step 10254/16670 completed (loss: 0.19407615065574646, acc: 0.949999988079071)
[2024-11-14 09:49:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:32][root][INFO] - Training Epoch: 2/2, step 10255/16670 completed (loss: 0.3905111849308014, acc: 0.8974359035491943)
[2024-11-14 09:49:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:32][root][INFO] - Training Epoch: 2/2, step 10256/16670 completed (loss: 0.11158040165901184, acc: 0.9577465057373047)
[2024-11-14 09:49:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:33][root][INFO] - Training Epoch: 2/2, step 10257/16670 completed (loss: 0.09660647809505463, acc: 0.9534883499145508)
[2024-11-14 09:49:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:33][root][INFO] - Training Epoch: 2/2, step 10258/16670 completed (loss: 0.4330997169017792, acc: 0.875)
[2024-11-14 09:49:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:33][root][INFO] - Training Epoch: 2/2, step 10259/16670 completed (loss: 1.5269032716751099, acc: 0.6666666865348816)
[2024-11-14 09:49:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:34][root][INFO] - Training Epoch: 2/2, step 10260/16670 completed (loss: 0.5236403942108154, acc: 0.8636363744735718)
[2024-11-14 09:49:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:34][root][INFO] - Training Epoch: 2/2, step 10261/16670 completed (loss: 0.15317164361476898, acc: 0.9718309640884399)
[2024-11-14 09:49:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:34][root][INFO] - Training Epoch: 2/2, step 10262/16670 completed (loss: 0.21152059733867645, acc: 0.970588207244873)
[2024-11-14 09:49:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:35][root][INFO] - Training Epoch: 2/2, step 10263/16670 completed (loss: 0.34157246351242065, acc: 0.9285714030265808)
[2024-11-14 09:49:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:35][root][INFO] - Training Epoch: 2/2, step 10264/16670 completed (loss: 0.360372394323349, acc: 0.9473684430122375)
[2024-11-14 09:49:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:36][root][INFO] - Training Epoch: 2/2, step 10265/16670 completed (loss: 0.13151372969150543, acc: 0.9661017060279846)
[2024-11-14 09:49:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:36][root][INFO] - Training Epoch: 2/2, step 10266/16670 completed (loss: 0.07747919857501984, acc: 1.0)
[2024-11-14 09:49:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:36][root][INFO] - Training Epoch: 2/2, step 10267/16670 completed (loss: 0.18227481842041016, acc: 0.9821428656578064)
[2024-11-14 09:49:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:37][root][INFO] - Training Epoch: 2/2, step 10268/16670 completed (loss: 0.44425928592681885, acc: 0.9047619104385376)
[2024-11-14 09:49:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:37][root][INFO] - Training Epoch: 2/2, step 10269/16670 completed (loss: 0.14860424399375916, acc: 0.936170220375061)
[2024-11-14 09:49:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:37][root][INFO] - Training Epoch: 2/2, step 10270/16670 completed (loss: 0.40282806754112244, acc: 0.9642857313156128)
[2024-11-14 09:49:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:38][root][INFO] - Training Epoch: 2/2, step 10271/16670 completed (loss: 0.11172369867563248, acc: 0.976190447807312)
[2024-11-14 09:49:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:38][root][INFO] - Training Epoch: 2/2, step 10272/16670 completed (loss: 0.26796117424964905, acc: 0.9111111164093018)
[2024-11-14 09:49:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:38][root][INFO] - Training Epoch: 2/2, step 10273/16670 completed (loss: 0.23216122388839722, acc: 0.9200000166893005)
[2024-11-14 09:49:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:39][root][INFO] - Training Epoch: 2/2, step 10274/16670 completed (loss: 0.28431716561317444, acc: 0.9285714030265808)
[2024-11-14 09:49:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:39][root][INFO] - Training Epoch: 2/2, step 10275/16670 completed (loss: 0.3297957479953766, acc: 0.9285714030265808)
[2024-11-14 09:49:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:39][root][INFO] - Training Epoch: 2/2, step 10276/16670 completed (loss: 0.3260502219200134, acc: 0.9166666865348816)
[2024-11-14 09:49:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:39][root][INFO] - Training Epoch: 2/2, step 10277/16670 completed (loss: 0.329463392496109, acc: 0.9275362491607666)
[2024-11-14 09:49:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:40][root][INFO] - Training Epoch: 2/2, step 10278/16670 completed (loss: 0.09824290871620178, acc: 0.9736841917037964)
[2024-11-14 09:49:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:40][root][INFO] - Training Epoch: 2/2, step 10279/16670 completed (loss: 0.21722078323364258, acc: 0.9397590160369873)
[2024-11-14 09:49:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:40][root][INFO] - Training Epoch: 2/2, step 10280/16670 completed (loss: 0.11430443823337555, acc: 0.9512194991111755)
[2024-11-14 09:49:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:41][root][INFO] - Training Epoch: 2/2, step 10281/16670 completed (loss: 0.1976165622472763, acc: 0.9750000238418579)
[2024-11-14 09:49:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:41][root][INFO] - Training Epoch: 2/2, step 10282/16670 completed (loss: 0.2713385820388794, acc: 0.9807692170143127)
[2024-11-14 09:49:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:42][root][INFO] - Training Epoch: 2/2, step 10283/16670 completed (loss: 0.47110655903816223, acc: 0.8488371968269348)
[2024-11-14 09:49:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:42][root][INFO] - Training Epoch: 2/2, step 10284/16670 completed (loss: 0.20092228055000305, acc: 0.925000011920929)
[2024-11-14 09:49:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:42][root][INFO] - Training Epoch: 2/2, step 10285/16670 completed (loss: 0.0891977995634079, acc: 0.9726027250289917)
[2024-11-14 09:49:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:43][root][INFO] - Training Epoch: 2/2, step 10286/16670 completed (loss: 0.11288349330425262, acc: 0.9807692170143127)
[2024-11-14 09:49:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:43][root][INFO] - Training Epoch: 2/2, step 10287/16670 completed (loss: 0.06573550403118134, acc: 0.9677419066429138)
[2024-11-14 09:49:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:43][root][INFO] - Training Epoch: 2/2, step 10288/16670 completed (loss: 0.3556293249130249, acc: 0.9418604373931885)
[2024-11-14 09:49:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:44][root][INFO] - Training Epoch: 2/2, step 10289/16670 completed (loss: 0.07517646253108978, acc: 0.9807692170143127)
[2024-11-14 09:49:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:44][root][INFO] - Training Epoch: 2/2, step 10290/16670 completed (loss: 0.29840022325515747, acc: 0.9354838728904724)
[2024-11-14 09:49:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:44][root][INFO] - Training Epoch: 2/2, step 10291/16670 completed (loss: 0.5456792712211609, acc: 0.8648648858070374)
[2024-11-14 09:49:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:45][root][INFO] - Training Epoch: 2/2, step 10292/16670 completed (loss: 0.027919190004467964, acc: 1.0)
[2024-11-14 09:49:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:45][root][INFO] - Training Epoch: 2/2, step 10293/16670 completed (loss: 0.48456597328186035, acc: 0.9166666865348816)
[2024-11-14 09:49:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:45][root][INFO] - Training Epoch: 2/2, step 10294/16670 completed (loss: 0.07347851991653442, acc: 0.9866666793823242)
[2024-11-14 09:49:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:46][root][INFO] - Training Epoch: 2/2, step 10295/16670 completed (loss: 0.43844422698020935, acc: 0.9066666960716248)
[2024-11-14 09:49:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:46][root][INFO] - Training Epoch: 2/2, step 10296/16670 completed (loss: 0.5283694863319397, acc: 0.9230769276618958)
[2024-11-14 09:49:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:46][root][INFO] - Training Epoch: 2/2, step 10297/16670 completed (loss: 0.35514432191848755, acc: 0.9122806787490845)
[2024-11-14 09:49:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:47][root][INFO] - Training Epoch: 2/2, step 10298/16670 completed (loss: 0.4245198369026184, acc: 0.8979591727256775)
[2024-11-14 09:49:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:47][root][INFO] - Training Epoch: 2/2, step 10299/16670 completed (loss: 0.09236937761306763, acc: 0.9830508232116699)
[2024-11-14 09:49:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:47][root][INFO] - Training Epoch: 2/2, step 10300/16670 completed (loss: 0.006729651242494583, acc: 1.0)
[2024-11-14 09:49:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:47][root][INFO] - Training Epoch: 2/2, step 10301/16670 completed (loss: 0.12940338253974915, acc: 0.9767441749572754)
[2024-11-14 09:49:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:48][root][INFO] - Training Epoch: 2/2, step 10302/16670 completed (loss: 0.23998676240444183, acc: 0.9545454382896423)
[2024-11-14 09:49:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:48][root][INFO] - Training Epoch: 2/2, step 10303/16670 completed (loss: 0.6341466903686523, acc: 0.8723404407501221)
[2024-11-14 09:49:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:49][root][INFO] - Training Epoch: 2/2, step 10304/16670 completed (loss: 0.051126815378665924, acc: 1.0)
[2024-11-14 09:49:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:49][root][INFO] - Training Epoch: 2/2, step 10305/16670 completed (loss: 0.5479375123977661, acc: 0.9200000166893005)
[2024-11-14 09:49:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:49][root][INFO] - Training Epoch: 2/2, step 10306/16670 completed (loss: 0.13910560309886932, acc: 0.9491525292396545)
[2024-11-14 09:49:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:50][root][INFO] - Training Epoch: 2/2, step 10307/16670 completed (loss: 0.012100824154913425, acc: 1.0)
[2024-11-14 09:49:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:50][root][INFO] - Training Epoch: 2/2, step 10308/16670 completed (loss: 0.16564488410949707, acc: 0.9454545378684998)
[2024-11-14 09:49:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:50][root][INFO] - Training Epoch: 2/2, step 10309/16670 completed (loss: 0.3114437162876129, acc: 0.8999999761581421)
[2024-11-14 09:49:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:51][root][INFO] - Training Epoch: 2/2, step 10310/16670 completed (loss: 0.4504803717136383, acc: 0.9506173133850098)
[2024-11-14 09:49:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:51][root][INFO] - Training Epoch: 2/2, step 10311/16670 completed (loss: 0.4894924759864807, acc: 0.8787878751754761)
[2024-11-14 09:49:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:51][root][INFO] - Training Epoch: 2/2, step 10312/16670 completed (loss: 0.3278598487377167, acc: 0.9166666865348816)
[2024-11-14 09:49:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:52][root][INFO] - Training Epoch: 2/2, step 10313/16670 completed (loss: 0.5447313189506531, acc: 0.859649121761322)
[2024-11-14 09:49:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:52][root][INFO] - Training Epoch: 2/2, step 10314/16670 completed (loss: 0.22595803439617157, acc: 0.9655172228813171)
[2024-11-14 09:49:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:52][root][INFO] - Training Epoch: 2/2, step 10315/16670 completed (loss: 0.07862184941768646, acc: 0.9870129823684692)
[2024-11-14 09:49:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:53][root][INFO] - Training Epoch: 2/2, step 10316/16670 completed (loss: 0.40656962990760803, acc: 0.84375)
[2024-11-14 09:49:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:53][root][INFO] - Training Epoch: 2/2, step 10317/16670 completed (loss: 0.13831162452697754, acc: 0.9189189076423645)
[2024-11-14 09:49:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:53][root][INFO] - Training Epoch: 2/2, step 10318/16670 completed (loss: 0.11843814700841904, acc: 0.9354838728904724)
[2024-11-14 09:49:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:54][root][INFO] - Training Epoch: 2/2, step 10319/16670 completed (loss: 1.631208062171936, acc: 0.760869562625885)
[2024-11-14 09:49:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:54][root][INFO] - Training Epoch: 2/2, step 10320/16670 completed (loss: 0.08375409245491028, acc: 0.96875)
[2024-11-14 09:49:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:54][root][INFO] - Training Epoch: 2/2, step 10321/16670 completed (loss: 0.06691189110279083, acc: 1.0)
[2024-11-14 09:49:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:55][root][INFO] - Training Epoch: 2/2, step 10322/16670 completed (loss: 0.18668107688426971, acc: 0.9259259104728699)
[2024-11-14 09:49:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:55][root][INFO] - Training Epoch: 2/2, step 10323/16670 completed (loss: 0.41675591468811035, acc: 0.8714285492897034)
[2024-11-14 09:49:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:55][root][INFO] - Training Epoch: 2/2, step 10324/16670 completed (loss: 0.10463865846395493, acc: 0.9729729890823364)
[2024-11-14 09:49:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:56][root][INFO] - Training Epoch: 2/2, step 10325/16670 completed (loss: 0.19587203860282898, acc: 0.9692307710647583)
[2024-11-14 09:49:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:56][root][INFO] - Training Epoch: 2/2, step 10326/16670 completed (loss: 0.2924809157848358, acc: 0.9230769276618958)
[2024-11-14 09:49:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:56][root][INFO] - Training Epoch: 2/2, step 10327/16670 completed (loss: 0.29273721575737, acc: 0.9166666865348816)
[2024-11-14 09:49:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:57][root][INFO] - Training Epoch: 2/2, step 10328/16670 completed (loss: 0.47887328267097473, acc: 0.9230769276618958)
[2024-11-14 09:49:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:57][root][INFO] - Training Epoch: 2/2, step 10329/16670 completed (loss: 0.07882460951805115, acc: 0.9756097793579102)
[2024-11-14 09:49:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:57][root][INFO] - Training Epoch: 2/2, step 10330/16670 completed (loss: 0.13607744872570038, acc: 0.9577465057373047)
[2024-11-14 09:49:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:58][root][INFO] - Training Epoch: 2/2, step 10331/16670 completed (loss: 0.06631015241146088, acc: 1.0)
[2024-11-14 09:49:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:58][root][INFO] - Training Epoch: 2/2, step 10332/16670 completed (loss: 0.4167785942554474, acc: 0.930232584476471)
[2024-11-14 09:49:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:58][root][INFO] - Training Epoch: 2/2, step 10333/16670 completed (loss: 0.14407414197921753, acc: 0.9677419066429138)
[2024-11-14 09:49:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:59][root][INFO] - Training Epoch: 2/2, step 10334/16670 completed (loss: 0.28118106722831726, acc: 0.9350649118423462)
[2024-11-14 09:49:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:59][root][INFO] - Training Epoch: 2/2, step 10335/16670 completed (loss: 0.26721200346946716, acc: 0.9354838728904724)
[2024-11-14 09:49:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:49:59][root][INFO] - Training Epoch: 2/2, step 10336/16670 completed (loss: 0.2673567235469818, acc: 0.9454545378684998)
[2024-11-14 09:49:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:00][root][INFO] - Training Epoch: 2/2, step 10337/16670 completed (loss: 0.0816878154873848, acc: 1.0)
[2024-11-14 09:50:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:00][root][INFO] - Training Epoch: 2/2, step 10338/16670 completed (loss: 0.02976095676422119, acc: 1.0)
[2024-11-14 09:50:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:00][root][INFO] - Training Epoch: 2/2, step 10339/16670 completed (loss: 0.9426767826080322, acc: 0.8478260636329651)
[2024-11-14 09:50:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:01][root][INFO] - Training Epoch: 2/2, step 10340/16670 completed (loss: 0.08379920572042465, acc: 0.9830508232116699)
[2024-11-14 09:50:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:01][root][INFO] - Training Epoch: 2/2, step 10341/16670 completed (loss: 0.09011629223823547, acc: 0.9615384340286255)
[2024-11-14 09:50:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:01][root][INFO] - Training Epoch: 2/2, step 10342/16670 completed (loss: 0.3359629213809967, acc: 0.8840579986572266)
[2024-11-14 09:50:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:02][root][INFO] - Training Epoch: 2/2, step 10343/16670 completed (loss: 0.20349597930908203, acc: 0.9333333373069763)
[2024-11-14 09:50:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:02][root][INFO] - Training Epoch: 2/2, step 10344/16670 completed (loss: 0.12058024853467941, acc: 0.9677419066429138)
[2024-11-14 09:50:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:02][root][INFO] - Training Epoch: 2/2, step 10345/16670 completed (loss: 0.0695749893784523, acc: 1.0)
[2024-11-14 09:50:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:03][root][INFO] - Training Epoch: 2/2, step 10346/16670 completed (loss: 0.1653260886669159, acc: 0.9354838728904724)
[2024-11-14 09:50:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:03][root][INFO] - Training Epoch: 2/2, step 10347/16670 completed (loss: 0.1800965815782547, acc: 0.9659090638160706)
[2024-11-14 09:50:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:03][root][INFO] - Training Epoch: 2/2, step 10348/16670 completed (loss: 0.41474419832229614, acc: 0.9090909361839294)
[2024-11-14 09:50:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:04][root][INFO] - Training Epoch: 2/2, step 10349/16670 completed (loss: 0.10058584064245224, acc: 0.9629629850387573)
[2024-11-14 09:50:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:04][root][INFO] - Training Epoch: 2/2, step 10350/16670 completed (loss: 0.10331403464078903, acc: 0.9583333134651184)
[2024-11-14 09:50:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:05][root][INFO] - Training Epoch: 2/2, step 10351/16670 completed (loss: 0.10879985243082047, acc: 0.9696969985961914)
[2024-11-14 09:50:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:05][root][INFO] - Training Epoch: 2/2, step 10352/16670 completed (loss: 0.3378613293170929, acc: 0.921875)
[2024-11-14 09:50:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:05][root][INFO] - Training Epoch: 2/2, step 10353/16670 completed (loss: 0.08880540728569031, acc: 0.97826087474823)
[2024-11-14 09:50:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:06][root][INFO] - Training Epoch: 2/2, step 10354/16670 completed (loss: 0.4934520125389099, acc: 0.9074074029922485)
[2024-11-14 09:50:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:06][root][INFO] - Training Epoch: 2/2, step 10355/16670 completed (loss: 0.11426876485347748, acc: 0.9583333134651184)
[2024-11-14 09:50:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:06][root][INFO] - Training Epoch: 2/2, step 10356/16670 completed (loss: 0.43699967861175537, acc: 0.8510638475418091)
[2024-11-14 09:50:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:07][root][INFO] - Training Epoch: 2/2, step 10357/16670 completed (loss: 0.43937721848487854, acc: 0.9117646813392639)
[2024-11-14 09:50:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:07][root][INFO] - Training Epoch: 2/2, step 10358/16670 completed (loss: 0.07994101941585541, acc: 1.0)
[2024-11-14 09:50:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:07][root][INFO] - Training Epoch: 2/2, step 10359/16670 completed (loss: 0.07107247412204742, acc: 0.9642857313156128)
[2024-11-14 09:50:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:08][root][INFO] - Training Epoch: 2/2, step 10360/16670 completed (loss: 0.3026124835014343, acc: 0.9411764740943909)
[2024-11-14 09:50:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:08][root][INFO] - Training Epoch: 2/2, step 10361/16670 completed (loss: 0.4149470925331116, acc: 0.9344262480735779)
[2024-11-14 09:50:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:08][root][INFO] - Training Epoch: 2/2, step 10362/16670 completed (loss: 0.13536813855171204, acc: 0.9729729890823364)
[2024-11-14 09:50:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:09][root][INFO] - Training Epoch: 2/2, step 10363/16670 completed (loss: 0.6088424921035767, acc: 0.8909090757369995)
[2024-11-14 09:50:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:09][root][INFO] - Training Epoch: 2/2, step 10364/16670 completed (loss: 0.5055276155471802, acc: 0.7692307829856873)
[2024-11-14 09:50:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:09][root][INFO] - Training Epoch: 2/2, step 10365/16670 completed (loss: 0.2284846305847168, acc: 0.9642857313156128)
[2024-11-14 09:50:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:10][root][INFO] - Training Epoch: 2/2, step 10366/16670 completed (loss: 0.27294328808784485, acc: 0.9318181872367859)
[2024-11-14 09:50:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:10][root][INFO] - Training Epoch: 2/2, step 10367/16670 completed (loss: 0.08861999213695526, acc: 0.9807692170143127)
[2024-11-14 09:50:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:11][root][INFO] - Training Epoch: 2/2, step 10368/16670 completed (loss: 0.2588667869567871, acc: 0.9333333373069763)
[2024-11-14 09:50:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:11][root][INFO] - Training Epoch: 2/2, step 10369/16670 completed (loss: 0.1598847508430481, acc: 0.9803921580314636)
[2024-11-14 09:50:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:11][root][INFO] - Training Epoch: 2/2, step 10370/16670 completed (loss: 0.030357960611581802, acc: 1.0)
[2024-11-14 09:50:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:12][root][INFO] - Training Epoch: 2/2, step 10371/16670 completed (loss: 0.47338175773620605, acc: 0.9387755393981934)
[2024-11-14 09:50:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:12][root][INFO] - Training Epoch: 2/2, step 10372/16670 completed (loss: 0.25392946600914, acc: 0.9482758641242981)
[2024-11-14 09:50:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:12][root][INFO] - Training Epoch: 2/2, step 10373/16670 completed (loss: 0.3625822067260742, acc: 0.9230769276618958)
[2024-11-14 09:50:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:13][root][INFO] - Training Epoch: 2/2, step 10374/16670 completed (loss: 0.2479737401008606, acc: 0.9512194991111755)
[2024-11-14 09:50:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:13][root][INFO] - Training Epoch: 2/2, step 10375/16670 completed (loss: 0.33187609910964966, acc: 0.9056603908538818)
[2024-11-14 09:50:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:13][root][INFO] - Training Epoch: 2/2, step 10376/16670 completed (loss: 0.653619110584259, acc: 0.942307710647583)
[2024-11-14 09:50:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:14][root][INFO] - Training Epoch: 2/2, step 10377/16670 completed (loss: 0.20012786984443665, acc: 0.9387755393981934)
[2024-11-14 09:50:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:14][root][INFO] - Training Epoch: 2/2, step 10378/16670 completed (loss: 0.1776839792728424, acc: 0.9491525292396545)
[2024-11-14 09:50:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:14][root][INFO] - Training Epoch: 2/2, step 10379/16670 completed (loss: 0.15281005203723907, acc: 0.9672130942344666)
[2024-11-14 09:50:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:15][root][INFO] - Training Epoch: 2/2, step 10380/16670 completed (loss: 0.219984233379364, acc: 0.9599999785423279)
[2024-11-14 09:50:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:15][root][INFO] - Training Epoch: 2/2, step 10381/16670 completed (loss: 0.14438514411449432, acc: 0.9677419066429138)
[2024-11-14 09:50:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:15][root][INFO] - Training Epoch: 2/2, step 10382/16670 completed (loss: 0.33224669098854065, acc: 0.9268292784690857)
[2024-11-14 09:50:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:16][root][INFO] - Training Epoch: 2/2, step 10383/16670 completed (loss: 0.2213003933429718, acc: 0.9433962106704712)
[2024-11-14 09:50:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:16][root][INFO] - Training Epoch: 2/2, step 10384/16670 completed (loss: 0.0383366160094738, acc: 1.0)
[2024-11-14 09:50:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:16][root][INFO] - Training Epoch: 2/2, step 10385/16670 completed (loss: 0.25880447030067444, acc: 0.9152542352676392)
[2024-11-14 09:50:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:17][root][INFO] - Training Epoch: 2/2, step 10386/16670 completed (loss: 0.12458471208810806, acc: 0.9722222089767456)
[2024-11-14 09:50:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:17][root][INFO] - Training Epoch: 2/2, step 10387/16670 completed (loss: 0.23420454561710358, acc: 0.9677419066429138)
[2024-11-14 09:50:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:17][root][INFO] - Training Epoch: 2/2, step 10388/16670 completed (loss: 0.9181283116340637, acc: 0.875)
[2024-11-14 09:50:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:18][root][INFO] - Training Epoch: 2/2, step 10389/16670 completed (loss: 0.10289492458105087, acc: 0.9756097793579102)
[2024-11-14 09:50:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:18][root][INFO] - Training Epoch: 2/2, step 10390/16670 completed (loss: 0.4691953957080841, acc: 0.914893627166748)
[2024-11-14 09:50:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:18][root][INFO] - Training Epoch: 2/2, step 10391/16670 completed (loss: 0.5488981604576111, acc: 0.9545454382896423)
[2024-11-14 09:50:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:19][root][INFO] - Training Epoch: 2/2, step 10392/16670 completed (loss: 0.433001309633255, acc: 0.9230769276618958)
[2024-11-14 09:50:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:19][root][INFO] - Training Epoch: 2/2, step 10393/16670 completed (loss: 0.1375637948513031, acc: 0.9777777791023254)
[2024-11-14 09:50:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:19][root][INFO] - Training Epoch: 2/2, step 10394/16670 completed (loss: 0.043279845267534256, acc: 1.0)
[2024-11-14 09:50:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:20][root][INFO] - Training Epoch: 2/2, step 10395/16670 completed (loss: 0.18136562407016754, acc: 0.9111111164093018)
[2024-11-14 09:50:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:20][root][INFO] - Training Epoch: 2/2, step 10396/16670 completed (loss: 0.289522260427475, acc: 0.9333333373069763)
[2024-11-14 09:50:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:20][root][INFO] - Training Epoch: 2/2, step 10397/16670 completed (loss: 0.3364585340023041, acc: 0.8999999761581421)
[2024-11-14 09:50:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:21][root][INFO] - Training Epoch: 2/2, step 10398/16670 completed (loss: 0.5375725030899048, acc: 0.8928571343421936)
[2024-11-14 09:50:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:21][root][INFO] - Training Epoch: 2/2, step 10399/16670 completed (loss: 0.333953857421875, acc: 0.9444444179534912)
[2024-11-14 09:50:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:21][root][INFO] - Training Epoch: 2/2, step 10400/16670 completed (loss: 0.40083980560302734, acc: 0.9189189076423645)
[2024-11-14 09:50:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:22][root][INFO] - Training Epoch: 2/2, step 10401/16670 completed (loss: 0.14277790486812592, acc: 0.9655172228813171)
[2024-11-14 09:50:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:22][root][INFO] - Training Epoch: 2/2, step 10402/16670 completed (loss: 0.1651555299758911, acc: 0.936170220375061)
[2024-11-14 09:50:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:22][root][INFO] - Training Epoch: 2/2, step 10403/16670 completed (loss: 0.1154216080904007, acc: 0.9841269850730896)
[2024-11-14 09:50:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:23][root][INFO] - Training Epoch: 2/2, step 10404/16670 completed (loss: 0.3177512288093567, acc: 0.9130434989929199)
[2024-11-14 09:50:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:23][root][INFO] - Training Epoch: 2/2, step 10405/16670 completed (loss: 0.398212194442749, acc: 0.8795180916786194)
[2024-11-14 09:50:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:23][root][INFO] - Training Epoch: 2/2, step 10406/16670 completed (loss: 0.2637925446033478, acc: 0.9677419066429138)
[2024-11-14 09:50:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:23][root][INFO] - Training Epoch: 2/2, step 10407/16670 completed (loss: 0.3954261243343353, acc: 0.8888888955116272)
[2024-11-14 09:50:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:24][root][INFO] - Training Epoch: 2/2, step 10408/16670 completed (loss: 0.17440177500247955, acc: 0.9772727489471436)
[2024-11-14 09:50:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:24][root][INFO] - Training Epoch: 2/2, step 10409/16670 completed (loss: 0.08812124282121658, acc: 0.9767441749572754)
[2024-11-14 09:50:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:24][root][INFO] - Training Epoch: 2/2, step 10410/16670 completed (loss: 0.11803033202886581, acc: 0.9459459185600281)
[2024-11-14 09:50:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:25][root][INFO] - Training Epoch: 2/2, step 10411/16670 completed (loss: 0.06322760134935379, acc: 0.9795918464660645)
[2024-11-14 09:50:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:25][root][INFO] - Training Epoch: 2/2, step 10412/16670 completed (loss: 0.046493612229824066, acc: 1.0)
[2024-11-14 09:50:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:25][root][INFO] - Training Epoch: 2/2, step 10413/16670 completed (loss: 0.22405993938446045, acc: 0.9375)
[2024-11-14 09:50:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:26][root][INFO] - Training Epoch: 2/2, step 10414/16670 completed (loss: 0.3186291754245758, acc: 0.9245283007621765)
[2024-11-14 09:50:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:26][root][INFO] - Training Epoch: 2/2, step 10415/16670 completed (loss: 0.43958747386932373, acc: 0.931034505367279)
[2024-11-14 09:50:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:26][root][INFO] - Training Epoch: 2/2, step 10416/16670 completed (loss: 0.3379426598548889, acc: 0.9452054500579834)
[2024-11-14 09:50:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:27][root][INFO] - Training Epoch: 2/2, step 10417/16670 completed (loss: 0.19232270121574402, acc: 0.9459459185600281)
[2024-11-14 09:50:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:27][root][INFO] - Training Epoch: 2/2, step 10418/16670 completed (loss: 0.21277637779712677, acc: 0.9473684430122375)
[2024-11-14 09:50:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:27][root][INFO] - Training Epoch: 2/2, step 10419/16670 completed (loss: 0.1243244856595993, acc: 0.930232584476471)
[2024-11-14 09:50:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:28][root][INFO] - Training Epoch: 2/2, step 10420/16670 completed (loss: 0.22321704030036926, acc: 0.9729729890823364)
[2024-11-14 09:50:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:28][root][INFO] - Training Epoch: 2/2, step 10421/16670 completed (loss: 0.2926812767982483, acc: 0.9019607901573181)
[2024-11-14 09:50:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:28][root][INFO] - Training Epoch: 2/2, step 10422/16670 completed (loss: 0.23827260732650757, acc: 0.9622641801834106)
[2024-11-14 09:50:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:29][root][INFO] - Training Epoch: 2/2, step 10423/16670 completed (loss: 0.28109899163246155, acc: 0.939393937587738)
[2024-11-14 09:50:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:29][root][INFO] - Training Epoch: 2/2, step 10424/16670 completed (loss: 0.29865461587905884, acc: 0.9487179517745972)
[2024-11-14 09:50:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:29][root][INFO] - Training Epoch: 2/2, step 10425/16670 completed (loss: 0.30130138993263245, acc: 0.9375)
[2024-11-14 09:50:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:30][root][INFO] - Training Epoch: 2/2, step 10426/16670 completed (loss: 0.29220858216285706, acc: 0.9210526347160339)
[2024-11-14 09:50:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:30][root][INFO] - Training Epoch: 2/2, step 10427/16670 completed (loss: 0.05670839548110962, acc: 1.0)
[2024-11-14 09:50:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:30][root][INFO] - Training Epoch: 2/2, step 10428/16670 completed (loss: 0.02045554295182228, acc: 1.0)
[2024-11-14 09:50:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:31][root][INFO] - Training Epoch: 2/2, step 10429/16670 completed (loss: 0.21206630766391754, acc: 0.9444444179534912)
[2024-11-14 09:50:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:31][root][INFO] - Training Epoch: 2/2, step 10430/16670 completed (loss: 0.20137345790863037, acc: 0.9122806787490845)
[2024-11-14 09:50:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:31][root][INFO] - Training Epoch: 2/2, step 10431/16670 completed (loss: 0.3308843970298767, acc: 0.9210526347160339)
[2024-11-14 09:50:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:32][root][INFO] - Training Epoch: 2/2, step 10432/16670 completed (loss: 0.1567220240831375, acc: 0.95652174949646)
[2024-11-14 09:50:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:32][root][INFO] - Training Epoch: 2/2, step 10433/16670 completed (loss: 0.31183114647865295, acc: 0.8717948794364929)
[2024-11-14 09:50:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:32][root][INFO] - Training Epoch: 2/2, step 10434/16670 completed (loss: 0.24075892567634583, acc: 0.9512194991111755)
[2024-11-14 09:50:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:33][root][INFO] - Training Epoch: 2/2, step 10435/16670 completed (loss: 0.3934030830860138, acc: 0.8787878751754761)
[2024-11-14 09:50:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:33][root][INFO] - Training Epoch: 2/2, step 10436/16670 completed (loss: 0.12200138717889786, acc: 0.9642857313156128)
[2024-11-14 09:50:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:33][root][INFO] - Training Epoch: 2/2, step 10437/16670 completed (loss: 0.3812844455242157, acc: 0.9459459185600281)
[2024-11-14 09:50:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:34][root][INFO] - Training Epoch: 2/2, step 10438/16670 completed (loss: 0.2528385519981384, acc: 0.9230769276618958)
[2024-11-14 09:50:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:34][root][INFO] - Training Epoch: 2/2, step 10439/16670 completed (loss: 0.4220406115055084, acc: 0.8867924809455872)
[2024-11-14 09:50:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:35][root][INFO] - Training Epoch: 2/2, step 10440/16670 completed (loss: 0.16537682712078094, acc: 0.9552238583564758)
[2024-11-14 09:50:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:35][root][INFO] - Training Epoch: 2/2, step 10441/16670 completed (loss: 0.2634229362010956, acc: 0.953125)
[2024-11-14 09:50:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:35][root][INFO] - Training Epoch: 2/2, step 10442/16670 completed (loss: 0.13549092411994934, acc: 0.9090909361839294)
[2024-11-14 09:50:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:36][root][INFO] - Training Epoch: 2/2, step 10443/16670 completed (loss: 0.37059977650642395, acc: 0.9130434989929199)
[2024-11-14 09:50:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:36][root][INFO] - Training Epoch: 2/2, step 10444/16670 completed (loss: 0.10363325476646423, acc: 1.0)
[2024-11-14 09:50:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:36][root][INFO] - Training Epoch: 2/2, step 10445/16670 completed (loss: 0.4471740424633026, acc: 0.9090909361839294)
[2024-11-14 09:50:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:37][root][INFO] - Training Epoch: 2/2, step 10446/16670 completed (loss: 0.20147453248500824, acc: 0.9545454382896423)
[2024-11-14 09:50:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:37][root][INFO] - Training Epoch: 2/2, step 10447/16670 completed (loss: 1.1845507621765137, acc: 0.7045454382896423)
[2024-11-14 09:50:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:37][root][INFO] - Training Epoch: 2/2, step 10448/16670 completed (loss: 0.7271479368209839, acc: 0.7931034564971924)
[2024-11-14 09:50:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:38][root][INFO] - Training Epoch: 2/2, step 10449/16670 completed (loss: 0.45611682534217834, acc: 0.892307698726654)
[2024-11-14 09:50:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:38][root][INFO] - Training Epoch: 2/2, step 10450/16670 completed (loss: 0.804665207862854, acc: 0.7368420958518982)
[2024-11-14 09:50:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:39][root][INFO] - Training Epoch: 2/2, step 10451/16670 completed (loss: 0.915308952331543, acc: 0.8846153616905212)
[2024-11-14 09:50:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:39][root][INFO] - Training Epoch: 2/2, step 10452/16670 completed (loss: 0.3630634844303131, acc: 0.949999988079071)
[2024-11-14 09:50:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:39][root][INFO] - Training Epoch: 2/2, step 10453/16670 completed (loss: 0.3592361807823181, acc: 0.8837209343910217)
[2024-11-14 09:50:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:40][root][INFO] - Training Epoch: 2/2, step 10454/16670 completed (loss: 0.6293200254440308, acc: 0.8333333134651184)
[2024-11-14 09:50:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:40][root][INFO] - Training Epoch: 2/2, step 10455/16670 completed (loss: 0.8479354977607727, acc: 0.800000011920929)
[2024-11-14 09:50:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:40][root][INFO] - Training Epoch: 2/2, step 10456/16670 completed (loss: 0.2488415539264679, acc: 1.0)
[2024-11-14 09:50:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:41][root][INFO] - Training Epoch: 2/2, step 10457/16670 completed (loss: 0.15169546008110046, acc: 0.9444444179534912)
[2024-11-14 09:50:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:41][root][INFO] - Training Epoch: 2/2, step 10458/16670 completed (loss: 0.2994290888309479, acc: 0.9795918464660645)
[2024-11-14 09:50:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:41][root][INFO] - Training Epoch: 2/2, step 10459/16670 completed (loss: 0.5200979709625244, acc: 0.8787878751754761)
[2024-11-14 09:50:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:42][root][INFO] - Training Epoch: 2/2, step 10460/16670 completed (loss: 0.12415869534015656, acc: 0.9682539701461792)
[2024-11-14 09:50:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:42][root][INFO] - Training Epoch: 2/2, step 10461/16670 completed (loss: 0.8388639092445374, acc: 0.7636363506317139)
[2024-11-14 09:50:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:42][root][INFO] - Training Epoch: 2/2, step 10462/16670 completed (loss: 0.8827728033065796, acc: 0.8148148059844971)
[2024-11-14 09:50:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:43][root][INFO] - Training Epoch: 2/2, step 10463/16670 completed (loss: 0.8102138042449951, acc: 0.8723404407501221)
[2024-11-14 09:50:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:43][root][INFO] - Training Epoch: 2/2, step 10464/16670 completed (loss: 0.5756621360778809, acc: 0.8108108043670654)
[2024-11-14 09:50:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:43][root][INFO] - Training Epoch: 2/2, step 10465/16670 completed (loss: 0.6172488331794739, acc: 0.9166666865348816)
[2024-11-14 09:50:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:44][root][INFO] - Training Epoch: 2/2, step 10466/16670 completed (loss: 0.19160544872283936, acc: 0.9375)
[2024-11-14 09:50:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:44][root][INFO] - Training Epoch: 2/2, step 10467/16670 completed (loss: 0.29435569047927856, acc: 0.936170220375061)
[2024-11-14 09:50:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:44][root][INFO] - Training Epoch: 2/2, step 10468/16670 completed (loss: 0.4192788898944855, acc: 0.8421052694320679)
[2024-11-14 09:50:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:45][root][INFO] - Training Epoch: 2/2, step 10469/16670 completed (loss: 0.16374313831329346, acc: 0.9516128897666931)
[2024-11-14 09:50:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:45][root][INFO] - Training Epoch: 2/2, step 10470/16670 completed (loss: 0.14845506846904755, acc: 0.949999988079071)
[2024-11-14 09:50:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:45][root][INFO] - Training Epoch: 2/2, step 10471/16670 completed (loss: 0.21947845816612244, acc: 0.9666666388511658)
[2024-11-14 09:50:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:46][root][INFO] - Training Epoch: 2/2, step 10472/16670 completed (loss: 0.15627117455005646, acc: 0.95652174949646)
[2024-11-14 09:50:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:46][root][INFO] - Training Epoch: 2/2, step 10473/16670 completed (loss: 0.6697235703468323, acc: 0.8666666746139526)
[2024-11-14 09:50:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:46][root][INFO] - Training Epoch: 2/2, step 10474/16670 completed (loss: 0.5822134613990784, acc: 0.8620689511299133)
[2024-11-14 09:50:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:47][root][INFO] - Training Epoch: 2/2, step 10475/16670 completed (loss: 0.2807692289352417, acc: 0.9599999785423279)
[2024-11-14 09:50:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:47][root][INFO] - Training Epoch: 2/2, step 10476/16670 completed (loss: 0.5165486335754395, acc: 0.8730158805847168)
[2024-11-14 09:50:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:48][root][INFO] - Training Epoch: 2/2, step 10477/16670 completed (loss: 0.21229875087738037, acc: 0.9259259104728699)
[2024-11-14 09:50:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:48][root][INFO] - Training Epoch: 2/2, step 10478/16670 completed (loss: 0.22109375894069672, acc: 0.9473684430122375)
[2024-11-14 09:50:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:48][root][INFO] - Training Epoch: 2/2, step 10479/16670 completed (loss: 0.14530473947525024, acc: 0.9411764740943909)
[2024-11-14 09:50:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:49][root][INFO] - Training Epoch: 2/2, step 10480/16670 completed (loss: 0.4087035059928894, acc: 0.9272727370262146)
[2024-11-14 09:50:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:49][root][INFO] - Training Epoch: 2/2, step 10481/16670 completed (loss: 1.1015092134475708, acc: 0.7799999713897705)
[2024-11-14 09:50:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:49][root][INFO] - Training Epoch: 2/2, step 10482/16670 completed (loss: 0.37694093585014343, acc: 0.9743589758872986)
[2024-11-14 09:50:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:50][root][INFO] - Training Epoch: 2/2, step 10483/16670 completed (loss: 0.2254219651222229, acc: 0.931034505367279)
[2024-11-14 09:50:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:50][root][INFO] - Training Epoch: 2/2, step 10484/16670 completed (loss: 0.36265021562576294, acc: 0.9230769276618958)
[2024-11-14 09:50:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:51][root][INFO] - Training Epoch: 2/2, step 10485/16670 completed (loss: 0.4093189537525177, acc: 0.9166666865348816)
[2024-11-14 09:50:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:51][root][INFO] - Training Epoch: 2/2, step 10486/16670 completed (loss: 0.393126517534256, acc: 0.8846153616905212)
[2024-11-14 09:50:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:51][root][INFO] - Training Epoch: 2/2, step 10487/16670 completed (loss: 0.2137959599494934, acc: 0.9411764740943909)
[2024-11-14 09:50:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:51][root][INFO] - Training Epoch: 2/2, step 10488/16670 completed (loss: 0.5217259526252747, acc: 0.9090909361839294)
[2024-11-14 09:50:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:52][root][INFO] - Training Epoch: 2/2, step 10489/16670 completed (loss: 0.8509121537208557, acc: 0.8787878751754761)
[2024-11-14 09:50:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:52][root][INFO] - Training Epoch: 2/2, step 10490/16670 completed (loss: 0.049146875739097595, acc: 1.0)
[2024-11-14 09:50:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:52][root][INFO] - Training Epoch: 2/2, step 10491/16670 completed (loss: 1.3511515855789185, acc: 0.7631579041481018)
[2024-11-14 09:50:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:53][root][INFO] - Training Epoch: 2/2, step 10492/16670 completed (loss: 0.42940983176231384, acc: 0.8857142925262451)
[2024-11-14 09:50:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:53][root][INFO] - Training Epoch: 2/2, step 10493/16670 completed (loss: 0.453409880399704, acc: 0.9019607901573181)
[2024-11-14 09:50:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:53][root][INFO] - Training Epoch: 2/2, step 10494/16670 completed (loss: 0.46812501549720764, acc: 0.9137930870056152)
[2024-11-14 09:50:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:54][root][INFO] - Training Epoch: 2/2, step 10495/16670 completed (loss: 0.43142709136009216, acc: 0.9019607901573181)
[2024-11-14 09:50:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:54][root][INFO] - Training Epoch: 2/2, step 10496/16670 completed (loss: 0.23503652215003967, acc: 0.9230769276618958)
[2024-11-14 09:50:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:54][root][INFO] - Training Epoch: 2/2, step 10497/16670 completed (loss: 0.3733654320240021, acc: 0.8873239159584045)
[2024-11-14 09:50:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:55][root][INFO] - Training Epoch: 2/2, step 10498/16670 completed (loss: 0.07187516242265701, acc: 1.0)
[2024-11-14 09:50:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:55][root][INFO] - Training Epoch: 2/2, step 10499/16670 completed (loss: 0.1442299485206604, acc: 0.9636363387107849)
[2024-11-14 09:50:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:55][root][INFO] - Training Epoch: 2/2, step 10500/16670 completed (loss: 0.7329536080360413, acc: 0.8421052694320679)
[2024-11-14 09:50:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:55][root][INFO] - Training Epoch: 2/2, step 10501/16670 completed (loss: 0.38111746311187744, acc: 0.8775510191917419)
[2024-11-14 09:50:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:56][root][INFO] - Training Epoch: 2/2, step 10502/16670 completed (loss: 0.4435526728630066, acc: 0.8600000143051147)
[2024-11-14 09:50:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:56][root][INFO] - Training Epoch: 2/2, step 10503/16670 completed (loss: 0.5214235186576843, acc: 0.8571428656578064)
[2024-11-14 09:50:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:56][root][INFO] - Training Epoch: 2/2, step 10504/16670 completed (loss: 0.09815854579210281, acc: 0.9622641801834106)
[2024-11-14 09:50:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:57][root][INFO] - Training Epoch: 2/2, step 10505/16670 completed (loss: 0.3491891026496887, acc: 0.931506872177124)
[2024-11-14 09:50:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:57][root][INFO] - Training Epoch: 2/2, step 10506/16670 completed (loss: 0.5487528443336487, acc: 0.8600000143051147)
[2024-11-14 09:50:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:57][root][INFO] - Training Epoch: 2/2, step 10507/16670 completed (loss: 0.5197325944900513, acc: 0.8604651093482971)
[2024-11-14 09:50:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:58][root][INFO] - Training Epoch: 2/2, step 10508/16670 completed (loss: 0.26234591007232666, acc: 0.9459459185600281)
[2024-11-14 09:50:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:58][root][INFO] - Training Epoch: 2/2, step 10509/16670 completed (loss: 0.23459777235984802, acc: 0.9836065769195557)
[2024-11-14 09:50:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:58][root][INFO] - Training Epoch: 2/2, step 10510/16670 completed (loss: 0.5825884938240051, acc: 0.8292682766914368)
[2024-11-14 09:50:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:59][root][INFO] - Training Epoch: 2/2, step 10511/16670 completed (loss: 0.10241738706827164, acc: 0.9722222089767456)
[2024-11-14 09:50:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:59][root][INFO] - Training Epoch: 2/2, step 10512/16670 completed (loss: 0.4799567461013794, acc: 0.8813559412956238)
[2024-11-14 09:50:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:50:59][root][INFO] - Training Epoch: 2/2, step 10513/16670 completed (loss: 0.0633063018321991, acc: 1.0)
[2024-11-14 09:50:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:00][root][INFO] - Training Epoch: 2/2, step 10514/16670 completed (loss: 0.12339013069868088, acc: 0.9436619877815247)
[2024-11-14 09:51:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:00][root][INFO] - Training Epoch: 2/2, step 10515/16670 completed (loss: 0.2648475170135498, acc: 0.9677419066429138)
[2024-11-14 09:51:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:00][root][INFO] - Training Epoch: 2/2, step 10516/16670 completed (loss: 0.6119099855422974, acc: 0.8666666746139526)
[2024-11-14 09:51:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:01][root][INFO] - Training Epoch: 2/2, step 10517/16670 completed (loss: 0.44784626364707947, acc: 0.9142857193946838)
[2024-11-14 09:51:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:01][root][INFO] - Training Epoch: 2/2, step 10518/16670 completed (loss: 0.6446456909179688, acc: 0.9038461446762085)
[2024-11-14 09:51:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:02][root][INFO] - Training Epoch: 2/2, step 10519/16670 completed (loss: 0.3259098529815674, acc: 0.89552241563797)
[2024-11-14 09:51:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:02][root][INFO] - Training Epoch: 2/2, step 10520/16670 completed (loss: 0.09128759056329727, acc: 0.9772727489471436)
[2024-11-14 09:51:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:02][root][INFO] - Training Epoch: 2/2, step 10521/16670 completed (loss: 0.31587064266204834, acc: 0.9180327653884888)
[2024-11-14 09:51:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:03][root][INFO] - Training Epoch: 2/2, step 10522/16670 completed (loss: 0.4728028178215027, acc: 0.8205128312110901)
[2024-11-14 09:51:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:03][root][INFO] - Training Epoch: 2/2, step 10523/16670 completed (loss: 0.401868999004364, acc: 0.8536585569381714)
[2024-11-14 09:51:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:04][root][INFO] - Training Epoch: 2/2, step 10524/16670 completed (loss: 0.4462951123714447, acc: 0.9090909361839294)
[2024-11-14 09:51:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:04][root][INFO] - Training Epoch: 2/2, step 10525/16670 completed (loss: 0.6058238744735718, acc: 0.9459459185600281)
[2024-11-14 09:51:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:04][root][INFO] - Training Epoch: 2/2, step 10526/16670 completed (loss: 0.43838340044021606, acc: 0.8799999952316284)
[2024-11-14 09:51:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:05][root][INFO] - Training Epoch: 2/2, step 10527/16670 completed (loss: 0.13498619198799133, acc: 0.9795918464660645)
[2024-11-14 09:51:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:05][root][INFO] - Training Epoch: 2/2, step 10528/16670 completed (loss: 0.3467961251735687, acc: 0.8799999952316284)
[2024-11-14 09:51:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:05][root][INFO] - Training Epoch: 2/2, step 10529/16670 completed (loss: 0.15763618052005768, acc: 0.9555555582046509)
[2024-11-14 09:51:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:06][root][INFO] - Training Epoch: 2/2, step 10530/16670 completed (loss: 0.913254976272583, acc: 0.7878788113594055)
[2024-11-14 09:51:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:06][root][INFO] - Training Epoch: 2/2, step 10531/16670 completed (loss: 0.2545022666454315, acc: 0.9795918464660645)
[2024-11-14 09:51:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:06][root][INFO] - Training Epoch: 2/2, step 10532/16670 completed (loss: 0.425521582365036, acc: 0.8888888955116272)
[2024-11-14 09:51:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:07][root][INFO] - Training Epoch: 2/2, step 10533/16670 completed (loss: 0.22088144719600677, acc: 0.8983050584793091)
[2024-11-14 09:51:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:07][root][INFO] - Training Epoch: 2/2, step 10534/16670 completed (loss: 0.22416070103645325, acc: 0.9253731369972229)
[2024-11-14 09:51:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:07][root][INFO] - Training Epoch: 2/2, step 10535/16670 completed (loss: 0.1684885025024414, acc: 0.9433962106704712)
[2024-11-14 09:51:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:08][root][INFO] - Training Epoch: 2/2, step 10536/16670 completed (loss: 0.36499446630477905, acc: 0.9137930870056152)
[2024-11-14 09:51:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:08][root][INFO] - Training Epoch: 2/2, step 10537/16670 completed (loss: 0.548958957195282, acc: 0.859649121761322)
[2024-11-14 09:51:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:08][root][INFO] - Training Epoch: 2/2, step 10538/16670 completed (loss: 0.1566503942012787, acc: 0.9375)
[2024-11-14 09:51:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:09][root][INFO] - Training Epoch: 2/2, step 10539/16670 completed (loss: 0.4144735336303711, acc: 0.9200000166893005)
[2024-11-14 09:51:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:09][root][INFO] - Training Epoch: 2/2, step 10540/16670 completed (loss: 0.9067606329917908, acc: 0.7777777910232544)
[2024-11-14 09:51:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:09][root][INFO] - Training Epoch: 2/2, step 10541/16670 completed (loss: 0.2817953824996948, acc: 0.9438202381134033)
[2024-11-14 09:51:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:10][root][INFO] - Training Epoch: 2/2, step 10542/16670 completed (loss: 0.27747178077697754, acc: 0.8983050584793091)
[2024-11-14 09:51:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:10][root][INFO] - Training Epoch: 2/2, step 10543/16670 completed (loss: 0.9548157453536987, acc: 0.8135592937469482)
[2024-11-14 09:51:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:10][root][INFO] - Training Epoch: 2/2, step 10544/16670 completed (loss: 0.6879305839538574, acc: 0.8947368264198303)
[2024-11-14 09:51:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:11][root][INFO] - Training Epoch: 2/2, step 10545/16670 completed (loss: 0.14297598600387573, acc: 0.9607843160629272)
[2024-11-14 09:51:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:11][root][INFO] - Training Epoch: 2/2, step 10546/16670 completed (loss: 0.32311081886291504, acc: 0.9333333373069763)
[2024-11-14 09:51:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:11][root][INFO] - Training Epoch: 2/2, step 10547/16670 completed (loss: 0.12724778056144714, acc: 0.9756097793579102)
[2024-11-14 09:51:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:12][root][INFO] - Training Epoch: 2/2, step 10548/16670 completed (loss: 0.1611289381980896, acc: 0.9807692170143127)
[2024-11-14 09:51:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:12][root][INFO] - Training Epoch: 2/2, step 10549/16670 completed (loss: 0.12052296847105026, acc: 0.9733333587646484)
[2024-11-14 09:51:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:13][root][INFO] - Training Epoch: 2/2, step 10550/16670 completed (loss: 0.4344019889831543, acc: 0.8484848737716675)
[2024-11-14 09:51:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:13][root][INFO] - Training Epoch: 2/2, step 10551/16670 completed (loss: 0.1083814799785614, acc: 0.9863013625144958)
[2024-11-14 09:51:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:13][root][INFO] - Training Epoch: 2/2, step 10552/16670 completed (loss: 0.485422283411026, acc: 0.8780487775802612)
[2024-11-14 09:51:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:14][root][INFO] - Training Epoch: 2/2, step 10553/16670 completed (loss: 0.22327153384685516, acc: 0.9452054500579834)
[2024-11-14 09:51:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:14][root][INFO] - Training Epoch: 2/2, step 10554/16670 completed (loss: 0.7142730355262756, acc: 0.8571428656578064)
[2024-11-14 09:51:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:14][root][INFO] - Training Epoch: 2/2, step 10555/16670 completed (loss: 0.737124502658844, acc: 0.8441558480262756)
[2024-11-14 09:51:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:15][root][INFO] - Training Epoch: 2/2, step 10556/16670 completed (loss: 0.6642225980758667, acc: 0.8269230723381042)
[2024-11-14 09:51:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:15][root][INFO] - Training Epoch: 2/2, step 10557/16670 completed (loss: 0.5702449083328247, acc: 0.9069767594337463)
[2024-11-14 09:51:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:15][root][INFO] - Training Epoch: 2/2, step 10558/16670 completed (loss: 0.22498786449432373, acc: 0.9428571462631226)
[2024-11-14 09:51:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:16][root][INFO] - Training Epoch: 2/2, step 10559/16670 completed (loss: 0.1731157898902893, acc: 0.9111111164093018)
[2024-11-14 09:51:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:16][root][INFO] - Training Epoch: 2/2, step 10560/16670 completed (loss: 0.5077230930328369, acc: 0.8541666865348816)
[2024-11-14 09:51:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:16][root][INFO] - Training Epoch: 2/2, step 10561/16670 completed (loss: 0.3417656123638153, acc: 0.9074074029922485)
[2024-11-14 09:51:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:17][root][INFO] - Training Epoch: 2/2, step 10562/16670 completed (loss: 0.537318229675293, acc: 0.8518518805503845)
[2024-11-14 09:51:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:17][root][INFO] - Training Epoch: 2/2, step 10563/16670 completed (loss: 0.14806486666202545, acc: 0.9696969985961914)
[2024-11-14 09:51:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:17][root][INFO] - Training Epoch: 2/2, step 10564/16670 completed (loss: 0.20252999663352966, acc: 0.9622641801834106)
[2024-11-14 09:51:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:18][root][INFO] - Training Epoch: 2/2, step 10565/16670 completed (loss: 0.5883548855781555, acc: 0.8358209133148193)
[2024-11-14 09:51:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:18][root][INFO] - Training Epoch: 2/2, step 10566/16670 completed (loss: 0.3721141815185547, acc: 0.8913043737411499)
[2024-11-14 09:51:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:18][root][INFO] - Training Epoch: 2/2, step 10567/16670 completed (loss: 0.5823909044265747, acc: 0.875)
[2024-11-14 09:51:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:19][root][INFO] - Training Epoch: 2/2, step 10568/16670 completed (loss: 0.17418262362480164, acc: 0.931034505367279)
[2024-11-14 09:51:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:19][root][INFO] - Training Epoch: 2/2, step 10569/16670 completed (loss: 0.38605785369873047, acc: 0.921875)
[2024-11-14 09:51:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:19][root][INFO] - Training Epoch: 2/2, step 10570/16670 completed (loss: 0.4273781180381775, acc: 0.931034505367279)
[2024-11-14 09:51:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:20][root][INFO] - Training Epoch: 2/2, step 10571/16670 completed (loss: 0.3463791310787201, acc: 0.8979591727256775)
[2024-11-14 09:51:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:20][root][INFO] - Training Epoch: 2/2, step 10572/16670 completed (loss: 0.5244562029838562, acc: 0.8571428656578064)
[2024-11-14 09:51:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:20][root][INFO] - Training Epoch: 2/2, step 10573/16670 completed (loss: 0.41215744614601135, acc: 0.8775510191917419)
[2024-11-14 09:51:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:21][root][INFO] - Training Epoch: 2/2, step 10574/16670 completed (loss: 0.35788166522979736, acc: 0.90625)
[2024-11-14 09:51:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:21][root][INFO] - Training Epoch: 2/2, step 10575/16670 completed (loss: 0.0810476690530777, acc: 0.9591836929321289)
[2024-11-14 09:51:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:21][root][INFO] - Training Epoch: 2/2, step 10576/16670 completed (loss: 0.26006701588630676, acc: 0.9411764740943909)
[2024-11-14 09:51:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:22][root][INFO] - Training Epoch: 2/2, step 10577/16670 completed (loss: 0.30707043409347534, acc: 0.8965517282485962)
[2024-11-14 09:51:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:22][root][INFO] - Training Epoch: 2/2, step 10578/16670 completed (loss: 0.158709317445755, acc: 0.9818181991577148)
[2024-11-14 09:51:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:23][root][INFO] - Training Epoch: 2/2, step 10579/16670 completed (loss: 0.138273224234581, acc: 0.9666666388511658)
[2024-11-14 09:51:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:23][root][INFO] - Training Epoch: 2/2, step 10580/16670 completed (loss: 0.2761755585670471, acc: 0.9333333373069763)
[2024-11-14 09:51:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:23][root][INFO] - Training Epoch: 2/2, step 10581/16670 completed (loss: 0.3775363862514496, acc: 0.8799999952316284)
[2024-11-14 09:51:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:24][root][INFO] - Training Epoch: 2/2, step 10582/16670 completed (loss: 0.2816998064517975, acc: 0.8928571343421936)
[2024-11-14 09:51:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:24][root][INFO] - Training Epoch: 2/2, step 10583/16670 completed (loss: 0.796575665473938, acc: 0.7674418687820435)
[2024-11-14 09:51:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:24][root][INFO] - Training Epoch: 2/2, step 10584/16670 completed (loss: 0.26057228446006775, acc: 0.949999988079071)
[2024-11-14 09:51:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:25][root][INFO] - Training Epoch: 2/2, step 10585/16670 completed (loss: 0.6535782814025879, acc: 0.804347813129425)
[2024-11-14 09:51:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:25][root][INFO] - Training Epoch: 2/2, step 10586/16670 completed (loss: 0.5567036867141724, acc: 0.824999988079071)
[2024-11-14 09:51:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:25][root][INFO] - Training Epoch: 2/2, step 10587/16670 completed (loss: 0.7651073932647705, acc: 0.8709677457809448)
[2024-11-14 09:51:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:26][root][INFO] - Training Epoch: 2/2, step 10588/16670 completed (loss: 0.4548736810684204, acc: 0.8636363744735718)
[2024-11-14 09:51:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:26][root][INFO] - Training Epoch: 2/2, step 10589/16670 completed (loss: 0.3851032257080078, acc: 0.8936170339584351)
[2024-11-14 09:51:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:27][root][INFO] - Training Epoch: 2/2, step 10590/16670 completed (loss: 0.922561764717102, acc: 0.8529411554336548)
[2024-11-14 09:51:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:27][root][INFO] - Training Epoch: 2/2, step 10591/16670 completed (loss: 0.8280209302902222, acc: 0.7674418687820435)
[2024-11-14 09:51:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:27][root][INFO] - Training Epoch: 2/2, step 10592/16670 completed (loss: 0.4447827637195587, acc: 0.8852459192276001)
[2024-11-14 09:51:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:28][root][INFO] - Training Epoch: 2/2, step 10593/16670 completed (loss: 0.16544915735721588, acc: 0.9399999976158142)
[2024-11-14 09:51:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:28][root][INFO] - Training Epoch: 2/2, step 10594/16670 completed (loss: 0.40447282791137695, acc: 0.8999999761581421)
[2024-11-14 09:51:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:28][root][INFO] - Training Epoch: 2/2, step 10595/16670 completed (loss: 0.3113214671611786, acc: 0.9333333373069763)
[2024-11-14 09:51:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:29][root][INFO] - Training Epoch: 2/2, step 10596/16670 completed (loss: 0.5872169137001038, acc: 0.8285714387893677)
[2024-11-14 09:51:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:29][root][INFO] - Training Epoch: 2/2, step 10597/16670 completed (loss: 0.05757037177681923, acc: 0.9841269850730896)
[2024-11-14 09:51:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:29][root][INFO] - Training Epoch: 2/2, step 10598/16670 completed (loss: 0.8796324133872986, acc: 0.7903226017951965)
[2024-11-14 09:51:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:30][root][INFO] - Training Epoch: 2/2, step 10599/16670 completed (loss: 0.051723793148994446, acc: 1.0)
[2024-11-14 09:51:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:30][root][INFO] - Training Epoch: 2/2, step 10600/16670 completed (loss: 0.40000981092453003, acc: 0.8604651093482971)
[2024-11-14 09:51:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:31][root][INFO] - Training Epoch: 2/2, step 10601/16670 completed (loss: 0.16339270770549774, acc: 0.9482758641242981)
[2024-11-14 09:51:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:31][root][INFO] - Training Epoch: 2/2, step 10602/16670 completed (loss: 0.21851961314678192, acc: 0.9285714030265808)
[2024-11-14 09:51:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:31][root][INFO] - Training Epoch: 2/2, step 10603/16670 completed (loss: 0.4632830023765564, acc: 0.8999999761581421)
[2024-11-14 09:51:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:32][root][INFO] - Training Epoch: 2/2, step 10604/16670 completed (loss: 0.2473163604736328, acc: 0.9545454382896423)
[2024-11-14 09:51:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:32][root][INFO] - Training Epoch: 2/2, step 10605/16670 completed (loss: 0.7313265800476074, acc: 0.8518518805503845)
[2024-11-14 09:51:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:32][root][INFO] - Training Epoch: 2/2, step 10606/16670 completed (loss: 0.2712237536907196, acc: 0.9333333373069763)
[2024-11-14 09:51:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:33][root][INFO] - Training Epoch: 2/2, step 10607/16670 completed (loss: 0.2790674567222595, acc: 0.8730158805847168)
[2024-11-14 09:51:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:33][root][INFO] - Training Epoch: 2/2, step 10608/16670 completed (loss: 0.16324937343597412, acc: 0.9622641801834106)
[2024-11-14 09:51:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:33][root][INFO] - Training Epoch: 2/2, step 10609/16670 completed (loss: 0.5356168150901794, acc: 0.7857142686843872)
[2024-11-14 09:51:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:34][root][INFO] - Training Epoch: 2/2, step 10610/16670 completed (loss: 0.18467183411121368, acc: 0.939393937587738)
[2024-11-14 09:51:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:34][root][INFO] - Training Epoch: 2/2, step 10611/16670 completed (loss: 1.1110007762908936, acc: 0.7586206793785095)
[2024-11-14 09:51:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:34][root][INFO] - Training Epoch: 2/2, step 10612/16670 completed (loss: 0.7456600666046143, acc: 0.8333333134651184)
[2024-11-14 09:51:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:35][root][INFO] - Training Epoch: 2/2, step 10613/16670 completed (loss: 0.4967420995235443, acc: 0.8709677457809448)
[2024-11-14 09:51:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:35][root][INFO] - Training Epoch: 2/2, step 10614/16670 completed (loss: 0.3453178405761719, acc: 0.9107142686843872)
[2024-11-14 09:51:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:35][root][INFO] - Training Epoch: 2/2, step 10615/16670 completed (loss: 0.49490684270858765, acc: 0.8867924809455872)
[2024-11-14 09:51:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:36][root][INFO] - Training Epoch: 2/2, step 10616/16670 completed (loss: 0.2760143280029297, acc: 0.8965517282485962)
[2024-11-14 09:51:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:36][root][INFO] - Training Epoch: 2/2, step 10617/16670 completed (loss: 0.7255509495735168, acc: 0.7692307829856873)
[2024-11-14 09:51:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:36][root][INFO] - Training Epoch: 2/2, step 10618/16670 completed (loss: 0.5561206340789795, acc: 0.8533333539962769)
[2024-11-14 09:51:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:37][root][INFO] - Training Epoch: 2/2, step 10619/16670 completed (loss: 0.4062071740627289, acc: 0.9166666865348816)
[2024-11-14 09:51:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:37][root][INFO] - Training Epoch: 2/2, step 10620/16670 completed (loss: 0.24521438777446747, acc: 0.9411764740943909)
[2024-11-14 09:51:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:37][root][INFO] - Training Epoch: 2/2, step 10621/16670 completed (loss: 1.101765751838684, acc: 0.7272727489471436)
[2024-11-14 09:51:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:38][root][INFO] - Training Epoch: 2/2, step 10622/16670 completed (loss: 0.4761578142642975, acc: 0.8809523582458496)
[2024-11-14 09:51:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:38][root][INFO] - Training Epoch: 2/2, step 10623/16670 completed (loss: 0.2813358008861542, acc: 0.9538461565971375)
[2024-11-14 09:51:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:38][root][INFO] - Training Epoch: 2/2, step 10624/16670 completed (loss: 0.3869578242301941, acc: 0.9666666388511658)
[2024-11-14 09:51:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:39][root][INFO] - Training Epoch: 2/2, step 10625/16670 completed (loss: 0.4737388491630554, acc: 0.8676470518112183)
[2024-11-14 09:51:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:39][root][INFO] - Training Epoch: 2/2, step 10626/16670 completed (loss: 0.6273474097251892, acc: 0.8615384697914124)
[2024-11-14 09:51:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:39][root][INFO] - Training Epoch: 2/2, step 10627/16670 completed (loss: 1.1913427114486694, acc: 0.8157894611358643)
[2024-11-14 09:51:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:40][root][INFO] - Training Epoch: 2/2, step 10628/16670 completed (loss: 0.4959772527217865, acc: 0.8611111044883728)
[2024-11-14 09:51:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:40][root][INFO] - Training Epoch: 2/2, step 10629/16670 completed (loss: 0.10336416214704514, acc: 0.9838709831237793)
[2024-11-14 09:51:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:40][root][INFO] - Training Epoch: 2/2, step 10630/16670 completed (loss: 0.24935735762119293, acc: 0.9545454382896423)
[2024-11-14 09:51:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:41][root][INFO] - Training Epoch: 2/2, step 10631/16670 completed (loss: 0.39114922285079956, acc: 0.8888888955116272)
[2024-11-14 09:51:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:41][root][INFO] - Training Epoch: 2/2, step 10632/16670 completed (loss: 0.31026965379714966, acc: 0.9090909361839294)
[2024-11-14 09:51:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:41][root][INFO] - Training Epoch: 2/2, step 10633/16670 completed (loss: 0.4054482877254486, acc: 0.8421052694320679)
[2024-11-14 09:51:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:42][root][INFO] - Training Epoch: 2/2, step 10634/16670 completed (loss: 0.24695482850074768, acc: 0.9365079402923584)
[2024-11-14 09:51:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:42][root][INFO] - Training Epoch: 2/2, step 10635/16670 completed (loss: 0.32855021953582764, acc: 0.9607843160629272)
[2024-11-14 09:51:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:42][root][INFO] - Training Epoch: 2/2, step 10636/16670 completed (loss: 0.540279746055603, acc: 0.8999999761581421)
[2024-11-14 09:51:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:43][root][INFO] - Training Epoch: 2/2, step 10637/16670 completed (loss: 0.28874310851097107, acc: 0.949999988079071)
[2024-11-14 09:51:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:43][root][INFO] - Training Epoch: 2/2, step 10638/16670 completed (loss: 0.1432226002216339, acc: 0.9459459185600281)
[2024-11-14 09:51:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:43][root][INFO] - Training Epoch: 2/2, step 10639/16670 completed (loss: 0.14144150912761688, acc: 0.976190447807312)
[2024-11-14 09:51:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:44][root][INFO] - Training Epoch: 2/2, step 10640/16670 completed (loss: 0.5768187642097473, acc: 0.8108108043670654)
[2024-11-14 09:51:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:44][root][INFO] - Training Epoch: 2/2, step 10641/16670 completed (loss: 0.30433034896850586, acc: 0.9350649118423462)
[2024-11-14 09:51:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:44][root][INFO] - Training Epoch: 2/2, step 10642/16670 completed (loss: 0.23864173889160156, acc: 0.9387755393981934)
[2024-11-14 09:51:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:45][root][INFO] - Training Epoch: 2/2, step 10643/16670 completed (loss: 0.39977583289146423, acc: 0.892307698726654)
[2024-11-14 09:51:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:45][root][INFO] - Training Epoch: 2/2, step 10644/16670 completed (loss: 0.4128859043121338, acc: 0.9270833134651184)
[2024-11-14 09:51:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:45][root][INFO] - Training Epoch: 2/2, step 10645/16670 completed (loss: 0.5695003867149353, acc: 0.8095238208770752)
[2024-11-14 09:51:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:46][root][INFO] - Training Epoch: 2/2, step 10646/16670 completed (loss: 0.4145873785018921, acc: 0.875)
[2024-11-14 09:51:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:46][root][INFO] - Training Epoch: 2/2, step 10647/16670 completed (loss: 0.1515766680240631, acc: 0.9473684430122375)
[2024-11-14 09:51:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:46][root][INFO] - Training Epoch: 2/2, step 10648/16670 completed (loss: 0.3033157289028168, acc: 0.9047619104385376)
[2024-11-14 09:51:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:47][root][INFO] - Training Epoch: 2/2, step 10649/16670 completed (loss: 0.7639540433883667, acc: 0.78125)
[2024-11-14 09:51:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:47][root][INFO] - Training Epoch: 2/2, step 10650/16670 completed (loss: 0.8689630031585693, acc: 0.782608687877655)
[2024-11-14 09:51:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:47][root][INFO] - Training Epoch: 2/2, step 10651/16670 completed (loss: 0.8659306764602661, acc: 0.8775510191917419)
[2024-11-14 09:51:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:47][root][INFO] - Training Epoch: 2/2, step 10652/16670 completed (loss: 0.48001572489738464, acc: 0.8947368264198303)
[2024-11-14 09:51:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:48][root][INFO] - Training Epoch: 2/2, step 10653/16670 completed (loss: 0.3376047909259796, acc: 0.8888888955116272)
[2024-11-14 09:51:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:48][root][INFO] - Training Epoch: 2/2, step 10654/16670 completed (loss: 0.583834171295166, acc: 0.8139534592628479)
[2024-11-14 09:51:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:48][root][INFO] - Training Epoch: 2/2, step 10655/16670 completed (loss: 0.5770930647850037, acc: 0.800000011920929)
[2024-11-14 09:51:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:49][root][INFO] - Training Epoch: 2/2, step 10656/16670 completed (loss: 0.1705741286277771, acc: 0.9629629850387573)
[2024-11-14 09:51:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:49][root][INFO] - Training Epoch: 2/2, step 10657/16670 completed (loss: 0.6524009108543396, acc: 0.8166666626930237)
[2024-11-14 09:51:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:49][root][INFO] - Training Epoch: 2/2, step 10658/16670 completed (loss: 0.1230064332485199, acc: 0.9696969985961914)
[2024-11-14 09:51:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:50][root][INFO] - Training Epoch: 2/2, step 10659/16670 completed (loss: 0.2588965594768524, acc: 0.9137930870056152)
[2024-11-14 09:51:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:50][root][INFO] - Training Epoch: 2/2, step 10660/16670 completed (loss: 0.9069461822509766, acc: 0.78125)
[2024-11-14 09:51:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:50][root][INFO] - Training Epoch: 2/2, step 10661/16670 completed (loss: 0.3148620128631592, acc: 0.9599999785423279)
[2024-11-14 09:51:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:50][root][INFO] - Training Epoch: 2/2, step 10662/16670 completed (loss: 0.27317535877227783, acc: 0.939393937587738)
[2024-11-14 09:51:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:51][root][INFO] - Training Epoch: 2/2, step 10663/16670 completed (loss: 0.4911823272705078, acc: 0.9200000166893005)
[2024-11-14 09:51:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:51][root][INFO] - Training Epoch: 2/2, step 10664/16670 completed (loss: 0.31975358724594116, acc: 0.9384615421295166)
[2024-11-14 09:51:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:51][root][INFO] - Training Epoch: 2/2, step 10665/16670 completed (loss: 0.21737773716449738, acc: 0.9375)
[2024-11-14 09:51:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:52][root][INFO] - Training Epoch: 2/2, step 10666/16670 completed (loss: 0.2998764216899872, acc: 0.949999988079071)
[2024-11-14 09:51:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:52][root][INFO] - Training Epoch: 2/2, step 10667/16670 completed (loss: 0.318036824464798, acc: 0.942307710647583)
[2024-11-14 09:51:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:52][root][INFO] - Training Epoch: 2/2, step 10668/16670 completed (loss: 0.22173288464546204, acc: 0.9130434989929199)
[2024-11-14 09:51:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:52][root][INFO] - Training Epoch: 2/2, step 10669/16670 completed (loss: 0.19937901198863983, acc: 0.978723406791687)
[2024-11-14 09:51:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:53][root][INFO] - Training Epoch: 2/2, step 10670/16670 completed (loss: 0.4887481927871704, acc: 0.930232584476471)
[2024-11-14 09:51:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:53][root][INFO] - Training Epoch: 2/2, step 10671/16670 completed (loss: 0.13360069692134857, acc: 0.96875)
[2024-11-14 09:51:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:53][root][INFO] - Training Epoch: 2/2, step 10672/16670 completed (loss: 0.3586869239807129, acc: 0.8840579986572266)
[2024-11-14 09:51:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:54][root][INFO] - Training Epoch: 2/2, step 10673/16670 completed (loss: 0.22061796486377716, acc: 0.9411764740943909)
[2024-11-14 09:51:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:54][root][INFO] - Training Epoch: 2/2, step 10674/16670 completed (loss: 0.44130808115005493, acc: 0.9411764740943909)
[2024-11-14 09:51:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:54][root][INFO] - Training Epoch: 2/2, step 10675/16670 completed (loss: 0.457086980342865, acc: 0.875)
[2024-11-14 09:51:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:55][root][INFO] - Training Epoch: 2/2, step 10676/16670 completed (loss: 0.09633079916238785, acc: 0.9555555582046509)
[2024-11-14 09:51:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:55][root][INFO] - Training Epoch: 2/2, step 10677/16670 completed (loss: 0.1511702984571457, acc: 0.9607843160629272)
[2024-11-14 09:51:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:55][root][INFO] - Training Epoch: 2/2, step 10678/16670 completed (loss: 0.33274340629577637, acc: 0.9354838728904724)
[2024-11-14 09:51:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:56][root][INFO] - Training Epoch: 2/2, step 10679/16670 completed (loss: 0.36086636781692505, acc: 0.8985507488250732)
[2024-11-14 09:51:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:56][root][INFO] - Training Epoch: 2/2, step 10680/16670 completed (loss: 0.36086195707321167, acc: 0.9090909361839294)
[2024-11-14 09:51:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:56][root][INFO] - Training Epoch: 2/2, step 10681/16670 completed (loss: 0.2382744550704956, acc: 0.9117646813392639)
[2024-11-14 09:51:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:56][root][INFO] - Training Epoch: 2/2, step 10682/16670 completed (loss: 0.30562064051628113, acc: 0.9473684430122375)
[2024-11-14 09:51:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:57][root][INFO] - Training Epoch: 2/2, step 10683/16670 completed (loss: 0.36811700463294983, acc: 0.8823529481887817)
[2024-11-14 09:51:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:57][root][INFO] - Training Epoch: 2/2, step 10684/16670 completed (loss: 0.684522807598114, acc: 0.8928571343421936)
[2024-11-14 09:51:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:57][root][INFO] - Training Epoch: 2/2, step 10685/16670 completed (loss: 0.24287116527557373, acc: 0.9210526347160339)
[2024-11-14 09:51:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:58][root][INFO] - Training Epoch: 2/2, step 10686/16670 completed (loss: 0.39596784114837646, acc: 0.8999999761581421)
[2024-11-14 09:51:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:58][root][INFO] - Training Epoch: 2/2, step 10687/16670 completed (loss: 0.1358703076839447, acc: 0.9607843160629272)
[2024-11-14 09:51:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:58][root][INFO] - Training Epoch: 2/2, step 10688/16670 completed (loss: 0.32738590240478516, acc: 0.9583333134651184)
[2024-11-14 09:51:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:59][root][INFO] - Training Epoch: 2/2, step 10689/16670 completed (loss: 0.0341070331633091, acc: 1.0)
[2024-11-14 09:51:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:59][root][INFO] - Training Epoch: 2/2, step 10690/16670 completed (loss: 0.45993974804878235, acc: 0.8829787373542786)
[2024-11-14 09:51:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:51:59][root][INFO] - Training Epoch: 2/2, step 10691/16670 completed (loss: 0.20022468268871307, acc: 0.949999988079071)
[2024-11-14 09:51:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:00][root][INFO] - Training Epoch: 2/2, step 10692/16670 completed (loss: 0.7187102437019348, acc: 0.7872340679168701)
[2024-11-14 09:52:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:00][root][INFO] - Training Epoch: 2/2, step 10693/16670 completed (loss: 0.2240563929080963, acc: 0.9285714030265808)
[2024-11-14 09:52:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:00][root][INFO] - Training Epoch: 2/2, step 10694/16670 completed (loss: 0.3234599530696869, acc: 0.9193548560142517)
[2024-11-14 09:52:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:01][root][INFO] - Training Epoch: 2/2, step 10695/16670 completed (loss: 0.7344369888305664, acc: 0.8444444537162781)
[2024-11-14 09:52:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:01][root][INFO] - Training Epoch: 2/2, step 10696/16670 completed (loss: 0.29179850220680237, acc: 0.9607843160629272)
[2024-11-14 09:52:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:01][root][INFO] - Training Epoch: 2/2, step 10697/16670 completed (loss: 0.7039343118667603, acc: 0.8604651093482971)
[2024-11-14 09:52:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:01][root][INFO] - Training Epoch: 2/2, step 10698/16670 completed (loss: 0.41045767068862915, acc: 0.9512194991111755)
[2024-11-14 09:52:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:02][root][INFO] - Training Epoch: 2/2, step 10699/16670 completed (loss: 0.30964773893356323, acc: 0.9111111164093018)
[2024-11-14 09:52:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:02][root][INFO] - Training Epoch: 2/2, step 10700/16670 completed (loss: 0.12771332263946533, acc: 0.9615384340286255)
[2024-11-14 09:52:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:02][root][INFO] - Training Epoch: 2/2, step 10701/16670 completed (loss: 0.38803890347480774, acc: 0.9074074029922485)
[2024-11-14 09:52:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:03][root][INFO] - Training Epoch: 2/2, step 10702/16670 completed (loss: 0.5824654698371887, acc: 0.8461538553237915)
[2024-11-14 09:52:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:03][root][INFO] - Training Epoch: 2/2, step 10703/16670 completed (loss: 0.20676207542419434, acc: 0.9454545378684998)
[2024-11-14 09:52:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:03][root][INFO] - Training Epoch: 2/2, step 10704/16670 completed (loss: 0.13442419469356537, acc: 0.9210526347160339)
[2024-11-14 09:52:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:04][root][INFO] - Training Epoch: 2/2, step 10705/16670 completed (loss: 0.1925070881843567, acc: 0.9436619877815247)
[2024-11-14 09:52:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:04][root][INFO] - Training Epoch: 2/2, step 10706/16670 completed (loss: 1.1454964876174927, acc: 0.7586206793785095)
[2024-11-14 09:52:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:04][root][INFO] - Training Epoch: 2/2, step 10707/16670 completed (loss: 0.3892056345939636, acc: 0.9178082346916199)
[2024-11-14 09:52:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:05][root][INFO] - Training Epoch: 2/2, step 10708/16670 completed (loss: 0.1670657843351364, acc: 0.9166666865348816)
[2024-11-14 09:52:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:05][root][INFO] - Training Epoch: 2/2, step 10709/16670 completed (loss: 0.0759393498301506, acc: 1.0)
[2024-11-14 09:52:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:05][root][INFO] - Training Epoch: 2/2, step 10710/16670 completed (loss: 0.14752206206321716, acc: 0.9642857313156128)
[2024-11-14 09:52:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:05][root][INFO] - Training Epoch: 2/2, step 10711/16670 completed (loss: 0.4691537916660309, acc: 0.8421052694320679)
[2024-11-14 09:52:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:06][root][INFO] - Training Epoch: 2/2, step 10712/16670 completed (loss: 0.19667492806911469, acc: 0.9512194991111755)
[2024-11-14 09:52:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:06][root][INFO] - Training Epoch: 2/2, step 10713/16670 completed (loss: 0.12260141968727112, acc: 0.9692307710647583)
[2024-11-14 09:52:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:06][root][INFO] - Training Epoch: 2/2, step 10714/16670 completed (loss: 0.28978103399276733, acc: 0.9624999761581421)
[2024-11-14 09:52:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:07][root][INFO] - Training Epoch: 2/2, step 10715/16670 completed (loss: 0.3089933693408966, acc: 0.9230769276618958)
[2024-11-14 09:52:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:07][root][INFO] - Training Epoch: 2/2, step 10716/16670 completed (loss: 0.20140478014945984, acc: 0.978723406791687)
[2024-11-14 09:52:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:07][root][INFO] - Training Epoch: 2/2, step 10717/16670 completed (loss: 0.20696021616458893, acc: 0.9215686321258545)
[2024-11-14 09:52:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:08][root][INFO] - Training Epoch: 2/2, step 10718/16670 completed (loss: 0.638119101524353, acc: 0.9047619104385376)
[2024-11-14 09:52:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:08][root][INFO] - Training Epoch: 2/2, step 10719/16670 completed (loss: 0.5595470666885376, acc: 0.8222222328186035)
[2024-11-14 09:52:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:08][root][INFO] - Training Epoch: 2/2, step 10720/16670 completed (loss: 0.3913416266441345, acc: 0.9166666865348816)
[2024-11-14 09:52:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:09][root][INFO] - Training Epoch: 2/2, step 10721/16670 completed (loss: 0.493146687746048, acc: 0.8679245114326477)
[2024-11-14 09:52:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:09][root][INFO] - Training Epoch: 2/2, step 10722/16670 completed (loss: 0.10969798266887665, acc: 0.95652174949646)
[2024-11-14 09:52:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:09][root][INFO] - Training Epoch: 2/2, step 10723/16670 completed (loss: 0.40022197365760803, acc: 0.8857142925262451)
[2024-11-14 09:52:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:10][root][INFO] - Training Epoch: 2/2, step 10724/16670 completed (loss: 1.1898449659347534, acc: 0.8363636136054993)
[2024-11-14 09:52:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:10][root][INFO] - Training Epoch: 2/2, step 10725/16670 completed (loss: 0.42428091168403625, acc: 0.8947368264198303)
[2024-11-14 09:52:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:10][root][INFO] - Training Epoch: 2/2, step 10726/16670 completed (loss: 0.02868976816534996, acc: 1.0)
[2024-11-14 09:52:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:10][root][INFO] - Training Epoch: 2/2, step 10727/16670 completed (loss: 0.5292247533798218, acc: 0.8809523582458496)
[2024-11-14 09:52:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:11][root][INFO] - Training Epoch: 2/2, step 10728/16670 completed (loss: 0.4695705771446228, acc: 0.8809523582458496)
[2024-11-14 09:52:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:11][root][INFO] - Training Epoch: 2/2, step 10729/16670 completed (loss: 0.1954192817211151, acc: 0.9454545378684998)
[2024-11-14 09:52:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:11][root][INFO] - Training Epoch: 2/2, step 10730/16670 completed (loss: 0.33743491768836975, acc: 0.9491525292396545)
[2024-11-14 09:52:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:12][root][INFO] - Training Epoch: 2/2, step 10731/16670 completed (loss: 0.37829306721687317, acc: 0.9230769276618958)
[2024-11-14 09:52:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:12][root][INFO] - Training Epoch: 2/2, step 10732/16670 completed (loss: 0.2799520194530487, acc: 0.9166666865348816)
[2024-11-14 09:52:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:12][root][INFO] - Training Epoch: 2/2, step 10733/16670 completed (loss: 0.47113266587257385, acc: 0.8421052694320679)
[2024-11-14 09:52:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:13][root][INFO] - Training Epoch: 2/2, step 10734/16670 completed (loss: 0.4805055260658264, acc: 0.875)
[2024-11-14 09:52:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:13][root][INFO] - Training Epoch: 2/2, step 10735/16670 completed (loss: 0.7427577376365662, acc: 0.8235294222831726)
[2024-11-14 09:52:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:13][root][INFO] - Training Epoch: 2/2, step 10736/16670 completed (loss: 0.43042606115341187, acc: 0.8653846383094788)
[2024-11-14 09:52:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:14][root][INFO] - Training Epoch: 2/2, step 10737/16670 completed (loss: 0.4367622137069702, acc: 0.8947368264198303)
[2024-11-14 09:52:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:14][root][INFO] - Training Epoch: 2/2, step 10738/16670 completed (loss: 0.03560243174433708, acc: 1.0)
[2024-11-14 09:52:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:14][root][INFO] - Training Epoch: 2/2, step 10739/16670 completed (loss: 0.66062992811203, acc: 0.8333333134651184)
[2024-11-14 09:52:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:15][root][INFO] - Training Epoch: 2/2, step 10740/16670 completed (loss: 0.10147744417190552, acc: 1.0)
[2024-11-14 09:52:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:15][root][INFO] - Training Epoch: 2/2, step 10741/16670 completed (loss: 0.4662764072418213, acc: 0.8823529481887817)
[2024-11-14 09:52:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:15][root][INFO] - Training Epoch: 2/2, step 10742/16670 completed (loss: 0.4937301576137543, acc: 0.9074074029922485)
[2024-11-14 09:52:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:16][root][INFO] - Training Epoch: 2/2, step 10743/16670 completed (loss: 0.0868566632270813, acc: 0.9772727489471436)
[2024-11-14 09:52:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:16][root][INFO] - Training Epoch: 2/2, step 10744/16670 completed (loss: 0.12198718637228012, acc: 0.9677419066429138)
[2024-11-14 09:52:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:16][root][INFO] - Training Epoch: 2/2, step 10745/16670 completed (loss: 0.1528545618057251, acc: 0.9200000166893005)
[2024-11-14 09:52:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:17][root][INFO] - Training Epoch: 2/2, step 10746/16670 completed (loss: 0.22908525168895721, acc: 0.9200000166893005)
[2024-11-14 09:52:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:17][root][INFO] - Training Epoch: 2/2, step 10747/16670 completed (loss: 0.42057445645332336, acc: 0.9090909361839294)
[2024-11-14 09:52:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:17][root][INFO] - Training Epoch: 2/2, step 10748/16670 completed (loss: 0.22898846864700317, acc: 0.930232584476471)
[2024-11-14 09:52:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:18][root][INFO] - Training Epoch: 2/2, step 10749/16670 completed (loss: 0.574046790599823, acc: 0.8787878751754761)
[2024-11-14 09:52:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:18][root][INFO] - Training Epoch: 2/2, step 10750/16670 completed (loss: 0.641701340675354, acc: 0.8928571343421936)
[2024-11-14 09:52:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:18][root][INFO] - Training Epoch: 2/2, step 10751/16670 completed (loss: 0.07479061931371689, acc: 0.9583333134651184)
[2024-11-14 09:52:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:19][root][INFO] - Training Epoch: 2/2, step 10752/16670 completed (loss: 0.8452269434928894, acc: 0.8333333134651184)
[2024-11-14 09:52:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:19][root][INFO] - Training Epoch: 2/2, step 10753/16670 completed (loss: 0.18107520043849945, acc: 0.9130434989929199)
[2024-11-14 09:52:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:19][root][INFO] - Training Epoch: 2/2, step 10754/16670 completed (loss: 0.3400212526321411, acc: 0.95652174949646)
[2024-11-14 09:52:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:20][root][INFO] - Training Epoch: 2/2, step 10755/16670 completed (loss: 0.16699373722076416, acc: 0.9466666579246521)
[2024-11-14 09:52:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:20][root][INFO] - Training Epoch: 2/2, step 10756/16670 completed (loss: 0.41231435537338257, acc: 0.8947368264198303)
[2024-11-14 09:52:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:20][root][INFO] - Training Epoch: 2/2, step 10757/16670 completed (loss: 0.19883225858211517, acc: 0.9433962106704712)
[2024-11-14 09:52:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:21][root][INFO] - Training Epoch: 2/2, step 10758/16670 completed (loss: 0.38405582308769226, acc: 0.8999999761581421)
[2024-11-14 09:52:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:21][root][INFO] - Training Epoch: 2/2, step 10759/16670 completed (loss: 0.09966474026441574, acc: 0.9722222089767456)
[2024-11-14 09:52:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:21][root][INFO] - Training Epoch: 2/2, step 10760/16670 completed (loss: 0.2888220548629761, acc: 0.8999999761581421)
[2024-11-14 09:52:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:22][root][INFO] - Training Epoch: 2/2, step 10761/16670 completed (loss: 1.1949089765548706, acc: 0.7333333492279053)
[2024-11-14 09:52:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:22][root][INFO] - Training Epoch: 2/2, step 10762/16670 completed (loss: 1.05901038646698, acc: 0.7272727489471436)
[2024-11-14 09:52:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:22][root][INFO] - Training Epoch: 2/2, step 10763/16670 completed (loss: 0.5838590264320374, acc: 0.890625)
[2024-11-14 09:52:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:23][root][INFO] - Training Epoch: 2/2, step 10764/16670 completed (loss: 0.6981576681137085, acc: 0.8615384697914124)
[2024-11-14 09:52:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:23][root][INFO] - Training Epoch: 2/2, step 10765/16670 completed (loss: 1.341186761856079, acc: 0.75)
[2024-11-14 09:52:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:23][root][INFO] - Training Epoch: 2/2, step 10766/16670 completed (loss: 0.2624671757221222, acc: 0.9166666865348816)
[2024-11-14 09:52:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:24][root][INFO] - Training Epoch: 2/2, step 10767/16670 completed (loss: 0.24476023018360138, acc: 0.9032257795333862)
[2024-11-14 09:52:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:24][root][INFO] - Training Epoch: 2/2, step 10768/16670 completed (loss: 0.48456332087516785, acc: 0.8684210777282715)
[2024-11-14 09:52:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:25][root][INFO] - Training Epoch: 2/2, step 10769/16670 completed (loss: 0.5441722273826599, acc: 0.8947368264198303)
[2024-11-14 09:52:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:25][root][INFO] - Training Epoch: 2/2, step 10770/16670 completed (loss: 0.4498414397239685, acc: 0.8450704216957092)
[2024-11-14 09:52:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:25][root][INFO] - Training Epoch: 2/2, step 10771/16670 completed (loss: 0.21777832508087158, acc: 0.9259259104728699)
[2024-11-14 09:52:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:26][root][INFO] - Training Epoch: 2/2, step 10772/16670 completed (loss: 0.34219223260879517, acc: 0.8867924809455872)
[2024-11-14 09:52:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:26][root][INFO] - Training Epoch: 2/2, step 10773/16670 completed (loss: 0.5980082750320435, acc: 0.9047619104385376)
[2024-11-14 09:52:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:26][root][INFO] - Training Epoch: 2/2, step 10774/16670 completed (loss: 0.8598541021347046, acc: 0.7903226017951965)
[2024-11-14 09:52:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:27][root][INFO] - Training Epoch: 2/2, step 10775/16670 completed (loss: 0.16191931068897247, acc: 0.9846153855323792)
[2024-11-14 09:52:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:27][root][INFO] - Training Epoch: 2/2, step 10776/16670 completed (loss: 0.3611634373664856, acc: 0.9032257795333862)
[2024-11-14 09:52:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:27][root][INFO] - Training Epoch: 2/2, step 10777/16670 completed (loss: 0.16933013498783112, acc: 0.9482758641242981)
[2024-11-14 09:52:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:28][root][INFO] - Training Epoch: 2/2, step 10778/16670 completed (loss: 0.3991265296936035, acc: 0.8860759735107422)
[2024-11-14 09:52:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:28][root][INFO] - Training Epoch: 2/2, step 10779/16670 completed (loss: 0.459480881690979, acc: 0.9473684430122375)
[2024-11-14 09:52:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:28][root][INFO] - Training Epoch: 2/2, step 10780/16670 completed (loss: 0.8331886529922485, acc: 0.8148148059844971)
[2024-11-14 09:52:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:29][root][INFO] - Training Epoch: 2/2, step 10781/16670 completed (loss: 0.38346999883651733, acc: 0.9074074029922485)
[2024-11-14 09:52:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:29][root][INFO] - Training Epoch: 2/2, step 10782/16670 completed (loss: 0.32122352719306946, acc: 0.918367326259613)
[2024-11-14 09:52:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:29][root][INFO] - Training Epoch: 2/2, step 10783/16670 completed (loss: 0.28865495324134827, acc: 0.8999999761581421)
[2024-11-14 09:52:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:30][root][INFO] - Training Epoch: 2/2, step 10784/16670 completed (loss: 0.11770698428153992, acc: 0.9411764740943909)
[2024-11-14 09:52:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:30][root][INFO] - Training Epoch: 2/2, step 10785/16670 completed (loss: 0.5361510515213013, acc: 0.8965517282485962)
[2024-11-14 09:52:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:30][root][INFO] - Training Epoch: 2/2, step 10786/16670 completed (loss: 0.739867091178894, acc: 0.7419354915618896)
[2024-11-14 09:52:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:31][root][INFO] - Training Epoch: 2/2, step 10787/16670 completed (loss: 0.30114099383354187, acc: 0.9090909361839294)
[2024-11-14 09:52:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:31][root][INFO] - Training Epoch: 2/2, step 10788/16670 completed (loss: 0.360100120306015, acc: 0.9230769276618958)
[2024-11-14 09:52:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:31][root][INFO] - Training Epoch: 2/2, step 10789/16670 completed (loss: 0.6846731901168823, acc: 0.8928571343421936)
[2024-11-14 09:52:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:32][root][INFO] - Training Epoch: 2/2, step 10790/16670 completed (loss: 0.5255888104438782, acc: 0.8730158805847168)
[2024-11-14 09:52:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:32][root][INFO] - Training Epoch: 2/2, step 10791/16670 completed (loss: 0.6391716003417969, acc: 0.8857142925262451)
[2024-11-14 09:52:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:32][root][INFO] - Training Epoch: 2/2, step 10792/16670 completed (loss: 0.12938785552978516, acc: 0.9464285969734192)
[2024-11-14 09:52:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:33][root][INFO] - Training Epoch: 2/2, step 10793/16670 completed (loss: 0.2999871075153351, acc: 0.9130434989929199)
[2024-11-14 09:52:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:33][root][INFO] - Training Epoch: 2/2, step 10794/16670 completed (loss: 0.49310266971588135, acc: 0.8888888955116272)
[2024-11-14 09:52:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:33][root][INFO] - Training Epoch: 2/2, step 10795/16670 completed (loss: 0.7427103519439697, acc: 0.8799999952316284)
[2024-11-14 09:52:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:34][root][INFO] - Training Epoch: 2/2, step 10796/16670 completed (loss: 0.5373384356498718, acc: 0.8545454740524292)
[2024-11-14 09:52:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:34][root][INFO] - Training Epoch: 2/2, step 10797/16670 completed (loss: 0.7606759071350098, acc: 0.7894737124443054)
[2024-11-14 09:52:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:34][root][INFO] - Training Epoch: 2/2, step 10798/16670 completed (loss: 0.18525099754333496, acc: 0.949999988079071)
[2024-11-14 09:52:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:35][root][INFO] - Training Epoch: 2/2, step 10799/16670 completed (loss: 0.7935750484466553, acc: 0.8461538553237915)
[2024-11-14 09:52:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:35][root][INFO] - Training Epoch: 2/2, step 10800/16670 completed (loss: 0.5772852897644043, acc: 0.8888888955116272)
[2024-11-14 09:52:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:35][root][INFO] - Training Epoch: 2/2, step 10801/16670 completed (loss: 0.715293288230896, acc: 0.8999999761581421)
[2024-11-14 09:52:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:36][root][INFO] - Training Epoch: 2/2, step 10802/16670 completed (loss: 0.1909136325120926, acc: 0.978723406791687)
[2024-11-14 09:52:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:36][root][INFO] - Training Epoch: 2/2, step 10803/16670 completed (loss: 0.6995901465415955, acc: 0.8529411554336548)
[2024-11-14 09:52:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:36][root][INFO] - Training Epoch: 2/2, step 10804/16670 completed (loss: 0.8014731407165527, acc: 0.800000011920929)
[2024-11-14 09:52:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:37][root][INFO] - Training Epoch: 2/2, step 10805/16670 completed (loss: 0.21521182358264923, acc: 0.918367326259613)
[2024-11-14 09:52:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:37][root][INFO] - Training Epoch: 2/2, step 10806/16670 completed (loss: 0.5017703771591187, acc: 0.9130434989929199)
[2024-11-14 09:52:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:37][root][INFO] - Training Epoch: 2/2, step 10807/16670 completed (loss: 0.18372632563114166, acc: 0.9672130942344666)
[2024-11-14 09:52:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:38][root][INFO] - Training Epoch: 2/2, step 10808/16670 completed (loss: 0.5113226771354675, acc: 0.8888888955116272)
[2024-11-14 09:52:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:38][root][INFO] - Training Epoch: 2/2, step 10809/16670 completed (loss: 0.19475047290325165, acc: 0.9387755393981934)
[2024-11-14 09:52:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:38][root][INFO] - Training Epoch: 2/2, step 10810/16670 completed (loss: 0.4580947458744049, acc: 0.8936170339584351)
[2024-11-14 09:52:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:38][root][INFO] - Training Epoch: 2/2, step 10811/16670 completed (loss: 0.35431504249572754, acc: 0.9387755393981934)
[2024-11-14 09:52:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:39][root][INFO] - Training Epoch: 2/2, step 10812/16670 completed (loss: 0.5533611178398132, acc: 0.8852459192276001)
[2024-11-14 09:52:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:39][root][INFO] - Training Epoch: 2/2, step 10813/16670 completed (loss: 0.49439099431037903, acc: 0.8684210777282715)
[2024-11-14 09:52:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:39][root][INFO] - Training Epoch: 2/2, step 10814/16670 completed (loss: 0.9138100743293762, acc: 0.8444444537162781)
[2024-11-14 09:52:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:40][root][INFO] - Training Epoch: 2/2, step 10815/16670 completed (loss: 0.49181637167930603, acc: 0.914893627166748)
[2024-11-14 09:52:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:40][root][INFO] - Training Epoch: 2/2, step 10816/16670 completed (loss: 0.4315488338470459, acc: 0.8947368264198303)
[2024-11-14 09:52:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:40][root][INFO] - Training Epoch: 2/2, step 10817/16670 completed (loss: 0.257155179977417, acc: 0.918367326259613)
[2024-11-14 09:52:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:41][root][INFO] - Training Epoch: 2/2, step 10818/16670 completed (loss: 0.3375522196292877, acc: 0.9454545378684998)
[2024-11-14 09:52:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:41][root][INFO] - Training Epoch: 2/2, step 10819/16670 completed (loss: 0.34610387682914734, acc: 0.9285714030265808)
[2024-11-14 09:52:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:41][root][INFO] - Training Epoch: 2/2, step 10820/16670 completed (loss: 0.7373352646827698, acc: 0.9016393423080444)
[2024-11-14 09:52:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:42][root][INFO] - Training Epoch: 2/2, step 10821/16670 completed (loss: 0.5335730910301208, acc: 0.898876428604126)
[2024-11-14 09:52:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:42][root][INFO] - Training Epoch: 2/2, step 10822/16670 completed (loss: 0.46466028690338135, acc: 0.9200000166893005)
[2024-11-14 09:52:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:42][root][INFO] - Training Epoch: 2/2, step 10823/16670 completed (loss: 0.3824548125267029, acc: 0.9433962106704712)
[2024-11-14 09:52:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:43][root][INFO] - Training Epoch: 2/2, step 10824/16670 completed (loss: 0.11320711672306061, acc: 0.9811320900917053)
[2024-11-14 09:52:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:43][root][INFO] - Training Epoch: 2/2, step 10825/16670 completed (loss: 0.35948610305786133, acc: 0.8571428656578064)
[2024-11-14 09:52:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:43][root][INFO] - Training Epoch: 2/2, step 10826/16670 completed (loss: 0.4066799581050873, acc: 0.8867924809455872)
[2024-11-14 09:52:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:43][root][INFO] - Training Epoch: 2/2, step 10827/16670 completed (loss: 0.4333864450454712, acc: 0.9090909361839294)
[2024-11-14 09:52:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:44][root][INFO] - Training Epoch: 2/2, step 10828/16670 completed (loss: 0.3396405279636383, acc: 0.930232584476471)
[2024-11-14 09:52:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:44][root][INFO] - Training Epoch: 2/2, step 10829/16670 completed (loss: 0.6926090121269226, acc: 0.9166666865348816)
[2024-11-14 09:52:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:44][root][INFO] - Training Epoch: 2/2, step 10830/16670 completed (loss: 0.3845105469226837, acc: 0.9047619104385376)
[2024-11-14 09:52:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:45][root][INFO] - Training Epoch: 2/2, step 10831/16670 completed (loss: 0.19816230237483978, acc: 0.9230769276618958)
[2024-11-14 09:52:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:45][root][INFO] - Training Epoch: 2/2, step 10832/16670 completed (loss: 0.5217545032501221, acc: 0.8717948794364929)
[2024-11-14 09:52:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:45][root][INFO] - Training Epoch: 2/2, step 10833/16670 completed (loss: 0.5469872951507568, acc: 0.849056601524353)
[2024-11-14 09:52:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:45][root][INFO] - Training Epoch: 2/2, step 10834/16670 completed (loss: 0.12642990052700043, acc: 0.9655172228813171)
[2024-11-14 09:52:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:46][root][INFO] - Training Epoch: 2/2, step 10835/16670 completed (loss: 0.32108622789382935, acc: 0.9347826242446899)
[2024-11-14 09:52:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:46][root][INFO] - Training Epoch: 2/2, step 10836/16670 completed (loss: 0.20459498465061188, acc: 0.9038461446762085)
[2024-11-14 09:52:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:46][root][INFO] - Training Epoch: 2/2, step 10837/16670 completed (loss: 0.1436605602502823, acc: 0.9444444179534912)
[2024-11-14 09:52:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:47][root][INFO] - Training Epoch: 2/2, step 10838/16670 completed (loss: 0.6823281645774841, acc: 0.892307698726654)
[2024-11-14 09:52:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:47][root][INFO] - Training Epoch: 2/2, step 10839/16670 completed (loss: 0.4987233579158783, acc: 0.8928571343421936)
[2024-11-14 09:52:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:47][root][INFO] - Training Epoch: 2/2, step 10840/16670 completed (loss: 0.6422067284584045, acc: 0.8965517282485962)
[2024-11-14 09:52:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:48][root][INFO] - Training Epoch: 2/2, step 10841/16670 completed (loss: 0.6512941122055054, acc: 0.8799999952316284)
[2024-11-14 09:52:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:48][root][INFO] - Training Epoch: 2/2, step 10842/16670 completed (loss: 0.4499155879020691, acc: 0.8780487775802612)
[2024-11-14 09:52:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:48][root][INFO] - Training Epoch: 2/2, step 10843/16670 completed (loss: 0.5310865044593811, acc: 0.8793103694915771)
[2024-11-14 09:52:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:49][root][INFO] - Training Epoch: 2/2, step 10844/16670 completed (loss: 0.9335482716560364, acc: 0.7567567825317383)
[2024-11-14 09:52:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:49][root][INFO] - Training Epoch: 2/2, step 10845/16670 completed (loss: 0.36635398864746094, acc: 0.8958333134651184)
[2024-11-14 09:52:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:49][root][INFO] - Training Epoch: 2/2, step 10846/16670 completed (loss: 0.687766969203949, acc: 0.800000011920929)
[2024-11-14 09:52:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:50][root][INFO] - Training Epoch: 2/2, step 10847/16670 completed (loss: 0.16265937685966492, acc: 0.936170220375061)
[2024-11-14 09:52:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:50][root][INFO] - Training Epoch: 2/2, step 10848/16670 completed (loss: 0.11791648715734482, acc: 0.9736841917037964)
[2024-11-14 09:52:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:50][root][INFO] - Training Epoch: 2/2, step 10849/16670 completed (loss: 0.39888522028923035, acc: 0.9464285969734192)
[2024-11-14 09:52:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:51][root][INFO] - Training Epoch: 2/2, step 10850/16670 completed (loss: 0.9426564574241638, acc: 0.7647058963775635)
[2024-11-14 09:52:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:51][root][INFO] - Training Epoch: 2/2, step 10851/16670 completed (loss: 0.89772629737854, acc: 0.7727272510528564)
[2024-11-14 09:52:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:51][root][INFO] - Training Epoch: 2/2, step 10852/16670 completed (loss: 0.2623532712459564, acc: 0.9508196711540222)
[2024-11-14 09:52:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:52][root][INFO] - Training Epoch: 2/2, step 10853/16670 completed (loss: 0.5667058825492859, acc: 0.8965517282485962)
[2024-11-14 09:52:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:52][root][INFO] - Training Epoch: 2/2, step 10854/16670 completed (loss: 0.8099352717399597, acc: 0.807692289352417)
[2024-11-14 09:52:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:52][root][INFO] - Training Epoch: 2/2, step 10855/16670 completed (loss: 0.2480398416519165, acc: 0.8799999952316284)
[2024-11-14 09:52:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:53][root][INFO] - Training Epoch: 2/2, step 10856/16670 completed (loss: 0.0634252056479454, acc: 0.96875)
[2024-11-14 09:52:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:53][root][INFO] - Training Epoch: 2/2, step 10857/16670 completed (loss: 0.34258654713630676, acc: 0.8958333134651184)
[2024-11-14 09:52:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:53][root][INFO] - Training Epoch: 2/2, step 10858/16670 completed (loss: 0.23351408541202545, acc: 0.9411764740943909)
[2024-11-14 09:52:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:53][root][INFO] - Training Epoch: 2/2, step 10859/16670 completed (loss: 0.18420451879501343, acc: 0.9772727489471436)
[2024-11-14 09:52:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:54][root][INFO] - Training Epoch: 2/2, step 10860/16670 completed (loss: 0.42380842566490173, acc: 0.8333333134651184)
[2024-11-14 09:52:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:54][root][INFO] - Training Epoch: 2/2, step 10861/16670 completed (loss: 0.44262629747390747, acc: 0.9152542352676392)
[2024-11-14 09:52:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:54][root][INFO] - Training Epoch: 2/2, step 10862/16670 completed (loss: 0.24903687834739685, acc: 0.931034505367279)
[2024-11-14 09:52:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:55][root][INFO] - Training Epoch: 2/2, step 10863/16670 completed (loss: 0.20512254536151886, acc: 0.9591836929321289)
[2024-11-14 09:52:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:55][root][INFO] - Training Epoch: 2/2, step 10864/16670 completed (loss: 0.37055253982543945, acc: 0.9411764740943909)
[2024-11-14 09:52:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:55][root][INFO] - Training Epoch: 2/2, step 10865/16670 completed (loss: 0.2955799996852875, acc: 0.949999988079071)
[2024-11-14 09:52:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:56][root][INFO] - Training Epoch: 2/2, step 10866/16670 completed (loss: 0.7086343765258789, acc: 0.7884615659713745)
[2024-11-14 09:52:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:56][root][INFO] - Training Epoch: 2/2, step 10867/16670 completed (loss: 0.6189145445823669, acc: 0.8541666865348816)
[2024-11-14 09:52:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:56][root][INFO] - Training Epoch: 2/2, step 10868/16670 completed (loss: 1.0476975440979004, acc: 0.8363636136054993)
[2024-11-14 09:52:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:57][root][INFO] - Training Epoch: 2/2, step 10869/16670 completed (loss: 0.3776502311229706, acc: 0.8627451062202454)
[2024-11-14 09:52:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:57][root][INFO] - Training Epoch: 2/2, step 10870/16670 completed (loss: 0.31566470861434937, acc: 0.9074074029922485)
[2024-11-14 09:52:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:57][root][INFO] - Training Epoch: 2/2, step 10871/16670 completed (loss: 0.2902499735355377, acc: 0.9629629850387573)
[2024-11-14 09:52:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:58][root][INFO] - Training Epoch: 2/2, step 10872/16670 completed (loss: 0.24304808676242828, acc: 0.9375)
[2024-11-14 09:52:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:58][root][INFO] - Training Epoch: 2/2, step 10873/16670 completed (loss: 0.584091305732727, acc: 0.8833333253860474)
[2024-11-14 09:52:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:58][root][INFO] - Training Epoch: 2/2, step 10874/16670 completed (loss: 0.613268256187439, acc: 0.8387096524238586)
[2024-11-14 09:52:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:59][root][INFO] - Training Epoch: 2/2, step 10875/16670 completed (loss: 0.2569787800312042, acc: 0.9591836929321289)
[2024-11-14 09:52:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:59][root][INFO] - Training Epoch: 2/2, step 10876/16670 completed (loss: 0.04483180120587349, acc: 1.0)
[2024-11-14 09:52:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:52:59][root][INFO] - Training Epoch: 2/2, step 10877/16670 completed (loss: 0.7295311689376831, acc: 0.8305084705352783)
[2024-11-14 09:52:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:00][root][INFO] - Training Epoch: 2/2, step 10878/16670 completed (loss: 0.25286614894866943, acc: 0.9285714030265808)
[2024-11-14 09:53:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:00][root][INFO] - Training Epoch: 2/2, step 10879/16670 completed (loss: 0.1804187297821045, acc: 0.9411764740943909)
[2024-11-14 09:53:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:00][root][INFO] - Training Epoch: 2/2, step 10880/16670 completed (loss: 0.2448154240846634, acc: 0.9122806787490845)
[2024-11-14 09:53:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:01][root][INFO] - Training Epoch: 2/2, step 10881/16670 completed (loss: 0.12986116111278534, acc: 0.9473684430122375)
[2024-11-14 09:53:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:01][root][INFO] - Training Epoch: 2/2, step 10882/16670 completed (loss: 0.42688968777656555, acc: 0.890625)
[2024-11-14 09:53:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:01][root][INFO] - Training Epoch: 2/2, step 10883/16670 completed (loss: 0.24943001568317413, acc: 0.9230769276618958)
[2024-11-14 09:53:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:02][root][INFO] - Training Epoch: 2/2, step 10884/16670 completed (loss: 0.40001437067985535, acc: 0.918367326259613)
[2024-11-14 09:53:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:02][root][INFO] - Training Epoch: 2/2, step 10885/16670 completed (loss: 1.0080697536468506, acc: 0.800000011920929)
[2024-11-14 09:53:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:02][root][INFO] - Training Epoch: 2/2, step 10886/16670 completed (loss: 0.25295475125312805, acc: 0.9318181872367859)
[2024-11-14 09:53:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:03][root][INFO] - Training Epoch: 2/2, step 10887/16670 completed (loss: 0.20380035042762756, acc: 0.9275362491607666)
[2024-11-14 09:53:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:03][root][INFO] - Training Epoch: 2/2, step 10888/16670 completed (loss: 0.24091045558452606, acc: 0.9729729890823364)
[2024-11-14 09:53:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:04][root][INFO] - Training Epoch: 2/2, step 10889/16670 completed (loss: 0.27543026208877563, acc: 0.939393937587738)
[2024-11-14 09:53:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:04][root][INFO] - Training Epoch: 2/2, step 10890/16670 completed (loss: 0.4359494745731354, acc: 0.8780487775802612)
[2024-11-14 09:53:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:04][root][INFO] - Training Epoch: 2/2, step 10891/16670 completed (loss: 0.5992786884307861, acc: 0.8181818127632141)
[2024-11-14 09:53:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:05][root][INFO] - Training Epoch: 2/2, step 10892/16670 completed (loss: 0.43151068687438965, acc: 0.8775510191917419)
[2024-11-14 09:53:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:05][root][INFO] - Training Epoch: 2/2, step 10893/16670 completed (loss: 0.4470806419849396, acc: 0.9215686321258545)
[2024-11-14 09:53:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:05][root][INFO] - Training Epoch: 2/2, step 10894/16670 completed (loss: 0.3494694232940674, acc: 0.9354838728904724)
[2024-11-14 09:53:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:06][root][INFO] - Training Epoch: 2/2, step 10895/16670 completed (loss: 0.0766902044415474, acc: 1.0)
[2024-11-14 09:53:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:06][root][INFO] - Training Epoch: 2/2, step 10896/16670 completed (loss: 0.08799703419208527, acc: 0.9756097793579102)
[2024-11-14 09:53:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:06][root][INFO] - Training Epoch: 2/2, step 10897/16670 completed (loss: 0.27075859904289246, acc: 0.96875)
[2024-11-14 09:53:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:07][root][INFO] - Training Epoch: 2/2, step 10898/16670 completed (loss: 0.08848964422941208, acc: 0.9714285731315613)
[2024-11-14 09:53:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:07][root][INFO] - Training Epoch: 2/2, step 10899/16670 completed (loss: 0.1490529328584671, acc: 0.96875)
[2024-11-14 09:53:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:07][root][INFO] - Training Epoch: 2/2, step 10900/16670 completed (loss: 0.5547209978103638, acc: 0.8604651093482971)
[2024-11-14 09:53:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:08][root][INFO] - Training Epoch: 2/2, step 10901/16670 completed (loss: 0.45077458024024963, acc: 0.8799999952316284)
[2024-11-14 09:53:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:08][root][INFO] - Training Epoch: 2/2, step 10902/16670 completed (loss: 0.10135623812675476, acc: 0.96875)
[2024-11-14 09:53:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:09][root][INFO] - Training Epoch: 2/2, step 10903/16670 completed (loss: 0.17983943223953247, acc: 0.9491525292396545)
[2024-11-14 09:53:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:09][root][INFO] - Training Epoch: 2/2, step 10904/16670 completed (loss: 0.10532817989587784, acc: 0.9736841917037964)
[2024-11-14 09:53:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:09][root][INFO] - Training Epoch: 2/2, step 10905/16670 completed (loss: 0.10648097842931747, acc: 0.9672130942344666)
[2024-11-14 09:53:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:10][root][INFO] - Training Epoch: 2/2, step 10906/16670 completed (loss: 0.23057283461093903, acc: 0.9607843160629272)
[2024-11-14 09:53:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:10][root][INFO] - Training Epoch: 2/2, step 10907/16670 completed (loss: 0.49124497175216675, acc: 0.875)
[2024-11-14 09:53:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:10][root][INFO] - Training Epoch: 2/2, step 10908/16670 completed (loss: 0.6877495646476746, acc: 0.90625)
[2024-11-14 09:53:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:11][root][INFO] - Training Epoch: 2/2, step 10909/16670 completed (loss: 0.22723190486431122, acc: 0.8999999761581421)
[2024-11-14 09:53:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:11][root][INFO] - Training Epoch: 2/2, step 10910/16670 completed (loss: 0.044314008206129074, acc: 1.0)
[2024-11-14 09:53:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:11][root][INFO] - Training Epoch: 2/2, step 10911/16670 completed (loss: 0.2920532524585724, acc: 0.9387755393981934)
[2024-11-14 09:53:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:12][root][INFO] - Training Epoch: 2/2, step 10912/16670 completed (loss: 0.043901946395635605, acc: 1.0)
[2024-11-14 09:53:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:12][root][INFO] - Training Epoch: 2/2, step 10913/16670 completed (loss: 0.3522832989692688, acc: 0.949999988079071)
[2024-11-14 09:53:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:12][root][INFO] - Training Epoch: 2/2, step 10914/16670 completed (loss: 0.3361264765262604, acc: 0.9512194991111755)
[2024-11-14 09:53:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:13][root][INFO] - Training Epoch: 2/2, step 10915/16670 completed (loss: 0.04825692996382713, acc: 1.0)
[2024-11-14 09:53:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:13][root][INFO] - Training Epoch: 2/2, step 10916/16670 completed (loss: 0.3114984631538391, acc: 0.9482758641242981)
[2024-11-14 09:53:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:13][root][INFO] - Training Epoch: 2/2, step 10917/16670 completed (loss: 0.2695772051811218, acc: 0.9032257795333862)
[2024-11-14 09:53:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:14][root][INFO] - Training Epoch: 2/2, step 10918/16670 completed (loss: 0.4405015707015991, acc: 0.9268292784690857)
[2024-11-14 09:53:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:14][root][INFO] - Training Epoch: 2/2, step 10919/16670 completed (loss: 0.08924799412488937, acc: 1.0)
[2024-11-14 09:53:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:14][root][INFO] - Training Epoch: 2/2, step 10920/16670 completed (loss: 0.1083935871720314, acc: 0.9428571462631226)
[2024-11-14 09:53:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:15][root][INFO] - Training Epoch: 2/2, step 10921/16670 completed (loss: 0.18799200654029846, acc: 0.9487179517745972)
[2024-11-14 09:53:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:15][root][INFO] - Training Epoch: 2/2, step 10922/16670 completed (loss: 0.18032914400100708, acc: 0.9736841917037964)
[2024-11-14 09:53:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:15][root][INFO] - Training Epoch: 2/2, step 10923/16670 completed (loss: 0.46117642521858215, acc: 0.9333333373069763)
[2024-11-14 09:53:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:16][root][INFO] - Training Epoch: 2/2, step 10924/16670 completed (loss: 0.2265099287033081, acc: 0.9591836929321289)
[2024-11-14 09:53:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:16][root][INFO] - Training Epoch: 2/2, step 10925/16670 completed (loss: 0.2658001780509949, acc: 0.9729729890823364)
[2024-11-14 09:53:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:16][root][INFO] - Training Epoch: 2/2, step 10926/16670 completed (loss: 0.1687362641096115, acc: 0.9473684430122375)
[2024-11-14 09:53:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:17][root][INFO] - Training Epoch: 2/2, step 10927/16670 completed (loss: 0.15962393581867218, acc: 0.9583333134651184)
[2024-11-14 09:53:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:17][root][INFO] - Training Epoch: 2/2, step 10928/16670 completed (loss: 0.049311649054288864, acc: 0.9803921580314636)
[2024-11-14 09:53:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:17][root][INFO] - Training Epoch: 2/2, step 10929/16670 completed (loss: 0.284156858921051, acc: 0.8983050584793091)
[2024-11-14 09:53:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:18][root][INFO] - Training Epoch: 2/2, step 10930/16670 completed (loss: 0.0254818182438612, acc: 1.0)
[2024-11-14 09:53:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:18][root][INFO] - Training Epoch: 2/2, step 10931/16670 completed (loss: 0.5685939192771912, acc: 0.931034505367279)
[2024-11-14 09:53:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:18][root][INFO] - Training Epoch: 2/2, step 10932/16670 completed (loss: 0.3006359338760376, acc: 0.9545454382896423)
[2024-11-14 09:53:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:19][root][INFO] - Training Epoch: 2/2, step 10933/16670 completed (loss: 0.3117816150188446, acc: 0.9074074029922485)
[2024-11-14 09:53:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:19][root][INFO] - Training Epoch: 2/2, step 10934/16670 completed (loss: 0.022549007087945938, acc: 1.0)
[2024-11-14 09:53:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:19][root][INFO] - Training Epoch: 2/2, step 10935/16670 completed (loss: 0.48357126116752625, acc: 0.9375)
[2024-11-14 09:53:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:20][root][INFO] - Training Epoch: 2/2, step 10936/16670 completed (loss: 0.15284353494644165, acc: 0.9591836929321289)
[2024-11-14 09:53:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:20][root][INFO] - Training Epoch: 2/2, step 10937/16670 completed (loss: 0.397450715303421, acc: 0.9166666865348816)
[2024-11-14 09:53:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:20][root][INFO] - Training Epoch: 2/2, step 10938/16670 completed (loss: 1.1952924728393555, acc: 0.7222222089767456)
[2024-11-14 09:53:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:21][root][INFO] - Training Epoch: 2/2, step 10939/16670 completed (loss: 0.10291437804698944, acc: 0.9666666388511658)
[2024-11-14 09:53:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:21][root][INFO] - Training Epoch: 2/2, step 10940/16670 completed (loss: 0.29397985339164734, acc: 0.9263157844543457)
[2024-11-14 09:53:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:21][root][INFO] - Training Epoch: 2/2, step 10941/16670 completed (loss: 0.06756776571273804, acc: 1.0)
[2024-11-14 09:53:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:22][root][INFO] - Training Epoch: 2/2, step 10942/16670 completed (loss: 0.45526763796806335, acc: 0.9333333373069763)
[2024-11-14 09:53:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:22][root][INFO] - Training Epoch: 2/2, step 10943/16670 completed (loss: 1.0339462757110596, acc: 0.774193525314331)
[2024-11-14 09:53:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:22][root][INFO] - Training Epoch: 2/2, step 10944/16670 completed (loss: 0.13641253113746643, acc: 0.9777777791023254)
[2024-11-14 09:53:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:23][root][INFO] - Training Epoch: 2/2, step 10945/16670 completed (loss: 0.6548716425895691, acc: 0.8709677457809448)
[2024-11-14 09:53:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:23][root][INFO] - Training Epoch: 2/2, step 10946/16670 completed (loss: 0.3434804081916809, acc: 0.9454545378684998)
[2024-11-14 09:53:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:23][root][INFO] - Training Epoch: 2/2, step 10947/16670 completed (loss: 0.038630206137895584, acc: 1.0)
[2024-11-14 09:53:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:23][root][INFO] - Training Epoch: 2/2, step 10948/16670 completed (loss: 0.5168520212173462, acc: 0.8571428656578064)
[2024-11-14 09:53:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:24][root][INFO] - Training Epoch: 2/2, step 10949/16670 completed (loss: 0.794436514377594, acc: 0.837837815284729)
[2024-11-14 09:53:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:24][root][INFO] - Training Epoch: 2/2, step 10950/16670 completed (loss: 0.29467061161994934, acc: 0.931034505367279)
[2024-11-14 09:53:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:24][root][INFO] - Training Epoch: 2/2, step 10951/16670 completed (loss: 0.12451154738664627, acc: 0.9615384340286255)
[2024-11-14 09:53:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:25][root][INFO] - Training Epoch: 2/2, step 10952/16670 completed (loss: 0.32753801345825195, acc: 0.939393937587738)
[2024-11-14 09:53:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:25][root][INFO] - Training Epoch: 2/2, step 10953/16670 completed (loss: 0.09153936803340912, acc: 0.9850746393203735)
[2024-11-14 09:53:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:25][root][INFO] - Training Epoch: 2/2, step 10954/16670 completed (loss: 0.6466216444969177, acc: 0.9607843160629272)
[2024-11-14 09:53:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:26][root][INFO] - Training Epoch: 2/2, step 10955/16670 completed (loss: 0.7518944144248962, acc: 0.8913043737411499)
[2024-11-14 09:53:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:26][root][INFO] - Training Epoch: 2/2, step 10956/16670 completed (loss: 0.4423045217990875, acc: 0.9166666865348816)
[2024-11-14 09:53:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:26][root][INFO] - Training Epoch: 2/2, step 10957/16670 completed (loss: 0.15017549693584442, acc: 0.9661017060279846)
[2024-11-14 09:53:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:27][root][INFO] - Training Epoch: 2/2, step 10958/16670 completed (loss: 0.24589835107326508, acc: 0.9473684430122375)
[2024-11-14 09:53:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:27][root][INFO] - Training Epoch: 2/2, step 10959/16670 completed (loss: 0.04328338801860809, acc: 1.0)
[2024-11-14 09:53:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:27][root][INFO] - Training Epoch: 2/2, step 10960/16670 completed (loss: 0.20662915706634521, acc: 0.9523809552192688)
[2024-11-14 09:53:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:28][root][INFO] - Training Epoch: 2/2, step 10961/16670 completed (loss: 0.4690304696559906, acc: 0.8571428656578064)
[2024-11-14 09:53:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:28][root][INFO] - Training Epoch: 2/2, step 10962/16670 completed (loss: 0.07287397235631943, acc: 1.0)
[2024-11-14 09:53:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:28][root][INFO] - Training Epoch: 2/2, step 10963/16670 completed (loss: 0.1364397555589676, acc: 0.936170220375061)
[2024-11-14 09:53:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:29][root][INFO] - Training Epoch: 2/2, step 10964/16670 completed (loss: 0.1929563730955124, acc: 0.9583333134651184)
[2024-11-14 09:53:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:29][root][INFO] - Training Epoch: 2/2, step 10965/16670 completed (loss: 0.1148003414273262, acc: 0.9846153855323792)
[2024-11-14 09:53:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:29][root][INFO] - Training Epoch: 2/2, step 10966/16670 completed (loss: 0.5500699281692505, acc: 0.8297872543334961)
[2024-11-14 09:53:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:30][root][INFO] - Training Epoch: 2/2, step 10967/16670 completed (loss: 0.1353318840265274, acc: 0.9558823704719543)
[2024-11-14 09:53:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:30][root][INFO] - Training Epoch: 2/2, step 10968/16670 completed (loss: 0.4221884310245514, acc: 0.8888888955116272)
[2024-11-14 09:53:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:30][root][INFO] - Training Epoch: 2/2, step 10969/16670 completed (loss: 0.06886265426874161, acc: 1.0)
[2024-11-14 09:53:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:31][root][INFO] - Training Epoch: 2/2, step 10970/16670 completed (loss: 0.2086593508720398, acc: 0.9433962106704712)
[2024-11-14 09:53:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:31][root][INFO] - Training Epoch: 2/2, step 10971/16670 completed (loss: 0.17899516224861145, acc: 0.9545454382896423)
[2024-11-14 09:53:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:31][root][INFO] - Training Epoch: 2/2, step 10972/16670 completed (loss: 0.15153326094150543, acc: 0.9677419066429138)
[2024-11-14 09:53:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:32][root][INFO] - Training Epoch: 2/2, step 10973/16670 completed (loss: 0.10471982508897781, acc: 0.9629629850387573)
[2024-11-14 09:53:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:32][root][INFO] - Training Epoch: 2/2, step 10974/16670 completed (loss: 0.1377362161874771, acc: 0.9629629850387573)
[2024-11-14 09:53:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:33][root][INFO] - Training Epoch: 2/2, step 10975/16670 completed (loss: 0.22958220541477203, acc: 0.9375)
[2024-11-14 09:53:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:33][root][INFO] - Training Epoch: 2/2, step 10976/16670 completed (loss: 0.32970088720321655, acc: 0.925000011920929)
[2024-11-14 09:53:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:33][root][INFO] - Training Epoch: 2/2, step 10977/16670 completed (loss: 0.41427773237228394, acc: 0.918367326259613)
[2024-11-14 09:53:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:34][root][INFO] - Training Epoch: 2/2, step 10978/16670 completed (loss: 0.32631418108940125, acc: 0.9268292784690857)
[2024-11-14 09:53:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:34][root][INFO] - Training Epoch: 2/2, step 10979/16670 completed (loss: 0.5642129182815552, acc: 0.8500000238418579)
[2024-11-14 09:53:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:34][root][INFO] - Training Epoch: 2/2, step 10980/16670 completed (loss: 0.9439172148704529, acc: 0.8085106611251831)
[2024-11-14 09:53:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:35][root][INFO] - Training Epoch: 2/2, step 10981/16670 completed (loss: 0.5357794761657715, acc: 0.8285714387893677)
[2024-11-14 09:53:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:35][root][INFO] - Training Epoch: 2/2, step 10982/16670 completed (loss: 0.3157840371131897, acc: 0.9599999785423279)
[2024-11-14 09:53:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:35][root][INFO] - Training Epoch: 2/2, step 10983/16670 completed (loss: 0.24165767431259155, acc: 0.9454545378684998)
[2024-11-14 09:53:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:36][root][INFO] - Training Epoch: 2/2, step 10984/16670 completed (loss: 0.26570621132850647, acc: 0.9473684430122375)
[2024-11-14 09:53:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:36][root][INFO] - Training Epoch: 2/2, step 10985/16670 completed (loss: 0.426720529794693, acc: 0.936170220375061)
[2024-11-14 09:53:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:36][root][INFO] - Training Epoch: 2/2, step 10986/16670 completed (loss: 0.17848479747772217, acc: 0.9444444179534912)
[2024-11-14 09:53:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:37][root][INFO] - Training Epoch: 2/2, step 10987/16670 completed (loss: 0.3858221769332886, acc: 0.8833333253860474)
[2024-11-14 09:53:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:37][root][INFO] - Training Epoch: 2/2, step 10988/16670 completed (loss: 0.024997608736157417, acc: 1.0)
[2024-11-14 09:53:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:38][root][INFO] - Training Epoch: 2/2, step 10989/16670 completed (loss: 0.24328282475471497, acc: 0.8974359035491943)
[2024-11-14 09:53:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:38][root][INFO] - Training Epoch: 2/2, step 10990/16670 completed (loss: 0.08919394761323929, acc: 0.9729729890823364)
[2024-11-14 09:53:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:38][root][INFO] - Training Epoch: 2/2, step 10991/16670 completed (loss: 0.07529059052467346, acc: 0.9857142567634583)
[2024-11-14 09:53:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:39][root][INFO] - Training Epoch: 2/2, step 10992/16670 completed (loss: 0.1994825154542923, acc: 0.9591836929321289)
[2024-11-14 09:53:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:39][root][INFO] - Training Epoch: 2/2, step 10993/16670 completed (loss: 0.44543400406837463, acc: 0.9090909361839294)
[2024-11-14 09:53:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:39][root][INFO] - Training Epoch: 2/2, step 10994/16670 completed (loss: 0.05608806386590004, acc: 0.9803921580314636)
[2024-11-14 09:53:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:40][root][INFO] - Training Epoch: 2/2, step 10995/16670 completed (loss: 0.4395577907562256, acc: 0.8909090757369995)
[2024-11-14 09:53:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:40][root][INFO] - Training Epoch: 2/2, step 10996/16670 completed (loss: 0.6169257760047913, acc: 0.8367347121238708)
[2024-11-14 09:53:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:40][root][INFO] - Training Epoch: 2/2, step 10997/16670 completed (loss: 0.196451798081398, acc: 0.9482758641242981)
[2024-11-14 09:53:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:41][root][INFO] - Training Epoch: 2/2, step 10998/16670 completed (loss: 0.4130954444408417, acc: 0.9508196711540222)
[2024-11-14 09:53:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:41][root][INFO] - Training Epoch: 2/2, step 10999/16670 completed (loss: 0.19091443717479706, acc: 0.9344262480735779)
[2024-11-14 09:53:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:41][root][INFO] - Training Epoch: 2/2, step 11000/16670 completed (loss: 0.3490159809589386, acc: 0.8769230842590332)
[2024-11-14 09:53:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:42][root][INFO] - Training Epoch: 2/2, step 11001/16670 completed (loss: 0.09686916321516037, acc: 0.9736841917037964)
[2024-11-14 09:53:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:42][root][INFO] - Training Epoch: 2/2, step 11002/16670 completed (loss: 0.21797102689743042, acc: 0.9666666388511658)
[2024-11-14 09:53:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:42][root][INFO] - Training Epoch: 2/2, step 11003/16670 completed (loss: 0.2691134512424469, acc: 0.9642857313156128)
[2024-11-14 09:53:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:43][root][INFO] - Training Epoch: 2/2, step 11004/16670 completed (loss: 0.23342496156692505, acc: 0.9594594836235046)
[2024-11-14 09:53:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:43][root][INFO] - Training Epoch: 2/2, step 11005/16670 completed (loss: 0.34815675020217896, acc: 0.936170220375061)
[2024-11-14 09:53:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:44][root][INFO] - Training Epoch: 2/2, step 11006/16670 completed (loss: 0.2517688274383545, acc: 0.9189189076423645)
[2024-11-14 09:53:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:44][root][INFO] - Training Epoch: 2/2, step 11007/16670 completed (loss: 0.4209843575954437, acc: 0.837837815284729)
[2024-11-14 09:53:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:44][root][INFO] - Training Epoch: 2/2, step 11008/16670 completed (loss: 0.05450880527496338, acc: 1.0)
[2024-11-14 09:53:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:45][root][INFO] - Training Epoch: 2/2, step 11009/16670 completed (loss: 0.13333985209465027, acc: 0.9811320900917053)
[2024-11-14 09:53:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:45][root][INFO] - Training Epoch: 2/2, step 11010/16670 completed (loss: 0.09242355823516846, acc: 0.9487179517745972)
[2024-11-14 09:53:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:45][root][INFO] - Training Epoch: 2/2, step 11011/16670 completed (loss: 0.4632793664932251, acc: 0.8636363744735718)
[2024-11-14 09:53:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:46][root][INFO] - Training Epoch: 2/2, step 11012/16670 completed (loss: 0.12489654123783112, acc: 0.96875)
[2024-11-14 09:53:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:46][root][INFO] - Training Epoch: 2/2, step 11013/16670 completed (loss: 0.2693467438220978, acc: 0.9285714030265808)
[2024-11-14 09:53:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:46][root][INFO] - Training Epoch: 2/2, step 11014/16670 completed (loss: 0.3004007935523987, acc: 0.9387755393981934)
[2024-11-14 09:53:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:47][root][INFO] - Training Epoch: 2/2, step 11015/16670 completed (loss: 0.2664208710193634, acc: 0.9193548560142517)
[2024-11-14 09:53:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:47][root][INFO] - Training Epoch: 2/2, step 11016/16670 completed (loss: 0.2618183493614197, acc: 0.9696969985961914)
[2024-11-14 09:53:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:48][root][INFO] - Training Epoch: 2/2, step 11017/16670 completed (loss: 0.22205179929733276, acc: 0.9677419066429138)
[2024-11-14 09:53:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:48][root][INFO] - Training Epoch: 2/2, step 11018/16670 completed (loss: 0.3510242700576782, acc: 0.8765432238578796)
[2024-11-14 09:53:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:48][root][INFO] - Training Epoch: 2/2, step 11019/16670 completed (loss: 0.5330091118812561, acc: 0.8333333134651184)
[2024-11-14 09:53:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:49][root][INFO] - Training Epoch: 2/2, step 11020/16670 completed (loss: 0.19868893921375275, acc: 0.936170220375061)
[2024-11-14 09:53:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:49][root][INFO] - Training Epoch: 2/2, step 11021/16670 completed (loss: 0.078427255153656, acc: 0.9629629850387573)
[2024-11-14 09:53:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:49][root][INFO] - Training Epoch: 2/2, step 11022/16670 completed (loss: 0.38468310236930847, acc: 0.9347826242446899)
[2024-11-14 09:53:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:49][root][INFO] - Training Epoch: 2/2, step 11023/16670 completed (loss: 0.24249553680419922, acc: 0.9591836929321289)
[2024-11-14 09:53:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:50][root][INFO] - Training Epoch: 2/2, step 11024/16670 completed (loss: 0.2337569296360016, acc: 0.9090909361839294)
[2024-11-14 09:53:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:50][root][INFO] - Training Epoch: 2/2, step 11025/16670 completed (loss: 0.34985238313674927, acc: 0.9166666865348816)
[2024-11-14 09:53:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:50][root][INFO] - Training Epoch: 2/2, step 11026/16670 completed (loss: 0.34069323539733887, acc: 0.9411764740943909)
[2024-11-14 09:53:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:51][root][INFO] - Training Epoch: 2/2, step 11027/16670 completed (loss: 0.18997524678707123, acc: 0.9200000166893005)
[2024-11-14 09:53:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:51][root][INFO] - Training Epoch: 2/2, step 11028/16670 completed (loss: 0.4583352208137512, acc: 0.936170220375061)
[2024-11-14 09:53:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:51][root][INFO] - Training Epoch: 2/2, step 11029/16670 completed (loss: 0.6284040212631226, acc: 0.930232584476471)
[2024-11-14 09:53:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:52][root][INFO] - Training Epoch: 2/2, step 11030/16670 completed (loss: 0.4748980402946472, acc: 0.9200000166893005)
[2024-11-14 09:53:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:52][root][INFO] - Training Epoch: 2/2, step 11031/16670 completed (loss: 0.11575628072023392, acc: 0.9756097793579102)
[2024-11-14 09:53:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:52][root][INFO] - Training Epoch: 2/2, step 11032/16670 completed (loss: 0.030583463609218597, acc: 1.0)
[2024-11-14 09:53:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:53][root][INFO] - Training Epoch: 2/2, step 11033/16670 completed (loss: 0.4871959984302521, acc: 0.9555555582046509)
[2024-11-14 09:53:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:53][root][INFO] - Training Epoch: 2/2, step 11034/16670 completed (loss: 0.42596104741096497, acc: 0.9024389982223511)
[2024-11-14 09:53:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:53][root][INFO] - Training Epoch: 2/2, step 11035/16670 completed (loss: 0.14176583290100098, acc: 0.96875)
[2024-11-14 09:53:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:54][root][INFO] - Training Epoch: 2/2, step 11036/16670 completed (loss: 0.28590771555900574, acc: 0.936170220375061)
[2024-11-14 09:53:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:54][root][INFO] - Training Epoch: 2/2, step 11037/16670 completed (loss: 0.1869836002588272, acc: 0.9200000166893005)
[2024-11-14 09:53:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:54][root][INFO] - Training Epoch: 2/2, step 11038/16670 completed (loss: 0.42964377999305725, acc: 0.8846153616905212)
[2024-11-14 09:53:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:55][root][INFO] - Training Epoch: 2/2, step 11039/16670 completed (loss: 0.13370513916015625, acc: 0.9767441749572754)
[2024-11-14 09:53:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:55][root][INFO] - Training Epoch: 2/2, step 11040/16670 completed (loss: 0.10243576765060425, acc: 0.9636363387107849)
[2024-11-14 09:53:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:55][root][INFO] - Training Epoch: 2/2, step 11041/16670 completed (loss: 0.2313864827156067, acc: 0.9259259104728699)
[2024-11-14 09:53:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:56][root][INFO] - Training Epoch: 2/2, step 11042/16670 completed (loss: 0.13550618290901184, acc: 0.9605262875556946)
[2024-11-14 09:53:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:56][root][INFO] - Training Epoch: 2/2, step 11043/16670 completed (loss: 0.2670885920524597, acc: 0.9591836929321289)
[2024-11-14 09:53:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:56][root][INFO] - Training Epoch: 2/2, step 11044/16670 completed (loss: 0.44178110361099243, acc: 0.8888888955116272)
[2024-11-14 09:53:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:57][root][INFO] - Training Epoch: 2/2, step 11045/16670 completed (loss: 0.21879848837852478, acc: 0.9464285969734192)
[2024-11-14 09:53:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:57][root][INFO] - Training Epoch: 2/2, step 11046/16670 completed (loss: 0.04769248142838478, acc: 1.0)
[2024-11-14 09:53:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:57][root][INFO] - Training Epoch: 2/2, step 11047/16670 completed (loss: 0.2865355610847473, acc: 0.9433962106704712)
[2024-11-14 09:53:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:58][root][INFO] - Training Epoch: 2/2, step 11048/16670 completed (loss: 0.2856355309486389, acc: 0.9375)
[2024-11-14 09:53:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:58][root][INFO] - Training Epoch: 2/2, step 11049/16670 completed (loss: 0.1960083693265915, acc: 0.9622641801834106)
[2024-11-14 09:53:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:58][root][INFO] - Training Epoch: 2/2, step 11050/16670 completed (loss: 0.2053373008966446, acc: 0.9677419066429138)
[2024-11-14 09:53:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:59][root][INFO] - Training Epoch: 2/2, step 11051/16670 completed (loss: 0.02116246335208416, acc: 1.0)
[2024-11-14 09:53:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:59][root][INFO] - Training Epoch: 2/2, step 11052/16670 completed (loss: 0.09658846259117126, acc: 0.9555555582046509)
[2024-11-14 09:53:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:53:59][root][INFO] - Training Epoch: 2/2, step 11053/16670 completed (loss: 0.05821974575519562, acc: 0.9857142567634583)
[2024-11-14 09:54:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:00][root][INFO] - Training Epoch: 2/2, step 11054/16670 completed (loss: 0.292328417301178, acc: 0.9038461446762085)
[2024-11-14 09:54:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:00][root][INFO] - Training Epoch: 2/2, step 11055/16670 completed (loss: 0.08436547964811325, acc: 1.0)
[2024-11-14 09:54:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:00][root][INFO] - Training Epoch: 2/2, step 11056/16670 completed (loss: 0.21511609852313995, acc: 0.9411764740943909)
[2024-11-14 09:54:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:01][root][INFO] - Training Epoch: 2/2, step 11057/16670 completed (loss: 0.19444851577281952, acc: 0.9636363387107849)
[2024-11-14 09:54:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:01][root][INFO] - Training Epoch: 2/2, step 11058/16670 completed (loss: 0.09362650662660599, acc: 0.9807692170143127)
[2024-11-14 09:54:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:01][root][INFO] - Training Epoch: 2/2, step 11059/16670 completed (loss: 0.5329145789146423, acc: 0.8571428656578064)
[2024-11-14 09:54:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:02][root][INFO] - Training Epoch: 2/2, step 11060/16670 completed (loss: 0.3643151819705963, acc: 0.9344262480735779)
[2024-11-14 09:54:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:02][root][INFO] - Training Epoch: 2/2, step 11061/16670 completed (loss: 0.12560290098190308, acc: 0.9791666865348816)
[2024-11-14 09:54:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:03][root][INFO] - Training Epoch: 2/2, step 11062/16670 completed (loss: 0.5183907151222229, acc: 0.8717948794364929)
[2024-11-14 09:54:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:03][root][INFO] - Training Epoch: 2/2, step 11063/16670 completed (loss: 0.4066678583621979, acc: 0.9444444179534912)
[2024-11-14 09:54:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:03][root][INFO] - Training Epoch: 2/2, step 11064/16670 completed (loss: 0.22835272550582886, acc: 0.942307710647583)
[2024-11-14 09:54:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:04][root][INFO] - Training Epoch: 2/2, step 11065/16670 completed (loss: 0.09361506998538971, acc: 1.0)
[2024-11-14 09:54:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:04][root][INFO] - Training Epoch: 2/2, step 11066/16670 completed (loss: 0.11359326541423798, acc: 0.97826087474823)
[2024-11-14 09:54:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:04][root][INFO] - Training Epoch: 2/2, step 11067/16670 completed (loss: 0.4088386297225952, acc: 0.8095238208770752)
[2024-11-14 09:54:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:05][root][INFO] - Training Epoch: 2/2, step 11068/16670 completed (loss: 0.1453007310628891, acc: 0.949999988079071)
[2024-11-14 09:54:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:05][root][INFO] - Training Epoch: 2/2, step 11069/16670 completed (loss: 0.12970967590808868, acc: 0.9512194991111755)
[2024-11-14 09:54:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:05][root][INFO] - Training Epoch: 2/2, step 11070/16670 completed (loss: 0.41405099630355835, acc: 0.9259259104728699)
[2024-11-14 09:54:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:06][root][INFO] - Training Epoch: 2/2, step 11071/16670 completed (loss: 0.2597818970680237, acc: 0.957446813583374)
[2024-11-14 09:54:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:06][root][INFO] - Training Epoch: 2/2, step 11072/16670 completed (loss: 0.17836681008338928, acc: 0.9518072009086609)
[2024-11-14 09:54:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:06][root][INFO] - Training Epoch: 2/2, step 11073/16670 completed (loss: 0.059664640575647354, acc: 1.0)
[2024-11-14 09:54:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:06][root][INFO] - Training Epoch: 2/2, step 11074/16670 completed (loss: 0.2712242305278778, acc: 0.931506872177124)
[2024-11-14 09:54:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:07][root][INFO] - Training Epoch: 2/2, step 11075/16670 completed (loss: 0.147820383310318, acc: 0.95652174949646)
[2024-11-14 09:54:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:07][root][INFO] - Training Epoch: 2/2, step 11076/16670 completed (loss: 0.295643150806427, acc: 0.9090909361839294)
[2024-11-14 09:54:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:07][root][INFO] - Training Epoch: 2/2, step 11077/16670 completed (loss: 0.11770691722631454, acc: 0.9682539701461792)
[2024-11-14 09:54:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:08][root][INFO] - Training Epoch: 2/2, step 11078/16670 completed (loss: 0.26675575971603394, acc: 0.9333333373069763)
[2024-11-14 09:54:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:08][root][INFO] - Training Epoch: 2/2, step 11079/16670 completed (loss: 0.16489338874816895, acc: 0.9534883499145508)
[2024-11-14 09:54:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:08][root][INFO] - Training Epoch: 2/2, step 11080/16670 completed (loss: 0.1791319102048874, acc: 0.9508196711540222)
[2024-11-14 09:54:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:09][root][INFO] - Training Epoch: 2/2, step 11081/16670 completed (loss: 0.09490393102169037, acc: 1.0)
[2024-11-14 09:54:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:09][root][INFO] - Training Epoch: 2/2, step 11082/16670 completed (loss: 0.4736008644104004, acc: 0.8999999761581421)
[2024-11-14 09:54:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:09][root][INFO] - Training Epoch: 2/2, step 11083/16670 completed (loss: 0.07237979769706726, acc: 0.982758641242981)
[2024-11-14 09:54:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:10][root][INFO] - Training Epoch: 2/2, step 11084/16670 completed (loss: 0.47165217995643616, acc: 0.9285714030265808)
[2024-11-14 09:54:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:10][root][INFO] - Training Epoch: 2/2, step 11085/16670 completed (loss: 0.3179301917552948, acc: 0.9074074029922485)
[2024-11-14 09:54:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:11][root][INFO] - Training Epoch: 2/2, step 11086/16670 completed (loss: 0.07474498450756073, acc: 1.0)
[2024-11-14 09:54:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:11][root][INFO] - Training Epoch: 2/2, step 11087/16670 completed (loss: 0.10320601612329483, acc: 0.9607843160629272)
[2024-11-14 09:54:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:11][root][INFO] - Training Epoch: 2/2, step 11088/16670 completed (loss: 0.3268056809902191, acc: 0.8999999761581421)
[2024-11-14 09:54:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:12][root][INFO] - Training Epoch: 2/2, step 11089/16670 completed (loss: 0.43816274404525757, acc: 0.939393937587738)
[2024-11-14 09:54:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:12][root][INFO] - Training Epoch: 2/2, step 11090/16670 completed (loss: 0.019616875797510147, acc: 1.0)
[2024-11-14 09:54:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:12][root][INFO] - Training Epoch: 2/2, step 11091/16670 completed (loss: 0.20471817255020142, acc: 0.9622641801834106)
[2024-11-14 09:54:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:13][root][INFO] - Training Epoch: 2/2, step 11092/16670 completed (loss: 0.04644469916820526, acc: 0.98591548204422)
[2024-11-14 09:54:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:13][root][INFO] - Training Epoch: 2/2, step 11093/16670 completed (loss: 0.0994846373796463, acc: 0.9545454382896423)
[2024-11-14 09:54:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:13][root][INFO] - Training Epoch: 2/2, step 11094/16670 completed (loss: 0.17655988037586212, acc: 0.9032257795333862)
[2024-11-14 09:54:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:14][root][INFO] - Training Epoch: 2/2, step 11095/16670 completed (loss: 0.18923385441303253, acc: 0.9615384340286255)
[2024-11-14 09:54:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:14][root][INFO] - Training Epoch: 2/2, step 11096/16670 completed (loss: 0.11828111857175827, acc: 0.9452054500579834)
[2024-11-14 09:54:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:14][root][INFO] - Training Epoch: 2/2, step 11097/16670 completed (loss: 0.4254361689090729, acc: 0.9019607901573181)
[2024-11-14 09:54:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:15][root][INFO] - Training Epoch: 2/2, step 11098/16670 completed (loss: 0.13652051985263824, acc: 0.9672130942344666)
[2024-11-14 09:54:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:15][root][INFO] - Training Epoch: 2/2, step 11099/16670 completed (loss: 0.23423078656196594, acc: 0.95652174949646)
[2024-11-14 09:54:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:15][root][INFO] - Training Epoch: 2/2, step 11100/16670 completed (loss: 0.2212878167629242, acc: 0.9599999785423279)
[2024-11-14 09:54:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:16][root][INFO] - Training Epoch: 2/2, step 11101/16670 completed (loss: 0.10191300511360168, acc: 0.9777777791023254)
[2024-11-14 09:54:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:16][root][INFO] - Training Epoch: 2/2, step 11102/16670 completed (loss: 0.29875656962394714, acc: 0.8965517282485962)
[2024-11-14 09:54:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:16][root][INFO] - Training Epoch: 2/2, step 11103/16670 completed (loss: 0.4060593545436859, acc: 0.9375)
[2024-11-14 09:54:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:17][root][INFO] - Training Epoch: 2/2, step 11104/16670 completed (loss: 0.4227488934993744, acc: 0.8999999761581421)
[2024-11-14 09:54:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:17][root][INFO] - Training Epoch: 2/2, step 11105/16670 completed (loss: 0.6731577515602112, acc: 0.9344262480735779)
[2024-11-14 09:54:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:17][root][INFO] - Training Epoch: 2/2, step 11106/16670 completed (loss: 0.10836084187030792, acc: 0.9821428656578064)
[2024-11-14 09:54:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:17][root][INFO] - Training Epoch: 2/2, step 11107/16670 completed (loss: 0.12580092251300812, acc: 0.9459459185600281)
[2024-11-14 09:54:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:18][root][INFO] - Training Epoch: 2/2, step 11108/16670 completed (loss: 0.21082864701747894, acc: 0.9333333373069763)
[2024-11-14 09:54:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:18][root][INFO] - Training Epoch: 2/2, step 11109/16670 completed (loss: 0.060394030064344406, acc: 0.978723406791687)
[2024-11-14 09:54:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:18][root][INFO] - Training Epoch: 2/2, step 11110/16670 completed (loss: 0.27107250690460205, acc: 0.9523809552192688)
[2024-11-14 09:54:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:19][root][INFO] - Training Epoch: 2/2, step 11111/16670 completed (loss: 0.5438442230224609, acc: 0.875)
[2024-11-14 09:54:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:19][root][INFO] - Training Epoch: 2/2, step 11112/16670 completed (loss: 0.08305273950099945, acc: 0.9459459185600281)
[2024-11-14 09:54:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:19][root][INFO] - Training Epoch: 2/2, step 11113/16670 completed (loss: 0.014177132397890091, acc: 1.0)
[2024-11-14 09:54:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:19][root][INFO] - Training Epoch: 2/2, step 11114/16670 completed (loss: 0.24437828361988068, acc: 0.9666666388511658)
[2024-11-14 09:54:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:20][root][INFO] - Training Epoch: 2/2, step 11115/16670 completed (loss: 0.028820175677537918, acc: 1.0)
[2024-11-14 09:54:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:20][root][INFO] - Training Epoch: 2/2, step 11116/16670 completed (loss: 0.2639785408973694, acc: 0.95652174949646)
[2024-11-14 09:54:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:20][root][INFO] - Training Epoch: 2/2, step 11117/16670 completed (loss: 0.313929945230484, acc: 0.9375)
[2024-11-14 09:54:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:21][root][INFO] - Training Epoch: 2/2, step 11118/16670 completed (loss: 0.03502044826745987, acc: 0.976190447807312)
[2024-11-14 09:54:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:21][root][INFO] - Training Epoch: 2/2, step 11119/16670 completed (loss: 0.09004654735326767, acc: 1.0)
[2024-11-14 09:54:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:21][root][INFO] - Training Epoch: 2/2, step 11120/16670 completed (loss: 0.027699261903762817, acc: 1.0)
[2024-11-14 09:54:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:22][root][INFO] - Training Epoch: 2/2, step 11121/16670 completed (loss: 0.9700337648391724, acc: 0.890625)
[2024-11-14 09:54:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:22][root][INFO] - Training Epoch: 2/2, step 11122/16670 completed (loss: 0.3510923683643341, acc: 0.9322034120559692)
[2024-11-14 09:54:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:22][root][INFO] - Training Epoch: 2/2, step 11123/16670 completed (loss: 0.20296478271484375, acc: 0.9375)
[2024-11-14 09:54:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:23][root][INFO] - Training Epoch: 2/2, step 11124/16670 completed (loss: 0.6165378093719482, acc: 0.9102563858032227)
[2024-11-14 09:54:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:23][root][INFO] - Training Epoch: 2/2, step 11125/16670 completed (loss: 0.13982628285884857, acc: 0.9411764740943909)
[2024-11-14 09:54:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:23][root][INFO] - Training Epoch: 2/2, step 11126/16670 completed (loss: 0.3901735246181488, acc: 0.931034505367279)
[2024-11-14 09:54:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:24][root][INFO] - Training Epoch: 2/2, step 11127/16670 completed (loss: 0.5124271512031555, acc: 0.8695651888847351)
[2024-11-14 09:54:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:24][root][INFO] - Training Epoch: 2/2, step 11128/16670 completed (loss: 0.10924304276704788, acc: 0.9756097793579102)
[2024-11-14 09:54:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:24][root][INFO] - Training Epoch: 2/2, step 11129/16670 completed (loss: 0.35867592692375183, acc: 0.8888888955116272)
[2024-11-14 09:54:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:25][root][INFO] - Training Epoch: 2/2, step 11130/16670 completed (loss: 0.04112061858177185, acc: 1.0)
[2024-11-14 09:54:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:25][root][INFO] - Training Epoch: 2/2, step 11131/16670 completed (loss: 0.17831295728683472, acc: 0.9629629850387573)
[2024-11-14 09:54:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:25][root][INFO] - Training Epoch: 2/2, step 11132/16670 completed (loss: 0.43559354543685913, acc: 0.9333333373069763)
[2024-11-14 09:54:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:26][root][INFO] - Training Epoch: 2/2, step 11133/16670 completed (loss: 0.1262572705745697, acc: 0.976190447807312)
[2024-11-14 09:54:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:26][root][INFO] - Training Epoch: 2/2, step 11134/16670 completed (loss: 0.050114117562770844, acc: 1.0)
[2024-11-14 09:54:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:26][root][INFO] - Training Epoch: 2/2, step 11135/16670 completed (loss: 0.03477116674184799, acc: 1.0)
[2024-11-14 09:54:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:27][root][INFO] - Training Epoch: 2/2, step 11136/16670 completed (loss: 0.21490105986595154, acc: 0.9555555582046509)
[2024-11-14 09:54:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:27][root][INFO] - Training Epoch: 2/2, step 11137/16670 completed (loss: 0.1294887810945511, acc: 0.9743589758872986)
[2024-11-14 09:54:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:27][root][INFO] - Training Epoch: 2/2, step 11138/16670 completed (loss: 0.1646880805492401, acc: 0.9642857313156128)
[2024-11-14 09:54:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:28][root][INFO] - Training Epoch: 2/2, step 11139/16670 completed (loss: 0.21872861683368683, acc: 0.9512194991111755)
[2024-11-14 09:54:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:28][root][INFO] - Training Epoch: 2/2, step 11140/16670 completed (loss: 0.4407065510749817, acc: 0.9016393423080444)
[2024-11-14 09:54:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:28][root][INFO] - Training Epoch: 2/2, step 11141/16670 completed (loss: 0.13861851394176483, acc: 0.95652174949646)
[2024-11-14 09:54:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:29][root][INFO] - Training Epoch: 2/2, step 11142/16670 completed (loss: 0.13416628539562225, acc: 0.9736841917037964)
[2024-11-14 09:54:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:29][root][INFO] - Training Epoch: 2/2, step 11143/16670 completed (loss: 0.016320431604981422, acc: 1.0)
[2024-11-14 09:54:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:29][root][INFO] - Training Epoch: 2/2, step 11144/16670 completed (loss: 0.1659252792596817, acc: 0.9629629850387573)
[2024-11-14 09:54:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:30][root][INFO] - Training Epoch: 2/2, step 11145/16670 completed (loss: 0.020699527114629745, acc: 1.0)
[2024-11-14 09:54:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:30][root][INFO] - Training Epoch: 2/2, step 11146/16670 completed (loss: 0.013106531463563442, acc: 1.0)
[2024-11-14 09:54:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:30][root][INFO] - Training Epoch: 2/2, step 11147/16670 completed (loss: 0.12119220942258835, acc: 0.9375)
[2024-11-14 09:54:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:31][root][INFO] - Training Epoch: 2/2, step 11148/16670 completed (loss: 0.40120115876197815, acc: 0.9215686321258545)
[2024-11-14 09:54:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:31][root][INFO] - Training Epoch: 2/2, step 11149/16670 completed (loss: 0.40892523527145386, acc: 0.9189189076423645)
[2024-11-14 09:54:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:31][root][INFO] - Training Epoch: 2/2, step 11150/16670 completed (loss: 0.21284028887748718, acc: 0.96875)
[2024-11-14 09:54:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:32][root][INFO] - Training Epoch: 2/2, step 11151/16670 completed (loss: 0.18654407560825348, acc: 0.9399999976158142)
[2024-11-14 09:54:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:32][root][INFO] - Training Epoch: 2/2, step 11152/16670 completed (loss: 0.5337539315223694, acc: 0.9230769276618958)
[2024-11-14 09:54:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:32][root][INFO] - Training Epoch: 2/2, step 11153/16670 completed (loss: 0.10085586458444595, acc: 0.9523809552192688)
[2024-11-14 09:54:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:33][root][INFO] - Training Epoch: 2/2, step 11154/16670 completed (loss: 0.09384433925151825, acc: 0.9607843160629272)
[2024-11-14 09:54:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:33][root][INFO] - Training Epoch: 2/2, step 11155/16670 completed (loss: 0.13355261087417603, acc: 0.9800000190734863)
[2024-11-14 09:54:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:33][root][INFO] - Training Epoch: 2/2, step 11156/16670 completed (loss: 0.09934442490339279, acc: 0.9642857313156128)
[2024-11-14 09:54:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:34][root][INFO] - Training Epoch: 2/2, step 11157/16670 completed (loss: 0.14178580045700073, acc: 0.9428571462631226)
[2024-11-14 09:54:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:34][root][INFO] - Training Epoch: 2/2, step 11158/16670 completed (loss: 0.269849568605423, acc: 0.9275362491607666)
[2024-11-14 09:54:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:34][root][INFO] - Training Epoch: 2/2, step 11159/16670 completed (loss: 0.10275189578533173, acc: 0.9800000190734863)
[2024-11-14 09:54:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:35][root][INFO] - Training Epoch: 2/2, step 11160/16670 completed (loss: 0.16330307722091675, acc: 0.9512194991111755)
[2024-11-14 09:54:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:35][root][INFO] - Training Epoch: 2/2, step 11161/16670 completed (loss: 0.11022432893514633, acc: 0.978723406791687)
[2024-11-14 09:54:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:35][root][INFO] - Training Epoch: 2/2, step 11162/16670 completed (loss: 0.5913107991218567, acc: 0.90625)
[2024-11-14 09:54:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:36][root][INFO] - Training Epoch: 2/2, step 11163/16670 completed (loss: 0.39287304878234863, acc: 0.8571428656578064)
[2024-11-14 09:54:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:36][root][INFO] - Training Epoch: 2/2, step 11164/16670 completed (loss: 0.18445934355258942, acc: 0.9491525292396545)
[2024-11-14 09:54:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:36][root][INFO] - Training Epoch: 2/2, step 11165/16670 completed (loss: 0.19197465479373932, acc: 0.9230769276618958)
[2024-11-14 09:54:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:37][root][INFO] - Training Epoch: 2/2, step 11166/16670 completed (loss: 0.021317750215530396, acc: 1.0)
[2024-11-14 09:54:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:37][root][INFO] - Training Epoch: 2/2, step 11167/16670 completed (loss: 0.13906626403331757, acc: 0.9696969985961914)
[2024-11-14 09:54:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:37][root][INFO] - Training Epoch: 2/2, step 11168/16670 completed (loss: 0.2497321516275406, acc: 0.9375)
[2024-11-14 09:54:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:38][root][INFO] - Training Epoch: 2/2, step 11169/16670 completed (loss: 0.1609940528869629, acc: 0.9399999976158142)
[2024-11-14 09:54:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:38][root][INFO] - Training Epoch: 2/2, step 11170/16670 completed (loss: 0.32403063774108887, acc: 0.8823529481887817)
[2024-11-14 09:54:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:38][root][INFO] - Training Epoch: 2/2, step 11171/16670 completed (loss: 0.2208678424358368, acc: 0.95652174949646)
[2024-11-14 09:54:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:39][root][INFO] - Training Epoch: 2/2, step 11172/16670 completed (loss: 0.08555024117231369, acc: 0.9736841917037964)
[2024-11-14 09:54:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:39][root][INFO] - Training Epoch: 2/2, step 11173/16670 completed (loss: 0.18836863338947296, acc: 0.970588207244873)
[2024-11-14 09:54:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:40][root][INFO] - Training Epoch: 2/2, step 11174/16670 completed (loss: 0.03637482598423958, acc: 1.0)
[2024-11-14 09:54:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:40][root][INFO] - Training Epoch: 2/2, step 11175/16670 completed (loss: 0.03256014361977577, acc: 1.0)
[2024-11-14 09:54:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:40][root][INFO] - Training Epoch: 2/2, step 11176/16670 completed (loss: 0.3764006495475769, acc: 0.95652174949646)
[2024-11-14 09:54:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:41][root][INFO] - Training Epoch: 2/2, step 11177/16670 completed (loss: 0.16794300079345703, acc: 0.9655172228813171)
[2024-11-14 09:54:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:41][root][INFO] - Training Epoch: 2/2, step 11178/16670 completed (loss: 0.49396267533302307, acc: 0.8684210777282715)
[2024-11-14 09:54:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:41][root][INFO] - Training Epoch: 2/2, step 11179/16670 completed (loss: 0.2859645187854767, acc: 0.9722222089767456)
[2024-11-14 09:54:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:42][root][INFO] - Training Epoch: 2/2, step 11180/16670 completed (loss: 0.2805154025554657, acc: 0.9268292784690857)
[2024-11-14 09:54:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:42][root][INFO] - Training Epoch: 2/2, step 11181/16670 completed (loss: 0.10458323359489441, acc: 0.9767441749572754)
[2024-11-14 09:54:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:42][root][INFO] - Training Epoch: 2/2, step 11182/16670 completed (loss: 0.31673571467399597, acc: 0.8695651888847351)
[2024-11-14 09:54:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:43][root][INFO] - Training Epoch: 2/2, step 11183/16670 completed (loss: 0.022005146369338036, acc: 1.0)
[2024-11-14 09:54:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:43][root][INFO] - Training Epoch: 2/2, step 11184/16670 completed (loss: 0.20644289255142212, acc: 0.9130434989929199)
[2024-11-14 09:54:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:43][root][INFO] - Training Epoch: 2/2, step 11185/16670 completed (loss: 0.22130562365055084, acc: 0.90625)
[2024-11-14 09:54:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:44][root][INFO] - Training Epoch: 2/2, step 11186/16670 completed (loss: 0.009676442481577396, acc: 1.0)
[2024-11-14 09:54:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:44][root][INFO] - Training Epoch: 2/2, step 11187/16670 completed (loss: 0.13915500044822693, acc: 0.95652174949646)
[2024-11-14 09:54:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:44][root][INFO] - Training Epoch: 2/2, step 11188/16670 completed (loss: 0.22298000752925873, acc: 0.9512194991111755)
[2024-11-14 09:54:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:45][root][INFO] - Training Epoch: 2/2, step 11189/16670 completed (loss: 0.18683567643165588, acc: 0.95652174949646)
[2024-11-14 09:54:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:45][root][INFO] - Training Epoch: 2/2, step 11190/16670 completed (loss: 0.7306346297264099, acc: 0.8648648858070374)
[2024-11-14 09:54:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:45][root][INFO] - Training Epoch: 2/2, step 11191/16670 completed (loss: 0.6410930156707764, acc: 0.9459459185600281)
[2024-11-14 09:54:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:46][root][INFO] - Training Epoch: 2/2, step 11192/16670 completed (loss: 0.37820351123809814, acc: 0.9166666865348816)
[2024-11-14 09:54:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:46][root][INFO] - Training Epoch: 2/2, step 11193/16670 completed (loss: 0.4224444627761841, acc: 0.9090909361839294)
[2024-11-14 09:54:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:46][root][INFO] - Training Epoch: 2/2, step 11194/16670 completed (loss: 0.052504442632198334, acc: 0.95652174949646)
[2024-11-14 09:54:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:47][root][INFO] - Training Epoch: 2/2, step 11195/16670 completed (loss: 0.45467883348464966, acc: 0.9253731369972229)
[2024-11-14 09:54:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:47][root][INFO] - Training Epoch: 2/2, step 11196/16670 completed (loss: 0.24955064058303833, acc: 0.918367326259613)
[2024-11-14 09:54:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:47][root][INFO] - Training Epoch: 2/2, step 11197/16670 completed (loss: 0.2611963748931885, acc: 0.96875)
[2024-11-14 09:54:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:48][root][INFO] - Training Epoch: 2/2, step 11198/16670 completed (loss: 0.24253049492835999, acc: 0.925000011920929)
[2024-11-14 09:54:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:48][root][INFO] - Training Epoch: 2/2, step 11199/16670 completed (loss: 0.1315586268901825, acc: 0.9512194991111755)
[2024-11-14 09:54:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:48][root][INFO] - Training Epoch: 2/2, step 11200/16670 completed (loss: 0.22505244612693787, acc: 0.9696969985961914)
[2024-11-14 09:54:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:49][root][INFO] - Training Epoch: 2/2, step 11201/16670 completed (loss: 0.09053411334753036, acc: 1.0)
[2024-11-14 09:54:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:49][root][INFO] - Training Epoch: 2/2, step 11202/16670 completed (loss: 0.4095832109451294, acc: 0.9130434989929199)
[2024-11-14 09:54:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:49][root][INFO] - Training Epoch: 2/2, step 11203/16670 completed (loss: 0.2845057249069214, acc: 0.8947368264198303)
[2024-11-14 09:54:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:50][root][INFO] - Training Epoch: 2/2, step 11204/16670 completed (loss: 0.25803133845329285, acc: 0.931034505367279)
[2024-11-14 09:54:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:50][root][INFO] - Training Epoch: 2/2, step 11205/16670 completed (loss: 0.023106517270207405, acc: 1.0)
[2024-11-14 09:54:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:50][root][INFO] - Training Epoch: 2/2, step 11206/16670 completed (loss: 0.2800053060054779, acc: 0.9555555582046509)
[2024-11-14 09:54:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:51][root][INFO] - Training Epoch: 2/2, step 11207/16670 completed (loss: 0.4270516335964203, acc: 0.8860759735107422)
[2024-11-14 09:54:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:51][root][INFO] - Training Epoch: 2/2, step 11208/16670 completed (loss: 0.22738225758075714, acc: 0.9428571462631226)
[2024-11-14 09:54:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:51][root][INFO] - Training Epoch: 2/2, step 11209/16670 completed (loss: 0.3236587345600128, acc: 0.918367326259613)
[2024-11-14 09:54:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:52][root][INFO] - Training Epoch: 2/2, step 11210/16670 completed (loss: 0.2797563374042511, acc: 0.9473684430122375)
[2024-11-14 09:54:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:52][root][INFO] - Training Epoch: 2/2, step 11211/16670 completed (loss: 0.03944380208849907, acc: 1.0)
[2024-11-14 09:54:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:52][root][INFO] - Training Epoch: 2/2, step 11212/16670 completed (loss: 0.32892075181007385, acc: 0.8928571343421936)
[2024-11-14 09:54:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:53][root][INFO] - Training Epoch: 2/2, step 11213/16670 completed (loss: 0.20237916707992554, acc: 0.95652174949646)
[2024-11-14 09:54:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:53][root][INFO] - Training Epoch: 2/2, step 11214/16670 completed (loss: 0.33595505356788635, acc: 0.8888888955116272)
[2024-11-14 09:54:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:53][root][INFO] - Training Epoch: 2/2, step 11215/16670 completed (loss: 0.2136220932006836, acc: 0.9444444179534912)
[2024-11-14 09:54:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:54][root][INFO] - Training Epoch: 2/2, step 11216/16670 completed (loss: 0.10605985671281815, acc: 0.9523809552192688)
[2024-11-14 09:54:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:54][root][INFO] - Training Epoch: 2/2, step 11217/16670 completed (loss: 0.12950755655765533, acc: 0.97826087474823)
[2024-11-14 09:54:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:54][root][INFO] - Training Epoch: 2/2, step 11218/16670 completed (loss: 0.3135679364204407, acc: 0.9333333373069763)
[2024-11-14 09:54:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:55][root][INFO] - Training Epoch: 2/2, step 11219/16670 completed (loss: 0.0325436145067215, acc: 1.0)
[2024-11-14 09:54:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:55][root][INFO] - Training Epoch: 2/2, step 11220/16670 completed (loss: 0.052643224596977234, acc: 0.9800000190734863)
[2024-11-14 09:54:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:55][root][INFO] - Training Epoch: 2/2, step 11221/16670 completed (loss: 0.5460822582244873, acc: 0.8965517282485962)
[2024-11-14 09:54:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:56][root][INFO] - Training Epoch: 2/2, step 11222/16670 completed (loss: 0.3345175087451935, acc: 0.9473684430122375)
[2024-11-14 09:54:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:56][root][INFO] - Training Epoch: 2/2, step 11223/16670 completed (loss: 0.537653386592865, acc: 0.8985507488250732)
[2024-11-14 09:54:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:56][root][INFO] - Training Epoch: 2/2, step 11224/16670 completed (loss: 0.6149348020553589, acc: 0.8648648858070374)
[2024-11-14 09:54:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:57][root][INFO] - Training Epoch: 2/2, step 11225/16670 completed (loss: 0.3295319676399231, acc: 0.949999988079071)
[2024-11-14 09:54:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:57][root][INFO] - Training Epoch: 2/2, step 11226/16670 completed (loss: 0.12493208795785904, acc: 0.9800000190734863)
[2024-11-14 09:54:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:57][root][INFO] - Training Epoch: 2/2, step 11227/16670 completed (loss: 0.0766301229596138, acc: 0.9666666388511658)
[2024-11-14 09:54:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:58][root][INFO] - Training Epoch: 2/2, step 11228/16670 completed (loss: 0.3680160343647003, acc: 0.8913043737411499)
[2024-11-14 09:54:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:58][root][INFO] - Training Epoch: 2/2, step 11229/16670 completed (loss: 0.26196160912513733, acc: 0.9516128897666931)
[2024-11-14 09:54:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:58][root][INFO] - Training Epoch: 2/2, step 11230/16670 completed (loss: 0.3169374167919159, acc: 0.9152542352676392)
[2024-11-14 09:54:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:59][root][INFO] - Training Epoch: 2/2, step 11231/16670 completed (loss: 0.10178333520889282, acc: 0.9818181991577148)
[2024-11-14 09:54:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:54:59][root][INFO] - Training Epoch: 2/2, step 11232/16670 completed (loss: 0.6223747730255127, acc: 0.8611111044883728)
[2024-11-14 09:54:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:00][root][INFO] - Training Epoch: 2/2, step 11233/16670 completed (loss: 0.5458461046218872, acc: 0.8653846383094788)
[2024-11-14 09:55:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:00][root][INFO] - Training Epoch: 2/2, step 11234/16670 completed (loss: 0.2385263442993164, acc: 0.925000011920929)
[2024-11-14 09:55:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:00][root][INFO] - Training Epoch: 2/2, step 11235/16670 completed (loss: 0.12455752491950989, acc: 0.9692307710647583)
[2024-11-14 09:55:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:01][root][INFO] - Training Epoch: 2/2, step 11236/16670 completed (loss: 0.17463883757591248, acc: 0.942307710647583)
[2024-11-14 09:55:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:01][root][INFO] - Training Epoch: 2/2, step 11237/16670 completed (loss: 0.2406945824623108, acc: 0.9333333373069763)
[2024-11-14 09:55:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:01][root][INFO] - Training Epoch: 2/2, step 11238/16670 completed (loss: 0.3329920470714569, acc: 0.8867924809455872)
[2024-11-14 09:55:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:02][root][INFO] - Training Epoch: 2/2, step 11239/16670 completed (loss: 0.05499983951449394, acc: 1.0)
[2024-11-14 09:55:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:02][root][INFO] - Training Epoch: 2/2, step 11240/16670 completed (loss: 0.3938242793083191, acc: 0.8888888955116272)
[2024-11-14 09:55:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:02][root][INFO] - Training Epoch: 2/2, step 11241/16670 completed (loss: 0.9607770442962646, acc: 0.8787878751754761)
[2024-11-14 09:55:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:03][root][INFO] - Training Epoch: 2/2, step 11242/16670 completed (loss: 0.45508480072021484, acc: 0.9473684430122375)
[2024-11-14 09:55:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:03][root][INFO] - Training Epoch: 2/2, step 11243/16670 completed (loss: 0.017438825219869614, acc: 1.0)
[2024-11-14 09:55:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:03][root][INFO] - Training Epoch: 2/2, step 11244/16670 completed (loss: 0.44510602951049805, acc: 0.90625)
[2024-11-14 09:55:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:03][root][INFO] - Training Epoch: 2/2, step 11245/16670 completed (loss: 0.4659484326839447, acc: 0.9047619104385376)
[2024-11-14 09:55:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:04][root][INFO] - Training Epoch: 2/2, step 11246/16670 completed (loss: 0.5017847418785095, acc: 0.8684210777282715)
[2024-11-14 09:55:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:04][root][INFO] - Training Epoch: 2/2, step 11247/16670 completed (loss: 0.2919671833515167, acc: 0.957446813583374)
[2024-11-14 09:55:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:04][root][INFO] - Training Epoch: 2/2, step 11248/16670 completed (loss: 0.5428229570388794, acc: 0.9259259104728699)
[2024-11-14 09:55:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:05][root][INFO] - Training Epoch: 2/2, step 11249/16670 completed (loss: 0.42263150215148926, acc: 0.9259259104728699)
[2024-11-14 09:55:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:05][root][INFO] - Training Epoch: 2/2, step 11250/16670 completed (loss: 0.28607943654060364, acc: 0.9534883499145508)
[2024-11-14 09:55:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:05][root][INFO] - Training Epoch: 2/2, step 11251/16670 completed (loss: 0.4631488025188446, acc: 0.9230769276618958)
[2024-11-14 09:55:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:06][root][INFO] - Training Epoch: 2/2, step 11252/16670 completed (loss: 0.8609476685523987, acc: 0.8333333134651184)
[2024-11-14 09:55:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:06][root][INFO] - Training Epoch: 2/2, step 11253/16670 completed (loss: 0.5538250207901001, acc: 0.890625)
[2024-11-14 09:55:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:06][root][INFO] - Training Epoch: 2/2, step 11254/16670 completed (loss: 0.4953816831111908, acc: 0.8709677457809448)
[2024-11-14 09:55:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:07][root][INFO] - Training Epoch: 2/2, step 11255/16670 completed (loss: 0.29159289598464966, acc: 0.8999999761581421)
[2024-11-14 09:55:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:07][root][INFO] - Training Epoch: 2/2, step 11256/16670 completed (loss: 0.4203072786331177, acc: 0.9444444179534912)
[2024-11-14 09:55:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:07][root][INFO] - Training Epoch: 2/2, step 11257/16670 completed (loss: 0.7468910217285156, acc: 0.8275862336158752)
[2024-11-14 09:55:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:08][root][INFO] - Training Epoch: 2/2, step 11258/16670 completed (loss: 0.16458311676979065, acc: 0.9473684430122375)
[2024-11-14 09:55:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:08][root][INFO] - Training Epoch: 2/2, step 11259/16670 completed (loss: 0.16095438599586487, acc: 0.9599999785423279)
[2024-11-14 09:55:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:09][root][INFO] - Training Epoch: 2/2, step 11260/16670 completed (loss: 0.1958455592393875, acc: 0.95652174949646)
[2024-11-14 09:55:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:09][root][INFO] - Training Epoch: 2/2, step 11261/16670 completed (loss: 0.4093877077102661, acc: 0.8695651888847351)
[2024-11-14 09:55:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:09][root][INFO] - Training Epoch: 2/2, step 11262/16670 completed (loss: 0.6205809712409973, acc: 0.8833333253860474)
[2024-11-14 09:55:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:10][root][INFO] - Training Epoch: 2/2, step 11263/16670 completed (loss: 0.27992916107177734, acc: 0.9591836929321289)
[2024-11-14 09:55:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:10][root][INFO] - Training Epoch: 2/2, step 11264/16670 completed (loss: 0.7278707027435303, acc: 0.8510638475418091)
[2024-11-14 09:55:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:10][root][INFO] - Training Epoch: 2/2, step 11265/16670 completed (loss: 0.12830306589603424, acc: 1.0)
[2024-11-14 09:55:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:11][root][INFO] - Training Epoch: 2/2, step 11266/16670 completed (loss: 0.31589314341545105, acc: 0.9411764740943909)
[2024-11-14 09:55:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:11][root][INFO] - Training Epoch: 2/2, step 11267/16670 completed (loss: 0.04013571888208389, acc: 1.0)
[2024-11-14 09:55:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:11][root][INFO] - Training Epoch: 2/2, step 11268/16670 completed (loss: 0.43128299713134766, acc: 0.9166666865348816)
[2024-11-14 09:55:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:12][root][INFO] - Training Epoch: 2/2, step 11269/16670 completed (loss: 1.1162573099136353, acc: 0.7333333492279053)
[2024-11-14 09:55:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:12][root][INFO] - Training Epoch: 2/2, step 11270/16670 completed (loss: 0.7632862329483032, acc: 0.8636363744735718)
[2024-11-14 09:55:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:12][root][INFO] - Training Epoch: 2/2, step 11271/16670 completed (loss: 0.7284784913063049, acc: 0.7777777910232544)
[2024-11-14 09:55:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:13][root][INFO] - Training Epoch: 2/2, step 11272/16670 completed (loss: 0.38038191199302673, acc: 0.9130434989929199)
[2024-11-14 09:55:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:13][root][INFO] - Training Epoch: 2/2, step 11273/16670 completed (loss: 0.06685835123062134, acc: 1.0)
[2024-11-14 09:55:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:13][root][INFO] - Training Epoch: 2/2, step 11274/16670 completed (loss: 0.15397851169109344, acc: 0.9047619104385376)
[2024-11-14 09:55:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:14][root][INFO] - Training Epoch: 2/2, step 11275/16670 completed (loss: 0.3141099810600281, acc: 0.8867924809455872)
[2024-11-14 09:55:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:14][root][INFO] - Training Epoch: 2/2, step 11276/16670 completed (loss: 0.2521638572216034, acc: 0.9666666388511658)
[2024-11-14 09:55:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:14][root][INFO] - Training Epoch: 2/2, step 11277/16670 completed (loss: 0.04875427857041359, acc: 1.0)
[2024-11-14 09:55:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:15][root][INFO] - Training Epoch: 2/2, step 11278/16670 completed (loss: 0.11925526708364487, acc: 0.9599999785423279)
[2024-11-14 09:55:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:15][root][INFO] - Training Epoch: 2/2, step 11279/16670 completed (loss: 0.34308117628097534, acc: 0.8846153616905212)
[2024-11-14 09:55:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:15][root][INFO] - Training Epoch: 2/2, step 11280/16670 completed (loss: 0.20456312596797943, acc: 0.9333333373069763)
[2024-11-14 09:55:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:16][root][INFO] - Training Epoch: 2/2, step 11281/16670 completed (loss: 0.5443585515022278, acc: 0.8970588445663452)
[2024-11-14 09:55:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:16][root][INFO] - Training Epoch: 2/2, step 11282/16670 completed (loss: 0.14284631609916687, acc: 0.9545454382896423)
[2024-11-14 09:55:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:16][root][INFO] - Training Epoch: 2/2, step 11283/16670 completed (loss: 0.35705217719078064, acc: 0.9047619104385376)
[2024-11-14 09:55:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:17][root][INFO] - Training Epoch: 2/2, step 11284/16670 completed (loss: 0.039269864559173584, acc: 1.0)
[2024-11-14 09:55:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:17][root][INFO] - Training Epoch: 2/2, step 11285/16670 completed (loss: 0.42309051752090454, acc: 0.8888888955116272)
[2024-11-14 09:55:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:17][root][INFO] - Training Epoch: 2/2, step 11286/16670 completed (loss: 0.36448341608047485, acc: 0.9200000166893005)
[2024-11-14 09:55:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:18][root][INFO] - Training Epoch: 2/2, step 11287/16670 completed (loss: 0.2676335275173187, acc: 0.9032257795333862)
[2024-11-14 09:55:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:18][root][INFO] - Training Epoch: 2/2, step 11288/16670 completed (loss: 0.2778424322605133, acc: 0.8947368264198303)
[2024-11-14 09:55:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:18][root][INFO] - Training Epoch: 2/2, step 11289/16670 completed (loss: 0.2199317216873169, acc: 0.939393937587738)
[2024-11-14 09:55:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:19][root][INFO] - Training Epoch: 2/2, step 11290/16670 completed (loss: 0.40002214908599854, acc: 0.9318181872367859)
[2024-11-14 09:55:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:19][root][INFO] - Training Epoch: 2/2, step 11291/16670 completed (loss: 0.014470680616796017, acc: 1.0)
[2024-11-14 09:55:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:19][root][INFO] - Training Epoch: 2/2, step 11292/16670 completed (loss: 0.48646655678749084, acc: 0.8799999952316284)
[2024-11-14 09:55:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:20][root][INFO] - Training Epoch: 2/2, step 11293/16670 completed (loss: 0.7512683868408203, acc: 0.8571428656578064)
[2024-11-14 09:55:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:20][root][INFO] - Training Epoch: 2/2, step 11294/16670 completed (loss: 0.46715047955513, acc: 0.8936170339584351)
[2024-11-14 09:55:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:20][root][INFO] - Training Epoch: 2/2, step 11295/16670 completed (loss: 0.09500547498464584, acc: 0.9830508232116699)
[2024-11-14 09:55:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:21][root][INFO] - Training Epoch: 2/2, step 11296/16670 completed (loss: 0.3891312777996063, acc: 0.9032257795333862)
[2024-11-14 09:55:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:21][root][INFO] - Training Epoch: 2/2, step 11297/16670 completed (loss: 0.375453919172287, acc: 0.875)
[2024-11-14 09:55:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:21][root][INFO] - Training Epoch: 2/2, step 11298/16670 completed (loss: 0.4813193380832672, acc: 0.9024389982223511)
[2024-11-14 09:55:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:22][root][INFO] - Training Epoch: 2/2, step 11299/16670 completed (loss: 0.3794083297252655, acc: 0.8837209343910217)
[2024-11-14 09:55:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:22][root][INFO] - Training Epoch: 2/2, step 11300/16670 completed (loss: 0.19109858572483063, acc: 0.9743589758872986)
[2024-11-14 09:55:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:22][root][INFO] - Training Epoch: 2/2, step 11301/16670 completed (loss: 0.4185757637023926, acc: 0.8999999761581421)
[2024-11-14 09:55:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:22][root][INFO] - Training Epoch: 2/2, step 11302/16670 completed (loss: 0.5719704031944275, acc: 0.8703703880310059)
[2024-11-14 09:55:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:23][root][INFO] - Training Epoch: 2/2, step 11303/16670 completed (loss: 0.2621400058269501, acc: 0.9318181872367859)
[2024-11-14 09:55:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:23][root][INFO] - Training Epoch: 2/2, step 11304/16670 completed (loss: 0.2399735301733017, acc: 0.9375)
[2024-11-14 09:55:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:23][root][INFO] - Training Epoch: 2/2, step 11305/16670 completed (loss: 0.10453084856271744, acc: 0.9629629850387573)
[2024-11-14 09:55:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:24][root][INFO] - Training Epoch: 2/2, step 11306/16670 completed (loss: 0.5397920608520508, acc: 0.837837815284729)
[2024-11-14 09:55:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:24][root][INFO] - Training Epoch: 2/2, step 11307/16670 completed (loss: 0.29006898403167725, acc: 0.9545454382896423)
[2024-11-14 09:55:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:24][root][INFO] - Training Epoch: 2/2, step 11308/16670 completed (loss: 0.6317026615142822, acc: 0.8399999737739563)
[2024-11-14 09:55:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:25][root][INFO] - Training Epoch: 2/2, step 11309/16670 completed (loss: 0.11322985589504242, acc: 1.0)
[2024-11-14 09:55:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:25][root][INFO] - Training Epoch: 2/2, step 11310/16670 completed (loss: 0.19251246750354767, acc: 0.9599999785423279)
[2024-11-14 09:55:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:25][root][INFO] - Training Epoch: 2/2, step 11311/16670 completed (loss: 0.6464425325393677, acc: 0.9166666865348816)
[2024-11-14 09:55:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:26][root][INFO] - Training Epoch: 2/2, step 11312/16670 completed (loss: 0.05017472058534622, acc: 1.0)
[2024-11-14 09:55:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:26][root][INFO] - Training Epoch: 2/2, step 11313/16670 completed (loss: 0.03389224037528038, acc: 0.9795918464660645)
[2024-11-14 09:55:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:26][root][INFO] - Training Epoch: 2/2, step 11314/16670 completed (loss: 0.620016872882843, acc: 0.8461538553237915)
[2024-11-14 09:55:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:27][root][INFO] - Training Epoch: 2/2, step 11315/16670 completed (loss: 0.16160885989665985, acc: 0.9230769276618958)
[2024-11-14 09:55:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:27][root][INFO] - Training Epoch: 2/2, step 11316/16670 completed (loss: 0.8881352543830872, acc: 0.8235294222831726)
[2024-11-14 09:55:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:28][root][INFO] - Training Epoch: 2/2, step 11317/16670 completed (loss: 0.25617682933807373, acc: 0.9285714030265808)
[2024-11-14 09:55:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:28][root][INFO] - Training Epoch: 2/2, step 11318/16670 completed (loss: 0.43289369344711304, acc: 0.9444444179534912)
[2024-11-14 09:55:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:28][root][INFO] - Training Epoch: 2/2, step 11319/16670 completed (loss: 0.15362371504306793, acc: 0.9666666388511658)
[2024-11-14 09:55:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:29][root][INFO] - Training Epoch: 2/2, step 11320/16670 completed (loss: 0.40816599130630493, acc: 0.9166666865348816)
[2024-11-14 09:55:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:29][root][INFO] - Training Epoch: 2/2, step 11321/16670 completed (loss: 0.6093646287918091, acc: 0.8536585569381714)
[2024-11-14 09:55:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:29][root][INFO] - Training Epoch: 2/2, step 11322/16670 completed (loss: 0.2825784385204315, acc: 0.9290780425071716)
[2024-11-14 09:55:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:30][root][INFO] - Training Epoch: 2/2, step 11323/16670 completed (loss: 0.26356223225593567, acc: 0.9411764740943909)
[2024-11-14 09:55:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:30][root][INFO] - Training Epoch: 2/2, step 11324/16670 completed (loss: 0.1019480749964714, acc: 0.963302731513977)
[2024-11-14 09:55:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:30][root][INFO] - Training Epoch: 2/2, step 11325/16670 completed (loss: 0.1288933902978897, acc: 0.9651162624359131)
[2024-11-14 09:55:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:31][root][INFO] - Training Epoch: 2/2, step 11326/16670 completed (loss: 0.193901926279068, acc: 0.9479768872261047)
[2024-11-14 09:55:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:31][root][INFO] - Training Epoch: 2/2, step 11327/16670 completed (loss: 0.08748681843280792, acc: 0.9682539701461792)
[2024-11-14 09:55:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:31][root][INFO] - Training Epoch: 2/2, step 11328/16670 completed (loss: 0.1447971761226654, acc: 0.9537814855575562)
[2024-11-14 09:55:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:32][root][INFO] - Training Epoch: 2/2, step 11329/16670 completed (loss: 0.12225008010864258, acc: 0.9714285731315613)
[2024-11-14 09:55:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:32][root][INFO] - Training Epoch: 2/2, step 11330/16670 completed (loss: 0.19323454797267914, acc: 0.9265536665916443)
[2024-11-14 09:55:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:32][root][INFO] - Training Epoch: 2/2, step 11331/16670 completed (loss: 0.07745571434497833, acc: 0.9830508232116699)
[2024-11-14 09:55:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:33][root][INFO] - Training Epoch: 2/2, step 11332/16670 completed (loss: 0.0669683963060379, acc: 0.9685039520263672)
[2024-11-14 09:55:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:33][root][INFO] - Training Epoch: 2/2, step 11333/16670 completed (loss: 0.2049873024225235, acc: 0.9340659379959106)
[2024-11-14 09:55:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:33][root][INFO] - Training Epoch: 2/2, step 11334/16670 completed (loss: 0.06492249667644501, acc: 0.9791666865348816)
[2024-11-14 09:55:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:33][root][INFO] - Training Epoch: 2/2, step 11335/16670 completed (loss: 0.14767992496490479, acc: 0.9558011293411255)
[2024-11-14 09:55:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:34][root][INFO] - Training Epoch: 2/2, step 11336/16670 completed (loss: 0.21926194429397583, acc: 0.9397590160369873)
[2024-11-14 09:55:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:34][root][INFO] - Training Epoch: 2/2, step 11337/16670 completed (loss: 0.30200526118278503, acc: 0.9159291982650757)
[2024-11-14 09:55:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:34][root][INFO] - Training Epoch: 2/2, step 11338/16670 completed (loss: 0.3602502644062042, acc: 0.9039999842643738)
[2024-11-14 09:55:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:35][root][INFO] - Training Epoch: 2/2, step 11339/16670 completed (loss: 0.05531728267669678, acc: 0.9806763529777527)
[2024-11-14 09:55:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:35][root][INFO] - Training Epoch: 2/2, step 11340/16670 completed (loss: 0.20088420808315277, acc: 0.9532710313796997)
[2024-11-14 09:55:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:35][root][INFO] - Training Epoch: 2/2, step 11341/16670 completed (loss: 0.6140146851539612, acc: 0.8225806355476379)
[2024-11-14 09:55:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:36][root][INFO] - Training Epoch: 2/2, step 11342/16670 completed (loss: 0.2095600813627243, acc: 0.9382715821266174)
[2024-11-14 09:55:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:36][root][INFO] - Training Epoch: 2/2, step 11343/16670 completed (loss: 0.0768478661775589, acc: 0.9722222089767456)
[2024-11-14 09:55:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:36][root][INFO] - Training Epoch: 2/2, step 11344/16670 completed (loss: 0.277361124753952, acc: 0.9418604373931885)
[2024-11-14 09:55:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:37][root][INFO] - Training Epoch: 2/2, step 11345/16670 completed (loss: 0.44269445538520813, acc: 0.8738738894462585)
[2024-11-14 09:55:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:37][root][INFO] - Training Epoch: 2/2, step 11346/16670 completed (loss: 0.1868768185377121, acc: 0.9464285969734192)
[2024-11-14 09:55:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:37][root][INFO] - Training Epoch: 2/2, step 11347/16670 completed (loss: 0.16020359098911285, acc: 0.9520958065986633)
[2024-11-14 09:55:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:38][root][INFO] - Training Epoch: 2/2, step 11348/16670 completed (loss: 0.22736485302448273, acc: 0.9279279112815857)
[2024-11-14 09:55:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:38][root][INFO] - Training Epoch: 2/2, step 11349/16670 completed (loss: 0.1235562339425087, acc: 0.9603960514068604)
[2024-11-14 09:55:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:38][root][INFO] - Training Epoch: 2/2, step 11350/16670 completed (loss: 0.014258380979299545, acc: 1.0)
[2024-11-14 09:55:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:38][root][INFO] - Training Epoch: 2/2, step 11351/16670 completed (loss: 0.2287784069776535, acc: 0.9420289993286133)
[2024-11-14 09:55:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:39][root][INFO] - Training Epoch: 2/2, step 11352/16670 completed (loss: 0.1319405883550644, acc: 0.9545454382896423)
[2024-11-14 09:55:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:39][root][INFO] - Training Epoch: 2/2, step 11353/16670 completed (loss: 0.12626054883003235, acc: 0.9603174328804016)
[2024-11-14 09:55:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:39][root][INFO] - Training Epoch: 2/2, step 11354/16670 completed (loss: 0.38270196318626404, acc: 0.8723404407501221)
[2024-11-14 09:55:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:40][root][INFO] - Training Epoch: 2/2, step 11355/16670 completed (loss: 0.08042001724243164, acc: 0.976190447807312)
[2024-11-14 09:55:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:40][root][INFO] - Training Epoch: 2/2, step 11356/16670 completed (loss: 0.1984577476978302, acc: 0.9428571462631226)
[2024-11-14 09:55:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:40][root][INFO] - Training Epoch: 2/2, step 11357/16670 completed (loss: 0.09209097176790237, acc: 0.9590643048286438)
[2024-11-14 09:55:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:41][root][INFO] - Training Epoch: 2/2, step 11358/16670 completed (loss: 0.13358476758003235, acc: 0.9607843160629272)
[2024-11-14 09:55:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:41][root][INFO] - Training Epoch: 2/2, step 11359/16670 completed (loss: 0.1721244901418686, acc: 0.9226519465446472)
[2024-11-14 09:55:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:41][root][INFO] - Training Epoch: 2/2, step 11360/16670 completed (loss: 0.12246809154748917, acc: 0.970588207244873)
[2024-11-14 09:55:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:42][root][INFO] - Training Epoch: 2/2, step 11361/16670 completed (loss: 0.2799558937549591, acc: 0.9090909361839294)
[2024-11-14 09:55:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:42][root][INFO] - Training Epoch: 2/2, step 11362/16670 completed (loss: 0.08273198455572128, acc: 0.9726027250289917)
[2024-11-14 09:55:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:42][root][INFO] - Training Epoch: 2/2, step 11363/16670 completed (loss: 0.1481132060289383, acc: 0.9618055820465088)
[2024-11-14 09:55:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:43][root][INFO] - Training Epoch: 2/2, step 11364/16670 completed (loss: 0.045940373092889786, acc: 0.9857142567634583)
[2024-11-14 09:55:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:43][root][INFO] - Training Epoch: 2/2, step 11365/16670 completed (loss: 0.37982743978500366, acc: 0.930232584476471)
[2024-11-14 09:55:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:43][root][INFO] - Training Epoch: 2/2, step 11366/16670 completed (loss: 0.2517668902873993, acc: 0.9514563083648682)
[2024-11-14 09:55:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:44][root][INFO] - Training Epoch: 2/2, step 11367/16670 completed (loss: 0.1428869068622589, acc: 0.9690141081809998)
[2024-11-14 09:55:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:44][root][INFO] - Training Epoch: 2/2, step 11368/16670 completed (loss: 0.1057741791009903, acc: 0.9624413251876831)
[2024-11-14 09:55:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:44][root][INFO] - Training Epoch: 2/2, step 11369/16670 completed (loss: 0.12458953261375427, acc: 0.9583333134651184)
[2024-11-14 09:55:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:45][root][INFO] - Training Epoch: 2/2, step 11370/16670 completed (loss: 0.14982089400291443, acc: 0.9724770784378052)
[2024-11-14 09:55:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:45][root][INFO] - Training Epoch: 2/2, step 11371/16670 completed (loss: 0.11865581572055817, acc: 0.9640287756919861)
[2024-11-14 09:55:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:45][root][INFO] - Training Epoch: 2/2, step 11372/16670 completed (loss: 0.25783899426460266, acc: 0.931034505367279)
[2024-11-14 09:55:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:46][root][INFO] - Training Epoch: 2/2, step 11373/16670 completed (loss: 0.22215527296066284, acc: 0.9268292784690857)
[2024-11-14 09:55:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:46][root][INFO] - Training Epoch: 2/2, step 11374/16670 completed (loss: 0.03964614123106003, acc: 0.9818181991577148)
[2024-11-14 09:55:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:46][root][INFO] - Training Epoch: 2/2, step 11375/16670 completed (loss: 0.14521105587482452, acc: 0.956204354763031)
[2024-11-14 09:55:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:47][root][INFO] - Training Epoch: 2/2, step 11376/16670 completed (loss: 0.016685307025909424, acc: 1.0)
[2024-11-14 09:55:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:47][root][INFO] - Training Epoch: 2/2, step 11377/16670 completed (loss: 0.019024206325411797, acc: 1.0)
[2024-11-14 09:55:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:48][root][INFO] - Training Epoch: 2/2, step 11378/16670 completed (loss: 0.07595579326152802, acc: 0.9756097793579102)
[2024-11-14 09:55:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:48][root][INFO] - Training Epoch: 2/2, step 11379/16670 completed (loss: 0.16037562489509583, acc: 0.9446808695793152)
[2024-11-14 09:55:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:48][root][INFO] - Training Epoch: 2/2, step 11380/16670 completed (loss: 0.30692967772483826, acc: 0.939393937587738)
[2024-11-14 09:55:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:48][root][INFO] - Training Epoch: 2/2, step 11381/16670 completed (loss: 0.05764802545309067, acc: 0.9909909963607788)
[2024-11-14 09:55:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:49][root][INFO] - Training Epoch: 2/2, step 11382/16670 completed (loss: 0.06479101628065109, acc: 0.9842519760131836)
[2024-11-14 09:55:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:49][root][INFO] - Training Epoch: 2/2, step 11383/16670 completed (loss: 0.055569883435964584, acc: 0.9901960492134094)
[2024-11-14 09:55:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:49][root][INFO] - Training Epoch: 2/2, step 11384/16670 completed (loss: 0.2518865764141083, acc: 0.9548872113227844)
[2024-11-14 09:55:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:50][root][INFO] - Training Epoch: 2/2, step 11385/16670 completed (loss: 0.33990606665611267, acc: 0.892405092716217)
[2024-11-14 09:55:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:50][root][INFO] - Training Epoch: 2/2, step 11386/16670 completed (loss: 0.24955852329730988, acc: 0.8974359035491943)
[2024-11-14 09:55:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:50][root][INFO] - Training Epoch: 2/2, step 11387/16670 completed (loss: 0.09242143481969833, acc: 0.96875)
[2024-11-14 09:55:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:51][root][INFO] - Training Epoch: 2/2, step 11388/16670 completed (loss: 0.06567207723855972, acc: 0.9829059839248657)
[2024-11-14 09:55:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:51][root][INFO] - Training Epoch: 2/2, step 11389/16670 completed (loss: 0.1416836977005005, acc: 0.9594095945358276)
[2024-11-14 09:55:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:52][root][INFO] - Training Epoch: 2/2, step 11390/16670 completed (loss: 0.13632580637931824, acc: 0.9603524208068848)
[2024-11-14 09:55:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:52][root][INFO] - Training Epoch: 2/2, step 11391/16670 completed (loss: 0.1202315092086792, acc: 0.970588207244873)
[2024-11-14 09:55:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:52][root][INFO] - Training Epoch: 2/2, step 11392/16670 completed (loss: 0.10248208791017532, acc: 0.978723406791687)
[2024-11-14 09:55:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:53][root][INFO] - Training Epoch: 2/2, step 11393/16670 completed (loss: 0.27661094069480896, acc: 0.9256198406219482)
[2024-11-14 09:55:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:53][root][INFO] - Training Epoch: 2/2, step 11394/16670 completed (loss: 0.2758781313896179, acc: 0.9107142686843872)
[2024-11-14 09:55:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:53][root][INFO] - Training Epoch: 2/2, step 11395/16670 completed (loss: 0.2800426483154297, acc: 0.9333333373069763)
[2024-11-14 09:55:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:54][root][INFO] - Training Epoch: 2/2, step 11396/16670 completed (loss: 0.11669020354747772, acc: 0.9603960514068604)
[2024-11-14 09:55:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:54][root][INFO] - Training Epoch: 2/2, step 11397/16670 completed (loss: 0.26763442158699036, acc: 0.9109947681427002)
[2024-11-14 09:55:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:54][root][INFO] - Training Epoch: 2/2, step 11398/16670 completed (loss: 0.23248480260372162, acc: 0.9318181872367859)
[2024-11-14 09:55:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:55][root][INFO] - Training Epoch: 2/2, step 11399/16670 completed (loss: 0.11288449913263321, acc: 0.970588207244873)
[2024-11-14 09:55:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:55][root][INFO] - Training Epoch: 2/2, step 11400/16670 completed (loss: 0.17881275713443756, acc: 0.9430379867553711)
[2024-11-14 09:55:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:55][root][INFO] - Training Epoch: 2/2, step 11401/16670 completed (loss: 0.15193338692188263, acc: 0.9560439586639404)
[2024-11-14 09:55:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:56][root][INFO] - Training Epoch: 2/2, step 11402/16670 completed (loss: 0.3099069595336914, acc: 0.9200000166893005)
[2024-11-14 09:55:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:56][root][INFO] - Training Epoch: 2/2, step 11403/16670 completed (loss: 0.13612650334835052, acc: 0.9575971961021423)
[2024-11-14 09:55:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:56][root][INFO] - Training Epoch: 2/2, step 11404/16670 completed (loss: 0.1987391859292984, acc: 0.9753086566925049)
[2024-11-14 09:55:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:57][root][INFO] - Training Epoch: 2/2, step 11405/16670 completed (loss: 0.032054293900728226, acc: 0.9920318722724915)
[2024-11-14 09:55:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:57][root][INFO] - Training Epoch: 2/2, step 11406/16670 completed (loss: 0.26785269379615784, acc: 0.9414893388748169)
[2024-11-14 09:55:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:58][root][INFO] - Training Epoch: 2/2, step 11407/16670 completed (loss: 0.23331297934055328, acc: 0.9494163393974304)
[2024-11-14 09:55:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:58][root][INFO] - Training Epoch: 2/2, step 11408/16670 completed (loss: 0.11360359191894531, acc: 0.9659090638160706)
[2024-11-14 09:55:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:58][root][INFO] - Training Epoch: 2/2, step 11409/16670 completed (loss: 0.18477973341941833, acc: 0.9450549483299255)
[2024-11-14 09:55:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:59][root][INFO] - Training Epoch: 2/2, step 11410/16670 completed (loss: 0.1067318543791771, acc: 0.9630996584892273)
[2024-11-14 09:55:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:59][root][INFO] - Training Epoch: 2/2, step 11411/16670 completed (loss: 0.17372660338878632, acc: 0.950138509273529)
[2024-11-14 09:55:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:55:59][root][INFO] - Training Epoch: 2/2, step 11412/16670 completed (loss: 0.17922493815422058, acc: 0.9543726444244385)
[2024-11-14 09:55:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:00][root][INFO] - Training Epoch: 2/2, step 11413/16670 completed (loss: 0.07979298382997513, acc: 0.9756097793579102)
[2024-11-14 09:56:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:00][root][INFO] - Training Epoch: 2/2, step 11414/16670 completed (loss: 0.2640908360481262, acc: 0.9043824672698975)
[2024-11-14 09:56:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:00][root][INFO] - Training Epoch: 2/2, step 11415/16670 completed (loss: 0.26088565587997437, acc: 0.9090909361839294)
[2024-11-14 09:56:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:01][root][INFO] - Training Epoch: 2/2, step 11416/16670 completed (loss: 0.07156591862440109, acc: 0.9708737730979919)
[2024-11-14 09:56:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:01][root][INFO] - Training Epoch: 2/2, step 11417/16670 completed (loss: 0.040925756096839905, acc: 0.982300877571106)
[2024-11-14 09:56:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:01][root][INFO] - Training Epoch: 2/2, step 11418/16670 completed (loss: 0.06769925355911255, acc: 0.9805825352668762)
[2024-11-14 09:56:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:02][root][INFO] - Training Epoch: 2/2, step 11419/16670 completed (loss: 0.17350135743618011, acc: 0.9547738432884216)
[2024-11-14 09:56:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:02][root][INFO] - Training Epoch: 2/2, step 11420/16670 completed (loss: 0.1357036530971527, acc: 0.9703264236450195)
[2024-11-14 09:56:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:02][root][INFO] - Training Epoch: 2/2, step 11421/16670 completed (loss: 0.21069714426994324, acc: 0.9210526347160339)
[2024-11-14 09:56:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:03][root][INFO] - Training Epoch: 2/2, step 11422/16670 completed (loss: 0.0651923418045044, acc: 0.9808743000030518)
[2024-11-14 09:56:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:03][root][INFO] - Training Epoch: 2/2, step 11423/16670 completed (loss: 0.018649807199835777, acc: 1.0)
[2024-11-14 09:56:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:03][root][INFO] - Training Epoch: 2/2, step 11424/16670 completed (loss: 0.4055323302745819, acc: 0.907975435256958)
[2024-11-14 09:56:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:04][root][INFO] - Training Epoch: 2/2, step 11425/16670 completed (loss: 0.24209727346897125, acc: 0.9268292784690857)
[2024-11-14 09:56:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:04][root][INFO] - Training Epoch: 2/2, step 11426/16670 completed (loss: 0.4345725476741791, acc: 0.9117646813392639)
[2024-11-14 09:56:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:05][root][INFO] - Training Epoch: 2/2, step 11427/16670 completed (loss: 0.17865824699401855, acc: 0.9542682766914368)
[2024-11-14 09:56:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:05][root][INFO] - Training Epoch: 2/2, step 11428/16670 completed (loss: 0.1658102422952652, acc: 0.9426751732826233)
[2024-11-14 09:56:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:05][root][INFO] - Training Epoch: 2/2, step 11429/16670 completed (loss: 0.1291080117225647, acc: 0.9522058963775635)
[2024-11-14 09:56:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:06][root][INFO] - Training Epoch: 2/2, step 11430/16670 completed (loss: 0.36237987875938416, acc: 0.9411764740943909)
[2024-11-14 09:56:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:06][root][INFO] - Training Epoch: 2/2, step 11431/16670 completed (loss: 0.09869910776615143, acc: 0.978723406791687)
[2024-11-14 09:56:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:06][root][INFO] - Training Epoch: 2/2, step 11432/16670 completed (loss: 0.38744938373565674, acc: 0.8894230723381042)
[2024-11-14 09:56:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:07][root][INFO] - Training Epoch: 2/2, step 11433/16670 completed (loss: 0.2159384936094284, acc: 0.942148745059967)
[2024-11-14 09:56:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:07][root][INFO] - Training Epoch: 2/2, step 11434/16670 completed (loss: 0.06863506883382797, acc: 0.9764150977134705)
[2024-11-14 09:56:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:07][root][INFO] - Training Epoch: 2/2, step 11435/16670 completed (loss: 0.09034143388271332, acc: 0.9878048896789551)
[2024-11-14 09:56:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:08][root][INFO] - Training Epoch: 2/2, step 11436/16670 completed (loss: 0.07143742591142654, acc: 0.9848484992980957)
[2024-11-14 09:56:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:08][root][INFO] - Training Epoch: 2/2, step 11437/16670 completed (loss: 0.23315957188606262, acc: 0.9444444179534912)
[2024-11-14 09:56:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:09][root][INFO] - Training Epoch: 2/2, step 11438/16670 completed (loss: 0.1443457305431366, acc: 0.9581993818283081)
[2024-11-14 09:56:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:09][root][INFO] - Training Epoch: 2/2, step 11439/16670 completed (loss: 0.1349383145570755, acc: 0.9552238583564758)
[2024-11-14 09:56:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:09][root][INFO] - Training Epoch: 2/2, step 11440/16670 completed (loss: 0.18384398519992828, acc: 0.940397322177887)
[2024-11-14 09:56:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:09][root][INFO] - Training Epoch: 2/2, step 11441/16670 completed (loss: 0.1274685263633728, acc: 0.9621621370315552)
[2024-11-14 09:56:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:10][root][INFO] - Training Epoch: 2/2, step 11442/16670 completed (loss: 0.12811316549777985, acc: 0.9506173133850098)
[2024-11-14 09:56:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:10][root][INFO] - Training Epoch: 2/2, step 11443/16670 completed (loss: 0.058037590235471725, acc: 0.9836065769195557)
[2024-11-14 09:56:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:10][root][INFO] - Training Epoch: 2/2, step 11444/16670 completed (loss: 0.08226076513528824, acc: 0.9720670580863953)
[2024-11-14 09:56:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:11][root][INFO] - Training Epoch: 2/2, step 11445/16670 completed (loss: 0.20543473958969116, acc: 0.9379310607910156)
[2024-11-14 09:56:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:11][root][INFO] - Training Epoch: 2/2, step 11446/16670 completed (loss: 0.2436126470565796, acc: 0.932584285736084)
[2024-11-14 09:56:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:11][root][INFO] - Training Epoch: 2/2, step 11447/16670 completed (loss: 0.09230700135231018, acc: 0.97826087474823)
[2024-11-14 09:56:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:12][root][INFO] - Training Epoch: 2/2, step 11448/16670 completed (loss: 0.20310482382774353, acc: 0.9473684430122375)
[2024-11-14 09:56:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:12][root][INFO] - Training Epoch: 2/2, step 11449/16670 completed (loss: 0.17985078692436218, acc: 0.9398906826972961)
[2024-11-14 09:56:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:12][root][INFO] - Training Epoch: 2/2, step 11450/16670 completed (loss: 0.05998527631163597, acc: 0.9886363744735718)
[2024-11-14 09:56:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:13][root][INFO] - Training Epoch: 2/2, step 11451/16670 completed (loss: 0.1618395745754242, acc: 0.9641255736351013)
[2024-11-14 09:56:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:13][root][INFO] - Training Epoch: 2/2, step 11452/16670 completed (loss: 0.20776118338108063, acc: 0.9516907930374146)
[2024-11-14 09:56:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:14][root][INFO] - Training Epoch: 2/2, step 11453/16670 completed (loss: 0.1444678157567978, acc: 0.9668246507644653)
[2024-11-14 09:56:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:14][root][INFO] - Training Epoch: 2/2, step 11454/16670 completed (loss: 0.26138243079185486, acc: 0.9398496150970459)
[2024-11-14 09:56:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:14][root][INFO] - Training Epoch: 2/2, step 11455/16670 completed (loss: 0.13253745436668396, acc: 0.9637096524238586)
[2024-11-14 09:56:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:15][root][INFO] - Training Epoch: 2/2, step 11456/16670 completed (loss: 0.08656040579080582, acc: 0.9726027250289917)
[2024-11-14 09:56:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:15][root][INFO] - Training Epoch: 2/2, step 11457/16670 completed (loss: 0.0785401463508606, acc: 0.9755101799964905)
[2024-11-14 09:56:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:15][root][INFO] - Training Epoch: 2/2, step 11458/16670 completed (loss: 0.2987205982208252, acc: 0.9328358173370361)
[2024-11-14 09:56:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:16][root][INFO] - Training Epoch: 2/2, step 11459/16670 completed (loss: 0.14076673984527588, acc: 0.9704433679580688)
[2024-11-14 09:56:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:16][root][INFO] - Training Epoch: 2/2, step 11460/16670 completed (loss: 0.20277352631092072, acc: 0.9318181872367859)
[2024-11-14 09:56:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:16][root][INFO] - Training Epoch: 2/2, step 11461/16670 completed (loss: 0.26472699642181396, acc: 0.9265305995941162)
[2024-11-14 09:56:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:17][root][INFO] - Training Epoch: 2/2, step 11462/16670 completed (loss: 0.07075182348489761, acc: 0.9861111044883728)
[2024-11-14 09:56:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:17][root][INFO] - Training Epoch: 2/2, step 11463/16670 completed (loss: 0.08196830004453659, acc: 0.9802631735801697)
[2024-11-14 09:56:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:17][root][INFO] - Training Epoch: 2/2, step 11464/16670 completed (loss: 0.06257105618715286, acc: 0.9784172773361206)
[2024-11-14 09:56:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:18][root][INFO] - Training Epoch: 2/2, step 11465/16670 completed (loss: 0.20826664566993713, acc: 0.9435028433799744)
[2024-11-14 09:56:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:18][root][INFO] - Training Epoch: 2/2, step 11466/16670 completed (loss: 0.09116683155298233, acc: 0.9818181991577148)
[2024-11-14 09:56:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:18][root][INFO] - Training Epoch: 2/2, step 11467/16670 completed (loss: 0.13538450002670288, acc: 0.9622641801834106)
[2024-11-14 09:56:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:19][root][INFO] - Training Epoch: 2/2, step 11468/16670 completed (loss: 0.15935997664928436, acc: 0.9536423683166504)
[2024-11-14 09:56:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:19][root][INFO] - Training Epoch: 2/2, step 11469/16670 completed (loss: 0.12584932148456573, acc: 0.9615384340286255)
[2024-11-14 09:56:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:19][root][INFO] - Training Epoch: 2/2, step 11470/16670 completed (loss: 0.06407726556062698, acc: 0.9814814925193787)
[2024-11-14 09:56:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:20][root][INFO] - Training Epoch: 2/2, step 11471/16670 completed (loss: 0.07581105828285217, acc: 0.9719626307487488)
[2024-11-14 09:56:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:20][root][INFO] - Training Epoch: 2/2, step 11472/16670 completed (loss: 0.05341639742255211, acc: 0.9850746393203735)
[2024-11-14 09:56:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:20][root][INFO] - Training Epoch: 2/2, step 11473/16670 completed (loss: 0.14452050626277924, acc: 0.9645389914512634)
[2024-11-14 09:56:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:21][root][INFO] - Training Epoch: 2/2, step 11474/16670 completed (loss: 0.3260755240917206, acc: 0.9009009003639221)
[2024-11-14 09:56:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:21][root][INFO] - Training Epoch: 2/2, step 11475/16670 completed (loss: 0.12960411608219147, acc: 0.9572953581809998)
[2024-11-14 09:56:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:21][root][INFO] - Training Epoch: 2/2, step 11476/16670 completed (loss: 0.1087302565574646, acc: 0.9662446975708008)
[2024-11-14 09:56:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:22][root][INFO] - Training Epoch: 2/2, step 11477/16670 completed (loss: 0.03634844347834587, acc: 0.9935897588729858)
[2024-11-14 09:56:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:22][root][INFO] - Training Epoch: 2/2, step 11478/16670 completed (loss: 0.10216248780488968, acc: 0.9866666793823242)
[2024-11-14 09:56:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:22][root][INFO] - Training Epoch: 2/2, step 11479/16670 completed (loss: 0.3101327419281006, acc: 0.9111111164093018)
[2024-11-14 09:56:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:23][root][INFO] - Training Epoch: 2/2, step 11480/16670 completed (loss: 0.2142110913991928, acc: 0.9560439586639404)
[2024-11-14 09:56:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:23][root][INFO] - Training Epoch: 2/2, step 11481/16670 completed (loss: 0.2571617662906647, acc: 0.9375)
[2024-11-14 09:56:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:23][root][INFO] - Training Epoch: 2/2, step 11482/16670 completed (loss: 0.16185057163238525, acc: 0.9513513445854187)
[2024-11-14 09:56:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:23][root][INFO] - Training Epoch: 2/2, step 11483/16670 completed (loss: 0.028566675260663033, acc: 0.9945054650306702)
[2024-11-14 09:56:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:24][root][INFO] - Training Epoch: 2/2, step 11484/16670 completed (loss: 0.10800734162330627, acc: 0.9729729890823364)
[2024-11-14 09:56:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:24][root][INFO] - Training Epoch: 2/2, step 11485/16670 completed (loss: 0.0756942629814148, acc: 0.9741697311401367)
[2024-11-14 09:56:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:24][root][INFO] - Training Epoch: 2/2, step 11486/16670 completed (loss: 0.11701743304729462, acc: 0.9929078221321106)
[2024-11-14 09:56:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:25][root][INFO] - Training Epoch: 2/2, step 11487/16670 completed (loss: 0.1344553530216217, acc: 0.9549180269241333)
[2024-11-14 09:56:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:25][root][INFO] - Training Epoch: 2/2, step 11488/16670 completed (loss: 0.18797332048416138, acc: 0.9528796076774597)
[2024-11-14 09:56:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:25][root][INFO] - Training Epoch: 2/2, step 11489/16670 completed (loss: 0.1911478191614151, acc: 0.9558823704719543)
[2024-11-14 09:56:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:26][root][INFO] - Training Epoch: 2/2, step 11490/16670 completed (loss: 0.257827490568161, acc: 0.9572649598121643)
[2024-11-14 09:56:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:26][root][INFO] - Training Epoch: 2/2, step 11491/16670 completed (loss: 0.06156814098358154, acc: 0.9935064911842346)
[2024-11-14 09:56:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:26][root][INFO] - Training Epoch: 2/2, step 11492/16670 completed (loss: 0.05140267312526703, acc: 0.9824561476707458)
[2024-11-14 09:56:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:26][root][INFO] - Training Epoch: 2/2, step 11493/16670 completed (loss: 0.14034871757030487, acc: 0.9669811129570007)
[2024-11-14 09:56:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:27][root][INFO] - Training Epoch: 2/2, step 11494/16670 completed (loss: 0.05227155610918999, acc: 0.9881423115730286)
[2024-11-14 09:56:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:27][root][INFO] - Training Epoch: 2/2, step 11495/16670 completed (loss: 0.1726643592119217, acc: 0.9441624283790588)
[2024-11-14 09:56:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:27][root][INFO] - Training Epoch: 2/2, step 11496/16670 completed (loss: 0.08348962664604187, acc: 0.9798657894134521)
[2024-11-14 09:56:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:28][root][INFO] - Training Epoch: 2/2, step 11497/16670 completed (loss: 0.11712512373924255, acc: 0.9664804339408875)
[2024-11-14 09:56:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:28][root][INFO] - Training Epoch: 2/2, step 11498/16670 completed (loss: 0.1460062563419342, acc: 0.9794520735740662)
[2024-11-14 09:56:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:28][root][INFO] - Training Epoch: 2/2, step 11499/16670 completed (loss: 0.07875789701938629, acc: 0.9833333492279053)
[2024-11-14 09:56:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:29][root][INFO] - Training Epoch: 2/2, step 11500/16670 completed (loss: 0.19827933609485626, acc: 0.9459459185600281)
[2024-11-14 09:56:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:29][root][INFO] - Training Epoch: 2/2, step 11501/16670 completed (loss: 0.1723770648241043, acc: 0.9453125)
[2024-11-14 09:56:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:29][root][INFO] - Training Epoch: 2/2, step 11502/16670 completed (loss: 0.06878115981817245, acc: 0.9848484992980957)
[2024-11-14 09:56:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:30][root][INFO] - Training Epoch: 2/2, step 11503/16670 completed (loss: 0.014324584975838661, acc: 1.0)
[2024-11-14 09:56:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:30][root][INFO] - Training Epoch: 2/2, step 11504/16670 completed (loss: 0.04765631631016731, acc: 0.9807692170143127)
[2024-11-14 09:56:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:30][root][INFO] - Training Epoch: 2/2, step 11505/16670 completed (loss: 0.009993876330554485, acc: 1.0)
[2024-11-14 09:56:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:31][root][INFO] - Training Epoch: 2/2, step 11506/16670 completed (loss: 0.05749409645795822, acc: 0.9931034445762634)
[2024-11-14 09:56:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:31][root][INFO] - Training Epoch: 2/2, step 11507/16670 completed (loss: 0.11723067611455917, acc: 0.978723406791687)
[2024-11-14 09:56:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:31][root][INFO] - Training Epoch: 2/2, step 11508/16670 completed (loss: 0.14296036958694458, acc: 0.9790209531784058)
[2024-11-14 09:56:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:32][root][INFO] - Training Epoch: 2/2, step 11509/16670 completed (loss: 0.2769026458263397, acc: 0.9457013607025146)
[2024-11-14 09:56:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:32][root][INFO] - Training Epoch: 2/2, step 11510/16670 completed (loss: 0.07789481431245804, acc: 0.9709302186965942)
[2024-11-14 09:56:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:32][root][INFO] - Training Epoch: 2/2, step 11511/16670 completed (loss: 0.18793441355228424, acc: 0.9477611780166626)
[2024-11-14 09:56:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:32][root][INFO] - Training Epoch: 2/2, step 11512/16670 completed (loss: 0.12344806641340256, acc: 0.9718875288963318)
[2024-11-14 09:56:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:33][root][INFO] - Training Epoch: 2/2, step 11513/16670 completed (loss: 0.014859437942504883, acc: 1.0)
[2024-11-14 09:56:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:33][root][INFO] - Training Epoch: 2/2, step 11514/16670 completed (loss: 0.05740393325686455, acc: 0.9852941036224365)
[2024-11-14 09:56:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:33][root][INFO] - Training Epoch: 2/2, step 11515/16670 completed (loss: 0.15764425694942474, acc: 0.9661971926689148)
[2024-11-14 09:56:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:34][root][INFO] - Training Epoch: 2/2, step 11516/16670 completed (loss: 0.011847461573779583, acc: 1.0)
[2024-11-14 09:56:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:34][root][INFO] - Training Epoch: 2/2, step 11517/16670 completed (loss: 0.05242948979139328, acc: 0.9850746393203735)
[2024-11-14 09:56:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:34][root][INFO] - Training Epoch: 2/2, step 11518/16670 completed (loss: 0.09967759251594543, acc: 0.9738219976425171)
[2024-11-14 09:56:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:35][root][INFO] - Training Epoch: 2/2, step 11519/16670 completed (loss: 0.2483004331588745, acc: 0.9166666865348816)
[2024-11-14 09:56:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:35][root][INFO] - Training Epoch: 2/2, step 11520/16670 completed (loss: 0.19047626852989197, acc: 0.9507042169570923)
[2024-11-14 09:56:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:35][root][INFO] - Training Epoch: 2/2, step 11521/16670 completed (loss: 0.03976479917764664, acc: 1.0)
[2024-11-14 09:56:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:35][root][INFO] - Training Epoch: 2/2, step 11522/16670 completed (loss: 0.17906811833381653, acc: 0.9454545378684998)
[2024-11-14 09:56:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:36][root][INFO] - Training Epoch: 2/2, step 11523/16670 completed (loss: 0.17060549557209015, acc: 0.9515151381492615)
[2024-11-14 09:56:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:36][root][INFO] - Training Epoch: 2/2, step 11524/16670 completed (loss: 0.02838997170329094, acc: 0.9932432174682617)
[2024-11-14 09:56:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:36][root][INFO] - Training Epoch: 2/2, step 11525/16670 completed (loss: 0.08670242875814438, acc: 0.970588207244873)
[2024-11-14 09:56:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:37][root][INFO] - Training Epoch: 2/2, step 11526/16670 completed (loss: 0.08208897709846497, acc: 0.9838709831237793)
[2024-11-14 09:56:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:37][root][INFO] - Training Epoch: 2/2, step 11527/16670 completed (loss: 0.11736144870519638, acc: 0.9734513163566589)
[2024-11-14 09:56:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:37][root][INFO] - Training Epoch: 2/2, step 11528/16670 completed (loss: 0.2677564024925232, acc: 0.925000011920929)
[2024-11-14 09:56:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:38][root][INFO] - Training Epoch: 2/2, step 11529/16670 completed (loss: 0.06725906580686569, acc: 0.9862068891525269)
[2024-11-14 09:56:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:38][root][INFO] - Training Epoch: 2/2, step 11530/16670 completed (loss: 0.0170025322586298, acc: 0.9943181872367859)
[2024-11-14 09:56:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:38][root][INFO] - Training Epoch: 2/2, step 11531/16670 completed (loss: 0.3353891968727112, acc: 0.8995434045791626)
[2024-11-14 09:56:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:39][root][INFO] - Training Epoch: 2/2, step 11532/16670 completed (loss: 0.05952541530132294, acc: 0.9906103014945984)
[2024-11-14 09:56:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:39][root][INFO] - Training Epoch: 2/2, step 11533/16670 completed (loss: 0.12234438210725784, acc: 0.96517413854599)
[2024-11-14 09:56:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:39][root][INFO] - Training Epoch: 2/2, step 11534/16670 completed (loss: 0.07030076533555984, acc: 0.9716981053352356)
[2024-11-14 09:56:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:40][root][INFO] - Training Epoch: 2/2, step 11535/16670 completed (loss: 0.07874219864606857, acc: 0.9803921580314636)
[2024-11-14 09:56:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:40][root][INFO] - Training Epoch: 2/2, step 11536/16670 completed (loss: 0.08327507227659225, acc: 0.9724770784378052)
[2024-11-14 09:56:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:40][root][INFO] - Training Epoch: 2/2, step 11537/16670 completed (loss: 0.08933970332145691, acc: 0.9790576100349426)
[2024-11-14 09:56:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:41][root][INFO] - Training Epoch: 2/2, step 11538/16670 completed (loss: 0.31187161803245544, acc: 0.9220183491706848)
[2024-11-14 09:56:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:41][root][INFO] - Training Epoch: 2/2, step 11539/16670 completed (loss: 0.188807412981987, acc: 0.9473684430122375)
[2024-11-14 09:56:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:41][root][INFO] - Training Epoch: 2/2, step 11540/16670 completed (loss: 0.06313573569059372, acc: 0.9701492786407471)
[2024-11-14 09:56:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:42][root][INFO] - Training Epoch: 2/2, step 11541/16670 completed (loss: 0.06881941854953766, acc: 0.9768785834312439)
[2024-11-14 09:56:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:42][root][INFO] - Training Epoch: 2/2, step 11542/16670 completed (loss: 0.1095409095287323, acc: 0.9739130139350891)
[2024-11-14 09:56:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:42][root][INFO] - Training Epoch: 2/2, step 11543/16670 completed (loss: 0.07023797184228897, acc: 0.991631805896759)
[2024-11-14 09:56:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:43][root][INFO] - Training Epoch: 2/2, step 11544/16670 completed (loss: 0.11074280738830566, acc: 0.9598662257194519)
[2024-11-14 09:56:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:43][root][INFO] - Training Epoch: 2/2, step 11545/16670 completed (loss: 0.11725588887929916, acc: 0.9837398529052734)
[2024-11-14 09:56:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:43][root][INFO] - Training Epoch: 2/2, step 11546/16670 completed (loss: 0.3105665147304535, acc: 0.9265536665916443)
[2024-11-14 09:56:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:44][root][INFO] - Training Epoch: 2/2, step 11547/16670 completed (loss: 0.16042585670948029, acc: 0.9632353186607361)
[2024-11-14 09:56:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:44][root][INFO] - Training Epoch: 2/2, step 11548/16670 completed (loss: 0.0691681057214737, acc: 0.9753086566925049)
[2024-11-14 09:56:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:44][root][INFO] - Training Epoch: 2/2, step 11549/16670 completed (loss: 0.11776299774646759, acc: 0.9620253443717957)
[2024-11-14 09:56:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:45][root][INFO] - Training Epoch: 2/2, step 11550/16670 completed (loss: 0.08485472947359085, acc: 0.9750000238418579)
[2024-11-14 09:56:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:45][root][INFO] - Training Epoch: 2/2, step 11551/16670 completed (loss: 0.16291406750679016, acc: 0.9671052694320679)
[2024-11-14 09:56:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:46][root][INFO] - Training Epoch: 2/2, step 11552/16670 completed (loss: 0.14618799090385437, acc: 0.9611650705337524)
[2024-11-14 09:56:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:46][root][INFO] - Training Epoch: 2/2, step 11553/16670 completed (loss: 0.04333633556962013, acc: 0.9849246144294739)
[2024-11-14 09:56:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:46][root][INFO] - Training Epoch: 2/2, step 11554/16670 completed (loss: 0.05969325825572014, acc: 0.9888888597488403)
[2024-11-14 09:56:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:47][root][INFO] - Training Epoch: 2/2, step 11555/16670 completed (loss: 0.013902478851377964, acc: 0.9952380657196045)
[2024-11-14 09:56:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:47][root][INFO] - Training Epoch: 2/2, step 11556/16670 completed (loss: 0.10702251642942429, acc: 0.9599999785423279)
[2024-11-14 09:56:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:47][root][INFO] - Training Epoch: 2/2, step 11557/16670 completed (loss: 0.1580820530653, acc: 0.9712918400764465)
[2024-11-14 09:56:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:48][root][INFO] - Training Epoch: 2/2, step 11558/16670 completed (loss: 0.18423332273960114, acc: 0.949367105960846)
[2024-11-14 09:56:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:48][root][INFO] - Training Epoch: 2/2, step 11559/16670 completed (loss: 0.16229839622974396, acc: 0.9498327970504761)
[2024-11-14 09:56:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:48][root][INFO] - Training Epoch: 2/2, step 11560/16670 completed (loss: 0.06572646647691727, acc: 0.9731183052062988)
[2024-11-14 09:56:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:49][root][INFO] - Training Epoch: 2/2, step 11561/16670 completed (loss: 0.049505576491355896, acc: 0.9806763529777527)
[2024-11-14 09:56:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:49][root][INFO] - Training Epoch: 2/2, step 11562/16670 completed (loss: 0.13755591213703156, acc: 0.9665071964263916)
[2024-11-14 09:56:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:49][root][INFO] - Training Epoch: 2/2, step 11563/16670 completed (loss: 0.1911034882068634, acc: 0.9390863180160522)
[2024-11-14 09:56:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:50][root][INFO] - Training Epoch: 2/2, step 11564/16670 completed (loss: 0.07210730016231537, acc: 0.9753086566925049)
[2024-11-14 09:56:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:50][root][INFO] - Training Epoch: 2/2, step 11565/16670 completed (loss: 0.14620667695999146, acc: 0.9634146094322205)
[2024-11-14 09:56:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:51][root][INFO] - Training Epoch: 2/2, step 11566/16670 completed (loss: 0.030665341764688492, acc: 0.9825327396392822)
[2024-11-14 09:56:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:51][root][INFO] - Training Epoch: 2/2, step 11567/16670 completed (loss: 0.15566784143447876, acc: 0.9710144996643066)
[2024-11-14 09:56:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:51][root][INFO] - Training Epoch: 2/2, step 11568/16670 completed (loss: 0.06998149305582047, acc: 0.9789915680885315)
[2024-11-14 09:56:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:52][root][INFO] - Training Epoch: 2/2, step 11569/16670 completed (loss: 0.06212514638900757, acc: 0.9803921580314636)
[2024-11-14 09:56:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:52][root][INFO] - Training Epoch: 2/2, step 11570/16670 completed (loss: 0.10521908849477768, acc: 0.9646017551422119)
[2024-11-14 09:56:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:52][root][INFO] - Training Epoch: 2/2, step 11571/16670 completed (loss: 0.0723089948296547, acc: 0.9870550036430359)
[2024-11-14 09:56:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:53][root][INFO] - Training Epoch: 2/2, step 11572/16670 completed (loss: 0.1460944265127182, acc: 0.9668508172035217)
[2024-11-14 09:56:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:53][root][INFO] - Training Epoch: 2/2, step 11573/16670 completed (loss: 0.02541128732264042, acc: 0.9894179701805115)
[2024-11-14 09:56:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:53][root][INFO] - Training Epoch: 2/2, step 11574/16670 completed (loss: 0.10632934421300888, acc: 0.9841269850730896)
[2024-11-14 09:56:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:54][root][INFO] - Training Epoch: 2/2, step 11575/16670 completed (loss: 0.10762342065572739, acc: 0.949999988079071)
[2024-11-14 09:56:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:54][root][INFO] - Training Epoch: 2/2, step 11576/16670 completed (loss: 0.011283596977591515, acc: 1.0)
[2024-11-14 09:56:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:55][root][INFO] - Training Epoch: 2/2, step 11577/16670 completed (loss: 0.12590695917606354, acc: 0.9653679728507996)
[2024-11-14 09:56:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:55][root][INFO] - Training Epoch: 2/2, step 11578/16670 completed (loss: 0.07914557307958603, acc: 0.976190447807312)
[2024-11-14 09:56:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:55][root][INFO] - Training Epoch: 2/2, step 11579/16670 completed (loss: 0.13909979164600372, acc: 0.9802631735801697)
[2024-11-14 09:56:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:56][root][INFO] - Training Epoch: 2/2, step 11580/16670 completed (loss: 0.04538343474268913, acc: 0.9905956387519836)
[2024-11-14 09:56:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:56][root][INFO] - Training Epoch: 2/2, step 11581/16670 completed (loss: 0.109556645154953, acc: 0.9871244430541992)
[2024-11-14 09:56:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:56][root][INFO] - Training Epoch: 2/2, step 11582/16670 completed (loss: 0.07415149360895157, acc: 0.970059871673584)
[2024-11-14 09:56:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:57][root][INFO] - Training Epoch: 2/2, step 11583/16670 completed (loss: 0.1854463368654251, acc: 0.9622641801834106)
[2024-11-14 09:56:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:57][root][INFO] - Training Epoch: 2/2, step 11584/16670 completed (loss: 0.5117210745811462, acc: 0.8656716346740723)
[2024-11-14 09:56:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:57][root][INFO] - Training Epoch: 2/2, step 11585/16670 completed (loss: 0.10341973602771759, acc: 0.9736841917037964)
[2024-11-14 09:56:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:58][root][INFO] - Training Epoch: 2/2, step 11586/16670 completed (loss: 0.13843663036823273, acc: 0.9567901492118835)
[2024-11-14 09:56:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:58][root][INFO] - Training Epoch: 2/2, step 11587/16670 completed (loss: 0.11717303842306137, acc: 0.9740932583808899)
[2024-11-14 09:56:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:58][root][INFO] - Training Epoch: 2/2, step 11588/16670 completed (loss: 0.036786630749702454, acc: 0.9814814925193787)
[2024-11-14 09:56:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:59][root][INFO] - Training Epoch: 2/2, step 11589/16670 completed (loss: 0.14633065462112427, acc: 0.961904764175415)
[2024-11-14 09:56:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:59][root][INFO] - Training Epoch: 2/2, step 11590/16670 completed (loss: 0.11665255576372147, acc: 0.9734513163566589)
[2024-11-14 09:56:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:56:59][root][INFO] - Training Epoch: 2/2, step 11591/16670 completed (loss: 0.3650403618812561, acc: 0.8897058963775635)
[2024-11-14 09:57:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:00][root][INFO] - Training Epoch: 2/2, step 11592/16670 completed (loss: 0.036885958164930344, acc: 0.9806451797485352)
[2024-11-14 09:57:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:00][root][INFO] - Training Epoch: 2/2, step 11593/16670 completed (loss: 0.03803365305066109, acc: 0.990338146686554)
[2024-11-14 09:57:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:00][root][INFO] - Training Epoch: 2/2, step 11594/16670 completed (loss: 0.0696708932518959, acc: 0.9897959232330322)
[2024-11-14 09:57:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:01][root][INFO] - Training Epoch: 2/2, step 11595/16670 completed (loss: 0.059439610689878464, acc: 0.9670329689979553)
[2024-11-14 09:57:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:01][root][INFO] - Training Epoch: 2/2, step 11596/16670 completed (loss: 0.10375986248254776, acc: 0.9693877696990967)
[2024-11-14 09:57:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:01][root][INFO] - Training Epoch: 2/2, step 11597/16670 completed (loss: 0.024686938151717186, acc: 1.0)
[2024-11-14 09:57:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:02][root][INFO] - Training Epoch: 2/2, step 11598/16670 completed (loss: 0.11509054899215698, acc: 0.9696969985961914)
[2024-11-14 09:57:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:02][root][INFO] - Training Epoch: 2/2, step 11599/16670 completed (loss: 0.017453912645578384, acc: 1.0)
[2024-11-14 09:57:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:02][root][INFO] - Training Epoch: 2/2, step 11600/16670 completed (loss: 0.12209125608205795, acc: 0.9624413251876831)
[2024-11-14 09:57:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:03][root][INFO] - Training Epoch: 2/2, step 11601/16670 completed (loss: 0.10586196929216385, acc: 0.9689440727233887)
[2024-11-14 09:57:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:03][root][INFO] - Training Epoch: 2/2, step 11602/16670 completed (loss: 0.05432549864053726, acc: 0.9896907210350037)
[2024-11-14 09:57:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:03][root][INFO] - Training Epoch: 2/2, step 11603/16670 completed (loss: 0.1822216510772705, acc: 0.9459459185600281)
[2024-11-14 09:57:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:04][root][INFO] - Training Epoch: 2/2, step 11604/16670 completed (loss: 0.12694503366947174, acc: 0.9673202633857727)
[2024-11-14 09:57:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:04][root][INFO] - Training Epoch: 2/2, step 11605/16670 completed (loss: 0.07890167087316513, acc: 0.9822221994400024)
[2024-11-14 09:57:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:04][root][INFO] - Training Epoch: 2/2, step 11606/16670 completed (loss: 0.10512502491474152, acc: 0.9797297120094299)
[2024-11-14 09:57:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:05][root][INFO] - Training Epoch: 2/2, step 11607/16670 completed (loss: 0.06614280492067337, acc: 0.9646643400192261)
[2024-11-14 09:57:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:05][root][INFO] - Training Epoch: 2/2, step 11608/16670 completed (loss: 0.08841358125209808, acc: 0.967391312122345)
[2024-11-14 09:57:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:05][root][INFO] - Training Epoch: 2/2, step 11609/16670 completed (loss: 0.1188756674528122, acc: 0.9584664702415466)
[2024-11-14 09:57:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:06][root][INFO] - Training Epoch: 2/2, step 11610/16670 completed (loss: 0.05924173817038536, acc: 0.9886363744735718)
[2024-11-14 09:57:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:06][root][INFO] - Training Epoch: 2/2, step 11611/16670 completed (loss: 0.04288129135966301, acc: 0.9870129823684692)
[2024-11-14 09:57:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:06][root][INFO] - Training Epoch: 2/2, step 11612/16670 completed (loss: 0.13192559778690338, acc: 0.9678714871406555)
[2024-11-14 09:57:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:06][root][INFO] - Training Epoch: 2/2, step 11613/16670 completed (loss: 0.12940816581249237, acc: 0.9516907930374146)
[2024-11-14 09:57:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:07][root][INFO] - Training Epoch: 2/2, step 11614/16670 completed (loss: 0.15946532785892487, acc: 0.9655172228813171)
[2024-11-14 09:57:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:07][root][INFO] - Training Epoch: 2/2, step 11615/16670 completed (loss: 0.06985566765069962, acc: 0.9629629850387573)
[2024-11-14 09:57:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:07][root][INFO] - Training Epoch: 2/2, step 11616/16670 completed (loss: 0.04166712239384651, acc: 0.9856459498405457)
[2024-11-14 09:57:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:08][root][INFO] - Training Epoch: 2/2, step 11617/16670 completed (loss: 0.10720530897378922, acc: 0.9793814420700073)
[2024-11-14 09:57:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:08][root][INFO] - Training Epoch: 2/2, step 11618/16670 completed (loss: 0.11904075741767883, acc: 0.9640718698501587)
[2024-11-14 09:57:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:08][root][INFO] - Training Epoch: 2/2, step 11619/16670 completed (loss: 0.039765894412994385, acc: 0.9817073345184326)
[2024-11-14 09:57:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:09][root][INFO] - Training Epoch: 2/2, step 11620/16670 completed (loss: 0.11700978875160217, acc: 0.9354838728904724)
[2024-11-14 09:57:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:09][root][INFO] - Training Epoch: 2/2, step 11621/16670 completed (loss: 0.06758566200733185, acc: 0.9655172228813171)
[2024-11-14 09:57:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:09][root][INFO] - Training Epoch: 2/2, step 11622/16670 completed (loss: 0.21164314448833466, acc: 0.9453125)
[2024-11-14 09:57:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:09][root][INFO] - Training Epoch: 2/2, step 11623/16670 completed (loss: 0.08812922984361649, acc: 0.9732620120048523)
[2024-11-14 09:57:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:10][root][INFO] - Training Epoch: 2/2, step 11624/16670 completed (loss: 0.18167445063591003, acc: 0.9545454382896423)
[2024-11-14 09:57:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:10][root][INFO] - Training Epoch: 2/2, step 11625/16670 completed (loss: 0.021717971190810204, acc: 0.9946236610412598)
[2024-11-14 09:57:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:10][root][INFO] - Training Epoch: 2/2, step 11626/16670 completed (loss: 0.09785573929548264, acc: 0.9803921580314636)
[2024-11-14 09:57:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:11][root][INFO] - Training Epoch: 2/2, step 11627/16670 completed (loss: 0.16429536044597626, acc: 0.9599999785423279)
[2024-11-14 09:57:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:11][root][INFO] - Training Epoch: 2/2, step 11628/16670 completed (loss: 0.08687353879213333, acc: 0.9684210419654846)
[2024-11-14 09:57:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:11][root][INFO] - Training Epoch: 2/2, step 11629/16670 completed (loss: 0.1439766138792038, acc: 0.954356849193573)
[2024-11-14 09:57:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:12][root][INFO] - Training Epoch: 2/2, step 11630/16670 completed (loss: 0.05332820862531662, acc: 0.9846938848495483)
[2024-11-14 09:57:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:12][root][INFO] - Training Epoch: 2/2, step 11631/16670 completed (loss: 0.10074068605899811, acc: 0.9748954176902771)
[2024-11-14 09:57:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:12][root][INFO] - Training Epoch: 2/2, step 11632/16670 completed (loss: 0.15382133424282074, acc: 0.9588015079498291)
[2024-11-14 09:57:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:13][root][INFO] - Training Epoch: 2/2, step 11633/16670 completed (loss: 0.09600194543600082, acc: 0.9685039520263672)
[2024-11-14 09:57:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:13][root][INFO] - Training Epoch: 2/2, step 11634/16670 completed (loss: 0.017191391438245773, acc: 1.0)
[2024-11-14 09:57:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:13][root][INFO] - Training Epoch: 2/2, step 11635/16670 completed (loss: 0.11884281784296036, acc: 0.970588207244873)
[2024-11-14 09:57:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:14][root][INFO] - Training Epoch: 2/2, step 11636/16670 completed (loss: 0.16502927243709564, acc: 0.9613733887672424)
[2024-11-14 09:57:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:14][root][INFO] - Training Epoch: 2/2, step 11637/16670 completed (loss: 0.33172908425331116, acc: 0.921875)
[2024-11-14 09:57:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:14][root][INFO] - Training Epoch: 2/2, step 11638/16670 completed (loss: 0.16210423409938812, acc: 0.9452054500579834)
[2024-11-14 09:57:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:15][root][INFO] - Training Epoch: 2/2, step 11639/16670 completed (loss: 0.2767230272293091, acc: 0.9411764740943909)
[2024-11-14 09:57:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:15][root][INFO] - Training Epoch: 2/2, step 11640/16670 completed (loss: 0.08039368689060211, acc: 0.9775280952453613)
[2024-11-14 09:57:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:16][root][INFO] - Training Epoch: 2/2, step 11641/16670 completed (loss: 0.0949421152472496, acc: 0.969072163105011)
[2024-11-14 09:57:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:16][root][INFO] - Training Epoch: 2/2, step 11642/16670 completed (loss: 0.13853216171264648, acc: 0.961904764175415)
[2024-11-14 09:57:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:16][root][INFO] - Training Epoch: 2/2, step 11643/16670 completed (loss: 0.05652925744652748, acc: 0.9852941036224365)
[2024-11-14 09:57:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:16][root][INFO] - Training Epoch: 2/2, step 11644/16670 completed (loss: 0.10512153804302216, acc: 0.9701492786407471)
[2024-11-14 09:57:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:17][root][INFO] - Training Epoch: 2/2, step 11645/16670 completed (loss: 0.5287328362464905, acc: 0.8428571224212646)
[2024-11-14 09:57:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:17][root][INFO] - Training Epoch: 2/2, step 11646/16670 completed (loss: 0.17593732476234436, acc: 0.9390243887901306)
[2024-11-14 09:57:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:17][root][INFO] - Training Epoch: 2/2, step 11647/16670 completed (loss: 0.054943159222602844, acc: 0.9818181991577148)
[2024-11-14 09:57:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:18][root][INFO] - Training Epoch: 2/2, step 11648/16670 completed (loss: 0.07986638695001602, acc: 0.9849056601524353)
[2024-11-14 09:57:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:18][root][INFO] - Training Epoch: 2/2, step 11649/16670 completed (loss: 0.1521432101726532, acc: 0.9572953581809998)
[2024-11-14 09:57:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:19][root][INFO] - Training Epoch: 2/2, step 11650/16670 completed (loss: 0.2670726478099823, acc: 0.9259259104728699)
[2024-11-14 09:57:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:19][root][INFO] - Training Epoch: 2/2, step 11651/16670 completed (loss: 0.1479586809873581, acc: 0.9586777091026306)
[2024-11-14 09:57:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:19][root][INFO] - Training Epoch: 2/2, step 11652/16670 completed (loss: 0.0915849357843399, acc: 0.978723406791687)
[2024-11-14 09:57:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:20][root][INFO] - Training Epoch: 2/2, step 11653/16670 completed (loss: 0.12149135023355484, acc: 0.9724137783050537)
[2024-11-14 09:57:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:20][root][INFO] - Training Epoch: 2/2, step 11654/16670 completed (loss: 0.14525803923606873, acc: 0.9629629850387573)
[2024-11-14 09:57:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:20][root][INFO] - Training Epoch: 2/2, step 11655/16670 completed (loss: 0.0882340744137764, acc: 0.9745042324066162)
[2024-11-14 09:57:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:21][root][INFO] - Training Epoch: 2/2, step 11656/16670 completed (loss: 0.1396140307188034, acc: 0.9583333134651184)
[2024-11-14 09:57:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:21][root][INFO] - Training Epoch: 2/2, step 11657/16670 completed (loss: 0.08007317781448364, acc: 0.9672130942344666)
[2024-11-14 09:57:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:21][root][INFO] - Training Epoch: 2/2, step 11658/16670 completed (loss: 0.1071339100599289, acc: 0.9813664555549622)
[2024-11-14 09:57:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:22][root][INFO] - Training Epoch: 2/2, step 11659/16670 completed (loss: 0.09567403048276901, acc: 0.9671052694320679)
[2024-11-14 09:57:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:22][root][INFO] - Training Epoch: 2/2, step 11660/16670 completed (loss: 0.09807899594306946, acc: 0.9736841917037964)
[2024-11-14 09:57:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:22][root][INFO] - Training Epoch: 2/2, step 11661/16670 completed (loss: 0.05947447195649147, acc: 0.9837837815284729)
[2024-11-14 09:57:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:23][root][INFO] - Training Epoch: 2/2, step 11662/16670 completed (loss: 0.06638368219137192, acc: 0.987261176109314)
[2024-11-14 09:57:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:23][root][INFO] - Training Epoch: 2/2, step 11663/16670 completed (loss: 0.08340508490800858, acc: 0.9829787015914917)
[2024-11-14 09:57:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:23][root][INFO] - Training Epoch: 2/2, step 11664/16670 completed (loss: 0.03824681416153908, acc: 0.9800000190734863)
[2024-11-14 09:57:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:24][root][INFO] - Training Epoch: 2/2, step 11665/16670 completed (loss: 0.14637528359889984, acc: 0.9534883499145508)
[2024-11-14 09:57:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:24][root][INFO] - Training Epoch: 2/2, step 11666/16670 completed (loss: 0.14522479474544525, acc: 0.9716598987579346)
[2024-11-14 09:57:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:24][root][INFO] - Training Epoch: 2/2, step 11667/16670 completed (loss: 0.009856997057795525, acc: 1.0)
[2024-11-14 09:57:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:25][root][INFO] - Training Epoch: 2/2, step 11668/16670 completed (loss: 0.2848711907863617, acc: 0.9316770434379578)
[2024-11-14 09:57:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:25][root][INFO] - Training Epoch: 2/2, step 11669/16670 completed (loss: 0.14897283911705017, acc: 0.9644444584846497)
[2024-11-14 09:57:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:25][root][INFO] - Training Epoch: 2/2, step 11670/16670 completed (loss: 0.10627385973930359, acc: 0.9665427803993225)
[2024-11-14 09:57:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:26][root][INFO] - Training Epoch: 2/2, step 11671/16670 completed (loss: 0.11827702075242996, acc: 0.9748603105545044)
[2024-11-14 09:57:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:26][root][INFO] - Training Epoch: 2/2, step 11672/16670 completed (loss: 0.12255578488111496, acc: 0.9684210419654846)
[2024-11-14 09:57:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:26][root][INFO] - Training Epoch: 2/2, step 11673/16670 completed (loss: 0.1270749568939209, acc: 0.9589743614196777)
[2024-11-14 09:57:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:27][root][INFO] - Training Epoch: 2/2, step 11674/16670 completed (loss: 0.04411450773477554, acc: 0.9801980257034302)
[2024-11-14 09:57:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:27][root][INFO] - Training Epoch: 2/2, step 11675/16670 completed (loss: 0.08851714432239532, acc: 0.9850187301635742)
[2024-11-14 09:57:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:27][root][INFO] - Training Epoch: 2/2, step 11676/16670 completed (loss: 0.14220939576625824, acc: 0.967391312122345)
[2024-11-14 09:57:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:28][root][INFO] - Training Epoch: 2/2, step 11677/16670 completed (loss: 0.1118645966053009, acc: 0.9595375657081604)
[2024-11-14 09:57:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:28][root][INFO] - Training Epoch: 2/2, step 11678/16670 completed (loss: 0.1641860455274582, acc: 0.9594594836235046)
[2024-11-14 09:57:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:28][root][INFO] - Training Epoch: 2/2, step 11679/16670 completed (loss: 0.2586171627044678, acc: 0.9629629850387573)
[2024-11-14 09:57:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:29][root][INFO] - Training Epoch: 2/2, step 11680/16670 completed (loss: 0.13301433622837067, acc: 0.9575289487838745)
[2024-11-14 09:57:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:29][root][INFO] - Training Epoch: 2/2, step 11681/16670 completed (loss: 0.042857613414525986, acc: 0.984000027179718)
[2024-11-14 09:57:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:29][root][INFO] - Training Epoch: 2/2, step 11682/16670 completed (loss: 0.23310282826423645, acc: 0.9365079402923584)
[2024-11-14 09:57:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:30][root][INFO] - Training Epoch: 2/2, step 11683/16670 completed (loss: 0.11548523604869843, acc: 0.9672130942344666)
[2024-11-14 09:57:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:30][root][INFO] - Training Epoch: 2/2, step 11684/16670 completed (loss: 0.1675594002008438, acc: 0.9610389471054077)
[2024-11-14 09:57:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:30][root][INFO] - Training Epoch: 2/2, step 11685/16670 completed (loss: 0.13666976988315582, acc: 0.9588235020637512)
[2024-11-14 09:57:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:31][root][INFO] - Training Epoch: 2/2, step 11686/16670 completed (loss: 0.04743353649973869, acc: 0.9760000109672546)
[2024-11-14 09:57:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:31][root][INFO] - Training Epoch: 2/2, step 11687/16670 completed (loss: 0.06571198254823685, acc: 0.9878048896789551)
[2024-11-14 09:57:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:31][root][INFO] - Training Epoch: 2/2, step 11688/16670 completed (loss: 0.032860856503248215, acc: 0.9929078221321106)
[2024-11-14 09:57:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:32][root][INFO] - Training Epoch: 2/2, step 11689/16670 completed (loss: 0.281304270029068, acc: 0.9230769276618958)
[2024-11-14 09:57:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:32][root][INFO] - Training Epoch: 2/2, step 11690/16670 completed (loss: 0.20239880681037903, acc: 0.9437500238418579)
[2024-11-14 09:57:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:32][root][INFO] - Training Epoch: 2/2, step 11691/16670 completed (loss: 0.1007537916302681, acc: 0.97826087474823)
[2024-11-14 09:57:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:33][root][INFO] - Training Epoch: 2/2, step 11692/16670 completed (loss: 0.15053801238536835, acc: 0.9586777091026306)
[2024-11-14 09:57:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:33][root][INFO] - Training Epoch: 2/2, step 11693/16670 completed (loss: 0.07144054025411606, acc: 0.9818181991577148)
[2024-11-14 09:57:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:34][root][INFO] - Training Epoch: 2/2, step 11694/16670 completed (loss: 0.08063550293445587, acc: 0.9627329111099243)
[2024-11-14 09:57:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:34][root][INFO] - Training Epoch: 2/2, step 11695/16670 completed (loss: 0.1488722860813141, acc: 0.9611111283302307)
[2024-11-14 09:57:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:34][root][INFO] - Training Epoch: 2/2, step 11696/16670 completed (loss: 0.21640725433826447, acc: 0.9515418410301208)
[2024-11-14 09:57:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:35][root][INFO] - Training Epoch: 2/2, step 11697/16670 completed (loss: 0.15017396211624146, acc: 0.9577465057373047)
[2024-11-14 09:57:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:35][root][INFO] - Training Epoch: 2/2, step 11698/16670 completed (loss: 0.05056281387805939, acc: 0.9795918464660645)
[2024-11-14 09:57:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:35][root][INFO] - Training Epoch: 2/2, step 11699/16670 completed (loss: 0.2412179559469223, acc: 0.9509202241897583)
[2024-11-14 09:57:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:36][root][INFO] - Training Epoch: 2/2, step 11700/16670 completed (loss: 0.04499667510390282, acc: 0.9934640526771545)
[2024-11-14 09:57:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:36][root][INFO] - Training Epoch: 2/2, step 11701/16670 completed (loss: 0.10732360184192657, acc: 0.9716312289237976)
[2024-11-14 09:57:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:36][root][INFO] - Training Epoch: 2/2, step 11702/16670 completed (loss: 0.0953693613409996, acc: 0.9809160232543945)
[2024-11-14 09:57:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:37][root][INFO] - Training Epoch: 2/2, step 11703/16670 completed (loss: 0.23124045133590698, acc: 0.9629629850387573)
[2024-11-14 09:57:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:37][root][INFO] - Training Epoch: 2/2, step 11704/16670 completed (loss: 0.11168750375509262, acc: 0.9829059839248657)
[2024-11-14 09:57:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:37][root][INFO] - Training Epoch: 2/2, step 11705/16670 completed (loss: 0.21692022681236267, acc: 0.9545454382896423)
[2024-11-14 09:57:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:38][root][INFO] - Training Epoch: 2/2, step 11706/16670 completed (loss: 0.07775384187698364, acc: 0.9760000109672546)
[2024-11-14 09:57:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:38][root][INFO] - Training Epoch: 2/2, step 11707/16670 completed (loss: 0.17365959286689758, acc: 0.9466666579246521)
[2024-11-14 09:57:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:38][root][INFO] - Training Epoch: 2/2, step 11708/16670 completed (loss: 0.08154226839542389, acc: 0.9850746393203735)
[2024-11-14 09:57:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:39][root][INFO] - Training Epoch: 2/2, step 11709/16670 completed (loss: 0.14100250601768494, acc: 0.9416666626930237)
[2024-11-14 09:57:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:39][root][INFO] - Training Epoch: 2/2, step 11710/16670 completed (loss: 0.2962636351585388, acc: 0.9014084339141846)
[2024-11-14 09:57:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:39][root][INFO] - Training Epoch: 2/2, step 11711/16670 completed (loss: 0.21963028609752655, acc: 0.9599999785423279)
[2024-11-14 09:57:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:40][root][INFO] - Training Epoch: 2/2, step 11712/16670 completed (loss: 0.1318923830986023, acc: 0.9809523820877075)
[2024-11-14 09:57:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:40][root][INFO] - Training Epoch: 2/2, step 11713/16670 completed (loss: 0.20013569295406342, acc: 0.936170220375061)
[2024-11-14 09:57:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:40][root][INFO] - Training Epoch: 2/2, step 11714/16670 completed (loss: 0.13738034665584564, acc: 0.9708737730979919)
[2024-11-14 09:57:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:41][root][INFO] - Training Epoch: 2/2, step 11715/16670 completed (loss: 0.07439892739057541, acc: 0.976190447807312)
[2024-11-14 09:57:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:41][root][INFO] - Training Epoch: 2/2, step 11716/16670 completed (loss: 0.08114098012447357, acc: 0.9708737730979919)
[2024-11-14 09:57:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:41][root][INFO] - Training Epoch: 2/2, step 11717/16670 completed (loss: 0.019932737573981285, acc: 0.9948717951774597)
[2024-11-14 09:57:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:42][root][INFO] - Training Epoch: 2/2, step 11718/16670 completed (loss: 0.30598264932632446, acc: 0.934959352016449)
[2024-11-14 09:57:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:42][root][INFO] - Training Epoch: 2/2, step 11719/16670 completed (loss: 0.025793444365262985, acc: 0.9898989796638489)
[2024-11-14 09:57:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:42][root][INFO] - Training Epoch: 2/2, step 11720/16670 completed (loss: 0.1564340889453888, acc: 0.9420289993286133)
[2024-11-14 09:57:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:43][root][INFO] - Training Epoch: 2/2, step 11721/16670 completed (loss: 0.149999737739563, acc: 0.9552238583564758)
[2024-11-14 09:57:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:43][root][INFO] - Training Epoch: 2/2, step 11722/16670 completed (loss: 0.10932324826717377, acc: 0.9428571462631226)
[2024-11-14 09:57:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:43][root][INFO] - Training Epoch: 2/2, step 11723/16670 completed (loss: 0.09258517622947693, acc: 0.9767441749572754)
[2024-11-14 09:57:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:44][root][INFO] - Training Epoch: 2/2, step 11724/16670 completed (loss: 0.13334883749485016, acc: 0.9746835231781006)
[2024-11-14 09:57:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:44][root][INFO] - Training Epoch: 2/2, step 11725/16670 completed (loss: 0.16468864679336548, acc: 0.9670329689979553)
[2024-11-14 09:57:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:45][root][INFO] - Training Epoch: 2/2, step 11726/16670 completed (loss: 0.06761471182107925, acc: 0.9792746305465698)
[2024-11-14 09:57:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:45][root][INFO] - Training Epoch: 2/2, step 11727/16670 completed (loss: 0.16878491640090942, acc: 0.9530201554298401)
[2024-11-14 09:57:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:45][root][INFO] - Training Epoch: 2/2, step 11728/16670 completed (loss: 0.07711631804704666, acc: 0.9800994992256165)
[2024-11-14 09:57:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:46][root][INFO] - Training Epoch: 2/2, step 11729/16670 completed (loss: 0.1385738104581833, acc: 0.9641434550285339)
[2024-11-14 09:57:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:46][root][INFO] - Training Epoch: 2/2, step 11730/16670 completed (loss: 0.30911099910736084, acc: 0.9279279112815857)
[2024-11-14 09:57:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:46][root][INFO] - Training Epoch: 2/2, step 11731/16670 completed (loss: 0.15462428331375122, acc: 0.9659090638160706)
[2024-11-14 09:57:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:46][root][INFO] - Training Epoch: 2/2, step 11732/16670 completed (loss: 0.30673739314079285, acc: 0.9090909361839294)
[2024-11-14 09:57:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:47][root][INFO] - Training Epoch: 2/2, step 11733/16670 completed (loss: 0.0654841810464859, acc: 0.9764705896377563)
[2024-11-14 09:57:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:47][root][INFO] - Training Epoch: 2/2, step 11734/16670 completed (loss: 0.09519742429256439, acc: 0.9802631735801697)
[2024-11-14 09:57:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:47][root][INFO] - Training Epoch: 2/2, step 11735/16670 completed (loss: 0.2211872935295105, acc: 0.9365079402923584)
[2024-11-14 09:57:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:48][root][INFO] - Training Epoch: 2/2, step 11736/16670 completed (loss: 0.17233416438102722, acc: 0.9424778819084167)
[2024-11-14 09:57:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:48][root][INFO] - Training Epoch: 2/2, step 11737/16670 completed (loss: 0.05135113373398781, acc: 0.9879518151283264)
[2024-11-14 09:57:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:48][root][INFO] - Training Epoch: 2/2, step 11738/16670 completed (loss: 0.14959914982318878, acc: 0.961904764175415)
[2024-11-14 09:57:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:49][root][INFO] - Training Epoch: 2/2, step 11739/16670 completed (loss: 0.03633202612400055, acc: 0.9950494766235352)
[2024-11-14 09:57:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:49][root][INFO] - Training Epoch: 2/2, step 11740/16670 completed (loss: 0.14848732948303223, acc: 0.9523809552192688)
[2024-11-14 09:57:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:49][root][INFO] - Training Epoch: 2/2, step 11741/16670 completed (loss: 0.13756297528743744, acc: 0.9496855139732361)
[2024-11-14 09:57:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:50][root][INFO] - Training Epoch: 2/2, step 11742/16670 completed (loss: 0.3632320165634155, acc: 0.9292929172515869)
[2024-11-14 09:57:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:50][root][INFO] - Training Epoch: 2/2, step 11743/16670 completed (loss: 0.1829468458890915, acc: 0.9506173133850098)
[2024-11-14 09:57:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:50][root][INFO] - Training Epoch: 2/2, step 11744/16670 completed (loss: 0.19217446446418762, acc: 0.9242424368858337)
[2024-11-14 09:57:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:51][root][INFO] - Training Epoch: 2/2, step 11745/16670 completed (loss: 0.1595783233642578, acc: 0.94525545835495)
[2024-11-14 09:57:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:51][root][INFO] - Training Epoch: 2/2, step 11746/16670 completed (loss: 0.12927186489105225, acc: 0.957446813583374)
[2024-11-14 09:57:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:51][root][INFO] - Training Epoch: 2/2, step 11747/16670 completed (loss: 0.05872586369514465, acc: 0.9850746393203735)
[2024-11-14 09:57:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:51][root][INFO] - Training Epoch: 2/2, step 11748/16670 completed (loss: 0.09079178422689438, acc: 0.9724137783050537)
[2024-11-14 09:57:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:52][root][INFO] - Training Epoch: 2/2, step 11749/16670 completed (loss: 0.02304096892476082, acc: 1.0)
[2024-11-14 09:57:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:52][root][INFO] - Training Epoch: 2/2, step 11750/16670 completed (loss: 0.19599996507167816, acc: 0.946601927280426)
[2024-11-14 09:57:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:52][root][INFO] - Training Epoch: 2/2, step 11751/16670 completed (loss: 0.29400235414505005, acc: 0.9464285969734192)
[2024-11-14 09:57:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:53][root][INFO] - Training Epoch: 2/2, step 11752/16670 completed (loss: 0.14334850013256073, acc: 0.9649122953414917)
[2024-11-14 09:57:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:53][root][INFO] - Training Epoch: 2/2, step 11753/16670 completed (loss: 0.07765589654445648, acc: 0.9833333492279053)
[2024-11-14 09:57:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:53][root][INFO] - Training Epoch: 2/2, step 11754/16670 completed (loss: 0.16429109871387482, acc: 0.9541984796524048)
[2024-11-14 09:57:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:54][root][INFO] - Training Epoch: 2/2, step 11755/16670 completed (loss: 0.12908656895160675, acc: 0.9693251252174377)
[2024-11-14 09:57:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:54][root][INFO] - Training Epoch: 2/2, step 11756/16670 completed (loss: 0.025191348046064377, acc: 0.9954128265380859)
[2024-11-14 09:57:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:54][root][INFO] - Training Epoch: 2/2, step 11757/16670 completed (loss: 0.08660034090280533, acc: 0.9766082167625427)
[2024-11-14 09:57:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:55][root][INFO] - Training Epoch: 2/2, step 11758/16670 completed (loss: 0.051517874002456665, acc: 0.991304337978363)
[2024-11-14 09:57:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:55][root][INFO] - Training Epoch: 2/2, step 11759/16670 completed (loss: 0.2755075991153717, acc: 0.9102563858032227)
[2024-11-14 09:57:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:55][root][INFO] - Training Epoch: 2/2, step 11760/16670 completed (loss: 0.11827027797698975, acc: 0.9739130139350891)
[2024-11-14 09:57:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:56][root][INFO] - Training Epoch: 2/2, step 11761/16670 completed (loss: 0.05754464492201805, acc: 0.9886363744735718)
[2024-11-14 09:57:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:56][root][INFO] - Training Epoch: 2/2, step 11762/16670 completed (loss: 0.08779995888471603, acc: 0.9769230484962463)
[2024-11-14 09:57:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:56][root][INFO] - Training Epoch: 2/2, step 11763/16670 completed (loss: 0.06922256201505661, acc: 0.9916666746139526)
[2024-11-14 09:57:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:57][root][INFO] - Training Epoch: 2/2, step 11764/16670 completed (loss: 0.3017055094242096, acc: 0.9439252614974976)
[2024-11-14 09:57:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:57][root][INFO] - Training Epoch: 2/2, step 11765/16670 completed (loss: 0.12869323790073395, acc: 0.9618320465087891)
[2024-11-14 09:57:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:57][root][INFO] - Training Epoch: 2/2, step 11766/16670 completed (loss: 0.029011232778429985, acc: 0.9863013625144958)
[2024-11-14 09:57:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:58][root][INFO] - Training Epoch: 2/2, step 11767/16670 completed (loss: 0.04595821723341942, acc: 0.9800000190734863)
[2024-11-14 09:57:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:58][root][INFO] - Training Epoch: 2/2, step 11768/16670 completed (loss: 0.1313096135854721, acc: 0.9597315192222595)
[2024-11-14 09:57:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:58][root][INFO] - Training Epoch: 2/2, step 11769/16670 completed (loss: 0.04292728379368782, acc: 0.9887640476226807)
[2024-11-14 09:57:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:59][root][INFO] - Training Epoch: 2/2, step 11770/16670 completed (loss: 0.23392532765865326, acc: 0.9384615421295166)
[2024-11-14 09:57:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:59][root][INFO] - Training Epoch: 2/2, step 11771/16670 completed (loss: 0.0833473950624466, acc: 0.9781659245491028)
[2024-11-14 09:57:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:59][root][INFO] - Training Epoch: 2/2, step 11772/16670 completed (loss: 0.16420423984527588, acc: 0.976190447807312)
[2024-11-14 09:57:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:57:59][root][INFO] - Training Epoch: 2/2, step 11773/16670 completed (loss: 0.12343981862068176, acc: 0.969924807548523)
[2024-11-14 09:57:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:00][root][INFO] - Training Epoch: 2/2, step 11774/16670 completed (loss: 0.13564518094062805, acc: 0.9680851101875305)
[2024-11-14 09:58:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:00][root][INFO] - Training Epoch: 2/2, step 11775/16670 completed (loss: 0.0579066202044487, acc: 0.9863013625144958)
[2024-11-14 09:58:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:00][root][INFO] - Training Epoch: 2/2, step 11776/16670 completed (loss: 0.14857721328735352, acc: 0.949999988079071)
[2024-11-14 09:58:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:01][root][INFO] - Training Epoch: 2/2, step 11777/16670 completed (loss: 0.0947512611746788, acc: 0.9863013625144958)
[2024-11-14 09:58:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:01][root][INFO] - Training Epoch: 2/2, step 11778/16670 completed (loss: 0.1302044838666916, acc: 0.970802903175354)
[2024-11-14 09:58:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:01][root][INFO] - Training Epoch: 2/2, step 11779/16670 completed (loss: 0.08885355293750763, acc: 0.9717513918876648)
[2024-11-14 09:58:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:02][root][INFO] - Training Epoch: 2/2, step 11780/16670 completed (loss: 0.17219243943691254, acc: 0.9652174115180969)
[2024-11-14 09:58:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:02][root][INFO] - Training Epoch: 2/2, step 11781/16670 completed (loss: 0.13186371326446533, acc: 0.9684210419654846)
[2024-11-14 09:58:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:02][root][INFO] - Training Epoch: 2/2, step 11782/16670 completed (loss: 0.1415107101202011, acc: 0.9551020264625549)
[2024-11-14 09:58:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:03][root][INFO] - Training Epoch: 2/2, step 11783/16670 completed (loss: 0.2193911373615265, acc: 0.9520547986030579)
[2024-11-14 09:58:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:03][root][INFO] - Training Epoch: 2/2, step 11784/16670 completed (loss: 0.21528133749961853, acc: 0.943965494632721)
[2024-11-14 09:58:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:03][root][INFO] - Training Epoch: 2/2, step 11785/16670 completed (loss: 0.09505180269479752, acc: 0.9656357169151306)
[2024-11-14 09:58:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:04][root][INFO] - Training Epoch: 2/2, step 11786/16670 completed (loss: 0.12804320454597473, acc: 0.9596412777900696)
[2024-11-14 09:58:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:04][root][INFO] - Training Epoch: 2/2, step 11787/16670 completed (loss: 0.1612863391637802, acc: 0.9656862616539001)
[2024-11-14 09:58:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:04][root][INFO] - Training Epoch: 2/2, step 11788/16670 completed (loss: 0.08900146186351776, acc: 0.9690265655517578)
[2024-11-14 09:58:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:05][root][INFO] - Training Epoch: 2/2, step 11789/16670 completed (loss: 0.058312345296144485, acc: 0.9855595827102661)
[2024-11-14 09:58:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:05][root][INFO] - Training Epoch: 2/2, step 11790/16670 completed (loss: 0.10578221827745438, acc: 0.9726027250289917)
[2024-11-14 09:58:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:05][root][INFO] - Training Epoch: 2/2, step 11791/16670 completed (loss: 0.05774662271142006, acc: 0.9823529124259949)
[2024-11-14 09:58:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:05][root][INFO] - Training Epoch: 2/2, step 11792/16670 completed (loss: 0.07288426160812378, acc: 0.9824561476707458)
[2024-11-14 09:58:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:06][root][INFO] - Training Epoch: 2/2, step 11793/16670 completed (loss: 0.25438162684440613, acc: 0.9480000138282776)
[2024-11-14 09:58:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:06][root][INFO] - Training Epoch: 2/2, step 11794/16670 completed (loss: 0.09695221483707428, acc: 0.9672726988792419)
[2024-11-14 09:58:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:07][root][INFO] - Training Epoch: 2/2, step 11795/16670 completed (loss: 0.15287469327449799, acc: 0.9528301954269409)
[2024-11-14 09:58:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:07][root][INFO] - Training Epoch: 2/2, step 11796/16670 completed (loss: 0.14230318367481232, acc: 0.9529411792755127)
[2024-11-14 09:58:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:07][root][INFO] - Training Epoch: 2/2, step 11797/16670 completed (loss: 0.1202722117304802, acc: 0.96484375)
[2024-11-14 09:58:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:07][root][INFO] - Training Epoch: 2/2, step 11798/16670 completed (loss: 0.2507709562778473, acc: 0.943965494632721)
[2024-11-14 09:58:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:08][root][INFO] - Training Epoch: 2/2, step 11799/16670 completed (loss: 0.15545913577079773, acc: 0.9617021083831787)
[2024-11-14 09:58:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:08][root][INFO] - Training Epoch: 2/2, step 11800/16670 completed (loss: 0.04753976687788963, acc: 0.9860627055168152)
[2024-11-14 09:58:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:08][root][INFO] - Training Epoch: 2/2, step 11801/16670 completed (loss: 0.10032536834478378, acc: 0.976190447807312)
[2024-11-14 09:58:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:09][root][INFO] - Training Epoch: 2/2, step 11802/16670 completed (loss: 0.21623744070529938, acc: 0.9509803652763367)
[2024-11-14 09:58:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:09][root][INFO] - Training Epoch: 2/2, step 11803/16670 completed (loss: 0.043753549456596375, acc: 0.9763779640197754)
[2024-11-14 09:58:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:09][root][INFO] - Training Epoch: 2/2, step 11804/16670 completed (loss: 0.13803093135356903, acc: 0.9580419659614563)
[2024-11-14 09:58:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:10][root][INFO] - Training Epoch: 2/2, step 11805/16670 completed (loss: 0.12702302634716034, acc: 0.9459459185600281)
[2024-11-14 09:58:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:10][root][INFO] - Training Epoch: 2/2, step 11806/16670 completed (loss: 0.1413424015045166, acc: 0.9623430967330933)
[2024-11-14 09:58:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:11][root][INFO] - Training Epoch: 2/2, step 11807/16670 completed (loss: 0.1223125159740448, acc: 0.9694322943687439)
[2024-11-14 09:58:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:11][root][INFO] - Training Epoch: 2/2, step 11808/16670 completed (loss: 0.13001953065395355, acc: 0.969348669052124)
[2024-11-14 09:58:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:11][root][INFO] - Training Epoch: 2/2, step 11809/16670 completed (loss: 0.09050729125738144, acc: 0.9723320007324219)
[2024-11-14 09:58:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:12][root][INFO] - Training Epoch: 2/2, step 11810/16670 completed (loss: 0.10604208707809448, acc: 0.9732142686843872)
[2024-11-14 09:58:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:12][root][INFO] - Training Epoch: 2/2, step 11811/16670 completed (loss: 0.19221167266368866, acc: 0.9479553699493408)
[2024-11-14 09:58:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:12][root][INFO] - Training Epoch: 2/2, step 11812/16670 completed (loss: 0.26843664050102234, acc: 0.9122806787490845)
[2024-11-14 09:58:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:13][root][INFO] - Training Epoch: 2/2, step 11813/16670 completed (loss: 0.16080182790756226, acc: 0.9572649598121643)
[2024-11-14 09:58:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:13][root][INFO] - Training Epoch: 2/2, step 11814/16670 completed (loss: 0.07750695198774338, acc: 0.9741697311401367)
[2024-11-14 09:58:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:13][root][INFO] - Training Epoch: 2/2, step 11815/16670 completed (loss: 0.1240428239107132, acc: 0.9723756909370422)
[2024-11-14 09:58:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:14][root][INFO] - Training Epoch: 2/2, step 11816/16670 completed (loss: 0.08212139457464218, acc: 0.9850000143051147)
[2024-11-14 09:58:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:14][root][INFO] - Training Epoch: 2/2, step 11817/16670 completed (loss: 0.1520671397447586, acc: 0.9576271176338196)
[2024-11-14 09:58:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:14][root][INFO] - Training Epoch: 2/2, step 11818/16670 completed (loss: 0.09407040476799011, acc: 0.9660193920135498)
[2024-11-14 09:58:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:15][root][INFO] - Training Epoch: 2/2, step 11819/16670 completed (loss: 0.021644309163093567, acc: 1.0)
[2024-11-14 09:58:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:15][root][INFO] - Training Epoch: 2/2, step 11820/16670 completed (loss: 0.07331041246652603, acc: 0.9826086759567261)
[2024-11-14 09:58:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:15][root][INFO] - Training Epoch: 2/2, step 11821/16670 completed (loss: 0.24106016755104065, acc: 0.9320987462997437)
[2024-11-14 09:58:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:16][root][INFO] - Training Epoch: 2/2, step 11822/16670 completed (loss: 0.07491762191057205, acc: 0.9783549904823303)
[2024-11-14 09:58:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:16][root][INFO] - Training Epoch: 2/2, step 11823/16670 completed (loss: 0.05755448713898659, acc: 0.9840255379676819)
[2024-11-14 09:58:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:16][root][INFO] - Training Epoch: 2/2, step 11824/16670 completed (loss: 0.1712656170129776, acc: 0.9375)
[2024-11-14 09:58:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:17][root][INFO] - Training Epoch: 2/2, step 11825/16670 completed (loss: 0.20495998859405518, acc: 0.9342105388641357)
[2024-11-14 09:58:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:17][root][INFO] - Training Epoch: 2/2, step 11826/16670 completed (loss: 0.06330616027116776, acc: 0.9816849827766418)
[2024-11-14 09:58:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:17][root][INFO] - Training Epoch: 2/2, step 11827/16670 completed (loss: 0.0758848562836647, acc: 0.98591548204422)
[2024-11-14 09:58:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:18][root][INFO] - Training Epoch: 2/2, step 11828/16670 completed (loss: 0.048446282744407654, acc: 0.9805447459220886)
[2024-11-14 09:58:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:18][root][INFO] - Training Epoch: 2/2, step 11829/16670 completed (loss: 0.11808944493532181, acc: 0.9657142758369446)
[2024-11-14 09:58:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:18][root][INFO] - Training Epoch: 2/2, step 11830/16670 completed (loss: 0.0876501202583313, acc: 0.9704433679580688)
[2024-11-14 09:58:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:19][root][INFO] - Training Epoch: 2/2, step 11831/16670 completed (loss: 0.1446613073348999, acc: 0.9567567706108093)
[2024-11-14 09:58:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:19][root][INFO] - Training Epoch: 2/2, step 11832/16670 completed (loss: 0.05174344405531883, acc: 0.9807692170143127)
[2024-11-14 09:58:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:20][root][INFO] - Training Epoch: 2/2, step 11833/16670 completed (loss: 0.05554460734128952, acc: 0.9863636493682861)
[2024-11-14 09:58:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:20][root][INFO] - Training Epoch: 2/2, step 11834/16670 completed (loss: 0.07613202929496765, acc: 0.981249988079071)
[2024-11-14 09:58:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:20][root][INFO] - Training Epoch: 2/2, step 11835/16670 completed (loss: 0.16730472445487976, acc: 0.9599999785423279)
[2024-11-14 09:58:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:21][root][INFO] - Training Epoch: 2/2, step 11836/16670 completed (loss: 0.05179134011268616, acc: 0.9824561476707458)
[2024-11-14 09:58:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:21][root][INFO] - Training Epoch: 2/2, step 11837/16670 completed (loss: 0.12991508841514587, acc: 0.9518072009086609)
[2024-11-14 09:58:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:21][root][INFO] - Training Epoch: 2/2, step 11838/16670 completed (loss: 0.13886752724647522, acc: 0.9752066135406494)
[2024-11-14 09:58:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:22][root][INFO] - Training Epoch: 2/2, step 11839/16670 completed (loss: 0.16913822293281555, acc: 0.9694656729698181)
[2024-11-14 09:58:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:22][root][INFO] - Training Epoch: 2/2, step 11840/16670 completed (loss: 0.08183581382036209, acc: 0.9770992398262024)
[2024-11-14 09:58:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:22][root][INFO] - Training Epoch: 2/2, step 11841/16670 completed (loss: 0.06899110972881317, acc: 0.9759615659713745)
[2024-11-14 09:58:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:23][root][INFO] - Training Epoch: 2/2, step 11842/16670 completed (loss: 0.22516010701656342, acc: 0.954285740852356)
[2024-11-14 09:58:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:23][root][INFO] - Training Epoch: 2/2, step 11843/16670 completed (loss: 0.044879209250211716, acc: 0.9822695255279541)
[2024-11-14 09:58:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:23][root][INFO] - Training Epoch: 2/2, step 11844/16670 completed (loss: 0.17052219808101654, acc: 0.9609755873680115)
[2024-11-14 09:58:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:24][root][INFO] - Training Epoch: 2/2, step 11845/16670 completed (loss: 0.05693570151925087, acc: 0.980861246585846)
[2024-11-14 09:58:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:24][root][INFO] - Training Epoch: 2/2, step 11846/16670 completed (loss: 0.052464719861745834, acc: 0.9806763529777527)
[2024-11-14 09:58:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:24][root][INFO] - Training Epoch: 2/2, step 11847/16670 completed (loss: 0.1018189862370491, acc: 0.9731183052062988)
[2024-11-14 09:58:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:25][root][INFO] - Training Epoch: 2/2, step 11848/16670 completed (loss: 0.10988066345453262, acc: 0.9800000190734863)
[2024-11-14 09:58:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:25][root][INFO] - Training Epoch: 2/2, step 11849/16670 completed (loss: 0.041267186403274536, acc: 0.987864077091217)
[2024-11-14 09:58:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:25][root][INFO] - Training Epoch: 2/2, step 11850/16670 completed (loss: 0.05494438111782074, acc: 0.9833333492279053)
[2024-11-14 09:58:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:26][root][INFO] - Training Epoch: 2/2, step 11851/16670 completed (loss: 0.12327439337968826, acc: 0.9683257937431335)
[2024-11-14 09:58:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:26][root][INFO] - Training Epoch: 2/2, step 11852/16670 completed (loss: 0.12553708255290985, acc: 0.9528796076774597)
[2024-11-14 09:58:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:27][root][INFO] - Training Epoch: 2/2, step 11853/16670 completed (loss: 0.2544402778148651, acc: 0.9142857193946838)
[2024-11-14 09:58:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:27][root][INFO] - Training Epoch: 2/2, step 11854/16670 completed (loss: 0.07527314126491547, acc: 0.9786096215248108)
[2024-11-14 09:58:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:27][root][INFO] - Training Epoch: 2/2, step 11855/16670 completed (loss: 0.11885252594947815, acc: 0.9727891087532043)
[2024-11-14 09:58:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:28][root][INFO] - Training Epoch: 2/2, step 11856/16670 completed (loss: 0.024262603372335434, acc: 0.9914529919624329)
[2024-11-14 09:58:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:28][root][INFO] - Training Epoch: 2/2, step 11857/16670 completed (loss: 0.1744755357503891, acc: 0.9760000109672546)
[2024-11-14 09:58:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:28][root][INFO] - Training Epoch: 2/2, step 11858/16670 completed (loss: 0.06402529031038284, acc: 0.9765886068344116)
[2024-11-14 09:58:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:29][root][INFO] - Training Epoch: 2/2, step 11859/16670 completed (loss: 0.20369696617126465, acc: 0.9316770434379578)
[2024-11-14 09:58:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:29][root][INFO] - Training Epoch: 2/2, step 11860/16670 completed (loss: 0.09495529532432556, acc: 0.982758641242981)
[2024-11-14 09:58:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:29][root][INFO] - Training Epoch: 2/2, step 11861/16670 completed (loss: 0.046960074454545975, acc: 0.9849246144294739)
[2024-11-14 09:58:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:30][root][INFO] - Training Epoch: 2/2, step 11862/16670 completed (loss: 0.11662121117115021, acc: 0.9637462496757507)
[2024-11-14 09:58:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:30][root][INFO] - Training Epoch: 2/2, step 11863/16670 completed (loss: 0.08436145633459091, acc: 0.9771689772605896)
[2024-11-14 09:58:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:30][root][INFO] - Training Epoch: 2/2, step 11864/16670 completed (loss: 0.0756717249751091, acc: 0.9870129823684692)
[2024-11-14 09:58:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:31][root][INFO] - Training Epoch: 2/2, step 11865/16670 completed (loss: 0.08204951137304306, acc: 0.9694656729698181)
[2024-11-14 09:58:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:31][root][INFO] - Training Epoch: 2/2, step 11866/16670 completed (loss: 0.1231808140873909, acc: 0.9583333134651184)
[2024-11-14 09:58:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:31][root][INFO] - Training Epoch: 2/2, step 11867/16670 completed (loss: 0.12346604466438293, acc: 0.977011501789093)
[2024-11-14 09:58:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:32][root][INFO] - Training Epoch: 2/2, step 11868/16670 completed (loss: 0.08393128961324692, acc: 0.9738562107086182)
[2024-11-14 09:58:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:32][root][INFO] - Training Epoch: 2/2, step 11869/16670 completed (loss: 0.07814964652061462, acc: 0.9836734533309937)
[2024-11-14 09:58:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:33][root][INFO] - Training Epoch: 2/2, step 11870/16670 completed (loss: 0.0757921040058136, acc: 0.9696969985961914)
[2024-11-14 09:58:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:33][root][INFO] - Training Epoch: 2/2, step 11871/16670 completed (loss: 0.010402818210422993, acc: 1.0)
[2024-11-14 09:58:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:33][root][INFO] - Training Epoch: 2/2, step 11872/16670 completed (loss: 0.11952576786279678, acc: 0.9728506803512573)
[2024-11-14 09:58:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:34][root][INFO] - Training Epoch: 2/2, step 11873/16670 completed (loss: 0.024456851184368134, acc: 1.0)
[2024-11-14 09:58:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:34][root][INFO] - Training Epoch: 2/2, step 11874/16670 completed (loss: 0.06745155155658722, acc: 0.9876922965049744)
[2024-11-14 09:58:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:34][root][INFO] - Training Epoch: 2/2, step 11875/16670 completed (loss: 0.15127509832382202, acc: 0.9571428298950195)
[2024-11-14 09:58:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:35][root][INFO] - Training Epoch: 2/2, step 11876/16670 completed (loss: 0.09446453303098679, acc: 0.9864406585693359)
[2024-11-14 09:58:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:35][root][INFO] - Training Epoch: 2/2, step 11877/16670 completed (loss: 0.12003087997436523, acc: 0.9570815563201904)
[2024-11-14 09:58:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:36][root][INFO] - Training Epoch: 2/2, step 11878/16670 completed (loss: 0.21443989872932434, acc: 0.9466666579246521)
[2024-11-14 09:58:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:36][root][INFO] - Training Epoch: 2/2, step 11879/16670 completed (loss: 0.20088210701942444, acc: 0.9514563083648682)
[2024-11-14 09:58:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:36][root][INFO] - Training Epoch: 2/2, step 11880/16670 completed (loss: 0.13788360357284546, acc: 0.9738805890083313)
[2024-11-14 09:58:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:37][root][INFO] - Training Epoch: 2/2, step 11881/16670 completed (loss: 0.11280035972595215, acc: 0.9783549904823303)
[2024-11-14 09:58:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:37][root][INFO] - Training Epoch: 2/2, step 11882/16670 completed (loss: 0.11692915111780167, acc: 0.9751243591308594)
[2024-11-14 09:58:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:37][root][INFO] - Training Epoch: 2/2, step 11883/16670 completed (loss: 0.060536421835422516, acc: 0.9855595827102661)
[2024-11-14 09:58:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:38][root][INFO] - Training Epoch: 2/2, step 11884/16670 completed (loss: 0.05373150482773781, acc: 0.9791666865348816)
[2024-11-14 09:58:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:38][root][INFO] - Training Epoch: 2/2, step 11885/16670 completed (loss: 0.07768820971250534, acc: 0.9883720874786377)
[2024-11-14 09:58:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:38][root][INFO] - Training Epoch: 2/2, step 11886/16670 completed (loss: 0.25455212593078613, acc: 0.9292035102844238)
[2024-11-14 09:58:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:39][root][INFO] - Training Epoch: 2/2, step 11887/16670 completed (loss: 0.11186854541301727, acc: 0.946107804775238)
[2024-11-14 09:58:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:39][root][INFO] - Training Epoch: 2/2, step 11888/16670 completed (loss: 0.08196861296892166, acc: 0.9696969985961914)
[2024-11-14 09:58:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:39][root][INFO] - Training Epoch: 2/2, step 11889/16670 completed (loss: 0.025870125740766525, acc: 0.9941860437393188)
[2024-11-14 09:58:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:40][root][INFO] - Training Epoch: 2/2, step 11890/16670 completed (loss: 0.060599640011787415, acc: 0.9780701994895935)
[2024-11-14 09:58:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:40][root][INFO] - Training Epoch: 2/2, step 11891/16670 completed (loss: 0.14844654500484467, acc: 0.9813084006309509)
[2024-11-14 09:58:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:40][root][INFO] - Training Epoch: 2/2, step 11892/16670 completed (loss: 0.3928057551383972, acc: 0.9291338324546814)
[2024-11-14 09:58:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:41][root][INFO] - Training Epoch: 2/2, step 11893/16670 completed (loss: 0.08732890337705612, acc: 0.9819819927215576)
[2024-11-14 09:58:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:41][root][INFO] - Training Epoch: 2/2, step 11894/16670 completed (loss: 0.08811122924089432, acc: 0.9767441749572754)
[2024-11-14 09:58:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:41][root][INFO] - Training Epoch: 2/2, step 11895/16670 completed (loss: 0.020294947549700737, acc: 0.9948717951774597)
[2024-11-14 09:58:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:42][root][INFO] - Training Epoch: 2/2, step 11896/16670 completed (loss: 0.01413471158593893, acc: 0.9965986609458923)
[2024-11-14 09:58:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:42][root][INFO] - Training Epoch: 2/2, step 11897/16670 completed (loss: 0.018593093380331993, acc: 1.0)
[2024-11-14 09:58:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:42][root][INFO] - Training Epoch: 2/2, step 11898/16670 completed (loss: 0.19483347237110138, acc: 0.9375)
[2024-11-14 09:58:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:43][root][INFO] - Training Epoch: 2/2, step 11899/16670 completed (loss: 0.1246621236205101, acc: 0.9634146094322205)
[2024-11-14 09:58:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:43][root][INFO] - Training Epoch: 2/2, step 11900/16670 completed (loss: 0.1502372771501541, acc: 0.9727891087532043)
[2024-11-14 09:58:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:43][root][INFO] - Training Epoch: 2/2, step 11901/16670 completed (loss: 0.11188231408596039, acc: 0.9700374603271484)
[2024-11-14 09:58:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:44][root][INFO] - Training Epoch: 2/2, step 11902/16670 completed (loss: 0.45845916867256165, acc: 0.9399999976158142)
[2024-11-14 09:58:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:44][root][INFO] - Training Epoch: 2/2, step 11903/16670 completed (loss: 0.25706639885902405, acc: 0.9308176040649414)
[2024-11-14 09:58:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:44][root][INFO] - Training Epoch: 2/2, step 11904/16670 completed (loss: 0.1205604150891304, acc: 0.9602649211883545)
[2024-11-14 09:58:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:45][root][INFO] - Training Epoch: 2/2, step 11905/16670 completed (loss: 0.0951165035367012, acc: 0.9674796462059021)
[2024-11-14 09:58:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:45][root][INFO] - Training Epoch: 2/2, step 11906/16670 completed (loss: 0.15659832954406738, acc: 0.9470198750495911)
[2024-11-14 09:58:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:45][root][INFO] - Training Epoch: 2/2, step 11907/16670 completed (loss: 0.34907442331314087, acc: 0.8947368264198303)
[2024-11-14 09:58:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:46][root][INFO] - Training Epoch: 2/2, step 11908/16670 completed (loss: 0.5170785784721375, acc: 0.8527607321739197)
[2024-11-14 09:58:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:46][root][INFO] - Training Epoch: 2/2, step 11909/16670 completed (loss: 0.17348645627498627, acc: 0.956250011920929)
[2024-11-14 09:58:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:47][root][INFO] - Training Epoch: 2/2, step 11910/16670 completed (loss: 0.3810303211212158, acc: 0.8947368264198303)
[2024-11-14 09:58:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:47][root][INFO] - Training Epoch: 2/2, step 11911/16670 completed (loss: 0.2285931408405304, acc: 0.9130434989929199)
[2024-11-14 09:58:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:47][root][INFO] - Training Epoch: 2/2, step 11912/16670 completed (loss: 0.24762524664402008, acc: 0.947169840335846)
[2024-11-14 09:58:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:48][root][INFO] - Training Epoch: 2/2, step 11913/16670 completed (loss: 0.14411279559135437, acc: 0.9723502397537231)
[2024-11-14 09:58:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:48][root][INFO] - Training Epoch: 2/2, step 11914/16670 completed (loss: 0.2801935076713562, acc: 0.9230769276618958)
[2024-11-14 09:58:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:48][root][INFO] - Training Epoch: 2/2, step 11915/16670 completed (loss: 0.5119332075119019, acc: 0.8571428656578064)
[2024-11-14 09:58:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:49][root][INFO] - Training Epoch: 2/2, step 11916/16670 completed (loss: 0.20467722415924072, acc: 0.9421965479850769)
[2024-11-14 09:58:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:49][root][INFO] - Training Epoch: 2/2, step 11917/16670 completed (loss: 0.10142242163419724, acc: 0.976190447807312)
[2024-11-14 09:58:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:49][root][INFO] - Training Epoch: 2/2, step 11918/16670 completed (loss: 0.3138224184513092, acc: 0.9120879173278809)
[2024-11-14 09:58:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:50][root][INFO] - Training Epoch: 2/2, step 11919/16670 completed (loss: 0.12351108342409134, acc: 0.970059871673584)
[2024-11-14 09:58:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:50][root][INFO] - Training Epoch: 2/2, step 11920/16670 completed (loss: 0.3135440945625305, acc: 0.9305555820465088)
[2024-11-14 09:58:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:50][root][INFO] - Training Epoch: 2/2, step 11921/16670 completed (loss: 0.13697652518749237, acc: 0.957446813583374)
[2024-11-14 09:58:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:51][root][INFO] - Training Epoch: 2/2, step 11922/16670 completed (loss: 0.20323258638381958, acc: 0.9517543911933899)
[2024-11-14 09:58:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:51][root][INFO] - Training Epoch: 2/2, step 11923/16670 completed (loss: 0.2182820588350296, acc: 0.9322034120559692)
[2024-11-14 09:58:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:51][root][INFO] - Training Epoch: 2/2, step 11924/16670 completed (loss: 0.24689021706581116, acc: 0.9238754510879517)
[2024-11-14 09:58:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:52][root][INFO] - Training Epoch: 2/2, step 11925/16670 completed (loss: 0.06345843523740768, acc: 0.9819819927215576)
[2024-11-14 09:58:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:52][root][INFO] - Training Epoch: 2/2, step 11926/16670 completed (loss: 0.33353447914123535, acc: 0.9068825840950012)
[2024-11-14 09:58:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:52][root][INFO] - Training Epoch: 2/2, step 11927/16670 completed (loss: 0.16483992338180542, acc: 0.9571428298950195)
[2024-11-14 09:58:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:53][root][INFO] - Training Epoch: 2/2, step 11928/16670 completed (loss: 0.28326818346977234, acc: 0.931271493434906)
[2024-11-14 09:58:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:53][root][INFO] - Training Epoch: 2/2, step 11929/16670 completed (loss: 0.3084731101989746, acc: 0.9015151262283325)
[2024-11-14 09:58:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:53][root][INFO] - Training Epoch: 2/2, step 11930/16670 completed (loss: 0.1514914631843567, acc: 0.9615384340286255)
[2024-11-14 09:58:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:54][root][INFO] - Training Epoch: 2/2, step 11931/16670 completed (loss: 0.23047612607479095, acc: 0.9314079284667969)
[2024-11-14 09:58:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:54][root][INFO] - Training Epoch: 2/2, step 11932/16670 completed (loss: 0.19851872324943542, acc: 0.9299362897872925)
[2024-11-14 09:58:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:54][root][INFO] - Training Epoch: 2/2, step 11933/16670 completed (loss: 0.095960833132267, acc: 0.9810426831245422)
[2024-11-14 09:58:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:55][root][INFO] - Training Epoch: 2/2, step 11934/16670 completed (loss: 0.26387304067611694, acc: 0.9233449697494507)
[2024-11-14 09:58:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:55][root][INFO] - Training Epoch: 2/2, step 11935/16670 completed (loss: 0.6175503730773926, acc: 0.8235294222831726)
[2024-11-14 09:58:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:56][root][INFO] - Training Epoch: 2/2, step 11936/16670 completed (loss: 0.2257925271987915, acc: 0.9375)
[2024-11-14 09:58:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:56][root][INFO] - Training Epoch: 2/2, step 11937/16670 completed (loss: 0.3134757876396179, acc: 0.9251337051391602)
[2024-11-14 09:58:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:56][root][INFO] - Training Epoch: 2/2, step 11938/16670 completed (loss: 0.34859809279441833, acc: 0.8951048851013184)
[2024-11-14 09:58:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:57][root][INFO] - Training Epoch: 2/2, step 11939/16670 completed (loss: 0.1553250402212143, acc: 0.9571428298950195)
[2024-11-14 09:58:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:57][root][INFO] - Training Epoch: 2/2, step 11940/16670 completed (loss: 0.2941318154335022, acc: 0.9137930870056152)
[2024-11-14 09:58:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:57][root][INFO] - Training Epoch: 2/2, step 11941/16670 completed (loss: 0.10381095111370087, acc: 0.9784172773361206)
[2024-11-14 09:58:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:57][root][INFO] - Training Epoch: 2/2, step 11942/16670 completed (loss: 0.09558712691068649, acc: 0.9717742204666138)
[2024-11-14 09:58:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:58][root][INFO] - Training Epoch: 2/2, step 11943/16670 completed (loss: 0.2206585556268692, acc: 0.9324324131011963)
[2024-11-14 09:58:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:58][root][INFO] - Training Epoch: 2/2, step 11944/16670 completed (loss: 0.16895002126693726, acc: 0.947826087474823)
[2024-11-14 09:58:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:59][root][INFO] - Training Epoch: 2/2, step 11945/16670 completed (loss: 0.1534011960029602, acc: 0.9644970297813416)
[2024-11-14 09:58:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:59][root][INFO] - Training Epoch: 2/2, step 11946/16670 completed (loss: 0.23052364587783813, acc: 0.9236111044883728)
[2024-11-14 09:58:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:58:59][root][INFO] - Training Epoch: 2/2, step 11947/16670 completed (loss: 0.11424581706523895, acc: 0.9796954393386841)
[2024-11-14 09:58:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:00][root][INFO] - Training Epoch: 2/2, step 11948/16670 completed (loss: 0.2272520214319229, acc: 0.9354838728904724)
[2024-11-14 09:59:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:00][root][INFO] - Training Epoch: 2/2, step 11949/16670 completed (loss: 0.12452872097492218, acc: 0.9615384340286255)
[2024-11-14 09:59:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:00][root][INFO] - Training Epoch: 2/2, step 11950/16670 completed (loss: 0.23700113594532013, acc: 0.9318181872367859)
[2024-11-14 09:59:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:01][root][INFO] - Training Epoch: 2/2, step 11951/16670 completed (loss: 0.3401190936565399, acc: 0.8971962332725525)
[2024-11-14 09:59:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:01][root][INFO] - Training Epoch: 2/2, step 11952/16670 completed (loss: 0.13735966384410858, acc: 0.9637681245803833)
[2024-11-14 09:59:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:01][root][INFO] - Training Epoch: 2/2, step 11953/16670 completed (loss: 0.12199390679597855, acc: 0.9658119678497314)
[2024-11-14 09:59:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:02][root][INFO] - Training Epoch: 2/2, step 11954/16670 completed (loss: 0.13010463118553162, acc: 0.9650349617004395)
[2024-11-14 09:59:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:02][root][INFO] - Training Epoch: 2/2, step 11955/16670 completed (loss: 0.07375188171863556, acc: 0.9675090312957764)
[2024-11-14 09:59:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:02][root][INFO] - Training Epoch: 2/2, step 11956/16670 completed (loss: 0.3783622682094574, acc: 0.8823529481887817)
[2024-11-14 09:59:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:03][root][INFO] - Training Epoch: 2/2, step 11957/16670 completed (loss: 0.1906990259885788, acc: 0.9510489702224731)
[2024-11-14 09:59:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:03][root][INFO] - Training Epoch: 2/2, step 11958/16670 completed (loss: 0.08583665639162064, acc: 0.9664429426193237)
[2024-11-14 09:59:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:03][root][INFO] - Training Epoch: 2/2, step 11959/16670 completed (loss: 0.20312285423278809, acc: 0.9494584798812866)
[2024-11-14 09:59:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:04][root][INFO] - Training Epoch: 2/2, step 11960/16670 completed (loss: 0.061246417462825775, acc: 0.9928057789802551)
[2024-11-14 09:59:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:04][root][INFO] - Training Epoch: 2/2, step 11961/16670 completed (loss: 0.13982029259204865, acc: 0.9599999785423279)
[2024-11-14 09:59:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:04][root][INFO] - Training Epoch: 2/2, step 11962/16670 completed (loss: 0.25439032912254333, acc: 0.9207921028137207)
[2024-11-14 09:59:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:05][root][INFO] - Training Epoch: 2/2, step 11963/16670 completed (loss: 0.13927173614501953, acc: 0.9536082744598389)
[2024-11-14 09:59:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:05][root][INFO] - Training Epoch: 2/2, step 11964/16670 completed (loss: 0.15139375627040863, acc: 0.9322034120559692)
[2024-11-14 09:59:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:05][root][INFO] - Training Epoch: 2/2, step 11965/16670 completed (loss: 0.31359097361564636, acc: 0.8888888955116272)
[2024-11-14 09:59:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:06][root][INFO] - Training Epoch: 2/2, step 11966/16670 completed (loss: 0.24054042994976044, acc: 0.949367105960846)
[2024-11-14 09:59:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:06][root][INFO] - Training Epoch: 2/2, step 11967/16670 completed (loss: 0.09035888314247131, acc: 0.9594594836235046)
[2024-11-14 09:59:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:06][root][INFO] - Training Epoch: 2/2, step 11968/16670 completed (loss: 0.2206808477640152, acc: 0.9612902998924255)
[2024-11-14 09:59:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:07][root][INFO] - Training Epoch: 2/2, step 11969/16670 completed (loss: 0.13575729727745056, acc: 0.9519650936126709)
[2024-11-14 09:59:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:07][root][INFO] - Training Epoch: 2/2, step 11970/16670 completed (loss: 0.2185060679912567, acc: 0.9533898234367371)
[2024-11-14 09:59:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:08][root][INFO] - Training Epoch: 2/2, step 11971/16670 completed (loss: 0.38864195346832275, acc: 0.8991596698760986)
[2024-11-14 09:59:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:08][root][INFO] - Training Epoch: 2/2, step 11972/16670 completed (loss: 0.14605911076068878, acc: 0.9593908786773682)
[2024-11-14 09:59:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:08][root][INFO] - Training Epoch: 2/2, step 11973/16670 completed (loss: 0.18077626824378967, acc: 0.9518072009086609)
[2024-11-14 09:59:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:09][root][INFO] - Training Epoch: 2/2, step 11974/16670 completed (loss: 0.23343943059444427, acc: 0.9202898740768433)
[2024-11-14 09:59:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:09][root][INFO] - Training Epoch: 2/2, step 11975/16670 completed (loss: 0.13900183141231537, acc: 0.9727891087532043)
[2024-11-14 09:59:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:09][root][INFO] - Training Epoch: 2/2, step 11976/16670 completed (loss: 0.21433718502521515, acc: 0.9420289993286133)
[2024-11-14 09:59:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:09][root][INFO] - Training Epoch: 2/2, step 11977/16670 completed (loss: 0.1297650933265686, acc: 0.9645389914512634)
[2024-11-14 09:59:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:10][root][INFO] - Training Epoch: 2/2, step 11978/16670 completed (loss: 0.08502858132123947, acc: 0.9775280952453613)
[2024-11-14 09:59:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:10][root][INFO] - Training Epoch: 2/2, step 11979/16670 completed (loss: 0.2621946930885315, acc: 0.9190751314163208)
[2024-11-14 09:59:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:10][root][INFO] - Training Epoch: 2/2, step 11980/16670 completed (loss: 0.12557826936244965, acc: 0.9690476059913635)
[2024-11-14 09:59:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:11][root][INFO] - Training Epoch: 2/2, step 11981/16670 completed (loss: 0.1086171567440033, acc: 0.9722222089767456)
[2024-11-14 09:59:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:11][root][INFO] - Training Epoch: 2/2, step 11982/16670 completed (loss: 0.23640680313110352, acc: 0.949999988079071)
[2024-11-14 09:59:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:11][root][INFO] - Training Epoch: 2/2, step 11983/16670 completed (loss: 0.1794414520263672, acc: 0.9417475461959839)
[2024-11-14 09:59:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:12][root][INFO] - Training Epoch: 2/2, step 11984/16670 completed (loss: 0.041543930768966675, acc: 0.9953488111495972)
[2024-11-14 09:59:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:12][root][INFO] - Training Epoch: 2/2, step 11985/16670 completed (loss: 0.22985433042049408, acc: 0.9476190209388733)
[2024-11-14 09:59:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:12][root][INFO] - Training Epoch: 2/2, step 11986/16670 completed (loss: 0.0796712264418602, acc: 0.9785714149475098)
[2024-11-14 09:59:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:13][root][INFO] - Training Epoch: 2/2, step 11987/16670 completed (loss: 0.14589200913906097, acc: 0.9591836929321289)
[2024-11-14 09:59:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:13][root][INFO] - Training Epoch: 2/2, step 11988/16670 completed (loss: 0.5247827768325806, acc: 0.875)
[2024-11-14 09:59:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:13][root][INFO] - Training Epoch: 2/2, step 11989/16670 completed (loss: 0.3436676859855652, acc: 0.9186046719551086)
[2024-11-14 09:59:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:14][root][INFO] - Training Epoch: 2/2, step 11990/16670 completed (loss: 0.13709084689617157, acc: 0.9583333134651184)
[2024-11-14 09:59:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:14][root][INFO] - Training Epoch: 2/2, step 11991/16670 completed (loss: 0.13917973637580872, acc: 0.9629629850387573)
[2024-11-14 09:59:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:15][root][INFO] - Training Epoch: 2/2, step 11992/16670 completed (loss: 0.23931273818016052, acc: 0.942307710647583)
[2024-11-14 09:59:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:15][root][INFO] - Training Epoch: 2/2, step 11993/16670 completed (loss: 0.1659747213125229, acc: 0.9535865187644958)
[2024-11-14 09:59:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:15][root][INFO] - Training Epoch: 2/2, step 11994/16670 completed (loss: 0.20227929949760437, acc: 0.9482758641242981)
[2024-11-14 09:59:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:16][root][INFO] - Training Epoch: 2/2, step 11995/16670 completed (loss: 0.25352972745895386, acc: 0.9200000166893005)
[2024-11-14 09:59:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:16][root][INFO] - Training Epoch: 2/2, step 11996/16670 completed (loss: 0.2601113021373749, acc: 0.9141104221343994)
[2024-11-14 09:59:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:16][root][INFO] - Training Epoch: 2/2, step 11997/16670 completed (loss: 0.13462911546230316, acc: 0.9666666388511658)
[2024-11-14 09:59:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:16][root][INFO] - Training Epoch: 2/2, step 11998/16670 completed (loss: 0.4083123803138733, acc: 0.90625)
[2024-11-14 09:59:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:17][root][INFO] - Training Epoch: 2/2, step 11999/16670 completed (loss: 0.29198721051216125, acc: 0.9298245906829834)
[2024-11-14 09:59:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:17][root][INFO] - Training Epoch: 2/2, step 12000/16670 completed (loss: 0.12836378812789917, acc: 0.9666666388511658)
[2024-11-14 09:59:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:18][root][INFO] - Training Epoch: 2/2, step 12001/16670 completed (loss: 0.18090452253818512, acc: 0.9644970297813416)
[2024-11-14 09:59:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:18][root][INFO] - Training Epoch: 2/2, step 12002/16670 completed (loss: 0.21864117681980133, acc: 0.9543147087097168)
[2024-11-14 09:59:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:18][root][INFO] - Training Epoch: 2/2, step 12003/16670 completed (loss: 0.16306722164154053, acc: 0.953667938709259)
[2024-11-14 09:59:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:19][root][INFO] - Training Epoch: 2/2, step 12004/16670 completed (loss: 0.13512390851974487, acc: 0.9503546357154846)
[2024-11-14 09:59:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:19][root][INFO] - Training Epoch: 2/2, step 12005/16670 completed (loss: 0.08855496346950531, acc: 0.9626168012619019)
[2024-11-14 09:59:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:19][root][INFO] - Training Epoch: 2/2, step 12006/16670 completed (loss: 0.4823753535747528, acc: 0.8757764101028442)
[2024-11-14 09:59:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:20][root][INFO] - Training Epoch: 2/2, step 12007/16670 completed (loss: 0.1731288880109787, acc: 0.9428571462631226)
[2024-11-14 09:59:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:20][root][INFO] - Training Epoch: 2/2, step 12008/16670 completed (loss: 0.05648554489016533, acc: 0.9850746393203735)
[2024-11-14 09:59:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:20][root][INFO] - Training Epoch: 2/2, step 12009/16670 completed (loss: 0.1740577220916748, acc: 0.9488054513931274)
[2024-11-14 09:59:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:21][root][INFO] - Training Epoch: 2/2, step 12010/16670 completed (loss: 0.1207742914557457, acc: 0.9752475023269653)
[2024-11-14 09:59:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:21][root][INFO] - Training Epoch: 2/2, step 12011/16670 completed (loss: 0.21064560115337372, acc: 0.9320388436317444)
[2024-11-14 09:59:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:21][root][INFO] - Training Epoch: 2/2, step 12012/16670 completed (loss: 0.14492134749889374, acc: 0.9655172228813171)
[2024-11-14 09:59:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:22][root][INFO] - Training Epoch: 2/2, step 12013/16670 completed (loss: 0.11610855162143707, acc: 0.9647576808929443)
[2024-11-14 09:59:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:22][root][INFO] - Training Epoch: 2/2, step 12014/16670 completed (loss: 0.17333367466926575, acc: 0.948387086391449)
[2024-11-14 09:59:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:22][root][INFO] - Training Epoch: 2/2, step 12015/16670 completed (loss: 0.20666158199310303, acc: 0.9591836929321289)
[2024-11-14 09:59:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:23][root][INFO] - Training Epoch: 2/2, step 12016/16670 completed (loss: 0.0876581072807312, acc: 0.970588207244873)
[2024-11-14 09:59:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:23][root][INFO] - Training Epoch: 2/2, step 12017/16670 completed (loss: 0.20556147396564484, acc: 0.9330357313156128)
[2024-11-14 09:59:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:23][root][INFO] - Training Epoch: 2/2, step 12018/16670 completed (loss: 0.3491482436656952, acc: 0.8947368264198303)
[2024-11-14 09:59:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:24][root][INFO] - Training Epoch: 2/2, step 12019/16670 completed (loss: 0.11870914697647095, acc: 0.9728682041168213)
[2024-11-14 09:59:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:24][root][INFO] - Training Epoch: 2/2, step 12020/16670 completed (loss: 0.07509403675794601, acc: 0.9873949289321899)
[2024-11-14 09:59:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:24][root][INFO] - Training Epoch: 2/2, step 12021/16670 completed (loss: 0.12486198544502258, acc: 0.95686274766922)
[2024-11-14 09:59:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:25][root][INFO] - Training Epoch: 2/2, step 12022/16670 completed (loss: 0.3881992995738983, acc: 0.8695651888847351)
[2024-11-14 09:59:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:25][root][INFO] - Training Epoch: 2/2, step 12023/16670 completed (loss: 0.11699768155813217, acc: 0.9704641103744507)
[2024-11-14 09:59:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:25][root][INFO] - Training Epoch: 2/2, step 12024/16670 completed (loss: 0.19863329827785492, acc: 0.9447236061096191)
[2024-11-14 09:59:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:26][root][INFO] - Training Epoch: 2/2, step 12025/16670 completed (loss: 0.23797105252742767, acc: 0.9335664510726929)
[2024-11-14 09:59:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:26][root][INFO] - Training Epoch: 2/2, step 12026/16670 completed (loss: 0.27601680159568787, acc: 0.9279999732971191)
[2024-11-14 09:59:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:26][root][INFO] - Training Epoch: 2/2, step 12027/16670 completed (loss: 0.19997702538967133, acc: 0.9406779408454895)
[2024-11-14 09:59:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:27][root][INFO] - Training Epoch: 2/2, step 12028/16670 completed (loss: 0.16292615234851837, acc: 0.9473684430122375)
[2024-11-14 09:59:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:27][root][INFO] - Training Epoch: 2/2, step 12029/16670 completed (loss: 0.2271779179573059, acc: 0.9492385983467102)
[2024-11-14 09:59:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:27][root][INFO] - Training Epoch: 2/2, step 12030/16670 completed (loss: 0.2396642416715622, acc: 0.9529914259910583)
[2024-11-14 09:59:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:28][root][INFO] - Training Epoch: 2/2, step 12031/16670 completed (loss: 0.29630377888679504, acc: 0.9200000166893005)
[2024-11-14 09:59:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:28][root][INFO] - Training Epoch: 2/2, step 12032/16670 completed (loss: 0.27875378727912903, acc: 0.90625)
[2024-11-14 09:59:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:28][root][INFO] - Training Epoch: 2/2, step 12033/16670 completed (loss: 0.1921764612197876, acc: 0.9523809552192688)
[2024-11-14 09:59:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:29][root][INFO] - Training Epoch: 2/2, step 12034/16670 completed (loss: 0.1252569556236267, acc: 0.9579439163208008)
[2024-11-14 09:59:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:29][root][INFO] - Training Epoch: 2/2, step 12035/16670 completed (loss: 0.20214837789535522, acc: 0.9558233022689819)
[2024-11-14 09:59:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:29][root][INFO] - Training Epoch: 2/2, step 12036/16670 completed (loss: 0.20976170897483826, acc: 0.9469026327133179)
[2024-11-14 09:59:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:30][root][INFO] - Training Epoch: 2/2, step 12037/16670 completed (loss: 0.5954646468162537, acc: 0.8333333134651184)
[2024-11-14 09:59:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:30][root][INFO] - Training Epoch: 2/2, step 12038/16670 completed (loss: 0.13968242704868317, acc: 0.9580838084220886)
[2024-11-14 09:59:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:30][root][INFO] - Training Epoch: 2/2, step 12039/16670 completed (loss: 0.0795515775680542, acc: 0.9729729890823364)
[2024-11-14 09:59:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:31][root][INFO] - Training Epoch: 2/2, step 12040/16670 completed (loss: 0.16565746068954468, acc: 0.9579439163208008)
[2024-11-14 09:59:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:31][root][INFO] - Training Epoch: 2/2, step 12041/16670 completed (loss: 0.24038094282150269, acc: 0.9385964870452881)
[2024-11-14 09:59:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:31][root][INFO] - Training Epoch: 2/2, step 12042/16670 completed (loss: 0.5774714946746826, acc: 0.8636363744735718)
[2024-11-14 09:59:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:32][root][INFO] - Training Epoch: 2/2, step 12043/16670 completed (loss: 0.38034191727638245, acc: 0.8782608509063721)
[2024-11-14 09:59:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:32][root][INFO] - Training Epoch: 2/2, step 12044/16670 completed (loss: 0.09270401298999786, acc: 0.9692307710647583)
[2024-11-14 09:59:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:32][root][INFO] - Training Epoch: 2/2, step 12045/16670 completed (loss: 0.09503469616174698, acc: 0.9750000238418579)
[2024-11-14 09:59:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:33][root][INFO] - Training Epoch: 2/2, step 12046/16670 completed (loss: 0.2019484043121338, acc: 0.9456067085266113)
[2024-11-14 09:59:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:33][root][INFO] - Training Epoch: 2/2, step 12047/16670 completed (loss: 0.08768747001886368, acc: 0.9785714149475098)
[2024-11-14 09:59:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:33][root][INFO] - Training Epoch: 2/2, step 12048/16670 completed (loss: 0.2633402347564697, acc: 0.925000011920929)
[2024-11-14 09:59:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:34][root][INFO] - Training Epoch: 2/2, step 12049/16670 completed (loss: 0.1450420618057251, acc: 0.9449541568756104)
[2024-11-14 09:59:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:34][root][INFO] - Training Epoch: 2/2, step 12050/16670 completed (loss: 0.09632796794176102, acc: 0.9713114500045776)
[2024-11-14 09:59:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:34][root][INFO] - Training Epoch: 2/2, step 12051/16670 completed (loss: 0.08255726844072342, acc: 0.9777777791023254)
[2024-11-14 09:59:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:35][root][INFO] - Training Epoch: 2/2, step 12052/16670 completed (loss: 0.20179404318332672, acc: 0.9255319237709045)
[2024-11-14 09:59:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:35][root][INFO] - Training Epoch: 2/2, step 12053/16670 completed (loss: 0.21600012481212616, acc: 0.9402173757553101)
[2024-11-14 09:59:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:36][root][INFO] - Training Epoch: 2/2, step 12054/16670 completed (loss: 0.13452382385730743, acc: 0.9533678889274597)
[2024-11-14 09:59:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:36][root][INFO] - Training Epoch: 2/2, step 12055/16670 completed (loss: 0.17980122566223145, acc: 0.949999988079071)
[2024-11-14 09:59:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:36][root][INFO] - Training Epoch: 2/2, step 12056/16670 completed (loss: 0.09815925359725952, acc: 0.9775280952453613)
[2024-11-14 09:59:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:37][root][INFO] - Training Epoch: 2/2, step 12057/16670 completed (loss: 0.1689041703939438, acc: 0.9386503100395203)
[2024-11-14 09:59:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:37][root][INFO] - Training Epoch: 2/2, step 12058/16670 completed (loss: 0.35056644678115845, acc: 0.9069767594337463)
[2024-11-14 09:59:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:37][root][INFO] - Training Epoch: 2/2, step 12059/16670 completed (loss: 0.1852368414402008, acc: 0.9408602118492126)
[2024-11-14 09:59:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:38][root][INFO] - Training Epoch: 2/2, step 12060/16670 completed (loss: 0.09200417250394821, acc: 0.9677419066429138)
[2024-11-14 09:59:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:38][root][INFO] - Training Epoch: 2/2, step 12061/16670 completed (loss: 0.32661938667297363, acc: 0.9122806787490845)
[2024-11-14 09:59:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:38][root][INFO] - Training Epoch: 2/2, step 12062/16670 completed (loss: 0.07590891420841217, acc: 0.976047933101654)
[2024-11-14 09:59:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:39][root][INFO] - Training Epoch: 2/2, step 12063/16670 completed (loss: 0.30247899889945984, acc: 0.9160305261611938)
[2024-11-14 09:59:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:39][root][INFO] - Training Epoch: 2/2, step 12064/16670 completed (loss: 0.3748093545436859, acc: 0.8636363744735718)
[2024-11-14 09:59:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:39][root][INFO] - Training Epoch: 2/2, step 12065/16670 completed (loss: 0.3017880916595459, acc: 0.9329608678817749)
[2024-11-14 09:59:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:40][root][INFO] - Training Epoch: 2/2, step 12066/16670 completed (loss: 0.2039177119731903, acc: 0.9575471878051758)
[2024-11-14 09:59:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:40][root][INFO] - Training Epoch: 2/2, step 12067/16670 completed (loss: 0.11109676957130432, acc: 0.9651162624359131)
[2024-11-14 09:59:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:40][root][INFO] - Training Epoch: 2/2, step 12068/16670 completed (loss: 0.1549777090549469, acc: 0.9714285731315613)
[2024-11-14 09:59:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:41][root][INFO] - Training Epoch: 2/2, step 12069/16670 completed (loss: 0.15528494119644165, acc: 0.9586206674575806)
[2024-11-14 09:59:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:41][root][INFO] - Training Epoch: 2/2, step 12070/16670 completed (loss: 0.3233117461204529, acc: 0.9024389982223511)
[2024-11-14 09:59:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:41][root][INFO] - Training Epoch: 2/2, step 12071/16670 completed (loss: 0.12711896002292633, acc: 0.9666666388511658)
[2024-11-14 09:59:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:42][root][INFO] - Training Epoch: 2/2, step 12072/16670 completed (loss: 0.19899363815784454, acc: 0.9480968713760376)
[2024-11-14 09:59:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:42][root][INFO] - Training Epoch: 2/2, step 12073/16670 completed (loss: 0.16775992512702942, acc: 0.9424083828926086)
[2024-11-14 09:59:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:43][root][INFO] - Training Epoch: 2/2, step 12074/16670 completed (loss: 0.07268094271421432, acc: 0.9733333587646484)
[2024-11-14 09:59:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:43][root][INFO] - Training Epoch: 2/2, step 12075/16670 completed (loss: 0.21907293796539307, acc: 0.9457013607025146)
[2024-11-14 09:59:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:43][root][INFO] - Training Epoch: 2/2, step 12076/16670 completed (loss: 0.2317473292350769, acc: 0.916201114654541)
[2024-11-14 09:59:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:44][root][INFO] - Training Epoch: 2/2, step 12077/16670 completed (loss: 0.1853753626346588, acc: 0.963087260723114)
[2024-11-14 09:59:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:44][root][INFO] - Training Epoch: 2/2, step 12078/16670 completed (loss: 0.18159930408000946, acc: 0.9487179517745972)
[2024-11-14 09:59:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:44][root][INFO] - Training Epoch: 2/2, step 12079/16670 completed (loss: 0.2541162669658661, acc: 0.9542483687400818)
[2024-11-14 09:59:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:45][root][INFO] - Training Epoch: 2/2, step 12080/16670 completed (loss: 0.08489997684955597, acc: 0.9681274890899658)
[2024-11-14 09:59:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:45][root][INFO] - Training Epoch: 2/2, step 12081/16670 completed (loss: 0.17732441425323486, acc: 0.9505494236946106)
[2024-11-14 09:59:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:45][root][INFO] - Training Epoch: 2/2, step 12082/16670 completed (loss: 0.2553541958332062, acc: 0.8952381014823914)
[2024-11-14 09:59:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:46][root][INFO] - Training Epoch: 2/2, step 12083/16670 completed (loss: 0.23015065491199493, acc: 0.9464285969734192)
[2024-11-14 09:59:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:46][root][INFO] - Training Epoch: 2/2, step 12084/16670 completed (loss: 0.24807330965995789, acc: 0.9347826242446899)
[2024-11-14 09:59:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:46][root][INFO] - Training Epoch: 2/2, step 12085/16670 completed (loss: 0.33522841334342957, acc: 0.9222797751426697)
[2024-11-14 09:59:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:47][root][INFO] - Training Epoch: 2/2, step 12086/16670 completed (loss: 0.3254995048046112, acc: 0.9031007885932922)
[2024-11-14 09:59:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:47][root][INFO] - Training Epoch: 2/2, step 12087/16670 completed (loss: 0.28397494554519653, acc: 0.908450722694397)
[2024-11-14 09:59:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:47][root][INFO] - Training Epoch: 2/2, step 12088/16670 completed (loss: 0.19998860359191895, acc: 0.9534883499145508)
[2024-11-14 09:59:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:48][root][INFO] - Training Epoch: 2/2, step 12089/16670 completed (loss: 0.25561726093292236, acc: 0.9234972596168518)
[2024-11-14 09:59:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:48][root][INFO] - Training Epoch: 2/2, step 12090/16670 completed (loss: 0.3182116746902466, acc: 0.9178571701049805)
[2024-11-14 09:59:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:48][root][INFO] - Training Epoch: 2/2, step 12091/16670 completed (loss: 0.2054036259651184, acc: 0.9353448152542114)
[2024-11-14 09:59:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:49][root][INFO] - Training Epoch: 2/2, step 12092/16670 completed (loss: 0.1795777678489685, acc: 0.9303797483444214)
[2024-11-14 09:59:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:49][root][INFO] - Training Epoch: 2/2, step 12093/16670 completed (loss: 0.11380601674318314, acc: 0.9730941653251648)
[2024-11-14 09:59:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:49][root][INFO] - Training Epoch: 2/2, step 12094/16670 completed (loss: 0.41753777861595154, acc: 0.8707482814788818)
[2024-11-14 09:59:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:50][root][INFO] - Training Epoch: 2/2, step 12095/16670 completed (loss: 0.21020841598510742, acc: 0.948369562625885)
[2024-11-14 09:59:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:50][root][INFO] - Training Epoch: 2/2, step 12096/16670 completed (loss: 0.7553632855415344, acc: 0.7432432174682617)
[2024-11-14 09:59:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:50][root][INFO] - Training Epoch: 2/2, step 12097/16670 completed (loss: 0.3917131721973419, acc: 0.9113300442695618)
[2024-11-14 09:59:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:51][root][INFO] - Training Epoch: 2/2, step 12098/16670 completed (loss: 0.23703517019748688, acc: 0.9456868767738342)
[2024-11-14 09:59:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:51][root][INFO] - Training Epoch: 2/2, step 12099/16670 completed (loss: 0.3728797435760498, acc: 0.8912134170532227)
[2024-11-14 09:59:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:51][root][INFO] - Training Epoch: 2/2, step 12100/16670 completed (loss: 0.13900217413902283, acc: 0.9599999785423279)
[2024-11-14 09:59:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:52][root][INFO] - Training Epoch: 2/2, step 12101/16670 completed (loss: 0.20208308100700378, acc: 0.9468085169792175)
[2024-11-14 09:59:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:52][root][INFO] - Training Epoch: 2/2, step 12102/16670 completed (loss: 0.2645948529243469, acc: 0.9032257795333862)
[2024-11-14 09:59:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:52][root][INFO] - Training Epoch: 2/2, step 12103/16670 completed (loss: 0.4225425720214844, acc: 0.8604651093482971)
[2024-11-14 09:59:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:53][root][INFO] - Training Epoch: 2/2, step 12104/16670 completed (loss: 0.31501519680023193, acc: 0.9166666865348816)
[2024-11-14 09:59:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:53][root][INFO] - Training Epoch: 2/2, step 12105/16670 completed (loss: 0.2982882559299469, acc: 0.9338235259056091)
[2024-11-14 09:59:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:53][root][INFO] - Training Epoch: 2/2, step 12106/16670 completed (loss: 0.25951898097991943, acc: 0.9192307591438293)
[2024-11-14 09:59:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:53][root][INFO] - Training Epoch: 2/2, step 12107/16670 completed (loss: 0.2610826790332794, acc: 0.9373040795326233)
[2024-11-14 09:59:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:54][root][INFO] - Training Epoch: 2/2, step 12108/16670 completed (loss: 0.24625647068023682, acc: 0.9360465407371521)
[2024-11-14 09:59:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:54][root][INFO] - Training Epoch: 2/2, step 12109/16670 completed (loss: 0.24777384102344513, acc: 0.9425287246704102)
[2024-11-14 09:59:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:54][root][INFO] - Training Epoch: 2/2, step 12110/16670 completed (loss: 0.131646528840065, acc: 0.9593023061752319)
[2024-11-14 09:59:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:55][root][INFO] - Training Epoch: 2/2, step 12111/16670 completed (loss: 0.20029373466968536, acc: 0.9338235259056091)
[2024-11-14 09:59:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:55][root][INFO] - Training Epoch: 2/2, step 12112/16670 completed (loss: 0.23756404221057892, acc: 0.9530201554298401)
[2024-11-14 09:59:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:55][root][INFO] - Training Epoch: 2/2, step 12113/16670 completed (loss: 0.18805623054504395, acc: 0.9558823704719543)
[2024-11-14 09:59:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:56][root][INFO] - Training Epoch: 2/2, step 12114/16670 completed (loss: 0.27637556195259094, acc: 0.9350649118423462)
[2024-11-14 09:59:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:56][root][INFO] - Training Epoch: 2/2, step 12115/16670 completed (loss: 0.24060796201229095, acc: 0.9202454090118408)
[2024-11-14 09:59:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:56][root][INFO] - Training Epoch: 2/2, step 12116/16670 completed (loss: 0.25102898478507996, acc: 0.9225806593894958)
[2024-11-14 09:59:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:57][root][INFO] - Training Epoch: 2/2, step 12117/16670 completed (loss: 0.16210509836673737, acc: 0.9560439586639404)
[2024-11-14 09:59:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:57][root][INFO] - Training Epoch: 2/2, step 12118/16670 completed (loss: 0.21962331235408783, acc: 0.9387755393981934)
[2024-11-14 09:59:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:57][root][INFO] - Training Epoch: 2/2, step 12119/16670 completed (loss: 0.3437241017818451, acc: 0.9140271544456482)
[2024-11-14 09:59:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:57][root][INFO] - Training Epoch: 2/2, step 12120/16670 completed (loss: 0.3150940239429474, acc: 0.9211618304252625)
[2024-11-14 09:59:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:58][root][INFO] - Training Epoch: 2/2, step 12121/16670 completed (loss: 0.17560116946697235, acc: 0.9567567706108093)
[2024-11-14 09:59:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:58][root][INFO] - Training Epoch: 2/2, step 12122/16670 completed (loss: 0.13247376680374146, acc: 0.9513888955116272)
[2024-11-14 09:59:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:58][root][INFO] - Training Epoch: 2/2, step 12123/16670 completed (loss: 0.21458867192268372, acc: 0.939393937587738)
[2024-11-14 09:59:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:59][root][INFO] - Training Epoch: 2/2, step 12124/16670 completed (loss: 0.2534092366695404, acc: 0.9155844449996948)
[2024-11-14 09:59:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:59][root][INFO] - Training Epoch: 2/2, step 12125/16670 completed (loss: 0.5947613716125488, acc: 0.8351648449897766)
[2024-11-14 09:59:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 09:59:59][root][INFO] - Training Epoch: 2/2, step 12126/16670 completed (loss: 0.10933199524879456, acc: 0.957446813583374)
[2024-11-14 10:00:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:00][root][INFO] - Training Epoch: 2/2, step 12127/16670 completed (loss: 0.16132859885692596, acc: 0.9495798349380493)
[2024-11-14 10:00:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:00][root][INFO] - Training Epoch: 2/2, step 12128/16670 completed (loss: 0.26980775594711304, acc: 0.9135135412216187)
[2024-11-14 10:00:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:00][root][INFO] - Training Epoch: 2/2, step 12129/16670 completed (loss: 0.3259873390197754, acc: 0.9024389982223511)
[2024-11-14 10:00:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:01][root][INFO] - Training Epoch: 2/2, step 12130/16670 completed (loss: 0.32149043679237366, acc: 0.9140625)
[2024-11-14 10:00:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:01][root][INFO] - Training Epoch: 2/2, step 12131/16670 completed (loss: 0.10620484501123428, acc: 0.9589040875434875)
[2024-11-14 10:00:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:01][root][INFO] - Training Epoch: 2/2, step 12132/16670 completed (loss: 0.2200222611427307, acc: 0.9554139971733093)
[2024-11-14 10:00:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:02][root][INFO] - Training Epoch: 2/2, step 12133/16670 completed (loss: 0.2371978461742401, acc: 0.9396551847457886)
[2024-11-14 10:00:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:02][root][INFO] - Training Epoch: 2/2, step 12134/16670 completed (loss: 0.353860080242157, acc: 0.9322034120559692)
[2024-11-14 10:00:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:02][root][INFO] - Training Epoch: 2/2, step 12135/16670 completed (loss: 0.14063531160354614, acc: 0.9573770761489868)
[2024-11-14 10:00:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:03][root][INFO] - Training Epoch: 2/2, step 12136/16670 completed (loss: 0.19730214774608612, acc: 0.949367105960846)
[2024-11-14 10:00:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:03][root][INFO] - Training Epoch: 2/2, step 12137/16670 completed (loss: 0.13234668970108032, acc: 0.9622641801834106)
[2024-11-14 10:00:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:03][root][INFO] - Training Epoch: 2/2, step 12138/16670 completed (loss: 0.37426692247390747, acc: 0.9210526347160339)
[2024-11-14 10:00:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:04][root][INFO] - Training Epoch: 2/2, step 12139/16670 completed (loss: 0.19992542266845703, acc: 0.9507575631141663)
[2024-11-14 10:00:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:04][root][INFO] - Training Epoch: 2/2, step 12140/16670 completed (loss: 0.3264898955821991, acc: 0.917391300201416)
[2024-11-14 10:00:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:04][root][INFO] - Training Epoch: 2/2, step 12141/16670 completed (loss: 0.15280142426490784, acc: 0.9610389471054077)
[2024-11-14 10:00:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:05][root][INFO] - Training Epoch: 2/2, step 12142/16670 completed (loss: 0.3660663962364197, acc: 0.9008264541625977)
[2024-11-14 10:00:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:05][root][INFO] - Training Epoch: 2/2, step 12143/16670 completed (loss: 0.3857085406780243, acc: 0.8877005577087402)
[2024-11-14 10:00:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:05][root][INFO] - Training Epoch: 2/2, step 12144/16670 completed (loss: 0.46196791529655457, acc: 0.904411792755127)
[2024-11-14 10:00:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:05][root][INFO] - Training Epoch: 2/2, step 12145/16670 completed (loss: 0.23611290752887726, acc: 0.9378882050514221)
[2024-11-14 10:00:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:06][root][INFO] - Training Epoch: 2/2, step 12146/16670 completed (loss: 0.25698980689048767, acc: 0.9366196990013123)
[2024-11-14 10:00:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:06][root][INFO] - Training Epoch: 2/2, step 12147/16670 completed (loss: 0.27562880516052246, acc: 0.9356223344802856)
[2024-11-14 10:00:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:06][root][INFO] - Training Epoch: 2/2, step 12148/16670 completed (loss: 0.40770041942596436, acc: 0.8730158805847168)
[2024-11-14 10:00:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:07][root][INFO] - Training Epoch: 2/2, step 12149/16670 completed (loss: 0.1880446821451187, acc: 0.9350000023841858)
[2024-11-14 10:00:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:07][root][INFO] - Training Epoch: 2/2, step 12150/16670 completed (loss: 0.5096305012702942, acc: 0.8516746163368225)
[2024-11-14 10:00:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:07][root][INFO] - Training Epoch: 2/2, step 12151/16670 completed (loss: 0.2833528518676758, acc: 0.9248826503753662)
[2024-11-14 10:00:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:08][root][INFO] - Training Epoch: 2/2, step 12152/16670 completed (loss: 0.408778578042984, acc: 0.8744394779205322)
[2024-11-14 10:00:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:08][root][INFO] - Training Epoch: 2/2, step 12153/16670 completed (loss: 0.22390694916248322, acc: 0.9466666579246521)
[2024-11-14 10:00:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:08][root][INFO] - Training Epoch: 2/2, step 12154/16670 completed (loss: 0.10901398956775665, acc: 0.9653179049491882)
[2024-11-14 10:00:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:09][root][INFO] - Training Epoch: 2/2, step 12155/16670 completed (loss: 0.3158019483089447, acc: 0.9172413945198059)
[2024-11-14 10:00:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:09][root][INFO] - Training Epoch: 2/2, step 12156/16670 completed (loss: 0.3419346809387207, acc: 0.89449542760849)
[2024-11-14 10:00:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:09][root][INFO] - Training Epoch: 2/2, step 12157/16670 completed (loss: 0.15090173482894897, acc: 0.9526315927505493)
[2024-11-14 10:00:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:10][root][INFO] - Training Epoch: 2/2, step 12158/16670 completed (loss: 0.10102242976427078, acc: 0.9788135886192322)
[2024-11-14 10:00:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:10][root][INFO] - Training Epoch: 2/2, step 12159/16670 completed (loss: 0.16564519703388214, acc: 0.944915235042572)
[2024-11-14 10:00:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:10][root][INFO] - Training Epoch: 2/2, step 12160/16670 completed (loss: 0.1346370279788971, acc: 0.9633333086967468)
[2024-11-14 10:00:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:11][root][INFO] - Training Epoch: 2/2, step 12161/16670 completed (loss: 0.19777056574821472, acc: 0.9470751881599426)
[2024-11-14 10:00:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:11][root][INFO] - Training Epoch: 2/2, step 12162/16670 completed (loss: 0.1956682652235031, acc: 0.9501915574073792)
[2024-11-14 10:00:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:11][root][INFO] - Training Epoch: 2/2, step 12163/16670 completed (loss: 0.36202552914619446, acc: 0.9102563858032227)
[2024-11-14 10:00:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:12][root][INFO] - Training Epoch: 2/2, step 12164/16670 completed (loss: 0.2059234231710434, acc: 0.9548386931419373)
[2024-11-14 10:00:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:12][root][INFO] - Training Epoch: 2/2, step 12165/16670 completed (loss: 0.3749921917915344, acc: 0.8920863270759583)
[2024-11-14 10:00:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:12][root][INFO] - Training Epoch: 2/2, step 12166/16670 completed (loss: 0.1786113977432251, acc: 0.9455252885818481)
[2024-11-14 10:00:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:12][root][INFO] - Training Epoch: 2/2, step 12167/16670 completed (loss: 0.26736536622047424, acc: 0.9166666865348816)
[2024-11-14 10:00:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:13][root][INFO] - Training Epoch: 2/2, step 12168/16670 completed (loss: 0.2837057411670685, acc: 0.9056603908538818)
[2024-11-14 10:00:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:13][root][INFO] - Training Epoch: 2/2, step 12169/16670 completed (loss: 0.16025960445404053, acc: 0.9691358208656311)
[2024-11-14 10:00:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:13][root][INFO] - Training Epoch: 2/2, step 12170/16670 completed (loss: 0.09655436128377914, acc: 0.9675925970077515)
[2024-11-14 10:00:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:14][root][INFO] - Training Epoch: 2/2, step 12171/16670 completed (loss: 0.045536912977695465, acc: 0.9899497628211975)
[2024-11-14 10:00:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:14][root][INFO] - Training Epoch: 2/2, step 12172/16670 completed (loss: 0.1597532033920288, acc: 0.9542483687400818)
[2024-11-14 10:00:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:14][root][INFO] - Training Epoch: 2/2, step 12173/16670 completed (loss: 0.17994973063468933, acc: 0.9516128897666931)
[2024-11-14 10:00:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:15][root][INFO] - Training Epoch: 2/2, step 12174/16670 completed (loss: 0.14183838665485382, acc: 0.942307710647583)
[2024-11-14 10:00:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:15][root][INFO] - Training Epoch: 2/2, step 12175/16670 completed (loss: 0.13119156658649445, acc: 0.9617224931716919)
[2024-11-14 10:00:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:15][root][INFO] - Training Epoch: 2/2, step 12176/16670 completed (loss: 0.21168506145477295, acc: 0.9435736536979675)
[2024-11-14 10:00:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:16][root][INFO] - Training Epoch: 2/2, step 12177/16670 completed (loss: 0.33438053727149963, acc: 0.913705587387085)
[2024-11-14 10:00:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:16][root][INFO] - Training Epoch: 2/2, step 12178/16670 completed (loss: 0.23361262679100037, acc: 0.926174521446228)
[2024-11-14 10:00:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:16][root][INFO] - Training Epoch: 2/2, step 12179/16670 completed (loss: 0.10559339076280594, acc: 0.971731424331665)
[2024-11-14 10:00:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:17][root][INFO] - Training Epoch: 2/2, step 12180/16670 completed (loss: 0.1804952323436737, acc: 0.9553072452545166)
[2024-11-14 10:00:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:17][root][INFO] - Training Epoch: 2/2, step 12181/16670 completed (loss: 0.08157727122306824, acc: 0.9834254384040833)
[2024-11-14 10:00:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:18][root][INFO] - Training Epoch: 2/2, step 12182/16670 completed (loss: 0.30170103907585144, acc: 0.9279999732971191)
[2024-11-14 10:00:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:18][root][INFO] - Training Epoch: 2/2, step 12183/16670 completed (loss: 0.24019178748130798, acc: 0.9350649118423462)
[2024-11-14 10:00:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:18][root][INFO] - Training Epoch: 2/2, step 12184/16670 completed (loss: 0.14945454895496368, acc: 0.9552845358848572)
[2024-11-14 10:00:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:19][root][INFO] - Training Epoch: 2/2, step 12185/16670 completed (loss: 0.10507404804229736, acc: 0.9754098653793335)
[2024-11-14 10:00:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:19][root][INFO] - Training Epoch: 2/2, step 12186/16670 completed (loss: 0.23219838738441467, acc: 0.9321428537368774)
[2024-11-14 10:00:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:19][root][INFO] - Training Epoch: 2/2, step 12187/16670 completed (loss: 0.2433573603630066, acc: 0.9279999732971191)
[2024-11-14 10:00:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:20][root][INFO] - Training Epoch: 2/2, step 12188/16670 completed (loss: 0.23419523239135742, acc: 0.95652174949646)
[2024-11-14 10:00:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:20][root][INFO] - Training Epoch: 2/2, step 12189/16670 completed (loss: 0.34177297353744507, acc: 0.9344978332519531)
[2024-11-14 10:00:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:20][root][INFO] - Training Epoch: 2/2, step 12190/16670 completed (loss: 0.06991932541131973, acc: 0.9839743375778198)
[2024-11-14 10:00:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:21][root][INFO] - Training Epoch: 2/2, step 12191/16670 completed (loss: 0.06651977449655533, acc: 0.9890710115432739)
[2024-11-14 10:00:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:21][root][INFO] - Training Epoch: 2/2, step 12192/16670 completed (loss: 0.18722324073314667, acc: 0.9594095945358276)
[2024-11-14 10:00:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:22][root][INFO] - Training Epoch: 2/2, step 12193/16670 completed (loss: 0.21536201238632202, acc: 0.9470198750495911)
[2024-11-14 10:00:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:22][root][INFO] - Training Epoch: 2/2, step 12194/16670 completed (loss: 0.4215337932109833, acc: 0.8585858345031738)
[2024-11-14 10:00:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:22][root][INFO] - Training Epoch: 2/2, step 12195/16670 completed (loss: 0.07814853638410568, acc: 0.982758641242981)
[2024-11-14 10:00:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:23][root][INFO] - Training Epoch: 2/2, step 12196/16670 completed (loss: 0.15135429799556732, acc: 0.9569536447525024)
[2024-11-14 10:00:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:23][root][INFO] - Training Epoch: 2/2, step 12197/16670 completed (loss: 0.11310569196939468, acc: 0.9655172228813171)
[2024-11-14 10:00:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:23][root][INFO] - Training Epoch: 2/2, step 12198/16670 completed (loss: 0.09989449381828308, acc: 0.9808917045593262)
[2024-11-14 10:00:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:24][root][INFO] - Training Epoch: 2/2, step 12199/16670 completed (loss: 0.28884389996528625, acc: 0.9351351261138916)
[2024-11-14 10:00:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:24][root][INFO] - Training Epoch: 2/2, step 12200/16670 completed (loss: 0.18749083578586578, acc: 0.9455445408821106)
[2024-11-14 10:00:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:24][root][INFO] - Training Epoch: 2/2, step 12201/16670 completed (loss: 0.3544551432132721, acc: 0.8672566413879395)
[2024-11-14 10:00:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:25][root][INFO] - Training Epoch: 2/2, step 12202/16670 completed (loss: 0.21018390357494354, acc: 0.9399141669273376)
[2024-11-14 10:00:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:25][root][INFO] - Training Epoch: 2/2, step 12203/16670 completed (loss: 0.18970118463039398, acc: 0.9516128897666931)
[2024-11-14 10:00:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:25][root][INFO] - Training Epoch: 2/2, step 12204/16670 completed (loss: 0.3226885497570038, acc: 0.8985507488250732)
[2024-11-14 10:00:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:26][root][INFO] - Training Epoch: 2/2, step 12205/16670 completed (loss: 0.3794328272342682, acc: 0.9107142686843872)
[2024-11-14 10:00:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:26][root][INFO] - Training Epoch: 2/2, step 12206/16670 completed (loss: 0.17091761529445648, acc: 0.9548022747039795)
[2024-11-14 10:00:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:26][root][INFO] - Training Epoch: 2/2, step 12207/16670 completed (loss: 0.15193308889865875, acc: 0.9516128897666931)
[2024-11-14 10:00:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:27][root][INFO] - Training Epoch: 2/2, step 12208/16670 completed (loss: 0.12825548648834229, acc: 0.969072163105011)
[2024-11-14 10:00:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:27][root][INFO] - Training Epoch: 2/2, step 12209/16670 completed (loss: 0.40935584902763367, acc: 0.8918918967247009)
[2024-11-14 10:00:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:27][root][INFO] - Training Epoch: 2/2, step 12210/16670 completed (loss: 0.20388337969779968, acc: 0.9377777576446533)
[2024-11-14 10:00:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:28][root][INFO] - Training Epoch: 2/2, step 12211/16670 completed (loss: 0.3952762484550476, acc: 0.8965517282485962)
[2024-11-14 10:00:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:28][root][INFO] - Training Epoch: 2/2, step 12212/16670 completed (loss: 0.3377152383327484, acc: 0.9105691313743591)
[2024-11-14 10:00:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:28][root][INFO] - Training Epoch: 2/2, step 12213/16670 completed (loss: 0.2758437991142273, acc: 0.936170220375061)
[2024-11-14 10:00:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:29][root][INFO] - Training Epoch: 2/2, step 12214/16670 completed (loss: 0.06693723797798157, acc: 0.9759036302566528)
[2024-11-14 10:00:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:29][root][INFO] - Training Epoch: 2/2, step 12215/16670 completed (loss: 0.11524645239114761, acc: 0.970588207244873)
[2024-11-14 10:00:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:29][root][INFO] - Training Epoch: 2/2, step 12216/16670 completed (loss: 0.1690930426120758, acc: 0.9532163739204407)
[2024-11-14 10:00:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:30][root][INFO] - Training Epoch: 2/2, step 12217/16670 completed (loss: 0.30693894624710083, acc: 0.9194630980491638)
[2024-11-14 10:00:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:30][root][INFO] - Training Epoch: 2/2, step 12218/16670 completed (loss: 0.2490631341934204, acc: 0.9330357313156128)
[2024-11-14 10:00:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:30][root][INFO] - Training Epoch: 2/2, step 12219/16670 completed (loss: 0.20861554145812988, acc: 0.95703125)
[2024-11-14 10:00:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:31][root][INFO] - Training Epoch: 2/2, step 12220/16670 completed (loss: 0.1455560326576233, acc: 0.964102566242218)
[2024-11-14 10:00:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:31][root][INFO] - Training Epoch: 2/2, step 12221/16670 completed (loss: 0.14864258468151093, acc: 0.9584905505180359)
[2024-11-14 10:00:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:31][root][INFO] - Training Epoch: 2/2, step 12222/16670 completed (loss: 0.25473806262016296, acc: 0.9369747638702393)
[2024-11-14 10:00:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:32][root][INFO] - Training Epoch: 2/2, step 12223/16670 completed (loss: 0.12771397829055786, acc: 0.9721448421478271)
[2024-11-14 10:00:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:32][root][INFO] - Training Epoch: 2/2, step 12224/16670 completed (loss: 0.20169806480407715, acc: 0.9363057613372803)
[2024-11-14 10:00:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:32][root][INFO] - Training Epoch: 2/2, step 12225/16670 completed (loss: 0.15431161224842072, acc: 0.9322034120559692)
[2024-11-14 10:00:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:33][root][INFO] - Training Epoch: 2/2, step 12226/16670 completed (loss: 0.2070414423942566, acc: 0.9444444179534912)
[2024-11-14 10:00:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:33][root][INFO] - Training Epoch: 2/2, step 12227/16670 completed (loss: 0.2192225158214569, acc: 0.9448275566101074)
[2024-11-14 10:00:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:33][root][INFO] - Training Epoch: 2/2, step 12228/16670 completed (loss: 0.0938856303691864, acc: 0.9684210419654846)
[2024-11-14 10:00:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:33][root][INFO] - Training Epoch: 2/2, step 12229/16670 completed (loss: 0.2884967029094696, acc: 0.9337349534034729)
[2024-11-14 10:00:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:34][root][INFO] - Training Epoch: 2/2, step 12230/16670 completed (loss: 0.15393297374248505, acc: 0.9666666388511658)
[2024-11-14 10:00:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:34][root][INFO] - Training Epoch: 2/2, step 12231/16670 completed (loss: 0.08704251050949097, acc: 0.9802371263504028)
[2024-11-14 10:00:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:34][root][INFO] - Training Epoch: 2/2, step 12232/16670 completed (loss: 0.19257068634033203, acc: 0.9478827118873596)
[2024-11-14 10:00:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:35][root][INFO] - Training Epoch: 2/2, step 12233/16670 completed (loss: 0.25858011841773987, acc: 0.929729700088501)
[2024-11-14 10:00:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:35][root][INFO] - Training Epoch: 2/2, step 12234/16670 completed (loss: 0.2734644412994385, acc: 0.9116883277893066)
[2024-11-14 10:00:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:36][root][INFO] - Training Epoch: 2/2, step 12235/16670 completed (loss: 0.25112518668174744, acc: 0.9305555820465088)
[2024-11-14 10:00:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:36][root][INFO] - Training Epoch: 2/2, step 12236/16670 completed (loss: 0.16770581901073456, acc: 0.9626556038856506)
[2024-11-14 10:00:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:36][root][INFO] - Training Epoch: 2/2, step 12237/16670 completed (loss: 0.19227878749370575, acc: 0.9648562073707581)
[2024-11-14 10:00:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:37][root][INFO] - Training Epoch: 2/2, step 12238/16670 completed (loss: 0.24171346426010132, acc: 0.9247311949729919)
[2024-11-14 10:00:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:37][root][INFO] - Training Epoch: 2/2, step 12239/16670 completed (loss: 0.20122818648815155, acc: 0.9416666626930237)
[2024-11-14 10:00:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:37][root][INFO] - Training Epoch: 2/2, step 12240/16670 completed (loss: 0.2428201287984848, acc: 0.9435897469520569)
[2024-11-14 10:00:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:38][root][INFO] - Training Epoch: 2/2, step 12241/16670 completed (loss: 0.10594291239976883, acc: 0.9685039520263672)
[2024-11-14 10:00:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:38][root][INFO] - Training Epoch: 2/2, step 12242/16670 completed (loss: 0.13476704061031342, acc: 0.9615384340286255)
[2024-11-14 10:00:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:38][root][INFO] - Training Epoch: 2/2, step 12243/16670 completed (loss: 0.09483375400304794, acc: 0.9738219976425171)
[2024-11-14 10:00:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:39][root][INFO] - Training Epoch: 2/2, step 12244/16670 completed (loss: 0.2162487953901291, acc: 0.9369369149208069)
[2024-11-14 10:00:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:39][root][INFO] - Training Epoch: 2/2, step 12245/16670 completed (loss: 0.17413271963596344, acc: 0.9512194991111755)
[2024-11-14 10:00:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:40][root][INFO] - Training Epoch: 2/2, step 12246/16670 completed (loss: 0.198552668094635, acc: 0.9413919448852539)
[2024-11-14 10:00:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:40][root][INFO] - Training Epoch: 2/2, step 12247/16670 completed (loss: 0.22859542071819305, acc: 0.9324324131011963)
[2024-11-14 10:00:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:40][root][INFO] - Training Epoch: 2/2, step 12248/16670 completed (loss: 0.21104814112186432, acc: 0.9425837397575378)
[2024-11-14 10:00:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:41][root][INFO] - Training Epoch: 2/2, step 12249/16670 completed (loss: 0.2451697140932083, acc: 0.9247311949729919)
[2024-11-14 10:00:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:41][root][INFO] - Training Epoch: 2/2, step 12250/16670 completed (loss: 0.20646557211875916, acc: 0.9584664702415466)
[2024-11-14 10:00:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:41][root][INFO] - Training Epoch: 2/2, step 12251/16670 completed (loss: 0.22322842478752136, acc: 0.9325153231620789)
[2024-11-14 10:00:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:42][root][INFO] - Training Epoch: 2/2, step 12252/16670 completed (loss: 0.19519446790218353, acc: 0.9485095143318176)
[2024-11-14 10:00:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:42][root][INFO] - Training Epoch: 2/2, step 12253/16670 completed (loss: 0.21099793910980225, acc: 0.9390581846237183)
[2024-11-14 10:00:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:42][root][INFO] - Training Epoch: 2/2, step 12254/16670 completed (loss: 0.23548132181167603, acc: 0.9367815852165222)
[2024-11-14 10:00:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:43][root][INFO] - Training Epoch: 2/2, step 12255/16670 completed (loss: 0.2205083817243576, acc: 0.9337016344070435)
[2024-11-14 10:00:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:43][root][INFO] - Training Epoch: 2/2, step 12256/16670 completed (loss: 0.10253339260816574, acc: 0.9581993818283081)
[2024-11-14 10:00:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:43][root][INFO] - Training Epoch: 2/2, step 12257/16670 completed (loss: 0.17389611899852753, acc: 0.9492753744125366)
[2024-11-14 10:00:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:44][root][INFO] - Training Epoch: 2/2, step 12258/16670 completed (loss: 0.14585065841674805, acc: 0.9509202241897583)
[2024-11-14 10:00:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:44][root][INFO] - Training Epoch: 2/2, step 12259/16670 completed (loss: 0.13650044798851013, acc: 0.9654178619384766)
[2024-11-14 10:00:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:44][root][INFO] - Training Epoch: 2/2, step 12260/16670 completed (loss: 0.20334787666797638, acc: 0.9372197389602661)
[2024-11-14 10:00:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:45][root][INFO] - Training Epoch: 2/2, step 12261/16670 completed (loss: 0.1669476330280304, acc: 0.9680232405662537)
[2024-11-14 10:00:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:45][root][INFO] - Training Epoch: 2/2, step 12262/16670 completed (loss: 0.1617746502161026, acc: 0.9720930457115173)
[2024-11-14 10:00:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:45][root][INFO] - Training Epoch: 2/2, step 12263/16670 completed (loss: 0.10045715421438217, acc: 0.9841772317886353)
[2024-11-14 10:00:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:46][root][INFO] - Training Epoch: 2/2, step 12264/16670 completed (loss: 0.11363033205270767, acc: 0.9702602028846741)
[2024-11-14 10:00:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:46][root][INFO] - Training Epoch: 2/2, step 12265/16670 completed (loss: 0.11040789633989334, acc: 0.9741935729980469)
[2024-11-14 10:00:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:46][root][INFO] - Training Epoch: 2/2, step 12266/16670 completed (loss: 0.11956410109996796, acc: 0.9555555582046509)
[2024-11-14 10:00:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:47][root][INFO] - Training Epoch: 2/2, step 12267/16670 completed (loss: 0.21606586873531342, acc: 0.9408866763114929)
[2024-11-14 10:00:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:47][root][INFO] - Training Epoch: 2/2, step 12268/16670 completed (loss: 0.20249220728874207, acc: 0.9345794320106506)
[2024-11-14 10:00:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:47][root][INFO] - Training Epoch: 2/2, step 12269/16670 completed (loss: 0.21331803500652313, acc: 0.9529411792755127)
[2024-11-14 10:00:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:48][root][INFO] - Training Epoch: 2/2, step 12270/16670 completed (loss: 0.26897522807121277, acc: 0.9308755993843079)
[2024-11-14 10:00:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:48][root][INFO] - Training Epoch: 2/2, step 12271/16670 completed (loss: 0.08946536481380463, acc: 0.975683867931366)
[2024-11-14 10:00:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:48][root][INFO] - Training Epoch: 2/2, step 12272/16670 completed (loss: 0.06202428787946701, acc: 0.9756097793579102)
[2024-11-14 10:00:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:49][root][INFO] - Training Epoch: 2/2, step 12273/16670 completed (loss: 0.19127175211906433, acc: 0.9316770434379578)
[2024-11-14 10:00:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:49][root][INFO] - Training Epoch: 2/2, step 12274/16670 completed (loss: 0.1192246675491333, acc: 0.9743589758872986)
[2024-11-14 10:00:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:49][root][INFO] - Training Epoch: 2/2, step 12275/16670 completed (loss: 0.05088603496551514, acc: 0.9909909963607788)
[2024-11-14 10:00:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:50][root][INFO] - Training Epoch: 2/2, step 12276/16670 completed (loss: 0.2085718810558319, acc: 0.948113203048706)
[2024-11-14 10:00:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:50][root][INFO] - Training Epoch: 2/2, step 12277/16670 completed (loss: 0.1638416349887848, acc: 0.9488054513931274)
[2024-11-14 10:00:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:50][root][INFO] - Training Epoch: 2/2, step 12278/16670 completed (loss: 0.18152843415737152, acc: 0.9642857313156128)
[2024-11-14 10:00:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:50][root][INFO] - Training Epoch: 2/2, step 12279/16670 completed (loss: 0.16555483639240265, acc: 0.9552238583564758)
[2024-11-14 10:00:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:51][root][INFO] - Training Epoch: 2/2, step 12280/16670 completed (loss: 0.28761932253837585, acc: 0.9246575236320496)
[2024-11-14 10:00:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:51][root][INFO] - Training Epoch: 2/2, step 12281/16670 completed (loss: 0.13550400733947754, acc: 0.9639999866485596)
[2024-11-14 10:00:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:51][root][INFO] - Training Epoch: 2/2, step 12282/16670 completed (loss: 0.1475648730993271, acc: 0.9584664702415466)
[2024-11-14 10:00:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:52][root][INFO] - Training Epoch: 2/2, step 12283/16670 completed (loss: 0.10891810804605484, acc: 0.9670329689979553)
[2024-11-14 10:00:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:52][root][INFO] - Training Epoch: 2/2, step 12284/16670 completed (loss: 0.23088304698467255, acc: 0.9268292784690857)
[2024-11-14 10:00:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:52][root][INFO] - Training Epoch: 2/2, step 12285/16670 completed (loss: 0.19837386906147003, acc: 0.946360170841217)
[2024-11-14 10:00:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:53][root][INFO] - Training Epoch: 2/2, step 12286/16670 completed (loss: 0.1430673897266388, acc: 0.9599999785423279)
[2024-11-14 10:00:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:53][root][INFO] - Training Epoch: 2/2, step 12287/16670 completed (loss: 0.2013838291168213, acc: 0.9479166865348816)
[2024-11-14 10:00:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:53][root][INFO] - Training Epoch: 2/2, step 12288/16670 completed (loss: 0.11470696330070496, acc: 0.9755351543426514)
[2024-11-14 10:00:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:54][root][INFO] - Training Epoch: 2/2, step 12289/16670 completed (loss: 0.11513976752758026, acc: 0.9682996869087219)
[2024-11-14 10:00:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:54][root][INFO] - Training Epoch: 2/2, step 12290/16670 completed (loss: 0.3134921193122864, acc: 0.9142857193946838)
[2024-11-14 10:00:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:55][root][INFO] - Training Epoch: 2/2, step 12291/16670 completed (loss: 0.18467716872692108, acc: 0.9405405521392822)
[2024-11-14 10:00:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:55][root][INFO] - Training Epoch: 2/2, step 12292/16670 completed (loss: 0.27203282713890076, acc: 0.9369369149208069)
[2024-11-14 10:00:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:55][root][INFO] - Training Epoch: 2/2, step 12293/16670 completed (loss: 0.17180143296718597, acc: 0.9598393440246582)
[2024-11-14 10:00:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:56][root][INFO] - Training Epoch: 2/2, step 12294/16670 completed (loss: 0.18717168271541595, acc: 0.9516907930374146)
[2024-11-14 10:00:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:56][root][INFO] - Training Epoch: 2/2, step 12295/16670 completed (loss: 0.06521177291870117, acc: 0.9865771532058716)
[2024-11-14 10:00:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:56][root][INFO] - Training Epoch: 2/2, step 12296/16670 completed (loss: 0.1166442409157753, acc: 0.9771863222122192)
[2024-11-14 10:00:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:57][root][INFO] - Training Epoch: 2/2, step 12297/16670 completed (loss: 0.19518806040287018, acc: 0.9414225816726685)
[2024-11-14 10:00:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:57][root][INFO] - Training Epoch: 2/2, step 12298/16670 completed (loss: 0.16538619995117188, acc: 0.9462810158729553)
[2024-11-14 10:00:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:57][root][INFO] - Training Epoch: 2/2, step 12299/16670 completed (loss: 0.1238856390118599, acc: 0.9518072009086609)
[2024-11-14 10:00:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:58][root][INFO] - Training Epoch: 2/2, step 12300/16670 completed (loss: 0.16022087633609772, acc: 0.9543378949165344)
[2024-11-14 10:00:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:58][root][INFO] - Training Epoch: 2/2, step 12301/16670 completed (loss: 0.11245971918106079, acc: 0.9685534834861755)
[2024-11-14 10:00:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:58][root][INFO] - Training Epoch: 2/2, step 12302/16670 completed (loss: 0.43031948804855347, acc: 0.8289473652839661)
[2024-11-14 10:00:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:59][root][INFO] - Training Epoch: 2/2, step 12303/16670 completed (loss: 0.16780750453472137, acc: 0.9575971961021423)
[2024-11-14 10:00:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:59][root][INFO] - Training Epoch: 2/2, step 12304/16670 completed (loss: 0.2083210051059723, acc: 0.9471153616905212)
[2024-11-14 10:00:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:00:59][root][INFO] - Training Epoch: 2/2, step 12305/16670 completed (loss: 0.30627280473709106, acc: 0.8833333253860474)
[2024-11-14 10:00:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:00][root][INFO] - Training Epoch: 2/2, step 12306/16670 completed (loss: 0.24380061030387878, acc: 0.9383260011672974)
[2024-11-14 10:01:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:00][root][INFO] - Training Epoch: 2/2, step 12307/16670 completed (loss: 0.09652054309844971, acc: 0.9725610017776489)
[2024-11-14 10:01:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:00][root][INFO] - Training Epoch: 2/2, step 12308/16670 completed (loss: 0.12266132235527039, acc: 0.9714964628219604)
[2024-11-14 10:01:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:01][root][INFO] - Training Epoch: 2/2, step 12309/16670 completed (loss: 0.17843323945999146, acc: 0.9411764740943909)
[2024-11-14 10:01:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:01][root][INFO] - Training Epoch: 2/2, step 12310/16670 completed (loss: 0.14376749098300934, acc: 0.9583333134651184)
[2024-11-14 10:01:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:01][root][INFO] - Training Epoch: 2/2, step 12311/16670 completed (loss: 0.1149943545460701, acc: 0.9740633964538574)
[2024-11-14 10:01:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:02][root][INFO] - Training Epoch: 2/2, step 12312/16670 completed (loss: 0.13230034708976746, acc: 0.9460784196853638)
[2024-11-14 10:01:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:02][root][INFO] - Training Epoch: 2/2, step 12313/16670 completed (loss: 0.06838884949684143, acc: 0.9817351698875427)
[2024-11-14 10:01:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:03][root][INFO] - Training Epoch: 2/2, step 12314/16670 completed (loss: 0.09033841639757156, acc: 0.9747474789619446)
[2024-11-14 10:01:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:03][root][INFO] - Training Epoch: 2/2, step 12315/16670 completed (loss: 0.1505010575056076, acc: 0.9659574627876282)
[2024-11-14 10:01:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:03][root][INFO] - Training Epoch: 2/2, step 12316/16670 completed (loss: 0.11054626852273941, acc: 0.9747633934020996)
[2024-11-14 10:01:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:04][root][INFO] - Training Epoch: 2/2, step 12317/16670 completed (loss: 0.19238965213298798, acc: 0.9425287246704102)
[2024-11-14 10:01:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:04][root][INFO] - Training Epoch: 2/2, step 12318/16670 completed (loss: 0.22559192776679993, acc: 0.9202454090118408)
[2024-11-14 10:01:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:04][root][INFO] - Training Epoch: 2/2, step 12319/16670 completed (loss: 0.08327293395996094, acc: 0.9735293984413147)
[2024-11-14 10:01:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:05][root][INFO] - Training Epoch: 2/2, step 12320/16670 completed (loss: 0.20987330377101898, acc: 0.9487179517745972)
[2024-11-14 10:01:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:05][root][INFO] - Training Epoch: 2/2, step 12321/16670 completed (loss: 0.14173464477062225, acc: 0.970059871673584)
[2024-11-14 10:01:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:05][root][INFO] - Training Epoch: 2/2, step 12322/16670 completed (loss: 0.05167221650481224, acc: 0.981203019618988)
[2024-11-14 10:01:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:06][root][INFO] - Training Epoch: 2/2, step 12323/16670 completed (loss: 0.1914854794740677, acc: 0.9409282803535461)
[2024-11-14 10:01:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:06][root][INFO] - Training Epoch: 2/2, step 12324/16670 completed (loss: 0.11421377211809158, acc: 0.9667773842811584)
[2024-11-14 10:01:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:06][root][INFO] - Training Epoch: 2/2, step 12325/16670 completed (loss: 0.18737956881523132, acc: 0.95652174949646)
[2024-11-14 10:01:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:06][root][INFO] - Training Epoch: 2/2, step 12326/16670 completed (loss: 0.28705543279647827, acc: 0.9285714030265808)
[2024-11-14 10:01:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:07][root][INFO] - Training Epoch: 2/2, step 12327/16670 completed (loss: 0.11405786126852036, acc: 0.9634464979171753)
[2024-11-14 10:01:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:07][root][INFO] - Training Epoch: 2/2, step 12328/16670 completed (loss: 0.24517273902893066, acc: 0.9297658801078796)
[2024-11-14 10:01:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:07][root][INFO] - Training Epoch: 2/2, step 12329/16670 completed (loss: 0.1926453411579132, acc: 0.9675324559211731)
[2024-11-14 10:01:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:08][root][INFO] - Training Epoch: 2/2, step 12330/16670 completed (loss: 0.2059086561203003, acc: 0.9433198571205139)
[2024-11-14 10:01:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:08][root][INFO] - Training Epoch: 2/2, step 12331/16670 completed (loss: 0.25430959463119507, acc: 0.9291784763336182)
[2024-11-14 10:01:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:09][root][INFO] - Training Epoch: 2/2, step 12332/16670 completed (loss: 0.2000700831413269, acc: 0.9431437849998474)
[2024-11-14 10:01:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:09][root][INFO] - Training Epoch: 2/2, step 12333/16670 completed (loss: 0.05936505272984505, acc: 0.9861111044883728)
[2024-11-14 10:01:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:09][root][INFO] - Training Epoch: 2/2, step 12334/16670 completed (loss: 0.17792250216007233, acc: 0.9505300521850586)
[2024-11-14 10:01:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:09][root][INFO] - Training Epoch: 2/2, step 12335/16670 completed (loss: 0.1267087608575821, acc: 0.9704641103744507)
[2024-11-14 10:01:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:10][root][INFO] - Training Epoch: 2/2, step 12336/16670 completed (loss: 0.1402626931667328, acc: 0.9624999761581421)
[2024-11-14 10:01:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:10][root][INFO] - Training Epoch: 2/2, step 12337/16670 completed (loss: 0.32678937911987305, acc: 0.9078947305679321)
[2024-11-14 10:01:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:11][root][INFO] - Training Epoch: 2/2, step 12338/16670 completed (loss: 0.10671310871839523, acc: 0.9631147384643555)
[2024-11-14 10:01:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:11][root][INFO] - Training Epoch: 2/2, step 12339/16670 completed (loss: 0.12569700181484222, acc: 0.9613526463508606)
[2024-11-14 10:01:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:11][root][INFO] - Training Epoch: 2/2, step 12340/16670 completed (loss: 0.1375853419303894, acc: 0.9580838084220886)
[2024-11-14 10:01:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:12][root][INFO] - Training Epoch: 2/2, step 12341/16670 completed (loss: 0.13885268568992615, acc: 0.9615384340286255)
[2024-11-14 10:01:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:12][root][INFO] - Training Epoch: 2/2, step 12342/16670 completed (loss: 0.18343010544776917, acc: 0.9615384340286255)
[2024-11-14 10:01:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:12][root][INFO] - Training Epoch: 2/2, step 12343/16670 completed (loss: 0.2876878082752228, acc: 0.9182389974594116)
[2024-11-14 10:01:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:12][root][INFO] - Training Epoch: 2/2, step 12344/16670 completed (loss: 0.23139473795890808, acc: 0.9386503100395203)
[2024-11-14 10:01:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:13][root][INFO] - Training Epoch: 2/2, step 12345/16670 completed (loss: 0.10497460514307022, acc: 0.9698795080184937)
[2024-11-14 10:01:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:13][root][INFO] - Training Epoch: 2/2, step 12346/16670 completed (loss: 0.05197376385331154, acc: 0.9857650995254517)
[2024-11-14 10:01:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:14][root][INFO] - Training Epoch: 2/2, step 12347/16670 completed (loss: 0.08118169009685516, acc: 0.9807074069976807)
[2024-11-14 10:01:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:14][root][INFO] - Training Epoch: 2/2, step 12348/16670 completed (loss: 0.2694999873638153, acc: 0.9259259104728699)
[2024-11-14 10:01:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:14][root][INFO] - Training Epoch: 2/2, step 12349/16670 completed (loss: 0.15256790816783905, acc: 0.9572649598121643)
[2024-11-14 10:01:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:15][root][INFO] - Training Epoch: 2/2, step 12350/16670 completed (loss: 0.11571214348077774, acc: 0.9695817232131958)
[2024-11-14 10:01:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:15][root][INFO] - Training Epoch: 2/2, step 12351/16670 completed (loss: 0.21324260532855988, acc: 0.9563318490982056)
[2024-11-14 10:01:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:15][root][INFO] - Training Epoch: 2/2, step 12352/16670 completed (loss: 0.19697830080986023, acc: 0.9345454573631287)
[2024-11-14 10:01:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:16][root][INFO] - Training Epoch: 2/2, step 12353/16670 completed (loss: 0.15304841101169586, acc: 0.9623430967330933)
[2024-11-14 10:01:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:16][root][INFO] - Training Epoch: 2/2, step 12354/16670 completed (loss: 0.11451992392539978, acc: 0.9713466763496399)
[2024-11-14 10:01:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:16][root][INFO] - Training Epoch: 2/2, step 12355/16670 completed (loss: 0.08703149110078812, acc: 0.9690265655517578)
[2024-11-14 10:01:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:17][root][INFO] - Training Epoch: 2/2, step 12356/16670 completed (loss: 0.0923120453953743, acc: 0.9703264236450195)
[2024-11-14 10:01:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:17][root][INFO] - Training Epoch: 2/2, step 12357/16670 completed (loss: 0.09031359106302261, acc: 0.9724770784378052)
[2024-11-14 10:01:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:17][root][INFO] - Training Epoch: 2/2, step 12358/16670 completed (loss: 0.1032838374376297, acc: 0.9735973477363586)
[2024-11-14 10:01:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:18][root][INFO] - Training Epoch: 2/2, step 12359/16670 completed (loss: 0.2296477109193802, acc: 0.9273504018783569)
[2024-11-14 10:01:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:18][root][INFO] - Training Epoch: 2/2, step 12360/16670 completed (loss: 0.15177614986896515, acc: 0.9572192430496216)
[2024-11-14 10:01:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:18][root][INFO] - Training Epoch: 2/2, step 12361/16670 completed (loss: 0.10183452814817429, acc: 0.9526315927505493)
[2024-11-14 10:01:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:19][root][INFO] - Training Epoch: 2/2, step 12362/16670 completed (loss: 0.14247986674308777, acc: 0.951298713684082)
[2024-11-14 10:01:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:19][root][INFO] - Training Epoch: 2/2, step 12363/16670 completed (loss: 0.30142757296562195, acc: 0.9017341136932373)
[2024-11-14 10:01:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:20][root][INFO] - Training Epoch: 2/2, step 12364/16670 completed (loss: 0.14071643352508545, acc: 0.9608433842658997)
[2024-11-14 10:01:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:20][root][INFO] - Training Epoch: 2/2, step 12365/16670 completed (loss: 0.21083524823188782, acc: 0.9464285969734192)
[2024-11-14 10:01:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:20][root][INFO] - Training Epoch: 2/2, step 12366/16670 completed (loss: 0.30264535546302795, acc: 0.9181286692619324)
[2024-11-14 10:01:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:21][root][INFO] - Training Epoch: 2/2, step 12367/16670 completed (loss: 0.20728439092636108, acc: 0.9470899701118469)
[2024-11-14 10:01:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:21][root][INFO] - Training Epoch: 2/2, step 12368/16670 completed (loss: 0.1291932612657547, acc: 0.9633333086967468)
[2024-11-14 10:01:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:21][root][INFO] - Training Epoch: 2/2, step 12369/16670 completed (loss: 0.1187315508723259, acc: 0.9626168012619019)
[2024-11-14 10:01:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:22][root][INFO] - Training Epoch: 2/2, step 12370/16670 completed (loss: 0.27453479170799255, acc: 0.9166666865348816)
[2024-11-14 10:01:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:22][root][INFO] - Training Epoch: 2/2, step 12371/16670 completed (loss: 0.255280464887619, acc: 0.90625)
[2024-11-14 10:01:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:22][root][INFO] - Training Epoch: 2/2, step 12372/16670 completed (loss: 0.21942968666553497, acc: 0.9596773982048035)
[2024-11-14 10:01:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:23][root][INFO] - Training Epoch: 2/2, step 12373/16670 completed (loss: 0.2089388072490692, acc: 0.9172932505607605)
[2024-11-14 10:01:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:23][root][INFO] - Training Epoch: 2/2, step 12374/16670 completed (loss: 0.3089737892150879, acc: 0.9533678889274597)
[2024-11-14 10:01:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:23][root][INFO] - Training Epoch: 2/2, step 12375/16670 completed (loss: 0.334418922662735, acc: 0.8965517282485962)
[2024-11-14 10:01:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:24][root][INFO] - Training Epoch: 2/2, step 12376/16670 completed (loss: 0.05188799276947975, acc: 0.9825581312179565)
[2024-11-14 10:01:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:24][root][INFO] - Training Epoch: 2/2, step 12377/16670 completed (loss: 0.27861276268959045, acc: 0.893081784248352)
[2024-11-14 10:01:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:24][root][INFO] - Training Epoch: 2/2, step 12378/16670 completed (loss: 0.17820359766483307, acc: 0.955719530582428)
[2024-11-14 10:01:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:25][root][INFO] - Training Epoch: 2/2, step 12379/16670 completed (loss: 0.2377711832523346, acc: 0.9375)
[2024-11-14 10:01:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:25][root][INFO] - Training Epoch: 2/2, step 12380/16670 completed (loss: 0.16914021968841553, acc: 0.9470587968826294)
[2024-11-14 10:01:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:25][root][INFO] - Training Epoch: 2/2, step 12381/16670 completed (loss: 0.21470333635807037, acc: 0.9248120188713074)
[2024-11-14 10:01:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:26][root][INFO] - Training Epoch: 2/2, step 12382/16670 completed (loss: 0.2213219255208969, acc: 0.9166666865348816)
[2024-11-14 10:01:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:26][root][INFO] - Training Epoch: 2/2, step 12383/16670 completed (loss: 0.12902575731277466, acc: 0.949367105960846)
[2024-11-14 10:01:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:26][root][INFO] - Training Epoch: 2/2, step 12384/16670 completed (loss: 0.25571057200431824, acc: 0.9166666865348816)
[2024-11-14 10:01:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:27][root][INFO] - Training Epoch: 2/2, step 12385/16670 completed (loss: 0.17120547592639923, acc: 0.9527027010917664)
[2024-11-14 10:01:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:27][root][INFO] - Training Epoch: 2/2, step 12386/16670 completed (loss: 0.11173637956380844, acc: 0.9736841917037964)
[2024-11-14 10:01:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:28][root][INFO] - Training Epoch: 2/2, step 12387/16670 completed (loss: 0.2140262871980667, acc: 0.9385964870452881)
[2024-11-14 10:01:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:28][root][INFO] - Training Epoch: 2/2, step 12388/16670 completed (loss: 0.14700737595558167, acc: 0.9780219793319702)
[2024-11-14 10:01:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:28][root][INFO] - Training Epoch: 2/2, step 12389/16670 completed (loss: 0.13378113508224487, acc: 0.9556650519371033)
[2024-11-14 10:01:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:28][root][INFO] - Training Epoch: 2/2, step 12390/16670 completed (loss: 0.23285521566867828, acc: 0.9384615421295166)
[2024-11-14 10:01:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:29][root][INFO] - Training Epoch: 2/2, step 12391/16670 completed (loss: 0.1470981389284134, acc: 0.9649122953414917)
[2024-11-14 10:01:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:29][root][INFO] - Training Epoch: 2/2, step 12392/16670 completed (loss: 0.23170457780361176, acc: 0.9191176295280457)
[2024-11-14 10:01:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:29][root][INFO] - Training Epoch: 2/2, step 12393/16670 completed (loss: 0.23668043315410614, acc: 0.9283488988876343)
[2024-11-14 10:01:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:30][root][INFO] - Training Epoch: 2/2, step 12394/16670 completed (loss: 0.2892608344554901, acc: 0.9440993666648865)
[2024-11-14 10:01:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:30][root][INFO] - Training Epoch: 2/2, step 12395/16670 completed (loss: 0.18870945274829865, acc: 0.9580644965171814)
[2024-11-14 10:01:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:30][root][INFO] - Training Epoch: 2/2, step 12396/16670 completed (loss: 0.14583569765090942, acc: 0.9736841917037964)
[2024-11-14 10:01:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:31][root][INFO] - Training Epoch: 2/2, step 12397/16670 completed (loss: 0.4201565086841583, acc: 0.8913043737411499)
[2024-11-14 10:01:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:31][root][INFO] - Training Epoch: 2/2, step 12398/16670 completed (loss: 0.12041662633419037, acc: 0.9545454382896423)
[2024-11-14 10:01:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:31][root][INFO] - Training Epoch: 2/2, step 12399/16670 completed (loss: 0.07241146266460419, acc: 0.9900000095367432)
[2024-11-14 10:01:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:32][root][INFO] - Training Epoch: 2/2, step 12400/16670 completed (loss: 0.15830372273921967, acc: 0.9717513918876648)
[2024-11-14 10:01:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:32][root][INFO] - Training Epoch: 2/2, step 12401/16670 completed (loss: 0.4498242437839508, acc: 0.887417197227478)
[2024-11-14 10:01:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:32][root][INFO] - Training Epoch: 2/2, step 12402/16670 completed (loss: 0.12160643935203552, acc: 0.9710982441902161)
[2024-11-14 10:01:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:33][root][INFO] - Training Epoch: 2/2, step 12403/16670 completed (loss: 0.41273823380470276, acc: 0.9073359370231628)
[2024-11-14 10:01:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:33][root][INFO] - Training Epoch: 2/2, step 12404/16670 completed (loss: 0.30242031812667847, acc: 0.9299065470695496)
[2024-11-14 10:01:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:33][root][INFO] - Training Epoch: 2/2, step 12405/16670 completed (loss: 0.038619834929704666, acc: 1.0)
[2024-11-14 10:01:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:34][root][INFO] - Training Epoch: 2/2, step 12406/16670 completed (loss: 0.39334622025489807, acc: 0.8951612710952759)
[2024-11-14 10:01:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:34][root][INFO] - Training Epoch: 2/2, step 12407/16670 completed (loss: 0.1331898719072342, acc: 0.9604519605636597)
[2024-11-14 10:01:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:34][root][INFO] - Training Epoch: 2/2, step 12408/16670 completed (loss: 0.2712383568286896, acc: 0.9282296895980835)
[2024-11-14 10:01:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:35][root][INFO] - Training Epoch: 2/2, step 12409/16670 completed (loss: 0.1439782977104187, acc: 0.9634146094322205)
[2024-11-14 10:01:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:35][root][INFO] - Training Epoch: 2/2, step 12410/16670 completed (loss: 0.1345837265253067, acc: 0.9669421315193176)
[2024-11-14 10:01:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:35][root][INFO] - Training Epoch: 2/2, step 12411/16670 completed (loss: 0.11027782410383224, acc: 0.970370352268219)
[2024-11-14 10:01:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:36][root][INFO] - Training Epoch: 2/2, step 12412/16670 completed (loss: 0.15450558066368103, acc: 0.9588235020637512)
[2024-11-14 10:01:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:36][root][INFO] - Training Epoch: 2/2, step 12413/16670 completed (loss: 0.231075257062912, acc: 0.9363057613372803)
[2024-11-14 10:01:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:36][root][INFO] - Training Epoch: 2/2, step 12414/16670 completed (loss: 0.20831264555454254, acc: 0.9555555582046509)
[2024-11-14 10:01:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:37][root][INFO] - Training Epoch: 2/2, step 12415/16670 completed (loss: 0.11783334612846375, acc: 0.9672726988792419)
[2024-11-14 10:01:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:37][root][INFO] - Training Epoch: 2/2, step 12416/16670 completed (loss: 0.4417836666107178, acc: 0.9120000004768372)
[2024-11-14 10:01:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:37][root][INFO] - Training Epoch: 2/2, step 12417/16670 completed (loss: 0.2713219225406647, acc: 0.9209486246109009)
[2024-11-14 10:01:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:37][root][INFO] - Training Epoch: 2/2, step 12418/16670 completed (loss: 0.266032874584198, acc: 0.941717803478241)
[2024-11-14 10:01:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:38][root][INFO] - Training Epoch: 2/2, step 12419/16670 completed (loss: 0.08847703039646149, acc: 0.9803921580314636)
[2024-11-14 10:01:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:38][root][INFO] - Training Epoch: 2/2, step 12420/16670 completed (loss: 0.1965785026550293, acc: 0.9431818127632141)
[2024-11-14 10:01:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:38][root][INFO] - Training Epoch: 2/2, step 12421/16670 completed (loss: 0.2629983425140381, acc: 0.94140625)
[2024-11-14 10:01:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:39][root][INFO] - Training Epoch: 2/2, step 12422/16670 completed (loss: 0.18578875064849854, acc: 0.9606741666793823)
[2024-11-14 10:01:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:39][root][INFO] - Training Epoch: 2/2, step 12423/16670 completed (loss: 0.14282448589801788, acc: 0.9656652212142944)
[2024-11-14 10:01:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:39][root][INFO] - Training Epoch: 2/2, step 12424/16670 completed (loss: 0.35792276263237, acc: 0.9298245906829834)
[2024-11-14 10:01:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:40][root][INFO] - Training Epoch: 2/2, step 12425/16670 completed (loss: 0.2248503565788269, acc: 0.9259259104728699)
[2024-11-14 10:01:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:40][root][INFO] - Training Epoch: 2/2, step 12426/16670 completed (loss: 0.12868696451187134, acc: 0.9595588445663452)
[2024-11-14 10:01:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:40][root][INFO] - Training Epoch: 2/2, step 12427/16670 completed (loss: 0.28293800354003906, acc: 0.9150000214576721)
[2024-11-14 10:01:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:41][root][INFO] - Training Epoch: 2/2, step 12428/16670 completed (loss: 0.04165695980191231, acc: 0.9888888597488403)
[2024-11-14 10:01:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:41][root][INFO] - Training Epoch: 2/2, step 12429/16670 completed (loss: 0.38731953501701355, acc: 0.9191176295280457)
[2024-11-14 10:01:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:41][root][INFO] - Training Epoch: 2/2, step 12430/16670 completed (loss: 0.10899659991264343, acc: 0.9700000286102295)
[2024-11-14 10:01:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:41][root][INFO] - Training Epoch: 2/2, step 12431/16670 completed (loss: 0.18380174040794373, acc: 0.9621621370315552)
[2024-11-14 10:01:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:42][root][INFO] - Training Epoch: 2/2, step 12432/16670 completed (loss: 0.0570635162293911, acc: 0.9784946441650391)
[2024-11-14 10:01:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:42][root][INFO] - Training Epoch: 2/2, step 12433/16670 completed (loss: 0.1094692274928093, acc: 0.9639639854431152)
[2024-11-14 10:01:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:42][root][INFO] - Training Epoch: 2/2, step 12434/16670 completed (loss: 0.29662275314331055, acc: 0.918367326259613)
[2024-11-14 10:01:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:43][root][INFO] - Training Epoch: 2/2, step 12435/16670 completed (loss: 0.14327554404735565, acc: 0.9609375)
[2024-11-14 10:01:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:43][root][INFO] - Training Epoch: 2/2, step 12436/16670 completed (loss: 0.4086763858795166, acc: 0.8951612710952759)
[2024-11-14 10:01:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:43][root][INFO] - Training Epoch: 2/2, step 12437/16670 completed (loss: 0.171898752450943, acc: 0.9428571462631226)
[2024-11-14 10:01:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:44][root][INFO] - Training Epoch: 2/2, step 12438/16670 completed (loss: 0.23077711462974548, acc: 0.9189189076423645)
[2024-11-14 10:01:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:44][root][INFO] - Training Epoch: 2/2, step 12439/16670 completed (loss: 0.11873792856931686, acc: 0.9583333134651184)
[2024-11-14 10:01:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:44][root][INFO] - Training Epoch: 2/2, step 12440/16670 completed (loss: 0.16222330927848816, acc: 0.9696969985961914)
[2024-11-14 10:01:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:45][root][INFO] - Training Epoch: 2/2, step 12441/16670 completed (loss: 0.17033980786800385, acc: 0.9224137663841248)
[2024-11-14 10:01:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:45][root][INFO] - Training Epoch: 2/2, step 12442/16670 completed (loss: 0.12739284336566925, acc: 0.9534883499145508)
[2024-11-14 10:01:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:45][root][INFO] - Training Epoch: 2/2, step 12443/16670 completed (loss: 0.14781102538108826, acc: 0.9509202241897583)
[2024-11-14 10:01:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:46][root][INFO] - Training Epoch: 2/2, step 12444/16670 completed (loss: 0.30902427434921265, acc: 0.949999988079071)
[2024-11-14 10:01:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:46][root][INFO] - Training Epoch: 2/2, step 12445/16670 completed (loss: 0.10109340399503708, acc: 0.9629629850387573)
[2024-11-14 10:01:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:46][root][INFO] - Training Epoch: 2/2, step 12446/16670 completed (loss: 0.2553407847881317, acc: 0.9312169551849365)
[2024-11-14 10:01:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:47][root][INFO] - Training Epoch: 2/2, step 12447/16670 completed (loss: 0.18880614638328552, acc: 0.9444444179534912)
[2024-11-14 10:01:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:47][root][INFO] - Training Epoch: 2/2, step 12448/16670 completed (loss: 0.16288259625434875, acc: 0.9527897238731384)
[2024-11-14 10:01:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:47][root][INFO] - Training Epoch: 2/2, step 12449/16670 completed (loss: 0.05558187887072563, acc: 0.9750000238418579)
[2024-11-14 10:01:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:48][root][INFO] - Training Epoch: 2/2, step 12450/16670 completed (loss: 0.3015236258506775, acc: 0.9384615421295166)
[2024-11-14 10:01:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:48][root][INFO] - Training Epoch: 2/2, step 12451/16670 completed (loss: 0.15221552550792694, acc: 0.9611111283302307)
[2024-11-14 10:01:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:48][root][INFO] - Training Epoch: 2/2, step 12452/16670 completed (loss: 0.2044914960861206, acc: 0.954081654548645)
[2024-11-14 10:01:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:49][root][INFO] - Training Epoch: 2/2, step 12453/16670 completed (loss: 0.21639782190322876, acc: 0.9371069073677063)
[2024-11-14 10:01:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:49][root][INFO] - Training Epoch: 2/2, step 12454/16670 completed (loss: 0.23325271904468536, acc: 0.9195402264595032)
[2024-11-14 10:01:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:49][root][INFO] - Training Epoch: 2/2, step 12455/16670 completed (loss: 0.1941208839416504, acc: 0.9458483457565308)
[2024-11-14 10:01:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:50][root][INFO] - Training Epoch: 2/2, step 12456/16670 completed (loss: 0.14725933969020844, acc: 0.9620853066444397)
[2024-11-14 10:01:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:50][root][INFO] - Training Epoch: 2/2, step 12457/16670 completed (loss: 0.3043014407157898, acc: 0.9215686321258545)
[2024-11-14 10:01:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:50][root][INFO] - Training Epoch: 2/2, step 12458/16670 completed (loss: 0.22182750701904297, acc: 0.9433962106704712)
[2024-11-14 10:01:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:50][root][INFO] - Training Epoch: 2/2, step 12459/16670 completed (loss: 0.19645920395851135, acc: 0.9313725233078003)
[2024-11-14 10:01:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:51][root][INFO] - Training Epoch: 2/2, step 12460/16670 completed (loss: 0.09943560510873795, acc: 0.9593495726585388)
[2024-11-14 10:01:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:51][root][INFO] - Training Epoch: 2/2, step 12461/16670 completed (loss: 0.20366249978542328, acc: 0.9637681245803833)
[2024-11-14 10:01:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:51][root][INFO] - Training Epoch: 2/2, step 12462/16670 completed (loss: 0.09351693838834763, acc: 0.9626168012619019)
[2024-11-14 10:01:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:52][root][INFO] - Training Epoch: 2/2, step 12463/16670 completed (loss: 0.40312692523002625, acc: 0.8995434045791626)
[2024-11-14 10:01:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:52][root][INFO] - Training Epoch: 2/2, step 12464/16670 completed (loss: 0.269199013710022, acc: 0.9329897165298462)
[2024-11-14 10:01:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:52][root][INFO] - Training Epoch: 2/2, step 12465/16670 completed (loss: 0.13786405324935913, acc: 0.9598214030265808)
[2024-11-14 10:01:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:53][root][INFO] - Training Epoch: 2/2, step 12466/16670 completed (loss: 0.0979870855808258, acc: 0.9772727489471436)
[2024-11-14 10:01:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:53][root][INFO] - Training Epoch: 2/2, step 12467/16670 completed (loss: 0.14077815413475037, acc: 0.9685534834861755)
[2024-11-14 10:01:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:53][root][INFO] - Training Epoch: 2/2, step 12468/16670 completed (loss: 0.35834041237831116, acc: 0.9114391207695007)
[2024-11-14 10:01:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:54][root][INFO] - Training Epoch: 2/2, step 12469/16670 completed (loss: 0.15136249363422394, acc: 0.9642857313156128)
[2024-11-14 10:01:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:54][root][INFO] - Training Epoch: 2/2, step 12470/16670 completed (loss: 0.14311635494232178, acc: 0.9567901492118835)
[2024-11-14 10:01:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:54][root][INFO] - Training Epoch: 2/2, step 12471/16670 completed (loss: 0.10314370691776276, acc: 0.9716981053352356)
[2024-11-14 10:01:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:55][root][INFO] - Training Epoch: 2/2, step 12472/16670 completed (loss: 0.23255665600299835, acc: 0.9242424368858337)
[2024-11-14 10:01:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:55][root][INFO] - Training Epoch: 2/2, step 12473/16670 completed (loss: 0.1875642091035843, acc: 0.9379310607910156)
[2024-11-14 10:01:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:55][root][INFO] - Training Epoch: 2/2, step 12474/16670 completed (loss: 0.28331395983695984, acc: 0.9166666865348816)
[2024-11-14 10:01:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:56][root][INFO] - Training Epoch: 2/2, step 12475/16670 completed (loss: 0.26631516218185425, acc: 0.9254902005195618)
[2024-11-14 10:01:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:56][root][INFO] - Training Epoch: 2/2, step 12476/16670 completed (loss: 0.1866959184408188, acc: 0.9617834687232971)
[2024-11-14 10:01:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:57][root][INFO] - Training Epoch: 2/2, step 12477/16670 completed (loss: 0.1755474954843521, acc: 0.9356725215911865)
[2024-11-14 10:01:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:57][root][INFO] - Training Epoch: 2/2, step 12478/16670 completed (loss: 0.23450967669487, acc: 0.9479768872261047)
[2024-11-14 10:01:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:57][root][INFO] - Training Epoch: 2/2, step 12479/16670 completed (loss: 0.23104511201381683, acc: 0.9541284441947937)
[2024-11-14 10:01:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:58][root][INFO] - Training Epoch: 2/2, step 12480/16670 completed (loss: 0.38347113132476807, acc: 0.8852459192276001)
[2024-11-14 10:01:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:58][root][INFO] - Training Epoch: 2/2, step 12481/16670 completed (loss: 0.07982572168111801, acc: 0.9890109896659851)
[2024-11-14 10:01:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:58][root][INFO] - Training Epoch: 2/2, step 12482/16670 completed (loss: 0.15701869130134583, acc: 0.9349112510681152)
[2024-11-14 10:01:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:59][root][INFO] - Training Epoch: 2/2, step 12483/16670 completed (loss: 0.23222112655639648, acc: 0.9490740895271301)
[2024-11-14 10:01:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:01:59][root][INFO] - Training Epoch: 2/2, step 12484/16670 completed (loss: 0.21650774776935577, acc: 0.9312977194786072)
[2024-11-14 10:01:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:00][root][INFO] - Training Epoch: 2/2, step 12485/16670 completed (loss: 0.13056787848472595, acc: 0.9758453965187073)
[2024-11-14 10:02:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:00][root][INFO] - Training Epoch: 2/2, step 12486/16670 completed (loss: 0.08620013296604156, acc: 0.9692307710647583)
[2024-11-14 10:02:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:00][root][INFO] - Training Epoch: 2/2, step 12487/16670 completed (loss: 0.14722496271133423, acc: 0.9527027010917664)
[2024-11-14 10:02:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:01][root][INFO] - Training Epoch: 2/2, step 12488/16670 completed (loss: 0.2533857822418213, acc: 0.931034505367279)
[2024-11-14 10:02:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:01][root][INFO] - Training Epoch: 2/2, step 12489/16670 completed (loss: 0.3068360686302185, acc: 0.9230769276618958)
[2024-11-14 10:02:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:01][root][INFO] - Training Epoch: 2/2, step 12490/16670 completed (loss: 0.19531287252902985, acc: 0.9379844665527344)
[2024-11-14 10:02:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:02][root][INFO] - Training Epoch: 2/2, step 12491/16670 completed (loss: 0.10665678232908249, acc: 0.95652174949646)
[2024-11-14 10:02:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:02][root][INFO] - Training Epoch: 2/2, step 12492/16670 completed (loss: 0.19928812980651855, acc: 0.9416058659553528)
[2024-11-14 10:02:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:02][root][INFO] - Training Epoch: 2/2, step 12493/16670 completed (loss: 0.30645444989204407, acc: 0.9375)
[2024-11-14 10:02:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:03][root][INFO] - Training Epoch: 2/2, step 12494/16670 completed (loss: 0.10451270639896393, acc: 0.981249988079071)
[2024-11-14 10:02:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:03][root][INFO] - Training Epoch: 2/2, step 12495/16670 completed (loss: 0.10709965229034424, acc: 0.9714285731315613)
[2024-11-14 10:02:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:03][root][INFO] - Training Epoch: 2/2, step 12496/16670 completed (loss: 0.11944005638360977, acc: 0.9747899174690247)
[2024-11-14 10:02:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:04][root][INFO] - Training Epoch: 2/2, step 12497/16670 completed (loss: 0.10651224106550217, acc: 0.9894737005233765)
[2024-11-14 10:02:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:04][root][INFO] - Training Epoch: 2/2, step 12498/16670 completed (loss: 0.142129048705101, acc: 0.9728506803512573)
[2024-11-14 10:02:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:02:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:03:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:04:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:05:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:06:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:07:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:08:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:09:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:10:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:11:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:12:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:52][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.7268, device='cuda:0') eval_epoch_loss=tensor(0.5463, device='cuda:0') eval_epoch_acc=tensor(0.8808, device='cuda:0')
[2024-11-14 10:13:52][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-14 10:13:52][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-14 10:13:52][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_12499_loss_0.5462759137153625/model.pt
[2024-11-14 10:13:52][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft directory
[2024-11-14 10:13:52][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.5462759137153625
[2024-11-14 10:13:52][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.8808495998382568
[2024-11-14 10:13:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:53][root][INFO] - Training Epoch: 2/2, step 12499/16670 completed (loss: 0.2624801993370056, acc: 0.953125)
[2024-11-14 10:13:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:53][root][INFO] - Training Epoch: 2/2, step 12500/16670 completed (loss: 0.24960707128047943, acc: 0.9364162087440491)
[2024-11-14 10:13:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:53][root][INFO] - Training Epoch: 2/2, step 12501/16670 completed (loss: 0.0936204046010971, acc: 0.9802631735801697)
[2024-11-14 10:13:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:54][root][INFO] - Training Epoch: 2/2, step 12502/16670 completed (loss: 0.1159285232424736, acc: 0.9729729890823364)
[2024-11-14 10:13:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:54][root][INFO] - Training Epoch: 2/2, step 12503/16670 completed (loss: 0.23421986401081085, acc: 0.9395349025726318)
[2024-11-14 10:13:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:54][root][INFO] - Training Epoch: 2/2, step 12504/16670 completed (loss: 0.20607921481132507, acc: 0.9523809552192688)
[2024-11-14 10:13:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:55][root][INFO] - Training Epoch: 2/2, step 12505/16670 completed (loss: 0.2356347143650055, acc: 0.94140625)
[2024-11-14 10:13:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:55][root][INFO] - Training Epoch: 2/2, step 12506/16670 completed (loss: 0.1131148487329483, acc: 0.9797979593276978)
[2024-11-14 10:13:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:55][root][INFO] - Training Epoch: 2/2, step 12507/16670 completed (loss: 0.1660255342721939, acc: 0.9508928656578064)
[2024-11-14 10:13:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:56][root][INFO] - Training Epoch: 2/2, step 12508/16670 completed (loss: 0.34025585651397705, acc: 0.9207317233085632)
[2024-11-14 10:13:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:56][root][INFO] - Training Epoch: 2/2, step 12509/16670 completed (loss: 0.1675955355167389, acc: 0.9365079402923584)
[2024-11-14 10:13:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:56][root][INFO] - Training Epoch: 2/2, step 12510/16670 completed (loss: 0.21504035592079163, acc: 0.9418604373931885)
[2024-11-14 10:13:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:57][root][INFO] - Training Epoch: 2/2, step 12511/16670 completed (loss: 0.16113980114459991, acc: 0.9568106532096863)
[2024-11-14 10:13:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:57][root][INFO] - Training Epoch: 2/2, step 12512/16670 completed (loss: 0.16848993301391602, acc: 0.9415584206581116)
[2024-11-14 10:13:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:57][root][INFO] - Training Epoch: 2/2, step 12513/16670 completed (loss: 0.1414620280265808, acc: 0.9693877696990967)
[2024-11-14 10:13:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:58][root][INFO] - Training Epoch: 2/2, step 12514/16670 completed (loss: 0.3244086802005768, acc: 0.9270386099815369)
[2024-11-14 10:13:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:58][root][INFO] - Training Epoch: 2/2, step 12515/16670 completed (loss: 0.17568553984165192, acc: 0.949367105960846)
[2024-11-14 10:13:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:58][root][INFO] - Training Epoch: 2/2, step 12516/16670 completed (loss: 0.1678444743156433, acc: 0.9508196711540222)
[2024-11-14 10:13:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:59][root][INFO] - Training Epoch: 2/2, step 12517/16670 completed (loss: 0.17788253724575043, acc: 0.9444444179534912)
[2024-11-14 10:13:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:13:59][root][INFO] - Training Epoch: 2/2, step 12518/16670 completed (loss: 0.16287168860435486, acc: 0.9487179517745972)
[2024-11-14 10:13:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:00][root][INFO] - Training Epoch: 2/2, step 12519/16670 completed (loss: 0.21182070672512054, acc: 0.9353846311569214)
[2024-11-14 10:14:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:00][root][INFO] - Training Epoch: 2/2, step 12520/16670 completed (loss: 0.11751941591501236, acc: 0.9519230723381042)
[2024-11-14 10:14:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:00][root][INFO] - Training Epoch: 2/2, step 12521/16670 completed (loss: 0.35739418864250183, acc: 0.9064748287200928)
[2024-11-14 10:14:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:01][root][INFO] - Training Epoch: 2/2, step 12522/16670 completed (loss: 0.42671918869018555, acc: 0.8616352081298828)
[2024-11-14 10:14:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:01][root][INFO] - Training Epoch: 2/2, step 12523/16670 completed (loss: 0.2716980278491974, acc: 0.9181286692619324)
[2024-11-14 10:14:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:01][root][INFO] - Training Epoch: 2/2, step 12524/16670 completed (loss: 0.14159035682678223, acc: 0.961240291595459)
[2024-11-14 10:14:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:02][root][INFO] - Training Epoch: 2/2, step 12525/16670 completed (loss: 0.3046054542064667, acc: 0.9152542352676392)
[2024-11-14 10:14:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:02][root][INFO] - Training Epoch: 2/2, step 12526/16670 completed (loss: 0.3326706886291504, acc: 0.897849440574646)
[2024-11-14 10:14:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:02][root][INFO] - Training Epoch: 2/2, step 12527/16670 completed (loss: 0.1333884298801422, acc: 0.963302731513977)
[2024-11-14 10:14:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:03][root][INFO] - Training Epoch: 2/2, step 12528/16670 completed (loss: 0.4935649335384369, acc: 0.8672566413879395)
[2024-11-14 10:14:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:03][root][INFO] - Training Epoch: 2/2, step 12529/16670 completed (loss: 0.17806366086006165, acc: 0.9578947424888611)
[2024-11-14 10:14:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:03][root][INFO] - Training Epoch: 2/2, step 12530/16670 completed (loss: 0.3376615047454834, acc: 0.9035087823867798)
[2024-11-14 10:14:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:03][root][INFO] - Training Epoch: 2/2, step 12531/16670 completed (loss: 0.5161458253860474, acc: 0.8632478713989258)
[2024-11-14 10:14:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:04][root][INFO] - Training Epoch: 2/2, step 12532/16670 completed (loss: 0.09790674597024918, acc: 0.9740259647369385)
[2024-11-14 10:14:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:04][root][INFO] - Training Epoch: 2/2, step 12533/16670 completed (loss: 0.06887514144182205, acc: 0.9658536314964294)
[2024-11-14 10:14:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:04][root][INFO] - Training Epoch: 2/2, step 12534/16670 completed (loss: 0.21599452197551727, acc: 0.9398148059844971)
[2024-11-14 10:14:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:05][root][INFO] - Training Epoch: 2/2, step 12535/16670 completed (loss: 0.28015080094337463, acc: 0.9099525809288025)
[2024-11-14 10:14:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:05][root][INFO] - Training Epoch: 2/2, step 12536/16670 completed (loss: 0.22544486820697784, acc: 0.9595959782600403)
[2024-11-14 10:14:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:05][root][INFO] - Training Epoch: 2/2, step 12537/16670 completed (loss: 0.20924055576324463, acc: 0.9466666579246521)
[2024-11-14 10:14:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:06][root][INFO] - Training Epoch: 2/2, step 12538/16670 completed (loss: 0.31018316745758057, acc: 0.9300000071525574)
[2024-11-14 10:14:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:06][root][INFO] - Training Epoch: 2/2, step 12539/16670 completed (loss: 0.4976716935634613, acc: 0.84375)
[2024-11-14 10:14:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:06][root][INFO] - Training Epoch: 2/2, step 12540/16670 completed (loss: 0.7308407425880432, acc: 0.7708333134651184)
[2024-11-14 10:14:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:07][root][INFO] - Training Epoch: 2/2, step 12541/16670 completed (loss: 0.24230362474918365, acc: 0.9475806355476379)
[2024-11-14 10:14:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:07][root][INFO] - Training Epoch: 2/2, step 12542/16670 completed (loss: 0.3878898620605469, acc: 0.8999999761581421)
[2024-11-14 10:14:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:07][root][INFO] - Training Epoch: 2/2, step 12543/16670 completed (loss: 0.09992415457963943, acc: 0.9659090638160706)
[2024-11-14 10:14:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:08][root][INFO] - Training Epoch: 2/2, step 12544/16670 completed (loss: 0.1324080377817154, acc: 0.9489051103591919)
[2024-11-14 10:14:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:08][root][INFO] - Training Epoch: 2/2, step 12545/16670 completed (loss: 0.2736518085002899, acc: 0.9204545617103577)
[2024-11-14 10:14:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:08][root][INFO] - Training Epoch: 2/2, step 12546/16670 completed (loss: 0.13233058154582977, acc: 0.9716981053352356)
[2024-11-14 10:14:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:09][root][INFO] - Training Epoch: 2/2, step 12547/16670 completed (loss: 0.23652343451976776, acc: 0.9278350472450256)
[2024-11-14 10:14:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:09][root][INFO] - Training Epoch: 2/2, step 12548/16670 completed (loss: 0.13577772676944733, acc: 0.95686274766922)
[2024-11-14 10:14:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:09][root][INFO] - Training Epoch: 2/2, step 12549/16670 completed (loss: 0.28922799229621887, acc: 0.9153439402580261)
[2024-11-14 10:14:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:10][root][INFO] - Training Epoch: 2/2, step 12550/16670 completed (loss: 0.11546411365270615, acc: 0.9748954176902771)
[2024-11-14 10:14:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:10][root][INFO] - Training Epoch: 2/2, step 12551/16670 completed (loss: 0.17845851182937622, acc: 0.9438775777816772)
[2024-11-14 10:14:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:10][root][INFO] - Training Epoch: 2/2, step 12552/16670 completed (loss: 0.11729907989501953, acc: 0.9637096524238586)
[2024-11-14 10:14:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:11][root][INFO] - Training Epoch: 2/2, step 12553/16670 completed (loss: 0.08250276744365692, acc: 0.9699570536613464)
[2024-11-14 10:14:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:11][root][INFO] - Training Epoch: 2/2, step 12554/16670 completed (loss: 0.3081769347190857, acc: 0.9266055226325989)
[2024-11-14 10:14:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:11][root][INFO] - Training Epoch: 2/2, step 12555/16670 completed (loss: 0.26912015676498413, acc: 0.9320388436317444)
[2024-11-14 10:14:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:12][root][INFO] - Training Epoch: 2/2, step 12556/16670 completed (loss: 0.22548720240592957, acc: 0.9404761791229248)
[2024-11-14 10:14:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:12][root][INFO] - Training Epoch: 2/2, step 12557/16670 completed (loss: 0.11899159103631973, acc: 0.970059871673584)
[2024-11-14 10:14:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:12][root][INFO] - Training Epoch: 2/2, step 12558/16670 completed (loss: 0.18791206181049347, acc: 0.9444444179534912)
[2024-11-14 10:14:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:12][root][INFO] - Training Epoch: 2/2, step 12559/16670 completed (loss: 0.15783032774925232, acc: 0.9623430967330933)
[2024-11-14 10:14:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:13][root][INFO] - Training Epoch: 2/2, step 12560/16670 completed (loss: 0.1579800844192505, acc: 0.9596773982048035)
[2024-11-14 10:14:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:13][root][INFO] - Training Epoch: 2/2, step 12561/16670 completed (loss: 0.16206179559230804, acc: 0.953987717628479)
[2024-11-14 10:14:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:13][root][INFO] - Training Epoch: 2/2, step 12562/16670 completed (loss: 0.20035375654697418, acc: 0.9512194991111755)
[2024-11-14 10:14:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:14][root][INFO] - Training Epoch: 2/2, step 12563/16670 completed (loss: 0.15076154470443726, acc: 0.9561403393745422)
[2024-11-14 10:14:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:14][root][INFO] - Training Epoch: 2/2, step 12564/16670 completed (loss: 0.2606043815612793, acc: 0.9184549450874329)
[2024-11-14 10:14:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:14][root][INFO] - Training Epoch: 2/2, step 12565/16670 completed (loss: 0.30696019530296326, acc: 0.9224806427955627)
[2024-11-14 10:14:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:15][root][INFO] - Training Epoch: 2/2, step 12566/16670 completed (loss: 0.11617099493741989, acc: 0.9579831957817078)
[2024-11-14 10:14:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:15][root][INFO] - Training Epoch: 2/2, step 12567/16670 completed (loss: 0.16804221272468567, acc: 0.9634146094322205)
[2024-11-14 10:14:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:15][root][INFO] - Training Epoch: 2/2, step 12568/16670 completed (loss: 0.04147401079535484, acc: 0.9811320900917053)
[2024-11-14 10:14:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:16][root][INFO] - Training Epoch: 2/2, step 12569/16670 completed (loss: 0.1349007487297058, acc: 0.9735099077224731)
[2024-11-14 10:14:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:16][root][INFO] - Training Epoch: 2/2, step 12570/16670 completed (loss: 0.11797941476106644, acc: 0.9622641801834106)
[2024-11-14 10:14:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:16][root][INFO] - Training Epoch: 2/2, step 12571/16670 completed (loss: 0.3993804454803467, acc: 0.8881788849830627)
[2024-11-14 10:14:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:17][root][INFO] - Training Epoch: 2/2, step 12572/16670 completed (loss: 0.15157508850097656, acc: 0.9710144996643066)
[2024-11-14 10:14:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:17][root][INFO] - Training Epoch: 2/2, step 12573/16670 completed (loss: 0.1595507115125656, acc: 0.9547511339187622)
[2024-11-14 10:14:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:17][root][INFO] - Training Epoch: 2/2, step 12574/16670 completed (loss: 0.08876094967126846, acc: 0.9709302186965942)
[2024-11-14 10:14:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:18][root][INFO] - Training Epoch: 2/2, step 12575/16670 completed (loss: 0.15034443140029907, acc: 0.9647058844566345)
[2024-11-14 10:14:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:18][root][INFO] - Training Epoch: 2/2, step 12576/16670 completed (loss: 0.1439085453748703, acc: 0.9583333134651184)
[2024-11-14 10:14:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:18][root][INFO] - Training Epoch: 2/2, step 12577/16670 completed (loss: 0.03509188070893288, acc: 0.9900000095367432)
[2024-11-14 10:14:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:19][root][INFO] - Training Epoch: 2/2, step 12578/16670 completed (loss: 0.15236268937587738, acc: 0.9470198750495911)
[2024-11-14 10:14:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:19][root][INFO] - Training Epoch: 2/2, step 12579/16670 completed (loss: 0.06316554546356201, acc: 0.9891892075538635)
[2024-11-14 10:14:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:19][root][INFO] - Training Epoch: 2/2, step 12580/16670 completed (loss: 0.14866425096988678, acc: 0.9777777791023254)
[2024-11-14 10:14:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:19][root][INFO] - Training Epoch: 2/2, step 12581/16670 completed (loss: 0.19254890084266663, acc: 0.9545454382896423)
[2024-11-14 10:14:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:20][root][INFO] - Training Epoch: 2/2, step 12582/16670 completed (loss: 0.37442395091056824, acc: 0.932330846786499)
[2024-11-14 10:14:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:20][root][INFO] - Training Epoch: 2/2, step 12583/16670 completed (loss: 0.2197602093219757, acc: 0.9503105878829956)
[2024-11-14 10:14:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:20][root][INFO] - Training Epoch: 2/2, step 12584/16670 completed (loss: 0.222206249833107, acc: 0.9370370507240295)
[2024-11-14 10:14:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:21][root][INFO] - Training Epoch: 2/2, step 12585/16670 completed (loss: 0.10580061376094818, acc: 0.9677419066429138)
[2024-11-14 10:14:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:21][root][INFO] - Training Epoch: 2/2, step 12586/16670 completed (loss: 0.16417299211025238, acc: 0.9634146094322205)
[2024-11-14 10:14:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:21][root][INFO] - Training Epoch: 2/2, step 12587/16670 completed (loss: 0.13095279037952423, acc: 0.9604519605636597)
[2024-11-14 10:14:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:22][root][INFO] - Training Epoch: 2/2, step 12588/16670 completed (loss: 0.05508367344737053, acc: 0.9885057210922241)
[2024-11-14 10:14:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:22][root][INFO] - Training Epoch: 2/2, step 12589/16670 completed (loss: 0.2034209817647934, acc: 0.954023003578186)
[2024-11-14 10:14:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:22][root][INFO] - Training Epoch: 2/2, step 12590/16670 completed (loss: 0.21080408990383148, acc: 0.9363636374473572)
[2024-11-14 10:14:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:23][root][INFO] - Training Epoch: 2/2, step 12591/16670 completed (loss: 0.08838529139757156, acc: 0.9692307710647583)
[2024-11-14 10:14:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:23][root][INFO] - Training Epoch: 2/2, step 12592/16670 completed (loss: 0.14883485436439514, acc: 0.9722222089767456)
[2024-11-14 10:14:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:23][root][INFO] - Training Epoch: 2/2, step 12593/16670 completed (loss: 0.2738664746284485, acc: 0.9390863180160522)
[2024-11-14 10:14:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:24][root][INFO] - Training Epoch: 2/2, step 12594/16670 completed (loss: 0.07910387963056564, acc: 0.9733333587646484)
[2024-11-14 10:14:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:24][root][INFO] - Training Epoch: 2/2, step 12595/16670 completed (loss: 0.07391998916864395, acc: 0.9803921580314636)
[2024-11-14 10:14:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:24][root][INFO] - Training Epoch: 2/2, step 12596/16670 completed (loss: 0.14728453755378723, acc: 0.9476439952850342)
[2024-11-14 10:14:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:25][root][INFO] - Training Epoch: 2/2, step 12597/16670 completed (loss: 0.2766371965408325, acc: 0.9111111164093018)
[2024-11-14 10:14:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:25][root][INFO] - Training Epoch: 2/2, step 12598/16670 completed (loss: 0.24604879319667816, acc: 0.9379844665527344)
[2024-11-14 10:14:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:25][root][INFO] - Training Epoch: 2/2, step 12599/16670 completed (loss: 0.2915615141391754, acc: 0.9188033938407898)
[2024-11-14 10:14:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:26][root][INFO] - Training Epoch: 2/2, step 12600/16670 completed (loss: 0.06606727093458176, acc: 0.9801980257034302)
[2024-11-14 10:14:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:26][root][INFO] - Training Epoch: 2/2, step 12601/16670 completed (loss: 0.19234183430671692, acc: 0.9516128897666931)
[2024-11-14 10:14:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:26][root][INFO] - Training Epoch: 2/2, step 12602/16670 completed (loss: 0.09246190637350082, acc: 0.9830508232116699)
[2024-11-14 10:14:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:27][root][INFO] - Training Epoch: 2/2, step 12603/16670 completed (loss: 0.11872018128633499, acc: 0.9674796462059021)
[2024-11-14 10:14:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:27][root][INFO] - Training Epoch: 2/2, step 12604/16670 completed (loss: 0.1533539742231369, acc: 0.9666666388511658)
[2024-11-14 10:14:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:27][root][INFO] - Training Epoch: 2/2, step 12605/16670 completed (loss: 0.2344708889722824, acc: 0.9252873659133911)
[2024-11-14 10:14:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:28][root][INFO] - Training Epoch: 2/2, step 12606/16670 completed (loss: 0.07383255660533905, acc: 0.9788359999656677)
[2024-11-14 10:14:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:28][root][INFO] - Training Epoch: 2/2, step 12607/16670 completed (loss: 0.05120352283120155, acc: 0.9545454382896423)
[2024-11-14 10:14:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:28][root][INFO] - Training Epoch: 2/2, step 12608/16670 completed (loss: 0.06077452376484871, acc: 0.9831932783126831)
[2024-11-14 10:14:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:29][root][INFO] - Training Epoch: 2/2, step 12609/16670 completed (loss: 0.053893499076366425, acc: 0.9873417615890503)
[2024-11-14 10:14:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:29][root][INFO] - Training Epoch: 2/2, step 12610/16670 completed (loss: 0.2264655977487564, acc: 0.9294871687889099)
[2024-11-14 10:14:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:29][root][INFO] - Training Epoch: 2/2, step 12611/16670 completed (loss: 0.2808592617511749, acc: 0.9285714030265808)
[2024-11-14 10:14:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:30][root][INFO] - Training Epoch: 2/2, step 12612/16670 completed (loss: 0.19112026691436768, acc: 0.9525862336158752)
[2024-11-14 10:14:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:30][root][INFO] - Training Epoch: 2/2, step 12613/16670 completed (loss: 0.10095120221376419, acc: 0.969072163105011)
[2024-11-14 10:14:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:30][root][INFO] - Training Epoch: 2/2, step 12614/16670 completed (loss: 0.20756877958774567, acc: 0.9635416865348816)
[2024-11-14 10:14:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:30][root][INFO] - Training Epoch: 2/2, step 12615/16670 completed (loss: 0.11045024544000626, acc: 0.9521530866622925)
[2024-11-14 10:14:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:31][root][INFO] - Training Epoch: 2/2, step 12616/16670 completed (loss: 0.09753866493701935, acc: 0.9707317352294922)
[2024-11-14 10:14:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:31][root][INFO] - Training Epoch: 2/2, step 12617/16670 completed (loss: 0.23812928795814514, acc: 0.9496855139732361)
[2024-11-14 10:14:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:31][root][INFO] - Training Epoch: 2/2, step 12618/16670 completed (loss: 0.08694133162498474, acc: 0.9805825352668762)
[2024-11-14 10:14:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:32][root][INFO] - Training Epoch: 2/2, step 12619/16670 completed (loss: 0.23729389905929565, acc: 0.9266409277915955)
[2024-11-14 10:14:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:32][root][INFO] - Training Epoch: 2/2, step 12620/16670 completed (loss: 0.13611556589603424, acc: 0.9632353186607361)
[2024-11-14 10:14:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:32][root][INFO] - Training Epoch: 2/2, step 12621/16670 completed (loss: 0.13913822174072266, acc: 0.95652174949646)
[2024-11-14 10:14:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:33][root][INFO] - Training Epoch: 2/2, step 12622/16670 completed (loss: 0.1502319574356079, acc: 0.9629629850387573)
[2024-11-14 10:14:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:33][root][INFO] - Training Epoch: 2/2, step 12623/16670 completed (loss: 0.10312299430370331, acc: 0.9552238583564758)
[2024-11-14 10:14:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:33][root][INFO] - Training Epoch: 2/2, step 12624/16670 completed (loss: 0.07064339518547058, acc: 0.9696969985961914)
[2024-11-14 10:14:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:34][root][INFO] - Training Epoch: 2/2, step 12625/16670 completed (loss: 0.056557849049568176, acc: 0.984000027179718)
[2024-11-14 10:14:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:34][root][INFO] - Training Epoch: 2/2, step 12626/16670 completed (loss: 0.1958843171596527, acc: 0.9333333373069763)
[2024-11-14 10:14:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:34][root][INFO] - Training Epoch: 2/2, step 12627/16670 completed (loss: 0.19551384449005127, acc: 0.9384615421295166)
[2024-11-14 10:14:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:35][root][INFO] - Training Epoch: 2/2, step 12628/16670 completed (loss: 0.18671242892742157, acc: 0.9537037014961243)
[2024-11-14 10:14:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:35][root][INFO] - Training Epoch: 2/2, step 12629/16670 completed (loss: 0.15433304011821747, acc: 0.949438214302063)
[2024-11-14 10:14:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:35][root][INFO] - Training Epoch: 2/2, step 12630/16670 completed (loss: 0.07325717806816101, acc: 0.9813953638076782)
[2024-11-14 10:14:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:36][root][INFO] - Training Epoch: 2/2, step 12631/16670 completed (loss: 0.1476295292377472, acc: 0.9485714435577393)
[2024-11-14 10:14:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:36][root][INFO] - Training Epoch: 2/2, step 12632/16670 completed (loss: 0.1555502712726593, acc: 0.9657142758369446)
[2024-11-14 10:14:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:36][root][INFO] - Training Epoch: 2/2, step 12633/16670 completed (loss: 0.11484342068433762, acc: 0.9580644965171814)
[2024-11-14 10:14:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:37][root][INFO] - Training Epoch: 2/2, step 12634/16670 completed (loss: 0.09292207658290863, acc: 0.9699570536613464)
[2024-11-14 10:14:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:37][root][INFO] - Training Epoch: 2/2, step 12635/16670 completed (loss: 0.09814321249723434, acc: 0.9686098694801331)
[2024-11-14 10:14:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:37][root][INFO] - Training Epoch: 2/2, step 12636/16670 completed (loss: 0.13728109002113342, acc: 0.9622641801834106)
[2024-11-14 10:14:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:38][root][INFO] - Training Epoch: 2/2, step 12637/16670 completed (loss: 0.11062941700220108, acc: 0.9784946441650391)
[2024-11-14 10:14:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:38][root][INFO] - Training Epoch: 2/2, step 12638/16670 completed (loss: 0.11967859417200089, acc: 0.9548386931419373)
[2024-11-14 10:14:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:38][root][INFO] - Training Epoch: 2/2, step 12639/16670 completed (loss: 0.10104798525571823, acc: 0.9659863710403442)
[2024-11-14 10:14:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:39][root][INFO] - Training Epoch: 2/2, step 12640/16670 completed (loss: 0.11714477092027664, acc: 0.9608938694000244)
[2024-11-14 10:14:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:39][root][INFO] - Training Epoch: 2/2, step 12641/16670 completed (loss: 0.09283825755119324, acc: 0.9756097793579102)
[2024-11-14 10:14:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:39][root][INFO] - Training Epoch: 2/2, step 12642/16670 completed (loss: 0.07898224890232086, acc: 0.9838709831237793)
[2024-11-14 10:14:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:39][root][INFO] - Training Epoch: 2/2, step 12643/16670 completed (loss: 0.10920136421918869, acc: 0.9631578922271729)
[2024-11-14 10:14:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:40][root][INFO] - Training Epoch: 2/2, step 12644/16670 completed (loss: 0.11974645406007767, acc: 0.9748743772506714)
[2024-11-14 10:14:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:40][root][INFO] - Training Epoch: 2/2, step 12645/16670 completed (loss: 0.03767231106758118, acc: 0.98591548204422)
[2024-11-14 10:14:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:40][root][INFO] - Training Epoch: 2/2, step 12646/16670 completed (loss: 0.11047682166099548, acc: 0.9685534834861755)
[2024-11-14 10:14:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:41][root][INFO] - Training Epoch: 2/2, step 12647/16670 completed (loss: 0.20746898651123047, acc: 0.9274193644523621)
[2024-11-14 10:14:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:41][root][INFO] - Training Epoch: 2/2, step 12648/16670 completed (loss: 0.10764180123806, acc: 0.9740259647369385)
[2024-11-14 10:14:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:41][root][INFO] - Training Epoch: 2/2, step 12649/16670 completed (loss: 0.15212616324424744, acc: 0.9724137783050537)
[2024-11-14 10:14:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:42][root][INFO] - Training Epoch: 2/2, step 12650/16670 completed (loss: 0.32467806339263916, acc: 0.8961039185523987)
[2024-11-14 10:14:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:42][root][INFO] - Training Epoch: 2/2, step 12651/16670 completed (loss: 0.1569044440984726, acc: 0.9479166865348816)
[2024-11-14 10:14:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:42][root][INFO] - Training Epoch: 2/2, step 12652/16670 completed (loss: 0.2311970740556717, acc: 0.936274528503418)
[2024-11-14 10:14:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:42][root][INFO] - Training Epoch: 2/2, step 12653/16670 completed (loss: 0.14603225886821747, acc: 0.9599999785423279)
[2024-11-14 10:14:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:43][root][INFO] - Training Epoch: 2/2, step 12654/16670 completed (loss: 0.2760951519012451, acc: 0.9275362491607666)
[2024-11-14 10:14:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:43][root][INFO] - Training Epoch: 2/2, step 12655/16670 completed (loss: 0.04626940190792084, acc: 0.9890710115432739)
[2024-11-14 10:14:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:43][root][INFO] - Training Epoch: 2/2, step 12656/16670 completed (loss: 0.11602458357810974, acc: 0.9736841917037964)
[2024-11-14 10:14:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:44][root][INFO] - Training Epoch: 2/2, step 12657/16670 completed (loss: 0.2002260386943817, acc: 0.9405405521392822)
[2024-11-14 10:14:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:44][root][INFO] - Training Epoch: 2/2, step 12658/16670 completed (loss: 0.14886797964572906, acc: 0.9629629850387573)
[2024-11-14 10:14:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:44][root][INFO] - Training Epoch: 2/2, step 12659/16670 completed (loss: 0.2128056436777115, acc: 0.9622641801834106)
[2024-11-14 10:14:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:45][root][INFO] - Training Epoch: 2/2, step 12660/16670 completed (loss: 0.12942631542682648, acc: 0.9607843160629272)
[2024-11-14 10:14:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:45][root][INFO] - Training Epoch: 2/2, step 12661/16670 completed (loss: 0.0073244874365627766, acc: 1.0)
[2024-11-14 10:14:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:45][root][INFO] - Training Epoch: 2/2, step 12662/16670 completed (loss: 0.20220650732517242, acc: 0.9479166865348816)
[2024-11-14 10:14:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:45][root][INFO] - Training Epoch: 2/2, step 12663/16670 completed (loss: 0.13193920254707336, acc: 0.9720930457115173)
[2024-11-14 10:14:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:46][root][INFO] - Training Epoch: 2/2, step 12664/16670 completed (loss: 0.10950209200382233, acc: 0.9635036587715149)
[2024-11-14 10:14:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:46][root][INFO] - Training Epoch: 2/2, step 12665/16670 completed (loss: 0.07310006022453308, acc: 0.9758453965187073)
[2024-11-14 10:14:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:46][root][INFO] - Training Epoch: 2/2, step 12666/16670 completed (loss: 0.06755363941192627, acc: 0.9905213117599487)
[2024-11-14 10:14:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:47][root][INFO] - Training Epoch: 2/2, step 12667/16670 completed (loss: 0.15929530560970306, acc: 0.95333331823349)
[2024-11-14 10:14:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:47][root][INFO] - Training Epoch: 2/2, step 12668/16670 completed (loss: 0.1977115273475647, acc: 0.9485714435577393)
[2024-11-14 10:14:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:47][root][INFO] - Training Epoch: 2/2, step 12669/16670 completed (loss: 0.1176498532295227, acc: 0.949999988079071)
[2024-11-14 10:14:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:48][root][INFO] - Training Epoch: 2/2, step 12670/16670 completed (loss: 0.0874994769692421, acc: 0.9841269850730896)
[2024-11-14 10:14:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:48][root][INFO] - Training Epoch: 2/2, step 12671/16670 completed (loss: 0.1833290010690689, acc: 0.9495798349380493)
[2024-11-14 10:14:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:48][root][INFO] - Training Epoch: 2/2, step 12672/16670 completed (loss: 0.0520133413374424, acc: 0.9829931855201721)
[2024-11-14 10:14:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:49][root][INFO] - Training Epoch: 2/2, step 12673/16670 completed (loss: 0.1603367179632187, acc: 0.9464285969734192)
[2024-11-14 10:14:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:49][root][INFO] - Training Epoch: 2/2, step 12674/16670 completed (loss: 0.11551254987716675, acc: 0.9730941653251648)
[2024-11-14 10:14:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:49][root][INFO] - Training Epoch: 2/2, step 12675/16670 completed (loss: 0.0432116836309433, acc: 0.9886363744735718)
[2024-11-14 10:14:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:50][root][INFO] - Training Epoch: 2/2, step 12676/16670 completed (loss: 0.07443670183420181, acc: 0.9698795080184937)
[2024-11-14 10:14:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:50][root][INFO] - Training Epoch: 2/2, step 12677/16670 completed (loss: 0.09940500557422638, acc: 0.9776119589805603)
[2024-11-14 10:14:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:50][root][INFO] - Training Epoch: 2/2, step 12678/16670 completed (loss: 0.23483926057815552, acc: 0.9497206807136536)
[2024-11-14 10:14:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:51][root][INFO] - Training Epoch: 2/2, step 12679/16670 completed (loss: 0.13226228952407837, acc: 0.9550561904907227)
[2024-11-14 10:14:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:51][root][INFO] - Training Epoch: 2/2, step 12680/16670 completed (loss: 0.019841834902763367, acc: 0.988304078578949)
[2024-11-14 10:14:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:51][root][INFO] - Training Epoch: 2/2, step 12681/16670 completed (loss: 0.11345169693231583, acc: 0.9620253443717957)
[2024-11-14 10:14:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:52][root][INFO] - Training Epoch: 2/2, step 12682/16670 completed (loss: 0.053238801658153534, acc: 0.9918032884597778)
[2024-11-14 10:14:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:52][root][INFO] - Training Epoch: 2/2, step 12683/16670 completed (loss: 0.09415807574987411, acc: 0.9631147384643555)
[2024-11-14 10:14:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:52][root][INFO] - Training Epoch: 2/2, step 12684/16670 completed (loss: 0.10798709839582443, acc: 0.9599999785423279)
[2024-11-14 10:14:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:52][root][INFO] - Training Epoch: 2/2, step 12685/16670 completed (loss: 0.2017388790845871, acc: 0.9545454382896423)
[2024-11-14 10:14:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:53][root][INFO] - Training Epoch: 2/2, step 12686/16670 completed (loss: 0.2099250853061676, acc: 0.9489796161651611)
[2024-11-14 10:14:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:53][root][INFO] - Training Epoch: 2/2, step 12687/16670 completed (loss: 0.213836207985878, acc: 0.9570552110671997)
[2024-11-14 10:14:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:53][root][INFO] - Training Epoch: 2/2, step 12688/16670 completed (loss: 0.12043078988790512, acc: 0.9726027250289917)
[2024-11-14 10:14:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:54][root][INFO] - Training Epoch: 2/2, step 12689/16670 completed (loss: 0.11176421493291855, acc: 0.9529411792755127)
[2024-11-14 10:14:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:54][root][INFO] - Training Epoch: 2/2, step 12690/16670 completed (loss: 0.23153360188007355, acc: 0.9305555820465088)
[2024-11-14 10:14:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:54][root][INFO] - Training Epoch: 2/2, step 12691/16670 completed (loss: 0.10865221172571182, acc: 0.9819819927215576)
[2024-11-14 10:14:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:55][root][INFO] - Training Epoch: 2/2, step 12692/16670 completed (loss: 0.14192989468574524, acc: 0.9716981053352356)
[2024-11-14 10:14:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:55][root][INFO] - Training Epoch: 2/2, step 12693/16670 completed (loss: 0.060529813170433044, acc: 0.9722222089767456)
[2024-11-14 10:14:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:55][root][INFO] - Training Epoch: 2/2, step 12694/16670 completed (loss: 0.09973909705877304, acc: 0.9824561476707458)
[2024-11-14 10:14:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:56][root][INFO] - Training Epoch: 2/2, step 12695/16670 completed (loss: 0.06508422642946243, acc: 0.9774011373519897)
[2024-11-14 10:14:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:56][root][INFO] - Training Epoch: 2/2, step 12696/16670 completed (loss: 0.1498846858739853, acc: 0.9471153616905212)
[2024-11-14 10:14:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:56][root][INFO] - Training Epoch: 2/2, step 12697/16670 completed (loss: 0.18780745565891266, acc: 0.9547738432884216)
[2024-11-14 10:14:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:57][root][INFO] - Training Epoch: 2/2, step 12698/16670 completed (loss: 0.05873666703701019, acc: 0.9773463010787964)
[2024-11-14 10:14:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:57][root][INFO] - Training Epoch: 2/2, step 12699/16670 completed (loss: 0.5321265459060669, acc: 0.885496199131012)
[2024-11-14 10:14:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:57][root][INFO] - Training Epoch: 2/2, step 12700/16670 completed (loss: 0.1174086183309555, acc: 0.9726027250289917)
[2024-11-14 10:14:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:58][root][INFO] - Training Epoch: 2/2, step 12701/16670 completed (loss: 0.1394040882587433, acc: 0.9568965435028076)
[2024-11-14 10:14:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:58][root][INFO] - Training Epoch: 2/2, step 12702/16670 completed (loss: 0.06781859695911407, acc: 0.9757281541824341)
[2024-11-14 10:14:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:58][root][INFO] - Training Epoch: 2/2, step 12703/16670 completed (loss: 0.14659301936626434, acc: 0.9529411792755127)
[2024-11-14 10:14:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:59][root][INFO] - Training Epoch: 2/2, step 12704/16670 completed (loss: 0.17965887486934662, acc: 0.9444444179534912)
[2024-11-14 10:14:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:59][root][INFO] - Training Epoch: 2/2, step 12705/16670 completed (loss: 0.17174740135669708, acc: 0.95652174949646)
[2024-11-14 10:14:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:59][root][INFO] - Training Epoch: 2/2, step 12706/16670 completed (loss: 0.12450053542852402, acc: 0.9277108311653137)
[2024-11-14 10:14:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:14:59][root][INFO] - Training Epoch: 2/2, step 12707/16670 completed (loss: 0.17043422162532806, acc: 0.9583333134651184)
[2024-11-14 10:15:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:00][root][INFO] - Training Epoch: 2/2, step 12708/16670 completed (loss: 0.07707809656858444, acc: 0.9730941653251648)
[2024-11-14 10:15:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:00][root][INFO] - Training Epoch: 2/2, step 12709/16670 completed (loss: 0.22021618485450745, acc: 0.9320755004882812)
[2024-11-14 10:15:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:00][root][INFO] - Training Epoch: 2/2, step 12710/16670 completed (loss: 0.12418825179338455, acc: 0.9552845358848572)
[2024-11-14 10:15:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:01][root][INFO] - Training Epoch: 2/2, step 12711/16670 completed (loss: 0.0856325700879097, acc: 0.9722222089767456)
[2024-11-14 10:15:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:01][root][INFO] - Training Epoch: 2/2, step 12712/16670 completed (loss: 0.17391172051429749, acc: 0.9679144620895386)
[2024-11-14 10:15:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:01][root][INFO] - Training Epoch: 2/2, step 12713/16670 completed (loss: 0.11790022253990173, acc: 0.9695122241973877)
[2024-11-14 10:15:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:02][root][INFO] - Training Epoch: 2/2, step 12714/16670 completed (loss: 0.22976747155189514, acc: 0.9549999833106995)
[2024-11-14 10:15:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:02][root][INFO] - Training Epoch: 2/2, step 12715/16670 completed (loss: 0.43975669145584106, acc: 0.9291338324546814)
[2024-11-14 10:15:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:02][root][INFO] - Training Epoch: 2/2, step 12716/16670 completed (loss: 0.13001573085784912, acc: 0.9652174115180969)
[2024-11-14 10:15:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:03][root][INFO] - Training Epoch: 2/2, step 12717/16670 completed (loss: 0.026573721319437027, acc: 1.0)
[2024-11-14 10:15:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:03][root][INFO] - Training Epoch: 2/2, step 12718/16670 completed (loss: 0.10315044969320297, acc: 0.9552238583564758)
[2024-11-14 10:15:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:03][root][INFO] - Training Epoch: 2/2, step 12719/16670 completed (loss: 0.08979445695877075, acc: 0.9679999947547913)
[2024-11-14 10:15:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:03][root][INFO] - Training Epoch: 2/2, step 12720/16670 completed (loss: 0.07728133350610733, acc: 0.9834024906158447)
[2024-11-14 10:15:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:04][root][INFO] - Training Epoch: 2/2, step 12721/16670 completed (loss: 0.10239394754171371, acc: 0.9663461446762085)
[2024-11-14 10:15:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:04][root][INFO] - Training Epoch: 2/2, step 12722/16670 completed (loss: 0.13188065588474274, acc: 0.9589040875434875)
[2024-11-14 10:15:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:04][root][INFO] - Training Epoch: 2/2, step 12723/16670 completed (loss: 0.23176506161689758, acc: 0.9325153231620789)
[2024-11-14 10:15:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:05][root][INFO] - Training Epoch: 2/2, step 12724/16670 completed (loss: 0.3243159353733063, acc: 0.9077490568161011)
[2024-11-14 10:15:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:05][root][INFO] - Training Epoch: 2/2, step 12725/16670 completed (loss: 0.17219728231430054, acc: 0.943231463432312)
[2024-11-14 10:15:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:05][root][INFO] - Training Epoch: 2/2, step 12726/16670 completed (loss: 0.1599799543619156, acc: 0.9599999785423279)
[2024-11-14 10:15:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:06][root][INFO] - Training Epoch: 2/2, step 12727/16670 completed (loss: 0.03886312246322632, acc: 0.9800000190734863)
[2024-11-14 10:15:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:06][root][INFO] - Training Epoch: 2/2, step 12728/16670 completed (loss: 0.16616924107074738, acc: 0.9382715821266174)
[2024-11-14 10:15:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:06][root][INFO] - Training Epoch: 2/2, step 12729/16670 completed (loss: 0.23428760468959808, acc: 0.9528796076774597)
[2024-11-14 10:15:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:06][root][INFO] - Training Epoch: 2/2, step 12730/16670 completed (loss: 0.060617852956056595, acc: 0.9949748516082764)
[2024-11-14 10:15:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:07][root][INFO] - Training Epoch: 2/2, step 12731/16670 completed (loss: 0.028080185875296593, acc: 0.9938271641731262)
[2024-11-14 10:15:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:07][root][INFO] - Training Epoch: 2/2, step 12732/16670 completed (loss: 0.18733324110507965, acc: 0.9481481313705444)
[2024-11-14 10:15:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:07][root][INFO] - Training Epoch: 2/2, step 12733/16670 completed (loss: 0.10749039053916931, acc: 0.969924807548523)
[2024-11-14 10:15:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:08][root][INFO] - Training Epoch: 2/2, step 12734/16670 completed (loss: 0.18078191578388214, acc: 0.9221556782722473)
[2024-11-14 10:15:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:08][root][INFO] - Training Epoch: 2/2, step 12735/16670 completed (loss: 0.12247532606124878, acc: 0.9660193920135498)
[2024-11-14 10:15:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:08][root][INFO] - Training Epoch: 2/2, step 12736/16670 completed (loss: 0.07244269549846649, acc: 0.9790794849395752)
[2024-11-14 10:15:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:09][root][INFO] - Training Epoch: 2/2, step 12737/16670 completed (loss: 0.15318964421749115, acc: 0.9513274431228638)
[2024-11-14 10:15:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:09][root][INFO] - Training Epoch: 2/2, step 12738/16670 completed (loss: 0.14017902314662933, acc: 0.9617224931716919)
[2024-11-14 10:15:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:09][root][INFO] - Training Epoch: 2/2, step 12739/16670 completed (loss: 0.15271690487861633, acc: 0.96484375)
[2024-11-14 10:15:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:10][root][INFO] - Training Epoch: 2/2, step 12740/16670 completed (loss: 0.13057845830917358, acc: 0.9629629850387573)
[2024-11-14 10:15:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:10][root][INFO] - Training Epoch: 2/2, step 12741/16670 completed (loss: 0.15376947820186615, acc: 0.9567307829856873)
[2024-11-14 10:15:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:10][root][INFO] - Training Epoch: 2/2, step 12742/16670 completed (loss: 0.09392387419939041, acc: 0.9685039520263672)
[2024-11-14 10:15:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:11][root][INFO] - Training Epoch: 2/2, step 12743/16670 completed (loss: 0.16539311408996582, acc: 0.9665427803993225)
[2024-11-14 10:15:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:11][root][INFO] - Training Epoch: 2/2, step 12744/16670 completed (loss: 0.049199800938367844, acc: 0.987730085849762)
[2024-11-14 10:15:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:11][root][INFO] - Training Epoch: 2/2, step 12745/16670 completed (loss: 0.04930662736296654, acc: 0.9866666793823242)
[2024-11-14 10:15:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:12][root][INFO] - Training Epoch: 2/2, step 12746/16670 completed (loss: 0.10411111265420914, acc: 0.9639639854431152)
[2024-11-14 10:15:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:12][root][INFO] - Training Epoch: 2/2, step 12747/16670 completed (loss: 0.10790625959634781, acc: 0.9512194991111755)
[2024-11-14 10:15:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:12][root][INFO] - Training Epoch: 2/2, step 12748/16670 completed (loss: 0.24996672570705414, acc: 0.8965517282485962)
[2024-11-14 10:15:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:13][root][INFO] - Training Epoch: 2/2, step 12749/16670 completed (loss: 0.11107399314641953, acc: 0.9768785834312439)
[2024-11-14 10:15:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:13][root][INFO] - Training Epoch: 2/2, step 12750/16670 completed (loss: 0.17644518613815308, acc: 0.9504132270812988)
[2024-11-14 10:15:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:13][root][INFO] - Training Epoch: 2/2, step 12751/16670 completed (loss: 0.14777015149593353, acc: 0.9623655676841736)
[2024-11-14 10:15:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:14][root][INFO] - Training Epoch: 2/2, step 12752/16670 completed (loss: 0.1419682651758194, acc: 0.9679999947547913)
[2024-11-14 10:15:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:14][root][INFO] - Training Epoch: 2/2, step 12753/16670 completed (loss: 0.12797240912914276, acc: 0.9599999785423279)
[2024-11-14 10:15:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:14][root][INFO] - Training Epoch: 2/2, step 12754/16670 completed (loss: 0.10992865264415741, acc: 0.9689119458198547)
[2024-11-14 10:15:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:15][root][INFO] - Training Epoch: 2/2, step 12755/16670 completed (loss: 0.19321823120117188, acc: 0.9550561904907227)
[2024-11-14 10:15:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:15][root][INFO] - Training Epoch: 2/2, step 12756/16670 completed (loss: 0.058529920876026154, acc: 0.985981285572052)
[2024-11-14 10:15:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:15][root][INFO] - Training Epoch: 2/2, step 12757/16670 completed (loss: 0.22077754139900208, acc: 0.9495798349380493)
[2024-11-14 10:15:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:16][root][INFO] - Training Epoch: 2/2, step 12758/16670 completed (loss: 0.11643979698419571, acc: 0.9742268323898315)
[2024-11-14 10:15:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:16][root][INFO] - Training Epoch: 2/2, step 12759/16670 completed (loss: 0.07112857699394226, acc: 0.9814814925193787)
[2024-11-14 10:15:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:16][root][INFO] - Training Epoch: 2/2, step 12760/16670 completed (loss: 0.10305515676736832, acc: 0.9714285731315613)
[2024-11-14 10:15:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:16][root][INFO] - Training Epoch: 2/2, step 12761/16670 completed (loss: 0.1362198293209076, acc: 0.9638554453849792)
[2024-11-14 10:15:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:17][root][INFO] - Training Epoch: 2/2, step 12762/16670 completed (loss: 0.12939518690109253, acc: 0.9492385983467102)
[2024-11-14 10:15:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:17][root][INFO] - Training Epoch: 2/2, step 12763/16670 completed (loss: 0.21175692975521088, acc: 0.9292035102844238)
[2024-11-14 10:15:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:17][root][INFO] - Training Epoch: 2/2, step 12764/16670 completed (loss: 0.07595867663621902, acc: 0.9907407164573669)
[2024-11-14 10:15:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:18][root][INFO] - Training Epoch: 2/2, step 12765/16670 completed (loss: 0.12422118335962296, acc: 0.969565212726593)
[2024-11-14 10:15:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:18][root][INFO] - Training Epoch: 2/2, step 12766/16670 completed (loss: 0.1526317298412323, acc: 0.9599999785423279)
[2024-11-14 10:15:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:18][root][INFO] - Training Epoch: 2/2, step 12767/16670 completed (loss: 0.0958351418375969, acc: 0.9803921580314636)
[2024-11-14 10:15:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:19][root][INFO] - Training Epoch: 2/2, step 12768/16670 completed (loss: 0.10438357293605804, acc: 0.9583333134651184)
[2024-11-14 10:15:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:19][root][INFO] - Training Epoch: 2/2, step 12769/16670 completed (loss: 0.14420482516288757, acc: 0.9661017060279846)
[2024-11-14 10:15:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:19][root][INFO] - Training Epoch: 2/2, step 12770/16670 completed (loss: 0.2390504628419876, acc: 0.9337016344070435)
[2024-11-14 10:15:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:20][root][INFO] - Training Epoch: 2/2, step 12771/16670 completed (loss: 0.08058192580938339, acc: 0.9696969985961914)
[2024-11-14 10:15:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:20][root][INFO] - Training Epoch: 2/2, step 12772/16670 completed (loss: 0.2129536122083664, acc: 0.918367326259613)
[2024-11-14 10:15:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:20][root][INFO] - Training Epoch: 2/2, step 12773/16670 completed (loss: 0.1054835319519043, acc: 0.9715909361839294)
[2024-11-14 10:15:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:21][root][INFO] - Training Epoch: 2/2, step 12774/16670 completed (loss: 0.1302933692932129, acc: 0.9631336331367493)
[2024-11-14 10:15:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:21][root][INFO] - Training Epoch: 2/2, step 12775/16670 completed (loss: 0.1116160899400711, acc: 0.9773755669593811)
[2024-11-14 10:15:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:21][root][INFO] - Training Epoch: 2/2, step 12776/16670 completed (loss: 0.147161066532135, acc: 0.9519230723381042)
[2024-11-14 10:15:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:22][root][INFO] - Training Epoch: 2/2, step 12777/16670 completed (loss: 0.10751990228891373, acc: 0.9506173133850098)
[2024-11-14 10:15:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:22][root][INFO] - Training Epoch: 2/2, step 12778/16670 completed (loss: 0.23823179304599762, acc: 0.9418604373931885)
[2024-11-14 10:15:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:23][root][INFO] - Training Epoch: 2/2, step 12779/16670 completed (loss: 0.06859376281499863, acc: 0.9770992398262024)
[2024-11-14 10:15:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:23][root][INFO] - Training Epoch: 2/2, step 12780/16670 completed (loss: 0.19101063907146454, acc: 0.9514563083648682)
[2024-11-14 10:15:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:23][root][INFO] - Training Epoch: 2/2, step 12781/16670 completed (loss: 0.2358582764863968, acc: 0.9411764740943909)
[2024-11-14 10:15:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:24][root][INFO] - Training Epoch: 2/2, step 12782/16670 completed (loss: 0.17199666798114777, acc: 0.9585798978805542)
[2024-11-14 10:15:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:24][root][INFO] - Training Epoch: 2/2, step 12783/16670 completed (loss: 0.15256191790103912, acc: 0.9572192430496216)
[2024-11-14 10:15:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:24][root][INFO] - Training Epoch: 2/2, step 12784/16670 completed (loss: 0.12672190368175507, acc: 0.9731543660163879)
[2024-11-14 10:15:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:25][root][INFO] - Training Epoch: 2/2, step 12785/16670 completed (loss: 0.1040855273604393, acc: 0.9788359999656677)
[2024-11-14 10:15:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:25][root][INFO] - Training Epoch: 2/2, step 12786/16670 completed (loss: 0.12322268635034561, acc: 0.9611307382583618)
[2024-11-14 10:15:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:25][root][INFO] - Training Epoch: 2/2, step 12787/16670 completed (loss: 0.3860403299331665, acc: 0.9090909361839294)
[2024-11-14 10:15:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:26][root][INFO] - Training Epoch: 2/2, step 12788/16670 completed (loss: 0.3156219720840454, acc: 0.915730357170105)
[2024-11-14 10:15:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:26][root][INFO] - Training Epoch: 2/2, step 12789/16670 completed (loss: 0.2179814577102661, acc: 0.9239130616188049)
[2024-11-14 10:15:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:26][root][INFO] - Training Epoch: 2/2, step 12790/16670 completed (loss: 0.12520650029182434, acc: 0.9441624283790588)
[2024-11-14 10:15:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:27][root][INFO] - Training Epoch: 2/2, step 12791/16670 completed (loss: 0.25773221254348755, acc: 0.9327354431152344)
[2024-11-14 10:15:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:27][root][INFO] - Training Epoch: 2/2, step 12792/16670 completed (loss: 0.1962849348783493, acc: 0.932692289352417)
[2024-11-14 10:15:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:28][root][INFO] - Training Epoch: 2/2, step 12793/16670 completed (loss: 0.33262762427330017, acc: 0.9153845906257629)
[2024-11-14 10:15:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:28][root][INFO] - Training Epoch: 2/2, step 12794/16670 completed (loss: 0.25303998589515686, acc: 0.9436619877815247)
[2024-11-14 10:15:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:28][root][INFO] - Training Epoch: 2/2, step 12795/16670 completed (loss: 0.13630633056163788, acc: 0.9581395387649536)
[2024-11-14 10:15:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:29][root][INFO] - Training Epoch: 2/2, step 12796/16670 completed (loss: 0.33392634987831116, acc: 0.9014598727226257)
[2024-11-14 10:15:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:29][root][INFO] - Training Epoch: 2/2, step 12797/16670 completed (loss: 0.21767951548099518, acc: 0.9256198406219482)
[2024-11-14 10:15:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:29][root][INFO] - Training Epoch: 2/2, step 12798/16670 completed (loss: 0.11929444223642349, acc: 0.9555555582046509)
[2024-11-14 10:15:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:30][root][INFO] - Training Epoch: 2/2, step 12799/16670 completed (loss: 0.3365282714366913, acc: 0.9207921028137207)
[2024-11-14 10:15:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:30][root][INFO] - Training Epoch: 2/2, step 12800/16670 completed (loss: 0.18525028228759766, acc: 0.9586206674575806)
[2024-11-14 10:15:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:30][root][INFO] - Training Epoch: 2/2, step 12801/16670 completed (loss: 0.30627474188804626, acc: 0.8983050584793091)
[2024-11-14 10:15:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:31][root][INFO] - Training Epoch: 2/2, step 12802/16670 completed (loss: 0.34975531697273254, acc: 0.9147982001304626)
[2024-11-14 10:15:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:31][root][INFO] - Training Epoch: 2/2, step 12803/16670 completed (loss: 0.03924821689724922, acc: 1.0)
[2024-11-14 10:15:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:31][root][INFO] - Training Epoch: 2/2, step 12804/16670 completed (loss: 0.22453145682811737, acc: 0.9515151381492615)
[2024-11-14 10:15:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:32][root][INFO] - Training Epoch: 2/2, step 12805/16670 completed (loss: 0.2899884581565857, acc: 0.9303797483444214)
[2024-11-14 10:15:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:32][root][INFO] - Training Epoch: 2/2, step 12806/16670 completed (loss: 0.16556181013584137, acc: 0.9542483687400818)
[2024-11-14 10:15:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:32][root][INFO] - Training Epoch: 2/2, step 12807/16670 completed (loss: 0.28250712156295776, acc: 0.9252336621284485)
[2024-11-14 10:15:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:33][root][INFO] - Training Epoch: 2/2, step 12808/16670 completed (loss: 0.12321943044662476, acc: 0.9551724195480347)
[2024-11-14 10:15:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:33][root][INFO] - Training Epoch: 2/2, step 12809/16670 completed (loss: 0.14369134604930878, acc: 0.9661654233932495)
[2024-11-14 10:15:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:34][root][INFO] - Training Epoch: 2/2, step 12810/16670 completed (loss: 0.09924008697271347, acc: 0.97826087474823)
[2024-11-14 10:15:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:34][root][INFO] - Training Epoch: 2/2, step 12811/16670 completed (loss: 0.17517995834350586, acc: 0.9488189220428467)
[2024-11-14 10:15:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:34][root][INFO] - Training Epoch: 2/2, step 12812/16670 completed (loss: 0.2266182005405426, acc: 0.9424778819084167)
[2024-11-14 10:15:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:35][root][INFO] - Training Epoch: 2/2, step 12813/16670 completed (loss: 0.40289562940597534, acc: 0.8943662047386169)
[2024-11-14 10:15:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:35][root][INFO] - Training Epoch: 2/2, step 12814/16670 completed (loss: 0.24251703917980194, acc: 0.9397590160369873)
[2024-11-14 10:15:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:35][root][INFO] - Training Epoch: 2/2, step 12815/16670 completed (loss: 0.32539102435112, acc: 0.9285714030265808)
[2024-11-14 10:15:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:36][root][INFO] - Training Epoch: 2/2, step 12816/16670 completed (loss: 0.0777483731508255, acc: 0.970588207244873)
[2024-11-14 10:15:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:36][root][INFO] - Training Epoch: 2/2, step 12817/16670 completed (loss: 0.23633065819740295, acc: 0.9329608678817749)
[2024-11-14 10:15:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:36][root][INFO] - Training Epoch: 2/2, step 12818/16670 completed (loss: 0.11615301668643951, acc: 0.9607843160629272)
[2024-11-14 10:15:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:37][root][INFO] - Training Epoch: 2/2, step 12819/16670 completed (loss: 0.13703811168670654, acc: 0.9525862336158752)
[2024-11-14 10:15:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:37][root][INFO] - Training Epoch: 2/2, step 12820/16670 completed (loss: 0.24435314536094666, acc: 0.93388432264328)
[2024-11-14 10:15:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:37][root][INFO] - Training Epoch: 2/2, step 12821/16670 completed (loss: 0.22310292720794678, acc: 0.9405204653739929)
[2024-11-14 10:15:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:38][root][INFO] - Training Epoch: 2/2, step 12822/16670 completed (loss: 0.34062597155570984, acc: 0.9160305261611938)
[2024-11-14 10:15:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:38][root][INFO] - Training Epoch: 2/2, step 12823/16670 completed (loss: 0.3267357647418976, acc: 0.9375)
[2024-11-14 10:15:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:38][root][INFO] - Training Epoch: 2/2, step 12824/16670 completed (loss: 0.15221692621707916, acc: 0.9545454382896423)
[2024-11-14 10:15:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:39][root][INFO] - Training Epoch: 2/2, step 12825/16670 completed (loss: 0.33985278010368347, acc: 0.9144384860992432)
[2024-11-14 10:15:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:39][root][INFO] - Training Epoch: 2/2, step 12826/16670 completed (loss: 0.23858340084552765, acc: 0.9399999976158142)
[2024-11-14 10:15:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:39][root][INFO] - Training Epoch: 2/2, step 12827/16670 completed (loss: 0.2589505910873413, acc: 0.9240506291389465)
[2024-11-14 10:15:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:40][root][INFO] - Training Epoch: 2/2, step 12828/16670 completed (loss: 0.24780982732772827, acc: 0.9166666865348816)
[2024-11-14 10:15:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:40][root][INFO] - Training Epoch: 2/2, step 12829/16670 completed (loss: 0.2774212956428528, acc: 0.9345454573631287)
[2024-11-14 10:15:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:41][root][INFO] - Training Epoch: 2/2, step 12830/16670 completed (loss: 0.11245494335889816, acc: 0.9722222089767456)
[2024-11-14 10:15:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:41][root][INFO] - Training Epoch: 2/2, step 12831/16670 completed (loss: 0.17586369812488556, acc: 0.9632353186607361)
[2024-11-14 10:15:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:41][root][INFO] - Training Epoch: 2/2, step 12832/16670 completed (loss: 0.10631341487169266, acc: 0.9657142758369446)
[2024-11-14 10:15:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:42][root][INFO] - Training Epoch: 2/2, step 12833/16670 completed (loss: 0.15188650786876678, acc: 0.9543147087097168)
[2024-11-14 10:15:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:42][root][INFO] - Training Epoch: 2/2, step 12834/16670 completed (loss: 0.22973237931728363, acc: 0.9174311757087708)
[2024-11-14 10:15:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:42][root][INFO] - Training Epoch: 2/2, step 12835/16670 completed (loss: 0.2037597894668579, acc: 0.938697338104248)
[2024-11-14 10:15:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:43][root][INFO] - Training Epoch: 2/2, step 12836/16670 completed (loss: 0.21139107644557953, acc: 0.9339622855186462)
[2024-11-14 10:15:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:43][root][INFO] - Training Epoch: 2/2, step 12837/16670 completed (loss: 0.2246255874633789, acc: 0.9473684430122375)
[2024-11-14 10:15:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:43][root][INFO] - Training Epoch: 2/2, step 12838/16670 completed (loss: 0.11089836806058884, acc: 0.969565212726593)
[2024-11-14 10:15:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:44][root][INFO] - Training Epoch: 2/2, step 12839/16670 completed (loss: 0.1340494006872177, acc: 0.9640718698501587)
[2024-11-14 10:15:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:44][root][INFO] - Training Epoch: 2/2, step 12840/16670 completed (loss: 0.22482214868068695, acc: 0.9427083134651184)
[2024-11-14 10:15:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:45][root][INFO] - Training Epoch: 2/2, step 12841/16670 completed (loss: 0.20100972056388855, acc: 0.937269389629364)
[2024-11-14 10:15:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:45][root][INFO] - Training Epoch: 2/2, step 12842/16670 completed (loss: 0.2450268268585205, acc: 0.935153603553772)
[2024-11-14 10:15:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:45][root][INFO] - Training Epoch: 2/2, step 12843/16670 completed (loss: 0.1057036817073822, acc: 0.9679999947547913)
[2024-11-14 10:15:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:46][root][INFO] - Training Epoch: 2/2, step 12844/16670 completed (loss: 0.34247857332229614, acc: 0.8844221234321594)
[2024-11-14 10:15:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:46][root][INFO] - Training Epoch: 2/2, step 12845/16670 completed (loss: 0.1561393439769745, acc: 0.9436619877815247)
[2024-11-14 10:15:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:46][root][INFO] - Training Epoch: 2/2, step 12846/16670 completed (loss: 0.11326391994953156, acc: 0.9675324559211731)
[2024-11-14 10:15:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:47][root][INFO] - Training Epoch: 2/2, step 12847/16670 completed (loss: 0.2226778268814087, acc: 0.9285714030265808)
[2024-11-14 10:15:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:47][root][INFO] - Training Epoch: 2/2, step 12848/16670 completed (loss: 0.38379228115081787, acc: 0.8803681135177612)
[2024-11-14 10:15:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:48][root][INFO] - Training Epoch: 2/2, step 12849/16670 completed (loss: 0.03254098817706108, acc: 0.9800000190734863)
[2024-11-14 10:15:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:48][root][INFO] - Training Epoch: 2/2, step 12850/16670 completed (loss: 0.1911037266254425, acc: 0.9539170265197754)
[2024-11-14 10:15:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:48][root][INFO] - Training Epoch: 2/2, step 12851/16670 completed (loss: 0.21905992925167084, acc: 0.9343283772468567)
[2024-11-14 10:15:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:49][root][INFO] - Training Epoch: 2/2, step 12852/16670 completed (loss: 0.1472521424293518, acc: 0.9674796462059021)
[2024-11-14 10:15:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:49][root][INFO] - Training Epoch: 2/2, step 12853/16670 completed (loss: 0.2007044553756714, acc: 0.9672130942344666)
[2024-11-14 10:15:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:49][root][INFO] - Training Epoch: 2/2, step 12854/16670 completed (loss: 0.16082791984081268, acc: 0.95652174949646)
[2024-11-14 10:15:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:50][root][INFO] - Training Epoch: 2/2, step 12855/16670 completed (loss: 0.12603797018527985, acc: 0.9728506803512573)
[2024-11-14 10:15:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:50][root][INFO] - Training Epoch: 2/2, step 12856/16670 completed (loss: 0.13074049353599548, acc: 0.9700854420661926)
[2024-11-14 10:15:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:50][root][INFO] - Training Epoch: 2/2, step 12857/16670 completed (loss: 0.24227216839790344, acc: 0.9523809552192688)
[2024-11-14 10:15:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:51][root][INFO] - Training Epoch: 2/2, step 12858/16670 completed (loss: 0.1450033187866211, acc: 0.9399999976158142)
[2024-11-14 10:15:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:51][root][INFO] - Training Epoch: 2/2, step 12859/16670 completed (loss: 0.09869325906038284, acc: 0.9793814420700073)
[2024-11-14 10:15:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:51][root][INFO] - Training Epoch: 2/2, step 12860/16670 completed (loss: 0.278790682554245, acc: 0.9056603908538818)
[2024-11-14 10:15:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:52][root][INFO] - Training Epoch: 2/2, step 12861/16670 completed (loss: 0.1564595252275467, acc: 0.9508196711540222)
[2024-11-14 10:15:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:52][root][INFO] - Training Epoch: 2/2, step 12862/16670 completed (loss: 0.2189929336309433, acc: 0.9322034120559692)
[2024-11-14 10:15:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:52][root][INFO] - Training Epoch: 2/2, step 12863/16670 completed (loss: 0.08524828404188156, acc: 0.9867109656333923)
[2024-11-14 10:15:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:53][root][INFO] - Training Epoch: 2/2, step 12864/16670 completed (loss: 0.18328920006752014, acc: 0.9431437849998474)
[2024-11-14 10:15:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:53][root][INFO] - Training Epoch: 2/2, step 12865/16670 completed (loss: 0.13867944478988647, acc: 0.9577465057373047)
[2024-11-14 10:15:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:53][root][INFO] - Training Epoch: 2/2, step 12866/16670 completed (loss: 0.32666927576065063, acc: 0.9245283007621765)
[2024-11-14 10:15:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:54][root][INFO] - Training Epoch: 2/2, step 12867/16670 completed (loss: 0.25750938057899475, acc: 0.9328358173370361)
[2024-11-14 10:15:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:54][root][INFO] - Training Epoch: 2/2, step 12868/16670 completed (loss: 0.39540523290634155, acc: 0.9137930870056152)
[2024-11-14 10:15:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:54][root][INFO] - Training Epoch: 2/2, step 12869/16670 completed (loss: 0.3842523694038391, acc: 0.893401026725769)
[2024-11-14 10:15:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:55][root][INFO] - Training Epoch: 2/2, step 12870/16670 completed (loss: 0.15736612677574158, acc: 0.9508196711540222)
[2024-11-14 10:15:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:55][root][INFO] - Training Epoch: 2/2, step 12871/16670 completed (loss: 0.29906588792800903, acc: 0.9194139242172241)
[2024-11-14 10:15:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:55][root][INFO] - Training Epoch: 2/2, step 12872/16670 completed (loss: 0.15090231597423553, acc: 0.9607843160629272)
[2024-11-14 10:15:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:56][root][INFO] - Training Epoch: 2/2, step 12873/16670 completed (loss: 0.31263235211372375, acc: 0.9025641083717346)
[2024-11-14 10:15:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:56][root][INFO] - Training Epoch: 2/2, step 12874/16670 completed (loss: 0.22426414489746094, acc: 0.929961085319519)
[2024-11-14 10:15:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:57][root][INFO] - Training Epoch: 2/2, step 12875/16670 completed (loss: 0.302106112241745, acc: 0.9432623982429504)
[2024-11-14 10:15:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:57][root][INFO] - Training Epoch: 2/2, step 12876/16670 completed (loss: 0.24631579220294952, acc: 0.9142857193946838)
[2024-11-14 10:15:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:57][root][INFO] - Training Epoch: 2/2, step 12877/16670 completed (loss: 0.33599424362182617, acc: 0.9240506291389465)
[2024-11-14 10:15:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:58][root][INFO] - Training Epoch: 2/2, step 12878/16670 completed (loss: 0.16810409724712372, acc: 0.9615384340286255)
[2024-11-14 10:15:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:58][root][INFO] - Training Epoch: 2/2, step 12879/16670 completed (loss: 0.1406179517507553, acc: 0.939393937587738)
[2024-11-14 10:15:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:58][root][INFO] - Training Epoch: 2/2, step 12880/16670 completed (loss: 0.17329944670200348, acc: 0.9577465057373047)
[2024-11-14 10:15:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:59][root][INFO] - Training Epoch: 2/2, step 12881/16670 completed (loss: 0.20008927583694458, acc: 0.9451219439506531)
[2024-11-14 10:15:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:15:59][root][INFO] - Training Epoch: 2/2, step 12882/16670 completed (loss: 0.21532317996025085, acc: 0.9432989954948425)
[2024-11-14 10:15:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:00][root][INFO] - Training Epoch: 2/2, step 12883/16670 completed (loss: 0.33985501527786255, acc: 0.8915094137191772)
[2024-11-14 10:16:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:00][root][INFO] - Training Epoch: 2/2, step 12884/16670 completed (loss: 0.5012747049331665, acc: 0.8500000238418579)
[2024-11-14 10:16:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:00][root][INFO] - Training Epoch: 2/2, step 12885/16670 completed (loss: 0.40439900755882263, acc: 0.8932584524154663)
[2024-11-14 10:16:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:01][root][INFO] - Training Epoch: 2/2, step 12886/16670 completed (loss: 0.12204734236001968, acc: 0.9759036302566528)
[2024-11-14 10:16:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:01][root][INFO] - Training Epoch: 2/2, step 12887/16670 completed (loss: 0.21662941575050354, acc: 0.9426751732826233)
[2024-11-14 10:16:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:01][root][INFO] - Training Epoch: 2/2, step 12888/16670 completed (loss: 0.27717944979667664, acc: 0.9294871687889099)
[2024-11-14 10:16:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:02][root][INFO] - Training Epoch: 2/2, step 12889/16670 completed (loss: 0.1974400281906128, acc: 0.9504132270812988)
[2024-11-14 10:16:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:02][root][INFO] - Training Epoch: 2/2, step 12890/16670 completed (loss: 0.09629102796316147, acc: 0.9783393740653992)
[2024-11-14 10:16:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:02][root][INFO] - Training Epoch: 2/2, step 12891/16670 completed (loss: 0.12288197875022888, acc: 0.9661017060279846)
[2024-11-14 10:16:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:03][root][INFO] - Training Epoch: 2/2, step 12892/16670 completed (loss: 0.11895984411239624, acc: 0.9554455280303955)
[2024-11-14 10:16:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:03][root][INFO] - Training Epoch: 2/2, step 12893/16670 completed (loss: 0.17973871529102325, acc: 0.9407894611358643)
[2024-11-14 10:16:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:03][root][INFO] - Training Epoch: 2/2, step 12894/16670 completed (loss: 0.3947625756263733, acc: 0.8928571343421936)
[2024-11-14 10:16:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:04][root][INFO] - Training Epoch: 2/2, step 12895/16670 completed (loss: 0.25740301609039307, acc: 0.9387755393981934)
[2024-11-14 10:16:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:04][root][INFO] - Training Epoch: 2/2, step 12896/16670 completed (loss: 0.16254101693630219, acc: 0.9644268751144409)
[2024-11-14 10:16:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:04][root][INFO] - Training Epoch: 2/2, step 12897/16670 completed (loss: 0.21797646582126617, acc: 0.9484536051750183)
[2024-11-14 10:16:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:05][root][INFO] - Training Epoch: 2/2, step 12898/16670 completed (loss: 0.3065590262413025, acc: 0.9241706132888794)
[2024-11-14 10:16:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:05][root][INFO] - Training Epoch: 2/2, step 12899/16670 completed (loss: 0.1293264478445053, acc: 0.9706840515136719)
[2024-11-14 10:16:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:06][root][INFO] - Training Epoch: 2/2, step 12900/16670 completed (loss: 0.2484143078327179, acc: 0.939226508140564)
[2024-11-14 10:16:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:06][root][INFO] - Training Epoch: 2/2, step 12901/16670 completed (loss: 0.1323910504579544, acc: 0.9503546357154846)
[2024-11-14 10:16:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:06][root][INFO] - Training Epoch: 2/2, step 12902/16670 completed (loss: 0.22411629557609558, acc: 0.936170220375061)
[2024-11-14 10:16:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:07][root][INFO] - Training Epoch: 2/2, step 12903/16670 completed (loss: 0.31134912371635437, acc: 0.9267241358757019)
[2024-11-14 10:16:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:07][root][INFO] - Training Epoch: 2/2, step 12904/16670 completed (loss: 0.42330843210220337, acc: 0.8771929740905762)
[2024-11-14 10:16:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:07][root][INFO] - Training Epoch: 2/2, step 12905/16670 completed (loss: 0.2344065010547638, acc: 0.9268292784690857)
[2024-11-14 10:16:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:08][root][INFO] - Training Epoch: 2/2, step 12906/16670 completed (loss: 0.09878204762935638, acc: 0.9714285731315613)
[2024-11-14 10:16:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:08][root][INFO] - Training Epoch: 2/2, step 12907/16670 completed (loss: 0.3391633629798889, acc: 0.874015748500824)
[2024-11-14 10:16:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:08][root][INFO] - Training Epoch: 2/2, step 12908/16670 completed (loss: 0.10808605700731277, acc: 0.9728915691375732)
[2024-11-14 10:16:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:09][root][INFO] - Training Epoch: 2/2, step 12909/16670 completed (loss: 0.1621127724647522, acc: 0.940559446811676)
[2024-11-14 10:16:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:09][root][INFO] - Training Epoch: 2/2, step 12910/16670 completed (loss: 0.14684732258319855, acc: 0.9677419066429138)
[2024-11-14 10:16:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:09][root][INFO] - Training Epoch: 2/2, step 12911/16670 completed (loss: 0.29571646451950073, acc: 0.8974359035491943)
[2024-11-14 10:16:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:10][root][INFO] - Training Epoch: 2/2, step 12912/16670 completed (loss: 0.2120906114578247, acc: 0.8958333134651184)
[2024-11-14 10:16:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:10][root][INFO] - Training Epoch: 2/2, step 12913/16670 completed (loss: 0.15349243581295013, acc: 0.9537572264671326)
[2024-11-14 10:16:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:10][root][INFO] - Training Epoch: 2/2, step 12914/16670 completed (loss: 0.06707997620105743, acc: 0.9790576100349426)
[2024-11-14 10:16:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:11][root][INFO] - Training Epoch: 2/2, step 12915/16670 completed (loss: 0.15414880216121674, acc: 0.9685314893722534)
[2024-11-14 10:16:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:11][root][INFO] - Training Epoch: 2/2, step 12916/16670 completed (loss: 0.32843199372291565, acc: 0.9342560768127441)
[2024-11-14 10:16:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:11][root][INFO] - Training Epoch: 2/2, step 12917/16670 completed (loss: 0.2033844143152237, acc: 0.9418604373931885)
[2024-11-14 10:16:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:12][root][INFO] - Training Epoch: 2/2, step 12918/16670 completed (loss: 0.4876461625099182, acc: 0.8648648858070374)
[2024-11-14 10:16:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:12][root][INFO] - Training Epoch: 2/2, step 12919/16670 completed (loss: 0.34180566668510437, acc: 0.9159663915634155)
[2024-11-14 10:16:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:13][root][INFO] - Training Epoch: 2/2, step 12920/16670 completed (loss: 0.1498527228832245, acc: 0.9437229633331299)
[2024-11-14 10:16:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:13][root][INFO] - Training Epoch: 2/2, step 12921/16670 completed (loss: 0.6045307517051697, acc: 0.8429751992225647)
[2024-11-14 10:16:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:13][root][INFO] - Training Epoch: 2/2, step 12922/16670 completed (loss: 0.13959847390651703, acc: 0.9583333134651184)
[2024-11-14 10:16:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:14][root][INFO] - Training Epoch: 2/2, step 12923/16670 completed (loss: 0.35178256034851074, acc: 0.9377593398094177)
[2024-11-14 10:16:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:14][root][INFO] - Training Epoch: 2/2, step 12924/16670 completed (loss: 0.16117237508296967, acc: 0.9561403393745422)
[2024-11-14 10:16:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:14][root][INFO] - Training Epoch: 2/2, step 12925/16670 completed (loss: 0.13058261573314667, acc: 0.9668246507644653)
[2024-11-14 10:16:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:15][root][INFO] - Training Epoch: 2/2, step 12926/16670 completed (loss: 0.1357179433107376, acc: 0.9609755873680115)
[2024-11-14 10:16:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:15][root][INFO] - Training Epoch: 2/2, step 12927/16670 completed (loss: 0.1522754728794098, acc: 0.9551020264625549)
[2024-11-14 10:16:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:15][root][INFO] - Training Epoch: 2/2, step 12928/16670 completed (loss: 0.33876749873161316, acc: 0.9090909361839294)
[2024-11-14 10:16:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:16][root][INFO] - Training Epoch: 2/2, step 12929/16670 completed (loss: 0.3937233090400696, acc: 0.9375)
[2024-11-14 10:16:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:16][root][INFO] - Training Epoch: 2/2, step 12930/16670 completed (loss: 0.14259788393974304, acc: 0.9555555582046509)
[2024-11-14 10:16:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:16][root][INFO] - Training Epoch: 2/2, step 12931/16670 completed (loss: 0.09672634303569794, acc: 0.969298243522644)
[2024-11-14 10:16:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:17][root][INFO] - Training Epoch: 2/2, step 12932/16670 completed (loss: 0.3239589035511017, acc: 0.9189189076423645)
[2024-11-14 10:16:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:17][root][INFO] - Training Epoch: 2/2, step 12933/16670 completed (loss: 0.2723952829837799, acc: 0.9252336621284485)
[2024-11-14 10:16:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:18][root][INFO] - Training Epoch: 2/2, step 12934/16670 completed (loss: 0.18539024889469147, acc: 0.9518072009086609)
[2024-11-14 10:16:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:18][root][INFO] - Training Epoch: 2/2, step 12935/16670 completed (loss: 0.1409606784582138, acc: 0.9646464586257935)
[2024-11-14 10:16:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:18][root][INFO] - Training Epoch: 2/2, step 12936/16670 completed (loss: 0.22973355650901794, acc: 0.9230769276618958)
[2024-11-14 10:16:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:19][root][INFO] - Training Epoch: 2/2, step 12937/16670 completed (loss: 0.2624971270561218, acc: 0.9333333373069763)
[2024-11-14 10:16:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:19][root][INFO] - Training Epoch: 2/2, step 12938/16670 completed (loss: 0.219236359000206, acc: 0.9185185432434082)
[2024-11-14 10:16:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:19][root][INFO] - Training Epoch: 2/2, step 12939/16670 completed (loss: 0.2492104470729828, acc: 0.9523809552192688)
[2024-11-14 10:16:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:20][root][INFO] - Training Epoch: 2/2, step 12940/16670 completed (loss: 0.14286582171916962, acc: 0.9593750238418579)
[2024-11-14 10:16:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:20][root][INFO] - Training Epoch: 2/2, step 12941/16670 completed (loss: 0.21861632168293, acc: 0.9388489127159119)
[2024-11-14 10:16:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:20][root][INFO] - Training Epoch: 2/2, step 12942/16670 completed (loss: 0.277000367641449, acc: 0.9142857193946838)
[2024-11-14 10:16:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:21][root][INFO] - Training Epoch: 2/2, step 12943/16670 completed (loss: 0.27035731077194214, acc: 0.9224137663841248)
[2024-11-14 10:16:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:21][root][INFO] - Training Epoch: 2/2, step 12944/16670 completed (loss: 0.17145195603370667, acc: 0.9484536051750183)
[2024-11-14 10:16:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:21][root][INFO] - Training Epoch: 2/2, step 12945/16670 completed (loss: 0.13302826881408691, acc: 0.9724137783050537)
[2024-11-14 10:16:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:22][root][INFO] - Training Epoch: 2/2, step 12946/16670 completed (loss: 0.47959816455841064, acc: 0.8702290058135986)
[2024-11-14 10:16:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:22][root][INFO] - Training Epoch: 2/2, step 12947/16670 completed (loss: 0.3132166266441345, acc: 0.9224137663841248)
[2024-11-14 10:16:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:23][root][INFO] - Training Epoch: 2/2, step 12948/16670 completed (loss: 0.20750832557678223, acc: 0.9372549057006836)
[2024-11-14 10:16:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:23][root][INFO] - Training Epoch: 2/2, step 12949/16670 completed (loss: 0.06992954015731812, acc: 0.9757575988769531)
[2024-11-14 10:16:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:23][root][INFO] - Training Epoch: 2/2, step 12950/16670 completed (loss: 0.16782033443450928, acc: 0.9528023600578308)
[2024-11-14 10:16:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:24][root][INFO] - Training Epoch: 2/2, step 12951/16670 completed (loss: 0.38081490993499756, acc: 0.9013158082962036)
[2024-11-14 10:16:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:24][root][INFO] - Training Epoch: 2/2, step 12952/16670 completed (loss: 0.160215362906456, acc: 0.9545454382896423)
[2024-11-14 10:16:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:24][root][INFO] - Training Epoch: 2/2, step 12953/16670 completed (loss: 0.1559647172689438, acc: 0.9563106894493103)
[2024-11-14 10:16:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:25][root][INFO] - Training Epoch: 2/2, step 12954/16670 completed (loss: 0.15540646016597748, acc: 0.9629629850387573)
[2024-11-14 10:16:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:25][root][INFO] - Training Epoch: 2/2, step 12955/16670 completed (loss: 0.24486508965492249, acc: 0.9426523447036743)
[2024-11-14 10:16:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:26][root][INFO] - Training Epoch: 2/2, step 12956/16670 completed (loss: 0.20814375579357147, acc: 0.9420849680900574)
[2024-11-14 10:16:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:26][root][INFO] - Training Epoch: 2/2, step 12957/16670 completed (loss: 0.14518128335475922, acc: 0.9534883499145508)
[2024-11-14 10:16:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:26][root][INFO] - Training Epoch: 2/2, step 12958/16670 completed (loss: 0.19372625648975372, acc: 0.9488636255264282)
[2024-11-14 10:16:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:27][root][INFO] - Training Epoch: 2/2, step 12959/16670 completed (loss: 0.18811661005020142, acc: 0.9464883208274841)
[2024-11-14 10:16:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:27][root][INFO] - Training Epoch: 2/2, step 12960/16670 completed (loss: 0.29276326298713684, acc: 0.9207547307014465)
[2024-11-14 10:16:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:27][root][INFO] - Training Epoch: 2/2, step 12961/16670 completed (loss: 0.1577303558588028, acc: 0.9701492786407471)
[2024-11-14 10:16:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:27][root][INFO] - Training Epoch: 2/2, step 12962/16670 completed (loss: 0.10702327638864517, acc: 0.984375)
[2024-11-14 10:16:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:28][root][INFO] - Training Epoch: 2/2, step 12963/16670 completed (loss: 0.38434499502182007, acc: 0.8901734352111816)
[2024-11-14 10:16:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:28][root][INFO] - Training Epoch: 2/2, step 12964/16670 completed (loss: 0.17201976478099823, acc: 0.9536423683166504)
[2024-11-14 10:16:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:29][root][INFO] - Training Epoch: 2/2, step 12965/16670 completed (loss: 0.14951013028621674, acc: 0.9580152630805969)
[2024-11-14 10:16:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:29][root][INFO] - Training Epoch: 2/2, step 12966/16670 completed (loss: 0.1475144624710083, acc: 0.9465240836143494)
[2024-11-14 10:16:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:29][root][INFO] - Training Epoch: 2/2, step 12967/16670 completed (loss: 0.28774914145469666, acc: 0.8967136144638062)
[2024-11-14 10:16:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:30][root][INFO] - Training Epoch: 2/2, step 12968/16670 completed (loss: 0.21962332725524902, acc: 0.9296296238899231)
[2024-11-14 10:16:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:30][root][INFO] - Training Epoch: 2/2, step 12969/16670 completed (loss: 0.23715758323669434, acc: 0.9424460530281067)
[2024-11-14 10:16:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:30][root][INFO] - Training Epoch: 2/2, step 12970/16670 completed (loss: 0.19489404559135437, acc: 0.9424778819084167)
[2024-11-14 10:16:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:31][root][INFO] - Training Epoch: 2/2, step 12971/16670 completed (loss: 0.299724280834198, acc: 0.9246231317520142)
[2024-11-14 10:16:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:31][root][INFO] - Training Epoch: 2/2, step 12972/16670 completed (loss: 0.14061956107616425, acc: 0.9460784196853638)
[2024-11-14 10:16:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:31][root][INFO] - Training Epoch: 2/2, step 12973/16670 completed (loss: 0.3653002381324768, acc: 0.912162184715271)
[2024-11-14 10:16:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:32][root][INFO] - Training Epoch: 2/2, step 12974/16670 completed (loss: 0.2850300669670105, acc: 0.9330143332481384)
[2024-11-14 10:16:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:32][root][INFO] - Training Epoch: 2/2, step 12975/16670 completed (loss: 0.22666949033737183, acc: 0.9457831382751465)
[2024-11-14 10:16:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:32][root][INFO] - Training Epoch: 2/2, step 12976/16670 completed (loss: 0.18536655604839325, acc: 0.9449999928474426)
[2024-11-14 10:16:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:33][root][INFO] - Training Epoch: 2/2, step 12977/16670 completed (loss: 0.16563920676708221, acc: 0.9604519605636597)
[2024-11-14 10:16:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:33][root][INFO] - Training Epoch: 2/2, step 12978/16670 completed (loss: 0.3937786817550659, acc: 0.8962963223457336)
[2024-11-14 10:16:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:33][root][INFO] - Training Epoch: 2/2, step 12979/16670 completed (loss: 0.2636273503303528, acc: 0.9311926364898682)
[2024-11-14 10:16:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:34][root][INFO] - Training Epoch: 2/2, step 12980/16670 completed (loss: 0.22357064485549927, acc: 0.9170984625816345)
[2024-11-14 10:16:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:34][root][INFO] - Training Epoch: 2/2, step 12981/16670 completed (loss: 0.22026042640209198, acc: 0.9379844665527344)
[2024-11-14 10:16:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:34][root][INFO] - Training Epoch: 2/2, step 12982/16670 completed (loss: 0.21840424835681915, acc: 0.9396551847457886)
[2024-11-14 10:16:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:35][root][INFO] - Training Epoch: 2/2, step 12983/16670 completed (loss: 0.11898533999919891, acc: 0.949999988079071)
[2024-11-14 10:16:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:35][root][INFO] - Training Epoch: 2/2, step 12984/16670 completed (loss: 0.1554265320301056, acc: 0.9333333373069763)
[2024-11-14 10:16:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:36][root][INFO] - Training Epoch: 2/2, step 12985/16670 completed (loss: 0.4803967773914337, acc: 0.8867924809455872)
[2024-11-14 10:16:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:36][root][INFO] - Training Epoch: 2/2, step 12986/16670 completed (loss: 0.20170824229717255, acc: 0.9479768872261047)
[2024-11-14 10:16:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:36][root][INFO] - Training Epoch: 2/2, step 12987/16670 completed (loss: 0.15687139332294464, acc: 0.9367815852165222)
[2024-11-14 10:16:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:37][root][INFO] - Training Epoch: 2/2, step 12988/16670 completed (loss: 0.14826789498329163, acc: 0.954285740852356)
[2024-11-14 10:16:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:37][root][INFO] - Training Epoch: 2/2, step 12989/16670 completed (loss: 0.13474099338054657, acc: 0.9702970385551453)
[2024-11-14 10:16:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:37][root][INFO] - Training Epoch: 2/2, step 12990/16670 completed (loss: 0.25667184591293335, acc: 0.8636363744735718)
[2024-11-14 10:16:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:38][root][INFO] - Training Epoch: 2/2, step 12991/16670 completed (loss: 0.13552671670913696, acc: 0.9657142758369446)
[2024-11-14 10:16:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:38][root][INFO] - Training Epoch: 2/2, step 12992/16670 completed (loss: 0.16312548518180847, acc: 0.9480000138282776)
[2024-11-14 10:16:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:38][root][INFO] - Training Epoch: 2/2, step 12993/16670 completed (loss: 0.22855716943740845, acc: 0.9552238583564758)
[2024-11-14 10:16:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:39][root][INFO] - Training Epoch: 2/2, step 12994/16670 completed (loss: 0.45112887024879456, acc: 0.848739504814148)
[2024-11-14 10:16:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:39][root][INFO] - Training Epoch: 2/2, step 12995/16670 completed (loss: 0.2561715245246887, acc: 0.8878504633903503)
[2024-11-14 10:16:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:40][root][INFO] - Training Epoch: 2/2, step 12996/16670 completed (loss: 0.11633617430925369, acc: 0.9802371263504028)
[2024-11-14 10:16:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:40][root][INFO] - Training Epoch: 2/2, step 12997/16670 completed (loss: 0.16038985550403595, acc: 0.9552715420722961)
[2024-11-14 10:16:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:40][root][INFO] - Training Epoch: 2/2, step 12998/16670 completed (loss: 0.16761431097984314, acc: 0.9554656147956848)
[2024-11-14 10:16:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:41][root][INFO] - Training Epoch: 2/2, step 12999/16670 completed (loss: 0.07877402007579803, acc: 0.9776536226272583)
[2024-11-14 10:16:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:41][root][INFO] - Training Epoch: 2/2, step 13000/16670 completed (loss: 0.19953271746635437, acc: 0.9382022619247437)
[2024-11-14 10:16:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:41][root][INFO] - Training Epoch: 2/2, step 13001/16670 completed (loss: 0.27044710516929626, acc: 0.9238754510879517)
[2024-11-14 10:16:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:42][root][INFO] - Training Epoch: 2/2, step 13002/16670 completed (loss: 0.2717623710632324, acc: 0.9156626462936401)
[2024-11-14 10:16:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:42][root][INFO] - Training Epoch: 2/2, step 13003/16670 completed (loss: 0.2525663375854492, acc: 0.9306358098983765)
[2024-11-14 10:16:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:42][root][INFO] - Training Epoch: 2/2, step 13004/16670 completed (loss: 0.37026554346084595, acc: 0.9251700639724731)
[2024-11-14 10:16:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:43][root][INFO] - Training Epoch: 2/2, step 13005/16670 completed (loss: 0.2223450392484665, acc: 0.9441624283790588)
[2024-11-14 10:16:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:43][root][INFO] - Training Epoch: 2/2, step 13006/16670 completed (loss: 0.14005041122436523, acc: 0.9484978318214417)
[2024-11-14 10:16:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:43][root][INFO] - Training Epoch: 2/2, step 13007/16670 completed (loss: 0.15482677519321442, acc: 0.9522058963775635)
[2024-11-14 10:16:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:44][root][INFO] - Training Epoch: 2/2, step 13008/16670 completed (loss: 0.07160724699497223, acc: 0.9928057789802551)
[2024-11-14 10:16:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:44][root][INFO] - Training Epoch: 2/2, step 13009/16670 completed (loss: 0.3030600845813751, acc: 0.8962655663490295)
[2024-11-14 10:16:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:44][root][INFO] - Training Epoch: 2/2, step 13010/16670 completed (loss: 0.29017147421836853, acc: 0.9261363744735718)
[2024-11-14 10:16:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:45][root][INFO] - Training Epoch: 2/2, step 13011/16670 completed (loss: 0.1131390854716301, acc: 0.9623430967330933)
[2024-11-14 10:16:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:45][root][INFO] - Training Epoch: 2/2, step 13012/16670 completed (loss: 0.13386306166648865, acc: 0.9655172228813171)
[2024-11-14 10:16:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:45][root][INFO] - Training Epoch: 2/2, step 13013/16670 completed (loss: 0.07816994935274124, acc: 0.9829545617103577)
[2024-11-14 10:16:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:46][root][INFO] - Training Epoch: 2/2, step 13014/16670 completed (loss: 0.22386792302131653, acc: 0.9371727705001831)
[2024-11-14 10:16:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:46][root][INFO] - Training Epoch: 2/2, step 13015/16670 completed (loss: 0.19358192384243011, acc: 0.9301310181617737)
[2024-11-14 10:16:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:46][root][INFO] - Training Epoch: 2/2, step 13016/16670 completed (loss: 0.33733388781547546, acc: 0.9035087823867798)
[2024-11-14 10:16:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:47][root][INFO] - Training Epoch: 2/2, step 13017/16670 completed (loss: 0.1902867704629898, acc: 0.9487179517745972)
[2024-11-14 10:16:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:47][root][INFO] - Training Epoch: 2/2, step 13018/16670 completed (loss: 0.2096441388130188, acc: 0.9444444179534912)
[2024-11-14 10:16:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:48][root][INFO] - Training Epoch: 2/2, step 13019/16670 completed (loss: 0.06516745686531067, acc: 0.9904761910438538)
[2024-11-14 10:16:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:48][root][INFO] - Training Epoch: 2/2, step 13020/16670 completed (loss: 0.11464497447013855, acc: 0.9631147384643555)
[2024-11-14 10:16:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:48][root][INFO] - Training Epoch: 2/2, step 13021/16670 completed (loss: 0.17177070677280426, acc: 0.9585798978805542)
[2024-11-14 10:16:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:48][root][INFO] - Training Epoch: 2/2, step 13022/16670 completed (loss: 0.17515230178833008, acc: 0.9577465057373047)
[2024-11-14 10:16:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:49][root][INFO] - Training Epoch: 2/2, step 13023/16670 completed (loss: 0.4478233754634857, acc: 0.8658536672592163)
[2024-11-14 10:16:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:49][root][INFO] - Training Epoch: 2/2, step 13024/16670 completed (loss: 0.2664874196052551, acc: 0.9222221970558167)
[2024-11-14 10:16:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:49][root][INFO] - Training Epoch: 2/2, step 13025/16670 completed (loss: 0.18034958839416504, acc: 0.9535865187644958)
[2024-11-14 10:16:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:50][root][INFO] - Training Epoch: 2/2, step 13026/16670 completed (loss: 0.2290167361497879, acc: 0.9285714030265808)
[2024-11-14 10:16:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:50][root][INFO] - Training Epoch: 2/2, step 13027/16670 completed (loss: 0.18257494270801544, acc: 0.9597315192222595)
[2024-11-14 10:16:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:51][root][INFO] - Training Epoch: 2/2, step 13028/16670 completed (loss: 0.21599560976028442, acc: 0.9420289993286133)
[2024-11-14 10:16:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:51][root][INFO] - Training Epoch: 2/2, step 13029/16670 completed (loss: 0.26337432861328125, acc: 0.9360465407371521)
[2024-11-14 10:16:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:51][root][INFO] - Training Epoch: 2/2, step 13030/16670 completed (loss: 0.168939009308815, acc: 0.9622641801834106)
[2024-11-14 10:16:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:52][root][INFO] - Training Epoch: 2/2, step 13031/16670 completed (loss: 0.10777750611305237, acc: 0.9825581312179565)
[2024-11-14 10:16:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:52][root][INFO] - Training Epoch: 2/2, step 13032/16670 completed (loss: 0.18085241317749023, acc: 0.9518072009086609)
[2024-11-14 10:16:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:52][root][INFO] - Training Epoch: 2/2, step 13033/16670 completed (loss: 0.17941543459892273, acc: 0.9528796076774597)
[2024-11-14 10:16:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:53][root][INFO] - Training Epoch: 2/2, step 13034/16670 completed (loss: 0.1654023975133896, acc: 0.9537814855575562)
[2024-11-14 10:16:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:53][root][INFO] - Training Epoch: 2/2, step 13035/16670 completed (loss: 0.2808566391468048, acc: 0.9033816456794739)
[2024-11-14 10:16:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:53][root][INFO] - Training Epoch: 2/2, step 13036/16670 completed (loss: 0.192082941532135, acc: 0.9520958065986633)
[2024-11-14 10:16:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:54][root][INFO] - Training Epoch: 2/2, step 13037/16670 completed (loss: 0.292359322309494, acc: 0.917475700378418)
[2024-11-14 10:16:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:54][root][INFO] - Training Epoch: 2/2, step 13038/16670 completed (loss: 0.3496282696723938, acc: 0.8994413614273071)
[2024-11-14 10:16:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:54][root][INFO] - Training Epoch: 2/2, step 13039/16670 completed (loss: 0.3303835988044739, acc: 0.9186046719551086)
[2024-11-14 10:16:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:55][root][INFO] - Training Epoch: 2/2, step 13040/16670 completed (loss: 0.11596988886594772, acc: 0.9683257937431335)
[2024-11-14 10:16:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:55][root][INFO] - Training Epoch: 2/2, step 13041/16670 completed (loss: 0.14085283875465393, acc: 0.9578059315681458)
[2024-11-14 10:16:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:55][root][INFO] - Training Epoch: 2/2, step 13042/16670 completed (loss: 0.11806491017341614, acc: 0.9618320465087891)
[2024-11-14 10:16:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:56][root][INFO] - Training Epoch: 2/2, step 13043/16670 completed (loss: 0.26695072650909424, acc: 0.9435028433799744)
[2024-11-14 10:16:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:56][root][INFO] - Training Epoch: 2/2, step 13044/16670 completed (loss: 0.18386125564575195, acc: 0.9732142686843872)
[2024-11-14 10:16:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:57][root][INFO] - Training Epoch: 2/2, step 13045/16670 completed (loss: 0.18552693724632263, acc: 0.9416666626930237)
[2024-11-14 10:16:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:57][root][INFO] - Training Epoch: 2/2, step 13046/16670 completed (loss: 0.10686992853879929, acc: 0.972000002861023)
[2024-11-14 10:16:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:57][root][INFO] - Training Epoch: 2/2, step 13047/16670 completed (loss: 0.10029114782810211, acc: 0.9691358208656311)
[2024-11-14 10:16:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:58][root][INFO] - Training Epoch: 2/2, step 13048/16670 completed (loss: 0.11233816295862198, acc: 0.9607843160629272)
[2024-11-14 10:16:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:58][root][INFO] - Training Epoch: 2/2, step 13049/16670 completed (loss: 0.23558305203914642, acc: 0.9276018142700195)
[2024-11-14 10:16:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:59][root][INFO] - Training Epoch: 2/2, step 13050/16670 completed (loss: 0.12224879860877991, acc: 0.970802903175354)
[2024-11-14 10:16:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:59][root][INFO] - Training Epoch: 2/2, step 13051/16670 completed (loss: 0.09999208152294159, acc: 0.9640718698501587)
[2024-11-14 10:16:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:16:59][root][INFO] - Training Epoch: 2/2, step 13052/16670 completed (loss: 0.14871764183044434, acc: 0.9659574627876282)
[2024-11-14 10:16:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:00][root][INFO] - Training Epoch: 2/2, step 13053/16670 completed (loss: 0.14087314903736115, acc: 0.9347826242446899)
[2024-11-14 10:17:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:00][root][INFO] - Training Epoch: 2/2, step 13054/16670 completed (loss: 0.2639651596546173, acc: 0.9459459185600281)
[2024-11-14 10:17:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:00][root][INFO] - Training Epoch: 2/2, step 13055/16670 completed (loss: 0.07099686563014984, acc: 0.9791666865348816)
[2024-11-14 10:17:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:01][root][INFO] - Training Epoch: 2/2, step 13056/16670 completed (loss: 0.20126695930957794, acc: 0.9514563083648682)
[2024-11-14 10:17:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:01][root][INFO] - Training Epoch: 2/2, step 13057/16670 completed (loss: 0.13957178592681885, acc: 0.9618320465087891)
[2024-11-14 10:17:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:01][root][INFO] - Training Epoch: 2/2, step 13058/16670 completed (loss: 0.23844192922115326, acc: 0.9239130616188049)
[2024-11-14 10:17:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:02][root][INFO] - Training Epoch: 2/2, step 13059/16670 completed (loss: 0.18697160482406616, acc: 0.9406779408454895)
[2024-11-14 10:17:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:02][root][INFO] - Training Epoch: 2/2, step 13060/16670 completed (loss: 0.2550983428955078, acc: 0.929347813129425)
[2024-11-14 10:17:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:02][root][INFO] - Training Epoch: 2/2, step 13061/16670 completed (loss: 0.22920989990234375, acc: 0.956250011920929)
[2024-11-14 10:17:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:03][root][INFO] - Training Epoch: 2/2, step 13062/16670 completed (loss: 0.24879470467567444, acc: 0.9241071343421936)
[2024-11-14 10:17:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:03][root][INFO] - Training Epoch: 2/2, step 13063/16670 completed (loss: 0.15023691952228546, acc: 0.9465240836143494)
[2024-11-14 10:17:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:04][root][INFO] - Training Epoch: 2/2, step 13064/16670 completed (loss: 0.14015349745750427, acc: 0.9647058844566345)
[2024-11-14 10:17:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:04][root][INFO] - Training Epoch: 2/2, step 13065/16670 completed (loss: 0.25448179244995117, acc: 0.9307692050933838)
[2024-11-14 10:17:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:04][root][INFO] - Training Epoch: 2/2, step 13066/16670 completed (loss: 0.1587178260087967, acc: 0.954023003578186)
[2024-11-14 10:17:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:05][root][INFO] - Training Epoch: 2/2, step 13067/16670 completed (loss: 0.6463868021965027, acc: 0.8837209343910217)
[2024-11-14 10:17:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:05][root][INFO] - Training Epoch: 2/2, step 13068/16670 completed (loss: 0.6941941976547241, acc: 0.8450704216957092)
[2024-11-14 10:17:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:05][root][INFO] - Training Epoch: 2/2, step 13069/16670 completed (loss: 0.8989349007606506, acc: 0.7857142686843872)
[2024-11-14 10:17:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:06][root][INFO] - Training Epoch: 2/2, step 13070/16670 completed (loss: 0.6344659924507141, acc: 0.835616409778595)
[2024-11-14 10:17:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:06][root][INFO] - Training Epoch: 2/2, step 13071/16670 completed (loss: 0.5122708082199097, acc: 0.8461538553237915)
[2024-11-14 10:17:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:06][root][INFO] - Training Epoch: 2/2, step 13072/16670 completed (loss: 0.34496551752090454, acc: 0.9333333373069763)
[2024-11-14 10:17:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:07][root][INFO] - Training Epoch: 2/2, step 13073/16670 completed (loss: 0.5290162563323975, acc: 0.9230769276618958)
[2024-11-14 10:17:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:07][root][INFO] - Training Epoch: 2/2, step 13074/16670 completed (loss: 0.42887452244758606, acc: 0.875)
[2024-11-14 10:17:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:07][root][INFO] - Training Epoch: 2/2, step 13075/16670 completed (loss: 0.22939065098762512, acc: 0.9354838728904724)
[2024-11-14 10:17:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:08][root][INFO] - Training Epoch: 2/2, step 13076/16670 completed (loss: 0.5683267116546631, acc: 0.8620689511299133)
[2024-11-14 10:17:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:08][root][INFO] - Training Epoch: 2/2, step 13077/16670 completed (loss: 1.4220863580703735, acc: 0.8181818127632141)
[2024-11-14 10:17:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:08][root][INFO] - Training Epoch: 2/2, step 13078/16670 completed (loss: 0.1712285876274109, acc: 0.9666666388511658)
[2024-11-14 10:17:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:09][root][INFO] - Training Epoch: 2/2, step 13079/16670 completed (loss: 0.5617745518684387, acc: 0.8125)
[2024-11-14 10:17:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:09][root][INFO] - Training Epoch: 2/2, step 13080/16670 completed (loss: 0.5016947388648987, acc: 0.9130434989929199)
[2024-11-14 10:17:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:09][root][INFO] - Training Epoch: 2/2, step 13081/16670 completed (loss: 0.720130443572998, acc: 0.8783783912658691)
[2024-11-14 10:17:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:10][root][INFO] - Training Epoch: 2/2, step 13082/16670 completed (loss: 0.3480619490146637, acc: 0.9318181872367859)
[2024-11-14 10:17:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:10][root][INFO] - Training Epoch: 2/2, step 13083/16670 completed (loss: 1.0457602739334106, acc: 0.7428571581840515)
[2024-11-14 10:17:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:10][root][INFO] - Training Epoch: 2/2, step 13084/16670 completed (loss: 0.329833447933197, acc: 0.939393937587738)
[2024-11-14 10:17:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:10][root][INFO] - Training Epoch: 2/2, step 13085/16670 completed (loss: 0.8013061881065369, acc: 0.7222222089767456)
[2024-11-14 10:17:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:11][root][INFO] - Training Epoch: 2/2, step 13086/16670 completed (loss: 0.8259192109107971, acc: 0.774193525314331)
[2024-11-14 10:17:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:11][root][INFO] - Training Epoch: 2/2, step 13087/16670 completed (loss: 0.2734025716781616, acc: 0.9318181872367859)
[2024-11-14 10:17:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:11][root][INFO] - Training Epoch: 2/2, step 13088/16670 completed (loss: 0.976443886756897, acc: 0.78125)
[2024-11-14 10:17:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:12][root][INFO] - Training Epoch: 2/2, step 13089/16670 completed (loss: 0.4546825587749481, acc: 0.930232584476471)
[2024-11-14 10:17:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:12][root][INFO] - Training Epoch: 2/2, step 13090/16670 completed (loss: 0.37071847915649414, acc: 0.9166666865348816)
[2024-11-14 10:17:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:12][root][INFO] - Training Epoch: 2/2, step 13091/16670 completed (loss: 0.7739841341972351, acc: 0.7631579041481018)
[2024-11-14 10:17:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:13][root][INFO] - Training Epoch: 2/2, step 13092/16670 completed (loss: 0.726792573928833, acc: 0.8644067645072937)
[2024-11-14 10:17:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:13][root][INFO] - Training Epoch: 2/2, step 13093/16670 completed (loss: 0.4779838025569916, acc: 0.8387096524238586)
[2024-11-14 10:17:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:13][root][INFO] - Training Epoch: 2/2, step 13094/16670 completed (loss: 0.7211775183677673, acc: 0.8644067645072937)
[2024-11-14 10:17:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:14][root][INFO] - Training Epoch: 2/2, step 13095/16670 completed (loss: 0.46517425775527954, acc: 0.8444444537162781)
[2024-11-14 10:17:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:14][root][INFO] - Training Epoch: 2/2, step 13096/16670 completed (loss: 0.29964324831962585, acc: 0.9200000166893005)
[2024-11-14 10:17:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:14][root][INFO] - Training Epoch: 2/2, step 13097/16670 completed (loss: 0.3765827715396881, acc: 0.8809523582458496)
[2024-11-14 10:17:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:15][root][INFO] - Training Epoch: 2/2, step 13098/16670 completed (loss: 0.5950021147727966, acc: 0.8387096524238586)
[2024-11-14 10:17:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:15][root][INFO] - Training Epoch: 2/2, step 13099/16670 completed (loss: 0.3872220516204834, acc: 0.9245283007621765)
[2024-11-14 10:17:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:15][root][INFO] - Training Epoch: 2/2, step 13100/16670 completed (loss: 0.6890896558761597, acc: 0.8636363744735718)
[2024-11-14 10:17:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:16][root][INFO] - Training Epoch: 2/2, step 13101/16670 completed (loss: 0.5307710766792297, acc: 0.8450704216957092)
[2024-11-14 10:17:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:16][root][INFO] - Training Epoch: 2/2, step 13102/16670 completed (loss: 0.5245155692100525, acc: 0.8387096524238586)
[2024-11-14 10:17:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:16][root][INFO] - Training Epoch: 2/2, step 13103/16670 completed (loss: 0.46657246351242065, acc: 0.9210526347160339)
[2024-11-14 10:17:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:16][root][INFO] - Training Epoch: 2/2, step 13104/16670 completed (loss: 0.24005986750125885, acc: 0.9333333373069763)
[2024-11-14 10:17:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:17][root][INFO] - Training Epoch: 2/2, step 13105/16670 completed (loss: 0.19833849370479584, acc: 0.9375)
[2024-11-14 10:17:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:17][root][INFO] - Training Epoch: 2/2, step 13106/16670 completed (loss: 0.17100326716899872, acc: 0.9411764740943909)
[2024-11-14 10:17:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:17][root][INFO] - Training Epoch: 2/2, step 13107/16670 completed (loss: 0.28328537940979004, acc: 0.8627451062202454)
[2024-11-14 10:17:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:18][root][INFO] - Training Epoch: 2/2, step 13108/16670 completed (loss: 0.9174208641052246, acc: 0.8679245114326477)
[2024-11-14 10:17:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:18][root][INFO] - Training Epoch: 2/2, step 13109/16670 completed (loss: 0.11948218941688538, acc: 0.9803921580314636)
[2024-11-14 10:17:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:18][root][INFO] - Training Epoch: 2/2, step 13110/16670 completed (loss: 0.14802055060863495, acc: 0.9629629850387573)
[2024-11-14 10:17:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:19][root][INFO] - Training Epoch: 2/2, step 13111/16670 completed (loss: 1.1527961492538452, acc: 0.7611940503120422)
[2024-11-14 10:17:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:19][root][INFO] - Training Epoch: 2/2, step 13112/16670 completed (loss: 0.819278359413147, acc: 0.8571428656578064)
[2024-11-14 10:17:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:19][root][INFO] - Training Epoch: 2/2, step 13113/16670 completed (loss: 0.6028862595558167, acc: 0.8846153616905212)
[2024-11-14 10:17:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:20][root][INFO] - Training Epoch: 2/2, step 13114/16670 completed (loss: 1.0836769342422485, acc: 0.8035714030265808)
[2024-11-14 10:17:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:20][root][INFO] - Training Epoch: 2/2, step 13115/16670 completed (loss: 1.4240585565567017, acc: 0.7358490824699402)
[2024-11-14 10:17:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:21][root][INFO] - Training Epoch: 2/2, step 13116/16670 completed (loss: 0.5208261609077454, acc: 0.875)
[2024-11-14 10:17:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:21][root][INFO] - Training Epoch: 2/2, step 13117/16670 completed (loss: 0.5135693550109863, acc: 0.90625)
[2024-11-14 10:17:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:21][root][INFO] - Training Epoch: 2/2, step 13118/16670 completed (loss: 1.082905650138855, acc: 0.75)
[2024-11-14 10:17:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:22][root][INFO] - Training Epoch: 2/2, step 13119/16670 completed (loss: 0.10844354331493378, acc: 0.9607843160629272)
[2024-11-14 10:17:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:22][root][INFO] - Training Epoch: 2/2, step 13120/16670 completed (loss: 1.5151355266571045, acc: 0.6595744490623474)
[2024-11-14 10:17:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:22][root][INFO] - Training Epoch: 2/2, step 13121/16670 completed (loss: 0.9607418775558472, acc: 0.7681159377098083)
[2024-11-14 10:17:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:23][root][INFO] - Training Epoch: 2/2, step 13122/16670 completed (loss: 0.8089277744293213, acc: 0.774193525314331)
[2024-11-14 10:17:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:23][root][INFO] - Training Epoch: 2/2, step 13123/16670 completed (loss: 0.21650171279907227, acc: 0.9411764740943909)
[2024-11-14 10:17:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:23][root][INFO] - Training Epoch: 2/2, step 13124/16670 completed (loss: 0.9280886650085449, acc: 0.7647058963775635)
[2024-11-14 10:17:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:24][root][INFO] - Training Epoch: 2/2, step 13125/16670 completed (loss: 0.8325157165527344, acc: 0.8636363744735718)
[2024-11-14 10:17:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:24][root][INFO] - Training Epoch: 2/2, step 13126/16670 completed (loss: 0.3405199944972992, acc: 0.9016393423080444)
[2024-11-14 10:17:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:24][root][INFO] - Training Epoch: 2/2, step 13127/16670 completed (loss: 0.19958607852458954, acc: 0.978723406791687)
[2024-11-14 10:17:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:25][root][INFO] - Training Epoch: 2/2, step 13128/16670 completed (loss: 0.44279196858406067, acc: 0.9137930870056152)
[2024-11-14 10:17:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:25][root][INFO] - Training Epoch: 2/2, step 13129/16670 completed (loss: 0.10199793428182602, acc: 1.0)
[2024-11-14 10:17:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:26][root][INFO] - Training Epoch: 2/2, step 13130/16670 completed (loss: 0.6973086595535278, acc: 0.8518518805503845)
[2024-11-14 10:17:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:26][root][INFO] - Training Epoch: 2/2, step 13131/16670 completed (loss: 0.6140229105949402, acc: 0.8421052694320679)
[2024-11-14 10:17:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:26][root][INFO] - Training Epoch: 2/2, step 13132/16670 completed (loss: 0.7116129398345947, acc: 0.8235294222831726)
[2024-11-14 10:17:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:27][root][INFO] - Training Epoch: 2/2, step 13133/16670 completed (loss: 0.5018667578697205, acc: 0.8372092843055725)
[2024-11-14 10:17:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:27][root][INFO] - Training Epoch: 2/2, step 13134/16670 completed (loss: 0.25440266728401184, acc: 0.9285714030265808)
[2024-11-14 10:17:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:27][root][INFO] - Training Epoch: 2/2, step 13135/16670 completed (loss: 0.3731096386909485, acc: 0.8793103694915771)
[2024-11-14 10:17:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:28][root][INFO] - Training Epoch: 2/2, step 13136/16670 completed (loss: 0.3728034794330597, acc: 0.8999999761581421)
[2024-11-14 10:17:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:28][root][INFO] - Training Epoch: 2/2, step 13137/16670 completed (loss: 0.41104570031166077, acc: 0.9069767594337463)
[2024-11-14 10:17:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:28][root][INFO] - Training Epoch: 2/2, step 13138/16670 completed (loss: 0.15864711999893188, acc: 0.9454545378684998)
[2024-11-14 10:17:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:29][root][INFO] - Training Epoch: 2/2, step 13139/16670 completed (loss: 0.5289607048034668, acc: 0.8823529481887817)
[2024-11-14 10:17:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:29][root][INFO] - Training Epoch: 2/2, step 13140/16670 completed (loss: 0.5472336411476135, acc: 0.9230769276618958)
[2024-11-14 10:17:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:29][root][INFO] - Training Epoch: 2/2, step 13141/16670 completed (loss: 0.8783366680145264, acc: 0.8518518805503845)
[2024-11-14 10:17:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:30][root][INFO] - Training Epoch: 2/2, step 13142/16670 completed (loss: 0.4725613594055176, acc: 0.8392857313156128)
[2024-11-14 10:17:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:30][root][INFO] - Training Epoch: 2/2, step 13143/16670 completed (loss: 0.9677248597145081, acc: 0.6774193644523621)
[2024-11-14 10:17:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:30][root][INFO] - Training Epoch: 2/2, step 13144/16670 completed (loss: 0.6258485317230225, acc: 0.8148148059844971)
[2024-11-14 10:17:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:31][root][INFO] - Training Epoch: 2/2, step 13145/16670 completed (loss: 0.33549201488494873, acc: 0.8888888955116272)
[2024-11-14 10:17:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:31][root][INFO] - Training Epoch: 2/2, step 13146/16670 completed (loss: 0.4844973087310791, acc: 0.8805969953536987)
[2024-11-14 10:17:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:31][root][INFO] - Training Epoch: 2/2, step 13147/16670 completed (loss: 0.694497287273407, acc: 0.8684210777282715)
[2024-11-14 10:17:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:32][root][INFO] - Training Epoch: 2/2, step 13148/16670 completed (loss: 1.0078173875808716, acc: 0.8194444179534912)
[2024-11-14 10:17:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:32][root][INFO] - Training Epoch: 2/2, step 13149/16670 completed (loss: 0.23319120705127716, acc: 0.9354838728904724)
[2024-11-14 10:17:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:32][root][INFO] - Training Epoch: 2/2, step 13150/16670 completed (loss: 0.6060439348220825, acc: 0.849056601524353)
[2024-11-14 10:17:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:33][root][INFO] - Training Epoch: 2/2, step 13151/16670 completed (loss: 0.6507977247238159, acc: 0.8666666746139526)
[2024-11-14 10:17:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:33][root][INFO] - Training Epoch: 2/2, step 13152/16670 completed (loss: 0.1113375797867775, acc: 1.0)
[2024-11-14 10:17:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:33][root][INFO] - Training Epoch: 2/2, step 13153/16670 completed (loss: 0.6329477429389954, acc: 0.8225806355476379)
[2024-11-14 10:17:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:34][root][INFO] - Training Epoch: 2/2, step 13154/16670 completed (loss: 0.4729142189025879, acc: 0.8771929740905762)
[2024-11-14 10:17:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:34][root][INFO] - Training Epoch: 2/2, step 13155/16670 completed (loss: 0.49045872688293457, acc: 0.8709677457809448)
[2024-11-14 10:17:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:34][root][INFO] - Training Epoch: 2/2, step 13156/16670 completed (loss: 0.7492460012435913, acc: 0.8372092843055725)
[2024-11-14 10:17:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:34][root][INFO] - Training Epoch: 2/2, step 13157/16670 completed (loss: 1.139471173286438, acc: 0.7674418687820435)
[2024-11-14 10:17:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:35][root][INFO] - Training Epoch: 2/2, step 13158/16670 completed (loss: 0.4195268750190735, acc: 0.8913043737411499)
[2024-11-14 10:17:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:35][root][INFO] - Training Epoch: 2/2, step 13159/16670 completed (loss: 0.5193342566490173, acc: 0.8602150678634644)
[2024-11-14 10:17:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:35][root][INFO] - Training Epoch: 2/2, step 13160/16670 completed (loss: 0.47910749912261963, acc: 0.8888888955116272)
[2024-11-14 10:17:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:36][root][INFO] - Training Epoch: 2/2, step 13161/16670 completed (loss: 0.7800130248069763, acc: 0.8333333134651184)
[2024-11-14 10:17:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:36][root][INFO] - Training Epoch: 2/2, step 13162/16670 completed (loss: 0.29744404554367065, acc: 0.9152542352676392)
[2024-11-14 10:17:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:36][root][INFO] - Training Epoch: 2/2, step 13163/16670 completed (loss: 0.3931327164173126, acc: 0.8636363744735718)
[2024-11-14 10:17:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:37][root][INFO] - Training Epoch: 2/2, step 13164/16670 completed (loss: 0.12152651697397232, acc: 0.9736841917037964)
[2024-11-14 10:17:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:37][root][INFO] - Training Epoch: 2/2, step 13165/16670 completed (loss: 0.898241400718689, acc: 0.800000011920929)
[2024-11-14 10:17:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:38][root][INFO] - Training Epoch: 2/2, step 13166/16670 completed (loss: 0.4470657408237457, acc: 0.9318181872367859)
[2024-11-14 10:17:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:38][root][INFO] - Training Epoch: 2/2, step 13167/16670 completed (loss: 1.0237141847610474, acc: 0.760869562625885)
[2024-11-14 10:17:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:38][root][INFO] - Training Epoch: 2/2, step 13168/16670 completed (loss: 0.30079150199890137, acc: 0.9523809552192688)
[2024-11-14 10:17:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:39][root][INFO] - Training Epoch: 2/2, step 13169/16670 completed (loss: 0.49983641505241394, acc: 0.914893627166748)
[2024-11-14 10:17:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:39][root][INFO] - Training Epoch: 2/2, step 13170/16670 completed (loss: 0.6725943088531494, acc: 0.8888888955116272)
[2024-11-14 10:17:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:39][root][INFO] - Training Epoch: 2/2, step 13171/16670 completed (loss: 0.7954295873641968, acc: 0.8571428656578064)
[2024-11-14 10:17:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:40][root][INFO] - Training Epoch: 2/2, step 13172/16670 completed (loss: 0.5752667188644409, acc: 0.8085106611251831)
[2024-11-14 10:17:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:40][root][INFO] - Training Epoch: 2/2, step 13173/16670 completed (loss: 0.5103234648704529, acc: 0.8947368264198303)
[2024-11-14 10:17:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:40][root][INFO] - Training Epoch: 2/2, step 13174/16670 completed (loss: 0.8554965853691101, acc: 0.7954545617103577)
[2024-11-14 10:17:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:41][root][INFO] - Training Epoch: 2/2, step 13175/16670 completed (loss: 0.6043321490287781, acc: 0.9230769276618958)
[2024-11-14 10:17:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:41][root][INFO] - Training Epoch: 2/2, step 13176/16670 completed (loss: 0.618445634841919, acc: 0.9268292784690857)
[2024-11-14 10:17:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:41][root][INFO] - Training Epoch: 2/2, step 13177/16670 completed (loss: 0.598950207233429, acc: 0.8604651093482971)
[2024-11-14 10:17:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:42][root][INFO] - Training Epoch: 2/2, step 13178/16670 completed (loss: 0.34193021059036255, acc: 0.8461538553237915)
[2024-11-14 10:17:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:42][root][INFO] - Training Epoch: 2/2, step 13179/16670 completed (loss: 0.5782468914985657, acc: 0.9074074029922485)
[2024-11-14 10:17:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:42][root][INFO] - Training Epoch: 2/2, step 13180/16670 completed (loss: 0.615587055683136, acc: 0.8135592937469482)
[2024-11-14 10:17:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:43][root][INFO] - Training Epoch: 2/2, step 13181/16670 completed (loss: 0.31188681721687317, acc: 0.9285714030265808)
[2024-11-14 10:17:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:43][root][INFO] - Training Epoch: 2/2, step 13182/16670 completed (loss: 0.504754364490509, acc: 0.8799999952316284)
[2024-11-14 10:17:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:43][root][INFO] - Training Epoch: 2/2, step 13183/16670 completed (loss: 0.39890170097351074, acc: 0.8999999761581421)
[2024-11-14 10:17:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:44][root][INFO] - Training Epoch: 2/2, step 13184/16670 completed (loss: 0.5252283215522766, acc: 0.8571428656578064)
[2024-11-14 10:17:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:44][root][INFO] - Training Epoch: 2/2, step 13185/16670 completed (loss: 0.4617782235145569, acc: 0.9056603908538818)
[2024-11-14 10:17:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:44][root][INFO] - Training Epoch: 2/2, step 13186/16670 completed (loss: 0.5690857768058777, acc: 0.8484848737716675)
[2024-11-14 10:17:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:45][root][INFO] - Training Epoch: 2/2, step 13187/16670 completed (loss: 0.9890756607055664, acc: 0.800000011920929)
[2024-11-14 10:17:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:45][root][INFO] - Training Epoch: 2/2, step 13188/16670 completed (loss: 0.4286673963069916, acc: 0.8717948794364929)
[2024-11-14 10:17:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:45][root][INFO] - Training Epoch: 2/2, step 13189/16670 completed (loss: 0.3128611147403717, acc: 0.9038461446762085)
[2024-11-14 10:17:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:46][root][INFO] - Training Epoch: 2/2, step 13190/16670 completed (loss: 0.4476024806499481, acc: 0.9285714030265808)
[2024-11-14 10:17:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:46][root][INFO] - Training Epoch: 2/2, step 13191/16670 completed (loss: 1.2498141527175903, acc: 0.7592592835426331)
[2024-11-14 10:17:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:47][root][INFO] - Training Epoch: 2/2, step 13192/16670 completed (loss: 0.7536983489990234, acc: 0.859375)
[2024-11-14 10:17:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:47][root][INFO] - Training Epoch: 2/2, step 13193/16670 completed (loss: 0.8734407424926758, acc: 0.7837837934494019)
[2024-11-14 10:17:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:47][root][INFO] - Training Epoch: 2/2, step 13194/16670 completed (loss: 0.2834121286869049, acc: 0.9210526347160339)
[2024-11-14 10:17:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:48][root][INFO] - Training Epoch: 2/2, step 13195/16670 completed (loss: 0.3119553327560425, acc: 0.9397590160369873)
[2024-11-14 10:17:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:48][root][INFO] - Training Epoch: 2/2, step 13196/16670 completed (loss: 0.3473593294620514, acc: 0.9365079402923584)
[2024-11-14 10:17:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:48][root][INFO] - Training Epoch: 2/2, step 13197/16670 completed (loss: 0.9114847183227539, acc: 0.8214285969734192)
[2024-11-14 10:17:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:49][root][INFO] - Training Epoch: 2/2, step 13198/16670 completed (loss: 0.25915881991386414, acc: 0.939393937587738)
[2024-11-14 10:17:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:49][root][INFO] - Training Epoch: 2/2, step 13199/16670 completed (loss: 0.49409011006355286, acc: 0.9019607901573181)
[2024-11-14 10:17:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:49][root][INFO] - Training Epoch: 2/2, step 13200/16670 completed (loss: 0.8729766607284546, acc: 0.8181818127632141)
[2024-11-14 10:17:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:50][root][INFO] - Training Epoch: 2/2, step 13201/16670 completed (loss: 0.6828553676605225, acc: 0.8245614171028137)
[2024-11-14 10:17:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:50][root][INFO] - Training Epoch: 2/2, step 13202/16670 completed (loss: 0.703815221786499, acc: 0.8194444179534912)
[2024-11-14 10:17:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:50][root][INFO] - Training Epoch: 2/2, step 13203/16670 completed (loss: 0.4878610372543335, acc: 0.8591549396514893)
[2024-11-14 10:17:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:51][root][INFO] - Training Epoch: 2/2, step 13204/16670 completed (loss: 0.12050800025463104, acc: 0.9743589758872986)
[2024-11-14 10:17:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:51][root][INFO] - Training Epoch: 2/2, step 13205/16670 completed (loss: 0.6310776472091675, acc: 0.8947368264198303)
[2024-11-14 10:17:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:51][root][INFO] - Training Epoch: 2/2, step 13206/16670 completed (loss: 1.3468879461288452, acc: 0.6842105388641357)
[2024-11-14 10:17:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:52][root][INFO] - Training Epoch: 2/2, step 13207/16670 completed (loss: 0.4715520143508911, acc: 0.8846153616905212)
[2024-11-14 10:17:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:52][root][INFO] - Training Epoch: 2/2, step 13208/16670 completed (loss: 0.7192832827568054, acc: 0.8113207817077637)
[2024-11-14 10:17:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:52][root][INFO] - Training Epoch: 2/2, step 13209/16670 completed (loss: 0.8920628428459167, acc: 0.8095238208770752)
[2024-11-14 10:17:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:52][root][INFO] - Training Epoch: 2/2, step 13210/16670 completed (loss: 0.6552717089653015, acc: 0.8448275923728943)
[2024-11-14 10:17:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:53][root][INFO] - Training Epoch: 2/2, step 13211/16670 completed (loss: 1.4238981008529663, acc: 0.7272727489471436)
[2024-11-14 10:17:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:53][root][INFO] - Training Epoch: 2/2, step 13212/16670 completed (loss: 0.5215198993682861, acc: 0.9242424368858337)
[2024-11-14 10:17:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:53][root][INFO] - Training Epoch: 2/2, step 13213/16670 completed (loss: 0.7225048542022705, acc: 0.8536585569381714)
[2024-11-14 10:17:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:54][root][INFO] - Training Epoch: 2/2, step 13214/16670 completed (loss: 0.30307477712631226, acc: 0.9354838728904724)
[2024-11-14 10:17:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:54][root][INFO] - Training Epoch: 2/2, step 13215/16670 completed (loss: 0.5736965537071228, acc: 0.868852436542511)
[2024-11-14 10:17:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:54][root][INFO] - Training Epoch: 2/2, step 13216/16670 completed (loss: 0.4282619059085846, acc: 0.8611111044883728)
[2024-11-14 10:17:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:55][root][INFO] - Training Epoch: 2/2, step 13217/16670 completed (loss: 0.4240970313549042, acc: 0.8333333134651184)
[2024-11-14 10:17:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:55][root][INFO] - Training Epoch: 2/2, step 13218/16670 completed (loss: 0.2053619921207428, acc: 0.9682539701461792)
[2024-11-14 10:17:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:55][root][INFO] - Training Epoch: 2/2, step 13219/16670 completed (loss: 0.08115173876285553, acc: 1.0)
[2024-11-14 10:17:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:56][root][INFO] - Training Epoch: 2/2, step 13220/16670 completed (loss: 0.9731823205947876, acc: 0.8571428656578064)
[2024-11-14 10:17:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:56][root][INFO] - Training Epoch: 2/2, step 13221/16670 completed (loss: 0.14680777490139008, acc: 0.9677419066429138)
[2024-11-14 10:17:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:56][root][INFO] - Training Epoch: 2/2, step 13222/16670 completed (loss: 0.4770660400390625, acc: 0.8461538553237915)
[2024-11-14 10:17:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:57][root][INFO] - Training Epoch: 2/2, step 13223/16670 completed (loss: 0.7764992713928223, acc: 0.9375)
[2024-11-14 10:17:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:57][root][INFO] - Training Epoch: 2/2, step 13224/16670 completed (loss: 0.5722092390060425, acc: 0.8474576473236084)
[2024-11-14 10:17:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:57][root][INFO] - Training Epoch: 2/2, step 13225/16670 completed (loss: 0.4988013505935669, acc: 0.837837815284729)
[2024-11-14 10:17:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:58][root][INFO] - Training Epoch: 2/2, step 13226/16670 completed (loss: 0.6979078054428101, acc: 0.8676470518112183)
[2024-11-14 10:17:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:58][root][INFO] - Training Epoch: 2/2, step 13227/16670 completed (loss: 0.24985341727733612, acc: 0.8947368264198303)
[2024-11-14 10:17:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:59][root][INFO] - Training Epoch: 2/2, step 13228/16670 completed (loss: 0.38205796480178833, acc: 0.875)
[2024-11-14 10:17:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:59][root][INFO] - Training Epoch: 2/2, step 13229/16670 completed (loss: 0.12901373207569122, acc: 0.9607843160629272)
[2024-11-14 10:17:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:17:59][root][INFO] - Training Epoch: 2/2, step 13230/16670 completed (loss: 0.6778737902641296, acc: 0.8253968358039856)
[2024-11-14 10:17:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:00][root][INFO] - Training Epoch: 2/2, step 13231/16670 completed (loss: 0.38591042160987854, acc: 0.7777777910232544)
[2024-11-14 10:18:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:00][root][INFO] - Training Epoch: 2/2, step 13232/16670 completed (loss: 0.6258941292762756, acc: 0.8055555820465088)
[2024-11-14 10:18:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:00][root][INFO] - Training Epoch: 2/2, step 13233/16670 completed (loss: 0.8465620875358582, acc: 0.8444444537162781)
[2024-11-14 10:18:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:01][root][INFO] - Training Epoch: 2/2, step 13234/16670 completed (loss: 0.691778838634491, acc: 0.8405796885490417)
[2024-11-14 10:18:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:01][root][INFO] - Training Epoch: 2/2, step 13235/16670 completed (loss: 0.5999298095703125, acc: 0.8588235378265381)
[2024-11-14 10:18:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:01][root][INFO] - Training Epoch: 2/2, step 13236/16670 completed (loss: 1.6543620824813843, acc: 0.6896551847457886)
[2024-11-14 10:18:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:02][root][INFO] - Training Epoch: 2/2, step 13237/16670 completed (loss: 0.5883885025978088, acc: 0.875)
[2024-11-14 10:18:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:02][root][INFO] - Training Epoch: 2/2, step 13238/16670 completed (loss: 0.6092318296432495, acc: 0.8387096524238586)
[2024-11-14 10:18:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:02][root][INFO] - Training Epoch: 2/2, step 13239/16670 completed (loss: 0.4836830794811249, acc: 0.8936170339584351)
[2024-11-14 10:18:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:03][root][INFO] - Training Epoch: 2/2, step 13240/16670 completed (loss: 0.507866621017456, acc: 0.8837209343910217)
[2024-11-14 10:18:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:03][root][INFO] - Training Epoch: 2/2, step 13241/16670 completed (loss: 0.5929126143455505, acc: 0.8799999952316284)
[2024-11-14 10:18:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:03][root][INFO] - Training Epoch: 2/2, step 13242/16670 completed (loss: 0.2097308486700058, acc: 0.9516128897666931)
[2024-11-14 10:18:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:04][root][INFO] - Training Epoch: 2/2, step 13243/16670 completed (loss: 0.2482914924621582, acc: 0.8947368264198303)
[2024-11-14 10:18:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:04][root][INFO] - Training Epoch: 2/2, step 13244/16670 completed (loss: 0.3661356270313263, acc: 0.9347826242446899)
[2024-11-14 10:18:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:04][root][INFO] - Training Epoch: 2/2, step 13245/16670 completed (loss: 0.8054569363594055, acc: 0.8333333134651184)
[2024-11-14 10:18:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:05][root][INFO] - Training Epoch: 2/2, step 13246/16670 completed (loss: 0.7881687879562378, acc: 0.7777777910232544)
[2024-11-14 10:18:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:05][root][INFO] - Training Epoch: 2/2, step 13247/16670 completed (loss: 0.37749746441841125, acc: 0.8769230842590332)
[2024-11-14 10:18:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:05][root][INFO] - Training Epoch: 2/2, step 13248/16670 completed (loss: 0.3205619156360626, acc: 0.9482758641242981)
[2024-11-14 10:18:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:06][root][INFO] - Training Epoch: 2/2, step 13249/16670 completed (loss: 0.8208145499229431, acc: 0.7727272510528564)
[2024-11-14 10:18:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:06][root][INFO] - Training Epoch: 2/2, step 13250/16670 completed (loss: 0.7017406821250916, acc: 0.8125)
[2024-11-14 10:18:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:06][root][INFO] - Training Epoch: 2/2, step 13251/16670 completed (loss: 0.6669650077819824, acc: 0.8571428656578064)
[2024-11-14 10:18:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:07][root][INFO] - Training Epoch: 2/2, step 13252/16670 completed (loss: 0.11044018715620041, acc: 0.9552238583564758)
[2024-11-14 10:18:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:07][root][INFO] - Training Epoch: 2/2, step 13253/16670 completed (loss: 0.4369414448738098, acc: 0.8947368264198303)
[2024-11-14 10:18:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:07][root][INFO] - Training Epoch: 2/2, step 13254/16670 completed (loss: 0.4000593423843384, acc: 0.931506872177124)
[2024-11-14 10:18:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:08][root][INFO] - Training Epoch: 2/2, step 13255/16670 completed (loss: 0.4767614006996155, acc: 0.8775510191917419)
[2024-11-14 10:18:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:08][root][INFO] - Training Epoch: 2/2, step 13256/16670 completed (loss: 0.4973175525665283, acc: 0.8809523582458496)
[2024-11-14 10:18:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:09][root][INFO] - Training Epoch: 2/2, step 13257/16670 completed (loss: 0.20993998646736145, acc: 0.9322034120559692)
[2024-11-14 10:18:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:09][root][INFO] - Training Epoch: 2/2, step 13258/16670 completed (loss: 0.7510073781013489, acc: 0.8285714387893677)
[2024-11-14 10:18:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:09][root][INFO] - Training Epoch: 2/2, step 13259/16670 completed (loss: 0.4496454894542694, acc: 0.8125)
[2024-11-14 10:18:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:10][root][INFO] - Training Epoch: 2/2, step 13260/16670 completed (loss: 0.9962821006774902, acc: 0.8125)
[2024-11-14 10:18:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:10][root][INFO] - Training Epoch: 2/2, step 13261/16670 completed (loss: 0.4814430773258209, acc: 0.7872340679168701)
[2024-11-14 10:18:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:10][root][INFO] - Training Epoch: 2/2, step 13262/16670 completed (loss: 0.44824251532554626, acc: 0.8823529481887817)
[2024-11-14 10:18:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:11][root][INFO] - Training Epoch: 2/2, step 13263/16670 completed (loss: 0.4792073667049408, acc: 0.925000011920929)
[2024-11-14 10:18:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:11][root][INFO] - Training Epoch: 2/2, step 13264/16670 completed (loss: 0.545985996723175, acc: 0.9047619104385376)
[2024-11-14 10:18:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:12][root][INFO] - Training Epoch: 2/2, step 13265/16670 completed (loss: 0.6807241439819336, acc: 0.8484848737716675)
[2024-11-14 10:18:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:12][root][INFO] - Training Epoch: 2/2, step 13266/16670 completed (loss: 0.5730005502700806, acc: 0.8809523582458496)
[2024-11-14 10:18:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:12][root][INFO] - Training Epoch: 2/2, step 13267/16670 completed (loss: 0.1985640823841095, acc: 0.9322034120559692)
[2024-11-14 10:18:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:13][root][INFO] - Training Epoch: 2/2, step 13268/16670 completed (loss: 0.7072988748550415, acc: 0.8461538553237915)
[2024-11-14 10:18:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:13][root][INFO] - Training Epoch: 2/2, step 13269/16670 completed (loss: 0.6601234674453735, acc: 0.892307698726654)
[2024-11-14 10:18:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:13][root][INFO] - Training Epoch: 2/2, step 13270/16670 completed (loss: 0.5178589820861816, acc: 0.8703703880310059)
[2024-11-14 10:18:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:14][root][INFO] - Training Epoch: 2/2, step 13271/16670 completed (loss: 0.40281474590301514, acc: 0.9259259104728699)
[2024-11-14 10:18:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:14][root][INFO] - Training Epoch: 2/2, step 13272/16670 completed (loss: 0.5617398619651794, acc: 0.9464285969734192)
[2024-11-14 10:18:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:14][root][INFO] - Training Epoch: 2/2, step 13273/16670 completed (loss: 0.538879930973053, acc: 0.8823529481887817)
[2024-11-14 10:18:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:15][root][INFO] - Training Epoch: 2/2, step 13274/16670 completed (loss: 0.09011092782020569, acc: 0.9726027250289917)
[2024-11-14 10:18:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:15][root][INFO] - Training Epoch: 2/2, step 13275/16670 completed (loss: 0.08180580288171768, acc: 1.0)
[2024-11-14 10:18:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:16][root][INFO] - Training Epoch: 2/2, step 13276/16670 completed (loss: 1.2300173044204712, acc: 0.7333333492279053)
[2024-11-14 10:18:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:16][root][INFO] - Training Epoch: 2/2, step 13277/16670 completed (loss: 0.9637120366096497, acc: 0.7674418687820435)
[2024-11-14 10:18:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:16][root][INFO] - Training Epoch: 2/2, step 13278/16670 completed (loss: 0.1106707826256752, acc: 0.9583333134651184)
[2024-11-14 10:18:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:17][root][INFO] - Training Epoch: 2/2, step 13279/16670 completed (loss: 0.294463574886322, acc: 0.9245283007621765)
[2024-11-14 10:18:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:17][root][INFO] - Training Epoch: 2/2, step 13280/16670 completed (loss: 0.6138700842857361, acc: 0.90625)
[2024-11-14 10:18:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:17][root][INFO] - Training Epoch: 2/2, step 13281/16670 completed (loss: 0.7492752075195312, acc: 0.8965517282485962)
[2024-11-14 10:18:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:18][root][INFO] - Training Epoch: 2/2, step 13282/16670 completed (loss: 0.22401843965053558, acc: 0.931506872177124)
[2024-11-14 10:18:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:18][root][INFO] - Training Epoch: 2/2, step 13283/16670 completed (loss: 0.4287365674972534, acc: 0.8536585569381714)
[2024-11-14 10:18:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:18][root][INFO] - Training Epoch: 2/2, step 13284/16670 completed (loss: 1.1393942832946777, acc: 0.7727272510528564)
[2024-11-14 10:18:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:19][root][INFO] - Training Epoch: 2/2, step 13285/16670 completed (loss: 0.4667367935180664, acc: 0.8863636255264282)
[2024-11-14 10:18:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:19][root][INFO] - Training Epoch: 2/2, step 13286/16670 completed (loss: 0.4094128906726837, acc: 0.890625)
[2024-11-14 10:18:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:19][root][INFO] - Training Epoch: 2/2, step 13287/16670 completed (loss: 0.08967941999435425, acc: 1.0)
[2024-11-14 10:18:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:20][root][INFO] - Training Epoch: 2/2, step 13288/16670 completed (loss: 0.2555151581764221, acc: 0.9354838728904724)
[2024-11-14 10:18:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:20][root][INFO] - Training Epoch: 2/2, step 13289/16670 completed (loss: 0.1428338587284088, acc: 0.9629629850387573)
[2024-11-14 10:18:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:20][root][INFO] - Training Epoch: 2/2, step 13290/16670 completed (loss: 0.4113396108150482, acc: 0.8493150472640991)
[2024-11-14 10:18:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:21][root][INFO] - Training Epoch: 2/2, step 13291/16670 completed (loss: 0.4395504891872406, acc: 0.936170220375061)
[2024-11-14 10:18:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:21][root][INFO] - Training Epoch: 2/2, step 13292/16670 completed (loss: 0.2217613011598587, acc: 0.9298245906829834)
[2024-11-14 10:18:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:21][root][INFO] - Training Epoch: 2/2, step 13293/16670 completed (loss: 0.47161927819252014, acc: 0.8999999761581421)
[2024-11-14 10:18:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:22][root][INFO] - Training Epoch: 2/2, step 13294/16670 completed (loss: 0.31713148951530457, acc: 0.9318181872367859)
[2024-11-14 10:18:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:22][root][INFO] - Training Epoch: 2/2, step 13295/16670 completed (loss: 0.40707841515541077, acc: 0.8928571343421936)
[2024-11-14 10:18:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:23][root][INFO] - Training Epoch: 2/2, step 13296/16670 completed (loss: 0.5868329405784607, acc: 0.8571428656578064)
[2024-11-14 10:18:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:23][root][INFO] - Training Epoch: 2/2, step 13297/16670 completed (loss: 0.4309414327144623, acc: 0.8809523582458496)
[2024-11-14 10:18:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:23][root][INFO] - Training Epoch: 2/2, step 13298/16670 completed (loss: 0.5572567582130432, acc: 0.8947368264198303)
[2024-11-14 10:18:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:24][root][INFO] - Training Epoch: 2/2, step 13299/16670 completed (loss: 0.9541463851928711, acc: 0.8111110925674438)
[2024-11-14 10:18:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:24][root][INFO] - Training Epoch: 2/2, step 13300/16670 completed (loss: 0.5722534656524658, acc: 0.8571428656578064)
[2024-11-14 10:18:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:24][root][INFO] - Training Epoch: 2/2, step 13301/16670 completed (loss: 0.6253007054328918, acc: 0.8500000238418579)
[2024-11-14 10:18:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:25][root][INFO] - Training Epoch: 2/2, step 13302/16670 completed (loss: 0.5502563118934631, acc: 0.800000011920929)
[2024-11-14 10:18:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:25][root][INFO] - Training Epoch: 2/2, step 13303/16670 completed (loss: 0.39216622710227966, acc: 0.9195402264595032)
[2024-11-14 10:18:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:25][root][INFO] - Training Epoch: 2/2, step 13304/16670 completed (loss: 0.3522902727127075, acc: 0.8653846383094788)
[2024-11-14 10:18:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:26][root][INFO] - Training Epoch: 2/2, step 13305/16670 completed (loss: 0.898496687412262, acc: 0.7857142686843872)
[2024-11-14 10:18:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:26][root][INFO] - Training Epoch: 2/2, step 13306/16670 completed (loss: 0.2503465414047241, acc: 0.9599999785423279)
[2024-11-14 10:18:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:26][root][INFO] - Training Epoch: 2/2, step 13307/16670 completed (loss: 0.4249620735645294, acc: 0.8717948794364929)
[2024-11-14 10:18:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:27][root][INFO] - Training Epoch: 2/2, step 13308/16670 completed (loss: 0.12944407761096954, acc: 0.978723406791687)
[2024-11-14 10:18:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:27][root][INFO] - Training Epoch: 2/2, step 13309/16670 completed (loss: 1.2483127117156982, acc: 0.8181818127632141)
[2024-11-14 10:18:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:27][root][INFO] - Training Epoch: 2/2, step 13310/16670 completed (loss: 0.24868103861808777, acc: 0.9285714030265808)
[2024-11-14 10:18:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:28][root][INFO] - Training Epoch: 2/2, step 13311/16670 completed (loss: 0.15822243690490723, acc: 0.9487179517745972)
[2024-11-14 10:18:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:28][root][INFO] - Training Epoch: 2/2, step 13312/16670 completed (loss: 0.5671676993370056, acc: 0.8999999761581421)
[2024-11-14 10:18:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:29][root][INFO] - Training Epoch: 2/2, step 13313/16670 completed (loss: 0.4275788366794586, acc: 0.9090909361839294)
[2024-11-14 10:18:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:29][root][INFO] - Training Epoch: 2/2, step 13314/16670 completed (loss: 0.0830749049782753, acc: 0.9777777791023254)
[2024-11-14 10:18:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:29][root][INFO] - Training Epoch: 2/2, step 13315/16670 completed (loss: 0.3517322242259979, acc: 0.9111111164093018)
[2024-11-14 10:18:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:30][root][INFO] - Training Epoch: 2/2, step 13316/16670 completed (loss: 0.5156975984573364, acc: 0.8627451062202454)
[2024-11-14 10:18:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:30][root][INFO] - Training Epoch: 2/2, step 13317/16670 completed (loss: 0.1462496668100357, acc: 0.9599999785423279)
[2024-11-14 10:18:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:30][root][INFO] - Training Epoch: 2/2, step 13318/16670 completed (loss: 0.2419254630804062, acc: 0.9577465057373047)
[2024-11-14 10:18:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:31][root][INFO] - Training Epoch: 2/2, step 13319/16670 completed (loss: 0.44315868616104126, acc: 0.9558823704719543)
[2024-11-14 10:18:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:31][root][INFO] - Training Epoch: 2/2, step 13320/16670 completed (loss: 0.7734856605529785, acc: 0.8305084705352783)
[2024-11-14 10:18:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:31][root][INFO] - Training Epoch: 2/2, step 13321/16670 completed (loss: 0.19912096858024597, acc: 0.942307710647583)
[2024-11-14 10:18:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:32][root][INFO] - Training Epoch: 2/2, step 13322/16670 completed (loss: 0.5519323945045471, acc: 0.8500000238418579)
[2024-11-14 10:18:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:32][root][INFO] - Training Epoch: 2/2, step 13323/16670 completed (loss: 0.7483972311019897, acc: 0.8279569745063782)
[2024-11-14 10:18:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:33][root][INFO] - Training Epoch: 2/2, step 13324/16670 completed (loss: 0.1771121621131897, acc: 0.9615384340286255)
[2024-11-14 10:18:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:33][root][INFO] - Training Epoch: 2/2, step 13325/16670 completed (loss: 0.6476338505744934, acc: 0.8928571343421936)
[2024-11-14 10:18:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:33][root][INFO] - Training Epoch: 2/2, step 13326/16670 completed (loss: 0.6119333505630493, acc: 0.8636363744735718)
[2024-11-14 10:18:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:34][root][INFO] - Training Epoch: 2/2, step 13327/16670 completed (loss: 0.43169745802879333, acc: 0.9333333373069763)
[2024-11-14 10:18:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:34][root][INFO] - Training Epoch: 2/2, step 13328/16670 completed (loss: 1.2095675468444824, acc: 0.8367347121238708)
[2024-11-14 10:18:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:34][root][INFO] - Training Epoch: 2/2, step 13329/16670 completed (loss: 0.9886701703071594, acc: 0.75)
[2024-11-14 10:18:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:35][root][INFO] - Training Epoch: 2/2, step 13330/16670 completed (loss: 0.6041361689567566, acc: 0.8395061492919922)
[2024-11-14 10:18:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:35][root][INFO] - Training Epoch: 2/2, step 13331/16670 completed (loss: 0.15088985860347748, acc: 0.9791666865348816)
[2024-11-14 10:18:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:35][root][INFO] - Training Epoch: 2/2, step 13332/16670 completed (loss: 0.6827229857444763, acc: 0.8857142925262451)
[2024-11-14 10:18:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:36][root][INFO] - Training Epoch: 2/2, step 13333/16670 completed (loss: 0.24422724545001984, acc: 0.9137930870056152)
[2024-11-14 10:18:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:36][root][INFO] - Training Epoch: 2/2, step 13334/16670 completed (loss: 0.28265875577926636, acc: 0.9454545378684998)
[2024-11-14 10:18:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:36][root][INFO] - Training Epoch: 2/2, step 13335/16670 completed (loss: 0.44569772481918335, acc: 0.8507462739944458)
[2024-11-14 10:18:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:37][root][INFO] - Training Epoch: 2/2, step 13336/16670 completed (loss: 0.3195646107196808, acc: 0.8630136847496033)
[2024-11-14 10:18:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:37][root][INFO] - Training Epoch: 2/2, step 13337/16670 completed (loss: 0.5797885060310364, acc: 0.9047619104385376)
[2024-11-14 10:18:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:38][root][INFO] - Training Epoch: 2/2, step 13338/16670 completed (loss: 0.4718828797340393, acc: 0.9016393423080444)
[2024-11-14 10:18:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:38][root][INFO] - Training Epoch: 2/2, step 13339/16670 completed (loss: 0.2935958802700043, acc: 0.8709677457809448)
[2024-11-14 10:18:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:38][root][INFO] - Training Epoch: 2/2, step 13340/16670 completed (loss: 0.2972809672355652, acc: 0.930232584476471)
[2024-11-14 10:18:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:39][root][INFO] - Training Epoch: 2/2, step 13341/16670 completed (loss: 0.43709999322891235, acc: 0.9154929518699646)
[2024-11-14 10:18:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:39][root][INFO] - Training Epoch: 2/2, step 13342/16670 completed (loss: 0.5950953364372253, acc: 0.8717948794364929)
[2024-11-14 10:18:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:39][root][INFO] - Training Epoch: 2/2, step 13343/16670 completed (loss: 0.15240353345870972, acc: 0.9736841917037964)
[2024-11-14 10:18:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:40][root][INFO] - Training Epoch: 2/2, step 13344/16670 completed (loss: 0.4399409890174866, acc: 0.8611111044883728)
[2024-11-14 10:18:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:40][root][INFO] - Training Epoch: 2/2, step 13345/16670 completed (loss: 0.6346089839935303, acc: 0.8260869383811951)
[2024-11-14 10:18:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:40][root][INFO] - Training Epoch: 2/2, step 13346/16670 completed (loss: 1.2282041311264038, acc: 0.75)
[2024-11-14 10:18:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:41][root][INFO] - Training Epoch: 2/2, step 13347/16670 completed (loss: 0.9500221610069275, acc: 0.8048780560493469)
[2024-11-14 10:18:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:41][root][INFO] - Training Epoch: 2/2, step 13348/16670 completed (loss: 0.07522694021463394, acc: 1.0)
[2024-11-14 10:18:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:41][root][INFO] - Training Epoch: 2/2, step 13349/16670 completed (loss: 0.723581850528717, acc: 0.8450704216957092)
[2024-11-14 10:18:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:42][root][INFO] - Training Epoch: 2/2, step 13350/16670 completed (loss: 0.18014536798000336, acc: 0.9756097793579102)
[2024-11-14 10:18:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:42][root][INFO] - Training Epoch: 2/2, step 13351/16670 completed (loss: 0.24438714981079102, acc: 0.95652174949646)
[2024-11-14 10:18:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:43][root][INFO] - Training Epoch: 2/2, step 13352/16670 completed (loss: 0.2549974322319031, acc: 0.9795918464660645)
[2024-11-14 10:18:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:43][root][INFO] - Training Epoch: 2/2, step 13353/16670 completed (loss: 0.6895865201950073, acc: 0.8035714030265808)
[2024-11-14 10:18:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:43][root][INFO] - Training Epoch: 2/2, step 13354/16670 completed (loss: 0.26626965403556824, acc: 0.930232584476471)
[2024-11-14 10:18:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:44][root][INFO] - Training Epoch: 2/2, step 13355/16670 completed (loss: 0.47900646924972534, acc: 0.875)
[2024-11-14 10:18:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:44][root][INFO] - Training Epoch: 2/2, step 13356/16670 completed (loss: 0.4784506559371948, acc: 0.8676470518112183)
[2024-11-14 10:18:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:44][root][INFO] - Training Epoch: 2/2, step 13357/16670 completed (loss: 0.46097373962402344, acc: 0.9047619104385376)
[2024-11-14 10:18:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:45][root][INFO] - Training Epoch: 2/2, step 13358/16670 completed (loss: 0.3579276502132416, acc: 0.9487179517745972)
[2024-11-14 10:18:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:45][root][INFO] - Training Epoch: 2/2, step 13359/16670 completed (loss: 0.46102485060691833, acc: 0.8500000238418579)
[2024-11-14 10:18:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:46][root][INFO] - Training Epoch: 2/2, step 13360/16670 completed (loss: 0.42893850803375244, acc: 0.8510638475418091)
[2024-11-14 10:18:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:46][root][INFO] - Training Epoch: 2/2, step 13361/16670 completed (loss: 0.3770761787891388, acc: 0.8913043737411499)
[2024-11-14 10:18:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:46][root][INFO] - Training Epoch: 2/2, step 13362/16670 completed (loss: 0.40432626008987427, acc: 0.9076923131942749)
[2024-11-14 10:18:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:47][root][INFO] - Training Epoch: 2/2, step 13363/16670 completed (loss: 0.13068439066410065, acc: 0.9545454382896423)
[2024-11-14 10:18:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:47][root][INFO] - Training Epoch: 2/2, step 13364/16670 completed (loss: 0.2569953501224518, acc: 0.9629629850387573)
[2024-11-14 10:18:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:48][root][INFO] - Training Epoch: 2/2, step 13365/16670 completed (loss: 0.10576366633176804, acc: 0.978723406791687)
[2024-11-14 10:18:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:48][root][INFO] - Training Epoch: 2/2, step 13366/16670 completed (loss: 0.4044743776321411, acc: 0.9069767594337463)
[2024-11-14 10:18:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:48][root][INFO] - Training Epoch: 2/2, step 13367/16670 completed (loss: 0.2906036376953125, acc: 0.9242424368858337)
[2024-11-14 10:18:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:49][root][INFO] - Training Epoch: 2/2, step 13368/16670 completed (loss: 0.30729618668556213, acc: 0.9019607901573181)
[2024-11-14 10:18:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:49][root][INFO] - Training Epoch: 2/2, step 13369/16670 completed (loss: 0.1018526703119278, acc: 0.9607843160629272)
[2024-11-14 10:18:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:49][root][INFO] - Training Epoch: 2/2, step 13370/16670 completed (loss: 0.2177155464887619, acc: 0.9473684430122375)
[2024-11-14 10:18:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:50][root][INFO] - Training Epoch: 2/2, step 13371/16670 completed (loss: 0.3344925045967102, acc: 0.925000011920929)
[2024-11-14 10:18:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:50][root][INFO] - Training Epoch: 2/2, step 13372/16670 completed (loss: 0.2988170385360718, acc: 0.931034505367279)
[2024-11-14 10:18:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:50][root][INFO] - Training Epoch: 2/2, step 13373/16670 completed (loss: 1.0651516914367676, acc: 0.7692307829856873)
[2024-11-14 10:18:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:51][root][INFO] - Training Epoch: 2/2, step 13374/16670 completed (loss: 0.13467392325401306, acc: 0.9642857313156128)
[2024-11-14 10:18:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:51][root][INFO] - Training Epoch: 2/2, step 13375/16670 completed (loss: 0.15826646983623505, acc: 0.9577465057373047)
[2024-11-14 10:18:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:51][root][INFO] - Training Epoch: 2/2, step 13376/16670 completed (loss: 0.11457136273384094, acc: 0.9482758641242981)
[2024-11-14 10:18:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:51][root][INFO] - Training Epoch: 2/2, step 13377/16670 completed (loss: 0.5113375782966614, acc: 0.875)
[2024-11-14 10:18:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:52][root][INFO] - Training Epoch: 2/2, step 13378/16670 completed (loss: 0.592369794845581, acc: 0.8823529481887817)
[2024-11-14 10:18:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:52][root][INFO] - Training Epoch: 2/2, step 13379/16670 completed (loss: 0.6184543967247009, acc: 0.8478260636329651)
[2024-11-14 10:18:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:52][root][INFO] - Training Epoch: 2/2, step 13380/16670 completed (loss: 0.7586941719055176, acc: 0.8571428656578064)
[2024-11-14 10:18:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:53][root][INFO] - Training Epoch: 2/2, step 13381/16670 completed (loss: 0.13019397854804993, acc: 0.95652174949646)
[2024-11-14 10:18:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:53][root][INFO] - Training Epoch: 2/2, step 13382/16670 completed (loss: 0.24721042811870575, acc: 0.9420289993286133)
[2024-11-14 10:18:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:54][root][INFO] - Training Epoch: 2/2, step 13383/16670 completed (loss: 0.22022081911563873, acc: 1.0)
[2024-11-14 10:18:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:54][root][INFO] - Training Epoch: 2/2, step 13384/16670 completed (loss: 0.26758894324302673, acc: 0.9375)
[2024-11-14 10:18:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:54][root][INFO] - Training Epoch: 2/2, step 13385/16670 completed (loss: 0.6105683445930481, acc: 0.8793103694915771)
[2024-11-14 10:18:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:55][root][INFO] - Training Epoch: 2/2, step 13386/16670 completed (loss: 0.7373932003974915, acc: 0.8444444537162781)
[2024-11-14 10:18:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:55][root][INFO] - Training Epoch: 2/2, step 13387/16670 completed (loss: 0.41561511158943176, acc: 0.8928571343421936)
[2024-11-14 10:18:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:55][root][INFO] - Training Epoch: 2/2, step 13388/16670 completed (loss: 0.29535967111587524, acc: 0.930232584476471)
[2024-11-14 10:18:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:56][root][INFO] - Training Epoch: 2/2, step 13389/16670 completed (loss: 0.4373129606246948, acc: 0.9142857193946838)
[2024-11-14 10:18:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:56][root][INFO] - Training Epoch: 2/2, step 13390/16670 completed (loss: 0.8204951882362366, acc: 0.8823529481887817)
[2024-11-14 10:18:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:56][root][INFO] - Training Epoch: 2/2, step 13391/16670 completed (loss: 0.0831892266869545, acc: 0.9736841917037964)
[2024-11-14 10:18:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:57][root][INFO] - Training Epoch: 2/2, step 13392/16670 completed (loss: 0.4762628972530365, acc: 0.8857142925262451)
[2024-11-14 10:18:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:57][root][INFO] - Training Epoch: 2/2, step 13393/16670 completed (loss: 0.17176876962184906, acc: 0.9552238583564758)
[2024-11-14 10:18:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:57][root][INFO] - Training Epoch: 2/2, step 13394/16670 completed (loss: 0.14341332018375397, acc: 0.9459459185600281)
[2024-11-14 10:18:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:58][root][INFO] - Training Epoch: 2/2, step 13395/16670 completed (loss: 0.5234876871109009, acc: 0.9322034120559692)
[2024-11-14 10:18:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:58][root][INFO] - Training Epoch: 2/2, step 13396/16670 completed (loss: 0.482181191444397, acc: 0.8833333253860474)
[2024-11-14 10:18:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:58][root][INFO] - Training Epoch: 2/2, step 13397/16670 completed (loss: 0.115413598716259, acc: 0.9599999785423279)
[2024-11-14 10:18:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:59][root][INFO] - Training Epoch: 2/2, step 13398/16670 completed (loss: 0.35662227869033813, acc: 0.8888888955116272)
[2024-11-14 10:18:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:59][root][INFO] - Training Epoch: 2/2, step 13399/16670 completed (loss: 0.5405645370483398, acc: 0.8333333134651184)
[2024-11-14 10:18:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:18:59][root][INFO] - Training Epoch: 2/2, step 13400/16670 completed (loss: 0.9756801128387451, acc: 0.8181818127632141)
[2024-11-14 10:19:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:00][root][INFO] - Training Epoch: 2/2, step 13401/16670 completed (loss: 0.11217112839221954, acc: 0.96875)
[2024-11-14 10:19:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:00][root][INFO] - Training Epoch: 2/2, step 13402/16670 completed (loss: 0.4202810525894165, acc: 0.8787878751754761)
[2024-11-14 10:19:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:01][root][INFO] - Training Epoch: 2/2, step 13403/16670 completed (loss: 0.5175470113754272, acc: 0.8500000238418579)
[2024-11-14 10:19:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:01][root][INFO] - Training Epoch: 2/2, step 13404/16670 completed (loss: 0.7403354048728943, acc: 0.8421052694320679)
[2024-11-14 10:19:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:01][root][INFO] - Training Epoch: 2/2, step 13405/16670 completed (loss: 0.3138342499732971, acc: 0.9210526347160339)
[2024-11-14 10:19:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:01][root][INFO] - Training Epoch: 2/2, step 13406/16670 completed (loss: 0.06308472156524658, acc: 0.9777777791023254)
[2024-11-14 10:19:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:02][root][INFO] - Training Epoch: 2/2, step 13407/16670 completed (loss: 0.5045533776283264, acc: 0.9117646813392639)
[2024-11-14 10:19:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:02][root][INFO] - Training Epoch: 2/2, step 13408/16670 completed (loss: 0.2459360957145691, acc: 0.9701492786407471)
[2024-11-14 10:19:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:03][root][INFO] - Training Epoch: 2/2, step 13409/16670 completed (loss: 0.8605347871780396, acc: 0.837837815284729)
[2024-11-14 10:19:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:03][root][INFO] - Training Epoch: 2/2, step 13410/16670 completed (loss: 0.44981053471565247, acc: 0.9117646813392639)
[2024-11-14 10:19:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:03][root][INFO] - Training Epoch: 2/2, step 13411/16670 completed (loss: 0.5088580846786499, acc: 0.782608687877655)
[2024-11-14 10:19:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:04][root][INFO] - Training Epoch: 2/2, step 13412/16670 completed (loss: 0.5419884920120239, acc: 0.8999999761581421)
[2024-11-14 10:19:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:04][root][INFO] - Training Epoch: 2/2, step 13413/16670 completed (loss: 0.5190978646278381, acc: 0.8636363744735718)
[2024-11-14 10:19:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:04][root][INFO] - Training Epoch: 2/2, step 13414/16670 completed (loss: 0.22867019474506378, acc: 0.9428571462631226)
[2024-11-14 10:19:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:05][root][INFO] - Training Epoch: 2/2, step 13415/16670 completed (loss: 0.3023233115673065, acc: 0.95652174949646)
[2024-11-14 10:19:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:05][root][INFO] - Training Epoch: 2/2, step 13416/16670 completed (loss: 0.33710789680480957, acc: 0.95652174949646)
[2024-11-14 10:19:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:05][root][INFO] - Training Epoch: 2/2, step 13417/16670 completed (loss: 0.3497295677661896, acc: 0.9090909361839294)
[2024-11-14 10:19:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:06][root][INFO] - Training Epoch: 2/2, step 13418/16670 completed (loss: 0.14987605810165405, acc: 0.9444444179534912)
[2024-11-14 10:19:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:06][root][INFO] - Training Epoch: 2/2, step 13419/16670 completed (loss: 0.14367343485355377, acc: 0.95652174949646)
[2024-11-14 10:19:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:06][root][INFO] - Training Epoch: 2/2, step 13420/16670 completed (loss: 0.5157809853553772, acc: 0.8947368264198303)
[2024-11-14 10:19:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:07][root][INFO] - Training Epoch: 2/2, step 13421/16670 completed (loss: 0.3395518958568573, acc: 0.9272727370262146)
[2024-11-14 10:19:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:07][root][INFO] - Training Epoch: 2/2, step 13422/16670 completed (loss: 0.19185678660869598, acc: 0.9454545378684998)
[2024-11-14 10:19:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:07][root][INFO] - Training Epoch: 2/2, step 13423/16670 completed (loss: 0.27090176939964294, acc: 0.9322034120559692)
[2024-11-14 10:19:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:08][root][INFO] - Training Epoch: 2/2, step 13424/16670 completed (loss: 0.5031255483627319, acc: 0.8666666746139526)
[2024-11-14 10:19:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:08][root][INFO] - Training Epoch: 2/2, step 13425/16670 completed (loss: 0.3552806079387665, acc: 0.9433962106704712)
[2024-11-14 10:19:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:08][root][INFO] - Training Epoch: 2/2, step 13426/16670 completed (loss: 0.40681391954421997, acc: 0.9024389982223511)
[2024-11-14 10:19:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:09][root][INFO] - Training Epoch: 2/2, step 13427/16670 completed (loss: 0.46083107590675354, acc: 0.925000011920929)
[2024-11-14 10:19:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:09][root][INFO] - Training Epoch: 2/2, step 13428/16670 completed (loss: 0.3080999553203583, acc: 0.9354838728904724)
[2024-11-14 10:19:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:09][root][INFO] - Training Epoch: 2/2, step 13429/16670 completed (loss: 0.9514918327331543, acc: 0.8399999737739563)
[2024-11-14 10:19:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:10][root][INFO] - Training Epoch: 2/2, step 13430/16670 completed (loss: 0.3806590139865875, acc: 0.8888888955116272)
[2024-11-14 10:19:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:10][root][INFO] - Training Epoch: 2/2, step 13431/16670 completed (loss: 0.24891218543052673, acc: 0.9818181991577148)
[2024-11-14 10:19:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:10][root][INFO] - Training Epoch: 2/2, step 13432/16670 completed (loss: 0.4456125497817993, acc: 0.918367326259613)
[2024-11-14 10:19:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:11][root][INFO] - Training Epoch: 2/2, step 13433/16670 completed (loss: 0.2212323248386383, acc: 0.9259259104728699)
[2024-11-14 10:19:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:11][root][INFO] - Training Epoch: 2/2, step 13434/16670 completed (loss: 0.3335375189781189, acc: 0.8888888955116272)
[2024-11-14 10:19:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:12][root][INFO] - Training Epoch: 2/2, step 13435/16670 completed (loss: 0.5988778471946716, acc: 0.8769230842590332)
[2024-11-14 10:19:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:12][root][INFO] - Training Epoch: 2/2, step 13436/16670 completed (loss: 0.2748706042766571, acc: 0.8837209343910217)
[2024-11-14 10:19:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:12][root][INFO] - Training Epoch: 2/2, step 13437/16670 completed (loss: 0.4607214033603668, acc: 0.837837815284729)
[2024-11-14 10:19:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:13][root][INFO] - Training Epoch: 2/2, step 13438/16670 completed (loss: 0.12123707681894302, acc: 0.9615384340286255)
[2024-11-14 10:19:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:13][root][INFO] - Training Epoch: 2/2, step 13439/16670 completed (loss: 0.3363196551799774, acc: 0.89552241563797)
[2024-11-14 10:19:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:13][root][INFO] - Training Epoch: 2/2, step 13440/16670 completed (loss: 0.709738552570343, acc: 0.8199999928474426)
[2024-11-14 10:19:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:14][root][INFO] - Training Epoch: 2/2, step 13441/16670 completed (loss: 0.21437783539295197, acc: 0.9607843160629272)
[2024-11-14 10:19:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:14][root][INFO] - Training Epoch: 2/2, step 13442/16670 completed (loss: 0.21779777109622955, acc: 0.9166666865348816)
[2024-11-14 10:19:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:14][root][INFO] - Training Epoch: 2/2, step 13443/16670 completed (loss: 0.22775033116340637, acc: 0.970588207244873)
[2024-11-14 10:19:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:15][root][INFO] - Training Epoch: 2/2, step 13444/16670 completed (loss: 0.17680682241916656, acc: 0.9464285969734192)
[2024-11-14 10:19:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:15][root][INFO] - Training Epoch: 2/2, step 13445/16670 completed (loss: 0.6208406686782837, acc: 0.8399999737739563)
[2024-11-14 10:19:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:15][root][INFO] - Training Epoch: 2/2, step 13446/16670 completed (loss: 0.9903479814529419, acc: 0.7419354915618896)
[2024-11-14 10:19:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:16][root][INFO] - Training Epoch: 2/2, step 13447/16670 completed (loss: 0.2694934904575348, acc: 0.939393937587738)
[2024-11-14 10:19:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:16][root][INFO] - Training Epoch: 2/2, step 13448/16670 completed (loss: 0.5419589877128601, acc: 0.8695651888847351)
[2024-11-14 10:19:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:16][root][INFO] - Training Epoch: 2/2, step 13449/16670 completed (loss: 0.3177160918712616, acc: 0.9137930870056152)
[2024-11-14 10:19:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:17][root][INFO] - Training Epoch: 2/2, step 13450/16670 completed (loss: 0.3505684733390808, acc: 0.9230769276618958)
[2024-11-14 10:19:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:17][root][INFO] - Training Epoch: 2/2, step 13451/16670 completed (loss: 0.4438154101371765, acc: 0.8536585569381714)
[2024-11-14 10:19:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:18][root][INFO] - Training Epoch: 2/2, step 13452/16670 completed (loss: 0.24193798005580902, acc: 0.9545454382896423)
[2024-11-14 10:19:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:18][root][INFO] - Training Epoch: 2/2, step 13453/16670 completed (loss: 0.2850171625614166, acc: 0.9464285969734192)
[2024-11-14 10:19:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:18][root][INFO] - Training Epoch: 2/2, step 13454/16670 completed (loss: 0.16516780853271484, acc: 0.925000011920929)
[2024-11-14 10:19:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:19][root][INFO] - Training Epoch: 2/2, step 13455/16670 completed (loss: 0.2850349545478821, acc: 0.936170220375061)
[2024-11-14 10:19:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:19][root][INFO] - Training Epoch: 2/2, step 13456/16670 completed (loss: 1.0869269371032715, acc: 0.8148148059844971)
[2024-11-14 10:19:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:19][root][INFO] - Training Epoch: 2/2, step 13457/16670 completed (loss: 0.23362091183662415, acc: 0.9200000166893005)
[2024-11-14 10:19:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:20][root][INFO] - Training Epoch: 2/2, step 13458/16670 completed (loss: 0.6803281903266907, acc: 0.8928571343421936)
[2024-11-14 10:19:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:20][root][INFO] - Training Epoch: 2/2, step 13459/16670 completed (loss: 1.299780249595642, acc: 0.8260869383811951)
[2024-11-14 10:19:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:20][root][INFO] - Training Epoch: 2/2, step 13460/16670 completed (loss: 0.4633270800113678, acc: 0.9076923131942749)
[2024-11-14 10:19:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:20][root][INFO] - Training Epoch: 2/2, step 13461/16670 completed (loss: 0.2512604594230652, acc: 0.9512194991111755)
[2024-11-14 10:19:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:21][root][INFO] - Training Epoch: 2/2, step 13462/16670 completed (loss: 0.9308026432991028, acc: 0.7894737124443054)
[2024-11-14 10:19:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:21][root][INFO] - Training Epoch: 2/2, step 13463/16670 completed (loss: 0.672884464263916, acc: 0.8333333134651184)
[2024-11-14 10:19:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:21][root][INFO] - Training Epoch: 2/2, step 13464/16670 completed (loss: 0.6184026002883911, acc: 0.8392857313156128)
[2024-11-14 10:19:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:22][root][INFO] - Training Epoch: 2/2, step 13465/16670 completed (loss: 0.6893447637557983, acc: 0.8666666746139526)
[2024-11-14 10:19:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:22][root][INFO] - Training Epoch: 2/2, step 13466/16670 completed (loss: 0.36668169498443604, acc: 0.9428571462631226)
[2024-11-14 10:19:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:22][root][INFO] - Training Epoch: 2/2, step 13467/16670 completed (loss: 0.25836366415023804, acc: 0.9152542352676392)
[2024-11-14 10:19:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:23][root][INFO] - Training Epoch: 2/2, step 13468/16670 completed (loss: 0.2844064235687256, acc: 0.9047619104385376)
[2024-11-14 10:19:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:23][root][INFO] - Training Epoch: 2/2, step 13469/16670 completed (loss: 0.7029348015785217, acc: 0.8039215803146362)
[2024-11-14 10:19:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:23][root][INFO] - Training Epoch: 2/2, step 13470/16670 completed (loss: 2.7483224868774414, acc: 0.6911764740943909)
[2024-11-14 10:19:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:24][root][INFO] - Training Epoch: 2/2, step 13471/16670 completed (loss: 0.390573114156723, acc: 0.8999999761581421)
[2024-11-14 10:19:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:24][root][INFO] - Training Epoch: 2/2, step 13472/16670 completed (loss: 0.5915929079055786, acc: 0.8292682766914368)
[2024-11-14 10:19:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:24][root][INFO] - Training Epoch: 2/2, step 13473/16670 completed (loss: 0.3757789433002472, acc: 0.9038461446762085)
[2024-11-14 10:19:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:25][root][INFO] - Training Epoch: 2/2, step 13474/16670 completed (loss: 0.0509064681828022, acc: 1.0)
[2024-11-14 10:19:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:25][root][INFO] - Training Epoch: 2/2, step 13475/16670 completed (loss: 0.8967275023460388, acc: 0.8333333134651184)
[2024-11-14 10:19:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:25][root][INFO] - Training Epoch: 2/2, step 13476/16670 completed (loss: 0.4344213306903839, acc: 0.859649121761322)
[2024-11-14 10:19:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:26][root][INFO] - Training Epoch: 2/2, step 13477/16670 completed (loss: 0.4506768584251404, acc: 0.8518518805503845)
[2024-11-14 10:19:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:26][root][INFO] - Training Epoch: 2/2, step 13478/16670 completed (loss: 0.5226644277572632, acc: 0.8837209343910217)
[2024-11-14 10:19:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:26][root][INFO] - Training Epoch: 2/2, step 13479/16670 completed (loss: 0.3734256625175476, acc: 0.9137930870056152)
[2024-11-14 10:19:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:27][root][INFO] - Training Epoch: 2/2, step 13480/16670 completed (loss: 0.44062918424606323, acc: 0.9142857193946838)
[2024-11-14 10:19:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:27][root][INFO] - Training Epoch: 2/2, step 13481/16670 completed (loss: 0.9140792489051819, acc: 0.7692307829856873)
[2024-11-14 10:19:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:27][root][INFO] - Training Epoch: 2/2, step 13482/16670 completed (loss: 0.6303878426551819, acc: 0.8474576473236084)
[2024-11-14 10:19:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:28][root][INFO] - Training Epoch: 2/2, step 13483/16670 completed (loss: 0.5642032027244568, acc: 0.8666666746139526)
[2024-11-14 10:19:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:28][root][INFO] - Training Epoch: 2/2, step 13484/16670 completed (loss: 0.3078109323978424, acc: 0.921875)
[2024-11-14 10:19:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:28][root][INFO] - Training Epoch: 2/2, step 13485/16670 completed (loss: 0.820683479309082, acc: 0.7435897588729858)
[2024-11-14 10:19:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:29][root][INFO] - Training Epoch: 2/2, step 13486/16670 completed (loss: 0.583411693572998, acc: 0.8695651888847351)
[2024-11-14 10:19:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:29][root][INFO] - Training Epoch: 2/2, step 13487/16670 completed (loss: 0.515373170375824, acc: 0.8591549396514893)
[2024-11-14 10:19:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:30][root][INFO] - Training Epoch: 2/2, step 13488/16670 completed (loss: 0.49073442816734314, acc: 0.8730158805847168)
[2024-11-14 10:19:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:30][root][INFO] - Training Epoch: 2/2, step 13489/16670 completed (loss: 0.28759709000587463, acc: 0.9230769276618958)
[2024-11-14 10:19:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:30][root][INFO] - Training Epoch: 2/2, step 13490/16670 completed (loss: 0.7696231603622437, acc: 0.9090909361839294)
[2024-11-14 10:19:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:31][root][INFO] - Training Epoch: 2/2, step 13491/16670 completed (loss: 0.8707786798477173, acc: 0.8695651888847351)
[2024-11-14 10:19:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:31][root][INFO] - Training Epoch: 2/2, step 13492/16670 completed (loss: 0.35464730858802795, acc: 0.8958333134651184)
[2024-11-14 10:19:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:31][root][INFO] - Training Epoch: 2/2, step 13493/16670 completed (loss: 0.7255144715309143, acc: 0.8478260636329651)
[2024-11-14 10:19:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:32][root][INFO] - Training Epoch: 2/2, step 13494/16670 completed (loss: 0.3033805191516876, acc: 0.938144326210022)
[2024-11-14 10:19:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:32][root][INFO] - Training Epoch: 2/2, step 13495/16670 completed (loss: 0.43195968866348267, acc: 0.9411764740943909)
[2024-11-14 10:19:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:32][root][INFO] - Training Epoch: 2/2, step 13496/16670 completed (loss: 0.8612566590309143, acc: 0.8148148059844971)
[2024-11-14 10:19:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:33][root][INFO] - Training Epoch: 2/2, step 13497/16670 completed (loss: 0.10568280518054962, acc: 1.0)
[2024-11-14 10:19:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:33][root][INFO] - Training Epoch: 2/2, step 13498/16670 completed (loss: 0.6946818232536316, acc: 0.8484848737716675)
[2024-11-14 10:19:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:33][root][INFO] - Training Epoch: 2/2, step 13499/16670 completed (loss: 0.3295867443084717, acc: 0.9245283007621765)
[2024-11-14 10:19:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:34][root][INFO] - Training Epoch: 2/2, step 13500/16670 completed (loss: 0.3617079257965088, acc: 0.9166666865348816)
[2024-11-14 10:19:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:34][root][INFO] - Training Epoch: 2/2, step 13501/16670 completed (loss: 0.5857390761375427, acc: 0.8518518805503845)
[2024-11-14 10:19:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:34][root][INFO] - Training Epoch: 2/2, step 13502/16670 completed (loss: 0.9307904839515686, acc: 0.7714285850524902)
[2024-11-14 10:19:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:35][root][INFO] - Training Epoch: 2/2, step 13503/16670 completed (loss: 0.5424415469169617, acc: 0.8888888955116272)
[2024-11-14 10:19:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:35][root][INFO] - Training Epoch: 2/2, step 13504/16670 completed (loss: 0.24088236689567566, acc: 0.9333333373069763)
[2024-11-14 10:19:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:35][root][INFO] - Training Epoch: 2/2, step 13505/16670 completed (loss: 0.5102229714393616, acc: 0.8888888955116272)
[2024-11-14 10:19:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:36][root][INFO] - Training Epoch: 2/2, step 13506/16670 completed (loss: 0.5562434792518616, acc: 0.8441558480262756)
[2024-11-14 10:19:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:36][root][INFO] - Training Epoch: 2/2, step 13507/16670 completed (loss: 0.2611081004142761, acc: 0.9166666865348816)
[2024-11-14 10:19:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:36][root][INFO] - Training Epoch: 2/2, step 13508/16670 completed (loss: 0.6332002282142639, acc: 0.8636363744735718)
[2024-11-14 10:19:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:37][root][INFO] - Training Epoch: 2/2, step 13509/16670 completed (loss: 0.795064389705658, acc: 0.8518518805503845)
[2024-11-14 10:19:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:37][root][INFO] - Training Epoch: 2/2, step 13510/16670 completed (loss: 0.305582195520401, acc: 0.9411764740943909)
[2024-11-14 10:19:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:37][root][INFO] - Training Epoch: 2/2, step 13511/16670 completed (loss: 0.2889557182788849, acc: 0.9120879173278809)
[2024-11-14 10:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:38][root][INFO] - Training Epoch: 2/2, step 13512/16670 completed (loss: 0.9629234671592712, acc: 0.8148148059844971)
[2024-11-14 10:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:38][root][INFO] - Training Epoch: 2/2, step 13513/16670 completed (loss: 0.5623751878738403, acc: 0.8507462739944458)
[2024-11-14 10:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:38][root][INFO] - Training Epoch: 2/2, step 13514/16670 completed (loss: 1.2172248363494873, acc: 0.7857142686843872)
[2024-11-14 10:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:39][root][INFO] - Training Epoch: 2/2, step 13515/16670 completed (loss: 0.313968688249588, acc: 0.9130434989929199)
[2024-11-14 10:19:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:39][root][INFO] - Training Epoch: 2/2, step 13516/16670 completed (loss: 0.4197814464569092, acc: 0.875)
[2024-11-14 10:19:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:39][root][INFO] - Training Epoch: 2/2, step 13517/16670 completed (loss: 0.38633280992507935, acc: 0.9166666865348816)
[2024-11-14 10:19:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:40][root][INFO] - Training Epoch: 2/2, step 13518/16670 completed (loss: 0.5409579873085022, acc: 0.8571428656578064)
[2024-11-14 10:19:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:40][root][INFO] - Training Epoch: 2/2, step 13519/16670 completed (loss: 0.5420240163803101, acc: 0.8679245114326477)
[2024-11-14 10:19:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:40][root][INFO] - Training Epoch: 2/2, step 13520/16670 completed (loss: 0.482962429523468, acc: 0.8620689511299133)
[2024-11-14 10:19:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:41][root][INFO] - Training Epoch: 2/2, step 13521/16670 completed (loss: 0.130620077252388, acc: 0.9591836929321289)
[2024-11-14 10:19:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:41][root][INFO] - Training Epoch: 2/2, step 13522/16670 completed (loss: 0.38252028822898865, acc: 0.8695651888847351)
[2024-11-14 10:19:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:41][root][INFO] - Training Epoch: 2/2, step 13523/16670 completed (loss: 0.6115689277648926, acc: 0.8450704216957092)
[2024-11-14 10:19:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:42][root][INFO] - Training Epoch: 2/2, step 13524/16670 completed (loss: 0.979047417640686, acc: 0.800000011920929)
[2024-11-14 10:19:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:42][root][INFO] - Training Epoch: 2/2, step 13525/16670 completed (loss: 1.061345100402832, acc: 0.8536585569381714)
[2024-11-14 10:19:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:42][root][INFO] - Training Epoch: 2/2, step 13526/16670 completed (loss: 1.011313557624817, acc: 0.796875)
[2024-11-14 10:19:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:43][root][INFO] - Training Epoch: 2/2, step 13527/16670 completed (loss: 0.4370271563529968, acc: 0.9130434989929199)
[2024-11-14 10:19:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:43][root][INFO] - Training Epoch: 2/2, step 13528/16670 completed (loss: 0.21519719064235687, acc: 0.9411764740943909)
[2024-11-14 10:19:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:43][root][INFO] - Training Epoch: 2/2, step 13529/16670 completed (loss: 0.800542950630188, acc: 0.807692289352417)
[2024-11-14 10:19:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:43][root][INFO] - Training Epoch: 2/2, step 13530/16670 completed (loss: 1.269650936126709, acc: 0.7058823704719543)
[2024-11-14 10:19:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:44][root][INFO] - Training Epoch: 2/2, step 13531/16670 completed (loss: 0.43901771306991577, acc: 0.9433962106704712)
[2024-11-14 10:19:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:44][root][INFO] - Training Epoch: 2/2, step 13532/16670 completed (loss: 0.4067383408546448, acc: 0.8548387289047241)
[2024-11-14 10:19:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:44][root][INFO] - Training Epoch: 2/2, step 13533/16670 completed (loss: 0.5300644636154175, acc: 0.8809523582458496)
[2024-11-14 10:19:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:45][root][INFO] - Training Epoch: 2/2, step 13534/16670 completed (loss: 0.959620475769043, acc: 0.7936508059501648)
[2024-11-14 10:19:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:45][root][INFO] - Training Epoch: 2/2, step 13535/16670 completed (loss: 0.7911814451217651, acc: 0.8181818127632141)
[2024-11-14 10:19:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:45][root][INFO] - Training Epoch: 2/2, step 13536/16670 completed (loss: 0.5513955354690552, acc: 0.7894737124443054)
[2024-11-14 10:19:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:46][root][INFO] - Training Epoch: 2/2, step 13537/16670 completed (loss: 0.6135880351066589, acc: 0.8723404407501221)
[2024-11-14 10:19:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:46][root][INFO] - Training Epoch: 2/2, step 13538/16670 completed (loss: 0.5187890529632568, acc: 0.8974359035491943)
[2024-11-14 10:19:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:46][root][INFO] - Training Epoch: 2/2, step 13539/16670 completed (loss: 0.5203028917312622, acc: 0.9272727370262146)
[2024-11-14 10:19:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:47][root][INFO] - Training Epoch: 2/2, step 13540/16670 completed (loss: 0.6750476956367493, acc: 0.9012345671653748)
[2024-11-14 10:19:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:47][root][INFO] - Training Epoch: 2/2, step 13541/16670 completed (loss: 0.691978931427002, acc: 0.8554216623306274)
[2024-11-14 10:19:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:47][root][INFO] - Training Epoch: 2/2, step 13542/16670 completed (loss: 0.2376478910446167, acc: 0.936170220375061)
[2024-11-14 10:19:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:48][root][INFO] - Training Epoch: 2/2, step 13543/16670 completed (loss: 0.4332922101020813, acc: 0.931034505367279)
[2024-11-14 10:19:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:48][root][INFO] - Training Epoch: 2/2, step 13544/16670 completed (loss: 0.4164848327636719, acc: 0.8857142925262451)
[2024-11-14 10:19:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:48][root][INFO] - Training Epoch: 2/2, step 13545/16670 completed (loss: 0.8231748342514038, acc: 0.75)
[2024-11-14 10:19:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:48][root][INFO] - Training Epoch: 2/2, step 13546/16670 completed (loss: 0.5825715661048889, acc: 0.800000011920929)
[2024-11-14 10:19:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:49][root][INFO] - Training Epoch: 2/2, step 13547/16670 completed (loss: 1.5748101472854614, acc: 0.6666666865348816)
[2024-11-14 10:19:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:49][root][INFO] - Training Epoch: 2/2, step 13548/16670 completed (loss: 0.36490440368652344, acc: 0.8999999761581421)
[2024-11-14 10:19:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:49][root][INFO] - Training Epoch: 2/2, step 13549/16670 completed (loss: 0.3451651930809021, acc: 0.8947368264198303)
[2024-11-14 10:19:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:50][root][INFO] - Training Epoch: 2/2, step 13550/16670 completed (loss: 0.2454303652048111, acc: 0.9814814925193787)
[2024-11-14 10:19:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:50][root][INFO] - Training Epoch: 2/2, step 13551/16670 completed (loss: 0.18238836526870728, acc: 0.9696969985961914)
[2024-11-14 10:19:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:50][root][INFO] - Training Epoch: 2/2, step 13552/16670 completed (loss: 0.7428380846977234, acc: 0.875)
[2024-11-14 10:19:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:51][root][INFO] - Training Epoch: 2/2, step 13553/16670 completed (loss: 1.0310251712799072, acc: 0.7924528121948242)
[2024-11-14 10:19:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:51][root][INFO] - Training Epoch: 2/2, step 13554/16670 completed (loss: 0.7396760582923889, acc: 0.7894737124443054)
[2024-11-14 10:19:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:51][root][INFO] - Training Epoch: 2/2, step 13555/16670 completed (loss: 0.2512899339199066, acc: 0.9230769276618958)
[2024-11-14 10:19:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:52][root][INFO] - Training Epoch: 2/2, step 13556/16670 completed (loss: 2.6694889068603516, acc: 0.5890411138534546)
[2024-11-14 10:19:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:52][root][INFO] - Training Epoch: 2/2, step 13557/16670 completed (loss: 0.38794687390327454, acc: 0.9074074029922485)
[2024-11-14 10:19:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:52][root][INFO] - Training Epoch: 2/2, step 13558/16670 completed (loss: 0.31543028354644775, acc: 0.9230769276618958)
[2024-11-14 10:19:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:53][root][INFO] - Training Epoch: 2/2, step 13559/16670 completed (loss: 0.28072038292884827, acc: 0.9433962106704712)
[2024-11-14 10:19:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:53][root][INFO] - Training Epoch: 2/2, step 13560/16670 completed (loss: 0.8002623915672302, acc: 0.8039215803146362)
[2024-11-14 10:19:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:53][root][INFO] - Training Epoch: 2/2, step 13561/16670 completed (loss: 0.6115622520446777, acc: 0.8301886916160583)
[2024-11-14 10:19:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:54][root][INFO] - Training Epoch: 2/2, step 13562/16670 completed (loss: 1.1163969039916992, acc: 0.782608687877655)
[2024-11-14 10:19:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:54][root][INFO] - Training Epoch: 2/2, step 13563/16670 completed (loss: 0.7421624064445496, acc: 0.84375)
[2024-11-14 10:19:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:54][root][INFO] - Training Epoch: 2/2, step 13564/16670 completed (loss: 0.44096946716308594, acc: 0.8965517282485962)
[2024-11-14 10:19:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:54][root][INFO] - Training Epoch: 2/2, step 13565/16670 completed (loss: 0.5481598377227783, acc: 0.9024389982223511)
[2024-11-14 10:19:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:55][root][INFO] - Training Epoch: 2/2, step 13566/16670 completed (loss: 1.2271159887313843, acc: 0.7894737124443054)
[2024-11-14 10:19:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:55][root][INFO] - Training Epoch: 2/2, step 13567/16670 completed (loss: 0.6993306875228882, acc: 0.8358209133148193)
[2024-11-14 10:19:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:55][root][INFO] - Training Epoch: 2/2, step 13568/16670 completed (loss: 0.10839804261922836, acc: 0.9649122953414917)
[2024-11-14 10:19:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:56][root][INFO] - Training Epoch: 2/2, step 13569/16670 completed (loss: 0.40466779470443726, acc: 0.9125000238418579)
[2024-11-14 10:19:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:56][root][INFO] - Training Epoch: 2/2, step 13570/16670 completed (loss: 0.6469019055366516, acc: 0.8399999737739563)
[2024-11-14 10:19:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:56][root][INFO] - Training Epoch: 2/2, step 13571/16670 completed (loss: 0.8524762392044067, acc: 0.800000011920929)
[2024-11-14 10:19:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:57][root][INFO] - Training Epoch: 2/2, step 13572/16670 completed (loss: 0.4325864613056183, acc: 0.9041095972061157)
[2024-11-14 10:19:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:57][root][INFO] - Training Epoch: 2/2, step 13573/16670 completed (loss: 0.7412037253379822, acc: 0.8139534592628479)
[2024-11-14 10:19:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:57][root][INFO] - Training Epoch: 2/2, step 13574/16670 completed (loss: 0.546942412853241, acc: 0.8732394576072693)
[2024-11-14 10:19:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:58][root][INFO] - Training Epoch: 2/2, step 13575/16670 completed (loss: 0.1286853551864624, acc: 0.9696969985961914)
[2024-11-14 10:19:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:58][root][INFO] - Training Epoch: 2/2, step 13576/16670 completed (loss: 0.6709439158439636, acc: 0.9019607901573181)
[2024-11-14 10:19:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:58][root][INFO] - Training Epoch: 2/2, step 13577/16670 completed (loss: 0.5083613991737366, acc: 0.8823529481887817)
[2024-11-14 10:19:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:59][root][INFO] - Training Epoch: 2/2, step 13578/16670 completed (loss: 0.8281996250152588, acc: 0.8181818127632141)
[2024-11-14 10:19:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:59][root][INFO] - Training Epoch: 2/2, step 13579/16670 completed (loss: 0.5829122066497803, acc: 0.9166666865348816)
[2024-11-14 10:19:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:59][root][INFO] - Training Epoch: 2/2, step 13580/16670 completed (loss: 0.3106420040130615, acc: 0.9210526347160339)
[2024-11-14 10:19:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:19:59][root][INFO] - Training Epoch: 2/2, step 13581/16670 completed (loss: 0.18728703260421753, acc: 0.9736841917037964)
[2024-11-14 10:20:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:00][root][INFO] - Training Epoch: 2/2, step 13582/16670 completed (loss: 0.49551284313201904, acc: 0.8823529481887817)
[2024-11-14 10:20:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:00][root][INFO] - Training Epoch: 2/2, step 13583/16670 completed (loss: 0.41289806365966797, acc: 0.9714285731315613)
[2024-11-14 10:20:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:00][root][INFO] - Training Epoch: 2/2, step 13584/16670 completed (loss: 0.2227553278207779, acc: 0.9538461565971375)
[2024-11-14 10:20:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:01][root][INFO] - Training Epoch: 2/2, step 13585/16670 completed (loss: 0.2584710717201233, acc: 0.9333333373069763)
[2024-11-14 10:20:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:01][root][INFO] - Training Epoch: 2/2, step 13586/16670 completed (loss: 0.424273818731308, acc: 0.8571428656578064)
[2024-11-14 10:20:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:01][root][INFO] - Training Epoch: 2/2, step 13587/16670 completed (loss: 1.4564452171325684, acc: 0.7567567825317383)
[2024-11-14 10:20:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:02][root][INFO] - Training Epoch: 2/2, step 13588/16670 completed (loss: 0.8513433933258057, acc: 0.8275862336158752)
[2024-11-14 10:20:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:02][root][INFO] - Training Epoch: 2/2, step 13589/16670 completed (loss: 1.041522741317749, acc: 0.7083333134651184)
[2024-11-14 10:20:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:02][root][INFO] - Training Epoch: 2/2, step 13590/16670 completed (loss: 0.4067702889442444, acc: 0.8867924809455872)
[2024-11-14 10:20:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:03][root][INFO] - Training Epoch: 2/2, step 13591/16670 completed (loss: 0.5101918578147888, acc: 0.8714285492897034)
[2024-11-14 10:20:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:03][root][INFO] - Training Epoch: 2/2, step 13592/16670 completed (loss: 0.23652292788028717, acc: 0.942307710647583)
[2024-11-14 10:20:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:03][root][INFO] - Training Epoch: 2/2, step 13593/16670 completed (loss: 0.7279611229896545, acc: 0.8888888955116272)
[2024-11-14 10:20:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:04][root][INFO] - Training Epoch: 2/2, step 13594/16670 completed (loss: 0.39574602246284485, acc: 0.8387096524238586)
[2024-11-14 10:20:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:04][root][INFO] - Training Epoch: 2/2, step 13595/16670 completed (loss: 0.227183535695076, acc: 0.8888888955116272)
[2024-11-14 10:20:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:04][root][INFO] - Training Epoch: 2/2, step 13596/16670 completed (loss: 1.0550652742385864, acc: 0.8627451062202454)
[2024-11-14 10:20:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:05][root][INFO] - Training Epoch: 2/2, step 13597/16670 completed (loss: 0.15879561007022858, acc: 0.9333333373069763)
[2024-11-14 10:20:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:05][root][INFO] - Training Epoch: 2/2, step 13598/16670 completed (loss: 0.7201168537139893, acc: 0.8600000143051147)
[2024-11-14 10:20:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:05][root][INFO] - Training Epoch: 2/2, step 13599/16670 completed (loss: 0.5578490495681763, acc: 0.9354838728904724)
[2024-11-14 10:20:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:06][root][INFO] - Training Epoch: 2/2, step 13600/16670 completed (loss: 0.5422058701515198, acc: 0.8888888955116272)
[2024-11-14 10:20:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:06][root][INFO] - Training Epoch: 2/2, step 13601/16670 completed (loss: 0.38261064887046814, acc: 0.8571428656578064)
[2024-11-14 10:20:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:06][root][INFO] - Training Epoch: 2/2, step 13602/16670 completed (loss: 0.28177016973495483, acc: 0.9074074029922485)
[2024-11-14 10:20:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:07][root][INFO] - Training Epoch: 2/2, step 13603/16670 completed (loss: 0.5473796725273132, acc: 0.9069767594337463)
[2024-11-14 10:20:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:07][root][INFO] - Training Epoch: 2/2, step 13604/16670 completed (loss: 0.2730996906757355, acc: 0.9454545378684998)
[2024-11-14 10:20:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:07][root][INFO] - Training Epoch: 2/2, step 13605/16670 completed (loss: 0.4125189781188965, acc: 0.9090909361839294)
[2024-11-14 10:20:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:08][root][INFO] - Training Epoch: 2/2, step 13606/16670 completed (loss: 0.8583211898803711, acc: 0.8181818127632141)
[2024-11-14 10:20:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:08][root][INFO] - Training Epoch: 2/2, step 13607/16670 completed (loss: 0.6813486814498901, acc: 0.8500000238418579)
[2024-11-14 10:20:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:08][root][INFO] - Training Epoch: 2/2, step 13608/16670 completed (loss: 0.805552065372467, acc: 0.843137264251709)
[2024-11-14 10:20:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:09][root][INFO] - Training Epoch: 2/2, step 13609/16670 completed (loss: 1.2047173976898193, acc: 0.7647058963775635)
[2024-11-14 10:20:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:09][root][INFO] - Training Epoch: 2/2, step 13610/16670 completed (loss: 0.23637810349464417, acc: 0.9333333373069763)
[2024-11-14 10:20:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:10][root][INFO] - Training Epoch: 2/2, step 13611/16670 completed (loss: 0.49276867508888245, acc: 0.8615384697914124)
[2024-11-14 10:20:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:10][root][INFO] - Training Epoch: 2/2, step 13612/16670 completed (loss: 1.2945407629013062, acc: 0.7575757503509521)
[2024-11-14 10:20:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:10][root][INFO] - Training Epoch: 2/2, step 13613/16670 completed (loss: 1.3428027629852295, acc: 0.699999988079071)
[2024-11-14 10:20:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:11][root][INFO] - Training Epoch: 2/2, step 13614/16670 completed (loss: 0.3661978244781494, acc: 0.8857142925262451)
[2024-11-14 10:20:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:11][root][INFO] - Training Epoch: 2/2, step 13615/16670 completed (loss: 0.5647745132446289, acc: 0.8450704216957092)
[2024-11-14 10:20:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:11][root][INFO] - Training Epoch: 2/2, step 13616/16670 completed (loss: 0.6466139554977417, acc: 0.9090909361839294)
[2024-11-14 10:20:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:12][root][INFO] - Training Epoch: 2/2, step 13617/16670 completed (loss: 0.663108229637146, acc: 0.8199999928474426)
[2024-11-14 10:20:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:12][root][INFO] - Training Epoch: 2/2, step 13618/16670 completed (loss: 0.41631749272346497, acc: 0.8909090757369995)
[2024-11-14 10:20:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:12][root][INFO] - Training Epoch: 2/2, step 13619/16670 completed (loss: 1.0753899812698364, acc: 0.7799999713897705)
[2024-11-14 10:20:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:13][root][INFO] - Training Epoch: 2/2, step 13620/16670 completed (loss: 0.3871142566204071, acc: 0.9523809552192688)
[2024-11-14 10:20:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:13][root][INFO] - Training Epoch: 2/2, step 13621/16670 completed (loss: 0.9447447061538696, acc: 0.7727272510528564)
[2024-11-14 10:20:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:13][root][INFO] - Training Epoch: 2/2, step 13622/16670 completed (loss: 0.36438268423080444, acc: 0.9107142686843872)
[2024-11-14 10:20:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:14][root][INFO] - Training Epoch: 2/2, step 13623/16670 completed (loss: 0.8450168967247009, acc: 0.8125)
[2024-11-14 10:20:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:14][root][INFO] - Training Epoch: 2/2, step 13624/16670 completed (loss: 0.40473705530166626, acc: 0.9047619104385376)
[2024-11-14 10:20:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:14][root][INFO] - Training Epoch: 2/2, step 13625/16670 completed (loss: 0.2419009506702423, acc: 0.9375)
[2024-11-14 10:20:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:15][root][INFO] - Training Epoch: 2/2, step 13626/16670 completed (loss: 0.4601958096027374, acc: 0.8846153616905212)
[2024-11-14 10:20:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:15][root][INFO] - Training Epoch: 2/2, step 13627/16670 completed (loss: 0.5051679611206055, acc: 0.9142857193946838)
[2024-11-14 10:20:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:15][root][INFO] - Training Epoch: 2/2, step 13628/16670 completed (loss: 0.362976998090744, acc: 0.914893627166748)
[2024-11-14 10:20:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:16][root][INFO] - Training Epoch: 2/2, step 13629/16670 completed (loss: 3.4837183952331543, acc: 0.446153849363327)
[2024-11-14 10:20:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:16][root][INFO] - Training Epoch: 2/2, step 13630/16670 completed (loss: 0.7235627174377441, acc: 0.8600000143051147)
[2024-11-14 10:20:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:16][root][INFO] - Training Epoch: 2/2, step 13631/16670 completed (loss: 0.6152995228767395, acc: 0.9411764740943909)
[2024-11-14 10:20:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:17][root][INFO] - Training Epoch: 2/2, step 13632/16670 completed (loss: 0.3845725953578949, acc: 0.8823529481887817)
[2024-11-14 10:20:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:17][root][INFO] - Training Epoch: 2/2, step 13633/16670 completed (loss: 0.21408633887767792, acc: 0.9599999785423279)
[2024-11-14 10:20:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:17][root][INFO] - Training Epoch: 2/2, step 13634/16670 completed (loss: 0.4131057560443878, acc: 0.9014084339141846)
[2024-11-14 10:20:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:18][root][INFO] - Training Epoch: 2/2, step 13635/16670 completed (loss: 1.1681382656097412, acc: 0.7627118825912476)
[2024-11-14 10:20:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:18][root][INFO] - Training Epoch: 2/2, step 13636/16670 completed (loss: 0.41892728209495544, acc: 0.914893627166748)
[2024-11-14 10:20:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:19][root][INFO] - Training Epoch: 2/2, step 13637/16670 completed (loss: 0.4752346873283386, acc: 0.9056603908538818)
[2024-11-14 10:20:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:19][root][INFO] - Training Epoch: 2/2, step 13638/16670 completed (loss: 0.637211799621582, acc: 0.8409090638160706)
[2024-11-14 10:20:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:19][root][INFO] - Training Epoch: 2/2, step 13639/16670 completed (loss: 1.009153962135315, acc: 0.7962962985038757)
[2024-11-14 10:20:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:20][root][INFO] - Training Epoch: 2/2, step 13640/16670 completed (loss: 0.5776050686836243, acc: 0.7916666865348816)
[2024-11-14 10:20:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:20][root][INFO] - Training Epoch: 2/2, step 13641/16670 completed (loss: 0.3573313355445862, acc: 0.8500000238418579)
[2024-11-14 10:20:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:20][root][INFO] - Training Epoch: 2/2, step 13642/16670 completed (loss: 0.387889564037323, acc: 0.8888888955116272)
[2024-11-14 10:20:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:21][root][INFO] - Training Epoch: 2/2, step 13643/16670 completed (loss: 0.6326122879981995, acc: 0.8723404407501221)
[2024-11-14 10:20:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:21][root][INFO] - Training Epoch: 2/2, step 13644/16670 completed (loss: 0.28163453936576843, acc: 0.9166666865348816)
[2024-11-14 10:20:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:21][root][INFO] - Training Epoch: 2/2, step 13645/16670 completed (loss: 0.20993085205554962, acc: 0.9473684430122375)
[2024-11-14 10:20:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:22][root][INFO] - Training Epoch: 2/2, step 13646/16670 completed (loss: 0.2861732244491577, acc: 0.9041095972061157)
[2024-11-14 10:20:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:22][root][INFO] - Training Epoch: 2/2, step 13647/16670 completed (loss: 0.7490249276161194, acc: 0.8974359035491943)
[2024-11-14 10:20:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:22][root][INFO] - Training Epoch: 2/2, step 13648/16670 completed (loss: 0.21353057026863098, acc: 0.9677419066429138)
[2024-11-14 10:20:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:23][root][INFO] - Training Epoch: 2/2, step 13649/16670 completed (loss: 0.8855552077293396, acc: 0.7903226017951965)
[2024-11-14 10:20:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:23][root][INFO] - Training Epoch: 2/2, step 13650/16670 completed (loss: 0.34533679485321045, acc: 0.9444444179534912)
[2024-11-14 10:20:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:24][root][INFO] - Training Epoch: 2/2, step 13651/16670 completed (loss: 0.801245391368866, acc: 0.8222222328186035)
[2024-11-14 10:20:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:24][root][INFO] - Training Epoch: 2/2, step 13652/16670 completed (loss: 3.031632423400879, acc: 0.6000000238418579)
[2024-11-14 10:20:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:24][root][INFO] - Training Epoch: 2/2, step 13653/16670 completed (loss: 0.3693206310272217, acc: 0.8958333134651184)
[2024-11-14 10:20:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:25][root][INFO] - Training Epoch: 2/2, step 13654/16670 completed (loss: 0.19560714066028595, acc: 0.9130434989929199)
[2024-11-14 10:20:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:25][root][INFO] - Training Epoch: 2/2, step 13655/16670 completed (loss: 0.2343180775642395, acc: 0.957446813583374)
[2024-11-14 10:20:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:25][root][INFO] - Training Epoch: 2/2, step 13656/16670 completed (loss: 0.19246819615364075, acc: 0.95652174949646)
[2024-11-14 10:20:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:26][root][INFO] - Training Epoch: 2/2, step 13657/16670 completed (loss: 1.4301788806915283, acc: 0.7692307829856873)
[2024-11-14 10:20:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:26][root][INFO] - Training Epoch: 2/2, step 13658/16670 completed (loss: 0.4965449571609497, acc: 0.8799999952316284)
[2024-11-14 10:20:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:26][root][INFO] - Training Epoch: 2/2, step 13659/16670 completed (loss: 0.6654677391052246, acc: 0.8372092843055725)
[2024-11-14 10:20:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:27][root][INFO] - Training Epoch: 2/2, step 13660/16670 completed (loss: 0.4508114159107208, acc: 0.931034505367279)
[2024-11-14 10:20:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:27][root][INFO] - Training Epoch: 2/2, step 13661/16670 completed (loss: 0.09485417604446411, acc: 0.9743589758872986)
[2024-11-14 10:20:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:28][root][INFO] - Training Epoch: 2/2, step 13662/16670 completed (loss: 1.0926356315612793, acc: 0.7368420958518982)
[2024-11-14 10:20:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:28][root][INFO] - Training Epoch: 2/2, step 13663/16670 completed (loss: 0.3931403160095215, acc: 0.9142857193946838)
[2024-11-14 10:20:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:28][root][INFO] - Training Epoch: 2/2, step 13664/16670 completed (loss: 0.7826399803161621, acc: 0.8372092843055725)
[2024-11-14 10:20:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:28][root][INFO] - Training Epoch: 2/2, step 13665/16670 completed (loss: 1.1111854314804077, acc: 0.7599999904632568)
[2024-11-14 10:20:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:29][root][INFO] - Training Epoch: 2/2, step 13666/16670 completed (loss: 0.3322587311267853, acc: 0.929411768913269)
[2024-11-14 10:20:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:29][root][INFO] - Training Epoch: 2/2, step 13667/16670 completed (loss: 0.4929119944572449, acc: 0.837837815284729)
[2024-11-14 10:20:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:30][root][INFO] - Training Epoch: 2/2, step 13668/16670 completed (loss: 0.9956801533699036, acc: 0.807692289352417)
[2024-11-14 10:20:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:30][root][INFO] - Training Epoch: 2/2, step 13669/16670 completed (loss: 0.7086281180381775, acc: 0.8269230723381042)
[2024-11-14 10:20:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:30][root][INFO] - Training Epoch: 2/2, step 13670/16670 completed (loss: 0.381551593542099, acc: 0.8999999761581421)
[2024-11-14 10:20:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:30][root][INFO] - Training Epoch: 2/2, step 13671/16670 completed (loss: 0.9244025349617004, acc: 0.7777777910232544)
[2024-11-14 10:20:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:31][root][INFO] - Training Epoch: 2/2, step 13672/16670 completed (loss: 0.5304464101791382, acc: 0.9019607901573181)
[2024-11-14 10:20:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:31][root][INFO] - Training Epoch: 2/2, step 13673/16670 completed (loss: 0.6598173975944519, acc: 0.8730158805847168)
[2024-11-14 10:20:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:32][root][INFO] - Training Epoch: 2/2, step 13674/16670 completed (loss: 0.38004621863365173, acc: 0.9090909361839294)
[2024-11-14 10:20:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:32][root][INFO] - Training Epoch: 2/2, step 13675/16670 completed (loss: 0.8789833784103394, acc: 0.875)
[2024-11-14 10:20:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:32][root][INFO] - Training Epoch: 2/2, step 13676/16670 completed (loss: 0.3079052269458771, acc: 0.9111111164093018)
[2024-11-14 10:20:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:33][root][INFO] - Training Epoch: 2/2, step 13677/16670 completed (loss: 0.17091414332389832, acc: 0.942307710647583)
[2024-11-14 10:20:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:33][root][INFO] - Training Epoch: 2/2, step 13678/16670 completed (loss: 1.0717805624008179, acc: 0.6499999761581421)
[2024-11-14 10:20:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:33][root][INFO] - Training Epoch: 2/2, step 13679/16670 completed (loss: 0.9982142448425293, acc: 0.7631579041481018)
[2024-11-14 10:20:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:34][root][INFO] - Training Epoch: 2/2, step 13680/16670 completed (loss: 1.044981837272644, acc: 0.707317054271698)
[2024-11-14 10:20:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:34][root][INFO] - Training Epoch: 2/2, step 13681/16670 completed (loss: 0.5116140842437744, acc: 0.9090909361839294)
[2024-11-14 10:20:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:34][root][INFO] - Training Epoch: 2/2, step 13682/16670 completed (loss: 0.47297346591949463, acc: 0.8421052694320679)
[2024-11-14 10:20:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:35][root][INFO] - Training Epoch: 2/2, step 13683/16670 completed (loss: 1.1504231691360474, acc: 0.7931034564971924)
[2024-11-14 10:20:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:35][root][INFO] - Training Epoch: 2/2, step 13684/16670 completed (loss: 0.564877450466156, acc: 0.8620689511299133)
[2024-11-14 10:20:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:35][root][INFO] - Training Epoch: 2/2, step 13685/16670 completed (loss: 0.9114070534706116, acc: 0.7818182110786438)
[2024-11-14 10:20:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:36][root][INFO] - Training Epoch: 2/2, step 13686/16670 completed (loss: 0.5473840832710266, acc: 0.8148148059844971)
[2024-11-14 10:20:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:36][root][INFO] - Training Epoch: 2/2, step 13687/16670 completed (loss: 0.04768858477473259, acc: 1.0)
[2024-11-14 10:20:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:36][root][INFO] - Training Epoch: 2/2, step 13688/16670 completed (loss: 0.5469042658805847, acc: 0.8428571224212646)
[2024-11-14 10:20:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:37][root][INFO] - Training Epoch: 2/2, step 13689/16670 completed (loss: 0.6666192412376404, acc: 0.8518518805503845)
[2024-11-14 10:20:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:37][root][INFO] - Training Epoch: 2/2, step 13690/16670 completed (loss: 0.27685582637786865, acc: 0.9166666865348816)
[2024-11-14 10:20:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:37][root][INFO] - Training Epoch: 2/2, step 13691/16670 completed (loss: 0.18352936208248138, acc: 0.9487179517745972)
[2024-11-14 10:20:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:38][root][INFO] - Training Epoch: 2/2, step 13692/16670 completed (loss: 0.5767398476600647, acc: 0.8510638475418091)
[2024-11-14 10:20:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:38][root][INFO] - Training Epoch: 2/2, step 13693/16670 completed (loss: 0.5488697290420532, acc: 0.875)
[2024-11-14 10:20:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:38][root][INFO] - Training Epoch: 2/2, step 13694/16670 completed (loss: 0.19717957079410553, acc: 0.9594594836235046)
[2024-11-14 10:20:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:39][root][INFO] - Training Epoch: 2/2, step 13695/16670 completed (loss: 0.4185933768749237, acc: 0.8461538553237915)
[2024-11-14 10:20:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:39][root][INFO] - Training Epoch: 2/2, step 13696/16670 completed (loss: 1.0213910341262817, acc: 0.7777777910232544)
[2024-11-14 10:20:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:39][root][INFO] - Training Epoch: 2/2, step 13697/16670 completed (loss: 0.8286553621292114, acc: 0.7948718070983887)
[2024-11-14 10:20:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:40][root][INFO] - Training Epoch: 2/2, step 13698/16670 completed (loss: 0.6922830939292908, acc: 0.8965517282485962)
[2024-11-14 10:20:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:40][root][INFO] - Training Epoch: 2/2, step 13699/16670 completed (loss: 1.1256649494171143, acc: 0.8095238208770752)
[2024-11-14 10:20:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:40][root][INFO] - Training Epoch: 2/2, step 13700/16670 completed (loss: 0.2049754112958908, acc: 0.9200000166893005)
[2024-11-14 10:20:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:41][root][INFO] - Training Epoch: 2/2, step 13701/16670 completed (loss: 0.41388750076293945, acc: 0.9117646813392639)
[2024-11-14 10:20:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:41][root][INFO] - Training Epoch: 2/2, step 13702/16670 completed (loss: 0.5189135074615479, acc: 0.9069767594337463)
[2024-11-14 10:20:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:41][root][INFO] - Training Epoch: 2/2, step 13703/16670 completed (loss: 1.4396120309829712, acc: 0.7142857313156128)
[2024-11-14 10:20:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:42][root][INFO] - Training Epoch: 2/2, step 13704/16670 completed (loss: 0.6368953585624695, acc: 0.9069767594337463)
[2024-11-14 10:20:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:42][root][INFO] - Training Epoch: 2/2, step 13705/16670 completed (loss: 0.4254671037197113, acc: 0.9090909361839294)
[2024-11-14 10:20:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:42][root][INFO] - Training Epoch: 2/2, step 13706/16670 completed (loss: 0.38534507155418396, acc: 0.9166666865348816)
[2024-11-14 10:20:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:43][root][INFO] - Training Epoch: 2/2, step 13707/16670 completed (loss: 0.419102281332016, acc: 0.949999988079071)
[2024-11-14 10:20:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:43][root][INFO] - Training Epoch: 2/2, step 13708/16670 completed (loss: 0.5348496437072754, acc: 0.9047619104385376)
[2024-11-14 10:20:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:43][root][INFO] - Training Epoch: 2/2, step 13709/16670 completed (loss: 0.5531938076019287, acc: 0.8541666865348816)
[2024-11-14 10:20:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:44][root][INFO] - Training Epoch: 2/2, step 13710/16670 completed (loss: 0.6883741021156311, acc: 0.8666666746139526)
[2024-11-14 10:20:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:44][root][INFO] - Training Epoch: 2/2, step 13711/16670 completed (loss: 0.23980122804641724, acc: 0.9696969985961914)
[2024-11-14 10:20:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:45][root][INFO] - Training Epoch: 2/2, step 13712/16670 completed (loss: 0.30984655022621155, acc: 0.9333333373069763)
[2024-11-14 10:20:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:45][root][INFO] - Training Epoch: 2/2, step 13713/16670 completed (loss: 0.3842735290527344, acc: 0.9117646813392639)
[2024-11-14 10:20:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:45][root][INFO] - Training Epoch: 2/2, step 13714/16670 completed (loss: 0.9682356119155884, acc: 0.75)
[2024-11-14 10:20:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:46][root][INFO] - Training Epoch: 2/2, step 13715/16670 completed (loss: 0.10821819305419922, acc: 0.949999988079071)
[2024-11-14 10:20:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:46][root][INFO] - Training Epoch: 2/2, step 13716/16670 completed (loss: 1.2243667840957642, acc: 0.800000011920929)
[2024-11-14 10:20:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:46][root][INFO] - Training Epoch: 2/2, step 13717/16670 completed (loss: 0.37897759675979614, acc: 0.9117646813392639)
[2024-11-14 10:20:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:47][root][INFO] - Training Epoch: 2/2, step 13718/16670 completed (loss: 0.180416539311409, acc: 0.970588207244873)
[2024-11-14 10:20:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:47][root][INFO] - Training Epoch: 2/2, step 13719/16670 completed (loss: 0.21744459867477417, acc: 0.9512194991111755)
[2024-11-14 10:20:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:47][root][INFO] - Training Epoch: 2/2, step 13720/16670 completed (loss: 0.6960241794586182, acc: 0.8235294222831726)
[2024-11-14 10:20:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:48][root][INFO] - Training Epoch: 2/2, step 13721/16670 completed (loss: 0.3641508221626282, acc: 0.8888888955116272)
[2024-11-14 10:20:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:48][root][INFO] - Training Epoch: 2/2, step 13722/16670 completed (loss: 0.41441524028778076, acc: 0.8888888955116272)
[2024-11-14 10:20:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:48][root][INFO] - Training Epoch: 2/2, step 13723/16670 completed (loss: 0.2710469961166382, acc: 0.9399999976158142)
[2024-11-14 10:20:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:49][root][INFO] - Training Epoch: 2/2, step 13724/16670 completed (loss: 0.3584224283695221, acc: 0.9428571462631226)
[2024-11-14 10:20:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:49][root][INFO] - Training Epoch: 2/2, step 13725/16670 completed (loss: 0.1493486762046814, acc: 0.9555555582046509)
[2024-11-14 10:20:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:49][root][INFO] - Training Epoch: 2/2, step 13726/16670 completed (loss: 0.3199729919433594, acc: 0.9333333373069763)
[2024-11-14 10:20:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:50][root][INFO] - Training Epoch: 2/2, step 13727/16670 completed (loss: 0.35047149658203125, acc: 0.8333333134651184)
[2024-11-14 10:20:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:50][root][INFO] - Training Epoch: 2/2, step 13728/16670 completed (loss: 0.4257320165634155, acc: 0.8857142925262451)
[2024-11-14 10:20:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:50][root][INFO] - Training Epoch: 2/2, step 13729/16670 completed (loss: 0.3509388566017151, acc: 0.8809523582458496)
[2024-11-14 10:20:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:50][root][INFO] - Training Epoch: 2/2, step 13730/16670 completed (loss: 0.3169468641281128, acc: 0.9333333373069763)
[2024-11-14 10:20:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:51][root][INFO] - Training Epoch: 2/2, step 13731/16670 completed (loss: 0.09382213652133942, acc: 0.9599999785423279)
[2024-11-14 10:20:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:51][root][INFO] - Training Epoch: 2/2, step 13732/16670 completed (loss: 0.29459547996520996, acc: 0.9512194991111755)
[2024-11-14 10:20:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:51][root][INFO] - Training Epoch: 2/2, step 13733/16670 completed (loss: 0.6529436707496643, acc: 0.9056603908538818)
[2024-11-14 10:20:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:52][root][INFO] - Training Epoch: 2/2, step 13734/16670 completed (loss: 0.06794750690460205, acc: 0.9795918464660645)
[2024-11-14 10:20:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:52][root][INFO] - Training Epoch: 2/2, step 13735/16670 completed (loss: 0.46324604749679565, acc: 0.8999999761581421)
[2024-11-14 10:20:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:52][root][INFO] - Training Epoch: 2/2, step 13736/16670 completed (loss: 1.504839539527893, acc: 0.800000011920929)
[2024-11-14 10:20:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:53][root][INFO] - Training Epoch: 2/2, step 13737/16670 completed (loss: 0.4226371645927429, acc: 0.8095238208770752)
[2024-11-14 10:20:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:53][root][INFO] - Training Epoch: 2/2, step 13738/16670 completed (loss: 0.14830052852630615, acc: 0.9473684430122375)
[2024-11-14 10:20:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:53][root][INFO] - Training Epoch: 2/2, step 13739/16670 completed (loss: 0.4634506404399872, acc: 0.914893627166748)
[2024-11-14 10:20:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:54][root][INFO] - Training Epoch: 2/2, step 13740/16670 completed (loss: 1.0342978239059448, acc: 0.7916666865348816)
[2024-11-14 10:20:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:54][root][INFO] - Training Epoch: 2/2, step 13741/16670 completed (loss: 0.34676486253738403, acc: 0.8999999761581421)
[2024-11-14 10:20:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:54][root][INFO] - Training Epoch: 2/2, step 13742/16670 completed (loss: 0.29899361729621887, acc: 0.9130434989929199)
[2024-11-14 10:20:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:55][root][INFO] - Training Epoch: 2/2, step 13743/16670 completed (loss: 0.3851071894168854, acc: 0.9166666865348816)
[2024-11-14 10:20:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:55][root][INFO] - Training Epoch: 2/2, step 13744/16670 completed (loss: 0.0991094633936882, acc: 1.0)
[2024-11-14 10:20:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:55][root][INFO] - Training Epoch: 2/2, step 13745/16670 completed (loss: 0.44737955927848816, acc: 0.8648648858070374)
[2024-11-14 10:20:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:55][root][INFO] - Training Epoch: 2/2, step 13746/16670 completed (loss: 0.2846914231777191, acc: 0.9242424368858337)
[2024-11-14 10:20:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:56][root][INFO] - Training Epoch: 2/2, step 13747/16670 completed (loss: 0.36920130252838135, acc: 0.9230769276618958)
[2024-11-14 10:20:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:56][root][INFO] - Training Epoch: 2/2, step 13748/16670 completed (loss: 0.20321309566497803, acc: 0.9346405267715454)
[2024-11-14 10:20:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:56][root][INFO] - Training Epoch: 2/2, step 13749/16670 completed (loss: 0.2761988639831543, acc: 0.9346405267715454)
[2024-11-14 10:20:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:57][root][INFO] - Training Epoch: 2/2, step 13750/16670 completed (loss: 0.351031631231308, acc: 0.8940092325210571)
[2024-11-14 10:20:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:57][root][INFO] - Training Epoch: 2/2, step 13751/16670 completed (loss: 0.35114580392837524, acc: 0.9008264541625977)
[2024-11-14 10:20:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:58][root][INFO] - Training Epoch: 2/2, step 13752/16670 completed (loss: 0.17433224618434906, acc: 0.9666666388511658)
[2024-11-14 10:20:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:58][root][INFO] - Training Epoch: 2/2, step 13753/16670 completed (loss: 0.3393831253051758, acc: 0.9135802388191223)
[2024-11-14 10:20:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:58][root][INFO] - Training Epoch: 2/2, step 13754/16670 completed (loss: 0.22839075326919556, acc: 0.9117646813392639)
[2024-11-14 10:20:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:59][root][INFO] - Training Epoch: 2/2, step 13755/16670 completed (loss: 0.18103821575641632, acc: 0.9367088675498962)
[2024-11-14 10:20:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:59][root][INFO] - Training Epoch: 2/2, step 13756/16670 completed (loss: 0.2818463146686554, acc: 0.9259259104728699)
[2024-11-14 10:20:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:20:59][root][INFO] - Training Epoch: 2/2, step 13757/16670 completed (loss: 0.21593250334262848, acc: 0.9599999785423279)
[2024-11-14 10:20:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:00][root][INFO] - Training Epoch: 2/2, step 13758/16670 completed (loss: 0.3539043366909027, acc: 0.9166666865348816)
[2024-11-14 10:21:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:00][root][INFO] - Training Epoch: 2/2, step 13759/16670 completed (loss: 0.19436411559581757, acc: 0.9447004795074463)
[2024-11-14 10:21:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:00][root][INFO] - Training Epoch: 2/2, step 13760/16670 completed (loss: 0.13890491425991058, acc: 0.96875)
[2024-11-14 10:21:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:01][root][INFO] - Training Epoch: 2/2, step 13761/16670 completed (loss: 0.177056223154068, acc: 0.9538461565971375)
[2024-11-14 10:21:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:01][root][INFO] - Training Epoch: 2/2, step 13762/16670 completed (loss: 0.20502838492393494, acc: 0.9382022619247437)
[2024-11-14 10:21:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:01][root][INFO] - Training Epoch: 2/2, step 13763/16670 completed (loss: 0.14795604348182678, acc: 0.9471946954727173)
[2024-11-14 10:21:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:02][root][INFO] - Training Epoch: 2/2, step 13764/16670 completed (loss: 0.11573955416679382, acc: 0.9681528806686401)
[2024-11-14 10:21:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:02][root][INFO] - Training Epoch: 2/2, step 13765/16670 completed (loss: 0.28051474690437317, acc: 0.93388432264328)
[2024-11-14 10:21:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:02][root][INFO] - Training Epoch: 2/2, step 13766/16670 completed (loss: 0.2636648118495941, acc: 0.9254385828971863)
[2024-11-14 10:21:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:03][root][INFO] - Training Epoch: 2/2, step 13767/16670 completed (loss: 0.31028828024864197, acc: 0.9074074029922485)
[2024-11-14 10:21:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:03][root][INFO] - Training Epoch: 2/2, step 13768/16670 completed (loss: 0.284912109375, acc: 0.934959352016449)
[2024-11-14 10:21:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:03][root][INFO] - Training Epoch: 2/2, step 13769/16670 completed (loss: 0.1939334273338318, acc: 0.94017094373703)
[2024-11-14 10:21:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:04][root][INFO] - Training Epoch: 2/2, step 13770/16670 completed (loss: 0.19726459681987762, acc: 0.9624060392379761)
[2024-11-14 10:21:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:04][root][INFO] - Training Epoch: 2/2, step 13771/16670 completed (loss: 0.3774383068084717, acc: 0.9047619104385376)
[2024-11-14 10:21:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:04][root][INFO] - Training Epoch: 2/2, step 13772/16670 completed (loss: 0.30930617451667786, acc: 0.9016393423080444)
[2024-11-14 10:21:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:05][root][INFO] - Training Epoch: 2/2, step 13773/16670 completed (loss: 0.6461251974105835, acc: 0.8410596251487732)
[2024-11-14 10:21:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:05][root][INFO] - Training Epoch: 2/2, step 13774/16670 completed (loss: 0.2823069095611572, acc: 0.9130434989929199)
[2024-11-14 10:21:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:06][root][INFO] - Training Epoch: 2/2, step 13775/16670 completed (loss: 0.33207809925079346, acc: 0.9117646813392639)
[2024-11-14 10:21:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:06][root][INFO] - Training Epoch: 2/2, step 13776/16670 completed (loss: 0.2449580430984497, acc: 0.9236640930175781)
[2024-11-14 10:21:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:06][root][INFO] - Training Epoch: 2/2, step 13777/16670 completed (loss: 0.09513434767723083, acc: 0.9850000143051147)
[2024-11-14 10:21:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:07][root][INFO] - Training Epoch: 2/2, step 13778/16670 completed (loss: 0.09080393612384796, acc: 0.982758641242981)
[2024-11-14 10:21:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:07][root][INFO] - Training Epoch: 2/2, step 13779/16670 completed (loss: 0.47795426845550537, acc: 0.8961039185523987)
[2024-11-14 10:21:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:07][root][INFO] - Training Epoch: 2/2, step 13780/16670 completed (loss: 0.17620769143104553, acc: 0.9618320465087891)
[2024-11-14 10:21:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:08][root][INFO] - Training Epoch: 2/2, step 13781/16670 completed (loss: 0.21791239082813263, acc: 0.9333333373069763)
[2024-11-14 10:21:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:08][root][INFO] - Training Epoch: 2/2, step 13782/16670 completed (loss: 0.15737445652484894, acc: 0.9455252885818481)
[2024-11-14 10:21:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:08][root][INFO] - Training Epoch: 2/2, step 13783/16670 completed (loss: 0.14892064034938812, acc: 0.9622641801834106)
[2024-11-14 10:21:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:09][root][INFO] - Training Epoch: 2/2, step 13784/16670 completed (loss: 0.1658790409564972, acc: 0.9576719403266907)
[2024-11-14 10:21:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:09][root][INFO] - Training Epoch: 2/2, step 13785/16670 completed (loss: 0.20010049641132355, acc: 0.9244186282157898)
[2024-11-14 10:21:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:09][root][INFO] - Training Epoch: 2/2, step 13786/16670 completed (loss: 0.234823539853096, acc: 0.9202454090118408)
[2024-11-14 10:21:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:10][root][INFO] - Training Epoch: 2/2, step 13787/16670 completed (loss: 0.13136549293994904, acc: 0.9642857313156128)
[2024-11-14 10:21:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:10][root][INFO] - Training Epoch: 2/2, step 13788/16670 completed (loss: 0.16108135879039764, acc: 0.9566666483879089)
[2024-11-14 10:21:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:10][root][INFO] - Training Epoch: 2/2, step 13789/16670 completed (loss: 0.1276320070028305, acc: 0.9704641103744507)
[2024-11-14 10:21:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:11][root][INFO] - Training Epoch: 2/2, step 13790/16670 completed (loss: 0.2130022794008255, acc: 0.93388432264328)
[2024-11-14 10:21:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:11][root][INFO] - Training Epoch: 2/2, step 13791/16670 completed (loss: 0.337337851524353, acc: 0.8985507488250732)
[2024-11-14 10:21:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:12][root][INFO] - Training Epoch: 2/2, step 13792/16670 completed (loss: 0.22869490087032318, acc: 0.9253731369972229)
[2024-11-14 10:21:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:12][root][INFO] - Training Epoch: 2/2, step 13793/16670 completed (loss: 0.11399200558662415, acc: 0.9753086566925049)
[2024-11-14 10:21:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:12][root][INFO] - Training Epoch: 2/2, step 13794/16670 completed (loss: 0.42443257570266724, acc: 0.8939393758773804)
[2024-11-14 10:21:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:13][root][INFO] - Training Epoch: 2/2, step 13795/16670 completed (loss: 0.17262260615825653, acc: 0.9558823704719543)
[2024-11-14 10:21:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:13][root][INFO] - Training Epoch: 2/2, step 13796/16670 completed (loss: 0.258368581533432, acc: 0.9285714030265808)
[2024-11-14 10:21:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:13][root][INFO] - Training Epoch: 2/2, step 13797/16670 completed (loss: 0.23837243020534515, acc: 0.9306930899620056)
[2024-11-14 10:21:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:14][root][INFO] - Training Epoch: 2/2, step 13798/16670 completed (loss: 0.09042173624038696, acc: 0.9797979593276978)
[2024-11-14 10:21:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:14][root][INFO] - Training Epoch: 2/2, step 13799/16670 completed (loss: 0.19882182776927948, acc: 0.9477611780166626)
[2024-11-14 10:21:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:14][root][INFO] - Training Epoch: 2/2, step 13800/16670 completed (loss: 0.20615805685520172, acc: 0.9432623982429504)
[2024-11-14 10:21:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:15][root][INFO] - Training Epoch: 2/2, step 13801/16670 completed (loss: 0.08439785987138748, acc: 0.9762845635414124)
[2024-11-14 10:21:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:15][root][INFO] - Training Epoch: 2/2, step 13802/16670 completed (loss: 0.2630331516265869, acc: 0.9444444179534912)
[2024-11-14 10:21:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:16][root][INFO] - Training Epoch: 2/2, step 13803/16670 completed (loss: 0.23873335123062134, acc: 0.9260450005531311)
[2024-11-14 10:21:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:16][root][INFO] - Training Epoch: 2/2, step 13804/16670 completed (loss: 0.2762548327445984, acc: 0.9189189076423645)
[2024-11-14 10:21:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:16][root][INFO] - Training Epoch: 2/2, step 13805/16670 completed (loss: 0.15032601356506348, acc: 0.9762712121009827)
[2024-11-14 10:21:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:17][root][INFO] - Training Epoch: 2/2, step 13806/16670 completed (loss: 0.16692374646663666, acc: 0.9471946954727173)
[2024-11-14 10:21:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:17][root][INFO] - Training Epoch: 2/2, step 13807/16670 completed (loss: 0.23212558031082153, acc: 0.9523809552192688)
[2024-11-14 10:21:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:17][root][INFO] - Training Epoch: 2/2, step 13808/16670 completed (loss: 0.24497228860855103, acc: 0.9375)
[2024-11-14 10:21:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:18][root][INFO] - Training Epoch: 2/2, step 13809/16670 completed (loss: 0.24781297147274017, acc: 0.925000011920929)
[2024-11-14 10:21:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:18][root][INFO] - Training Epoch: 2/2, step 13810/16670 completed (loss: 0.05388667806982994, acc: 0.9900990128517151)
[2024-11-14 10:21:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:19][root][INFO] - Training Epoch: 2/2, step 13811/16670 completed (loss: 0.1811266541481018, acc: 0.9517543911933899)
[2024-11-14 10:21:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:19][root][INFO] - Training Epoch: 2/2, step 13812/16670 completed (loss: 0.074935682117939, acc: 0.971563994884491)
[2024-11-14 10:21:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:19][root][INFO] - Training Epoch: 2/2, step 13813/16670 completed (loss: 0.20227305591106415, acc: 0.9607843160629272)
[2024-11-14 10:21:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:20][root][INFO] - Training Epoch: 2/2, step 13814/16670 completed (loss: 0.14407141506671906, acc: 0.9590443968772888)
[2024-11-14 10:21:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:20][root][INFO] - Training Epoch: 2/2, step 13815/16670 completed (loss: 0.132105752825737, acc: 0.9515151381492615)
[2024-11-14 10:21:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:20][root][INFO] - Training Epoch: 2/2, step 13816/16670 completed (loss: 0.20123402774333954, acc: 0.9441860318183899)
[2024-11-14 10:21:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:21][root][INFO] - Training Epoch: 2/2, step 13817/16670 completed (loss: 0.17129060626029968, acc: 0.9369369149208069)
[2024-11-14 10:21:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:21][root][INFO] - Training Epoch: 2/2, step 13818/16670 completed (loss: 0.10737282037734985, acc: 0.9748427867889404)
[2024-11-14 10:21:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:22][root][INFO] - Training Epoch: 2/2, step 13819/16670 completed (loss: 0.14413461089134216, acc: 0.95652174949646)
[2024-11-14 10:21:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:22][root][INFO] - Training Epoch: 2/2, step 13820/16670 completed (loss: 0.15855328738689423, acc: 0.9629629850387573)
[2024-11-14 10:21:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:22][root][INFO] - Training Epoch: 2/2, step 13821/16670 completed (loss: 0.06041780114173889, acc: 0.9828571677207947)
[2024-11-14 10:21:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:23][root][INFO] - Training Epoch: 2/2, step 13822/16670 completed (loss: 0.15466108918190002, acc: 0.9605262875556946)
[2024-11-14 10:21:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:23][root][INFO] - Training Epoch: 2/2, step 13823/16670 completed (loss: 0.12463395297527313, acc: 0.9533073902130127)
[2024-11-14 10:21:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:23][root][INFO] - Training Epoch: 2/2, step 13824/16670 completed (loss: 0.26090341806411743, acc: 0.912162184715271)
[2024-11-14 10:21:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:24][root][INFO] - Training Epoch: 2/2, step 13825/16670 completed (loss: 0.16684222221374512, acc: 0.9370370507240295)
[2024-11-14 10:21:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:24][root][INFO] - Training Epoch: 2/2, step 13826/16670 completed (loss: 0.154325470328331, acc: 0.9537366628646851)
[2024-11-14 10:21:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:24][root][INFO] - Training Epoch: 2/2, step 13827/16670 completed (loss: 0.19688822329044342, acc: 0.9427312612533569)
[2024-11-14 10:21:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:25][root][INFO] - Training Epoch: 2/2, step 13828/16670 completed (loss: 0.21494117379188538, acc: 0.9395604133605957)
[2024-11-14 10:21:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:25][root][INFO] - Training Epoch: 2/2, step 13829/16670 completed (loss: 0.18247193098068237, acc: 0.9636363387107849)
[2024-11-14 10:21:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:25][root][INFO] - Training Epoch: 2/2, step 13830/16670 completed (loss: 0.19546513259410858, acc: 0.9426229596138)
[2024-11-14 10:21:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:26][root][INFO] - Training Epoch: 2/2, step 13831/16670 completed (loss: 0.13858555257320404, acc: 0.9635416865348816)
[2024-11-14 10:21:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:26][root][INFO] - Training Epoch: 2/2, step 13832/16670 completed (loss: 0.04589666798710823, acc: 0.9886363744735718)
[2024-11-14 10:21:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:27][root][INFO] - Training Epoch: 2/2, step 13833/16670 completed (loss: 0.1504139006137848, acc: 0.961904764175415)
[2024-11-14 10:21:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:27][root][INFO] - Training Epoch: 2/2, step 13834/16670 completed (loss: 0.15530842542648315, acc: 0.9411764740943909)
[2024-11-14 10:21:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:27][root][INFO] - Training Epoch: 2/2, step 13835/16670 completed (loss: 0.13966606557369232, acc: 0.9619565010070801)
[2024-11-14 10:21:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:28][root][INFO] - Training Epoch: 2/2, step 13836/16670 completed (loss: 0.1322292983531952, acc: 0.9642857313156128)
[2024-11-14 10:21:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:28][root][INFO] - Training Epoch: 2/2, step 13837/16670 completed (loss: 0.21909822523593903, acc: 0.9387755393981934)
[2024-11-14 10:21:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:28][root][INFO] - Training Epoch: 2/2, step 13838/16670 completed (loss: 0.14259926974773407, acc: 0.9527272582054138)
[2024-11-14 10:21:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:29][root][INFO] - Training Epoch: 2/2, step 13839/16670 completed (loss: 0.17685666680335999, acc: 0.9460431933403015)
[2024-11-14 10:21:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:29][root][INFO] - Training Epoch: 2/2, step 13840/16670 completed (loss: 0.19379258155822754, acc: 0.9255319237709045)
[2024-11-14 10:21:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:29][root][INFO] - Training Epoch: 2/2, step 13841/16670 completed (loss: 0.21413759887218475, acc: 0.9257950782775879)
[2024-11-14 10:21:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:30][root][INFO] - Training Epoch: 2/2, step 13842/16670 completed (loss: 0.20712172985076904, acc: 0.9473684430122375)
[2024-11-14 10:21:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:30][root][INFO] - Training Epoch: 2/2, step 13843/16670 completed (loss: 0.15439468622207642, acc: 0.9487179517745972)
[2024-11-14 10:21:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:31][root][INFO] - Training Epoch: 2/2, step 13844/16670 completed (loss: 0.2933231294155121, acc: 0.9166666865348816)
[2024-11-14 10:21:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:31][root][INFO] - Training Epoch: 2/2, step 13845/16670 completed (loss: 0.08245362341403961, acc: 0.9652174115180969)
[2024-11-14 10:21:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:31][root][INFO] - Training Epoch: 2/2, step 13846/16670 completed (loss: 0.24212110042572021, acc: 0.9534883499145508)
[2024-11-14 10:21:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:32][root][INFO] - Training Epoch: 2/2, step 13847/16670 completed (loss: 0.14811831712722778, acc: 0.9618055820465088)
[2024-11-14 10:21:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:32][root][INFO] - Training Epoch: 2/2, step 13848/16670 completed (loss: 0.1265546679496765, acc: 0.9608938694000244)
[2024-11-14 10:21:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:32][root][INFO] - Training Epoch: 2/2, step 13849/16670 completed (loss: 0.1854468584060669, acc: 0.9452054500579834)
[2024-11-14 10:21:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:33][root][INFO] - Training Epoch: 2/2, step 13850/16670 completed (loss: 0.1713184416294098, acc: 0.9692307710647583)
[2024-11-14 10:21:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:33][root][INFO] - Training Epoch: 2/2, step 13851/16670 completed (loss: 0.2720996141433716, acc: 0.9112903475761414)
[2024-11-14 10:21:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:33][root][INFO] - Training Epoch: 2/2, step 13852/16670 completed (loss: 0.3439233899116516, acc: 0.9038461446762085)
[2024-11-14 10:21:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:34][root][INFO] - Training Epoch: 2/2, step 13853/16670 completed (loss: 0.1553991734981537, acc: 0.96517413854599)
[2024-11-14 10:21:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:34][root][INFO] - Training Epoch: 2/2, step 13854/16670 completed (loss: 0.2958325445652008, acc: 0.9307692050933838)
[2024-11-14 10:21:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:34][root][INFO] - Training Epoch: 2/2, step 13855/16670 completed (loss: 0.23991543054580688, acc: 0.9429429173469543)
[2024-11-14 10:21:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:35][root][INFO] - Training Epoch: 2/2, step 13856/16670 completed (loss: 0.13423582911491394, acc: 0.9636963605880737)
[2024-11-14 10:21:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:35][root][INFO] - Training Epoch: 2/2, step 13857/16670 completed (loss: 0.15443696081638336, acc: 0.961904764175415)
[2024-11-14 10:21:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:35][root][INFO] - Training Epoch: 2/2, step 13858/16670 completed (loss: 0.3289364278316498, acc: 0.9145299196243286)
[2024-11-14 10:21:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:36][root][INFO] - Training Epoch: 2/2, step 13859/16670 completed (loss: 0.18891924619674683, acc: 0.948616623878479)
[2024-11-14 10:21:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:36][root][INFO] - Training Epoch: 2/2, step 13860/16670 completed (loss: 0.14540426433086395, acc: 0.9572649598121643)
[2024-11-14 10:21:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:36][root][INFO] - Training Epoch: 2/2, step 13861/16670 completed (loss: 0.09740803390741348, acc: 0.9684684872627258)
[2024-11-14 10:21:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:37][root][INFO] - Training Epoch: 2/2, step 13862/16670 completed (loss: 0.27233466506004333, acc: 0.908450722694397)
[2024-11-14 10:21:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:37][root][INFO] - Training Epoch: 2/2, step 13863/16670 completed (loss: 0.2306925356388092, acc: 0.9399293065071106)
[2024-11-14 10:21:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:37][root][INFO] - Training Epoch: 2/2, step 13864/16670 completed (loss: 0.19100689888000488, acc: 0.9555555582046509)
[2024-11-14 10:21:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:38][root][INFO] - Training Epoch: 2/2, step 13865/16670 completed (loss: 0.19237148761749268, acc: 0.9343434572219849)
[2024-11-14 10:21:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:38][root][INFO] - Training Epoch: 2/2, step 13866/16670 completed (loss: 0.08500635623931885, acc: 0.9750000238418579)
[2024-11-14 10:21:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:38][root][INFO] - Training Epoch: 2/2, step 13867/16670 completed (loss: 0.24708449840545654, acc: 0.9353448152542114)
[2024-11-14 10:21:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:39][root][INFO] - Training Epoch: 2/2, step 13868/16670 completed (loss: 0.1273295283317566, acc: 0.9589040875434875)
[2024-11-14 10:21:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:39][root][INFO] - Training Epoch: 2/2, step 13869/16670 completed (loss: 0.11555957049131393, acc: 0.9720930457115173)
[2024-11-14 10:21:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:39][root][INFO] - Training Epoch: 2/2, step 13870/16670 completed (loss: 0.17079022526741028, acc: 0.9575471878051758)
[2024-11-14 10:21:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:40][root][INFO] - Training Epoch: 2/2, step 13871/16670 completed (loss: 0.22259734570980072, acc: 0.9344262480735779)
[2024-11-14 10:21:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:40][root][INFO] - Training Epoch: 2/2, step 13872/16670 completed (loss: 0.08984088897705078, acc: 0.970802903175354)
[2024-11-14 10:21:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:40][root][INFO] - Training Epoch: 2/2, step 13873/16670 completed (loss: 0.2657822370529175, acc: 0.9348534345626831)
[2024-11-14 10:21:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:40][root][INFO] - Training Epoch: 2/2, step 13874/16670 completed (loss: 0.2045804262161255, acc: 0.9625668525695801)
[2024-11-14 10:21:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:41][root][INFO] - Training Epoch: 2/2, step 13875/16670 completed (loss: 0.06263509392738342, acc: 0.9836065769195557)
[2024-11-14 10:21:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:41][root][INFO] - Training Epoch: 2/2, step 13876/16670 completed (loss: 0.18353188037872314, acc: 0.942307710647583)
[2024-11-14 10:21:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:41][root][INFO] - Training Epoch: 2/2, step 13877/16670 completed (loss: 0.15229076147079468, acc: 0.9655172228813171)
[2024-11-14 10:21:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:42][root][INFO] - Training Epoch: 2/2, step 13878/16670 completed (loss: 0.10134562104940414, acc: 0.9624413251876831)
[2024-11-14 10:21:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:42][root][INFO] - Training Epoch: 2/2, step 13879/16670 completed (loss: 0.2829374670982361, acc: 0.916201114654541)
[2024-11-14 10:21:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:42][root][INFO] - Training Epoch: 2/2, step 13880/16670 completed (loss: 0.17349447309970856, acc: 0.9441340565681458)
[2024-11-14 10:21:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:43][root][INFO] - Training Epoch: 2/2, step 13881/16670 completed (loss: 0.18717707693576813, acc: 0.9481707215309143)
[2024-11-14 10:21:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:43][root][INFO] - Training Epoch: 2/2, step 13882/16670 completed (loss: 0.19259141385555267, acc: 0.9567901492118835)
[2024-11-14 10:21:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:43][root][INFO] - Training Epoch: 2/2, step 13883/16670 completed (loss: 0.2675241231918335, acc: 0.920634925365448)
[2024-11-14 10:21:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:44][root][INFO] - Training Epoch: 2/2, step 13884/16670 completed (loss: 0.28119102120399475, acc: 0.9176470637321472)
[2024-11-14 10:21:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:44][root][INFO] - Training Epoch: 2/2, step 13885/16670 completed (loss: 0.1436348706483841, acc: 0.9575471878051758)
[2024-11-14 10:21:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:45][root][INFO] - Training Epoch: 2/2, step 13886/16670 completed (loss: 0.17504306137561798, acc: 0.9529780745506287)
[2024-11-14 10:21:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:45][root][INFO] - Training Epoch: 2/2, step 13887/16670 completed (loss: 0.27956733107566833, acc: 0.9269406199455261)
[2024-11-14 10:21:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:45][root][INFO] - Training Epoch: 2/2, step 13888/16670 completed (loss: 0.45702847838401794, acc: 0.8897637724876404)
[2024-11-14 10:21:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:45][root][INFO] - Training Epoch: 2/2, step 13889/16670 completed (loss: 0.08714354038238525, acc: 0.9675324559211731)
[2024-11-14 10:21:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:46][root][INFO] - Training Epoch: 2/2, step 13890/16670 completed (loss: 0.10384662449359894, acc: 0.9815950989723206)
[2024-11-14 10:21:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:46][root][INFO] - Training Epoch: 2/2, step 13891/16670 completed (loss: 0.16320064663887024, acc: 0.9422222375869751)
[2024-11-14 10:21:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:47][root][INFO] - Training Epoch: 2/2, step 13892/16670 completed (loss: 0.2995203137397766, acc: 0.9170507192611694)
[2024-11-14 10:21:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:47][root][INFO] - Training Epoch: 2/2, step 13893/16670 completed (loss: 0.1347394585609436, acc: 0.9549999833106995)
[2024-11-14 10:21:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:47][root][INFO] - Training Epoch: 2/2, step 13894/16670 completed (loss: 0.20734864473342896, acc: 0.9547511339187622)
[2024-11-14 10:21:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:47][root][INFO] - Training Epoch: 2/2, step 13895/16670 completed (loss: 0.14547859132289886, acc: 0.9515151381492615)
[2024-11-14 10:21:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:48][root][INFO] - Training Epoch: 2/2, step 13896/16670 completed (loss: 0.10097112506628036, acc: 0.9749216437339783)
[2024-11-14 10:21:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:48][root][INFO] - Training Epoch: 2/2, step 13897/16670 completed (loss: 0.1508890688419342, acc: 0.9750000238418579)
[2024-11-14 10:21:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:48][root][INFO] - Training Epoch: 2/2, step 13898/16670 completed (loss: 0.07948087900876999, acc: 0.985401451587677)
[2024-11-14 10:21:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:49][root][INFO] - Training Epoch: 2/2, step 13899/16670 completed (loss: 0.0999952182173729, acc: 0.9715302586555481)
[2024-11-14 10:21:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:49][root][INFO] - Training Epoch: 2/2, step 13900/16670 completed (loss: 0.2206849604845047, acc: 0.9473684430122375)
[2024-11-14 10:21:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:49][root][INFO] - Training Epoch: 2/2, step 13901/16670 completed (loss: 0.23783844709396362, acc: 0.9400749206542969)
[2024-11-14 10:21:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:50][root][INFO] - Training Epoch: 2/2, step 13902/16670 completed (loss: 0.0765421912074089, acc: 0.97826087474823)
[2024-11-14 10:21:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:50][root][INFO] - Training Epoch: 2/2, step 13903/16670 completed (loss: 0.17464299499988556, acc: 0.9649999737739563)
[2024-11-14 10:21:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:50][root][INFO] - Training Epoch: 2/2, step 13904/16670 completed (loss: 0.15647844970226288, acc: 0.9669811129570007)
[2024-11-14 10:21:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:51][root][INFO] - Training Epoch: 2/2, step 13905/16670 completed (loss: 0.07575143128633499, acc: 0.9783281683921814)
[2024-11-14 10:21:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:51][root][INFO] - Training Epoch: 2/2, step 13906/16670 completed (loss: 0.1740896850824356, acc: 0.9719626307487488)
[2024-11-14 10:21:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:51][root][INFO] - Training Epoch: 2/2, step 13907/16670 completed (loss: 0.10793930292129517, acc: 0.9718875288963318)
[2024-11-14 10:21:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:52][root][INFO] - Training Epoch: 2/2, step 13908/16670 completed (loss: 0.1613135188817978, acc: 0.9589442610740662)
[2024-11-14 10:21:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:52][root][INFO] - Training Epoch: 2/2, step 13909/16670 completed (loss: 0.14595378935337067, acc: 0.9604743123054504)
[2024-11-14 10:21:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:52][root][INFO] - Training Epoch: 2/2, step 13910/16670 completed (loss: 0.19202430546283722, acc: 0.9470587968826294)
[2024-11-14 10:21:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:52][root][INFO] - Training Epoch: 2/2, step 13911/16670 completed (loss: 0.1042616218328476, acc: 0.9717513918876648)
[2024-11-14 10:21:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:53][root][INFO] - Training Epoch: 2/2, step 13912/16670 completed (loss: 0.04720798879861832, acc: 0.9922480583190918)
[2024-11-14 10:21:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:53][root][INFO] - Training Epoch: 2/2, step 13913/16670 completed (loss: 0.10088800638914108, acc: 0.9722222089767456)
[2024-11-14 10:21:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:53][root][INFO] - Training Epoch: 2/2, step 13914/16670 completed (loss: 0.21326006948947906, acc: 0.9439775943756104)
[2024-11-14 10:21:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:54][root][INFO] - Training Epoch: 2/2, step 13915/16670 completed (loss: 0.16018378734588623, acc: 0.9510489702224731)
[2024-11-14 10:21:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:54][root][INFO] - Training Epoch: 2/2, step 13916/16670 completed (loss: 0.10619518160820007, acc: 0.9785407781600952)
[2024-11-14 10:21:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:54][root][INFO] - Training Epoch: 2/2, step 13917/16670 completed (loss: 0.21353963017463684, acc: 0.9333333373069763)
[2024-11-14 10:21:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:55][root][INFO] - Training Epoch: 2/2, step 13918/16670 completed (loss: 0.17582839727401733, acc: 0.9551724195480347)
[2024-11-14 10:21:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:55][root][INFO] - Training Epoch: 2/2, step 13919/16670 completed (loss: 0.25813716650009155, acc: 0.9448275566101074)
[2024-11-14 10:21:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:55][root][INFO] - Training Epoch: 2/2, step 13920/16670 completed (loss: 0.13554081320762634, acc: 0.9609929323196411)
[2024-11-14 10:21:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:56][root][INFO] - Training Epoch: 2/2, step 13921/16670 completed (loss: 0.18501423299312592, acc: 0.953125)
[2024-11-14 10:21:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:56][root][INFO] - Training Epoch: 2/2, step 13922/16670 completed (loss: 0.1610461324453354, acc: 0.9540635943412781)
[2024-11-14 10:21:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:56][root][INFO] - Training Epoch: 2/2, step 13923/16670 completed (loss: 0.24019008874893188, acc: 0.9427609443664551)
[2024-11-14 10:21:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:57][root][INFO] - Training Epoch: 2/2, step 13924/16670 completed (loss: 0.0946766659617424, acc: 0.9651898741722107)
[2024-11-14 10:21:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:57][root][INFO] - Training Epoch: 2/2, step 13925/16670 completed (loss: 0.22955907881259918, acc: 0.9473684430122375)
[2024-11-14 10:21:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:57][root][INFO] - Training Epoch: 2/2, step 13926/16670 completed (loss: 0.22345277667045593, acc: 0.9237288236618042)
[2024-11-14 10:21:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:58][root][INFO] - Training Epoch: 2/2, step 13927/16670 completed (loss: 0.07287023216485977, acc: 0.9624999761581421)
[2024-11-14 10:21:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:58][root][INFO] - Training Epoch: 2/2, step 13928/16670 completed (loss: 0.16931749880313873, acc: 0.9477611780166626)
[2024-11-14 10:21:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:58][root][INFO] - Training Epoch: 2/2, step 13929/16670 completed (loss: 0.24123583734035492, acc: 0.9285714030265808)
[2024-11-14 10:21:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:59][root][INFO] - Training Epoch: 2/2, step 13930/16670 completed (loss: 0.16480618715286255, acc: 0.9551281929016113)
[2024-11-14 10:21:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:59][root][INFO] - Training Epoch: 2/2, step 13931/16670 completed (loss: 0.14597326517105103, acc: 0.9784946441650391)
[2024-11-14 10:21:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:21:59][root][INFO] - Training Epoch: 2/2, step 13932/16670 completed (loss: 0.2755134403705597, acc: 0.9166666865348816)
[2024-11-14 10:22:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:00][root][INFO] - Training Epoch: 2/2, step 13933/16670 completed (loss: 0.21758592128753662, acc: 0.9223300814628601)
[2024-11-14 10:22:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:00][root][INFO] - Training Epoch: 2/2, step 13934/16670 completed (loss: 0.23248855769634247, acc: 0.9294871687889099)
[2024-11-14 10:22:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:00][root][INFO] - Training Epoch: 2/2, step 13935/16670 completed (loss: 0.11838819831609726, acc: 0.959770143032074)
[2024-11-14 10:22:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:01][root][INFO] - Training Epoch: 2/2, step 13936/16670 completed (loss: 0.46376103162765503, acc: 0.8785714507102966)
[2024-11-14 10:22:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:01][root][INFO] - Training Epoch: 2/2, step 13937/16670 completed (loss: 0.13811060786247253, acc: 0.9685039520263672)
[2024-11-14 10:22:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:01][root][INFO] - Training Epoch: 2/2, step 13938/16670 completed (loss: 0.1553773581981659, acc: 0.9567099809646606)
[2024-11-14 10:22:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:02][root][INFO] - Training Epoch: 2/2, step 13939/16670 completed (loss: 0.35082295536994934, acc: 0.8950276374816895)
[2024-11-14 10:22:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:02][root][INFO] - Training Epoch: 2/2, step 13940/16670 completed (loss: 0.5228874683380127, acc: 0.848739504814148)
[2024-11-14 10:22:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:03][root][INFO] - Training Epoch: 2/2, step 13941/16670 completed (loss: 0.09942296892404556, acc: 0.9741935729980469)
[2024-11-14 10:22:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:03][root][INFO] - Training Epoch: 2/2, step 13942/16670 completed (loss: 0.1617787629365921, acc: 0.9725490212440491)
[2024-11-14 10:22:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:03][root][INFO] - Training Epoch: 2/2, step 13943/16670 completed (loss: 0.2477518767118454, acc: 0.9253731369972229)
[2024-11-14 10:22:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:04][root][INFO] - Training Epoch: 2/2, step 13944/16670 completed (loss: 0.12262057512998581, acc: 0.9641434550285339)
[2024-11-14 10:22:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:04][root][INFO] - Training Epoch: 2/2, step 13945/16670 completed (loss: 0.10782025754451752, acc: 0.9647887349128723)
[2024-11-14 10:22:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:04][root][INFO] - Training Epoch: 2/2, step 13946/16670 completed (loss: 0.15603415668010712, acc: 0.9523809552192688)
[2024-11-14 10:22:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:04][root][INFO] - Training Epoch: 2/2, step 13947/16670 completed (loss: 0.1872727870941162, acc: 0.9351351261138916)
[2024-11-14 10:22:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:05][root][INFO] - Training Epoch: 2/2, step 13948/16670 completed (loss: 0.10867605358362198, acc: 0.9631901979446411)
[2024-11-14 10:22:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:05][root][INFO] - Training Epoch: 2/2, step 13949/16670 completed (loss: 0.17926768958568573, acc: 0.9527272582054138)
[2024-11-14 10:22:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:06][root][INFO] - Training Epoch: 2/2, step 13950/16670 completed (loss: 0.06649009883403778, acc: 0.9728506803512573)
[2024-11-14 10:22:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:06][root][INFO] - Training Epoch: 2/2, step 13951/16670 completed (loss: 0.0653572827577591, acc: 0.9858490824699402)
[2024-11-14 10:22:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:06][root][INFO] - Training Epoch: 2/2, step 13952/16670 completed (loss: 0.27781403064727783, acc: 0.9140625)
[2024-11-14 10:22:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:07][root][INFO] - Training Epoch: 2/2, step 13953/16670 completed (loss: 0.10151436924934387, acc: 0.9716981053352356)
[2024-11-14 10:22:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:07][root][INFO] - Training Epoch: 2/2, step 13954/16670 completed (loss: 0.16251859068870544, acc: 0.9494949579238892)
[2024-11-14 10:22:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:08][root][INFO] - Training Epoch: 2/2, step 13955/16670 completed (loss: 0.1956796497106552, acc: 0.953125)
[2024-11-14 10:22:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:08][root][INFO] - Training Epoch: 2/2, step 13956/16670 completed (loss: 0.2117578387260437, acc: 0.9370861053466797)
[2024-11-14 10:22:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:08][root][INFO] - Training Epoch: 2/2, step 13957/16670 completed (loss: 0.048535846173763275, acc: 1.0)
[2024-11-14 10:22:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:09][root][INFO] - Training Epoch: 2/2, step 13958/16670 completed (loss: 0.2622135877609253, acc: 0.9277108311653137)
[2024-11-14 10:22:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:09][root][INFO] - Training Epoch: 2/2, step 13959/16670 completed (loss: 0.08311153203248978, acc: 0.975806474685669)
[2024-11-14 10:22:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:09][root][INFO] - Training Epoch: 2/2, step 13960/16670 completed (loss: 0.5790159106254578, acc: 0.8796992301940918)
[2024-11-14 10:22:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:10][root][INFO] - Training Epoch: 2/2, step 13961/16670 completed (loss: 0.16656674444675446, acc: 0.9532163739204407)
[2024-11-14 10:22:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:10][root][INFO] - Training Epoch: 2/2, step 13962/16670 completed (loss: 0.24791797995567322, acc: 0.9555555582046509)
[2024-11-14 10:22:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:10][root][INFO] - Training Epoch: 2/2, step 13963/16670 completed (loss: 0.14228172600269318, acc: 0.9368420839309692)
[2024-11-14 10:22:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:11][root][INFO] - Training Epoch: 2/2, step 13964/16670 completed (loss: 0.12696397304534912, acc: 0.9729729890823364)
[2024-11-14 10:22:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:11][root][INFO] - Training Epoch: 2/2, step 13965/16670 completed (loss: 0.170397087931633, acc: 0.9685534834861755)
[2024-11-14 10:22:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:11][root][INFO] - Training Epoch: 2/2, step 13966/16670 completed (loss: 0.1873081922531128, acc: 0.9406779408454895)
[2024-11-14 10:22:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:12][root][INFO] - Training Epoch: 2/2, step 13967/16670 completed (loss: 0.17992915213108063, acc: 0.948630154132843)
[2024-11-14 10:22:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:12][root][INFO] - Training Epoch: 2/2, step 13968/16670 completed (loss: 0.19051192700862885, acc: 0.9481481313705444)
[2024-11-14 10:22:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:12][root][INFO] - Training Epoch: 2/2, step 13969/16670 completed (loss: 0.1642800271511078, acc: 0.9583333134651184)
[2024-11-14 10:22:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:13][root][INFO] - Training Epoch: 2/2, step 13970/16670 completed (loss: 0.21591299772262573, acc: 0.9386792182922363)
[2024-11-14 10:22:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:13][root][INFO] - Training Epoch: 2/2, step 13971/16670 completed (loss: 0.06181671470403671, acc: 0.984000027179718)
[2024-11-14 10:22:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:14][root][INFO] - Training Epoch: 2/2, step 13972/16670 completed (loss: 0.2699519693851471, acc: 0.9378238320350647)
[2024-11-14 10:22:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:14][root][INFO] - Training Epoch: 2/2, step 13973/16670 completed (loss: 0.21265560388565063, acc: 0.9306930899620056)
[2024-11-14 10:22:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:14][root][INFO] - Training Epoch: 2/2, step 13974/16670 completed (loss: 0.1770292967557907, acc: 0.9417989253997803)
[2024-11-14 10:22:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:14][root][INFO] - Training Epoch: 2/2, step 13975/16670 completed (loss: 0.18547886610031128, acc: 0.9371428489685059)
[2024-11-14 10:22:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:15][root][INFO] - Training Epoch: 2/2, step 13976/16670 completed (loss: 0.20425337553024292, acc: 0.9484127163887024)
[2024-11-14 10:22:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:15][root][INFO] - Training Epoch: 2/2, step 13977/16670 completed (loss: 0.2520313858985901, acc: 0.9324324131011963)
[2024-11-14 10:22:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:16][root][INFO] - Training Epoch: 2/2, step 13978/16670 completed (loss: 0.0654137134552002, acc: 0.9844961166381836)
[2024-11-14 10:22:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:16][root][INFO] - Training Epoch: 2/2, step 13979/16670 completed (loss: 0.13909576833248138, acc: 0.932584285736084)
[2024-11-14 10:22:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:16][root][INFO] - Training Epoch: 2/2, step 13980/16670 completed (loss: 0.4052864611148834, acc: 0.862500011920929)
[2024-11-14 10:22:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:17][root][INFO] - Training Epoch: 2/2, step 13981/16670 completed (loss: 0.07856062799692154, acc: 0.9855072498321533)
[2024-11-14 10:22:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:17][root][INFO] - Training Epoch: 2/2, step 13982/16670 completed (loss: 0.6114436984062195, acc: 0.7767857313156128)
[2024-11-14 10:22:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:17][root][INFO] - Training Epoch: 2/2, step 13983/16670 completed (loss: 0.24989643692970276, acc: 0.9304347634315491)
[2024-11-14 10:22:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:17][root][INFO] - Training Epoch: 2/2, step 13984/16670 completed (loss: 0.20267857611179352, acc: 0.9432989954948425)
[2024-11-14 10:22:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:18][root][INFO] - Training Epoch: 2/2, step 13985/16670 completed (loss: 0.07339689135551453, acc: 0.9833333492279053)
[2024-11-14 10:22:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:18][root][INFO] - Training Epoch: 2/2, step 13986/16670 completed (loss: 0.0900810956954956, acc: 0.9857142567634583)
[2024-11-14 10:22:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:19][root][INFO] - Training Epoch: 2/2, step 13987/16670 completed (loss: 0.23569081723690033, acc: 0.9333333373069763)
[2024-11-14 10:22:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:19][root][INFO] - Training Epoch: 2/2, step 13988/16670 completed (loss: 0.07792885601520538, acc: 0.970370352268219)
[2024-11-14 10:22:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:19][root][INFO] - Training Epoch: 2/2, step 13989/16670 completed (loss: 0.2622675895690918, acc: 0.9487179517745972)
[2024-11-14 10:22:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:20][root][INFO] - Training Epoch: 2/2, step 13990/16670 completed (loss: 0.06156337261199951, acc: 0.9770641922950745)
[2024-11-14 10:22:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:20][root][INFO] - Training Epoch: 2/2, step 13991/16670 completed (loss: 0.21500766277313232, acc: 0.9254658222198486)
[2024-11-14 10:22:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:20][root][INFO] - Training Epoch: 2/2, step 13992/16670 completed (loss: 0.2525072991847992, acc: 0.9241379499435425)
[2024-11-14 10:22:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:21][root][INFO] - Training Epoch: 2/2, step 13993/16670 completed (loss: 0.15471524000167847, acc: 0.9452054500579834)
[2024-11-14 10:22:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:21][root][INFO] - Training Epoch: 2/2, step 13994/16670 completed (loss: 0.41259172558784485, acc: 0.9230769276618958)
[2024-11-14 10:22:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:22][root][INFO] - Training Epoch: 2/2, step 13995/16670 completed (loss: 0.29886874556541443, acc: 0.9024389982223511)
[2024-11-14 10:22:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:22][root][INFO] - Training Epoch: 2/2, step 13996/16670 completed (loss: 0.2670024335384369, acc: 0.9109588861465454)
[2024-11-14 10:22:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:22][root][INFO] - Training Epoch: 2/2, step 13997/16670 completed (loss: 0.21445968747138977, acc: 0.9553903341293335)
[2024-11-14 10:22:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:23][root][INFO] - Training Epoch: 2/2, step 13998/16670 completed (loss: 0.46587297320365906, acc: 0.9059829115867615)
[2024-11-14 10:22:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:23][root][INFO] - Training Epoch: 2/2, step 13999/16670 completed (loss: 0.11287110298871994, acc: 0.9519650936126709)
[2024-11-14 10:22:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:23][root][INFO] - Training Epoch: 2/2, step 14000/16670 completed (loss: 0.21442580223083496, acc: 0.9260700345039368)
[2024-11-14 10:22:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:24][root][INFO] - Training Epoch: 2/2, step 14001/16670 completed (loss: 0.2619740068912506, acc: 0.9274193644523621)
[2024-11-14 10:22:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:24][root][INFO] - Training Epoch: 2/2, step 14002/16670 completed (loss: 0.16188016533851624, acc: 0.9395161271095276)
[2024-11-14 10:22:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:24][root][INFO] - Training Epoch: 2/2, step 14003/16670 completed (loss: 0.1519080549478531, acc: 0.9476190209388733)
[2024-11-14 10:22:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:25][root][INFO] - Training Epoch: 2/2, step 14004/16670 completed (loss: 0.29584813117980957, acc: 0.9367815852165222)
[2024-11-14 10:22:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:25][root][INFO] - Training Epoch: 2/2, step 14005/16670 completed (loss: 0.14548026025295258, acc: 0.957446813583374)
[2024-11-14 10:22:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:25][root][INFO] - Training Epoch: 2/2, step 14006/16670 completed (loss: 0.31227725744247437, acc: 0.9202127456665039)
[2024-11-14 10:22:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:26][root][INFO] - Training Epoch: 2/2, step 14007/16670 completed (loss: 0.09184838831424713, acc: 0.9742765426635742)
[2024-11-14 10:22:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:26][root][INFO] - Training Epoch: 2/2, step 14008/16670 completed (loss: 0.3797118067741394, acc: 0.8510638475418091)
[2024-11-14 10:22:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:27][root][INFO] - Training Epoch: 2/2, step 14009/16670 completed (loss: 0.2921590805053711, acc: 0.9154929518699646)
[2024-11-14 10:22:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:27][root][INFO] - Training Epoch: 2/2, step 14010/16670 completed (loss: 0.17276012897491455, acc: 0.954954981803894)
[2024-11-14 10:22:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:27][root][INFO] - Training Epoch: 2/2, step 14011/16670 completed (loss: 0.11159291118383408, acc: 0.982758641242981)
[2024-11-14 10:22:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:28][root][INFO] - Training Epoch: 2/2, step 14012/16670 completed (loss: 0.25947272777557373, acc: 0.9292929172515869)
[2024-11-14 10:22:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:28][root][INFO] - Training Epoch: 2/2, step 14013/16670 completed (loss: 0.2629500925540924, acc: 0.9395604133605957)
[2024-11-14 10:22:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:28][root][INFO] - Training Epoch: 2/2, step 14014/16670 completed (loss: 0.20946146547794342, acc: 0.9511111378669739)
[2024-11-14 10:22:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:29][root][INFO] - Training Epoch: 2/2, step 14015/16670 completed (loss: 0.13632521033287048, acc: 0.9506173133850098)
[2024-11-14 10:22:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:29][root][INFO] - Training Epoch: 2/2, step 14016/16670 completed (loss: 0.3926539719104767, acc: 0.8863636255264282)
[2024-11-14 10:22:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:30][root][INFO] - Training Epoch: 2/2, step 14017/16670 completed (loss: 0.15162107348442078, acc: 0.949999988079071)
[2024-11-14 10:22:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:30][root][INFO] - Training Epoch: 2/2, step 14018/16670 completed (loss: 0.22459745407104492, acc: 0.9295774698257446)
[2024-11-14 10:22:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:30][root][INFO] - Training Epoch: 2/2, step 14019/16670 completed (loss: 0.23635074496269226, acc: 0.9384615421295166)
[2024-11-14 10:22:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:31][root][INFO] - Training Epoch: 2/2, step 14020/16670 completed (loss: 0.10405676811933517, acc: 0.9568965435028076)
[2024-11-14 10:22:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:31][root][INFO] - Training Epoch: 2/2, step 14021/16670 completed (loss: 0.2517065107822418, acc: 0.9346405267715454)
[2024-11-14 10:22:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:31][root][INFO] - Training Epoch: 2/2, step 14022/16670 completed (loss: 0.09734194725751877, acc: 0.9679487347602844)
[2024-11-14 10:22:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:32][root][INFO] - Training Epoch: 2/2, step 14023/16670 completed (loss: 0.15437962114810944, acc: 0.9465020298957825)
[2024-11-14 10:22:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:32][root][INFO] - Training Epoch: 2/2, step 14024/16670 completed (loss: 0.22175735235214233, acc: 0.9396551847457886)
[2024-11-14 10:22:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:32][root][INFO] - Training Epoch: 2/2, step 14025/16670 completed (loss: 0.20967401564121246, acc: 0.9521912336349487)
[2024-11-14 10:22:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:32][root][INFO] - Training Epoch: 2/2, step 14026/16670 completed (loss: 0.16594727337360382, acc: 0.9559471607208252)
[2024-11-14 10:22:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:33][root][INFO] - Training Epoch: 2/2, step 14027/16670 completed (loss: 0.29219579696655273, acc: 0.887499988079071)
[2024-11-14 10:22:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:33][root][INFO] - Training Epoch: 2/2, step 14028/16670 completed (loss: 0.2515004277229309, acc: 0.9289940595626831)
[2024-11-14 10:22:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:33][root][INFO] - Training Epoch: 2/2, step 14029/16670 completed (loss: 0.239791139960289, acc: 0.9173553586006165)
[2024-11-14 10:22:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:34][root][INFO] - Training Epoch: 2/2, step 14030/16670 completed (loss: 0.44279080629348755, acc: 0.8867924809455872)
[2024-11-14 10:22:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:34][root][INFO] - Training Epoch: 2/2, step 14031/16670 completed (loss: 0.17993055284023285, acc: 0.9583333134651184)
[2024-11-14 10:22:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:34][root][INFO] - Training Epoch: 2/2, step 14032/16670 completed (loss: 0.1837863028049469, acc: 0.9563106894493103)
[2024-11-14 10:22:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:35][root][INFO] - Training Epoch: 2/2, step 14033/16670 completed (loss: 0.10681328177452087, acc: 0.9702970385551453)
[2024-11-14 10:22:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:35][root][INFO] - Training Epoch: 2/2, step 14034/16670 completed (loss: 0.23572425544261932, acc: 0.9069767594337463)
[2024-11-14 10:22:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:35][root][INFO] - Training Epoch: 2/2, step 14035/16670 completed (loss: 0.20866021513938904, acc: 0.95652174949646)
[2024-11-14 10:22:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:36][root][INFO] - Training Epoch: 2/2, step 14036/16670 completed (loss: 0.08610513061285019, acc: 0.97826087474823)
[2024-11-14 10:22:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:36][root][INFO] - Training Epoch: 2/2, step 14037/16670 completed (loss: 0.2841337025165558, acc: 0.9188033938407898)
[2024-11-14 10:22:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:36][root][INFO] - Training Epoch: 2/2, step 14038/16670 completed (loss: 0.11777298897504807, acc: 0.9534883499145508)
[2024-11-14 10:22:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:37][root][INFO] - Training Epoch: 2/2, step 14039/16670 completed (loss: 0.16769960522651672, acc: 0.9553571343421936)
[2024-11-14 10:22:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:37][root][INFO] - Training Epoch: 2/2, step 14040/16670 completed (loss: 0.16939601302146912, acc: 0.9402984976768494)
[2024-11-14 10:22:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:38][root][INFO] - Training Epoch: 2/2, step 14041/16670 completed (loss: 0.11547084152698517, acc: 0.9652174115180969)
[2024-11-14 10:22:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:38][root][INFO] - Training Epoch: 2/2, step 14042/16670 completed (loss: 0.1118253767490387, acc: 0.9754098653793335)
[2024-11-14 10:22:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:38][root][INFO] - Training Epoch: 2/2, step 14043/16670 completed (loss: 0.2657533586025238, acc: 0.9363636374473572)
[2024-11-14 10:22:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:39][root][INFO] - Training Epoch: 2/2, step 14044/16670 completed (loss: 0.17486250400543213, acc: 0.9575163125991821)
[2024-11-14 10:22:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:39][root][INFO] - Training Epoch: 2/2, step 14045/16670 completed (loss: 0.3115179240703583, acc: 0.9272727370262146)
[2024-11-14 10:22:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:39][root][INFO] - Training Epoch: 2/2, step 14046/16670 completed (loss: 0.3904784619808197, acc: 0.8994082808494568)
[2024-11-14 10:22:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:40][root][INFO] - Training Epoch: 2/2, step 14047/16670 completed (loss: 0.3092060387134552, acc: 0.9324324131011963)
[2024-11-14 10:22:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:40][root][INFO] - Training Epoch: 2/2, step 14048/16670 completed (loss: 0.2130710780620575, acc: 0.944915235042572)
[2024-11-14 10:22:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:40][root][INFO] - Training Epoch: 2/2, step 14049/16670 completed (loss: 0.1814860850572586, acc: 0.9568106532096863)
[2024-11-14 10:22:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:41][root][INFO] - Training Epoch: 2/2, step 14050/16670 completed (loss: 0.33517831563949585, acc: 0.9193548560142517)
[2024-11-14 10:22:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:41][root][INFO] - Training Epoch: 2/2, step 14051/16670 completed (loss: 0.2641861140727997, acc: 0.9264705777168274)
[2024-11-14 10:22:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:42][root][INFO] - Training Epoch: 2/2, step 14052/16670 completed (loss: 0.13486316800117493, acc: 0.9589040875434875)
[2024-11-14 10:22:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:42][root][INFO] - Training Epoch: 2/2, step 14053/16670 completed (loss: 0.2327899932861328, acc: 0.9318181872367859)
[2024-11-14 10:22:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:42][root][INFO] - Training Epoch: 2/2, step 14054/16670 completed (loss: 0.11765671521425247, acc: 0.9784946441650391)
[2024-11-14 10:22:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:43][root][INFO] - Training Epoch: 2/2, step 14055/16670 completed (loss: 0.4949391484260559, acc: 0.8543046116828918)
[2024-11-14 10:22:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:43][root][INFO] - Training Epoch: 2/2, step 14056/16670 completed (loss: 0.22798943519592285, acc: 0.9314641952514648)
[2024-11-14 10:22:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:43][root][INFO] - Training Epoch: 2/2, step 14057/16670 completed (loss: 0.10780850052833557, acc: 0.9601770043373108)
[2024-11-14 10:22:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:44][root][INFO] - Training Epoch: 2/2, step 14058/16670 completed (loss: 0.2029322236776352, acc: 0.9341563582420349)
[2024-11-14 10:22:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:44][root][INFO] - Training Epoch: 2/2, step 14059/16670 completed (loss: 0.18638579547405243, acc: 0.9328858852386475)
[2024-11-14 10:22:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:44][root][INFO] - Training Epoch: 2/2, step 14060/16670 completed (loss: 0.22357812523841858, acc: 0.9389312863349915)
[2024-11-14 10:22:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:45][root][INFO] - Training Epoch: 2/2, step 14061/16670 completed (loss: 0.2908603847026825, acc: 0.8999999761581421)
[2024-11-14 10:22:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:45][root][INFO] - Training Epoch: 2/2, step 14062/16670 completed (loss: 0.14822180569171906, acc: 0.9575757384300232)
[2024-11-14 10:22:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:45][root][INFO] - Training Epoch: 2/2, step 14063/16670 completed (loss: 0.2392723709344864, acc: 0.9180327653884888)
[2024-11-14 10:22:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:46][root][INFO] - Training Epoch: 2/2, step 14064/16670 completed (loss: 0.25411269068717957, acc: 0.9234449863433838)
[2024-11-14 10:22:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:46][root][INFO] - Training Epoch: 2/2, step 14065/16670 completed (loss: 0.22043143212795258, acc: 0.945652186870575)
[2024-11-14 10:22:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:47][root][INFO] - Training Epoch: 2/2, step 14066/16670 completed (loss: 0.11530271917581558, acc: 0.95652174949646)
[2024-11-14 10:22:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:47][root][INFO] - Training Epoch: 2/2, step 14067/16670 completed (loss: 0.2590646743774414, acc: 0.930232584476471)
[2024-11-14 10:22:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:47][root][INFO] - Training Epoch: 2/2, step 14068/16670 completed (loss: 0.4721561372280121, acc: 0.8651685118675232)
[2024-11-14 10:22:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:48][root][INFO] - Training Epoch: 2/2, step 14069/16670 completed (loss: 0.25969696044921875, acc: 0.9220778942108154)
[2024-11-14 10:22:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:48][root][INFO] - Training Epoch: 2/2, step 14070/16670 completed (loss: 0.18310146033763885, acc: 0.9357798099517822)
[2024-11-14 10:22:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:48][root][INFO] - Training Epoch: 2/2, step 14071/16670 completed (loss: 0.2613932490348816, acc: 0.9382715821266174)
[2024-11-14 10:22:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:49][root][INFO] - Training Epoch: 2/2, step 14072/16670 completed (loss: 0.07280351221561432, acc: 0.9677419066429138)
[2024-11-14 10:22:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:49][root][INFO] - Training Epoch: 2/2, step 14073/16670 completed (loss: 0.1454118937253952, acc: 0.939068078994751)
[2024-11-14 10:22:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:49][root][INFO] - Training Epoch: 2/2, step 14074/16670 completed (loss: 0.23862655460834503, acc: 0.948051929473877)
[2024-11-14 10:22:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:50][root][INFO] - Training Epoch: 2/2, step 14075/16670 completed (loss: 0.2838953733444214, acc: 0.9306930899620056)
[2024-11-14 10:22:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:50][root][INFO] - Training Epoch: 2/2, step 14076/16670 completed (loss: 0.18575063347816467, acc: 0.9583333134651184)
[2024-11-14 10:22:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:50][root][INFO] - Training Epoch: 2/2, step 14077/16670 completed (loss: 0.15517452359199524, acc: 0.9645389914512634)
[2024-11-14 10:22:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:51][root][INFO] - Training Epoch: 2/2, step 14078/16670 completed (loss: 0.31487444043159485, acc: 0.9115044474601746)
[2024-11-14 10:22:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:51][root][INFO] - Training Epoch: 2/2, step 14079/16670 completed (loss: 0.138307586312294, acc: 0.9536082744598389)
[2024-11-14 10:22:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:51][root][INFO] - Training Epoch: 2/2, step 14080/16670 completed (loss: 0.15035799145698547, acc: 0.9677419066429138)
[2024-11-14 10:22:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:52][root][INFO] - Training Epoch: 2/2, step 14081/16670 completed (loss: 0.36586853861808777, acc: 0.8787878751754761)
[2024-11-14 10:22:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:52][root][INFO] - Training Epoch: 2/2, step 14082/16670 completed (loss: 0.21023201942443848, acc: 0.9473684430122375)
[2024-11-14 10:22:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:53][root][INFO] - Training Epoch: 2/2, step 14083/16670 completed (loss: 0.10067872703075409, acc: 0.976190447807312)
[2024-11-14 10:22:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:53][root][INFO] - Training Epoch: 2/2, step 14084/16670 completed (loss: 0.2605099380016327, acc: 0.9156626462936401)
[2024-11-14 10:22:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:53][root][INFO] - Training Epoch: 2/2, step 14085/16670 completed (loss: 0.14399152994155884, acc: 0.9586206674575806)
[2024-11-14 10:22:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:54][root][INFO] - Training Epoch: 2/2, step 14086/16670 completed (loss: 0.06919418275356293, acc: 0.9811320900917053)
[2024-11-14 10:22:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:54][root][INFO] - Training Epoch: 2/2, step 14087/16670 completed (loss: 0.34901243448257446, acc: 0.893750011920929)
[2024-11-14 10:22:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:54][root][INFO] - Training Epoch: 2/2, step 14088/16670 completed (loss: 0.42131707072257996, acc: 0.8905109763145447)
[2024-11-14 10:22:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:55][root][INFO] - Training Epoch: 2/2, step 14089/16670 completed (loss: 0.10595208406448364, acc: 0.9576271176338196)
[2024-11-14 10:22:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:55][root][INFO] - Training Epoch: 2/2, step 14090/16670 completed (loss: 0.13162696361541748, acc: 0.9586206674575806)
[2024-11-14 10:22:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:55][root][INFO] - Training Epoch: 2/2, step 14091/16670 completed (loss: 0.1870460957288742, acc: 0.9489051103591919)
[2024-11-14 10:22:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:56][root][INFO] - Training Epoch: 2/2, step 14092/16670 completed (loss: 0.11367929726839066, acc: 0.9590643048286438)
[2024-11-14 10:22:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:56][root][INFO] - Training Epoch: 2/2, step 14093/16670 completed (loss: 0.19658394157886505, acc: 0.9473684430122375)
[2024-11-14 10:22:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:56][root][INFO] - Training Epoch: 2/2, step 14094/16670 completed (loss: 0.25882354378700256, acc: 0.9545454382896423)
[2024-11-14 10:22:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:57][root][INFO] - Training Epoch: 2/2, step 14095/16670 completed (loss: 0.1136389672756195, acc: 0.9504132270812988)
[2024-11-14 10:22:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:57][root][INFO] - Training Epoch: 2/2, step 14096/16670 completed (loss: 0.1479577273130417, acc: 0.9717742204666138)
[2024-11-14 10:22:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:57][root][INFO] - Training Epoch: 2/2, step 14097/16670 completed (loss: 0.3583258092403412, acc: 0.9042553305625916)
[2024-11-14 10:22:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:58][root][INFO] - Training Epoch: 2/2, step 14098/16670 completed (loss: 0.298974871635437, acc: 0.9365079402923584)
[2024-11-14 10:22:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:58][root][INFO] - Training Epoch: 2/2, step 14099/16670 completed (loss: 0.07260029762983322, acc: 0.9840425252914429)
[2024-11-14 10:22:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:58][root][INFO] - Training Epoch: 2/2, step 14100/16670 completed (loss: 0.2474410980939865, acc: 0.9448529481887817)
[2024-11-14 10:22:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:59][root][INFO] - Training Epoch: 2/2, step 14101/16670 completed (loss: 0.32620060443878174, acc: 0.929411768913269)
[2024-11-14 10:22:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:59][root][INFO] - Training Epoch: 2/2, step 14102/16670 completed (loss: 0.2968921661376953, acc: 0.9207921028137207)
[2024-11-14 10:22:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:22:59][root][INFO] - Training Epoch: 2/2, step 14103/16670 completed (loss: 0.3600368797779083, acc: 0.9276315569877625)
[2024-11-14 10:22:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:00][root][INFO] - Training Epoch: 2/2, step 14104/16670 completed (loss: 0.1515408754348755, acc: 0.9502262473106384)
[2024-11-14 10:23:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:00][root][INFO] - Training Epoch: 2/2, step 14105/16670 completed (loss: 0.22345197200775146, acc: 0.9253731369972229)
[2024-11-14 10:23:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:00][root][INFO] - Training Epoch: 2/2, step 14106/16670 completed (loss: 0.10483533889055252, acc: 0.9682539701461792)
[2024-11-14 10:23:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:00][root][INFO] - Training Epoch: 2/2, step 14107/16670 completed (loss: 0.1868581622838974, acc: 0.9548386931419373)
[2024-11-14 10:23:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:01][root][INFO] - Training Epoch: 2/2, step 14108/16670 completed (loss: 0.03221431374549866, acc: 0.9929577708244324)
[2024-11-14 10:23:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:01][root][INFO] - Training Epoch: 2/2, step 14109/16670 completed (loss: 0.10893760621547699, acc: 0.9718309640884399)
[2024-11-14 10:23:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:01][root][INFO] - Training Epoch: 2/2, step 14110/16670 completed (loss: 0.5974326133728027, acc: 0.8284313678741455)
[2024-11-14 10:23:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:02][root][INFO] - Training Epoch: 2/2, step 14111/16670 completed (loss: 0.07331550121307373, acc: 0.9845361113548279)
[2024-11-14 10:23:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:02][root][INFO] - Training Epoch: 2/2, step 14112/16670 completed (loss: 0.2692401111125946, acc: 0.9224806427955627)
[2024-11-14 10:23:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:02][root][INFO] - Training Epoch: 2/2, step 14113/16670 completed (loss: 0.29938334226608276, acc: 0.9306930899620056)
[2024-11-14 10:23:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:03][root][INFO] - Training Epoch: 2/2, step 14114/16670 completed (loss: 0.0583270899951458, acc: 0.9784946441650391)
[2024-11-14 10:23:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:03][root][INFO] - Training Epoch: 2/2, step 14115/16670 completed (loss: 0.06143658608198166, acc: 0.9858490824699402)
[2024-11-14 10:23:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:03][root][INFO] - Training Epoch: 2/2, step 14116/16670 completed (loss: 0.20212715864181519, acc: 0.9248554706573486)
[2024-11-14 10:23:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:04][root][INFO] - Training Epoch: 2/2, step 14117/16670 completed (loss: 0.24801823496818542, acc: 0.9371727705001831)
[2024-11-14 10:23:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:04][root][INFO] - Training Epoch: 2/2, step 14118/16670 completed (loss: 0.08521085977554321, acc: 0.9738219976425171)
[2024-11-14 10:23:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:04][root][INFO] - Training Epoch: 2/2, step 14119/16670 completed (loss: 0.24240949749946594, acc: 0.9271255135536194)
[2024-11-14 10:23:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:05][root][INFO] - Training Epoch: 2/2, step 14120/16670 completed (loss: 0.1063137874007225, acc: 0.9801980257034302)
[2024-11-14 10:23:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:05][root][INFO] - Training Epoch: 2/2, step 14121/16670 completed (loss: 0.20445825159549713, acc: 0.9487179517745972)
[2024-11-14 10:23:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:06][root][INFO] - Training Epoch: 2/2, step 14122/16670 completed (loss: 0.6599665880203247, acc: 0.8653846383094788)
[2024-11-14 10:23:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:06][root][INFO] - Training Epoch: 2/2, step 14123/16670 completed (loss: 0.10080809146165848, acc: 0.9701492786407471)
[2024-11-14 10:23:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:06][root][INFO] - Training Epoch: 2/2, step 14124/16670 completed (loss: 0.30395832657814026, acc: 0.9270833134651184)
[2024-11-14 10:23:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:07][root][INFO] - Training Epoch: 2/2, step 14125/16670 completed (loss: 0.1438625305891037, acc: 0.9579831957817078)
[2024-11-14 10:23:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:07][root][INFO] - Training Epoch: 2/2, step 14126/16670 completed (loss: 0.21946150064468384, acc: 0.9452054500579834)
[2024-11-14 10:23:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:07][root][INFO] - Training Epoch: 2/2, step 14127/16670 completed (loss: 0.3313245475292206, acc: 0.9210526347160339)
[2024-11-14 10:23:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:08][root][INFO] - Training Epoch: 2/2, step 14128/16670 completed (loss: 0.312494695186615, acc: 0.9188191890716553)
[2024-11-14 10:23:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:08][root][INFO] - Training Epoch: 2/2, step 14129/16670 completed (loss: 0.2587597072124481, acc: 0.9172932505607605)
[2024-11-14 10:23:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:08][root][INFO] - Training Epoch: 2/2, step 14130/16670 completed (loss: 0.3602222800254822, acc: 0.9252336621284485)
[2024-11-14 10:23:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:09][root][INFO] - Training Epoch: 2/2, step 14131/16670 completed (loss: 0.2553858757019043, acc: 0.9288703203201294)
[2024-11-14 10:23:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:09][root][INFO] - Training Epoch: 2/2, step 14132/16670 completed (loss: 0.12490367889404297, acc: 0.9719626307487488)
[2024-11-14 10:23:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:09][root][INFO] - Training Epoch: 2/2, step 14133/16670 completed (loss: 0.14092478156089783, acc: 0.9645669460296631)
[2024-11-14 10:23:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:10][root][INFO] - Training Epoch: 2/2, step 14134/16670 completed (loss: 0.2804156541824341, acc: 0.9235668778419495)
[2024-11-14 10:23:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:10][root][INFO] - Training Epoch: 2/2, step 14135/16670 completed (loss: 0.09929630160331726, acc: 0.9784946441650391)
[2024-11-14 10:23:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:10][root][INFO] - Training Epoch: 2/2, step 14136/16670 completed (loss: 0.3976011872291565, acc: 0.8888888955116272)
[2024-11-14 10:23:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:11][root][INFO] - Training Epoch: 2/2, step 14137/16670 completed (loss: 0.1731584221124649, acc: 0.9583333134651184)
[2024-11-14 10:23:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:11][root][INFO] - Training Epoch: 2/2, step 14138/16670 completed (loss: 0.17601698637008667, acc: 0.9626865386962891)
[2024-11-14 10:23:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:11][root][INFO] - Training Epoch: 2/2, step 14139/16670 completed (loss: 0.04851026087999344, acc: 0.9931034445762634)
[2024-11-14 10:23:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:12][root][INFO] - Training Epoch: 2/2, step 14140/16670 completed (loss: 0.09468792378902435, acc: 0.9882352948188782)
[2024-11-14 10:23:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:12][root][INFO] - Training Epoch: 2/2, step 14141/16670 completed (loss: 0.2437940537929535, acc: 0.918181836605072)
[2024-11-14 10:23:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:12][root][INFO] - Training Epoch: 2/2, step 14142/16670 completed (loss: 0.09094754606485367, acc: 0.9679487347602844)
[2024-11-14 10:23:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:13][root][INFO] - Training Epoch: 2/2, step 14143/16670 completed (loss: 0.05011933669447899, acc: 0.9944751262664795)
[2024-11-14 10:23:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:13][root][INFO] - Training Epoch: 2/2, step 14144/16670 completed (loss: 0.08786261081695557, acc: 0.9718309640884399)
[2024-11-14 10:23:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:13][root][INFO] - Training Epoch: 2/2, step 14145/16670 completed (loss: 0.08380559086799622, acc: 0.9846153855323792)
[2024-11-14 10:23:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:14][root][INFO] - Training Epoch: 2/2, step 14146/16670 completed (loss: 0.3031134009361267, acc: 0.9126637578010559)
[2024-11-14 10:23:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:14][root][INFO] - Training Epoch: 2/2, step 14147/16670 completed (loss: 0.18810492753982544, acc: 0.9402390718460083)
[2024-11-14 10:23:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:14][root][INFO] - Training Epoch: 2/2, step 14148/16670 completed (loss: 0.2985188364982605, acc: 0.9176470637321472)
[2024-11-14 10:23:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:15][root][INFO] - Training Epoch: 2/2, step 14149/16670 completed (loss: 0.16204355657100677, acc: 0.960698664188385)
[2024-11-14 10:23:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:15][root][INFO] - Training Epoch: 2/2, step 14150/16670 completed (loss: 0.22557824850082397, acc: 0.939393937587738)
[2024-11-14 10:23:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:15][root][INFO] - Training Epoch: 2/2, step 14151/16670 completed (loss: 0.14044739305973053, acc: 0.9722222089767456)
[2024-11-14 10:23:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:16][root][INFO] - Training Epoch: 2/2, step 14152/16670 completed (loss: 0.46181827783584595, acc: 0.8518518805503845)
[2024-11-14 10:23:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:16][root][INFO] - Training Epoch: 2/2, step 14153/16670 completed (loss: 0.46027496457099915, acc: 0.8692307472229004)
[2024-11-14 10:23:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:17][root][INFO] - Training Epoch: 2/2, step 14154/16670 completed (loss: 0.0552179329097271, acc: 0.981249988079071)
[2024-11-14 10:23:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:17][root][INFO] - Training Epoch: 2/2, step 14155/16670 completed (loss: 0.19309942424297333, acc: 0.9354838728904724)
[2024-11-14 10:23:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:17][root][INFO] - Training Epoch: 2/2, step 14156/16670 completed (loss: 0.13298346102237701, acc: 0.9607843160629272)
[2024-11-14 10:23:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:18][root][INFO] - Training Epoch: 2/2, step 14157/16670 completed (loss: 0.3125264048576355, acc: 0.8961039185523987)
[2024-11-14 10:23:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:18][root][INFO] - Training Epoch: 2/2, step 14158/16670 completed (loss: 0.053435537964105606, acc: 0.9750000238418579)
[2024-11-14 10:23:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:18][root][INFO] - Training Epoch: 2/2, step 14159/16670 completed (loss: 0.11037254333496094, acc: 0.9635416865348816)
[2024-11-14 10:23:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:19][root][INFO] - Training Epoch: 2/2, step 14160/16670 completed (loss: 0.1996605545282364, acc: 0.9439252614974976)
[2024-11-14 10:23:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:19][root][INFO] - Training Epoch: 2/2, step 14161/16670 completed (loss: 0.17423279583454132, acc: 0.940397322177887)
[2024-11-14 10:23:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:19][root][INFO] - Training Epoch: 2/2, step 14162/16670 completed (loss: 0.08129067718982697, acc: 0.9729729890823364)
[2024-11-14 10:23:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:20][root][INFO] - Training Epoch: 2/2, step 14163/16670 completed (loss: 0.11024177074432373, acc: 0.9655172228813171)
[2024-11-14 10:23:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:20][root][INFO] - Training Epoch: 2/2, step 14164/16670 completed (loss: 0.21825279295444489, acc: 0.939393937587738)
[2024-11-14 10:23:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:21][root][INFO] - Training Epoch: 2/2, step 14165/16670 completed (loss: 0.09267337620258331, acc: 0.9741697311401367)
[2024-11-14 10:23:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:21][root][INFO] - Training Epoch: 2/2, step 14166/16670 completed (loss: 0.24499914050102234, acc: 0.9337349534034729)
[2024-11-14 10:23:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:21][root][INFO] - Training Epoch: 2/2, step 14167/16670 completed (loss: 0.2637139558792114, acc: 0.895348846912384)
[2024-11-14 10:23:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:22][root][INFO] - Training Epoch: 2/2, step 14168/16670 completed (loss: 0.0682254433631897, acc: 0.9801324605941772)
[2024-11-14 10:23:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:22][root][INFO] - Training Epoch: 2/2, step 14169/16670 completed (loss: 0.2009682059288025, acc: 0.9358288645744324)
[2024-11-14 10:23:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:22][root][INFO] - Training Epoch: 2/2, step 14170/16670 completed (loss: 0.15700511634349823, acc: 0.9279999732971191)
[2024-11-14 10:23:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:23][root][INFO] - Training Epoch: 2/2, step 14171/16670 completed (loss: 0.019897395744919777, acc: 0.9946808218955994)
[2024-11-14 10:23:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:23][root][INFO] - Training Epoch: 2/2, step 14172/16670 completed (loss: 0.13335148990154266, acc: 0.948387086391449)
[2024-11-14 10:23:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:23][root][INFO] - Training Epoch: 2/2, step 14173/16670 completed (loss: 0.04412072151899338, acc: 0.9826086759567261)
[2024-11-14 10:23:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:24][root][INFO] - Training Epoch: 2/2, step 14174/16670 completed (loss: 0.06283506751060486, acc: 0.977477490901947)
[2024-11-14 10:23:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:24][root][INFO] - Training Epoch: 2/2, step 14175/16670 completed (loss: 0.3001576364040375, acc: 0.9230769276618958)
[2024-11-14 10:23:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:24][root][INFO] - Training Epoch: 2/2, step 14176/16670 completed (loss: 0.05866856873035431, acc: 0.991525411605835)
[2024-11-14 10:23:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:25][root][INFO] - Training Epoch: 2/2, step 14177/16670 completed (loss: 0.25726908445358276, acc: 0.9425837397575378)
[2024-11-14 10:23:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:25][root][INFO] - Training Epoch: 2/2, step 14178/16670 completed (loss: 0.07311934977769852, acc: 0.9662162065505981)
[2024-11-14 10:23:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:25][root][INFO] - Training Epoch: 2/2, step 14179/16670 completed (loss: 0.1490640640258789, acc: 0.9612902998924255)
[2024-11-14 10:23:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:26][root][INFO] - Training Epoch: 2/2, step 14180/16670 completed (loss: 0.15786604583263397, acc: 0.949999988079071)
[2024-11-14 10:23:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:26][root][INFO] - Training Epoch: 2/2, step 14181/16670 completed (loss: 0.1581721007823944, acc: 0.9647887349128723)
[2024-11-14 10:23:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:27][root][INFO] - Training Epoch: 2/2, step 14182/16670 completed (loss: 0.382479190826416, acc: 0.901098906993866)
[2024-11-14 10:23:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:27][root][INFO] - Training Epoch: 2/2, step 14183/16670 completed (loss: 0.02084035612642765, acc: 0.9923664331436157)
[2024-11-14 10:23:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:27][root][INFO] - Training Epoch: 2/2, step 14184/16670 completed (loss: 0.13317403197288513, acc: 0.9677419066429138)
[2024-11-14 10:23:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:28][root][INFO] - Training Epoch: 2/2, step 14185/16670 completed (loss: 0.10569801181554794, acc: 0.970588207244873)
[2024-11-14 10:23:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:28][root][INFO] - Training Epoch: 2/2, step 14186/16670 completed (loss: 0.10497140139341354, acc: 0.9660193920135498)
[2024-11-14 10:23:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:28][root][INFO] - Training Epoch: 2/2, step 14187/16670 completed (loss: 0.12866146862506866, acc: 0.9509202241897583)
[2024-11-14 10:23:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:29][root][INFO] - Training Epoch: 2/2, step 14188/16670 completed (loss: 0.24682514369487762, acc: 0.9175257682800293)
[2024-11-14 10:23:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:29][root][INFO] - Training Epoch: 2/2, step 14189/16670 completed (loss: 0.33632102608680725, acc: 0.9339622855186462)
[2024-11-14 10:23:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:29][root][INFO] - Training Epoch: 2/2, step 14190/16670 completed (loss: 0.11024843901395798, acc: 0.9801324605941772)
[2024-11-14 10:23:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:30][root][INFO] - Training Epoch: 2/2, step 14191/16670 completed (loss: 0.3178296387195587, acc: 0.9196428656578064)
[2024-11-14 10:23:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:30][root][INFO] - Training Epoch: 2/2, step 14192/16670 completed (loss: 0.24501074850559235, acc: 0.9407894611358643)
[2024-11-14 10:23:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:30][root][INFO] - Training Epoch: 2/2, step 14193/16670 completed (loss: 0.07639224827289581, acc: 0.9836956262588501)
[2024-11-14 10:23:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:31][root][INFO] - Training Epoch: 2/2, step 14194/16670 completed (loss: 0.11443831026554108, acc: 0.9680851101875305)
[2024-11-14 10:23:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:31][root][INFO] - Training Epoch: 2/2, step 14195/16670 completed (loss: 0.1621537059545517, acc: 0.9694656729698181)
[2024-11-14 10:23:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:31][root][INFO] - Training Epoch: 2/2, step 14196/16670 completed (loss: 0.1527533233165741, acc: 0.9521530866622925)
[2024-11-14 10:23:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:32][root][INFO] - Training Epoch: 2/2, step 14197/16670 completed (loss: 0.2147105634212494, acc: 0.9329268336296082)
[2024-11-14 10:23:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:32][root][INFO] - Training Epoch: 2/2, step 14198/16670 completed (loss: 0.2297227382659912, acc: 0.9453551769256592)
[2024-11-14 10:23:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:32][root][INFO] - Training Epoch: 2/2, step 14199/16670 completed (loss: 0.1845119297504425, acc: 0.9601593613624573)
[2024-11-14 10:23:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:33][root][INFO] - Training Epoch: 2/2, step 14200/16670 completed (loss: 0.09693309664726257, acc: 0.9728682041168213)
[2024-11-14 10:23:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:33][root][INFO] - Training Epoch: 2/2, step 14201/16670 completed (loss: 0.6690949201583862, acc: 0.7666666507720947)
[2024-11-14 10:23:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:33][root][INFO] - Training Epoch: 2/2, step 14202/16670 completed (loss: 0.14150884747505188, acc: 0.9436619877815247)
[2024-11-14 10:23:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:34][root][INFO] - Training Epoch: 2/2, step 14203/16670 completed (loss: 0.15680404007434845, acc: 0.9664804339408875)
[2024-11-14 10:23:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:34][root][INFO] - Training Epoch: 2/2, step 14204/16670 completed (loss: 0.17937684059143066, acc: 0.9458128213882446)
[2024-11-14 10:23:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:34][root][INFO] - Training Epoch: 2/2, step 14205/16670 completed (loss: 0.1529974639415741, acc: 0.963350772857666)
[2024-11-14 10:23:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:35][root][INFO] - Training Epoch: 2/2, step 14206/16670 completed (loss: 0.2229064255952835, acc: 0.9437751173973083)
[2024-11-14 10:23:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:35][root][INFO] - Training Epoch: 2/2, step 14207/16670 completed (loss: 0.45495402812957764, acc: 0.9007633328437805)
[2024-11-14 10:23:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:36][root][INFO] - Training Epoch: 2/2, step 14208/16670 completed (loss: 0.5327284336090088, acc: 0.8709677457809448)
[2024-11-14 10:23:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:36][root][INFO] - Training Epoch: 2/2, step 14209/16670 completed (loss: 0.2408602088689804, acc: 0.9406779408454895)
[2024-11-14 10:23:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:36][root][INFO] - Training Epoch: 2/2, step 14210/16670 completed (loss: 0.1908019483089447, acc: 0.9583333134651184)
[2024-11-14 10:23:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:36][root][INFO] - Training Epoch: 2/2, step 14211/16670 completed (loss: 0.02813120372593403, acc: 1.0)
[2024-11-14 10:23:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:37][root][INFO] - Training Epoch: 2/2, step 14212/16670 completed (loss: 0.08363105356693268, acc: 0.9746192693710327)
[2024-11-14 10:23:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:37][root][INFO] - Training Epoch: 2/2, step 14213/16670 completed (loss: 0.14382801949977875, acc: 0.9387755393981934)
[2024-11-14 10:23:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:38][root][INFO] - Training Epoch: 2/2, step 14214/16670 completed (loss: 0.16535602509975433, acc: 0.9504950642585754)
[2024-11-14 10:23:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:38][root][INFO] - Training Epoch: 2/2, step 14215/16670 completed (loss: 0.037042003124952316, acc: 0.9947916865348816)
[2024-11-14 10:23:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:38][root][INFO] - Training Epoch: 2/2, step 14216/16670 completed (loss: 0.13108283281326294, acc: 0.9663865566253662)
[2024-11-14 10:23:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:39][root][INFO] - Training Epoch: 2/2, step 14217/16670 completed (loss: 0.2213662713766098, acc: 0.9285714030265808)
[2024-11-14 10:23:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:39][root][INFO] - Training Epoch: 2/2, step 14218/16670 completed (loss: 0.31308355927467346, acc: 0.9136690497398376)
[2024-11-14 10:23:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:39][root][INFO] - Training Epoch: 2/2, step 14219/16670 completed (loss: 0.27024152874946594, acc: 0.9154929518699646)
[2024-11-14 10:23:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:40][root][INFO] - Training Epoch: 2/2, step 14220/16670 completed (loss: 0.11129634082317352, acc: 0.966292142868042)
[2024-11-14 10:23:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:40][root][INFO] - Training Epoch: 2/2, step 14221/16670 completed (loss: 0.1137266755104065, acc: 0.9784946441650391)
[2024-11-14 10:23:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:40][root][INFO] - Training Epoch: 2/2, step 14222/16670 completed (loss: 0.047693196684122086, acc: 0.984375)
[2024-11-14 10:23:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:41][root][INFO] - Training Epoch: 2/2, step 14223/16670 completed (loss: 0.15790750086307526, acc: 0.9611940383911133)
[2024-11-14 10:23:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:41][root][INFO] - Training Epoch: 2/2, step 14224/16670 completed (loss: 0.2034282386302948, acc: 0.9502262473106384)
[2024-11-14 10:23:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:41][root][INFO] - Training Epoch: 2/2, step 14225/16670 completed (loss: 0.17650625109672546, acc: 0.9702970385551453)
[2024-11-14 10:23:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:42][root][INFO] - Training Epoch: 2/2, step 14226/16670 completed (loss: 0.11384779214859009, acc: 0.9752475023269653)
[2024-11-14 10:23:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:42][root][INFO] - Training Epoch: 2/2, step 14227/16670 completed (loss: 0.2160252332687378, acc: 0.9446640610694885)
[2024-11-14 10:23:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:42][root][INFO] - Training Epoch: 2/2, step 14228/16670 completed (loss: 0.16636957228183746, acc: 0.9735099077224731)
[2024-11-14 10:23:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:43][root][INFO] - Training Epoch: 2/2, step 14229/16670 completed (loss: 0.2731950581073761, acc: 0.929729700088501)
[2024-11-14 10:23:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:43][root][INFO] - Training Epoch: 2/2, step 14230/16670 completed (loss: 0.13845297694206238, acc: 0.961904764175415)
[2024-11-14 10:23:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:43][root][INFO] - Training Epoch: 2/2, step 14231/16670 completed (loss: 0.21296760439872742, acc: 0.9117646813392639)
[2024-11-14 10:23:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:44][root][INFO] - Training Epoch: 2/2, step 14232/16670 completed (loss: 0.1323520988225937, acc: 0.95652174949646)
[2024-11-14 10:23:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:44][root][INFO] - Training Epoch: 2/2, step 14233/16670 completed (loss: 0.26139548420906067, acc: 0.9315789341926575)
[2024-11-14 10:23:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:45][root][INFO] - Training Epoch: 2/2, step 14234/16670 completed (loss: 0.05007944628596306, acc: 0.9855072498321533)
[2024-11-14 10:23:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:45][root][INFO] - Training Epoch: 2/2, step 14235/16670 completed (loss: 0.291462242603302, acc: 0.9480000138282776)
[2024-11-14 10:23:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:45][root][INFO] - Training Epoch: 2/2, step 14236/16670 completed (loss: 0.22346876561641693, acc: 0.9444444179534912)
[2024-11-14 10:23:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:46][root][INFO] - Training Epoch: 2/2, step 14237/16670 completed (loss: 0.19785189628601074, acc: 0.9496855139732361)
[2024-11-14 10:23:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:46][root][INFO] - Training Epoch: 2/2, step 14238/16670 completed (loss: 0.18059910833835602, acc: 0.957446813583374)
[2024-11-14 10:23:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:46][root][INFO] - Training Epoch: 2/2, step 14239/16670 completed (loss: 0.15565373003482819, acc: 0.9748427867889404)
[2024-11-14 10:23:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:47][root][INFO] - Training Epoch: 2/2, step 14240/16670 completed (loss: 0.07093790173530579, acc: 0.9852941036224365)
[2024-11-14 10:23:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:47][root][INFO] - Training Epoch: 2/2, step 14241/16670 completed (loss: 0.21028248965740204, acc: 0.9421965479850769)
[2024-11-14 10:23:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:47][root][INFO] - Training Epoch: 2/2, step 14242/16670 completed (loss: 0.17195472121238708, acc: 0.9567567706108093)
[2024-11-14 10:23:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:48][root][INFO] - Training Epoch: 2/2, step 14243/16670 completed (loss: 0.07642342895269394, acc: 0.9778761267662048)
[2024-11-14 10:23:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:48][root][INFO] - Training Epoch: 2/2, step 14244/16670 completed (loss: 0.2868947982788086, acc: 0.913241982460022)
[2024-11-14 10:23:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:48][root][INFO] - Training Epoch: 2/2, step 14245/16670 completed (loss: 0.26569345593452454, acc: 0.9324324131011963)
[2024-11-14 10:23:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:49][root][INFO] - Training Epoch: 2/2, step 14246/16670 completed (loss: 0.35514265298843384, acc: 0.9127907156944275)
[2024-11-14 10:23:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:49][root][INFO] - Training Epoch: 2/2, step 14247/16670 completed (loss: 0.14442385733127594, acc: 0.9602649211883545)
[2024-11-14 10:23:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:49][root][INFO] - Training Epoch: 2/2, step 14248/16670 completed (loss: 0.14856120944023132, acc: 0.9578947424888611)
[2024-11-14 10:23:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:50][root][INFO] - Training Epoch: 2/2, step 14249/16670 completed (loss: 0.06034054979681969, acc: 0.978723406791687)
[2024-11-14 10:23:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:50][root][INFO] - Training Epoch: 2/2, step 14250/16670 completed (loss: 0.15212593972682953, acc: 0.9653179049491882)
[2024-11-14 10:23:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:50][root][INFO] - Training Epoch: 2/2, step 14251/16670 completed (loss: 0.1839359700679779, acc: 0.95652174949646)
[2024-11-14 10:23:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:50][root][INFO] - Training Epoch: 2/2, step 14252/16670 completed (loss: 0.09788829833269119, acc: 0.9732142686843872)
[2024-11-14 10:23:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:51][root][INFO] - Training Epoch: 2/2, step 14253/16670 completed (loss: 0.06202816218137741, acc: 0.970588207244873)
[2024-11-14 10:23:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:51][root][INFO] - Training Epoch: 2/2, step 14254/16670 completed (loss: 0.17346248030662537, acc: 0.9513108730316162)
[2024-11-14 10:23:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:51][root][INFO] - Training Epoch: 2/2, step 14255/16670 completed (loss: 0.21137188374996185, acc: 0.9366196990013123)
[2024-11-14 10:23:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:52][root][INFO] - Training Epoch: 2/2, step 14256/16670 completed (loss: 0.12858465313911438, acc: 0.9584905505180359)
[2024-11-14 10:23:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:52][root][INFO] - Training Epoch: 2/2, step 14257/16670 completed (loss: 0.18975135684013367, acc: 0.9575471878051758)
[2024-11-14 10:23:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:52][root][INFO] - Training Epoch: 2/2, step 14258/16670 completed (loss: 0.20230738818645477, acc: 0.938095211982727)
[2024-11-14 10:23:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:53][root][INFO] - Training Epoch: 2/2, step 14259/16670 completed (loss: 0.13498137891292572, acc: 0.9691630005836487)
[2024-11-14 10:23:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:53][root][INFO] - Training Epoch: 2/2, step 14260/16670 completed (loss: 0.06535662710666656, acc: 0.9874213933944702)
[2024-11-14 10:23:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:53][root][INFO] - Training Epoch: 2/2, step 14261/16670 completed (loss: 0.13788534700870514, acc: 0.9473684430122375)
[2024-11-14 10:23:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:54][root][INFO] - Training Epoch: 2/2, step 14262/16670 completed (loss: 0.023767584934830666, acc: 0.9954751133918762)
[2024-11-14 10:23:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:54][root][INFO] - Training Epoch: 2/2, step 14263/16670 completed (loss: 0.21171727776527405, acc: 0.9392523169517517)
[2024-11-14 10:23:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:54][root][INFO] - Training Epoch: 2/2, step 14264/16670 completed (loss: 0.05733718350529671, acc: 0.9884615540504456)
[2024-11-14 10:23:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:54][root][INFO] - Training Epoch: 2/2, step 14265/16670 completed (loss: 0.056602418422698975, acc: 0.9910714030265808)
[2024-11-14 10:23:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:55][root][INFO] - Training Epoch: 2/2, step 14266/16670 completed (loss: 0.19846363365650177, acc: 0.9516128897666931)
[2024-11-14 10:23:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:55][root][INFO] - Training Epoch: 2/2, step 14267/16670 completed (loss: 0.10393493622541428, acc: 0.98046875)
[2024-11-14 10:23:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:55][root][INFO] - Training Epoch: 2/2, step 14268/16670 completed (loss: 0.07587830722332001, acc: 0.9848942756652832)
[2024-11-14 10:23:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:56][root][INFO] - Training Epoch: 2/2, step 14269/16670 completed (loss: 0.1618531048297882, acc: 0.9447513818740845)
[2024-11-14 10:23:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:56][root][INFO] - Training Epoch: 2/2, step 14270/16670 completed (loss: 0.15915493667125702, acc: 0.9615384340286255)
[2024-11-14 10:23:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:56][root][INFO] - Training Epoch: 2/2, step 14271/16670 completed (loss: 0.3530209958553314, acc: 0.9064327478408813)
[2024-11-14 10:23:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:57][root][INFO] - Training Epoch: 2/2, step 14272/16670 completed (loss: 0.13938342034816742, acc: 0.9731543660163879)
[2024-11-14 10:23:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:57][root][INFO] - Training Epoch: 2/2, step 14273/16670 completed (loss: 0.044792819768190384, acc: 0.9857142567634583)
[2024-11-14 10:23:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:57][root][INFO] - Training Epoch: 2/2, step 14274/16670 completed (loss: 0.16563282907009125, acc: 0.9518072009086609)
[2024-11-14 10:23:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:58][root][INFO] - Training Epoch: 2/2, step 14275/16670 completed (loss: 0.02125677652657032, acc: 1.0)
[2024-11-14 10:23:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:58][root][INFO] - Training Epoch: 2/2, step 14276/16670 completed (loss: 0.12394701689481735, acc: 0.974554717540741)
[2024-11-14 10:23:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:58][root][INFO] - Training Epoch: 2/2, step 14277/16670 completed (loss: 0.2353287637233734, acc: 0.9352940917015076)
[2024-11-14 10:23:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:58][root][INFO] - Training Epoch: 2/2, step 14278/16670 completed (loss: 0.02876969799399376, acc: 0.9939393997192383)
[2024-11-14 10:23:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:59][root][INFO] - Training Epoch: 2/2, step 14279/16670 completed (loss: 0.04048595204949379, acc: 0.9839357137680054)
[2024-11-14 10:23:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:59][root][INFO] - Training Epoch: 2/2, step 14280/16670 completed (loss: 0.1095568835735321, acc: 0.9599999785423279)
[2024-11-14 10:23:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:23:59][root][INFO] - Training Epoch: 2/2, step 14281/16670 completed (loss: 0.1709297001361847, acc: 0.9462365508079529)
[2024-11-14 10:23:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:00][root][INFO] - Training Epoch: 2/2, step 14282/16670 completed (loss: 0.038069192320108414, acc: 0.9883720874786377)
[2024-11-14 10:24:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:00][root][INFO] - Training Epoch: 2/2, step 14283/16670 completed (loss: 0.13902291655540466, acc: 0.9494949579238892)
[2024-11-14 10:24:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:00][root][INFO] - Training Epoch: 2/2, step 14284/16670 completed (loss: 0.04126085713505745, acc: 0.9912280440330505)
[2024-11-14 10:24:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:01][root][INFO] - Training Epoch: 2/2, step 14285/16670 completed (loss: 0.09935643523931503, acc: 0.9673202633857727)
[2024-11-14 10:24:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:01][root][INFO] - Training Epoch: 2/2, step 14286/16670 completed (loss: 0.12243038415908813, acc: 0.9629629850387573)
[2024-11-14 10:24:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:01][root][INFO] - Training Epoch: 2/2, step 14287/16670 completed (loss: 0.2143244743347168, acc: 0.9405940771102905)
[2024-11-14 10:24:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:02][root][INFO] - Training Epoch: 2/2, step 14288/16670 completed (loss: 0.07093033194541931, acc: 0.9813084006309509)
[2024-11-14 10:24:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:02][root][INFO] - Training Epoch: 2/2, step 14289/16670 completed (loss: 0.08740126341581345, acc: 0.9627906680107117)
[2024-11-14 10:24:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:02][root][INFO] - Training Epoch: 2/2, step 14290/16670 completed (loss: 0.17085334658622742, acc: 0.9601989984512329)
[2024-11-14 10:24:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:02][root][INFO] - Training Epoch: 2/2, step 14291/16670 completed (loss: 0.1424138844013214, acc: 0.9577465057373047)
[2024-11-14 10:24:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:03][root][INFO] - Training Epoch: 2/2, step 14292/16670 completed (loss: 0.05104057490825653, acc: 0.9830508232116699)
[2024-11-14 10:24:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:03][root][INFO] - Training Epoch: 2/2, step 14293/16670 completed (loss: 0.28576454520225525, acc: 0.9195402264595032)
[2024-11-14 10:24:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:03][root][INFO] - Training Epoch: 2/2, step 14294/16670 completed (loss: 0.046981994062662125, acc: 0.9862068891525269)
[2024-11-14 10:24:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:04][root][INFO] - Training Epoch: 2/2, step 14295/16670 completed (loss: 0.19777075946331024, acc: 0.9298245906829834)
[2024-11-14 10:24:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:04][root][INFO] - Training Epoch: 2/2, step 14296/16670 completed (loss: 0.06906703114509583, acc: 0.9819276928901672)
[2024-11-14 10:24:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:04][root][INFO] - Training Epoch: 2/2, step 14297/16670 completed (loss: 0.15260837972164154, acc: 0.9444444179534912)
[2024-11-14 10:24:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:05][root][INFO] - Training Epoch: 2/2, step 14298/16670 completed (loss: 0.14619354903697968, acc: 0.982758641242981)
[2024-11-14 10:24:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:05][root][INFO] - Training Epoch: 2/2, step 14299/16670 completed (loss: 0.14244858920574188, acc: 0.9382715821266174)
[2024-11-14 10:24:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:05][root][INFO] - Training Epoch: 2/2, step 14300/16670 completed (loss: 0.3044743835926056, acc: 0.8978102207183838)
[2024-11-14 10:24:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:06][root][INFO] - Training Epoch: 2/2, step 14301/16670 completed (loss: 0.2807248532772064, acc: 0.9224137663841248)
[2024-11-14 10:24:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:06][root][INFO] - Training Epoch: 2/2, step 14302/16670 completed (loss: 0.14092279970645905, acc: 0.9587628841400146)
[2024-11-14 10:24:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:06][root][INFO] - Training Epoch: 2/2, step 14303/16670 completed (loss: 0.18276427686214447, acc: 0.9607843160629272)
[2024-11-14 10:24:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:07][root][INFO] - Training Epoch: 2/2, step 14304/16670 completed (loss: 0.10646222531795502, acc: 0.9820359349250793)
[2024-11-14 10:24:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:07][root][INFO] - Training Epoch: 2/2, step 14305/16670 completed (loss: 0.06610821187496185, acc: 0.976190447807312)
[2024-11-14 10:24:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:07][root][INFO] - Training Epoch: 2/2, step 14306/16670 completed (loss: 0.04482850804924965, acc: 0.9878048896789551)
[2024-11-14 10:24:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:07][root][INFO] - Training Epoch: 2/2, step 14307/16670 completed (loss: 0.137640580534935, acc: 0.963302731513977)
[2024-11-14 10:24:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:08][root][INFO] - Training Epoch: 2/2, step 14308/16670 completed (loss: 0.0844414159655571, acc: 0.9610389471054077)
[2024-11-14 10:24:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:08][root][INFO] - Training Epoch: 2/2, step 14309/16670 completed (loss: 0.19377322494983673, acc: 0.9455782175064087)
[2024-11-14 10:24:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:08][root][INFO] - Training Epoch: 2/2, step 14310/16670 completed (loss: 0.2247459441423416, acc: 0.95652174949646)
[2024-11-14 10:24:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:09][root][INFO] - Training Epoch: 2/2, step 14311/16670 completed (loss: 0.17354212701320648, acc: 0.9615384340286255)
[2024-11-14 10:24:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:09][root][INFO] - Training Epoch: 2/2, step 14312/16670 completed (loss: 0.14499080181121826, acc: 0.9550561904907227)
[2024-11-14 10:24:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:09][root][INFO] - Training Epoch: 2/2, step 14313/16670 completed (loss: 0.09590001404285431, acc: 0.9791666865348816)
[2024-11-14 10:24:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:10][root][INFO] - Training Epoch: 2/2, step 14314/16670 completed (loss: 0.051676925271749496, acc: 0.9831932783126831)
[2024-11-14 10:24:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:10][root][INFO] - Training Epoch: 2/2, step 14315/16670 completed (loss: 0.20155926048755646, acc: 0.9573643207550049)
[2024-11-14 10:24:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:10][root][INFO] - Training Epoch: 2/2, step 14316/16670 completed (loss: 0.07854939997196198, acc: 0.9939393997192383)
[2024-11-14 10:24:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:11][root][INFO] - Training Epoch: 2/2, step 14317/16670 completed (loss: 0.14691680669784546, acc: 0.9552238583564758)
[2024-11-14 10:24:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:11][root][INFO] - Training Epoch: 2/2, step 14318/16670 completed (loss: 0.18692894279956818, acc: 0.9453125)
[2024-11-14 10:24:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:11][root][INFO] - Training Epoch: 2/2, step 14319/16670 completed (loss: 0.17342188954353333, acc: 0.9551281929016113)
[2024-11-14 10:24:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:12][root][INFO] - Training Epoch: 2/2, step 14320/16670 completed (loss: 0.15077295899391174, acc: 0.9509803652763367)
[2024-11-14 10:24:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:12][root][INFO] - Training Epoch: 2/2, step 14321/16670 completed (loss: 0.18047493696212769, acc: 0.9532710313796997)
[2024-11-14 10:24:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:13][root][INFO] - Training Epoch: 2/2, step 14322/16670 completed (loss: 0.21219399571418762, acc: 0.9473684430122375)
[2024-11-14 10:24:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:13][root][INFO] - Training Epoch: 2/2, step 14323/16670 completed (loss: 0.17349213361740112, acc: 0.9750000238418579)
[2024-11-14 10:24:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:13][root][INFO] - Training Epoch: 2/2, step 14324/16670 completed (loss: 0.21798378229141235, acc: 0.929411768913269)
[2024-11-14 10:24:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:14][root][INFO] - Training Epoch: 2/2, step 14325/16670 completed (loss: 0.09511985629796982, acc: 0.9709302186965942)
[2024-11-14 10:24:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:14][root][INFO] - Training Epoch: 2/2, step 14326/16670 completed (loss: 0.2046932578086853, acc: 0.967391312122345)
[2024-11-14 10:24:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:14][root][INFO] - Training Epoch: 2/2, step 14327/16670 completed (loss: 0.10563959181308746, acc: 0.9733333587646484)
[2024-11-14 10:24:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:15][root][INFO] - Training Epoch: 2/2, step 14328/16670 completed (loss: 0.12352046370506287, acc: 0.960422158241272)
[2024-11-14 10:24:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:15][root][INFO] - Training Epoch: 2/2, step 14329/16670 completed (loss: 0.14343497157096863, acc: 0.9591078162193298)
[2024-11-14 10:24:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:16][root][INFO] - Training Epoch: 2/2, step 14330/16670 completed (loss: 0.07609811425209045, acc: 0.9702127575874329)
[2024-11-14 10:24:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:16][root][INFO] - Training Epoch: 2/2, step 14331/16670 completed (loss: 0.10449698567390442, acc: 0.9618055820465088)
[2024-11-14 10:24:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:16][root][INFO] - Training Epoch: 2/2, step 14332/16670 completed (loss: 0.16172932088375092, acc: 0.9642857313156128)
[2024-11-14 10:24:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:17][root][INFO] - Training Epoch: 2/2, step 14333/16670 completed (loss: 0.12529130280017853, acc: 0.9518072009086609)
[2024-11-14 10:24:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:17][root][INFO] - Training Epoch: 2/2, step 14334/16670 completed (loss: 0.12265913933515549, acc: 0.959854006767273)
[2024-11-14 10:24:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:17][root][INFO] - Training Epoch: 2/2, step 14335/16670 completed (loss: 0.20178289711475372, acc: 0.9431279897689819)
[2024-11-14 10:24:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:18][root][INFO] - Training Epoch: 2/2, step 14336/16670 completed (loss: 0.1167178824543953, acc: 0.9572192430496216)
[2024-11-14 10:24:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:18][root][INFO] - Training Epoch: 2/2, step 14337/16670 completed (loss: 0.17964211106300354, acc: 0.9290322661399841)
[2024-11-14 10:24:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:19][root][INFO] - Training Epoch: 2/2, step 14338/16670 completed (loss: 0.23379108309745789, acc: 0.9396551847457886)
[2024-11-14 10:24:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:19][root][INFO] - Training Epoch: 2/2, step 14339/16670 completed (loss: 0.175093412399292, acc: 0.9537814855575562)
[2024-11-14 10:24:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:19][root][INFO] - Training Epoch: 2/2, step 14340/16670 completed (loss: 0.2705526649951935, acc: 0.9270386099815369)
[2024-11-14 10:24:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:20][root][INFO] - Training Epoch: 2/2, step 14341/16670 completed (loss: 0.11068642884492874, acc: 0.9722222089767456)
[2024-11-14 10:24:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:20][root][INFO] - Training Epoch: 2/2, step 14342/16670 completed (loss: 0.10599701851606369, acc: 0.9634146094322205)
[2024-11-14 10:24:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:20][root][INFO] - Training Epoch: 2/2, step 14343/16670 completed (loss: 0.19669628143310547, acc: 0.953125)
[2024-11-14 10:24:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:20][root][INFO] - Training Epoch: 2/2, step 14344/16670 completed (loss: 0.23695796728134155, acc: 0.9279661178588867)
[2024-11-14 10:24:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:21][root][INFO] - Training Epoch: 2/2, step 14345/16670 completed (loss: 0.134343221783638, acc: 0.9642857313156128)
[2024-11-14 10:24:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:21][root][INFO] - Training Epoch: 2/2, step 14346/16670 completed (loss: 0.09628454595804214, acc: 0.9789473414421082)
[2024-11-14 10:24:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:21][root][INFO] - Training Epoch: 2/2, step 14347/16670 completed (loss: 0.20158876478672028, acc: 0.9532163739204407)
[2024-11-14 10:24:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:22][root][INFO] - Training Epoch: 2/2, step 14348/16670 completed (loss: 0.24332353472709656, acc: 0.9555555582046509)
[2024-11-14 10:24:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:22][root][INFO] - Training Epoch: 2/2, step 14349/16670 completed (loss: 0.12216241657733917, acc: 0.9753086566925049)
[2024-11-14 10:24:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:22][root][INFO] - Training Epoch: 2/2, step 14350/16670 completed (loss: 0.10878588259220123, acc: 0.9638242721557617)
[2024-11-14 10:24:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:23][root][INFO] - Training Epoch: 2/2, step 14351/16670 completed (loss: 0.02587953582406044, acc: 0.9953488111495972)
[2024-11-14 10:24:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:23][root][INFO] - Training Epoch: 2/2, step 14352/16670 completed (loss: 0.12129166722297668, acc: 0.9711934328079224)
[2024-11-14 10:24:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:23][root][INFO] - Training Epoch: 2/2, step 14353/16670 completed (loss: 0.1041598841547966, acc: 0.9762712121009827)
[2024-11-14 10:24:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:24][root][INFO] - Training Epoch: 2/2, step 14354/16670 completed (loss: 0.09143777191638947, acc: 0.9722222089767456)
[2024-11-14 10:24:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:24][root][INFO] - Training Epoch: 2/2, step 14355/16670 completed (loss: 0.15369613468647003, acc: 0.9563758373260498)
[2024-11-14 10:24:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:24][root][INFO] - Training Epoch: 2/2, step 14356/16670 completed (loss: 0.09013710916042328, acc: 0.9731543660163879)
[2024-11-14 10:24:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:25][root][INFO] - Training Epoch: 2/2, step 14357/16670 completed (loss: 0.114727683365345, acc: 0.9750889539718628)
[2024-11-14 10:24:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:25][root][INFO] - Training Epoch: 2/2, step 14358/16670 completed (loss: 0.1060456708073616, acc: 0.9777777791023254)
[2024-11-14 10:24:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:25][root][INFO] - Training Epoch: 2/2, step 14359/16670 completed (loss: 0.10233891010284424, acc: 0.9801980257034302)
[2024-11-14 10:24:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:25][root][INFO] - Training Epoch: 2/2, step 14360/16670 completed (loss: 0.0753750279545784, acc: 0.9826989769935608)
[2024-11-14 10:24:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:26][root][INFO] - Training Epoch: 2/2, step 14361/16670 completed (loss: 0.07782340049743652, acc: 0.9800000190734863)
[2024-11-14 10:24:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:26][root][INFO] - Training Epoch: 2/2, step 14362/16670 completed (loss: 0.14579087495803833, acc: 0.9644669890403748)
[2024-11-14 10:24:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:26][root][INFO] - Training Epoch: 2/2, step 14363/16670 completed (loss: 0.19805863499641418, acc: 0.9562682509422302)
[2024-11-14 10:24:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:27][root][INFO] - Training Epoch: 2/2, step 14364/16670 completed (loss: 0.11076493561267853, acc: 0.9675324559211731)
[2024-11-14 10:24:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:27][root][INFO] - Training Epoch: 2/2, step 14365/16670 completed (loss: 0.14077484607696533, acc: 0.9456067085266113)
[2024-11-14 10:24:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:27][root][INFO] - Training Epoch: 2/2, step 14366/16670 completed (loss: 0.15949749946594238, acc: 0.9547325372695923)
[2024-11-14 10:24:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:28][root][INFO] - Training Epoch: 2/2, step 14367/16670 completed (loss: 0.035067684948444366, acc: 0.9869706630706787)
[2024-11-14 10:24:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:28][root][INFO] - Training Epoch: 2/2, step 14368/16670 completed (loss: 0.11726125329732895, acc: 0.9666666388511658)
[2024-11-14 10:24:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:28][root][INFO] - Training Epoch: 2/2, step 14369/16670 completed (loss: 0.08316489309072495, acc: 0.9772727489471436)
[2024-11-14 10:24:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:29][root][INFO] - Training Epoch: 2/2, step 14370/16670 completed (loss: 0.09618949145078659, acc: 0.9736147522926331)
[2024-11-14 10:24:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:29][root][INFO] - Training Epoch: 2/2, step 14371/16670 completed (loss: 0.03836338222026825, acc: 0.9923664331436157)
[2024-11-14 10:24:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:29][root][INFO] - Training Epoch: 2/2, step 14372/16670 completed (loss: 0.04254996404051781, acc: 0.9885931611061096)
[2024-11-14 10:24:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:30][root][INFO] - Training Epoch: 2/2, step 14373/16670 completed (loss: 0.04013536497950554, acc: 0.9878419637680054)
[2024-11-14 10:24:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:30][root][INFO] - Training Epoch: 2/2, step 14374/16670 completed (loss: 0.06625653803348541, acc: 0.9849056601524353)
[2024-11-14 10:24:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:30][root][INFO] - Training Epoch: 2/2, step 14375/16670 completed (loss: 0.13268283009529114, acc: 0.9599999785423279)
[2024-11-14 10:24:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:30][root][INFO] - Training Epoch: 2/2, step 14376/16670 completed (loss: 0.06788050383329391, acc: 0.9832636117935181)
[2024-11-14 10:24:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:31][root][INFO] - Training Epoch: 2/2, step 14377/16670 completed (loss: 0.10442955791950226, acc: 0.9760000109672546)
[2024-11-14 10:24:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:31][root][INFO] - Training Epoch: 2/2, step 14378/16670 completed (loss: 0.055862460285425186, acc: 0.9824561476707458)
[2024-11-14 10:24:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:31][root][INFO] - Training Epoch: 2/2, step 14379/16670 completed (loss: 0.04999539256095886, acc: 0.9851852059364319)
[2024-11-14 10:24:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:32][root][INFO] - Training Epoch: 2/2, step 14380/16670 completed (loss: 0.05682792887091637, acc: 0.9805194735527039)
[2024-11-14 10:24:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:32][root][INFO] - Training Epoch: 2/2, step 14381/16670 completed (loss: 0.11616650968790054, acc: 0.9762712121009827)
[2024-11-14 10:24:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:32][root][INFO] - Training Epoch: 2/2, step 14382/16670 completed (loss: 0.03663768619298935, acc: 0.9878787994384766)
[2024-11-14 10:24:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:33][root][INFO] - Training Epoch: 2/2, step 14383/16670 completed (loss: 0.10262098908424377, acc: 0.9767441749572754)
[2024-11-14 10:24:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:33][root][INFO] - Training Epoch: 2/2, step 14384/16670 completed (loss: 0.10302639752626419, acc: 0.9753694534301758)
[2024-11-14 10:24:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:33][root][INFO] - Training Epoch: 2/2, step 14385/16670 completed (loss: 0.07644782215356827, acc: 0.9784946441650391)
[2024-11-14 10:24:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:34][root][INFO] - Training Epoch: 2/2, step 14386/16670 completed (loss: 0.036918364465236664, acc: 0.9953488111495972)
[2024-11-14 10:24:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:34][root][INFO] - Training Epoch: 2/2, step 14387/16670 completed (loss: 0.06618410348892212, acc: 0.9877675771713257)
[2024-11-14 10:24:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:34][root][INFO] - Training Epoch: 2/2, step 14388/16670 completed (loss: 0.25592175126075745, acc: 0.9407114386558533)
[2024-11-14 10:24:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:35][root][INFO] - Training Epoch: 2/2, step 14389/16670 completed (loss: 0.20703266561031342, acc: 0.9228295683860779)
[2024-11-14 10:24:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:35][root][INFO] - Training Epoch: 2/2, step 14390/16670 completed (loss: 0.04627592861652374, acc: 0.984674334526062)
[2024-11-14 10:24:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:35][root][INFO] - Training Epoch: 2/2, step 14391/16670 completed (loss: 0.06966859847307205, acc: 0.980728030204773)
[2024-11-14 10:24:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:35][root][INFO] - Training Epoch: 2/2, step 14392/16670 completed (loss: 0.2510109841823578, acc: 0.928205132484436)
[2024-11-14 10:24:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:36][root][INFO] - Training Epoch: 2/2, step 14393/16670 completed (loss: 0.18583422899246216, acc: 0.9466666579246521)
[2024-11-14 10:24:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:36][root][INFO] - Training Epoch: 2/2, step 14394/16670 completed (loss: 0.09528806805610657, acc: 0.9774647951126099)
[2024-11-14 10:24:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:36][root][INFO] - Training Epoch: 2/2, step 14395/16670 completed (loss: 0.11032683402299881, acc: 0.9685314893722534)
[2024-11-14 10:24:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:37][root][INFO] - Training Epoch: 2/2, step 14396/16670 completed (loss: 0.10164883732795715, acc: 0.9732441306114197)
[2024-11-14 10:24:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:37][root][INFO] - Training Epoch: 2/2, step 14397/16670 completed (loss: 0.1144280880689621, acc: 0.9649681448936462)
[2024-11-14 10:24:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:37][root][INFO] - Training Epoch: 2/2, step 14398/16670 completed (loss: 0.03127642720937729, acc: 0.9887005686759949)
[2024-11-14 10:24:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:38][root][INFO] - Training Epoch: 2/2, step 14399/16670 completed (loss: 0.07688356935977936, acc: 0.981249988079071)
[2024-11-14 10:24:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:38][root][INFO] - Training Epoch: 2/2, step 14400/16670 completed (loss: 0.14511384069919586, acc: 0.9655172228813171)
[2024-11-14 10:24:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:38][root][INFO] - Training Epoch: 2/2, step 14401/16670 completed (loss: 0.06277748942375183, acc: 0.9836956262588501)
[2024-11-14 10:24:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:39][root][INFO] - Training Epoch: 2/2, step 14402/16670 completed (loss: 0.05868281051516533, acc: 0.9834254384040833)
[2024-11-14 10:24:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:39][root][INFO] - Training Epoch: 2/2, step 14403/16670 completed (loss: 0.07621052116155624, acc: 0.9820144176483154)
[2024-11-14 10:24:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:39][root][INFO] - Training Epoch: 2/2, step 14404/16670 completed (loss: 0.08020675927400589, acc: 0.9688888788223267)
[2024-11-14 10:24:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:40][root][INFO] - Training Epoch: 2/2, step 14405/16670 completed (loss: 0.12789955735206604, acc: 0.9609929323196411)
[2024-11-14 10:24:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:40][root][INFO] - Training Epoch: 2/2, step 14406/16670 completed (loss: 0.08711130172014236, acc: 0.9771241545677185)
[2024-11-14 10:24:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:40][root][INFO] - Training Epoch: 2/2, step 14407/16670 completed (loss: 0.07736372202634811, acc: 0.9878419637680054)
[2024-11-14 10:24:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:41][root][INFO] - Training Epoch: 2/2, step 14408/16670 completed (loss: 0.081847183406353, acc: 0.9796609878540039)
[2024-11-14 10:24:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:41][root][INFO] - Training Epoch: 2/2, step 14409/16670 completed (loss: 0.07547468692064285, acc: 0.9767441749572754)
[2024-11-14 10:24:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:41][root][INFO] - Training Epoch: 2/2, step 14410/16670 completed (loss: 0.08141916245222092, acc: 0.9794871807098389)
[2024-11-14 10:24:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:41][root][INFO] - Training Epoch: 2/2, step 14411/16670 completed (loss: 0.08137659728527069, acc: 0.977886974811554)
[2024-11-14 10:24:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:42][root][INFO] - Training Epoch: 2/2, step 14412/16670 completed (loss: 0.06543517857789993, acc: 0.9887640476226807)
[2024-11-14 10:24:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:42][root][INFO] - Training Epoch: 2/2, step 14413/16670 completed (loss: 0.07512996345758438, acc: 0.9832402467727661)
[2024-11-14 10:24:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:42][root][INFO] - Training Epoch: 2/2, step 14414/16670 completed (loss: 0.10361918807029724, acc: 0.9569377899169922)
[2024-11-14 10:24:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:43][root][INFO] - Training Epoch: 2/2, step 14415/16670 completed (loss: 0.1134551391005516, acc: 0.9693877696990967)
[2024-11-14 10:24:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:43][root][INFO] - Training Epoch: 2/2, step 14416/16670 completed (loss: 0.0898134857416153, acc: 0.9711934328079224)
[2024-11-14 10:24:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:43][root][INFO] - Training Epoch: 2/2, step 14417/16670 completed (loss: 0.13581319153308868, acc: 0.970059871673584)
[2024-11-14 10:24:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:44][root][INFO] - Training Epoch: 2/2, step 14418/16670 completed (loss: 0.061325762420892715, acc: 0.9821428656578064)
[2024-11-14 10:24:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:44][root][INFO] - Training Epoch: 2/2, step 14419/16670 completed (loss: 0.10853176563978195, acc: 0.974595844745636)
[2024-11-14 10:24:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:44][root][INFO] - Training Epoch: 2/2, step 14420/16670 completed (loss: 0.05910925194621086, acc: 0.9869281053543091)
[2024-11-14 10:24:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:44][root][INFO] - Training Epoch: 2/2, step 14421/16670 completed (loss: 0.19123056530952454, acc: 0.9444444179534912)
[2024-11-14 10:24:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:45][root][INFO] - Training Epoch: 2/2, step 14422/16670 completed (loss: 0.04266214743256569, acc: 0.9884169697761536)
[2024-11-14 10:24:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:45][root][INFO] - Training Epoch: 2/2, step 14423/16670 completed (loss: 0.058938708156347275, acc: 0.9741100072860718)
[2024-11-14 10:24:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:45][root][INFO] - Training Epoch: 2/2, step 14424/16670 completed (loss: 0.035370610654354095, acc: 0.9878542423248291)
[2024-11-14 10:24:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:46][root][INFO] - Training Epoch: 2/2, step 14425/16670 completed (loss: 0.06589328497648239, acc: 0.978622317314148)
[2024-11-14 10:24:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:46][root][INFO] - Training Epoch: 2/2, step 14426/16670 completed (loss: 0.05431049317121506, acc: 0.9870550036430359)
[2024-11-14 10:24:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:46][root][INFO] - Training Epoch: 2/2, step 14427/16670 completed (loss: 0.09750884026288986, acc: 0.9808917045593262)
[2024-11-14 10:24:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:47][root][INFO] - Training Epoch: 2/2, step 14428/16670 completed (loss: 0.07895072549581528, acc: 0.9723756909370422)
[2024-11-14 10:24:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:47][root][INFO] - Training Epoch: 2/2, step 14429/16670 completed (loss: 0.09644749760627747, acc: 0.9785714149475098)
[2024-11-14 10:24:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:47][root][INFO] - Training Epoch: 2/2, step 14430/16670 completed (loss: 0.03517397120594978, acc: 0.989847719669342)
[2024-11-14 10:24:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:48][root][INFO] - Training Epoch: 2/2, step 14431/16670 completed (loss: 0.025499550625681877, acc: 0.9925925731658936)
[2024-11-14 10:24:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:48][root][INFO] - Training Epoch: 2/2, step 14432/16670 completed (loss: 0.23509974777698517, acc: 0.9431437849998474)
[2024-11-14 10:24:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:48][root][INFO] - Training Epoch: 2/2, step 14433/16670 completed (loss: 0.04927477240562439, acc: 0.9840255379676819)
[2024-11-14 10:24:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:49][root][INFO] - Training Epoch: 2/2, step 14434/16670 completed (loss: 0.07617180794477463, acc: 0.9807692170143127)
[2024-11-14 10:24:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:49][root][INFO] - Training Epoch: 2/2, step 14435/16670 completed (loss: 0.1360812485218048, acc: 0.96875)
[2024-11-14 10:24:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:49][root][INFO] - Training Epoch: 2/2, step 14436/16670 completed (loss: 0.1725545972585678, acc: 0.9427083134651184)
[2024-11-14 10:24:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:49][root][INFO] - Training Epoch: 2/2, step 14437/16670 completed (loss: 0.1269562989473343, acc: 0.9771863222122192)
[2024-11-14 10:24:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:50][root][INFO] - Training Epoch: 2/2, step 14438/16670 completed (loss: 0.17141777276992798, acc: 0.954674243927002)
[2024-11-14 10:24:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:50][root][INFO] - Training Epoch: 2/2, step 14439/16670 completed (loss: 0.01370715070515871, acc: 0.9951456189155579)
[2024-11-14 10:24:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:50][root][INFO] - Training Epoch: 2/2, step 14440/16670 completed (loss: 0.14157193899154663, acc: 0.963350772857666)
[2024-11-14 10:24:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:51][root][INFO] - Training Epoch: 2/2, step 14441/16670 completed (loss: 0.18519249558448792, acc: 0.949999988079071)
[2024-11-14 10:24:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:51][root][INFO] - Training Epoch: 2/2, step 14442/16670 completed (loss: 0.03822620213031769, acc: 0.9833333492279053)
[2024-11-14 10:24:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:51][root][INFO] - Training Epoch: 2/2, step 14443/16670 completed (loss: 0.027512967586517334, acc: 0.9883720874786377)
[2024-11-14 10:24:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:52][root][INFO] - Training Epoch: 2/2, step 14444/16670 completed (loss: 0.0543062798678875, acc: 0.9841269850730896)
[2024-11-14 10:24:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:52][root][INFO] - Training Epoch: 2/2, step 14445/16670 completed (loss: 0.1515420526266098, acc: 0.9511111378669739)
[2024-11-14 10:24:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:52][root][INFO] - Training Epoch: 2/2, step 14446/16670 completed (loss: 0.1382984220981598, acc: 0.9653679728507996)
[2024-11-14 10:24:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:53][root][INFO] - Training Epoch: 2/2, step 14447/16670 completed (loss: 0.03551005572080612, acc: 0.9896551966667175)
[2024-11-14 10:24:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:53][root][INFO] - Training Epoch: 2/2, step 14448/16670 completed (loss: 0.11092532426118851, acc: 0.9583333134651184)
[2024-11-14 10:24:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:53][root][INFO] - Training Epoch: 2/2, step 14449/16670 completed (loss: 0.04892167076468468, acc: 0.9863481521606445)
[2024-11-14 10:24:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:54][root][INFO] - Training Epoch: 2/2, step 14450/16670 completed (loss: 0.05764305964112282, acc: 0.9814814925193787)
[2024-11-14 10:24:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:54][root][INFO] - Training Epoch: 2/2, step 14451/16670 completed (loss: 0.05509749427437782, acc: 0.9776951670646667)
[2024-11-14 10:24:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:54][root][INFO] - Training Epoch: 2/2, step 14452/16670 completed (loss: 0.1548045575618744, acc: 0.9657142758369446)
[2024-11-14 10:24:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:55][root][INFO] - Training Epoch: 2/2, step 14453/16670 completed (loss: 0.1873849481344223, acc: 0.9627659320831299)
[2024-11-14 10:24:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:55][root][INFO] - Training Epoch: 2/2, step 14454/16670 completed (loss: 0.05157444626092911, acc: 0.9835391044616699)
[2024-11-14 10:24:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:55][root][INFO] - Training Epoch: 2/2, step 14455/16670 completed (loss: 0.09403663873672485, acc: 0.9739583134651184)
[2024-11-14 10:24:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:55][root][INFO] - Training Epoch: 2/2, step 14456/16670 completed (loss: 0.12393772602081299, acc: 0.9714285731315613)
[2024-11-14 10:24:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:56][root][INFO] - Training Epoch: 2/2, step 14457/16670 completed (loss: 0.16339661180973053, acc: 0.9475806355476379)
[2024-11-14 10:24:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:56][root][INFO] - Training Epoch: 2/2, step 14458/16670 completed (loss: 0.09647082537412643, acc: 0.9710144996643066)
[2024-11-14 10:24:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:56][root][INFO] - Training Epoch: 2/2, step 14459/16670 completed (loss: 0.2961810231208801, acc: 0.9130434989929199)
[2024-11-14 10:24:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:57][root][INFO] - Training Epoch: 2/2, step 14460/16670 completed (loss: 0.1012992411851883, acc: 0.978787899017334)
[2024-11-14 10:24:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:57][root][INFO] - Training Epoch: 2/2, step 14461/16670 completed (loss: 0.1537160873413086, acc: 0.9569892287254333)
[2024-11-14 10:24:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:58][root][INFO] - Training Epoch: 2/2, step 14462/16670 completed (loss: 0.05181816965341568, acc: 0.9855072498321533)
[2024-11-14 10:24:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:58][root][INFO] - Training Epoch: 2/2, step 14463/16670 completed (loss: 0.062153592705726624, acc: 0.9770491719245911)
[2024-11-14 10:24:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:58][root][INFO] - Training Epoch: 2/2, step 14464/16670 completed (loss: 0.011615145951509476, acc: 1.0)
[2024-11-14 10:24:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:59][root][INFO] - Training Epoch: 2/2, step 14465/16670 completed (loss: 0.03869760036468506, acc: 0.9935897588729858)
[2024-11-14 10:24:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:59][root][INFO] - Training Epoch: 2/2, step 14466/16670 completed (loss: 0.028846172615885735, acc: 0.9898989796638489)
[2024-11-14 10:24:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:24:59][root][INFO] - Training Epoch: 2/2, step 14467/16670 completed (loss: 0.09015940874814987, acc: 0.9685534834861755)
[2024-11-14 10:24:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:00][root][INFO] - Training Epoch: 2/2, step 14468/16670 completed (loss: 0.10390450805425644, acc: 0.9764705896377563)
[2024-11-14 10:25:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:00][root][INFO] - Training Epoch: 2/2, step 14469/16670 completed (loss: 0.1641097515821457, acc: 0.9692307710647583)
[2024-11-14 10:25:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:00][root][INFO] - Training Epoch: 2/2, step 14470/16670 completed (loss: 0.10136641561985016, acc: 0.9784172773361206)
[2024-11-14 10:25:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:01][root][INFO] - Training Epoch: 2/2, step 14471/16670 completed (loss: 0.2080763727426529, acc: 0.9523809552192688)
[2024-11-14 10:25:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:01][root][INFO] - Training Epoch: 2/2, step 14472/16670 completed (loss: 0.015015104785561562, acc: 0.9953271150588989)
[2024-11-14 10:25:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:01][root][INFO] - Training Epoch: 2/2, step 14473/16670 completed (loss: 0.0863272100687027, acc: 0.9740932583808899)
[2024-11-14 10:25:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:02][root][INFO] - Training Epoch: 2/2, step 14474/16670 completed (loss: 0.0784560963511467, acc: 0.9813664555549622)
[2024-11-14 10:25:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:02][root][INFO] - Training Epoch: 2/2, step 14475/16670 completed (loss: 0.05117935687303543, acc: 0.9855769276618958)
[2024-11-14 10:25:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:02][root][INFO] - Training Epoch: 2/2, step 14476/16670 completed (loss: 0.11215568333864212, acc: 0.972000002861023)
[2024-11-14 10:25:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:03][root][INFO] - Training Epoch: 2/2, step 14477/16670 completed (loss: 0.07857932150363922, acc: 0.9769585132598877)
[2024-11-14 10:25:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:03][root][INFO] - Training Epoch: 2/2, step 14478/16670 completed (loss: 0.10945358872413635, acc: 0.9739583134651184)
[2024-11-14 10:25:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:03][root][INFO] - Training Epoch: 2/2, step 14479/16670 completed (loss: 0.08910059928894043, acc: 0.9763033390045166)
[2024-11-14 10:25:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:04][root][INFO] - Training Epoch: 2/2, step 14480/16670 completed (loss: 0.09339302778244019, acc: 0.9783783555030823)
[2024-11-14 10:25:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:04][root][INFO] - Training Epoch: 2/2, step 14481/16670 completed (loss: 0.086540088057518, acc: 0.9742765426635742)
[2024-11-14 10:25:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:04][root][INFO] - Training Epoch: 2/2, step 14482/16670 completed (loss: 0.06374644488096237, acc: 0.9781818389892578)
[2024-11-14 10:25:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:05][root][INFO] - Training Epoch: 2/2, step 14483/16670 completed (loss: 0.11009867489337921, acc: 0.9776536226272583)
[2024-11-14 10:25:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:05][root][INFO] - Training Epoch: 2/2, step 14484/16670 completed (loss: 0.07211823016405106, acc: 0.9800000190734863)
[2024-11-14 10:25:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:05][root][INFO] - Training Epoch: 2/2, step 14485/16670 completed (loss: 0.029851092025637627, acc: 0.9957982897758484)
[2024-11-14 10:25:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:06][root][INFO] - Training Epoch: 2/2, step 14486/16670 completed (loss: 0.21045343577861786, acc: 0.95652174949646)
[2024-11-14 10:25:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:06][root][INFO] - Training Epoch: 2/2, step 14487/16670 completed (loss: 0.09646262973546982, acc: 0.9639344215393066)
[2024-11-14 10:25:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:06][root][INFO] - Training Epoch: 2/2, step 14488/16670 completed (loss: 0.10410082340240479, acc: 0.9719887971878052)
[2024-11-14 10:25:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:07][root][INFO] - Training Epoch: 2/2, step 14489/16670 completed (loss: 0.2513103485107422, acc: 0.9428571462631226)
[2024-11-14 10:25:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:07][root][INFO] - Training Epoch: 2/2, step 14490/16670 completed (loss: 0.10855388641357422, acc: 0.9807692170143127)
[2024-11-14 10:25:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:07][root][INFO] - Training Epoch: 2/2, step 14491/16670 completed (loss: 0.051417846232652664, acc: 0.9898989796638489)
[2024-11-14 10:25:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:08][root][INFO] - Training Epoch: 2/2, step 14492/16670 completed (loss: 0.11625857651233673, acc: 0.9653679728507996)
[2024-11-14 10:25:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:08][root][INFO] - Training Epoch: 2/2, step 14493/16670 completed (loss: 0.08916925638914108, acc: 0.9708333611488342)
[2024-11-14 10:25:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:08][root][INFO] - Training Epoch: 2/2, step 14494/16670 completed (loss: 0.07938848435878754, acc: 0.9839743375778198)
[2024-11-14 10:25:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:09][root][INFO] - Training Epoch: 2/2, step 14495/16670 completed (loss: 0.16633518040180206, acc: 0.9599999785423279)
[2024-11-14 10:25:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:09][root][INFO] - Training Epoch: 2/2, step 14496/16670 completed (loss: 0.1783740371465683, acc: 0.9492753744125366)
[2024-11-14 10:25:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:09][root][INFO] - Training Epoch: 2/2, step 14497/16670 completed (loss: 0.1868388056755066, acc: 0.9358288645744324)
[2024-11-14 10:25:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:10][root][INFO] - Training Epoch: 2/2, step 14498/16670 completed (loss: 0.03524765744805336, acc: 0.9915966391563416)
[2024-11-14 10:25:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:10][root][INFO] - Training Epoch: 2/2, step 14499/16670 completed (loss: 0.05334998667240143, acc: 0.9837398529052734)
[2024-11-14 10:25:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:10][root][INFO] - Training Epoch: 2/2, step 14500/16670 completed (loss: 0.041567590087652206, acc: 0.989830493927002)
[2024-11-14 10:25:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:11][root][INFO] - Training Epoch: 2/2, step 14501/16670 completed (loss: 0.13863343000411987, acc: 0.9666666388511658)
[2024-11-14 10:25:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:11][root][INFO] - Training Epoch: 2/2, step 14502/16670 completed (loss: 0.10206248611211777, acc: 0.9679999947547913)
[2024-11-14 10:25:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:11][root][INFO] - Training Epoch: 2/2, step 14503/16670 completed (loss: 0.18121837079524994, acc: 0.9395349025726318)
[2024-11-14 10:25:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:12][root][INFO] - Training Epoch: 2/2, step 14504/16670 completed (loss: 0.04915788769721985, acc: 0.9905956387519836)
[2024-11-14 10:25:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:12][root][INFO] - Training Epoch: 2/2, step 14505/16670 completed (loss: 0.06365079432725906, acc: 0.9882352948188782)
[2024-11-14 10:25:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:12][root][INFO] - Training Epoch: 2/2, step 14506/16670 completed (loss: 0.05205187946557999, acc: 0.9896907210350037)
[2024-11-14 10:25:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:13][root][INFO] - Training Epoch: 2/2, step 14507/16670 completed (loss: 0.04156593605875969, acc: 0.9944444298744202)
[2024-11-14 10:25:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:13][root][INFO] - Training Epoch: 2/2, step 14508/16670 completed (loss: 0.1496230661869049, acc: 0.9657142758369446)
[2024-11-14 10:25:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:13][root][INFO] - Training Epoch: 2/2, step 14509/16670 completed (loss: 0.04698693007230759, acc: 0.9853372573852539)
[2024-11-14 10:25:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:14][root][INFO] - Training Epoch: 2/2, step 14510/16670 completed (loss: 0.3855922818183899, acc: 0.9090909361839294)
[2024-11-14 10:25:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:14][root][INFO] - Training Epoch: 2/2, step 14511/16670 completed (loss: 0.08052466064691544, acc: 0.9873949289321899)
[2024-11-14 10:25:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:14][root][INFO] - Training Epoch: 2/2, step 14512/16670 completed (loss: 0.10421384125947952, acc: 0.9740740656852722)
[2024-11-14 10:25:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:15][root][INFO] - Training Epoch: 2/2, step 14513/16670 completed (loss: 0.07251478731632233, acc: 0.9702970385551453)
[2024-11-14 10:25:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:15][root][INFO] - Training Epoch: 2/2, step 14514/16670 completed (loss: 0.07589501887559891, acc: 0.9811320900917053)
[2024-11-14 10:25:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:15][root][INFO] - Training Epoch: 2/2, step 14515/16670 completed (loss: 0.10238907486200333, acc: 0.9681274890899658)
[2024-11-14 10:25:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:16][root][INFO] - Training Epoch: 2/2, step 14516/16670 completed (loss: 0.21572254598140717, acc: 0.9375)
[2024-11-14 10:25:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:16][root][INFO] - Training Epoch: 2/2, step 14517/16670 completed (loss: 0.22592033445835114, acc: 0.9466666579246521)
[2024-11-14 10:25:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:16][root][INFO] - Training Epoch: 2/2, step 14518/16670 completed (loss: 0.09713663160800934, acc: 0.9843137264251709)
[2024-11-14 10:25:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:17][root][INFO] - Training Epoch: 2/2, step 14519/16670 completed (loss: 0.3855997920036316, acc: 0.8795180916786194)
[2024-11-14 10:25:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:17][root][INFO] - Training Epoch: 2/2, step 14520/16670 completed (loss: 0.1556525081396103, acc: 0.9700374603271484)
[2024-11-14 10:25:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:17][root][INFO] - Training Epoch: 2/2, step 14521/16670 completed (loss: 0.07749925553798676, acc: 0.9918699264526367)
[2024-11-14 10:25:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:18][root][INFO] - Training Epoch: 2/2, step 14522/16670 completed (loss: 0.08824706077575684, acc: 0.9666666388511658)
[2024-11-14 10:25:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:18][root][INFO] - Training Epoch: 2/2, step 14523/16670 completed (loss: 0.035357993096113205, acc: 0.9969040155410767)
[2024-11-14 10:25:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:18][root][INFO] - Training Epoch: 2/2, step 14524/16670 completed (loss: 0.1261039823293686, acc: 0.9710982441902161)
[2024-11-14 10:25:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:19][root][INFO] - Training Epoch: 2/2, step 14525/16670 completed (loss: 0.034626320004463196, acc: 0.9900332093238831)
[2024-11-14 10:25:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:19][root][INFO] - Training Epoch: 2/2, step 14526/16670 completed (loss: 0.06719309836626053, acc: 0.9696969985961914)
[2024-11-14 10:25:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:19][root][INFO] - Training Epoch: 2/2, step 14527/16670 completed (loss: 0.07641298323869705, acc: 0.9963898658752441)
[2024-11-14 10:25:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:20][root][INFO] - Training Epoch: 2/2, step 14528/16670 completed (loss: 0.05858886241912842, acc: 0.979522168636322)
[2024-11-14 10:25:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:20][root][INFO] - Training Epoch: 2/2, step 14529/16670 completed (loss: 0.11862868070602417, acc: 0.9510489702224731)
[2024-11-14 10:25:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:20][root][INFO] - Training Epoch: 2/2, step 14530/16670 completed (loss: 0.0832991972565651, acc: 0.9754601120948792)
[2024-11-14 10:25:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:20][root][INFO] - Training Epoch: 2/2, step 14531/16670 completed (loss: 0.12590420246124268, acc: 0.9767441749572754)
[2024-11-14 10:25:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:21][root][INFO] - Training Epoch: 2/2, step 14532/16670 completed (loss: 0.1788216084241867, acc: 0.9457364082336426)
[2024-11-14 10:25:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:21][root][INFO] - Training Epoch: 2/2, step 14533/16670 completed (loss: 0.11424114555120468, acc: 0.9589743614196777)
[2024-11-14 10:25:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:21][root][INFO] - Training Epoch: 2/2, step 14534/16670 completed (loss: 0.29259350895881653, acc: 0.9090909361839294)
[2024-11-14 10:25:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:22][root][INFO] - Training Epoch: 2/2, step 14535/16670 completed (loss: 0.06398862600326538, acc: 0.9800570011138916)
[2024-11-14 10:25:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:22][root][INFO] - Training Epoch: 2/2, step 14536/16670 completed (loss: 0.1562124341726303, acc: 0.9551724195480347)
[2024-11-14 10:25:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:22][root][INFO] - Training Epoch: 2/2, step 14537/16670 completed (loss: 0.04223036766052246, acc: 0.9891892075538635)
[2024-11-14 10:25:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:23][root][INFO] - Training Epoch: 2/2, step 14538/16670 completed (loss: 0.06626822799444199, acc: 0.9904153347015381)
[2024-11-14 10:25:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:23][root][INFO] - Training Epoch: 2/2, step 14539/16670 completed (loss: 0.07281652092933655, acc: 0.9746031761169434)
[2024-11-14 10:25:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:23][root][INFO] - Training Epoch: 2/2, step 14540/16670 completed (loss: 0.0907859280705452, acc: 0.9795918464660645)
[2024-11-14 10:25:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:23][root][INFO] - Training Epoch: 2/2, step 14541/16670 completed (loss: 0.1738153100013733, acc: 0.9567901492118835)
[2024-11-14 10:25:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:24][root][INFO] - Training Epoch: 2/2, step 14542/16670 completed (loss: 0.043632812798023224, acc: 0.984375)
[2024-11-14 10:25:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:24][root][INFO] - Training Epoch: 2/2, step 14543/16670 completed (loss: 0.05693697929382324, acc: 0.973372757434845)
[2024-11-14 10:25:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:25][root][INFO] - Training Epoch: 2/2, step 14544/16670 completed (loss: 0.05202821269631386, acc: 0.9867724776268005)
[2024-11-14 10:25:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:25][root][INFO] - Training Epoch: 2/2, step 14545/16670 completed (loss: 0.06304893642663956, acc: 0.9791666865348816)
[2024-11-14 10:25:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:25][root][INFO] - Training Epoch: 2/2, step 14546/16670 completed (loss: 0.057436779141426086, acc: 0.9849849939346313)
[2024-11-14 10:25:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:25][root][INFO] - Training Epoch: 2/2, step 14547/16670 completed (loss: 0.06695188581943512, acc: 0.9847715497016907)
[2024-11-14 10:25:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:26][root][INFO] - Training Epoch: 2/2, step 14548/16670 completed (loss: 0.0314265713095665, acc: 0.9873417615890503)
[2024-11-14 10:25:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:26][root][INFO] - Training Epoch: 2/2, step 14549/16670 completed (loss: 0.2075009047985077, acc: 0.9424460530281067)
[2024-11-14 10:25:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:26][root][INFO] - Training Epoch: 2/2, step 14550/16670 completed (loss: 0.07668639719486237, acc: 0.9846153855323792)
[2024-11-14 10:25:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:27][root][INFO] - Training Epoch: 2/2, step 14551/16670 completed (loss: 0.06879881024360657, acc: 0.9795918464660645)
[2024-11-14 10:25:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:27][root][INFO] - Training Epoch: 2/2, step 14552/16670 completed (loss: 0.1853211373090744, acc: 0.9478827118873596)
[2024-11-14 10:25:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:27][root][INFO] - Training Epoch: 2/2, step 14553/16670 completed (loss: 0.16294099390506744, acc: 0.9512194991111755)
[2024-11-14 10:25:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:28][root][INFO] - Training Epoch: 2/2, step 14554/16670 completed (loss: 0.11476186662912369, acc: 0.9648241400718689)
[2024-11-14 10:25:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:28][root][INFO] - Training Epoch: 2/2, step 14555/16670 completed (loss: 0.0750674158334732, acc: 0.9688888788223267)
[2024-11-14 10:25:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:28][root][INFO] - Training Epoch: 2/2, step 14556/16670 completed (loss: 0.2185060679912567, acc: 0.9399293065071106)
[2024-11-14 10:25:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:29][root][INFO] - Training Epoch: 2/2, step 14557/16670 completed (loss: 0.21425877511501312, acc: 0.9255319237709045)
[2024-11-14 10:25:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:29][root][INFO] - Training Epoch: 2/2, step 14558/16670 completed (loss: 0.1912050098180771, acc: 0.9591836929321289)
[2024-11-14 10:25:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:29][root][INFO] - Training Epoch: 2/2, step 14559/16670 completed (loss: 0.12520185112953186, acc: 0.948051929473877)
[2024-11-14 10:25:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:30][root][INFO] - Training Epoch: 2/2, step 14560/16670 completed (loss: 0.13680598139762878, acc: 0.9612902998924255)
[2024-11-14 10:25:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:30][root][INFO] - Training Epoch: 2/2, step 14561/16670 completed (loss: 0.05927727743983269, acc: 0.980079710483551)
[2024-11-14 10:25:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:30][root][INFO] - Training Epoch: 2/2, step 14562/16670 completed (loss: 0.01840479113161564, acc: 1.0)
[2024-11-14 10:25:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:31][root][INFO] - Training Epoch: 2/2, step 14563/16670 completed (loss: 0.10812928527593613, acc: 0.976190447807312)
[2024-11-14 10:25:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:31][root][INFO] - Training Epoch: 2/2, step 14564/16670 completed (loss: 0.12419967353343964, acc: 0.9577465057373047)
[2024-11-14 10:25:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:31][root][INFO] - Training Epoch: 2/2, step 14565/16670 completed (loss: 0.06125630810856819, acc: 0.9811320900917053)
[2024-11-14 10:25:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:32][root][INFO] - Training Epoch: 2/2, step 14566/16670 completed (loss: 0.2621549367904663, acc: 0.9333333373069763)
[2024-11-14 10:25:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:32][root][INFO] - Training Epoch: 2/2, step 14567/16670 completed (loss: 0.18954522907733917, acc: 0.9444444179534912)
[2024-11-14 10:25:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:32][root][INFO] - Training Epoch: 2/2, step 14568/16670 completed (loss: 0.10278741270303726, acc: 0.9729729890823364)
[2024-11-14 10:25:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:32][root][INFO] - Training Epoch: 2/2, step 14569/16670 completed (loss: 0.13267642259597778, acc: 0.9759036302566528)
[2024-11-14 10:25:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:33][root][INFO] - Training Epoch: 2/2, step 14570/16670 completed (loss: 0.18638230860233307, acc: 0.9542483687400818)
[2024-11-14 10:25:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:33][root][INFO] - Training Epoch: 2/2, step 14571/16670 completed (loss: 0.08011296391487122, acc: 0.9779005646705627)
[2024-11-14 10:25:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:33][root][INFO] - Training Epoch: 2/2, step 14572/16670 completed (loss: 0.4662511944770813, acc: 0.8691588640213013)
[2024-11-14 10:25:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:34][root][INFO] - Training Epoch: 2/2, step 14573/16670 completed (loss: 0.09965012222528458, acc: 0.9792746305465698)
[2024-11-14 10:25:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:34][root][INFO] - Training Epoch: 2/2, step 14574/16670 completed (loss: 0.07914130389690399, acc: 0.9777777791023254)
[2024-11-14 10:25:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:34][root][INFO] - Training Epoch: 2/2, step 14575/16670 completed (loss: 0.19556380808353424, acc: 0.9433962106704712)
[2024-11-14 10:25:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:35][root][INFO] - Training Epoch: 2/2, step 14576/16670 completed (loss: 0.01911834441125393, acc: 1.0)
[2024-11-14 10:25:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:35][root][INFO] - Training Epoch: 2/2, step 14577/16670 completed (loss: 0.036450885236263275, acc: 0.9880239367485046)
[2024-11-14 10:25:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:35][root][INFO] - Training Epoch: 2/2, step 14578/16670 completed (loss: 0.11480974406003952, acc: 0.9656862616539001)
[2024-11-14 10:25:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:36][root][INFO] - Training Epoch: 2/2, step 14579/16670 completed (loss: 0.29239025712013245, acc: 0.903553307056427)
[2024-11-14 10:25:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:36][root][INFO] - Training Epoch: 2/2, step 14580/16670 completed (loss: 0.04266070947051048, acc: 0.9885714054107666)
[2024-11-14 10:25:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:36][root][INFO] - Training Epoch: 2/2, step 14581/16670 completed (loss: 0.108122818171978, acc: 0.9651162624359131)
[2024-11-14 10:25:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:37][root][INFO] - Training Epoch: 2/2, step 14582/16670 completed (loss: 0.11015965044498444, acc: 0.9793103337287903)
[2024-11-14 10:25:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:37][root][INFO] - Training Epoch: 2/2, step 14583/16670 completed (loss: 0.08909985423088074, acc: 0.982758641242981)
[2024-11-14 10:25:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:38][root][INFO] - Training Epoch: 2/2, step 14584/16670 completed (loss: 0.0877305120229721, acc: 0.9703390002250671)
[2024-11-14 10:25:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:38][root][INFO] - Training Epoch: 2/2, step 14585/16670 completed (loss: 0.08014021068811417, acc: 0.9739583134651184)
[2024-11-14 10:25:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:38][root][INFO] - Training Epoch: 2/2, step 14586/16670 completed (loss: 0.12629812955856323, acc: 0.9729729890823364)
[2024-11-14 10:25:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:39][root][INFO] - Training Epoch: 2/2, step 14587/16670 completed (loss: 0.19359944760799408, acc: 0.9406779408454895)
[2024-11-14 10:25:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:39][root][INFO] - Training Epoch: 2/2, step 14588/16670 completed (loss: 0.17689566314220428, acc: 0.9428571462631226)
[2024-11-14 10:25:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:39][root][INFO] - Training Epoch: 2/2, step 14589/16670 completed (loss: 0.1052289828658104, acc: 0.971222996711731)
[2024-11-14 10:25:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:40][root][INFO] - Training Epoch: 2/2, step 14590/16670 completed (loss: 0.07166706770658493, acc: 0.9813084006309509)
[2024-11-14 10:25:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:40][root][INFO] - Training Epoch: 2/2, step 14591/16670 completed (loss: 0.06736603379249573, acc: 0.9819276928901672)
[2024-11-14 10:25:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:41][root][INFO] - Training Epoch: 2/2, step 14592/16670 completed (loss: 0.110628142952919, acc: 0.9659863710403442)
[2024-11-14 10:25:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:41][root][INFO] - Training Epoch: 2/2, step 14593/16670 completed (loss: 0.07869981974363327, acc: 0.9771689772605896)
[2024-11-14 10:25:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:41][root][INFO] - Training Epoch: 2/2, step 14594/16670 completed (loss: 0.0909382551908493, acc: 0.9593908786773682)
[2024-11-14 10:25:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:42][root][INFO] - Training Epoch: 2/2, step 14595/16670 completed (loss: 0.23742906749248505, acc: 0.9299362897872925)
[2024-11-14 10:25:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:42][root][INFO] - Training Epoch: 2/2, step 14596/16670 completed (loss: 0.2194610983133316, acc: 0.9438202381134033)
[2024-11-14 10:25:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:42][root][INFO] - Training Epoch: 2/2, step 14597/16670 completed (loss: 0.10268688946962357, acc: 0.9713114500045776)
[2024-11-14 10:25:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:43][root][INFO] - Training Epoch: 2/2, step 14598/16670 completed (loss: 0.06792526692152023, acc: 0.9791666865348816)
[2024-11-14 10:25:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:43][root][INFO] - Training Epoch: 2/2, step 14599/16670 completed (loss: 0.11599597334861755, acc: 0.9632107019424438)
[2024-11-14 10:25:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:44][root][INFO] - Training Epoch: 2/2, step 14600/16670 completed (loss: 0.11883129179477692, acc: 0.9642857313156128)
[2024-11-14 10:25:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:44][root][INFO] - Training Epoch: 2/2, step 14601/16670 completed (loss: 0.3272881507873535, acc: 0.9017857313156128)
[2024-11-14 10:25:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:44][root][INFO] - Training Epoch: 2/2, step 14602/16670 completed (loss: 0.11898883432149887, acc: 0.9657320976257324)
[2024-11-14 10:25:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:45][root][INFO] - Training Epoch: 2/2, step 14603/16670 completed (loss: 0.2583174705505371, acc: 0.9518072009086609)
[2024-11-14 10:25:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:45][root][INFO] - Training Epoch: 2/2, step 14604/16670 completed (loss: 0.21449065208435059, acc: 0.9495412707328796)
[2024-11-14 10:25:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:45][root][INFO] - Training Epoch: 2/2, step 14605/16670 completed (loss: 0.2986489236354828, acc: 0.9300699234008789)
[2024-11-14 10:25:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:46][root][INFO] - Training Epoch: 2/2, step 14606/16670 completed (loss: 0.21727818250656128, acc: 0.9363057613372803)
[2024-11-14 10:25:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:46][root][INFO] - Training Epoch: 2/2, step 14607/16670 completed (loss: 0.20240186154842377, acc: 0.936170220375061)
[2024-11-14 10:25:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:47][root][INFO] - Training Epoch: 2/2, step 14608/16670 completed (loss: 0.1822056919336319, acc: 0.9523809552192688)
[2024-11-14 10:25:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:47][root][INFO] - Training Epoch: 2/2, step 14609/16670 completed (loss: 0.2702394127845764, acc: 0.8877550959587097)
[2024-11-14 10:25:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:47][root][INFO] - Training Epoch: 2/2, step 14610/16670 completed (loss: 0.27617427706718445, acc: 0.9171597361564636)
[2024-11-14 10:25:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:48][root][INFO] - Training Epoch: 2/2, step 14611/16670 completed (loss: 0.18067224323749542, acc: 0.9591836929321289)
[2024-11-14 10:25:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:48][root][INFO] - Training Epoch: 2/2, step 14612/16670 completed (loss: 0.2128537893295288, acc: 0.9463087320327759)
[2024-11-14 10:25:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:48][root][INFO] - Training Epoch: 2/2, step 14613/16670 completed (loss: 0.21736346185207367, acc: 0.961240291595459)
[2024-11-14 10:25:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:49][root][INFO] - Training Epoch: 2/2, step 14614/16670 completed (loss: 0.09576138854026794, acc: 0.9713114500045776)
[2024-11-14 10:25:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:49][root][INFO] - Training Epoch: 2/2, step 14615/16670 completed (loss: 0.0652087926864624, acc: 0.9631901979446411)
[2024-11-14 10:25:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:49][root][INFO] - Training Epoch: 2/2, step 14616/16670 completed (loss: 0.07221348583698273, acc: 0.9738562107086182)
[2024-11-14 10:25:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:50][root][INFO] - Training Epoch: 2/2, step 14617/16670 completed (loss: 0.10621476173400879, acc: 0.9646017551422119)
[2024-11-14 10:25:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:50][root][INFO] - Training Epoch: 2/2, step 14618/16670 completed (loss: 0.10614590346813202, acc: 0.9618320465087891)
[2024-11-14 10:25:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:50][root][INFO] - Training Epoch: 2/2, step 14619/16670 completed (loss: 0.12288638204336166, acc: 0.9703947305679321)
[2024-11-14 10:25:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:50][root][INFO] - Training Epoch: 2/2, step 14620/16670 completed (loss: 0.18371543288230896, acc: 0.970802903175354)
[2024-11-14 10:25:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:51][root][INFO] - Training Epoch: 2/2, step 14621/16670 completed (loss: 0.10547816008329391, acc: 0.9784172773361206)
[2024-11-14 10:25:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:51][root][INFO] - Training Epoch: 2/2, step 14622/16670 completed (loss: 0.11439238488674164, acc: 0.969348669052124)
[2024-11-14 10:25:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:51][root][INFO] - Training Epoch: 2/2, step 14623/16670 completed (loss: 0.10500149428844452, acc: 0.9624573588371277)
[2024-11-14 10:25:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:52][root][INFO] - Training Epoch: 2/2, step 14624/16670 completed (loss: 0.2643006145954132, acc: 0.9512194991111755)
[2024-11-14 10:25:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:52][root][INFO] - Training Epoch: 2/2, step 14625/16670 completed (loss: 0.17604981362819672, acc: 0.951298713684082)
[2024-11-14 10:25:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:52][root][INFO] - Training Epoch: 2/2, step 14626/16670 completed (loss: 0.21033507585525513, acc: 0.9413919448852539)
[2024-11-14 10:25:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:53][root][INFO] - Training Epoch: 2/2, step 14627/16670 completed (loss: 0.11805722117424011, acc: 0.9561753273010254)
[2024-11-14 10:25:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:53][root][INFO] - Training Epoch: 2/2, step 14628/16670 completed (loss: 0.03652957081794739, acc: 0.9897260069847107)
[2024-11-14 10:25:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:53][root][INFO] - Training Epoch: 2/2, step 14629/16670 completed (loss: 0.07540157437324524, acc: 0.9934210777282715)
[2024-11-14 10:25:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:54][root][INFO] - Training Epoch: 2/2, step 14630/16670 completed (loss: 0.06183357164263725, acc: 0.9723320007324219)
[2024-11-14 10:25:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:54][root][INFO] - Training Epoch: 2/2, step 14631/16670 completed (loss: 0.34314095973968506, acc: 0.9125000238418579)
[2024-11-14 10:25:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:54][root][INFO] - Training Epoch: 2/2, step 14632/16670 completed (loss: 0.23703564703464508, acc: 0.9462365508079529)
[2024-11-14 10:25:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:55][root][INFO] - Training Epoch: 2/2, step 14633/16670 completed (loss: 0.10664032399654388, acc: 0.9605262875556946)
[2024-11-14 10:25:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:55][root][INFO] - Training Epoch: 2/2, step 14634/16670 completed (loss: 0.11566391587257385, acc: 0.970370352268219)
[2024-11-14 10:25:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:55][root][INFO] - Training Epoch: 2/2, step 14635/16670 completed (loss: 0.602316677570343, acc: 0.8607594966888428)
[2024-11-14 10:25:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:56][root][INFO] - Training Epoch: 2/2, step 14636/16670 completed (loss: 0.2735796868801117, acc: 0.8857142925262451)
[2024-11-14 10:25:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:56][root][INFO] - Training Epoch: 2/2, step 14637/16670 completed (loss: 0.09539750218391418, acc: 0.9729729890823364)
[2024-11-14 10:25:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:56][root][INFO] - Training Epoch: 2/2, step 14638/16670 completed (loss: 0.10982178896665573, acc: 0.9791666865348816)
[2024-11-14 10:25:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:57][root][INFO] - Training Epoch: 2/2, step 14639/16670 completed (loss: 0.12602244317531586, acc: 0.9623430967330933)
[2024-11-14 10:25:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:57][root][INFO] - Training Epoch: 2/2, step 14640/16670 completed (loss: 0.3283776044845581, acc: 0.9090909361839294)
[2024-11-14 10:25:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:57][root][INFO] - Training Epoch: 2/2, step 14641/16670 completed (loss: 0.423239529132843, acc: 0.8533333539962769)
[2024-11-14 10:25:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:58][root][INFO] - Training Epoch: 2/2, step 14642/16670 completed (loss: 0.2457154244184494, acc: 0.9078947305679321)
[2024-11-14 10:25:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:58][root][INFO] - Training Epoch: 2/2, step 14643/16670 completed (loss: 0.2872861623764038, acc: 0.9237288236618042)
[2024-11-14 10:25:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:58][root][INFO] - Training Epoch: 2/2, step 14644/16670 completed (loss: 0.11270982772111893, acc: 0.9634146094322205)
[2024-11-14 10:25:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:58][root][INFO] - Training Epoch: 2/2, step 14645/16670 completed (loss: 0.18302902579307556, acc: 0.949999988079071)
[2024-11-14 10:25:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:59][root][INFO] - Training Epoch: 2/2, step 14646/16670 completed (loss: 0.09014706313610077, acc: 0.9711538553237915)
[2024-11-14 10:25:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:59][root][INFO] - Training Epoch: 2/2, step 14647/16670 completed (loss: 0.1899738758802414, acc: 0.9459459185600281)
[2024-11-14 10:25:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:25:59][root][INFO] - Training Epoch: 2/2, step 14648/16670 completed (loss: 0.11065373569726944, acc: 0.9814814925193787)
[2024-11-14 10:25:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:00][root][INFO] - Training Epoch: 2/2, step 14649/16670 completed (loss: 0.25341251492500305, acc: 0.9369369149208069)
[2024-11-14 10:26:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:00][root][INFO] - Training Epoch: 2/2, step 14650/16670 completed (loss: 0.18767112493515015, acc: 0.966292142868042)
[2024-11-14 10:26:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:00][root][INFO] - Training Epoch: 2/2, step 14651/16670 completed (loss: 0.04374443739652634, acc: 1.0)
[2024-11-14 10:26:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:01][root][INFO] - Training Epoch: 2/2, step 14652/16670 completed (loss: 0.19774863123893738, acc: 0.9278350472450256)
[2024-11-14 10:26:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:01][root][INFO] - Training Epoch: 2/2, step 14653/16670 completed (loss: 0.3366968333721161, acc: 0.917391300201416)
[2024-11-14 10:26:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:01][root][INFO] - Training Epoch: 2/2, step 14654/16670 completed (loss: 0.20770564675331116, acc: 0.9577465057373047)
[2024-11-14 10:26:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:02][root][INFO] - Training Epoch: 2/2, step 14655/16670 completed (loss: 0.10075558722019196, acc: 0.9777777791023254)
[2024-11-14 10:26:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:02][root][INFO] - Training Epoch: 2/2, step 14656/16670 completed (loss: 0.04239847883582115, acc: 0.9821428656578064)
[2024-11-14 10:26:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:02][root][INFO] - Training Epoch: 2/2, step 14657/16670 completed (loss: 0.03843601793050766, acc: 1.0)
[2024-11-14 10:26:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:03][root][INFO] - Training Epoch: 2/2, step 14658/16670 completed (loss: 0.28096064925193787, acc: 0.9552238583564758)
[2024-11-14 10:26:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:03][root][INFO] - Training Epoch: 2/2, step 14659/16670 completed (loss: 0.21071681380271912, acc: 0.9270073175430298)
[2024-11-14 10:26:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:03][root][INFO] - Training Epoch: 2/2, step 14660/16670 completed (loss: 0.24530154466629028, acc: 0.9333333373069763)
[2024-11-14 10:26:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:04][root][INFO] - Training Epoch: 2/2, step 14661/16670 completed (loss: 0.23368202149868011, acc: 0.9365079402923584)
[2024-11-14 10:26:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:04][root][INFO] - Training Epoch: 2/2, step 14662/16670 completed (loss: 0.08653286844491959, acc: 0.9629629850387573)
[2024-11-14 10:26:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:04][root][INFO] - Training Epoch: 2/2, step 14663/16670 completed (loss: 0.3231602907180786, acc: 0.9090909361839294)
[2024-11-14 10:26:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:05][root][INFO] - Training Epoch: 2/2, step 14664/16670 completed (loss: 0.4395574927330017, acc: 0.874015748500824)
[2024-11-14 10:26:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:05][root][INFO] - Training Epoch: 2/2, step 14665/16670 completed (loss: 0.35779303312301636, acc: 0.9142857193946838)
[2024-11-14 10:26:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:06][root][INFO] - Training Epoch: 2/2, step 14666/16670 completed (loss: 0.22957561910152435, acc: 0.9346153736114502)
[2024-11-14 10:26:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:06][root][INFO] - Training Epoch: 2/2, step 14667/16670 completed (loss: 0.44446828961372375, acc: 0.8805969953536987)
[2024-11-14 10:26:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:06][root][INFO] - Training Epoch: 2/2, step 14668/16670 completed (loss: 0.1787089854478836, acc: 0.9534883499145508)
[2024-11-14 10:26:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:07][root][INFO] - Training Epoch: 2/2, step 14669/16670 completed (loss: 0.09915811568498611, acc: 0.978723406791687)
[2024-11-14 10:26:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:07][root][INFO] - Training Epoch: 2/2, step 14670/16670 completed (loss: 0.10354279726743698, acc: 0.9675324559211731)
[2024-11-14 10:26:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:07][root][INFO] - Training Epoch: 2/2, step 14671/16670 completed (loss: 0.13664664328098297, acc: 0.9591836929321289)
[2024-11-14 10:26:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:07][root][INFO] - Training Epoch: 2/2, step 14672/16670 completed (loss: 0.17906850576400757, acc: 0.9505300521850586)
[2024-11-14 10:26:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:08][root][INFO] - Training Epoch: 2/2, step 14673/16670 completed (loss: 0.256445050239563, acc: 0.9178082346916199)
[2024-11-14 10:26:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:08][root][INFO] - Training Epoch: 2/2, step 14674/16670 completed (loss: 0.1962074190378189, acc: 0.9518716335296631)
[2024-11-14 10:26:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:08][root][INFO] - Training Epoch: 2/2, step 14675/16670 completed (loss: 0.8582525849342346, acc: 0.7536231875419617)
[2024-11-14 10:26:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:09][root][INFO] - Training Epoch: 2/2, step 14676/16670 completed (loss: 0.11600446701049805, acc: 0.9677419066429138)
[2024-11-14 10:26:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:09][root][INFO] - Training Epoch: 2/2, step 14677/16670 completed (loss: 0.25267988443374634, acc: 0.9140625)
[2024-11-14 10:26:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:09][root][INFO] - Training Epoch: 2/2, step 14678/16670 completed (loss: 0.7234511375427246, acc: 0.7708333134651184)
[2024-11-14 10:26:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:10][root][INFO] - Training Epoch: 2/2, step 14679/16670 completed (loss: 0.12093303352594376, acc: 0.9707112908363342)
[2024-11-14 10:26:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:10][root][INFO] - Training Epoch: 2/2, step 14680/16670 completed (loss: 0.2452983409166336, acc: 0.9021739363670349)
[2024-11-14 10:26:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:10][root][INFO] - Training Epoch: 2/2, step 14681/16670 completed (loss: 0.2158278524875641, acc: 0.9323671460151672)
[2024-11-14 10:26:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:11][root][INFO] - Training Epoch: 2/2, step 14682/16670 completed (loss: 0.3325038552284241, acc: 0.9285714030265808)
[2024-11-14 10:26:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:11][root][INFO] - Training Epoch: 2/2, step 14683/16670 completed (loss: 0.1009722426533699, acc: 0.97826087474823)
[2024-11-14 10:26:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:11][root][INFO] - Training Epoch: 2/2, step 14684/16670 completed (loss: 0.4240686297416687, acc: 0.8855421543121338)
[2024-11-14 10:26:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:12][root][INFO] - Training Epoch: 2/2, step 14685/16670 completed (loss: 0.1902773678302765, acc: 0.9506173133850098)
[2024-11-14 10:26:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:12][root][INFO] - Training Epoch: 2/2, step 14686/16670 completed (loss: 0.17806726694107056, acc: 0.9603658318519592)
[2024-11-14 10:26:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:12][root][INFO] - Training Epoch: 2/2, step 14687/16670 completed (loss: 0.17730121314525604, acc: 0.9599999785423279)
[2024-11-14 10:26:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:13][root][INFO] - Training Epoch: 2/2, step 14688/16670 completed (loss: 0.23472653329372406, acc: 0.93034827709198)
[2024-11-14 10:26:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:13][root][INFO] - Training Epoch: 2/2, step 14689/16670 completed (loss: 0.05163874849677086, acc: 0.9768518805503845)
[2024-11-14 10:26:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:13][root][INFO] - Training Epoch: 2/2, step 14690/16670 completed (loss: 0.27774229645729065, acc: 0.9239766001701355)
[2024-11-14 10:26:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:14][root][INFO] - Training Epoch: 2/2, step 14691/16670 completed (loss: 0.32432177662849426, acc: 0.9078013896942139)
[2024-11-14 10:26:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:14][root][INFO] - Training Epoch: 2/2, step 14692/16670 completed (loss: 0.29561206698417664, acc: 0.8992805480957031)
[2024-11-14 10:26:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:14][root][INFO] - Training Epoch: 2/2, step 14693/16670 completed (loss: 0.5155752897262573, acc: 0.8414633870124817)
[2024-11-14 10:26:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:14][root][INFO] - Training Epoch: 2/2, step 14694/16670 completed (loss: 0.13780242204666138, acc: 0.9508196711540222)
[2024-11-14 10:26:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:15][root][INFO] - Training Epoch: 2/2, step 14695/16670 completed (loss: 0.654973566532135, acc: 0.8155339956283569)
[2024-11-14 10:26:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:15][root][INFO] - Training Epoch: 2/2, step 14696/16670 completed (loss: 0.21640661358833313, acc: 0.9359999895095825)
[2024-11-14 10:26:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:15][root][INFO] - Training Epoch: 2/2, step 14697/16670 completed (loss: 0.3909792900085449, acc: 0.8920454382896423)
[2024-11-14 10:26:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:16][root][INFO] - Training Epoch: 2/2, step 14698/16670 completed (loss: 0.31838157773017883, acc: 0.9115646481513977)
[2024-11-14 10:26:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:16][root][INFO] - Training Epoch: 2/2, step 14699/16670 completed (loss: 0.06525365263223648, acc: 0.9764150977134705)
[2024-11-14 10:26:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:16][root][INFO] - Training Epoch: 2/2, step 14700/16670 completed (loss: 0.31638261675834656, acc: 0.9158878326416016)
[2024-11-14 10:26:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:17][root][INFO] - Training Epoch: 2/2, step 14701/16670 completed (loss: 0.022470830008387566, acc: 0.9950000047683716)
[2024-11-14 10:26:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:17][root][INFO] - Training Epoch: 2/2, step 14702/16670 completed (loss: 0.08990427851676941, acc: 0.9670782089233398)
[2024-11-14 10:26:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:17][root][INFO] - Training Epoch: 2/2, step 14703/16670 completed (loss: 0.17859576642513275, acc: 0.9383886456489563)
[2024-11-14 10:26:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:18][root][INFO] - Training Epoch: 2/2, step 14704/16670 completed (loss: 0.4701753258705139, acc: 0.8571428656578064)
[2024-11-14 10:26:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:18][root][INFO] - Training Epoch: 2/2, step 14705/16670 completed (loss: 0.36620640754699707, acc: 0.9052631855010986)
[2024-11-14 10:26:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:18][root][INFO] - Training Epoch: 2/2, step 14706/16670 completed (loss: 0.18168656527996063, acc: 0.9469026327133179)
[2024-11-14 10:26:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:19][root][INFO] - Training Epoch: 2/2, step 14707/16670 completed (loss: 0.14041545987129211, acc: 0.9540635943412781)
[2024-11-14 10:26:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:19][root][INFO] - Training Epoch: 2/2, step 14708/16670 completed (loss: 0.05511314049363136, acc: 0.9791666865348816)
[2024-11-14 10:26:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:19][root][INFO] - Training Epoch: 2/2, step 14709/16670 completed (loss: 0.12617921829223633, acc: 0.9628099203109741)
[2024-11-14 10:26:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:19][root][INFO] - Training Epoch: 2/2, step 14710/16670 completed (loss: 0.28446444869041443, acc: 0.9189189076423645)
[2024-11-14 10:26:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:20][root][INFO] - Training Epoch: 2/2, step 14711/16670 completed (loss: 0.29501691460609436, acc: 0.9157894849777222)
[2024-11-14 10:26:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:20][root][INFO] - Training Epoch: 2/2, step 14712/16670 completed (loss: 0.3094329237937927, acc: 0.9079498052597046)
[2024-11-14 10:26:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:20][root][INFO] - Training Epoch: 2/2, step 14713/16670 completed (loss: 0.20357421040534973, acc: 0.9346733689308167)
[2024-11-14 10:26:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:21][root][INFO] - Training Epoch: 2/2, step 14714/16670 completed (loss: 0.47193044424057007, acc: 0.8677685856819153)
[2024-11-14 10:26:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:21][root][INFO] - Training Epoch: 2/2, step 14715/16670 completed (loss: 0.10466824471950531, acc: 0.9645389914512634)
[2024-11-14 10:26:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:21][root][INFO] - Training Epoch: 2/2, step 14716/16670 completed (loss: 0.0692407488822937, acc: 0.984455943107605)
[2024-11-14 10:26:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:22][root][INFO] - Training Epoch: 2/2, step 14717/16670 completed (loss: 0.3796578049659729, acc: 0.8974359035491943)
[2024-11-14 10:26:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:22][root][INFO] - Training Epoch: 2/2, step 14718/16670 completed (loss: 0.3643512725830078, acc: 0.8783783912658691)
[2024-11-14 10:26:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:22][root][INFO] - Training Epoch: 2/2, step 14719/16670 completed (loss: 0.4349062144756317, acc: 0.899328887462616)
[2024-11-14 10:26:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:23][root][INFO] - Training Epoch: 2/2, step 14720/16670 completed (loss: 0.5179880857467651, acc: 0.8484848737716675)
[2024-11-14 10:26:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:23][root][INFO] - Training Epoch: 2/2, step 14721/16670 completed (loss: 0.3399447500705719, acc: 0.9069767594337463)
[2024-11-14 10:26:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:23][root][INFO] - Training Epoch: 2/2, step 14722/16670 completed (loss: 0.3548499643802643, acc: 0.893203854560852)
[2024-11-14 10:26:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:24][root][INFO] - Training Epoch: 2/2, step 14723/16670 completed (loss: 0.34378957748413086, acc: 0.8833333253860474)
[2024-11-14 10:26:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:24][root][INFO] - Training Epoch: 2/2, step 14724/16670 completed (loss: 0.4470946192741394, acc: 0.8846153616905212)
[2024-11-14 10:26:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:24][root][INFO] - Training Epoch: 2/2, step 14725/16670 completed (loss: 0.46205848455429077, acc: 0.8951048851013184)
[2024-11-14 10:26:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:24][root][INFO] - Training Epoch: 2/2, step 14726/16670 completed (loss: 0.15200866758823395, acc: 0.95652174949646)
[2024-11-14 10:26:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:25][root][INFO] - Training Epoch: 2/2, step 14727/16670 completed (loss: 0.1377101093530655, acc: 0.9506173133850098)
[2024-11-14 10:26:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:25][root][INFO] - Training Epoch: 2/2, step 14728/16670 completed (loss: 0.2400481104850769, acc: 0.9436619877815247)
[2024-11-14 10:26:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:25][root][INFO] - Training Epoch: 2/2, step 14729/16670 completed (loss: 0.1761004775762558, acc: 0.9495412707328796)
[2024-11-14 10:26:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:26][root][INFO] - Training Epoch: 2/2, step 14730/16670 completed (loss: 0.041765958070755005, acc: 0.9904761910438538)
[2024-11-14 10:26:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:26][root][INFO] - Training Epoch: 2/2, step 14731/16670 completed (loss: 0.27907830476760864, acc: 0.9248554706573486)
[2024-11-14 10:26:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:26][root][INFO] - Training Epoch: 2/2, step 14732/16670 completed (loss: 0.23685213923454285, acc: 0.9248120188713074)
[2024-11-14 10:26:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:27][root][INFO] - Training Epoch: 2/2, step 14733/16670 completed (loss: 0.096302330493927, acc: 0.980861246585846)
[2024-11-14 10:26:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:27][root][INFO] - Training Epoch: 2/2, step 14734/16670 completed (loss: 0.2732256054878235, acc: 0.936170220375061)
[2024-11-14 10:26:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:27][root][INFO] - Training Epoch: 2/2, step 14735/16670 completed (loss: 0.13256637752056122, acc: 0.9677419066429138)
[2024-11-14 10:26:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:28][root][INFO] - Training Epoch: 2/2, step 14736/16670 completed (loss: 0.34625244140625, acc: 0.916201114654541)
[2024-11-14 10:26:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:28][root][INFO] - Training Epoch: 2/2, step 14737/16670 completed (loss: 0.09569890797138214, acc: 0.9626168012619019)
[2024-11-14 10:26:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:28][root][INFO] - Training Epoch: 2/2, step 14738/16670 completed (loss: 0.13711877167224884, acc: 0.956204354763031)
[2024-11-14 10:26:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:29][root][INFO] - Training Epoch: 2/2, step 14739/16670 completed (loss: 0.08702552318572998, acc: 0.9750000238418579)
[2024-11-14 10:26:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:29][root][INFO] - Training Epoch: 2/2, step 14740/16670 completed (loss: 0.15514330565929413, acc: 0.9595015645027161)
[2024-11-14 10:26:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:29][root][INFO] - Training Epoch: 2/2, step 14741/16670 completed (loss: 0.5651764869689941, acc: 0.8392857313156128)
[2024-11-14 10:26:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:30][root][INFO] - Training Epoch: 2/2, step 14742/16670 completed (loss: 0.2586800456047058, acc: 0.9263157844543457)
[2024-11-14 10:26:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:30][root][INFO] - Training Epoch: 2/2, step 14743/16670 completed (loss: 0.34528592228889465, acc: 0.910614550113678)
[2024-11-14 10:26:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:30][root][INFO] - Training Epoch: 2/2, step 14744/16670 completed (loss: 0.1303190141916275, acc: 0.9649122953414917)
[2024-11-14 10:26:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:31][root][INFO] - Training Epoch: 2/2, step 14745/16670 completed (loss: 0.19946473836898804, acc: 0.9403669834136963)
[2024-11-14 10:26:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:31][root][INFO] - Training Epoch: 2/2, step 14746/16670 completed (loss: 0.2273443192243576, acc: 0.9312499761581421)
[2024-11-14 10:26:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:31][root][INFO] - Training Epoch: 2/2, step 14747/16670 completed (loss: 0.24125151336193085, acc: 0.9402173757553101)
[2024-11-14 10:26:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:32][root][INFO] - Training Epoch: 2/2, step 14748/16670 completed (loss: 0.4615470767021179, acc: 0.8454545736312866)
[2024-11-14 10:26:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:32][root][INFO] - Training Epoch: 2/2, step 14749/16670 completed (loss: 0.20440274477005005, acc: 0.9593908786773682)
[2024-11-14 10:26:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:32][root][INFO] - Training Epoch: 2/2, step 14750/16670 completed (loss: 0.30128130316734314, acc: 0.8961039185523987)
[2024-11-14 10:26:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:33][root][INFO] - Training Epoch: 2/2, step 14751/16670 completed (loss: 0.16568690538406372, acc: 0.945652186870575)
[2024-11-14 10:26:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:33][root][INFO] - Training Epoch: 2/2, step 14752/16670 completed (loss: 0.1524643898010254, acc: 0.9395973086357117)
[2024-11-14 10:26:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:33][root][INFO] - Training Epoch: 2/2, step 14753/16670 completed (loss: 0.08763480931520462, acc: 0.9741379022598267)
[2024-11-14 10:26:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:34][root][INFO] - Training Epoch: 2/2, step 14754/16670 completed (loss: 0.19830450415611267, acc: 0.957317054271698)
[2024-11-14 10:26:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:34][root][INFO] - Training Epoch: 2/2, step 14755/16670 completed (loss: 0.23300766944885254, acc: 0.9395973086357117)
[2024-11-14 10:26:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:34][root][INFO] - Training Epoch: 2/2, step 14756/16670 completed (loss: 0.031471796333789825, acc: 0.9907833933830261)
[2024-11-14 10:26:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:35][root][INFO] - Training Epoch: 2/2, step 14757/16670 completed (loss: 0.11245939135551453, acc: 0.9776119589805603)
[2024-11-14 10:26:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:35][root][INFO] - Training Epoch: 2/2, step 14758/16670 completed (loss: 0.11089779436588287, acc: 0.9772727489471436)
[2024-11-14 10:26:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:35][root][INFO] - Training Epoch: 2/2, step 14759/16670 completed (loss: 0.17425639927387238, acc: 0.9573459625244141)
[2024-11-14 10:26:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:36][root][INFO] - Training Epoch: 2/2, step 14760/16670 completed (loss: 0.026648927479982376, acc: 0.9927007555961609)
[2024-11-14 10:26:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:36][root][INFO] - Training Epoch: 2/2, step 14761/16670 completed (loss: 0.15362653136253357, acc: 0.9468085169792175)
[2024-11-14 10:26:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:36][root][INFO] - Training Epoch: 2/2, step 14762/16670 completed (loss: 0.1687282770872116, acc: 0.9585062265396118)
[2024-11-14 10:26:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:37][root][INFO] - Training Epoch: 2/2, step 14763/16670 completed (loss: 0.0771825760602951, acc: 0.9832402467727661)
[2024-11-14 10:26:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:37][root][INFO] - Training Epoch: 2/2, step 14764/16670 completed (loss: 0.24336019158363342, acc: 0.946601927280426)
[2024-11-14 10:26:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:38][root][INFO] - Training Epoch: 2/2, step 14765/16670 completed (loss: 0.09833475202322006, acc: 0.9681817889213562)
[2024-11-14 10:26:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:38][root][INFO] - Training Epoch: 2/2, step 14766/16670 completed (loss: 0.1503453552722931, acc: 0.9657794833183289)
[2024-11-14 10:26:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:38][root][INFO] - Training Epoch: 2/2, step 14767/16670 completed (loss: 0.12620197236537933, acc: 0.9585492014884949)
[2024-11-14 10:26:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:39][root][INFO] - Training Epoch: 2/2, step 14768/16670 completed (loss: 0.5524647831916809, acc: 0.8484848737716675)
[2024-11-14 10:26:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:39][root][INFO] - Training Epoch: 2/2, step 14769/16670 completed (loss: 0.099467933177948, acc: 0.9814814925193787)
[2024-11-14 10:26:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:39][root][INFO] - Training Epoch: 2/2, step 14770/16670 completed (loss: 0.07902102172374725, acc: 0.9695431590080261)
[2024-11-14 10:26:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:40][root][INFO] - Training Epoch: 2/2, step 14771/16670 completed (loss: 0.1482962816953659, acc: 0.9631336331367493)
[2024-11-14 10:26:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:40][root][INFO] - Training Epoch: 2/2, step 14772/16670 completed (loss: 0.09064938127994537, acc: 0.9567567706108093)
[2024-11-14 10:26:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:40][root][INFO] - Training Epoch: 2/2, step 14773/16670 completed (loss: 0.1288415640592575, acc: 0.9593023061752319)
[2024-11-14 10:26:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:41][root][INFO] - Training Epoch: 2/2, step 14774/16670 completed (loss: 0.09851843118667603, acc: 0.9731543660163879)
[2024-11-14 10:26:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:41][root][INFO] - Training Epoch: 2/2, step 14775/16670 completed (loss: 0.035601500421762466, acc: 0.9846153855323792)
[2024-11-14 10:26:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:41][root][INFO] - Training Epoch: 2/2, step 14776/16670 completed (loss: 0.1927865594625473, acc: 0.9491525292396545)
[2024-11-14 10:26:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:42][root][INFO] - Training Epoch: 2/2, step 14777/16670 completed (loss: 0.12412863969802856, acc: 0.9584569931030273)
[2024-11-14 10:26:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:42][root][INFO] - Training Epoch: 2/2, step 14778/16670 completed (loss: 0.2065386027097702, acc: 0.9272727370262146)
[2024-11-14 10:26:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:42][root][INFO] - Training Epoch: 2/2, step 14779/16670 completed (loss: 0.33717674016952515, acc: 0.90625)
[2024-11-14 10:26:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:43][root][INFO] - Training Epoch: 2/2, step 14780/16670 completed (loss: 0.14756852388381958, acc: 0.9672130942344666)
[2024-11-14 10:26:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:43][root][INFO] - Training Epoch: 2/2, step 14781/16670 completed (loss: 0.10342445224523544, acc: 0.9666666388511658)
[2024-11-14 10:26:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:43][root][INFO] - Training Epoch: 2/2, step 14782/16670 completed (loss: 0.05847174674272537, acc: 0.9791666865348816)
[2024-11-14 10:26:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:44][root][INFO] - Training Epoch: 2/2, step 14783/16670 completed (loss: 0.02579193376004696, acc: 0.9933775067329407)
[2024-11-14 10:26:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:44][root][INFO] - Training Epoch: 2/2, step 14784/16670 completed (loss: 0.14052969217300415, acc: 0.9662446975708008)
[2024-11-14 10:26:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:44][root][INFO] - Training Epoch: 2/2, step 14785/16670 completed (loss: 0.12313616275787354, acc: 0.9585798978805542)
[2024-11-14 10:26:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:45][root][INFO] - Training Epoch: 2/2, step 14786/16670 completed (loss: 0.07585130631923676, acc: 0.9779411554336548)
[2024-11-14 10:26:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:45][root][INFO] - Training Epoch: 2/2, step 14787/16670 completed (loss: 0.1903863549232483, acc: 0.9485714435577393)
[2024-11-14 10:26:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:45][root][INFO] - Training Epoch: 2/2, step 14788/16670 completed (loss: 0.06904182583093643, acc: 0.974452555179596)
[2024-11-14 10:26:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:46][root][INFO] - Training Epoch: 2/2, step 14789/16670 completed (loss: 0.1690436154603958, acc: 0.9477124214172363)
[2024-11-14 10:26:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:46][root][INFO] - Training Epoch: 2/2, step 14790/16670 completed (loss: 0.34830474853515625, acc: 0.9248826503753662)
[2024-11-14 10:26:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:46][root][INFO] - Training Epoch: 2/2, step 14791/16670 completed (loss: 0.23980507254600525, acc: 0.9479768872261047)
[2024-11-14 10:26:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:47][root][INFO] - Training Epoch: 2/2, step 14792/16670 completed (loss: 0.16257542371749878, acc: 0.9488372206687927)
[2024-11-14 10:26:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:47][root][INFO] - Training Epoch: 2/2, step 14793/16670 completed (loss: 0.17408472299575806, acc: 0.9557521939277649)
[2024-11-14 10:26:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:47][root][INFO] - Training Epoch: 2/2, step 14794/16670 completed (loss: 0.14685523509979248, acc: 0.9626865386962891)
[2024-11-14 10:26:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:48][root][INFO] - Training Epoch: 2/2, step 14795/16670 completed (loss: 0.09518749266862869, acc: 0.9750889539718628)
[2024-11-14 10:26:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:48][root][INFO] - Training Epoch: 2/2, step 14796/16670 completed (loss: 0.11773379892110825, acc: 0.9723502397537231)
[2024-11-14 10:26:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:49][root][INFO] - Training Epoch: 2/2, step 14797/16670 completed (loss: 0.19226326048374176, acc: 0.949999988079071)
[2024-11-14 10:26:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:49][root][INFO] - Training Epoch: 2/2, step 14798/16670 completed (loss: 0.17021045088768005, acc: 0.9539473652839661)
[2024-11-14 10:26:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:49][root][INFO] - Training Epoch: 2/2, step 14799/16670 completed (loss: 0.2356504201889038, acc: 0.9508196711540222)
[2024-11-14 10:26:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:50][root][INFO] - Training Epoch: 2/2, step 14800/16670 completed (loss: 0.20947785675525665, acc: 0.9417989253997803)
[2024-11-14 10:26:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:50][root][INFO] - Training Epoch: 2/2, step 14801/16670 completed (loss: 0.21485671401023865, acc: 0.9298245906829834)
[2024-11-14 10:26:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:50][root][INFO] - Training Epoch: 2/2, step 14802/16670 completed (loss: 0.14219939708709717, acc: 0.9559321999549866)
[2024-11-14 10:26:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:51][root][INFO] - Training Epoch: 2/2, step 14803/16670 completed (loss: 0.1802060753107071, acc: 0.9612902998924255)
[2024-11-14 10:26:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:51][root][INFO] - Training Epoch: 2/2, step 14804/16670 completed (loss: 0.08713407069444656, acc: 0.9863013625144958)
[2024-11-14 10:26:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:51][root][INFO] - Training Epoch: 2/2, step 14805/16670 completed (loss: 0.46661248803138733, acc: 0.9111111164093018)
[2024-11-14 10:26:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:52][root][INFO] - Training Epoch: 2/2, step 14806/16670 completed (loss: 0.16429345309734344, acc: 0.963350772857666)
[2024-11-14 10:26:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:52][root][INFO] - Training Epoch: 2/2, step 14807/16670 completed (loss: 0.21926555037498474, acc: 0.9527559280395508)
[2024-11-14 10:26:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:53][root][INFO] - Training Epoch: 2/2, step 14808/16670 completed (loss: 0.19266720116138458, acc: 0.9611111283302307)
[2024-11-14 10:26:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:53][root][INFO] - Training Epoch: 2/2, step 14809/16670 completed (loss: 0.08222127705812454, acc: 0.9702970385551453)
[2024-11-14 10:26:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:53][root][INFO] - Training Epoch: 2/2, step 14810/16670 completed (loss: 0.10204838961362839, acc: 0.970588207244873)
[2024-11-14 10:26:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:54][root][INFO] - Training Epoch: 2/2, step 14811/16670 completed (loss: 0.05498383939266205, acc: 0.9877551198005676)
[2024-11-14 10:26:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:54][root][INFO] - Training Epoch: 2/2, step 14812/16670 completed (loss: 0.14480112493038177, acc: 0.9644268751144409)
[2024-11-14 10:26:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:54][root][INFO] - Training Epoch: 2/2, step 14813/16670 completed (loss: 0.09218886494636536, acc: 0.9760956168174744)
[2024-11-14 10:26:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:55][root][INFO] - Training Epoch: 2/2, step 14814/16670 completed (loss: 0.34283721446990967, acc: 0.932692289352417)
[2024-11-14 10:26:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:55][root][INFO] - Training Epoch: 2/2, step 14815/16670 completed (loss: 0.3104724884033203, acc: 0.9277108311653137)
[2024-11-14 10:26:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:56][root][INFO] - Training Epoch: 2/2, step 14816/16670 completed (loss: 0.1360330581665039, acc: 0.95703125)
[2024-11-14 10:26:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:56][root][INFO] - Training Epoch: 2/2, step 14817/16670 completed (loss: 0.06843559443950653, acc: 0.9777777791023254)
[2024-11-14 10:26:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:56][root][INFO] - Training Epoch: 2/2, step 14818/16670 completed (loss: 0.16841457784175873, acc: 0.9588235020637512)
[2024-11-14 10:26:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:57][root][INFO] - Training Epoch: 2/2, step 14819/16670 completed (loss: 0.18202254176139832, acc: 0.9479768872261047)
[2024-11-14 10:26:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:57][root][INFO] - Training Epoch: 2/2, step 14820/16670 completed (loss: 0.14673270285129547, acc: 0.9431818127632141)
[2024-11-14 10:26:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:57][root][INFO] - Training Epoch: 2/2, step 14821/16670 completed (loss: 0.11089039593935013, acc: 0.9783549904823303)
[2024-11-14 10:26:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:58][root][INFO] - Training Epoch: 2/2, step 14822/16670 completed (loss: 0.13908542692661285, acc: 0.9541284441947937)
[2024-11-14 10:26:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:58][root][INFO] - Training Epoch: 2/2, step 14823/16670 completed (loss: 0.15447749197483063, acc: 0.9651162624359131)
[2024-11-14 10:26:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:59][root][INFO] - Training Epoch: 2/2, step 14824/16670 completed (loss: 0.2920185923576355, acc: 0.9300000071525574)
[2024-11-14 10:26:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:59][root][INFO] - Training Epoch: 2/2, step 14825/16670 completed (loss: 0.1425071656703949, acc: 0.9657142758369446)
[2024-11-14 10:26:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:26:59][root][INFO] - Training Epoch: 2/2, step 14826/16670 completed (loss: 0.15505503118038177, acc: 0.9615384340286255)
[2024-11-14 10:26:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:00][root][INFO] - Training Epoch: 2/2, step 14827/16670 completed (loss: 0.1586042046546936, acc: 0.9666666388511658)
[2024-11-14 10:27:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:00][root][INFO] - Training Epoch: 2/2, step 14828/16670 completed (loss: 0.1411607265472412, acc: 0.9618644118309021)
[2024-11-14 10:27:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:00][root][INFO] - Training Epoch: 2/2, step 14829/16670 completed (loss: 0.10944973677396774, acc: 0.9727891087532043)
[2024-11-14 10:27:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:01][root][INFO] - Training Epoch: 2/2, step 14830/16670 completed (loss: 0.24017417430877686, acc: 0.946601927280426)
[2024-11-14 10:27:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:01][root][INFO] - Training Epoch: 2/2, step 14831/16670 completed (loss: 0.12362823635339737, acc: 0.9668874144554138)
[2024-11-14 10:27:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:02][root][INFO] - Training Epoch: 2/2, step 14832/16670 completed (loss: 0.07267243415117264, acc: 0.991416335105896)
[2024-11-14 10:27:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:02][root][INFO] - Training Epoch: 2/2, step 14833/16670 completed (loss: 0.13208630681037903, acc: 0.9640287756919861)
[2024-11-14 10:27:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:02][root][INFO] - Training Epoch: 2/2, step 14834/16670 completed (loss: 0.1448427438735962, acc: 0.9579287767410278)
[2024-11-14 10:27:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:02][root][INFO] - Training Epoch: 2/2, step 14835/16670 completed (loss: 0.15099021792411804, acc: 0.9523809552192688)
[2024-11-14 10:27:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:03][root][INFO] - Training Epoch: 2/2, step 14836/16670 completed (loss: 0.20079892873764038, acc: 0.947826087474823)
[2024-11-14 10:27:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:03][root][INFO] - Training Epoch: 2/2, step 14837/16670 completed (loss: 0.14865943789482117, acc: 0.9542483687400818)
[2024-11-14 10:27:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:03][root][INFO] - Training Epoch: 2/2, step 14838/16670 completed (loss: 0.05963674932718277, acc: 0.9767441749572754)
[2024-11-14 10:27:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:04][root][INFO] - Training Epoch: 2/2, step 14839/16670 completed (loss: 0.23294712603092194, acc: 0.9344262480735779)
[2024-11-14 10:27:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:04][root][INFO] - Training Epoch: 2/2, step 14840/16670 completed (loss: 0.03029482811689377, acc: 0.98591548204422)
[2024-11-14 10:27:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:04][root][INFO] - Training Epoch: 2/2, step 14841/16670 completed (loss: 0.0495791919529438, acc: 0.9855072498321533)
[2024-11-14 10:27:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:05][root][INFO] - Training Epoch: 2/2, step 14842/16670 completed (loss: 0.1395164281129837, acc: 0.9673202633857727)
[2024-11-14 10:27:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:05][root][INFO] - Training Epoch: 2/2, step 14843/16670 completed (loss: 0.20160116255283356, acc: 0.953125)
[2024-11-14 10:27:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:05][root][INFO] - Training Epoch: 2/2, step 14844/16670 completed (loss: 0.18516072630882263, acc: 0.9230769276618958)
[2024-11-14 10:27:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:06][root][INFO] - Training Epoch: 2/2, step 14845/16670 completed (loss: 0.12162783741950989, acc: 0.965753436088562)
[2024-11-14 10:27:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:06][root][INFO] - Training Epoch: 2/2, step 14846/16670 completed (loss: 0.058033913373947144, acc: 0.978723406791687)
[2024-11-14 10:27:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:06][root][INFO] - Training Epoch: 2/2, step 14847/16670 completed (loss: 0.14722280204296112, acc: 0.946601927280426)
[2024-11-14 10:27:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:07][root][INFO] - Training Epoch: 2/2, step 14848/16670 completed (loss: 0.17663933336734772, acc: 0.9615384340286255)
[2024-11-14 10:27:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:07][root][INFO] - Training Epoch: 2/2, step 14849/16670 completed (loss: 0.11401914805173874, acc: 0.9665272235870361)
[2024-11-14 10:27:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:08][root][INFO] - Training Epoch: 2/2, step 14850/16670 completed (loss: 0.03749493137001991, acc: 0.9913793206214905)
[2024-11-14 10:27:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:08][root][INFO] - Training Epoch: 2/2, step 14851/16670 completed (loss: 0.20480407774448395, acc: 0.9640287756919861)
[2024-11-14 10:27:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:08][root][INFO] - Training Epoch: 2/2, step 14852/16670 completed (loss: 0.1897757202386856, acc: 0.935251772403717)
[2024-11-14 10:27:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:09][root][INFO] - Training Epoch: 2/2, step 14853/16670 completed (loss: 0.18491896986961365, acc: 0.9514563083648682)
[2024-11-14 10:27:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:09][root][INFO] - Training Epoch: 2/2, step 14854/16670 completed (loss: 0.1985182762145996, acc: 0.949999988079071)
[2024-11-14 10:27:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:09][root][INFO] - Training Epoch: 2/2, step 14855/16670 completed (loss: 0.27605918049812317, acc: 0.9375)
[2024-11-14 10:27:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:10][root][INFO] - Training Epoch: 2/2, step 14856/16670 completed (loss: 0.1827079802751541, acc: 0.9384615421295166)
[2024-11-14 10:27:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:10][root][INFO] - Training Epoch: 2/2, step 14857/16670 completed (loss: 0.17760948836803436, acc: 0.9629629850387573)
[2024-11-14 10:27:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:10][root][INFO] - Training Epoch: 2/2, step 14858/16670 completed (loss: 0.3699749708175659, acc: 0.8823529481887817)
[2024-11-14 10:27:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:11][root][INFO] - Training Epoch: 2/2, step 14859/16670 completed (loss: 0.06947257369756699, acc: 0.9747899174690247)
[2024-11-14 10:27:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:11][root][INFO] - Training Epoch: 2/2, step 14860/16670 completed (loss: 0.12977595627307892, acc: 0.9545454382896423)
[2024-11-14 10:27:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:11][root][INFO] - Training Epoch: 2/2, step 14861/16670 completed (loss: 0.06609845161437988, acc: 0.9772727489471436)
[2024-11-14 10:27:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:12][root][INFO] - Training Epoch: 2/2, step 14862/16670 completed (loss: 0.09845879673957825, acc: 0.9669811129570007)
[2024-11-14 10:27:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:12][root][INFO] - Training Epoch: 2/2, step 14863/16670 completed (loss: 0.22402654588222504, acc: 0.9107142686843872)
[2024-11-14 10:27:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:12][root][INFO] - Training Epoch: 2/2, step 14864/16670 completed (loss: 0.2805935740470886, acc: 0.9545454382896423)
[2024-11-14 10:27:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:13][root][INFO] - Training Epoch: 2/2, step 14865/16670 completed (loss: 0.16413965821266174, acc: 0.9512194991111755)
[2024-11-14 10:27:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:13][root][INFO] - Training Epoch: 2/2, step 14866/16670 completed (loss: 0.23675139248371124, acc: 0.9365671873092651)
[2024-11-14 10:27:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:13][root][INFO] - Training Epoch: 2/2, step 14867/16670 completed (loss: 0.15347757935523987, acc: 0.9729729890823364)
[2024-11-14 10:27:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:14][root][INFO] - Training Epoch: 2/2, step 14868/16670 completed (loss: 0.3688892424106598, acc: 0.9130434989929199)
[2024-11-14 10:27:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:14][root][INFO] - Training Epoch: 2/2, step 14869/16670 completed (loss: 0.09704795479774475, acc: 0.949999988079071)
[2024-11-14 10:27:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:15][root][INFO] - Training Epoch: 2/2, step 14870/16670 completed (loss: 0.1635899692773819, acc: 0.9473684430122375)
[2024-11-14 10:27:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:15][root][INFO] - Training Epoch: 2/2, step 14871/16670 completed (loss: 0.2906290888786316, acc: 0.9203540086746216)
[2024-11-14 10:27:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:15][root][INFO] - Training Epoch: 2/2, step 14872/16670 completed (loss: 0.03754568472504616, acc: 0.9931034445762634)
[2024-11-14 10:27:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:15][root][INFO] - Training Epoch: 2/2, step 14873/16670 completed (loss: 0.10558148473501205, acc: 0.9800000190734863)
[2024-11-14 10:27:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:16][root][INFO] - Training Epoch: 2/2, step 14874/16670 completed (loss: 0.2078150361776352, acc: 0.9356435537338257)
[2024-11-14 10:27:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:16][root][INFO] - Training Epoch: 2/2, step 14875/16670 completed (loss: 0.10980943590402603, acc: 0.9670329689979553)
[2024-11-14 10:27:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:17][root][INFO] - Training Epoch: 2/2, step 14876/16670 completed (loss: 0.2618570029735565, acc: 0.9090909361839294)
[2024-11-14 10:27:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:17][root][INFO] - Training Epoch: 2/2, step 14877/16670 completed (loss: 0.19510725140571594, acc: 0.922535240650177)
[2024-11-14 10:27:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:17][root][INFO] - Training Epoch: 2/2, step 14878/16670 completed (loss: 0.06827279180288315, acc: 0.9870129823684692)
[2024-11-14 10:27:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:17][root][INFO] - Training Epoch: 2/2, step 14879/16670 completed (loss: 0.05450155586004257, acc: 1.0)
[2024-11-14 10:27:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:18][root][INFO] - Training Epoch: 2/2, step 14880/16670 completed (loss: 0.24337291717529297, acc: 0.951724112033844)
[2024-11-14 10:27:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:18][root][INFO] - Training Epoch: 2/2, step 14881/16670 completed (loss: 0.18463367223739624, acc: 0.9567901492118835)
[2024-11-14 10:27:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:19][root][INFO] - Training Epoch: 2/2, step 14882/16670 completed (loss: 0.6073344349861145, acc: 0.8409090638160706)
[2024-11-14 10:27:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:19][root][INFO] - Training Epoch: 2/2, step 14883/16670 completed (loss: 0.13977693021297455, acc: 0.9496402740478516)
[2024-11-14 10:27:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:19][root][INFO] - Training Epoch: 2/2, step 14884/16670 completed (loss: 0.04782969132065773, acc: 0.9887640476226807)
[2024-11-14 10:27:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:20][root][INFO] - Training Epoch: 2/2, step 14885/16670 completed (loss: 0.09411301463842392, acc: 0.9729729890823364)
[2024-11-14 10:27:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:20][root][INFO] - Training Epoch: 2/2, step 14886/16670 completed (loss: 0.23617103695869446, acc: 0.9448275566101074)
[2024-11-14 10:27:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:20][root][INFO] - Training Epoch: 2/2, step 14887/16670 completed (loss: 0.5842435956001282, acc: 0.876288652420044)
[2024-11-14 10:27:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:21][root][INFO] - Training Epoch: 2/2, step 14888/16670 completed (loss: 0.23853296041488647, acc: 0.9032257795333862)
[2024-11-14 10:27:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:21][root][INFO] - Training Epoch: 2/2, step 14889/16670 completed (loss: 0.13850003480911255, acc: 0.9470198750495911)
[2024-11-14 10:27:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:21][root][INFO] - Training Epoch: 2/2, step 14890/16670 completed (loss: 0.06656689196825027, acc: 0.9855072498321533)
[2024-11-14 10:27:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:22][root][INFO] - Training Epoch: 2/2, step 14891/16670 completed (loss: 0.11220841854810715, acc: 0.9618320465087891)
[2024-11-14 10:27:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:22][root][INFO] - Training Epoch: 2/2, step 14892/16670 completed (loss: 0.3398860692977905, acc: 0.9130434989929199)
[2024-11-14 10:27:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:22][root][INFO] - Training Epoch: 2/2, step 14893/16670 completed (loss: 0.12428814172744751, acc: 0.9669421315193176)
[2024-11-14 10:27:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:23][root][INFO] - Training Epoch: 2/2, step 14894/16670 completed (loss: 0.1550740897655487, acc: 0.9733333587646484)
[2024-11-14 10:27:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:23][root][INFO] - Training Epoch: 2/2, step 14895/16670 completed (loss: 0.24623484909534454, acc: 0.9195979833602905)
[2024-11-14 10:27:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:23][root][INFO] - Training Epoch: 2/2, step 14896/16670 completed (loss: 0.20890364050865173, acc: 0.9661017060279846)
[2024-11-14 10:27:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:24][root][INFO] - Training Epoch: 2/2, step 14897/16670 completed (loss: 0.18248233199119568, acc: 0.9441340565681458)
[2024-11-14 10:27:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:24][root][INFO] - Training Epoch: 2/2, step 14898/16670 completed (loss: 0.2058195322751999, acc: 0.948051929473877)
[2024-11-14 10:27:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:24][root][INFO] - Training Epoch: 2/2, step 14899/16670 completed (loss: 0.29218825697898865, acc: 0.9230769276618958)
[2024-11-14 10:27:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:25][root][INFO] - Training Epoch: 2/2, step 14900/16670 completed (loss: 0.18415282666683197, acc: 0.9451219439506531)
[2024-11-14 10:27:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:25][root][INFO] - Training Epoch: 2/2, step 14901/16670 completed (loss: 0.24307477474212646, acc: 0.938144326210022)
[2024-11-14 10:27:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:25][root][INFO] - Training Epoch: 2/2, step 14902/16670 completed (loss: 0.3258691728115082, acc: 0.9020978808403015)
[2024-11-14 10:27:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:26][root][INFO] - Training Epoch: 2/2, step 14903/16670 completed (loss: 0.21090233325958252, acc: 0.939393937587738)
[2024-11-14 10:27:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:26][root][INFO] - Training Epoch: 2/2, step 14904/16670 completed (loss: 0.07104845345020294, acc: 0.9764705896377563)
[2024-11-14 10:27:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:26][root][INFO] - Training Epoch: 2/2, step 14905/16670 completed (loss: 0.2300567328929901, acc: 0.9320388436317444)
[2024-11-14 10:27:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:27][root][INFO] - Training Epoch: 2/2, step 14906/16670 completed (loss: 0.16100050508975983, acc: 0.942307710647583)
[2024-11-14 10:27:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:27][root][INFO] - Training Epoch: 2/2, step 14907/16670 completed (loss: 0.06143840029835701, acc: 0.9797297120094299)
[2024-11-14 10:27:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:27][root][INFO] - Training Epoch: 2/2, step 14908/16670 completed (loss: 0.24983526766300201, acc: 0.9202454090118408)
[2024-11-14 10:27:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:28][root][INFO] - Training Epoch: 2/2, step 14909/16670 completed (loss: 0.17819179594516754, acc: 0.9415584206581116)
[2024-11-14 10:27:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:28][root][INFO] - Training Epoch: 2/2, step 14910/16670 completed (loss: 0.21925216913223267, acc: 0.9523809552192688)
[2024-11-14 10:27:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:29][root][INFO] - Training Epoch: 2/2, step 14911/16670 completed (loss: 0.12066815048456192, acc: 0.9675675630569458)
[2024-11-14 10:27:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:29][root][INFO] - Training Epoch: 2/2, step 14912/16670 completed (loss: 0.15196886658668518, acc: 0.9545454382896423)
[2024-11-14 10:27:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:29][root][INFO] - Training Epoch: 2/2, step 14913/16670 completed (loss: 0.19617092609405518, acc: 0.9491525292396545)
[2024-11-14 10:27:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:30][root][INFO] - Training Epoch: 2/2, step 14914/16670 completed (loss: 0.29529425501823425, acc: 0.8987341523170471)
[2024-11-14 10:27:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:30][root][INFO] - Training Epoch: 2/2, step 14915/16670 completed (loss: 0.1208595260977745, acc: 0.9568965435028076)
[2024-11-14 10:27:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:30][root][INFO] - Training Epoch: 2/2, step 14916/16670 completed (loss: 0.20652572810649872, acc: 0.939393937587738)
[2024-11-14 10:27:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:30][root][INFO] - Training Epoch: 2/2, step 14917/16670 completed (loss: 0.1433301568031311, acc: 0.9627329111099243)
[2024-11-14 10:27:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:31][root][INFO] - Training Epoch: 2/2, step 14918/16670 completed (loss: 0.23589980602264404, acc: 0.9448275566101074)
[2024-11-14 10:27:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:31][root][INFO] - Training Epoch: 2/2, step 14919/16670 completed (loss: 0.2229071855545044, acc: 0.9481481313705444)
[2024-11-14 10:27:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:31][root][INFO] - Training Epoch: 2/2, step 14920/16670 completed (loss: 0.23185871541500092, acc: 0.9399999976158142)
[2024-11-14 10:27:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:32][root][INFO] - Training Epoch: 2/2, step 14921/16670 completed (loss: 0.14313314855098724, acc: 0.9439252614974976)
[2024-11-14 10:27:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:32][root][INFO] - Training Epoch: 2/2, step 14922/16670 completed (loss: 0.17233102023601532, acc: 0.9541284441947937)
[2024-11-14 10:27:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:32][root][INFO] - Training Epoch: 2/2, step 14923/16670 completed (loss: 0.16383782029151917, acc: 0.930232584476471)
[2024-11-14 10:27:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:33][root][INFO] - Training Epoch: 2/2, step 14924/16670 completed (loss: 0.12916602194309235, acc: 0.9663865566253662)
[2024-11-14 10:27:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:33][root][INFO] - Training Epoch: 2/2, step 14925/16670 completed (loss: 0.1993403136730194, acc: 0.9530201554298401)
[2024-11-14 10:27:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:33][root][INFO] - Training Epoch: 2/2, step 14926/16670 completed (loss: 0.10996107757091522, acc: 0.9679999947547913)
[2024-11-14 10:27:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:34][root][INFO] - Training Epoch: 2/2, step 14927/16670 completed (loss: 0.1810786873102188, acc: 0.9690265655517578)
[2024-11-14 10:27:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:34][root][INFO] - Training Epoch: 2/2, step 14928/16670 completed (loss: 0.22957059741020203, acc: 0.9460784196853638)
[2024-11-14 10:27:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:34][root][INFO] - Training Epoch: 2/2, step 14929/16670 completed (loss: 0.0716213807463646, acc: 0.9759615659713745)
[2024-11-14 10:27:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:35][root][INFO] - Training Epoch: 2/2, step 14930/16670 completed (loss: 0.14537757635116577, acc: 0.9649805426597595)
[2024-11-14 10:27:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:35][root][INFO] - Training Epoch: 2/2, step 14931/16670 completed (loss: 0.11300752311944962, acc: 0.9624060392379761)
[2024-11-14 10:27:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:35][root][INFO] - Training Epoch: 2/2, step 14932/16670 completed (loss: 0.17559367418289185, acc: 0.949999988079071)
[2024-11-14 10:27:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:36][root][INFO] - Training Epoch: 2/2, step 14933/16670 completed (loss: 0.18354420363903046, acc: 0.9481481313705444)
[2024-11-14 10:27:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:36][root][INFO] - Training Epoch: 2/2, step 14934/16670 completed (loss: 0.25122636556625366, acc: 0.9240506291389465)
[2024-11-14 10:27:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:36][root][INFO] - Training Epoch: 2/2, step 14935/16670 completed (loss: 0.20598696172237396, acc: 0.9318181872367859)
[2024-11-14 10:27:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:37][root][INFO] - Training Epoch: 2/2, step 14936/16670 completed (loss: 0.07141119986772537, acc: 0.9807692170143127)
[2024-11-14 10:27:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:37][root][INFO] - Training Epoch: 2/2, step 14937/16670 completed (loss: 0.3067605793476105, acc: 0.9506173133850098)
[2024-11-14 10:27:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:37][root][INFO] - Training Epoch: 2/2, step 14938/16670 completed (loss: 0.11377587169408798, acc: 0.9710144996643066)
[2024-11-14 10:27:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:37][root][INFO] - Training Epoch: 2/2, step 14939/16670 completed (loss: 0.38677993416786194, acc: 0.9007092118263245)
[2024-11-14 10:27:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:38][root][INFO] - Training Epoch: 2/2, step 14940/16670 completed (loss: 0.10238298028707504, acc: 0.9789473414421082)
[2024-11-14 10:27:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:38][root][INFO] - Training Epoch: 2/2, step 14941/16670 completed (loss: 0.12510956823825836, acc: 0.9545454382896423)
[2024-11-14 10:27:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:38][root][INFO] - Training Epoch: 2/2, step 14942/16670 completed (loss: 0.5569063425064087, acc: 0.8779069781303406)
[2024-11-14 10:27:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:39][root][INFO] - Training Epoch: 2/2, step 14943/16670 completed (loss: 0.167638897895813, acc: 0.9462365508079529)
[2024-11-14 10:27:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:39][root][INFO] - Training Epoch: 2/2, step 14944/16670 completed (loss: 0.13251455128192902, acc: 0.9878048896789551)
[2024-11-14 10:27:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:39][root][INFO] - Training Epoch: 2/2, step 14945/16670 completed (loss: 0.13567332923412323, acc: 0.9774436354637146)
[2024-11-14 10:27:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:40][root][INFO] - Training Epoch: 2/2, step 14946/16670 completed (loss: 0.21725527942180634, acc: 0.9649122953414917)
[2024-11-14 10:27:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:40][root][INFO] - Training Epoch: 2/2, step 14947/16670 completed (loss: 0.033393580466508865, acc: 0.9907407164573669)
[2024-11-14 10:27:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:40][root][INFO] - Training Epoch: 2/2, step 14948/16670 completed (loss: 0.4781377911567688, acc: 0.8989899158477783)
[2024-11-14 10:27:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:40][root][INFO] - Training Epoch: 2/2, step 14949/16670 completed (loss: 0.38620731234550476, acc: 0.9107142686843872)
[2024-11-14 10:27:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:41][root][INFO] - Training Epoch: 2/2, step 14950/16670 completed (loss: 0.3825646638870239, acc: 0.9074074029922485)
[2024-11-14 10:27:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:41][root][INFO] - Training Epoch: 2/2, step 14951/16670 completed (loss: 0.26477861404418945, acc: 0.9368420839309692)
[2024-11-14 10:27:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:41][root][INFO] - Training Epoch: 2/2, step 14952/16670 completed (loss: 0.18846048414707184, acc: 0.9666666388511658)
[2024-11-14 10:27:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:42][root][INFO] - Training Epoch: 2/2, step 14953/16670 completed (loss: 0.11051955819129944, acc: 0.9887640476226807)
[2024-11-14 10:27:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:42][root][INFO] - Training Epoch: 2/2, step 14954/16670 completed (loss: 0.14190541207790375, acc: 0.9530201554298401)
[2024-11-14 10:27:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:42][root][INFO] - Training Epoch: 2/2, step 14955/16670 completed (loss: 0.17495128512382507, acc: 0.948113203048706)
[2024-11-14 10:27:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:43][root][INFO] - Training Epoch: 2/2, step 14956/16670 completed (loss: 0.14025142788887024, acc: 0.9541984796524048)
[2024-11-14 10:27:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:43][root][INFO] - Training Epoch: 2/2, step 14957/16670 completed (loss: 0.23304438591003418, acc: 0.9534883499145508)
[2024-11-14 10:27:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:43][root][INFO] - Training Epoch: 2/2, step 14958/16670 completed (loss: 0.15660318732261658, acc: 0.9694322943687439)
[2024-11-14 10:27:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:43][root][INFO] - Training Epoch: 2/2, step 14959/16670 completed (loss: 0.17184489965438843, acc: 0.9532163739204407)
[2024-11-14 10:27:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:44][root][INFO] - Training Epoch: 2/2, step 14960/16670 completed (loss: 0.29994142055511475, acc: 0.9207921028137207)
[2024-11-14 10:27:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:44][root][INFO] - Training Epoch: 2/2, step 14961/16670 completed (loss: 0.23492228984832764, acc: 0.9347826242446899)
[2024-11-14 10:27:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:44][root][INFO] - Training Epoch: 2/2, step 14962/16670 completed (loss: 0.10648192465305328, acc: 0.9668049812316895)
[2024-11-14 10:27:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:45][root][INFO] - Training Epoch: 2/2, step 14963/16670 completed (loss: 0.1481824666261673, acc: 0.9523809552192688)
[2024-11-14 10:27:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:45][root][INFO] - Training Epoch: 2/2, step 14964/16670 completed (loss: 0.0808999091386795, acc: 0.976190447807312)
[2024-11-14 10:27:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:45][root][INFO] - Training Epoch: 2/2, step 14965/16670 completed (loss: 0.2108125388622284, acc: 0.925000011920929)
[2024-11-14 10:27:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:46][root][INFO] - Training Epoch: 2/2, step 14966/16670 completed (loss: 0.19082890450954437, acc: 0.9662162065505981)
[2024-11-14 10:27:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:46][root][INFO] - Training Epoch: 2/2, step 14967/16670 completed (loss: 0.24937844276428223, acc: 0.9388889074325562)
[2024-11-14 10:27:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:46][root][INFO] - Training Epoch: 2/2, step 14968/16670 completed (loss: 0.15521278977394104, acc: 0.9449541568756104)
[2024-11-14 10:27:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:47][root][INFO] - Training Epoch: 2/2, step 14969/16670 completed (loss: 0.17773644626140594, acc: 0.9417475461959839)
[2024-11-14 10:27:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:47][root][INFO] - Training Epoch: 2/2, step 14970/16670 completed (loss: 0.23789867758750916, acc: 0.9277108311653137)
[2024-11-14 10:27:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:47][root][INFO] - Training Epoch: 2/2, step 14971/16670 completed (loss: 0.10483188182115555, acc: 0.9655172228813171)
[2024-11-14 10:27:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:47][root][INFO] - Training Epoch: 2/2, step 14972/16670 completed (loss: 0.2257544845342636, acc: 0.9259259104728699)
[2024-11-14 10:27:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:48][root][INFO] - Training Epoch: 2/2, step 14973/16670 completed (loss: 0.07864444702863693, acc: 0.9756097793579102)
[2024-11-14 10:27:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:48][root][INFO] - Training Epoch: 2/2, step 14974/16670 completed (loss: 0.10393587499856949, acc: 0.9658119678497314)
[2024-11-14 10:27:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:48][root][INFO] - Training Epoch: 2/2, step 14975/16670 completed (loss: 0.16960299015045166, acc: 0.9547738432884216)
[2024-11-14 10:27:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:49][root][INFO] - Training Epoch: 2/2, step 14976/16670 completed (loss: 0.1880905032157898, acc: 0.9583333134651184)
[2024-11-14 10:27:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:49][root][INFO] - Training Epoch: 2/2, step 14977/16670 completed (loss: 0.08844765275716782, acc: 0.9765625)
[2024-11-14 10:27:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:49][root][INFO] - Training Epoch: 2/2, step 14978/16670 completed (loss: 0.12043841928243637, acc: 0.976190447807312)
[2024-11-14 10:27:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:50][root][INFO] - Training Epoch: 2/2, step 14979/16670 completed (loss: 0.18065015971660614, acc: 0.9349112510681152)
[2024-11-14 10:27:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:50][root][INFO] - Training Epoch: 2/2, step 14980/16670 completed (loss: 0.13766248524188995, acc: 0.9545454382896423)
[2024-11-14 10:27:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:50][root][INFO] - Training Epoch: 2/2, step 14981/16670 completed (loss: 0.31946197152137756, acc: 0.907216489315033)
[2024-11-14 10:27:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:50][root][INFO] - Training Epoch: 2/2, step 14982/16670 completed (loss: 0.15569737553596497, acc: 0.9436619877815247)
[2024-11-14 10:27:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:51][root][INFO] - Training Epoch: 2/2, step 14983/16670 completed (loss: 0.12286543846130371, acc: 0.9710144996643066)
[2024-11-14 10:27:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:51][root][INFO] - Training Epoch: 2/2, step 14984/16670 completed (loss: 0.2244802713394165, acc: 0.935251772403717)
[2024-11-14 10:27:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:51][root][INFO] - Training Epoch: 2/2, step 14985/16670 completed (loss: 0.11870431900024414, acc: 0.9644669890403748)
[2024-11-14 10:27:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:52][root][INFO] - Training Epoch: 2/2, step 14986/16670 completed (loss: 0.2545959949493408, acc: 0.9285714030265808)
[2024-11-14 10:27:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:52][root][INFO] - Training Epoch: 2/2, step 14987/16670 completed (loss: 0.11781706660985947, acc: 0.9599999785423279)
[2024-11-14 10:27:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:52][root][INFO] - Training Epoch: 2/2, step 14988/16670 completed (loss: 0.24168802797794342, acc: 0.9567901492118835)
[2024-11-14 10:27:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:53][root][INFO] - Training Epoch: 2/2, step 14989/16670 completed (loss: 0.3440527021884918, acc: 0.90625)
[2024-11-14 10:27:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:53][root][INFO] - Training Epoch: 2/2, step 14990/16670 completed (loss: 0.1793823391199112, acc: 0.940397322177887)
[2024-11-14 10:27:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:53][root][INFO] - Training Epoch: 2/2, step 14991/16670 completed (loss: 0.36540457606315613, acc: 0.9230769276618958)
[2024-11-14 10:27:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:54][root][INFO] - Training Epoch: 2/2, step 14992/16670 completed (loss: 0.19744786620140076, acc: 0.9605911374092102)
[2024-11-14 10:27:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:54][root][INFO] - Training Epoch: 2/2, step 14993/16670 completed (loss: 0.09644827246665955, acc: 0.9727626442909241)
[2024-11-14 10:27:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:54][root][INFO] - Training Epoch: 2/2, step 14994/16670 completed (loss: 0.17662963271141052, acc: 0.9322034120559692)
[2024-11-14 10:27:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:55][root][INFO] - Training Epoch: 2/2, step 14995/16670 completed (loss: 0.1257033348083496, acc: 0.9629629850387573)
[2024-11-14 10:27:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:55][root][INFO] - Training Epoch: 2/2, step 14996/16670 completed (loss: 0.09659958630800247, acc: 0.9781022071838379)
[2024-11-14 10:27:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:55][root][INFO] - Training Epoch: 2/2, step 14997/16670 completed (loss: 0.05229455605149269, acc: 0.9816513657569885)
[2024-11-14 10:27:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:56][root][INFO] - Training Epoch: 2/2, step 14998/16670 completed (loss: 0.09985457360744476, acc: 0.9696969985961914)
[2024-11-14 10:27:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:56][root][INFO] - Training Epoch: 2/2, step 14999/16670 completed (loss: 0.45678403973579407, acc: 0.8548387289047241)
[2024-11-14 10:27:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:57][root][INFO] - Training Epoch: 2/2, step 15000/16670 completed (loss: 0.2752176523208618, acc: 0.9375)
[2024-11-14 10:27:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:57][root][INFO] - Training Epoch: 2/2, step 15001/16670 completed (loss: 0.10066430270671844, acc: 0.9612902998924255)
[2024-11-14 10:27:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:57][root][INFO] - Training Epoch: 2/2, step 15002/16670 completed (loss: 0.16142886877059937, acc: 0.95652174949646)
[2024-11-14 10:27:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:58][root][INFO] - Training Epoch: 2/2, step 15003/16670 completed (loss: 0.1351533681154251, acc: 0.9680851101875305)
[2024-11-14 10:27:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:58][root][INFO] - Training Epoch: 2/2, step 15004/16670 completed (loss: 0.029996907338500023, acc: 1.0)
[2024-11-14 10:27:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:58][root][INFO] - Training Epoch: 2/2, step 15005/16670 completed (loss: 0.08532673120498657, acc: 0.9652777910232544)
[2024-11-14 10:27:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:59][root][INFO] - Training Epoch: 2/2, step 15006/16670 completed (loss: 0.2152004987001419, acc: 0.9572649598121643)
[2024-11-14 10:27:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:59][root][INFO] - Training Epoch: 2/2, step 15007/16670 completed (loss: 0.2851584553718567, acc: 0.932692289352417)
[2024-11-14 10:27:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:27:59][root][INFO] - Training Epoch: 2/2, step 15008/16670 completed (loss: 0.16321350634098053, acc: 0.9652777910232544)
[2024-11-14 10:28:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:00][root][INFO] - Training Epoch: 2/2, step 15009/16670 completed (loss: 0.12407776713371277, acc: 0.966292142868042)
[2024-11-14 10:28:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:00][root][INFO] - Training Epoch: 2/2, step 15010/16670 completed (loss: 0.18224410712718964, acc: 0.9617224931716919)
[2024-11-14 10:28:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:00][root][INFO] - Training Epoch: 2/2, step 15011/16670 completed (loss: 0.14260108768939972, acc: 0.9395604133605957)
[2024-11-14 10:28:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:01][root][INFO] - Training Epoch: 2/2, step 15012/16670 completed (loss: 0.1322420835494995, acc: 0.9696969985961914)
[2024-11-14 10:28:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:01][root][INFO] - Training Epoch: 2/2, step 15013/16670 completed (loss: 0.33965152502059937, acc: 0.9142857193946838)
[2024-11-14 10:28:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:01][root][INFO] - Training Epoch: 2/2, step 15014/16670 completed (loss: 0.1328655630350113, acc: 0.9640287756919861)
[2024-11-14 10:28:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:02][root][INFO] - Training Epoch: 2/2, step 15015/16670 completed (loss: 0.2144487053155899, acc: 0.9290780425071716)
[2024-11-14 10:28:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:02][root][INFO] - Training Epoch: 2/2, step 15016/16670 completed (loss: 0.29540446400642395, acc: 0.9347826242446899)
[2024-11-14 10:28:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:02][root][INFO] - Training Epoch: 2/2, step 15017/16670 completed (loss: 0.12542493641376495, acc: 0.9679999947547913)
[2024-11-14 10:28:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:02][root][INFO] - Training Epoch: 2/2, step 15018/16670 completed (loss: 0.2780793011188507, acc: 0.9226519465446472)
[2024-11-14 10:28:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:03][root][INFO] - Training Epoch: 2/2, step 15019/16670 completed (loss: 0.34026482701301575, acc: 0.907216489315033)
[2024-11-14 10:28:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:03][root][INFO] - Training Epoch: 2/2, step 15020/16670 completed (loss: 0.20453976094722748, acc: 0.9254658222198486)
[2024-11-14 10:28:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:03][root][INFO] - Training Epoch: 2/2, step 15021/16670 completed (loss: 0.08811258524656296, acc: 0.9655172228813171)
[2024-11-14 10:28:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:04][root][INFO] - Training Epoch: 2/2, step 15022/16670 completed (loss: 0.13939175009727478, acc: 0.9638554453849792)
[2024-11-14 10:28:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:04][root][INFO] - Training Epoch: 2/2, step 15023/16670 completed (loss: 0.34198737144470215, acc: 0.9107142686843872)
[2024-11-14 10:28:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:04][root][INFO] - Training Epoch: 2/2, step 15024/16670 completed (loss: 0.4840945899486542, acc: 0.8901098966598511)
[2024-11-14 10:28:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:05][root][INFO] - Training Epoch: 2/2, step 15025/16670 completed (loss: 0.1418638676404953, acc: 0.9590163826942444)
[2024-11-14 10:28:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:05][root][INFO] - Training Epoch: 2/2, step 15026/16670 completed (loss: 0.039974410086870193, acc: 0.9905213117599487)
[2024-11-14 10:28:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:05][root][INFO] - Training Epoch: 2/2, step 15027/16670 completed (loss: 0.3443145453929901, acc: 0.9157894849777222)
[2024-11-14 10:28:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:06][root][INFO] - Training Epoch: 2/2, step 15028/16670 completed (loss: 0.09003008157014847, acc: 0.976047933101654)
[2024-11-14 10:28:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:06][root][INFO] - Training Epoch: 2/2, step 15029/16670 completed (loss: 0.11860178411006927, acc: 0.9679144620895386)
[2024-11-14 10:28:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:06][root][INFO] - Training Epoch: 2/2, step 15030/16670 completed (loss: 0.16559533774852753, acc: 0.9444444179534912)
[2024-11-14 10:28:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:07][root][INFO] - Training Epoch: 2/2, step 15031/16670 completed (loss: 0.08094790577888489, acc: 0.9623655676841736)
[2024-11-14 10:28:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:07][root][INFO] - Training Epoch: 2/2, step 15032/16670 completed (loss: 0.2596454918384552, acc: 0.9444444179534912)
[2024-11-14 10:28:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:07][root][INFO] - Training Epoch: 2/2, step 15033/16670 completed (loss: 0.13840997219085693, acc: 0.9647058844566345)
[2024-11-14 10:28:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:08][root][INFO] - Training Epoch: 2/2, step 15034/16670 completed (loss: 0.19284501671791077, acc: 0.936170220375061)
[2024-11-14 10:28:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:08][root][INFO] - Training Epoch: 2/2, step 15035/16670 completed (loss: 0.03247912600636482, acc: 1.0)
[2024-11-14 10:28:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:09][root][INFO] - Training Epoch: 2/2, step 15036/16670 completed (loss: 0.12109959125518799, acc: 0.9587156176567078)
[2024-11-14 10:28:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:09][root][INFO] - Training Epoch: 2/2, step 15037/16670 completed (loss: 0.10286644846200943, acc: 0.9694656729698181)
[2024-11-14 10:28:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:09][root][INFO] - Training Epoch: 2/2, step 15038/16670 completed (loss: 0.1948235034942627, acc: 0.9621848464012146)
[2024-11-14 10:28:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:10][root][INFO] - Training Epoch: 2/2, step 15039/16670 completed (loss: 0.06713990122079849, acc: 0.9825581312179565)
[2024-11-14 10:28:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:10][root][INFO] - Training Epoch: 2/2, step 15040/16670 completed (loss: 0.1265106499195099, acc: 0.9587156176567078)
[2024-11-14 10:28:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:10][root][INFO] - Training Epoch: 2/2, step 15041/16670 completed (loss: 0.08878342062234879, acc: 0.9743589758872986)
[2024-11-14 10:28:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:11][root][INFO] - Training Epoch: 2/2, step 15042/16670 completed (loss: 0.12650366127490997, acc: 0.9708737730979919)
[2024-11-14 10:28:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:11][root][INFO] - Training Epoch: 2/2, step 15043/16670 completed (loss: 0.10375244915485382, acc: 0.9550561904907227)
[2024-11-14 10:28:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:11][root][INFO] - Training Epoch: 2/2, step 15044/16670 completed (loss: 0.1567961871623993, acc: 0.9495798349380493)
[2024-11-14 10:28:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:12][root][INFO] - Training Epoch: 2/2, step 15045/16670 completed (loss: 0.15933342278003693, acc: 0.9523809552192688)
[2024-11-14 10:28:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:12][root][INFO] - Training Epoch: 2/2, step 15046/16670 completed (loss: 0.15778902173042297, acc: 0.9465020298957825)
[2024-11-14 10:28:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:12][root][INFO] - Training Epoch: 2/2, step 15047/16670 completed (loss: 0.15394821763038635, acc: 0.9568965435028076)
[2024-11-14 10:28:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:13][root][INFO] - Training Epoch: 2/2, step 15048/16670 completed (loss: 0.06879166513681412, acc: 0.9742646813392639)
[2024-11-14 10:28:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:13][root][INFO] - Training Epoch: 2/2, step 15049/16670 completed (loss: 0.10996794700622559, acc: 0.969348669052124)
[2024-11-14 10:28:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:13][root][INFO] - Training Epoch: 2/2, step 15050/16670 completed (loss: 0.2864018976688385, acc: 0.9320755004882812)
[2024-11-14 10:28:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:14][root][INFO] - Training Epoch: 2/2, step 15051/16670 completed (loss: 0.22867044806480408, acc: 0.9375)
[2024-11-14 10:28:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:14][root][INFO] - Training Epoch: 2/2, step 15052/16670 completed (loss: 0.13845232129096985, acc: 0.9541284441947937)
[2024-11-14 10:28:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:14][root][INFO] - Training Epoch: 2/2, step 15053/16670 completed (loss: 0.06855808943510056, acc: 0.9916666746139526)
[2024-11-14 10:28:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:15][root][INFO] - Training Epoch: 2/2, step 15054/16670 completed (loss: 0.13538330793380737, acc: 0.9727272987365723)
[2024-11-14 10:28:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:15][root][INFO] - Training Epoch: 2/2, step 15055/16670 completed (loss: 0.23627053201198578, acc: 0.9426229596138)
[2024-11-14 10:28:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:15][root][INFO] - Training Epoch: 2/2, step 15056/16670 completed (loss: 0.10780870169401169, acc: 0.9615384340286255)
[2024-11-14 10:28:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:16][root][INFO] - Training Epoch: 2/2, step 15057/16670 completed (loss: 0.13010959327220917, acc: 0.9595588445663452)
[2024-11-14 10:28:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:16][root][INFO] - Training Epoch: 2/2, step 15058/16670 completed (loss: 0.07329917699098587, acc: 0.977477490901947)
[2024-11-14 10:28:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:16][root][INFO] - Training Epoch: 2/2, step 15059/16670 completed (loss: 0.10307963192462921, acc: 0.9749103784561157)
[2024-11-14 10:28:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:16][root][INFO] - Training Epoch: 2/2, step 15060/16670 completed (loss: 0.09024275839328766, acc: 0.9743589758872986)
[2024-11-14 10:28:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:17][root][INFO] - Training Epoch: 2/2, step 15061/16670 completed (loss: 0.17401929199695587, acc: 0.9556962251663208)
[2024-11-14 10:28:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:17][root][INFO] - Training Epoch: 2/2, step 15062/16670 completed (loss: 0.08823418617248535, acc: 0.981566846370697)
[2024-11-14 10:28:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:17][root][INFO] - Training Epoch: 2/2, step 15063/16670 completed (loss: 0.14281053841114044, acc: 0.9648648500442505)
[2024-11-14 10:28:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:18][root][INFO] - Training Epoch: 2/2, step 15064/16670 completed (loss: 0.07706381380558014, acc: 0.9724137783050537)
[2024-11-14 10:28:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:18][root][INFO] - Training Epoch: 2/2, step 15065/16670 completed (loss: 0.15785598754882812, acc: 0.9664804339408875)
[2024-11-14 10:28:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:18][root][INFO] - Training Epoch: 2/2, step 15066/16670 completed (loss: 0.253023236989975, acc: 0.9318181872367859)
[2024-11-14 10:28:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:19][root][INFO] - Training Epoch: 2/2, step 15067/16670 completed (loss: 0.23627114295959473, acc: 0.9190751314163208)
[2024-11-14 10:28:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:19][root][INFO] - Training Epoch: 2/2, step 15068/16670 completed (loss: 0.0233638733625412, acc: 0.9935275316238403)
[2024-11-14 10:28:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:19][root][INFO] - Training Epoch: 2/2, step 15069/16670 completed (loss: 0.08942297846078873, acc: 0.9764150977134705)
[2024-11-14 10:28:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:20][root][INFO] - Training Epoch: 2/2, step 15070/16670 completed (loss: 0.08402074873447418, acc: 0.9737991094589233)
[2024-11-14 10:28:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:20][root][INFO] - Training Epoch: 2/2, step 15071/16670 completed (loss: 0.06851880997419357, acc: 0.9862385392189026)
[2024-11-14 10:28:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:20][root][INFO] - Training Epoch: 2/2, step 15072/16670 completed (loss: 0.10103051364421844, acc: 0.9740259647369385)
[2024-11-14 10:28:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:21][root][INFO] - Training Epoch: 2/2, step 15073/16670 completed (loss: 0.078202985227108, acc: 0.984000027179718)
[2024-11-14 10:28:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:21][root][INFO] - Training Epoch: 2/2, step 15074/16670 completed (loss: 0.1443212479352951, acc: 0.9719626307487488)
[2024-11-14 10:28:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:21][root][INFO] - Training Epoch: 2/2, step 15075/16670 completed (loss: 0.19605588912963867, acc: 0.945652186870575)
[2024-11-14 10:28:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:22][root][INFO] - Training Epoch: 2/2, step 15076/16670 completed (loss: 0.13856351375579834, acc: 0.9543147087097168)
[2024-11-14 10:28:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:22][root][INFO] - Training Epoch: 2/2, step 15077/16670 completed (loss: 0.1078946590423584, acc: 0.9630681872367859)
[2024-11-14 10:28:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:22][root][INFO] - Training Epoch: 2/2, step 15078/16670 completed (loss: 0.04926038533449173, acc: 0.9838709831237793)
[2024-11-14 10:28:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:23][root][INFO] - Training Epoch: 2/2, step 15079/16670 completed (loss: 0.06608738750219345, acc: 0.9840637445449829)
[2024-11-14 10:28:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:23][root][INFO] - Training Epoch: 2/2, step 15080/16670 completed (loss: 0.3205631971359253, acc: 0.9060773253440857)
[2024-11-14 10:28:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:23][root][INFO] - Training Epoch: 2/2, step 15081/16670 completed (loss: 0.13568490743637085, acc: 0.9560810923576355)
[2024-11-14 10:28:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:23][root][INFO] - Training Epoch: 2/2, step 15082/16670 completed (loss: 0.06999092549085617, acc: 0.9680851101875305)
[2024-11-14 10:28:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:24][root][INFO] - Training Epoch: 2/2, step 15083/16670 completed (loss: 0.08426347374916077, acc: 0.9770773649215698)
[2024-11-14 10:28:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:24][root][INFO] - Training Epoch: 2/2, step 15084/16670 completed (loss: 0.06817205995321274, acc: 0.9743589758872986)
[2024-11-14 10:28:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:24][root][INFO] - Training Epoch: 2/2, step 15085/16670 completed (loss: 0.07829225808382034, acc: 0.9774436354637146)
[2024-11-14 10:28:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:25][root][INFO] - Training Epoch: 2/2, step 15086/16670 completed (loss: 0.20027217268943787, acc: 0.931034505367279)
[2024-11-14 10:28:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:25][root][INFO] - Training Epoch: 2/2, step 15087/16670 completed (loss: 0.39092615246772766, acc: 0.875)
[2024-11-14 10:28:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:25][root][INFO] - Training Epoch: 2/2, step 15088/16670 completed (loss: 0.22111506760120392, acc: 0.9210526347160339)
[2024-11-14 10:28:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:26][root][INFO] - Training Epoch: 2/2, step 15089/16670 completed (loss: 0.7518848180770874, acc: 0.791208803653717)
[2024-11-14 10:28:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:26][root][INFO] - Training Epoch: 2/2, step 15090/16670 completed (loss: 0.3681992292404175, acc: 0.8709677457809448)
[2024-11-14 10:28:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:26][root][INFO] - Training Epoch: 2/2, step 15091/16670 completed (loss: 0.6435890197753906, acc: 0.8452380895614624)
[2024-11-14 10:28:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:27][root][INFO] - Training Epoch: 2/2, step 15092/16670 completed (loss: 0.35347750782966614, acc: 0.9111111164093018)
[2024-11-14 10:28:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:27][root][INFO] - Training Epoch: 2/2, step 15093/16670 completed (loss: 0.37867796421051025, acc: 0.9215686321258545)
[2024-11-14 10:28:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:27][root][INFO] - Training Epoch: 2/2, step 15094/16670 completed (loss: 0.45174044370651245, acc: 0.929411768913269)
[2024-11-14 10:28:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:28][root][INFO] - Training Epoch: 2/2, step 15095/16670 completed (loss: 0.3193883001804352, acc: 0.9268292784690857)
[2024-11-14 10:28:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:28][root][INFO] - Training Epoch: 2/2, step 15096/16670 completed (loss: 0.12285809218883514, acc: 0.9666666388511658)
[2024-11-14 10:28:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:28][root][INFO] - Training Epoch: 2/2, step 15097/16670 completed (loss: 0.06715475767850876, acc: 0.9814814925193787)
[2024-11-14 10:28:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:29][root][INFO] - Training Epoch: 2/2, step 15098/16670 completed (loss: 0.08702388405799866, acc: 0.9824561476707458)
[2024-11-14 10:28:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:29][root][INFO] - Training Epoch: 2/2, step 15099/16670 completed (loss: 0.17481260001659393, acc: 0.9629629850387573)
[2024-11-14 10:28:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:29][root][INFO] - Training Epoch: 2/2, step 15100/16670 completed (loss: 0.2432788759469986, acc: 0.9487179517745972)
[2024-11-14 10:28:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:29][root][INFO] - Training Epoch: 2/2, step 15101/16670 completed (loss: 0.3800830543041229, acc: 0.9285714030265808)
[2024-11-14 10:28:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:30][root][INFO] - Training Epoch: 2/2, step 15102/16670 completed (loss: 0.1577715277671814, acc: 0.9722222089767456)
[2024-11-14 10:28:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:30][root][INFO] - Training Epoch: 2/2, step 15103/16670 completed (loss: 0.19624687731266022, acc: 0.9454545378684998)
[2024-11-14 10:28:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:30][root][INFO] - Training Epoch: 2/2, step 15104/16670 completed (loss: 0.4028073251247406, acc: 0.914893627166748)
[2024-11-14 10:28:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:31][root][INFO] - Training Epoch: 2/2, step 15105/16670 completed (loss: 0.43224191665649414, acc: 0.9464285969734192)
[2024-11-14 10:28:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:31][root][INFO] - Training Epoch: 2/2, step 15106/16670 completed (loss: 0.33805331587791443, acc: 0.8125)
[2024-11-14 10:28:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:32][root][INFO] - Training Epoch: 2/2, step 15107/16670 completed (loss: 0.009854351170361042, acc: 1.0)
[2024-11-14 10:28:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:32][root][INFO] - Training Epoch: 2/2, step 15108/16670 completed (loss: 0.30984583497047424, acc: 0.949367105960846)
[2024-11-14 10:28:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:32][root][INFO] - Training Epoch: 2/2, step 15109/16670 completed (loss: 0.15972208976745605, acc: 0.948051929473877)
[2024-11-14 10:28:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:33][root][INFO] - Training Epoch: 2/2, step 15110/16670 completed (loss: 0.7091947197914124, acc: 0.875)
[2024-11-14 10:28:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:33][root][INFO] - Training Epoch: 2/2, step 15111/16670 completed (loss: 0.17948168516159058, acc: 0.9569892287254333)
[2024-11-14 10:28:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:33][root][INFO] - Training Epoch: 2/2, step 15112/16670 completed (loss: 0.552541196346283, acc: 0.8333333134651184)
[2024-11-14 10:28:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:34][root][INFO] - Training Epoch: 2/2, step 15113/16670 completed (loss: 0.14040492475032806, acc: 0.9599999785423279)
[2024-11-14 10:28:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:34][root][INFO] - Training Epoch: 2/2, step 15114/16670 completed (loss: 0.3213426470756531, acc: 0.9487179517745972)
[2024-11-14 10:28:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:34][root][INFO] - Training Epoch: 2/2, step 15115/16670 completed (loss: 0.42636218667030334, acc: 0.9411764740943909)
[2024-11-14 10:28:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:35][root][INFO] - Training Epoch: 2/2, step 15116/16670 completed (loss: 0.2694101333618164, acc: 0.939393937587738)
[2024-11-14 10:28:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:35][root][INFO] - Training Epoch: 2/2, step 15117/16670 completed (loss: 0.34891489148139954, acc: 0.9032257795333862)
[2024-11-14 10:28:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:35][root][INFO] - Training Epoch: 2/2, step 15118/16670 completed (loss: 0.27472153306007385, acc: 0.9629629850387573)
[2024-11-14 10:28:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:36][root][INFO] - Training Epoch: 2/2, step 15119/16670 completed (loss: 0.30155640840530396, acc: 0.9473684430122375)
[2024-11-14 10:28:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:36][root][INFO] - Training Epoch: 2/2, step 15120/16670 completed (loss: 0.3432450294494629, acc: 0.9523809552192688)
[2024-11-14 10:28:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:37][root][INFO] - Training Epoch: 2/2, step 15121/16670 completed (loss: 0.8904442191123962, acc: 0.800000011920929)
[2024-11-14 10:28:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:37][root][INFO] - Training Epoch: 2/2, step 15122/16670 completed (loss: 0.526563823223114, acc: 0.8793103694915771)
[2024-11-14 10:28:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:37][root][INFO] - Training Epoch: 2/2, step 15123/16670 completed (loss: 0.10903456062078476, acc: 0.9803921580314636)
[2024-11-14 10:28:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:37][root][INFO] - Training Epoch: 2/2, step 15124/16670 completed (loss: 0.4540989100933075, acc: 0.9027777910232544)
[2024-11-14 10:28:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:38][root][INFO] - Training Epoch: 2/2, step 15125/16670 completed (loss: 0.1532735526561737, acc: 0.9610389471054077)
[2024-11-14 10:28:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:38][root][INFO] - Training Epoch: 2/2, step 15126/16670 completed (loss: 0.1282498687505722, acc: 0.9615384340286255)
[2024-11-14 10:28:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:39][root][INFO] - Training Epoch: 2/2, step 15127/16670 completed (loss: 0.335883766412735, acc: 0.9137930870056152)
[2024-11-14 10:28:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:39][root][INFO] - Training Epoch: 2/2, step 15128/16670 completed (loss: 0.26412785053253174, acc: 0.9591836929321289)
[2024-11-14 10:28:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:39][root][INFO] - Training Epoch: 2/2, step 15129/16670 completed (loss: 0.4694470167160034, acc: 0.8780487775802612)
[2024-11-14 10:28:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:40][root][INFO] - Training Epoch: 2/2, step 15130/16670 completed (loss: 0.07653582096099854, acc: 1.0)
[2024-11-14 10:28:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:40][root][INFO] - Training Epoch: 2/2, step 15131/16670 completed (loss: 0.398452490568161, acc: 0.90625)
[2024-11-14 10:28:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:40][root][INFO] - Training Epoch: 2/2, step 15132/16670 completed (loss: 0.32467103004455566, acc: 0.9275362491607666)
[2024-11-14 10:28:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:41][root][INFO] - Training Epoch: 2/2, step 15133/16670 completed (loss: 0.4616656005382538, acc: 0.9298245906829834)
[2024-11-14 10:28:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:41][root][INFO] - Training Epoch: 2/2, step 15134/16670 completed (loss: 0.4643041789531708, acc: 0.8936170339584351)
[2024-11-14 10:28:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:41][root][INFO] - Training Epoch: 2/2, step 15135/16670 completed (loss: 1.2770439386367798, acc: 0.7857142686843872)
[2024-11-14 10:28:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:42][root][INFO] - Training Epoch: 2/2, step 15136/16670 completed (loss: 0.14979521930217743, acc: 0.9666666388511658)
[2024-11-14 10:28:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:42][root][INFO] - Training Epoch: 2/2, step 15137/16670 completed (loss: 0.8182758688926697, acc: 0.8181818127632141)
[2024-11-14 10:28:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:42][root][INFO] - Training Epoch: 2/2, step 15138/16670 completed (loss: 0.38835352659225464, acc: 0.875)
[2024-11-14 10:28:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:43][root][INFO] - Training Epoch: 2/2, step 15139/16670 completed (loss: 0.2711610198020935, acc: 0.925000011920929)
[2024-11-14 10:28:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:43][root][INFO] - Training Epoch: 2/2, step 15140/16670 completed (loss: 0.4278375208377838, acc: 0.8873239159584045)
[2024-11-14 10:28:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:44][root][INFO] - Training Epoch: 2/2, step 15141/16670 completed (loss: 0.568356990814209, acc: 0.8235294222831726)
[2024-11-14 10:28:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:44][root][INFO] - Training Epoch: 2/2, step 15142/16670 completed (loss: 0.2655274271965027, acc: 0.9811320900917053)
[2024-11-14 10:28:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:44][root][INFO] - Training Epoch: 2/2, step 15143/16670 completed (loss: 0.3531414270401001, acc: 0.9210526347160339)
[2024-11-14 10:28:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:44][root][INFO] - Training Epoch: 2/2, step 15144/16670 completed (loss: 0.3550655245780945, acc: 0.936170220375061)
[2024-11-14 10:28:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:45][root][INFO] - Training Epoch: 2/2, step 15145/16670 completed (loss: 0.5598345994949341, acc: 0.8333333134651184)
[2024-11-14 10:28:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:45][root][INFO] - Training Epoch: 2/2, step 15146/16670 completed (loss: 0.1687754988670349, acc: 0.9491525292396545)
[2024-11-14 10:28:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:46][root][INFO] - Training Epoch: 2/2, step 15147/16670 completed (loss: 0.19760960340499878, acc: 0.9589040875434875)
[2024-11-14 10:28:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:46][root][INFO] - Training Epoch: 2/2, step 15148/16670 completed (loss: 0.25218790769577026, acc: 0.9384615421295166)
[2024-11-14 10:28:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:46][root][INFO] - Training Epoch: 2/2, step 15149/16670 completed (loss: 0.35150426626205444, acc: 0.9272727370262146)
[2024-11-14 10:28:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:47][root][INFO] - Training Epoch: 2/2, step 15150/16670 completed (loss: 0.4857836067676544, acc: 0.8969072103500366)
[2024-11-14 10:28:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:47][root][INFO] - Training Epoch: 2/2, step 15151/16670 completed (loss: 0.6680160760879517, acc: 0.8780487775802612)
[2024-11-14 10:28:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:47][root][INFO] - Training Epoch: 2/2, step 15152/16670 completed (loss: 0.1050821915268898, acc: 1.0)
[2024-11-14 10:28:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:48][root][INFO] - Training Epoch: 2/2, step 15153/16670 completed (loss: 0.4532966613769531, acc: 0.8965517282485962)
[2024-11-14 10:28:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:48][root][INFO] - Training Epoch: 2/2, step 15154/16670 completed (loss: 0.1815205067396164, acc: 0.9473684430122375)
[2024-11-14 10:28:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:48][root][INFO] - Training Epoch: 2/2, step 15155/16670 completed (loss: 0.3239944577217102, acc: 0.9399999976158142)
[2024-11-14 10:28:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:49][root][INFO] - Training Epoch: 2/2, step 15156/16670 completed (loss: 0.42122939229011536, acc: 0.8714285492897034)
[2024-11-14 10:28:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:49][root][INFO] - Training Epoch: 2/2, step 15157/16670 completed (loss: 0.26583749055862427, acc: 0.9200000166893005)
[2024-11-14 10:28:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:49][root][INFO] - Training Epoch: 2/2, step 15158/16670 completed (loss: 0.5491652488708496, acc: 0.8850574493408203)
[2024-11-14 10:28:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:50][root][INFO] - Training Epoch: 2/2, step 15159/16670 completed (loss: 0.1776229292154312, acc: 0.9605262875556946)
[2024-11-14 10:28:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:50][root][INFO] - Training Epoch: 2/2, step 15160/16670 completed (loss: 0.32795825600624084, acc: 0.9178082346916199)
[2024-11-14 10:28:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:50][root][INFO] - Training Epoch: 2/2, step 15161/16670 completed (loss: 0.23749381303787231, acc: 0.9444444179534912)
[2024-11-14 10:28:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:51][root][INFO] - Training Epoch: 2/2, step 15162/16670 completed (loss: 0.4290904998779297, acc: 0.8999999761581421)
[2024-11-14 10:28:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:51][root][INFO] - Training Epoch: 2/2, step 15163/16670 completed (loss: 0.132469043135643, acc: 0.9655172228813171)
[2024-11-14 10:28:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:52][root][INFO] - Training Epoch: 2/2, step 15164/16670 completed (loss: 0.4450075626373291, acc: 0.8999999761581421)
[2024-11-14 10:28:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:52][root][INFO] - Training Epoch: 2/2, step 15165/16670 completed (loss: 0.0341530442237854, acc: 1.0)
[2024-11-14 10:28:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:52][root][INFO] - Training Epoch: 2/2, step 15166/16670 completed (loss: 0.2841361463069916, acc: 0.9333333373069763)
[2024-11-14 10:28:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:53][root][INFO] - Training Epoch: 2/2, step 15167/16670 completed (loss: 0.41136717796325684, acc: 0.8791208863258362)
[2024-11-14 10:28:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:53][root][INFO] - Training Epoch: 2/2, step 15168/16670 completed (loss: 0.6246508955955505, acc: 0.8703703880310059)
[2024-11-14 10:28:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:53][root][INFO] - Training Epoch: 2/2, step 15169/16670 completed (loss: 0.5470729470252991, acc: 0.9032257795333862)
[2024-11-14 10:28:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:54][root][INFO] - Training Epoch: 2/2, step 15170/16670 completed (loss: 0.43856513500213623, acc: 0.8235294222831726)
[2024-11-14 10:28:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:54][root][INFO] - Training Epoch: 2/2, step 15171/16670 completed (loss: 0.5036458373069763, acc: 0.8888888955116272)
[2024-11-14 10:28:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:54][root][INFO] - Training Epoch: 2/2, step 15172/16670 completed (loss: 0.3580690622329712, acc: 0.8727272748947144)
[2024-11-14 10:28:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:55][root][INFO] - Training Epoch: 2/2, step 15173/16670 completed (loss: 0.49707940220832825, acc: 0.8684210777282715)
[2024-11-14 10:28:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:55][root][INFO] - Training Epoch: 2/2, step 15174/16670 completed (loss: 0.13855451345443726, acc: 0.949999988079071)
[2024-11-14 10:28:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:55][root][INFO] - Training Epoch: 2/2, step 15175/16670 completed (loss: 0.8726577162742615, acc: 0.804347813129425)
[2024-11-14 10:28:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:56][root][INFO] - Training Epoch: 2/2, step 15176/16670 completed (loss: 0.21117372810840607, acc: 0.9056603908538818)
[2024-11-14 10:28:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:56][root][INFO] - Training Epoch: 2/2, step 15177/16670 completed (loss: 0.48915985226631165, acc: 0.8863636255264282)
[2024-11-14 10:28:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:56][root][INFO] - Training Epoch: 2/2, step 15178/16670 completed (loss: 0.025239156559109688, acc: 1.0)
[2024-11-14 10:28:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:57][root][INFO] - Training Epoch: 2/2, step 15179/16670 completed (loss: 0.15190176665782928, acc: 0.9736841917037964)
[2024-11-14 10:28:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:57][root][INFO] - Training Epoch: 2/2, step 15180/16670 completed (loss: 0.20573221147060394, acc: 0.9473684430122375)
[2024-11-14 10:28:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:57][root][INFO] - Training Epoch: 2/2, step 15181/16670 completed (loss: 0.15553534030914307, acc: 0.96875)
[2024-11-14 10:28:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:58][root][INFO] - Training Epoch: 2/2, step 15182/16670 completed (loss: 0.21077625453472137, acc: 0.9285714030265808)
[2024-11-14 10:28:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:58][root][INFO] - Training Epoch: 2/2, step 15183/16670 completed (loss: 0.2524946331977844, acc: 0.9275362491607666)
[2024-11-14 10:28:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:58][root][INFO] - Training Epoch: 2/2, step 15184/16670 completed (loss: 0.488444060087204, acc: 0.9111111164093018)
[2024-11-14 10:28:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:59][root][INFO] - Training Epoch: 2/2, step 15185/16670 completed (loss: 0.24663156270980835, acc: 0.9482758641242981)
[2024-11-14 10:28:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:59][root][INFO] - Training Epoch: 2/2, step 15186/16670 completed (loss: 0.3550143539905548, acc: 0.8703703880310059)
[2024-11-14 10:28:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:59][root][INFO] - Training Epoch: 2/2, step 15187/16670 completed (loss: 0.24967075884342194, acc: 0.9347826242446899)
[2024-11-14 10:28:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:28:59][root][INFO] - Training Epoch: 2/2, step 15188/16670 completed (loss: 0.10179959237575531, acc: 0.9512194991111755)
[2024-11-14 10:29:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:00][root][INFO] - Training Epoch: 2/2, step 15189/16670 completed (loss: 0.4586147964000702, acc: 0.8275862336158752)
[2024-11-14 10:29:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:00][root][INFO] - Training Epoch: 2/2, step 15190/16670 completed (loss: 0.46109408140182495, acc: 0.9166666865348816)
[2024-11-14 10:29:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:01][root][INFO] - Training Epoch: 2/2, step 15191/16670 completed (loss: 0.5063984394073486, acc: 0.8723404407501221)
[2024-11-14 10:29:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:01][root][INFO] - Training Epoch: 2/2, step 15192/16670 completed (loss: 0.5196909308433533, acc: 0.90625)
[2024-11-14 10:29:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:01][root][INFO] - Training Epoch: 2/2, step 15193/16670 completed (loss: 0.3090096116065979, acc: 0.9354838728904724)
[2024-11-14 10:29:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:02][root][INFO] - Training Epoch: 2/2, step 15194/16670 completed (loss: 0.15791788697242737, acc: 0.9333333373069763)
[2024-11-14 10:29:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:02][root][INFO] - Training Epoch: 2/2, step 15195/16670 completed (loss: 0.1836005002260208, acc: 0.9487179517745972)
[2024-11-14 10:29:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:02][root][INFO] - Training Epoch: 2/2, step 15196/16670 completed (loss: 0.4449649453163147, acc: 0.8939393758773804)
[2024-11-14 10:29:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:03][root][INFO] - Training Epoch: 2/2, step 15197/16670 completed (loss: 0.5152004957199097, acc: 0.8795180916786194)
[2024-11-14 10:29:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:03][root][INFO] - Training Epoch: 2/2, step 15198/16670 completed (loss: 0.4015786349773407, acc: 0.9210526347160339)
[2024-11-14 10:29:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:03][root][INFO] - Training Epoch: 2/2, step 15199/16670 completed (loss: 0.8233798146247864, acc: 0.8541666865348816)
[2024-11-14 10:29:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:04][root][INFO] - Training Epoch: 2/2, step 15200/16670 completed (loss: 0.057958297431468964, acc: 1.0)
[2024-11-14 10:29:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:04][root][INFO] - Training Epoch: 2/2, step 15201/16670 completed (loss: 0.4863918125629425, acc: 0.8974359035491943)
[2024-11-14 10:29:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:04][root][INFO] - Training Epoch: 2/2, step 15202/16670 completed (loss: 0.16734285652637482, acc: 0.9324324131011963)
[2024-11-14 10:29:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:05][root][INFO] - Training Epoch: 2/2, step 15203/16670 completed (loss: 0.1815478503704071, acc: 0.9347826242446899)
[2024-11-14 10:29:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:05][root][INFO] - Training Epoch: 2/2, step 15204/16670 completed (loss: 0.34035828709602356, acc: 0.8999999761581421)
[2024-11-14 10:29:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:05][root][INFO] - Training Epoch: 2/2, step 15205/16670 completed (loss: 0.11925065517425537, acc: 0.9607843160629272)
[2024-11-14 10:29:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:06][root][INFO] - Training Epoch: 2/2, step 15206/16670 completed (loss: 0.40121331810951233, acc: 0.8999999761581421)
[2024-11-14 10:29:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:06][root][INFO] - Training Epoch: 2/2, step 15207/16670 completed (loss: 0.2915528416633606, acc: 0.9066666960716248)
[2024-11-14 10:29:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:06][root][INFO] - Training Epoch: 2/2, step 15208/16670 completed (loss: 0.03312480449676514, acc: 1.0)
[2024-11-14 10:29:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:07][root][INFO] - Training Epoch: 2/2, step 15209/16670 completed (loss: 0.29171687364578247, acc: 0.9157894849777222)
[2024-11-14 10:29:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:07][root][INFO] - Training Epoch: 2/2, step 15210/16670 completed (loss: 0.30284345149993896, acc: 0.8936170339584351)
[2024-11-14 10:29:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:07][root][INFO] - Training Epoch: 2/2, step 15211/16670 completed (loss: 0.4099661111831665, acc: 0.9375)
[2024-11-14 10:29:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:08][root][INFO] - Training Epoch: 2/2, step 15212/16670 completed (loss: 0.4094191789627075, acc: 0.8767123222351074)
[2024-11-14 10:29:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:08][root][INFO] - Training Epoch: 2/2, step 15213/16670 completed (loss: 0.1335076242685318, acc: 0.9729729890823364)
[2024-11-14 10:29:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:09][root][INFO] - Training Epoch: 2/2, step 15214/16670 completed (loss: 0.43026143312454224, acc: 0.9444444179534912)
[2024-11-14 10:29:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:09][root][INFO] - Training Epoch: 2/2, step 15215/16670 completed (loss: 0.18596789240837097, acc: 0.970588207244873)
[2024-11-14 10:29:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:09][root][INFO] - Training Epoch: 2/2, step 15216/16670 completed (loss: 0.25890710949897766, acc: 0.9428571462631226)
[2024-11-14 10:29:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:10][root][INFO] - Training Epoch: 2/2, step 15217/16670 completed (loss: 0.5601540207862854, acc: 0.8867924809455872)
[2024-11-14 10:29:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:10][root][INFO] - Training Epoch: 2/2, step 15218/16670 completed (loss: 0.2703944444656372, acc: 0.9365079402923584)
[2024-11-14 10:29:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:10][root][INFO] - Training Epoch: 2/2, step 15219/16670 completed (loss: 0.17280809581279755, acc: 0.8947368264198303)
[2024-11-14 10:29:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:11][root][INFO] - Training Epoch: 2/2, step 15220/16670 completed (loss: 0.9409219622612, acc: 0.8260869383811951)
[2024-11-14 10:29:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:11][root][INFO] - Training Epoch: 2/2, step 15221/16670 completed (loss: 0.3179299831390381, acc: 0.9285714030265808)
[2024-11-14 10:29:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:12][root][INFO] - Training Epoch: 2/2, step 15222/16670 completed (loss: 0.6232788562774658, acc: 0.8653846383094788)
[2024-11-14 10:29:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:12][root][INFO] - Training Epoch: 2/2, step 15223/16670 completed (loss: 0.2605888843536377, acc: 0.931034505367279)
[2024-11-14 10:29:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:12][root][INFO] - Training Epoch: 2/2, step 15224/16670 completed (loss: 0.3344937264919281, acc: 0.8297872543334961)
[2024-11-14 10:29:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:13][root][INFO] - Training Epoch: 2/2, step 15225/16670 completed (loss: 0.3598842918872833, acc: 0.9024389982223511)
[2024-11-14 10:29:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:13][root][INFO] - Training Epoch: 2/2, step 15226/16670 completed (loss: 0.6136351227760315, acc: 0.875)
[2024-11-14 10:29:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:13][root][INFO] - Training Epoch: 2/2, step 15227/16670 completed (loss: 0.12894636392593384, acc: 0.9661017060279846)
[2024-11-14 10:29:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:14][root][INFO] - Training Epoch: 2/2, step 15228/16670 completed (loss: 0.46418413519859314, acc: 0.9074074029922485)
[2024-11-14 10:29:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:14][root][INFO] - Training Epoch: 2/2, step 15229/16670 completed (loss: 0.6939161419868469, acc: 0.8529411554336548)
[2024-11-14 10:29:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:14][root][INFO] - Training Epoch: 2/2, step 15230/16670 completed (loss: 0.28877928853034973, acc: 0.925000011920929)
[2024-11-14 10:29:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:15][root][INFO] - Training Epoch: 2/2, step 15231/16670 completed (loss: 0.3231648802757263, acc: 0.939393937587738)
[2024-11-14 10:29:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:15][root][INFO] - Training Epoch: 2/2, step 15232/16670 completed (loss: 0.26625335216522217, acc: 0.921875)
[2024-11-14 10:29:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:15][root][INFO] - Training Epoch: 2/2, step 15233/16670 completed (loss: 0.3756283223628998, acc: 0.9180327653884888)
[2024-11-14 10:29:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:16][root][INFO] - Training Epoch: 2/2, step 15234/16670 completed (loss: 0.497483491897583, acc: 0.8965517282485962)
[2024-11-14 10:29:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:16][root][INFO] - Training Epoch: 2/2, step 15235/16670 completed (loss: 0.05251426622271538, acc: 0.9777777791023254)
[2024-11-14 10:29:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:16][root][INFO] - Training Epoch: 2/2, step 15236/16670 completed (loss: 0.24086838960647583, acc: 0.9454545378684998)
[2024-11-14 10:29:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:17][root][INFO] - Training Epoch: 2/2, step 15237/16670 completed (loss: 0.4985281229019165, acc: 0.8199999928474426)
[2024-11-14 10:29:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:17][root][INFO] - Training Epoch: 2/2, step 15238/16670 completed (loss: 0.3593612313270569, acc: 0.930232584476471)
[2024-11-14 10:29:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:17][root][INFO] - Training Epoch: 2/2, step 15239/16670 completed (loss: 0.7463427186012268, acc: 0.8181818127632141)
[2024-11-14 10:29:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:18][root][INFO] - Training Epoch: 2/2, step 15240/16670 completed (loss: 0.07935768365859985, acc: 0.9824561476707458)
[2024-11-14 10:29:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:18][root][INFO] - Training Epoch: 2/2, step 15241/16670 completed (loss: 0.3530251085758209, acc: 0.9245283007621765)
[2024-11-14 10:29:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:18][root][INFO] - Training Epoch: 2/2, step 15242/16670 completed (loss: 0.1088448092341423, acc: 0.9736841917037964)
[2024-11-14 10:29:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:19][root][INFO] - Training Epoch: 2/2, step 15243/16670 completed (loss: 0.2804766297340393, acc: 0.9399999976158142)
[2024-11-14 10:29:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:19][root][INFO] - Training Epoch: 2/2, step 15244/16670 completed (loss: 0.3656359612941742, acc: 0.8965517282485962)
[2024-11-14 10:29:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:19][root][INFO] - Training Epoch: 2/2, step 15245/16670 completed (loss: 0.3524185121059418, acc: 0.9322034120559692)
[2024-11-14 10:29:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:20][root][INFO] - Training Epoch: 2/2, step 15246/16670 completed (loss: 0.5877856612205505, acc: 0.9230769276618958)
[2024-11-14 10:29:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:20][root][INFO] - Training Epoch: 2/2, step 15247/16670 completed (loss: 0.462507963180542, acc: 0.8666666746139526)
[2024-11-14 10:29:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:20][root][INFO] - Training Epoch: 2/2, step 15248/16670 completed (loss: 0.02715235762298107, acc: 1.0)
[2024-11-14 10:29:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:21][root][INFO] - Training Epoch: 2/2, step 15249/16670 completed (loss: 0.38463813066482544, acc: 0.8999999761581421)
[2024-11-14 10:29:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:21][root][INFO] - Training Epoch: 2/2, step 15250/16670 completed (loss: 0.234017476439476, acc: 0.9375)
[2024-11-14 10:29:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:21][root][INFO] - Training Epoch: 2/2, step 15251/16670 completed (loss: 0.5725265741348267, acc: 0.8600000143051147)
[2024-11-14 10:29:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:22][root][INFO] - Training Epoch: 2/2, step 15252/16670 completed (loss: 0.41922345757484436, acc: 0.9107142686843872)
[2024-11-14 10:29:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:22][root][INFO] - Training Epoch: 2/2, step 15253/16670 completed (loss: 0.55654376745224, acc: 0.8297872543334961)
[2024-11-14 10:29:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:23][root][INFO] - Training Epoch: 2/2, step 15254/16670 completed (loss: 0.18268176913261414, acc: 0.9607843160629272)
[2024-11-14 10:29:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:23][root][INFO] - Training Epoch: 2/2, step 15255/16670 completed (loss: 1.1103403568267822, acc: 0.8064516186714172)
[2024-11-14 10:29:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:23][root][INFO] - Training Epoch: 2/2, step 15256/16670 completed (loss: 0.6655578017234802, acc: 0.8857142925262451)
[2024-11-14 10:29:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:24][root][INFO] - Training Epoch: 2/2, step 15257/16670 completed (loss: 0.22946345806121826, acc: 0.9473684430122375)
[2024-11-14 10:29:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:24][root][INFO] - Training Epoch: 2/2, step 15258/16670 completed (loss: 0.9459927678108215, acc: 0.8139534592628479)
[2024-11-14 10:29:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:24][root][INFO] - Training Epoch: 2/2, step 15259/16670 completed (loss: 0.5090669989585876, acc: 0.8799999952316284)
[2024-11-14 10:29:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:25][root][INFO] - Training Epoch: 2/2, step 15260/16670 completed (loss: 0.527627170085907, acc: 0.800000011920929)
[2024-11-14 10:29:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:25][root][INFO] - Training Epoch: 2/2, step 15261/16670 completed (loss: 0.41905221343040466, acc: 0.8793103694915771)
[2024-11-14 10:29:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:26][root][INFO] - Training Epoch: 2/2, step 15262/16670 completed (loss: 0.4526626169681549, acc: 0.8857142925262451)
[2024-11-14 10:29:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:26][root][INFO] - Training Epoch: 2/2, step 15263/16670 completed (loss: 0.08597985655069351, acc: 0.9807692170143127)
[2024-11-14 10:29:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:26][root][INFO] - Training Epoch: 2/2, step 15264/16670 completed (loss: 0.1397055685520172, acc: 0.9743589758872986)
[2024-11-14 10:29:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:27][root][INFO] - Training Epoch: 2/2, step 15265/16670 completed (loss: 0.4056653380393982, acc: 0.8666666746139526)
[2024-11-14 10:29:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:27][root][INFO] - Training Epoch: 2/2, step 15266/16670 completed (loss: 0.40367406606674194, acc: 0.8421052694320679)
[2024-11-14 10:29:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:27][root][INFO] - Training Epoch: 2/2, step 15267/16670 completed (loss: 0.2747558057308197, acc: 0.9117646813392639)
[2024-11-14 10:29:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:28][root][INFO] - Training Epoch: 2/2, step 15268/16670 completed (loss: 0.09626764804124832, acc: 0.9743589758872986)
[2024-11-14 10:29:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:28][root][INFO] - Training Epoch: 2/2, step 15269/16670 completed (loss: 0.27729693055152893, acc: 0.9333333373069763)
[2024-11-14 10:29:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:28][root][INFO] - Training Epoch: 2/2, step 15270/16670 completed (loss: 0.374449223279953, acc: 0.9166666865348816)
[2024-11-14 10:29:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:29][root][INFO] - Training Epoch: 2/2, step 15271/16670 completed (loss: 0.2895459234714508, acc: 0.9459459185600281)
[2024-11-14 10:29:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:29][root][INFO] - Training Epoch: 2/2, step 15272/16670 completed (loss: 0.7379506230354309, acc: 0.7878788113594055)
[2024-11-14 10:29:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:29][root][INFO] - Training Epoch: 2/2, step 15273/16670 completed (loss: 0.5766655802726746, acc: 0.8863636255264282)
[2024-11-14 10:29:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:30][root][INFO] - Training Epoch: 2/2, step 15274/16670 completed (loss: 0.1264372020959854, acc: 0.9555555582046509)
[2024-11-14 10:29:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:30][root][INFO] - Training Epoch: 2/2, step 15275/16670 completed (loss: 0.15819938480854034, acc: 0.9268292784690857)
[2024-11-14 10:29:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:30][root][INFO] - Training Epoch: 2/2, step 15276/16670 completed (loss: 0.17351043224334717, acc: 0.9583333134651184)
[2024-11-14 10:29:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:31][root][INFO] - Training Epoch: 2/2, step 15277/16670 completed (loss: 0.2110888510942459, acc: 0.9529411792755127)
[2024-11-14 10:29:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:31][root][INFO] - Training Epoch: 2/2, step 15278/16670 completed (loss: 0.7279982566833496, acc: 0.8367347121238708)
[2024-11-14 10:29:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:32][root][INFO] - Training Epoch: 2/2, step 15279/16670 completed (loss: 0.17203372716903687, acc: 0.9622641801834106)
[2024-11-14 10:29:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:32][root][INFO] - Training Epoch: 2/2, step 15280/16670 completed (loss: 0.24010294675827026, acc: 0.9186046719551086)
[2024-11-14 10:29:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:32][root][INFO] - Training Epoch: 2/2, step 15281/16670 completed (loss: 0.22318017482757568, acc: 0.931034505367279)
[2024-11-14 10:29:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:33][root][INFO] - Training Epoch: 2/2, step 15282/16670 completed (loss: 0.11202609539031982, acc: 0.9636363387107849)
[2024-11-14 10:29:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:33][root][INFO] - Training Epoch: 2/2, step 15283/16670 completed (loss: 0.34611791372299194, acc: 0.8823529481887817)
[2024-11-14 10:29:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:34][root][INFO] - Training Epoch: 2/2, step 15284/16670 completed (loss: 0.029212959110736847, acc: 1.0)
[2024-11-14 10:29:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:34][root][INFO] - Training Epoch: 2/2, step 15285/16670 completed (loss: 0.2811731994152069, acc: 0.9333333373069763)
[2024-11-14 10:29:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:34][root][INFO] - Training Epoch: 2/2, step 15286/16670 completed (loss: 0.6864592432975769, acc: 0.8571428656578064)
[2024-11-14 10:29:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:35][root][INFO] - Training Epoch: 2/2, step 15287/16670 completed (loss: 0.931198239326477, acc: 0.7297297120094299)
[2024-11-14 10:29:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:35][root][INFO] - Training Epoch: 2/2, step 15288/16670 completed (loss: 0.6674326658248901, acc: 0.8840579986572266)
[2024-11-14 10:29:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:35][root][INFO] - Training Epoch: 2/2, step 15289/16670 completed (loss: 0.6245259046554565, acc: 0.9615384340286255)
[2024-11-14 10:29:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:36][root][INFO] - Training Epoch: 2/2, step 15290/16670 completed (loss: 0.46622234582901, acc: 0.8888888955116272)
[2024-11-14 10:29:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:36][root][INFO] - Training Epoch: 2/2, step 15291/16670 completed (loss: 0.09739366173744202, acc: 0.9523809552192688)
[2024-11-14 10:29:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:36][root][INFO] - Training Epoch: 2/2, step 15292/16670 completed (loss: 0.2841118276119232, acc: 0.9117646813392639)
[2024-11-14 10:29:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:37][root][INFO] - Training Epoch: 2/2, step 15293/16670 completed (loss: 0.5068058967590332, acc: 0.8653846383094788)
[2024-11-14 10:29:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:37][root][INFO] - Training Epoch: 2/2, step 15294/16670 completed (loss: 0.30114877223968506, acc: 0.8823529481887817)
[2024-11-14 10:29:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:37][root][INFO] - Training Epoch: 2/2, step 15295/16670 completed (loss: 0.9762083888053894, acc: 0.7586206793785095)
[2024-11-14 10:29:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:38][root][INFO] - Training Epoch: 2/2, step 15296/16670 completed (loss: 0.0644952729344368, acc: 0.9807692170143127)
[2024-11-14 10:29:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:38][root][INFO] - Training Epoch: 2/2, step 15297/16670 completed (loss: 1.0523085594177246, acc: 0.8333333134651184)
[2024-11-14 10:29:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:38][root][INFO] - Training Epoch: 2/2, step 15298/16670 completed (loss: 0.1097194254398346, acc: 1.0)
[2024-11-14 10:29:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:39][root][INFO] - Training Epoch: 2/2, step 15299/16670 completed (loss: 0.46492016315460205, acc: 0.8387096524238586)
[2024-11-14 10:29:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:39][root][INFO] - Training Epoch: 2/2, step 15300/16670 completed (loss: 0.32496899366378784, acc: 0.9111111164093018)
[2024-11-14 10:29:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:39][root][INFO] - Training Epoch: 2/2, step 15301/16670 completed (loss: 0.21438871324062347, acc: 0.9354838728904724)
[2024-11-14 10:29:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:40][root][INFO] - Training Epoch: 2/2, step 15302/16670 completed (loss: 0.2550787627696991, acc: 0.9230769276618958)
[2024-11-14 10:29:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:40][root][INFO] - Training Epoch: 2/2, step 15303/16670 completed (loss: 0.4794579744338989, acc: 0.8837209343910217)
[2024-11-14 10:29:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:40][root][INFO] - Training Epoch: 2/2, step 15304/16670 completed (loss: 0.5887309908866882, acc: 0.8333333134651184)
[2024-11-14 10:29:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:41][root][INFO] - Training Epoch: 2/2, step 15305/16670 completed (loss: 0.20335617661476135, acc: 0.9333333373069763)
[2024-11-14 10:29:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:41][root][INFO] - Training Epoch: 2/2, step 15306/16670 completed (loss: 0.8640518188476562, acc: 0.765625)
[2024-11-14 10:29:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:41][root][INFO] - Training Epoch: 2/2, step 15307/16670 completed (loss: 0.21728970110416412, acc: 0.9599999785423279)
[2024-11-14 10:29:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:42][root][INFO] - Training Epoch: 2/2, step 15308/16670 completed (loss: 0.3320126533508301, acc: 0.875)
[2024-11-14 10:29:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:42][root][INFO] - Training Epoch: 2/2, step 15309/16670 completed (loss: 0.209479421377182, acc: 0.9285714030265808)
[2024-11-14 10:29:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:42][root][INFO] - Training Epoch: 2/2, step 15310/16670 completed (loss: 0.4782067835330963, acc: 0.8947368264198303)
[2024-11-14 10:29:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:43][root][INFO] - Training Epoch: 2/2, step 15311/16670 completed (loss: 0.21942012012004852, acc: 0.9411764740943909)
[2024-11-14 10:29:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:43][root][INFO] - Training Epoch: 2/2, step 15312/16670 completed (loss: 0.2433299869298935, acc: 0.930232584476471)
[2024-11-14 10:29:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:43][root][INFO] - Training Epoch: 2/2, step 15313/16670 completed (loss: 0.4897082448005676, acc: 0.9387755393981934)
[2024-11-14 10:29:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:44][root][INFO] - Training Epoch: 2/2, step 15314/16670 completed (loss: 0.6107168197631836, acc: 0.9152542352676392)
[2024-11-14 10:29:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:44][root][INFO] - Training Epoch: 2/2, step 15315/16670 completed (loss: 0.3135014474391937, acc: 0.9215686321258545)
[2024-11-14 10:29:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:44][root][INFO] - Training Epoch: 2/2, step 15316/16670 completed (loss: 0.6356647610664368, acc: 0.8723404407501221)
[2024-11-14 10:29:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:45][root][INFO] - Training Epoch: 2/2, step 15317/16670 completed (loss: 0.4891752600669861, acc: 0.8888888955116272)
[2024-11-14 10:29:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:45][root][INFO] - Training Epoch: 2/2, step 15318/16670 completed (loss: 0.5316040515899658, acc: 0.8055555820465088)
[2024-11-14 10:29:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:45][root][INFO] - Training Epoch: 2/2, step 15319/16670 completed (loss: 0.8742746710777283, acc: 0.7777777910232544)
[2024-11-14 10:29:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:45][root][INFO] - Training Epoch: 2/2, step 15320/16670 completed (loss: 0.09482017904520035, acc: 0.976190447807312)
[2024-11-14 10:29:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:46][root][INFO] - Training Epoch: 2/2, step 15321/16670 completed (loss: 0.8234676718711853, acc: 0.9074074029922485)
[2024-11-14 10:29:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:46][root][INFO] - Training Epoch: 2/2, step 15322/16670 completed (loss: 0.5527867078781128, acc: 0.8461538553237915)
[2024-11-14 10:29:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:46][root][INFO] - Training Epoch: 2/2, step 15323/16670 completed (loss: 0.14063552021980286, acc: 0.976190447807312)
[2024-11-14 10:29:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:47][root][INFO] - Training Epoch: 2/2, step 15324/16670 completed (loss: 0.258119136095047, acc: 0.8399999737739563)
[2024-11-14 10:29:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:47][root][INFO] - Training Epoch: 2/2, step 15325/16670 completed (loss: 0.4252052307128906, acc: 0.9166666865348816)
[2024-11-14 10:29:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:47][root][INFO] - Training Epoch: 2/2, step 15326/16670 completed (loss: 0.8488539457321167, acc: 0.8833333253860474)
[2024-11-14 10:29:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:48][root][INFO] - Training Epoch: 2/2, step 15327/16670 completed (loss: 1.0384433269500732, acc: 0.7719298005104065)
[2024-11-14 10:29:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:48][root][INFO] - Training Epoch: 2/2, step 15328/16670 completed (loss: 0.09476710110902786, acc: 0.9583333134651184)
[2024-11-14 10:29:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:48][root][INFO] - Training Epoch: 2/2, step 15329/16670 completed (loss: 0.2889549732208252, acc: 0.9180327653884888)
[2024-11-14 10:29:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:49][root][INFO] - Training Epoch: 2/2, step 15330/16670 completed (loss: 0.20006006956100464, acc: 0.9166666865348816)
[2024-11-14 10:29:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:49][root][INFO] - Training Epoch: 2/2, step 15331/16670 completed (loss: 0.4989725947380066, acc: 0.9090909361839294)
[2024-11-14 10:29:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:49][root][INFO] - Training Epoch: 2/2, step 15332/16670 completed (loss: 0.20156411826610565, acc: 0.9259259104728699)
[2024-11-14 10:29:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:50][root][INFO] - Training Epoch: 2/2, step 15333/16670 completed (loss: 0.2904541492462158, acc: 0.9090909361839294)
[2024-11-14 10:29:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:50][root][INFO] - Training Epoch: 2/2, step 15334/16670 completed (loss: 0.23123127222061157, acc: 0.9333333373069763)
[2024-11-14 10:29:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:50][root][INFO] - Training Epoch: 2/2, step 15335/16670 completed (loss: 1.1855096817016602, acc: 0.760869562625885)
[2024-11-14 10:29:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:51][root][INFO] - Training Epoch: 2/2, step 15336/16670 completed (loss: 0.2568220794200897, acc: 0.875)
[2024-11-14 10:29:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:51][root][INFO] - Training Epoch: 2/2, step 15337/16670 completed (loss: 0.4326118528842926, acc: 0.8500000238418579)
[2024-11-14 10:29:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:51][root][INFO] - Training Epoch: 2/2, step 15338/16670 completed (loss: 0.48643696308135986, acc: 0.9111111164093018)
[2024-11-14 10:29:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:52][root][INFO] - Training Epoch: 2/2, step 15339/16670 completed (loss: 0.14900366961956024, acc: 0.9583333134651184)
[2024-11-14 10:29:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:52][root][INFO] - Training Epoch: 2/2, step 15340/16670 completed (loss: 0.36847877502441406, acc: 0.8695651888847351)
[2024-11-14 10:29:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:52][root][INFO] - Training Epoch: 2/2, step 15341/16670 completed (loss: 0.4826470613479614, acc: 0.8823529481887817)
[2024-11-14 10:29:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:53][root][INFO] - Training Epoch: 2/2, step 15342/16670 completed (loss: 0.1338331252336502, acc: 0.9375)
[2024-11-14 10:29:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:53][root][INFO] - Training Epoch: 2/2, step 15343/16670 completed (loss: 0.5693471431732178, acc: 0.942307710647583)
[2024-11-14 10:29:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:53][root][INFO] - Training Epoch: 2/2, step 15344/16670 completed (loss: 0.43284791707992554, acc: 0.84375)
[2024-11-14 10:29:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:54][root][INFO] - Training Epoch: 2/2, step 15345/16670 completed (loss: 0.4515697956085205, acc: 0.8571428656578064)
[2024-11-14 10:29:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:54][root][INFO] - Training Epoch: 2/2, step 15346/16670 completed (loss: 0.5508977174758911, acc: 0.8863636255264282)
[2024-11-14 10:29:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:55][root][INFO] - Training Epoch: 2/2, step 15347/16670 completed (loss: 0.5933188199996948, acc: 0.8444444537162781)
[2024-11-14 10:29:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:55][root][INFO] - Training Epoch: 2/2, step 15348/16670 completed (loss: 0.23443138599395752, acc: 0.9130434989929199)
[2024-11-14 10:29:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:55][root][INFO] - Training Epoch: 2/2, step 15349/16670 completed (loss: 0.2333357334136963, acc: 0.8999999761581421)
[2024-11-14 10:29:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:56][root][INFO] - Training Epoch: 2/2, step 15350/16670 completed (loss: 0.3293113708496094, acc: 0.8961039185523987)
[2024-11-14 10:29:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:56][root][INFO] - Training Epoch: 2/2, step 15351/16670 completed (loss: 0.5756714344024658, acc: 0.9230769276618958)
[2024-11-14 10:29:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:56][root][INFO] - Training Epoch: 2/2, step 15352/16670 completed (loss: 0.7527395486831665, acc: 0.8478260636329651)
[2024-11-14 10:29:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:57][root][INFO] - Training Epoch: 2/2, step 15353/16670 completed (loss: 0.6241452097892761, acc: 0.7333333492279053)
[2024-11-14 10:29:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:57][root][INFO] - Training Epoch: 2/2, step 15354/16670 completed (loss: 0.4601098597049713, acc: 0.8684210777282715)
[2024-11-14 10:29:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:57][root][INFO] - Training Epoch: 2/2, step 15355/16670 completed (loss: 0.507073700428009, acc: 0.8709677457809448)
[2024-11-14 10:29:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:58][root][INFO] - Training Epoch: 2/2, step 15356/16670 completed (loss: 0.1577805131673813, acc: 0.9729729890823364)
[2024-11-14 10:29:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:58][root][INFO] - Training Epoch: 2/2, step 15357/16670 completed (loss: 0.13723905384540558, acc: 0.9795918464660645)
[2024-11-14 10:29:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:58][root][INFO] - Training Epoch: 2/2, step 15358/16670 completed (loss: 0.4543193280696869, acc: 0.8611111044883728)
[2024-11-14 10:29:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:59][root][INFO] - Training Epoch: 2/2, step 15359/16670 completed (loss: 0.24412035942077637, acc: 0.9189189076423645)
[2024-11-14 10:29:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:59][root][INFO] - Training Epoch: 2/2, step 15360/16670 completed (loss: 0.2427830845117569, acc: 0.90625)
[2024-11-14 10:29:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:29:59][root][INFO] - Training Epoch: 2/2, step 15361/16670 completed (loss: 0.6544739603996277, acc: 0.8367347121238708)
[2024-11-14 10:29:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:00][root][INFO] - Training Epoch: 2/2, step 15362/16670 completed (loss: 0.445293664932251, acc: 0.8823529481887817)
[2024-11-14 10:30:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:00][root][INFO] - Training Epoch: 2/2, step 15363/16670 completed (loss: 0.6739795804023743, acc: 0.8181818127632141)
[2024-11-14 10:30:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:00][root][INFO] - Training Epoch: 2/2, step 15364/16670 completed (loss: 0.35792919993400574, acc: 0.875)
[2024-11-14 10:30:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:01][root][INFO] - Training Epoch: 2/2, step 15365/16670 completed (loss: 0.6965849995613098, acc: 0.8666666746139526)
[2024-11-14 10:30:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:01][root][INFO] - Training Epoch: 2/2, step 15366/16670 completed (loss: 0.44825291633605957, acc: 0.8928571343421936)
[2024-11-14 10:30:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:01][root][INFO] - Training Epoch: 2/2, step 15367/16670 completed (loss: 0.48490551114082336, acc: 0.8588235378265381)
[2024-11-14 10:30:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:02][root][INFO] - Training Epoch: 2/2, step 15368/16670 completed (loss: 0.5459103584289551, acc: 0.8857142925262451)
[2024-11-14 10:30:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:02][root][INFO] - Training Epoch: 2/2, step 15369/16670 completed (loss: 0.3871764838695526, acc: 0.9130434989929199)
[2024-11-14 10:30:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:02][root][INFO] - Training Epoch: 2/2, step 15370/16670 completed (loss: 0.5051101446151733, acc: 0.931034505367279)
[2024-11-14 10:30:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:03][root][INFO] - Training Epoch: 2/2, step 15371/16670 completed (loss: 0.021630801260471344, acc: 1.0)
[2024-11-14 10:30:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:03][root][INFO] - Training Epoch: 2/2, step 15372/16670 completed (loss: 0.16434580087661743, acc: 0.9387755393981934)
[2024-11-14 10:30:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:03][root][INFO] - Training Epoch: 2/2, step 15373/16670 completed (loss: 0.598884642124176, acc: 0.7931034564971924)
[2024-11-14 10:30:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:04][root][INFO] - Training Epoch: 2/2, step 15374/16670 completed (loss: 0.4011620879173279, acc: 0.8846153616905212)
[2024-11-14 10:30:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:04][root][INFO] - Training Epoch: 2/2, step 15375/16670 completed (loss: 0.26274573802948, acc: 0.8979591727256775)
[2024-11-14 10:30:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:04][root][INFO] - Training Epoch: 2/2, step 15376/16670 completed (loss: 0.6119859218597412, acc: 0.8461538553237915)
[2024-11-14 10:30:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:05][root][INFO] - Training Epoch: 2/2, step 15377/16670 completed (loss: 0.917904794216156, acc: 0.78125)
[2024-11-14 10:30:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:05][root][INFO] - Training Epoch: 2/2, step 15378/16670 completed (loss: 0.4627895653247833, acc: 0.8518518805503845)
[2024-11-14 10:30:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:05][root][INFO] - Training Epoch: 2/2, step 15379/16670 completed (loss: 0.5478376150131226, acc: 0.9166666865348816)
[2024-11-14 10:30:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:06][root][INFO] - Training Epoch: 2/2, step 15380/16670 completed (loss: 0.5316673517227173, acc: 0.8524590134620667)
[2024-11-14 10:30:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:06][root][INFO] - Training Epoch: 2/2, step 15381/16670 completed (loss: 0.49773645401000977, acc: 0.8723404407501221)
[2024-11-14 10:30:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:06][root][INFO] - Training Epoch: 2/2, step 15382/16670 completed (loss: 0.2486017644405365, acc: 0.9459459185600281)
[2024-11-14 10:30:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:07][root][INFO] - Training Epoch: 2/2, step 15383/16670 completed (loss: 0.5233823657035828, acc: 0.9090909361839294)
[2024-11-14 10:30:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:07][root][INFO] - Training Epoch: 2/2, step 15384/16670 completed (loss: 0.3156638741493225, acc: 0.8958333134651184)
[2024-11-14 10:30:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:07][root][INFO] - Training Epoch: 2/2, step 15385/16670 completed (loss: 0.5228342413902283, acc: 0.875)
[2024-11-14 10:30:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:08][root][INFO] - Training Epoch: 2/2, step 15386/16670 completed (loss: 0.10222391039133072, acc: 0.9599999785423279)
[2024-11-14 10:30:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:08][root][INFO] - Training Epoch: 2/2, step 15387/16670 completed (loss: 0.3908338248729706, acc: 0.8888888955116272)
[2024-11-14 10:30:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:08][root][INFO] - Training Epoch: 2/2, step 15388/16670 completed (loss: 0.2867424488067627, acc: 0.9375)
[2024-11-14 10:30:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:09][root][INFO] - Training Epoch: 2/2, step 15389/16670 completed (loss: 0.15677239000797272, acc: 0.9677419066429138)
[2024-11-14 10:30:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:09][root][INFO] - Training Epoch: 2/2, step 15390/16670 completed (loss: 0.7354670166969299, acc: 0.8095238208770752)
[2024-11-14 10:30:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:09][root][INFO] - Training Epoch: 2/2, step 15391/16670 completed (loss: 0.4101649820804596, acc: 0.8888888955116272)
[2024-11-14 10:30:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:10][root][INFO] - Training Epoch: 2/2, step 15392/16670 completed (loss: 0.3215634822845459, acc: 0.8684210777282715)
[2024-11-14 10:30:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:10][root][INFO] - Training Epoch: 2/2, step 15393/16670 completed (loss: 0.5081769227981567, acc: 0.8235294222831726)
[2024-11-14 10:30:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:10][root][INFO] - Training Epoch: 2/2, step 15394/16670 completed (loss: 0.10507357120513916, acc: 0.9583333134651184)
[2024-11-14 10:30:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:11][root][INFO] - Training Epoch: 2/2, step 15395/16670 completed (loss: 0.462746262550354, acc: 0.8666666746139526)
[2024-11-14 10:30:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:11][root][INFO] - Training Epoch: 2/2, step 15396/16670 completed (loss: 0.5718196630477905, acc: 0.9642857313156128)
[2024-11-14 10:30:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:11][root][INFO] - Training Epoch: 2/2, step 15397/16670 completed (loss: 0.7361631393432617, acc: 0.8222222328186035)
[2024-11-14 10:30:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:12][root][INFO] - Training Epoch: 2/2, step 15398/16670 completed (loss: 0.6021609902381897, acc: 0.8780487775802612)
[2024-11-14 10:30:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:12][root][INFO] - Training Epoch: 2/2, step 15399/16670 completed (loss: 0.16707240045070648, acc: 0.957446813583374)
[2024-11-14 10:30:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:13][root][INFO] - Training Epoch: 2/2, step 15400/16670 completed (loss: 0.5723071694374084, acc: 0.8529411554336548)
[2024-11-14 10:30:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:13][root][INFO] - Training Epoch: 2/2, step 15401/16670 completed (loss: 0.18231326341629028, acc: 0.8965517282485962)
[2024-11-14 10:30:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:13][root][INFO] - Training Epoch: 2/2, step 15402/16670 completed (loss: 0.16425806283950806, acc: 1.0)
[2024-11-14 10:30:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:14][root][INFO] - Training Epoch: 2/2, step 15403/16670 completed (loss: 0.1731804758310318, acc: 0.9655172228813171)
[2024-11-14 10:30:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:14][root][INFO] - Training Epoch: 2/2, step 15404/16670 completed (loss: 0.9825903177261353, acc: 0.6399999856948853)
[2024-11-14 10:30:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:14][root][INFO] - Training Epoch: 2/2, step 15405/16670 completed (loss: 0.23357413709163666, acc: 0.9230769276618958)
[2024-11-14 10:30:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:15][root][INFO] - Training Epoch: 2/2, step 15406/16670 completed (loss: 0.4659265875816345, acc: 0.8653846383094788)
[2024-11-14 10:30:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:15][root][INFO] - Training Epoch: 2/2, step 15407/16670 completed (loss: 0.5411396622657776, acc: 0.8571428656578064)
[2024-11-14 10:30:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:16][root][INFO] - Training Epoch: 2/2, step 15408/16670 completed (loss: 0.464053213596344, acc: 0.8604651093482971)
[2024-11-14 10:30:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:16][root][INFO] - Training Epoch: 2/2, step 15409/16670 completed (loss: 0.17995737493038177, acc: 0.9722222089767456)
[2024-11-14 10:30:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:16][root][INFO] - Training Epoch: 2/2, step 15410/16670 completed (loss: 1.1909769773483276, acc: 0.8571428656578064)
[2024-11-14 10:30:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:17][root][INFO] - Training Epoch: 2/2, step 15411/16670 completed (loss: 0.9689996242523193, acc: 0.8518518805503845)
[2024-11-14 10:30:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:17][root][INFO] - Training Epoch: 2/2, step 15412/16670 completed (loss: 0.5219969749450684, acc: 0.8684210777282715)
[2024-11-14 10:30:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:17][root][INFO] - Training Epoch: 2/2, step 15413/16670 completed (loss: 0.35072410106658936, acc: 0.9166666865348816)
[2024-11-14 10:30:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:18][root][INFO] - Training Epoch: 2/2, step 15414/16670 completed (loss: 0.42401123046875, acc: 0.800000011920929)
[2024-11-14 10:30:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:18][root][INFO] - Training Epoch: 2/2, step 15415/16670 completed (loss: 0.2551972270011902, acc: 0.9599999785423279)
[2024-11-14 10:30:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:18][root][INFO] - Training Epoch: 2/2, step 15416/16670 completed (loss: 0.5628500580787659, acc: 0.8399999737739563)
[2024-11-14 10:30:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:19][root][INFO] - Training Epoch: 2/2, step 15417/16670 completed (loss: 0.56540846824646, acc: 0.7941176295280457)
[2024-11-14 10:30:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:19][root][INFO] - Training Epoch: 2/2, step 15418/16670 completed (loss: 0.013417565263807774, acc: 1.0)
[2024-11-14 10:30:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:19][root][INFO] - Training Epoch: 2/2, step 15419/16670 completed (loss: 0.3750385344028473, acc: 0.9090909361839294)
[2024-11-14 10:30:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:20][root][INFO] - Training Epoch: 2/2, step 15420/16670 completed (loss: 0.24424053728580475, acc: 0.8636363744735718)
[2024-11-14 10:30:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:20][root][INFO] - Training Epoch: 2/2, step 15421/16670 completed (loss: 0.6731023192405701, acc: 0.800000011920929)
[2024-11-14 10:30:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:20][root][INFO] - Training Epoch: 2/2, step 15422/16670 completed (loss: 0.2510332465171814, acc: 0.9333333373069763)
[2024-11-14 10:30:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:21][root][INFO] - Training Epoch: 2/2, step 15423/16670 completed (loss: 0.5470689535140991, acc: 0.8285714387893677)
[2024-11-14 10:30:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:21][root][INFO] - Training Epoch: 2/2, step 15424/16670 completed (loss: 0.435063898563385, acc: 0.8888888955116272)
[2024-11-14 10:30:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:21][root][INFO] - Training Epoch: 2/2, step 15425/16670 completed (loss: 0.5291706323623657, acc: 0.8529411554336548)
[2024-11-14 10:30:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:22][root][INFO] - Training Epoch: 2/2, step 15426/16670 completed (loss: 0.33600670099258423, acc: 0.9523809552192688)
[2024-11-14 10:30:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:22][root][INFO] - Training Epoch: 2/2, step 15427/16670 completed (loss: 0.20592597126960754, acc: 0.9459459185600281)
[2024-11-14 10:30:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:22][root][INFO] - Training Epoch: 2/2, step 15428/16670 completed (loss: 0.27952778339385986, acc: 0.9655172228813171)
[2024-11-14 10:30:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:23][root][INFO] - Training Epoch: 2/2, step 15429/16670 completed (loss: 0.38015347719192505, acc: 0.9230769276618958)
[2024-11-14 10:30:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:23][root][INFO] - Training Epoch: 2/2, step 15430/16670 completed (loss: 0.22624237835407257, acc: 0.9444444179534912)
[2024-11-14 10:30:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:24][root][INFO] - Training Epoch: 2/2, step 15431/16670 completed (loss: 0.07855024933815002, acc: 1.0)
[2024-11-14 10:30:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:24][root][INFO] - Training Epoch: 2/2, step 15432/16670 completed (loss: 0.46859800815582275, acc: 0.8823529481887817)
[2024-11-14 10:30:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:24][root][INFO] - Training Epoch: 2/2, step 15433/16670 completed (loss: 0.334979385137558, acc: 0.875)
[2024-11-14 10:30:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:25][root][INFO] - Training Epoch: 2/2, step 15434/16670 completed (loss: 0.23537588119506836, acc: 0.9090909361839294)
[2024-11-14 10:30:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:25][root][INFO] - Training Epoch: 2/2, step 15435/16670 completed (loss: 0.41014865040779114, acc: 0.8723404407501221)
[2024-11-14 10:30:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:25][root][INFO] - Training Epoch: 2/2, step 15436/16670 completed (loss: 0.14444249868392944, acc: 0.9772727489471436)
[2024-11-14 10:30:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:26][root][INFO] - Training Epoch: 2/2, step 15437/16670 completed (loss: 0.2648279070854187, acc: 0.9411764740943909)
[2024-11-14 10:30:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:26][root][INFO] - Training Epoch: 2/2, step 15438/16670 completed (loss: 0.37794989347457886, acc: 0.95652174949646)
[2024-11-14 10:30:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:26][root][INFO] - Training Epoch: 2/2, step 15439/16670 completed (loss: 0.22412359714508057, acc: 0.9736841917037964)
[2024-11-14 10:30:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:27][root][INFO] - Training Epoch: 2/2, step 15440/16670 completed (loss: 0.21621152758598328, acc: 0.9111111164093018)
[2024-11-14 10:30:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:27][root][INFO] - Training Epoch: 2/2, step 15441/16670 completed (loss: 0.5977565050125122, acc: 0.8181818127632141)
[2024-11-14 10:30:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:27][root][INFO] - Training Epoch: 2/2, step 15442/16670 completed (loss: 0.2513720989227295, acc: 0.9523809552192688)
[2024-11-14 10:30:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:28][root][INFO] - Training Epoch: 2/2, step 15443/16670 completed (loss: 0.1916109323501587, acc: 0.9399999976158142)
[2024-11-14 10:30:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:28][root][INFO] - Training Epoch: 2/2, step 15444/16670 completed (loss: 0.33250105381011963, acc: 0.8888888955116272)
[2024-11-14 10:30:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:28][root][INFO] - Training Epoch: 2/2, step 15445/16670 completed (loss: 0.6733708381652832, acc: 0.8888888955116272)
[2024-11-14 10:30:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:29][root][INFO] - Training Epoch: 2/2, step 15446/16670 completed (loss: 0.05566048622131348, acc: 0.9729729890823364)
[2024-11-14 10:30:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:29][root][INFO] - Training Epoch: 2/2, step 15447/16670 completed (loss: 0.49444979429244995, acc: 0.8928571343421936)
[2024-11-14 10:30:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:29][root][INFO] - Training Epoch: 2/2, step 15448/16670 completed (loss: 0.37007176876068115, acc: 0.9375)
[2024-11-14 10:30:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:30][root][INFO] - Training Epoch: 2/2, step 15449/16670 completed (loss: 0.10805777460336685, acc: 0.9672130942344666)
[2024-11-14 10:30:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:30][root][INFO] - Training Epoch: 2/2, step 15450/16670 completed (loss: 0.4131733477115631, acc: 0.9019607901573181)
[2024-11-14 10:30:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:30][root][INFO] - Training Epoch: 2/2, step 15451/16670 completed (loss: 0.40470263361930847, acc: 0.9166666865348816)
[2024-11-14 10:30:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:30][root][INFO] - Training Epoch: 2/2, step 15452/16670 completed (loss: 0.5203032493591309, acc: 0.8571428656578064)
[2024-11-14 10:30:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:31][root][INFO] - Training Epoch: 2/2, step 15453/16670 completed (loss: 0.5300060510635376, acc: 0.8478260636329651)
[2024-11-14 10:30:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:31][root][INFO] - Training Epoch: 2/2, step 15454/16670 completed (loss: 0.4431798756122589, acc: 0.8939393758773804)
[2024-11-14 10:30:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:31][root][INFO] - Training Epoch: 2/2, step 15455/16670 completed (loss: 0.27970269322395325, acc: 0.9069767594337463)
[2024-11-14 10:30:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:32][root][INFO] - Training Epoch: 2/2, step 15456/16670 completed (loss: 0.5788297057151794, acc: 0.8709677457809448)
[2024-11-14 10:30:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:32][root][INFO] - Training Epoch: 2/2, step 15457/16670 completed (loss: 0.2903752326965332, acc: 0.9111111164093018)
[2024-11-14 10:30:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:32][root][INFO] - Training Epoch: 2/2, step 15458/16670 completed (loss: 0.12010777741670609, acc: 0.9375)
[2024-11-14 10:30:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:33][root][INFO] - Training Epoch: 2/2, step 15459/16670 completed (loss: 0.5638624429702759, acc: 0.8787878751754761)
[2024-11-14 10:30:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:33][root][INFO] - Training Epoch: 2/2, step 15460/16670 completed (loss: 0.112941212952137, acc: 0.95652174949646)
[2024-11-14 10:30:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:33][root][INFO] - Training Epoch: 2/2, step 15461/16670 completed (loss: 0.16995905339717865, acc: 0.9591836929321289)
[2024-11-14 10:30:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:34][root][INFO] - Training Epoch: 2/2, step 15462/16670 completed (loss: 0.3539236783981323, acc: 0.953125)
[2024-11-14 10:30:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:34][root][INFO] - Training Epoch: 2/2, step 15463/16670 completed (loss: 0.04745067283511162, acc: 0.9857142567634583)
[2024-11-14 10:30:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:34][root][INFO] - Training Epoch: 2/2, step 15464/16670 completed (loss: 0.42467135190963745, acc: 0.9285714030265808)
[2024-11-14 10:30:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:34][root][INFO] - Training Epoch: 2/2, step 15465/16670 completed (loss: 0.3218533992767334, acc: 0.9122806787490845)
[2024-11-14 10:30:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:35][root][INFO] - Training Epoch: 2/2, step 15466/16670 completed (loss: 0.36523470282554626, acc: 0.875)
[2024-11-14 10:30:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:35][root][INFO] - Training Epoch: 2/2, step 15467/16670 completed (loss: 0.5712692737579346, acc: 0.8620689511299133)
[2024-11-14 10:30:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:35][root][INFO] - Training Epoch: 2/2, step 15468/16670 completed (loss: 0.4553460478782654, acc: 0.914893627166748)
[2024-11-14 10:30:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:36][root][INFO] - Training Epoch: 2/2, step 15469/16670 completed (loss: 0.6951162815093994, acc: 0.8275862336158752)
[2024-11-14 10:30:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:36][root][INFO] - Training Epoch: 2/2, step 15470/16670 completed (loss: 0.480616956949234, acc: 0.8536585569381714)
[2024-11-14 10:30:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:36][root][INFO] - Training Epoch: 2/2, step 15471/16670 completed (loss: 0.315494567155838, acc: 0.931034505367279)
[2024-11-14 10:30:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:37][root][INFO] - Training Epoch: 2/2, step 15472/16670 completed (loss: 0.19815300405025482, acc: 0.9555555582046509)
[2024-11-14 10:30:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:37][root][INFO] - Training Epoch: 2/2, step 15473/16670 completed (loss: 0.39966005086898804, acc: 0.9024389982223511)
[2024-11-14 10:30:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:38][root][INFO] - Training Epoch: 2/2, step 15474/16670 completed (loss: 0.9522104859352112, acc: 0.8235294222831726)
[2024-11-14 10:30:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:38][root][INFO] - Training Epoch: 2/2, step 15475/16670 completed (loss: 0.20682695508003235, acc: 0.9545454382896423)
[2024-11-14 10:30:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:38][root][INFO] - Training Epoch: 2/2, step 15476/16670 completed (loss: 0.25770992040634155, acc: 0.9411764740943909)
[2024-11-14 10:30:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:39][root][INFO] - Training Epoch: 2/2, step 15477/16670 completed (loss: 0.28027060627937317, acc: 0.9333333373069763)
[2024-11-14 10:30:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:39][root][INFO] - Training Epoch: 2/2, step 15478/16670 completed (loss: 0.25483009219169617, acc: 0.920634925365448)
[2024-11-14 10:30:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:39][root][INFO] - Training Epoch: 2/2, step 15479/16670 completed (loss: 0.7497739195823669, acc: 0.875)
[2024-11-14 10:30:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:40][root][INFO] - Training Epoch: 2/2, step 15480/16670 completed (loss: 0.22295105457305908, acc: 0.9411764740943909)
[2024-11-14 10:30:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:40][root][INFO] - Training Epoch: 2/2, step 15481/16670 completed (loss: 0.2290988713502884, acc: 0.9090909361839294)
[2024-11-14 10:30:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:40][root][INFO] - Training Epoch: 2/2, step 15482/16670 completed (loss: 0.21468254923820496, acc: 0.9714285731315613)
[2024-11-14 10:30:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:41][root][INFO] - Training Epoch: 2/2, step 15483/16670 completed (loss: 0.407873272895813, acc: 0.9111111164093018)
[2024-11-14 10:30:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:41][root][INFO] - Training Epoch: 2/2, step 15484/16670 completed (loss: 0.2810983955860138, acc: 0.8918918967247009)
[2024-11-14 10:30:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:41][root][INFO] - Training Epoch: 2/2, step 15485/16670 completed (loss: 0.25994372367858887, acc: 0.9411764740943909)
[2024-11-14 10:30:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:42][root][INFO] - Training Epoch: 2/2, step 15486/16670 completed (loss: 0.1630123108625412, acc: 0.9516128897666931)
[2024-11-14 10:30:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:42][root][INFO] - Training Epoch: 2/2, step 15487/16670 completed (loss: 0.16294290125370026, acc: 0.9852941036224365)
[2024-11-14 10:30:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:42][root][INFO] - Training Epoch: 2/2, step 15488/16670 completed (loss: 0.12647108733654022, acc: 0.970588207244873)
[2024-11-14 10:30:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:43][root][INFO] - Training Epoch: 2/2, step 15489/16670 completed (loss: 0.451850026845932, acc: 0.9189189076423645)
[2024-11-14 10:30:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:43][root][INFO] - Training Epoch: 2/2, step 15490/16670 completed (loss: 0.2476467341184616, acc: 0.9714285731315613)
[2024-11-14 10:30:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:43][root][INFO] - Training Epoch: 2/2, step 15491/16670 completed (loss: 0.4931681156158447, acc: 0.9019607901573181)
[2024-11-14 10:30:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:44][root][INFO] - Training Epoch: 2/2, step 15492/16670 completed (loss: 0.44811582565307617, acc: 0.9264705777168274)
[2024-11-14 10:30:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:44][root][INFO] - Training Epoch: 2/2, step 15493/16670 completed (loss: 0.38759082555770874, acc: 0.8913043737411499)
[2024-11-14 10:30:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:45][root][INFO] - Training Epoch: 2/2, step 15494/16670 completed (loss: 0.35681119561195374, acc: 0.9259259104728699)
[2024-11-14 10:30:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:45][root][INFO] - Training Epoch: 2/2, step 15495/16670 completed (loss: 0.26648417115211487, acc: 0.9189189076423645)
[2024-11-14 10:30:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:45][root][INFO] - Training Epoch: 2/2, step 15496/16670 completed (loss: 0.4550517797470093, acc: 0.8867924809455872)
[2024-11-14 10:30:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:46][root][INFO] - Training Epoch: 2/2, step 15497/16670 completed (loss: 0.5116453766822815, acc: 0.8999999761581421)
[2024-11-14 10:30:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:46][root][INFO] - Training Epoch: 2/2, step 15498/16670 completed (loss: 0.34678149223327637, acc: 0.9545454382896423)
[2024-11-14 10:30:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:46][root][INFO] - Training Epoch: 2/2, step 15499/16670 completed (loss: 0.46796485781669617, acc: 0.8958333134651184)
[2024-11-14 10:30:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:47][root][INFO] - Training Epoch: 2/2, step 15500/16670 completed (loss: 0.5474029183387756, acc: 0.7857142686843872)
[2024-11-14 10:30:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:47][root][INFO] - Training Epoch: 2/2, step 15501/16670 completed (loss: 0.3974502384662628, acc: 0.9259259104728699)
[2024-11-14 10:30:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:47][root][INFO] - Training Epoch: 2/2, step 15502/16670 completed (loss: 0.2953457832336426, acc: 0.9200000166893005)
[2024-11-14 10:30:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:48][root][INFO] - Training Epoch: 2/2, step 15503/16670 completed (loss: 0.19902768731117249, acc: 0.95652174949646)
[2024-11-14 10:30:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:48][root][INFO] - Training Epoch: 2/2, step 15504/16670 completed (loss: 0.28108593821525574, acc: 0.9534883499145508)
[2024-11-14 10:30:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:48][root][INFO] - Training Epoch: 2/2, step 15505/16670 completed (loss: 0.28612664341926575, acc: 0.9122806787490845)
[2024-11-14 10:30:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:49][root][INFO] - Training Epoch: 2/2, step 15506/16670 completed (loss: 0.6000676155090332, acc: 0.875)
[2024-11-14 10:30:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:49][root][INFO] - Training Epoch: 2/2, step 15507/16670 completed (loss: 0.047549616545438766, acc: 0.9821428656578064)
[2024-11-14 10:30:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:49][root][INFO] - Training Epoch: 2/2, step 15508/16670 completed (loss: 0.34689486026763916, acc: 0.9166666865348816)
[2024-11-14 10:30:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:50][root][INFO] - Training Epoch: 2/2, step 15509/16670 completed (loss: 0.18823930621147156, acc: 0.9230769276618958)
[2024-11-14 10:30:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:50][root][INFO] - Training Epoch: 2/2, step 15510/16670 completed (loss: 0.3271433115005493, acc: 0.918367326259613)
[2024-11-14 10:30:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:50][root][INFO] - Training Epoch: 2/2, step 15511/16670 completed (loss: 0.1401967853307724, acc: 0.9661017060279846)
[2024-11-14 10:30:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:51][root][INFO] - Training Epoch: 2/2, step 15512/16670 completed (loss: 0.47089800238609314, acc: 0.8536585569381714)
[2024-11-14 10:30:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:51][root][INFO] - Training Epoch: 2/2, step 15513/16670 completed (loss: 0.3078395426273346, acc: 0.9189189076423645)
[2024-11-14 10:30:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:52][root][INFO] - Training Epoch: 2/2, step 15514/16670 completed (loss: 0.3106262981891632, acc: 0.9545454382896423)
[2024-11-14 10:30:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:52][root][INFO] - Training Epoch: 2/2, step 15515/16670 completed (loss: 0.571653425693512, acc: 0.9066666960716248)
[2024-11-14 10:30:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:52][root][INFO] - Training Epoch: 2/2, step 15516/16670 completed (loss: 0.11247347295284271, acc: 0.9622641801834106)
[2024-11-14 10:30:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:53][root][INFO] - Training Epoch: 2/2, step 15517/16670 completed (loss: 0.24036744236946106, acc: 0.9545454382896423)
[2024-11-14 10:30:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:53][root][INFO] - Training Epoch: 2/2, step 15518/16670 completed (loss: 0.5185939073562622, acc: 0.8723404407501221)
[2024-11-14 10:30:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:53][root][INFO] - Training Epoch: 2/2, step 15519/16670 completed (loss: 0.1426558941602707, acc: 0.9655172228813171)
[2024-11-14 10:30:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:54][root][INFO] - Training Epoch: 2/2, step 15520/16670 completed (loss: 0.4383639693260193, acc: 0.8965517282485962)
[2024-11-14 10:30:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:54][root][INFO] - Training Epoch: 2/2, step 15521/16670 completed (loss: 0.33726412057876587, acc: 0.9230769276618958)
[2024-11-14 10:30:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:55][root][INFO] - Training Epoch: 2/2, step 15522/16670 completed (loss: 0.25105419754981995, acc: 0.9399999976158142)
[2024-11-14 10:30:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:55][root][INFO] - Training Epoch: 2/2, step 15523/16670 completed (loss: 0.23340649902820587, acc: 0.9402984976768494)
[2024-11-14 10:30:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:55][root][INFO] - Training Epoch: 2/2, step 15524/16670 completed (loss: 0.39731165766716003, acc: 0.8913043737411499)
[2024-11-14 10:30:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:56][root][INFO] - Training Epoch: 2/2, step 15525/16670 completed (loss: 0.753670871257782, acc: 0.8541666865348816)
[2024-11-14 10:30:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:56][root][INFO] - Training Epoch: 2/2, step 15526/16670 completed (loss: 0.33157455921173096, acc: 0.9318181872367859)
[2024-11-14 10:30:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:56][root][INFO] - Training Epoch: 2/2, step 15527/16670 completed (loss: 0.2185070514678955, acc: 0.9268292784690857)
[2024-11-14 10:30:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:57][root][INFO] - Training Epoch: 2/2, step 15528/16670 completed (loss: 0.5264224410057068, acc: 0.8837209343910217)
[2024-11-14 10:30:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:57][root][INFO] - Training Epoch: 2/2, step 15529/16670 completed (loss: 0.05928843468427658, acc: 0.9803921580314636)
[2024-11-14 10:30:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:57][root][INFO] - Training Epoch: 2/2, step 15530/16670 completed (loss: 0.7674118876457214, acc: 0.8709677457809448)
[2024-11-14 10:30:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:58][root][INFO] - Training Epoch: 2/2, step 15531/16670 completed (loss: 0.09115477651357651, acc: 1.0)
[2024-11-14 10:30:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:58][root][INFO] - Training Epoch: 2/2, step 15532/16670 completed (loss: 0.2418290078639984, acc: 0.9420289993286133)
[2024-11-14 10:30:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:58][root][INFO] - Training Epoch: 2/2, step 15533/16670 completed (loss: 0.5816105604171753, acc: 0.8958333134651184)
[2024-11-14 10:30:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:59][root][INFO] - Training Epoch: 2/2, step 15534/16670 completed (loss: 0.0642642229795456, acc: 0.9750000238418579)
[2024-11-14 10:30:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:59][root][INFO] - Training Epoch: 2/2, step 15535/16670 completed (loss: 0.40077507495880127, acc: 0.9411764740943909)
[2024-11-14 10:30:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:30:59][root][INFO] - Training Epoch: 2/2, step 15536/16670 completed (loss: 0.2953469753265381, acc: 0.8936170339584351)
[2024-11-14 10:30:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:00][root][INFO] - Training Epoch: 2/2, step 15537/16670 completed (loss: 0.4779837429523468, acc: 0.9285714030265808)
[2024-11-14 10:31:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:00][root][INFO] - Training Epoch: 2/2, step 15538/16670 completed (loss: 0.04259703680872917, acc: 1.0)
[2024-11-14 10:31:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:00][root][INFO] - Training Epoch: 2/2, step 15539/16670 completed (loss: 0.10665836930274963, acc: 0.9772727489471436)
[2024-11-14 10:31:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:01][root][INFO] - Training Epoch: 2/2, step 15540/16670 completed (loss: 0.1596604883670807, acc: 0.9615384340286255)
[2024-11-14 10:31:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:01][root][INFO] - Training Epoch: 2/2, step 15541/16670 completed (loss: 0.30116352438926697, acc: 0.8999999761581421)
[2024-11-14 10:31:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:01][root][INFO] - Training Epoch: 2/2, step 15542/16670 completed (loss: 0.2062244564294815, acc: 0.9387755393981934)
[2024-11-14 10:31:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:02][root][INFO] - Training Epoch: 2/2, step 15543/16670 completed (loss: 0.2747837007045746, acc: 0.9240506291389465)
[2024-11-14 10:31:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:02][root][INFO] - Training Epoch: 2/2, step 15544/16670 completed (loss: 0.2887571156024933, acc: 0.9259259104728699)
[2024-11-14 10:31:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:02][root][INFO] - Training Epoch: 2/2, step 15545/16670 completed (loss: 0.048887331038713455, acc: 1.0)
[2024-11-14 10:31:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:03][root][INFO] - Training Epoch: 2/2, step 15546/16670 completed (loss: 0.064853735268116, acc: 1.0)
[2024-11-14 10:31:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:03][root][INFO] - Training Epoch: 2/2, step 15547/16670 completed (loss: 0.9090405702590942, acc: 0.8928571343421936)
[2024-11-14 10:31:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:03][root][INFO] - Training Epoch: 2/2, step 15548/16670 completed (loss: 0.5341142416000366, acc: 0.8723404407501221)
[2024-11-14 10:31:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:04][root][INFO] - Training Epoch: 2/2, step 15549/16670 completed (loss: 0.5433613061904907, acc: 0.9444444179534912)
[2024-11-14 10:31:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:04][root][INFO] - Training Epoch: 2/2, step 15550/16670 completed (loss: 0.6571362018585205, acc: 0.8974359035491943)
[2024-11-14 10:31:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:05][root][INFO] - Training Epoch: 2/2, step 15551/16670 completed (loss: 0.3245776891708374, acc: 0.9230769276618958)
[2024-11-14 10:31:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:05][root][INFO] - Training Epoch: 2/2, step 15552/16670 completed (loss: 0.46698641777038574, acc: 0.8999999761581421)
[2024-11-14 10:31:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:05][root][INFO] - Training Epoch: 2/2, step 15553/16670 completed (loss: 0.19820497930049896, acc: 0.9305555820465088)
[2024-11-14 10:31:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:05][root][INFO] - Training Epoch: 2/2, step 15554/16670 completed (loss: 0.7395592331886292, acc: 0.8727272748947144)
[2024-11-14 10:31:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:06][root][INFO] - Training Epoch: 2/2, step 15555/16670 completed (loss: 0.2570001780986786, acc: 0.9117646813392639)
[2024-11-14 10:31:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:06][root][INFO] - Training Epoch: 2/2, step 15556/16670 completed (loss: 0.43597882986068726, acc: 0.9090909361839294)
[2024-11-14 10:31:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:07][root][INFO] - Training Epoch: 2/2, step 15557/16670 completed (loss: 0.5713059902191162, acc: 0.8636363744735718)
[2024-11-14 10:31:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:07][root][INFO] - Training Epoch: 2/2, step 15558/16670 completed (loss: 1.041088342666626, acc: 0.8392857313156128)
[2024-11-14 10:31:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:07][root][INFO] - Training Epoch: 2/2, step 15559/16670 completed (loss: 0.2827569544315338, acc: 0.9523809552192688)
[2024-11-14 10:31:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:08][root][INFO] - Training Epoch: 2/2, step 15560/16670 completed (loss: 0.17124910652637482, acc: 0.9545454382896423)
[2024-11-14 10:31:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:08][root][INFO] - Training Epoch: 2/2, step 15561/16670 completed (loss: 0.4659062325954437, acc: 0.9599999785423279)
[2024-11-14 10:31:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:08][root][INFO] - Training Epoch: 2/2, step 15562/16670 completed (loss: 0.3314615786075592, acc: 0.9135802388191223)
[2024-11-14 10:31:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:09][root][INFO] - Training Epoch: 2/2, step 15563/16670 completed (loss: 0.17706726491451263, acc: 0.9491525292396545)
[2024-11-14 10:31:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:09][root][INFO] - Training Epoch: 2/2, step 15564/16670 completed (loss: 0.02220778353512287, acc: 1.0)
[2024-11-14 10:31:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:09][root][INFO] - Training Epoch: 2/2, step 15565/16670 completed (loss: 0.21295252442359924, acc: 0.9200000166893005)
[2024-11-14 10:31:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:10][root][INFO] - Training Epoch: 2/2, step 15566/16670 completed (loss: 0.5805431604385376, acc: 0.9756097793579102)
[2024-11-14 10:31:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:10][root][INFO] - Training Epoch: 2/2, step 15567/16670 completed (loss: 0.11081619560718536, acc: 0.9599999785423279)
[2024-11-14 10:31:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:10][root][INFO] - Training Epoch: 2/2, step 15568/16670 completed (loss: 0.4532676637172699, acc: 0.8205128312110901)
[2024-11-14 10:31:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:11][root][INFO] - Training Epoch: 2/2, step 15569/16670 completed (loss: 1.0667632818222046, acc: 0.8205128312110901)
[2024-11-14 10:31:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:11][root][INFO] - Training Epoch: 2/2, step 15570/16670 completed (loss: 0.11936771869659424, acc: 0.9642857313156128)
[2024-11-14 10:31:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:11][root][INFO] - Training Epoch: 2/2, step 15571/16670 completed (loss: 0.3603288531303406, acc: 0.8888888955116272)
[2024-11-14 10:31:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:12][root][INFO] - Training Epoch: 2/2, step 15572/16670 completed (loss: 0.6346556544303894, acc: 0.875)
[2024-11-14 10:31:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:12][root][INFO] - Training Epoch: 2/2, step 15573/16670 completed (loss: 0.1532086879014969, acc: 0.976190447807312)
[2024-11-14 10:31:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:12][root][INFO] - Training Epoch: 2/2, step 15574/16670 completed (loss: 0.1585056036710739, acc: 0.9354838728904724)
[2024-11-14 10:31:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:13][root][INFO] - Training Epoch: 2/2, step 15575/16670 completed (loss: 0.1141708716750145, acc: 0.9558823704719543)
[2024-11-14 10:31:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:13][root][INFO] - Training Epoch: 2/2, step 15576/16670 completed (loss: 0.28748083114624023, acc: 0.9253731369972229)
[2024-11-14 10:31:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:13][root][INFO] - Training Epoch: 2/2, step 15577/16670 completed (loss: 0.22066500782966614, acc: 0.976190447807312)
[2024-11-14 10:31:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:14][root][INFO] - Training Epoch: 2/2, step 15578/16670 completed (loss: 0.44484418630599976, acc: 0.918367326259613)
[2024-11-14 10:31:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:14][root][INFO] - Training Epoch: 2/2, step 15579/16670 completed (loss: 0.37128692865371704, acc: 0.9285714030265808)
[2024-11-14 10:31:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:15][root][INFO] - Training Epoch: 2/2, step 15580/16670 completed (loss: 0.30790507793426514, acc: 0.9333333373069763)
[2024-11-14 10:31:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:15][root][INFO] - Training Epoch: 2/2, step 15581/16670 completed (loss: 0.07935399562120438, acc: 0.96875)
[2024-11-14 10:31:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:15][root][INFO] - Training Epoch: 2/2, step 15582/16670 completed (loss: 0.36463463306427, acc: 0.9104477763175964)
[2024-11-14 10:31:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:16][root][INFO] - Training Epoch: 2/2, step 15583/16670 completed (loss: 0.24383768439292908, acc: 0.949999988079071)
[2024-11-14 10:31:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:16][root][INFO] - Training Epoch: 2/2, step 15584/16670 completed (loss: 0.15741226077079773, acc: 0.949999988079071)
[2024-11-14 10:31:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:16][root][INFO] - Training Epoch: 2/2, step 15585/16670 completed (loss: 0.09381967037916183, acc: 0.9777777791023254)
[2024-11-14 10:31:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:17][root][INFO] - Training Epoch: 2/2, step 15586/16670 completed (loss: 0.20572294294834137, acc: 0.9375)
[2024-11-14 10:31:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:17][root][INFO] - Training Epoch: 2/2, step 15587/16670 completed (loss: 1.1146459579467773, acc: 0.699999988079071)
[2024-11-14 10:31:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:18][root][INFO] - Training Epoch: 2/2, step 15588/16670 completed (loss: 0.721767246723175, acc: 0.8199999928474426)
[2024-11-14 10:31:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:18][root][INFO] - Training Epoch: 2/2, step 15589/16670 completed (loss: 0.2706359326839447, acc: 0.9642857313156128)
[2024-11-14 10:31:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:18][root][INFO] - Training Epoch: 2/2, step 15590/16670 completed (loss: 0.11442852020263672, acc: 0.9811320900917053)
[2024-11-14 10:31:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:19][root][INFO] - Training Epoch: 2/2, step 15591/16670 completed (loss: 0.34372785687446594, acc: 0.8684210777282715)
[2024-11-14 10:31:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:19][root][INFO] - Training Epoch: 2/2, step 15592/16670 completed (loss: 0.39600756764411926, acc: 0.8947368264198303)
[2024-11-14 10:31:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:19][root][INFO] - Training Epoch: 2/2, step 15593/16670 completed (loss: 0.19990015029907227, acc: 0.9677419066429138)
[2024-11-14 10:31:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:20][root][INFO] - Training Epoch: 2/2, step 15594/16670 completed (loss: 0.304993599653244, acc: 0.8999999761581421)
[2024-11-14 10:31:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:20][root][INFO] - Training Epoch: 2/2, step 15595/16670 completed (loss: 0.4523315727710724, acc: 0.8305084705352783)
[2024-11-14 10:31:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:20][root][INFO] - Training Epoch: 2/2, step 15596/16670 completed (loss: 0.36668795347213745, acc: 0.9189189076423645)
[2024-11-14 10:31:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:21][root][INFO] - Training Epoch: 2/2, step 15597/16670 completed (loss: 0.0590488538146019, acc: 0.9803921580314636)
[2024-11-14 10:31:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:21][root][INFO] - Training Epoch: 2/2, step 15598/16670 completed (loss: 0.19035591185092926, acc: 0.9333333373069763)
[2024-11-14 10:31:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:21][root][INFO] - Training Epoch: 2/2, step 15599/16670 completed (loss: 0.3149213492870331, acc: 0.9333333373069763)
[2024-11-14 10:31:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:22][root][INFO] - Training Epoch: 2/2, step 15600/16670 completed (loss: 0.2588315010070801, acc: 0.8939393758773804)
[2024-11-14 10:31:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:22][root][INFO] - Training Epoch: 2/2, step 15601/16670 completed (loss: 0.39173781871795654, acc: 0.8999999761581421)
[2024-11-14 10:31:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:22][root][INFO] - Training Epoch: 2/2, step 15602/16670 completed (loss: 0.14612655341625214, acc: 0.9811320900917053)
[2024-11-14 10:31:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:23][root][INFO] - Training Epoch: 2/2, step 15603/16670 completed (loss: 0.2091217339038849, acc: 0.9230769276618958)
[2024-11-14 10:31:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:23][root][INFO] - Training Epoch: 2/2, step 15604/16670 completed (loss: 0.0766792744398117, acc: 0.9777777791023254)
[2024-11-14 10:31:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:23][root][INFO] - Training Epoch: 2/2, step 15605/16670 completed (loss: 0.27898353338241577, acc: 0.9444444179534912)
[2024-11-14 10:31:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:24][root][INFO] - Training Epoch: 2/2, step 15606/16670 completed (loss: 0.3290663957595825, acc: 0.9047619104385376)
[2024-11-14 10:31:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:24][root][INFO] - Training Epoch: 2/2, step 15607/16670 completed (loss: 0.39396417140960693, acc: 0.9677419066429138)
[2024-11-14 10:31:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:25][root][INFO] - Training Epoch: 2/2, step 15608/16670 completed (loss: 0.2595546841621399, acc: 0.9411764740943909)
[2024-11-14 10:31:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:25][root][INFO] - Training Epoch: 2/2, step 15609/16670 completed (loss: 0.11284640431404114, acc: 0.9607843160629272)
[2024-11-14 10:31:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:25][root][INFO] - Training Epoch: 2/2, step 15610/16670 completed (loss: 0.5897462368011475, acc: 0.8888888955116272)
[2024-11-14 10:31:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:26][root][INFO] - Training Epoch: 2/2, step 15611/16670 completed (loss: 0.27423369884490967, acc: 0.9245283007621765)
[2024-11-14 10:31:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:26][root][INFO] - Training Epoch: 2/2, step 15612/16670 completed (loss: 0.45029547810554504, acc: 0.9032257795333862)
[2024-11-14 10:31:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:26][root][INFO] - Training Epoch: 2/2, step 15613/16670 completed (loss: 0.21247923374176025, acc: 0.9642857313156128)
[2024-11-14 10:31:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:27][root][INFO] - Training Epoch: 2/2, step 15614/16670 completed (loss: 0.1573639214038849, acc: 0.9591836929321289)
[2024-11-14 10:31:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:27][root][INFO] - Training Epoch: 2/2, step 15615/16670 completed (loss: 0.11686506122350693, acc: 0.9534883499145508)
[2024-11-14 10:31:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:27][root][INFO] - Training Epoch: 2/2, step 15616/16670 completed (loss: 0.4575294256210327, acc: 0.9365079402923584)
[2024-11-14 10:31:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:28][root][INFO] - Training Epoch: 2/2, step 15617/16670 completed (loss: 0.4373498857021332, acc: 0.8500000238418579)
[2024-11-14 10:31:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:28][root][INFO] - Training Epoch: 2/2, step 15618/16670 completed (loss: 0.20713338255882263, acc: 0.9622641801834106)
[2024-11-14 10:31:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:28][root][INFO] - Training Epoch: 2/2, step 15619/16670 completed (loss: 0.3406473398208618, acc: 0.8936170339584351)
[2024-11-14 10:31:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:29][root][INFO] - Training Epoch: 2/2, step 15620/16670 completed (loss: 0.2539842426776886, acc: 0.9479166865348816)
[2024-11-14 10:31:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:29][root][INFO] - Training Epoch: 2/2, step 15621/16670 completed (loss: 0.3953690528869629, acc: 0.9242424368858337)
[2024-11-14 10:31:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:29][root][INFO] - Training Epoch: 2/2, step 15622/16670 completed (loss: 0.09157615900039673, acc: 0.9830508232116699)
[2024-11-14 10:31:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:30][root][INFO] - Training Epoch: 2/2, step 15623/16670 completed (loss: 0.8995999097824097, acc: 0.8360655903816223)
[2024-11-14 10:31:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:30][root][INFO] - Training Epoch: 2/2, step 15624/16670 completed (loss: 0.43425479531288147, acc: 0.8372092843055725)
[2024-11-14 10:31:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:30][root][INFO] - Training Epoch: 2/2, step 15625/16670 completed (loss: 0.28465431928634644, acc: 0.9298245906829834)
[2024-11-14 10:31:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:31][root][INFO] - Training Epoch: 2/2, step 15626/16670 completed (loss: 0.03933573141694069, acc: 1.0)
[2024-11-14 10:31:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:31][root][INFO] - Training Epoch: 2/2, step 15627/16670 completed (loss: 0.5246444344520569, acc: 0.9041095972061157)
[2024-11-14 10:31:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:31][root][INFO] - Training Epoch: 2/2, step 15628/16670 completed (loss: 0.18316927552223206, acc: 0.9464285969734192)
[2024-11-14 10:31:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:31][root][INFO] - Training Epoch: 2/2, step 15629/16670 completed (loss: 0.5050622820854187, acc: 0.9230769276618958)
[2024-11-14 10:31:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:32][root][INFO] - Training Epoch: 2/2, step 15630/16670 completed (loss: 0.2302221655845642, acc: 0.9444444179534912)
[2024-11-14 10:31:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:32][root][INFO] - Training Epoch: 2/2, step 15631/16670 completed (loss: 0.7205228209495544, acc: 0.9032257795333862)
[2024-11-14 10:31:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:32][root][INFO] - Training Epoch: 2/2, step 15632/16670 completed (loss: 0.3212263882160187, acc: 0.9032257795333862)
[2024-11-14 10:31:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:33][root][INFO] - Training Epoch: 2/2, step 15633/16670 completed (loss: 0.024175086989998817, acc: 1.0)
[2024-11-14 10:31:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:33][root][INFO] - Training Epoch: 2/2, step 15634/16670 completed (loss: 0.5345239639282227, acc: 0.8909090757369995)
[2024-11-14 10:31:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:33][root][INFO] - Training Epoch: 2/2, step 15635/16670 completed (loss: 0.4678545892238617, acc: 0.9333333373069763)
[2024-11-14 10:31:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:34][root][INFO] - Training Epoch: 2/2, step 15636/16670 completed (loss: 0.03484238684177399, acc: 1.0)
[2024-11-14 10:31:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:34][root][INFO] - Training Epoch: 2/2, step 15637/16670 completed (loss: 0.47091996669769287, acc: 0.8809523582458496)
[2024-11-14 10:31:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:34][root][INFO] - Training Epoch: 2/2, step 15638/16670 completed (loss: 0.7444507479667664, acc: 0.8666666746139526)
[2024-11-14 10:31:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:35][root][INFO] - Training Epoch: 2/2, step 15639/16670 completed (loss: 0.4689905047416687, acc: 0.8799999952316284)
[2024-11-14 10:31:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:35][root][INFO] - Training Epoch: 2/2, step 15640/16670 completed (loss: 0.7724661827087402, acc: 0.8809523582458496)
[2024-11-14 10:31:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:35][root][INFO] - Training Epoch: 2/2, step 15641/16670 completed (loss: 0.6101170182228088, acc: 0.8387096524238586)
[2024-11-14 10:31:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:35][root][INFO] - Training Epoch: 2/2, step 15642/16670 completed (loss: 0.45349493622779846, acc: 0.9189189076423645)
[2024-11-14 10:31:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:36][root][INFO] - Training Epoch: 2/2, step 15643/16670 completed (loss: 0.9861399531364441, acc: 0.7333333492279053)
[2024-11-14 10:31:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:36][root][INFO] - Training Epoch: 2/2, step 15644/16670 completed (loss: 0.30253955721855164, acc: 0.8999999761581421)
[2024-11-14 10:31:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:36][root][INFO] - Training Epoch: 2/2, step 15645/16670 completed (loss: 0.05961652845144272, acc: 0.978723406791687)
[2024-11-14 10:31:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:37][root][INFO] - Training Epoch: 2/2, step 15646/16670 completed (loss: 0.2030462771654129, acc: 0.95652174949646)
[2024-11-14 10:31:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:37][root][INFO] - Training Epoch: 2/2, step 15647/16670 completed (loss: 0.47994324564933777, acc: 0.8965517282485962)
[2024-11-14 10:31:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:37][root][INFO] - Training Epoch: 2/2, step 15648/16670 completed (loss: 0.2869705557823181, acc: 0.9512194991111755)
[2024-11-14 10:31:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:38][root][INFO] - Training Epoch: 2/2, step 15649/16670 completed (loss: 0.41923612356185913, acc: 0.8709677457809448)
[2024-11-14 10:31:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:38][root][INFO] - Training Epoch: 2/2, step 15650/16670 completed (loss: 0.5945627093315125, acc: 0.8461538553237915)
[2024-11-14 10:31:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:38][root][INFO] - Training Epoch: 2/2, step 15651/16670 completed (loss: 0.43696558475494385, acc: 0.9200000166893005)
[2024-11-14 10:31:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:39][root][INFO] - Training Epoch: 2/2, step 15652/16670 completed (loss: 0.19316871464252472, acc: 0.9230769276618958)
[2024-11-14 10:31:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:39][root][INFO] - Training Epoch: 2/2, step 15653/16670 completed (loss: 0.6532025337219238, acc: 0.8709677457809448)
[2024-11-14 10:31:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:39][root][INFO] - Training Epoch: 2/2, step 15654/16670 completed (loss: 0.6239227056503296, acc: 0.8500000238418579)
[2024-11-14 10:31:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:40][root][INFO] - Training Epoch: 2/2, step 15655/16670 completed (loss: 0.33578962087631226, acc: 0.8979591727256775)
[2024-11-14 10:31:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:40][root][INFO] - Training Epoch: 2/2, step 15656/16670 completed (loss: 0.6097344160079956, acc: 0.875)
[2024-11-14 10:31:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:40][root][INFO] - Training Epoch: 2/2, step 15657/16670 completed (loss: 0.5189569592475891, acc: 0.921875)
[2024-11-14 10:31:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:41][root][INFO] - Training Epoch: 2/2, step 15658/16670 completed (loss: 0.691392719745636, acc: 0.8260869383811951)
[2024-11-14 10:31:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:41][root][INFO] - Training Epoch: 2/2, step 15659/16670 completed (loss: 0.6236414909362793, acc: 0.8536585569381714)
[2024-11-14 10:31:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:41][root][INFO] - Training Epoch: 2/2, step 15660/16670 completed (loss: 0.5649975538253784, acc: 0.8148148059844971)
[2024-11-14 10:31:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:42][root][INFO] - Training Epoch: 2/2, step 15661/16670 completed (loss: 0.4183090925216675, acc: 0.8620689511299133)
[2024-11-14 10:31:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:42][root][INFO] - Training Epoch: 2/2, step 15662/16670 completed (loss: 0.02518683485686779, acc: 1.0)
[2024-11-14 10:31:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:42][root][INFO] - Training Epoch: 2/2, step 15663/16670 completed (loss: 0.23179206252098083, acc: 0.9487179517745972)
[2024-11-14 10:31:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:42][root][INFO] - Training Epoch: 2/2, step 15664/16670 completed (loss: 0.21421031653881073, acc: 0.9692307710647583)
[2024-11-14 10:31:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:43][root][INFO] - Training Epoch: 2/2, step 15665/16670 completed (loss: 0.19425956904888153, acc: 0.9523809552192688)
[2024-11-14 10:31:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:43][root][INFO] - Training Epoch: 2/2, step 15666/16670 completed (loss: 1.1182842254638672, acc: 0.6666666865348816)
[2024-11-14 10:31:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:43][root][INFO] - Training Epoch: 2/2, step 15667/16670 completed (loss: 1.143925666809082, acc: 0.7894737124443054)
[2024-11-14 10:31:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:44][root][INFO] - Training Epoch: 2/2, step 15668/16670 completed (loss: 0.5608839988708496, acc: 0.800000011920929)
[2024-11-14 10:31:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:44][root][INFO] - Training Epoch: 2/2, step 15669/16670 completed (loss: 0.506528913974762, acc: 0.9090909361839294)
[2024-11-14 10:31:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:44][root][INFO] - Training Epoch: 2/2, step 15670/16670 completed (loss: 0.23633304238319397, acc: 0.939393937587738)
[2024-11-14 10:31:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:45][root][INFO] - Training Epoch: 2/2, step 15671/16670 completed (loss: 0.6903030276298523, acc: 0.8620689511299133)
[2024-11-14 10:31:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:45][root][INFO] - Training Epoch: 2/2, step 15672/16670 completed (loss: 0.23758237063884735, acc: 0.949999988079071)
[2024-11-14 10:31:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:45][root][INFO] - Training Epoch: 2/2, step 15673/16670 completed (loss: 0.5211035013198853, acc: 0.8333333134651184)
[2024-11-14 10:31:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:46][root][INFO] - Training Epoch: 2/2, step 15674/16670 completed (loss: 0.3397815525531769, acc: 0.8837209343910217)
[2024-11-14 10:31:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:46][root][INFO] - Training Epoch: 2/2, step 15675/16670 completed (loss: 0.9660571813583374, acc: 0.7941176295280457)
[2024-11-14 10:31:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:46][root][INFO] - Training Epoch: 2/2, step 15676/16670 completed (loss: 0.22375354170799255, acc: 0.9090909361839294)
[2024-11-14 10:31:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:46][root][INFO] - Training Epoch: 2/2, step 15677/16670 completed (loss: 0.8166496157646179, acc: 0.7333333492279053)
[2024-11-14 10:31:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:47][root][INFO] - Training Epoch: 2/2, step 15678/16670 completed (loss: 0.35339248180389404, acc: 0.8666666746139526)
[2024-11-14 10:31:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:47][root][INFO] - Training Epoch: 2/2, step 15679/16670 completed (loss: 0.17358137667179108, acc: 0.9736841917037964)
[2024-11-14 10:31:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:47][root][INFO] - Training Epoch: 2/2, step 15680/16670 completed (loss: 0.13789159059524536, acc: 0.9677419066429138)
[2024-11-14 10:31:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:48][root][INFO] - Training Epoch: 2/2, step 15681/16670 completed (loss: 0.6336869597434998, acc: 0.8571428656578064)
[2024-11-14 10:31:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:48][root][INFO] - Training Epoch: 2/2, step 15682/16670 completed (loss: 0.3496929407119751, acc: 0.9074074029922485)
[2024-11-14 10:31:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:49][root][INFO] - Training Epoch: 2/2, step 15683/16670 completed (loss: 0.2689305245876312, acc: 0.931034505367279)
[2024-11-14 10:31:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:49][root][INFO] - Training Epoch: 2/2, step 15684/16670 completed (loss: 0.25370535254478455, acc: 0.9333333373069763)
[2024-11-14 10:31:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:49][root][INFO] - Training Epoch: 2/2, step 15685/16670 completed (loss: 1.4180364608764648, acc: 0.6190476417541504)
[2024-11-14 10:31:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:50][root][INFO] - Training Epoch: 2/2, step 15686/16670 completed (loss: 0.29106605052948, acc: 0.9210526347160339)
[2024-11-14 10:31:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:50][root][INFO] - Training Epoch: 2/2, step 15687/16670 completed (loss: 1.0755789279937744, acc: 0.6000000238418579)
[2024-11-14 10:31:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:50][root][INFO] - Training Epoch: 2/2, step 15688/16670 completed (loss: 0.921669065952301, acc: 0.7843137383460999)
[2024-11-14 10:31:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:51][root][INFO] - Training Epoch: 2/2, step 15689/16670 completed (loss: 0.11935484409332275, acc: 0.9714285731315613)
[2024-11-14 10:31:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:51][root][INFO] - Training Epoch: 2/2, step 15690/16670 completed (loss: 0.8315266370773315, acc: 0.7333333492279053)
[2024-11-14 10:31:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:51][root][INFO] - Training Epoch: 2/2, step 15691/16670 completed (loss: 0.4396401643753052, acc: 0.9215686321258545)
[2024-11-14 10:31:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:52][root][INFO] - Training Epoch: 2/2, step 15692/16670 completed (loss: 0.4868323802947998, acc: 0.9019607901573181)
[2024-11-14 10:31:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:52][root][INFO] - Training Epoch: 2/2, step 15693/16670 completed (loss: 0.46788716316223145, acc: 0.8823529481887817)
[2024-11-14 10:31:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:53][root][INFO] - Training Epoch: 2/2, step 15694/16670 completed (loss: 0.3100668489933014, acc: 0.9111111164093018)
[2024-11-14 10:31:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:53][root][INFO] - Training Epoch: 2/2, step 15695/16670 completed (loss: 0.4650258421897888, acc: 0.859649121761322)
[2024-11-14 10:31:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:53][root][INFO] - Training Epoch: 2/2, step 15696/16670 completed (loss: 0.06454403698444366, acc: 1.0)
[2024-11-14 10:31:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:53][root][INFO] - Training Epoch: 2/2, step 15697/16670 completed (loss: 0.07842402905225754, acc: 1.0)
[2024-11-14 10:31:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:54][root][INFO] - Training Epoch: 2/2, step 15698/16670 completed (loss: 0.39156869053840637, acc: 0.914893627166748)
[2024-11-14 10:31:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:54][root][INFO] - Training Epoch: 2/2, step 15699/16670 completed (loss: 0.5413188934326172, acc: 0.9411764740943909)
[2024-11-14 10:31:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:55][root][INFO] - Training Epoch: 2/2, step 15700/16670 completed (loss: 0.4038333594799042, acc: 0.8787878751754761)
[2024-11-14 10:31:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:55][root][INFO] - Training Epoch: 2/2, step 15701/16670 completed (loss: 0.7352055311203003, acc: 0.8085106611251831)
[2024-11-14 10:31:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:55][root][INFO] - Training Epoch: 2/2, step 15702/16670 completed (loss: 0.4890235662460327, acc: 0.8936170339584351)
[2024-11-14 10:31:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:56][root][INFO] - Training Epoch: 2/2, step 15703/16670 completed (loss: 0.09525484591722488, acc: 0.9545454382896423)
[2024-11-14 10:31:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:56][root][INFO] - Training Epoch: 2/2, step 15704/16670 completed (loss: 0.3895578980445862, acc: 0.8888888955116272)
[2024-11-14 10:31:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:56][root][INFO] - Training Epoch: 2/2, step 15705/16670 completed (loss: 0.34197723865509033, acc: 0.9200000166893005)
[2024-11-14 10:31:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:57][root][INFO] - Training Epoch: 2/2, step 15706/16670 completed (loss: 0.2353544980287552, acc: 0.949999988079071)
[2024-11-14 10:31:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:57][root][INFO] - Training Epoch: 2/2, step 15707/16670 completed (loss: 0.3690434396266937, acc: 0.8837209343910217)
[2024-11-14 10:31:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:57][root][INFO] - Training Epoch: 2/2, step 15708/16670 completed (loss: 0.28731855750083923, acc: 0.9069767594337463)
[2024-11-14 10:31:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:58][root][INFO] - Training Epoch: 2/2, step 15709/16670 completed (loss: 0.2083766758441925, acc: 0.914893627166748)
[2024-11-14 10:31:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:58][root][INFO] - Training Epoch: 2/2, step 15710/16670 completed (loss: 0.42459890246391296, acc: 0.8444444537162781)
[2024-11-14 10:31:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:58][root][INFO] - Training Epoch: 2/2, step 15711/16670 completed (loss: 0.27647387981414795, acc: 0.9629629850387573)
[2024-11-14 10:31:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:59][root][INFO] - Training Epoch: 2/2, step 15712/16670 completed (loss: 0.4237964153289795, acc: 0.9285714030265808)
[2024-11-14 10:31:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:59][root][INFO] - Training Epoch: 2/2, step 15713/16670 completed (loss: 0.038518235087394714, acc: 1.0)
[2024-11-14 10:31:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:31:59][root][INFO] - Training Epoch: 2/2, step 15714/16670 completed (loss: 0.6237872242927551, acc: 0.8805969953536987)
[2024-11-14 10:32:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:00][root][INFO] - Training Epoch: 2/2, step 15715/16670 completed (loss: 0.9152038097381592, acc: 0.8775510191917419)
[2024-11-14 10:32:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:00][root][INFO] - Training Epoch: 2/2, step 15716/16670 completed (loss: 0.35567691922187805, acc: 0.8787878751754761)
[2024-11-14 10:32:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:01][root][INFO] - Training Epoch: 2/2, step 15717/16670 completed (loss: 0.3698991537094116, acc: 0.918367326259613)
[2024-11-14 10:32:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:01][root][INFO] - Training Epoch: 2/2, step 15718/16670 completed (loss: 0.7362538576126099, acc: 0.843137264251709)
[2024-11-14 10:32:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:01][root][INFO] - Training Epoch: 2/2, step 15719/16670 completed (loss: 0.5877293348312378, acc: 0.8571428656578064)
[2024-11-14 10:32:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:02][root][INFO] - Training Epoch: 2/2, step 15720/16670 completed (loss: 0.39048731327056885, acc: 0.859375)
[2024-11-14 10:32:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:02][root][INFO] - Training Epoch: 2/2, step 15721/16670 completed (loss: 0.8849875926971436, acc: 0.8235294222831726)
[2024-11-14 10:32:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:02][root][INFO] - Training Epoch: 2/2, step 15722/16670 completed (loss: 0.12079755961894989, acc: 0.949999988079071)
[2024-11-14 10:32:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:03][root][INFO] - Training Epoch: 2/2, step 15723/16670 completed (loss: 0.8884647488594055, acc: 0.8214285969734192)
[2024-11-14 10:32:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:03][root][INFO] - Training Epoch: 2/2, step 15724/16670 completed (loss: 0.24465098977088928, acc: 0.9534883499145508)
[2024-11-14 10:32:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:03][root][INFO] - Training Epoch: 2/2, step 15725/16670 completed (loss: 0.3620879054069519, acc: 0.9154929518699646)
[2024-11-14 10:32:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:04][root][INFO] - Training Epoch: 2/2, step 15726/16670 completed (loss: 0.2621769905090332, acc: 0.9056603908538818)
[2024-11-14 10:32:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:04][root][INFO] - Training Epoch: 2/2, step 15727/16670 completed (loss: 0.36939698457717896, acc: 0.9130434989929199)
[2024-11-14 10:32:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:05][root][INFO] - Training Epoch: 2/2, step 15728/16670 completed (loss: 0.35826000571250916, acc: 0.930232584476471)
[2024-11-14 10:32:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:05][root][INFO] - Training Epoch: 2/2, step 15729/16670 completed (loss: 0.26830148696899414, acc: 0.9215686321258545)
[2024-11-14 10:32:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:05][root][INFO] - Training Epoch: 2/2, step 15730/16670 completed (loss: 0.11669700592756271, acc: 0.9722222089767456)
[2024-11-14 10:32:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:06][root][INFO] - Training Epoch: 2/2, step 15731/16670 completed (loss: 0.8867121338844299, acc: 0.8214285969734192)
[2024-11-14 10:32:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:06][root][INFO] - Training Epoch: 2/2, step 15732/16670 completed (loss: 0.45334404706954956, acc: 0.9069767594337463)
[2024-11-14 10:32:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:06][root][INFO] - Training Epoch: 2/2, step 15733/16670 completed (loss: 0.6992717981338501, acc: 0.8444444537162781)
[2024-11-14 10:32:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:07][root][INFO] - Training Epoch: 2/2, step 15734/16670 completed (loss: 0.18030744791030884, acc: 0.949999988079071)
[2024-11-14 10:32:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:07][root][INFO] - Training Epoch: 2/2, step 15735/16670 completed (loss: 0.4021925628185272, acc: 0.8705882430076599)
[2024-11-14 10:32:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:07][root][INFO] - Training Epoch: 2/2, step 15736/16670 completed (loss: 0.18158261477947235, acc: 0.9615384340286255)
[2024-11-14 10:32:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:08][root][INFO] - Training Epoch: 2/2, step 15737/16670 completed (loss: 0.8523673415184021, acc: 0.8163265585899353)
[2024-11-14 10:32:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:08][root][INFO] - Training Epoch: 2/2, step 15738/16670 completed (loss: 0.12307412177324295, acc: 0.9459459185600281)
[2024-11-14 10:32:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:08][root][INFO] - Training Epoch: 2/2, step 15739/16670 completed (loss: 0.5623440146446228, acc: 0.8285714387893677)
[2024-11-14 10:32:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:09][root][INFO] - Training Epoch: 2/2, step 15740/16670 completed (loss: 0.1693303883075714, acc: 0.914893627166748)
[2024-11-14 10:32:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:09][root][INFO] - Training Epoch: 2/2, step 15741/16670 completed (loss: 0.04482812061905861, acc: 1.0)
[2024-11-14 10:32:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:09][root][INFO] - Training Epoch: 2/2, step 15742/16670 completed (loss: 0.43964654207229614, acc: 0.8823529481887817)
[2024-11-14 10:32:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:10][root][INFO] - Training Epoch: 2/2, step 15743/16670 completed (loss: 0.559977114200592, acc: 0.9230769276618958)
[2024-11-14 10:32:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:10][root][INFO] - Training Epoch: 2/2, step 15744/16670 completed (loss: 0.967381477355957, acc: 0.8589743375778198)
[2024-11-14 10:32:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:10][root][INFO] - Training Epoch: 2/2, step 15745/16670 completed (loss: 0.4293685853481293, acc: 0.8717948794364929)
[2024-11-14 10:32:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:11][root][INFO] - Training Epoch: 2/2, step 15746/16670 completed (loss: 0.6396937966346741, acc: 0.8484848737716675)
[2024-11-14 10:32:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:11][root][INFO] - Training Epoch: 2/2, step 15747/16670 completed (loss: 0.5038267374038696, acc: 0.8399999737739563)
[2024-11-14 10:32:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:11][root][INFO] - Training Epoch: 2/2, step 15748/16670 completed (loss: 0.06058009713888168, acc: 0.9818181991577148)
[2024-11-14 10:32:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:12][root][INFO] - Training Epoch: 2/2, step 15749/16670 completed (loss: 0.6169098615646362, acc: 0.8648648858070374)
[2024-11-14 10:32:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:12][root][INFO] - Training Epoch: 2/2, step 15750/16670 completed (loss: 0.20473314821720123, acc: 0.9642857313156128)
[2024-11-14 10:32:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:12][root][INFO] - Training Epoch: 2/2, step 15751/16670 completed (loss: 0.3641083538532257, acc: 0.8888888955116272)
[2024-11-14 10:32:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:13][root][INFO] - Training Epoch: 2/2, step 15752/16670 completed (loss: 0.40733614563941956, acc: 0.800000011920929)
[2024-11-14 10:32:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:13][root][INFO] - Training Epoch: 2/2, step 15753/16670 completed (loss: 0.570124089717865, acc: 0.8260869383811951)
[2024-11-14 10:32:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:13][root][INFO] - Training Epoch: 2/2, step 15754/16670 completed (loss: 0.14568819105625153, acc: 0.9411764740943909)
[2024-11-14 10:32:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:14][root][INFO] - Training Epoch: 2/2, step 15755/16670 completed (loss: 0.6392016410827637, acc: 0.8928571343421936)
[2024-11-14 10:32:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:14][root][INFO] - Training Epoch: 2/2, step 15756/16670 completed (loss: 0.33529794216156006, acc: 0.9090909361839294)
[2024-11-14 10:32:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:14][root][INFO] - Training Epoch: 2/2, step 15757/16670 completed (loss: 0.5044026970863342, acc: 0.9130434989929199)
[2024-11-14 10:32:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:15][root][INFO] - Training Epoch: 2/2, step 15758/16670 completed (loss: 0.15006040036678314, acc: 0.9516128897666931)
[2024-11-14 10:32:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:15][root][INFO] - Training Epoch: 2/2, step 15759/16670 completed (loss: 0.1734999269247055, acc: 0.9729729890823364)
[2024-11-14 10:32:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:16][root][INFO] - Training Epoch: 2/2, step 15760/16670 completed (loss: 0.5904941558837891, acc: 0.9032257795333862)
[2024-11-14 10:32:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:16][root][INFO] - Training Epoch: 2/2, step 15761/16670 completed (loss: 0.15160754323005676, acc: 0.9487179517745972)
[2024-11-14 10:32:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:16][root][INFO] - Training Epoch: 2/2, step 15762/16670 completed (loss: 0.4211689233779907, acc: 0.8846153616905212)
[2024-11-14 10:32:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:17][root][INFO] - Training Epoch: 2/2, step 15763/16670 completed (loss: 0.20649346709251404, acc: 0.939393937587738)
[2024-11-14 10:32:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:17][root][INFO] - Training Epoch: 2/2, step 15764/16670 completed (loss: 0.4171057641506195, acc: 0.9318181872367859)
[2024-11-14 10:32:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:17][root][INFO] - Training Epoch: 2/2, step 15765/16670 completed (loss: 0.08118069171905518, acc: 0.9767441749572754)
[2024-11-14 10:32:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:18][root][INFO] - Training Epoch: 2/2, step 15766/16670 completed (loss: 0.16241800785064697, acc: 0.9772727489471436)
[2024-11-14 10:32:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:18][root][INFO] - Training Epoch: 2/2, step 15767/16670 completed (loss: 0.5462332367897034, acc: 0.9180327653884888)
[2024-11-14 10:32:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:19][root][INFO] - Training Epoch: 2/2, step 15768/16670 completed (loss: 0.700965166091919, acc: 0.8510638475418091)
[2024-11-14 10:32:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:19][root][INFO] - Training Epoch: 2/2, step 15769/16670 completed (loss: 0.2956964373588562, acc: 0.9102563858032227)
[2024-11-14 10:32:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:19][root][INFO] - Training Epoch: 2/2, step 15770/16670 completed (loss: 0.18276692926883698, acc: 0.9696969985961914)
[2024-11-14 10:32:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:20][root][INFO] - Training Epoch: 2/2, step 15771/16670 completed (loss: 0.48749324679374695, acc: 0.9090909361839294)
[2024-11-14 10:32:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:20][root][INFO] - Training Epoch: 2/2, step 15772/16670 completed (loss: 0.29100263118743896, acc: 0.9090909361839294)
[2024-11-14 10:32:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:20][root][INFO] - Training Epoch: 2/2, step 15773/16670 completed (loss: 0.2207529991865158, acc: 0.9242424368858337)
[2024-11-14 10:32:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:21][root][INFO] - Training Epoch: 2/2, step 15774/16670 completed (loss: 0.23639044165611267, acc: 0.9666666388511658)
[2024-11-14 10:32:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:21][root][INFO] - Training Epoch: 2/2, step 15775/16670 completed (loss: 0.4026114344596863, acc: 0.9375)
[2024-11-14 10:32:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:22][root][INFO] - Training Epoch: 2/2, step 15776/16670 completed (loss: 0.4607839286327362, acc: 0.8636363744735718)
[2024-11-14 10:32:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:22][root][INFO] - Training Epoch: 2/2, step 15777/16670 completed (loss: 0.2742103338241577, acc: 0.9577465057373047)
[2024-11-14 10:32:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:22][root][INFO] - Training Epoch: 2/2, step 15778/16670 completed (loss: 0.21157117187976837, acc: 1.0)
[2024-11-14 10:32:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:23][root][INFO] - Training Epoch: 2/2, step 15779/16670 completed (loss: 0.2648365795612335, acc: 0.936170220375061)
[2024-11-14 10:32:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:23][root][INFO] - Training Epoch: 2/2, step 15780/16670 completed (loss: 0.11755365878343582, acc: 1.0)
[2024-11-14 10:32:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:23][root][INFO] - Training Epoch: 2/2, step 15781/16670 completed (loss: 0.5887483954429626, acc: 0.8571428656578064)
[2024-11-14 10:32:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:24][root][INFO] - Training Epoch: 2/2, step 15782/16670 completed (loss: 0.2367805689573288, acc: 0.9534883499145508)
[2024-11-14 10:32:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:24][root][INFO] - Training Epoch: 2/2, step 15783/16670 completed (loss: 0.15351489186286926, acc: 0.9638554453849792)
[2024-11-14 10:32:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:24][root][INFO] - Training Epoch: 2/2, step 15784/16670 completed (loss: 0.5258405208587646, acc: 0.9130434989929199)
[2024-11-14 10:32:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:25][root][INFO] - Training Epoch: 2/2, step 15785/16670 completed (loss: 0.059570666402578354, acc: 1.0)
[2024-11-14 10:32:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:25][root][INFO] - Training Epoch: 2/2, step 15786/16670 completed (loss: 0.6070504784584045, acc: 0.8536585569381714)
[2024-11-14 10:32:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:25][root][INFO] - Training Epoch: 2/2, step 15787/16670 completed (loss: 0.04457659646868706, acc: 0.97826087474823)
[2024-11-14 10:32:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:26][root][INFO] - Training Epoch: 2/2, step 15788/16670 completed (loss: 0.6616161465644836, acc: 0.8297872543334961)
[2024-11-14 10:32:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:26][root][INFO] - Training Epoch: 2/2, step 15789/16670 completed (loss: 0.3819640278816223, acc: 0.9599999785423279)
[2024-11-14 10:32:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:26][root][INFO] - Training Epoch: 2/2, step 15790/16670 completed (loss: 0.34079593420028687, acc: 0.9285714030265808)
[2024-11-14 10:32:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:26][root][INFO] - Training Epoch: 2/2, step 15791/16670 completed (loss: 0.5953885912895203, acc: 0.9215686321258545)
[2024-11-14 10:32:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:27][root][INFO] - Training Epoch: 2/2, step 15792/16670 completed (loss: 0.3619179129600525, acc: 0.9200000166893005)
[2024-11-14 10:32:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:27][root][INFO] - Training Epoch: 2/2, step 15793/16670 completed (loss: 0.6947523355484009, acc: 0.8536585569381714)
[2024-11-14 10:32:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:28][root][INFO] - Training Epoch: 2/2, step 15794/16670 completed (loss: 0.9406660199165344, acc: 0.8333333134651184)
[2024-11-14 10:32:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:28][root][INFO] - Training Epoch: 2/2, step 15795/16670 completed (loss: 0.1682814657688141, acc: 0.9375)
[2024-11-14 10:32:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:28][root][INFO] - Training Epoch: 2/2, step 15796/16670 completed (loss: 0.7931529879570007, acc: 0.8285714387893677)
[2024-11-14 10:32:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:29][root][INFO] - Training Epoch: 2/2, step 15797/16670 completed (loss: 0.8581801652908325, acc: 0.8214285969734192)
[2024-11-14 10:32:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:29][root][INFO] - Training Epoch: 2/2, step 15798/16670 completed (loss: 0.5650917887687683, acc: 0.8484848737716675)
[2024-11-14 10:32:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:29][root][INFO] - Training Epoch: 2/2, step 15799/16670 completed (loss: 0.2602179944515228, acc: 0.9125000238418579)
[2024-11-14 10:32:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:30][root][INFO] - Training Epoch: 2/2, step 15800/16670 completed (loss: 0.1305326372385025, acc: 0.9655172228813171)
[2024-11-14 10:32:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:30][root][INFO] - Training Epoch: 2/2, step 15801/16670 completed (loss: 0.437928169965744, acc: 0.8983050584793091)
[2024-11-14 10:32:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:30][root][INFO] - Training Epoch: 2/2, step 15802/16670 completed (loss: 0.16671410202980042, acc: 0.953125)
[2024-11-14 10:32:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:31][root][INFO] - Training Epoch: 2/2, step 15803/16670 completed (loss: 0.1981211155653, acc: 0.9399141669273376)
[2024-11-14 10:32:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:31][root][INFO] - Training Epoch: 2/2, step 15804/16670 completed (loss: 0.15169863402843475, acc: 0.9677419066429138)
[2024-11-14 10:32:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:31][root][INFO] - Training Epoch: 2/2, step 15805/16670 completed (loss: 0.22345077991485596, acc: 0.9405940771102905)
[2024-11-14 10:32:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:32][root][INFO] - Training Epoch: 2/2, step 15806/16670 completed (loss: 0.15706436336040497, acc: 0.9532710313796997)
[2024-11-14 10:32:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:32][root][INFO] - Training Epoch: 2/2, step 15807/16670 completed (loss: 0.19132046401500702, acc: 0.9621211886405945)
[2024-11-14 10:32:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:32][root][INFO] - Training Epoch: 2/2, step 15808/16670 completed (loss: 0.13347063958644867, acc: 0.9635036587715149)
[2024-11-14 10:32:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:33][root][INFO] - Training Epoch: 2/2, step 15809/16670 completed (loss: 0.10806085169315338, acc: 0.9626865386962891)
[2024-11-14 10:32:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:33][root][INFO] - Training Epoch: 2/2, step 15810/16670 completed (loss: 0.13738366961479187, acc: 0.9534883499145508)
[2024-11-14 10:32:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:34][root][INFO] - Training Epoch: 2/2, step 15811/16670 completed (loss: 0.2457415908575058, acc: 0.9166666865348816)
[2024-11-14 10:32:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:34][root][INFO] - Training Epoch: 2/2, step 15812/16670 completed (loss: 0.23161305487155914, acc: 0.9237288236618042)
[2024-11-14 10:32:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:34][root][INFO] - Training Epoch: 2/2, step 15813/16670 completed (loss: 0.095782071352005, acc: 0.9789473414421082)
[2024-11-14 10:32:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:35][root][INFO] - Training Epoch: 2/2, step 15814/16670 completed (loss: 0.2096778005361557, acc: 0.9369369149208069)
[2024-11-14 10:32:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:35][root][INFO] - Training Epoch: 2/2, step 15815/16670 completed (loss: 0.25429224967956543, acc: 0.9175823926925659)
[2024-11-14 10:32:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:35][root][INFO] - Training Epoch: 2/2, step 15816/16670 completed (loss: 0.08343184739351273, acc: 0.9702970385551453)
[2024-11-14 10:32:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:36][root][INFO] - Training Epoch: 2/2, step 15817/16670 completed (loss: 0.09407171607017517, acc: 0.9685863852500916)
[2024-11-14 10:32:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:36][root][INFO] - Training Epoch: 2/2, step 15818/16670 completed (loss: 0.15188373625278473, acc: 0.949999988079071)
[2024-11-14 10:32:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:36][root][INFO] - Training Epoch: 2/2, step 15819/16670 completed (loss: 0.1506168395280838, acc: 0.9664804339408875)
[2024-11-14 10:32:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:37][root][INFO] - Training Epoch: 2/2, step 15820/16670 completed (loss: 0.1447194665670395, acc: 0.9737704992294312)
[2024-11-14 10:32:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:37][root][INFO] - Training Epoch: 2/2, step 15821/16670 completed (loss: 0.2881857752799988, acc: 0.9130434989929199)
[2024-11-14 10:32:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:38][root][INFO] - Training Epoch: 2/2, step 15822/16670 completed (loss: 0.2126825898885727, acc: 0.9516128897666931)
[2024-11-14 10:32:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:38][root][INFO] - Training Epoch: 2/2, step 15823/16670 completed (loss: 0.3412870764732361, acc: 0.9200000166893005)
[2024-11-14 10:32:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:38][root][INFO] - Training Epoch: 2/2, step 15824/16670 completed (loss: 0.07813487946987152, acc: 0.9690265655517578)
[2024-11-14 10:32:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:39][root][INFO] - Training Epoch: 2/2, step 15825/16670 completed (loss: 0.11900754272937775, acc: 0.9661017060279846)
[2024-11-14 10:32:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:39][root][INFO] - Training Epoch: 2/2, step 15826/16670 completed (loss: 0.0747712254524231, acc: 0.9836065769195557)
[2024-11-14 10:32:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:39][root][INFO] - Training Epoch: 2/2, step 15827/16670 completed (loss: 0.21027661859989166, acc: 0.9494949579238892)
[2024-11-14 10:32:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:40][root][INFO] - Training Epoch: 2/2, step 15828/16670 completed (loss: 0.19951818883419037, acc: 0.9626865386962891)
[2024-11-14 10:32:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:40][root][INFO] - Training Epoch: 2/2, step 15829/16670 completed (loss: 0.08903901278972626, acc: 0.9769230484962463)
[2024-11-14 10:32:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:40][root][INFO] - Training Epoch: 2/2, step 15830/16670 completed (loss: 0.1039356216788292, acc: 0.9708737730979919)
[2024-11-14 10:32:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:41][root][INFO] - Training Epoch: 2/2, step 15831/16670 completed (loss: 0.3386491537094116, acc: 0.9059829115867615)
[2024-11-14 10:32:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:41][root][INFO] - Training Epoch: 2/2, step 15832/16670 completed (loss: 0.18186619877815247, acc: 0.9473684430122375)
[2024-11-14 10:32:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:41][root][INFO] - Training Epoch: 2/2, step 15833/16670 completed (loss: 0.07441844046115875, acc: 0.9844720363616943)
[2024-11-14 10:32:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:41][root][INFO] - Training Epoch: 2/2, step 15834/16670 completed (loss: 0.11056211590766907, acc: 0.9615384340286255)
[2024-11-14 10:32:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:42][root][INFO] - Training Epoch: 2/2, step 15835/16670 completed (loss: 0.04151219502091408, acc: 0.9880239367485046)
[2024-11-14 10:32:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:42][root][INFO] - Training Epoch: 2/2, step 15836/16670 completed (loss: 0.25341421365737915, acc: 0.9166666865348816)
[2024-11-14 10:32:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:42][root][INFO] - Training Epoch: 2/2, step 15837/16670 completed (loss: 0.12302950769662857, acc: 0.9696969985961914)
[2024-11-14 10:32:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:43][root][INFO] - Training Epoch: 2/2, step 15838/16670 completed (loss: 0.14573130011558533, acc: 0.9420289993286133)
[2024-11-14 10:32:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:43][root][INFO] - Training Epoch: 2/2, step 15839/16670 completed (loss: 0.1178201213479042, acc: 0.9746835231781006)
[2024-11-14 10:32:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:43][root][INFO] - Training Epoch: 2/2, step 15840/16670 completed (loss: 0.0862167626619339, acc: 0.9720670580863953)
[2024-11-14 10:32:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:44][root][INFO] - Training Epoch: 2/2, step 15841/16670 completed (loss: 0.17929713428020477, acc: 0.9518716335296631)
[2024-11-14 10:32:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:44][root][INFO] - Training Epoch: 2/2, step 15842/16670 completed (loss: 0.13165859878063202, acc: 0.9672130942344666)
[2024-11-14 10:32:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:44][root][INFO] - Training Epoch: 2/2, step 15843/16670 completed (loss: 0.28530019521713257, acc: 0.9170731902122498)
[2024-11-14 10:32:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:45][root][INFO] - Training Epoch: 2/2, step 15844/16670 completed (loss: 0.11912041902542114, acc: 0.9603960514068604)
[2024-11-14 10:32:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:45][root][INFO] - Training Epoch: 2/2, step 15845/16670 completed (loss: 0.4426674544811249, acc: 0.8829787373542786)
[2024-11-14 10:32:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:45][root][INFO] - Training Epoch: 2/2, step 15846/16670 completed (loss: 0.25042569637298584, acc: 0.9508196711540222)
[2024-11-14 10:32:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:46][root][INFO] - Training Epoch: 2/2, step 15847/16670 completed (loss: 0.1713128685951233, acc: 0.9494949579238892)
[2024-11-14 10:32:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:46][root][INFO] - Training Epoch: 2/2, step 15848/16670 completed (loss: 0.22715666890144348, acc: 0.9553571343421936)
[2024-11-14 10:32:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:46][root][INFO] - Training Epoch: 2/2, step 15849/16670 completed (loss: 0.2260817587375641, acc: 0.9354838728904724)
[2024-11-14 10:32:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:47][root][INFO] - Training Epoch: 2/2, step 15850/16670 completed (loss: 0.2934629023075104, acc: 0.9281437397003174)
[2024-11-14 10:32:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:47][root][INFO] - Training Epoch: 2/2, step 15851/16670 completed (loss: 0.15723662078380585, acc: 0.9518518447875977)
[2024-11-14 10:32:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:47][root][INFO] - Training Epoch: 2/2, step 15852/16670 completed (loss: 0.20181870460510254, acc: 0.931034505367279)
[2024-11-14 10:32:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:48][root][INFO] - Training Epoch: 2/2, step 15853/16670 completed (loss: 0.12336011976003647, acc: 0.96875)
[2024-11-14 10:32:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:48][root][INFO] - Training Epoch: 2/2, step 15854/16670 completed (loss: 0.1666553020477295, acc: 0.9593023061752319)
[2024-11-14 10:32:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:48][root][INFO] - Training Epoch: 2/2, step 15855/16670 completed (loss: 0.06770628690719604, acc: 0.9775784611701965)
[2024-11-14 10:32:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:49][root][INFO] - Training Epoch: 2/2, step 15856/16670 completed (loss: 0.20667827129364014, acc: 0.95652174949646)
[2024-11-14 10:32:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:49][root][INFO] - Training Epoch: 2/2, step 15857/16670 completed (loss: 0.4145332872867584, acc: 0.8782608509063721)
[2024-11-14 10:32:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:49][root][INFO] - Training Epoch: 2/2, step 15858/16670 completed (loss: 0.25636565685272217, acc: 0.9368420839309692)
[2024-11-14 10:32:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:50][root][INFO] - Training Epoch: 2/2, step 15859/16670 completed (loss: 0.22627289593219757, acc: 0.9473684430122375)
[2024-11-14 10:32:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:50][root][INFO] - Training Epoch: 2/2, step 15860/16670 completed (loss: 0.16774792969226837, acc: 0.9651162624359131)
[2024-11-14 10:32:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:50][root][INFO] - Training Epoch: 2/2, step 15861/16670 completed (loss: 0.10895267128944397, acc: 0.9800000190734863)
[2024-11-14 10:32:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:51][root][INFO] - Training Epoch: 2/2, step 15862/16670 completed (loss: 0.0654074177145958, acc: 0.9823788404464722)
[2024-11-14 10:32:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:51][root][INFO] - Training Epoch: 2/2, step 15863/16670 completed (loss: 0.17908568680286407, acc: 0.9470587968826294)
[2024-11-14 10:32:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:52][root][INFO] - Training Epoch: 2/2, step 15864/16670 completed (loss: 0.08309422433376312, acc: 0.9793103337287903)
[2024-11-14 10:32:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:52][root][INFO] - Training Epoch: 2/2, step 15865/16670 completed (loss: 0.15399183332920074, acc: 0.9609755873680115)
[2024-11-14 10:32:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:52][root][INFO] - Training Epoch: 2/2, step 15866/16670 completed (loss: 0.15786993503570557, acc: 0.9575757384300232)
[2024-11-14 10:32:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:52][root][INFO] - Training Epoch: 2/2, step 15867/16670 completed (loss: 0.17396330833435059, acc: 0.9489796161651611)
[2024-11-14 10:32:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:53][root][INFO] - Training Epoch: 2/2, step 15868/16670 completed (loss: 0.22027184069156647, acc: 0.957446813583374)
[2024-11-14 10:32:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:53][root][INFO] - Training Epoch: 2/2, step 15869/16670 completed (loss: 0.22312383353710175, acc: 0.9624999761581421)
[2024-11-14 10:32:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:53][root][INFO] - Training Epoch: 2/2, step 15870/16670 completed (loss: 0.057243507355451584, acc: 0.9861111044883728)
[2024-11-14 10:32:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:54][root][INFO] - Training Epoch: 2/2, step 15871/16670 completed (loss: 0.18127617239952087, acc: 0.955974817276001)
[2024-11-14 10:32:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:54][root][INFO] - Training Epoch: 2/2, step 15872/16670 completed (loss: 0.14862865209579468, acc: 0.9638554453849792)
[2024-11-14 10:32:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:55][root][INFO] - Training Epoch: 2/2, step 15873/16670 completed (loss: 0.08876490592956543, acc: 0.9805194735527039)
[2024-11-14 10:32:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:55][root][INFO] - Training Epoch: 2/2, step 15874/16670 completed (loss: 0.16007636487483978, acc: 0.9507389068603516)
[2024-11-14 10:32:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:55][root][INFO] - Training Epoch: 2/2, step 15875/16670 completed (loss: 0.23128965497016907, acc: 0.9142857193946838)
[2024-11-14 10:32:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:56][root][INFO] - Training Epoch: 2/2, step 15876/16670 completed (loss: 0.08530828356742859, acc: 0.9745222926139832)
[2024-11-14 10:32:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:56][root][INFO] - Training Epoch: 2/2, step 15877/16670 completed (loss: 0.04044358804821968, acc: 0.9918032884597778)
[2024-11-14 10:32:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:56][root][INFO] - Training Epoch: 2/2, step 15878/16670 completed (loss: 0.1366644650697708, acc: 0.9809523820877075)
[2024-11-14 10:32:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:56][root][INFO] - Training Epoch: 2/2, step 15879/16670 completed (loss: 0.08582279831171036, acc: 0.96875)
[2024-11-14 10:32:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:57][root][INFO] - Training Epoch: 2/2, step 15880/16670 completed (loss: 0.2401072233915329, acc: 0.9333333373069763)
[2024-11-14 10:32:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:57][root][INFO] - Training Epoch: 2/2, step 15881/16670 completed (loss: 0.11661341041326523, acc: 0.9767441749572754)
[2024-11-14 10:32:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:58][root][INFO] - Training Epoch: 2/2, step 15882/16670 completed (loss: 0.16391699016094208, acc: 0.9504132270812988)
[2024-11-14 10:32:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:58][root][INFO] - Training Epoch: 2/2, step 15883/16670 completed (loss: 0.030773824080824852, acc: 0.9921259880065918)
[2024-11-14 10:32:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:58][root][INFO] - Training Epoch: 2/2, step 15884/16670 completed (loss: 0.17246180772781372, acc: 0.9624060392379761)
[2024-11-14 10:32:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:59][root][INFO] - Training Epoch: 2/2, step 15885/16670 completed (loss: 0.036173850297927856, acc: 0.9906542301177979)
[2024-11-14 10:32:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:59][root][INFO] - Training Epoch: 2/2, step 15886/16670 completed (loss: 0.3594628572463989, acc: 0.8981481194496155)
[2024-11-14 10:32:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:32:59][root][INFO] - Training Epoch: 2/2, step 15887/16670 completed (loss: 0.1464054137468338, acc: 0.9629629850387573)
[2024-11-14 10:32:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:00][root][INFO] - Training Epoch: 2/2, step 15888/16670 completed (loss: 0.18710297346115112, acc: 0.942105233669281)
[2024-11-14 10:33:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:00][root][INFO] - Training Epoch: 2/2, step 15889/16670 completed (loss: 0.3618759512901306, acc: 0.9142857193946838)
[2024-11-14 10:33:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:00][root][INFO] - Training Epoch: 2/2, step 15890/16670 completed (loss: 0.14321449398994446, acc: 0.9292929172515869)
[2024-11-14 10:33:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:01][root][INFO] - Training Epoch: 2/2, step 15891/16670 completed (loss: 0.3444403111934662, acc: 0.8902438879013062)
[2024-11-14 10:33:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:01][root][INFO] - Training Epoch: 2/2, step 15892/16670 completed (loss: 0.10071749985218048, acc: 0.9750000238418579)
[2024-11-14 10:33:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:02][root][INFO] - Training Epoch: 2/2, step 15893/16670 completed (loss: 0.15361659228801727, acc: 0.9444444179534912)
[2024-11-14 10:33:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:02][root][INFO] - Training Epoch: 2/2, step 15894/16670 completed (loss: 0.3532610833644867, acc: 0.891566276550293)
[2024-11-14 10:33:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:02][root][INFO] - Training Epoch: 2/2, step 15895/16670 completed (loss: 0.18069621920585632, acc: 0.9635036587715149)
[2024-11-14 10:33:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:03][root][INFO] - Training Epoch: 2/2, step 15896/16670 completed (loss: 0.1866496205329895, acc: 0.9240506291389465)
[2024-11-14 10:33:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:03][root][INFO] - Training Epoch: 2/2, step 15897/16670 completed (loss: 0.060553718358278275, acc: 0.9756097793579102)
[2024-11-14 10:33:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:03][root][INFO] - Training Epoch: 2/2, step 15898/16670 completed (loss: 0.2554660439491272, acc: 0.9347826242446899)
[2024-11-14 10:33:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:04][root][INFO] - Training Epoch: 2/2, step 15899/16670 completed (loss: 0.1292857974767685, acc: 0.9661017060279846)
[2024-11-14 10:33:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:04][root][INFO] - Training Epoch: 2/2, step 15900/16670 completed (loss: 0.18275676667690277, acc: 0.9459459185600281)
[2024-11-14 10:33:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:04][root][INFO] - Training Epoch: 2/2, step 15901/16670 completed (loss: 0.3810989558696747, acc: 0.8910890817642212)
[2024-11-14 10:33:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:05][root][INFO] - Training Epoch: 2/2, step 15902/16670 completed (loss: 0.3440045118331909, acc: 0.9166666865348816)
[2024-11-14 10:33:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:05][root][INFO] - Training Epoch: 2/2, step 15903/16670 completed (loss: 0.5375219583511353, acc: 0.8351648449897766)
[2024-11-14 10:33:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:05][root][INFO] - Training Epoch: 2/2, step 15904/16670 completed (loss: 0.20557744801044464, acc: 0.9714285731315613)
[2024-11-14 10:33:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:06][root][INFO] - Training Epoch: 2/2, step 15905/16670 completed (loss: 0.14903725683689117, acc: 0.9646017551422119)
[2024-11-14 10:33:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:06][root][INFO] - Training Epoch: 2/2, step 15906/16670 completed (loss: 0.1020561009645462, acc: 0.9677419066429138)
[2024-11-14 10:33:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:06][root][INFO] - Training Epoch: 2/2, step 15907/16670 completed (loss: 0.1375262588262558, acc: 0.971222996711731)
[2024-11-14 10:33:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:07][root][INFO] - Training Epoch: 2/2, step 15908/16670 completed (loss: 0.5827348232269287, acc: 0.8636363744735718)
[2024-11-14 10:33:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:07][root][INFO] - Training Epoch: 2/2, step 15909/16670 completed (loss: 0.16044434905052185, acc: 0.9411764740943909)
[2024-11-14 10:33:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:07][root][INFO] - Training Epoch: 2/2, step 15910/16670 completed (loss: 0.40300700068473816, acc: 0.9144737124443054)
[2024-11-14 10:33:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:08][root][INFO] - Training Epoch: 2/2, step 15911/16670 completed (loss: 0.29397857189178467, acc: 0.9210526347160339)
[2024-11-14 10:33:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:08][root][INFO] - Training Epoch: 2/2, step 15912/16670 completed (loss: 0.08911363035440445, acc: 0.9734513163566589)
[2024-11-14 10:33:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:08][root][INFO] - Training Epoch: 2/2, step 15913/16670 completed (loss: 0.17631472647190094, acc: 0.930232584476471)
[2024-11-14 10:33:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:09][root][INFO] - Training Epoch: 2/2, step 15914/16670 completed (loss: 0.17979204654693604, acc: 0.931506872177124)
[2024-11-14 10:33:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:09][root][INFO] - Training Epoch: 2/2, step 15915/16670 completed (loss: 0.11374124139547348, acc: 0.9743589758872986)
[2024-11-14 10:33:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:09][root][INFO] - Training Epoch: 2/2, step 15916/16670 completed (loss: 0.18700465559959412, acc: 0.9624999761581421)
[2024-11-14 10:33:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:10][root][INFO] - Training Epoch: 2/2, step 15917/16670 completed (loss: 0.3838192820549011, acc: 0.9213483333587646)
[2024-11-14 10:33:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:10][root][INFO] - Training Epoch: 2/2, step 15918/16670 completed (loss: 0.15431450307369232, acc: 0.9502487778663635)
[2024-11-14 10:33:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:10][root][INFO] - Training Epoch: 2/2, step 15919/16670 completed (loss: 0.30661121010780334, acc: 0.8902438879013062)
[2024-11-14 10:33:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:11][root][INFO] - Training Epoch: 2/2, step 15920/16670 completed (loss: 0.19621138274669647, acc: 0.9659090638160706)
[2024-11-14 10:33:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:11][root][INFO] - Training Epoch: 2/2, step 15921/16670 completed (loss: 0.10236754268407822, acc: 0.9726027250289917)
[2024-11-14 10:33:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:11][root][INFO] - Training Epoch: 2/2, step 15922/16670 completed (loss: 0.35371652245521545, acc: 0.9015544056892395)
[2024-11-14 10:33:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:12][root][INFO] - Training Epoch: 2/2, step 15923/16670 completed (loss: 0.18613240122795105, acc: 0.9537037014961243)
[2024-11-14 10:33:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:12][root][INFO] - Training Epoch: 2/2, step 15924/16670 completed (loss: 0.16358856856822968, acc: 0.9594594836235046)
[2024-11-14 10:33:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:12][root][INFO] - Training Epoch: 2/2, step 15925/16670 completed (loss: 0.22013257443904877, acc: 0.9230769276618958)
[2024-11-14 10:33:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:13][root][INFO] - Training Epoch: 2/2, step 15926/16670 completed (loss: 0.12842398881912231, acc: 0.9647058844566345)
[2024-11-14 10:33:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:13][root][INFO] - Training Epoch: 2/2, step 15927/16670 completed (loss: 0.053351737558841705, acc: 0.9871794581413269)
[2024-11-14 10:33:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:13][root][INFO] - Training Epoch: 2/2, step 15928/16670 completed (loss: 0.10992169380187988, acc: 0.9666666388511658)
[2024-11-14 10:33:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:14][root][INFO] - Training Epoch: 2/2, step 15929/16670 completed (loss: 0.09624059498310089, acc: 0.9677419066429138)
[2024-11-14 10:33:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:14][root][INFO] - Training Epoch: 2/2, step 15930/16670 completed (loss: 0.25932249426841736, acc: 0.9145299196243286)
[2024-11-14 10:33:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:15][root][INFO] - Training Epoch: 2/2, step 15931/16670 completed (loss: 0.2253452092409134, acc: 0.9038461446762085)
[2024-11-14 10:33:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:15][root][INFO] - Training Epoch: 2/2, step 15932/16670 completed (loss: 0.209383025765419, acc: 0.9432623982429504)
[2024-11-14 10:33:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:15][root][INFO] - Training Epoch: 2/2, step 15933/16670 completed (loss: 0.37291866540908813, acc: 0.9024389982223511)
[2024-11-14 10:33:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:16][root][INFO] - Training Epoch: 2/2, step 15934/16670 completed (loss: 0.25196608901023865, acc: 0.9047619104385376)
[2024-11-14 10:33:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:16][root][INFO] - Training Epoch: 2/2, step 15935/16670 completed (loss: 0.15501192212104797, acc: 0.9636363387107849)
[2024-11-14 10:33:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:16][root][INFO] - Training Epoch: 2/2, step 15936/16670 completed (loss: 0.2588913142681122, acc: 0.9428571462631226)
[2024-11-14 10:33:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:17][root][INFO] - Training Epoch: 2/2, step 15937/16670 completed (loss: 0.17692360281944275, acc: 0.9441340565681458)
[2024-11-14 10:33:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:17][root][INFO] - Training Epoch: 2/2, step 15938/16670 completed (loss: 0.05311289429664612, acc: 0.9733333587646484)
[2024-11-14 10:33:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:17][root][INFO] - Training Epoch: 2/2, step 15939/16670 completed (loss: 0.2584882378578186, acc: 0.9189189076423645)
[2024-11-14 10:33:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:18][root][INFO] - Training Epoch: 2/2, step 15940/16670 completed (loss: 0.16231735050678253, acc: 0.9405940771102905)
[2024-11-14 10:33:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:18][root][INFO] - Training Epoch: 2/2, step 15941/16670 completed (loss: 0.38461339473724365, acc: 0.90625)
[2024-11-14 10:33:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:18][root][INFO] - Training Epoch: 2/2, step 15942/16670 completed (loss: 0.0642201378941536, acc: 0.9776119589805603)
[2024-11-14 10:33:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:19][root][INFO] - Training Epoch: 2/2, step 15943/16670 completed (loss: 0.0909157320857048, acc: 0.9743589758872986)
[2024-11-14 10:33:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:19][root][INFO] - Training Epoch: 2/2, step 15944/16670 completed (loss: 0.05596769601106644, acc: 0.9803149700164795)
[2024-11-14 10:33:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:19][root][INFO] - Training Epoch: 2/2, step 15945/16670 completed (loss: 0.2987103760242462, acc: 0.932584285736084)
[2024-11-14 10:33:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:20][root][INFO] - Training Epoch: 2/2, step 15946/16670 completed (loss: 0.2803562879562378, acc: 0.9433962106704712)
[2024-11-14 10:33:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:20][root][INFO] - Training Epoch: 2/2, step 15947/16670 completed (loss: 0.16360270977020264, acc: 0.961240291595459)
[2024-11-14 10:33:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:20][root][INFO] - Training Epoch: 2/2, step 15948/16670 completed (loss: 0.1281091421842575, acc: 0.9449541568756104)
[2024-11-14 10:33:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:21][root][INFO] - Training Epoch: 2/2, step 15949/16670 completed (loss: 0.09449180215597153, acc: 0.9834710955619812)
[2024-11-14 10:33:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:21][root][INFO] - Training Epoch: 2/2, step 15950/16670 completed (loss: 0.08628854155540466, acc: 0.9746835231781006)
[2024-11-14 10:33:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:21][root][INFO] - Training Epoch: 2/2, step 15951/16670 completed (loss: 0.24413830041885376, acc: 0.9599999785423279)
[2024-11-14 10:33:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:22][root][INFO] - Training Epoch: 2/2, step 15952/16670 completed (loss: 0.17351704835891724, acc: 0.939130425453186)
[2024-11-14 10:33:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:22][root][INFO] - Training Epoch: 2/2, step 15953/16670 completed (loss: 0.18574567139148712, acc: 0.9507042169570923)
[2024-11-14 10:33:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:22][root][INFO] - Training Epoch: 2/2, step 15954/16670 completed (loss: 0.36793991923332214, acc: 0.891566276550293)
[2024-11-14 10:33:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:23][root][INFO] - Training Epoch: 2/2, step 15955/16670 completed (loss: 0.4029345214366913, acc: 0.9224806427955627)
[2024-11-14 10:33:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:23][root][INFO] - Training Epoch: 2/2, step 15956/16670 completed (loss: 0.14183340966701508, acc: 0.9433962106704712)
[2024-11-14 10:33:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:23][root][INFO] - Training Epoch: 2/2, step 15957/16670 completed (loss: 0.1472466140985489, acc: 0.9647058844566345)
[2024-11-14 10:33:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:24][root][INFO] - Training Epoch: 2/2, step 15958/16670 completed (loss: 0.15037700533866882, acc: 0.9716981053352356)
[2024-11-14 10:33:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:24][root][INFO] - Training Epoch: 2/2, step 15959/16670 completed (loss: 0.31134721636772156, acc: 0.921875)
[2024-11-14 10:33:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:24][root][INFO] - Training Epoch: 2/2, step 15960/16670 completed (loss: 0.10350612550973892, acc: 0.9647058844566345)
[2024-11-14 10:33:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:25][root][INFO] - Training Epoch: 2/2, step 15961/16670 completed (loss: 0.1956821084022522, acc: 0.9242424368858337)
[2024-11-14 10:33:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:25][root][INFO] - Training Epoch: 2/2, step 15962/16670 completed (loss: 0.2016950249671936, acc: 0.925000011920929)
[2024-11-14 10:33:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:25][root][INFO] - Training Epoch: 2/2, step 15963/16670 completed (loss: 0.07323969155550003, acc: 0.9864864945411682)
[2024-11-14 10:33:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:26][root][INFO] - Training Epoch: 2/2, step 15964/16670 completed (loss: 0.16836823523044586, acc: 0.9339622855186462)
[2024-11-14 10:33:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:26][root][INFO] - Training Epoch: 2/2, step 15965/16670 completed (loss: 0.2156931757926941, acc: 0.9111111164093018)
[2024-11-14 10:33:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:26][root][INFO] - Training Epoch: 2/2, step 15966/16670 completed (loss: 0.1948864907026291, acc: 0.9449541568756104)
[2024-11-14 10:33:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:27][root][INFO] - Training Epoch: 2/2, step 15967/16670 completed (loss: 0.08201852440834045, acc: 0.9837398529052734)
[2024-11-14 10:33:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:27][root][INFO] - Training Epoch: 2/2, step 15968/16670 completed (loss: 0.1278625875711441, acc: 0.9615384340286255)
[2024-11-14 10:33:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:27][root][INFO] - Training Epoch: 2/2, step 15969/16670 completed (loss: 0.28818830847740173, acc: 0.9024389982223511)
[2024-11-14 10:33:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:27][root][INFO] - Training Epoch: 2/2, step 15970/16670 completed (loss: 0.20641599595546722, acc: 0.9193548560142517)
[2024-11-14 10:33:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:28][root][INFO] - Training Epoch: 2/2, step 15971/16670 completed (loss: 0.06371348351240158, acc: 0.9781022071838379)
[2024-11-14 10:33:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:28][root][INFO] - Training Epoch: 2/2, step 15972/16670 completed (loss: 0.11949524283409119, acc: 0.9718309640884399)
[2024-11-14 10:33:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:28][root][INFO] - Training Epoch: 2/2, step 15973/16670 completed (loss: 0.23716610670089722, acc: 0.9333333373069763)
[2024-11-14 10:33:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:29][root][INFO] - Training Epoch: 2/2, step 15974/16670 completed (loss: 0.25778359174728394, acc: 0.9450549483299255)
[2024-11-14 10:33:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:29][root][INFO] - Training Epoch: 2/2, step 15975/16670 completed (loss: 0.3628069758415222, acc: 0.9090909361839294)
[2024-11-14 10:33:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:29][root][INFO] - Training Epoch: 2/2, step 15976/16670 completed (loss: 0.12459488958120346, acc: 0.9626865386962891)
[2024-11-14 10:33:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:30][root][INFO] - Training Epoch: 2/2, step 15977/16670 completed (loss: 0.10533607751131058, acc: 0.9605262875556946)
[2024-11-14 10:33:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:30][root][INFO] - Training Epoch: 2/2, step 15978/16670 completed (loss: 0.13184793293476105, acc: 0.9599999785423279)
[2024-11-14 10:33:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:30][root][INFO] - Training Epoch: 2/2, step 15979/16670 completed (loss: 0.2029278725385666, acc: 0.925000011920929)
[2024-11-14 10:33:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:31][root][INFO] - Training Epoch: 2/2, step 15980/16670 completed (loss: 0.08543908596038818, acc: 0.96875)
[2024-11-14 10:33:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:31][root][INFO] - Training Epoch: 2/2, step 15981/16670 completed (loss: 0.2707969844341278, acc: 0.9122806787490845)
[2024-11-14 10:33:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:31][root][INFO] - Training Epoch: 2/2, step 15982/16670 completed (loss: 0.19632363319396973, acc: 0.9450980424880981)
[2024-11-14 10:33:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:32][root][INFO] - Training Epoch: 2/2, step 15983/16670 completed (loss: 0.06797316670417786, acc: 0.9800000190734863)
[2024-11-14 10:33:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:32][root][INFO] - Training Epoch: 2/2, step 15984/16670 completed (loss: 0.2905280888080597, acc: 0.901098906993866)
[2024-11-14 10:33:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:32][root][INFO] - Training Epoch: 2/2, step 15985/16670 completed (loss: 0.2590731084346771, acc: 0.9351851940155029)
[2024-11-14 10:33:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:33][root][INFO] - Training Epoch: 2/2, step 15986/16670 completed (loss: 0.22826692461967468, acc: 0.9519230723381042)
[2024-11-14 10:33:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:33][root][INFO] - Training Epoch: 2/2, step 15987/16670 completed (loss: 0.14018958806991577, acc: 0.978723406791687)
[2024-11-14 10:33:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:33][root][INFO] - Training Epoch: 2/2, step 15988/16670 completed (loss: 0.29295864701271057, acc: 0.8831169009208679)
[2024-11-14 10:33:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:34][root][INFO] - Training Epoch: 2/2, step 15989/16670 completed (loss: 0.30565187335014343, acc: 0.9318181872367859)
[2024-11-14 10:33:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:34][root][INFO] - Training Epoch: 2/2, step 15990/16670 completed (loss: 0.24236245453357697, acc: 0.953125)
[2024-11-14 10:33:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:34][root][INFO] - Training Epoch: 2/2, step 15991/16670 completed (loss: 0.07440363615751266, acc: 0.9885057210922241)
[2024-11-14 10:33:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:35][root][INFO] - Training Epoch: 2/2, step 15992/16670 completed (loss: 0.0937514379620552, acc: 0.9873417615890503)
[2024-11-14 10:33:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:35][root][INFO] - Training Epoch: 2/2, step 15993/16670 completed (loss: 0.26658156514167786, acc: 0.966292142868042)
[2024-11-14 10:33:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:36][root][INFO] - Training Epoch: 2/2, step 15994/16670 completed (loss: 0.21475516259670258, acc: 0.9130434989929199)
[2024-11-14 10:33:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:36][root][INFO] - Training Epoch: 2/2, step 15995/16670 completed (loss: 0.1700311005115509, acc: 0.9404761791229248)
[2024-11-14 10:33:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:36][root][INFO] - Training Epoch: 2/2, step 15996/16670 completed (loss: 0.1914023607969284, acc: 0.9150943160057068)
[2024-11-14 10:33:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:37][root][INFO] - Training Epoch: 2/2, step 15997/16670 completed (loss: 0.07875761389732361, acc: 0.9802631735801697)
[2024-11-14 10:33:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:37][root][INFO] - Training Epoch: 2/2, step 15998/16670 completed (loss: 0.28777366876602173, acc: 0.9464285969734192)
[2024-11-14 10:33:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:37][root][INFO] - Training Epoch: 2/2, step 15999/16670 completed (loss: 0.2627496123313904, acc: 0.8965517282485962)
[2024-11-14 10:33:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:37][root][INFO] - Training Epoch: 2/2, step 16000/16670 completed (loss: 0.07835002988576889, acc: 0.9770992398262024)
[2024-11-14 10:33:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:38][root][INFO] - Training Epoch: 2/2, step 16001/16670 completed (loss: 0.16336071491241455, acc: 0.9754098653793335)
[2024-11-14 10:33:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:38][root][INFO] - Training Epoch: 2/2, step 16002/16670 completed (loss: 0.23009982705116272, acc: 0.9354838728904724)
[2024-11-14 10:33:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:39][root][INFO] - Training Epoch: 2/2, step 16003/16670 completed (loss: 0.09161443263292313, acc: 0.9693877696990967)
[2024-11-14 10:33:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:39][root][INFO] - Training Epoch: 2/2, step 16004/16670 completed (loss: 0.03572876378893852, acc: 0.9886363744735718)
[2024-11-14 10:33:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:39][root][INFO] - Training Epoch: 2/2, step 16005/16670 completed (loss: 0.08979607373476028, acc: 0.984375)
[2024-11-14 10:33:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:40][root][INFO] - Training Epoch: 2/2, step 16006/16670 completed (loss: 0.1749683916568756, acc: 0.9464285969734192)
[2024-11-14 10:33:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:40][root][INFO] - Training Epoch: 2/2, step 16007/16670 completed (loss: 0.19773787260055542, acc: 0.9649122953414917)
[2024-11-14 10:33:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:40][root][INFO] - Training Epoch: 2/2, step 16008/16670 completed (loss: 0.07338530570268631, acc: 0.9629629850387573)
[2024-11-14 10:33:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:41][root][INFO] - Training Epoch: 2/2, step 16009/16670 completed (loss: 0.1804582178592682, acc: 0.9548872113227844)
[2024-11-14 10:33:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:41][root][INFO] - Training Epoch: 2/2, step 16010/16670 completed (loss: 0.1057424247264862, acc: 0.9696969985961914)
[2024-11-14 10:33:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:41][root][INFO] - Training Epoch: 2/2, step 16011/16670 completed (loss: 0.11711093783378601, acc: 0.9718309640884399)
[2024-11-14 10:33:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:42][root][INFO] - Training Epoch: 2/2, step 16012/16670 completed (loss: 0.022822491824626923, acc: 0.9940119981765747)
[2024-11-14 10:33:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:42][root][INFO] - Training Epoch: 2/2, step 16013/16670 completed (loss: 0.20339614152908325, acc: 0.9444444179534912)
[2024-11-14 10:33:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:42][root][INFO] - Training Epoch: 2/2, step 16014/16670 completed (loss: 0.10154636204242706, acc: 0.9825581312179565)
[2024-11-14 10:33:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:43][root][INFO] - Training Epoch: 2/2, step 16015/16670 completed (loss: 0.1493031531572342, acc: 0.9629629850387573)
[2024-11-14 10:33:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:43][root][INFO] - Training Epoch: 2/2, step 16016/16670 completed (loss: 0.1692832112312317, acc: 0.9186046719551086)
[2024-11-14 10:33:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:44][root][INFO] - Training Epoch: 2/2, step 16017/16670 completed (loss: 0.2932743430137634, acc: 0.9285714030265808)
[2024-11-14 10:33:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:44][root][INFO] - Training Epoch: 2/2, step 16018/16670 completed (loss: 0.32804909348487854, acc: 0.9166666865348816)
[2024-11-14 10:33:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:44][root][INFO] - Training Epoch: 2/2, step 16019/16670 completed (loss: 0.1721460372209549, acc: 0.9610894918441772)
[2024-11-14 10:33:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:45][root][INFO] - Training Epoch: 2/2, step 16020/16670 completed (loss: 0.09717711061239243, acc: 0.9757281541824341)
[2024-11-14 10:33:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:45][root][INFO] - Training Epoch: 2/2, step 16021/16670 completed (loss: 0.37051668763160706, acc: 0.9375)
[2024-11-14 10:33:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:45][root][INFO] - Training Epoch: 2/2, step 16022/16670 completed (loss: 0.22637346386909485, acc: 0.9378882050514221)
[2024-11-14 10:33:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:46][root][INFO] - Training Epoch: 2/2, step 16023/16670 completed (loss: 0.1804754137992859, acc: 0.954023003578186)
[2024-11-14 10:33:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:46][root][INFO] - Training Epoch: 2/2, step 16024/16670 completed (loss: 0.4079589545726776, acc: 0.8888888955116272)
[2024-11-14 10:33:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:46][root][INFO] - Training Epoch: 2/2, step 16025/16670 completed (loss: 0.3694831430912018, acc: 0.9230769276618958)
[2024-11-14 10:33:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:47][root][INFO] - Training Epoch: 2/2, step 16026/16670 completed (loss: 0.14856022596359253, acc: 0.9510489702224731)
[2024-11-14 10:33:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:47][root][INFO] - Training Epoch: 2/2, step 16027/16670 completed (loss: 0.13048318028450012, acc: 0.9659863710403442)
[2024-11-14 10:33:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:48][root][INFO] - Training Epoch: 2/2, step 16028/16670 completed (loss: 0.20316968858242035, acc: 0.9444444179534912)
[2024-11-14 10:33:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:48][root][INFO] - Training Epoch: 2/2, step 16029/16670 completed (loss: 0.0967835932970047, acc: 0.9736841917037964)
[2024-11-14 10:33:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:48][root][INFO] - Training Epoch: 2/2, step 16030/16670 completed (loss: 0.2634768486022949, acc: 0.9439252614974976)
[2024-11-14 10:33:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:49][root][INFO] - Training Epoch: 2/2, step 16031/16670 completed (loss: 0.08165466040372849, acc: 0.976331353187561)
[2024-11-14 10:33:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:49][root][INFO] - Training Epoch: 2/2, step 16032/16670 completed (loss: 0.14335404336452484, acc: 0.9671052694320679)
[2024-11-14 10:33:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:49][root][INFO] - Training Epoch: 2/2, step 16033/16670 completed (loss: 0.1607811003923416, acc: 0.9593023061752319)
[2024-11-14 10:33:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:50][root][INFO] - Training Epoch: 2/2, step 16034/16670 completed (loss: 0.07989319413900375, acc: 0.9719626307487488)
[2024-11-14 10:33:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:50][root][INFO] - Training Epoch: 2/2, step 16035/16670 completed (loss: 0.34743237495422363, acc: 0.8888888955116272)
[2024-11-14 10:33:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:51][root][INFO] - Training Epoch: 2/2, step 16036/16670 completed (loss: 0.09244385361671448, acc: 0.96875)
[2024-11-14 10:33:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:51][root][INFO] - Training Epoch: 2/2, step 16037/16670 completed (loss: 0.16278065741062164, acc: 0.9583333134651184)
[2024-11-14 10:33:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:51][root][INFO] - Training Epoch: 2/2, step 16038/16670 completed (loss: 0.25161415338516235, acc: 0.9756097793579102)
[2024-11-14 10:33:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:52][root][INFO] - Training Epoch: 2/2, step 16039/16670 completed (loss: 0.4602508842945099, acc: 0.8999999761581421)
[2024-11-14 10:33:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:52][root][INFO] - Training Epoch: 2/2, step 16040/16670 completed (loss: 0.19519588351249695, acc: 0.9515151381492615)
[2024-11-14 10:33:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:52][root][INFO] - Training Epoch: 2/2, step 16041/16670 completed (loss: 0.11765224486589432, acc: 0.9615384340286255)
[2024-11-14 10:33:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:53][root][INFO] - Training Epoch: 2/2, step 16042/16670 completed (loss: 0.16781792044639587, acc: 0.9528301954269409)
[2024-11-14 10:33:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:53][root][INFO] - Training Epoch: 2/2, step 16043/16670 completed (loss: 0.13868720829486847, acc: 0.9666666388511658)
[2024-11-14 10:33:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:53][root][INFO] - Training Epoch: 2/2, step 16044/16670 completed (loss: 0.18157264590263367, acc: 0.957446813583374)
[2024-11-14 10:33:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:54][root][INFO] - Training Epoch: 2/2, step 16045/16670 completed (loss: 0.16522842645645142, acc: 0.9459459185600281)
[2024-11-14 10:33:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:54][root][INFO] - Training Epoch: 2/2, step 16046/16670 completed (loss: 0.1634548455476761, acc: 0.9450549483299255)
[2024-11-14 10:33:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:54][root][INFO] - Training Epoch: 2/2, step 16047/16670 completed (loss: 0.26844078302383423, acc: 0.9047619104385376)
[2024-11-14 10:33:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:55][root][INFO] - Training Epoch: 2/2, step 16048/16670 completed (loss: 0.4148574471473694, acc: 0.9027777910232544)
[2024-11-14 10:33:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:55][root][INFO] - Training Epoch: 2/2, step 16049/16670 completed (loss: 0.1455264687538147, acc: 0.9649122953414917)
[2024-11-14 10:33:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:55][root][INFO] - Training Epoch: 2/2, step 16050/16670 completed (loss: 0.2414649873971939, acc: 0.9523809552192688)
[2024-11-14 10:33:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:56][root][INFO] - Training Epoch: 2/2, step 16051/16670 completed (loss: 0.2447362095117569, acc: 0.9246231317520142)
[2024-11-14 10:33:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:56][root][INFO] - Training Epoch: 2/2, step 16052/16670 completed (loss: 0.07091391831636429, acc: 0.9898989796638489)
[2024-11-14 10:33:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:56][root][INFO] - Training Epoch: 2/2, step 16053/16670 completed (loss: 0.2783812880516052, acc: 0.8980582356452942)
[2024-11-14 10:33:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:57][root][INFO] - Training Epoch: 2/2, step 16054/16670 completed (loss: 0.24592271447181702, acc: 0.9260355234146118)
[2024-11-14 10:33:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:57][root][INFO] - Training Epoch: 2/2, step 16055/16670 completed (loss: 0.2904951572418213, acc: 0.9166666865348816)
[2024-11-14 10:33:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:57][root][INFO] - Training Epoch: 2/2, step 16056/16670 completed (loss: 0.09885431826114655, acc: 0.9806950092315674)
[2024-11-14 10:33:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:58][root][INFO] - Training Epoch: 2/2, step 16057/16670 completed (loss: 0.14465971291065216, acc: 0.957317054271698)
[2024-11-14 10:33:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:58][root][INFO] - Training Epoch: 2/2, step 16058/16670 completed (loss: 0.14732255041599274, acc: 0.9523809552192688)
[2024-11-14 10:33:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:58][root][INFO] - Training Epoch: 2/2, step 16059/16670 completed (loss: 0.08450216054916382, acc: 0.9744898080825806)
[2024-11-14 10:33:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:59][root][INFO] - Training Epoch: 2/2, step 16060/16670 completed (loss: 0.27087268233299255, acc: 0.9108911156654358)
[2024-11-14 10:33:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:59][root][INFO] - Training Epoch: 2/2, step 16061/16670 completed (loss: 0.1777983158826828, acc: 0.939393937587738)
[2024-11-14 10:33:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:59][root][INFO] - Training Epoch: 2/2, step 16062/16670 completed (loss: 0.01899864338338375, acc: 1.0)
[2024-11-14 10:33:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:33:59][root][INFO] - Training Epoch: 2/2, step 16063/16670 completed (loss: 0.23911842703819275, acc: 0.9009009003639221)
[2024-11-14 10:34:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:00][root][INFO] - Training Epoch: 2/2, step 16064/16670 completed (loss: 0.11275686323642731, acc: 0.961240291595459)
[2024-11-14 10:34:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:00][root][INFO] - Training Epoch: 2/2, step 16065/16670 completed (loss: 0.058733973652124405, acc: 0.977011501789093)
[2024-11-14 10:34:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:00][root][INFO] - Training Epoch: 2/2, step 16066/16670 completed (loss: 0.21485978364944458, acc: 0.9329268336296082)
[2024-11-14 10:34:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:01][root][INFO] - Training Epoch: 2/2, step 16067/16670 completed (loss: 0.36149969696998596, acc: 0.9090909361839294)
[2024-11-14 10:34:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:01][root][INFO] - Training Epoch: 2/2, step 16068/16670 completed (loss: 0.15228956937789917, acc: 0.9715909361839294)
[2024-11-14 10:34:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:02][root][INFO] - Training Epoch: 2/2, step 16069/16670 completed (loss: 0.25980043411254883, acc: 0.9371428489685059)
[2024-11-14 10:34:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:02][root][INFO] - Training Epoch: 2/2, step 16070/16670 completed (loss: 0.3131147027015686, acc: 0.904411792755127)
[2024-11-14 10:34:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:02][root][INFO] - Training Epoch: 2/2, step 16071/16670 completed (loss: 0.21563856303691864, acc: 0.9484127163887024)
[2024-11-14 10:34:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:03][root][INFO] - Training Epoch: 2/2, step 16072/16670 completed (loss: 0.12966078519821167, acc: 0.9672130942344666)
[2024-11-14 10:34:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:03][root][INFO] - Training Epoch: 2/2, step 16073/16670 completed (loss: 0.049868516623973846, acc: 0.9930555820465088)
[2024-11-14 10:34:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:03][root][INFO] - Training Epoch: 2/2, step 16074/16670 completed (loss: 0.1310616284608841, acc: 0.9672897458076477)
[2024-11-14 10:34:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:03][root][INFO] - Training Epoch: 2/2, step 16075/16670 completed (loss: 0.08598516136407852, acc: 0.9864864945411682)
[2024-11-14 10:34:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:04][root][INFO] - Training Epoch: 2/2, step 16076/16670 completed (loss: 0.28301265835762024, acc: 0.9034482836723328)
[2024-11-14 10:34:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:04][root][INFO] - Training Epoch: 2/2, step 16077/16670 completed (loss: 0.07709534466266632, acc: 0.9748743772506714)
[2024-11-14 10:34:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:04][root][INFO] - Training Epoch: 2/2, step 16078/16670 completed (loss: 0.12225304543972015, acc: 0.9553571343421936)
[2024-11-14 10:34:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:05][root][INFO] - Training Epoch: 2/2, step 16079/16670 completed (loss: 0.3075256645679474, acc: 0.8918918967247009)
[2024-11-14 10:34:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:05][root][INFO] - Training Epoch: 2/2, step 16080/16670 completed (loss: 0.21498149633407593, acc: 0.9444444179534912)
[2024-11-14 10:34:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:05][root][INFO] - Training Epoch: 2/2, step 16081/16670 completed (loss: 0.11236518621444702, acc: 0.96875)
[2024-11-14 10:34:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:06][root][INFO] - Training Epoch: 2/2, step 16082/16670 completed (loss: 0.5495578646659851, acc: 0.868852436542511)
[2024-11-14 10:34:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:06][root][INFO] - Training Epoch: 2/2, step 16083/16670 completed (loss: 0.08594603836536407, acc: 0.9910714030265808)
[2024-11-14 10:34:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:07][root][INFO] - Training Epoch: 2/2, step 16084/16670 completed (loss: 0.21408642828464508, acc: 0.9482758641242981)
[2024-11-14 10:34:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:07][root][INFO] - Training Epoch: 2/2, step 16085/16670 completed (loss: 0.5080364942550659, acc: 0.849056601524353)
[2024-11-14 10:34:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:07][root][INFO] - Training Epoch: 2/2, step 16086/16670 completed (loss: 0.3059219419956207, acc: 0.9161290526390076)
[2024-11-14 10:34:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:08][root][INFO] - Training Epoch: 2/2, step 16087/16670 completed (loss: 0.15916407108306885, acc: 0.9612069129943848)
[2024-11-14 10:34:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:08][root][INFO] - Training Epoch: 2/2, step 16088/16670 completed (loss: 0.5996062755584717, acc: 0.8522727489471436)
[2024-11-14 10:34:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:08][root][INFO] - Training Epoch: 2/2, step 16089/16670 completed (loss: 0.16522516310214996, acc: 0.9583333134651184)
[2024-11-14 10:34:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:09][root][INFO] - Training Epoch: 2/2, step 16090/16670 completed (loss: 0.11290641129016876, acc: 0.9694915413856506)
[2024-11-14 10:34:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:09][root][INFO] - Training Epoch: 2/2, step 16091/16670 completed (loss: 0.1292436569929123, acc: 0.9685039520263672)
[2024-11-14 10:34:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:09][root][INFO] - Training Epoch: 2/2, step 16092/16670 completed (loss: 0.1455681174993515, acc: 0.9473684430122375)
[2024-11-14 10:34:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:10][root][INFO] - Training Epoch: 2/2, step 16093/16670 completed (loss: 0.19796502590179443, acc: 0.9569892287254333)
[2024-11-14 10:34:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:10][root][INFO] - Training Epoch: 2/2, step 16094/16670 completed (loss: 0.13087931275367737, acc: 0.9523809552192688)
[2024-11-14 10:34:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:10][root][INFO] - Training Epoch: 2/2, step 16095/16670 completed (loss: 0.15076389908790588, acc: 0.9473684430122375)
[2024-11-14 10:34:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:11][root][INFO] - Training Epoch: 2/2, step 16096/16670 completed (loss: 0.38746845722198486, acc: 0.8958333134651184)
[2024-11-14 10:34:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:11][root][INFO] - Training Epoch: 2/2, step 16097/16670 completed (loss: 0.10344865173101425, acc: 0.982758641242981)
[2024-11-14 10:34:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:11][root][INFO] - Training Epoch: 2/2, step 16098/16670 completed (loss: 0.26512154936790466, acc: 0.9279279112815857)
[2024-11-14 10:34:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:12][root][INFO] - Training Epoch: 2/2, step 16099/16670 completed (loss: 0.032742902636528015, acc: 0.9919999837875366)
[2024-11-14 10:34:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:12][root][INFO] - Training Epoch: 2/2, step 16100/16670 completed (loss: 0.2718338668346405, acc: 0.9395973086357117)
[2024-11-14 10:34:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:12][root][INFO] - Training Epoch: 2/2, step 16101/16670 completed (loss: 0.11973349750041962, acc: 0.9830508232116699)
[2024-11-14 10:34:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:13][root][INFO] - Training Epoch: 2/2, step 16102/16670 completed (loss: 0.3046591877937317, acc: 0.9345238208770752)
[2024-11-14 10:34:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:13][root][INFO] - Training Epoch: 2/2, step 16103/16670 completed (loss: 0.1413862258195877, acc: 0.9640718698501587)
[2024-11-14 10:34:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:14][root][INFO] - Training Epoch: 2/2, step 16104/16670 completed (loss: 0.21286772191524506, acc: 0.9519230723381042)
[2024-11-14 10:34:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:14][root][INFO] - Training Epoch: 2/2, step 16105/16670 completed (loss: 0.2253006249666214, acc: 0.9477611780166626)
[2024-11-14 10:34:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:14][root][INFO] - Training Epoch: 2/2, step 16106/16670 completed (loss: 0.23084184527397156, acc: 0.9430052042007446)
[2024-11-14 10:34:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:15][root][INFO] - Training Epoch: 2/2, step 16107/16670 completed (loss: 0.08560044318437576, acc: 0.9743589758872986)
[2024-11-14 10:34:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:15][root][INFO] - Training Epoch: 2/2, step 16108/16670 completed (loss: 0.4058593809604645, acc: 0.8461538553237915)
[2024-11-14 10:34:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:15][root][INFO] - Training Epoch: 2/2, step 16109/16670 completed (loss: 0.30185407400131226, acc: 0.904347836971283)
[2024-11-14 10:34:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:16][root][INFO] - Training Epoch: 2/2, step 16110/16670 completed (loss: 0.13396425545215607, acc: 0.9556962251663208)
[2024-11-14 10:34:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:16][root][INFO] - Training Epoch: 2/2, step 16111/16670 completed (loss: 0.09616444259881973, acc: 0.9729729890823364)
[2024-11-14 10:34:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:16][root][INFO] - Training Epoch: 2/2, step 16112/16670 completed (loss: 0.1112770065665245, acc: 0.9555555582046509)
[2024-11-14 10:34:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:17][root][INFO] - Training Epoch: 2/2, step 16113/16670 completed (loss: 0.12081454694271088, acc: 0.9717513918876648)
[2024-11-14 10:34:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:17][root][INFO] - Training Epoch: 2/2, step 16114/16670 completed (loss: 0.615330159664154, acc: 0.8560606241226196)
[2024-11-14 10:34:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:17][root][INFO] - Training Epoch: 2/2, step 16115/16670 completed (loss: 0.24124543368816376, acc: 0.9462365508079529)
[2024-11-14 10:34:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:17][root][INFO] - Training Epoch: 2/2, step 16116/16670 completed (loss: 0.06825350970029831, acc: 0.988304078578949)
[2024-11-14 10:34:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:18][root][INFO] - Training Epoch: 2/2, step 16117/16670 completed (loss: 0.2052610218524933, acc: 0.9454545378684998)
[2024-11-14 10:34:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:18][root][INFO] - Training Epoch: 2/2, step 16118/16670 completed (loss: 0.34712135791778564, acc: 0.9354838728904724)
[2024-11-14 10:34:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:19][root][INFO] - Training Epoch: 2/2, step 16119/16670 completed (loss: 0.17591166496276855, acc: 0.9543147087097168)
[2024-11-14 10:34:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:19][root][INFO] - Training Epoch: 2/2, step 16120/16670 completed (loss: 0.21800760924816132, acc: 0.9596773982048035)
[2024-11-14 10:34:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:19][root][INFO] - Training Epoch: 2/2, step 16121/16670 completed (loss: 0.23841995000839233, acc: 0.9354838728904724)
[2024-11-14 10:34:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:20][root][INFO] - Training Epoch: 2/2, step 16122/16670 completed (loss: 0.0984773114323616, acc: 0.970802903175354)
[2024-11-14 10:34:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:20][root][INFO] - Training Epoch: 2/2, step 16123/16670 completed (loss: 0.1519637405872345, acc: 0.9545454382896423)
[2024-11-14 10:34:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:20][root][INFO] - Training Epoch: 2/2, step 16124/16670 completed (loss: 0.12127777934074402, acc: 0.9628252983093262)
[2024-11-14 10:34:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:21][root][INFO] - Training Epoch: 2/2, step 16125/16670 completed (loss: 0.057547420263290405, acc: 0.984000027179718)
[2024-11-14 10:34:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:21][root][INFO] - Training Epoch: 2/2, step 16126/16670 completed (loss: 0.18953268229961395, acc: 0.9514563083648682)
[2024-11-14 10:34:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:21][root][INFO] - Training Epoch: 2/2, step 16127/16670 completed (loss: 0.18279536068439484, acc: 0.9523809552192688)
[2024-11-14 10:34:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:22][root][INFO] - Training Epoch: 2/2, step 16128/16670 completed (loss: 0.059185925871133804, acc: 0.9901960492134094)
[2024-11-14 10:34:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:22][root][INFO] - Training Epoch: 2/2, step 16129/16670 completed (loss: 0.07160935550928116, acc: 0.9747474789619446)
[2024-11-14 10:34:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:22][root][INFO] - Training Epoch: 2/2, step 16130/16670 completed (loss: 0.11594198644161224, acc: 0.9666666388511658)
[2024-11-14 10:34:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:23][root][INFO] - Training Epoch: 2/2, step 16131/16670 completed (loss: 0.23771114647388458, acc: 0.9484536051750183)
[2024-11-14 10:34:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:23][root][INFO] - Training Epoch: 2/2, step 16132/16670 completed (loss: 0.3419809639453888, acc: 0.9019607901573181)
[2024-11-14 10:34:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:23][root][INFO] - Training Epoch: 2/2, step 16133/16670 completed (loss: 0.17490291595458984, acc: 0.9354838728904724)
[2024-11-14 10:34:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:24][root][INFO] - Training Epoch: 2/2, step 16134/16670 completed (loss: 0.1480635106563568, acc: 0.946601927280426)
[2024-11-14 10:34:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:24][root][INFO] - Training Epoch: 2/2, step 16135/16670 completed (loss: 0.10208047181367874, acc: 0.9822485446929932)
[2024-11-14 10:34:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:24][root][INFO] - Training Epoch: 2/2, step 16136/16670 completed (loss: 0.10462313145399094, acc: 0.9642857313156128)
[2024-11-14 10:34:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:25][root][INFO] - Training Epoch: 2/2, step 16137/16670 completed (loss: 0.27515679597854614, acc: 0.9405940771102905)
[2024-11-14 10:34:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:25][root][INFO] - Training Epoch: 2/2, step 16138/16670 completed (loss: 0.15491610765457153, acc: 0.9593495726585388)
[2024-11-14 10:34:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:26][root][INFO] - Training Epoch: 2/2, step 16139/16670 completed (loss: 0.15626078844070435, acc: 0.9515151381492615)
[2024-11-14 10:34:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:26][root][INFO] - Training Epoch: 2/2, step 16140/16670 completed (loss: 0.09167254716157913, acc: 0.9795918464660645)
[2024-11-14 10:34:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:26][root][INFO] - Training Epoch: 2/2, step 16141/16670 completed (loss: 0.21686168015003204, acc: 0.931034505367279)
[2024-11-14 10:34:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:27][root][INFO] - Training Epoch: 2/2, step 16142/16670 completed (loss: 0.1070619598031044, acc: 0.949999988079071)
[2024-11-14 10:34:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:27][root][INFO] - Training Epoch: 2/2, step 16143/16670 completed (loss: 0.15472885966300964, acc: 0.9487179517745972)
[2024-11-14 10:34:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:27][root][INFO] - Training Epoch: 2/2, step 16144/16670 completed (loss: 0.15936608612537384, acc: 0.9556962251663208)
[2024-11-14 10:34:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:28][root][INFO] - Training Epoch: 2/2, step 16145/16670 completed (loss: 0.04605444148182869, acc: 0.9887217879295349)
[2024-11-14 10:34:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:28][root][INFO] - Training Epoch: 2/2, step 16146/16670 completed (loss: 0.24564221501350403, acc: 0.9344262480735779)
[2024-11-14 10:34:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:28][root][INFO] - Training Epoch: 2/2, step 16147/16670 completed (loss: 0.35450488328933716, acc: 0.9426229596138)
[2024-11-14 10:34:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:29][root][INFO] - Training Epoch: 2/2, step 16148/16670 completed (loss: 0.08346417546272278, acc: 0.9791666865348816)
[2024-11-14 10:34:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:29][root][INFO] - Training Epoch: 2/2, step 16149/16670 completed (loss: 0.26455503702163696, acc: 0.9432623982429504)
[2024-11-14 10:34:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:29][root][INFO] - Training Epoch: 2/2, step 16150/16670 completed (loss: 0.25871923565864563, acc: 0.9139072895050049)
[2024-11-14 10:34:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:30][root][INFO] - Training Epoch: 2/2, step 16151/16670 completed (loss: 0.15801867842674255, acc: 0.9677419066429138)
[2024-11-14 10:34:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:30][root][INFO] - Training Epoch: 2/2, step 16152/16670 completed (loss: 0.4885426163673401, acc: 0.8783783912658691)
[2024-11-14 10:34:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:30][root][INFO] - Training Epoch: 2/2, step 16153/16670 completed (loss: 0.1460002213716507, acc: 0.9612675905227661)
[2024-11-14 10:34:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:31][root][INFO] - Training Epoch: 2/2, step 16154/16670 completed (loss: 0.2680578827857971, acc: 0.9299362897872925)
[2024-11-14 10:34:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:31][root][INFO] - Training Epoch: 2/2, step 16155/16670 completed (loss: 0.06438614428043365, acc: 0.9839357137680054)
[2024-11-14 10:34:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:31][root][INFO] - Training Epoch: 2/2, step 16156/16670 completed (loss: 0.08201958984136581, acc: 0.9836065769195557)
[2024-11-14 10:34:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:32][root][INFO] - Training Epoch: 2/2, step 16157/16670 completed (loss: 0.2148885577917099, acc: 0.9320388436317444)
[2024-11-14 10:34:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:32][root][INFO] - Training Epoch: 2/2, step 16158/16670 completed (loss: 0.13755165040493011, acc: 1.0)
[2024-11-14 10:34:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:33][root][INFO] - Training Epoch: 2/2, step 16159/16670 completed (loss: 0.5546365976333618, acc: 0.8600000143051147)
[2024-11-14 10:34:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:33][root][INFO] - Training Epoch: 2/2, step 16160/16670 completed (loss: 0.9956101775169373, acc: 0.779411792755127)
[2024-11-14 10:34:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:33][root][INFO] - Training Epoch: 2/2, step 16161/16670 completed (loss: 0.6596350073814392, acc: 0.9019607901573181)
[2024-11-14 10:34:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:34][root][INFO] - Training Epoch: 2/2, step 16162/16670 completed (loss: 0.7568433284759521, acc: 0.7727272510528564)
[2024-11-14 10:34:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:34][root][INFO] - Training Epoch: 2/2, step 16163/16670 completed (loss: 0.3798893988132477, acc: 0.9189189076423645)
[2024-11-14 10:34:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:34][root][INFO] - Training Epoch: 2/2, step 16164/16670 completed (loss: 0.2459862232208252, acc: 0.914893627166748)
[2024-11-14 10:34:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:35][root][INFO] - Training Epoch: 2/2, step 16165/16670 completed (loss: 0.48350584506988525, acc: 0.8723404407501221)
[2024-11-14 10:34:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:35][root][INFO] - Training Epoch: 2/2, step 16166/16670 completed (loss: 0.4844271242618561, acc: 0.9230769276618958)
[2024-11-14 10:34:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:35][root][INFO] - Training Epoch: 2/2, step 16167/16670 completed (loss: 0.280726820230484, acc: 0.8947368264198303)
[2024-11-14 10:34:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:36][root][INFO] - Training Epoch: 2/2, step 16168/16670 completed (loss: 0.06654583662748337, acc: 0.9868420958518982)
[2024-11-14 10:34:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:36][root][INFO] - Training Epoch: 2/2, step 16169/16670 completed (loss: 0.1585671454668045, acc: 0.930232584476471)
[2024-11-14 10:34:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:36][root][INFO] - Training Epoch: 2/2, step 16170/16670 completed (loss: 0.2701684832572937, acc: 0.9230769276618958)
[2024-11-14 10:34:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:37][root][INFO] - Training Epoch: 2/2, step 16171/16670 completed (loss: 0.6713292002677917, acc: 0.8867924809455872)
[2024-11-14 10:34:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:37][root][INFO] - Training Epoch: 2/2, step 16172/16670 completed (loss: 0.5984914898872375, acc: 0.8734177350997925)
[2024-11-14 10:34:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:37][root][INFO] - Training Epoch: 2/2, step 16173/16670 completed (loss: 0.11737111210823059, acc: 0.9814814925193787)
[2024-11-14 10:34:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:38][root][INFO] - Training Epoch: 2/2, step 16174/16670 completed (loss: 0.7161933183670044, acc: 0.75)
[2024-11-14 10:34:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:38][root][INFO] - Training Epoch: 2/2, step 16175/16670 completed (loss: 0.19543740153312683, acc: 0.9433962106704712)
[2024-11-14 10:34:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:38][root][INFO] - Training Epoch: 2/2, step 16176/16670 completed (loss: 0.2444738894701004, acc: 0.925000011920929)
[2024-11-14 10:34:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:39][root][INFO] - Training Epoch: 2/2, step 16177/16670 completed (loss: 0.11947448551654816, acc: 0.95652174949646)
[2024-11-14 10:34:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:39][root][INFO] - Training Epoch: 2/2, step 16178/16670 completed (loss: 0.8854588270187378, acc: 0.8461538553237915)
[2024-11-14 10:34:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:40][root][INFO] - Training Epoch: 2/2, step 16179/16670 completed (loss: 0.8729645013809204, acc: 0.7647058963775635)
[2024-11-14 10:34:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:40][root][INFO] - Training Epoch: 2/2, step 16180/16670 completed (loss: 0.5910722613334656, acc: 0.8684210777282715)
[2024-11-14 10:34:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:40][root][INFO] - Training Epoch: 2/2, step 16181/16670 completed (loss: 0.05949338525533676, acc: 1.0)
[2024-11-14 10:34:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:40][root][INFO] - Training Epoch: 2/2, step 16182/16670 completed (loss: 0.31465092301368713, acc: 0.9599999785423279)
[2024-11-14 10:34:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:41][root][INFO] - Training Epoch: 2/2, step 16183/16670 completed (loss: 0.5622120499610901, acc: 0.8604651093482971)
[2024-11-14 10:34:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:41][root][INFO] - Training Epoch: 2/2, step 16184/16670 completed (loss: 0.24500113725662231, acc: 0.918367326259613)
[2024-11-14 10:34:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:42][root][INFO] - Training Epoch: 2/2, step 16185/16670 completed (loss: 0.5182496905326843, acc: 0.8548387289047241)
[2024-11-14 10:34:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:42][root][INFO] - Training Epoch: 2/2, step 16186/16670 completed (loss: 0.4348413944244385, acc: 0.9117646813392639)
[2024-11-14 10:34:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:42][root][INFO] - Training Epoch: 2/2, step 16187/16670 completed (loss: 0.6822668313980103, acc: 0.8837209343910217)
[2024-11-14 10:34:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:43][root][INFO] - Training Epoch: 2/2, step 16188/16670 completed (loss: 0.370084285736084, acc: 0.914893627166748)
[2024-11-14 10:34:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:43][root][INFO] - Training Epoch: 2/2, step 16189/16670 completed (loss: 0.26200541853904724, acc: 0.9298245906829834)
[2024-11-14 10:34:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:43][root][INFO] - Training Epoch: 2/2, step 16190/16670 completed (loss: 0.4700283110141754, acc: 0.8983050584793091)
[2024-11-14 10:34:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:44][root][INFO] - Training Epoch: 2/2, step 16191/16670 completed (loss: 0.2808038890361786, acc: 0.949999988079071)
[2024-11-14 10:34:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:44][root][INFO] - Training Epoch: 2/2, step 16192/16670 completed (loss: 0.19455388188362122, acc: 0.9756097793579102)
[2024-11-14 10:34:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:45][root][INFO] - Training Epoch: 2/2, step 16193/16670 completed (loss: 0.5314158201217651, acc: 0.9108911156654358)
[2024-11-14 10:34:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:45][root][INFO] - Training Epoch: 2/2, step 16194/16670 completed (loss: 0.611416757106781, acc: 0.8103448152542114)
[2024-11-14 10:34:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:45][root][INFO] - Training Epoch: 2/2, step 16195/16670 completed (loss: 1.4885814189910889, acc: 0.7346938848495483)
[2024-11-14 10:34:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:45][root][INFO] - Training Epoch: 2/2, step 16196/16670 completed (loss: 0.8273057341575623, acc: 0.875)
[2024-11-14 10:34:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:46][root][INFO] - Training Epoch: 2/2, step 16197/16670 completed (loss: 0.567427933216095, acc: 0.8484848737716675)
[2024-11-14 10:34:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:46][root][INFO] - Training Epoch: 2/2, step 16198/16670 completed (loss: 0.4347679316997528, acc: 0.8823529481887817)
[2024-11-14 10:34:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:47][root][INFO] - Training Epoch: 2/2, step 16199/16670 completed (loss: 0.40044596791267395, acc: 0.9130434989929199)
[2024-11-14 10:34:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:47][root][INFO] - Training Epoch: 2/2, step 16200/16670 completed (loss: 0.2801719605922699, acc: 0.97826087474823)
[2024-11-14 10:34:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:47][root][INFO] - Training Epoch: 2/2, step 16201/16670 completed (loss: 0.19900235533714294, acc: 0.9047619104385376)
[2024-11-14 10:34:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:48][root][INFO] - Training Epoch: 2/2, step 16202/16670 completed (loss: 0.4837641716003418, acc: 0.9069767594337463)
[2024-11-14 10:34:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:48][root][INFO] - Training Epoch: 2/2, step 16203/16670 completed (loss: 0.2051466852426529, acc: 0.9411764740943909)
[2024-11-14 10:34:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:48][root][INFO] - Training Epoch: 2/2, step 16204/16670 completed (loss: 0.5474732518196106, acc: 0.8399999737739563)
[2024-11-14 10:34:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:49][root][INFO] - Training Epoch: 2/2, step 16205/16670 completed (loss: 0.5479989647865295, acc: 0.8863636255264282)
[2024-11-14 10:34:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:49][root][INFO] - Training Epoch: 2/2, step 16206/16670 completed (loss: 0.3021906316280365, acc: 0.9268292784690857)
[2024-11-14 10:34:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:49][root][INFO] - Training Epoch: 2/2, step 16207/16670 completed (loss: 0.3113175630569458, acc: 0.931506872177124)
[2024-11-14 10:34:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:50][root][INFO] - Training Epoch: 2/2, step 16208/16670 completed (loss: 0.09319107979536057, acc: 0.9428571462631226)
[2024-11-14 10:34:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:50][root][INFO] - Training Epoch: 2/2, step 16209/16670 completed (loss: 0.17679649591445923, acc: 0.9411764740943909)
[2024-11-14 10:34:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:50][root][INFO] - Training Epoch: 2/2, step 16210/16670 completed (loss: 0.2937373220920563, acc: 0.9333333373069763)
[2024-11-14 10:34:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:51][root][INFO] - Training Epoch: 2/2, step 16211/16670 completed (loss: 0.5367751717567444, acc: 0.90625)
[2024-11-14 10:34:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:51][root][INFO] - Training Epoch: 2/2, step 16212/16670 completed (loss: 0.27741339802742004, acc: 0.875)
[2024-11-14 10:34:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:51][root][INFO] - Training Epoch: 2/2, step 16213/16670 completed (loss: 0.7155640125274658, acc: 0.8571428656578064)
[2024-11-14 10:34:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:52][root][INFO] - Training Epoch: 2/2, step 16214/16670 completed (loss: 0.5652765035629272, acc: 0.8367347121238708)
[2024-11-14 10:34:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:52][root][INFO] - Training Epoch: 2/2, step 16215/16670 completed (loss: 0.16671858727931976, acc: 0.970588207244873)
[2024-11-14 10:34:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:52][root][INFO] - Training Epoch: 2/2, step 16216/16670 completed (loss: 0.4345244765281677, acc: 0.8999999761581421)
[2024-11-14 10:34:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:53][root][INFO] - Training Epoch: 2/2, step 16217/16670 completed (loss: 0.6338135600090027, acc: 0.8500000238418579)
[2024-11-14 10:34:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:53][root][INFO] - Training Epoch: 2/2, step 16218/16670 completed (loss: 0.17445507645606995, acc: 0.9649122953414917)
[2024-11-14 10:34:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:53][root][INFO] - Training Epoch: 2/2, step 16219/16670 completed (loss: 0.6924821138381958, acc: 0.7924528121948242)
[2024-11-14 10:34:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:54][root][INFO] - Training Epoch: 2/2, step 16220/16670 completed (loss: 0.42675429582595825, acc: 0.949999988079071)
[2024-11-14 10:34:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:54][root][INFO] - Training Epoch: 2/2, step 16221/16670 completed (loss: 0.3442438840866089, acc: 0.9166666865348816)
[2024-11-14 10:34:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:54][root][INFO] - Training Epoch: 2/2, step 16222/16670 completed (loss: 0.6060372591018677, acc: 0.8902438879013062)
[2024-11-14 10:34:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:55][root][INFO] - Training Epoch: 2/2, step 16223/16670 completed (loss: 0.588127613067627, acc: 0.8333333134651184)
[2024-11-14 10:34:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:55][root][INFO] - Training Epoch: 2/2, step 16224/16670 completed (loss: 0.6416062116622925, acc: 0.7857142686843872)
[2024-11-14 10:34:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:55][root][INFO] - Training Epoch: 2/2, step 16225/16670 completed (loss: 0.4902237057685852, acc: 0.8500000238418579)
[2024-11-14 10:34:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:56][root][INFO] - Training Epoch: 2/2, step 16226/16670 completed (loss: 0.2703334391117096, acc: 0.9047619104385376)
[2024-11-14 10:34:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:56][root][INFO] - Training Epoch: 2/2, step 16227/16670 completed (loss: 0.431742787361145, acc: 0.8695651888847351)
[2024-11-14 10:34:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:56][root][INFO] - Training Epoch: 2/2, step 16228/16670 completed (loss: 0.5618304014205933, acc: 0.8125)
[2024-11-14 10:34:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:56][root][INFO] - Training Epoch: 2/2, step 16229/16670 completed (loss: 0.4200095236301422, acc: 0.8571428656578064)
[2024-11-14 10:34:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:57][root][INFO] - Training Epoch: 2/2, step 16230/16670 completed (loss: 0.556959867477417, acc: 0.8571428656578064)
[2024-11-14 10:34:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:57][root][INFO] - Training Epoch: 2/2, step 16231/16670 completed (loss: 0.7119398713111877, acc: 0.7765957713127136)
[2024-11-14 10:34:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:57][root][INFO] - Training Epoch: 2/2, step 16232/16670 completed (loss: 0.47573426365852356, acc: 0.8571428656578064)
[2024-11-14 10:34:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:58][root][INFO] - Training Epoch: 2/2, step 16233/16670 completed (loss: 0.4251352548599243, acc: 0.9259259104728699)
[2024-11-14 10:34:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:58][root][INFO] - Training Epoch: 2/2, step 16234/16670 completed (loss: 0.7763392329216003, acc: 0.8918918967247009)
[2024-11-14 10:34:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:58][root][INFO] - Training Epoch: 2/2, step 16235/16670 completed (loss: 0.16343288123607635, acc: 0.9523809552192688)
[2024-11-14 10:34:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:59][root][INFO] - Training Epoch: 2/2, step 16236/16670 completed (loss: 0.34174564480781555, acc: 0.9024389982223511)
[2024-11-14 10:34:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:59][root][INFO] - Training Epoch: 2/2, step 16237/16670 completed (loss: 0.4117392599582672, acc: 0.8823529481887817)
[2024-11-14 10:34:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:34:59][root][INFO] - Training Epoch: 2/2, step 16238/16670 completed (loss: 0.1641586571931839, acc: 0.931034505367279)
[2024-11-14 10:34:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:00][root][INFO] - Training Epoch: 2/2, step 16239/16670 completed (loss: 0.8344232439994812, acc: 0.8292682766914368)
[2024-11-14 10:35:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:00][root][INFO] - Training Epoch: 2/2, step 16240/16670 completed (loss: 0.8443586230278015, acc: 0.8500000238418579)
[2024-11-14 10:35:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:00][root][INFO] - Training Epoch: 2/2, step 16241/16670 completed (loss: 0.4142369329929352, acc: 0.9399999976158142)
[2024-11-14 10:35:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:01][root][INFO] - Training Epoch: 2/2, step 16242/16670 completed (loss: 0.49088695645332336, acc: 0.8285714387893677)
[2024-11-14 10:35:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:01][root][INFO] - Training Epoch: 2/2, step 16243/16670 completed (loss: 0.43926215171813965, acc: 0.9019607901573181)
[2024-11-14 10:35:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:01][root][INFO] - Training Epoch: 2/2, step 16244/16670 completed (loss: 0.8012780547142029, acc: 0.8999999761581421)
[2024-11-14 10:35:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:02][root][INFO] - Training Epoch: 2/2, step 16245/16670 completed (loss: 0.3558070957660675, acc: 0.9090909361839294)
[2024-11-14 10:35:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:02][root][INFO] - Training Epoch: 2/2, step 16246/16670 completed (loss: 0.6887068152427673, acc: 0.868852436542511)
[2024-11-14 10:35:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:02][root][INFO] - Training Epoch: 2/2, step 16247/16670 completed (loss: 0.23210880160331726, acc: 0.9333333373069763)
[2024-11-14 10:35:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:02][root][INFO] - Training Epoch: 2/2, step 16248/16670 completed (loss: 1.1735268831253052, acc: 0.7333333492279053)
[2024-11-14 10:35:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:03][root][INFO] - Training Epoch: 2/2, step 16249/16670 completed (loss: 0.16965502500534058, acc: 1.0)
[2024-11-14 10:35:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:03][root][INFO] - Training Epoch: 2/2, step 16250/16670 completed (loss: 0.7016838788986206, acc: 0.8809523582458496)
[2024-11-14 10:35:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:03][root][INFO] - Training Epoch: 2/2, step 16251/16670 completed (loss: 0.5853594541549683, acc: 0.8913043737411499)
[2024-11-14 10:35:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:04][root][INFO] - Training Epoch: 2/2, step 16252/16670 completed (loss: 0.6280914545059204, acc: 0.9210526347160339)
[2024-11-14 10:35:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:04][root][INFO] - Training Epoch: 2/2, step 16253/16670 completed (loss: 0.7020047307014465, acc: 0.8387096524238586)
[2024-11-14 10:35:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:04][root][INFO] - Training Epoch: 2/2, step 16254/16670 completed (loss: 0.13389086723327637, acc: 0.9722222089767456)
[2024-11-14 10:35:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:05][root][INFO] - Training Epoch: 2/2, step 16255/16670 completed (loss: 0.45850449800491333, acc: 0.8999999761581421)
[2024-11-14 10:35:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:05][root][INFO] - Training Epoch: 2/2, step 16256/16670 completed (loss: 0.13643868267536163, acc: 0.9354838728904724)
[2024-11-14 10:35:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:05][root][INFO] - Training Epoch: 2/2, step 16257/16670 completed (loss: 0.20313911139965057, acc: 0.9333333373069763)
[2024-11-14 10:35:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:05][root][INFO] - Training Epoch: 2/2, step 16258/16670 completed (loss: 0.06589347869157791, acc: 1.0)
[2024-11-14 10:35:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:06][root][INFO] - Training Epoch: 2/2, step 16259/16670 completed (loss: 0.034396588802337646, acc: 1.0)
[2024-11-14 10:35:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:06][root][INFO] - Training Epoch: 2/2, step 16260/16670 completed (loss: 0.15257753431797028, acc: 0.9629629850387573)
[2024-11-14 10:35:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:06][root][INFO] - Training Epoch: 2/2, step 16261/16670 completed (loss: 0.5384544730186462, acc: 0.8545454740524292)
[2024-11-14 10:35:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:07][root][INFO] - Training Epoch: 2/2, step 16262/16670 completed (loss: 0.28990402817726135, acc: 0.9347826242446899)
[2024-11-14 10:35:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:07][root][INFO] - Training Epoch: 2/2, step 16263/16670 completed (loss: 0.42601361870765686, acc: 0.939393937587738)
[2024-11-14 10:35:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:07][root][INFO] - Training Epoch: 2/2, step 16264/16670 completed (loss: 0.3525659441947937, acc: 0.9076923131942749)
[2024-11-14 10:35:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:07][root][INFO] - Training Epoch: 2/2, step 16265/16670 completed (loss: 0.5137114524841309, acc: 0.8399999737739563)
[2024-11-14 10:35:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:08][root][INFO] - Training Epoch: 2/2, step 16266/16670 completed (loss: 0.8500769734382629, acc: 0.8518518805503845)
[2024-11-14 10:35:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:08][root][INFO] - Training Epoch: 2/2, step 16267/16670 completed (loss: 0.3227183520793915, acc: 0.9210526347160339)
[2024-11-14 10:35:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:08][root][INFO] - Training Epoch: 2/2, step 16268/16670 completed (loss: 0.08710496127605438, acc: 1.0)
[2024-11-14 10:35:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:09][root][INFO] - Training Epoch: 2/2, step 16269/16670 completed (loss: 0.6027963161468506, acc: 0.8999999761581421)
[2024-11-14 10:35:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:09][root][INFO] - Training Epoch: 2/2, step 16270/16670 completed (loss: 0.3035116493701935, acc: 0.9333333373069763)
[2024-11-14 10:35:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:09][root][INFO] - Training Epoch: 2/2, step 16271/16670 completed (loss: 0.3005788028240204, acc: 0.9193548560142517)
[2024-11-14 10:35:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:10][root][INFO] - Training Epoch: 2/2, step 16272/16670 completed (loss: 0.4127157926559448, acc: 0.8846153616905212)
[2024-11-14 10:35:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:10][root][INFO] - Training Epoch: 2/2, step 16273/16670 completed (loss: 0.09655161201953888, acc: 0.9523809552192688)
[2024-11-14 10:35:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:10][root][INFO] - Training Epoch: 2/2, step 16274/16670 completed (loss: 0.47936850786209106, acc: 0.8367347121238708)
[2024-11-14 10:35:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:11][root][INFO] - Training Epoch: 2/2, step 16275/16670 completed (loss: 0.35790351033210754, acc: 0.9137930870056152)
[2024-11-14 10:35:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:11][root][INFO] - Training Epoch: 2/2, step 16276/16670 completed (loss: 0.29037800431251526, acc: 0.9047619104385376)
[2024-11-14 10:35:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:11][root][INFO] - Training Epoch: 2/2, step 16277/16670 completed (loss: 0.19357293844223022, acc: 0.9803921580314636)
[2024-11-14 10:35:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:12][root][INFO] - Training Epoch: 2/2, step 16278/16670 completed (loss: 0.2960255742073059, acc: 0.9122806787490845)
[2024-11-14 10:35:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:12][root][INFO] - Training Epoch: 2/2, step 16279/16670 completed (loss: 0.9110416173934937, acc: 0.7441860437393188)
[2024-11-14 10:35:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:12][root][INFO] - Training Epoch: 2/2, step 16280/16670 completed (loss: 0.28220903873443604, acc: 0.931034505367279)
[2024-11-14 10:35:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:12][root][INFO] - Training Epoch: 2/2, step 16281/16670 completed (loss: 0.31051695346832275, acc: 0.9444444179534912)
[2024-11-14 10:35:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:13][root][INFO] - Training Epoch: 2/2, step 16282/16670 completed (loss: 0.8046184182167053, acc: 0.7948718070983887)
[2024-11-14 10:35:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:13][root][INFO] - Training Epoch: 2/2, step 16283/16670 completed (loss: 0.18722479045391083, acc: 0.9583333134651184)
[2024-11-14 10:35:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:13][root][INFO] - Training Epoch: 2/2, step 16284/16670 completed (loss: 0.6879439949989319, acc: 0.8208954930305481)
[2024-11-14 10:35:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:14][root][INFO] - Training Epoch: 2/2, step 16285/16670 completed (loss: 0.9911649823188782, acc: 0.75)
[2024-11-14 10:35:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:14][root][INFO] - Training Epoch: 2/2, step 16286/16670 completed (loss: 0.3935050368309021, acc: 0.868852436542511)
[2024-11-14 10:35:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:14][root][INFO] - Training Epoch: 2/2, step 16287/16670 completed (loss: 0.6893618106842041, acc: 0.8199999928474426)
[2024-11-14 10:35:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:15][root][INFO] - Training Epoch: 2/2, step 16288/16670 completed (loss: 0.45103827118873596, acc: 0.9113923907279968)
[2024-11-14 10:35:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:15][root][INFO] - Training Epoch: 2/2, step 16289/16670 completed (loss: 0.8356549739837646, acc: 0.7758620977401733)
[2024-11-14 10:35:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:15][root][INFO] - Training Epoch: 2/2, step 16290/16670 completed (loss: 0.12960878014564514, acc: 0.96875)
[2024-11-14 10:35:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:16][root][INFO] - Training Epoch: 2/2, step 16291/16670 completed (loss: 0.7257150411605835, acc: 0.8524590134620667)
[2024-11-14 10:35:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:16][root][INFO] - Training Epoch: 2/2, step 16292/16670 completed (loss: 0.40025779604911804, acc: 0.8799999952316284)
[2024-11-14 10:35:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:16][root][INFO] - Training Epoch: 2/2, step 16293/16670 completed (loss: 0.23179851472377777, acc: 0.8999999761581421)
[2024-11-14 10:35:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:16][root][INFO] - Training Epoch: 2/2, step 16294/16670 completed (loss: 0.3813934326171875, acc: 0.9285714030265808)
[2024-11-14 10:35:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:17][root][INFO] - Training Epoch: 2/2, step 16295/16670 completed (loss: 0.21114075183868408, acc: 0.9117646813392639)
[2024-11-14 10:35:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:17][root][INFO] - Training Epoch: 2/2, step 16296/16670 completed (loss: 0.2423885315656662, acc: 0.9375)
[2024-11-14 10:35:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:17][root][INFO] - Training Epoch: 2/2, step 16297/16670 completed (loss: 0.6579642295837402, acc: 0.8199999928474426)
[2024-11-14 10:35:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:18][root][INFO] - Training Epoch: 2/2, step 16298/16670 completed (loss: 0.1586410403251648, acc: 0.9622641801834106)
[2024-11-14 10:35:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:18][root][INFO] - Training Epoch: 2/2, step 16299/16670 completed (loss: 0.4859883189201355, acc: 0.824999988079071)
[2024-11-14 10:35:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:18][root][INFO] - Training Epoch: 2/2, step 16300/16670 completed (loss: 0.18413640558719635, acc: 0.931034505367279)
[2024-11-14 10:35:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:19][root][INFO] - Training Epoch: 2/2, step 16301/16670 completed (loss: 0.3498331904411316, acc: 0.942307710647583)
[2024-11-14 10:35:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:19][root][INFO] - Training Epoch: 2/2, step 16302/16670 completed (loss: 0.6508475542068481, acc: 0.8095238208770752)
[2024-11-14 10:35:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:19][root][INFO] - Training Epoch: 2/2, step 16303/16670 completed (loss: 0.6500919461250305, acc: 0.8518518805503845)
[2024-11-14 10:35:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:19][root][INFO] - Training Epoch: 2/2, step 16304/16670 completed (loss: 0.6797323226928711, acc: 0.8113207817077637)
[2024-11-14 10:35:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:20][root][INFO] - Training Epoch: 2/2, step 16305/16670 completed (loss: 0.5187241435050964, acc: 0.9166666865348816)
[2024-11-14 10:35:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:20][root][INFO] - Training Epoch: 2/2, step 16306/16670 completed (loss: 0.7364152669906616, acc: 0.8409090638160706)
[2024-11-14 10:35:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:20][root][INFO] - Training Epoch: 2/2, step 16307/16670 completed (loss: 0.35971271991729736, acc: 0.9318181872367859)
[2024-11-14 10:35:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:21][root][INFO] - Training Epoch: 2/2, step 16308/16670 completed (loss: 0.5792838335037231, acc: 0.875)
[2024-11-14 10:35:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:21][root][INFO] - Training Epoch: 2/2, step 16309/16670 completed (loss: 0.3698701858520508, acc: 0.9090909361839294)
[2024-11-14 10:35:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:21][root][INFO] - Training Epoch: 2/2, step 16310/16670 completed (loss: 0.2724820077419281, acc: 0.945652186870575)
[2024-11-14 10:35:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:22][root][INFO] - Training Epoch: 2/2, step 16311/16670 completed (loss: 0.155122309923172, acc: 0.9642857313156128)
[2024-11-14 10:35:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:22][root][INFO] - Training Epoch: 2/2, step 16312/16670 completed (loss: 0.3443894684314728, acc: 0.9090909361839294)
[2024-11-14 10:35:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:22][root][INFO] - Training Epoch: 2/2, step 16313/16670 completed (loss: 0.4478815793991089, acc: 0.875)
[2024-11-14 10:35:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:23][root][INFO] - Training Epoch: 2/2, step 16314/16670 completed (loss: 0.45607954263687134, acc: 0.8974359035491943)
[2024-11-14 10:35:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:23][root][INFO] - Training Epoch: 2/2, step 16315/16670 completed (loss: 0.260637491941452, acc: 0.9411764740943909)
[2024-11-14 10:35:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:23][root][INFO] - Training Epoch: 2/2, step 16316/16670 completed (loss: 0.37407049536705017, acc: 0.920634925365448)
[2024-11-14 10:35:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:23][root][INFO] - Training Epoch: 2/2, step 16317/16670 completed (loss: 0.7647480368614197, acc: 0.8048780560493469)
[2024-11-14 10:35:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:24][root][INFO] - Training Epoch: 2/2, step 16318/16670 completed (loss: 0.17529524862766266, acc: 0.9607843160629272)
[2024-11-14 10:35:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:24][root][INFO] - Training Epoch: 2/2, step 16319/16670 completed (loss: 0.6336950659751892, acc: 0.8591549396514893)
[2024-11-14 10:35:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:24][root][INFO] - Training Epoch: 2/2, step 16320/16670 completed (loss: 0.2855318784713745, acc: 0.9318181872367859)
[2024-11-14 10:35:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:25][root][INFO] - Training Epoch: 2/2, step 16321/16670 completed (loss: 0.35636743903160095, acc: 0.9512194991111755)
[2024-11-14 10:35:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:25][root][INFO] - Training Epoch: 2/2, step 16322/16670 completed (loss: 0.889855146408081, acc: 0.699999988079071)
[2024-11-14 10:35:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:25][root][INFO] - Training Epoch: 2/2, step 16323/16670 completed (loss: 0.4365238547325134, acc: 0.9090909361839294)
[2024-11-14 10:35:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:26][root][INFO] - Training Epoch: 2/2, step 16324/16670 completed (loss: 0.2305273711681366, acc: 0.9122806787490845)
[2024-11-14 10:35:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:26][root][INFO] - Training Epoch: 2/2, step 16325/16670 completed (loss: 0.8478323221206665, acc: 0.800000011920929)
[2024-11-14 10:35:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:26][root][INFO] - Training Epoch: 2/2, step 16326/16670 completed (loss: 0.3626038730144501, acc: 0.9285714030265808)
[2024-11-14 10:35:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:26][root][INFO] - Training Epoch: 2/2, step 16327/16670 completed (loss: 0.749941349029541, acc: 0.8163265585899353)
[2024-11-14 10:35:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:27][root][INFO] - Training Epoch: 2/2, step 16328/16670 completed (loss: 0.19099733233451843, acc: 0.949999988079071)
[2024-11-14 10:35:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:27][root][INFO] - Training Epoch: 2/2, step 16329/16670 completed (loss: 0.4552563428878784, acc: 0.8823529481887817)
[2024-11-14 10:35:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:27][root][INFO] - Training Epoch: 2/2, step 16330/16670 completed (loss: 0.31719955801963806, acc: 0.9024389982223511)
[2024-11-14 10:35:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:28][root][INFO] - Training Epoch: 2/2, step 16331/16670 completed (loss: 0.5233580470085144, acc: 0.8681318759918213)
[2024-11-14 10:35:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:28][root][INFO] - Training Epoch: 2/2, step 16332/16670 completed (loss: 0.7075948119163513, acc: 0.8666666746139526)
[2024-11-14 10:35:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:28][root][INFO] - Training Epoch: 2/2, step 16333/16670 completed (loss: 0.12567734718322754, acc: 0.9743589758872986)
[2024-11-14 10:35:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:29][root][INFO] - Training Epoch: 2/2, step 16334/16670 completed (loss: 0.4724469482898712, acc: 0.8979591727256775)
[2024-11-14 10:35:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:29][root][INFO] - Training Epoch: 2/2, step 16335/16670 completed (loss: 0.6793694496154785, acc: 0.8823529481887817)
[2024-11-14 10:35:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:29][root][INFO] - Training Epoch: 2/2, step 16336/16670 completed (loss: 0.6353399157524109, acc: 0.8666666746139526)
[2024-11-14 10:35:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:30][root][INFO] - Training Epoch: 2/2, step 16337/16670 completed (loss: 0.9400699138641357, acc: 0.8048780560493469)
[2024-11-14 10:35:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:30][root][INFO] - Training Epoch: 2/2, step 16338/16670 completed (loss: 1.0847712755203247, acc: 0.807692289352417)
[2024-11-14 10:35:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:30][root][INFO] - Training Epoch: 2/2, step 16339/16670 completed (loss: 0.4832758605480194, acc: 0.7931034564971924)
[2024-11-14 10:35:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:31][root][INFO] - Training Epoch: 2/2, step 16340/16670 completed (loss: 0.6645723581314087, acc: 0.7948718070983887)
[2024-11-14 10:35:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:31][root][INFO] - Training Epoch: 2/2, step 16341/16670 completed (loss: 0.40244200825691223, acc: 0.8734177350997925)
[2024-11-14 10:35:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:31][root][INFO] - Training Epoch: 2/2, step 16342/16670 completed (loss: 0.6101858019828796, acc: 0.875)
[2024-11-14 10:35:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:31][root][INFO] - Training Epoch: 2/2, step 16343/16670 completed (loss: 0.3678878843784332, acc: 0.9152542352676392)
[2024-11-14 10:35:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:32][root][INFO] - Training Epoch: 2/2, step 16344/16670 completed (loss: 0.12315139919519424, acc: 0.9743589758872986)
[2024-11-14 10:35:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:32][root][INFO] - Training Epoch: 2/2, step 16345/16670 completed (loss: 0.24227511882781982, acc: 0.9482758641242981)
[2024-11-14 10:35:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:32][root][INFO] - Training Epoch: 2/2, step 16346/16670 completed (loss: 0.8529729247093201, acc: 0.7916666865348816)
[2024-11-14 10:35:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:33][root][INFO] - Training Epoch: 2/2, step 16347/16670 completed (loss: 0.4779279828071594, acc: 0.8837209343910217)
[2024-11-14 10:35:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:33][root][INFO] - Training Epoch: 2/2, step 16348/16670 completed (loss: 0.5981729626655579, acc: 0.8571428656578064)
[2024-11-14 10:35:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:33][root][INFO] - Training Epoch: 2/2, step 16349/16670 completed (loss: 0.11426138877868652, acc: 0.9722222089767456)
[2024-11-14 10:35:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:34][root][INFO] - Training Epoch: 2/2, step 16350/16670 completed (loss: 0.13563217222690582, acc: 0.96875)
[2024-11-14 10:35:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:34][root][INFO] - Training Epoch: 2/2, step 16351/16670 completed (loss: 0.3875346779823303, acc: 0.9090909361839294)
[2024-11-14 10:35:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:34][root][INFO] - Training Epoch: 2/2, step 16352/16670 completed (loss: 0.2261633425951004, acc: 0.9285714030265808)
[2024-11-14 10:35:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:34][root][INFO] - Training Epoch: 2/2, step 16353/16670 completed (loss: 0.27297142148017883, acc: 0.9375)
[2024-11-14 10:35:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:35][root][INFO] - Training Epoch: 2/2, step 16354/16670 completed (loss: 0.9719063639640808, acc: 0.8421052694320679)
[2024-11-14 10:35:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:35][root][INFO] - Training Epoch: 2/2, step 16355/16670 completed (loss: 1.4144057035446167, acc: 0.7037037014961243)
[2024-11-14 10:35:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:35][root][INFO] - Training Epoch: 2/2, step 16356/16670 completed (loss: 0.8483063578605652, acc: 0.8285714387893677)
[2024-11-14 10:35:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:36][root][INFO] - Training Epoch: 2/2, step 16357/16670 completed (loss: 0.40439221262931824, acc: 0.8695651888847351)
[2024-11-14 10:35:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:36][root][INFO] - Training Epoch: 2/2, step 16358/16670 completed (loss: 0.42307204008102417, acc: 0.875)
[2024-11-14 10:35:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:36][root][INFO] - Training Epoch: 2/2, step 16359/16670 completed (loss: 0.1730492264032364, acc: 0.953125)
[2024-11-14 10:35:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:37][root][INFO] - Training Epoch: 2/2, step 16360/16670 completed (loss: 0.3481130003929138, acc: 0.9354838728904724)
[2024-11-14 10:35:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:37][root][INFO] - Training Epoch: 2/2, step 16361/16670 completed (loss: 0.218088299036026, acc: 0.9264705777168274)
[2024-11-14 10:35:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:37][root][INFO] - Training Epoch: 2/2, step 16362/16670 completed (loss: 0.5219071507453918, acc: 0.8947368264198303)
[2024-11-14 10:35:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:37][root][INFO] - Training Epoch: 2/2, step 16363/16670 completed (loss: 0.34194090962409973, acc: 0.9074074029922485)
[2024-11-14 10:35:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:38][root][INFO] - Training Epoch: 2/2, step 16364/16670 completed (loss: 0.358150452375412, acc: 0.9038461446762085)
[2024-11-14 10:35:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:38][root][INFO] - Training Epoch: 2/2, step 16365/16670 completed (loss: 0.1223379597067833, acc: 0.9756097793579102)
[2024-11-14 10:35:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:38][root][INFO] - Training Epoch: 2/2, step 16366/16670 completed (loss: 0.4104234576225281, acc: 0.8571428656578064)
[2024-11-14 10:35:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:39][root][INFO] - Training Epoch: 2/2, step 16367/16670 completed (loss: 0.09644174575805664, acc: 0.9459459185600281)
[2024-11-14 10:35:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:39][root][INFO] - Training Epoch: 2/2, step 16368/16670 completed (loss: 0.3663094639778137, acc: 0.925000011920929)
[2024-11-14 10:35:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:39][root][INFO] - Training Epoch: 2/2, step 16369/16670 completed (loss: 0.30982404947280884, acc: 0.9354838728904724)
[2024-11-14 10:35:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:40][root][INFO] - Training Epoch: 2/2, step 16370/16670 completed (loss: 0.0877639651298523, acc: 0.9795918464660645)
[2024-11-14 10:35:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:40][root][INFO] - Training Epoch: 2/2, step 16371/16670 completed (loss: 0.727776050567627, acc: 0.8214285969734192)
[2024-11-14 10:35:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:41][root][INFO] - Training Epoch: 2/2, step 16372/16670 completed (loss: 0.141721710562706, acc: 1.0)
[2024-11-14 10:35:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:41][root][INFO] - Training Epoch: 2/2, step 16373/16670 completed (loss: 0.6582434773445129, acc: 0.8181818127632141)
[2024-11-14 10:35:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:41][root][INFO] - Training Epoch: 2/2, step 16374/16670 completed (loss: 0.2993740439414978, acc: 0.9411764740943909)
[2024-11-14 10:35:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:42][root][INFO] - Training Epoch: 2/2, step 16375/16670 completed (loss: 0.1578909456729889, acc: 0.9444444179534912)
[2024-11-14 10:35:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:42][root][INFO] - Training Epoch: 2/2, step 16376/16670 completed (loss: 0.28193971514701843, acc: 0.875)
[2024-11-14 10:35:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:42][root][INFO] - Training Epoch: 2/2, step 16377/16670 completed (loss: 0.27285847067832947, acc: 0.9333333373069763)
[2024-11-14 10:35:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:43][root][INFO] - Training Epoch: 2/2, step 16378/16670 completed (loss: 0.10244417935609818, acc: 0.96875)
[2024-11-14 10:35:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:43][root][INFO] - Training Epoch: 2/2, step 16379/16670 completed (loss: 0.4477313756942749, acc: 0.9090909361839294)
[2024-11-14 10:35:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:43][root][INFO] - Training Epoch: 2/2, step 16380/16670 completed (loss: 1.1906883716583252, acc: 0.7307692170143127)
[2024-11-14 10:35:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:44][root][INFO] - Training Epoch: 2/2, step 16381/16670 completed (loss: 0.19625048339366913, acc: 0.90625)
[2024-11-14 10:35:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:44][root][INFO] - Training Epoch: 2/2, step 16382/16670 completed (loss: 0.39334768056869507, acc: 0.8823529481887817)
[2024-11-14 10:35:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:44][root][INFO] - Training Epoch: 2/2, step 16383/16670 completed (loss: 0.5726484656333923, acc: 0.8199999928474426)
[2024-11-14 10:35:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:45][root][INFO] - Training Epoch: 2/2, step 16384/16670 completed (loss: 0.4948863089084625, acc: 0.8510638475418091)
[2024-11-14 10:35:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:45][root][INFO] - Training Epoch: 2/2, step 16385/16670 completed (loss: 0.3414788842201233, acc: 0.8928571343421936)
[2024-11-14 10:35:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:46][root][INFO] - Training Epoch: 2/2, step 16386/16670 completed (loss: 0.2565769851207733, acc: 0.9444444179534912)
[2024-11-14 10:35:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:46][root][INFO] - Training Epoch: 2/2, step 16387/16670 completed (loss: 0.3764786720275879, acc: 0.9069767594337463)
[2024-11-14 10:35:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:46][root][INFO] - Training Epoch: 2/2, step 16388/16670 completed (loss: 0.6558277010917664, acc: 0.9032257795333862)
[2024-11-14 10:35:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:47][root][INFO] - Training Epoch: 2/2, step 16389/16670 completed (loss: 0.23920755088329315, acc: 0.9516128897666931)
[2024-11-14 10:35:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:47][root][INFO] - Training Epoch: 2/2, step 16390/16670 completed (loss: 0.33091872930526733, acc: 0.9189189076423645)
[2024-11-14 10:35:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:47][root][INFO] - Training Epoch: 2/2, step 16391/16670 completed (loss: 0.15516610443592072, acc: 0.9591836929321289)
[2024-11-14 10:35:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:48][root][INFO] - Training Epoch: 2/2, step 16392/16670 completed (loss: 0.4839633107185364, acc: 0.9090909361839294)
[2024-11-14 10:35:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:48][root][INFO] - Training Epoch: 2/2, step 16393/16670 completed (loss: 0.07120601832866669, acc: 0.9615384340286255)
[2024-11-14 10:35:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:48][root][INFO] - Training Epoch: 2/2, step 16394/16670 completed (loss: 0.5309296250343323, acc: 0.8630136847496033)
[2024-11-14 10:35:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:49][root][INFO] - Training Epoch: 2/2, step 16395/16670 completed (loss: 0.19335901737213135, acc: 0.930232584476471)
[2024-11-14 10:35:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:49][root][INFO] - Training Epoch: 2/2, step 16396/16670 completed (loss: 0.32821929454803467, acc: 0.8636363744735718)
[2024-11-14 10:35:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:49][root][INFO] - Training Epoch: 2/2, step 16397/16670 completed (loss: 0.27276116609573364, acc: 0.9111111164093018)
[2024-11-14 10:35:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:50][root][INFO] - Training Epoch: 2/2, step 16398/16670 completed (loss: 0.3841535747051239, acc: 0.8823529481887817)
[2024-11-14 10:35:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:50][root][INFO] - Training Epoch: 2/2, step 16399/16670 completed (loss: 0.22761574387550354, acc: 0.9666666388511658)
[2024-11-14 10:35:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:50][root][INFO] - Training Epoch: 2/2, step 16400/16670 completed (loss: 0.14102956652641296, acc: 0.9677419066429138)
[2024-11-14 10:35:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:51][root][INFO] - Training Epoch: 2/2, step 16401/16670 completed (loss: 0.12115569412708282, acc: 0.9411764740943909)
[2024-11-14 10:35:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:51][root][INFO] - Training Epoch: 2/2, step 16402/16670 completed (loss: 0.11316026747226715, acc: 0.9764705896377563)
[2024-11-14 10:35:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:51][root][INFO] - Training Epoch: 2/2, step 16403/16670 completed (loss: 0.594251275062561, acc: 0.8769230842590332)
[2024-11-14 10:35:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:52][root][INFO] - Training Epoch: 2/2, step 16404/16670 completed (loss: 0.04433183744549751, acc: 1.0)
[2024-11-14 10:35:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:52][root][INFO] - Training Epoch: 2/2, step 16405/16670 completed (loss: 0.24399055540561676, acc: 0.9464285969734192)
[2024-11-14 10:35:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:52][root][INFO] - Training Epoch: 2/2, step 16406/16670 completed (loss: 0.28371572494506836, acc: 0.8813559412956238)
[2024-11-14 10:35:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:52][root][INFO] - Training Epoch: 2/2, step 16407/16670 completed (loss: 0.16911379992961884, acc: 0.9130434989929199)
[2024-11-14 10:35:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:53][root][INFO] - Training Epoch: 2/2, step 16408/16670 completed (loss: 0.4208209812641144, acc: 0.9375)
[2024-11-14 10:35:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:53][root][INFO] - Training Epoch: 2/2, step 16409/16670 completed (loss: 0.589030921459198, acc: 0.8571428656578064)
[2024-11-14 10:35:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:53][root][INFO] - Training Epoch: 2/2, step 16410/16670 completed (loss: 0.6180984377861023, acc: 0.8958333134651184)
[2024-11-14 10:35:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:54][root][INFO] - Training Epoch: 2/2, step 16411/16670 completed (loss: 0.34236568212509155, acc: 0.931034505367279)
[2024-11-14 10:35:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:54][root][INFO] - Training Epoch: 2/2, step 16412/16670 completed (loss: 0.3798057734966278, acc: 0.8961039185523987)
[2024-11-14 10:35:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:54][root][INFO] - Training Epoch: 2/2, step 16413/16670 completed (loss: 0.3161033093929291, acc: 0.9333333373069763)
[2024-11-14 10:35:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:55][root][INFO] - Training Epoch: 2/2, step 16414/16670 completed (loss: 0.4300290644168854, acc: 0.8333333134651184)
[2024-11-14 10:35:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:55][root][INFO] - Training Epoch: 2/2, step 16415/16670 completed (loss: 0.6069604754447937, acc: 0.8620689511299133)
[2024-11-14 10:35:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:56][root][INFO] - Training Epoch: 2/2, step 16416/16670 completed (loss: 0.19866760075092316, acc: 0.9259259104728699)
[2024-11-14 10:35:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:56][root][INFO] - Training Epoch: 2/2, step 16417/16670 completed (loss: 0.03146626427769661, acc: 1.0)
[2024-11-14 10:35:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:56][root][INFO] - Training Epoch: 2/2, step 16418/16670 completed (loss: 0.2130410224199295, acc: 0.931034505367279)
[2024-11-14 10:35:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:56][root][INFO] - Training Epoch: 2/2, step 16419/16670 completed (loss: 0.1410551816225052, acc: 0.9166666865348816)
[2024-11-14 10:35:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:57][root][INFO] - Training Epoch: 2/2, step 16420/16670 completed (loss: 0.4481830596923828, acc: 0.8666666746139526)
[2024-11-14 10:35:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:57][root][INFO] - Training Epoch: 2/2, step 16421/16670 completed (loss: 0.2587907612323761, acc: 0.9420289993286133)
[2024-11-14 10:35:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:57][root][INFO] - Training Epoch: 2/2, step 16422/16670 completed (loss: 0.315569132566452, acc: 0.9459459185600281)
[2024-11-14 10:35:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:58][root][INFO] - Training Epoch: 2/2, step 16423/16670 completed (loss: 0.2646907866001129, acc: 0.9032257795333862)
[2024-11-14 10:35:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:58][root][INFO] - Training Epoch: 2/2, step 16424/16670 completed (loss: 0.09623056650161743, acc: 0.9714285731315613)
[2024-11-14 10:35:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:59][root][INFO] - Training Epoch: 2/2, step 16425/16670 completed (loss: 0.8522387742996216, acc: 0.8148148059844971)
[2024-11-14 10:35:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:59][root][INFO] - Training Epoch: 2/2, step 16426/16670 completed (loss: 0.25130778551101685, acc: 0.8999999761581421)
[2024-11-14 10:35:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:35:59][root][INFO] - Training Epoch: 2/2, step 16427/16670 completed (loss: 0.4747164845466614, acc: 0.849056601524353)
[2024-11-14 10:35:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:00][root][INFO] - Training Epoch: 2/2, step 16428/16670 completed (loss: 0.6208871603012085, acc: 0.8199999928474426)
[2024-11-14 10:36:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:00][root][INFO] - Training Epoch: 2/2, step 16429/16670 completed (loss: 0.49588102102279663, acc: 0.8979591727256775)
[2024-11-14 10:36:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:00][root][INFO] - Training Epoch: 2/2, step 16430/16670 completed (loss: 0.39247724413871765, acc: 0.9069767594337463)
[2024-11-14 10:36:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:01][root][INFO] - Training Epoch: 2/2, step 16431/16670 completed (loss: 0.5630959868431091, acc: 0.8409090638160706)
[2024-11-14 10:36:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:01][root][INFO] - Training Epoch: 2/2, step 16432/16670 completed (loss: 0.5974718332290649, acc: 0.8409090638160706)
[2024-11-14 10:36:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:01][root][INFO] - Training Epoch: 2/2, step 16433/16670 completed (loss: 0.11384530365467072, acc: 0.96875)
[2024-11-14 10:36:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:02][root][INFO] - Training Epoch: 2/2, step 16434/16670 completed (loss: 0.3446681797504425, acc: 0.9253731369972229)
[2024-11-14 10:36:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:02][root][INFO] - Training Epoch: 2/2, step 16435/16670 completed (loss: 0.2994236648082733, acc: 0.8695651888847351)
[2024-11-14 10:36:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:02][root][INFO] - Training Epoch: 2/2, step 16436/16670 completed (loss: 0.5248449444770813, acc: 0.9125000238418579)
[2024-11-14 10:36:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:03][root][INFO] - Training Epoch: 2/2, step 16437/16670 completed (loss: 1.020268201828003, acc: 0.7936508059501648)
[2024-11-14 10:36:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:03][root][INFO] - Training Epoch: 2/2, step 16438/16670 completed (loss: 0.48878586292266846, acc: 0.8636363744735718)
[2024-11-14 10:36:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:03][root][INFO] - Training Epoch: 2/2, step 16439/16670 completed (loss: 0.3046976625919342, acc: 0.9259259104728699)
[2024-11-14 10:36:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:04][root][INFO] - Training Epoch: 2/2, step 16440/16670 completed (loss: 0.29858478903770447, acc: 0.8983050584793091)
[2024-11-14 10:36:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:04][root][INFO] - Training Epoch: 2/2, step 16441/16670 completed (loss: 0.43257519602775574, acc: 0.9200000166893005)
[2024-11-14 10:36:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:04][root][INFO] - Training Epoch: 2/2, step 16442/16670 completed (loss: 0.2688908576965332, acc: 0.9090909361839294)
[2024-11-14 10:36:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:05][root][INFO] - Training Epoch: 2/2, step 16443/16670 completed (loss: 0.2986730635166168, acc: 0.9629629850387573)
[2024-11-14 10:36:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:05][root][INFO] - Training Epoch: 2/2, step 16444/16670 completed (loss: 0.20062008500099182, acc: 0.9482758641242981)
[2024-11-14 10:36:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:05][root][INFO] - Training Epoch: 2/2, step 16445/16670 completed (loss: 0.33783218264579773, acc: 0.8679245114326477)
[2024-11-14 10:36:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:06][root][INFO] - Training Epoch: 2/2, step 16446/16670 completed (loss: 0.17839327454566956, acc: 0.9506173133850098)
[2024-11-14 10:36:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:06][root][INFO] - Training Epoch: 2/2, step 16447/16670 completed (loss: 0.8003210425376892, acc: 0.8548387289047241)
[2024-11-14 10:36:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:06][root][INFO] - Training Epoch: 2/2, step 16448/16670 completed (loss: 0.3221414387226105, acc: 0.9487179517745972)
[2024-11-14 10:36:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:07][root][INFO] - Training Epoch: 2/2, step 16449/16670 completed (loss: 1.257399559020996, acc: 0.6666666865348816)
[2024-11-14 10:36:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:07][root][INFO] - Training Epoch: 2/2, step 16450/16670 completed (loss: 0.16026556491851807, acc: 0.9523809552192688)
[2024-11-14 10:36:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:07][root][INFO] - Training Epoch: 2/2, step 16451/16670 completed (loss: 1.0378966331481934, acc: 0.8363636136054993)
[2024-11-14 10:36:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:08][root][INFO] - Training Epoch: 2/2, step 16452/16670 completed (loss: 0.14401085674762726, acc: 0.9558823704719543)
[2024-11-14 10:36:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:08][root][INFO] - Training Epoch: 2/2, step 16453/16670 completed (loss: 0.2684975266456604, acc: 0.9154929518699646)
[2024-11-14 10:36:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:09][root][INFO] - Training Epoch: 2/2, step 16454/16670 completed (loss: 0.7870337963104248, acc: 0.8518518805503845)
[2024-11-14 10:36:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:09][root][INFO] - Training Epoch: 2/2, step 16455/16670 completed (loss: 0.33456993103027344, acc: 0.890625)
[2024-11-14 10:36:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:09][root][INFO] - Training Epoch: 2/2, step 16456/16670 completed (loss: 0.1946835070848465, acc: 0.9622641801834106)
[2024-11-14 10:36:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:10][root][INFO] - Training Epoch: 2/2, step 16457/16670 completed (loss: 0.5357182621955872, acc: 0.8600000143051147)
[2024-11-14 10:36:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:10][root][INFO] - Training Epoch: 2/2, step 16458/16670 completed (loss: 0.27725815773010254, acc: 0.9347826242446899)
[2024-11-14 10:36:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:10][root][INFO] - Training Epoch: 2/2, step 16459/16670 completed (loss: 0.08595359325408936, acc: 0.9523809552192688)
[2024-11-14 10:36:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:11][root][INFO] - Training Epoch: 2/2, step 16460/16670 completed (loss: 0.2972504794597626, acc: 0.921875)
[2024-11-14 10:36:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:11][root][INFO] - Training Epoch: 2/2, step 16461/16670 completed (loss: 0.6565256118774414, acc: 0.8695651888847351)
[2024-11-14 10:36:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:11][root][INFO] - Training Epoch: 2/2, step 16462/16670 completed (loss: 0.09148874133825302, acc: 0.9696969985961914)
[2024-11-14 10:36:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:12][root][INFO] - Training Epoch: 2/2, step 16463/16670 completed (loss: 0.4244804382324219, acc: 0.890625)
[2024-11-14 10:36:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:12][root][INFO] - Training Epoch: 2/2, step 16464/16670 completed (loss: 0.4804801046848297, acc: 0.9107142686843872)
[2024-11-14 10:36:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:13][root][INFO] - Training Epoch: 2/2, step 16465/16670 completed (loss: 0.619942307472229, acc: 0.8913043737411499)
[2024-11-14 10:36:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:13][root][INFO] - Training Epoch: 2/2, step 16466/16670 completed (loss: 0.27921751141548157, acc: 0.8771929740905762)
[2024-11-14 10:36:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:13][root][INFO] - Training Epoch: 2/2, step 16467/16670 completed (loss: 0.19265875220298767, acc: 0.9444444179534912)
[2024-11-14 10:36:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:14][root][INFO] - Training Epoch: 2/2, step 16468/16670 completed (loss: 0.33534926176071167, acc: 0.9230769276618958)
[2024-11-14 10:36:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:14][root][INFO] - Training Epoch: 2/2, step 16469/16670 completed (loss: 0.19441255927085876, acc: 0.949999988079071)
[2024-11-14 10:36:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:14][root][INFO] - Training Epoch: 2/2, step 16470/16670 completed (loss: 0.2910556197166443, acc: 0.9354838728904724)
[2024-11-14 10:36:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:15][root][INFO] - Training Epoch: 2/2, step 16471/16670 completed (loss: 0.24394100904464722, acc: 0.9473684430122375)
[2024-11-14 10:36:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:15][root][INFO] - Training Epoch: 2/2, step 16472/16670 completed (loss: 0.4369397461414337, acc: 0.9038461446762085)
[2024-11-14 10:36:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:15][root][INFO] - Training Epoch: 2/2, step 16473/16670 completed (loss: 0.8124392032623291, acc: 0.78125)
[2024-11-14 10:36:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:16][root][INFO] - Training Epoch: 2/2, step 16474/16670 completed (loss: 1.3888908624649048, acc: 0.6829268336296082)
[2024-11-14 10:36:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:16][root][INFO] - Training Epoch: 2/2, step 16475/16670 completed (loss: 0.45593151450157166, acc: 0.8611111044883728)
[2024-11-14 10:36:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:16][root][INFO] - Training Epoch: 2/2, step 16476/16670 completed (loss: 0.5342973470687866, acc: 0.8999999761581421)
[2024-11-14 10:36:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:17][root][INFO] - Training Epoch: 2/2, step 16477/16670 completed (loss: 0.3151091933250427, acc: 0.8983050584793091)
[2024-11-14 10:36:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:17][root][INFO] - Training Epoch: 2/2, step 16478/16670 completed (loss: 0.4407263696193695, acc: 0.8979591727256775)
[2024-11-14 10:36:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:17][root][INFO] - Training Epoch: 2/2, step 16479/16670 completed (loss: 0.37209296226501465, acc: 0.918367326259613)
[2024-11-14 10:36:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:18][root][INFO] - Training Epoch: 2/2, step 16480/16670 completed (loss: 0.19152529537677765, acc: 0.9090909361839294)
[2024-11-14 10:36:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:18][root][INFO] - Training Epoch: 2/2, step 16481/16670 completed (loss: 0.9924156665802002, acc: 0.7804877758026123)
[2024-11-14 10:36:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:18][root][INFO] - Training Epoch: 2/2, step 16482/16670 completed (loss: 1.5152631998062134, acc: 0.7142857313156128)
[2024-11-14 10:36:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:19][root][INFO] - Training Epoch: 2/2, step 16483/16670 completed (loss: 0.08158541470766068, acc: 0.9767441749572754)
[2024-11-14 10:36:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:19][root][INFO] - Training Epoch: 2/2, step 16484/16670 completed (loss: 0.4052974581718445, acc: 0.8999999761581421)
[2024-11-14 10:36:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:19][root][INFO] - Training Epoch: 2/2, step 16485/16670 completed (loss: 0.2576751112937927, acc: 0.939393937587738)
[2024-11-14 10:36:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:20][root][INFO] - Training Epoch: 2/2, step 16486/16670 completed (loss: 0.2141539752483368, acc: 0.9489796161651611)
[2024-11-14 10:36:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:20][root][INFO] - Training Epoch: 2/2, step 16487/16670 completed (loss: 0.48021069169044495, acc: 0.8510638475418091)
[2024-11-14 10:36:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:20][root][INFO] - Training Epoch: 2/2, step 16488/16670 completed (loss: 0.2820025086402893, acc: 0.9275362491607666)
[2024-11-14 10:36:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:21][root][INFO] - Training Epoch: 2/2, step 16489/16670 completed (loss: 0.47908544540405273, acc: 0.8533333539962769)
[2024-11-14 10:36:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:21][root][INFO] - Training Epoch: 2/2, step 16490/16670 completed (loss: 0.3801593780517578, acc: 0.8727272748947144)
[2024-11-14 10:36:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:21][root][INFO] - Training Epoch: 2/2, step 16491/16670 completed (loss: 0.3761812150478363, acc: 0.920634925365448)
[2024-11-14 10:36:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:22][root][INFO] - Training Epoch: 2/2, step 16492/16670 completed (loss: 0.8160212635993958, acc: 0.8214285969734192)
[2024-11-14 10:36:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:22][root][INFO] - Training Epoch: 2/2, step 16493/16670 completed (loss: 0.3178945481777191, acc: 0.930232584476471)
[2024-11-14 10:36:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:22][root][INFO] - Training Epoch: 2/2, step 16494/16670 completed (loss: 0.36938613653182983, acc: 0.8620689511299133)
[2024-11-14 10:36:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:23][root][INFO] - Training Epoch: 2/2, step 16495/16670 completed (loss: 0.1954999715089798, acc: 0.9534883499145508)
[2024-11-14 10:36:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:23][root][INFO] - Training Epoch: 2/2, step 16496/16670 completed (loss: 0.7297921180725098, acc: 0.8225806355476379)
[2024-11-14 10:36:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:23][root][INFO] - Training Epoch: 2/2, step 16497/16670 completed (loss: 0.515651524066925, acc: 0.8815789222717285)
[2024-11-14 10:36:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:23][root][INFO] - Training Epoch: 2/2, step 16498/16670 completed (loss: 0.14793266355991364, acc: 0.9666666388511658)
[2024-11-14 10:36:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:24][root][INFO] - Training Epoch: 2/2, step 16499/16670 completed (loss: 0.4042854905128479, acc: 0.875)
[2024-11-14 10:36:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:24][root][INFO] - Training Epoch: 2/2, step 16500/16670 completed (loss: 0.1820012778043747, acc: 0.9411764740943909)
[2024-11-14 10:36:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:24][root][INFO] - Training Epoch: 2/2, step 16501/16670 completed (loss: 0.428186297416687, acc: 0.9142857193946838)
[2024-11-14 10:36:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:25][root][INFO] - Training Epoch: 2/2, step 16502/16670 completed (loss: 0.6552759408950806, acc: 0.800000011920929)
[2024-11-14 10:36:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:25][root][INFO] - Training Epoch: 2/2, step 16503/16670 completed (loss: 0.39753663539886475, acc: 0.8709677457809448)
[2024-11-14 10:36:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:25][root][INFO] - Training Epoch: 2/2, step 16504/16670 completed (loss: 0.1666727513074875, acc: 0.9298245906829834)
[2024-11-14 10:36:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:26][root][INFO] - Training Epoch: 2/2, step 16505/16670 completed (loss: 0.18295975029468536, acc: 0.9777777791023254)
[2024-11-14 10:36:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:26][root][INFO] - Training Epoch: 2/2, step 16506/16670 completed (loss: 0.5291231870651245, acc: 0.8870967626571655)
[2024-11-14 10:36:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:26][root][INFO] - Training Epoch: 2/2, step 16507/16670 completed (loss: 0.29079851508140564, acc: 0.9230769276618958)
[2024-11-14 10:36:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:26][root][INFO] - Training Epoch: 2/2, step 16508/16670 completed (loss: 0.29786795377731323, acc: 0.9111111164093018)
[2024-11-14 10:36:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:27][root][INFO] - Training Epoch: 2/2, step 16509/16670 completed (loss: 0.4654936194419861, acc: 0.7878788113594055)
[2024-11-14 10:36:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:27][root][INFO] - Training Epoch: 2/2, step 16510/16670 completed (loss: 0.3317452371120453, acc: 0.931034505367279)
[2024-11-14 10:36:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:27][root][INFO] - Training Epoch: 2/2, step 16511/16670 completed (loss: 0.08189947158098221, acc: 0.9756097793579102)
[2024-11-14 10:36:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:28][root][INFO] - Training Epoch: 2/2, step 16512/16670 completed (loss: 0.7461457848548889, acc: 0.7804877758026123)
[2024-11-14 10:36:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:28][root][INFO] - Training Epoch: 2/2, step 16513/16670 completed (loss: 0.19848085939884186, acc: 0.9166666865348816)
[2024-11-14 10:36:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:28][root][INFO] - Training Epoch: 2/2, step 16514/16670 completed (loss: 0.7463939785957336, acc: 0.8571428656578064)
[2024-11-14 10:36:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:29][root][INFO] - Training Epoch: 2/2, step 16515/16670 completed (loss: 0.8432977795600891, acc: 0.8026315569877625)
[2024-11-14 10:36:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:29][root][INFO] - Training Epoch: 2/2, step 16516/16670 completed (loss: 0.5194531083106995, acc: 0.8644067645072937)
[2024-11-14 10:36:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:29][root][INFO] - Training Epoch: 2/2, step 16517/16670 completed (loss: 0.45250603556632996, acc: 0.8769230842590332)
[2024-11-14 10:36:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:30][root][INFO] - Training Epoch: 2/2, step 16518/16670 completed (loss: 0.2918851971626282, acc: 0.9166666865348816)
[2024-11-14 10:36:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:30][root][INFO] - Training Epoch: 2/2, step 16519/16670 completed (loss: 0.13034197688102722, acc: 0.9661017060279846)
[2024-11-14 10:36:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:30][root][INFO] - Training Epoch: 2/2, step 16520/16670 completed (loss: 2.151588201522827, acc: 0.6521739363670349)
[2024-11-14 10:36:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:30][root][INFO] - Training Epoch: 2/2, step 16521/16670 completed (loss: 0.45172369480133057, acc: 0.8936170339584351)
[2024-11-14 10:36:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:31][root][INFO] - Training Epoch: 2/2, step 16522/16670 completed (loss: 0.5985384583473206, acc: 0.8536585569381714)
[2024-11-14 10:36:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:31][root][INFO] - Training Epoch: 2/2, step 16523/16670 completed (loss: 0.2640257775783539, acc: 0.9324324131011963)
[2024-11-14 10:36:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:31][root][INFO] - Training Epoch: 2/2, step 16524/16670 completed (loss: 0.3482138216495514, acc: 0.8947368264198303)
[2024-11-14 10:36:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:32][root][INFO] - Training Epoch: 2/2, step 16525/16670 completed (loss: 1.1386511325836182, acc: 0.7931034564971924)
[2024-11-14 10:36:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:32][root][INFO] - Training Epoch: 2/2, step 16526/16670 completed (loss: 0.43284955620765686, acc: 0.8805969953536987)
[2024-11-14 10:36:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:32][root][INFO] - Training Epoch: 2/2, step 16527/16670 completed (loss: 0.5338557362556458, acc: 0.8500000238418579)
[2024-11-14 10:36:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:33][root][INFO] - Training Epoch: 2/2, step 16528/16670 completed (loss: 0.14069828391075134, acc: 0.9459459185600281)
[2024-11-14 10:36:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:33][root][INFO] - Training Epoch: 2/2, step 16529/16670 completed (loss: 0.26441559195518494, acc: 0.9696969985961914)
[2024-11-14 10:36:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:33][root][INFO] - Training Epoch: 2/2, step 16530/16670 completed (loss: 0.648693323135376, acc: 0.8548387289047241)
[2024-11-14 10:36:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:34][root][INFO] - Training Epoch: 2/2, step 16531/16670 completed (loss: 0.3709763288497925, acc: 0.9555555582046509)
[2024-11-14 10:36:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:34][root][INFO] - Training Epoch: 2/2, step 16532/16670 completed (loss: 0.4246671795845032, acc: 0.8780487775802612)
[2024-11-14 10:36:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:34][root][INFO] - Training Epoch: 2/2, step 16533/16670 completed (loss: 0.5139145255088806, acc: 0.8428571224212646)
[2024-11-14 10:36:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:35][root][INFO] - Training Epoch: 2/2, step 16534/16670 completed (loss: 0.5004307627677917, acc: 0.9074074029922485)
[2024-11-14 10:36:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:35][root][INFO] - Training Epoch: 2/2, step 16535/16670 completed (loss: 0.40826675295829773, acc: 0.9512194991111755)
[2024-11-14 10:36:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:35][root][INFO] - Training Epoch: 2/2, step 16536/16670 completed (loss: 0.38474616408348083, acc: 0.8888888955116272)
[2024-11-14 10:36:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:35][root][INFO] - Training Epoch: 2/2, step 16537/16670 completed (loss: 1.523425579071045, acc: 0.699999988079071)
[2024-11-14 10:36:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:36][root][INFO] - Training Epoch: 2/2, step 16538/16670 completed (loss: 1.536136269569397, acc: 0.6666666865348816)
[2024-11-14 10:36:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:36][root][INFO] - Training Epoch: 2/2, step 16539/16670 completed (loss: 0.3758561313152313, acc: 0.9215686321258545)
[2024-11-14 10:36:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:36][root][INFO] - Training Epoch: 2/2, step 16540/16670 completed (loss: 0.2719820439815521, acc: 0.9384615421295166)
[2024-11-14 10:36:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:37][root][INFO] - Training Epoch: 2/2, step 16541/16670 completed (loss: 0.36717525124549866, acc: 0.8600000143051147)
[2024-11-14 10:36:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:37][root][INFO] - Training Epoch: 2/2, step 16542/16670 completed (loss: 0.49520087242126465, acc: 0.8399999737739563)
[2024-11-14 10:36:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:38][root][INFO] - Training Epoch: 2/2, step 16543/16670 completed (loss: 0.690003514289856, acc: 0.8548387289047241)
[2024-11-14 10:36:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:38][root][INFO] - Training Epoch: 2/2, step 16544/16670 completed (loss: 0.5565476417541504, acc: 0.7758620977401733)
[2024-11-14 10:36:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:38][root][INFO] - Training Epoch: 2/2, step 16545/16670 completed (loss: 0.5210563540458679, acc: 0.8684210777282715)
[2024-11-14 10:36:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:39][root][INFO] - Training Epoch: 2/2, step 16546/16670 completed (loss: 0.3045659065246582, acc: 0.9076923131942749)
[2024-11-14 10:36:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:39][root][INFO] - Training Epoch: 2/2, step 16547/16670 completed (loss: 0.7090699672698975, acc: 0.8550724387168884)
[2024-11-14 10:36:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:39][root][INFO] - Training Epoch: 2/2, step 16548/16670 completed (loss: 0.2836405634880066, acc: 0.914893627166748)
[2024-11-14 10:36:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:40][root][INFO] - Training Epoch: 2/2, step 16549/16670 completed (loss: 0.45139065384864807, acc: 0.8591549396514893)
[2024-11-14 10:36:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:40][root][INFO] - Training Epoch: 2/2, step 16550/16670 completed (loss: 0.41409239172935486, acc: 0.8421052694320679)
[2024-11-14 10:36:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:40][root][INFO] - Training Epoch: 2/2, step 16551/16670 completed (loss: 0.4060613512992859, acc: 0.8928571343421936)
[2024-11-14 10:36:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:41][root][INFO] - Training Epoch: 2/2, step 16552/16670 completed (loss: 0.21882422268390656, acc: 0.9666666388511658)
[2024-11-14 10:36:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:41][root][INFO] - Training Epoch: 2/2, step 16553/16670 completed (loss: 1.1027225255966187, acc: 0.7222222089767456)
[2024-11-14 10:36:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:41][root][INFO] - Training Epoch: 2/2, step 16554/16670 completed (loss: 0.43848365545272827, acc: 0.8999999761581421)
[2024-11-14 10:36:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:42][root][INFO] - Training Epoch: 2/2, step 16555/16670 completed (loss: 0.12126033753156662, acc: 1.0)
[2024-11-14 10:36:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:42][root][INFO] - Training Epoch: 2/2, step 16556/16670 completed (loss: 0.3416880965232849, acc: 0.9230769276618958)
[2024-11-14 10:36:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:42][root][INFO] - Training Epoch: 2/2, step 16557/16670 completed (loss: 1.0219945907592773, acc: 0.7419354915618896)
[2024-11-14 10:36:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:43][root][INFO] - Training Epoch: 2/2, step 16558/16670 completed (loss: 1.573232889175415, acc: 0.75)
[2024-11-14 10:36:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:43][root][INFO] - Training Epoch: 2/2, step 16559/16670 completed (loss: 0.5079761743545532, acc: 0.9038461446762085)
[2024-11-14 10:36:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:43][root][INFO] - Training Epoch: 2/2, step 16560/16670 completed (loss: 0.3433276116847992, acc: 0.9666666388511658)
[2024-11-14 10:36:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:44][root][INFO] - Training Epoch: 2/2, step 16561/16670 completed (loss: 0.630073606967926, acc: 0.9090909361839294)
[2024-11-14 10:36:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:44][root][INFO] - Training Epoch: 2/2, step 16562/16670 completed (loss: 0.17084252834320068, acc: 0.949999988079071)
[2024-11-14 10:36:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:45][root][INFO] - Training Epoch: 2/2, step 16563/16670 completed (loss: 0.2743014991283417, acc: 0.949999988079071)
[2024-11-14 10:36:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:45][root][INFO] - Training Epoch: 2/2, step 16564/16670 completed (loss: 0.7218930721282959, acc: 0.7368420958518982)
[2024-11-14 10:36:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:45][root][INFO] - Training Epoch: 2/2, step 16565/16670 completed (loss: 0.6285580992698669, acc: 0.8974359035491943)
[2024-11-14 10:36:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:46][root][INFO] - Training Epoch: 2/2, step 16566/16670 completed (loss: 0.2192140817642212, acc: 0.931034505367279)
[2024-11-14 10:36:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:46][root][INFO] - Training Epoch: 2/2, step 16567/16670 completed (loss: 0.30719196796417236, acc: 0.8799999952316284)
[2024-11-14 10:36:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:46][root][INFO] - Training Epoch: 2/2, step 16568/16670 completed (loss: 0.18280796706676483, acc: 0.939393937587738)
[2024-11-14 10:36:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:46][root][INFO] - Training Epoch: 2/2, step 16569/16670 completed (loss: 0.40912097692489624, acc: 0.849056601524353)
[2024-11-14 10:36:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:47][root][INFO] - Training Epoch: 2/2, step 16570/16670 completed (loss: 1.4419994354248047, acc: 0.7692307829856873)
[2024-11-14 10:36:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:47][root][INFO] - Training Epoch: 2/2, step 16571/16670 completed (loss: 0.45900994539260864, acc: 0.9104477763175964)
[2024-11-14 10:36:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:47][root][INFO] - Training Epoch: 2/2, step 16572/16670 completed (loss: 0.511847198009491, acc: 0.9375)
[2024-11-14 10:36:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:48][root][INFO] - Training Epoch: 2/2, step 16573/16670 completed (loss: 0.38124287128448486, acc: 0.8979591727256775)
[2024-11-14 10:36:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:48][root][INFO] - Training Epoch: 2/2, step 16574/16670 completed (loss: 0.5671124458312988, acc: 0.8679245114326477)
[2024-11-14 10:36:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:48][root][INFO] - Training Epoch: 2/2, step 16575/16670 completed (loss: 0.30753061175346375, acc: 0.9285714030265808)
[2024-11-14 10:36:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:49][root][INFO] - Training Epoch: 2/2, step 16576/16670 completed (loss: 0.02544420212507248, acc: 1.0)
[2024-11-14 10:36:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:49][root][INFO] - Training Epoch: 2/2, step 16577/16670 completed (loss: 0.33137890696525574, acc: 0.9555555582046509)
[2024-11-14 10:36:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:49][root][INFO] - Training Epoch: 2/2, step 16578/16670 completed (loss: 0.36076244711875916, acc: 0.9411764740943909)
[2024-11-14 10:36:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:50][root][INFO] - Training Epoch: 2/2, step 16579/16670 completed (loss: 0.6056592464447021, acc: 0.8888888955116272)
[2024-11-14 10:36:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:50][root][INFO] - Training Epoch: 2/2, step 16580/16670 completed (loss: 0.47314465045928955, acc: 0.9038461446762085)
[2024-11-14 10:36:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:50][root][INFO] - Training Epoch: 2/2, step 16581/16670 completed (loss: 0.391019731760025, acc: 0.9272727370262146)
[2024-11-14 10:36:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:51][root][INFO] - Training Epoch: 2/2, step 16582/16670 completed (loss: 0.5127306580543518, acc: 0.9032257795333862)
[2024-11-14 10:36:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:51][root][INFO] - Training Epoch: 2/2, step 16583/16670 completed (loss: 0.8553112149238586, acc: 0.8113207817077637)
[2024-11-14 10:36:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:51][root][INFO] - Training Epoch: 2/2, step 16584/16670 completed (loss: 0.5237470269203186, acc: 0.8333333134651184)
[2024-11-14 10:36:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:52][root][INFO] - Training Epoch: 2/2, step 16585/16670 completed (loss: 0.3656686544418335, acc: 0.9259259104728699)
[2024-11-14 10:36:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:52][root][INFO] - Training Epoch: 2/2, step 16586/16670 completed (loss: 0.11918049305677414, acc: 0.9649122953414917)
[2024-11-14 10:36:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:52][root][INFO] - Training Epoch: 2/2, step 16587/16670 completed (loss: 0.7690823078155518, acc: 0.8181818127632141)
[2024-11-14 10:36:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:53][root][INFO] - Training Epoch: 2/2, step 16588/16670 completed (loss: 0.4596460461616516, acc: 0.8888888955116272)
[2024-11-14 10:36:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:53][root][INFO] - Training Epoch: 2/2, step 16589/16670 completed (loss: 0.04314234107732773, acc: 1.0)
[2024-11-14 10:36:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:53][root][INFO] - Training Epoch: 2/2, step 16590/16670 completed (loss: 0.8685470819473267, acc: 0.7857142686843872)
[2024-11-14 10:36:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:54][root][INFO] - Training Epoch: 2/2, step 16591/16670 completed (loss: 0.305453360080719, acc: 0.9729729890823364)
[2024-11-14 10:36:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:54][root][INFO] - Training Epoch: 2/2, step 16592/16670 completed (loss: 0.2495059072971344, acc: 0.8999999761581421)
[2024-11-14 10:36:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:54][root][INFO] - Training Epoch: 2/2, step 16593/16670 completed (loss: 0.14911013841629028, acc: 0.9268292784690857)
[2024-11-14 10:36:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:55][root][INFO] - Training Epoch: 2/2, step 16594/16670 completed (loss: 0.23995476961135864, acc: 0.9166666865348816)
[2024-11-14 10:36:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:55][root][INFO] - Training Epoch: 2/2, step 16595/16670 completed (loss: 0.3703436851501465, acc: 0.9215686321258545)
[2024-11-14 10:36:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:56][root][INFO] - Training Epoch: 2/2, step 16596/16670 completed (loss: 0.2214944213628769, acc: 0.9545454382896423)
[2024-11-14 10:36:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:56][root][INFO] - Training Epoch: 2/2, step 16597/16670 completed (loss: 1.051466703414917, acc: 0.7083333134651184)
[2024-11-14 10:36:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:56][root][INFO] - Training Epoch: 2/2, step 16598/16670 completed (loss: 0.3913016617298126, acc: 0.9230769276618958)
[2024-11-14 10:36:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:57][root][INFO] - Training Epoch: 2/2, step 16599/16670 completed (loss: 0.17672087252140045, acc: 0.9642857313156128)
[2024-11-14 10:36:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:57][root][INFO] - Training Epoch: 2/2, step 16600/16670 completed (loss: 0.13504411280155182, acc: 1.0)
[2024-11-14 10:36:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:57][root][INFO] - Training Epoch: 2/2, step 16601/16670 completed (loss: 0.9976759552955627, acc: 0.7647058963775635)
[2024-11-14 10:36:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:58][root][INFO] - Training Epoch: 2/2, step 16602/16670 completed (loss: 0.2527165114879608, acc: 0.9642857313156128)
[2024-11-14 10:36:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:58][root][INFO] - Training Epoch: 2/2, step 16603/16670 completed (loss: 0.18553122878074646, acc: 0.9555555582046509)
[2024-11-14 10:36:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:58][root][INFO] - Training Epoch: 2/2, step 16604/16670 completed (loss: 0.5386698842048645, acc: 0.875)
[2024-11-14 10:36:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:58][root][INFO] - Training Epoch: 2/2, step 16605/16670 completed (loss: 0.17041286826133728, acc: 0.9454545378684998)
[2024-11-14 10:36:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:59][root][INFO] - Training Epoch: 2/2, step 16606/16670 completed (loss: 0.3656446933746338, acc: 0.9090909361839294)
[2024-11-14 10:36:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:36:59][root][INFO] - Training Epoch: 2/2, step 16607/16670 completed (loss: 0.18250516057014465, acc: 0.9512194991111755)
[2024-11-14 10:36:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:00][root][INFO] - Training Epoch: 2/2, step 16608/16670 completed (loss: 0.48197197914123535, acc: 0.890625)
[2024-11-14 10:37:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:00][root][INFO] - Training Epoch: 2/2, step 16609/16670 completed (loss: 0.9045884013175964, acc: 0.8157894611358643)
[2024-11-14 10:37:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:00][root][INFO] - Training Epoch: 2/2, step 16610/16670 completed (loss: 0.19864465296268463, acc: 0.939393937587738)
[2024-11-14 10:37:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:01][root][INFO] - Training Epoch: 2/2, step 16611/16670 completed (loss: 0.4082185924053192, acc: 0.9166666865348816)
[2024-11-14 10:37:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:01][root][INFO] - Training Epoch: 2/2, step 16612/16670 completed (loss: 0.4176030158996582, acc: 0.8837209343910217)
[2024-11-14 10:37:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:01][root][INFO] - Training Epoch: 2/2, step 16613/16670 completed (loss: 0.32767245173454285, acc: 0.932584285736084)
[2024-11-14 10:37:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:02][root][INFO] - Training Epoch: 2/2, step 16614/16670 completed (loss: 0.31964340806007385, acc: 0.9230769276618958)
[2024-11-14 10:37:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:02][root][INFO] - Training Epoch: 2/2, step 16615/16670 completed (loss: 0.0817520022392273, acc: 0.9545454382896423)
[2024-11-14 10:37:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:02][root][INFO] - Training Epoch: 2/2, step 16616/16670 completed (loss: 0.5749613642692566, acc: 0.8958333134651184)
[2024-11-14 10:37:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:03][root][INFO] - Training Epoch: 2/2, step 16617/16670 completed (loss: 0.37384751439094543, acc: 0.9342105388641357)
[2024-11-14 10:37:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:03][root][INFO] - Training Epoch: 2/2, step 16618/16670 completed (loss: 0.14611242711544037, acc: 0.9740259647369385)
[2024-11-14 10:37:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:03][root][INFO] - Training Epoch: 2/2, step 16619/16670 completed (loss: 0.6386080980300903, acc: 0.8666666746139526)
[2024-11-14 10:37:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:04][root][INFO] - Training Epoch: 2/2, step 16620/16670 completed (loss: 0.8412569761276245, acc: 0.8360655903816223)
[2024-11-14 10:37:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:04][root][INFO] - Training Epoch: 2/2, step 16621/16670 completed (loss: 0.09961216151714325, acc: 0.9767441749572754)
[2024-11-14 10:37:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:04][root][INFO] - Training Epoch: 2/2, step 16622/16670 completed (loss: 0.36271435022354126, acc: 0.8928571343421936)
[2024-11-14 10:37:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:05][root][INFO] - Training Epoch: 2/2, step 16623/16670 completed (loss: 0.3453173339366913, acc: 0.8846153616905212)
[2024-11-14 10:37:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:05][root][INFO] - Training Epoch: 2/2, step 16624/16670 completed (loss: 0.2327043116092682, acc: 0.9387755393981934)
[2024-11-14 10:37:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:05][root][INFO] - Training Epoch: 2/2, step 16625/16670 completed (loss: 0.3349771499633789, acc: 0.875)
[2024-11-14 10:37:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:06][root][INFO] - Training Epoch: 2/2, step 16626/16670 completed (loss: 1.046776533126831, acc: 0.7755101919174194)
[2024-11-14 10:37:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:06][root][INFO] - Training Epoch: 2/2, step 16627/16670 completed (loss: 0.42333483695983887, acc: 0.8999999761581421)
[2024-11-14 10:37:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:06][root][INFO] - Training Epoch: 2/2, step 16628/16670 completed (loss: 0.3573998212814331, acc: 0.9347826242446899)
[2024-11-14 10:37:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:07][root][INFO] - Training Epoch: 2/2, step 16629/16670 completed (loss: 0.6116774678230286, acc: 0.8208954930305481)
[2024-11-14 10:37:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:07][root][INFO] - Training Epoch: 2/2, step 16630/16670 completed (loss: 0.1458899825811386, acc: 0.9166666865348816)
[2024-11-14 10:37:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:07][root][INFO] - Training Epoch: 2/2, step 16631/16670 completed (loss: 0.43825480341911316, acc: 0.868852436542511)
[2024-11-14 10:37:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:08][root][INFO] - Training Epoch: 2/2, step 16632/16670 completed (loss: 0.6296092867851257, acc: 0.843137264251709)
[2024-11-14 10:37:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:08][root][INFO] - Training Epoch: 2/2, step 16633/16670 completed (loss: 0.8912215828895569, acc: 0.7777777910232544)
[2024-11-14 10:37:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:08][root][INFO] - Training Epoch: 2/2, step 16634/16670 completed (loss: 0.40049874782562256, acc: 0.8636363744735718)
[2024-11-14 10:37:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:09][root][INFO] - Training Epoch: 2/2, step 16635/16670 completed (loss: 0.10511691868305206, acc: 0.978723406791687)
[2024-11-14 10:37:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:09][root][INFO] - Training Epoch: 2/2, step 16636/16670 completed (loss: 0.8215633034706116, acc: 0.8235294222831726)
[2024-11-14 10:37:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:09][root][INFO] - Training Epoch: 2/2, step 16637/16670 completed (loss: 0.5698667764663696, acc: 0.936170220375061)
[2024-11-14 10:37:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:10][root][INFO] - Training Epoch: 2/2, step 16638/16670 completed (loss: 0.2637345492839813, acc: 0.9137930870056152)
[2024-11-14 10:37:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:10][root][INFO] - Training Epoch: 2/2, step 16639/16670 completed (loss: 0.7650531530380249, acc: 0.7843137383460999)
[2024-11-14 10:37:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:10][root][INFO] - Training Epoch: 2/2, step 16640/16670 completed (loss: 0.8911542892456055, acc: 0.7727272510528564)
[2024-11-14 10:37:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:10][root][INFO] - Training Epoch: 2/2, step 16641/16670 completed (loss: 0.18224088847637177, acc: 0.9375)
[2024-11-14 10:37:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:11][root][INFO] - Training Epoch: 2/2, step 16642/16670 completed (loss: 1.0228623151779175, acc: 0.8139534592628479)
[2024-11-14 10:37:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:11][root][INFO] - Training Epoch: 2/2, step 16643/16670 completed (loss: 0.20315417647361755, acc: 0.9722222089767456)
[2024-11-14 10:37:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:11][root][INFO] - Training Epoch: 2/2, step 16644/16670 completed (loss: 0.27644309401512146, acc: 0.936170220375061)
[2024-11-14 10:37:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:12][root][INFO] - Training Epoch: 2/2, step 16645/16670 completed (loss: 0.4462391436100006, acc: 0.9230769276618958)
[2024-11-14 10:37:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:12][root][INFO] - Training Epoch: 2/2, step 16646/16670 completed (loss: 0.17895516753196716, acc: 0.9722222089767456)
[2024-11-14 10:37:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:12][root][INFO] - Training Epoch: 2/2, step 16647/16670 completed (loss: 0.5277361273765564, acc: 0.9090909361839294)
[2024-11-14 10:37:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:13][root][INFO] - Training Epoch: 2/2, step 16648/16670 completed (loss: 0.6007718443870544, acc: 0.9024389982223511)
[2024-11-14 10:37:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:13][root][INFO] - Training Epoch: 2/2, step 16649/16670 completed (loss: 0.7935591340065002, acc: 0.8604651093482971)
[2024-11-14 10:37:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:13][root][INFO] - Training Epoch: 2/2, step 16650/16670 completed (loss: 0.5987128615379333, acc: 0.8730158805847168)
[2024-11-14 10:37:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:14][root][INFO] - Training Epoch: 2/2, step 16651/16670 completed (loss: 0.47267308831214905, acc: 0.892307698726654)
[2024-11-14 10:37:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:14][root][INFO] - Training Epoch: 2/2, step 16652/16670 completed (loss: 0.4633581042289734, acc: 0.8909090757369995)
[2024-11-14 10:37:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:14][root][INFO] - Training Epoch: 2/2, step 16653/16670 completed (loss: 0.30094850063323975, acc: 0.9024389982223511)
[2024-11-14 10:37:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:15][root][INFO] - Training Epoch: 2/2, step 16654/16670 completed (loss: 0.41110870242118835, acc: 0.875)
[2024-11-14 10:37:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:15][root][INFO] - Training Epoch: 2/2, step 16655/16670 completed (loss: 0.5143948197364807, acc: 0.859649121761322)
[2024-11-14 10:37:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:15][root][INFO] - Training Epoch: 2/2, step 16656/16670 completed (loss: 0.8392325639724731, acc: 0.800000011920929)
[2024-11-14 10:37:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:16][root][INFO] - Training Epoch: 2/2, step 16657/16670 completed (loss: 0.7133644819259644, acc: 0.800000011920929)
[2024-11-14 10:37:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:16][root][INFO] - Training Epoch: 2/2, step 16658/16670 completed (loss: 0.6712701916694641, acc: 0.8867924809455872)
[2024-11-14 10:37:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:17][root][INFO] - Training Epoch: 2/2, step 16659/16670 completed (loss: 0.44400668144226074, acc: 0.9142857193946838)
[2024-11-14 10:37:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:17][root][INFO] - Training Epoch: 2/2, step 16660/16670 completed (loss: 0.25252076983451843, acc: 0.9622641801834106)
[2024-11-14 10:37:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:17][root][INFO] - Training Epoch: 2/2, step 16661/16670 completed (loss: 0.048197049647569656, acc: 1.0)
[2024-11-14 10:37:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:17][root][INFO] - Training Epoch: 2/2, step 16662/16670 completed (loss: 0.30228233337402344, acc: 0.914893627166748)
[2024-11-14 10:37:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:18][root][INFO] - Training Epoch: 2/2, step 16663/16670 completed (loss: 0.43507465720176697, acc: 0.8787878751754761)
[2024-11-14 10:37:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:18][root][INFO] - Training Epoch: 2/2, step 16664/16670 completed (loss: 0.27217745780944824, acc: 0.925000011920929)
[2024-11-14 10:37:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:18][root][INFO] - Training Epoch: 2/2, step 16665/16670 completed (loss: 0.3218981623649597, acc: 0.8799999952316284)
[2024-11-14 10:37:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:37:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:38:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:39:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:40:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:41:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:42:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:43:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:44:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:45:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:46:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:47:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:48][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.7320, device='cuda:0') eval_epoch_loss=tensor(0.5493, device='cuda:0') eval_epoch_acc=tensor(0.8796, device='cuda:0')
[2024-11-14 10:48:48][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-14 10:48:48][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-14 10:48:49][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_16666_loss_0.5492833256721497/model.pt
[2024-11-14 10:48:49][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft directory
[2024-11-14 10:48:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:49][root][INFO] - Training Epoch: 2/2, step 16666/16670 completed (loss: 0.5120902061462402, acc: 0.859649121761322)
[2024-11-14 10:48:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:50][root][INFO] - Training Epoch: 2/2, step 16667/16670 completed (loss: 0.3792824149131775, acc: 0.8732394576072693)
[2024-11-14 10:48:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:50][root][INFO] - Training Epoch: 2/2, step 16668/16670 completed (loss: 0.5088690519332886, acc: 0.8604651093482971)
[2024-11-14 10:48:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:50][root][INFO] - Training Epoch: 2/2, step 16669/16670 completed (loss: 0.1949315220117569, acc: 1.0)
[2024-11-14 10:48:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:48:51][root][INFO] - Training Epoch: 2/2, step 16670/16670 completed (loss: 0.3596625030040741, acc: 0.8571428656578064)
[2024-11-14 10:48:51][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=1.2230, train_epoch_loss=0.2013, epoch time 6368.42090786621s
[2024-11-14 10:48:51][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 11 GB
[2024-11-14 10:48:51][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-14 10:48:51][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 11 GB
[2024-11-14 10:48:51][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-11-14 10:48:51][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-14 10:48:51][root][INFO] - Key: avg_train_prep, Value: 1.2230045795440674
[2024-11-14 10:48:51][root][INFO] - Key: avg_train_loss, Value: 0.20131060481071472
[2024-11-14 10:48:51][root][INFO] - Key: avg_train_acc, Value: 0.7006232738494873
[2024-11-14 10:48:51][root][INFO] - Key: avg_eval_prep, Value: 1.7645857334136963
[2024-11-14 10:48:51][root][INFO] - Key: avg_eval_loss, Value: 0.5675228834152222
[2024-11-14 10:48:51][root][INFO] - Key: avg_eval_acc, Value: 0.8764675855636597
[2024-11-14 10:48:51][root][INFO] - Key: avg_epoch_time, Value: 6368.42090786621
[2024-11-14 10:48:51][root][INFO] - Key: avg_checkpoint_time, Value: 0.4374465849250555
Selected lowest loss checkpoint: asr_epoch_2_step_8332_loss_0.5268601775169373
Latest file: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_8332_loss_0.5268601775169373/model.pt
ckpt_folder /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_8332_loss_0.5268601775169373
[2024-11-14 10:49:29][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False}
[2024-11-14 10:49:29][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-11-14 10:49:29][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-11-14 10:49:31][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-11-14 10:49:36][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-11-14 10:49:36][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-11-14 10:49:36][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-11-14 10:49:36][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-11-14 10:49:41][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-14 10:49:41][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-11-14 10:49:41][slam_llm.models.slam_model][INFO] - setup peft...
trainable params: 5,636,096 || all params: 1,241,450,496 || trainable%: 0.4539928106807088
[2024-11-14 10:49:42][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-14 10:49:42][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-11-14 10:49:42][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-11-14 10:49:42][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-11-14 10:49:42][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_8332_loss_0.5268601775169373/model.pt
[2024-11-14 10:49:42][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-11-14 10:49:42][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-11-14 10:49:44][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_phoneme_only/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-11-14 10:49:45][root][INFO] - --> Training Set Length = 7545
[2024-11-14 10:49:45][root][INFO] - =====================================
[2024-11-14 10:49:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:49:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:49:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:49:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:49:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:49:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:49:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:50:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:51:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:52:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:53:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:54:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:55:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:56:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:57:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:58:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 10:59:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:00:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:01:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:02:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:03:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:04:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:05:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:06:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:07:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:08:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:09:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:10:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:11:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:12:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:13:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:14:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:15:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:16:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:17:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:18:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:19:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:20:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:21:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:22:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:23:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:24:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:25:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:26:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:27:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:28:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:29:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:30:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:31:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:32:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:33:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:34:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:35:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:36:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:37:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:38:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:39:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:40:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:41:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:42:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:43:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:44:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:45:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:46:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:47:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:48:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:49:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:50:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:51:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:52:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:53:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:54:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:55:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:56:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:57:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:58:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 11:59:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:00:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:01:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:02:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:03:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-14 12:04:47][slam_llm.models.slam_model][INFO] - modality encoder
Using folder: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft
Multiple GT files found. Using the first one: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_phoneme_only_wavlm_llama32_1b_linear_peft/decode_test_beam4_20241114_053437_gt
Initial Word Error Rate (WER) before filtering: 0.16201022146507665
Number of GT lines after filtering: 7538
Number of original PRED lines: 7545
Number of filtered repeated lines: 7 out of 7545
Lines with repeated words in PRED file:
- which isn't i the docking station isn't even in this sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc sc
- it's just a a a a a a a a a a a a a a a
- well there isn't any choice there because we're using the the the the the display
- yeah it's for for la uh laughing up a a a a a a a a a a a a a
- DH AE T  F AO R  S K OW  R OW L Z  W IY  HH AE V  T UW  G OW  F AO R  AH  S AA F IH S T AH K EY T AH D  AH N D  AH  AH  AH  AH  AH  F UH L  AH  K AH M P L IY T  CH IH P
- in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in
- OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW  OW
Filtered Word Error Rate (WER) after removing repeated lines: 0.15956651011287024
