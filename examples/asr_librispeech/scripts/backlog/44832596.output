Using dataset file: src/slam_llm/datasets/speech_dataset.py:get_speech_dataset
speech encoder name: wavlm
speech encoder path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt
speech encoder2 name: w2v2
speech encoder2 path: vitouphy/wav2vec2-xls-r-300m-timit-phoneme
llm_path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/TinyLlama-1.1B-Chat-v1.0
Identifier: librispeech-100_wavlm_TinyLlama_dual_phoneme_freeze
use_peft: true
use_fp16: true
Final identifier: librispeech-100_wavlm_TinyLlama_dual_peft
No checkpoint found in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_TinyLlama_dual_peft
ckpt_folder: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_TinyLlama_dual_peft/
Resume epoch: 1
Resume step: 0
[2024-10-22 03:04:53][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_TinyLlama_dual_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': False}
[2024-10-22 03:04:53][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-10-22 03:04:53][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'TinyLlama', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/TinyLlama-1.1B-Chat-v1.0', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'dual', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': 'w2v2', 'encoder2_dim': 1024, 'encoder2_path': 'vitouphy/wav2vec2-xls-r-300m-timit-phoneme'}
[2024-10-22 03:04:53][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_wavlm_TinyLlama_dual_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-10-22_03-04-53.txt', 'log_interval': 5}
[2024-10-22 03:05:17][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-10-22 03:05:22][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-10-22 03:05:22][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-10-22 03:05:22][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-10-22 03:05:22][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-10-22 03:05:25][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2024-10-22 03:05:25][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2024-10-22 03:05:25][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2024-10-22 03:05:25][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2024-10-22 03:05:31][slam_llm.utils.train_utils][INFO] - --> Module TinyLlama
[2024-10-22 03:05:31][slam_llm.utils.train_utils][INFO] - --> TinyLlama has 1100.048384 Million params

[2024-10-22 03:05:31][slam_llm.models.slam_model][INFO] - setup peft...
trainable params: 6,307,840 || all params: 1,106,356,224 || trainable%: 0.570145479653396
[2024-10-22 03:05:31][slam_llm.utils.train_utils][INFO] - --> Module TinyLlama
[2024-10-22 03:05:31][slam_llm.utils.train_utils][INFO] - --> TinyLlama has 6.30784 Million params

[2024-10-22 03:05:31][slam_llm.utils.train_utils][INFO] - --> Module dual
[2024-10-22 03:05:31][slam_llm.utils.train_utils][INFO] - --> dual has 25.16992 Million params

[2024-10-22 03:05:31][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-10-22 03:05:31][slam_llm.utils.train_utils][INFO] - --> asr has 346.91648 Million params

[2024-10-22 03:05:33][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': 'Transcribe speech to text. ', 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-10-22 03:05:35][root][INFO] - --> Training Set Length = 28539
[2024-10-22 03:05:35][root][INFO] - --> Validation Set Length = 2703
[2024-10-22 03:05:35][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-10-22 03:05:35][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-10-22 03:05:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:38][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-10-22 03:05:39][root][INFO] - Training Epoch: 1/2, step 0/7134 completed (loss: 6.253710746765137, acc: 0.10240963846445084)
[2024-10-22 03:05:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:40][root][INFO] - Training Epoch: 1/2, step 1/7134 completed (loss: 6.318700790405273, acc: 0.08187134563922882)
[2024-10-22 03:05:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:40][root][INFO] - Training Epoch: 1/2, step 2/7134 completed (loss: 5.659104347229004, acc: 0.11518324911594391)
[2024-10-22 03:05:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:41][root][INFO] - Training Epoch: 1/2, step 3/7134 completed (loss: 6.163267612457275, acc: 0.1135135143995285)
[2024-10-22 03:05:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:42][root][INFO] - Training Epoch: 1/2, step 4/7134 completed (loss: 6.303973197937012, acc: 0.07999999821186066)
[2024-10-22 03:05:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:42][root][INFO] - Training Epoch: 1/2, step 5/7134 completed (loss: 6.063220024108887, acc: 0.09743589907884598)
[2024-10-22 03:05:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:43][root][INFO] - Training Epoch: 1/2, step 6/7134 completed (loss: 5.4105305671691895, acc: 0.15789473056793213)
[2024-10-22 03:05:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:43][root][INFO] - Training Epoch: 1/2, step 7/7134 completed (loss: 6.327917098999023, acc: 0.08292683213949203)
[2024-10-22 03:05:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:44][root][INFO] - Training Epoch: 1/2, step 8/7134 completed (loss: 6.122038841247559, acc: 0.07821229100227356)
[2024-10-22 03:05:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:45][root][INFO] - Training Epoch: 1/2, step 9/7134 completed (loss: 5.828932285308838, acc: 0.09815950691699982)
[2024-10-22 03:05:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:45][root][INFO] - Training Epoch: 1/2, step 10/7134 completed (loss: 6.002628326416016, acc: 0.13978494703769684)
[2024-10-22 03:05:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:46][root][INFO] - Training Epoch: 1/2, step 11/7134 completed (loss: 6.0801849365234375, acc: 0.10791366547346115)
[2024-10-22 03:05:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:46][root][INFO] - Training Epoch: 1/2, step 12/7134 completed (loss: 5.56788969039917, acc: 0.14917127788066864)
[2024-10-22 03:05:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:47][root][INFO] - Training Epoch: 1/2, step 13/7134 completed (loss: 5.889805793762207, acc: 0.1442786008119583)
[2024-10-22 03:05:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:48][root][INFO] - Training Epoch: 1/2, step 14/7134 completed (loss: 5.8083577156066895, acc: 0.10126582533121109)
[2024-10-22 03:05:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:48][root][INFO] - Training Epoch: 1/2, step 15/7134 completed (loss: 5.758941650390625, acc: 0.10884353518486023)
[2024-10-22 03:05:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:49][root][INFO] - Training Epoch: 1/2, step 16/7134 completed (loss: 5.647200107574463, acc: 0.09243697673082352)
[2024-10-22 03:05:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:49][root][INFO] - Training Epoch: 1/2, step 17/7134 completed (loss: 6.1255927085876465, acc: 0.0776699036359787)
[2024-10-22 03:05:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:50][root][INFO] - Training Epoch: 1/2, step 18/7134 completed (loss: 5.256848335266113, acc: 0.15000000596046448)
[2024-10-22 03:05:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:51][root][INFO] - Training Epoch: 1/2, step 19/7134 completed (loss: 5.711172580718994, acc: 0.1428571492433548)
[2024-10-22 03:05:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:51][root][INFO] - Training Epoch: 1/2, step 20/7134 completed (loss: 5.345941066741943, acc: 0.1340206116437912)
[2024-10-22 03:05:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:52][root][INFO] - Training Epoch: 1/2, step 21/7134 completed (loss: 5.928560733795166, acc: 0.12299465388059616)
[2024-10-22 03:05:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:52][root][INFO] - Training Epoch: 1/2, step 22/7134 completed (loss: 5.065153121948242, acc: 0.1428571492433548)
[2024-10-22 03:05:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:53][root][INFO] - Training Epoch: 1/2, step 23/7134 completed (loss: 4.975961208343506, acc: 0.17894737422466278)
[2024-10-22 03:05:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:53][root][INFO] - Training Epoch: 1/2, step 24/7134 completed (loss: 5.479562282562256, acc: 0.11398963630199432)
[2024-10-22 03:05:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:54][root][INFO] - Training Epoch: 1/2, step 25/7134 completed (loss: 5.250316619873047, acc: 0.15846994519233704)
[2024-10-22 03:05:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:55][root][INFO] - Training Epoch: 1/2, step 26/7134 completed (loss: 5.711647033691406, acc: 0.11046511679887772)
[2024-10-22 03:05:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:55][root][INFO] - Training Epoch: 1/2, step 27/7134 completed (loss: 5.314813613891602, acc: 0.13609467446804047)
[2024-10-22 03:05:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:56][root][INFO] - Training Epoch: 1/2, step 28/7134 completed (loss: 5.6743597984313965, acc: 0.12612612545490265)
[2024-10-22 03:05:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:57][root][INFO] - Training Epoch: 1/2, step 29/7134 completed (loss: 5.201603412628174, acc: 0.13661202788352966)
[2024-10-22 03:05:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:57][root][INFO] - Training Epoch: 1/2, step 30/7134 completed (loss: 5.36140775680542, acc: 0.16736401617527008)
[2024-10-22 03:05:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:58][root][INFO] - Training Epoch: 1/2, step 31/7134 completed (loss: 5.664729118347168, acc: 0.1764705926179886)
[2024-10-22 03:05:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:58][root][INFO] - Training Epoch: 1/2, step 32/7134 completed (loss: 5.609422206878662, acc: 0.1336633712053299)
[2024-10-22 03:05:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:59][root][INFO] - Training Epoch: 1/2, step 33/7134 completed (loss: 5.134837627410889, acc: 0.16083915531635284)
[2024-10-22 03:05:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:05:59][root][INFO] - Training Epoch: 1/2, step 34/7134 completed (loss: 5.232483386993408, acc: 0.156521737575531)
[2024-10-22 03:06:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:00][root][INFO] - Training Epoch: 1/2, step 35/7134 completed (loss: 5.161571025848389, acc: 0.14695340394973755)
[2024-10-22 03:06:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:01][root][INFO] - Training Epoch: 1/2, step 36/7134 completed (loss: 4.928378582000732, acc: 0.18799999356269836)
[2024-10-22 03:06:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:01][root][INFO] - Training Epoch: 1/2, step 37/7134 completed (loss: 5.424501419067383, acc: 0.18446601927280426)
[2024-10-22 03:06:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:02][root][INFO] - Training Epoch: 1/2, step 38/7134 completed (loss: 5.3755388259887695, acc: 0.15642458200454712)
[2024-10-22 03:06:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:02][root][INFO] - Training Epoch: 1/2, step 39/7134 completed (loss: 5.138669013977051, acc: 0.1912568360567093)
[2024-10-22 03:06:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:03][root][INFO] - Training Epoch: 1/2, step 40/7134 completed (loss: 5.366068363189697, acc: 0.15267175436019897)
[2024-10-22 03:06:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:04][root][INFO] - Training Epoch: 1/2, step 41/7134 completed (loss: 4.855444431304932, acc: 0.1866028755903244)
[2024-10-22 03:06:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:04][root][INFO] - Training Epoch: 1/2, step 42/7134 completed (loss: 5.249078273773193, acc: 0.14705882966518402)
[2024-10-22 03:06:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:05][root][INFO] - Training Epoch: 1/2, step 43/7134 completed (loss: 4.752842903137207, acc: 0.2395833283662796)
[2024-10-22 03:06:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:05][root][INFO] - Training Epoch: 1/2, step 44/7134 completed (loss: 4.734297275543213, acc: 0.22380952537059784)
[2024-10-22 03:06:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:06][root][INFO] - Training Epoch: 1/2, step 45/7134 completed (loss: 4.990264415740967, acc: 0.18143460154533386)
[2024-10-22 03:06:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:06][root][INFO] - Training Epoch: 1/2, step 46/7134 completed (loss: 5.387302398681641, acc: 0.1599999964237213)
[2024-10-22 03:06:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:07][root][INFO] - Training Epoch: 1/2, step 47/7134 completed (loss: 4.687704563140869, acc: 0.19323670864105225)
[2024-10-22 03:06:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:08][root][INFO] - Training Epoch: 1/2, step 48/7134 completed (loss: 4.9601359367370605, acc: 0.19730941951274872)
[2024-10-22 03:06:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:08][root][INFO] - Training Epoch: 1/2, step 49/7134 completed (loss: 4.966726779937744, acc: 0.17525772750377655)
[2024-10-22 03:06:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:09][root][INFO] - Training Epoch: 1/2, step 50/7134 completed (loss: 5.044427394866943, acc: 0.21120689809322357)
[2024-10-22 03:06:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:09][root][INFO] - Training Epoch: 1/2, step 51/7134 completed (loss: 4.797016620635986, acc: 0.20909090340137482)
[2024-10-22 03:06:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:10][root][INFO] - Training Epoch: 1/2, step 52/7134 completed (loss: 4.765451908111572, acc: 0.15853658318519592)
[2024-10-22 03:06:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:11][root][INFO] - Training Epoch: 1/2, step 53/7134 completed (loss: 4.765305995941162, acc: 0.190476194024086)
[2024-10-22 03:06:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:11][root][INFO] - Training Epoch: 1/2, step 54/7134 completed (loss: 4.9410247802734375, acc: 0.17872340977191925)
[2024-10-22 03:06:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:12][root][INFO] - Training Epoch: 1/2, step 55/7134 completed (loss: 4.604521751403809, acc: 0.2455357164144516)
[2024-10-22 03:06:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:12][root][INFO] - Training Epoch: 1/2, step 56/7134 completed (loss: 5.238216400146484, acc: 0.15000000596046448)
[2024-10-22 03:06:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:13][root][INFO] - Training Epoch: 1/2, step 57/7134 completed (loss: 5.418802738189697, acc: 0.1442786008119583)
[2024-10-22 03:06:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:13][root][INFO] - Training Epoch: 1/2, step 58/7134 completed (loss: 5.053746700286865, acc: 0.14720812439918518)
[2024-10-22 03:06:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:14][root][INFO] - Training Epoch: 1/2, step 59/7134 completed (loss: 5.067893981933594, acc: 0.16417910158634186)
[2024-10-22 03:06:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:15][root][INFO] - Training Epoch: 1/2, step 60/7134 completed (loss: 5.096358776092529, acc: 0.13333334028720856)
[2024-10-22 03:06:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:15][root][INFO] - Training Epoch: 1/2, step 61/7134 completed (loss: 4.8094892501831055, acc: 0.2385786771774292)
[2024-10-22 03:06:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:16][root][INFO] - Training Epoch: 1/2, step 62/7134 completed (loss: 5.69486141204834, acc: 0.11052631586790085)
[2024-10-22 03:06:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:16][root][INFO] - Training Epoch: 1/2, step 63/7134 completed (loss: 4.9805097579956055, acc: 0.17241379618644714)
[2024-10-22 03:06:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:17][root][INFO] - Training Epoch: 1/2, step 64/7134 completed (loss: 5.177486419677734, acc: 0.1925133615732193)
[2024-10-22 03:06:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:18][root][INFO] - Training Epoch: 1/2, step 65/7134 completed (loss: 5.605371475219727, acc: 0.16826923191547394)
[2024-10-22 03:06:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:18][root][INFO] - Training Epoch: 1/2, step 66/7134 completed (loss: 5.167567729949951, acc: 0.19078947603702545)
[2024-10-22 03:06:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:19][root][INFO] - Training Epoch: 1/2, step 67/7134 completed (loss: 5.070834159851074, acc: 0.19072164595127106)
[2024-10-22 03:06:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:19][root][INFO] - Training Epoch: 1/2, step 68/7134 completed (loss: 4.913099765777588, acc: 0.2829268276691437)
[2024-10-22 03:06:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:20][root][INFO] - Training Epoch: 1/2, step 69/7134 completed (loss: 5.048871040344238, acc: 0.16908212006092072)
[2024-10-22 03:06:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:21][root][INFO] - Training Epoch: 1/2, step 70/7134 completed (loss: 4.974094390869141, acc: 0.20408163964748383)
[2024-10-22 03:06:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:21][root][INFO] - Training Epoch: 1/2, step 71/7134 completed (loss: 4.527233123779297, acc: 0.26404494047164917)
[2024-10-22 03:06:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:22][root][INFO] - Training Epoch: 1/2, step 72/7134 completed (loss: 5.042736530303955, acc: 0.22680412232875824)
[2024-10-22 03:06:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:22][root][INFO] - Training Epoch: 1/2, step 73/7134 completed (loss: 5.101179122924805, acc: 0.15425531566143036)
[2024-10-22 03:06:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:23][root][INFO] - Training Epoch: 1/2, step 74/7134 completed (loss: 4.961907386779785, acc: 0.1764705926179886)
[2024-10-22 03:06:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:23][root][INFO] - Training Epoch: 1/2, step 75/7134 completed (loss: 4.827674865722656, acc: 0.2568306028842926)
[2024-10-22 03:06:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:24][root][INFO] - Training Epoch: 1/2, step 76/7134 completed (loss: 4.497734069824219, acc: 0.24761904776096344)
[2024-10-22 03:06:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:25][root][INFO] - Training Epoch: 1/2, step 77/7134 completed (loss: 4.301145553588867, acc: 0.2571428716182709)
[2024-10-22 03:06:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:25][root][INFO] - Training Epoch: 1/2, step 78/7134 completed (loss: 4.625824451446533, acc: 0.22543352842330933)
[2024-10-22 03:06:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:26][root][INFO] - Training Epoch: 1/2, step 79/7134 completed (loss: 4.666909217834473, acc: 0.23952095210552216)
[2024-10-22 03:06:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:26][root][INFO] - Training Epoch: 1/2, step 80/7134 completed (loss: 4.554371356964111, acc: 0.19473683834075928)
[2024-10-22 03:06:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:27][root][INFO] - Training Epoch: 1/2, step 81/7134 completed (loss: 4.745528221130371, acc: 0.22549019753932953)
[2024-10-22 03:06:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:27][root][INFO] - Training Epoch: 1/2, step 82/7134 completed (loss: 4.714297294616699, acc: 0.20994475483894348)
[2024-10-22 03:06:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:28][root][INFO] - Training Epoch: 1/2, step 83/7134 completed (loss: 5.045125961303711, acc: 0.18000000715255737)
[2024-10-22 03:06:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:29][root][INFO] - Training Epoch: 1/2, step 84/7134 completed (loss: 4.287873268127441, acc: 0.2368421107530594)
[2024-10-22 03:06:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:29][root][INFO] - Training Epoch: 1/2, step 85/7134 completed (loss: 4.67155122756958, acc: 0.19266055524349213)
[2024-10-22 03:06:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:30][root][INFO] - Training Epoch: 1/2, step 86/7134 completed (loss: 4.376956939697266, acc: 0.2651515007019043)
[2024-10-22 03:06:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:30][root][INFO] - Training Epoch: 1/2, step 87/7134 completed (loss: 4.411640167236328, acc: 0.28248587250709534)
[2024-10-22 03:06:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:31][root][INFO] - Training Epoch: 1/2, step 88/7134 completed (loss: 4.761463165283203, acc: 0.23280423879623413)
[2024-10-22 03:06:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:31][root][INFO] - Training Epoch: 1/2, step 89/7134 completed (loss: 4.270327568054199, acc: 0.25757575035095215)
[2024-10-22 03:06:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:32][root][INFO] - Training Epoch: 1/2, step 90/7134 completed (loss: 4.472919940948486, acc: 0.27819550037384033)
[2024-10-22 03:06:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:33][root][INFO] - Training Epoch: 1/2, step 91/7134 completed (loss: 4.650751113891602, acc: 0.2442748099565506)
[2024-10-22 03:06:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:33][root][INFO] - Training Epoch: 1/2, step 92/7134 completed (loss: 4.342613220214844, acc: 0.25581395626068115)
[2024-10-22 03:06:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:34][root][INFO] - Training Epoch: 1/2, step 93/7134 completed (loss: 4.325861930847168, acc: 0.24193547666072845)
[2024-10-22 03:06:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:34][root][INFO] - Training Epoch: 1/2, step 94/7134 completed (loss: 4.543895244598389, acc: 0.25641027092933655)
[2024-10-22 03:06:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:35][root][INFO] - Training Epoch: 1/2, step 95/7134 completed (loss: 4.455718040466309, acc: 0.23529411852359772)
[2024-10-22 03:06:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:35][root][INFO] - Training Epoch: 1/2, step 96/7134 completed (loss: 4.55047607421875, acc: 0.26446279883384705)
[2024-10-22 03:06:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:36][root][INFO] - Training Epoch: 1/2, step 97/7134 completed (loss: 5.513377666473389, acc: 0.24528302252292633)
[2024-10-22 03:06:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:37][root][INFO] - Training Epoch: 1/2, step 98/7134 completed (loss: 4.124647617340088, acc: 0.2544378638267517)
[2024-10-22 03:06:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:37][root][INFO] - Training Epoch: 1/2, step 99/7134 completed (loss: 3.8318653106689453, acc: 0.3379310369491577)
[2024-10-22 03:06:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:38][root][INFO] - Training Epoch: 1/2, step 100/7134 completed (loss: 4.290184020996094, acc: 0.29901960492134094)
[2024-10-22 03:06:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:38][root][INFO] - Training Epoch: 1/2, step 101/7134 completed (loss: 4.493058681488037, acc: 0.23178808391094208)
[2024-10-22 03:06:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:39][root][INFO] - Training Epoch: 1/2, step 102/7134 completed (loss: 4.226625442504883, acc: 0.2341463416814804)
[2024-10-22 03:06:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:39][root][INFO] - Training Epoch: 1/2, step 103/7134 completed (loss: 4.418698310852051, acc: 0.23030303418636322)
[2024-10-22 03:06:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:40][root][INFO] - Training Epoch: 1/2, step 104/7134 completed (loss: 3.9026641845703125, acc: 0.2634730637073517)
[2024-10-22 03:06:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:41][root][INFO] - Training Epoch: 1/2, step 105/7134 completed (loss: 3.771348714828491, acc: 0.32919254899024963)
[2024-10-22 03:06:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:41][root][INFO] - Training Epoch: 1/2, step 106/7134 completed (loss: 3.96463680267334, acc: 0.30645161867141724)
[2024-10-22 03:06:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:42][root][INFO] - Training Epoch: 1/2, step 107/7134 completed (loss: 3.994439125061035, acc: 0.3668341636657715)
[2024-10-22 03:06:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:43][root][INFO] - Training Epoch: 1/2, step 108/7134 completed (loss: 4.129854202270508, acc: 0.29556649923324585)
[2024-10-22 03:06:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:43][root][INFO] - Training Epoch: 1/2, step 109/7134 completed (loss: 4.306016445159912, acc: 0.2374100685119629)
[2024-10-22 03:06:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:44][root][INFO] - Training Epoch: 1/2, step 110/7134 completed (loss: 3.790963888168335, acc: 0.3216080367565155)
[2024-10-22 03:06:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:44][root][INFO] - Training Epoch: 1/2, step 111/7134 completed (loss: 3.7565572261810303, acc: 0.3076923191547394)
[2024-10-22 03:06:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:45][root][INFO] - Training Epoch: 1/2, step 112/7134 completed (loss: 3.8695497512817383, acc: 0.3132530152797699)
[2024-10-22 03:06:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:45][root][INFO] - Training Epoch: 1/2, step 113/7134 completed (loss: 3.621548891067505, acc: 0.3216080367565155)
[2024-10-22 03:06:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:46][root][INFO] - Training Epoch: 1/2, step 114/7134 completed (loss: 3.764578342437744, acc: 0.3222748935222626)
[2024-10-22 03:06:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:46][root][INFO] - Training Epoch: 1/2, step 115/7134 completed (loss: 3.956125020980835, acc: 0.30894309282302856)
[2024-10-22 03:06:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:47][root][INFO] - Training Epoch: 1/2, step 116/7134 completed (loss: 4.407199859619141, acc: 0.23469388484954834)
[2024-10-22 03:06:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:48][root][INFO] - Training Epoch: 1/2, step 117/7134 completed (loss: 4.045032501220703, acc: 0.30054643750190735)
[2024-10-22 03:06:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:48][root][INFO] - Training Epoch: 1/2, step 118/7134 completed (loss: 4.587983131408691, acc: 0.2199999988079071)
[2024-10-22 03:06:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:49][root][INFO] - Training Epoch: 1/2, step 119/7134 completed (loss: 4.4353179931640625, acc: 0.25)
[2024-10-22 03:06:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:49][root][INFO] - Training Epoch: 1/2, step 120/7134 completed (loss: 3.962210178375244, acc: 0.22513088583946228)
[2024-10-22 03:06:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:50][root][INFO] - Training Epoch: 1/2, step 121/7134 completed (loss: 4.46485710144043, acc: 0.2551020383834839)
[2024-10-22 03:06:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:50][root][INFO] - Training Epoch: 1/2, step 122/7134 completed (loss: 3.795198917388916, acc: 0.3050000071525574)
[2024-10-22 03:06:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:51][root][INFO] - Training Epoch: 1/2, step 123/7134 completed (loss: 4.178197383880615, acc: 0.25287356972694397)
[2024-10-22 03:06:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:52][root][INFO] - Training Epoch: 1/2, step 124/7134 completed (loss: 3.653754234313965, acc: 0.353658527135849)
[2024-10-22 03:06:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:52][root][INFO] - Training Epoch: 1/2, step 125/7134 completed (loss: 3.7426764965057373, acc: 0.33898305892944336)
[2024-10-22 03:06:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:53][root][INFO] - Training Epoch: 1/2, step 126/7134 completed (loss: 4.123169422149658, acc: 0.27619048953056335)
[2024-10-22 03:06:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:53][root][INFO] - Training Epoch: 1/2, step 127/7134 completed (loss: 3.5112264156341553, acc: 0.375)
[2024-10-22 03:06:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:54][root][INFO] - Training Epoch: 1/2, step 128/7134 completed (loss: 3.8163440227508545, acc: 0.3025210201740265)
[2024-10-22 03:06:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:54][root][INFO] - Training Epoch: 1/2, step 129/7134 completed (loss: 3.6500747203826904, acc: 0.2885572016239166)
[2024-10-22 03:06:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:55][root][INFO] - Training Epoch: 1/2, step 130/7134 completed (loss: 3.706342935562134, acc: 0.31578946113586426)
[2024-10-22 03:06:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:56][root][INFO] - Training Epoch: 1/2, step 131/7134 completed (loss: 3.7259182929992676, acc: 0.3174603283405304)
[2024-10-22 03:06:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:56][root][INFO] - Training Epoch: 1/2, step 132/7134 completed (loss: 3.953315496444702, acc: 0.3139534890651703)
[2024-10-22 03:06:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:57][root][INFO] - Training Epoch: 1/2, step 133/7134 completed (loss: 4.071318626403809, acc: 0.26056337356567383)
[2024-10-22 03:06:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:57][root][INFO] - Training Epoch: 1/2, step 134/7134 completed (loss: 3.9054737091064453, acc: 0.27272728085517883)
[2024-10-22 03:06:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:58][root][INFO] - Training Epoch: 1/2, step 135/7134 completed (loss: 3.4008002281188965, acc: 0.33640551567077637)
[2024-10-22 03:06:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:58][root][INFO] - Training Epoch: 1/2, step 136/7134 completed (loss: 3.9412102699279785, acc: 0.2788461446762085)
[2024-10-22 03:06:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:06:59][root][INFO] - Training Epoch: 1/2, step 137/7134 completed (loss: 3.400810480117798, acc: 0.36771300435066223)
[2024-10-22 03:06:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:00][root][INFO] - Training Epoch: 1/2, step 138/7134 completed (loss: 3.4756293296813965, acc: 0.3507108986377716)
[2024-10-22 03:07:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:00][root][INFO] - Training Epoch: 1/2, step 139/7134 completed (loss: 3.9043667316436768, acc: 0.2801932394504547)
[2024-10-22 03:07:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:01][root][INFO] - Training Epoch: 1/2, step 140/7134 completed (loss: 3.6589066982269287, acc: 0.3166666626930237)
[2024-10-22 03:07:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:01][root][INFO] - Training Epoch: 1/2, step 141/7134 completed (loss: 3.508390188217163, acc: 0.3632287085056305)
[2024-10-22 03:07:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:02][root][INFO] - Training Epoch: 1/2, step 142/7134 completed (loss: 3.9626684188842773, acc: 0.2590673565864563)
[2024-10-22 03:07:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:02][root][INFO] - Training Epoch: 1/2, step 143/7134 completed (loss: 3.3546857833862305, acc: 0.3449999988079071)
[2024-10-22 03:07:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:03][root][INFO] - Training Epoch: 1/2, step 144/7134 completed (loss: 4.208601951599121, acc: 0.25)
[2024-10-22 03:07:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:04][root][INFO] - Training Epoch: 1/2, step 145/7134 completed (loss: 4.833922863006592, acc: 0.20093457400798798)
[2024-10-22 03:07:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:04][root][INFO] - Training Epoch: 1/2, step 146/7134 completed (loss: 4.260900020599365, acc: 0.30150753259658813)
[2024-10-22 03:07:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:05][root][INFO] - Training Epoch: 1/2, step 147/7134 completed (loss: 3.98636794090271, acc: 0.3136094808578491)
[2024-10-22 03:07:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:05][root][INFO] - Training Epoch: 1/2, step 148/7134 completed (loss: 4.304827690124512, acc: 0.3356643319129944)
[2024-10-22 03:07:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:06][root][INFO] - Training Epoch: 1/2, step 149/7134 completed (loss: 3.957300901412964, acc: 0.3160173296928406)
[2024-10-22 03:07:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:06][root][INFO] - Training Epoch: 1/2, step 150/7134 completed (loss: 4.349787712097168, acc: 0.2718893885612488)
[2024-10-22 03:07:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:07][root][INFO] - Training Epoch: 1/2, step 151/7134 completed (loss: 3.61494517326355, acc: 0.3349514603614807)
[2024-10-22 03:07:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:08][root][INFO] - Training Epoch: 1/2, step 152/7134 completed (loss: 4.112547874450684, acc: 0.23636363446712494)
[2024-10-22 03:07:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:08][root][INFO] - Training Epoch: 1/2, step 153/7134 completed (loss: 4.233760356903076, acc: 0.2588832378387451)
[2024-10-22 03:07:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:09][root][INFO] - Training Epoch: 1/2, step 154/7134 completed (loss: 4.142238616943359, acc: 0.2662721872329712)
[2024-10-22 03:07:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:09][root][INFO] - Training Epoch: 1/2, step 155/7134 completed (loss: 3.871821641921997, acc: 0.30392158031463623)
[2024-10-22 03:07:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:10][root][INFO] - Training Epoch: 1/2, step 156/7134 completed (loss: 3.8520543575286865, acc: 0.26363635063171387)
[2024-10-22 03:07:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:10][root][INFO] - Training Epoch: 1/2, step 157/7134 completed (loss: 4.260868072509766, acc: 0.23222748935222626)
[2024-10-22 03:07:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:11][root][INFO] - Training Epoch: 1/2, step 158/7134 completed (loss: 3.8533384799957275, acc: 0.27272728085517883)
[2024-10-22 03:07:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:11][root][INFO] - Training Epoch: 1/2, step 159/7134 completed (loss: 3.783069133758545, acc: 0.3169398903846741)
[2024-10-22 03:07:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:12][root][INFO] - Training Epoch: 1/2, step 160/7134 completed (loss: 3.899705648422241, acc: 0.24626865983009338)
[2024-10-22 03:07:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:12][root][INFO] - Training Epoch: 1/2, step 161/7134 completed (loss: 3.9741344451904297, acc: 0.30666667222976685)
[2024-10-22 03:07:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:13][root][INFO] - Training Epoch: 1/2, step 162/7134 completed (loss: 4.135858058929443, acc: 0.2469135820865631)
[2024-10-22 03:07:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:13][root][INFO] - Training Epoch: 1/2, step 163/7134 completed (loss: 3.886082172393799, acc: 0.30201342701911926)
[2024-10-22 03:07:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:14][root][INFO] - Training Epoch: 1/2, step 164/7134 completed (loss: 4.022910118103027, acc: 0.3009708821773529)
[2024-10-22 03:07:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:15][root][INFO] - Training Epoch: 1/2, step 165/7134 completed (loss: 3.793044090270996, acc: 0.291262149810791)
[2024-10-22 03:07:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:15][root][INFO] - Training Epoch: 1/2, step 166/7134 completed (loss: 4.190394401550293, acc: 0.2857142984867096)
[2024-10-22 03:07:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:16][root][INFO] - Training Epoch: 1/2, step 167/7134 completed (loss: 4.794823169708252, acc: 0.22580644488334656)
[2024-10-22 03:07:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:16][root][INFO] - Training Epoch: 1/2, step 168/7134 completed (loss: 5.643613815307617, acc: 0.11290322244167328)
[2024-10-22 03:07:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:17][root][INFO] - Training Epoch: 1/2, step 169/7134 completed (loss: 5.153752326965332, acc: 0.14482758939266205)
[2024-10-22 03:07:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:17][root][INFO] - Training Epoch: 1/2, step 170/7134 completed (loss: 4.3666582107543945, acc: 0.25925925374031067)
[2024-10-22 03:07:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:18][root][INFO] - Training Epoch: 1/2, step 171/7134 completed (loss: 5.0149922370910645, acc: 0.2110091745853424)
[2024-10-22 03:07:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:18][root][INFO] - Training Epoch: 1/2, step 172/7134 completed (loss: 4.251309871673584, acc: 0.21830986440181732)
[2024-10-22 03:07:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:19][root][INFO] - Training Epoch: 1/2, step 173/7134 completed (loss: 4.883302688598633, acc: 0.17293232679367065)
[2024-10-22 03:07:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:19][root][INFO] - Training Epoch: 1/2, step 174/7134 completed (loss: 4.696807384490967, acc: 0.2142857164144516)
[2024-10-22 03:07:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:20][root][INFO] - Training Epoch: 1/2, step 175/7134 completed (loss: 3.9313390254974365, acc: 0.3238636255264282)
[2024-10-22 03:07:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:20][root][INFO] - Training Epoch: 1/2, step 176/7134 completed (loss: 3.8916373252868652, acc: 0.3270142078399658)
[2024-10-22 03:07:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:21][root][INFO] - Training Epoch: 1/2, step 177/7134 completed (loss: 4.3150763511657715, acc: 0.25789472460746765)
[2024-10-22 03:07:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:21][root][INFO] - Training Epoch: 1/2, step 178/7134 completed (loss: 4.262258052825928, acc: 0.21686747670173645)
[2024-10-22 03:07:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:22][root][INFO] - Training Epoch: 1/2, step 179/7134 completed (loss: 3.7141425609588623, acc: 0.30666667222976685)
[2024-10-22 03:07:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:23][root][INFO] - Training Epoch: 1/2, step 180/7134 completed (loss: 3.856107234954834, acc: 0.3195266127586365)
[2024-10-22 03:07:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:23][root][INFO] - Training Epoch: 1/2, step 181/7134 completed (loss: 3.6775152683258057, acc: 0.31707316637039185)
[2024-10-22 03:07:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:24][root][INFO] - Training Epoch: 1/2, step 182/7134 completed (loss: 3.7944176197052, acc: 0.25581395626068115)
[2024-10-22 03:07:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:24][root][INFO] - Training Epoch: 1/2, step 183/7134 completed (loss: 3.7244977951049805, acc: 0.28658536076545715)
[2024-10-22 03:07:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:25][root][INFO] - Training Epoch: 1/2, step 184/7134 completed (loss: 3.677239418029785, acc: 0.3469387888908386)
[2024-10-22 03:07:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:25][root][INFO] - Training Epoch: 1/2, step 185/7134 completed (loss: 3.5275063514709473, acc: 0.38749998807907104)
[2024-10-22 03:07:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:26][root][INFO] - Training Epoch: 1/2, step 186/7134 completed (loss: 3.668494701385498, acc: 0.281879186630249)
[2024-10-22 03:07:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:27][root][INFO] - Training Epoch: 1/2, step 187/7134 completed (loss: 3.0073485374450684, acc: 0.42690059542655945)
[2024-10-22 03:07:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:27][root][INFO] - Training Epoch: 1/2, step 188/7134 completed (loss: 3.461961269378662, acc: 0.3615819215774536)
[2024-10-22 03:07:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:28][root][INFO] - Training Epoch: 1/2, step 189/7134 completed (loss: 3.432434320449829, acc: 0.3884892165660858)
[2024-10-22 03:07:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:28][root][INFO] - Training Epoch: 1/2, step 190/7134 completed (loss: 3.3424060344696045, acc: 0.3181818127632141)
[2024-10-22 03:07:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:29][root][INFO] - Training Epoch: 1/2, step 191/7134 completed (loss: 3.2200534343719482, acc: 0.40336135029792786)
[2024-10-22 03:07:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:30][root][INFO] - Training Epoch: 1/2, step 192/7134 completed (loss: 3.212073802947998, acc: 0.3776595890522003)
[2024-10-22 03:07:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:30][root][INFO] - Training Epoch: 1/2, step 193/7134 completed (loss: 3.238334894180298, acc: 0.4171122908592224)
[2024-10-22 03:07:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:31][root][INFO] - Training Epoch: 1/2, step 194/7134 completed (loss: 3.748643636703491, acc: 0.3011363744735718)
[2024-10-22 03:07:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:31][root][INFO] - Training Epoch: 1/2, step 195/7134 completed (loss: 4.090523719787598, acc: 0.27397260069847107)
[2024-10-22 03:07:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:32][root][INFO] - Training Epoch: 1/2, step 196/7134 completed (loss: 4.176899433135986, acc: 0.26530611515045166)
[2024-10-22 03:07:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:33][root][INFO] - Training Epoch: 1/2, step 197/7134 completed (loss: 3.0307915210723877, acc: 0.4573170840740204)
[2024-10-22 03:07:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:33][root][INFO] - Training Epoch: 1/2, step 198/7134 completed (loss: 3.346036195755005, acc: 0.3333333432674408)
[2024-10-22 03:07:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:34][root][INFO] - Training Epoch: 1/2, step 199/7134 completed (loss: 3.5148069858551025, acc: 0.3379310369491577)
[2024-10-22 03:07:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:34][root][INFO] - Training Epoch: 1/2, step 200/7134 completed (loss: 3.524442434310913, acc: 0.3855421543121338)
[2024-10-22 03:07:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:35][root][INFO] - Training Epoch: 1/2, step 201/7134 completed (loss: 3.8332531452178955, acc: 0.3395061790943146)
[2024-10-22 03:07:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:35][root][INFO] - Training Epoch: 1/2, step 202/7134 completed (loss: 3.8683934211730957, acc: 0.3103448152542114)
[2024-10-22 03:07:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:36][root][INFO] - Training Epoch: 1/2, step 203/7134 completed (loss: 4.117321491241455, acc: 0.32460734248161316)
[2024-10-22 03:07:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:37][root][INFO] - Training Epoch: 1/2, step 204/7134 completed (loss: 4.2426252365112305, acc: 0.2711864411830902)
[2024-10-22 03:07:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:37][root][INFO] - Training Epoch: 1/2, step 205/7134 completed (loss: 4.25379753112793, acc: 0.27753305435180664)
[2024-10-22 03:07:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:38][root][INFO] - Training Epoch: 1/2, step 206/7134 completed (loss: 3.5995142459869385, acc: 0.3664596378803253)
[2024-10-22 03:07:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:38][root][INFO] - Training Epoch: 1/2, step 207/7134 completed (loss: 3.8664255142211914, acc: 0.2699386477470398)
[2024-10-22 03:07:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:39][root][INFO] - Training Epoch: 1/2, step 208/7134 completed (loss: 4.602550506591797, acc: 0.2434210479259491)
[2024-10-22 03:07:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:39][root][INFO] - Training Epoch: 1/2, step 209/7134 completed (loss: 4.2615065574646, acc: 0.27586206793785095)
[2024-10-22 03:07:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:40][root][INFO] - Training Epoch: 1/2, step 210/7134 completed (loss: 3.857774019241333, acc: 0.29133859276771545)
[2024-10-22 03:07:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:41][root][INFO] - Training Epoch: 1/2, step 211/7134 completed (loss: 3.8097970485687256, acc: 0.35975611209869385)
[2024-10-22 03:07:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:41][root][INFO] - Training Epoch: 1/2, step 212/7134 completed (loss: 4.877101421356201, acc: 0.2238806039094925)
[2024-10-22 03:07:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:42][root][INFO] - Training Epoch: 1/2, step 213/7134 completed (loss: 3.7481186389923096, acc: 0.364705890417099)
[2024-10-22 03:07:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:42][root][INFO] - Training Epoch: 1/2, step 214/7134 completed (loss: 4.602751731872559, acc: 0.2347826063632965)
[2024-10-22 03:07:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:43][root][INFO] - Training Epoch: 1/2, step 215/7134 completed (loss: 3.5464117527008057, acc: 0.35849055647850037)
[2024-10-22 03:07:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:43][root][INFO] - Training Epoch: 1/2, step 216/7134 completed (loss: 3.2268803119659424, acc: 0.3645320236682892)
[2024-10-22 03:07:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:44][root][INFO] - Training Epoch: 1/2, step 217/7134 completed (loss: 3.156944990158081, acc: 0.3761467933654785)
[2024-10-22 03:07:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:45][root][INFO] - Training Epoch: 1/2, step 218/7134 completed (loss: 3.495363473892212, acc: 0.3700000047683716)
[2024-10-22 03:07:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:45][root][INFO] - Training Epoch: 1/2, step 219/7134 completed (loss: 4.225611686706543, acc: 0.27272728085517883)
[2024-10-22 03:07:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:46][root][INFO] - Training Epoch: 1/2, step 220/7134 completed (loss: 3.734562635421753, acc: 0.31707316637039185)
[2024-10-22 03:07:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:46][root][INFO] - Training Epoch: 1/2, step 221/7134 completed (loss: 3.281480550765991, acc: 0.38797813653945923)
[2024-10-22 03:07:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:47][root][INFO] - Training Epoch: 1/2, step 222/7134 completed (loss: 3.7168686389923096, acc: 0.33000001311302185)
[2024-10-22 03:07:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:48][root][INFO] - Training Epoch: 1/2, step 223/7134 completed (loss: 4.204965114593506, acc: 0.2549019753932953)
[2024-10-22 03:07:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:48][root][INFO] - Training Epoch: 1/2, step 224/7134 completed (loss: 3.984327793121338, acc: 0.3561643958091736)
[2024-10-22 03:07:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:49][root][INFO] - Training Epoch: 1/2, step 225/7134 completed (loss: 3.715060234069824, acc: 0.34951457381248474)
[2024-10-22 03:07:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:49][root][INFO] - Training Epoch: 1/2, step 226/7134 completed (loss: 3.956423282623291, acc: 0.3316831588745117)
[2024-10-22 03:07:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:50][root][INFO] - Training Epoch: 1/2, step 227/7134 completed (loss: 3.9692013263702393, acc: 0.3198198080062866)
[2024-10-22 03:07:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:50][root][INFO] - Training Epoch: 1/2, step 228/7134 completed (loss: 3.995650053024292, acc: 0.34574466943740845)
[2024-10-22 03:07:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:51][root][INFO] - Training Epoch: 1/2, step 229/7134 completed (loss: 4.092344284057617, acc: 0.28780487179756165)
[2024-10-22 03:07:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:52][root][INFO] - Training Epoch: 1/2, step 230/7134 completed (loss: 4.116514682769775, acc: 0.2926829159259796)
[2024-10-22 03:07:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:52][root][INFO] - Training Epoch: 1/2, step 231/7134 completed (loss: 4.11553430557251, acc: 0.25190839171409607)
[2024-10-22 03:07:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:53][root][INFO] - Training Epoch: 1/2, step 232/7134 completed (loss: 3.8951570987701416, acc: 0.29629629850387573)
[2024-10-22 03:07:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:53][root][INFO] - Training Epoch: 1/2, step 233/7134 completed (loss: 3.9554812908172607, acc: 0.3354838788509369)
[2024-10-22 03:07:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:54][root][INFO] - Training Epoch: 1/2, step 234/7134 completed (loss: 3.985788583755493, acc: 0.2716049253940582)
[2024-10-22 03:07:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:55][root][INFO] - Training Epoch: 1/2, step 235/7134 completed (loss: 3.829503297805786, acc: 0.3174603283405304)
[2024-10-22 03:07:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:55][root][INFO] - Training Epoch: 1/2, step 236/7134 completed (loss: 3.7562403678894043, acc: 0.35975611209869385)
[2024-10-22 03:07:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:56][root][INFO] - Training Epoch: 1/2, step 237/7134 completed (loss: 3.9890964031219482, acc: 0.3085106313228607)
[2024-10-22 03:07:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:56][root][INFO] - Training Epoch: 1/2, step 238/7134 completed (loss: 3.9718375205993652, acc: 0.3290322721004486)
[2024-10-22 03:07:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:57][root][INFO] - Training Epoch: 1/2, step 239/7134 completed (loss: 4.368714332580566, acc: 0.22764228284358978)
[2024-10-22 03:07:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:57][root][INFO] - Training Epoch: 1/2, step 240/7134 completed (loss: 3.5982582569122314, acc: 0.3606557250022888)
[2024-10-22 03:07:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:58][root][INFO] - Training Epoch: 1/2, step 241/7134 completed (loss: 3.835397958755493, acc: 0.3589743673801422)
[2024-10-22 03:07:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:59][root][INFO] - Training Epoch: 1/2, step 242/7134 completed (loss: 3.8313634395599365, acc: 0.3274853825569153)
[2024-10-22 03:07:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:07:59][root][INFO] - Training Epoch: 1/2, step 243/7134 completed (loss: 4.276084899902344, acc: 0.25465837121009827)
[2024-10-22 03:07:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:00][root][INFO] - Training Epoch: 1/2, step 244/7134 completed (loss: 3.812387228012085, acc: 0.30666667222976685)
[2024-10-22 03:08:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:00][root][INFO] - Training Epoch: 1/2, step 245/7134 completed (loss: 3.8107616901397705, acc: 0.35338345170021057)
[2024-10-22 03:08:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:01][root][INFO] - Training Epoch: 1/2, step 246/7134 completed (loss: 3.8694679737091064, acc: 0.29605263471603394)
[2024-10-22 03:08:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:01][root][INFO] - Training Epoch: 1/2, step 247/7134 completed (loss: 3.415069341659546, acc: 0.3945578336715698)
[2024-10-22 03:08:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:02][root][INFO] - Training Epoch: 1/2, step 248/7134 completed (loss: 3.6740756034851074, acc: 0.35036495327949524)
[2024-10-22 03:08:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:02][root][INFO] - Training Epoch: 1/2, step 249/7134 completed (loss: 3.7637693881988525, acc: 0.3469387888908386)
[2024-10-22 03:08:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:03][root][INFO] - Training Epoch: 1/2, step 250/7134 completed (loss: 3.597111940383911, acc: 0.31578946113586426)
[2024-10-22 03:08:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:04][root][INFO] - Training Epoch: 1/2, step 251/7134 completed (loss: 3.8538877964019775, acc: 0.3246753215789795)
[2024-10-22 03:08:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:04][root][INFO] - Training Epoch: 1/2, step 252/7134 completed (loss: 3.6336262226104736, acc: 0.3576158881187439)
[2024-10-22 03:08:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:05][root][INFO] - Training Epoch: 1/2, step 253/7134 completed (loss: 3.3900182247161865, acc: 0.2857142984867096)
[2024-10-22 03:08:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:05][root][INFO] - Training Epoch: 1/2, step 254/7134 completed (loss: 3.9091060161590576, acc: 0.25196850299835205)
[2024-10-22 03:08:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:06][root][INFO] - Training Epoch: 1/2, step 255/7134 completed (loss: 3.732041597366333, acc: 0.3030303120613098)
[2024-10-22 03:08:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:07][root][INFO] - Training Epoch: 1/2, step 256/7134 completed (loss: 4.024644374847412, acc: 0.27710843086242676)
[2024-10-22 03:08:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:07][root][INFO] - Training Epoch: 1/2, step 257/7134 completed (loss: 3.984614133834839, acc: 0.3604651093482971)
[2024-10-22 03:08:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:08][root][INFO] - Training Epoch: 1/2, step 258/7134 completed (loss: 3.517951726913452, acc: 0.3469387888908386)
[2024-10-22 03:08:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:08][root][INFO] - Training Epoch: 1/2, step 259/7134 completed (loss: 3.5165317058563232, acc: 0.35947713255882263)
[2024-10-22 03:08:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:09][root][INFO] - Training Epoch: 1/2, step 260/7134 completed (loss: 3.4662909507751465, acc: 0.3448275923728943)
[2024-10-22 03:08:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:09][root][INFO] - Training Epoch: 1/2, step 261/7134 completed (loss: 3.6043262481689453, acc: 0.3361344635486603)
[2024-10-22 03:08:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:10][root][INFO] - Training Epoch: 1/2, step 262/7134 completed (loss: 3.530653953552246, acc: 0.34328359365463257)
[2024-10-22 03:08:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:11][root][INFO] - Training Epoch: 1/2, step 263/7134 completed (loss: 3.6409568786621094, acc: 0.34972676634788513)
[2024-10-22 03:08:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:11][root][INFO] - Training Epoch: 1/2, step 264/7134 completed (loss: 3.718299150466919, acc: 0.3174603283405304)
[2024-10-22 03:08:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:12][root][INFO] - Training Epoch: 1/2, step 265/7134 completed (loss: 3.8019165992736816, acc: 0.3195876181125641)
[2024-10-22 03:08:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:12][root][INFO] - Training Epoch: 1/2, step 266/7134 completed (loss: 3.9293742179870605, acc: 0.29756098985671997)
[2024-10-22 03:08:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:13][root][INFO] - Training Epoch: 1/2, step 267/7134 completed (loss: 3.9630849361419678, acc: 0.29756098985671997)
[2024-10-22 03:08:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:14][root][INFO] - Training Epoch: 1/2, step 268/7134 completed (loss: 3.961210012435913, acc: 0.30337077379226685)
[2024-10-22 03:08:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:14][root][INFO] - Training Epoch: 1/2, step 269/7134 completed (loss: 3.991903066635132, acc: 0.25)
[2024-10-22 03:08:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:15][root][INFO] - Training Epoch: 1/2, step 270/7134 completed (loss: 3.8994531631469727, acc: 0.3257142901420593)
[2024-10-22 03:08:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:15][root][INFO] - Training Epoch: 1/2, step 271/7134 completed (loss: 4.3001790046691895, acc: 0.24365481734275818)
[2024-10-22 03:08:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:16][root][INFO] - Training Epoch: 1/2, step 272/7134 completed (loss: 3.6853084564208984, acc: 0.34597155451774597)
[2024-10-22 03:08:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:16][root][INFO] - Training Epoch: 1/2, step 273/7134 completed (loss: 3.656416416168213, acc: 0.2970297038555145)
[2024-10-22 03:08:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:17][root][INFO] - Training Epoch: 1/2, step 274/7134 completed (loss: 4.154804706573486, acc: 0.2447916716337204)
[2024-10-22 03:08:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:17][root][INFO] - Training Epoch: 1/2, step 275/7134 completed (loss: 3.713869333267212, acc: 0.33944955468177795)
[2024-10-22 03:08:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:18][root][INFO] - Training Epoch: 1/2, step 276/7134 completed (loss: 3.954522132873535, acc: 0.2818181812763214)
[2024-10-22 03:08:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:19][root][INFO] - Training Epoch: 1/2, step 277/7134 completed (loss: 3.7547426223754883, acc: 0.31018519401550293)
[2024-10-22 03:08:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:19][root][INFO] - Training Epoch: 1/2, step 278/7134 completed (loss: 4.030076026916504, acc: 0.3113207519054413)
[2024-10-22 03:08:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:20][root][INFO] - Training Epoch: 1/2, step 279/7134 completed (loss: 3.5124223232269287, acc: 0.32093024253845215)
[2024-10-22 03:08:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:20][root][INFO] - Training Epoch: 1/2, step 280/7134 completed (loss: 4.045289516448975, acc: 0.30463576316833496)
[2024-10-22 03:08:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:21][root][INFO] - Training Epoch: 1/2, step 281/7134 completed (loss: 3.92531681060791, acc: 0.31578946113586426)
[2024-10-22 03:08:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:21][root][INFO] - Training Epoch: 1/2, step 282/7134 completed (loss: 3.9420928955078125, acc: 0.2742857038974762)
[2024-10-22 03:08:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:22][root][INFO] - Training Epoch: 1/2, step 283/7134 completed (loss: 4.13790225982666, acc: 0.2733812928199768)
[2024-10-22 03:08:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:23][root][INFO] - Training Epoch: 1/2, step 284/7134 completed (loss: 3.870595932006836, acc: 0.2631579041481018)
[2024-10-22 03:08:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:23][root][INFO] - Training Epoch: 1/2, step 285/7134 completed (loss: 4.209474563598633, acc: 0.2708333432674408)
[2024-10-22 03:08:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:24][root][INFO] - Training Epoch: 1/2, step 286/7134 completed (loss: 4.3831071853637695, acc: 0.25641027092933655)
[2024-10-22 03:08:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:24][root][INFO] - Training Epoch: 1/2, step 287/7134 completed (loss: 3.94193696975708, acc: 0.31677019596099854)
[2024-10-22 03:08:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:25][root][INFO] - Training Epoch: 1/2, step 288/7134 completed (loss: 3.929046869277954, acc: 0.31386861205101013)
[2024-10-22 03:08:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:26][root][INFO] - Training Epoch: 1/2, step 289/7134 completed (loss: 3.757009267807007, acc: 0.30985915660858154)
[2024-10-22 03:08:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:26][root][INFO] - Training Epoch: 1/2, step 290/7134 completed (loss: 3.5501186847686768, acc: 0.3641618490219116)
[2024-10-22 03:08:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:27][root][INFO] - Training Epoch: 1/2, step 291/7134 completed (loss: 3.84023118019104, acc: 0.3229813575744629)
[2024-10-22 03:08:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:27][root][INFO] - Training Epoch: 1/2, step 292/7134 completed (loss: 4.357574462890625, acc: 0.25882354378700256)
[2024-10-22 03:08:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:28][root][INFO] - Training Epoch: 1/2, step 293/7134 completed (loss: 3.878170967102051, acc: 0.341269850730896)
[2024-10-22 03:08:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:29][root][INFO] - Training Epoch: 1/2, step 294/7134 completed (loss: 4.489795684814453, acc: 0.19847328960895538)
[2024-10-22 03:08:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:29][root][INFO] - Training Epoch: 1/2, step 295/7134 completed (loss: 3.9028024673461914, acc: 0.3076923191547394)
[2024-10-22 03:08:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:30][root][INFO] - Training Epoch: 1/2, step 296/7134 completed (loss: 3.881840229034424, acc: 0.347517728805542)
[2024-10-22 03:08:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:30][root][INFO] - Training Epoch: 1/2, step 297/7134 completed (loss: 3.6995389461517334, acc: 0.31386861205101013)
[2024-10-22 03:08:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:31][root][INFO] - Training Epoch: 1/2, step 298/7134 completed (loss: 3.947622537612915, acc: 0.3287671208381653)
[2024-10-22 03:08:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:32][root][INFO] - Training Epoch: 1/2, step 299/7134 completed (loss: 3.8498964309692383, acc: 0.2751677930355072)
[2024-10-22 03:08:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:32][root][INFO] - Training Epoch: 1/2, step 300/7134 completed (loss: 3.3867852687835693, acc: 0.40816327929496765)
[2024-10-22 03:08:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:33][root][INFO] - Training Epoch: 1/2, step 301/7134 completed (loss: 3.9120171070098877, acc: 0.33974358439445496)
[2024-10-22 03:08:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:33][root][INFO] - Training Epoch: 1/2, step 302/7134 completed (loss: 3.766843557357788, acc: 0.32743361592292786)
[2024-10-22 03:08:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:34][root][INFO] - Training Epoch: 1/2, step 303/7134 completed (loss: 4.363339424133301, acc: 0.28688523173332214)
[2024-10-22 03:08:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:34][root][INFO] - Training Epoch: 1/2, step 304/7134 completed (loss: 4.1463236808776855, acc: 0.30909091234207153)
[2024-10-22 03:08:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:35][root][INFO] - Training Epoch: 1/2, step 305/7134 completed (loss: 3.5981733798980713, acc: 0.2847222089767456)
[2024-10-22 03:08:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:36][root][INFO] - Training Epoch: 1/2, step 306/7134 completed (loss: 4.12405252456665, acc: 0.27272728085517883)
[2024-10-22 03:08:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:36][root][INFO] - Training Epoch: 1/2, step 307/7134 completed (loss: 3.635326862335205, acc: 0.3870967626571655)
[2024-10-22 03:08:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:37][root][INFO] - Training Epoch: 1/2, step 308/7134 completed (loss: 3.7106246948242188, acc: 0.3188405930995941)
[2024-10-22 03:08:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:37][root][INFO] - Training Epoch: 1/2, step 309/7134 completed (loss: 3.9863839149475098, acc: 0.27906978130340576)
[2024-10-22 03:08:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:38][root][INFO] - Training Epoch: 1/2, step 310/7134 completed (loss: 3.8591630458831787, acc: 0.3308270573616028)
[2024-10-22 03:08:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:39][root][INFO] - Training Epoch: 1/2, step 311/7134 completed (loss: 3.9292538166046143, acc: 0.2957746386528015)
[2024-10-22 03:08:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:39][root][INFO] - Training Epoch: 1/2, step 312/7134 completed (loss: 3.819230794906616, acc: 0.2777777910232544)
[2024-10-22 03:08:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:40][root][INFO] - Training Epoch: 1/2, step 313/7134 completed (loss: 3.8174896240234375, acc: 0.3037036955356598)
[2024-10-22 03:08:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:40][root][INFO] - Training Epoch: 1/2, step 314/7134 completed (loss: 3.918980836868286, acc: 0.3561643958091736)
[2024-10-22 03:08:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:41][root][INFO] - Training Epoch: 1/2, step 315/7134 completed (loss: 3.658848524093628, acc: 0.3955223858356476)
[2024-10-22 03:08:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:42][root][INFO] - Training Epoch: 1/2, step 316/7134 completed (loss: 3.3684403896331787, acc: 0.3798449635505676)
[2024-10-22 03:08:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:42][root][INFO] - Training Epoch: 1/2, step 317/7134 completed (loss: 3.8659873008728027, acc: 0.28313252329826355)
[2024-10-22 03:08:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:43][root][INFO] - Training Epoch: 1/2, step 318/7134 completed (loss: 4.024460792541504, acc: 0.2970297038555145)
[2024-10-22 03:08:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:43][root][INFO] - Training Epoch: 1/2, step 319/7134 completed (loss: 4.018314838409424, acc: 0.2881355881690979)
[2024-10-22 03:08:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:44][root][INFO] - Training Epoch: 1/2, step 320/7134 completed (loss: 3.8109700679779053, acc: 0.2888889014720917)
[2024-10-22 03:08:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:45][root][INFO] - Training Epoch: 1/2, step 321/7134 completed (loss: 3.653594732284546, acc: 0.3636363744735718)
[2024-10-22 03:08:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:45][root][INFO] - Training Epoch: 1/2, step 322/7134 completed (loss: 3.605257272720337, acc: 0.3452380895614624)
[2024-10-22 03:08:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:46][root][INFO] - Training Epoch: 1/2, step 323/7134 completed (loss: 3.8482916355133057, acc: 0.3378378450870514)
[2024-10-22 03:08:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:46][root][INFO] - Training Epoch: 1/2, step 324/7134 completed (loss: 3.276676893234253, acc: 0.40400001406669617)
[2024-10-22 03:08:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:47][root][INFO] - Training Epoch: 1/2, step 325/7134 completed (loss: 3.5640408992767334, acc: 0.3520408272743225)
[2024-10-22 03:08:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:48][root][INFO] - Training Epoch: 1/2, step 326/7134 completed (loss: 3.1373648643493652, acc: 0.38679245114326477)
[2024-10-22 03:08:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:48][root][INFO] - Training Epoch: 1/2, step 327/7134 completed (loss: 3.634873151779175, acc: 0.31506848335266113)
[2024-10-22 03:08:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:49][root][INFO] - Training Epoch: 1/2, step 328/7134 completed (loss: 3.707618474960327, acc: 0.29651162028312683)
[2024-10-22 03:08:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:49][root][INFO] - Training Epoch: 1/2, step 329/7134 completed (loss: 3.7796356678009033, acc: 0.3457943797111511)
[2024-10-22 03:08:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:50][root][INFO] - Training Epoch: 1/2, step 330/7134 completed (loss: 3.1768901348114014, acc: 0.41600000858306885)
[2024-10-22 03:08:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:50][root][INFO] - Training Epoch: 1/2, step 331/7134 completed (loss: 3.492021322250366, acc: 0.35185185074806213)
[2024-10-22 03:08:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:51][root][INFO] - Training Epoch: 1/2, step 332/7134 completed (loss: 3.452526569366455, acc: 0.3457943797111511)
[2024-10-22 03:08:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:52][root][INFO] - Training Epoch: 1/2, step 333/7134 completed (loss: 4.026382923126221, acc: 0.23923444747924805)
[2024-10-22 03:08:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:52][root][INFO] - Training Epoch: 1/2, step 334/7134 completed (loss: 3.835922956466675, acc: 0.3147208094596863)
[2024-10-22 03:08:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:53][root][INFO] - Training Epoch: 1/2, step 335/7134 completed (loss: 3.4512391090393066, acc: 0.35329341888427734)
[2024-10-22 03:08:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:53][root][INFO] - Training Epoch: 1/2, step 336/7134 completed (loss: 3.609549045562744, acc: 0.302325576543808)
[2024-10-22 03:08:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:54][root][INFO] - Training Epoch: 1/2, step 337/7134 completed (loss: 3.498030424118042, acc: 0.34065935015678406)
[2024-10-22 03:08:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:54][root][INFO] - Training Epoch: 1/2, step 338/7134 completed (loss: 3.907806873321533, acc: 0.28837209939956665)
[2024-10-22 03:08:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:55][root][INFO] - Training Epoch: 1/2, step 339/7134 completed (loss: 3.7260797023773193, acc: 0.2985782027244568)
[2024-10-22 03:08:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:55][root][INFO] - Training Epoch: 1/2, step 340/7134 completed (loss: 3.470041275024414, acc: 0.37837839126586914)
[2024-10-22 03:08:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:56][root][INFO] - Training Epoch: 1/2, step 341/7134 completed (loss: 3.548544406890869, acc: 0.3317972421646118)
[2024-10-22 03:08:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:57][root][INFO] - Training Epoch: 1/2, step 342/7134 completed (loss: 3.500326633453369, acc: 0.33898305892944336)
[2024-10-22 03:08:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:57][root][INFO] - Training Epoch: 1/2, step 343/7134 completed (loss: 3.6959261894226074, acc: 0.2957746386528015)
[2024-10-22 03:08:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:58][root][INFO] - Training Epoch: 1/2, step 344/7134 completed (loss: 3.8171896934509277, acc: 0.29801324009895325)
[2024-10-22 03:08:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:58][root][INFO] - Training Epoch: 1/2, step 345/7134 completed (loss: 4.068058967590332, acc: 0.2532467544078827)
[2024-10-22 03:08:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:08:59][root][INFO] - Training Epoch: 1/2, step 346/7134 completed (loss: 3.9915976524353027, acc: 0.26249998807907104)
[2024-10-22 03:08:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:00][root][INFO] - Training Epoch: 1/2, step 347/7134 completed (loss: 3.646998405456543, acc: 0.3444444537162781)
[2024-10-22 03:09:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:00][root][INFO] - Training Epoch: 1/2, step 348/7134 completed (loss: 3.427018642425537, acc: 0.3172042965888977)
[2024-10-22 03:09:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:01][root][INFO] - Training Epoch: 1/2, step 349/7134 completed (loss: 3.7509100437164307, acc: 0.31550800800323486)
[2024-10-22 03:09:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:02][root][INFO] - Training Epoch: 1/2, step 350/7134 completed (loss: 3.7918596267700195, acc: 0.2757009267807007)
[2024-10-22 03:09:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:02][root][INFO] - Training Epoch: 1/2, step 351/7134 completed (loss: 3.8623695373535156, acc: 0.30693069100379944)
[2024-10-22 03:09:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:03][root][INFO] - Training Epoch: 1/2, step 352/7134 completed (loss: 3.459731101989746, acc: 0.376963347196579)
[2024-10-22 03:09:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:03][root][INFO] - Training Epoch: 1/2, step 353/7134 completed (loss: 3.7701988220214844, acc: 0.2793295979499817)
[2024-10-22 03:09:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:04][root][INFO] - Training Epoch: 1/2, step 354/7134 completed (loss: 3.660762071609497, acc: 0.3255814015865326)
[2024-10-22 03:09:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:05][root][INFO] - Training Epoch: 1/2, step 355/7134 completed (loss: 3.632495403289795, acc: 0.32258063554763794)
[2024-10-22 03:09:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:05][root][INFO] - Training Epoch: 1/2, step 356/7134 completed (loss: 3.3150315284729004, acc: 0.375)
[2024-10-22 03:09:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:06][root][INFO] - Training Epoch: 1/2, step 357/7134 completed (loss: 3.6650125980377197, acc: 0.28342247009277344)
[2024-10-22 03:09:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:06][root][INFO] - Training Epoch: 1/2, step 358/7134 completed (loss: 3.1615517139434814, acc: 0.38624337315559387)
[2024-10-22 03:09:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:07][root][INFO] - Training Epoch: 1/2, step 359/7134 completed (loss: 3.2378721237182617, acc: 0.37823835015296936)
[2024-10-22 03:09:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:08][root][INFO] - Training Epoch: 1/2, step 360/7134 completed (loss: 3.537614107131958, acc: 0.26829269528388977)
[2024-10-22 03:09:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:08][root][INFO] - Training Epoch: 1/2, step 361/7134 completed (loss: 3.3178560733795166, acc: 0.29050278663635254)
[2024-10-22 03:09:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:09][root][INFO] - Training Epoch: 1/2, step 362/7134 completed (loss: 3.536966562271118, acc: 0.3179190754890442)
[2024-10-22 03:09:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:09][root][INFO] - Training Epoch: 1/2, step 363/7134 completed (loss: 3.685164213180542, acc: 0.2525252401828766)
[2024-10-22 03:09:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:10][root][INFO] - Training Epoch: 1/2, step 364/7134 completed (loss: 3.6362171173095703, acc: 0.29906541109085083)
[2024-10-22 03:09:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:10][root][INFO] - Training Epoch: 1/2, step 365/7134 completed (loss: 3.465719223022461, acc: 0.3195266127586365)
[2024-10-22 03:09:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:11][root][INFO] - Training Epoch: 1/2, step 366/7134 completed (loss: 3.2522172927856445, acc: 0.35057470202445984)
[2024-10-22 03:09:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:12][root][INFO] - Training Epoch: 1/2, step 367/7134 completed (loss: 3.320127248764038, acc: 0.33816424012184143)
[2024-10-22 03:09:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:12][root][INFO] - Training Epoch: 1/2, step 368/7134 completed (loss: 3.2406210899353027, acc: 0.3314606845378876)
[2024-10-22 03:09:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:13][root][INFO] - Training Epoch: 1/2, step 369/7134 completed (loss: 3.8467886447906494, acc: 0.299435019493103)
[2024-10-22 03:09:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:13][root][INFO] - Training Epoch: 1/2, step 370/7134 completed (loss: 3.8087923526763916, acc: 0.27167630195617676)
[2024-10-22 03:09:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:14][root][INFO] - Training Epoch: 1/2, step 371/7134 completed (loss: 3.582933187484741, acc: 0.3045977056026459)
[2024-10-22 03:09:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:14][root][INFO] - Training Epoch: 1/2, step 372/7134 completed (loss: 3.7464799880981445, acc: 0.3005780279636383)
[2024-10-22 03:09:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:15][root][INFO] - Training Epoch: 1/2, step 373/7134 completed (loss: 3.4011688232421875, acc: 0.371257483959198)
[2024-10-22 03:09:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:16][root][INFO] - Training Epoch: 1/2, step 374/7134 completed (loss: 2.9683892726898193, acc: 0.34730538725852966)
[2024-10-22 03:09:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:16][root][INFO] - Training Epoch: 1/2, step 375/7134 completed (loss: 3.311367988586426, acc: 0.37735849618911743)
[2024-10-22 03:09:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:17][root][INFO] - Training Epoch: 1/2, step 376/7134 completed (loss: 3.53283953666687, acc: 0.3640776574611664)
[2024-10-22 03:09:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:17][root][INFO] - Training Epoch: 1/2, step 377/7134 completed (loss: 3.627100944519043, acc: 0.3025641143321991)
[2024-10-22 03:09:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:18][root][INFO] - Training Epoch: 1/2, step 378/7134 completed (loss: 3.969367027282715, acc: 0.25128206610679626)
[2024-10-22 03:09:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:18][root][INFO] - Training Epoch: 1/2, step 379/7134 completed (loss: 3.132209062576294, acc: 0.35348838567733765)
[2024-10-22 03:09:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:19][root][INFO] - Training Epoch: 1/2, step 380/7134 completed (loss: 3.8739638328552246, acc: 0.2991071343421936)
[2024-10-22 03:09:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:20][root][INFO] - Training Epoch: 1/2, step 381/7134 completed (loss: 3.7359583377838135, acc: 0.34761905670166016)
[2024-10-22 03:09:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:20][root][INFO] - Training Epoch: 1/2, step 382/7134 completed (loss: 3.190835475921631, acc: 0.4054054021835327)
[2024-10-22 03:09:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:21][root][INFO] - Training Epoch: 1/2, step 383/7134 completed (loss: 3.105053186416626, acc: 0.3529411852359772)
[2024-10-22 03:09:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:21][root][INFO] - Training Epoch: 1/2, step 384/7134 completed (loss: 3.1270337104797363, acc: 0.39423078298568726)
[2024-10-22 03:09:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:22][root][INFO] - Training Epoch: 1/2, step 385/7134 completed (loss: 3.123173236846924, acc: 0.3720930218696594)
[2024-10-22 03:09:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:22][root][INFO] - Training Epoch: 1/2, step 386/7134 completed (loss: 3.379429817199707, acc: 0.3828125)
[2024-10-22 03:09:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:23][root][INFO] - Training Epoch: 1/2, step 387/7134 completed (loss: 3.731663465499878, acc: 0.2879581153392792)
[2024-10-22 03:09:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:23][root][INFO] - Training Epoch: 1/2, step 388/7134 completed (loss: 3.0109498500823975, acc: 0.4067796468734741)
[2024-10-22 03:09:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:24][root][INFO] - Training Epoch: 1/2, step 389/7134 completed (loss: 3.2252352237701416, acc: 0.3700000047683716)
[2024-10-22 03:09:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:25][root][INFO] - Training Epoch: 1/2, step 390/7134 completed (loss: 3.219533920288086, acc: 0.39156627655029297)
[2024-10-22 03:09:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:25][root][INFO] - Training Epoch: 1/2, step 391/7134 completed (loss: 3.0383505821228027, acc: 0.4378698170185089)
[2024-10-22 03:09:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:26][root][INFO] - Training Epoch: 1/2, step 392/7134 completed (loss: 3.1377789974212646, acc: 0.3567567467689514)
[2024-10-22 03:09:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:26][root][INFO] - Training Epoch: 1/2, step 393/7134 completed (loss: 3.1248834133148193, acc: 0.41826921701431274)
[2024-10-22 03:09:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:27][root][INFO] - Training Epoch: 1/2, step 394/7134 completed (loss: 3.163001298904419, acc: 0.40909090638160706)
[2024-10-22 03:09:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:28][root][INFO] - Training Epoch: 1/2, step 395/7134 completed (loss: 3.0670175552368164, acc: 0.37438422441482544)
[2024-10-22 03:09:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:28][root][INFO] - Training Epoch: 1/2, step 396/7134 completed (loss: 3.453996419906616, acc: 0.34375)
[2024-10-22 03:09:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:29][root][INFO] - Training Epoch: 1/2, step 397/7134 completed (loss: 3.2252025604248047, acc: 0.3857142925262451)
[2024-10-22 03:09:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:29][root][INFO] - Training Epoch: 1/2, step 398/7134 completed (loss: 2.8542017936706543, acc: 0.45798319578170776)
[2024-10-22 03:09:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:30][root][INFO] - Training Epoch: 1/2, step 399/7134 completed (loss: 2.9178073406219482, acc: 0.4193548262119293)
[2024-10-22 03:09:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:30][root][INFO] - Training Epoch: 1/2, step 400/7134 completed (loss: 3.5610029697418213, acc: 0.385869562625885)
[2024-10-22 03:09:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:31][root][INFO] - Training Epoch: 1/2, step 401/7134 completed (loss: 3.653183698654175, acc: 0.3243243098258972)
[2024-10-22 03:09:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:32][root][INFO] - Training Epoch: 1/2, step 402/7134 completed (loss: 3.605648994445801, acc: 0.2752293646335602)
[2024-10-22 03:09:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:32][root][INFO] - Training Epoch: 1/2, step 403/7134 completed (loss: 3.312605619430542, acc: 0.369047611951828)
[2024-10-22 03:09:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:33][root][INFO] - Training Epoch: 1/2, step 404/7134 completed (loss: 3.3064675331115723, acc: 0.3349514603614807)
[2024-10-22 03:09:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:33][root][INFO] - Training Epoch: 1/2, step 405/7134 completed (loss: 3.5395240783691406, acc: 0.34736841917037964)
[2024-10-22 03:09:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:34][root][INFO] - Training Epoch: 1/2, step 406/7134 completed (loss: 3.0645909309387207, acc: 0.36574074625968933)
[2024-10-22 03:09:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:35][root][INFO] - Training Epoch: 1/2, step 407/7134 completed (loss: 2.877788782119751, acc: 0.46276596188545227)
[2024-10-22 03:09:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:35][root][INFO] - Training Epoch: 1/2, step 408/7134 completed (loss: 2.9820351600646973, acc: 0.4103773534297943)
[2024-10-22 03:09:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:36][root][INFO] - Training Epoch: 1/2, step 409/7134 completed (loss: 3.3283097743988037, acc: 0.35746607184410095)
[2024-10-22 03:09:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:36][root][INFO] - Training Epoch: 1/2, step 410/7134 completed (loss: 3.0074329376220703, acc: 0.3804347813129425)
[2024-10-22 03:09:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:37][root][INFO] - Training Epoch: 1/2, step 411/7134 completed (loss: 3.195997953414917, acc: 0.3654618561267853)
[2024-10-22 03:09:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:37][root][INFO] - Training Epoch: 1/2, step 412/7134 completed (loss: 3.1391360759735107, acc: 0.3960784375667572)
[2024-10-22 03:09:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:38][root][INFO] - Training Epoch: 1/2, step 413/7134 completed (loss: 3.431663990020752, acc: 0.3507108986377716)
[2024-10-22 03:09:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:39][root][INFO] - Training Epoch: 1/2, step 414/7134 completed (loss: 3.334306478500366, acc: 0.3731343150138855)
[2024-10-22 03:09:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:39][root][INFO] - Training Epoch: 1/2, step 415/7134 completed (loss: 3.3626341819763184, acc: 0.373913049697876)
[2024-10-22 03:09:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:40][root][INFO] - Training Epoch: 1/2, step 416/7134 completed (loss: 3.110306978225708, acc: 0.3648068606853485)
[2024-10-22 03:09:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:40][root][INFO] - Training Epoch: 1/2, step 417/7134 completed (loss: 3.2130959033966064, acc: 0.3396226465702057)
[2024-10-22 03:09:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:41][root][INFO] - Training Epoch: 1/2, step 418/7134 completed (loss: 3.2136170864105225, acc: 0.40084388852119446)
[2024-10-22 03:09:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:41][root][INFO] - Training Epoch: 1/2, step 419/7134 completed (loss: 3.1102051734924316, acc: 0.3794642984867096)
[2024-10-22 03:09:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:42][root][INFO] - Training Epoch: 1/2, step 420/7134 completed (loss: 3.614149808883667, acc: 0.3032258152961731)
[2024-10-22 03:09:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:43][root][INFO] - Training Epoch: 1/2, step 421/7134 completed (loss: 3.198646068572998, acc: 0.32947975397109985)
[2024-10-22 03:09:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:43][root][INFO] - Training Epoch: 1/2, step 422/7134 completed (loss: 3.5781772136688232, acc: 0.2747252881526947)
[2024-10-22 03:09:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:44][root][INFO] - Training Epoch: 1/2, step 423/7134 completed (loss: 3.192797899246216, acc: 0.318918913602829)
[2024-10-22 03:09:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:44][root][INFO] - Training Epoch: 1/2, step 424/7134 completed (loss: 3.442051649093628, acc: 0.3192771077156067)
[2024-10-22 03:09:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:45][root][INFO] - Training Epoch: 1/2, step 425/7134 completed (loss: 2.975919246673584, acc: 0.4021163880825043)
[2024-10-22 03:09:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:46][root][INFO] - Training Epoch: 1/2, step 426/7134 completed (loss: 3.12900972366333, acc: 0.3606557250022888)
[2024-10-22 03:09:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:46][root][INFO] - Training Epoch: 1/2, step 427/7134 completed (loss: 3.3738396167755127, acc: 0.401197612285614)
[2024-10-22 03:09:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:47][root][INFO] - Training Epoch: 1/2, step 428/7134 completed (loss: 3.429706573486328, acc: 0.3463687002658844)
[2024-10-22 03:09:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:47][root][INFO] - Training Epoch: 1/2, step 429/7134 completed (loss: 3.400646686553955, acc: 0.3392857015132904)
[2024-10-22 03:09:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:48][root][INFO] - Training Epoch: 1/2, step 430/7134 completed (loss: 3.5553133487701416, acc: 0.3489583432674408)
[2024-10-22 03:09:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:48][root][INFO] - Training Epoch: 1/2, step 431/7134 completed (loss: 3.354231834411621, acc: 0.3480663001537323)
[2024-10-22 03:09:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:49][root][INFO] - Training Epoch: 1/2, step 432/7134 completed (loss: 3.4403703212738037, acc: 0.33552631735801697)
[2024-10-22 03:09:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:50][root][INFO] - Training Epoch: 1/2, step 433/7134 completed (loss: 2.967071771621704, acc: 0.4166666567325592)
[2024-10-22 03:09:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:50][root][INFO] - Training Epoch: 1/2, step 434/7134 completed (loss: 3.212890863418579, acc: 0.34090909361839294)
[2024-10-22 03:09:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:51][root][INFO] - Training Epoch: 1/2, step 435/7134 completed (loss: 3.496697425842285, acc: 0.3105263113975525)
[2024-10-22 03:09:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:51][root][INFO] - Training Epoch: 1/2, step 436/7134 completed (loss: 3.087346076965332, acc: 0.36538460850715637)
[2024-10-22 03:09:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:52][root][INFO] - Training Epoch: 1/2, step 437/7134 completed (loss: 3.371678590774536, acc: 0.327160507440567)
[2024-10-22 03:09:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:52][root][INFO] - Training Epoch: 1/2, step 438/7134 completed (loss: 3.2186224460601807, acc: 0.3525179922580719)
[2024-10-22 03:09:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:53][root][INFO] - Training Epoch: 1/2, step 439/7134 completed (loss: 3.2405600547790527, acc: 0.3814432919025421)
[2024-10-22 03:09:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:54][root][INFO] - Training Epoch: 1/2, step 440/7134 completed (loss: 3.4800209999084473, acc: 0.3550724685192108)
[2024-10-22 03:09:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:54][root][INFO] - Training Epoch: 1/2, step 441/7134 completed (loss: 3.2140753269195557, acc: 0.4037266969680786)
[2024-10-22 03:09:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:55][root][INFO] - Training Epoch: 1/2, step 442/7134 completed (loss: 3.228966236114502, acc: 0.32824426889419556)
[2024-10-22 03:09:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:56][root][INFO] - Training Epoch: 1/2, step 443/7134 completed (loss: 3.099613666534424, acc: 0.3734177350997925)
[2024-10-22 03:09:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:56][root][INFO] - Training Epoch: 1/2, step 444/7134 completed (loss: 3.0535964965820312, acc: 0.3805970251560211)
[2024-10-22 03:09:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:57][root][INFO] - Training Epoch: 1/2, step 445/7134 completed (loss: 3.4591598510742188, acc: 0.31137725710868835)
[2024-10-22 03:09:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:57][root][INFO] - Training Epoch: 1/2, step 446/7134 completed (loss: 3.385080099105835, acc: 0.3615819215774536)
[2024-10-22 03:09:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:58][root][INFO] - Training Epoch: 1/2, step 447/7134 completed (loss: 3.366727590560913, acc: 0.30337077379226685)
[2024-10-22 03:09:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:59][root][INFO] - Training Epoch: 1/2, step 448/7134 completed (loss: 3.559138059616089, acc: 0.3578431308269501)
[2024-10-22 03:09:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:09:59][root][INFO] - Training Epoch: 1/2, step 449/7134 completed (loss: 3.3735604286193848, acc: 0.3649289011955261)
[2024-10-22 03:09:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:00][root][INFO] - Training Epoch: 1/2, step 450/7134 completed (loss: 3.361253023147583, acc: 0.38493722677230835)
[2024-10-22 03:10:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:00][root][INFO] - Training Epoch: 1/2, step 451/7134 completed (loss: 3.6672792434692383, acc: 0.3217054307460785)
[2024-10-22 03:10:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:01][root][INFO] - Training Epoch: 1/2, step 452/7134 completed (loss: 3.3795695304870605, acc: 0.3951219618320465)
[2024-10-22 03:10:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:01][root][INFO] - Training Epoch: 1/2, step 453/7134 completed (loss: 3.311342239379883, acc: 0.41290321946144104)
[2024-10-22 03:10:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:02][root][INFO] - Training Epoch: 1/2, step 454/7134 completed (loss: 3.29510760307312, acc: 0.38223937153816223)
[2024-10-22 03:10:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:03][root][INFO] - Training Epoch: 1/2, step 455/7134 completed (loss: 3.2326555252075195, acc: 0.41484716534614563)
[2024-10-22 03:10:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:03][root][INFO] - Training Epoch: 1/2, step 456/7134 completed (loss: 3.576443910598755, acc: 0.30000001192092896)
[2024-10-22 03:10:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:04][root][INFO] - Training Epoch: 1/2, step 457/7134 completed (loss: 3.1832430362701416, acc: 0.3395061790943146)
[2024-10-22 03:10:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:04][root][INFO] - Training Epoch: 1/2, step 458/7134 completed (loss: 3.4065513610839844, acc: 0.33088234066963196)
[2024-10-22 03:10:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:05][root][INFO] - Training Epoch: 1/2, step 459/7134 completed (loss: 3.347355604171753, acc: 0.3494623601436615)
[2024-10-22 03:10:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:06][root][INFO] - Training Epoch: 1/2, step 460/7134 completed (loss: 3.5784733295440674, acc: 0.31578946113586426)
[2024-10-22 03:10:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:06][root][INFO] - Training Epoch: 1/2, step 461/7134 completed (loss: 3.4996960163116455, acc: 0.3492063581943512)
[2024-10-22 03:10:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:07][root][INFO] - Training Epoch: 1/2, step 462/7134 completed (loss: 3.402432918548584, acc: 0.3390558063983917)
[2024-10-22 03:10:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:07][root][INFO] - Training Epoch: 1/2, step 463/7134 completed (loss: 3.6840310096740723, acc: 0.3497757911682129)
[2024-10-22 03:10:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:08][root][INFO] - Training Epoch: 1/2, step 464/7134 completed (loss: 3.0615906715393066, acc: 0.3888888955116272)
[2024-10-22 03:10:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:08][root][INFO] - Training Epoch: 1/2, step 465/7134 completed (loss: 3.195131778717041, acc: 0.43877550959587097)
[2024-10-22 03:10:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:09][root][INFO] - Training Epoch: 1/2, step 466/7134 completed (loss: 3.638308048248291, acc: 0.3882978856563568)
[2024-10-22 03:10:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:10][root][INFO] - Training Epoch: 1/2, step 467/7134 completed (loss: 3.505354881286621, acc: 0.3870967626571655)
[2024-10-22 03:10:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:10][root][INFO] - Training Epoch: 1/2, step 468/7134 completed (loss: 3.529078960418701, acc: 0.38787877559661865)
[2024-10-22 03:10:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:11][root][INFO] - Training Epoch: 1/2, step 469/7134 completed (loss: 3.6316590309143066, acc: 0.4124999940395355)
[2024-10-22 03:10:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:11][root][INFO] - Training Epoch: 1/2, step 470/7134 completed (loss: 3.333357334136963, acc: 0.4127906858921051)
[2024-10-22 03:10:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:12][root][INFO] - Training Epoch: 1/2, step 471/7134 completed (loss: 3.452327013015747, acc: 0.3448275923728943)
[2024-10-22 03:10:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:12][root][INFO] - Training Epoch: 1/2, step 472/7134 completed (loss: 3.4309158325195312, acc: 0.3764705955982208)
[2024-10-22 03:10:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:13][root][INFO] - Training Epoch: 1/2, step 473/7134 completed (loss: 3.469939947128296, acc: 0.33557048439979553)
[2024-10-22 03:10:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:14][root][INFO] - Training Epoch: 1/2, step 474/7134 completed (loss: 3.6903581619262695, acc: 0.3709677457809448)
[2024-10-22 03:10:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:14][root][INFO] - Training Epoch: 1/2, step 475/7134 completed (loss: 3.0191502571105957, acc: 0.45402297377586365)
[2024-10-22 03:10:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:15][root][INFO] - Training Epoch: 1/2, step 476/7134 completed (loss: 3.573528289794922, acc: 0.3870967626571655)
[2024-10-22 03:10:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:15][root][INFO] - Training Epoch: 1/2, step 477/7134 completed (loss: 3.1650550365448, acc: 0.38317757844924927)
[2024-10-22 03:10:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:16][root][INFO] - Training Epoch: 1/2, step 478/7134 completed (loss: 3.17958927154541, acc: 0.39230769872665405)
[2024-10-22 03:10:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:16][root][INFO] - Training Epoch: 1/2, step 479/7134 completed (loss: 3.366471290588379, acc: 0.42134830355644226)
[2024-10-22 03:10:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:17][root][INFO] - Training Epoch: 1/2, step 480/7134 completed (loss: 3.808041572570801, acc: 0.3238636255264282)
[2024-10-22 03:10:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:18][root][INFO] - Training Epoch: 1/2, step 481/7134 completed (loss: 3.5489535331726074, acc: 0.38121548295021057)
[2024-10-22 03:10:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:18][root][INFO] - Training Epoch: 1/2, step 482/7134 completed (loss: 3.5363717079162598, acc: 0.3779069781303406)
[2024-10-22 03:10:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:19][root][INFO] - Training Epoch: 1/2, step 483/7134 completed (loss: 3.4180142879486084, acc: 0.31683167815208435)
[2024-10-22 03:10:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:19][root][INFO] - Training Epoch: 1/2, step 484/7134 completed (loss: 4.074211120605469, acc: 0.2626728117465973)
[2024-10-22 03:10:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:20][root][INFO] - Training Epoch: 1/2, step 485/7134 completed (loss: 3.722119092941284, acc: 0.3684210479259491)
[2024-10-22 03:10:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:20][root][INFO] - Training Epoch: 1/2, step 486/7134 completed (loss: 3.862311840057373, acc: 0.35593220591545105)
[2024-10-22 03:10:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:21][root][INFO] - Training Epoch: 1/2, step 487/7134 completed (loss: 3.591491937637329, acc: 0.3478260934352875)
[2024-10-22 03:10:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:21][root][INFO] - Training Epoch: 1/2, step 488/7134 completed (loss: 3.928006887435913, acc: 0.28859061002731323)
[2024-10-22 03:10:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:22][root][INFO] - Training Epoch: 1/2, step 489/7134 completed (loss: 3.807500123977661, acc: 0.3288590610027313)
[2024-10-22 03:10:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:23][root][INFO] - Training Epoch: 1/2, step 490/7134 completed (loss: 3.187509536743164, acc: 0.4000000059604645)
[2024-10-22 03:10:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:23][root][INFO] - Training Epoch: 1/2, step 491/7134 completed (loss: 3.1192526817321777, acc: 0.42424243688583374)
[2024-10-22 03:10:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:24][root][INFO] - Training Epoch: 1/2, step 492/7134 completed (loss: 3.4798381328582764, acc: 0.3272727131843567)
[2024-10-22 03:10:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:24][root][INFO] - Training Epoch: 1/2, step 493/7134 completed (loss: 3.8430678844451904, acc: 0.29032257199287415)
[2024-10-22 03:10:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:25][root][INFO] - Training Epoch: 1/2, step 494/7134 completed (loss: 3.9237160682678223, acc: 0.28654971718788147)
[2024-10-22 03:10:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:25][root][INFO] - Training Epoch: 1/2, step 495/7134 completed (loss: 2.764322280883789, acc: 0.3897058963775635)
[2024-10-22 03:10:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:26][root][INFO] - Training Epoch: 1/2, step 496/7134 completed (loss: 3.5349326133728027, acc: 0.35922330617904663)
[2024-10-22 03:10:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:27][root][INFO] - Training Epoch: 1/2, step 497/7134 completed (loss: 3.093221664428711, acc: 0.4797297418117523)
[2024-10-22 03:10:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:27][root][INFO] - Training Epoch: 1/2, step 498/7134 completed (loss: 3.1989071369171143, acc: 0.40243902802467346)
[2024-10-22 03:10:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:28][root][INFO] - Training Epoch: 1/2, step 499/7134 completed (loss: 2.7531802654266357, acc: 0.4263959527015686)
[2024-10-22 03:10:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:28][root][INFO] - Training Epoch: 1/2, step 500/7134 completed (loss: 3.2521352767944336, acc: 0.38265305757522583)
[2024-10-22 03:10:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:29][root][INFO] - Training Epoch: 1/2, step 501/7134 completed (loss: 3.1684982776641846, acc: 0.35384616255760193)
[2024-10-22 03:10:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:29][root][INFO] - Training Epoch: 1/2, step 502/7134 completed (loss: 2.8093302249908447, acc: 0.4277108311653137)
[2024-10-22 03:10:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:30][root][INFO] - Training Epoch: 1/2, step 503/7134 completed (loss: 3.0104424953460693, acc: 0.3799999952316284)
[2024-10-22 03:10:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:31][root][INFO] - Training Epoch: 1/2, step 504/7134 completed (loss: 3.2069125175476074, acc: 0.3333333432674408)
[2024-10-22 03:10:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:31][root][INFO] - Training Epoch: 1/2, step 505/7134 completed (loss: 3.8042445182800293, acc: 0.3820224702358246)
[2024-10-22 03:10:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:32][root][INFO] - Training Epoch: 1/2, step 506/7134 completed (loss: 3.226510524749756, acc: 0.3723404109477997)
[2024-10-22 03:10:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:32][root][INFO] - Training Epoch: 1/2, step 507/7134 completed (loss: 3.328233480453491, acc: 0.3807106614112854)
[2024-10-22 03:10:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:33][root][INFO] - Training Epoch: 1/2, step 508/7134 completed (loss: 3.444600820541382, acc: 0.3492063581943512)
[2024-10-22 03:10:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:34][root][INFO] - Training Epoch: 1/2, step 509/7134 completed (loss: 3.9383668899536133, acc: 0.3048780560493469)
[2024-10-22 03:10:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:34][root][INFO] - Training Epoch: 1/2, step 510/7134 completed (loss: 4.415042400360107, acc: 0.26618704199790955)
[2024-10-22 03:10:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:35][root][INFO] - Training Epoch: 1/2, step 511/7134 completed (loss: 4.12484073638916, acc: 0.26724138855934143)
[2024-10-22 03:10:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:35][root][INFO] - Training Epoch: 1/2, step 512/7134 completed (loss: 4.141786098480225, acc: 0.2702702581882477)
[2024-10-22 03:10:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:36][root][INFO] - Training Epoch: 1/2, step 513/7134 completed (loss: 3.63651967048645, acc: 0.35465115308761597)
[2024-10-22 03:10:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:36][root][INFO] - Training Epoch: 1/2, step 514/7134 completed (loss: 4.2451043128967285, acc: 0.2195121943950653)
[2024-10-22 03:10:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:37][root][INFO] - Training Epoch: 1/2, step 515/7134 completed (loss: 4.060035228729248, acc: 0.3081081211566925)
[2024-10-22 03:10:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:38][root][INFO] - Training Epoch: 1/2, step 516/7134 completed (loss: 3.933682680130005, acc: 0.2890625)
[2024-10-22 03:10:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:38][root][INFO] - Training Epoch: 1/2, step 517/7134 completed (loss: 4.139134407043457, acc: 0.30434781312942505)
[2024-10-22 03:10:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:39][root][INFO] - Training Epoch: 1/2, step 518/7134 completed (loss: 4.052840232849121, acc: 0.28205129504203796)
[2024-10-22 03:10:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:39][root][INFO] - Training Epoch: 1/2, step 519/7134 completed (loss: 3.8560032844543457, acc: 0.2857142984867096)
[2024-10-22 03:10:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:40][root][INFO] - Training Epoch: 1/2, step 520/7134 completed (loss: 3.677255392074585, acc: 0.34355828166007996)
[2024-10-22 03:10:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:40][root][INFO] - Training Epoch: 1/2, step 521/7134 completed (loss: 4.0511250495910645, acc: 0.29050278663635254)
[2024-10-22 03:10:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:41][root][INFO] - Training Epoch: 1/2, step 522/7134 completed (loss: 3.8330371379852295, acc: 0.29015544056892395)
[2024-10-22 03:10:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:42][root][INFO] - Training Epoch: 1/2, step 523/7134 completed (loss: 3.154845952987671, acc: 0.4021163880825043)
[2024-10-22 03:10:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:42][root][INFO] - Training Epoch: 1/2, step 524/7134 completed (loss: 3.618393898010254, acc: 0.3403141498565674)
[2024-10-22 03:10:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:43][root][INFO] - Training Epoch: 1/2, step 525/7134 completed (loss: 3.5483202934265137, acc: 0.3563218414783478)
[2024-10-22 03:10:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:43][root][INFO] - Training Epoch: 1/2, step 526/7134 completed (loss: 3.8594870567321777, acc: 0.30481284856796265)
[2024-10-22 03:10:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:44][root][INFO] - Training Epoch: 1/2, step 527/7134 completed (loss: 3.843517541885376, acc: 0.32116788625717163)
[2024-10-22 03:10:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:44][root][INFO] - Training Epoch: 1/2, step 528/7134 completed (loss: 4.015020370483398, acc: 0.328000009059906)
[2024-10-22 03:10:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:45][root][INFO] - Training Epoch: 1/2, step 529/7134 completed (loss: 3.814741611480713, acc: 0.3028571307659149)
[2024-10-22 03:10:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:45][root][INFO] - Training Epoch: 1/2, step 530/7134 completed (loss: 4.119213581085205, acc: 0.27586206793785095)
[2024-10-22 03:10:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:46][root][INFO] - Training Epoch: 1/2, step 531/7134 completed (loss: 3.573225736618042, acc: 0.2976190447807312)
[2024-10-22 03:10:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:47][root][INFO] - Training Epoch: 1/2, step 532/7134 completed (loss: 3.8580431938171387, acc: 0.2857142984867096)
[2024-10-22 03:10:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:47][root][INFO] - Training Epoch: 1/2, step 533/7134 completed (loss: 3.710557699203491, acc: 0.30674847960472107)
[2024-10-22 03:10:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:48][root][INFO] - Training Epoch: 1/2, step 534/7134 completed (loss: 3.9855659008026123, acc: 0.26966291666030884)
[2024-10-22 03:10:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:48][root][INFO] - Training Epoch: 1/2, step 535/7134 completed (loss: 3.723182201385498, acc: 0.3178808093070984)
[2024-10-22 03:10:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:49][root][INFO] - Training Epoch: 1/2, step 536/7134 completed (loss: 3.7777655124664307, acc: 0.3186813294887543)
[2024-10-22 03:10:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:49][root][INFO] - Training Epoch: 1/2, step 537/7134 completed (loss: 3.8513541221618652, acc: 0.3403141498565674)
[2024-10-22 03:10:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:50][root][INFO] - Training Epoch: 1/2, step 538/7134 completed (loss: 3.5158207416534424, acc: 0.3368983864784241)
[2024-10-22 03:10:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:51][root][INFO] - Training Epoch: 1/2, step 539/7134 completed (loss: 4.0811262130737305, acc: 0.33571428060531616)
[2024-10-22 03:10:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:51][root][INFO] - Training Epoch: 1/2, step 540/7134 completed (loss: 4.194269180297852, acc: 0.3103448152542114)
[2024-10-22 03:10:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:52][root][INFO] - Training Epoch: 1/2, step 541/7134 completed (loss: 3.640681505203247, acc: 0.3141361176967621)
[2024-10-22 03:10:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:52][root][INFO] - Training Epoch: 1/2, step 542/7134 completed (loss: 4.146745681762695, acc: 0.2649572789669037)
[2024-10-22 03:10:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:53][root][INFO] - Training Epoch: 1/2, step 543/7134 completed (loss: 3.737443447113037, acc: 0.34161490201950073)
[2024-10-22 03:10:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:53][root][INFO] - Training Epoch: 1/2, step 544/7134 completed (loss: 3.964066505432129, acc: 0.3670886158943176)
[2024-10-22 03:10:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:54][root][INFO] - Training Epoch: 1/2, step 545/7134 completed (loss: 3.827432155609131, acc: 0.3581081032752991)
[2024-10-22 03:10:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:55][root][INFO] - Training Epoch: 1/2, step 546/7134 completed (loss: 3.578606367111206, acc: 0.3658536672592163)
[2024-10-22 03:10:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:55][root][INFO] - Training Epoch: 1/2, step 547/7134 completed (loss: 3.6611099243164062, acc: 0.34337350726127625)
[2024-10-22 03:10:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:56][root][INFO] - Training Epoch: 1/2, step 548/7134 completed (loss: 3.8487014770507812, acc: 0.3491124212741852)
[2024-10-22 03:10:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:56][root][INFO] - Training Epoch: 1/2, step 549/7134 completed (loss: 4.05559778213501, acc: 0.3062500059604645)
[2024-10-22 03:10:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:57][root][INFO] - Training Epoch: 1/2, step 550/7134 completed (loss: 3.7900638580322266, acc: 0.37837839126586914)
[2024-10-22 03:10:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:57][root][INFO] - Training Epoch: 1/2, step 551/7134 completed (loss: 3.504652500152588, acc: 0.3935483992099762)
[2024-10-22 03:10:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:58][root][INFO] - Training Epoch: 1/2, step 552/7134 completed (loss: 3.515336513519287, acc: 0.42774567008018494)
[2024-10-22 03:10:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:58][root][INFO] - Training Epoch: 1/2, step 553/7134 completed (loss: 3.7254891395568848, acc: 0.35576921701431274)
[2024-10-22 03:10:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:10:59][root][INFO] - Training Epoch: 1/2, step 554/7134 completed (loss: 3.706667423248291, acc: 0.30337077379226685)
[2024-10-22 03:10:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:00][root][INFO] - Training Epoch: 1/2, step 555/7134 completed (loss: 3.623814821243286, acc: 0.31609195470809937)
[2024-10-22 03:11:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:00][root][INFO] - Training Epoch: 1/2, step 556/7134 completed (loss: 3.1282222270965576, acc: 0.42696627974510193)
[2024-10-22 03:11:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:01][root][INFO] - Training Epoch: 1/2, step 557/7134 completed (loss: 3.705371141433716, acc: 0.3580246865749359)
[2024-10-22 03:11:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:01][root][INFO] - Training Epoch: 1/2, step 558/7134 completed (loss: 3.5129587650299072, acc: 0.37569060921669006)
[2024-10-22 03:11:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:02][root][INFO] - Training Epoch: 1/2, step 559/7134 completed (loss: 3.316150188446045, acc: 0.3988439440727234)
[2024-10-22 03:11:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:03][root][INFO] - Training Epoch: 1/2, step 560/7134 completed (loss: 4.020987033843994, acc: 0.27407407760620117)
[2024-10-22 03:11:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:03][root][INFO] - Training Epoch: 1/2, step 561/7134 completed (loss: 3.2527518272399902, acc: 0.4032258093357086)
[2024-10-22 03:11:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:04][root][INFO] - Training Epoch: 1/2, step 562/7134 completed (loss: 3.5242159366607666, acc: 0.3257142901420593)
[2024-10-22 03:11:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:04][root][INFO] - Training Epoch: 1/2, step 563/7134 completed (loss: 3.8648133277893066, acc: 0.3333333432674408)
[2024-10-22 03:11:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:05][root][INFO] - Training Epoch: 1/2, step 564/7134 completed (loss: 3.4358508586883545, acc: 0.3834196925163269)
[2024-10-22 03:11:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:05][root][INFO] - Training Epoch: 1/2, step 565/7134 completed (loss: 3.305969715118408, acc: 0.37012988328933716)
[2024-10-22 03:11:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:06][root][INFO] - Training Epoch: 1/2, step 566/7134 completed (loss: 3.5292844772338867, acc: 0.3481481373310089)
[2024-10-22 03:11:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:07][root][INFO] - Training Epoch: 1/2, step 567/7134 completed (loss: 3.8161821365356445, acc: 0.3575129508972168)
[2024-10-22 03:11:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:07][root][INFO] - Training Epoch: 1/2, step 568/7134 completed (loss: 3.3107564449310303, acc: 0.41904762387275696)
[2024-10-22 03:11:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:08][root][INFO] - Training Epoch: 1/2, step 569/7134 completed (loss: 3.6330525875091553, acc: 0.3232323229312897)
[2024-10-22 03:11:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:08][root][INFO] - Training Epoch: 1/2, step 570/7134 completed (loss: 3.668386697769165, acc: 0.3378995358943939)
[2024-10-22 03:11:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:09][root][INFO] - Training Epoch: 1/2, step 571/7134 completed (loss: 3.639803886413574, acc: 0.3365853726863861)
[2024-10-22 03:11:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:10][root][INFO] - Training Epoch: 1/2, step 572/7134 completed (loss: 3.4755656719207764, acc: 0.42105263471603394)
[2024-10-22 03:11:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:10][root][INFO] - Training Epoch: 1/2, step 573/7134 completed (loss: 3.466931104660034, acc: 0.3571428656578064)
[2024-10-22 03:11:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:11][root][INFO] - Training Epoch: 1/2, step 574/7134 completed (loss: 3.667524576187134, acc: 0.3144329786300659)
[2024-10-22 03:11:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:11][root][INFO] - Training Epoch: 1/2, step 575/7134 completed (loss: 3.5644450187683105, acc: 0.33838382363319397)
[2024-10-22 03:11:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:12][root][INFO] - Training Epoch: 1/2, step 576/7134 completed (loss: 3.512132167816162, acc: 0.3623853325843811)
[2024-10-22 03:11:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:12][root][INFO] - Training Epoch: 1/2, step 577/7134 completed (loss: 3.8556933403015137, acc: 0.30927833914756775)
[2024-10-22 03:11:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:13][root][INFO] - Training Epoch: 1/2, step 578/7134 completed (loss: 3.445977210998535, acc: 0.3911111056804657)
[2024-10-22 03:11:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:14][root][INFO] - Training Epoch: 1/2, step 579/7134 completed (loss: 3.4262404441833496, acc: 0.38425925374031067)
[2024-10-22 03:11:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:14][root][INFO] - Training Epoch: 1/2, step 580/7134 completed (loss: 3.8072328567504883, acc: 0.31553396582603455)
[2024-10-22 03:11:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:15][root][INFO] - Training Epoch: 1/2, step 581/7134 completed (loss: 3.8411054611206055, acc: 0.32163742184638977)
[2024-10-22 03:11:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:15][root][INFO] - Training Epoch: 1/2, step 582/7134 completed (loss: 3.55769419670105, acc: 0.3317756950855255)
[2024-10-22 03:11:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:16][root][INFO] - Training Epoch: 1/2, step 583/7134 completed (loss: 3.764141082763672, acc: 0.34871795773506165)
[2024-10-22 03:11:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:17][root][INFO] - Training Epoch: 1/2, step 584/7134 completed (loss: 3.1755480766296387, acc: 0.38164252042770386)
[2024-10-22 03:11:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:17][root][INFO] - Training Epoch: 1/2, step 585/7134 completed (loss: 3.5511562824249268, acc: 0.3034825921058655)
[2024-10-22 03:11:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:18][root][INFO] - Training Epoch: 1/2, step 586/7134 completed (loss: 3.414140224456787, acc: 0.35545024275779724)
[2024-10-22 03:11:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:18][root][INFO] - Training Epoch: 1/2, step 587/7134 completed (loss: 3.7015843391418457, acc: 0.3543689250946045)
[2024-10-22 03:11:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:19][root][INFO] - Training Epoch: 1/2, step 588/7134 completed (loss: 3.817925453186035, acc: 0.30061349272727966)
[2024-10-22 03:11:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:20][root][INFO] - Training Epoch: 1/2, step 589/7134 completed (loss: 3.9309589862823486, acc: 0.29050278663635254)
[2024-10-22 03:11:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:20][root][INFO] - Training Epoch: 1/2, step 590/7134 completed (loss: 3.4638242721557617, acc: 0.3636363744735718)
[2024-10-22 03:11:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:21][root][INFO] - Training Epoch: 1/2, step 591/7134 completed (loss: 3.2822937965393066, acc: 0.32499998807907104)
[2024-10-22 03:11:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:21][root][INFO] - Training Epoch: 1/2, step 592/7134 completed (loss: 3.324125289916992, acc: 0.3469387888908386)
[2024-10-22 03:11:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:22][root][INFO] - Training Epoch: 1/2, step 593/7134 completed (loss: 3.309746503829956, acc: 0.3659793734550476)
[2024-10-22 03:11:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:23][root][INFO] - Training Epoch: 1/2, step 594/7134 completed (loss: 3.423017740249634, acc: 0.34574466943740845)
[2024-10-22 03:11:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:23][root][INFO] - Training Epoch: 1/2, step 595/7134 completed (loss: 3.2433922290802, acc: 0.3497537076473236)
[2024-10-22 03:11:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:24][root][INFO] - Training Epoch: 1/2, step 596/7134 completed (loss: 3.6701996326446533, acc: 0.36125653982162476)
[2024-10-22 03:11:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:25][root][INFO] - Training Epoch: 1/2, step 597/7134 completed (loss: 3.5691425800323486, acc: 0.3076923191547394)
[2024-10-22 03:11:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:25][root][INFO] - Training Epoch: 1/2, step 598/7134 completed (loss: 3.8515472412109375, acc: 0.2985074520111084)
[2024-10-22 03:11:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:26][root][INFO] - Training Epoch: 1/2, step 599/7134 completed (loss: 3.376593828201294, acc: 0.3400000035762787)
[2024-10-22 03:11:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:26][root][INFO] - Training Epoch: 1/2, step 600/7134 completed (loss: 3.6552469730377197, acc: 0.3707317113876343)
[2024-10-22 03:11:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:27][root][INFO] - Training Epoch: 1/2, step 601/7134 completed (loss: 3.7935802936553955, acc: 0.3108808398246765)
[2024-10-22 03:11:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:28][root][INFO] - Training Epoch: 1/2, step 602/7134 completed (loss: 3.3475611209869385, acc: 0.35467979311943054)
[2024-10-22 03:11:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:28][root][INFO] - Training Epoch: 1/2, step 603/7134 completed (loss: 3.6999616622924805, acc: 0.34634146094322205)
[2024-10-22 03:11:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:29][root][INFO] - Training Epoch: 1/2, step 604/7134 completed (loss: 3.443516254425049, acc: 0.3494623601436615)
[2024-10-22 03:11:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:29][root][INFO] - Training Epoch: 1/2, step 605/7134 completed (loss: 3.5347237586975098, acc: 0.35748791694641113)
[2024-10-22 03:11:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:30][root][INFO] - Training Epoch: 1/2, step 606/7134 completed (loss: 3.5808558464050293, acc: 0.3271889388561249)
[2024-10-22 03:11:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:31][root][INFO] - Training Epoch: 1/2, step 607/7134 completed (loss: 3.368952512741089, acc: 0.34972676634788513)
[2024-10-22 03:11:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:31][root][INFO] - Training Epoch: 1/2, step 608/7134 completed (loss: 3.9009482860565186, acc: 0.2970297038555145)
[2024-10-22 03:11:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:32][root][INFO] - Training Epoch: 1/2, step 609/7134 completed (loss: 3.478274345397949, acc: 0.41363635659217834)
[2024-10-22 03:11:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:32][root][INFO] - Training Epoch: 1/2, step 610/7134 completed (loss: 3.517082452774048, acc: 0.36199095845222473)
[2024-10-22 03:11:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:33][root][INFO] - Training Epoch: 1/2, step 611/7134 completed (loss: 3.5409114360809326, acc: 0.38235294818878174)
[2024-10-22 03:11:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:33][root][INFO] - Training Epoch: 1/2, step 612/7134 completed (loss: 3.498108148574829, acc: 0.4019607901573181)
[2024-10-22 03:11:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:34][root][INFO] - Training Epoch: 1/2, step 613/7134 completed (loss: 3.6965487003326416, acc: 0.35746607184410095)
[2024-10-22 03:11:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:35][root][INFO] - Training Epoch: 1/2, step 614/7134 completed (loss: 3.445169687271118, acc: 0.3444976210594177)
[2024-10-22 03:11:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:35][root][INFO] - Training Epoch: 1/2, step 615/7134 completed (loss: 3.0058774948120117, acc: 0.4178403615951538)
[2024-10-22 03:11:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:36][root][INFO] - Training Epoch: 1/2, step 616/7134 completed (loss: 3.5454752445220947, acc: 0.3670886158943176)
[2024-10-22 03:11:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:36][root][INFO] - Training Epoch: 1/2, step 617/7134 completed (loss: 3.4320898056030273, acc: 0.36444443464279175)
[2024-10-22 03:11:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:37][root][INFO] - Training Epoch: 1/2, step 618/7134 completed (loss: 3.4890060424804688, acc: 0.3282051384449005)
[2024-10-22 03:11:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:37][root][INFO] - Training Epoch: 1/2, step 619/7134 completed (loss: 4.201790809631348, acc: 0.2945736348628998)
[2024-10-22 03:11:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:38][root][INFO] - Training Epoch: 1/2, step 620/7134 completed (loss: 3.409693956375122, acc: 0.32335329055786133)
[2024-10-22 03:11:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:39][root][INFO] - Training Epoch: 1/2, step 621/7134 completed (loss: 3.462672472000122, acc: 0.39772728085517883)
[2024-10-22 03:11:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:39][root][INFO] - Training Epoch: 1/2, step 622/7134 completed (loss: 3.676107168197632, acc: 0.369047611951828)
[2024-10-22 03:11:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:40][root][INFO] - Training Epoch: 1/2, step 623/7134 completed (loss: 3.5312387943267822, acc: 0.3819444477558136)
[2024-10-22 03:11:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:40][root][INFO] - Training Epoch: 1/2, step 624/7134 completed (loss: 3.7429487705230713, acc: 0.3493150770664215)
[2024-10-22 03:11:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:41][root][INFO] - Training Epoch: 1/2, step 625/7134 completed (loss: 3.3117775917053223, acc: 0.40340909361839294)
[2024-10-22 03:11:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:41][root][INFO] - Training Epoch: 1/2, step 626/7134 completed (loss: 3.523334503173828, acc: 0.3916083872318268)
[2024-10-22 03:11:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:42][root][INFO] - Training Epoch: 1/2, step 627/7134 completed (loss: 3.310182809829712, acc: 0.3333333432674408)
[2024-10-22 03:11:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:43][root][INFO] - Training Epoch: 1/2, step 628/7134 completed (loss: 3.275722026824951, acc: 0.36666667461395264)
[2024-10-22 03:11:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:43][root][INFO] - Training Epoch: 1/2, step 629/7134 completed (loss: 3.339933156967163, acc: 0.4146341383457184)
[2024-10-22 03:11:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:44][root][INFO] - Training Epoch: 1/2, step 630/7134 completed (loss: 3.3443586826324463, acc: 0.410526305437088)
[2024-10-22 03:11:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:44][root][INFO] - Training Epoch: 1/2, step 631/7134 completed (loss: 3.5914909839630127, acc: 0.31976744532585144)
[2024-10-22 03:11:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:45][root][INFO] - Training Epoch: 1/2, step 632/7134 completed (loss: 3.5663366317749023, acc: 0.3734177350997925)
[2024-10-22 03:11:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:45][root][INFO] - Training Epoch: 1/2, step 633/7134 completed (loss: 3.357848882675171, acc: 0.34224599599838257)
[2024-10-22 03:11:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:46][root][INFO] - Training Epoch: 1/2, step 634/7134 completed (loss: 3.355820417404175, acc: 0.33125001192092896)
[2024-10-22 03:11:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:47][root][INFO] - Training Epoch: 1/2, step 635/7134 completed (loss: 3.3905398845672607, acc: 0.4114285707473755)
[2024-10-22 03:11:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:47][root][INFO] - Training Epoch: 1/2, step 636/7134 completed (loss: 3.4751360416412354, acc: 0.3316326439380646)
[2024-10-22 03:11:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:48][root][INFO] - Training Epoch: 1/2, step 637/7134 completed (loss: 3.3595540523529053, acc: 0.3333333432674408)
[2024-10-22 03:11:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:48][root][INFO] - Training Epoch: 1/2, step 638/7134 completed (loss: 3.71767258644104, acc: 0.32926830649375916)
[2024-10-22 03:11:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:49][root][INFO] - Training Epoch: 1/2, step 639/7134 completed (loss: 3.4952049255371094, acc: 0.3717948794364929)
[2024-10-22 03:11:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:49][root][INFO] - Training Epoch: 1/2, step 640/7134 completed (loss: 3.7801711559295654, acc: 0.25)
[2024-10-22 03:11:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:50][root][INFO] - Training Epoch: 1/2, step 641/7134 completed (loss: 3.477532386779785, acc: 0.3529411852359772)
[2024-10-22 03:11:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:51][root][INFO] - Training Epoch: 1/2, step 642/7134 completed (loss: 3.564741849899292, acc: 0.36486485600471497)
[2024-10-22 03:11:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:51][root][INFO] - Training Epoch: 1/2, step 643/7134 completed (loss: 3.1509687900543213, acc: 0.3877550959587097)
[2024-10-22 03:11:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:52][root][INFO] - Training Epoch: 1/2, step 644/7134 completed (loss: 3.4116106033325195, acc: 0.3333333432674408)
[2024-10-22 03:11:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:52][root][INFO] - Training Epoch: 1/2, step 645/7134 completed (loss: 3.468961715698242, acc: 0.33766233921051025)
[2024-10-22 03:11:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:53][root][INFO] - Training Epoch: 1/2, step 646/7134 completed (loss: 3.3933448791503906, acc: 0.3181818127632141)
[2024-10-22 03:11:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:53][root][INFO] - Training Epoch: 1/2, step 647/7134 completed (loss: 3.489307165145874, acc: 0.3509933650493622)
[2024-10-22 03:11:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:54][root][INFO] - Training Epoch: 1/2, step 648/7134 completed (loss: 4.161062717437744, acc: 0.29931971430778503)
[2024-10-22 03:11:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:55][root][INFO] - Training Epoch: 1/2, step 649/7134 completed (loss: 4.008018970489502, acc: 0.28921568393707275)
[2024-10-22 03:11:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:55][root][INFO] - Training Epoch: 1/2, step 650/7134 completed (loss: 4.463996887207031, acc: 0.2866241931915283)
[2024-10-22 03:11:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:56][root][INFO] - Training Epoch: 1/2, step 651/7134 completed (loss: 3.906697988510132, acc: 0.3631284832954407)
[2024-10-22 03:11:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:56][root][INFO] - Training Epoch: 1/2, step 652/7134 completed (loss: 4.44505500793457, acc: 0.24836601316928864)
[2024-10-22 03:11:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:57][root][INFO] - Training Epoch: 1/2, step 653/7134 completed (loss: 3.692953586578369, acc: 0.34594595432281494)
[2024-10-22 03:11:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:58][root][INFO] - Training Epoch: 1/2, step 654/7134 completed (loss: 3.6392908096313477, acc: 0.3404255211353302)
[2024-10-22 03:11:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:58][root][INFO] - Training Epoch: 1/2, step 655/7134 completed (loss: 4.500529766082764, acc: 0.234375)
[2024-10-22 03:11:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:59][root][INFO] - Training Epoch: 1/2, step 656/7134 completed (loss: 4.204855442047119, acc: 0.25)
[2024-10-22 03:11:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:11:59][root][INFO] - Training Epoch: 1/2, step 657/7134 completed (loss: 4.382584571838379, acc: 0.24203822016716003)
[2024-10-22 03:12:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:00][root][INFO] - Training Epoch: 1/2, step 658/7134 completed (loss: 3.5282156467437744, acc: 0.31216931343078613)
[2024-10-22 03:12:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:00][root][INFO] - Training Epoch: 1/2, step 659/7134 completed (loss: 3.089150905609131, acc: 0.3567567467689514)
[2024-10-22 03:12:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:01][root][INFO] - Training Epoch: 1/2, step 660/7134 completed (loss: 3.3717894554138184, acc: 0.36180904507637024)
[2024-10-22 03:12:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:02][root][INFO] - Training Epoch: 1/2, step 661/7134 completed (loss: 3.234241008758545, acc: 0.3385826647281647)
[2024-10-22 03:12:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:02][root][INFO] - Training Epoch: 1/2, step 662/7134 completed (loss: 3.334331750869751, acc: 0.3368421196937561)
[2024-10-22 03:12:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:03][root][INFO] - Training Epoch: 1/2, step 663/7134 completed (loss: 3.632969856262207, acc: 0.32478633522987366)
[2024-10-22 03:12:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:03][root][INFO] - Training Epoch: 1/2, step 664/7134 completed (loss: 3.8807106018066406, acc: 0.3187499940395355)
[2024-10-22 03:12:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:04][root][INFO] - Training Epoch: 1/2, step 665/7134 completed (loss: 3.4584577083587646, acc: 0.32367148995399475)
[2024-10-22 03:12:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:04][root][INFO] - Training Epoch: 1/2, step 666/7134 completed (loss: 3.8630752563476562, acc: 0.3076923191547394)
[2024-10-22 03:12:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:05][root][INFO] - Training Epoch: 1/2, step 667/7134 completed (loss: 3.7972259521484375, acc: 0.3020833432674408)
[2024-10-22 03:12:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:06][root][INFO] - Training Epoch: 1/2, step 668/7134 completed (loss: 3.619626045227051, acc: 0.3316062092781067)
[2024-10-22 03:12:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:06][root][INFO] - Training Epoch: 1/2, step 669/7134 completed (loss: 3.4669041633605957, acc: 0.3560209572315216)
[2024-10-22 03:12:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:07][root][INFO] - Training Epoch: 1/2, step 670/7134 completed (loss: 3.576512336730957, acc: 0.33877551555633545)
[2024-10-22 03:12:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:07][root][INFO] - Training Epoch: 1/2, step 671/7134 completed (loss: 3.4497230052948, acc: 0.33984375)
[2024-10-22 03:12:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:08][root][INFO] - Training Epoch: 1/2, step 672/7134 completed (loss: 3.427433967590332, acc: 0.3238636255264282)
[2024-10-22 03:12:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:09][root][INFO] - Training Epoch: 1/2, step 673/7134 completed (loss: 3.8255906105041504, acc: 0.2579185664653778)
[2024-10-22 03:12:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:09][root][INFO] - Training Epoch: 1/2, step 674/7134 completed (loss: 3.1787095069885254, acc: 0.37288135290145874)
[2024-10-22 03:12:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:10][root][INFO] - Training Epoch: 1/2, step 675/7134 completed (loss: 3.194575786590576, acc: 0.3897435963153839)
[2024-10-22 03:12:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:10][root][INFO] - Training Epoch: 1/2, step 676/7134 completed (loss: 3.569005250930786, acc: 0.3222748935222626)
[2024-10-22 03:12:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:11][root][INFO] - Training Epoch: 1/2, step 677/7134 completed (loss: 3.247591257095337, acc: 0.3707317113876343)
[2024-10-22 03:12:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:11][root][INFO] - Training Epoch: 1/2, step 678/7134 completed (loss: 3.226548433303833, acc: 0.39790576696395874)
[2024-10-22 03:12:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:12][root][INFO] - Training Epoch: 1/2, step 679/7134 completed (loss: 3.3151793479919434, acc: 0.3935483992099762)
[2024-10-22 03:12:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:12][root][INFO] - Training Epoch: 1/2, step 680/7134 completed (loss: 3.2292981147766113, acc: 0.3883928656578064)
[2024-10-22 03:12:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:13][root][INFO] - Training Epoch: 1/2, step 681/7134 completed (loss: 3.0068588256835938, acc: 0.4082568883895874)
[2024-10-22 03:12:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:14][root][INFO] - Training Epoch: 1/2, step 682/7134 completed (loss: 3.0753133296966553, acc: 0.38999998569488525)
[2024-10-22 03:12:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:14][root][INFO] - Training Epoch: 1/2, step 683/7134 completed (loss: 3.331334352493286, acc: 0.35467979311943054)
[2024-10-22 03:12:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:15][root][INFO] - Training Epoch: 1/2, step 684/7134 completed (loss: 3.2312443256378174, acc: 0.42786070704460144)
[2024-10-22 03:12:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:16][root][INFO] - Training Epoch: 1/2, step 685/7134 completed (loss: 3.3833000659942627, acc: 0.36818182468414307)
[2024-10-22 03:12:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:16][root][INFO] - Training Epoch: 1/2, step 686/7134 completed (loss: 2.8637497425079346, acc: 0.4126213490962982)
[2024-10-22 03:12:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:17][root][INFO] - Training Epoch: 1/2, step 687/7134 completed (loss: 3.5439400672912598, acc: 0.3309859037399292)
[2024-10-22 03:12:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:17][root][INFO] - Training Epoch: 1/2, step 688/7134 completed (loss: 3.0184240341186523, acc: 0.41111111640930176)
[2024-10-22 03:12:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:18][root][INFO] - Training Epoch: 1/2, step 689/7134 completed (loss: 3.540874719619751, acc: 0.3910256326198578)
[2024-10-22 03:12:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:18][root][INFO] - Training Epoch: 1/2, step 690/7134 completed (loss: 3.1285502910614014, acc: 0.375)
[2024-10-22 03:12:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:19][root][INFO] - Training Epoch: 1/2, step 691/7134 completed (loss: 3.9421966075897217, acc: 0.3139534890651703)
[2024-10-22 03:12:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:20][root][INFO] - Training Epoch: 1/2, step 692/7134 completed (loss: 3.7605459690093994, acc: 0.33170732855796814)
[2024-10-22 03:12:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:20][root][INFO] - Training Epoch: 1/2, step 693/7134 completed (loss: 3.6017167568206787, acc: 0.36942675709724426)
[2024-10-22 03:12:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:21][root][INFO] - Training Epoch: 1/2, step 694/7134 completed (loss: 3.7190513610839844, acc: 0.32275131344795227)
[2024-10-22 03:12:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:21][root][INFO] - Training Epoch: 1/2, step 695/7134 completed (loss: 4.087412357330322, acc: 0.28947368264198303)
[2024-10-22 03:12:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:22][root][INFO] - Training Epoch: 1/2, step 696/7134 completed (loss: 3.811619281768799, acc: 0.3519552946090698)
[2024-10-22 03:12:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:23][root][INFO] - Training Epoch: 1/2, step 697/7134 completed (loss: 3.0667405128479004, acc: 0.4238095283508301)
[2024-10-22 03:12:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:23][root][INFO] - Training Epoch: 1/2, step 698/7134 completed (loss: 3.7955987453460693, acc: 0.25874125957489014)
[2024-10-22 03:12:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:24][root][INFO] - Training Epoch: 1/2, step 699/7134 completed (loss: 3.8159172534942627, acc: 0.30061349272727966)
[2024-10-22 03:12:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:24][root][INFO] - Training Epoch: 1/2, step 700/7134 completed (loss: 3.5221240520477295, acc: 0.39436620473861694)
[2024-10-22 03:12:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:25][root][INFO] - Training Epoch: 1/2, step 701/7134 completed (loss: 3.9741885662078857, acc: 0.3191489279270172)
[2024-10-22 03:12:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:25][root][INFO] - Training Epoch: 1/2, step 702/7134 completed (loss: 3.8936212062835693, acc: 0.3353293538093567)
[2024-10-22 03:12:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:26][root][INFO] - Training Epoch: 1/2, step 703/7134 completed (loss: 4.024576187133789, acc: 0.35465115308761597)
[2024-10-22 03:12:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:27][root][INFO] - Training Epoch: 1/2, step 704/7134 completed (loss: 3.788161039352417, acc: 0.33734938502311707)
[2024-10-22 03:12:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:27][root][INFO] - Training Epoch: 1/2, step 705/7134 completed (loss: 3.42087459564209, acc: 0.3855932056903839)
[2024-10-22 03:12:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:28][root][INFO] - Training Epoch: 1/2, step 706/7134 completed (loss: 3.432190179824829, acc: 0.3705357015132904)
[2024-10-22 03:12:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:28][root][INFO] - Training Epoch: 1/2, step 707/7134 completed (loss: 3.515634059906006, acc: 0.33039647340774536)
[2024-10-22 03:12:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:29][root][INFO] - Training Epoch: 1/2, step 708/7134 completed (loss: 3.8434197902679443, acc: 0.3125)
[2024-10-22 03:12:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:29][root][INFO] - Training Epoch: 1/2, step 709/7134 completed (loss: 3.2759897708892822, acc: 0.42131978273391724)
[2024-10-22 03:12:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:30][root][INFO] - Training Epoch: 1/2, step 710/7134 completed (loss: 3.656256675720215, acc: 0.3400000035762787)
[2024-10-22 03:12:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:31][root][INFO] - Training Epoch: 1/2, step 711/7134 completed (loss: 3.463710069656372, acc: 0.3139013350009918)
[2024-10-22 03:12:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:31][root][INFO] - Training Epoch: 1/2, step 712/7134 completed (loss: 3.4681365489959717, acc: 0.3283582031726837)
[2024-10-22 03:12:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:32][root][INFO] - Training Epoch: 1/2, step 713/7134 completed (loss: 3.428154230117798, acc: 0.3502304255962372)
[2024-10-22 03:12:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:32][root][INFO] - Training Epoch: 1/2, step 714/7134 completed (loss: 3.7923765182495117, acc: 0.2666666805744171)
[2024-10-22 03:12:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:33][root][INFO] - Training Epoch: 1/2, step 715/7134 completed (loss: 3.352938652038574, acc: 0.3333333432674408)
[2024-10-22 03:12:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:33][root][INFO] - Training Epoch: 1/2, step 716/7134 completed (loss: 3.1166000366210938, acc: 0.36936935782432556)
[2024-10-22 03:12:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:34][root][INFO] - Training Epoch: 1/2, step 717/7134 completed (loss: 3.4777638912200928, acc: 0.3448275923728943)
[2024-10-22 03:12:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:34][root][INFO] - Training Epoch: 1/2, step 718/7134 completed (loss: 3.56333589553833, acc: 0.3100000023841858)
[2024-10-22 03:12:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:35][root][INFO] - Training Epoch: 1/2, step 719/7134 completed (loss: 3.0832977294921875, acc: 0.38255032896995544)
[2024-10-22 03:12:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:35][root][INFO] - Training Epoch: 1/2, step 720/7134 completed (loss: 3.357619047164917, acc: 0.3195876181125641)
[2024-10-22 03:12:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:36][root][INFO] - Training Epoch: 1/2, step 721/7134 completed (loss: 3.0833935737609863, acc: 0.35323384404182434)
[2024-10-22 03:12:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:37][root][INFO] - Training Epoch: 1/2, step 722/7134 completed (loss: 3.3138298988342285, acc: 0.3640553057193756)
[2024-10-22 03:12:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:37][root][INFO] - Training Epoch: 1/2, step 723/7134 completed (loss: 3.063286066055298, acc: 0.3921568691730499)
[2024-10-22 03:12:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:38][root][INFO] - Training Epoch: 1/2, step 724/7134 completed (loss: 3.4394609928131104, acc: 0.33888888359069824)
[2024-10-22 03:12:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:39][root][INFO] - Training Epoch: 1/2, step 725/7134 completed (loss: 3.0495338439941406, acc: 0.3488371968269348)
[2024-10-22 03:12:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:39][root][INFO] - Training Epoch: 1/2, step 726/7134 completed (loss: 3.034440517425537, acc: 0.35483869910240173)
[2024-10-22 03:12:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:40][root][INFO] - Training Epoch: 1/2, step 727/7134 completed (loss: 3.1105685234069824, acc: 0.38333332538604736)
[2024-10-22 03:12:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:40][root][INFO] - Training Epoch: 1/2, step 728/7134 completed (loss: 3.285978317260742, acc: 0.32608696818351746)
[2024-10-22 03:12:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:41][root][INFO] - Training Epoch: 1/2, step 729/7134 completed (loss: 2.867515802383423, acc: 0.38728323578834534)
[2024-10-22 03:12:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:41][root][INFO] - Training Epoch: 1/2, step 730/7134 completed (loss: 2.661607027053833, acc: 0.39500001072883606)
[2024-10-22 03:12:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:42][root][INFO] - Training Epoch: 1/2, step 731/7134 completed (loss: 2.9431052207946777, acc: 0.375)
[2024-10-22 03:12:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:43][root][INFO] - Training Epoch: 1/2, step 732/7134 completed (loss: 3.554957866668701, acc: 0.3359375)
[2024-10-22 03:12:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:43][root][INFO] - Training Epoch: 1/2, step 733/7134 completed (loss: 3.8733785152435303, acc: 0.30882352590560913)
[2024-10-22 03:12:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:44][root][INFO] - Training Epoch: 1/2, step 734/7134 completed (loss: 4.030087947845459, acc: 0.3435114622116089)
[2024-10-22 03:12:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:44][root][INFO] - Training Epoch: 1/2, step 735/7134 completed (loss: 3.5724070072174072, acc: 0.3112582862377167)
[2024-10-22 03:12:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:45][root][INFO] - Training Epoch: 1/2, step 736/7134 completed (loss: 3.7056143283843994, acc: 0.315315306186676)
[2024-10-22 03:12:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:45][root][INFO] - Training Epoch: 1/2, step 737/7134 completed (loss: 3.5606415271759033, acc: 0.3730158805847168)
[2024-10-22 03:12:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:46][root][INFO] - Training Epoch: 1/2, step 738/7134 completed (loss: 4.351140022277832, acc: 0.24778760969638824)
[2024-10-22 03:12:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:47][root][INFO] - Training Epoch: 1/2, step 739/7134 completed (loss: 4.021963119506836, acc: 0.30645161867141724)
[2024-10-22 03:12:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:47][root][INFO] - Training Epoch: 1/2, step 740/7134 completed (loss: 3.496366500854492, acc: 0.3636363744735718)
[2024-10-22 03:12:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:48][root][INFO] - Training Epoch: 1/2, step 741/7134 completed (loss: 3.535867929458618, acc: 0.3426573574542999)
[2024-10-22 03:12:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:48][root][INFO] - Training Epoch: 1/2, step 742/7134 completed (loss: 3.64026141166687, acc: 0.3689320385456085)
[2024-10-22 03:12:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:49][root][INFO] - Training Epoch: 1/2, step 743/7134 completed (loss: 3.39168119430542, acc: 0.3612903356552124)
[2024-10-22 03:12:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:49][root][INFO] - Training Epoch: 1/2, step 744/7134 completed (loss: 3.587958812713623, acc: 0.35185185074806213)
[2024-10-22 03:12:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:50][root][INFO] - Training Epoch: 1/2, step 745/7134 completed (loss: 3.139857769012451, acc: 0.34228187799453735)
[2024-10-22 03:12:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:51][root][INFO] - Training Epoch: 1/2, step 746/7134 completed (loss: 3.492556095123291, acc: 0.35333332419395447)
[2024-10-22 03:12:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:51][root][INFO] - Training Epoch: 1/2, step 747/7134 completed (loss: 3.5980730056762695, acc: 0.4154929518699646)
[2024-10-22 03:12:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:52][root][INFO] - Training Epoch: 1/2, step 748/7134 completed (loss: 3.3262269496917725, acc: 0.3986486494541168)
[2024-10-22 03:12:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:52][root][INFO] - Training Epoch: 1/2, step 749/7134 completed (loss: 3.1349170207977295, acc: 0.3935483992099762)
[2024-10-22 03:12:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:53][root][INFO] - Training Epoch: 1/2, step 750/7134 completed (loss: 3.8944742679595947, acc: 0.3181818127632141)
[2024-10-22 03:12:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:54][root][INFO] - Training Epoch: 1/2, step 751/7134 completed (loss: 3.63649320602417, acc: 0.3741496503353119)
[2024-10-22 03:12:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:54][root][INFO] - Training Epoch: 1/2, step 752/7134 completed (loss: 3.713102340698242, acc: 0.4117647111415863)
[2024-10-22 03:12:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:55][root][INFO] - Training Epoch: 1/2, step 753/7134 completed (loss: 3.5911102294921875, acc: 0.3550724685192108)
[2024-10-22 03:12:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:55][root][INFO] - Training Epoch: 1/2, step 754/7134 completed (loss: 3.113420009613037, acc: 0.4275861978530884)
[2024-10-22 03:12:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:56][root][INFO] - Training Epoch: 1/2, step 755/7134 completed (loss: 3.607839584350586, acc: 0.3602941036224365)
[2024-10-22 03:12:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:56][root][INFO] - Training Epoch: 1/2, step 756/7134 completed (loss: 3.8237292766571045, acc: 0.30327868461608887)
[2024-10-22 03:12:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:57][root][INFO] - Training Epoch: 1/2, step 757/7134 completed (loss: 3.95815372467041, acc: 0.28070175647735596)
[2024-10-22 03:12:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:58][root][INFO] - Training Epoch: 1/2, step 758/7134 completed (loss: 3.3275787830352783, acc: 0.3467741906642914)
[2024-10-22 03:12:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:58][root][INFO] - Training Epoch: 1/2, step 759/7134 completed (loss: 3.81180477142334, acc: 0.28099173307418823)
[2024-10-22 03:12:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:59][root][INFO] - Training Epoch: 1/2, step 760/7134 completed (loss: 3.6201272010803223, acc: 0.347517728805542)
[2024-10-22 03:12:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:12:59][root][INFO] - Training Epoch: 1/2, step 761/7134 completed (loss: 3.4778947830200195, acc: 0.3218390941619873)
[2024-10-22 03:12:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:00][root][INFO] - Training Epoch: 1/2, step 762/7134 completed (loss: 3.8745503425598145, acc: 0.3137255012989044)
[2024-10-22 03:13:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:00][root][INFO] - Training Epoch: 1/2, step 763/7134 completed (loss: 3.630425214767456, acc: 0.34117648005485535)
[2024-10-22 03:13:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:01][root][INFO] - Training Epoch: 1/2, step 764/7134 completed (loss: 3.763355255126953, acc: 0.30000001192092896)
[2024-10-22 03:13:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:01][root][INFO] - Training Epoch: 1/2, step 765/7134 completed (loss: 3.603372097015381, acc: 0.3030303120613098)
[2024-10-22 03:13:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:02][root][INFO] - Training Epoch: 1/2, step 766/7134 completed (loss: 3.603177785873413, acc: 0.28313252329826355)
[2024-10-22 03:13:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:03][root][INFO] - Training Epoch: 1/2, step 767/7134 completed (loss: 3.2824671268463135, acc: 0.35227271914482117)
[2024-10-22 03:13:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:03][root][INFO] - Training Epoch: 1/2, step 768/7134 completed (loss: 3.3518738746643066, acc: 0.34020617604255676)
[2024-10-22 03:13:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:04][root][INFO] - Training Epoch: 1/2, step 769/7134 completed (loss: 3.615183115005493, acc: 0.3005780279636383)
[2024-10-22 03:13:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:04][root][INFO] - Training Epoch: 1/2, step 770/7134 completed (loss: 3.3818166255950928, acc: 0.3785310685634613)
[2024-10-22 03:13:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:05][root][INFO] - Training Epoch: 1/2, step 771/7134 completed (loss: 3.35294508934021, acc: 0.3469387888908386)
[2024-10-22 03:13:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:05][root][INFO] - Training Epoch: 1/2, step 772/7134 completed (loss: 3.1339354515075684, acc: 0.3636363744735718)
[2024-10-22 03:13:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:06][root][INFO] - Training Epoch: 1/2, step 773/7134 completed (loss: 3.317347288131714, acc: 0.3497537076473236)
[2024-10-22 03:13:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:07][root][INFO] - Training Epoch: 1/2, step 774/7134 completed (loss: 3.844542980194092, acc: 0.25827813148498535)
[2024-10-22 03:13:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:07][root][INFO] - Training Epoch: 1/2, step 775/7134 completed (loss: 3.3597519397735596, acc: 0.36868685483932495)
[2024-10-22 03:13:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:08][root][INFO] - Training Epoch: 1/2, step 776/7134 completed (loss: 3.3431854248046875, acc: 0.3619631826877594)
[2024-10-22 03:13:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:08][root][INFO] - Training Epoch: 1/2, step 777/7134 completed (loss: 3.2873177528381348, acc: 0.36477985978126526)
[2024-10-22 03:13:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:09][root][INFO] - Training Epoch: 1/2, step 778/7134 completed (loss: 3.5797441005706787, acc: 0.33136093616485596)
[2024-10-22 03:13:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:09][root][INFO] - Training Epoch: 1/2, step 779/7134 completed (loss: 3.45405650138855, acc: 0.3687150776386261)
[2024-10-22 03:13:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:10][root][INFO] - Training Epoch: 1/2, step 780/7134 completed (loss: 3.4853334426879883, acc: 0.37931033968925476)
[2024-10-22 03:13:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:11][root][INFO] - Training Epoch: 1/2, step 781/7134 completed (loss: 3.3568642139434814, acc: 0.3378378450870514)
[2024-10-22 03:13:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:11][root][INFO] - Training Epoch: 1/2, step 782/7134 completed (loss: 3.519556999206543, acc: 0.3222222328186035)
[2024-10-22 03:13:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:12][root][INFO] - Training Epoch: 1/2, step 783/7134 completed (loss: 3.3029966354370117, acc: 0.3583333194255829)
[2024-10-22 03:13:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:12][root][INFO] - Training Epoch: 1/2, step 784/7134 completed (loss: 3.0226542949676514, acc: 0.336448609828949)
[2024-10-22 03:13:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:13][root][INFO] - Training Epoch: 1/2, step 785/7134 completed (loss: 3.850534439086914, acc: 0.31481480598449707)
[2024-10-22 03:13:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:13][root][INFO] - Training Epoch: 1/2, step 786/7134 completed (loss: 3.714815616607666, acc: 0.3496503531932831)
[2024-10-22 03:13:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:14][root][INFO] - Training Epoch: 1/2, step 787/7134 completed (loss: 3.4527602195739746, acc: 0.32374101877212524)
[2024-10-22 03:13:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:14][root][INFO] - Training Epoch: 1/2, step 788/7134 completed (loss: 3.3804678916931152, acc: 0.3636363744735718)
[2024-10-22 03:13:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:15][root][INFO] - Training Epoch: 1/2, step 789/7134 completed (loss: 3.9628515243530273, acc: 0.2732558250427246)
[2024-10-22 03:13:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:16][root][INFO] - Training Epoch: 1/2, step 790/7134 completed (loss: 3.868952751159668, acc: 0.2634730637073517)
[2024-10-22 03:13:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:16][root][INFO] - Training Epoch: 1/2, step 791/7134 completed (loss: 3.9263463020324707, acc: 0.3046875)
[2024-10-22 03:13:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:17][root][INFO] - Training Epoch: 1/2, step 792/7134 completed (loss: 3.702911853790283, acc: 0.3142857253551483)
[2024-10-22 03:13:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:17][root][INFO] - Training Epoch: 1/2, step 793/7134 completed (loss: 3.8300600051879883, acc: 0.28070175647735596)
[2024-10-22 03:13:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:18][root][INFO] - Training Epoch: 1/2, step 794/7134 completed (loss: 3.972022533416748, acc: 0.3193277418613434)
[2024-10-22 03:13:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:18][root][INFO] - Training Epoch: 1/2, step 795/7134 completed (loss: 3.4316916465759277, acc: 0.3820224702358246)
[2024-10-22 03:13:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:19][root][INFO] - Training Epoch: 1/2, step 796/7134 completed (loss: 3.841740846633911, acc: 0.30000001192092896)
[2024-10-22 03:13:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:20][root][INFO] - Training Epoch: 1/2, step 797/7134 completed (loss: 4.235488414764404, acc: 0.17557251453399658)
[2024-10-22 03:13:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:20][root][INFO] - Training Epoch: 1/2, step 798/7134 completed (loss: 3.9996469020843506, acc: 0.2571428716182709)
[2024-10-22 03:13:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:21][root][INFO] - Training Epoch: 1/2, step 799/7134 completed (loss: 4.018221378326416, acc: 0.3100775182247162)
[2024-10-22 03:13:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:21][root][INFO] - Training Epoch: 1/2, step 800/7134 completed (loss: 3.4668731689453125, acc: 0.3472222089767456)
[2024-10-22 03:13:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:22][root][INFO] - Training Epoch: 1/2, step 801/7134 completed (loss: 3.967162847518921, acc: 0.3257142901420593)
[2024-10-22 03:13:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:22][root][INFO] - Training Epoch: 1/2, step 802/7134 completed (loss: 3.7299389839172363, acc: 0.35624998807907104)
[2024-10-22 03:13:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:23][root][INFO] - Training Epoch: 1/2, step 803/7134 completed (loss: 3.9190831184387207, acc: 0.2638888955116272)
[2024-10-22 03:13:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:23][root][INFO] - Training Epoch: 1/2, step 804/7134 completed (loss: 3.5930111408233643, acc: 0.326241135597229)
[2024-10-22 03:13:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:24][root][INFO] - Training Epoch: 1/2, step 805/7134 completed (loss: 3.953831672668457, acc: 0.29559749364852905)
[2024-10-22 03:13:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:25][root][INFO] - Training Epoch: 1/2, step 806/7134 completed (loss: 3.3439829349517822, acc: 0.3238636255264282)
[2024-10-22 03:13:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:25][root][INFO] - Training Epoch: 1/2, step 807/7134 completed (loss: 3.31976580619812, acc: 0.3835616409778595)
[2024-10-22 03:13:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:26][root][INFO] - Training Epoch: 1/2, step 808/7134 completed (loss: 3.3772990703582764, acc: 0.35779815912246704)
[2024-10-22 03:13:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:26][root][INFO] - Training Epoch: 1/2, step 809/7134 completed (loss: 3.4387710094451904, acc: 0.3313252925872803)
[2024-10-22 03:13:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:27][root][INFO] - Training Epoch: 1/2, step 810/7134 completed (loss: 3.2202951908111572, acc: 0.3251231610774994)
[2024-10-22 03:13:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:27][root][INFO] - Training Epoch: 1/2, step 811/7134 completed (loss: 3.5298047065734863, acc: 0.3757961690425873)
[2024-10-22 03:13:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:28][root][INFO] - Training Epoch: 1/2, step 812/7134 completed (loss: 3.453465223312378, acc: 0.3719806671142578)
[2024-10-22 03:13:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:29][root][INFO] - Training Epoch: 1/2, step 813/7134 completed (loss: 3.320966958999634, acc: 0.36612021923065186)
[2024-10-22 03:13:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:29][root][INFO] - Training Epoch: 1/2, step 814/7134 completed (loss: 3.4062180519104004, acc: 0.32828283309936523)
[2024-10-22 03:13:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:30][root][INFO] - Training Epoch: 1/2, step 815/7134 completed (loss: 3.4083216190338135, acc: 0.39156627655029297)
[2024-10-22 03:13:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:30][root][INFO] - Training Epoch: 1/2, step 816/7134 completed (loss: 3.6386711597442627, acc: 0.276729553937912)
[2024-10-22 03:13:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:31][root][INFO] - Training Epoch: 1/2, step 817/7134 completed (loss: 3.7918694019317627, acc: 0.32692307233810425)
[2024-10-22 03:13:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:32][root][INFO] - Training Epoch: 1/2, step 818/7134 completed (loss: 3.696927309036255, acc: 0.3076923191547394)
[2024-10-22 03:13:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:32][root][INFO] - Training Epoch: 1/2, step 819/7134 completed (loss: 3.6387791633605957, acc: 0.37974682450294495)
[2024-10-22 03:13:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:33][root][INFO] - Training Epoch: 1/2, step 820/7134 completed (loss: 3.2497217655181885, acc: 0.4080459773540497)
[2024-10-22 03:13:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:33][root][INFO] - Training Epoch: 1/2, step 821/7134 completed (loss: 3.1157052516937256, acc: 0.40526315569877625)
[2024-10-22 03:13:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:34][root][INFO] - Training Epoch: 1/2, step 822/7134 completed (loss: 2.909602403640747, acc: 0.38372093439102173)
[2024-10-22 03:13:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:35][root][INFO] - Training Epoch: 1/2, step 823/7134 completed (loss: 3.1422922611236572, acc: 0.37857142090797424)
[2024-10-22 03:13:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:35][root][INFO] - Training Epoch: 1/2, step 824/7134 completed (loss: 3.1796562671661377, acc: 0.4113923907279968)
[2024-10-22 03:13:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:36][root][INFO] - Training Epoch: 1/2, step 825/7134 completed (loss: 3.2069759368896484, acc: 0.4070351719856262)
[2024-10-22 03:13:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:37][root][INFO] - Training Epoch: 1/2, step 826/7134 completed (loss: 2.985558032989502, acc: 0.4188481569290161)
[2024-10-22 03:13:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:37][root][INFO] - Training Epoch: 1/2, step 827/7134 completed (loss: 3.131268262863159, acc: 0.36734694242477417)
[2024-10-22 03:13:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:38][root][INFO] - Training Epoch: 1/2, step 828/7134 completed (loss: 2.981888771057129, acc: 0.42937853932380676)
[2024-10-22 03:13:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:38][root][INFO] - Training Epoch: 1/2, step 829/7134 completed (loss: 3.7337746620178223, acc: 0.2956521809101105)
[2024-10-22 03:13:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:39][root][INFO] - Training Epoch: 1/2, step 830/7134 completed (loss: 2.894106864929199, acc: 0.40645161271095276)
[2024-10-22 03:13:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:40][root][INFO] - Training Epoch: 1/2, step 831/7134 completed (loss: 3.214853525161743, acc: 0.3591160178184509)
[2024-10-22 03:13:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:40][root][INFO] - Training Epoch: 1/2, step 832/7134 completed (loss: 3.2474498748779297, acc: 0.36994218826293945)
[2024-10-22 03:13:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:41][root][INFO] - Training Epoch: 1/2, step 833/7134 completed (loss: 3.8867571353912354, acc: 0.2752808928489685)
[2024-10-22 03:13:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:42][root][INFO] - Training Epoch: 1/2, step 834/7134 completed (loss: 3.1309404373168945, acc: 0.4216216206550598)
[2024-10-22 03:13:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:42][root][INFO] - Training Epoch: 1/2, step 835/7134 completed (loss: 3.265321731567383, acc: 0.35078534483909607)
[2024-10-22 03:13:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:43][root][INFO] - Training Epoch: 1/2, step 836/7134 completed (loss: 2.9483437538146973, acc: 0.4235807955265045)
[2024-10-22 03:13:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:43][root][INFO] - Training Epoch: 1/2, step 837/7134 completed (loss: 3.512458324432373, acc: 0.3571428656578064)
[2024-10-22 03:13:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:44][root][INFO] - Training Epoch: 1/2, step 838/7134 completed (loss: 3.5459959506988525, acc: 0.2781065106391907)
[2024-10-22 03:13:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:45][root][INFO] - Training Epoch: 1/2, step 839/7134 completed (loss: 2.984036445617676, acc: 0.4051724076271057)
[2024-10-22 03:13:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:45][root][INFO] - Training Epoch: 1/2, step 840/7134 completed (loss: 2.6574618816375732, acc: 0.4736842215061188)
[2024-10-22 03:13:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:46][root][INFO] - Training Epoch: 1/2, step 841/7134 completed (loss: 3.554987907409668, acc: 0.34375)
[2024-10-22 03:13:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:46][root][INFO] - Training Epoch: 1/2, step 842/7134 completed (loss: 3.101639747619629, acc: 0.37837839126586914)
[2024-10-22 03:13:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:47][root][INFO] - Training Epoch: 1/2, step 843/7134 completed (loss: 3.084380865097046, acc: 0.4021739065647125)
[2024-10-22 03:13:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:48][root][INFO] - Training Epoch: 1/2, step 844/7134 completed (loss: 2.840639114379883, acc: 0.42405062913894653)
[2024-10-22 03:13:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:48][root][INFO] - Training Epoch: 1/2, step 845/7134 completed (loss: 2.964970350265503, acc: 0.42424243688583374)
[2024-10-22 03:13:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:49][root][INFO] - Training Epoch: 1/2, step 846/7134 completed (loss: 3.0434412956237793, acc: 0.43558281660079956)
[2024-10-22 03:13:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:49][root][INFO] - Training Epoch: 1/2, step 847/7134 completed (loss: 3.147280693054199, acc: 0.42131978273391724)
[2024-10-22 03:13:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:50][root][INFO] - Training Epoch: 1/2, step 848/7134 completed (loss: 3.7479546070098877, acc: 0.3144329786300659)
[2024-10-22 03:13:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:51][root][INFO] - Training Epoch: 1/2, step 849/7134 completed (loss: 3.4747464656829834, acc: 0.32786884903907776)
[2024-10-22 03:13:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:51][root][INFO] - Training Epoch: 1/2, step 850/7134 completed (loss: 3.061760425567627, acc: 0.42500001192092896)
[2024-10-22 03:13:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:52][root][INFO] - Training Epoch: 1/2, step 851/7134 completed (loss: 3.3901515007019043, acc: 0.35978835821151733)
[2024-10-22 03:13:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:52][root][INFO] - Training Epoch: 1/2, step 852/7134 completed (loss: 3.267404079437256, acc: 0.35960590839385986)
[2024-10-22 03:13:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:53][root][INFO] - Training Epoch: 1/2, step 853/7134 completed (loss: 3.4442696571350098, acc: 0.3838862478733063)
[2024-10-22 03:13:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:53][root][INFO] - Training Epoch: 1/2, step 854/7134 completed (loss: 3.099942207336426, acc: 0.40229883790016174)
[2024-10-22 03:13:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:54][root][INFO] - Training Epoch: 1/2, step 855/7134 completed (loss: 3.1328396797180176, acc: 0.35078534483909607)
[2024-10-22 03:13:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:55][root][INFO] - Training Epoch: 1/2, step 856/7134 completed (loss: 3.130244255065918, acc: 0.36734694242477417)
[2024-10-22 03:13:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:55][root][INFO] - Training Epoch: 1/2, step 857/7134 completed (loss: 3.2350013256073, acc: 0.3664596378803253)
[2024-10-22 03:13:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:56][root][INFO] - Training Epoch: 1/2, step 858/7134 completed (loss: 3.414966344833374, acc: 0.3834196925163269)
[2024-10-22 03:13:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:56][root][INFO] - Training Epoch: 1/2, step 859/7134 completed (loss: 3.1754891872406006, acc: 0.36538460850715637)
[2024-10-22 03:13:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:57][root][INFO] - Training Epoch: 1/2, step 860/7134 completed (loss: 3.706456422805786, acc: 0.4000000059604645)
[2024-10-22 03:13:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:57][root][INFO] - Training Epoch: 1/2, step 861/7134 completed (loss: 3.068242073059082, acc: 0.43518519401550293)
[2024-10-22 03:13:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:58][root][INFO] - Training Epoch: 1/2, step 862/7134 completed (loss: 3.7423605918884277, acc: 0.3100000023841858)
[2024-10-22 03:13:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:58][root][INFO] - Training Epoch: 1/2, step 863/7134 completed (loss: 3.4933953285217285, acc: 0.3619047701358795)
[2024-10-22 03:13:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:13:59][root][INFO] - Training Epoch: 1/2, step 864/7134 completed (loss: 3.226135492324829, acc: 0.3904109597206116)
[2024-10-22 03:13:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:00][root][INFO] - Training Epoch: 1/2, step 865/7134 completed (loss: 3.345278024673462, acc: 0.3891625702381134)
[2024-10-22 03:14:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:00][root][INFO] - Training Epoch: 1/2, step 866/7134 completed (loss: 3.515462636947632, acc: 0.36477985978126526)
[2024-10-22 03:14:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:01][root][INFO] - Training Epoch: 1/2, step 867/7134 completed (loss: 3.567458391189575, acc: 0.32065218687057495)
[2024-10-22 03:14:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:01][root][INFO] - Training Epoch: 1/2, step 868/7134 completed (loss: 3.8047637939453125, acc: 0.32275131344795227)
[2024-10-22 03:14:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:02][root][INFO] - Training Epoch: 1/2, step 869/7134 completed (loss: 4.810686111450195, acc: 0.20930232107639313)
[2024-10-22 03:14:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:02][root][INFO] - Training Epoch: 1/2, step 870/7134 completed (loss: 3.8885204792022705, acc: 0.3513513505458832)
[2024-10-22 03:14:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:03][root][INFO] - Training Epoch: 1/2, step 871/7134 completed (loss: 3.9168267250061035, acc: 0.3251533806324005)
[2024-10-22 03:14:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:04][root][INFO] - Training Epoch: 1/2, step 872/7134 completed (loss: 3.4647295475006104, acc: 0.3076923191547394)
[2024-10-22 03:14:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:04][root][INFO] - Training Epoch: 1/2, step 873/7134 completed (loss: 3.503976345062256, acc: 0.34972676634788513)
[2024-10-22 03:14:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:05][root][INFO] - Training Epoch: 1/2, step 874/7134 completed (loss: 3.7955658435821533, acc: 0.290909081697464)
[2024-10-22 03:14:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:05][root][INFO] - Training Epoch: 1/2, step 875/7134 completed (loss: 3.4098000526428223, acc: 0.337579607963562)
[2024-10-22 03:14:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:06][root][INFO] - Training Epoch: 1/2, step 876/7134 completed (loss: 3.5479483604431152, acc: 0.327160507440567)
[2024-10-22 03:14:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:06][root][INFO] - Training Epoch: 1/2, step 877/7134 completed (loss: 3.3789803981781006, acc: 0.3314606845378876)
[2024-10-22 03:14:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:07][root][INFO] - Training Epoch: 1/2, step 878/7134 completed (loss: 3.43091082572937, acc: 0.3513513505458832)
[2024-10-22 03:14:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:08][root][INFO] - Training Epoch: 1/2, step 879/7134 completed (loss: 3.823460817337036, acc: 0.32335329055786133)
[2024-10-22 03:14:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:08][root][INFO] - Training Epoch: 1/2, step 880/7134 completed (loss: 3.7264230251312256, acc: 0.2971428632736206)
[2024-10-22 03:14:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:09][root][INFO] - Training Epoch: 1/2, step 881/7134 completed (loss: 3.6596672534942627, acc: 0.3030303120613098)
[2024-10-22 03:14:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:09][root][INFO] - Training Epoch: 1/2, step 882/7134 completed (loss: 3.3720591068267822, acc: 0.2857142984867096)
[2024-10-22 03:14:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:10][root][INFO] - Training Epoch: 1/2, step 883/7134 completed (loss: 3.684068441390991, acc: 0.3199999928474426)
[2024-10-22 03:14:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:10][root][INFO] - Training Epoch: 1/2, step 884/7134 completed (loss: 3.846992254257202, acc: 0.3181818127632141)
[2024-10-22 03:14:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:11][root][INFO] - Training Epoch: 1/2, step 885/7134 completed (loss: 3.3775203227996826, acc: 0.3502824902534485)
[2024-10-22 03:14:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:11][root][INFO] - Training Epoch: 1/2, step 886/7134 completed (loss: 3.3537676334381104, acc: 0.31578946113586426)
[2024-10-22 03:14:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:12][root][INFO] - Training Epoch: 1/2, step 887/7134 completed (loss: 3.687328338623047, acc: 0.2657342553138733)
[2024-10-22 03:14:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:13][root][INFO] - Training Epoch: 1/2, step 888/7134 completed (loss: 3.6268742084503174, acc: 0.32499998807907104)
[2024-10-22 03:14:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:13][root][INFO] - Training Epoch: 1/2, step 889/7134 completed (loss: 3.927299737930298, acc: 0.30000001192092896)
[2024-10-22 03:14:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:14][root][INFO] - Training Epoch: 1/2, step 890/7134 completed (loss: 3.451955795288086, acc: 0.35329341888427734)
[2024-10-22 03:14:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:14][root][INFO] - Training Epoch: 1/2, step 891/7134 completed (loss: 3.281140089035034, acc: 0.3333333432674408)
[2024-10-22 03:14:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:15][root][INFO] - Training Epoch: 1/2, step 892/7134 completed (loss: 3.2926392555236816, acc: 0.3068181872367859)
[2024-10-22 03:14:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:15][root][INFO] - Training Epoch: 1/2, step 893/7134 completed (loss: 3.294591188430786, acc: 0.35757574439048767)
[2024-10-22 03:14:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:16][root][INFO] - Training Epoch: 1/2, step 894/7134 completed (loss: 3.119737148284912, acc: 0.40512821078300476)
[2024-10-22 03:14:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:16][root][INFO] - Training Epoch: 1/2, step 895/7134 completed (loss: 3.1760711669921875, acc: 0.35483869910240173)
[2024-10-22 03:14:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:17][root][INFO] - Training Epoch: 1/2, step 896/7134 completed (loss: 3.3363280296325684, acc: 0.3695652186870575)
[2024-10-22 03:14:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:18][root][INFO] - Training Epoch: 1/2, step 897/7134 completed (loss: 3.2021572589874268, acc: 0.36868685483932495)
[2024-10-22 03:14:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:18][root][INFO] - Training Epoch: 1/2, step 898/7134 completed (loss: 3.528650999069214, acc: 0.3505154550075531)
[2024-10-22 03:14:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:19][root][INFO] - Training Epoch: 1/2, step 899/7134 completed (loss: 3.249044418334961, acc: 0.3446601927280426)
[2024-10-22 03:14:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:19][root][INFO] - Training Epoch: 1/2, step 900/7134 completed (loss: 3.3055837154388428, acc: 0.3502824902534485)
[2024-10-22 03:14:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:20][root][INFO] - Training Epoch: 1/2, step 901/7134 completed (loss: 3.0089521408081055, acc: 0.421875)
[2024-10-22 03:14:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:20][root][INFO] - Training Epoch: 1/2, step 902/7134 completed (loss: 3.486154079437256, acc: 0.2823529541492462)
[2024-10-22 03:14:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:21][root][INFO] - Training Epoch: 1/2, step 903/7134 completed (loss: 3.2248620986938477, acc: 0.33155080676078796)
[2024-10-22 03:14:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:22][root][INFO] - Training Epoch: 1/2, step 904/7134 completed (loss: 3.2771012783050537, acc: 0.37172773480415344)
[2024-10-22 03:14:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:22][root][INFO] - Training Epoch: 1/2, step 905/7134 completed (loss: 3.0512354373931885, acc: 0.3854166567325592)
[2024-10-22 03:14:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:23][root][INFO] - Training Epoch: 1/2, step 906/7134 completed (loss: 3.2905378341674805, acc: 0.3210526406764984)
[2024-10-22 03:14:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:23][root][INFO] - Training Epoch: 1/2, step 907/7134 completed (loss: 3.2978427410125732, acc: 0.3585858643054962)
[2024-10-22 03:14:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:24][root][INFO] - Training Epoch: 1/2, step 908/7134 completed (loss: 3.0766499042510986, acc: 0.4375)
[2024-10-22 03:14:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:24][root][INFO] - Training Epoch: 1/2, step 909/7134 completed (loss: 2.7359440326690674, acc: 0.46060606837272644)
[2024-10-22 03:14:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:25][root][INFO] - Training Epoch: 1/2, step 910/7134 completed (loss: 3.6218085289001465, acc: 0.33701658248901367)
[2024-10-22 03:14:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:25][root][INFO] - Training Epoch: 1/2, step 911/7134 completed (loss: 3.7061266899108887, acc: 0.3333333432674408)
[2024-10-22 03:14:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:26][root][INFO] - Training Epoch: 1/2, step 912/7134 completed (loss: 3.4042181968688965, acc: 0.35499998927116394)
[2024-10-22 03:14:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:27][root][INFO] - Training Epoch: 1/2, step 913/7134 completed (loss: 3.485626459121704, acc: 0.3711340129375458)
[2024-10-22 03:14:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:27][root][INFO] - Training Epoch: 1/2, step 914/7134 completed (loss: 3.7434732913970947, acc: 0.3089887499809265)
[2024-10-22 03:14:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:28][root][INFO] - Training Epoch: 1/2, step 915/7134 completed (loss: 3.5804429054260254, acc: 0.3670886158943176)
[2024-10-22 03:14:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:28][root][INFO] - Training Epoch: 1/2, step 916/7134 completed (loss: 3.366224765777588, acc: 0.37956205010414124)
[2024-10-22 03:14:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:29][root][INFO] - Training Epoch: 1/2, step 917/7134 completed (loss: 3.8493964672088623, acc: 0.28915661573410034)
[2024-10-22 03:14:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:29][root][INFO] - Training Epoch: 1/2, step 918/7134 completed (loss: 3.1914114952087402, acc: 0.3827160596847534)
[2024-10-22 03:14:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:30][root][INFO] - Training Epoch: 1/2, step 919/7134 completed (loss: 3.0163166522979736, acc: 0.4121212065219879)
[2024-10-22 03:14:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:31][root][INFO] - Training Epoch: 1/2, step 920/7134 completed (loss: 3.27217173576355, acc: 0.34224599599838257)
[2024-10-22 03:14:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:31][root][INFO] - Training Epoch: 1/2, step 921/7134 completed (loss: 3.5149283409118652, acc: 0.31216931343078613)
[2024-10-22 03:14:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:32][root][INFO] - Training Epoch: 1/2, step 922/7134 completed (loss: 3.0681169033050537, acc: 0.3426573574542999)
[2024-10-22 03:14:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:32][root][INFO] - Training Epoch: 1/2, step 923/7134 completed (loss: 2.988798141479492, acc: 0.3606557250022888)
[2024-10-22 03:14:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:33][root][INFO] - Training Epoch: 1/2, step 924/7134 completed (loss: 3.0087201595306396, acc: 0.3505154550075531)
[2024-10-22 03:14:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:33][root][INFO] - Training Epoch: 1/2, step 925/7134 completed (loss: 3.2899913787841797, acc: 0.4157303273677826)
[2024-10-22 03:14:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:34][root][INFO] - Training Epoch: 1/2, step 926/7134 completed (loss: 2.9115376472473145, acc: 0.3910891115665436)
[2024-10-22 03:14:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:35][root][INFO] - Training Epoch: 1/2, step 927/7134 completed (loss: 3.0937271118164062, acc: 0.3581081032752991)
[2024-10-22 03:14:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:35][root][INFO] - Training Epoch: 1/2, step 928/7134 completed (loss: 3.1733083724975586, acc: 0.35593220591545105)
[2024-10-22 03:14:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:36][root][INFO] - Training Epoch: 1/2, step 929/7134 completed (loss: 3.5925824642181396, acc: 0.2981366515159607)
[2024-10-22 03:14:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:36][root][INFO] - Training Epoch: 1/2, step 930/7134 completed (loss: 3.3835463523864746, acc: 0.4318181872367859)
[2024-10-22 03:14:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:37][root][INFO] - Training Epoch: 1/2, step 931/7134 completed (loss: 3.553223133087158, acc: 0.3426573574542999)
[2024-10-22 03:14:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:37][root][INFO] - Training Epoch: 1/2, step 932/7134 completed (loss: 3.1033968925476074, acc: 0.37288135290145874)
[2024-10-22 03:14:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:38][root][INFO] - Training Epoch: 1/2, step 933/7134 completed (loss: 3.754117965698242, acc: 0.3224043846130371)
[2024-10-22 03:14:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:38][root][INFO] - Training Epoch: 1/2, step 934/7134 completed (loss: 3.6820013523101807, acc: 0.3076923191547394)
[2024-10-22 03:14:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:39][root][INFO] - Training Epoch: 1/2, step 935/7134 completed (loss: 3.0444235801696777, acc: 0.40140846371650696)
[2024-10-22 03:14:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:39][root][INFO] - Training Epoch: 1/2, step 936/7134 completed (loss: 3.3800737857818604, acc: 0.3571428656578064)
[2024-10-22 03:14:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:40][root][INFO] - Training Epoch: 1/2, step 937/7134 completed (loss: 3.872771978378296, acc: 0.2846715450286865)
[2024-10-22 03:14:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:41][root][INFO] - Training Epoch: 1/2, step 938/7134 completed (loss: 3.3017144203186035, acc: 0.3579545319080353)
[2024-10-22 03:14:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:41][root][INFO] - Training Epoch: 1/2, step 939/7134 completed (loss: 3.396068811416626, acc: 0.35519126057624817)
[2024-10-22 03:14:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:42][root][INFO] - Training Epoch: 1/2, step 940/7134 completed (loss: 3.648606300354004, acc: 0.3055555522441864)
[2024-10-22 03:14:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:42][root][INFO] - Training Epoch: 1/2, step 941/7134 completed (loss: 3.2954413890838623, acc: 0.31550800800323486)
[2024-10-22 03:14:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:43][root][INFO] - Training Epoch: 1/2, step 942/7134 completed (loss: 3.334501266479492, acc: 0.3796791434288025)
[2024-10-22 03:14:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:43][root][INFO] - Training Epoch: 1/2, step 943/7134 completed (loss: 3.331418752670288, acc: 0.34090909361839294)
[2024-10-22 03:14:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:44][root][INFO] - Training Epoch: 1/2, step 944/7134 completed (loss: 3.1348674297332764, acc: 0.3764044940471649)
[2024-10-22 03:14:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:45][root][INFO] - Training Epoch: 1/2, step 945/7134 completed (loss: 3.2426834106445312, acc: 0.3855421543121338)
[2024-10-22 03:14:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:45][root][INFO] - Training Epoch: 1/2, step 946/7134 completed (loss: 3.7306764125823975, acc: 0.3243243098258972)
[2024-10-22 03:14:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:46][root][INFO] - Training Epoch: 1/2, step 947/7134 completed (loss: 3.5566554069519043, acc: 0.30201342701911926)
[2024-10-22 03:14:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:46][root][INFO] - Training Epoch: 1/2, step 948/7134 completed (loss: 3.1797738075256348, acc: 0.31284916400909424)
[2024-10-22 03:14:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:47][root][INFO] - Training Epoch: 1/2, step 949/7134 completed (loss: 3.4483556747436523, acc: 0.3895348906517029)
[2024-10-22 03:14:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:47][root][INFO] - Training Epoch: 1/2, step 950/7134 completed (loss: 3.245002508163452, acc: 0.4085365831851959)
[2024-10-22 03:14:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:48][root][INFO] - Training Epoch: 1/2, step 951/7134 completed (loss: 3.2267167568206787, acc: 0.41428571939468384)
[2024-10-22 03:14:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:49][root][INFO] - Training Epoch: 1/2, step 952/7134 completed (loss: 2.9866764545440674, acc: 0.4768211841583252)
[2024-10-22 03:14:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:49][root][INFO] - Training Epoch: 1/2, step 953/7134 completed (loss: 3.5470540523529053, acc: 0.3461538553237915)
[2024-10-22 03:14:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:50][root][INFO] - Training Epoch: 1/2, step 954/7134 completed (loss: 3.1495583057403564, acc: 0.395061731338501)
[2024-10-22 03:14:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:50][root][INFO] - Training Epoch: 1/2, step 955/7134 completed (loss: 3.3705151081085205, acc: 0.3854166567325592)
[2024-10-22 03:14:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:51][root][INFO] - Training Epoch: 1/2, step 956/7134 completed (loss: 2.9709792137145996, acc: 0.4236453175544739)
[2024-10-22 03:14:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:51][root][INFO] - Training Epoch: 1/2, step 957/7134 completed (loss: 3.025653839111328, acc: 0.3720930218696594)
[2024-10-22 03:14:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:52][root][INFO] - Training Epoch: 1/2, step 958/7134 completed (loss: 3.65580153465271, acc: 0.3219178020954132)
[2024-10-22 03:14:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:52][root][INFO] - Training Epoch: 1/2, step 959/7134 completed (loss: 3.646042823791504, acc: 0.3444976210594177)
[2024-10-22 03:14:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:53][root][INFO] - Training Epoch: 1/2, step 960/7134 completed (loss: 3.6919643878936768, acc: 0.317241370677948)
[2024-10-22 03:14:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:54][root][INFO] - Training Epoch: 1/2, step 961/7134 completed (loss: 3.785266637802124, acc: 0.296875)
[2024-10-22 03:14:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:54][root][INFO] - Training Epoch: 1/2, step 962/7134 completed (loss: 3.7810211181640625, acc: 0.32620319724082947)
[2024-10-22 03:14:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:55][root][INFO] - Training Epoch: 1/2, step 963/7134 completed (loss: 3.270750045776367, acc: 0.3461538553237915)
[2024-10-22 03:14:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:55][root][INFO] - Training Epoch: 1/2, step 964/7134 completed (loss: 3.9343080520629883, acc: 0.2914285659790039)
[2024-10-22 03:14:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:56][root][INFO] - Training Epoch: 1/2, step 965/7134 completed (loss: 3.4292140007019043, acc: 0.3350515365600586)
[2024-10-22 03:14:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:56][root][INFO] - Training Epoch: 1/2, step 966/7134 completed (loss: 3.3316097259521484, acc: 0.3235294222831726)
[2024-10-22 03:14:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:57][root][INFO] - Training Epoch: 1/2, step 967/7134 completed (loss: 3.3438804149627686, acc: 0.38725489377975464)
[2024-10-22 03:14:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:57][root][INFO] - Training Epoch: 1/2, step 968/7134 completed (loss: 3.6660521030426025, acc: 0.3767123222351074)
[2024-10-22 03:14:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:58][root][INFO] - Training Epoch: 1/2, step 969/7134 completed (loss: 3.4749538898468018, acc: 0.3510638177394867)
[2024-10-22 03:14:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:59][root][INFO] - Training Epoch: 1/2, step 970/7134 completed (loss: 3.4548442363739014, acc: 0.40136054158210754)
[2024-10-22 03:14:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:14:59][root][INFO] - Training Epoch: 1/2, step 971/7134 completed (loss: 2.924468755722046, acc: 0.3963963985443115)
[2024-10-22 03:14:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:00][root][INFO] - Training Epoch: 1/2, step 972/7134 completed (loss: 3.657390594482422, acc: 0.32380953431129456)
[2024-10-22 03:15:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:00][root][INFO] - Training Epoch: 1/2, step 973/7134 completed (loss: 3.4735326766967773, acc: 0.34825870394706726)
[2024-10-22 03:15:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:01][root][INFO] - Training Epoch: 1/2, step 974/7134 completed (loss: 3.4716098308563232, acc: 0.3287671208381653)
[2024-10-22 03:15:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:01][root][INFO] - Training Epoch: 1/2, step 975/7134 completed (loss: 3.660543203353882, acc: 0.3254716992378235)
[2024-10-22 03:15:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:02][root][INFO] - Training Epoch: 1/2, step 976/7134 completed (loss: 3.1375203132629395, acc: 0.3658536672592163)
[2024-10-22 03:15:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:03][root][INFO] - Training Epoch: 1/2, step 977/7134 completed (loss: 3.362452745437622, acc: 0.3821989595890045)
[2024-10-22 03:15:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:03][root][INFO] - Training Epoch: 1/2, step 978/7134 completed (loss: 3.1815507411956787, acc: 0.4103773534297943)
[2024-10-22 03:15:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:04][root][INFO] - Training Epoch: 1/2, step 979/7134 completed (loss: 3.1800901889801025, acc: 0.42583730816841125)
[2024-10-22 03:15:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:04][root][INFO] - Training Epoch: 1/2, step 980/7134 completed (loss: 3.1423537731170654, acc: 0.39662447571754456)
[2024-10-22 03:15:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:05][root][INFO] - Training Epoch: 1/2, step 981/7134 completed (loss: 3.568615198135376, acc: 0.38596490025520325)
[2024-10-22 03:15:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:05][root][INFO] - Training Epoch: 1/2, step 982/7134 completed (loss: 3.5511391162872314, acc: 0.376963347196579)
[2024-10-22 03:15:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:06][root][INFO] - Training Epoch: 1/2, step 983/7134 completed (loss: 3.3351335525512695, acc: 0.3287671208381653)
[2024-10-22 03:15:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:07][root][INFO] - Training Epoch: 1/2, step 984/7134 completed (loss: 2.955775022506714, acc: 0.42307692766189575)
[2024-10-22 03:15:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:07][root][INFO] - Training Epoch: 1/2, step 985/7134 completed (loss: 3.0666298866271973, acc: 0.393782377243042)
[2024-10-22 03:15:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:08][root][INFO] - Training Epoch: 1/2, step 986/7134 completed (loss: 2.899174213409424, acc: 0.42288556694984436)
[2024-10-22 03:15:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:08][root][INFO] - Training Epoch: 1/2, step 987/7134 completed (loss: 2.843141794204712, acc: 0.37804877758026123)
[2024-10-22 03:15:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:09][root][INFO] - Training Epoch: 1/2, step 988/7134 completed (loss: 3.263400077819824, acc: 0.3842364549636841)
[2024-10-22 03:15:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:09][root][INFO] - Training Epoch: 1/2, step 989/7134 completed (loss: 3.466362476348877, acc: 0.36021506786346436)
[2024-10-22 03:15:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:10][root][INFO] - Training Epoch: 1/2, step 990/7134 completed (loss: 3.3854141235351562, acc: 0.29556649923324585)
[2024-10-22 03:15:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:10][root][INFO] - Training Epoch: 1/2, step 991/7134 completed (loss: 3.6741416454315186, acc: 0.37569060921669006)
[2024-10-22 03:15:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:11][root][INFO] - Training Epoch: 1/2, step 992/7134 completed (loss: 3.4987082481384277, acc: 0.3796791434288025)
[2024-10-22 03:15:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:12][root][INFO] - Training Epoch: 1/2, step 993/7134 completed (loss: 3.42844295501709, acc: 0.34319525957107544)
[2024-10-22 03:15:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:12][root][INFO] - Training Epoch: 1/2, step 994/7134 completed (loss: 2.864293336868286, acc: 0.4196428656578064)
[2024-10-22 03:15:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:13][root][INFO] - Training Epoch: 1/2, step 995/7134 completed (loss: 3.5018434524536133, acc: 0.3086419701576233)
[2024-10-22 03:15:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:13][root][INFO] - Training Epoch: 1/2, step 996/7134 completed (loss: 3.200270414352417, acc: 0.37435898184776306)
[2024-10-22 03:15:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:14][root][INFO] - Training Epoch: 1/2, step 997/7134 completed (loss: 3.174830913543701, acc: 0.37566137313842773)
[2024-10-22 03:15:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:14][root][INFO] - Training Epoch: 1/2, step 998/7134 completed (loss: 3.285377264022827, acc: 0.3729729652404785)
[2024-10-22 03:15:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:15][root][INFO] - Training Epoch: 1/2, step 999/7134 completed (loss: 3.681664228439331, acc: 0.317241370677948)
[2024-10-22 03:15:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:15:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:16:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:17:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:18:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:19:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:20:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03:21:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 03: