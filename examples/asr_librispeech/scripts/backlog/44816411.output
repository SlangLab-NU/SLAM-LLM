Using dataset file: examples/asr_librispeech/dataset/dynamic_prompt_speech_dataset.py:get_speech_dataset
speech encoder name: wavlm
speech encoder path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt
speech encoder2 name: 
speech encoder2 path: 
llm_path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/TinyLlama-1.1B-Chat-v1.0
Identifier: ami_wavlm_TinyLlama_linear_phoneme_freeze
use_peft: true
use_fp16: true
Final identifier: ami_wavlm_TinyLlama_linear_peft_separate
No checkpoint found in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_wavlm_TinyLlama_linear_peft_separate
ckpt_folder: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_wavlm_TinyLlama_linear_peft_separate/
Resume epoch: 1
Resume step: 0
[2024-10-21 02:43:30][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 6, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 6, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_wavlm_TinyLlama_linear_peft_separate', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': False}
[2024-10-21 02:43:30][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-10-21 02:43:30][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'TinyLlama', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/TinyLlama-1.1B-Chat-v1.0', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-10-21 02:43:30][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'ami_wavlm_TinyLlama_linear_peft_separate', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-10-21_02-43-29.txt', 'log_interval': 5}
[2024-10-21 02:43:50][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-10-21 02:43:56][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-10-21 02:43:56][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-10-21 02:43:56][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-10-21 02:43:56][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-10-21 02:44:03][slam_llm.utils.train_utils][INFO] - --> Module TinyLlama
[2024-10-21 02:44:03][slam_llm.utils.train_utils][INFO] - --> TinyLlama has 1100.048384 Million params

[2024-10-21 02:44:03][slam_llm.models.slam_model][INFO] - setup peft...
trainable params: 6,307,840 || all params: 1,106,356,224 || trainable%: 0.570145479653396
[2024-10-21 02:44:04][slam_llm.utils.train_utils][INFO] - --> Module TinyLlama
[2024-10-21 02:44:04][slam_llm.utils.train_utils][INFO] - --> TinyLlama has 6.30784 Million params

[2024-10-21 02:44:04][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-10-21 02:44:04][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-10-21 02:44:04][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-10-21 02:44:04][slam_llm.utils.train_utils][INFO] - --> asr has 20.992 Million params

[2024-10-21 02:44:06][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'examples/asr_librispeech/dataset/dynamic_prompt_speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': 'Transcribe speech to text. ', 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-10-21 02:44:08][root][INFO] - --> Training Set Length = 107898
[2024-10-21 02:44:08][root][INFO] - --> Validation Set Length = 8351
[2024-10-21 02:44:08][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-10-21 02:44:08][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-10-21 02:44:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:11][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-10-21 02:44:11][root][INFO] - Training Epoch: 1/2, step 0/17983 completed (loss: 6.717762470245361, acc: 0.10000000149011612)
[2024-10-21 02:44:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:12][root][INFO] - Training Epoch: 1/2, step 1/17983 completed (loss: 6.6850361824035645, acc: 0.0859375)
[2024-10-21 02:44:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:12][root][INFO] - Training Epoch: 1/2, step 2/17983 completed (loss: 6.856129169464111, acc: 0.09090909361839294)
[2024-10-21 02:44:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:13][root][INFO] - Training Epoch: 1/2, step 3/17983 completed (loss: 7.258149147033691, acc: 0.03846153989434242)
[2024-10-21 02:44:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:13][root][INFO] - Training Epoch: 1/2, step 4/17983 completed (loss: 6.844433784484863, acc: 0.07446808367967606)
[2024-10-21 02:44:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:13][root][INFO] - Training Epoch: 1/2, step 5/17983 completed (loss: 6.921475887298584, acc: 0.046875)
[2024-10-21 02:44:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:14][root][INFO] - Training Epoch: 1/2, step 6/17983 completed (loss: 6.449258327484131, acc: 0.13636364042758942)
[2024-10-21 02:44:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:14][root][INFO] - Training Epoch: 1/2, step 7/17983 completed (loss: 6.813782691955566, acc: 0.09090909361839294)
[2024-10-21 02:44:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:15][root][INFO] - Training Epoch: 1/2, step 8/17983 completed (loss: 6.3707804679870605, acc: 0.10743801295757294)
[2024-10-21 02:44:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:15][root][INFO] - Training Epoch: 1/2, step 9/17983 completed (loss: 7.5567827224731445, acc: 0.03999999910593033)
[2024-10-21 02:44:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:16][root][INFO] - Training Epoch: 1/2, step 10/17983 completed (loss: 6.049304962158203, acc: 0.09859155118465424)
[2024-10-21 02:44:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:16][root][INFO] - Training Epoch: 1/2, step 11/17983 completed (loss: 6.187314033508301, acc: 0.0782608687877655)
[2024-10-21 02:44:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:17][root][INFO] - Training Epoch: 1/2, step 12/17983 completed (loss: 6.791118144989014, acc: 0.0625)
[2024-10-21 02:44:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:17][root][INFO] - Training Epoch: 1/2, step 13/17983 completed (loss: 6.522812843322754, acc: 0.09090909361839294)
[2024-10-21 02:44:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:18][root][INFO] - Training Epoch: 1/2, step 14/17983 completed (loss: 6.689864635467529, acc: 0.08510638028383255)
[2024-10-21 02:44:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:18][root][INFO] - Training Epoch: 1/2, step 15/17983 completed (loss: 7.824446201324463, acc: 0.02500000037252903)
[2024-10-21 02:44:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:18][root][INFO] - Training Epoch: 1/2, step 16/17983 completed (loss: 7.973721504211426, acc: 0.022727273404598236)
[2024-10-21 02:44:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:19][root][INFO] - Training Epoch: 1/2, step 17/17983 completed (loss: 6.908897876739502, acc: 0.06593406945466995)
[2024-10-21 02:44:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:19][root][INFO] - Training Epoch: 1/2, step 18/17983 completed (loss: 6.395414352416992, acc: 0.0422535203397274)
[2024-10-21 02:44:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:20][root][INFO] - Training Epoch: 1/2, step 19/17983 completed (loss: 6.939048767089844, acc: 0.1428571492433548)
[2024-10-21 02:44:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:20][root][INFO] - Training Epoch: 1/2, step 20/17983 completed (loss: 6.067621231079102, acc: 0.12371134012937546)
[2024-10-21 02:44:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:21][root][INFO] - Training Epoch: 1/2, step 21/17983 completed (loss: 5.1345930099487305, acc: 0.26724138855934143)
[2024-10-21 02:44:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:21][root][INFO] - Training Epoch: 1/2, step 22/17983 completed (loss: 6.884359359741211, acc: 0.024390242993831635)
[2024-10-21 02:44:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:22][root][INFO] - Training Epoch: 1/2, step 23/17983 completed (loss: 6.387241840362549, acc: 0.08602150529623032)
[2024-10-21 02:44:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:22][root][INFO] - Training Epoch: 1/2, step 24/17983 completed (loss: 5.558317184448242, acc: 0.1756756752729416)
[2024-10-21 02:44:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:23][root][INFO] - Training Epoch: 1/2, step 25/17983 completed (loss: 7.01754903793335, acc: 0.13333334028720856)
[2024-10-21 02:44:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:23][root][INFO] - Training Epoch: 1/2, step 26/17983 completed (loss: 7.025781631469727, acc: 0.07407407462596893)
[2024-10-21 02:44:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:23][root][INFO] - Training Epoch: 1/2, step 27/17983 completed (loss: 6.426783561706543, acc: 0.1764705926179886)
[2024-10-21 02:44:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:24][root][INFO] - Training Epoch: 1/2, step 28/17983 completed (loss: 5.924849987030029, acc: 0.1764705926179886)
[2024-10-21 02:44:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:24][root][INFO] - Training Epoch: 1/2, step 29/17983 completed (loss: 5.705028057098389, acc: 0.19178082048892975)
[2024-10-21 02:44:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:25][root][INFO] - Training Epoch: 1/2, step 30/17983 completed (loss: 5.755269527435303, acc: 0.125)
[2024-10-21 02:44:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:25][root][INFO] - Training Epoch: 1/2, step 31/17983 completed (loss: 6.0880913734436035, acc: 0.095238097012043)
[2024-10-21 02:44:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:26][root][INFO] - Training Epoch: 1/2, step 32/17983 completed (loss: 5.449310302734375, acc: 0.17159762978553772)
[2024-10-21 02:44:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:26][root][INFO] - Training Epoch: 1/2, step 33/17983 completed (loss: 6.427923679351807, acc: 0.1875)
[2024-10-21 02:44:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:27][root][INFO] - Training Epoch: 1/2, step 34/17983 completed (loss: 6.217630386352539, acc: 0.1525423675775528)
[2024-10-21 02:44:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:27][root][INFO] - Training Epoch: 1/2, step 35/17983 completed (loss: 5.540451526641846, acc: 0.18367347121238708)
[2024-10-21 02:44:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:28][root][INFO] - Training Epoch: 1/2, step 36/17983 completed (loss: 5.876031398773193, acc: 0.13333334028720856)
[2024-10-21 02:44:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:28][root][INFO] - Training Epoch: 1/2, step 37/17983 completed (loss: 5.751669883728027, acc: 0.2054794579744339)
[2024-10-21 02:44:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:28][root][INFO] - Training Epoch: 1/2, step 38/17983 completed (loss: 5.690995216369629, acc: 0.1388888955116272)
[2024-10-21 02:44:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:29][root][INFO] - Training Epoch: 1/2, step 39/17983 completed (loss: 6.997063159942627, acc: 0.10256410390138626)
[2024-10-21 02:44:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:29][root][INFO] - Training Epoch: 1/2, step 40/17983 completed (loss: 5.572671413421631, acc: 0.11666666716337204)
[2024-10-21 02:44:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:30][root][INFO] - Training Epoch: 1/2, step 41/17983 completed (loss: 5.030091285705566, acc: 0.2195121943950653)
[2024-10-21 02:44:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:30][root][INFO] - Training Epoch: 1/2, step 42/17983 completed (loss: 5.700928688049316, acc: 0.19696970283985138)
[2024-10-21 02:44:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:31][root][INFO] - Training Epoch: 1/2, step 43/17983 completed (loss: 5.954170227050781, acc: 0.12857143580913544)
[2024-10-21 02:44:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:31][root][INFO] - Training Epoch: 1/2, step 44/17983 completed (loss: 5.440185070037842, acc: 0.15789473056793213)
[2024-10-21 02:44:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:32][root][INFO] - Training Epoch: 1/2, step 45/17983 completed (loss: 6.2370781898498535, acc: 0.08510638028383255)
[2024-10-21 02:44:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:32][root][INFO] - Training Epoch: 1/2, step 46/17983 completed (loss: 5.245735168457031, acc: 0.20408163964748383)
[2024-10-21 02:44:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:33][root][INFO] - Training Epoch: 1/2, step 47/17983 completed (loss: 5.287035942077637, acc: 0.17582418024539948)
[2024-10-21 02:44:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:33][root][INFO] - Training Epoch: 1/2, step 48/17983 completed (loss: 5.322632789611816, acc: 0.20000000298023224)
[2024-10-21 02:44:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:34][root][INFO] - Training Epoch: 1/2, step 49/17983 completed (loss: 5.866177082061768, acc: 0.10294117778539658)
[2024-10-21 02:44:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:34][root][INFO] - Training Epoch: 1/2, step 50/17983 completed (loss: 5.372652053833008, acc: 0.25)
[2024-10-21 02:44:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:34][root][INFO] - Training Epoch: 1/2, step 51/17983 completed (loss: 5.218817234039307, acc: 0.12999999523162842)
[2024-10-21 02:44:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:35][root][INFO] - Training Epoch: 1/2, step 52/17983 completed (loss: 5.403972148895264, acc: 0.2133333384990692)
[2024-10-21 02:44:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:35][root][INFO] - Training Epoch: 1/2, step 53/17983 completed (loss: 4.849174976348877, acc: 0.24175824224948883)
[2024-10-21 02:44:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:36][root][INFO] - Training Epoch: 1/2, step 54/17983 completed (loss: 5.143876075744629, acc: 0.21250000596046448)
[2024-10-21 02:44:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:36][root][INFO] - Training Epoch: 1/2, step 55/17983 completed (loss: 5.512587547302246, acc: 0.1428571492433548)
[2024-10-21 02:44:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:37][root][INFO] - Training Epoch: 1/2, step 56/17983 completed (loss: 4.994673728942871, acc: 0.14754098653793335)
[2024-10-21 02:44:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:37][root][INFO] - Training Epoch: 1/2, step 57/17983 completed (loss: 4.915605068206787, acc: 0.13333334028720856)
[2024-10-21 02:44:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:37][root][INFO] - Training Epoch: 1/2, step 58/17983 completed (loss: 4.505527019500732, acc: 0.2525252401828766)
[2024-10-21 02:44:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:38][root][INFO] - Training Epoch: 1/2, step 59/17983 completed (loss: 5.1233625411987305, acc: 0.2380952388048172)
[2024-10-21 02:44:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:38][root][INFO] - Training Epoch: 1/2, step 60/17983 completed (loss: 5.608345031738281, acc: 0.13445378839969635)
[2024-10-21 02:44:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:39][root][INFO] - Training Epoch: 1/2, step 61/17983 completed (loss: 5.109503269195557, acc: 0.2118644118309021)
[2024-10-21 02:44:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:39][root][INFO] - Training Epoch: 1/2, step 62/17983 completed (loss: 5.355342864990234, acc: 0.17499999701976776)
[2024-10-21 02:44:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:40][root][INFO] - Training Epoch: 1/2, step 63/17983 completed (loss: 4.994867324829102, acc: 0.17105263471603394)
[2024-10-21 02:44:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:40][root][INFO] - Training Epoch: 1/2, step 64/17983 completed (loss: 5.432863235473633, acc: 0.1568627506494522)
[2024-10-21 02:44:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:40][root][INFO] - Training Epoch: 1/2, step 65/17983 completed (loss: 5.364908218383789, acc: 0.11267605423927307)
[2024-10-21 02:44:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:41][root][INFO] - Training Epoch: 1/2, step 66/17983 completed (loss: 4.953139305114746, acc: 0.18292683362960815)
[2024-10-21 02:44:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:41][root][INFO] - Training Epoch: 1/2, step 67/17983 completed (loss: 5.146833896636963, acc: 0.05882352963089943)
[2024-10-21 02:44:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:42][root][INFO] - Training Epoch: 1/2, step 68/17983 completed (loss: 5.134571552276611, acc: 0.18840579688549042)
[2024-10-21 02:44:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:42][root][INFO] - Training Epoch: 1/2, step 69/17983 completed (loss: 5.050547122955322, acc: 0.23076923191547394)
[2024-10-21 02:44:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:42][root][INFO] - Training Epoch: 1/2, step 70/17983 completed (loss: 5.187240123748779, acc: 0.1764705926179886)
[2024-10-21 02:44:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:43][root][INFO] - Training Epoch: 1/2, step 71/17983 completed (loss: 5.785536289215088, acc: 0.13483145833015442)
[2024-10-21 02:44:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:43][root][INFO] - Training Epoch: 1/2, step 72/17983 completed (loss: 4.316162109375, acc: 0.27586206793785095)
[2024-10-21 02:44:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:44][root][INFO] - Training Epoch: 1/2, step 73/17983 completed (loss: 5.327121734619141, acc: 0.21111111342906952)
[2024-10-21 02:44:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:44][root][INFO] - Training Epoch: 1/2, step 74/17983 completed (loss: 5.598050117492676, acc: 0.13750000298023224)
[2024-10-21 02:44:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:44][root][INFO] - Training Epoch: 1/2, step 75/17983 completed (loss: 5.256444454193115, acc: 0.1458333283662796)
[2024-10-21 02:44:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:45][root][INFO] - Training Epoch: 1/2, step 76/17983 completed (loss: 4.554664611816406, acc: 0.09615384787321091)
[2024-10-21 02:44:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:45][root][INFO] - Training Epoch: 1/2, step 77/17983 completed (loss: 5.305946350097656, acc: 0.10169491171836853)
[2024-10-21 02:44:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:46][root][INFO] - Training Epoch: 1/2, step 78/17983 completed (loss: 4.702064037322998, acc: 0.1875)
[2024-10-21 02:44:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:46][root][INFO] - Training Epoch: 1/2, step 79/17983 completed (loss: 4.592017650604248, acc: 0.26829269528388977)
[2024-10-21 02:44:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:46][root][INFO] - Training Epoch: 1/2, step 80/17983 completed (loss: 4.663890361785889, acc: 0.15555556118488312)
[2024-10-21 02:44:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:47][root][INFO] - Training Epoch: 1/2, step 81/17983 completed (loss: 4.715514659881592, acc: 0.19230769574642181)
[2024-10-21 02:44:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:47][root][INFO] - Training Epoch: 1/2, step 82/17983 completed (loss: 4.749911785125732, acc: 0.190476194024086)
[2024-10-21 02:44:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:48][root][INFO] - Training Epoch: 1/2, step 83/17983 completed (loss: 5.068637371063232, acc: 0.16249999403953552)
[2024-10-21 02:44:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:48][root][INFO] - Training Epoch: 1/2, step 84/17983 completed (loss: 5.079935550689697, acc: 0.15094339847564697)
[2024-10-21 02:44:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:48][root][INFO] - Training Epoch: 1/2, step 85/17983 completed (loss: 4.251074314117432, acc: 0.23999999463558197)
[2024-10-21 02:44:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:49][root][INFO] - Training Epoch: 1/2, step 86/17983 completed (loss: 4.3460845947265625, acc: 0.26153847575187683)
[2024-10-21 02:44:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:49][root][INFO] - Training Epoch: 1/2, step 87/17983 completed (loss: 4.918778896331787, acc: 0.18918919563293457)
[2024-10-21 02:44:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:50][root][INFO] - Training Epoch: 1/2, step 88/17983 completed (loss: 4.764493942260742, acc: 0.1666666716337204)
[2024-10-21 02:44:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:50][root][INFO] - Training Epoch: 1/2, step 89/17983 completed (loss: 4.246878623962402, acc: 0.25)
[2024-10-21 02:44:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:51][root][INFO] - Training Epoch: 1/2, step 90/17983 completed (loss: 4.721896648406982, acc: 0.30612245202064514)
[2024-10-21 02:44:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:51][root][INFO] - Training Epoch: 1/2, step 91/17983 completed (loss: 4.192553520202637, acc: 0.2881355881690979)
[2024-10-21 02:44:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:52][root][INFO] - Training Epoch: 1/2, step 92/17983 completed (loss: 4.438255786895752, acc: 0.22077922523021698)
[2024-10-21 02:44:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:52][root][INFO] - Training Epoch: 1/2, step 93/17983 completed (loss: 3.179386854171753, acc: 0.3333333432674408)
[2024-10-21 02:44:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:52][root][INFO] - Training Epoch: 1/2, step 94/17983 completed (loss: 4.20514440536499, acc: 0.19354838132858276)
[2024-10-21 02:44:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:53][root][INFO] - Training Epoch: 1/2, step 95/17983 completed (loss: 4.038058757781982, acc: 0.26582279801368713)
[2024-10-21 02:44:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:53][root][INFO] - Training Epoch: 1/2, step 96/17983 completed (loss: 4.0162858963012695, acc: 0.2639999985694885)
[2024-10-21 02:44:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:54][root][INFO] - Training Epoch: 1/2, step 97/17983 completed (loss: 4.165318489074707, acc: 0.2461538463830948)
[2024-10-21 02:44:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:54][root][INFO] - Training Epoch: 1/2, step 98/17983 completed (loss: 3.975745677947998, acc: 0.2857142984867096)
[2024-10-21 02:44:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:54][root][INFO] - Training Epoch: 1/2, step 99/17983 completed (loss: 3.807136058807373, acc: 0.27659574151039124)
[2024-10-21 02:44:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:55][root][INFO] - Training Epoch: 1/2, step 100/17983 completed (loss: 3.7103633880615234, acc: 0.302325576543808)
[2024-10-21 02:44:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:55][root][INFO] - Training Epoch: 1/2, step 101/17983 completed (loss: 4.422708034515381, acc: 0.2716049253940582)
[2024-10-21 02:44:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:56][root][INFO] - Training Epoch: 1/2, step 102/17983 completed (loss: 4.957866191864014, acc: 0.17000000178813934)
[2024-10-21 02:44:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:56][root][INFO] - Training Epoch: 1/2, step 103/17983 completed (loss: 4.095141887664795, acc: 0.2068965584039688)
[2024-10-21 02:44:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:56][root][INFO] - Training Epoch: 1/2, step 104/17983 completed (loss: 4.362019062042236, acc: 0.2795698940753937)
[2024-10-21 02:44:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:57][root][INFO] - Training Epoch: 1/2, step 105/17983 completed (loss: 3.784048318862915, acc: 0.36666667461395264)
[2024-10-21 02:44:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:57][root][INFO] - Training Epoch: 1/2, step 106/17983 completed (loss: 3.762556314468384, acc: 0.25555557012557983)
[2024-10-21 02:44:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:58][root][INFO] - Training Epoch: 1/2, step 107/17983 completed (loss: 4.276195526123047, acc: 0.25641027092933655)
[2024-10-21 02:44:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:58][root][INFO] - Training Epoch: 1/2, step 108/17983 completed (loss: 4.724356651306152, acc: 0.17391304671764374)
[2024-10-21 02:44:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:58][root][INFO] - Training Epoch: 1/2, step 109/17983 completed (loss: 4.01573371887207, acc: 0.2650602459907532)
[2024-10-21 02:44:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:59][root][INFO] - Training Epoch: 1/2, step 110/17983 completed (loss: 3.769041061401367, acc: 0.30612245202064514)
[2024-10-21 02:44:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:44:59][root][INFO] - Training Epoch: 1/2, step 111/17983 completed (loss: 3.8196728229522705, acc: 0.30985915660858154)
[2024-10-21 02:44:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:00][root][INFO] - Training Epoch: 1/2, step 112/17983 completed (loss: 3.919656753540039, acc: 0.20000000298023224)
[2024-10-21 02:45:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:00][root][INFO] - Training Epoch: 1/2, step 113/17983 completed (loss: 4.238828182220459, acc: 0.20661157369613647)
[2024-10-21 02:45:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:01][root][INFO] - Training Epoch: 1/2, step 114/17983 completed (loss: 3.5360491275787354, acc: 0.3255814015865326)
[2024-10-21 02:45:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:01][root][INFO] - Training Epoch: 1/2, step 115/17983 completed (loss: 4.285427570343018, acc: 0.24137930572032928)
[2024-10-21 02:45:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:02][root][INFO] - Training Epoch: 1/2, step 116/17983 completed (loss: 3.5195188522338867, acc: 0.3193277418613434)
[2024-10-21 02:45:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:02][root][INFO] - Training Epoch: 1/2, step 117/17983 completed (loss: 3.128200054168701, acc: 0.4193548262119293)
[2024-10-21 02:45:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:03][root][INFO] - Training Epoch: 1/2, step 118/17983 completed (loss: 3.735759735107422, acc: 0.3414634168148041)
[2024-10-21 02:45:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:03][root][INFO] - Training Epoch: 1/2, step 119/17983 completed (loss: 4.463497638702393, acc: 0.27272728085517883)
[2024-10-21 02:45:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:04][root][INFO] - Training Epoch: 1/2, step 120/17983 completed (loss: 3.545318603515625, acc: 0.349056601524353)
[2024-10-21 02:45:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:04][root][INFO] - Training Epoch: 1/2, step 121/17983 completed (loss: 3.663663625717163, acc: 0.3658536672592163)
[2024-10-21 02:45:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:04][root][INFO] - Training Epoch: 1/2, step 122/17983 completed (loss: 3.6387059688568115, acc: 0.3173076808452606)
[2024-10-21 02:45:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:05][root][INFO] - Training Epoch: 1/2, step 123/17983 completed (loss: 3.488863945007324, acc: 0.37931033968925476)
[2024-10-21 02:45:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:05][root][INFO] - Training Epoch: 1/2, step 124/17983 completed (loss: 3.70202374458313, acc: 0.3358778655529022)
[2024-10-21 02:45:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:06][root][INFO] - Training Epoch: 1/2, step 125/17983 completed (loss: 3.3400721549987793, acc: 0.3636363744735718)
[2024-10-21 02:45:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:06][root][INFO] - Training Epoch: 1/2, step 126/17983 completed (loss: 3.633995294570923, acc: 0.30392158031463623)
[2024-10-21 02:45:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:06][root][INFO] - Training Epoch: 1/2, step 127/17983 completed (loss: 4.083384990692139, acc: 0.2888889014720917)
[2024-10-21 02:45:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:07][root][INFO] - Training Epoch: 1/2, step 128/17983 completed (loss: 3.4658432006835938, acc: 0.3125)
[2024-10-21 02:45:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:07][root][INFO] - Training Epoch: 1/2, step 129/17983 completed (loss: 4.204740524291992, acc: 0.23636363446712494)
[2024-10-21 02:45:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:08][root][INFO] - Training Epoch: 1/2, step 130/17983 completed (loss: 3.4493021965026855, acc: 0.39759036898612976)
[2024-10-21 02:45:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:08][root][INFO] - Training Epoch: 1/2, step 131/17983 completed (loss: 4.133701801300049, acc: 0.25)
[2024-10-21 02:45:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:09][root][INFO] - Training Epoch: 1/2, step 132/17983 completed (loss: 4.482904434204102, acc: 0.20909090340137482)
[2024-10-21 02:45:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:09][root][INFO] - Training Epoch: 1/2, step 133/17983 completed (loss: 4.373401165008545, acc: 0.11594203114509583)
[2024-10-21 02:45:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:09][root][INFO] - Training Epoch: 1/2, step 134/17983 completed (loss: 3.726837158203125, acc: 0.22522522509098053)
[2024-10-21 02:45:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:10][root][INFO] - Training Epoch: 1/2, step 135/17983 completed (loss: 3.858565092086792, acc: 0.25217390060424805)
[2024-10-21 02:45:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:10][root][INFO] - Training Epoch: 1/2, step 136/17983 completed (loss: 3.5424156188964844, acc: 0.3333333432674408)
[2024-10-21 02:45:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:11][root][INFO] - Training Epoch: 1/2, step 137/17983 completed (loss: 3.4902682304382324, acc: 0.36090224981307983)
[2024-10-21 02:45:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:11][root][INFO] - Training Epoch: 1/2, step 138/17983 completed (loss: 3.602893114089966, acc: 0.3799999952316284)
[2024-10-21 02:45:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:11][root][INFO] - Training Epoch: 1/2, step 139/17983 completed (loss: 3.6014676094055176, acc: 0.3396226465702057)
[2024-10-21 02:45:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:12][root][INFO] - Training Epoch: 1/2, step 140/17983 completed (loss: 3.1199562549591064, acc: 0.3947368562221527)
[2024-10-21 02:45:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:12][root][INFO] - Training Epoch: 1/2, step 141/17983 completed (loss: 4.016726970672607, acc: 0.25581395626068115)
[2024-10-21 02:45:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:13][root][INFO] - Training Epoch: 1/2, step 142/17983 completed (loss: 4.11207914352417, acc: 0.24468085169792175)
[2024-10-21 02:45:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:13][root][INFO] - Training Epoch: 1/2, step 143/17983 completed (loss: 4.111619472503662, acc: 0.23943662643432617)
[2024-10-21 02:45:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:13][root][INFO] - Training Epoch: 1/2, step 144/17983 completed (loss: 3.3677568435668945, acc: 0.3218390941619873)
[2024-10-21 02:45:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:14][root][INFO] - Training Epoch: 1/2, step 145/17983 completed (loss: 3.4617323875427246, acc: 0.3700000047683716)
[2024-10-21 02:45:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:14][root][INFO] - Training Epoch: 1/2, step 146/17983 completed (loss: 3.7715718746185303, acc: 0.29870128631591797)
[2024-10-21 02:45:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:15][root][INFO] - Training Epoch: 1/2, step 147/17983 completed (loss: 4.030587673187256, acc: 0.23529411852359772)
[2024-10-21 02:45:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:15][root][INFO] - Training Epoch: 1/2, step 148/17983 completed (loss: 3.835020065307617, acc: 0.24137930572032928)
[2024-10-21 02:45:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:15][root][INFO] - Training Epoch: 1/2, step 149/17983 completed (loss: 2.6514341831207275, acc: 0.44897958636283875)
[2024-10-21 02:45:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:16][root][INFO] - Training Epoch: 1/2, step 150/17983 completed (loss: 3.089036703109741, acc: 0.3466666638851166)
[2024-10-21 02:45:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:16][root][INFO] - Training Epoch: 1/2, step 151/17983 completed (loss: 4.113877296447754, acc: 0.2542372941970825)
[2024-10-21 02:45:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:16][root][INFO] - Training Epoch: 1/2, step 152/17983 completed (loss: 4.085557460784912, acc: 0.2571428716182709)
[2024-10-21 02:45:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:17][root][INFO] - Training Epoch: 1/2, step 153/17983 completed (loss: 3.3871541023254395, acc: 0.353658527135849)
[2024-10-21 02:45:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:17][root][INFO] - Training Epoch: 1/2, step 154/17983 completed (loss: 2.89081072807312, acc: 0.4528301954269409)
[2024-10-21 02:45:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:17][root][INFO] - Training Epoch: 1/2, step 155/17983 completed (loss: 4.1472954750061035, acc: 0.23529411852359772)
[2024-10-21 02:45:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:18][root][INFO] - Training Epoch: 1/2, step 156/17983 completed (loss: 2.781538724899292, acc: 0.4262295067310333)
[2024-10-21 02:45:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:18][root][INFO] - Training Epoch: 1/2, step 157/17983 completed (loss: 3.5146095752716064, acc: 0.30434781312942505)
[2024-10-21 02:45:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:19][root][INFO] - Training Epoch: 1/2, step 158/17983 completed (loss: 3.157313585281372, acc: 0.2982456088066101)
[2024-10-21 02:45:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:19][root][INFO] - Training Epoch: 1/2, step 159/17983 completed (loss: 3.798398017883301, acc: 0.27358490228652954)
[2024-10-21 02:45:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:20][root][INFO] - Training Epoch: 1/2, step 160/17983 completed (loss: 4.412782192230225, acc: 0.3125)
[2024-10-21 02:45:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:20][root][INFO] - Training Epoch: 1/2, step 161/17983 completed (loss: 2.9967310428619385, acc: 0.3243243098258972)
[2024-10-21 02:45:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:20][root][INFO] - Training Epoch: 1/2, step 162/17983 completed (loss: 3.6988840103149414, acc: 0.2777777910232544)
[2024-10-21 02:45:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:21][root][INFO] - Training Epoch: 1/2, step 163/17983 completed (loss: 3.976196527481079, acc: 0.3258427083492279)
[2024-10-21 02:45:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:21][root][INFO] - Training Epoch: 1/2, step 164/17983 completed (loss: 3.618818759918213, acc: 0.3333333432674408)
[2024-10-21 02:45:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:22][root][INFO] - Training Epoch: 1/2, step 165/17983 completed (loss: 3.7483391761779785, acc: 0.3047619163990021)
[2024-10-21 02:45:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:22][root][INFO] - Training Epoch: 1/2, step 166/17983 completed (loss: 3.7106144428253174, acc: 0.25471699237823486)
[2024-10-21 02:45:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:22][root][INFO] - Training Epoch: 1/2, step 167/17983 completed (loss: 3.4690639972686768, acc: 0.4722222089767456)
[2024-10-21 02:45:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:23][root][INFO] - Training Epoch: 1/2, step 168/17983 completed (loss: 3.8151893615722656, acc: 0.3083333373069763)
[2024-10-21 02:45:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:23][root][INFO] - Training Epoch: 1/2, step 169/17983 completed (loss: 2.271970748901367, acc: 0.5)
[2024-10-21 02:45:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:24][root][INFO] - Training Epoch: 1/2, step 170/17983 completed (loss: 3.882028818130493, acc: 0.3030303120613098)
[2024-10-21 02:45:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:25][root][INFO] - Training Epoch: 1/2, step 171/17983 completed (loss: 3.5511186122894287, acc: 0.31168830394744873)
[2024-10-21 02:45:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:25][root][INFO] - Training Epoch: 1/2, step 172/17983 completed (loss: 3.4837424755096436, acc: 0.30612245202064514)
[2024-10-21 02:45:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:25][root][INFO] - Training Epoch: 1/2, step 173/17983 completed (loss: 3.0104641914367676, acc: 0.3857142925262451)
[2024-10-21 02:45:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:26][root][INFO] - Training Epoch: 1/2, step 174/17983 completed (loss: 3.242147922515869, acc: 0.24444444477558136)
[2024-10-21 02:45:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:26][root][INFO] - Training Epoch: 1/2, step 175/17983 completed (loss: 2.9430336952209473, acc: 0.3294117748737335)
[2024-10-21 02:45:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:27][root][INFO] - Training Epoch: 1/2, step 176/17983 completed (loss: 3.8994364738464355, acc: 0.28333333134651184)
[2024-10-21 02:45:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:27][root][INFO] - Training Epoch: 1/2, step 177/17983 completed (loss: 3.870919942855835, acc: 0.3333333432674408)
[2024-10-21 02:45:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:27][root][INFO] - Training Epoch: 1/2, step 178/17983 completed (loss: 4.143972396850586, acc: 0.25609755516052246)
[2024-10-21 02:45:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:28][root][INFO] - Training Epoch: 1/2, step 179/17983 completed (loss: 3.8717188835144043, acc: 0.2716049253940582)
[2024-10-21 02:45:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:28][root][INFO] - Training Epoch: 1/2, step 180/17983 completed (loss: 3.054414987564087, acc: 0.5178571343421936)
[2024-10-21 02:45:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:29][root][INFO] - Training Epoch: 1/2, step 181/17983 completed (loss: 3.7424256801605225, acc: 0.24242424964904785)
[2024-10-21 02:45:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:29][root][INFO] - Training Epoch: 1/2, step 182/17983 completed (loss: 3.5049078464508057, acc: 0.22580644488334656)
[2024-10-21 02:45:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:30][root][INFO] - Training Epoch: 1/2, step 183/17983 completed (loss: 3.2852916717529297, acc: 0.30909091234207153)
[2024-10-21 02:45:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:30][root][INFO] - Training Epoch: 1/2, step 184/17983 completed (loss: 3.4161484241485596, acc: 0.3333333432674408)
[2024-10-21 02:45:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:30][root][INFO] - Training Epoch: 1/2, step 185/17983 completed (loss: 3.5521862506866455, acc: 0.32692307233810425)
[2024-10-21 02:45:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:31][root][INFO] - Training Epoch: 1/2, step 186/17983 completed (loss: 2.795175790786743, acc: 0.43939393758773804)
[2024-10-21 02:45:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:32][root][INFO] - Training Epoch: 1/2, step 187/17983 completed (loss: 2.4258174896240234, acc: 0.4838709533214569)
[2024-10-21 02:45:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:32][root][INFO] - Training Epoch: 1/2, step 188/17983 completed (loss: 3.2926955223083496, acc: 0.421875)
[2024-10-21 02:45:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:32][root][INFO] - Training Epoch: 1/2, step 189/17983 completed (loss: 3.2535831928253174, acc: 0.3333333432674408)
[2024-10-21 02:45:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:33][root][INFO] - Training Epoch: 1/2, step 190/17983 completed (loss: 3.7761306762695312, acc: 0.32499998807907104)
[2024-10-21 02:45:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:33][root][INFO] - Training Epoch: 1/2, step 191/17983 completed (loss: 3.406036376953125, acc: 0.3020833432674408)
[2024-10-21 02:45:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:34][root][INFO] - Training Epoch: 1/2, step 192/17983 completed (loss: 3.7120578289031982, acc: 0.25925925374031067)
[2024-10-21 02:45:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:34][root][INFO] - Training Epoch: 1/2, step 193/17983 completed (loss: 4.345278739929199, acc: 0.2857142984867096)
[2024-10-21 02:45:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:35][root][INFO] - Training Epoch: 1/2, step 194/17983 completed (loss: 2.9428350925445557, acc: 0.4285714328289032)
[2024-10-21 02:45:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:35][root][INFO] - Training Epoch: 1/2, step 195/17983 completed (loss: 3.2725839614868164, acc: 0.2876712381839752)
[2024-10-21 02:45:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:36][root][INFO] - Training Epoch: 1/2, step 196/17983 completed (loss: 3.1436753273010254, acc: 0.3870967626571655)
[2024-10-21 02:45:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:36][root][INFO] - Training Epoch: 1/2, step 197/17983 completed (loss: 3.1789469718933105, acc: 0.3333333432674408)
[2024-10-21 02:45:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:36][root][INFO] - Training Epoch: 1/2, step 198/17983 completed (loss: 3.693655014038086, acc: 0.4137931168079376)
[2024-10-21 02:45:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:37][root][INFO] - Training Epoch: 1/2, step 199/17983 completed (loss: 3.538533926010132, acc: 0.2970297038555145)
[2024-10-21 02:45:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:37][root][INFO] - Training Epoch: 1/2, step 200/17983 completed (loss: 2.8212783336639404, acc: 0.5370370149612427)
[2024-10-21 02:45:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:38][root][INFO] - Training Epoch: 1/2, step 201/17983 completed (loss: 3.606457471847534, acc: 0.35820895433425903)
[2024-10-21 02:45:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:38][root][INFO] - Training Epoch: 1/2, step 202/17983 completed (loss: 3.3650691509246826, acc: 0.3510638177394867)
[2024-10-21 02:45:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:39][root][INFO] - Training Epoch: 1/2, step 203/17983 completed (loss: 3.4976208209991455, acc: 0.3163265287876129)
[2024-10-21 02:45:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:39][root][INFO] - Training Epoch: 1/2, step 204/17983 completed (loss: 3.516218900680542, acc: 0.3947368562221527)
[2024-10-21 02:45:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:40][root][INFO] - Training Epoch: 1/2, step 205/17983 completed (loss: 3.306124210357666, acc: 0.3076923191547394)
[2024-10-21 02:45:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:40][root][INFO] - Training Epoch: 1/2, step 206/17983 completed (loss: 3.8272383213043213, acc: 0.2380952388048172)
[2024-10-21 02:45:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:41][root][INFO] - Training Epoch: 1/2, step 207/17983 completed (loss: 3.3334202766418457, acc: 0.33636364340782166)
[2024-10-21 02:45:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:41][root][INFO] - Training Epoch: 1/2, step 208/17983 completed (loss: 2.547820806503296, acc: 0.45783132314682007)
[2024-10-21 02:45:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:41][root][INFO] - Training Epoch: 1/2, step 209/17983 completed (loss: 3.5268185138702393, acc: 0.3333333432674408)
[2024-10-21 02:45:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:42][root][INFO] - Training Epoch: 1/2, step 210/17983 completed (loss: 3.2795259952545166, acc: 0.4029850661754608)
[2024-10-21 02:45:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:43][root][INFO] - Training Epoch: 1/2, step 211/17983 completed (loss: 3.7240281105041504, acc: 0.2380952388048172)
[2024-10-21 02:45:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:43][root][INFO] - Training Epoch: 1/2, step 212/17983 completed (loss: 3.3343636989593506, acc: 0.3488371968269348)
[2024-10-21 02:45:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:43][root][INFO] - Training Epoch: 1/2, step 213/17983 completed (loss: 3.7119102478027344, acc: 0.30000001192092896)
[2024-10-21 02:45:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:44][root][INFO] - Training Epoch: 1/2, step 214/17983 completed (loss: 3.535629987716675, acc: 0.3047619163990021)
[2024-10-21 02:45:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:44][root][INFO] - Training Epoch: 1/2, step 215/17983 completed (loss: 3.776501178741455, acc: 0.3448275923728943)
[2024-10-21 02:45:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:45][root][INFO] - Training Epoch: 1/2, step 216/17983 completed (loss: 3.1111392974853516, acc: 0.31578946113586426)
[2024-10-21 02:45:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:45][root][INFO] - Training Epoch: 1/2, step 217/17983 completed (loss: 2.471045732498169, acc: 0.49462366104125977)
[2024-10-21 02:45:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:46][root][INFO] - Training Epoch: 1/2, step 218/17983 completed (loss: 3.3170907497406006, acc: 0.3958333432674408)
[2024-10-21 02:45:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:46][root][INFO] - Training Epoch: 1/2, step 219/17983 completed (loss: 2.755453109741211, acc: 0.4285714328289032)
[2024-10-21 02:45:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:47][root][INFO] - Training Epoch: 1/2, step 220/17983 completed (loss: 3.2967426776885986, acc: 0.3442623019218445)
[2024-10-21 02:45:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:47][root][INFO] - Training Epoch: 1/2, step 221/17983 completed (loss: 3.428145408630371, acc: 0.3295454680919647)
[2024-10-21 02:45:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:48][root][INFO] - Training Epoch: 1/2, step 222/17983 completed (loss: 3.2012205123901367, acc: 0.3076923191547394)
[2024-10-21 02:45:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:48][root][INFO] - Training Epoch: 1/2, step 223/17983 completed (loss: 3.4879801273345947, acc: 0.3571428656578064)
[2024-10-21 02:45:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:48][root][INFO] - Training Epoch: 1/2, step 224/17983 completed (loss: 3.0435047149658203, acc: 0.3265306055545807)
[2024-10-21 02:45:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:49][root][INFO] - Training Epoch: 1/2, step 225/17983 completed (loss: 3.418868064880371, acc: 0.25581395626068115)
[2024-10-21 02:45:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:49][root][INFO] - Training Epoch: 1/2, step 226/17983 completed (loss: 3.5845706462860107, acc: 0.29629629850387573)
[2024-10-21 02:45:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:49][root][INFO] - Training Epoch: 1/2, step 227/17983 completed (loss: 3.0152065753936768, acc: 0.4067796468734741)
[2024-10-21 02:45:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:50][root][INFO] - Training Epoch: 1/2, step 228/17983 completed (loss: 3.6292827129364014, acc: 0.3529411852359772)
[2024-10-21 02:45:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:50][root][INFO] - Training Epoch: 1/2, step 229/17983 completed (loss: 3.2655210494995117, acc: 0.40909090638160706)
[2024-10-21 02:45:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:51][root][INFO] - Training Epoch: 1/2, step 230/17983 completed (loss: 3.1989760398864746, acc: 0.4318181872367859)
[2024-10-21 02:45:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:51][root][INFO] - Training Epoch: 1/2, step 231/17983 completed (loss: 3.277492046356201, acc: 0.37681159377098083)
[2024-10-21 02:45:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:52][root][INFO] - Training Epoch: 1/2, step 232/17983 completed (loss: 2.741520643234253, acc: 0.375)
[2024-10-21 02:45:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:52][root][INFO] - Training Epoch: 1/2, step 233/17983 completed (loss: 2.921377658843994, acc: 0.446153849363327)
[2024-10-21 02:45:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:53][root][INFO] - Training Epoch: 1/2, step 234/17983 completed (loss: 3.30810809135437, acc: 0.3467741906642914)
[2024-10-21 02:45:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:53][root][INFO] - Training Epoch: 1/2, step 235/17983 completed (loss: 2.999485492706299, acc: 0.3499999940395355)
[2024-10-21 02:45:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:53][root][INFO] - Training Epoch: 1/2, step 236/17983 completed (loss: 3.254129409790039, acc: 0.3804347813129425)
[2024-10-21 02:45:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:54][root][INFO] - Training Epoch: 1/2, step 237/17983 completed (loss: 3.0949368476867676, acc: 0.35185185074806213)
[2024-10-21 02:45:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:54][root][INFO] - Training Epoch: 1/2, step 238/17983 completed (loss: 3.111666440963745, acc: 0.359375)
[2024-10-21 02:45:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:55][root][INFO] - Training Epoch: 1/2, step 239/17983 completed (loss: 3.397207736968994, acc: 0.33766233921051025)
[2024-10-21 02:45:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:55][root][INFO] - Training Epoch: 1/2, step 240/17983 completed (loss: 3.366304636001587, acc: 0.31460675597190857)
[2024-10-21 02:45:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:56][root][INFO] - Training Epoch: 1/2, step 241/17983 completed (loss: 3.533050537109375, acc: 0.3483146131038666)
[2024-10-21 02:45:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:56][root][INFO] - Training Epoch: 1/2, step 242/17983 completed (loss: 3.0069901943206787, acc: 0.34020617604255676)
[2024-10-21 02:45:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:57][root][INFO] - Training Epoch: 1/2, step 243/17983 completed (loss: 3.2663893699645996, acc: 0.3305785059928894)
[2024-10-21 02:45:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:57][root][INFO] - Training Epoch: 1/2, step 244/17983 completed (loss: 2.5025157928466797, acc: 0.44186046719551086)
[2024-10-21 02:45:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:57][root][INFO] - Training Epoch: 1/2, step 245/17983 completed (loss: 3.9487361907958984, acc: 0.3125)
[2024-10-21 02:45:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:58][root][INFO] - Training Epoch: 1/2, step 246/17983 completed (loss: 2.6801741123199463, acc: 0.4285714328289032)
[2024-10-21 02:45:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:58][root][INFO] - Training Epoch: 1/2, step 247/17983 completed (loss: 3.355177164077759, acc: 0.38317757844924927)
[2024-10-21 02:45:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:59][root][INFO] - Training Epoch: 1/2, step 248/17983 completed (loss: 3.5552613735198975, acc: 0.3505154550075531)
[2024-10-21 02:45:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:45:59][root][INFO] - Training Epoch: 1/2, step 249/17983 completed (loss: 3.450547933578491, acc: 0.3191489279270172)
[2024-10-21 02:45:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:00][root][INFO] - Training Epoch: 1/2, step 250/17983 completed (loss: 2.3827786445617676, acc: 0.4285714328289032)
[2024-10-21 02:46:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:00][root][INFO] - Training Epoch: 1/2, step 251/17983 completed (loss: 2.6582984924316406, acc: 0.3888888955116272)
[2024-10-21 02:46:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:01][root][INFO] - Training Epoch: 1/2, step 252/17983 completed (loss: 2.8918445110321045, acc: 0.3962264060974121)
[2024-10-21 02:46:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:01][root][INFO] - Training Epoch: 1/2, step 253/17983 completed (loss: 3.4993624687194824, acc: 0.3695652186870575)
[2024-10-21 02:46:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:01][root][INFO] - Training Epoch: 1/2, step 254/17983 completed (loss: 2.779053211212158, acc: 0.37078651785850525)
[2024-10-21 02:46:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:02][root][INFO] - Training Epoch: 1/2, step 255/17983 completed (loss: 3.4326655864715576, acc: 0.3382352888584137)
[2024-10-21 02:46:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:02][root][INFO] - Training Epoch: 1/2, step 256/17983 completed (loss: 3.0944910049438477, acc: 0.4054054021835327)
[2024-10-21 02:46:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:03][root][INFO] - Training Epoch: 1/2, step 257/17983 completed (loss: 2.9061896800994873, acc: 0.40625)
[2024-10-21 02:46:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:03][root][INFO] - Training Epoch: 1/2, step 258/17983 completed (loss: 3.6818134784698486, acc: 0.291262149810791)
[2024-10-21 02:46:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:04][root][INFO] - Training Epoch: 1/2, step 259/17983 completed (loss: 3.039006471633911, acc: 0.32203391194343567)
[2024-10-21 02:46:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:04][root][INFO] - Training Epoch: 1/2, step 260/17983 completed (loss: 2.6822516918182373, acc: 0.4920634925365448)
[2024-10-21 02:46:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:05][root][INFO] - Training Epoch: 1/2, step 261/17983 completed (loss: 3.4445605278015137, acc: 0.3333333432674408)
[2024-10-21 02:46:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:05][root][INFO] - Training Epoch: 1/2, step 262/17983 completed (loss: 3.246711254119873, acc: 0.38333332538604736)
[2024-10-21 02:46:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:05][root][INFO] - Training Epoch: 1/2, step 263/17983 completed (loss: 2.8826539516448975, acc: 0.38805970549583435)
[2024-10-21 02:46:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:06][root][INFO] - Training Epoch: 1/2, step 264/17983 completed (loss: 1.4233278036117554, acc: 0.7916666865348816)
[2024-10-21 02:46:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:06][root][INFO] - Training Epoch: 1/2, step 265/17983 completed (loss: 3.3690435886383057, acc: 0.35164836049079895)
[2024-10-21 02:46:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:07][root][INFO] - Training Epoch: 1/2, step 266/17983 completed (loss: 2.5704143047332764, acc: 0.5254237055778503)
[2024-10-21 02:46:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:07][root][INFO] - Training Epoch: 1/2, step 267/17983 completed (loss: 3.7477011680603027, acc: 0.3235294222831726)
[2024-10-21 02:46:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:08][root][INFO] - Training Epoch: 1/2, step 268/17983 completed (loss: 2.7730484008789062, acc: 0.5600000023841858)
[2024-10-21 02:46:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:08][root][INFO] - Training Epoch: 1/2, step 269/17983 completed (loss: 3.5046231746673584, acc: 0.29203540086746216)
[2024-10-21 02:46:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:09][root][INFO] - Training Epoch: 1/2, step 270/17983 completed (loss: 2.813141345977783, acc: 0.43396225571632385)
[2024-10-21 02:46:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:09][root][INFO] - Training Epoch: 1/2, step 271/17983 completed (loss: 3.5353565216064453, acc: 0.36764705181121826)
[2024-10-21 02:46:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:09][root][INFO] - Training Epoch: 1/2, step 272/17983 completed (loss: 3.6104981899261475, acc: 0.3207547068595886)
[2024-10-21 02:46:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:10][root][INFO] - Training Epoch: 1/2, step 273/17983 completed (loss: 3.1917519569396973, acc: 0.3472222089767456)
[2024-10-21 02:46:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:10][root][INFO] - Training Epoch: 1/2, step 274/17983 completed (loss: 3.859750509262085, acc: 0.3478260934352875)
[2024-10-21 02:46:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:11][root][INFO] - Training Epoch: 1/2, step 275/17983 completed (loss: 3.049424409866333, acc: 0.3947368562221527)
[2024-10-21 02:46:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:11][root][INFO] - Training Epoch: 1/2, step 276/17983 completed (loss: 3.0630080699920654, acc: 0.38235294818878174)
[2024-10-21 02:46:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:12][root][INFO] - Training Epoch: 1/2, step 277/17983 completed (loss: 3.6015872955322266, acc: 0.34567901492118835)
[2024-10-21 02:46:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:12][root][INFO] - Training Epoch: 1/2, step 278/17983 completed (loss: 2.46396541595459, acc: 0.47999998927116394)
[2024-10-21 02:46:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:13][root][INFO] - Training Epoch: 1/2, step 279/17983 completed (loss: 2.8941619396209717, acc: 0.4285714328289032)
[2024-10-21 02:46:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:13][root][INFO] - Training Epoch: 1/2, step 280/17983 completed (loss: 3.1411004066467285, acc: 0.3636363744735718)
[2024-10-21 02:46:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:14][root][INFO] - Training Epoch: 1/2, step 281/17983 completed (loss: 3.563969612121582, acc: 0.3188405930995941)
[2024-10-21 02:46:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:14][root][INFO] - Training Epoch: 1/2, step 282/17983 completed (loss: 3.3874337673187256, acc: 0.38372093439102173)
[2024-10-21 02:46:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:14][root][INFO] - Training Epoch: 1/2, step 283/17983 completed (loss: 3.2444331645965576, acc: 0.3896103799343109)
[2024-10-21 02:46:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:15][root][INFO] - Training Epoch: 1/2, step 284/17983 completed (loss: 3.4765284061431885, acc: 0.3333333432674408)
[2024-10-21 02:46:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:15][root][INFO] - Training Epoch: 1/2, step 285/17983 completed (loss: 3.8820154666900635, acc: 0.25925925374031067)
[2024-10-21 02:46:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:16][root][INFO] - Training Epoch: 1/2, step 286/17983 completed (loss: 3.954002857208252, acc: 0.2750000059604645)
[2024-10-21 02:46:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:16][root][INFO] - Training Epoch: 1/2, step 287/17983 completed (loss: 3.4580013751983643, acc: 0.3469387888908386)
[2024-10-21 02:46:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:17][root][INFO] - Training Epoch: 1/2, step 288/17983 completed (loss: 3.2869606018066406, acc: 0.38805970549583435)
[2024-10-21 02:46:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:17][root][INFO] - Training Epoch: 1/2, step 289/17983 completed (loss: 3.248014450073242, acc: 0.3709677457809448)
[2024-10-21 02:46:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:17][root][INFO] - Training Epoch: 1/2, step 290/17983 completed (loss: 3.746713876724243, acc: 0.23529411852359772)
[2024-10-21 02:46:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:18][root][INFO] - Training Epoch: 1/2, step 291/17983 completed (loss: 3.935645580291748, acc: 0.2857142984867096)
[2024-10-21 02:46:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:18][root][INFO] - Training Epoch: 1/2, step 292/17983 completed (loss: 3.056029796600342, acc: 0.33870968222618103)
[2024-10-21 02:46:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:19][root][INFO] - Training Epoch: 1/2, step 293/17983 completed (loss: 3.191232919692993, acc: 0.3396226465702057)
[2024-10-21 02:46:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:19][root][INFO] - Training Epoch: 1/2, step 294/17983 completed (loss: 3.350010633468628, acc: 0.37634408473968506)
[2024-10-21 02:46:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:19][root][INFO] - Training Epoch: 1/2, step 295/17983 completed (loss: 3.272063732147217, acc: 0.2857142984867096)
[2024-10-21 02:46:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:20][root][INFO] - Training Epoch: 1/2, step 296/17983 completed (loss: 3.5831780433654785, acc: 0.28947368264198303)
[2024-10-21 02:46:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:20][root][INFO] - Training Epoch: 1/2, step 297/17983 completed (loss: 3.2086002826690674, acc: 0.3076923191547394)
[2024-10-21 02:46:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:21][root][INFO] - Training Epoch: 1/2, step 298/17983 completed (loss: 3.0994510650634766, acc: 0.39393940567970276)
[2024-10-21 02:46:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:21][root][INFO] - Training Epoch: 1/2, step 299/17983 completed (loss: 1.8726919889450073, acc: 0.6296296119689941)
[2024-10-21 02:46:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:22][root][INFO] - Training Epoch: 1/2, step 300/17983 completed (loss: 3.9453423023223877, acc: 0.20253165066242218)
[2024-10-21 02:46:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:22][root][INFO] - Training Epoch: 1/2, step 301/17983 completed (loss: 3.5116066932678223, acc: 0.2884615361690521)
[2024-10-21 02:46:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:22][root][INFO] - Training Epoch: 1/2, step 302/17983 completed (loss: 3.240452766418457, acc: 0.3333333432674408)
[2024-10-21 02:46:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:23][root][INFO] - Training Epoch: 1/2, step 303/17983 completed (loss: 2.5104386806488037, acc: 0.568965494632721)
[2024-10-21 02:46:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:23][root][INFO] - Training Epoch: 1/2, step 304/17983 completed (loss: 3.744112968444824, acc: 0.32710281014442444)
[2024-10-21 02:46:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:24][root][INFO] - Training Epoch: 1/2, step 305/17983 completed (loss: 3.7910869121551514, acc: 0.3333333432674408)
[2024-10-21 02:46:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:24][root][INFO] - Training Epoch: 1/2, step 306/17983 completed (loss: 2.860775947570801, acc: 0.4166666567325592)
[2024-10-21 02:46:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:25][root][INFO] - Training Epoch: 1/2, step 307/17983 completed (loss: 3.4529898166656494, acc: 0.26923078298568726)
[2024-10-21 02:46:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:25][root][INFO] - Training Epoch: 1/2, step 308/17983 completed (loss: 2.7363393306732178, acc: 0.4107142984867096)
[2024-10-21 02:46:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:26][root][INFO] - Training Epoch: 1/2, step 309/17983 completed (loss: 3.0992350578308105, acc: 0.40506330132484436)
[2024-10-21 02:46:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:26][root][INFO] - Training Epoch: 1/2, step 310/17983 completed (loss: 3.582113027572632, acc: 0.27619048953056335)
[2024-10-21 02:46:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:26][root][INFO] - Training Epoch: 1/2, step 311/17983 completed (loss: 2.7013938426971436, acc: 0.49295774102211)
[2024-10-21 02:46:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:27][root][INFO] - Training Epoch: 1/2, step 312/17983 completed (loss: 3.7512645721435547, acc: 0.3928571343421936)
[2024-10-21 02:46:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:27][root][INFO] - Training Epoch: 1/2, step 313/17983 completed (loss: 3.0425918102264404, acc: 0.3513513505458832)
[2024-10-21 02:46:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:28][root][INFO] - Training Epoch: 1/2, step 314/17983 completed (loss: 3.379441261291504, acc: 0.3047619163990021)
[2024-10-21 02:46:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:28][root][INFO] - Training Epoch: 1/2, step 315/17983 completed (loss: 3.4089879989624023, acc: 0.3295454680919647)
[2024-10-21 02:46:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:29][root][INFO] - Training Epoch: 1/2, step 316/17983 completed (loss: 3.423562526702881, acc: 0.3297872245311737)
[2024-10-21 02:46:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:29][root][INFO] - Training Epoch: 1/2, step 317/17983 completed (loss: 3.416555881500244, acc: 0.4124999940395355)
[2024-10-21 02:46:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:29][root][INFO] - Training Epoch: 1/2, step 318/17983 completed (loss: 2.732956647872925, acc: 0.44594594836235046)
[2024-10-21 02:46:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:30][root][INFO] - Training Epoch: 1/2, step 319/17983 completed (loss: 2.912349224090576, acc: 0.3392857015132904)
[2024-10-21 02:46:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:30][root][INFO] - Training Epoch: 1/2, step 320/17983 completed (loss: 3.4251346588134766, acc: 0.26213592290878296)
[2024-10-21 02:46:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:31][root][INFO] - Training Epoch: 1/2, step 321/17983 completed (loss: 3.613210678100586, acc: 0.32786884903907776)
[2024-10-21 02:46:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:31][root][INFO] - Training Epoch: 1/2, step 322/17983 completed (loss: 3.131270170211792, acc: 0.3614457845687866)
[2024-10-21 02:46:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:31][root][INFO] - Training Epoch: 1/2, step 323/17983 completed (loss: 3.7778079509735107, acc: 0.31168830394744873)
[2024-10-21 02:46:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:32][root][INFO] - Training Epoch: 1/2, step 324/17983 completed (loss: 4.071042537689209, acc: 0.2526315748691559)
[2024-10-21 02:46:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:32][root][INFO] - Training Epoch: 1/2, step 325/17983 completed (loss: 3.5990593433380127, acc: 0.29487180709838867)
[2024-10-21 02:46:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:33][root][INFO] - Training Epoch: 1/2, step 326/17983 completed (loss: 2.579923629760742, acc: 0.35555556416511536)
[2024-10-21 02:46:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:33][root][INFO] - Training Epoch: 1/2, step 327/17983 completed (loss: 3.3261215686798096, acc: 0.3529411852359772)
[2024-10-21 02:46:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:34][root][INFO] - Training Epoch: 1/2, step 328/17983 completed (loss: 2.7437374591827393, acc: 0.4107142984867096)
[2024-10-21 02:46:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:34][root][INFO] - Training Epoch: 1/2, step 329/17983 completed (loss: 3.1248817443847656, acc: 0.29807692766189575)
[2024-10-21 02:46:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:35][root][INFO] - Training Epoch: 1/2, step 330/17983 completed (loss: 2.7135045528411865, acc: 0.40789473056793213)
[2024-10-21 02:46:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:35][root][INFO] - Training Epoch: 1/2, step 331/17983 completed (loss: 3.1349666118621826, acc: 0.40625)
[2024-10-21 02:46:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:35][root][INFO] - Training Epoch: 1/2, step 332/17983 completed (loss: 3.519973039627075, acc: 0.3333333432674408)
[2024-10-21 02:46:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:36][root][INFO] - Training Epoch: 1/2, step 333/17983 completed (loss: 2.555453300476074, acc: 0.4655172526836395)
[2024-10-21 02:46:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:36][root][INFO] - Training Epoch: 1/2, step 334/17983 completed (loss: 2.8968636989593506, acc: 0.359375)
[2024-10-21 02:46:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:37][root][INFO] - Training Epoch: 1/2, step 335/17983 completed (loss: 2.9304916858673096, acc: 0.37078651785850525)
[2024-10-21 02:46:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:37][root][INFO] - Training Epoch: 1/2, step 336/17983 completed (loss: 2.19995379447937, acc: 0.6153846383094788)
[2024-10-21 02:46:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:38][root][INFO] - Training Epoch: 1/2, step 337/17983 completed (loss: 2.871424913406372, acc: 0.410526305437088)
[2024-10-21 02:46:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:38][root][INFO] - Training Epoch: 1/2, step 338/17983 completed (loss: 2.960301637649536, acc: 0.4727272689342499)
[2024-10-21 02:46:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:38][root][INFO] - Training Epoch: 1/2, step 339/17983 completed (loss: 2.833867073059082, acc: 0.4545454680919647)
[2024-10-21 02:46:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:39][root][INFO] - Training Epoch: 1/2, step 340/17983 completed (loss: 3.1886990070343018, acc: 0.336448609828949)
[2024-10-21 02:46:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:39][root][INFO] - Training Epoch: 1/2, step 341/17983 completed (loss: 3.1341207027435303, acc: 0.32926830649375916)
[2024-10-21 02:46:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:40][root][INFO] - Training Epoch: 1/2, step 342/17983 completed (loss: 3.0055932998657227, acc: 0.37735849618911743)
[2024-10-21 02:46:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:40][root][INFO] - Training Epoch: 1/2, step 343/17983 completed (loss: 3.157776117324829, acc: 0.33571428060531616)
[2024-10-21 02:46:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:41][root][INFO] - Training Epoch: 1/2, step 344/17983 completed (loss: 2.5253970623016357, acc: 0.5423728823661804)
[2024-10-21 02:46:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:41][root][INFO] - Training Epoch: 1/2, step 345/17983 completed (loss: 2.727357864379883, acc: 0.41304346919059753)
[2024-10-21 02:46:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:41][root][INFO] - Training Epoch: 1/2, step 346/17983 completed (loss: 2.8073678016662598, acc: 0.38461539149284363)
[2024-10-21 02:46:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:42][root][INFO] - Training Epoch: 1/2, step 347/17983 completed (loss: 2.761472225189209, acc: 0.4000000059604645)
[2024-10-21 02:46:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:42][root][INFO] - Training Epoch: 1/2, step 348/17983 completed (loss: 3.5728325843811035, acc: 0.37931033968925476)
[2024-10-21 02:46:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:43][root][INFO] - Training Epoch: 1/2, step 349/17983 completed (loss: 3.125809669494629, acc: 0.38596490025520325)
[2024-10-21 02:46:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:43][root][INFO] - Training Epoch: 1/2, step 350/17983 completed (loss: 3.1891844272613525, acc: 0.35483869910240173)
[2024-10-21 02:46:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:43][root][INFO] - Training Epoch: 1/2, step 351/17983 completed (loss: 2.872246265411377, acc: 0.3529411852359772)
[2024-10-21 02:46:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:44][root][INFO] - Training Epoch: 1/2, step 352/17983 completed (loss: 3.646371364593506, acc: 0.2210526317358017)
[2024-10-21 02:46:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:44][root][INFO] - Training Epoch: 1/2, step 353/17983 completed (loss: 2.7603442668914795, acc: 0.3932584226131439)
[2024-10-21 02:46:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:45][root][INFO] - Training Epoch: 1/2, step 354/17983 completed (loss: 2.5166449546813965, acc: 0.4647887349128723)
[2024-10-21 02:46:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:45][root][INFO] - Training Epoch: 1/2, step 355/17983 completed (loss: 3.870016574859619, acc: 0.32203391194343567)
[2024-10-21 02:46:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:45][root][INFO] - Training Epoch: 1/2, step 356/17983 completed (loss: 2.6234140396118164, acc: 0.43478259444236755)
[2024-10-21 02:46:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:46][root][INFO] - Training Epoch: 1/2, step 357/17983 completed (loss: 3.387354850769043, acc: 0.3137255012989044)
[2024-10-21 02:46:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:46][root][INFO] - Training Epoch: 1/2, step 358/17983 completed (loss: 3.769510507583618, acc: 0.27272728085517883)
[2024-10-21 02:46:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:47][root][INFO] - Training Epoch: 1/2, step 359/17983 completed (loss: 3.496281385421753, acc: 0.30534350872039795)
[2024-10-21 02:46:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:47][root][INFO] - Training Epoch: 1/2, step 360/17983 completed (loss: 3.117938756942749, acc: 0.3103448152542114)
[2024-10-21 02:46:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:48][root][INFO] - Training Epoch: 1/2, step 361/17983 completed (loss: 4.03333044052124, acc: 0.2063492089509964)
[2024-10-21 02:46:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:48][root][INFO] - Training Epoch: 1/2, step 362/17983 completed (loss: 3.937175989151001, acc: 0.25531914830207825)
[2024-10-21 02:46:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:49][root][INFO] - Training Epoch: 1/2, step 363/17983 completed (loss: 3.1614255905151367, acc: 0.3380281627178192)
[2024-10-21 02:46:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:49][root][INFO] - Training Epoch: 1/2, step 364/17983 completed (loss: 3.1459999084472656, acc: 0.37804877758026123)
[2024-10-21 02:46:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:49][root][INFO] - Training Epoch: 1/2, step 365/17983 completed (loss: 3.1575405597686768, acc: 0.3380281627178192)
[2024-10-21 02:46:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:50][root][INFO] - Training Epoch: 1/2, step 366/17983 completed (loss: 2.9519407749176025, acc: 0.390625)
[2024-10-21 02:46:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:50][root][INFO] - Training Epoch: 1/2, step 367/17983 completed (loss: 3.3512156009674072, acc: 0.3417721390724182)
[2024-10-21 02:46:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:51][root][INFO] - Training Epoch: 1/2, step 368/17983 completed (loss: 2.7949585914611816, acc: 0.3968254029750824)
[2024-10-21 02:46:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:51][root][INFO] - Training Epoch: 1/2, step 369/17983 completed (loss: 3.015313148498535, acc: 0.4000000059604645)
[2024-10-21 02:46:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:52][root][INFO] - Training Epoch: 1/2, step 370/17983 completed (loss: 3.3604438304901123, acc: 0.26595744490623474)
[2024-10-21 02:46:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:52][root][INFO] - Training Epoch: 1/2, step 371/17983 completed (loss: 2.623481512069702, acc: 0.4642857015132904)
[2024-10-21 02:46:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:52][root][INFO] - Training Epoch: 1/2, step 372/17983 completed (loss: 2.919559955596924, acc: 0.36800000071525574)
[2024-10-21 02:46:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:53][root][INFO] - Training Epoch: 1/2, step 373/17983 completed (loss: 3.196160316467285, acc: 0.3195876181125641)
[2024-10-21 02:46:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:53][root][INFO] - Training Epoch: 1/2, step 374/17983 completed (loss: 3.4066660404205322, acc: 0.2916666567325592)
[2024-10-21 02:46:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:54][root][INFO] - Training Epoch: 1/2, step 375/17983 completed (loss: 3.033560037612915, acc: 0.4444444477558136)
[2024-10-21 02:46:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:54][root][INFO] - Training Epoch: 1/2, step 376/17983 completed (loss: 3.858581066131592, acc: 0.290909081697464)
[2024-10-21 02:46:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:54][root][INFO] - Training Epoch: 1/2, step 377/17983 completed (loss: 3.07657790184021, acc: 0.33734938502311707)
[2024-10-21 02:46:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:55][root][INFO] - Training Epoch: 1/2, step 378/17983 completed (loss: 3.531465768814087, acc: 0.30392158031463623)
[2024-10-21 02:46:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:55][root][INFO] - Training Epoch: 1/2, step 379/17983 completed (loss: 3.3565964698791504, acc: 0.2967033088207245)
[2024-10-21 02:46:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:56][root][INFO] - Training Epoch: 1/2, step 380/17983 completed (loss: 3.0973784923553467, acc: 0.3684210479259491)
[2024-10-21 02:46:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:56][root][INFO] - Training Epoch: 1/2, step 381/17983 completed (loss: 3.030712842941284, acc: 0.42105263471603394)
[2024-10-21 02:46:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:57][root][INFO] - Training Epoch: 1/2, step 382/17983 completed (loss: 3.355640411376953, acc: 0.4406779706478119)
[2024-10-21 02:46:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:57][root][INFO] - Training Epoch: 1/2, step 383/17983 completed (loss: 3.262763500213623, acc: 0.3589743673801422)
[2024-10-21 02:46:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:57][root][INFO] - Training Epoch: 1/2, step 384/17983 completed (loss: 3.1746068000793457, acc: 0.33707866072654724)
[2024-10-21 02:46:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:58][root][INFO] - Training Epoch: 1/2, step 385/17983 completed (loss: 3.12532114982605, acc: 0.41860464215278625)
[2024-10-21 02:46:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:58][root][INFO] - Training Epoch: 1/2, step 386/17983 completed (loss: 2.6080338954925537, acc: 0.4690265357494354)
[2024-10-21 02:46:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:59][root][INFO] - Training Epoch: 1/2, step 387/17983 completed (loss: 3.692988872528076, acc: 0.30645161867141724)
[2024-10-21 02:46:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:46:59][root][INFO] - Training Epoch: 1/2, step 388/17983 completed (loss: 3.310823440551758, acc: 0.28947368264198303)
[2024-10-21 02:46:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:00][root][INFO] - Training Epoch: 1/2, step 389/17983 completed (loss: 2.911972761154175, acc: 0.30434781312942505)
[2024-10-21 02:47:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:00][root][INFO] - Training Epoch: 1/2, step 390/17983 completed (loss: 2.8000314235687256, acc: 0.375)
[2024-10-21 02:47:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:01][root][INFO] - Training Epoch: 1/2, step 391/17983 completed (loss: 3.335782289505005, acc: 0.43283581733703613)
[2024-10-21 02:47:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:01][root][INFO] - Training Epoch: 1/2, step 392/17983 completed (loss: 3.478832244873047, acc: 0.35555556416511536)
[2024-10-21 02:47:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:02][root][INFO] - Training Epoch: 1/2, step 393/17983 completed (loss: 3.25093412399292, acc: 0.343137264251709)
[2024-10-21 02:47:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:02][root][INFO] - Training Epoch: 1/2, step 394/17983 completed (loss: 2.7496931552886963, acc: 0.3777777850627899)
[2024-10-21 02:47:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:03][root][INFO] - Training Epoch: 1/2, step 395/17983 completed (loss: 3.3330414295196533, acc: 0.3484848439693451)
[2024-10-21 02:47:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:03][root][INFO] - Training Epoch: 1/2, step 396/17983 completed (loss: 3.0904526710510254, acc: 0.3614457845687866)
[2024-10-21 02:47:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:04][root][INFO] - Training Epoch: 1/2, step 397/17983 completed (loss: 3.2446320056915283, acc: 0.2666666805744171)
[2024-10-21 02:47:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:04][root][INFO] - Training Epoch: 1/2, step 398/17983 completed (loss: 3.0841686725616455, acc: 0.38823530077934265)
[2024-10-21 02:47:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:05][root][INFO] - Training Epoch: 1/2, step 399/17983 completed (loss: 2.9016599655151367, acc: 0.40909090638160706)
[2024-10-21 02:47:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:05][root][INFO] - Training Epoch: 1/2, step 400/17983 completed (loss: 3.0765976905822754, acc: 0.40697672963142395)
[2024-10-21 02:47:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:06][root][INFO] - Training Epoch: 1/2, step 401/17983 completed (loss: 3.4072704315185547, acc: 0.3461538553237915)
[2024-10-21 02:47:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:06][root][INFO] - Training Epoch: 1/2, step 402/17983 completed (loss: 3.4509363174438477, acc: 0.3636363744735718)
[2024-10-21 02:47:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:06][root][INFO] - Training Epoch: 1/2, step 403/17983 completed (loss: 2.782456636428833, acc: 0.5)
[2024-10-21 02:47:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:07][root][INFO] - Training Epoch: 1/2, step 404/17983 completed (loss: 3.22468900680542, acc: 0.30188679695129395)
[2024-10-21 02:47:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:07][root][INFO] - Training Epoch: 1/2, step 405/17983 completed (loss: 3.4968132972717285, acc: 0.31578946113586426)
[2024-10-21 02:47:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:08][root][INFO] - Training Epoch: 1/2, step 406/17983 completed (loss: 3.243134021759033, acc: 0.36752137541770935)
[2024-10-21 02:47:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:08][root][INFO] - Training Epoch: 1/2, step 407/17983 completed (loss: 3.2219858169555664, acc: 0.2857142984867096)
[2024-10-21 02:47:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:08][root][INFO] - Training Epoch: 1/2, step 408/17983 completed (loss: 3.060880422592163, acc: 0.3820224702358246)
[2024-10-21 02:47:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:09][root][INFO] - Training Epoch: 1/2, step 409/17983 completed (loss: 3.6564393043518066, acc: 0.2616822421550751)
[2024-10-21 02:47:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:09][root][INFO] - Training Epoch: 1/2, step 410/17983 completed (loss: 3.672241449356079, acc: 0.3333333432674408)
[2024-10-21 02:47:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:10][root][INFO] - Training Epoch: 1/2, step 411/17983 completed (loss: 2.6554839611053467, acc: 0.4571428596973419)
[2024-10-21 02:47:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:10][root][INFO] - Training Epoch: 1/2, step 412/17983 completed (loss: 2.7419066429138184, acc: 0.4285714328289032)
[2024-10-21 02:47:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:10][root][INFO] - Training Epoch: 1/2, step 413/17983 completed (loss: 3.0621345043182373, acc: 0.42105263471603394)
[2024-10-21 02:47:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:11][root][INFO] - Training Epoch: 1/2, step 414/17983 completed (loss: 3.2926294803619385, acc: 0.34328359365463257)
[2024-10-21 02:47:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:11][root][INFO] - Training Epoch: 1/2, step 415/17983 completed (loss: 2.960256338119507, acc: 0.3529411852359772)
[2024-10-21 02:47:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:12][root][INFO] - Training Epoch: 1/2, step 416/17983 completed (loss: 2.9450509548187256, acc: 0.3529411852359772)
[2024-10-21 02:47:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:12][root][INFO] - Training Epoch: 1/2, step 417/17983 completed (loss: 2.8740994930267334, acc: 0.4677419364452362)
[2024-10-21 02:47:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:13][root][INFO] - Training Epoch: 1/2, step 418/17983 completed (loss: 2.301654815673828, acc: 0.5365853905677795)
[2024-10-21 02:47:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:13][root][INFO] - Training Epoch: 1/2, step 419/17983 completed (loss: 3.2067904472351074, acc: 0.3333333432674408)
[2024-10-21 02:47:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:13][root][INFO] - Training Epoch: 1/2, step 420/17983 completed (loss: 3.182206630706787, acc: 0.3461538553237915)
[2024-10-21 02:47:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:14][root][INFO] - Training Epoch: 1/2, step 421/17983 completed (loss: 2.034410238265991, acc: 0.5438596606254578)
[2024-10-21 02:47:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:14][root][INFO] - Training Epoch: 1/2, step 422/17983 completed (loss: 3.0924148559570312, acc: 0.3546099364757538)
[2024-10-21 02:47:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:15][root][INFO] - Training Epoch: 1/2, step 423/17983 completed (loss: 3.478091239929199, acc: 0.34285715222358704)
[2024-10-21 02:47:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:15][root][INFO] - Training Epoch: 1/2, step 424/17983 completed (loss: 2.801241874694824, acc: 0.4430379867553711)
[2024-10-21 02:47:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:16][root][INFO] - Training Epoch: 1/2, step 425/17983 completed (loss: 3.478451728820801, acc: 0.3359375)
[2024-10-21 02:47:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:16][root][INFO] - Training Epoch: 1/2, step 426/17983 completed (loss: 2.899111747741699, acc: 0.44736841320991516)
[2024-10-21 02:47:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:17][root][INFO] - Training Epoch: 1/2, step 427/17983 completed (loss: 3.076314926147461, acc: 0.42105263471603394)
[2024-10-21 02:47:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:17][root][INFO] - Training Epoch: 1/2, step 428/17983 completed (loss: 2.7676641941070557, acc: 0.3595505654811859)
[2024-10-21 02:47:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:17][root][INFO] - Training Epoch: 1/2, step 429/17983 completed (loss: 3.0780162811279297, acc: 0.3400000035762787)
[2024-10-21 02:47:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:18][root][INFO] - Training Epoch: 1/2, step 430/17983 completed (loss: 3.6907663345336914, acc: 0.30000001192092896)
[2024-10-21 02:47:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:18][root][INFO] - Training Epoch: 1/2, step 431/17983 completed (loss: 3.665302038192749, acc: 0.24806201457977295)
[2024-10-21 02:47:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:19][root][INFO] - Training Epoch: 1/2, step 432/17983 completed (loss: 3.806485652923584, acc: 0.21794871985912323)
[2024-10-21 02:47:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:19][root][INFO] - Training Epoch: 1/2, step 433/17983 completed (loss: 3.2045814990997314, acc: 0.32894736528396606)
[2024-10-21 02:47:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:19][root][INFO] - Training Epoch: 1/2, step 434/17983 completed (loss: 2.679548978805542, acc: 0.39240506291389465)
[2024-10-21 02:47:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:20][root][INFO] - Training Epoch: 1/2, step 435/17983 completed (loss: 2.963142156600952, acc: 0.4137931168079376)
[2024-10-21 02:47:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:20][root][INFO] - Training Epoch: 1/2, step 436/17983 completed (loss: 2.7321531772613525, acc: 0.4883720874786377)
[2024-10-21 02:47:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:21][root][INFO] - Training Epoch: 1/2, step 437/17983 completed (loss: 3.5990614891052246, acc: 0.2666666805744171)
[2024-10-21 02:47:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:21][root][INFO] - Training Epoch: 1/2, step 438/17983 completed (loss: 2.486799955368042, acc: 0.3962264060974121)
[2024-10-21 02:47:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:22][root][INFO] - Training Epoch: 1/2, step 439/17983 completed (loss: 2.2717058658599854, acc: 0.47297295928001404)
[2024-10-21 02:47:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:22][root][INFO] - Training Epoch: 1/2, step 440/17983 completed (loss: 2.035337448120117, acc: 0.5681818127632141)
[2024-10-21 02:47:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:22][root][INFO] - Training Epoch: 1/2, step 441/17983 completed (loss: 3.018404483795166, acc: 0.33898305892944336)
[2024-10-21 02:47:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:23][root][INFO] - Training Epoch: 1/2, step 442/17983 completed (loss: 3.2209982872009277, acc: 0.3636363744735718)
[2024-10-21 02:47:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:23][root][INFO] - Training Epoch: 1/2, step 443/17983 completed (loss: 3.4553332328796387, acc: 0.32692307233810425)
[2024-10-21 02:47:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:24][root][INFO] - Training Epoch: 1/2, step 444/17983 completed (loss: 3.218797445297241, acc: 0.3181818127632141)
[2024-10-21 02:47:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:24][root][INFO] - Training Epoch: 1/2, step 445/17983 completed (loss: 3.440375804901123, acc: 0.31578946113586426)
[2024-10-21 02:47:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:25][root][INFO] - Training Epoch: 1/2, step 446/17983 completed (loss: 3.675797939300537, acc: 0.32258063554763794)
[2024-10-21 02:47:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:25][root][INFO] - Training Epoch: 1/2, step 447/17983 completed (loss: 2.738492965698242, acc: 0.4528301954269409)
[2024-10-21 02:47:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:25][root][INFO] - Training Epoch: 1/2, step 448/17983 completed (loss: 3.7823486328125, acc: 0.3448275923728943)
[2024-10-21 02:47:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:26][root][INFO] - Training Epoch: 1/2, step 449/17983 completed (loss: 2.89892840385437, acc: 0.4444444477558136)
[2024-10-21 02:47:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:26][root][INFO] - Training Epoch: 1/2, step 450/17983 completed (loss: 2.657390594482422, acc: 0.5)
[2024-10-21 02:47:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:27][root][INFO] - Training Epoch: 1/2, step 451/17983 completed (loss: 3.3054301738739014, acc: 0.39080458879470825)
[2024-10-21 02:47:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:27][root][INFO] - Training Epoch: 1/2, step 452/17983 completed (loss: 3.809145212173462, acc: 0.2584269642829895)
[2024-10-21 02:47:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:28][root][INFO] - Training Epoch: 1/2, step 453/17983 completed (loss: 2.9665915966033936, acc: 0.4324324429035187)
[2024-10-21 02:47:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:28][root][INFO] - Training Epoch: 1/2, step 454/17983 completed (loss: 3.359912395477295, acc: 0.37837839126586914)
[2024-10-21 02:47:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:28][root][INFO] - Training Epoch: 1/2, step 455/17983 completed (loss: 2.969374418258667, acc: 0.3968254029750824)
[2024-10-21 02:47:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:29][root][INFO] - Training Epoch: 1/2, step 456/17983 completed (loss: 2.7693958282470703, acc: 0.4270833432674408)
[2024-10-21 02:47:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:29][root][INFO] - Training Epoch: 1/2, step 457/17983 completed (loss: 3.436561346054077, acc: 0.30909091234207153)
[2024-10-21 02:47:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:30][root][INFO] - Training Epoch: 1/2, step 458/17983 completed (loss: 3.8099896907806396, acc: 0.27173912525177)
[2024-10-21 02:47:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:30][root][INFO] - Training Epoch: 1/2, step 459/17983 completed (loss: 2.5060768127441406, acc: 0.4642857015132904)
[2024-10-21 02:47:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:31][root][INFO] - Training Epoch: 1/2, step 460/17983 completed (loss: 3.069528579711914, acc: 0.39436620473861694)
[2024-10-21 02:47:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:31][root][INFO] - Training Epoch: 1/2, step 461/17983 completed (loss: 3.315868854522705, acc: 0.3466666638851166)
[2024-10-21 02:47:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:32][root][INFO] - Training Epoch: 1/2, step 462/17983 completed (loss: 2.8977596759796143, acc: 0.4285714328289032)
[2024-10-21 02:47:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:32][root][INFO] - Training Epoch: 1/2, step 463/17983 completed (loss: 3.2809746265411377, acc: 0.3731343150138855)
[2024-10-21 02:47:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:32][root][INFO] - Training Epoch: 1/2, step 464/17983 completed (loss: 2.8396224975585938, acc: 0.4153846204280853)
[2024-10-21 02:47:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:33][root][INFO] - Training Epoch: 1/2, step 465/17983 completed (loss: 3.1050949096679688, acc: 0.3855421543121338)
[2024-10-21 02:47:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:33][root][INFO] - Training Epoch: 1/2, step 466/17983 completed (loss: 2.872037649154663, acc: 0.4166666567325592)
[2024-10-21 02:47:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:33][root][INFO] - Training Epoch: 1/2, step 467/17983 completed (loss: 2.965186834335327, acc: 0.3855421543121338)
[2024-10-21 02:47:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:34][root][INFO] - Training Epoch: 1/2, step 468/17983 completed (loss: 3.1848442554473877, acc: 0.390625)
[2024-10-21 02:47:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:34][root][INFO] - Training Epoch: 1/2, step 469/17983 completed (loss: 3.084219217300415, acc: 0.3035714328289032)
[2024-10-21 02:47:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:35][root][INFO] - Training Epoch: 1/2, step 470/17983 completed (loss: 3.2960989475250244, acc: 0.3777777850627899)
[2024-10-21 02:47:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:35][root][INFO] - Training Epoch: 1/2, step 471/17983 completed (loss: 3.10117769241333, acc: 0.3483146131038666)
[2024-10-21 02:47:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:35][root][INFO] - Training Epoch: 1/2, step 472/17983 completed (loss: 2.809955358505249, acc: 0.4864864945411682)
[2024-10-21 02:47:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:36][root][INFO] - Training Epoch: 1/2, step 473/17983 completed (loss: 3.425184726715088, acc: 0.3452380895614624)
[2024-10-21 02:47:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:36][root][INFO] - Training Epoch: 1/2, step 474/17983 completed (loss: 2.691939115524292, acc: 0.4423076808452606)
[2024-10-21 02:47:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:37][root][INFO] - Training Epoch: 1/2, step 475/17983 completed (loss: 3.2978107929229736, acc: 0.375)
[2024-10-21 02:47:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:37][root][INFO] - Training Epoch: 1/2, step 476/17983 completed (loss: 2.9671740531921387, acc: 0.375)
[2024-10-21 02:47:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:38][root][INFO] - Training Epoch: 1/2, step 477/17983 completed (loss: 2.293043613433838, acc: 0.4941176474094391)
[2024-10-21 02:47:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:38][root][INFO] - Training Epoch: 1/2, step 478/17983 completed (loss: 3.1868879795074463, acc: 0.328125)
[2024-10-21 02:47:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:39][root][INFO] - Training Epoch: 1/2, step 479/17983 completed (loss: 3.2121059894561768, acc: 0.3571428656578064)
[2024-10-21 02:47:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:39][root][INFO] - Training Epoch: 1/2, step 480/17983 completed (loss: 2.859689235687256, acc: 0.3333333432674408)
[2024-10-21 02:47:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:39][root][INFO] - Training Epoch: 1/2, step 481/17983 completed (loss: 3.869129180908203, acc: 0.3085106313228607)
[2024-10-21 02:47:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:40][root][INFO] - Training Epoch: 1/2, step 482/17983 completed (loss: 2.0190343856811523, acc: 0.604651153087616)
[2024-10-21 02:47:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:40][root][INFO] - Training Epoch: 1/2, step 483/17983 completed (loss: 2.115487575531006, acc: 0.5333333611488342)
[2024-10-21 02:47:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:41][root][INFO] - Training Epoch: 1/2, step 484/17983 completed (loss: 2.2152321338653564, acc: 0.4736842215061188)
[2024-10-21 02:47:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:41][root][INFO] - Training Epoch: 1/2, step 485/17983 completed (loss: 2.0376479625701904, acc: 0.5806451439857483)
[2024-10-21 02:47:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:42][root][INFO] - Training Epoch: 1/2, step 486/17983 completed (loss: 2.9381918907165527, acc: 0.4590163826942444)
[2024-10-21 02:47:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:42][root][INFO] - Training Epoch: 1/2, step 487/17983 completed (loss: 3.103977918624878, acc: 0.3970588147640228)
[2024-10-21 02:47:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:42][root][INFO] - Training Epoch: 1/2, step 488/17983 completed (loss: 2.8317832946777344, acc: 0.46666666865348816)
[2024-10-21 02:47:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:43][root][INFO] - Training Epoch: 1/2, step 489/17983 completed (loss: 3.111009120941162, acc: 0.359649121761322)
[2024-10-21 02:47:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:43][root][INFO] - Training Epoch: 1/2, step 490/17983 completed (loss: 3.915081024169922, acc: 0.1805555522441864)
[2024-10-21 02:47:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:44][root][INFO] - Training Epoch: 1/2, step 491/17983 completed (loss: 3.3587517738342285, acc: 0.35483869910240173)
[2024-10-21 02:47:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:44][root][INFO] - Training Epoch: 1/2, step 492/17983 completed (loss: 2.9581902027130127, acc: 0.36000001430511475)
[2024-10-21 02:47:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:44][root][INFO] - Training Epoch: 1/2, step 493/17983 completed (loss: 2.7332327365875244, acc: 0.39743590354919434)
[2024-10-21 02:47:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:45][root][INFO] - Training Epoch: 1/2, step 494/17983 completed (loss: 2.7247564792633057, acc: 0.4313725531101227)
[2024-10-21 02:47:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:45][root][INFO] - Training Epoch: 1/2, step 495/17983 completed (loss: 3.566061496734619, acc: 0.29629629850387573)
[2024-10-21 02:47:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:46][root][INFO] - Training Epoch: 1/2, step 496/17983 completed (loss: 3.4455044269561768, acc: 0.3499999940395355)
[2024-10-21 02:47:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:46][root][INFO] - Training Epoch: 1/2, step 497/17983 completed (loss: 2.6485323905944824, acc: 0.5128205418586731)
[2024-10-21 02:47:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:47][root][INFO] - Training Epoch: 1/2, step 498/17983 completed (loss: 3.442305564880371, acc: 0.3291139304637909)
[2024-10-21 02:47:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:47][root][INFO] - Training Epoch: 1/2, step 499/17983 completed (loss: 3.4815497398376465, acc: 0.3333333432674408)
[2024-10-21 02:47:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:48][root][INFO] - Training Epoch: 1/2, step 500/17983 completed (loss: 2.7939586639404297, acc: 0.4318181872367859)
[2024-10-21 02:47:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:48][root][INFO] - Training Epoch: 1/2, step 501/17983 completed (loss: 3.646777629852295, acc: 0.3113207519054413)
[2024-10-21 02:47:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:49][root][INFO] - Training Epoch: 1/2, step 502/17983 completed (loss: 3.29756236076355, acc: 0.3488371968269348)
[2024-10-21 02:47:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:49][root][INFO] - Training Epoch: 1/2, step 503/17983 completed (loss: 3.1817567348480225, acc: 0.40740740299224854)
[2024-10-21 02:47:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:50][root][INFO] - Training Epoch: 1/2, step 504/17983 completed (loss: 3.2661216259002686, acc: 0.33707866072654724)
[2024-10-21 02:47:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:50][root][INFO] - Training Epoch: 1/2, step 505/17983 completed (loss: 3.4841408729553223, acc: 0.3505154550075531)
[2024-10-21 02:47:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:50][root][INFO] - Training Epoch: 1/2, step 506/17983 completed (loss: 3.358952522277832, acc: 0.3132530152797699)
[2024-10-21 02:47:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:51][root][INFO] - Training Epoch: 1/2, step 507/17983 completed (loss: 2.924516439437866, acc: 0.39344263076782227)
[2024-10-21 02:47:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:51][root][INFO] - Training Epoch: 1/2, step 508/17983 completed (loss: 3.0858700275421143, acc: 0.3835616409778595)
[2024-10-21 02:47:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:52][root][INFO] - Training Epoch: 1/2, step 509/17983 completed (loss: 3.218971014022827, acc: 0.4642857015132904)
[2024-10-21 02:47:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:52][root][INFO] - Training Epoch: 1/2, step 510/17983 completed (loss: 2.93096923828125, acc: 0.48275861144065857)
[2024-10-21 02:47:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:52][root][INFO] - Training Epoch: 1/2, step 511/17983 completed (loss: 3.0180673599243164, acc: 0.37142857909202576)
[2024-10-21 02:47:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:53][root][INFO] - Training Epoch: 1/2, step 512/17983 completed (loss: 2.789031744003296, acc: 0.4383561611175537)
[2024-10-21 02:47:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:53][root][INFO] - Training Epoch: 1/2, step 513/17983 completed (loss: 2.9705941677093506, acc: 0.4693877696990967)
[2024-10-21 02:47:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:54][root][INFO] - Training Epoch: 1/2, step 514/17983 completed (loss: 3.600569009780884, acc: 0.3461538553237915)
[2024-10-21 02:47:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:54][root][INFO] - Training Epoch: 1/2, step 515/17983 completed (loss: 2.776721954345703, acc: 0.4912280738353729)
[2024-10-21 02:47:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:55][root][INFO] - Training Epoch: 1/2, step 516/17983 completed (loss: 2.533071994781494, acc: 0.4464285671710968)
[2024-10-21 02:47:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:55][root][INFO] - Training Epoch: 1/2, step 517/17983 completed (loss: 2.6489415168762207, acc: 0.4367816150188446)
[2024-10-21 02:47:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:55][root][INFO] - Training Epoch: 1/2, step 518/17983 completed (loss: 3.216477632522583, acc: 0.35789474844932556)
[2024-10-21 02:47:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:56][root][INFO] - Training Epoch: 1/2, step 519/17983 completed (loss: 3.072139263153076, acc: 0.4166666567325592)
[2024-10-21 02:47:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:56][root][INFO] - Training Epoch: 1/2, step 520/17983 completed (loss: 3.227315664291382, acc: 0.35849055647850037)
[2024-10-21 02:47:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:57][root][INFO] - Training Epoch: 1/2, step 521/17983 completed (loss: 2.9174883365631104, acc: 0.4038461446762085)
[2024-10-21 02:47:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:57][root][INFO] - Training Epoch: 1/2, step 522/17983 completed (loss: 3.2290186882019043, acc: 0.3382352888584137)
[2024-10-21 02:47:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:57][root][INFO] - Training Epoch: 1/2, step 523/17983 completed (loss: 3.386037588119507, acc: 0.2777777910232544)
[2024-10-21 02:47:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:58][root][INFO] - Training Epoch: 1/2, step 524/17983 completed (loss: 2.6349337100982666, acc: 0.4615384638309479)
[2024-10-21 02:47:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:58][root][INFO] - Training Epoch: 1/2, step 525/17983 completed (loss: 2.9759068489074707, acc: 0.38596490025520325)
[2024-10-21 02:47:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:59][root][INFO] - Training Epoch: 1/2, step 526/17983 completed (loss: 3.6039958000183105, acc: 0.3235294222831726)
[2024-10-21 02:47:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:47:59][root][INFO] - Training Epoch: 1/2, step 527/17983 completed (loss: 3.3362772464752197, acc: 0.34020617604255676)
[2024-10-21 02:47:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:00][root][INFO] - Training Epoch: 1/2, step 528/17983 completed (loss: 3.9602625370025635, acc: 0.31343284249305725)
[2024-10-21 02:48:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:00][root][INFO] - Training Epoch: 1/2, step 529/17983 completed (loss: 3.4215281009674072, acc: 0.2844827473163605)
[2024-10-21 02:48:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:01][root][INFO] - Training Epoch: 1/2, step 530/17983 completed (loss: 2.441462755203247, acc: 0.5263158082962036)
[2024-10-21 02:48:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:01][root][INFO] - Training Epoch: 1/2, step 531/17983 completed (loss: 3.6273305416107178, acc: 0.3392857015132904)
[2024-10-21 02:48:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:02][root][INFO] - Training Epoch: 1/2, step 532/17983 completed (loss: 2.2258124351501465, acc: 0.5098039507865906)
[2024-10-21 02:48:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:02][root][INFO] - Training Epoch: 1/2, step 533/17983 completed (loss: 3.0217857360839844, acc: 0.39823007583618164)
[2024-10-21 02:48:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:02][root][INFO] - Training Epoch: 1/2, step 534/17983 completed (loss: 1.899588942527771, acc: 0.5)
[2024-10-21 02:48:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:03][root][INFO] - Training Epoch: 1/2, step 535/17983 completed (loss: 2.611163377761841, acc: 0.4571428596973419)
[2024-10-21 02:48:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:03][root][INFO] - Training Epoch: 1/2, step 536/17983 completed (loss: 2.6964051723480225, acc: 0.36666667461395264)
[2024-10-21 02:48:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:04][root][INFO] - Training Epoch: 1/2, step 537/17983 completed (loss: 2.8385884761810303, acc: 0.4444444477558136)
[2024-10-21 02:48:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:04][root][INFO] - Training Epoch: 1/2, step 538/17983 completed (loss: 2.552962303161621, acc: 0.5066666603088379)
[2024-10-21 02:48:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:04][root][INFO] - Training Epoch: 1/2, step 539/17983 completed (loss: 3.8864543437957764, acc: 0.3125)
[2024-10-21 02:48:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:05][root][INFO] - Training Epoch: 1/2, step 540/17983 completed (loss: 2.9995734691619873, acc: 0.38235294818878174)
[2024-10-21 02:48:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:05][root][INFO] - Training Epoch: 1/2, step 541/17983 completed (loss: 3.260289192199707, acc: 0.364705890417099)
[2024-10-21 02:48:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:06][root][INFO] - Training Epoch: 1/2, step 542/17983 completed (loss: 3.749826431274414, acc: 0.380952388048172)
[2024-10-21 02:48:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:06][root][INFO] - Training Epoch: 1/2, step 543/17983 completed (loss: 3.161721706390381, acc: 0.34090909361839294)
[2024-10-21 02:48:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:07][root][INFO] - Training Epoch: 1/2, step 544/17983 completed (loss: 2.7243428230285645, acc: 0.4615384638309479)
[2024-10-21 02:48:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:07][root][INFO] - Training Epoch: 1/2, step 545/17983 completed (loss: 2.8898308277130127, acc: 0.3947368562221527)
[2024-10-21 02:48:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:07][root][INFO] - Training Epoch: 1/2, step 546/17983 completed (loss: 2.6649725437164307, acc: 0.46875)
[2024-10-21 02:48:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:08][root][INFO] - Training Epoch: 1/2, step 547/17983 completed (loss: 2.8802506923675537, acc: 0.31111112236976624)
[2024-10-21 02:48:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:08][root][INFO] - Training Epoch: 1/2, step 548/17983 completed (loss: 3.6300346851348877, acc: 0.313043475151062)
[2024-10-21 02:48:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:09][root][INFO] - Training Epoch: 1/2, step 549/17983 completed (loss: 3.1220970153808594, acc: 0.3932584226131439)
[2024-10-21 02:48:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:09][root][INFO] - Training Epoch: 1/2, step 550/17983 completed (loss: 3.302241325378418, acc: 0.3499999940395355)
[2024-10-21 02:48:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:10][root][INFO] - Training Epoch: 1/2, step 551/17983 completed (loss: 2.507197856903076, acc: 0.40697672963142395)
[2024-10-21 02:48:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:10][root][INFO] - Training Epoch: 1/2, step 552/17983 completed (loss: 2.6820592880249023, acc: 0.40566039085388184)
[2024-10-21 02:48:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:10][root][INFO] - Training Epoch: 1/2, step 553/17983 completed (loss: 3.324270486831665, acc: 0.3684210479259491)
[2024-10-21 02:48:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:11][root][INFO] - Training Epoch: 1/2, step 554/17983 completed (loss: 3.224179744720459, acc: 0.35576921701431274)
[2024-10-21 02:48:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:11][root][INFO] - Training Epoch: 1/2, step 555/17983 completed (loss: 2.857057809829712, acc: 0.3253012001514435)
[2024-10-21 02:48:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:12][root][INFO] - Training Epoch: 1/2, step 556/17983 completed (loss: 2.926571846008301, acc: 0.5454545617103577)
[2024-10-21 02:48:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:12][root][INFO] - Training Epoch: 1/2, step 557/17983 completed (loss: 3.3107268810272217, acc: 0.34285715222358704)
[2024-10-21 02:48:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:12][root][INFO] - Training Epoch: 1/2, step 558/17983 completed (loss: 3.1365795135498047, acc: 0.40449437499046326)
[2024-10-21 02:48:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:13][root][INFO] - Training Epoch: 1/2, step 559/17983 completed (loss: 2.957036018371582, acc: 0.4363636374473572)
[2024-10-21 02:48:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:13][root][INFO] - Training Epoch: 1/2, step 560/17983 completed (loss: 3.5008723735809326, acc: 0.29411765933036804)
[2024-10-21 02:48:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:14][root][INFO] - Training Epoch: 1/2, step 561/17983 completed (loss: 2.294184446334839, acc: 0.5324675440788269)
[2024-10-21 02:48:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:14][root][INFO] - Training Epoch: 1/2, step 562/17983 completed (loss: 3.8072614669799805, acc: 0.25757575035095215)
[2024-10-21 02:48:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:14][root][INFO] - Training Epoch: 1/2, step 563/17983 completed (loss: 3.18476939201355, acc: 0.375)
[2024-10-21 02:48:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:15][root][INFO] - Training Epoch: 1/2, step 564/17983 completed (loss: 3.034475803375244, acc: 0.460317462682724)
[2024-10-21 02:48:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:15][root][INFO] - Training Epoch: 1/2, step 565/17983 completed (loss: 3.703632116317749, acc: 0.3076923191547394)
[2024-10-21 02:48:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:15][root][INFO] - Training Epoch: 1/2, step 566/17983 completed (loss: 2.88572359085083, acc: 0.4396551847457886)
[2024-10-21 02:48:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:16][root][INFO] - Training Epoch: 1/2, step 567/17983 completed (loss: 3.0520803928375244, acc: 0.3142857253551483)
[2024-10-21 02:48:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:16][root][INFO] - Training Epoch: 1/2, step 568/17983 completed (loss: 3.2582273483276367, acc: 0.35593220591545105)
[2024-10-21 02:48:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:17][root][INFO] - Training Epoch: 1/2, step 569/17983 completed (loss: 2.8559272289276123, acc: 0.3142857253551483)
[2024-10-21 02:48:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:17][root][INFO] - Training Epoch: 1/2, step 570/17983 completed (loss: 2.806504487991333, acc: 0.4000000059604645)
[2024-10-21 02:48:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:17][root][INFO] - Training Epoch: 1/2, step 571/17983 completed (loss: 3.441345691680908, acc: 0.4035087823867798)
[2024-10-21 02:48:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:18][root][INFO] - Training Epoch: 1/2, step 572/17983 completed (loss: 3.752081871032715, acc: 0.36666667461395264)
[2024-10-21 02:48:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:18][root][INFO] - Training Epoch: 1/2, step 573/17983 completed (loss: 3.4902687072753906, acc: 0.36734694242477417)
[2024-10-21 02:48:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:19][root][INFO] - Training Epoch: 1/2, step 574/17983 completed (loss: 2.9494311809539795, acc: 0.3815789520740509)
[2024-10-21 02:48:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:19][root][INFO] - Training Epoch: 1/2, step 575/17983 completed (loss: 3.354145050048828, acc: 0.375)
[2024-10-21 02:48:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:20][root][INFO] - Training Epoch: 1/2, step 576/17983 completed (loss: 3.204834222793579, acc: 0.43661972880363464)
[2024-10-21 02:48:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:20][root][INFO] - Training Epoch: 1/2, step 577/17983 completed (loss: 3.5411219596862793, acc: 0.3717948794364929)
[2024-10-21 02:48:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:20][root][INFO] - Training Epoch: 1/2, step 578/17983 completed (loss: 2.552478075027466, acc: 0.3636363744735718)
[2024-10-21 02:48:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:21][root][INFO] - Training Epoch: 1/2, step 579/17983 completed (loss: 2.9194273948669434, acc: 0.34090909361839294)
[2024-10-21 02:48:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:21][root][INFO] - Training Epoch: 1/2, step 580/17983 completed (loss: 3.121980667114258, acc: 0.410526305437088)
[2024-10-21 02:48:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:22][root][INFO] - Training Epoch: 1/2, step 581/17983 completed (loss: 3.0002682209014893, acc: 0.35652172565460205)
[2024-10-21 02:48:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:22][root][INFO] - Training Epoch: 1/2, step 582/17983 completed (loss: 3.290945291519165, acc: 0.3205128312110901)
[2024-10-21 02:48:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:23][root][INFO] - Training Epoch: 1/2, step 583/17983 completed (loss: 3.271911382675171, acc: 0.3499999940395355)
[2024-10-21 02:48:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:23][root][INFO] - Training Epoch: 1/2, step 584/17983 completed (loss: 3.492854595184326, acc: 0.32499998807907104)
[2024-10-21 02:48:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:23][root][INFO] - Training Epoch: 1/2, step 585/17983 completed (loss: 3.114448070526123, acc: 0.40594059228897095)
[2024-10-21 02:48:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:24][root][INFO] - Training Epoch: 1/2, step 586/17983 completed (loss: 3.0294947624206543, acc: 0.38461539149284363)
[2024-10-21 02:48:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:24][root][INFO] - Training Epoch: 1/2, step 587/17983 completed (loss: 2.8604321479797363, acc: 0.5178571343421936)
[2024-10-21 02:48:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:25][root][INFO] - Training Epoch: 1/2, step 588/17983 completed (loss: 2.118483781814575, acc: 0.568965494632721)
[2024-10-21 02:48:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:25][root][INFO] - Training Epoch: 1/2, step 589/17983 completed (loss: 2.6400387287139893, acc: 0.49253731966018677)
[2024-10-21 02:48:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:25][root][INFO] - Training Epoch: 1/2, step 590/17983 completed (loss: 2.4196245670318604, acc: 0.508474588394165)
[2024-10-21 02:48:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:26][root][INFO] - Training Epoch: 1/2, step 591/17983 completed (loss: 3.56327748298645, acc: 0.3255814015865326)
[2024-10-21 02:48:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:26][root][INFO] - Training Epoch: 1/2, step 592/17983 completed (loss: 3.2340569496154785, acc: 0.3333333432674408)
[2024-10-21 02:48:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:26][root][INFO] - Training Epoch: 1/2, step 593/17983 completed (loss: 1.9775539636611938, acc: 0.5098039507865906)
[2024-10-21 02:48:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:27][root][INFO] - Training Epoch: 1/2, step 594/17983 completed (loss: 3.285703182220459, acc: 0.3214285671710968)
[2024-10-21 02:48:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:27][root][INFO] - Training Epoch: 1/2, step 595/17983 completed (loss: 0.8504073619842529, acc: 0.7916666865348816)
[2024-10-21 02:48:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:27][root][INFO] - Training Epoch: 1/2, step 596/17983 completed (loss: 2.9942104816436768, acc: 0.4285714328289032)
[2024-10-21 02:48:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:28][root][INFO] - Training Epoch: 1/2, step 597/17983 completed (loss: 3.408968448638916, acc: 0.3243243098258972)
[2024-10-21 02:48:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:28][root][INFO] - Training Epoch: 1/2, step 598/17983 completed (loss: 3.1048262119293213, acc: 0.43939393758773804)
[2024-10-21 02:48:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:29][root][INFO] - Training Epoch: 1/2, step 599/17983 completed (loss: 3.196115493774414, acc: 0.36231884360313416)
[2024-10-21 02:48:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:29][root][INFO] - Training Epoch: 1/2, step 600/17983 completed (loss: 3.0130724906921387, acc: 0.4027777910232544)
[2024-10-21 02:48:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:30][root][INFO] - Training Epoch: 1/2, step 601/17983 completed (loss: 2.820828676223755, acc: 0.4821428656578064)
[2024-10-21 02:48:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:30][root][INFO] - Training Epoch: 1/2, step 602/17983 completed (loss: 3.3174996376037598, acc: 0.3695652186870575)
[2024-10-21 02:48:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:30][root][INFO] - Training Epoch: 1/2, step 603/17983 completed (loss: 2.959310293197632, acc: 0.40425533056259155)
[2024-10-21 02:48:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:31][root][INFO] - Training Epoch: 1/2, step 604/17983 completed (loss: 3.3163323402404785, acc: 0.3375000059604645)
[2024-10-21 02:48:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:31][root][INFO] - Training Epoch: 1/2, step 605/17983 completed (loss: 3.0768110752105713, acc: 0.38749998807907104)
[2024-10-21 02:48:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:31][root][INFO] - Training Epoch: 1/2, step 606/17983 completed (loss: 3.285745620727539, acc: 0.2921348214149475)
[2024-10-21 02:48:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:32][root][INFO] - Training Epoch: 1/2, step 607/17983 completed (loss: 2.2944531440734863, acc: 0.48148149251937866)
[2024-10-21 02:48:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:32][root][INFO] - Training Epoch: 1/2, step 608/17983 completed (loss: 3.505337715148926, acc: 0.35820895433425903)
[2024-10-21 02:48:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:33][root][INFO] - Training Epoch: 1/2, step 609/17983 completed (loss: 3.3496718406677246, acc: 0.34645670652389526)
[2024-10-21 02:48:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:33][root][INFO] - Training Epoch: 1/2, step 610/17983 completed (loss: 3.482290506362915, acc: 0.3055555522441864)
[2024-10-21 02:48:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:34][root][INFO] - Training Epoch: 1/2, step 611/17983 completed (loss: 3.1830313205718994, acc: 0.34736841917037964)
[2024-10-21 02:48:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:34][root][INFO] - Training Epoch: 1/2, step 612/17983 completed (loss: 3.5694189071655273, acc: 0.31081080436706543)
[2024-10-21 02:48:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:35][root][INFO] - Training Epoch: 1/2, step 613/17983 completed (loss: 3.289858341217041, acc: 0.32608696818351746)
[2024-10-21 02:48:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:35][root][INFO] - Training Epoch: 1/2, step 614/17983 completed (loss: 2.360628128051758, acc: 0.5849056839942932)
[2024-10-21 02:48:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:36][root][INFO] - Training Epoch: 1/2, step 615/17983 completed (loss: 3.105654239654541, acc: 0.46666666865348816)
[2024-10-21 02:48:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:36][root][INFO] - Training Epoch: 1/2, step 616/17983 completed (loss: 2.627808094024658, acc: 0.4406779706478119)
[2024-10-21 02:48:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:36][root][INFO] - Training Epoch: 1/2, step 617/17983 completed (loss: 2.0642454624176025, acc: 0.5614035129547119)
[2024-10-21 02:48:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:37][root][INFO] - Training Epoch: 1/2, step 618/17983 completed (loss: 2.46335506439209, acc: 0.4651162922382355)
[2024-10-21 02:48:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:37][root][INFO] - Training Epoch: 1/2, step 619/17983 completed (loss: 2.928757667541504, acc: 0.4117647111415863)
[2024-10-21 02:48:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:38][root][INFO] - Training Epoch: 1/2, step 620/17983 completed (loss: 1.9789916276931763, acc: 0.5762711763381958)
[2024-10-21 02:48:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:38][root][INFO] - Training Epoch: 1/2, step 621/17983 completed (loss: 2.7631301879882812, acc: 0.42500001192092896)
[2024-10-21 02:48:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:38][root][INFO] - Training Epoch: 1/2, step 622/17983 completed (loss: 2.8528220653533936, acc: 0.3913043439388275)
[2024-10-21 02:48:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:39][root][INFO] - Training Epoch: 1/2, step 623/17983 completed (loss: 3.024796485900879, acc: 0.38372093439102173)
[2024-10-21 02:48:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:39][root][INFO] - Training Epoch: 1/2, step 624/17983 completed (loss: 2.422544479370117, acc: 0.47058823704719543)
[2024-10-21 02:48:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:40][root][INFO] - Training Epoch: 1/2, step 625/17983 completed (loss: 2.5308611392974854, acc: 0.44680851697921753)
[2024-10-21 02:48:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:40][root][INFO] - Training Epoch: 1/2, step 626/17983 completed (loss: 3.2242836952209473, acc: 0.41333332657814026)
[2024-10-21 02:48:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:40][root][INFO] - Training Epoch: 1/2, step 627/17983 completed (loss: 2.8078973293304443, acc: 0.4680851101875305)
[2024-10-21 02:48:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:41][root][INFO] - Training Epoch: 1/2, step 628/17983 completed (loss: 2.8868567943573, acc: 0.45945945382118225)
[2024-10-21 02:48:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:41][root][INFO] - Training Epoch: 1/2, step 629/17983 completed (loss: 3.7854180335998535, acc: 0.3375000059604645)
[2024-10-21 02:48:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:42][root][INFO] - Training Epoch: 1/2, step 630/17983 completed (loss: 2.610203266143799, acc: 0.4032258093357086)
[2024-10-21 02:48:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:42][root][INFO] - Training Epoch: 1/2, step 631/17983 completed (loss: 2.779418706893921, acc: 0.49056604504585266)
[2024-10-21 02:48:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:43][root][INFO] - Training Epoch: 1/2, step 632/17983 completed (loss: 2.8599793910980225, acc: 0.4027777910232544)
[2024-10-21 02:48:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:43][root][INFO] - Training Epoch: 1/2, step 633/17983 completed (loss: 3.5192089080810547, acc: 0.32499998807907104)
[2024-10-21 02:48:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:43][root][INFO] - Training Epoch: 1/2, step 634/17983 completed (loss: 3.3336737155914307, acc: 0.3854166567325592)
[2024-10-21 02:48:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:44][root][INFO] - Training Epoch: 1/2, step 635/17983 completed (loss: 3.474064588546753, acc: 0.35483869910240173)
[2024-10-21 02:48:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:44][root][INFO] - Training Epoch: 1/2, step 636/17983 completed (loss: 3.1008498668670654, acc: 0.3913043439388275)
[2024-10-21 02:48:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:45][root][INFO] - Training Epoch: 1/2, step 637/17983 completed (loss: 3.259448528289795, acc: 0.4000000059604645)
[2024-10-21 02:48:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:45][root][INFO] - Training Epoch: 1/2, step 638/17983 completed (loss: 3.0159852504730225, acc: 0.3695652186870575)
[2024-10-21 02:48:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:45][root][INFO] - Training Epoch: 1/2, step 639/17983 completed (loss: 1.9206328392028809, acc: 0.6388888955116272)
[2024-10-21 02:48:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:46][root][INFO] - Training Epoch: 1/2, step 640/17983 completed (loss: 1.9279308319091797, acc: 0.5777778029441833)
[2024-10-21 02:48:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:46][root][INFO] - Training Epoch: 1/2, step 641/17983 completed (loss: 2.938321590423584, acc: 0.3461538553237915)
[2024-10-21 02:48:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:47][root][INFO] - Training Epoch: 1/2, step 642/17983 completed (loss: 2.3028266429901123, acc: 0.5641025900840759)
[2024-10-21 02:48:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:47][root][INFO] - Training Epoch: 1/2, step 643/17983 completed (loss: 2.8716981410980225, acc: 0.43023255467414856)
[2024-10-21 02:48:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:47][root][INFO] - Training Epoch: 1/2, step 644/17983 completed (loss: 3.118271827697754, acc: 0.3222222328186035)
[2024-10-21 02:48:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:48][root][INFO] - Training Epoch: 1/2, step 645/17983 completed (loss: 3.0623557567596436, acc: 0.380952388048172)
[2024-10-21 02:48:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:48][root][INFO] - Training Epoch: 1/2, step 646/17983 completed (loss: 3.5276122093200684, acc: 0.2954545319080353)
[2024-10-21 02:48:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:49][root][INFO] - Training Epoch: 1/2, step 647/17983 completed (loss: 2.992384910583496, acc: 0.3488371968269348)
[2024-10-21 02:48:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:49][root][INFO] - Training Epoch: 1/2, step 648/17983 completed (loss: 3.414088487625122, acc: 0.3366336524486542)
[2024-10-21 02:48:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:49][root][INFO] - Training Epoch: 1/2, step 649/17983 completed (loss: 2.2427687644958496, acc: 0.5666666626930237)
[2024-10-21 02:48:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:50][root][INFO] - Training Epoch: 1/2, step 650/17983 completed (loss: 2.5633580684661865, acc: 0.45652174949645996)
[2024-10-21 02:48:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:51][root][INFO] - Training Epoch: 1/2, step 651/17983 completed (loss: 3.766535758972168, acc: 0.31578946113586426)
[2024-10-21 02:48:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:51][root][INFO] - Training Epoch: 1/2, step 652/17983 completed (loss: 3.521437168121338, acc: 0.3375000059604645)
[2024-10-21 02:48:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:52][root][INFO] - Training Epoch: 1/2, step 653/17983 completed (loss: 2.9265127182006836, acc: 0.36250001192092896)
[2024-10-21 02:48:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:52][root][INFO] - Training Epoch: 1/2, step 654/17983 completed (loss: 3.191441774368286, acc: 0.39080458879470825)
[2024-10-21 02:48:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:53][root][INFO] - Training Epoch: 1/2, step 655/17983 completed (loss: 3.3643574714660645, acc: 0.27586206793785095)
[2024-10-21 02:48:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:53][root][INFO] - Training Epoch: 1/2, step 656/17983 completed (loss: 2.747112989425659, acc: 0.3928571343421936)
[2024-10-21 02:48:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:53][root][INFO] - Training Epoch: 1/2, step 657/17983 completed (loss: 2.5932626724243164, acc: 0.4576271176338196)
[2024-10-21 02:48:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:54][root][INFO] - Training Epoch: 1/2, step 658/17983 completed (loss: 3.1574041843414307, acc: 0.4000000059604645)
[2024-10-21 02:48:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:54][root][INFO] - Training Epoch: 1/2, step 659/17983 completed (loss: 3.686309337615967, acc: 0.3181818127632141)
[2024-10-21 02:48:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:55][root][INFO] - Training Epoch: 1/2, step 660/17983 completed (loss: 2.6084389686584473, acc: 0.47999998927116394)
[2024-10-21 02:48:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:55][root][INFO] - Training Epoch: 1/2, step 661/17983 completed (loss: 3.7649497985839844, acc: 0.3499999940395355)
[2024-10-21 02:48:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:55][root][INFO] - Training Epoch: 1/2, step 662/17983 completed (loss: 2.25642728805542, acc: 0.4523809552192688)
[2024-10-21 02:48:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:56][root][INFO] - Training Epoch: 1/2, step 663/17983 completed (loss: 1.5884695053100586, acc: 0.6086956262588501)
[2024-10-21 02:48:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:56][root][INFO] - Training Epoch: 1/2, step 664/17983 completed (loss: 3.069664239883423, acc: 0.3658536672592163)
[2024-10-21 02:48:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:57][root][INFO] - Training Epoch: 1/2, step 665/17983 completed (loss: 2.901433229446411, acc: 0.3888888955116272)
[2024-10-21 02:48:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:57][root][INFO] - Training Epoch: 1/2, step 666/17983 completed (loss: 2.6037046909332275, acc: 0.4482758641242981)
[2024-10-21 02:48:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:57][root][INFO] - Training Epoch: 1/2, step 667/17983 completed (loss: 2.991224527359009, acc: 0.44329896569252014)
[2024-10-21 02:48:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:58][root][INFO] - Training Epoch: 1/2, step 668/17983 completed (loss: 3.376823902130127, acc: 0.32380953431129456)
[2024-10-21 02:48:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:58][root][INFO] - Training Epoch: 1/2, step 669/17983 completed (loss: 3.088514566421509, acc: 0.40816327929496765)
[2024-10-21 02:48:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:59][root][INFO] - Training Epoch: 1/2, step 670/17983 completed (loss: 2.969302177429199, acc: 0.35483869910240173)
[2024-10-21 02:48:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:48:59][root][INFO] - Training Epoch: 1/2, step 671/17983 completed (loss: 3.289783000946045, acc: 0.35849055647850037)
[2024-10-21 02:48:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:00][root][INFO] - Training Epoch: 1/2, step 672/17983 completed (loss: 3.214280605316162, acc: 0.3333333432674408)
[2024-10-21 02:49:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:00][root][INFO] - Training Epoch: 1/2, step 673/17983 completed (loss: 2.978621482849121, acc: 0.4375)
[2024-10-21 02:49:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:00][root][INFO] - Training Epoch: 1/2, step 674/17983 completed (loss: 3.699432611465454, acc: 0.28205129504203796)
[2024-10-21 02:49:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:01][root][INFO] - Training Epoch: 1/2, step 675/17983 completed (loss: 3.4913330078125, acc: 0.4038461446762085)
[2024-10-21 02:49:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:01][root][INFO] - Training Epoch: 1/2, step 676/17983 completed (loss: 2.891190767288208, acc: 0.36036035418510437)
[2024-10-21 02:49:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:02][root][INFO] - Training Epoch: 1/2, step 677/17983 completed (loss: 3.818958044052124, acc: 0.29032257199287415)
[2024-10-21 02:49:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:02][root][INFO] - Training Epoch: 1/2, step 678/17983 completed (loss: 3.0995936393737793, acc: 0.36666667461395264)
[2024-10-21 02:49:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:02][root][INFO] - Training Epoch: 1/2, step 679/17983 completed (loss: 2.2492051124572754, acc: 0.5757575631141663)
[2024-10-21 02:49:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:03][root][INFO] - Training Epoch: 1/2, step 680/17983 completed (loss: 2.753856658935547, acc: 0.44680851697921753)
[2024-10-21 02:49:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:03][root][INFO] - Training Epoch: 1/2, step 681/17983 completed (loss: 3.225069522857666, acc: 0.4000000059604645)
[2024-10-21 02:49:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:03][root][INFO] - Training Epoch: 1/2, step 682/17983 completed (loss: 2.4731926918029785, acc: 0.4285714328289032)
[2024-10-21 02:49:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:04][root][INFO] - Training Epoch: 1/2, step 683/17983 completed (loss: 3.3788561820983887, acc: 0.38129496574401855)
[2024-10-21 02:49:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:04][root][INFO] - Training Epoch: 1/2, step 684/17983 completed (loss: 2.9161536693573, acc: 0.3366336524486542)
[2024-10-21 02:49:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:05][root][INFO] - Training Epoch: 1/2, step 685/17983 completed (loss: 2.5518832206726074, acc: 0.4767441749572754)
[2024-10-21 02:49:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:05][root][INFO] - Training Epoch: 1/2, step 686/17983 completed (loss: 2.632606029510498, acc: 0.40860214829444885)
[2024-10-21 02:49:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:06][root][INFO] - Training Epoch: 1/2, step 687/17983 completed (loss: 2.6010994911193848, acc: 0.4399999976158142)
[2024-10-21 02:49:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:06][root][INFO] - Training Epoch: 1/2, step 688/17983 completed (loss: 2.4421823024749756, acc: 0.5147058963775635)
[2024-10-21 02:49:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:06][root][INFO] - Training Epoch: 1/2, step 689/17983 completed (loss: 2.1546592712402344, acc: 0.5454545617103577)
[2024-10-21 02:49:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:07][root][INFO] - Training Epoch: 1/2, step 690/17983 completed (loss: 2.545897960662842, acc: 0.4912280738353729)
[2024-10-21 02:49:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:07][root][INFO] - Training Epoch: 1/2, step 691/17983 completed (loss: 2.893084764480591, acc: 0.36274510622024536)
[2024-10-21 02:49:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:08][root][INFO] - Training Epoch: 1/2, step 692/17983 completed (loss: 3.0339276790618896, acc: 0.3658536672592163)
[2024-10-21 02:49:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:08][root][INFO] - Training Epoch: 1/2, step 693/17983 completed (loss: 2.6897530555725098, acc: 0.4606741666793823)
[2024-10-21 02:49:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:09][root][INFO] - Training Epoch: 1/2, step 694/17983 completed (loss: 2.8456640243530273, acc: 0.41747573018074036)
[2024-10-21 02:49:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:09][root][INFO] - Training Epoch: 1/2, step 695/17983 completed (loss: 3.4655284881591797, acc: 0.3472222089767456)
[2024-10-21 02:49:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:10][root][INFO] - Training Epoch: 1/2, step 696/17983 completed (loss: 2.6105639934539795, acc: 0.4285714328289032)
[2024-10-21 02:49:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:10][root][INFO] - Training Epoch: 1/2, step 697/17983 completed (loss: 3.3254446983337402, acc: 0.3486238420009613)
[2024-10-21 02:49:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:10][root][INFO] - Training Epoch: 1/2, step 698/17983 completed (loss: 3.03017520904541, acc: 0.34020617604255676)
[2024-10-21 02:49:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:11][root][INFO] - Training Epoch: 1/2, step 699/17983 completed (loss: 2.6424741744995117, acc: 0.46987950801849365)
[2024-10-21 02:49:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:11][root][INFO] - Training Epoch: 1/2, step 700/17983 completed (loss: 2.870837926864624, acc: 0.39534884691238403)
[2024-10-21 02:49:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:12][root][INFO] - Training Epoch: 1/2, step 701/17983 completed (loss: 3.0626959800720215, acc: 0.46000000834465027)
[2024-10-21 02:49:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:12][root][INFO] - Training Epoch: 1/2, step 702/17983 completed (loss: 3.3211188316345215, acc: 0.3529411852359772)
[2024-10-21 02:49:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:13][root][INFO] - Training Epoch: 1/2, step 703/17983 completed (loss: 2.7551403045654297, acc: 0.47058823704719543)
[2024-10-21 02:49:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:13][root][INFO] - Training Epoch: 1/2, step 704/17983 completed (loss: 3.3403406143188477, acc: 0.34210526943206787)
[2024-10-21 02:49:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:13][root][INFO] - Training Epoch: 1/2, step 705/17983 completed (loss: 2.702470541000366, acc: 0.5)
[2024-10-21 02:49:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:14][root][INFO] - Training Epoch: 1/2, step 706/17983 completed (loss: 3.476733446121216, acc: 0.28999999165534973)
[2024-10-21 02:49:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:14][root][INFO] - Training Epoch: 1/2, step 707/17983 completed (loss: 2.4496614933013916, acc: 0.5230769515037537)
[2024-10-21 02:49:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:15][root][INFO] - Training Epoch: 1/2, step 708/17983 completed (loss: 3.414111852645874, acc: 0.38333332538604736)
[2024-10-21 02:49:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:15][root][INFO] - Training Epoch: 1/2, step 709/17983 completed (loss: 3.1498398780822754, acc: 0.3571428656578064)
[2024-10-21 02:49:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:16][root][INFO] - Training Epoch: 1/2, step 710/17983 completed (loss: 3.2380073070526123, acc: 0.40697672963142395)
[2024-10-21 02:49:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:16][root][INFO] - Training Epoch: 1/2, step 711/17983 completed (loss: 3.244215726852417, acc: 0.3529411852359772)
[2024-10-21 02:49:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:16][root][INFO] - Training Epoch: 1/2, step 712/17983 completed (loss: 3.3250792026519775, acc: 0.3913043439388275)
[2024-10-21 02:49:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:17][root][INFO] - Training Epoch: 1/2, step 713/17983 completed (loss: 3.217623233795166, acc: 0.3199999928474426)
[2024-10-21 02:49:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:17][root][INFO] - Training Epoch: 1/2, step 714/17983 completed (loss: 3.079341411590576, acc: 0.3478260934352875)
[2024-10-21 02:49:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:18][root][INFO] - Training Epoch: 1/2, step 715/17983 completed (loss: 2.1593167781829834, acc: 0.6029411554336548)
[2024-10-21 02:49:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:18][root][INFO] - Training Epoch: 1/2, step 716/17983 completed (loss: 2.9028425216674805, acc: 0.39436620473861694)
[2024-10-21 02:49:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:19][root][INFO] - Training Epoch: 1/2, step 717/17983 completed (loss: 3.2735252380371094, acc: 0.39423078298568726)
[2024-10-21 02:49:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:19][root][INFO] - Training Epoch: 1/2, step 718/17983 completed (loss: 3.505906105041504, acc: 0.3333333432674408)
[2024-10-21 02:49:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:20][root][INFO] - Training Epoch: 1/2, step 719/17983 completed (loss: 2.9415645599365234, acc: 0.3928571343421936)
[2024-10-21 02:49:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:20][root][INFO] - Training Epoch: 1/2, step 720/17983 completed (loss: 2.530287504196167, acc: 0.36666667461395264)
[2024-10-21 02:49:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:21][root][INFO] - Training Epoch: 1/2, step 721/17983 completed (loss: 3.2391343116760254, acc: 0.38749998807907104)
[2024-10-21 02:49:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:21][root][INFO] - Training Epoch: 1/2, step 722/17983 completed (loss: 2.901271104812622, acc: 0.4516128897666931)
[2024-10-21 02:49:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:21][root][INFO] - Training Epoch: 1/2, step 723/17983 completed (loss: 3.1489036083221436, acc: 0.4067796468734741)
[2024-10-21 02:49:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:22][root][INFO] - Training Epoch: 1/2, step 724/17983 completed (loss: 1.9057387113571167, acc: 0.5799999833106995)
[2024-10-21 02:49:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:22][root][INFO] - Training Epoch: 1/2, step 725/17983 completed (loss: 2.285205602645874, acc: 0.5652173757553101)
[2024-10-21 02:49:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:23][root][INFO] - Training Epoch: 1/2, step 726/17983 completed (loss: 3.5659608840942383, acc: 0.3095238208770752)
[2024-10-21 02:49:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:23][root][INFO] - Training Epoch: 1/2, step 727/17983 completed (loss: 2.5891127586364746, acc: 0.40909090638160706)
[2024-10-21 02:49:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:24][root][INFO] - Training Epoch: 1/2, step 728/17983 completed (loss: 2.95487642288208, acc: 0.4000000059604645)
[2024-10-21 02:49:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:24][root][INFO] - Training Epoch: 1/2, step 729/17983 completed (loss: 2.4661660194396973, acc: 0.44117647409439087)
[2024-10-21 02:49:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:24][root][INFO] - Training Epoch: 1/2, step 730/17983 completed (loss: 2.9354584217071533, acc: 0.42500001192092896)
[2024-10-21 02:49:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:25][root][INFO] - Training Epoch: 1/2, step 731/17983 completed (loss: 2.7673110961914062, acc: 0.4264705777168274)
[2024-10-21 02:49:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:25][root][INFO] - Training Epoch: 1/2, step 732/17983 completed (loss: 3.6931376457214355, acc: 0.3333333432674408)
[2024-10-21 02:49:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:26][root][INFO] - Training Epoch: 1/2, step 733/17983 completed (loss: 3.1378095149993896, acc: 0.39436620473861694)
[2024-10-21 02:49:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:26][root][INFO] - Training Epoch: 1/2, step 734/17983 completed (loss: 3.67747163772583, acc: 0.4150943458080292)
[2024-10-21 02:49:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:26][root][INFO] - Training Epoch: 1/2, step 735/17983 completed (loss: 3.1459121704101562, acc: 0.3655914068222046)
[2024-10-21 02:49:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:27][root][INFO] - Training Epoch: 1/2, step 736/17983 completed (loss: 2.3060805797576904, acc: 0.43478259444236755)
[2024-10-21 02:49:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:27][root][INFO] - Training Epoch: 1/2, step 737/17983 completed (loss: 2.806607961654663, acc: 0.4571428596973419)
[2024-10-21 02:49:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:28][root][INFO] - Training Epoch: 1/2, step 738/17983 completed (loss: 3.039990186691284, acc: 0.4590163826942444)
[2024-10-21 02:49:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:28][root][INFO] - Training Epoch: 1/2, step 739/17983 completed (loss: 2.4756829738616943, acc: 0.4888888895511627)
[2024-10-21 02:49:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:29][root][INFO] - Training Epoch: 1/2, step 740/17983 completed (loss: 2.887782096862793, acc: 0.36000001430511475)
[2024-10-21 02:49:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:29][root][INFO] - Training Epoch: 1/2, step 741/17983 completed (loss: 3.3919053077697754, acc: 0.37931033968925476)
[2024-10-21 02:49:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:29][root][INFO] - Training Epoch: 1/2, step 742/17983 completed (loss: 1.8621922731399536, acc: 0.5263158082962036)
[2024-10-21 02:49:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:30][root][INFO] - Training Epoch: 1/2, step 743/17983 completed (loss: 2.6155290603637695, acc: 0.47297295928001404)
[2024-10-21 02:49:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:30][root][INFO] - Training Epoch: 1/2, step 744/17983 completed (loss: 2.1797895431518555, acc: 0.5686274766921997)
[2024-10-21 02:49:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:31][root][INFO] - Training Epoch: 1/2, step 745/17983 completed (loss: 3.670020341873169, acc: 0.45945945382118225)
[2024-10-21 02:49:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:31][root][INFO] - Training Epoch: 1/2, step 746/17983 completed (loss: 2.5472700595855713, acc: 0.460317462682724)
[2024-10-21 02:49:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:31][root][INFO] - Training Epoch: 1/2, step 747/17983 completed (loss: 2.8147053718566895, acc: 0.347457617521286)
[2024-10-21 02:49:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:32][root][INFO] - Training Epoch: 1/2, step 748/17983 completed (loss: 3.081132173538208, acc: 0.3523809611797333)
[2024-10-21 02:49:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:32][root][INFO] - Training Epoch: 1/2, step 749/17983 completed (loss: 2.988640069961548, acc: 0.4000000059604645)
[2024-10-21 02:49:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:33][root][INFO] - Training Epoch: 1/2, step 750/17983 completed (loss: 2.7464704513549805, acc: 0.4861111044883728)
[2024-10-21 02:49:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:33][root][INFO] - Training Epoch: 1/2, step 751/17983 completed (loss: 2.8631350994110107, acc: 0.40869563817977905)
[2024-10-21 02:49:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:33][root][INFO] - Training Epoch: 1/2, step 752/17983 completed (loss: 3.259260654449463, acc: 0.37142857909202576)
[2024-10-21 02:49:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:34][root][INFO] - Training Epoch: 1/2, step 753/17983 completed (loss: 3.4933431148529053, acc: 0.33000001311302185)
[2024-10-21 02:49:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:34][root][INFO] - Training Epoch: 1/2, step 754/17983 completed (loss: 3.419128656387329, acc: 0.3199999928474426)
[2024-10-21 02:49:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:35][root][INFO] - Training Epoch: 1/2, step 755/17983 completed (loss: 2.9330592155456543, acc: 0.450549453496933)
[2024-10-21 02:49:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:35][root][INFO] - Training Epoch: 1/2, step 756/17983 completed (loss: 2.416938304901123, acc: 0.42105263471603394)
[2024-10-21 02:49:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:36][root][INFO] - Training Epoch: 1/2, step 757/17983 completed (loss: 3.811796188354492, acc: 0.3541666567325592)
[2024-10-21 02:49:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:36][root][INFO] - Training Epoch: 1/2, step 758/17983 completed (loss: 2.6887049674987793, acc: 0.4326923191547394)
[2024-10-21 02:49:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:36][root][INFO] - Training Epoch: 1/2, step 759/17983 completed (loss: 2.9729983806610107, acc: 0.4000000059604645)
[2024-10-21 02:49:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:37][root][INFO] - Training Epoch: 1/2, step 760/17983 completed (loss: 1.6589665412902832, acc: 0.5581395626068115)
[2024-10-21 02:49:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:37][root][INFO] - Training Epoch: 1/2, step 761/17983 completed (loss: 2.9998366832733154, acc: 0.37837839126586914)
[2024-10-21 02:49:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:38][root][INFO] - Training Epoch: 1/2, step 762/17983 completed (loss: 2.9799675941467285, acc: 0.4354838728904724)
[2024-10-21 02:49:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:38][root][INFO] - Training Epoch: 1/2, step 763/17983 completed (loss: 2.902247428894043, acc: 0.4166666567325592)
[2024-10-21 02:49:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:38][root][INFO] - Training Epoch: 1/2, step 764/17983 completed (loss: 3.1720781326293945, acc: 0.364705890417099)
[2024-10-21 02:49:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:39][root][INFO] - Training Epoch: 1/2, step 765/17983 completed (loss: 2.8175158500671387, acc: 0.4262295067310333)
[2024-10-21 02:49:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:39][root][INFO] - Training Epoch: 1/2, step 766/17983 completed (loss: 3.7817556858062744, acc: 0.3086419701576233)
[2024-10-21 02:49:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:40][root][INFO] - Training Epoch: 1/2, step 767/17983 completed (loss: 3.086336851119995, acc: 0.47058823704719543)
[2024-10-21 02:49:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:40][root][INFO] - Training Epoch: 1/2, step 768/17983 completed (loss: 2.4068257808685303, acc: 0.5454545617103577)
[2024-10-21 02:49:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:40][root][INFO] - Training Epoch: 1/2, step 769/17983 completed (loss: 2.466581106185913, acc: 0.38749998807907104)
[2024-10-21 02:49:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:41][root][INFO] - Training Epoch: 1/2, step 770/17983 completed (loss: 2.701094627380371, acc: 0.4430379867553711)
[2024-10-21 02:49:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:41][root][INFO] - Training Epoch: 1/2, step 771/17983 completed (loss: 2.7514655590057373, acc: 0.44999998807907104)
[2024-10-21 02:49:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:42][root][INFO] - Training Epoch: 1/2, step 772/17983 completed (loss: 3.5101571083068848, acc: 0.30337077379226685)
[2024-10-21 02:49:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:42][root][INFO] - Training Epoch: 1/2, step 773/17983 completed (loss: 3.002734422683716, acc: 0.3263157904148102)
[2024-10-21 02:49:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:42][root][INFO] - Training Epoch: 1/2, step 774/17983 completed (loss: 3.8013923168182373, acc: 0.3333333432674408)
[2024-10-21 02:49:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:43][root][INFO] - Training Epoch: 1/2, step 775/17983 completed (loss: 2.7406134605407715, acc: 0.41904762387275696)
[2024-10-21 02:49:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:43][root][INFO] - Training Epoch: 1/2, step 776/17983 completed (loss: 3.097217082977295, acc: 0.4769230782985687)
[2024-10-21 02:49:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:44][root][INFO] - Training Epoch: 1/2, step 777/17983 completed (loss: 2.357465982437134, acc: 0.46296295523643494)
[2024-10-21 02:49:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:44][root][INFO] - Training Epoch: 1/2, step 778/17983 completed (loss: 1.9926631450653076, acc: 0.692307710647583)
[2024-10-21 02:49:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:45][root][INFO] - Training Epoch: 1/2, step 779/17983 completed (loss: 3.2216577529907227, acc: 0.43396225571632385)
[2024-10-21 02:49:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:45][root][INFO] - Training Epoch: 1/2, step 780/17983 completed (loss: 3.090486526489258, acc: 0.35151514410972595)
[2024-10-21 02:49:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:46][root][INFO] - Training Epoch: 1/2, step 781/17983 completed (loss: 2.786623239517212, acc: 0.4144144058227539)
[2024-10-21 02:49:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:46][root][INFO] - Training Epoch: 1/2, step 782/17983 completed (loss: 3.3495941162109375, acc: 0.30645161867141724)
[2024-10-21 02:49:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:47][root][INFO] - Training Epoch: 1/2, step 783/17983 completed (loss: 2.9662766456604004, acc: 0.3965517282485962)
[2024-10-21 02:49:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:47][root][INFO] - Training Epoch: 1/2, step 784/17983 completed (loss: 3.199969530105591, acc: 0.38235294818878174)
[2024-10-21 02:49:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:47][root][INFO] - Training Epoch: 1/2, step 785/17983 completed (loss: 2.441227436065674, acc: 0.5223880410194397)
[2024-10-21 02:49:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:48][root][INFO] - Training Epoch: 1/2, step 786/17983 completed (loss: 3.3421969413757324, acc: 0.3741496503353119)
[2024-10-21 02:49:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:48][root][INFO] - Training Epoch: 1/2, step 787/17983 completed (loss: 3.0461137294769287, acc: 0.4655172526836395)
[2024-10-21 02:49:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:49][root][INFO] - Training Epoch: 1/2, step 788/17983 completed (loss: 3.081883668899536, acc: 0.36538460850715637)
[2024-10-21 02:49:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:49][root][INFO] - Training Epoch: 1/2, step 789/17983 completed (loss: 3.2688324451446533, acc: 0.39534884691238403)
[2024-10-21 02:49:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:50][root][INFO] - Training Epoch: 1/2, step 790/17983 completed (loss: 2.3269567489624023, acc: 0.6078431606292725)
[2024-10-21 02:49:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:50][root][INFO] - Training Epoch: 1/2, step 791/17983 completed (loss: 2.9470741748809814, acc: 0.47727271914482117)
[2024-10-21 02:49:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:51][root][INFO] - Training Epoch: 1/2, step 792/17983 completed (loss: 2.948500394821167, acc: 0.4285714328289032)
[2024-10-21 02:49:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:51][root][INFO] - Training Epoch: 1/2, step 793/17983 completed (loss: 2.8039493560791016, acc: 0.4196428656578064)
[2024-10-21 02:49:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:51][root][INFO] - Training Epoch: 1/2, step 794/17983 completed (loss: 2.905219793319702, acc: 0.4677419364452362)
[2024-10-21 02:49:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:52][root][INFO] - Training Epoch: 1/2, step 795/17983 completed (loss: 3.1305813789367676, acc: 0.34567901492118835)
[2024-10-21 02:49:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:52][root][INFO] - Training Epoch: 1/2, step 796/17983 completed (loss: 2.6321942806243896, acc: 0.4722222089767456)
[2024-10-21 02:49:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:53][root][INFO] - Training Epoch: 1/2, step 797/17983 completed (loss: 2.68804669380188, acc: 0.4655172526836395)
[2024-10-21 02:49:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:53][root][INFO] - Training Epoch: 1/2, step 798/17983 completed (loss: 3.1758835315704346, acc: 0.38297873735427856)
[2024-10-21 02:49:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:54][root][INFO] - Training Epoch: 1/2, step 799/17983 completed (loss: 2.5650436878204346, acc: 0.4385964870452881)
[2024-10-21 02:49:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:54][root][INFO] - Training Epoch: 1/2, step 800/17983 completed (loss: 2.7820627689361572, acc: 0.4146341383457184)
[2024-10-21 02:49:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:55][root][INFO] - Training Epoch: 1/2, step 801/17983 completed (loss: 3.1880557537078857, acc: 0.37037035822868347)
[2024-10-21 02:49:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:55][root][INFO] - Training Epoch: 1/2, step 802/17983 completed (loss: 2.7854745388031006, acc: 0.4313725531101227)
[2024-10-21 02:49:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:55][root][INFO] - Training Epoch: 1/2, step 803/17983 completed (loss: 3.3952322006225586, acc: 0.3163265287876129)
[2024-10-21 02:49:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:56][root][INFO] - Training Epoch: 1/2, step 804/17983 completed (loss: 2.4722845554351807, acc: 0.4848484992980957)
[2024-10-21 02:49:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:56][root][INFO] - Training Epoch: 1/2, step 805/17983 completed (loss: 3.026738405227661, acc: 0.469696968793869)
[2024-10-21 02:49:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:57][root][INFO] - Training Epoch: 1/2, step 806/17983 completed (loss: 2.4564642906188965, acc: 0.5384615659713745)
[2024-10-21 02:49:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:57][root][INFO] - Training Epoch: 1/2, step 807/17983 completed (loss: 3.1498942375183105, acc: 0.4117647111415863)
[2024-10-21 02:49:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:57][root][INFO] - Training Epoch: 1/2, step 808/17983 completed (loss: 3.555992364883423, acc: 0.3164556920528412)
[2024-10-21 02:49:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:58][root][INFO] - Training Epoch: 1/2, step 809/17983 completed (loss: 2.0195391178131104, acc: 0.5581395626068115)
[2024-10-21 02:49:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:58][root][INFO] - Training Epoch: 1/2, step 810/17983 completed (loss: 1.844978928565979, acc: 0.5555555820465088)
[2024-10-21 02:49:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:59][root][INFO] - Training Epoch: 1/2, step 811/17983 completed (loss: 3.020038604736328, acc: 0.3461538553237915)
[2024-10-21 02:49:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:59][root][INFO] - Training Epoch: 1/2, step 812/17983 completed (loss: 3.190685510635376, acc: 0.3731343150138855)
[2024-10-21 02:49:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:49:59][root][INFO] - Training Epoch: 1/2, step 813/17983 completed (loss: 3.1580121517181396, acc: 0.36734694242477417)
[2024-10-21 02:50:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:00][root][INFO] - Training Epoch: 1/2, step 814/17983 completed (loss: 2.656230926513672, acc: 0.410526305437088)
[2024-10-21 02:50:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:00][root][INFO] - Training Epoch: 1/2, step 815/17983 completed (loss: 3.0981991291046143, acc: 0.38805970549583435)
[2024-10-21 02:50:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:01][root][INFO] - Training Epoch: 1/2, step 816/17983 completed (loss: 2.8217854499816895, acc: 0.4444444477558136)
[2024-10-21 02:50:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:01][root][INFO] - Training Epoch: 1/2, step 817/17983 completed (loss: 2.4726619720458984, acc: 0.5072463750839233)
[2024-10-21 02:50:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:01][root][INFO] - Training Epoch: 1/2, step 818/17983 completed (loss: 3.4372153282165527, acc: 0.4545454680919647)
[2024-10-21 02:50:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:02][root][INFO] - Training Epoch: 1/2, step 819/17983 completed (loss: 3.073455572128296, acc: 0.4262295067310333)
[2024-10-21 02:50:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:02][root][INFO] - Training Epoch: 1/2, step 820/17983 completed (loss: 2.6071841716766357, acc: 0.5)
[2024-10-21 02:50:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:03][root][INFO] - Training Epoch: 1/2, step 821/17983 completed (loss: 2.3377060890197754, acc: 0.5344827771186829)
[2024-10-21 02:50:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:03][root][INFO] - Training Epoch: 1/2, step 822/17983 completed (loss: 2.983522653579712, acc: 0.4095238149166107)
[2024-10-21 02:50:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:04][root][INFO] - Training Epoch: 1/2, step 823/17983 completed (loss: 2.467954397201538, acc: 0.5)
[2024-10-21 02:50:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:04][root][INFO] - Training Epoch: 1/2, step 824/17983 completed (loss: 2.798240900039673, acc: 0.4313725531101227)
[2024-10-21 02:50:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:04][root][INFO] - Training Epoch: 1/2, step 825/17983 completed (loss: 2.3562803268432617, acc: 0.43103447556495667)
[2024-10-21 02:50:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:05][root][INFO] - Training Epoch: 1/2, step 826/17983 completed (loss: 3.125749111175537, acc: 0.4247787594795227)
[2024-10-21 02:50:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:05][root][INFO] - Training Epoch: 1/2, step 827/17983 completed (loss: 3.0347976684570312, acc: 0.39772728085517883)
[2024-10-21 02:50:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:06][root][INFO] - Training Epoch: 1/2, step 828/17983 completed (loss: 3.4541497230529785, acc: 0.3194444477558136)
[2024-10-21 02:50:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:06][root][INFO] - Training Epoch: 1/2, step 829/17983 completed (loss: 2.3828940391540527, acc: 0.5714285969734192)
[2024-10-21 02:50:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:07][root][INFO] - Training Epoch: 1/2, step 830/17983 completed (loss: 3.03802490234375, acc: 0.36781609058380127)
[2024-10-21 02:50:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:07][root][INFO] - Training Epoch: 1/2, step 831/17983 completed (loss: 3.2621712684631348, acc: 0.3863636255264282)
[2024-10-21 02:50:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:08][root][INFO] - Training Epoch: 1/2, step 832/17983 completed (loss: 2.8968565464019775, acc: 0.5094339847564697)
[2024-10-21 02:50:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:08][root][INFO] - Training Epoch: 1/2, step 833/17983 completed (loss: 3.25888991355896, acc: 0.41025641560554504)
[2024-10-21 02:50:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:08][root][INFO] - Training Epoch: 1/2, step 834/17983 completed (loss: 2.913687229156494, acc: 0.41489362716674805)
[2024-10-21 02:50:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:09][root][INFO] - Training Epoch: 1/2, step 835/17983 completed (loss: 2.707872152328491, acc: 0.4430379867553711)
[2024-10-21 02:50:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:09][root][INFO] - Training Epoch: 1/2, step 836/17983 completed (loss: 0.4048283100128174, acc: 0.8235294222831726)
[2024-10-21 02:50:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:10][root][INFO] - Training Epoch: 1/2, step 837/17983 completed (loss: 3.1970908641815186, acc: 0.3855421543121338)
[2024-10-21 02:50:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:10][root][INFO] - Training Epoch: 1/2, step 838/17983 completed (loss: 2.6375720500946045, acc: 0.4305555522441864)
[2024-10-21 02:50:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:11][root][INFO] - Training Epoch: 1/2, step 839/17983 completed (loss: 2.5592453479766846, acc: 0.483146071434021)
[2024-10-21 02:50:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:11][root][INFO] - Training Epoch: 1/2, step 840/17983 completed (loss: 2.4270784854888916, acc: 0.447761207818985)
[2024-10-21 02:50:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:12][root][INFO] - Training Epoch: 1/2, step 841/17983 completed (loss: 3.0301005840301514, acc: 0.3979591727256775)
[2024-10-21 02:50:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:12][root][INFO] - Training Epoch: 1/2, step 842/17983 completed (loss: 2.663120985031128, acc: 0.4533333480358124)
[2024-10-21 02:50:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:12][root][INFO] - Training Epoch: 1/2, step 843/17983 completed (loss: 2.9164562225341797, acc: 0.3827160596847534)
[2024-10-21 02:50:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:13][root][INFO] - Training Epoch: 1/2, step 844/17983 completed (loss: 2.6763551235198975, acc: 0.4000000059604645)
[2024-10-21 02:50:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:13][root][INFO] - Training Epoch: 1/2, step 845/17983 completed (loss: 2.615732192993164, acc: 0.42105263471603394)
[2024-10-21 02:50:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:14][root][INFO] - Training Epoch: 1/2, step 846/17983 completed (loss: 3.157360315322876, acc: 0.4189189076423645)
[2024-10-21 02:50:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:14][root][INFO] - Training Epoch: 1/2, step 847/17983 completed (loss: 2.80588960647583, acc: 0.4556961953639984)
[2024-10-21 02:50:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:14][root][INFO] - Training Epoch: 1/2, step 848/17983 completed (loss: 2.6035962104797363, acc: 0.446153849363327)
[2024-10-21 02:50:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:15][root][INFO] - Training Epoch: 1/2, step 849/17983 completed (loss: 2.7344970703125, acc: 0.41818180680274963)
[2024-10-21 02:50:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:15][root][INFO] - Training Epoch: 1/2, step 850/17983 completed (loss: 2.993528127670288, acc: 0.3932584226131439)
[2024-10-21 02:50:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:16][root][INFO] - Training Epoch: 1/2, step 851/17983 completed (loss: 3.1076948642730713, acc: 0.450549453496933)
[2024-10-21 02:50:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:16][root][INFO] - Training Epoch: 1/2, step 852/17983 completed (loss: 2.871290922164917, acc: 0.3947368562221527)
[2024-10-21 02:50:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:17][root][INFO] - Training Epoch: 1/2, step 853/17983 completed (loss: 3.205693244934082, acc: 0.4655172526836395)
[2024-10-21 02:50:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:17][root][INFO] - Training Epoch: 1/2, step 854/17983 completed (loss: 3.194892406463623, acc: 0.31111112236976624)
[2024-10-21 02:50:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:18][root][INFO] - Training Epoch: 1/2, step 855/17983 completed (loss: 3.0197019577026367, acc: 0.38461539149284363)
[2024-10-21 02:50:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:18][root][INFO] - Training Epoch: 1/2, step 856/17983 completed (loss: 2.3633368015289307, acc: 0.574999988079071)
[2024-10-21 02:50:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:18][root][INFO] - Training Epoch: 1/2, step 857/17983 completed (loss: 2.671182870864868, acc: 0.45205479860305786)
[2024-10-21 02:50:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:19][root][INFO] - Training Epoch: 1/2, step 858/17983 completed (loss: 3.1298506259918213, acc: 0.41860464215278625)
[2024-10-21 02:50:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:19][root][INFO] - Training Epoch: 1/2, step 859/17983 completed (loss: 3.012242555618286, acc: 0.35483869910240173)
[2024-10-21 02:50:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:20][root][INFO] - Training Epoch: 1/2, step 860/17983 completed (loss: 2.3839874267578125, acc: 0.4794520437717438)
[2024-10-21 02:50:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:20][root][INFO] - Training Epoch: 1/2, step 861/17983 completed (loss: 2.4683849811553955, acc: 0.4651162922382355)
[2024-10-21 02:50:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:20][root][INFO] - Training Epoch: 1/2, step 862/17983 completed (loss: 2.2694361209869385, acc: 0.53125)
[2024-10-21 02:50:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:21][root][INFO] - Training Epoch: 1/2, step 863/17983 completed (loss: 2.659724235534668, acc: 0.460317462682724)
[2024-10-21 02:50:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:21][root][INFO] - Training Epoch: 1/2, step 864/17983 completed (loss: 2.7114312648773193, acc: 0.4848484992980957)
[2024-10-21 02:50:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:22][root][INFO] - Training Epoch: 1/2, step 865/17983 completed (loss: 2.7868576049804688, acc: 0.4285714328289032)
[2024-10-21 02:50:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:22][root][INFO] - Training Epoch: 1/2, step 866/17983 completed (loss: 2.4665372371673584, acc: 0.48514851927757263)
[2024-10-21 02:50:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:23][root][INFO] - Training Epoch: 1/2, step 867/17983 completed (loss: 1.1335091590881348, acc: 0.7575757503509521)
[2024-10-21 02:50:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:23][root][INFO] - Training Epoch: 1/2, step 868/17983 completed (loss: 3.1985342502593994, acc: 0.4237288236618042)
[2024-10-21 02:50:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:24][root][INFO] - Training Epoch: 1/2, step 869/17983 completed (loss: 2.503070831298828, acc: 0.4743589758872986)
[2024-10-21 02:50:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:24][root][INFO] - Training Epoch: 1/2, step 870/17983 completed (loss: 2.9232091903686523, acc: 0.44329896569252014)
[2024-10-21 02:50:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:24][root][INFO] - Training Epoch: 1/2, step 871/17983 completed (loss: 1.9106568098068237, acc: 0.5957446694374084)
[2024-10-21 02:50:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:25][root][INFO] - Training Epoch: 1/2, step 872/17983 completed (loss: 3.067204236984253, acc: 0.31460675597190857)
[2024-10-21 02:50:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:25][root][INFO] - Training Epoch: 1/2, step 873/17983 completed (loss: 3.4622080326080322, acc: 0.41818180680274963)
[2024-10-21 02:50:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:26][root][INFO] - Training Epoch: 1/2, step 874/17983 completed (loss: 2.8687222003936768, acc: 0.39393940567970276)
[2024-10-21 02:50:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:26][root][INFO] - Training Epoch: 1/2, step 875/17983 completed (loss: 2.640610456466675, acc: 0.4268292784690857)
[2024-10-21 02:50:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:27][root][INFO] - Training Epoch: 1/2, step 876/17983 completed (loss: 2.8816182613372803, acc: 0.45588234066963196)
[2024-10-21 02:50:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:27][root][INFO] - Training Epoch: 1/2, step 877/17983 completed (loss: 3.065133571624756, acc: 0.3968254029750824)
[2024-10-21 02:50:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:28][root][INFO] - Training Epoch: 1/2, step 878/17983 completed (loss: 2.6441848278045654, acc: 0.390625)
[2024-10-21 02:50:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:28][root][INFO] - Training Epoch: 1/2, step 879/17983 completed (loss: 2.8211233615875244, acc: 0.3764705955982208)
[2024-10-21 02:50:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:28][root][INFO] - Training Epoch: 1/2, step 880/17983 completed (loss: 2.8115499019622803, acc: 0.4749999940395355)
[2024-10-21 02:50:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:29][root][INFO] - Training Epoch: 1/2, step 881/17983 completed (loss: 3.1506741046905518, acc: 0.38181817531585693)
[2024-10-21 02:50:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:29][root][INFO] - Training Epoch: 1/2, step 882/17983 completed (loss: 2.859598398208618, acc: 0.36206895112991333)
[2024-10-21 02:50:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:30][root][INFO] - Training Epoch: 1/2, step 883/17983 completed (loss: 2.129992723464966, acc: 0.5121951103210449)
[2024-10-21 02:50:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:30][root][INFO] - Training Epoch: 1/2, step 884/17983 completed (loss: 2.7412712574005127, acc: 0.4545454680919647)
[2024-10-21 02:50:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:31][root][INFO] - Training Epoch: 1/2, step 885/17983 completed (loss: 2.087228536605835, acc: 0.5476190447807312)
[2024-10-21 02:50:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:31][root][INFO] - Training Epoch: 1/2, step 886/17983 completed (loss: 3.257585287094116, acc: 0.37288135290145874)
[2024-10-21 02:50:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:31][root][INFO] - Training Epoch: 1/2, step 887/17983 completed (loss: 3.0846903324127197, acc: 0.4038461446762085)
[2024-10-21 02:50:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:32][root][INFO] - Training Epoch: 1/2, step 888/17983 completed (loss: 2.1400997638702393, acc: 0.6346153616905212)
[2024-10-21 02:50:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:32][root][INFO] - Training Epoch: 1/2, step 889/17983 completed (loss: 3.1306755542755127, acc: 0.3529411852359772)
[2024-10-21 02:50:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:33][root][INFO] - Training Epoch: 1/2, step 890/17983 completed (loss: 2.596991777420044, acc: 0.5641025900840759)
[2024-10-21 02:50:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:33][root][INFO] - Training Epoch: 1/2, step 891/17983 completed (loss: 2.7917723655700684, acc: 0.365217387676239)
[2024-10-21 02:50:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:33][root][INFO] - Training Epoch: 1/2, step 892/17983 completed (loss: 2.4658265113830566, acc: 0.4861111044883728)
[2024-10-21 02:50:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:34][root][INFO] - Training Epoch: 1/2, step 893/17983 completed (loss: 2.3421852588653564, acc: 0.48148149251937866)
[2024-10-21 02:50:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:34][root][INFO] - Training Epoch: 1/2, step 894/17983 completed (loss: 2.9182422161102295, acc: 0.4324324429035187)
[2024-10-21 02:50:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:35][root][INFO] - Training Epoch: 1/2, step 895/17983 completed (loss: 2.8719747066497803, acc: 0.4637681245803833)
[2024-10-21 02:50:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:35][root][INFO] - Training Epoch: 1/2, step 896/17983 completed (loss: 2.333936929702759, acc: 0.5869565010070801)
[2024-10-21 02:50:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:35][root][INFO] - Training Epoch: 1/2, step 897/17983 completed (loss: 2.256779432296753, acc: 0.44262295961380005)
[2024-10-21 02:50:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:36][root][INFO] - Training Epoch: 1/2, step 898/17983 completed (loss: 2.571859359741211, acc: 0.4367816150188446)
[2024-10-21 02:50:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:36][root][INFO] - Training Epoch: 1/2, step 899/17983 completed (loss: 2.6622636318206787, acc: 0.5277777910232544)
[2024-10-21 02:50:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:37][root][INFO] - Training Epoch: 1/2, step 900/17983 completed (loss: 2.4030344486236572, acc: 0.5106382966041565)
[2024-10-21 02:50:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:37][root][INFO] - Training Epoch: 1/2, step 901/17983 completed (loss: 2.469118595123291, acc: 0.5249999761581421)
[2024-10-21 02:50:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:37][root][INFO] - Training Epoch: 1/2, step 902/17983 completed (loss: 3.0378215312957764, acc: 0.43518519401550293)
[2024-10-21 02:50:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:38][root][INFO] - Training Epoch: 1/2, step 903/17983 completed (loss: 2.9121766090393066, acc: 0.48148149251937866)
[2024-10-21 02:50:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:38][root][INFO] - Training Epoch: 1/2, step 904/17983 completed (loss: 2.80399751663208, acc: 0.30188679695129395)
[2024-10-21 02:50:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:39][root][INFO] - Training Epoch: 1/2, step 905/17983 completed (loss: 2.5081706047058105, acc: 0.5)
[2024-10-21 02:50:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:39][root][INFO] - Training Epoch: 1/2, step 906/17983 completed (loss: 2.979396343231201, acc: 0.3870967626571655)
[2024-10-21 02:50:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:39][root][INFO] - Training Epoch: 1/2, step 907/17983 completed (loss: 2.3464603424072266, acc: 0.4571428596973419)
[2024-10-21 02:50:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:40][root][INFO] - Training Epoch: 1/2, step 908/17983 completed (loss: 3.0843334197998047, acc: 0.40789473056793213)
[2024-10-21 02:50:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:40][root][INFO] - Training Epoch: 1/2, step 909/17983 completed (loss: 2.04630970954895, acc: 0.5675675868988037)
[2024-10-21 02:50:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:41][root][INFO] - Training Epoch: 1/2, step 910/17983 completed (loss: 2.4637277126312256, acc: 0.4912280738353729)
[2024-10-21 02:50:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:41][root][INFO] - Training Epoch: 1/2, step 911/17983 completed (loss: 2.801952362060547, acc: 0.484375)
[2024-10-21 02:50:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:42][root][INFO] - Training Epoch: 1/2, step 912/17983 completed (loss: 3.0093650817871094, acc: 0.373913049697876)
[2024-10-21 02:50:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:42][root][INFO] - Training Epoch: 1/2, step 913/17983 completed (loss: 2.5002269744873047, acc: 0.4909090995788574)
[2024-10-21 02:50:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:42][root][INFO] - Training Epoch: 1/2, step 914/17983 completed (loss: 2.6776976585388184, acc: 0.39344263076782227)
[2024-10-21 02:50:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:43][root][INFO] - Training Epoch: 1/2, step 915/17983 completed (loss: 2.7824602127075195, acc: 0.3720930218696594)
[2024-10-21 02:50:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:43][root][INFO] - Training Epoch: 1/2, step 916/17983 completed (loss: 2.223691701889038, acc: 0.4848484992980957)
[2024-10-21 02:50:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:44][root][INFO] - Training Epoch: 1/2, step 917/17983 completed (loss: 2.6746866703033447, acc: 0.4150943458080292)
[2024-10-21 02:50:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:44][root][INFO] - Training Epoch: 1/2, step 918/17983 completed (loss: 2.3029234409332275, acc: 0.5)
[2024-10-21 02:50:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:44][root][INFO] - Training Epoch: 1/2, step 919/17983 completed (loss: 2.212569236755371, acc: 0.5479452013969421)
[2024-10-21 02:50:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:45][root][INFO] - Training Epoch: 1/2, step 920/17983 completed (loss: 3.2832019329071045, acc: 0.390625)
[2024-10-21 02:50:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:45][root][INFO] - Training Epoch: 1/2, step 921/17983 completed (loss: 3.0756616592407227, acc: 0.3499999940395355)
[2024-10-21 02:50:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:46][root][INFO] - Training Epoch: 1/2, step 922/17983 completed (loss: 2.942579507827759, acc: 0.37704917788505554)
[2024-10-21 02:50:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:46][root][INFO] - Training Epoch: 1/2, step 923/17983 completed (loss: 2.9265828132629395, acc: 0.3469387888908386)
[2024-10-21 02:50:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:46][root][INFO] - Training Epoch: 1/2, step 924/17983 completed (loss: 1.7191643714904785, acc: 0.6888889074325562)
[2024-10-21 02:50:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:47][root][INFO] - Training Epoch: 1/2, step 925/17983 completed (loss: 1.7147401571273804, acc: 0.5806451439857483)
[2024-10-21 02:50:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:47][root][INFO] - Training Epoch: 1/2, step 926/17983 completed (loss: 2.6746625900268555, acc: 0.31578946113586426)
[2024-10-21 02:50:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:48][root][INFO] - Training Epoch: 1/2, step 927/17983 completed (loss: 2.256739377975464, acc: 0.516853928565979)
[2024-10-21 02:50:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:48][root][INFO] - Training Epoch: 1/2, step 928/17983 completed (loss: 2.498523235321045, acc: 0.4262295067310333)
[2024-10-21 02:50:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:48][root][INFO] - Training Epoch: 1/2, step 929/17983 completed (loss: 2.0725061893463135, acc: 0.5789473652839661)
[2024-10-21 02:50:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:49][root][INFO] - Training Epoch: 1/2, step 930/17983 completed (loss: 3.278790235519409, acc: 0.42500001192092896)
[2024-10-21 02:50:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:49][root][INFO] - Training Epoch: 1/2, step 931/17983 completed (loss: 2.3564319610595703, acc: 0.5526315569877625)
[2024-10-21 02:50:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:50][root][INFO] - Training Epoch: 1/2, step 932/17983 completed (loss: 2.1655831336975098, acc: 0.5)
[2024-10-21 02:50:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:50][root][INFO] - Training Epoch: 1/2, step 933/17983 completed (loss: 2.7753653526306152, acc: 0.42465752363204956)
[2024-10-21 02:50:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:51][root][INFO] - Training Epoch: 1/2, step 934/17983 completed (loss: 2.843027353286743, acc: 0.4743589758872986)
[2024-10-21 02:50:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:51][root][INFO] - Training Epoch: 1/2, step 935/17983 completed (loss: 1.5794103145599365, acc: 0.6491228342056274)
[2024-10-21 02:50:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:51][root][INFO] - Training Epoch: 1/2, step 936/17983 completed (loss: 0.8473056554794312, acc: 0.8484848737716675)
[2024-10-21 02:50:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:52][root][INFO] - Training Epoch: 1/2, step 937/17983 completed (loss: 1.8939287662506104, acc: 0.6410256624221802)
[2024-10-21 02:50:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:52][root][INFO] - Training Epoch: 1/2, step 938/17983 completed (loss: 1.917047381401062, acc: 0.6896551847457886)
[2024-10-21 02:50:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:53][root][INFO] - Training Epoch: 1/2, step 939/17983 completed (loss: 2.6772148609161377, acc: 0.4406779706478119)
[2024-10-21 02:50:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:53][root][INFO] - Training Epoch: 1/2, step 940/17983 completed (loss: 3.0928256511688232, acc: 0.41860464215278625)
[2024-10-21 02:50:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:54][root][INFO] - Training Epoch: 1/2, step 941/17983 completed (loss: 3.156604290008545, acc: 0.4471544623374939)
[2024-10-21 02:50:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:54][root][INFO] - Training Epoch: 1/2, step 942/17983 completed (loss: 3.741356134414673, acc: 0.28205129504203796)
[2024-10-21 02:50:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:55][root][INFO] - Training Epoch: 1/2, step 943/17983 completed (loss: 2.523568868637085, acc: 0.4864864945411682)
[2024-10-21 02:50:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:55][root][INFO] - Training Epoch: 1/2, step 944/17983 completed (loss: 2.546238899230957, acc: 0.48148149251937866)
[2024-10-21 02:50:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:55][root][INFO] - Training Epoch: 1/2, step 945/17983 completed (loss: 2.3526461124420166, acc: 0.5384615659713745)
[2024-10-21 02:50:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:56][root][INFO] - Training Epoch: 1/2, step 946/17983 completed (loss: 1.4957891702651978, acc: 0.692307710647583)
[2024-10-21 02:50:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:56][root][INFO] - Training Epoch: 1/2, step 947/17983 completed (loss: 2.420710563659668, acc: 0.4833333194255829)
[2024-10-21 02:50:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:56][root][INFO] - Training Epoch: 1/2, step 948/17983 completed (loss: 2.8988521099090576, acc: 0.34166666865348816)
[2024-10-21 02:50:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:57][root][INFO] - Training Epoch: 1/2, step 949/17983 completed (loss: 2.550442695617676, acc: 0.5096153616905212)
[2024-10-21 02:50:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:57][root][INFO] - Training Epoch: 1/2, step 950/17983 completed (loss: 2.401500940322876, acc: 0.4166666567325592)
[2024-10-21 02:50:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:58][root][INFO] - Training Epoch: 1/2, step 951/17983 completed (loss: 2.1298060417175293, acc: 0.5714285969734192)
[2024-10-21 02:50:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:58][root][INFO] - Training Epoch: 1/2, step 952/17983 completed (loss: 2.3730151653289795, acc: 0.5142857432365417)
[2024-10-21 02:50:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:58][root][INFO] - Training Epoch: 1/2, step 953/17983 completed (loss: 2.8816018104553223, acc: 0.395061731338501)
[2024-10-21 02:50:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:59][root][INFO] - Training Epoch: 1/2, step 954/17983 completed (loss: 2.8399503231048584, acc: 0.4237288236618042)
[2024-10-21 02:50:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:50:59][root][INFO] - Training Epoch: 1/2, step 955/17983 completed (loss: 2.592741012573242, acc: 0.447761207818985)
[2024-10-21 02:51:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:00][root][INFO] - Training Epoch: 1/2, step 956/17983 completed (loss: 1.7869277000427246, acc: 0.5517241358757019)
[2024-10-21 02:51:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:00][root][INFO] - Training Epoch: 1/2, step 957/17983 completed (loss: 2.7038159370422363, acc: 0.4000000059604645)
[2024-10-21 02:51:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:01][root][INFO] - Training Epoch: 1/2, step 958/17983 completed (loss: 3.252704381942749, acc: 0.3333333432674408)
[2024-10-21 02:51:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:01][root][INFO] - Training Epoch: 1/2, step 959/17983 completed (loss: 2.3669748306274414, acc: 0.5494505763053894)
[2024-10-21 02:51:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:02][root][INFO] - Training Epoch: 1/2, step 960/17983 completed (loss: 0.10399902611970901, acc: 1.0)
[2024-10-21 02:51:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:02][root][INFO] - Training Epoch: 1/2, step 961/17983 completed (loss: 2.3119490146636963, acc: 0.5)
[2024-10-21 02:51:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:02][root][INFO] - Training Epoch: 1/2, step 962/17983 completed (loss: 2.6545848846435547, acc: 0.4923076927661896)
[2024-10-21 02:51:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:03][root][INFO] - Training Epoch: 1/2, step 963/17983 completed (loss: 2.9373223781585693, acc: 0.3956044018268585)
[2024-10-21 02:51:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:03][root][INFO] - Training Epoch: 1/2, step 964/17983 completed (loss: 2.1547584533691406, acc: 0.5102040767669678)
[2024-10-21 02:51:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:03][root][INFO] - Training Epoch: 1/2, step 965/17983 completed (loss: 2.5878236293792725, acc: 0.42105263471603394)
[2024-10-21 02:51:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:04][root][INFO] - Training Epoch: 1/2, step 966/17983 completed (loss: 3.0278961658477783, acc: 0.38333332538604736)
[2024-10-21 02:51:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:04][root][INFO] - Training Epoch: 1/2, step 967/17983 completed (loss: 2.0851128101348877, acc: 0.568965494632721)
[2024-10-21 02:51:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:05][root][INFO] - Training Epoch: 1/2, step 968/17983 completed (loss: 2.437208414077759, acc: 0.4939759075641632)
[2024-10-21 02:51:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:05][root][INFO] - Training Epoch: 1/2, step 969/17983 completed (loss: 2.0348055362701416, acc: 0.5636363625526428)
[2024-10-21 02:51:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:05][root][INFO] - Training Epoch: 1/2, step 970/17983 completed (loss: 2.2339015007019043, acc: 0.48275861144065857)
[2024-10-21 02:51:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:06][root][INFO] - Training Epoch: 1/2, step 971/17983 completed (loss: 1.8186147212982178, acc: 0.625)
[2024-10-21 02:51:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:06][root][INFO] - Training Epoch: 1/2, step 972/17983 completed (loss: 2.186800956726074, acc: 0.5531914830207825)
[2024-10-21 02:51:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:07][root][INFO] - Training Epoch: 1/2, step 973/17983 completed (loss: 3.624446392059326, acc: 0.3913043439388275)
[2024-10-21 02:51:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:07][root][INFO] - Training Epoch: 1/2, step 974/17983 completed (loss: 2.8800644874572754, acc: 0.46268656849861145)
[2024-10-21 02:51:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:08][root][INFO] - Training Epoch: 1/2, step 975/17983 completed (loss: 2.050004482269287, acc: 0.5636363625526428)
[2024-10-21 02:51:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:08][root][INFO] - Training Epoch: 1/2, step 976/17983 completed (loss: 2.6461198329925537, acc: 0.446153849363327)
[2024-10-21 02:51:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:09][root][INFO] - Training Epoch: 1/2, step 977/17983 completed (loss: 3.469376802444458, acc: 0.37142857909202576)
[2024-10-21 02:51:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:09][root][INFO] - Training Epoch: 1/2, step 978/17983 completed (loss: 3.2732393741607666, acc: 0.4252873659133911)
[2024-10-21 02:51:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:09][root][INFO] - Training Epoch: 1/2, step 979/17983 completed (loss: 3.0955562591552734, acc: 0.39743590354919434)
[2024-10-21 02:51:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:10][root][INFO] - Training Epoch: 1/2, step 980/17983 completed (loss: 3.43056583404541, acc: 0.4395604431629181)
[2024-10-21 02:51:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:10][root][INFO] - Training Epoch: 1/2, step 981/17983 completed (loss: 2.7080304622650146, acc: 0.5151515007019043)
[2024-10-21 02:51:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:11][root][INFO] - Training Epoch: 1/2, step 982/17983 completed (loss: 2.851114273071289, acc: 0.4444444477558136)
[2024-10-21 02:51:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:11][root][INFO] - Training Epoch: 1/2, step 983/17983 completed (loss: 2.938816785812378, acc: 0.44680851697921753)
[2024-10-21 02:51:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:12][root][INFO] - Training Epoch: 1/2, step 984/17983 completed (loss: 3.365535020828247, acc: 0.36206895112991333)
[2024-10-21 02:51:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:12][root][INFO] - Training Epoch: 1/2, step 985/17983 completed (loss: 3.2657620906829834, acc: 0.36206895112991333)
[2024-10-21 02:51:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:12][root][INFO] - Training Epoch: 1/2, step 986/17983 completed (loss: 2.138801336288452, acc: 0.6363636255264282)
[2024-10-21 02:51:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:13][root][INFO] - Training Epoch: 1/2, step 987/17983 completed (loss: 2.7040703296661377, acc: 0.4912280738353729)
[2024-10-21 02:51:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:13][root][INFO] - Training Epoch: 1/2, step 988/17983 completed (loss: 2.805568218231201, acc: 0.4025973975658417)
[2024-10-21 02:51:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:14][root][INFO] - Training Epoch: 1/2, step 989/17983 completed (loss: 3.3704802989959717, acc: 0.3589743673801422)
[2024-10-21 02:51:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:14][root][INFO] - Training Epoch: 1/2, step 990/17983 completed (loss: 3.2858197689056396, acc: 0.3586956560611725)
[2024-10-21 02:51:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:15][root][INFO] - Training Epoch: 1/2, step 991/17983 completed (loss: 3.2231974601745605, acc: 0.3711340129375458)
[2024-10-21 02:51:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:15][root][INFO] - Training Epoch: 1/2, step 992/17983 completed (loss: 3.167478084564209, acc: 0.4313725531101227)
[2024-10-21 02:51:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:16][root][INFO] - Training Epoch: 1/2, step 993/17983 completed (loss: 1.6952520608901978, acc: 0.6666666865348816)
[2024-10-21 02:51:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:16][root][INFO] - Training Epoch: 1/2, step 994/17983 completed (loss: 2.8354437351226807, acc: 0.47058823704719543)
[2024-10-21 02:51:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:17][root][INFO] - Training Epoch: 1/2, step 995/17983 completed (loss: 3.3479888439178467, acc: 0.3636363744735718)
[2024-10-21 02:51:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:17][root][INFO] - Training Epoch: 1/2, step 996/17983 completed (loss: 3.0204226970672607, acc: 0.3684210479259491)
[2024-10-21 02:51:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:18][root][INFO] - Training Epoch: 1/2, step 997/17983 completed (loss: 2.542283296585083, acc: 0.4285714328289032)
[2024-10-21 02:51:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:18][root][INFO] - Training Epoch: 1/2, step 998/17983 completed (loss: 2.4713382720947266, acc: 0.5735294222831726)
[2024-10-21 02:51:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:18][root][INFO] - Training Epoch: 1/2, step 999/17983 completed (loss: 2.659795045852661, acc: 0.5306122303009033)
[2024-10-21 02:51:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:51:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:52:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:53:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:54:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-21 02:55:3