Warning: llm is not set. Setting it to 'TinyLlama' by default.
speech encoder name: whisper
speech encoder path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt
speech encoder2 name: 
speech encoder2 path: 
llm_path: 
Identifier: 
use_peft: true
use_fp16: 
Final identifier: ami_nbest_whisper_TinyLlama_linear_peft_separate
No checkpoint found in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_nbest_whisper_TinyLlama_linear_peft_separate
ckpt_folder: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_nbest_whisper_TinyLlama_linear_peft_separate/
Resume epoch: 1
Resume step: 0
[2024-11-03 04:24:27][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 2, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_nbest_whisper_TinyLlama_linear_peft_separate', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': False}
[2024-11-03 04:24:27][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-11-03 04:24:27][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'TinyLlama', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/TinyLlama-1.1B-Chat-v1.0', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-11-03 04:24:27][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'ami_nbest_whisper_TinyLlama_linear_peft_separate', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-11-03_04-24-26.txt', 'log_interval': 5}
[2024-11-03 04:25:08][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2024-11-03 04:25:08][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2024-11-03 04:25:08][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2024-11-03 04:25:08][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2024-11-03 04:25:14][slam_llm.utils.train_utils][INFO] - --> Module TinyLlama
[2024-11-03 04:25:14][slam_llm.utils.train_utils][INFO] - --> TinyLlama has 1100.048384 Million params

[2024-11-03 04:25:14][slam_llm.models.slam_model][INFO] - setup peft...
trainable params: 6,307,840 || all params: 1,106,356,224 || trainable%: 0.570145479653396
[2024-11-03 04:25:14][slam_llm.utils.train_utils][INFO] - --> Module TinyLlama
[2024-11-03 04:25:14][slam_llm.utils.train_utils][INFO] - --> TinyLlama has 6.30784 Million params

[2024-11-03 04:25:14][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-11-03 04:25:14][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2024-11-03 04:25:14][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-11-03 04:25:14][slam_llm.utils.train_utils][INFO] - --> asr has 23.61344 Million params

[2024-11-03 04:25:19][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_nbest/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_nbest/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': 'Transcribe speech to text. ', 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'mel', 'mel_size': 128, 'normalize': True}
[2024-11-03 04:25:20][root][INFO] - --> Training Set Length = 108502
[2024-11-03 04:25:20][root][INFO] - --> Validation Set Length = 13098
[2024-11-03 04:25:20][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-03 04:25:20][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-03 04:25:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:25][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-11-03 04:25:28][root][INFO] - Training Epoch: 1/2, step 0/54251 completed (loss: 9.481419563293457, acc: 0.0)
[2024-11-03 04:25:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:28][root][INFO] - Training Epoch: 1/2, step 1/54251 completed (loss: 11.169092178344727, acc: 0.0)
[2024-11-03 04:25:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:29][root][INFO] - Training Epoch: 1/2, step 2/54251 completed (loss: 9.791895866394043, acc: 0.0)
[2024-11-03 04:25:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:29][root][INFO] - Training Epoch: 1/2, step 3/54251 completed (loss: 11.789161682128906, acc: 0.0)
[2024-11-03 04:25:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:30][root][INFO] - Training Epoch: 1/2, step 4/54251 completed (loss: 12.795782089233398, acc: 0.0)
[2024-11-03 04:25:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:30][root][INFO] - Training Epoch: 1/2, step 5/54251 completed (loss: 10.323890686035156, acc: 0.0)
[2024-11-03 04:25:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:31][root][INFO] - Training Epoch: 1/2, step 6/54251 completed (loss: 11.171198844909668, acc: 0.0)
[2024-11-03 04:25:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:31][root][INFO] - Training Epoch: 1/2, step 7/54251 completed (loss: 10.940825462341309, acc: 0.0)
[2024-11-03 04:25:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:32][root][INFO] - Training Epoch: 1/2, step 8/54251 completed (loss: 11.532678604125977, acc: 0.0)
[2024-11-03 04:25:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:32][root][INFO] - Training Epoch: 1/2, step 9/54251 completed (loss: 13.263082504272461, acc: 0.0)
[2024-11-03 04:25:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:33][root][INFO] - Training Epoch: 1/2, step 10/54251 completed (loss: 11.936161994934082, acc: 0.0)
[2024-11-03 04:25:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:33][root][INFO] - Training Epoch: 1/2, step 11/54251 completed (loss: 11.367450714111328, acc: 0.0)
[2024-11-03 04:25:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:34][root][INFO] - Training Epoch: 1/2, step 12/54251 completed (loss: 8.593478202819824, acc: 0.0)
[2024-11-03 04:25:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:34][root][INFO] - Training Epoch: 1/2, step 13/54251 completed (loss: 8.96191120147705, acc: 0.0)
[2024-11-03 04:25:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:35][root][INFO] - Training Epoch: 1/2, step 14/54251 completed (loss: 8.818751335144043, acc: 0.019607843831181526)
[2024-11-03 04:25:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:35][root][INFO] - Training Epoch: 1/2, step 15/54251 completed (loss: 7.625258922576904, acc: 0.0)
[2024-11-03 04:25:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:36][root][INFO] - Training Epoch: 1/2, step 16/54251 completed (loss: 7.196196556091309, acc: 0.13793103396892548)
[2024-11-03 04:25:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:37][root][INFO] - Training Epoch: 1/2, step 17/54251 completed (loss: 9.190094947814941, acc: 0.0)
[2024-11-03 04:25:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:37][root][INFO] - Training Epoch: 1/2, step 18/54251 completed (loss: 6.477564334869385, acc: 0.095238097012043)
[2024-11-03 04:25:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:38][root][INFO] - Training Epoch: 1/2, step 19/54251 completed (loss: 7.294149398803711, acc: 0.0)
[2024-11-03 04:25:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:38][root][INFO] - Training Epoch: 1/2, step 20/54251 completed (loss: 8.426815032958984, acc: 0.0)
[2024-11-03 04:25:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:39][root][INFO] - Training Epoch: 1/2, step 21/54251 completed (loss: 6.142532825469971, acc: 0.21739129722118378)
[2024-11-03 04:25:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:39][root][INFO] - Training Epoch: 1/2, step 22/54251 completed (loss: 6.439481735229492, acc: 0.0)
[2024-11-03 04:25:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:40][root][INFO] - Training Epoch: 1/2, step 23/54251 completed (loss: 5.027228355407715, acc: 0.20000000298023224)
[2024-11-03 04:25:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:40][root][INFO] - Training Epoch: 1/2, step 24/54251 completed (loss: 5.242591857910156, acc: 0.2222222238779068)
[2024-11-03 04:25:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:41][root][INFO] - Training Epoch: 1/2, step 25/54251 completed (loss: 6.453505992889404, acc: 0.07999999821186066)
[2024-11-03 04:25:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:41][root][INFO] - Training Epoch: 1/2, step 26/54251 completed (loss: 4.848957538604736, acc: 0.29411765933036804)
[2024-11-03 04:25:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:42][root][INFO] - Training Epoch: 1/2, step 27/54251 completed (loss: 4.458848476409912, acc: 0.21052631735801697)
[2024-11-03 04:25:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:42][root][INFO] - Training Epoch: 1/2, step 28/54251 completed (loss: 3.8373210430145264, acc: 0.3333333432674408)
[2024-11-03 04:25:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:43][root][INFO] - Training Epoch: 1/2, step 29/54251 completed (loss: 4.783169269561768, acc: 0.375)
[2024-11-03 04:25:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:43][root][INFO] - Training Epoch: 1/2, step 30/54251 completed (loss: 5.166350841522217, acc: 0.23333333432674408)
[2024-11-03 04:25:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:44][root][INFO] - Training Epoch: 1/2, step 31/54251 completed (loss: 2.759122133255005, acc: 0.5)
[2024-11-03 04:25:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:44][root][INFO] - Training Epoch: 1/2, step 32/54251 completed (loss: 3.610551118850708, acc: 0.4444444477558136)
[2024-11-03 04:25:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:45][root][INFO] - Training Epoch: 1/2, step 33/54251 completed (loss: 3.1768105030059814, acc: 0.4444444477558136)
[2024-11-03 04:25:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:45][root][INFO] - Training Epoch: 1/2, step 34/54251 completed (loss: 3.2339282035827637, acc: 0.4893617033958435)
[2024-11-03 04:25:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:46][root][INFO] - Training Epoch: 1/2, step 35/54251 completed (loss: 3.219620704650879, acc: 0.4375)
[2024-11-03 04:25:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:46][root][INFO] - Training Epoch: 1/2, step 36/54251 completed (loss: 3.4821207523345947, acc: 0.4545454680919647)
[2024-11-03 04:25:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:47][root][INFO] - Training Epoch: 1/2, step 37/54251 completed (loss: 3.072301149368286, acc: 0.5555555820465088)
[2024-11-03 04:25:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:47][root][INFO] - Training Epoch: 1/2, step 38/54251 completed (loss: 3.268094062805176, acc: 0.5)
[2024-11-03 04:25:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:48][root][INFO] - Training Epoch: 1/2, step 39/54251 completed (loss: 4.476876258850098, acc: 0.1111111119389534)
[2024-11-03 04:25:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:48][root][INFO] - Training Epoch: 1/2, step 40/54251 completed (loss: 2.9846599102020264, acc: 0.5)
[2024-11-03 04:25:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:49][root][INFO] - Training Epoch: 1/2, step 41/54251 completed (loss: 2.0463433265686035, acc: 0.6744186282157898)
[2024-11-03 04:25:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:49][root][INFO] - Training Epoch: 1/2, step 42/54251 completed (loss: 3.161470651626587, acc: 0.4166666567325592)
[2024-11-03 04:25:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:50][root][INFO] - Training Epoch: 1/2, step 43/54251 completed (loss: 2.6684813499450684, acc: 0.6666666865348816)
[2024-11-03 04:25:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:50][root][INFO] - Training Epoch: 1/2, step 44/54251 completed (loss: 3.6785216331481934, acc: 0.3571428656578064)
[2024-11-03 04:25:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:51][root][INFO] - Training Epoch: 1/2, step 45/54251 completed (loss: 3.478550910949707, acc: 0.5384615659713745)
[2024-11-03 04:25:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:51][root][INFO] - Training Epoch: 1/2, step 46/54251 completed (loss: 2.5386016368865967, acc: 0.4761904776096344)
[2024-11-03 04:25:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:52][root][INFO] - Training Epoch: 1/2, step 47/54251 completed (loss: 3.2453453540802, acc: 0.1666666716337204)
[2024-11-03 04:25:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:52][root][INFO] - Training Epoch: 1/2, step 48/54251 completed (loss: 4.593715190887451, acc: 0.3499999940395355)
[2024-11-03 04:25:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:53][root][INFO] - Training Epoch: 1/2, step 49/54251 completed (loss: 2.6637685298919678, acc: 0.5625)
[2024-11-03 04:25:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:53][root][INFO] - Training Epoch: 1/2, step 50/54251 completed (loss: 4.153360843658447, acc: 0.25)
[2024-11-03 04:25:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:54][root][INFO] - Training Epoch: 1/2, step 51/54251 completed (loss: 2.5506694316864014, acc: 0.6000000238418579)
[2024-11-03 04:25:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:54][root][INFO] - Training Epoch: 1/2, step 52/54251 completed (loss: 2.0040245056152344, acc: 0.6470588445663452)
[2024-11-03 04:25:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:55][root][INFO] - Training Epoch: 1/2, step 53/54251 completed (loss: 3.109929084777832, acc: 0.5)
[2024-11-03 04:25:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:56][root][INFO] - Training Epoch: 1/2, step 54/54251 completed (loss: 1.9698989391326904, acc: 0.6000000238418579)
[2024-11-03 04:25:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:56][root][INFO] - Training Epoch: 1/2, step 55/54251 completed (loss: 3.9290335178375244, acc: 0.3333333432674408)
[2024-11-03 04:25:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:57][root][INFO] - Training Epoch: 1/2, step 56/54251 completed (loss: 2.0303452014923096, acc: 0.5853658318519592)
[2024-11-03 04:25:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:57][root][INFO] - Training Epoch: 1/2, step 57/54251 completed (loss: 3.033777952194214, acc: 0.25)
[2024-11-03 04:25:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:58][root][INFO] - Training Epoch: 1/2, step 58/54251 completed (loss: 1.8259207010269165, acc: 0.625)
[2024-11-03 04:25:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:58][root][INFO] - Training Epoch: 1/2, step 59/54251 completed (loss: 2.8507494926452637, acc: 0.6060606241226196)
[2024-11-03 04:25:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:59][root][INFO] - Training Epoch: 1/2, step 60/54251 completed (loss: 2.986830949783325, acc: 0.5416666865348816)
[2024-11-03 04:25:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:25:59][root][INFO] - Training Epoch: 1/2, step 61/54251 completed (loss: 1.6090909242630005, acc: 0.7105262875556946)
[2024-11-03 04:25:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:00][root][INFO] - Training Epoch: 1/2, step 62/54251 completed (loss: 3.4581007957458496, acc: 0.27272728085517883)
[2024-11-03 04:26:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:00][root][INFO] - Training Epoch: 1/2, step 63/54251 completed (loss: 4.196242332458496, acc: 0.20000000298023224)
[2024-11-03 04:26:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:01][root][INFO] - Training Epoch: 1/2, step 64/54251 completed (loss: 5.868715763092041, acc: 0.20000000298023224)
[2024-11-03 04:26:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:01][root][INFO] - Training Epoch: 1/2, step 65/54251 completed (loss: 2.451202869415283, acc: 0.6515151262283325)
[2024-11-03 04:26:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:02][root][INFO] - Training Epoch: 1/2, step 66/54251 completed (loss: 2.5764923095703125, acc: 0.4285714328289032)
[2024-11-03 04:26:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:02][root][INFO] - Training Epoch: 1/2, step 67/54251 completed (loss: 3.1951563358306885, acc: 0.3684210479259491)
[2024-11-03 04:26:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:03][root][INFO] - Training Epoch: 1/2, step 68/54251 completed (loss: 2.6256463527679443, acc: 0.375)
[2024-11-03 04:26:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:03][root][INFO] - Training Epoch: 1/2, step 69/54251 completed (loss: 3.330838918685913, acc: 0.5625)
[2024-11-03 04:26:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:04][root][INFO] - Training Epoch: 1/2, step 70/54251 completed (loss: 1.9827022552490234, acc: 0.6666666865348816)
[2024-11-03 04:26:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:04][root][INFO] - Training Epoch: 1/2, step 71/54251 completed (loss: 3.000649929046631, acc: 0.4642857015132904)
[2024-11-03 04:26:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:05][root][INFO] - Training Epoch: 1/2, step 72/54251 completed (loss: 1.8602179288864136, acc: 0.625)
[2024-11-03 04:26:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:05][root][INFO] - Training Epoch: 1/2, step 73/54251 completed (loss: 3.699950695037842, acc: 0.4117647111415863)
[2024-11-03 04:26:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:06][root][INFO] - Training Epoch: 1/2, step 74/54251 completed (loss: 3.4024171829223633, acc: 0.4390243887901306)
[2024-11-03 04:26:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:06][root][INFO] - Training Epoch: 1/2, step 75/54251 completed (loss: 2.3105437755584717, acc: 0.6666666865348816)
[2024-11-03 04:26:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:07][root][INFO] - Training Epoch: 1/2, step 76/54251 completed (loss: 1.685815453529358, acc: 0.65625)
[2024-11-03 04:26:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:07][root][INFO] - Training Epoch: 1/2, step 77/54251 completed (loss: 4.0091471672058105, acc: 0.2857142984867096)
[2024-11-03 04:26:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:08][root][INFO] - Training Epoch: 1/2, step 78/54251 completed (loss: 4.414080619812012, acc: 0.375)
[2024-11-03 04:26:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:08][root][INFO] - Training Epoch: 1/2, step 79/54251 completed (loss: 3.1506242752075195, acc: 0.5625)
[2024-11-03 04:26:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:09][root][INFO] - Training Epoch: 1/2, step 80/54251 completed (loss: 2.189366102218628, acc: 0.6666666865348816)
[2024-11-03 04:26:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:09][root][INFO] - Training Epoch: 1/2, step 81/54251 completed (loss: 0.6744914054870605, acc: 0.8947368264198303)
[2024-11-03 04:26:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:10][root][INFO] - Training Epoch: 1/2, step 82/54251 completed (loss: 1.2961437702178955, acc: 0.7142857313156128)
[2024-11-03 04:26:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:10][root][INFO] - Training Epoch: 1/2, step 83/54251 completed (loss: 1.7870582342147827, acc: 0.6399999856948853)
[2024-11-03 04:26:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:11][root][INFO] - Training Epoch: 1/2, step 84/54251 completed (loss: 5.239175796508789, acc: 0.3333333432674408)
[2024-11-03 04:26:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:11][root][INFO] - Training Epoch: 1/2, step 85/54251 completed (loss: 2.847895622253418, acc: 0.5555555820465088)
[2024-11-03 04:26:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:12][root][INFO] - Training Epoch: 1/2, step 86/54251 completed (loss: 0.6973473429679871, acc: 0.9166666865348816)
[2024-11-03 04:26:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:12][root][INFO] - Training Epoch: 1/2, step 87/54251 completed (loss: 2.230586290359497, acc: 0.6470588445663452)
[2024-11-03 04:26:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:13][root][INFO] - Training Epoch: 1/2, step 88/54251 completed (loss: 2.129004716873169, acc: 0.6666666865348816)
[2024-11-03 04:26:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:13][root][INFO] - Training Epoch: 1/2, step 89/54251 completed (loss: 3.0801732540130615, acc: 0.5)
[2024-11-03 04:26:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:14][root][INFO] - Training Epoch: 1/2, step 90/54251 completed (loss: 1.2274253368377686, acc: 0.7333333492279053)
[2024-11-03 04:26:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:14][root][INFO] - Training Epoch: 1/2, step 91/54251 completed (loss: 1.2787184715270996, acc: 0.7931034564971924)
[2024-11-03 04:26:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:15][root][INFO] - Training Epoch: 1/2, step 92/54251 completed (loss: 1.5804117918014526, acc: 0.6578947305679321)
[2024-11-03 04:26:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:15][root][INFO] - Training Epoch: 1/2, step 93/54251 completed (loss: 2.7351479530334473, acc: 0.375)
[2024-11-03 04:26:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:16][root][INFO] - Training Epoch: 1/2, step 94/54251 completed (loss: 1.9615949392318726, acc: 0.7142857313156128)
[2024-11-03 04:26:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:16][root][INFO] - Training Epoch: 1/2, step 95/54251 completed (loss: 1.7606775760650635, acc: 0.7317073345184326)
[2024-11-03 04:26:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:17][root][INFO] - Training Epoch: 1/2, step 96/54251 completed (loss: 1.8903160095214844, acc: 0.6288659572601318)
[2024-11-03 04:26:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:17][root][INFO] - Training Epoch: 1/2, step 97/54251 completed (loss: 4.219389915466309, acc: 0.21875)
[2024-11-03 04:26:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:18][root][INFO] - Training Epoch: 1/2, step 98/54251 completed (loss: 2.6566786766052246, acc: 0.6000000238418579)
[2024-11-03 04:26:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:18][root][INFO] - Training Epoch: 1/2, step 99/54251 completed (loss: 1.7127865552902222, acc: 0.625)
[2024-11-03 04:26:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:19][root][INFO] - Training Epoch: 1/2, step 100/54251 completed (loss: 4.637126922607422, acc: 0.4000000059604645)
[2024-11-03 04:26:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:19][root][INFO] - Training Epoch: 1/2, step 101/54251 completed (loss: 1.6239672899246216, acc: 0.6428571343421936)
[2024-11-03 04:26:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:20][root][INFO] - Training Epoch: 1/2, step 102/54251 completed (loss: 2.1069753170013428, acc: 0.6666666865348816)
[2024-11-03 04:26:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:21][root][INFO] - Training Epoch: 1/2, step 103/54251 completed (loss: 3.076333522796631, acc: 0.6363636255264282)
[2024-11-03 04:26:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:21][root][INFO] - Training Epoch: 1/2, step 104/54251 completed (loss: 1.8151134252548218, acc: 0.6071428656578064)
[2024-11-03 04:26:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:22][root][INFO] - Training Epoch: 1/2, step 105/54251 completed (loss: 0.696940004825592, acc: 0.8529411554336548)
[2024-11-03 04:26:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:22][root][INFO] - Training Epoch: 1/2, step 106/54251 completed (loss: 0.7342525124549866, acc: 0.8235294222831726)
[2024-11-03 04:26:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:23][root][INFO] - Training Epoch: 1/2, step 107/54251 completed (loss: 1.1704981327056885, acc: 0.800000011920929)
[2024-11-03 04:26:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:23][root][INFO] - Training Epoch: 1/2, step 108/54251 completed (loss: 1.693975806236267, acc: 0.6000000238418579)
[2024-11-03 04:26:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:24][root][INFO] - Training Epoch: 1/2, step 109/54251 completed (loss: 1.5202295780181885, acc: 0.875)
[2024-11-03 04:26:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:24][root][INFO] - Training Epoch: 1/2, step 110/54251 completed (loss: 1.0777769088745117, acc: 0.7894737124443054)
[2024-11-03 04:26:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:25][root][INFO] - Training Epoch: 1/2, step 111/54251 completed (loss: 0.9430230855941772, acc: 0.8333333134651184)
[2024-11-03 04:26:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:25][root][INFO] - Training Epoch: 1/2, step 112/54251 completed (loss: 2.7689836025238037, acc: 0.6000000238418579)
[2024-11-03 04:26:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:25][root][INFO] - Training Epoch: 1/2, step 113/54251 completed (loss: 5.259043216705322, acc: 0.3076923191547394)
[2024-11-03 04:26:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:26][root][INFO] - Training Epoch: 1/2, step 114/54251 completed (loss: 2.289233446121216, acc: 0.6000000238418579)
[2024-11-03 04:26:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:26][root][INFO] - Training Epoch: 1/2, step 115/54251 completed (loss: 0.9904932379722595, acc: 0.8275862336158752)
[2024-11-03 04:26:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:27][root][INFO] - Training Epoch: 1/2, step 116/54251 completed (loss: 2.4437289237976074, acc: 0.6071428656578064)
[2024-11-03 04:26:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:27][root][INFO] - Training Epoch: 1/2, step 117/54251 completed (loss: 1.9830974340438843, acc: 0.550000011920929)
[2024-11-03 04:26:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:28][root][INFO] - Training Epoch: 1/2, step 118/54251 completed (loss: 3.8204452991485596, acc: 0.3333333432674408)
[2024-11-03 04:26:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:28][root][INFO] - Training Epoch: 1/2, step 119/54251 completed (loss: 2.650075912475586, acc: 0.4285714328289032)
[2024-11-03 04:26:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:29][root][INFO] - Training Epoch: 1/2, step 120/54251 completed (loss: 0.7617100477218628, acc: 0.8999999761581421)
[2024-11-03 04:26:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:29][root][INFO] - Training Epoch: 1/2, step 121/54251 completed (loss: 1.2987141609191895, acc: 0.7234042286872864)
[2024-11-03 04:26:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:30][root][INFO] - Training Epoch: 1/2, step 122/54251 completed (loss: 1.7347859144210815, acc: 0.6984127163887024)
[2024-11-03 04:26:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:30][root][INFO] - Training Epoch: 1/2, step 123/54251 completed (loss: 2.0104219913482666, acc: 0.6428571343421936)
[2024-11-03 04:26:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:31][root][INFO] - Training Epoch: 1/2, step 124/54251 completed (loss: 2.488003730773926, acc: 0.5789473652839661)
[2024-11-03 04:26:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:31][root][INFO] - Training Epoch: 1/2, step 125/54251 completed (loss: 2.7708117961883545, acc: 0.5142857432365417)
[2024-11-03 04:26:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:32][root][INFO] - Training Epoch: 1/2, step 126/54251 completed (loss: 1.9004147052764893, acc: 0.692307710647583)
[2024-11-03 04:26:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:32][root][INFO] - Training Epoch: 1/2, step 127/54251 completed (loss: 4.705945014953613, acc: 0.1621621549129486)
[2024-11-03 04:26:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:33][root][INFO] - Training Epoch: 1/2, step 128/54251 completed (loss: 1.0050655603408813, acc: 0.75)
[2024-11-03 04:26:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:33][root][INFO] - Training Epoch: 1/2, step 129/54251 completed (loss: 1.1744413375854492, acc: 0.7777777910232544)
[2024-11-03 04:26:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:34][root][INFO] - Training Epoch: 1/2, step 130/54251 completed (loss: 3.229810953140259, acc: 0.5116279125213623)
[2024-11-03 04:26:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:34][root][INFO] - Training Epoch: 1/2, step 131/54251 completed (loss: 2.8150060176849365, acc: 0.5555555820465088)
[2024-11-03 04:26:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:35][root][INFO] - Training Epoch: 1/2, step 132/54251 completed (loss: 2.555819272994995, acc: 0.6071428656578064)
[2024-11-03 04:26:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:35][root][INFO] - Training Epoch: 1/2, step 133/54251 completed (loss: 0.891869306564331, acc: 0.8333333134651184)
[2024-11-03 04:26:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:36][root][INFO] - Training Epoch: 1/2, step 134/54251 completed (loss: 1.9899054765701294, acc: 0.7307692170143127)
[2024-11-03 04:26:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:36][root][INFO] - Training Epoch: 1/2, step 135/54251 completed (loss: 1.2150177955627441, acc: 0.800000011920929)
[2024-11-03 04:26:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:37][root][INFO] - Training Epoch: 1/2, step 136/54251 completed (loss: 3.2204020023345947, acc: 0.5454545617103577)
[2024-11-03 04:26:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:37][root][INFO] - Training Epoch: 1/2, step 137/54251 completed (loss: 2.064814329147339, acc: 0.5806451439857483)
[2024-11-03 04:26:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:38][root][INFO] - Training Epoch: 1/2, step 138/54251 completed (loss: 2.0393528938293457, acc: 0.5714285969734192)
[2024-11-03 04:26:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:38][root][INFO] - Training Epoch: 1/2, step 139/54251 completed (loss: 1.2324373722076416, acc: 0.7727272510528564)
[2024-11-03 04:26:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:39][root][INFO] - Training Epoch: 1/2, step 140/54251 completed (loss: 1.0334045886993408, acc: 0.8333333134651184)
[2024-11-03 04:26:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:39][root][INFO] - Training Epoch: 1/2, step 141/54251 completed (loss: 1.9981763362884521, acc: 0.6756756901741028)
[2024-11-03 04:26:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:40][root][INFO] - Training Epoch: 1/2, step 142/54251 completed (loss: 1.7723413705825806, acc: 0.7307692170143127)
[2024-11-03 04:26:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:40][root][INFO] - Training Epoch: 1/2, step 143/54251 completed (loss: 1.5284696817398071, acc: 0.6785714030265808)
[2024-11-03 04:26:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:41][root][INFO] - Training Epoch: 1/2, step 144/54251 completed (loss: 1.8266425132751465, acc: 0.5862069129943848)
[2024-11-03 04:26:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:41][root][INFO] - Training Epoch: 1/2, step 145/54251 completed (loss: 1.741594672203064, acc: 0.6756756901741028)
[2024-11-03 04:26:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:42][root][INFO] - Training Epoch: 1/2, step 146/54251 completed (loss: 0.8958945274353027, acc: 0.7142857313156128)
[2024-11-03 04:26:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:42][root][INFO] - Training Epoch: 1/2, step 147/54251 completed (loss: 4.129297733306885, acc: 0.4615384638309479)
[2024-11-03 04:26:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:43][root][INFO] - Training Epoch: 1/2, step 148/54251 completed (loss: 1.8394997119903564, acc: 0.375)
[2024-11-03 04:26:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:43][root][INFO] - Training Epoch: 1/2, step 149/54251 completed (loss: 0.7781442403793335, acc: 0.8510638475418091)
[2024-11-03 04:26:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:44][root][INFO] - Training Epoch: 1/2, step 150/54251 completed (loss: 2.852027177810669, acc: 0.3333333432674408)
[2024-11-03 04:26:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:44][root][INFO] - Training Epoch: 1/2, step 151/54251 completed (loss: 2.64168119430542, acc: 0.5789473652839661)
[2024-11-03 04:26:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:45][root][INFO] - Training Epoch: 1/2, step 152/54251 completed (loss: 1.7986257076263428, acc: 0.6190476417541504)
[2024-11-03 04:26:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:45][root][INFO] - Training Epoch: 1/2, step 153/54251 completed (loss: 1.6401581764221191, acc: 0.738095223903656)
[2024-11-03 04:26:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:46][root][INFO] - Training Epoch: 1/2, step 154/54251 completed (loss: 0.6745133399963379, acc: 0.8333333134651184)
[2024-11-03 04:26:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:46][root][INFO] - Training Epoch: 1/2, step 155/54251 completed (loss: 1.2275382280349731, acc: 0.7884615659713745)
[2024-11-03 04:26:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:47][root][INFO] - Training Epoch: 1/2, step 156/54251 completed (loss: 2.41825532913208, acc: 0.8571428656578064)
[2024-11-03 04:26:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:47][root][INFO] - Training Epoch: 1/2, step 157/54251 completed (loss: 2.6987926959991455, acc: 0.5593220591545105)
[2024-11-03 04:26:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:48][root][INFO] - Training Epoch: 1/2, step 158/54251 completed (loss: 2.061654567718506, acc: 0.5555555820465088)
[2024-11-03 04:26:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:48][root][INFO] - Training Epoch: 1/2, step 159/54251 completed (loss: 1.7389986515045166, acc: 0.738095223903656)
[2024-11-03 04:26:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:49][root][INFO] - Training Epoch: 1/2, step 160/54251 completed (loss: 1.190611481666565, acc: 0.800000011920929)
[2024-11-03 04:26:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:49][root][INFO] - Training Epoch: 1/2, step 161/54251 completed (loss: 0.9663881063461304, acc: 0.7857142686843872)
[2024-11-03 04:26:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:50][root][INFO] - Training Epoch: 1/2, step 162/54251 completed (loss: 1.0804331302642822, acc: 0.7931034564971924)
[2024-11-03 04:26:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:50][root][INFO] - Training Epoch: 1/2, step 163/54251 completed (loss: 3.9214224815368652, acc: 0.4285714328289032)
[2024-11-03 04:26:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:51][root][INFO] - Training Epoch: 1/2, step 164/54251 completed (loss: 0.6177116632461548, acc: 0.9130434989929199)
[2024-11-03 04:26:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:51][root][INFO] - Training Epoch: 1/2, step 165/54251 completed (loss: 0.6418893933296204, acc: 1.0)
[2024-11-03 04:26:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:52][root][INFO] - Training Epoch: 1/2, step 166/54251 completed (loss: 1.2511308193206787, acc: 0.7704917788505554)
[2024-11-03 04:26:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:52][root][INFO] - Training Epoch: 1/2, step 167/54251 completed (loss: 2.986525774002075, acc: 0.4888888895511627)
[2024-11-03 04:26:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:53][root][INFO] - Training Epoch: 1/2, step 168/54251 completed (loss: 0.9193120002746582, acc: 0.8421052694320679)
[2024-11-03 04:26:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:54][root][INFO] - Training Epoch: 1/2, step 169/54251 completed (loss: 1.6157259941101074, acc: 0.4545454680919647)
[2024-11-03 04:26:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:54][root][INFO] - Training Epoch: 1/2, step 170/54251 completed (loss: 1.7060271501541138, acc: 0.5833333134651184)
[2024-11-03 04:26:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:55][root][INFO] - Training Epoch: 1/2, step 171/54251 completed (loss: 2.815702199935913, acc: 0.4722222089767456)
[2024-11-03 04:26:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:55][root][INFO] - Training Epoch: 1/2, step 172/54251 completed (loss: 1.697357177734375, acc: 0.5862069129943848)
[2024-11-03 04:26:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:56][root][INFO] - Training Epoch: 1/2, step 173/54251 completed (loss: 1.5897910594940186, acc: 0.6499999761581421)
[2024-11-03 04:26:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:56][root][INFO] - Training Epoch: 1/2, step 174/54251 completed (loss: 1.2219778299331665, acc: 0.7666666507720947)
[2024-11-03 04:26:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:57][root][INFO] - Training Epoch: 1/2, step 175/54251 completed (loss: 3.2065558433532715, acc: 0.45945945382118225)
[2024-11-03 04:26:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:57][root][INFO] - Training Epoch: 1/2, step 176/54251 completed (loss: 1.3495216369628906, acc: 0.6875)
[2024-11-03 04:26:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:58][root][INFO] - Training Epoch: 1/2, step 177/54251 completed (loss: 2.0374343395233154, acc: 0.5384615659713745)
[2024-11-03 04:26:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:58][root][INFO] - Training Epoch: 1/2, step 178/54251 completed (loss: 3.574779987335205, acc: 0.4000000059604645)
[2024-11-03 04:26:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:59][root][INFO] - Training Epoch: 1/2, step 179/54251 completed (loss: 1.297255039215088, acc: 0.8399999737739563)
[2024-11-03 04:26:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:26:59][root][INFO] - Training Epoch: 1/2, step 180/54251 completed (loss: 2.500417947769165, acc: 0.5853658318519592)
[2024-11-03 04:26:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:00][root][INFO] - Training Epoch: 1/2, step 181/54251 completed (loss: 2.471684694290161, acc: 0.4848484992980957)
[2024-11-03 04:27:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:00][root][INFO] - Training Epoch: 1/2, step 182/54251 completed (loss: 2.431074619293213, acc: 0.5555555820465088)
[2024-11-03 04:27:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:01][root][INFO] - Training Epoch: 1/2, step 183/54251 completed (loss: 1.869330883026123, acc: 0.688524603843689)
[2024-11-03 04:27:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:01][root][INFO] - Training Epoch: 1/2, step 184/54251 completed (loss: 0.9440670013427734, acc: 0.7941176295280457)
[2024-11-03 04:27:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:02][root][INFO] - Training Epoch: 1/2, step 185/54251 completed (loss: 1.4371930360794067, acc: 0.695652186870575)
[2024-11-03 04:27:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:02][root][INFO] - Training Epoch: 1/2, step 186/54251 completed (loss: 3.124016284942627, acc: 0.5555555820465088)
[2024-11-03 04:27:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:03][root][INFO] - Training Epoch: 1/2, step 187/54251 completed (loss: 0.790109395980835, acc: 0.7222222089767456)
[2024-11-03 04:27:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:03][root][INFO] - Training Epoch: 1/2, step 188/54251 completed (loss: 1.2751129865646362, acc: 0.692307710647583)
[2024-11-03 04:27:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:04][root][INFO] - Training Epoch: 1/2, step 189/54251 completed (loss: 3.0550239086151123, acc: 0.46000000834465027)
[2024-11-03 04:27:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:04][root][INFO] - Training Epoch: 1/2, step 190/54251 completed (loss: 0.6600565910339355, acc: 0.8571428656578064)
[2024-11-03 04:27:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:05][root][INFO] - Training Epoch: 1/2, step 191/54251 completed (loss: 1.5633299350738525, acc: 0.6842105388641357)
[2024-11-03 04:27:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:05][root][INFO] - Training Epoch: 1/2, step 192/54251 completed (loss: 1.0668116807937622, acc: 0.8275862336158752)
[2024-11-03 04:27:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:06][root][INFO] - Training Epoch: 1/2, step 193/54251 completed (loss: 3.7844948768615723, acc: 0.375)
[2024-11-03 04:27:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:06][root][INFO] - Training Epoch: 1/2, step 194/54251 completed (loss: 0.8960862755775452, acc: 0.8333333134651184)
[2024-11-03 04:27:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:07][root][INFO] - Training Epoch: 1/2, step 195/54251 completed (loss: 3.45204496383667, acc: 0.4761904776096344)
[2024-11-03 04:27:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:07][root][INFO] - Training Epoch: 1/2, step 196/54251 completed (loss: 2.3186028003692627, acc: 0.4000000059604645)
[2024-11-03 04:27:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:08][root][INFO] - Training Epoch: 1/2, step 197/54251 completed (loss: 1.4662671089172363, acc: 0.7083333134651184)
[2024-11-03 04:27:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:08][root][INFO] - Training Epoch: 1/2, step 198/54251 completed (loss: 0.9183630347251892, acc: 0.849056601524353)
[2024-11-03 04:27:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:09][root][INFO] - Training Epoch: 1/2, step 199/54251 completed (loss: 5.203125476837158, acc: 0.190476194024086)
[2024-11-03 04:27:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:09][root][INFO] - Training Epoch: 1/2, step 200/54251 completed (loss: 1.8586516380310059, acc: 0.6000000238418579)
[2024-11-03 04:27:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:10][root][INFO] - Training Epoch: 1/2, step 201/54251 completed (loss: 1.377593755722046, acc: 0.8666666746139526)
[2024-11-03 04:27:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:10][root][INFO] - Training Epoch: 1/2, step 202/54251 completed (loss: 1.1237770318984985, acc: 0.7586206793785095)
[2024-11-03 04:27:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:11][root][INFO] - Training Epoch: 1/2, step 203/54251 completed (loss: 0.4546677768230438, acc: 0.8333333134651184)
[2024-11-03 04:27:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:11][root][INFO] - Training Epoch: 1/2, step 204/54251 completed (loss: 0.06604085862636566, acc: 1.0)
[2024-11-03 04:27:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:12][root][INFO] - Training Epoch: 1/2, step 205/54251 completed (loss: 1.8031543493270874, acc: 0.6666666865348816)
[2024-11-03 04:27:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:12][root][INFO] - Training Epoch: 1/2, step 206/54251 completed (loss: 1.9820321798324585, acc: 0.6399999856948853)
[2024-11-03 04:27:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:13][root][INFO] - Training Epoch: 1/2, step 207/54251 completed (loss: 1.048343300819397, acc: 0.7333333492279053)
[2024-11-03 04:27:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:13][root][INFO] - Training Epoch: 1/2, step 208/54251 completed (loss: 2.6179239749908447, acc: 0.5)
[2024-11-03 04:27:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:14][root][INFO] - Training Epoch: 1/2, step 209/54251 completed (loss: 1.3997355699539185, acc: 0.8181818127632141)
[2024-11-03 04:27:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:14][root][INFO] - Training Epoch: 1/2, step 210/54251 completed (loss: 1.9315283298492432, acc: 0.675000011920929)
[2024-11-03 04:27:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:15][root][INFO] - Training Epoch: 1/2, step 211/54251 completed (loss: 3.7138147354125977, acc: 0.47058823704719543)
[2024-11-03 04:27:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:15][root][INFO] - Training Epoch: 1/2, step 212/54251 completed (loss: 0.8016327619552612, acc: 0.7307692170143127)
[2024-11-03 04:27:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:16][root][INFO] - Training Epoch: 1/2, step 213/54251 completed (loss: 1.8242157697677612, acc: 0.7272727489471436)
[2024-11-03 04:27:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:16][root][INFO] - Training Epoch: 1/2, step 214/54251 completed (loss: 2.77891206741333, acc: 0.52173912525177)
[2024-11-03 04:27:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:17][root][INFO] - Training Epoch: 1/2, step 215/54251 completed (loss: 1.9702266454696655, acc: 0.6875)
[2024-11-03 04:27:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:17][root][INFO] - Training Epoch: 1/2, step 216/54251 completed (loss: 1.7723196744918823, acc: 0.6206896305084229)
[2024-11-03 04:27:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:18][root][INFO] - Training Epoch: 1/2, step 217/54251 completed (loss: 1.2672103643417358, acc: 0.6666666865348816)
[2024-11-03 04:27:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:18][root][INFO] - Training Epoch: 1/2, step 218/54251 completed (loss: 0.8952996730804443, acc: 0.7222222089767456)
[2024-11-03 04:27:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:19][root][INFO] - Training Epoch: 1/2, step 219/54251 completed (loss: 3.4920079708099365, acc: 0.5714285969734192)
[2024-11-03 04:27:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:19][root][INFO] - Training Epoch: 1/2, step 220/54251 completed (loss: 2.143134355545044, acc: 0.5882353186607361)
[2024-11-03 04:27:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:20][root][INFO] - Training Epoch: 1/2, step 221/54251 completed (loss: 2.398951530456543, acc: 0.59375)
[2024-11-03 04:27:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:20][root][INFO] - Training Epoch: 1/2, step 222/54251 completed (loss: 1.9232690334320068, acc: 0.6666666865348816)
[2024-11-03 04:27:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:21][root][INFO] - Training Epoch: 1/2, step 223/54251 completed (loss: 1.5573288202285767, acc: 0.7291666865348816)
[2024-11-03 04:27:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:21][root][INFO] - Training Epoch: 1/2, step 224/54251 completed (loss: 3.5134031772613525, acc: 0.4444444477558136)
[2024-11-03 04:27:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:22][root][INFO] - Training Epoch: 1/2, step 225/54251 completed (loss: 1.4969828128814697, acc: 0.7666666507720947)
[2024-11-03 04:27:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:22][root][INFO] - Training Epoch: 1/2, step 226/54251 completed (loss: 2.347364664077759, acc: 0.6315789222717285)
[2024-11-03 04:27:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:23][root][INFO] - Training Epoch: 1/2, step 227/54251 completed (loss: 2.2563366889953613, acc: 0.5517241358757019)
[2024-11-03 04:27:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:23][root][INFO] - Training Epoch: 1/2, step 228/54251 completed (loss: 0.863008439540863, acc: 0.8181818127632141)
[2024-11-03 04:27:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:24][root][INFO] - Training Epoch: 1/2, step 229/54251 completed (loss: 1.773719072341919, acc: 0.6190476417541504)
[2024-11-03 04:27:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:24][root][INFO] - Training Epoch: 1/2, step 230/54251 completed (loss: 0.7925670742988586, acc: 0.8333333134651184)
[2024-11-03 04:27:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:25][root][INFO] - Training Epoch: 1/2, step 231/54251 completed (loss: 1.001823902130127, acc: 0.7777777910232544)
[2024-11-03 04:27:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:25][root][INFO] - Training Epoch: 1/2, step 232/54251 completed (loss: 1.332004427909851, acc: 0.7142857313156128)
[2024-11-03 04:27:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:26][root][INFO] - Training Epoch: 1/2, step 233/54251 completed (loss: 1.3249164819717407, acc: 0.739130437374115)
[2024-11-03 04:27:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:26][root][INFO] - Training Epoch: 1/2, step 234/54251 completed (loss: 1.479253888130188, acc: 0.75)
[2024-11-03 04:27:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:27][root][INFO] - Training Epoch: 1/2, step 235/54251 completed (loss: 0.5807284712791443, acc: 0.7777777910232544)
[2024-11-03 04:27:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:27][root][INFO] - Training Epoch: 1/2, step 236/54251 completed (loss: 0.658568263053894, acc: 0.8333333134651184)
[2024-11-03 04:27:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:28][root][INFO] - Training Epoch: 1/2, step 237/54251 completed (loss: 1.347316861152649, acc: 0.6363636255264282)
[2024-11-03 04:27:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:28][root][INFO] - Training Epoch: 1/2, step 238/54251 completed (loss: 4.130974292755127, acc: 0.25)
[2024-11-03 04:27:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:29][root][INFO] - Training Epoch: 1/2, step 239/54251 completed (loss: 1.4803696870803833, acc: 0.692307710647583)
[2024-11-03 04:27:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:29][root][INFO] - Training Epoch: 1/2, step 240/54251 completed (loss: 1.748590350151062, acc: 0.7272727489471436)
[2024-11-03 04:27:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:30][root][INFO] - Training Epoch: 1/2, step 241/54251 completed (loss: 1.6045387983322144, acc: 0.695652186870575)
[2024-11-03 04:27:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:30][root][INFO] - Training Epoch: 1/2, step 242/54251 completed (loss: 1.1541845798492432, acc: 0.7714285850524902)
[2024-11-03 04:27:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:31][root][INFO] - Training Epoch: 1/2, step 243/54251 completed (loss: 0.12574924528598785, acc: 1.0)
[2024-11-03 04:27:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:31][root][INFO] - Training Epoch: 1/2, step 244/54251 completed (loss: 1.2060348987579346, acc: 0.6875)
[2024-11-03 04:27:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:32][root][INFO] - Training Epoch: 1/2, step 245/54251 completed (loss: 0.46223214268684387, acc: 0.9473684430122375)
[2024-11-03 04:27:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:32][root][INFO] - Training Epoch: 1/2, step 246/54251 completed (loss: 0.41990694403648376, acc: 0.9166666865348816)
[2024-11-03 04:27:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:33][root][INFO] - Training Epoch: 1/2, step 247/54251 completed (loss: 1.7661149501800537, acc: 0.6296296119689941)
[2024-11-03 04:27:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:33][root][INFO] - Training Epoch: 1/2, step 248/54251 completed (loss: 0.7506773471832275, acc: 0.8709677457809448)
[2024-11-03 04:27:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:34][root][INFO] - Training Epoch: 1/2, step 249/54251 completed (loss: 1.8452236652374268, acc: 0.6410256624221802)
[2024-11-03 04:27:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:34][root][INFO] - Training Epoch: 1/2, step 250/54251 completed (loss: 2.8976619243621826, acc: 0.5)
[2024-11-03 04:27:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:35][root][INFO] - Training Epoch: 1/2, step 251/54251 completed (loss: 0.9729732871055603, acc: 0.760869562625885)
[2024-11-03 04:27:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:35][root][INFO] - Training Epoch: 1/2, step 252/54251 completed (loss: 2.067622184753418, acc: 0.6666666865348816)
[2024-11-03 04:27:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:36][root][INFO] - Training Epoch: 1/2, step 253/54251 completed (loss: 0.9228840470314026, acc: 0.8125)
[2024-11-03 04:27:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:36][root][INFO] - Training Epoch: 1/2, step 254/54251 completed (loss: 0.447897344827652, acc: 0.9166666865348816)
[2024-11-03 04:27:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:37][root][INFO] - Training Epoch: 1/2, step 255/54251 completed (loss: 1.127392292022705, acc: 0.7368420958518982)
[2024-11-03 04:27:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:37][root][INFO] - Training Epoch: 1/2, step 256/54251 completed (loss: 1.094217300415039, acc: 0.7647058963775635)
[2024-11-03 04:27:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:38][root][INFO] - Training Epoch: 1/2, step 257/54251 completed (loss: 1.5846507549285889, acc: 0.6206896305084229)
[2024-11-03 04:27:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:38][root][INFO] - Training Epoch: 1/2, step 258/54251 completed (loss: 0.23445124924182892, acc: 1.0)
[2024-11-03 04:27:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:39][root][INFO] - Training Epoch: 1/2, step 259/54251 completed (loss: 2.4780044555664062, acc: 0.48148149251937866)
[2024-11-03 04:27:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:39][root][INFO] - Training Epoch: 1/2, step 260/54251 completed (loss: 1.667736291885376, acc: 0.71875)
[2024-11-03 04:27:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:40][root][INFO] - Training Epoch: 1/2, step 261/54251 completed (loss: 0.7184805870056152, acc: 0.8333333134651184)
[2024-11-03 04:27:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:40][root][INFO] - Training Epoch: 1/2, step 262/54251 completed (loss: 1.5624815225601196, acc: 0.6976743936538696)
[2024-11-03 04:27:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:41][root][INFO] - Training Epoch: 1/2, step 263/54251 completed (loss: 2.3882641792297363, acc: 0.6538461446762085)
[2024-11-03 04:27:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:41][root][INFO] - Training Epoch: 1/2, step 264/54251 completed (loss: 0.9837854504585266, acc: 0.6000000238418579)
[2024-11-03 04:27:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:42][root][INFO] - Training Epoch: 1/2, step 265/54251 completed (loss: 2.426137685775757, acc: 0.4166666567325592)
[2024-11-03 04:27:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:42][root][INFO] - Training Epoch: 1/2, step 266/54251 completed (loss: 1.4400852918624878, acc: 0.6666666865348816)
[2024-11-03 04:27:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:43][root][INFO] - Training Epoch: 1/2, step 267/54251 completed (loss: 0.20311613380908966, acc: 1.0)
[2024-11-03 04:27:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:43][root][INFO] - Training Epoch: 1/2, step 268/54251 completed (loss: 1.0554146766662598, acc: 0.7105262875556946)
[2024-11-03 04:27:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:44][root][INFO] - Training Epoch: 1/2, step 269/54251 completed (loss: 2.291184425354004, acc: 0.6086956262588501)
[2024-11-03 04:27:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:44][root][INFO] - Training Epoch: 1/2, step 270/54251 completed (loss: 1.345529317855835, acc: 0.7692307829856873)
[2024-11-03 04:27:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:45][root][INFO] - Training Epoch: 1/2, step 271/54251 completed (loss: 1.9650219678878784, acc: 0.5625)
[2024-11-03 04:27:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:45][root][INFO] - Training Epoch: 1/2, step 272/54251 completed (loss: 2.6388258934020996, acc: 0.5185185074806213)
[2024-11-03 04:27:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:46][root][INFO] - Training Epoch: 1/2, step 273/54251 completed (loss: 0.4125535190105438, acc: 0.8333333134651184)
[2024-11-03 04:27:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:46][root][INFO] - Training Epoch: 1/2, step 274/54251 completed (loss: 1.509761929512024, acc: 0.6976743936538696)
[2024-11-03 04:27:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:47][root][INFO] - Training Epoch: 1/2, step 275/54251 completed (loss: 0.17370611429214478, acc: 1.0)
[2024-11-03 04:27:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:47][root][INFO] - Training Epoch: 1/2, step 276/54251 completed (loss: 1.482007384300232, acc: 0.699999988079071)
[2024-11-03 04:27:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:48][root][INFO] - Training Epoch: 1/2, step 277/54251 completed (loss: 1.9626989364624023, acc: 0.52173912525177)
[2024-11-03 04:27:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:48][root][INFO] - Training Epoch: 1/2, step 278/54251 completed (loss: 1.2186146974563599, acc: 0.75)
[2024-11-03 04:27:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:49][root][INFO] - Training Epoch: 1/2, step 279/54251 completed (loss: 1.492615818977356, acc: 0.5)
[2024-11-03 04:27:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:49][root][INFO] - Training Epoch: 1/2, step 280/54251 completed (loss: 1.6943780183792114, acc: 0.6000000238418579)
[2024-11-03 04:27:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:50][root][INFO] - Training Epoch: 1/2, step 281/54251 completed (loss: 0.3914496898651123, acc: 0.8333333134651184)
[2024-11-03 04:27:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:50][root][INFO] - Training Epoch: 1/2, step 282/54251 completed (loss: 0.8462381362915039, acc: 0.6666666865348816)
[2024-11-03 04:27:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:51][root][INFO] - Training Epoch: 1/2, step 283/54251 completed (loss: 1.7405883073806763, acc: 0.6896551847457886)
[2024-11-03 04:27:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:51][root][INFO] - Training Epoch: 1/2, step 284/54251 completed (loss: 2.4539294242858887, acc: 0.5789473652839661)
[2024-11-03 04:27:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:52][root][INFO] - Training Epoch: 1/2, step 285/54251 completed (loss: 1.038849115371704, acc: 0.7142857313156128)
[2024-11-03 04:27:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:52][root][INFO] - Training Epoch: 1/2, step 286/54251 completed (loss: 1.286786675453186, acc: 0.6857143044471741)
[2024-11-03 04:27:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:53][root][INFO] - Training Epoch: 1/2, step 287/54251 completed (loss: 3.1267902851104736, acc: 0.4285714328289032)
[2024-11-03 04:27:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:53][root][INFO] - Training Epoch: 1/2, step 288/54251 completed (loss: 1.1338436603546143, acc: 0.7666666507720947)
[2024-11-03 04:27:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:54][root][INFO] - Training Epoch: 1/2, step 289/54251 completed (loss: 1.137581467628479, acc: 0.7857142686843872)
[2024-11-03 04:27:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:54][root][INFO] - Training Epoch: 1/2, step 290/54251 completed (loss: 0.7931718230247498, acc: 0.8032786846160889)
[2024-11-03 04:27:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:55][root][INFO] - Training Epoch: 1/2, step 291/54251 completed (loss: 1.5185620784759521, acc: 0.6944444179534912)
[2024-11-03 04:27:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:55][root][INFO] - Training Epoch: 1/2, step 292/54251 completed (loss: 1.8859089612960815, acc: 0.5625)
[2024-11-03 04:27:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:56][root][INFO] - Training Epoch: 1/2, step 293/54251 completed (loss: 1.5034593343734741, acc: 0.4375)
[2024-11-03 04:27:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:56][root][INFO] - Training Epoch: 1/2, step 294/54251 completed (loss: 1.6648046970367432, acc: 0.6470588445663452)
[2024-11-03 04:27:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:57][root][INFO] - Training Epoch: 1/2, step 295/54251 completed (loss: 2.0941383838653564, acc: 0.5)
[2024-11-03 04:27:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:57][root][INFO] - Training Epoch: 1/2, step 296/54251 completed (loss: 0.8192238211631775, acc: 0.625)
[2024-11-03 04:27:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:58][root][INFO] - Training Epoch: 1/2, step 297/54251 completed (loss: 2.1330301761627197, acc: 0.53125)
[2024-11-03 04:27:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:58][root][INFO] - Training Epoch: 1/2, step 298/54251 completed (loss: 0.5268061757087708, acc: 0.8571428656578064)
[2024-11-03 04:27:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:59][root][INFO] - Training Epoch: 1/2, step 299/54251 completed (loss: 0.7448403835296631, acc: 0.7142857313156128)
[2024-11-03 04:27:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:27:59][root][INFO] - Training Epoch: 1/2, step 300/54251 completed (loss: 0.3927895128726959, acc: 1.0)
[2024-11-03 04:28:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:00][root][INFO] - Training Epoch: 1/2, step 301/54251 completed (loss: 0.9756821990013123, acc: 0.6666666865348816)
[2024-11-03 04:28:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:00][root][INFO] - Training Epoch: 1/2, step 302/54251 completed (loss: 1.1581015586853027, acc: 0.7333333492279053)
[2024-11-03 04:28:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:01][root][INFO] - Training Epoch: 1/2, step 303/54251 completed (loss: 1.0723512172698975, acc: 0.7428571581840515)
[2024-11-03 04:28:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:02][root][INFO] - Training Epoch: 1/2, step 304/54251 completed (loss: 2.6904654502868652, acc: 0.5862069129943848)
[2024-11-03 04:28:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:02][root][INFO] - Training Epoch: 1/2, step 305/54251 completed (loss: 0.6360374689102173, acc: 0.8837209343910217)
[2024-11-03 04:28:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:02][root][INFO] - Training Epoch: 1/2, step 306/54251 completed (loss: 0.6338037252426147, acc: 0.7777777910232544)
[2024-11-03 04:28:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:03][root][INFO] - Training Epoch: 1/2, step 307/54251 completed (loss: 1.6871849298477173, acc: 0.6458333134651184)
[2024-11-03 04:28:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:04][root][INFO] - Training Epoch: 1/2, step 308/54251 completed (loss: 1.5808565616607666, acc: 0.7142857313156128)
[2024-11-03 04:28:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:04][root][INFO] - Training Epoch: 1/2, step 309/54251 completed (loss: 2.535736322402954, acc: 0.5483871102333069)
[2024-11-03 04:28:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:05][root][INFO] - Training Epoch: 1/2, step 310/54251 completed (loss: 2.0761125087738037, acc: 0.5555555820465088)
[2024-11-03 04:28:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:05][root][INFO] - Training Epoch: 1/2, step 311/54251 completed (loss: 1.1734318733215332, acc: 0.7058823704719543)
[2024-11-03 04:28:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:06][root][INFO] - Training Epoch: 1/2, step 312/54251 completed (loss: 2.090651035308838, acc: 0.5555555820465088)
[2024-11-03 04:28:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:06][root][INFO] - Training Epoch: 1/2, step 313/54251 completed (loss: 1.5734939575195312, acc: 0.75)
[2024-11-03 04:28:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:07][root][INFO] - Training Epoch: 1/2, step 314/54251 completed (loss: 2.9630024433135986, acc: 0.6000000238418579)
[2024-11-03 04:28:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:07][root][INFO] - Training Epoch: 1/2, step 315/54251 completed (loss: 4.2072553634643555, acc: 0.3529411852359772)
[2024-11-03 04:28:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:08][root][INFO] - Training Epoch: 1/2, step 316/54251 completed (loss: 1.1449799537658691, acc: 0.7777777910232544)
[2024-11-03 04:28:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:08][root][INFO] - Training Epoch: 1/2, step 317/54251 completed (loss: 0.43604776263237, acc: 0.875)
[2024-11-03 04:28:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:09][root][INFO] - Training Epoch: 1/2, step 318/54251 completed (loss: 1.8583362102508545, acc: 0.692307710647583)
[2024-11-03 04:28:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:09][root][INFO] - Training Epoch: 1/2, step 319/54251 completed (loss: 1.8669921159744263, acc: 0.6153846383094788)
[2024-11-03 04:28:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:10][root][INFO] - Training Epoch: 1/2, step 320/54251 completed (loss: 1.4478660821914673, acc: 0.6086956262588501)
[2024-11-03 04:28:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:10][root][INFO] - Training Epoch: 1/2, step 321/54251 completed (loss: 2.1315135955810547, acc: 0.5882353186607361)
[2024-11-03 04:28:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:11][root][INFO] - Training Epoch: 1/2, step 322/54251 completed (loss: 1.924538493156433, acc: 0.6896551847457886)
[2024-11-03 04:28:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:11][root][INFO] - Training Epoch: 1/2, step 323/54251 completed (loss: 1.4615341424942017, acc: 0.75)
[2024-11-03 04:28:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:12][root][INFO] - Training Epoch: 1/2, step 324/54251 completed (loss: 0.7333322763442993, acc: 0.8695651888847351)
[2024-11-03 04:28:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:12][root][INFO] - Training Epoch: 1/2, step 325/54251 completed (loss: 1.8970527648925781, acc: 0.692307710647583)
[2024-11-03 04:28:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:13][root][INFO] - Training Epoch: 1/2, step 326/54251 completed (loss: 3.9877028465270996, acc: 0.3636363744735718)
[2024-11-03 04:28:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:13][root][INFO] - Training Epoch: 1/2, step 327/54251 completed (loss: 1.326355218887329, acc: 0.7272727489471436)
[2024-11-03 04:28:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:14][root][INFO] - Training Epoch: 1/2, step 328/54251 completed (loss: 3.6884021759033203, acc: 0.4000000059604645)
[2024-11-03 04:28:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:14][root][INFO] - Training Epoch: 1/2, step 329/54251 completed (loss: 1.8124325275421143, acc: 0.625)
[2024-11-03 04:28:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:15][root][INFO] - Training Epoch: 1/2, step 330/54251 completed (loss: 0.6939941644668579, acc: 0.8478260636329651)
[2024-11-03 04:28:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:15][root][INFO] - Training Epoch: 1/2, step 331/54251 completed (loss: 3.7728655338287354, acc: 0.23076923191547394)
[2024-11-03 04:28:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:16][root][INFO] - Training Epoch: 1/2, step 332/54251 completed (loss: 0.7674514651298523, acc: 0.8367347121238708)
[2024-11-03 04:28:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:16][root][INFO] - Training Epoch: 1/2, step 333/54251 completed (loss: 3.315718173980713, acc: 0.5)
[2024-11-03 04:28:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:17][root][INFO] - Training Epoch: 1/2, step 334/54251 completed (loss: 0.9147406220436096, acc: 0.8085106611251831)
[2024-11-03 04:28:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:17][root][INFO] - Training Epoch: 1/2, step 335/54251 completed (loss: 1.6547939777374268, acc: 0.7272727489471436)
[2024-11-03 04:28:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:18][root][INFO] - Training Epoch: 1/2, step 336/54251 completed (loss: 1.4399112462997437, acc: 0.5833333134651184)
[2024-11-03 04:28:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:18][root][INFO] - Training Epoch: 1/2, step 337/54251 completed (loss: 1.814007043838501, acc: 0.6944444179534912)
[2024-11-03 04:28:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:19][root][INFO] - Training Epoch: 1/2, step 338/54251 completed (loss: 1.8956955671310425, acc: 0.6666666865348816)
[2024-11-03 04:28:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:20][root][INFO] - Training Epoch: 1/2, step 339/54251 completed (loss: 3.3942596912384033, acc: 0.3720930218696594)
[2024-11-03 04:28:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:20][root][INFO] - Training Epoch: 1/2, step 340/54251 completed (loss: 0.9455592036247253, acc: 0.8979591727256775)
[2024-11-03 04:28:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:21][root][INFO] - Training Epoch: 1/2, step 341/54251 completed (loss: 2.772855520248413, acc: 0.5)
[2024-11-03 04:28:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:21][root][INFO] - Training Epoch: 1/2, step 342/54251 completed (loss: 2.7114651203155518, acc: 0.4642857015132904)
[2024-11-03 04:28:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:22][root][INFO] - Training Epoch: 1/2, step 343/54251 completed (loss: 0.8311775326728821, acc: 0.79347825050354)
[2024-11-03 04:28:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:22][root][INFO] - Training Epoch: 1/2, step 344/54251 completed (loss: 1.5434012413024902, acc: 0.5555555820465088)
[2024-11-03 04:28:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:23][root][INFO] - Training Epoch: 1/2, step 345/54251 completed (loss: 3.414552927017212, acc: 0.3888888955116272)
[2024-11-03 04:28:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:23][root][INFO] - Training Epoch: 1/2, step 346/54251 completed (loss: 0.937736988067627, acc: 0.75)
[2024-11-03 04:28:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:24][root][INFO] - Training Epoch: 1/2, step 347/54251 completed (loss: 2.999108076095581, acc: 0.5)
[2024-11-03 04:28:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:24][root][INFO] - Training Epoch: 1/2, step 348/54251 completed (loss: 1.673109531402588, acc: 0.5384615659713745)
[2024-11-03 04:28:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:25][root][INFO] - Training Epoch: 1/2, step 349/54251 completed (loss: 0.47662732005119324, acc: 0.8636363744735718)
[2024-11-03 04:28:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:25][root][INFO] - Training Epoch: 1/2, step 350/54251 completed (loss: 0.11640983074903488, acc: 0.9629629850387573)
[2024-11-03 04:28:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:26][root][INFO] - Training Epoch: 1/2, step 351/54251 completed (loss: 0.9634969234466553, acc: 0.7777777910232544)
[2024-11-03 04:28:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:26][root][INFO] - Training Epoch: 1/2, step 352/54251 completed (loss: 1.017089605331421, acc: 0.7837837934494019)
[2024-11-03 04:28:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:27][root][INFO] - Training Epoch: 1/2, step 353/54251 completed (loss: 0.4584323763847351, acc: 0.800000011920929)
[2024-11-03 04:28:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:27][root][INFO] - Training Epoch: 1/2, step 354/54251 completed (loss: 0.6488875150680542, acc: 0.8571428656578064)
[2024-11-03 04:28:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:28][root][INFO] - Training Epoch: 1/2, step 355/54251 completed (loss: 2.9544341564178467, acc: 0.6000000238418579)
[2024-11-03 04:28:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:28][root][INFO] - Training Epoch: 1/2, step 356/54251 completed (loss: 1.7254718542099, acc: 0.699999988079071)
[2024-11-03 04:28:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:29][root][INFO] - Training Epoch: 1/2, step 357/54251 completed (loss: 2.5412914752960205, acc: 0.4680851101875305)
[2024-11-03 04:28:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:29][root][INFO] - Training Epoch: 1/2, step 358/54251 completed (loss: 2.0683624744415283, acc: 0.5625)
[2024-11-03 04:28:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:30][root][INFO] - Training Epoch: 1/2, step 359/54251 completed (loss: 2.1118531227111816, acc: 0.6000000238418579)
[2024-11-03 04:28:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:30][root][INFO] - Training Epoch: 1/2, step 360/54251 completed (loss: 2.130566120147705, acc: 0.5757575631141663)
[2024-11-03 04:28:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:31][root][INFO] - Training Epoch: 1/2, step 361/54251 completed (loss: 1.250107765197754, acc: 0.6451612710952759)
[2024-11-03 04:28:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:31][root][INFO] - Training Epoch: 1/2, step 362/54251 completed (loss: 0.8139722347259521, acc: 0.78125)
[2024-11-03 04:28:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:32][root][INFO] - Training Epoch: 1/2, step 363/54251 completed (loss: 2.9716501235961914, acc: 0.4324324429035187)
[2024-11-03 04:28:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:32][root][INFO] - Training Epoch: 1/2, step 364/54251 completed (loss: 1.0742840766906738, acc: 0.7777777910232544)
[2024-11-03 04:28:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:33][root][INFO] - Training Epoch: 1/2, step 365/54251 completed (loss: 1.3639650344848633, acc: 0.5)
[2024-11-03 04:28:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:33][root][INFO] - Training Epoch: 1/2, step 366/54251 completed (loss: 0.784100353717804, acc: 0.782608687877655)
[2024-11-03 04:28:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:34][root][INFO] - Training Epoch: 1/2, step 367/54251 completed (loss: 0.43184953927993774, acc: 0.9047619104385376)
[2024-11-03 04:28:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:34][root][INFO] - Training Epoch: 1/2, step 368/54251 completed (loss: 1.483832836151123, acc: 0.7941176295280457)
[2024-11-03 04:28:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:35][root][INFO] - Training Epoch: 1/2, step 369/54251 completed (loss: 1.0840924978256226, acc: 0.7272727489471436)
[2024-11-03 04:28:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:35][root][INFO] - Training Epoch: 1/2, step 370/54251 completed (loss: 1.0416173934936523, acc: 0.7837837934494019)
[2024-11-03 04:28:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:36][root][INFO] - Training Epoch: 1/2, step 371/54251 completed (loss: 1.054052710533142, acc: 0.75)
[2024-11-03 04:28:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:36][root][INFO] - Training Epoch: 1/2, step 372/54251 completed (loss: 1.1421732902526855, acc: 0.7692307829856873)
[2024-11-03 04:28:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:37][root][INFO] - Training Epoch: 1/2, step 373/54251 completed (loss: 2.6820077896118164, acc: 0.5454545617103577)
[2024-11-03 04:28:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:37][root][INFO] - Training Epoch: 1/2, step 374/54251 completed (loss: 2.037463903427124, acc: 0.5806451439857483)
[2024-11-03 04:28:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:38][root][INFO] - Training Epoch: 1/2, step 375/54251 completed (loss: 0.8260195851325989, acc: 0.8181818127632141)
[2024-11-03 04:28:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:38][root][INFO] - Training Epoch: 1/2, step 376/54251 completed (loss: 0.4648229777812958, acc: 0.8888888955116272)
[2024-11-03 04:28:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:39][root][INFO] - Training Epoch: 1/2, step 377/54251 completed (loss: 0.3804624676704407, acc: 0.8888888955116272)
[2024-11-03 04:28:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:39][root][INFO] - Training Epoch: 1/2, step 378/54251 completed (loss: 0.6702684164047241, acc: 0.8260869383811951)
[2024-11-03 04:28:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:40][root][INFO] - Training Epoch: 1/2, step 379/54251 completed (loss: 1.338149070739746, acc: 0.760869562625885)
[2024-11-03 04:28:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:40][root][INFO] - Training Epoch: 1/2, step 380/54251 completed (loss: 0.1038336455821991, acc: 1.0)
[2024-11-03 04:28:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:41][root][INFO] - Training Epoch: 1/2, step 381/54251 completed (loss: 0.7147843837738037, acc: 0.8909090757369995)
[2024-11-03 04:28:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:41][root][INFO] - Training Epoch: 1/2, step 382/54251 completed (loss: 1.810084342956543, acc: 0.7419354915618896)
[2024-11-03 04:28:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:42][root][INFO] - Training Epoch: 1/2, step 383/54251 completed (loss: 1.1533513069152832, acc: 0.7777777910232544)
[2024-11-03 04:28:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:42][root][INFO] - Training Epoch: 1/2, step 384/54251 completed (loss: 1.8732600212097168, acc: 0.6153846383094788)
[2024-11-03 04:28:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:43][root][INFO] - Training Epoch: 1/2, step 385/54251 completed (loss: 0.8935807943344116, acc: 0.7727272510528564)
[2024-11-03 04:28:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:43][root][INFO] - Training Epoch: 1/2, step 386/54251 completed (loss: 1.2517167329788208, acc: 0.75)
[2024-11-03 04:28:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:44][root][INFO] - Training Epoch: 1/2, step 387/54251 completed (loss: 0.815123438835144, acc: 0.800000011920929)
[2024-11-03 04:28:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:44][root][INFO] - Training Epoch: 1/2, step 388/54251 completed (loss: 1.7744560241699219, acc: 0.6521739363670349)
[2024-11-03 04:28:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:45][root][INFO] - Training Epoch: 1/2, step 389/54251 completed (loss: 0.6309107542037964, acc: 0.8461538553237915)
[2024-11-03 04:28:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:45][root][INFO] - Training Epoch: 1/2, step 390/54251 completed (loss: 3.0617942810058594, acc: 0.40909090638160706)
[2024-11-03 04:28:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:46][root][INFO] - Training Epoch: 1/2, step 391/54251 completed (loss: 1.791413426399231, acc: 0.6666666865348816)
[2024-11-03 04:28:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:46][root][INFO] - Training Epoch: 1/2, step 392/54251 completed (loss: 2.0155835151672363, acc: 0.6666666865348816)
[2024-11-03 04:28:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:47][root][INFO] - Training Epoch: 1/2, step 393/54251 completed (loss: 0.5430445671081543, acc: 0.8867924809455872)
[2024-11-03 04:28:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:47][root][INFO] - Training Epoch: 1/2, step 394/54251 completed (loss: 0.8545466065406799, acc: 0.8571428656578064)
[2024-11-03 04:28:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:48][root][INFO] - Training Epoch: 1/2, step 395/54251 completed (loss: 2.0039010047912598, acc: 0.692307710647583)
[2024-11-03 04:28:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:48][root][INFO] - Training Epoch: 1/2, step 396/54251 completed (loss: 1.1440153121948242, acc: 0.7647058963775635)
[2024-11-03 04:28:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:49][root][INFO] - Training Epoch: 1/2, step 397/54251 completed (loss: 1.0062347650527954, acc: 0.8461538553237915)
[2024-11-03 04:28:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:49][root][INFO] - Training Epoch: 1/2, step 398/54251 completed (loss: 1.530807375907898, acc: 0.6440678238868713)
[2024-11-03 04:28:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:50][root][INFO] - Training Epoch: 1/2, step 399/54251 completed (loss: 2.095623016357422, acc: 0.6060606241226196)
[2024-11-03 04:28:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:50][root][INFO] - Training Epoch: 1/2, step 400/54251 completed (loss: 1.0641275644302368, acc: 0.7916666865348816)
[2024-11-03 04:28:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:51][root][INFO] - Training Epoch: 1/2, step 401/54251 completed (loss: 1.5954320430755615, acc: 0.7647058963775635)
[2024-11-03 04:28:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:51][root][INFO] - Training Epoch: 1/2, step 402/54251 completed (loss: 0.9928704500198364, acc: 0.7857142686843872)
[2024-11-03 04:28:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:52][root][INFO] - Training Epoch: 1/2, step 403/54251 completed (loss: 2.7154242992401123, acc: 0.5)
[2024-11-03 04:28:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:52][root][INFO] - Training Epoch: 1/2, step 404/54251 completed (loss: 1.8675775527954102, acc: 0.6470588445663452)
[2024-11-03 04:28:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:53][root][INFO] - Training Epoch: 1/2, step 405/54251 completed (loss: 1.1300262212753296, acc: 0.7878788113594055)
[2024-11-03 04:28:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:53][root][INFO] - Training Epoch: 1/2, step 406/54251 completed (loss: 1.4275751113891602, acc: 0.6867470145225525)
[2024-11-03 04:28:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:54][root][INFO] - Training Epoch: 1/2, step 407/54251 completed (loss: 2.0425920486450195, acc: 0.5483871102333069)
[2024-11-03 04:28:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:54][root][INFO] - Training Epoch: 1/2, step 408/54251 completed (loss: 1.9171103239059448, acc: 0.6538461446762085)
[2024-11-03 04:28:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:55][root][INFO] - Training Epoch: 1/2, step 409/54251 completed (loss: 1.7047098875045776, acc: 0.6153846383094788)
[2024-11-03 04:28:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:55][root][INFO] - Training Epoch: 1/2, step 410/54251 completed (loss: 2.750713586807251, acc: 0.7272727489471436)
[2024-11-03 04:28:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:56][root][INFO] - Training Epoch: 1/2, step 411/54251 completed (loss: 3.6667935848236084, acc: 0.1666666716337204)
[2024-11-03 04:28:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:56][root][INFO] - Training Epoch: 1/2, step 412/54251 completed (loss: 0.9611768126487732, acc: 0.7857142686843872)
[2024-11-03 04:28:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:57][root][INFO] - Training Epoch: 1/2, step 413/54251 completed (loss: 1.4422175884246826, acc: 0.75)
[2024-11-03 04:28:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:57][root][INFO] - Training Epoch: 1/2, step 414/54251 completed (loss: 0.9691995978355408, acc: 0.7799999713897705)
[2024-11-03 04:28:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:58][root][INFO] - Training Epoch: 1/2, step 415/54251 completed (loss: 0.8316764235496521, acc: 0.8260869383811951)
[2024-11-03 04:28:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:58][root][INFO] - Training Epoch: 1/2, step 416/54251 completed (loss: 0.42809706926345825, acc: 0.8947368264198303)
[2024-11-03 04:28:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:59][root][INFO] - Training Epoch: 1/2, step 417/54251 completed (loss: 1.492096185684204, acc: 0.7037037014961243)
[2024-11-03 04:28:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:28:59][root][INFO] - Training Epoch: 1/2, step 418/54251 completed (loss: 1.4177519083023071, acc: 0.6976743936538696)
[2024-11-03 04:28:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:00][root][INFO] - Training Epoch: 1/2, step 419/54251 completed (loss: 0.6609329581260681, acc: 0.9285714030265808)
[2024-11-03 04:29:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:00][root][INFO] - Training Epoch: 1/2, step 420/54251 completed (loss: 1.2146168947219849, acc: 0.6470588445663452)
[2024-11-03 04:29:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:01][root][INFO] - Training Epoch: 1/2, step 421/54251 completed (loss: 1.3427973985671997, acc: 0.7333333492279053)
[2024-11-03 04:29:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:01][root][INFO] - Training Epoch: 1/2, step 422/54251 completed (loss: 1.3068031072616577, acc: 0.800000011920929)
[2024-11-03 04:29:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:02][root][INFO] - Training Epoch: 1/2, step 423/54251 completed (loss: 0.4997578561306, acc: 0.949999988079071)
[2024-11-03 04:29:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:03][root][INFO] - Training Epoch: 1/2, step 424/54251 completed (loss: 2.547184467315674, acc: 0.7142857313156128)
[2024-11-03 04:29:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:03][root][INFO] - Training Epoch: 1/2, step 425/54251 completed (loss: 2.817756414413452, acc: 0.44186046719551086)
[2024-11-03 04:29:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:04][root][INFO] - Training Epoch: 1/2, step 426/54251 completed (loss: 1.9802720546722412, acc: 0.6428571343421936)
[2024-11-03 04:29:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:04][root][INFO] - Training Epoch: 1/2, step 427/54251 completed (loss: 1.535971999168396, acc: 0.7647058963775635)
[2024-11-03 04:29:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:05][root][INFO] - Training Epoch: 1/2, step 428/54251 completed (loss: 0.8911624550819397, acc: 0.625)
[2024-11-03 04:29:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:05][root][INFO] - Training Epoch: 1/2, step 429/54251 completed (loss: 1.423279881477356, acc: 0.7555555701255798)
[2024-11-03 04:29:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:06][root][INFO] - Training Epoch: 1/2, step 430/54251 completed (loss: 1.0061668157577515, acc: 0.7142857313156128)
[2024-11-03 04:29:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:06][root][INFO] - Training Epoch: 1/2, step 431/54251 completed (loss: 1.1605629920959473, acc: 0.7222222089767456)
[2024-11-03 04:29:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:07][root][INFO] - Training Epoch: 1/2, step 432/54251 completed (loss: 2.2100634574890137, acc: 0.3333333432674408)
[2024-11-03 04:29:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:07][root][INFO] - Training Epoch: 1/2, step 433/54251 completed (loss: 1.8811848163604736, acc: 0.5862069129943848)
[2024-11-03 04:29:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:08][root][INFO] - Training Epoch: 1/2, step 434/54251 completed (loss: 1.994572639465332, acc: 0.6000000238418579)
[2024-11-03 04:29:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:08][root][INFO] - Training Epoch: 1/2, step 435/54251 completed (loss: 0.9863321781158447, acc: 0.7222222089767456)
[2024-11-03 04:29:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:09][root][INFO] - Training Epoch: 1/2, step 436/54251 completed (loss: 3.1947243213653564, acc: 0.4576271176338196)
[2024-11-03 04:29:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:09][root][INFO] - Training Epoch: 1/2, step 437/54251 completed (loss: 1.3460346460342407, acc: 0.6666666865348816)
[2024-11-03 04:29:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:10][root][INFO] - Training Epoch: 1/2, step 438/54251 completed (loss: 0.6998306512832642, acc: 0.8888888955116272)
[2024-11-03 04:29:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:10][root][INFO] - Training Epoch: 1/2, step 439/54251 completed (loss: 2.314542293548584, acc: 0.6000000238418579)
[2024-11-03 04:29:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:11][root][INFO] - Training Epoch: 1/2, step 440/54251 completed (loss: 0.9307730793952942, acc: 0.8095238208770752)
[2024-11-03 04:29:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:11][root][INFO] - Training Epoch: 1/2, step 441/54251 completed (loss: 2.3195619583129883, acc: 0.6521739363670349)
[2024-11-03 04:29:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:12][root][INFO] - Training Epoch: 1/2, step 442/54251 completed (loss: 0.8512420654296875, acc: 0.8214285969734192)
[2024-11-03 04:29:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:12][root][INFO] - Training Epoch: 1/2, step 443/54251 completed (loss: 0.4898763597011566, acc: 0.8947368264198303)
[2024-11-03 04:29:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:13][root][INFO] - Training Epoch: 1/2, step 444/54251 completed (loss: 0.5358920097351074, acc: 0.9024389982223511)
[2024-11-03 04:29:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:13][root][INFO] - Training Epoch: 1/2, step 445/54251 completed (loss: 1.4253802299499512, acc: 0.7674418687820435)
[2024-11-03 04:29:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:14][root][INFO] - Training Epoch: 1/2, step 446/54251 completed (loss: 1.4409961700439453, acc: 0.7441860437393188)
[2024-11-03 04:29:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:14][root][INFO] - Training Epoch: 1/2, step 447/54251 completed (loss: 1.3725465536117554, acc: 0.695652186870575)
[2024-11-03 04:29:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:15][root][INFO] - Training Epoch: 1/2, step 448/54251 completed (loss: 0.8482528924942017, acc: 0.8260869383811951)
[2024-11-03 04:29:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:15][root][INFO] - Training Epoch: 1/2, step 449/54251 completed (loss: 0.8471240401268005, acc: 0.8636363744735718)
[2024-11-03 04:29:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:16][root][INFO] - Training Epoch: 1/2, step 450/54251 completed (loss: 1.28208589553833, acc: 0.6363636255264282)
[2024-11-03 04:29:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:16][root][INFO] - Training Epoch: 1/2, step 451/54251 completed (loss: 1.711990475654602, acc: 0.5416666865348816)
[2024-11-03 04:29:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:17][root][INFO] - Training Epoch: 1/2, step 452/54251 completed (loss: 1.519342303276062, acc: 0.7037037014961243)
[2024-11-03 04:29:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:17][root][INFO] - Training Epoch: 1/2, step 453/54251 completed (loss: 2.1260826587677, acc: 0.6000000238418579)
[2024-11-03 04:29:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:18][root][INFO] - Training Epoch: 1/2, step 454/54251 completed (loss: 1.905680537223816, acc: 0.5862069129943848)
[2024-11-03 04:29:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:18][root][INFO] - Training Epoch: 1/2, step 455/54251 completed (loss: 1.4166721105575562, acc: 0.75)
[2024-11-03 04:29:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:19][root][INFO] - Training Epoch: 1/2, step 456/54251 completed (loss: 0.19517335295677185, acc: 1.0)
[2024-11-03 04:29:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:19][root][INFO] - Training Epoch: 1/2, step 457/54251 completed (loss: 2.477936029434204, acc: 0.5454545617103577)
[2024-11-03 04:29:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:20][root][INFO] - Training Epoch: 1/2, step 458/54251 completed (loss: 1.1406923532485962, acc: 0.75)
[2024-11-03 04:29:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:20][root][INFO] - Training Epoch: 1/2, step 459/54251 completed (loss: 1.9827219247817993, acc: 0.6875)
[2024-11-03 04:29:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:21][root][INFO] - Training Epoch: 1/2, step 460/54251 completed (loss: 3.191390037536621, acc: 0.4482758641242981)
[2024-11-03 04:29:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:21][root][INFO] - Training Epoch: 1/2, step 461/54251 completed (loss: 0.7211089134216309, acc: 0.8367347121238708)
[2024-11-03 04:29:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:22][root][INFO] - Training Epoch: 1/2, step 462/54251 completed (loss: 1.5094572305679321, acc: 0.7692307829856873)
[2024-11-03 04:29:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:23][root][INFO] - Training Epoch: 1/2, step 463/54251 completed (loss: 1.3168680667877197, acc: 0.800000011920929)
[2024-11-03 04:29:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:23][root][INFO] - Training Epoch: 1/2, step 464/54251 completed (loss: 0.6247111558914185, acc: 0.875)
[2024-11-03 04:29:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:24][root][INFO] - Training Epoch: 1/2, step 465/54251 completed (loss: 2.856480121612549, acc: 0.40909090638160706)
[2024-11-03 04:29:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:24][root][INFO] - Training Epoch: 1/2, step 466/54251 completed (loss: 1.3720595836639404, acc: 0.625)
[2024-11-03 04:29:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:24][root][INFO] - Training Epoch: 1/2, step 467/54251 completed (loss: 1.3678131103515625, acc: 0.8064516186714172)
[2024-11-03 04:29:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:25][root][INFO] - Training Epoch: 1/2, step 468/54251 completed (loss: 1.3641880750656128, acc: 0.7857142686843872)
[2024-11-03 04:29:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:25][root][INFO] - Training Epoch: 1/2, step 469/54251 completed (loss: 0.622903048992157, acc: 0.75)
[2024-11-03 04:29:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:26][root][INFO] - Training Epoch: 1/2, step 470/54251 completed (loss: 0.517564594745636, acc: 0.8918918967247009)
[2024-11-03 04:29:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:26][root][INFO] - Training Epoch: 1/2, step 471/54251 completed (loss: 1.6001390218734741, acc: 0.6666666865348816)
[2024-11-03 04:29:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:27][root][INFO] - Training Epoch: 1/2, step 472/54251 completed (loss: 1.4591978788375854, acc: 0.699999988079071)
[2024-11-03 04:29:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:28][root][INFO] - Training Epoch: 1/2, step 473/54251 completed (loss: 0.6473502516746521, acc: 0.8589743375778198)
[2024-11-03 04:29:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:28][root][INFO] - Training Epoch: 1/2, step 474/54251 completed (loss: 0.7514177560806274, acc: 0.8999999761581421)
[2024-11-03 04:29:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:29][root][INFO] - Training Epoch: 1/2, step 475/54251 completed (loss: 2.3522071838378906, acc: 0.625)
[2024-11-03 04:29:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:29][root][INFO] - Training Epoch: 1/2, step 476/54251 completed (loss: 1.6908142566680908, acc: 0.6363636255264282)
[2024-11-03 04:29:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:30][root][INFO] - Training Epoch: 1/2, step 477/54251 completed (loss: 0.7194424867630005, acc: 0.8064516186714172)
[2024-11-03 04:29:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:30][root][INFO] - Training Epoch: 1/2, step 478/54251 completed (loss: 2.730992078781128, acc: 0.4583333432674408)
[2024-11-03 04:29:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:31][root][INFO] - Training Epoch: 1/2, step 479/54251 completed (loss: 0.3402523994445801, acc: 0.8666666746139526)
[2024-11-03 04:29:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:31][root][INFO] - Training Epoch: 1/2, step 480/54251 completed (loss: 1.235567331314087, acc: 0.7222222089767456)
[2024-11-03 04:29:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:32][root][INFO] - Training Epoch: 1/2, step 481/54251 completed (loss: 1.484521508216858, acc: 0.7037037014961243)
[2024-11-03 04:29:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:32][root][INFO] - Training Epoch: 1/2, step 482/54251 completed (loss: 2.3980674743652344, acc: 0.5)
[2024-11-03 04:29:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:33][root][INFO] - Training Epoch: 1/2, step 483/54251 completed (loss: 2.6948254108428955, acc: 0.4285714328289032)
[2024-11-03 04:29:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:33][root][INFO] - Training Epoch: 1/2, step 484/54251 completed (loss: 2.4529263973236084, acc: 0.625)
[2024-11-03 04:29:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:34][root][INFO] - Training Epoch: 1/2, step 485/54251 completed (loss: 0.280534565448761, acc: 1.0)
[2024-11-03 04:29:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:34][root][INFO] - Training Epoch: 1/2, step 486/54251 completed (loss: 1.1879485845565796, acc: 0.8636363744735718)
[2024-11-03 04:29:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:35][root][INFO] - Training Epoch: 1/2, step 487/54251 completed (loss: 1.0648921728134155, acc: 0.5)
[2024-11-03 04:29:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:35][root][INFO] - Training Epoch: 1/2, step 488/54251 completed (loss: 0.13669361174106598, acc: 1.0)
[2024-11-03 04:29:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:36][root][INFO] - Training Epoch: 1/2, step 489/54251 completed (loss: 1.1338579654693604, acc: 0.739130437374115)
[2024-11-03 04:29:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:36][root][INFO] - Training Epoch: 1/2, step 490/54251 completed (loss: 1.3518484830856323, acc: 0.5555555820465088)
[2024-11-03 04:29:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:37][root][INFO] - Training Epoch: 1/2, step 491/54251 completed (loss: 1.3157193660736084, acc: 0.6000000238418579)
[2024-11-03 04:29:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:37][root][INFO] - Training Epoch: 1/2, step 492/54251 completed (loss: 1.855442762374878, acc: 0.6363636255264282)
[2024-11-03 04:29:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:38][root][INFO] - Training Epoch: 1/2, step 493/54251 completed (loss: 1.354050874710083, acc: 0.675000011920929)
[2024-11-03 04:29:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:38][root][INFO] - Training Epoch: 1/2, step 494/54251 completed (loss: 0.5608551502227783, acc: 0.8771929740905762)
[2024-11-03 04:29:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:39][root][INFO] - Training Epoch: 1/2, step 495/54251 completed (loss: 2.694425106048584, acc: 0.5882353186607361)
[2024-11-03 04:29:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:39][root][INFO] - Training Epoch: 1/2, step 496/54251 completed (loss: 1.3410508632659912, acc: 0.8055555820465088)
[2024-11-03 04:29:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:40][root][INFO] - Training Epoch: 1/2, step 497/54251 completed (loss: 3.0525505542755127, acc: 0.41860464215278625)
[2024-11-03 04:29:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:40][root][INFO] - Training Epoch: 1/2, step 498/54251 completed (loss: 1.765547275543213, acc: 0.6451612710952759)
[2024-11-03 04:29:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:41][root][INFO] - Training Epoch: 1/2, step 499/54251 completed (loss: 2.1799721717834473, acc: 0.5416666865348816)
[2024-11-03 04:29:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:41][root][INFO] - Training Epoch: 1/2, step 500/54251 completed (loss: 0.8308485150337219, acc: 0.7777777910232544)
[2024-11-03 04:29:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:42][root][INFO] - Training Epoch: 1/2, step 501/54251 completed (loss: 1.7109549045562744, acc: 0.625)
[2024-11-03 04:29:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:42][root][INFO] - Training Epoch: 1/2, step 502/54251 completed (loss: 0.3063450753688812, acc: 0.9454545378684998)
[2024-11-03 04:29:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:43][root][INFO] - Training Epoch: 1/2, step 503/54251 completed (loss: 0.7686182856559753, acc: 0.8333333134651184)
[2024-11-03 04:29:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:43][root][INFO] - Training Epoch: 1/2, step 504/54251 completed (loss: 1.2312263250350952, acc: 0.6666666865348816)
[2024-11-03 04:29:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:44][root][INFO] - Training Epoch: 1/2, step 505/54251 completed (loss: 2.634183883666992, acc: 0.6666666865348816)
[2024-11-03 04:29:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:44][root][INFO] - Training Epoch: 1/2, step 506/54251 completed (loss: 1.0289684534072876, acc: 0.8301886916160583)
[2024-11-03 04:29:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:45][root][INFO] - Training Epoch: 1/2, step 507/54251 completed (loss: 1.6972135305404663, acc: 0.7948718070983887)
[2024-11-03 04:29:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:45][root][INFO] - Training Epoch: 1/2, step 508/54251 completed (loss: 1.2146726846694946, acc: 0.75)
[2024-11-03 04:29:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:46][root][INFO] - Training Epoch: 1/2, step 509/54251 completed (loss: 0.803261399269104, acc: 0.75)
[2024-11-03 04:29:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:46][root][INFO] - Training Epoch: 1/2, step 510/54251 completed (loss: 2.436544895172119, acc: 0.6000000238418579)
[2024-11-03 04:29:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:47][root][INFO] - Training Epoch: 1/2, step 511/54251 completed (loss: 1.296065092086792, acc: 0.7272727489471436)
[2024-11-03 04:29:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:47][root][INFO] - Training Epoch: 1/2, step 512/54251 completed (loss: 1.6413830518722534, acc: 0.6785714030265808)
[2024-11-03 04:29:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:48][root][INFO] - Training Epoch: 1/2, step 513/54251 completed (loss: 4.442056179046631, acc: 0.1304347813129425)
[2024-11-03 04:29:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:48][root][INFO] - Training Epoch: 1/2, step 514/54251 completed (loss: 1.2985272407531738, acc: 0.75)
[2024-11-03 04:29:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:49][root][INFO] - Training Epoch: 1/2, step 515/54251 completed (loss: 1.058932900428772, acc: 0.800000011920929)
[2024-11-03 04:29:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:49][root][INFO] - Training Epoch: 1/2, step 516/54251 completed (loss: 1.8909863233566284, acc: 0.7142857313156128)
[2024-11-03 04:29:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:50][root][INFO] - Training Epoch: 1/2, step 517/54251 completed (loss: 1.208764910697937, acc: 0.75)
[2024-11-03 04:29:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:50][root][INFO] - Training Epoch: 1/2, step 518/54251 completed (loss: 3.5869674682617188, acc: 0.5833333134651184)
[2024-11-03 04:29:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:51][root][INFO] - Training Epoch: 1/2, step 519/54251 completed (loss: 1.3702501058578491, acc: 0.7096773982048035)
[2024-11-03 04:29:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:51][root][INFO] - Training Epoch: 1/2, step 520/54251 completed (loss: 0.856757640838623, acc: 1.0)
[2024-11-03 04:29:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:52][root][INFO] - Training Epoch: 1/2, step 521/54251 completed (loss: 1.4386192560195923, acc: 0.8148148059844971)
[2024-11-03 04:29:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:52][root][INFO] - Training Epoch: 1/2, step 522/54251 completed (loss: 0.48233315348625183, acc: 0.9166666865348816)
[2024-11-03 04:29:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:53][root][INFO] - Training Epoch: 1/2, step 523/54251 completed (loss: 0.9200446009635925, acc: 0.8387096524238586)
[2024-11-03 04:29:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:53][root][INFO] - Training Epoch: 1/2, step 524/54251 completed (loss: 0.9167843461036682, acc: 0.782608687877655)
[2024-11-03 04:29:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:54][root][INFO] - Training Epoch: 1/2, step 525/54251 completed (loss: 2.0233218669891357, acc: 0.5714285969734192)
[2024-11-03 04:29:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:54][root][INFO] - Training Epoch: 1/2, step 526/54251 completed (loss: 1.1700987815856934, acc: 0.7333333492279053)
[2024-11-03 04:29:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:55][root][INFO] - Training Epoch: 1/2, step 527/54251 completed (loss: 1.4542293548583984, acc: 0.7111111283302307)
[2024-11-03 04:29:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:55][root][INFO] - Training Epoch: 1/2, step 528/54251 completed (loss: 0.6417478919029236, acc: 0.8799999952316284)
[2024-11-03 04:29:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:56][root][INFO] - Training Epoch: 1/2, step 529/54251 completed (loss: 0.811200737953186, acc: 0.800000011920929)
[2024-11-03 04:29:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:56][root][INFO] - Training Epoch: 1/2, step 530/54251 completed (loss: 1.4622814655303955, acc: 0.65625)
[2024-11-03 04:29:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:57][root][INFO] - Training Epoch: 1/2, step 531/54251 completed (loss: 0.6248381733894348, acc: 0.7692307829856873)
[2024-11-03 04:29:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:57][root][INFO] - Training Epoch: 1/2, step 532/54251 completed (loss: 1.182000756263733, acc: 0.7333333492279053)
[2024-11-03 04:29:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:58][root][INFO] - Training Epoch: 1/2, step 533/54251 completed (loss: 0.9635595083236694, acc: 0.8399999737739563)
[2024-11-03 04:29:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:58][root][INFO] - Training Epoch: 1/2, step 534/54251 completed (loss: 1.0809943675994873, acc: 0.8333333134651184)
[2024-11-03 04:29:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:59][root][INFO] - Training Epoch: 1/2, step 535/54251 completed (loss: 1.3394804000854492, acc: 0.7647058963775635)
[2024-11-03 04:29:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:29:59][root][INFO] - Training Epoch: 1/2, step 536/54251 completed (loss: 4.207021713256836, acc: 0.2777777910232544)
[2024-11-03 04:29:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:00][root][INFO] - Training Epoch: 1/2, step 537/54251 completed (loss: 1.4685331583023071, acc: 0.78125)
[2024-11-03 04:30:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:00][root][INFO] - Training Epoch: 1/2, step 538/54251 completed (loss: 0.5799923539161682, acc: 0.90625)
[2024-11-03 04:30:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:01][root][INFO] - Training Epoch: 1/2, step 539/54251 completed (loss: 1.1031023263931274, acc: 0.8205128312110901)
[2024-11-03 04:30:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:01][root][INFO] - Training Epoch: 1/2, step 540/54251 completed (loss: 0.9831581115722656, acc: 0.7058823704719543)
[2024-11-03 04:30:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:02][root][INFO] - Training Epoch: 1/2, step 541/54251 completed (loss: 1.3160972595214844, acc: 0.7599999904632568)
[2024-11-03 04:30:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:02][root][INFO] - Training Epoch: 1/2, step 542/54251 completed (loss: 0.8438534736633301, acc: 0.782608687877655)
[2024-11-03 04:30:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:03][root][INFO] - Training Epoch: 1/2, step 543/54251 completed (loss: 1.6524549722671509, acc: 0.7333333492279053)
[2024-11-03 04:30:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:03][root][INFO] - Training Epoch: 1/2, step 544/54251 completed (loss: 1.983072280883789, acc: 0.6666666865348816)
[2024-11-03 04:30:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:04][root][INFO] - Training Epoch: 1/2, step 545/54251 completed (loss: 1.2041492462158203, acc: 0.6000000238418579)
[2024-11-03 04:30:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:04][root][INFO] - Training Epoch: 1/2, step 546/54251 completed (loss: 1.670365571975708, acc: 0.6976743936538696)
[2024-11-03 04:30:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:05][root][INFO] - Training Epoch: 1/2, step 547/54251 completed (loss: 2.308774948120117, acc: 0.75)
[2024-11-03 04:30:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:05][root][INFO] - Training Epoch: 1/2, step 548/54251 completed (loss: 1.245473027229309, acc: 0.7674418687820435)
[2024-11-03 04:30:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:06][root][INFO] - Training Epoch: 1/2, step 549/54251 completed (loss: 0.4670964479446411, acc: 0.8888888955116272)
[2024-11-03 04:30:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:06][root][INFO] - Training Epoch: 1/2, step 550/54251 completed (loss: 0.653488278388977, acc: 0.84375)
[2024-11-03 04:30:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:07][root][INFO] - Training Epoch: 1/2, step 551/54251 completed (loss: 1.5136085748672485, acc: 0.6875)
[2024-11-03 04:30:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:07][root][INFO] - Training Epoch: 1/2, step 552/54251 completed (loss: 0.9883931279182434, acc: 0.7777777910232544)
[2024-11-03 04:30:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:08][root][INFO] - Training Epoch: 1/2, step 553/54251 completed (loss: 1.1765745878219604, acc: 0.7241379022598267)
[2024-11-03 04:30:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:08][root][INFO] - Training Epoch: 1/2, step 554/54251 completed (loss: 2.1598141193389893, acc: 0.6000000238418579)
[2024-11-03 04:30:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:09][root][INFO] - Training Epoch: 1/2, step 555/54251 completed (loss: 1.5312221050262451, acc: 0.7368420958518982)
[2024-11-03 04:30:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:09][root][INFO] - Training Epoch: 1/2, step 556/54251 completed (loss: 0.3551695942878723, acc: 0.9545454382896423)
[2024-11-03 04:30:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:10][root][INFO] - Training Epoch: 1/2, step 557/54251 completed (loss: 1.0375351905822754, acc: 0.8571428656578064)
[2024-11-03 04:30:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:10][root][INFO] - Training Epoch: 1/2, step 558/54251 completed (loss: 1.7989803552627563, acc: 0.6363636255264282)
[2024-11-03 04:30:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:11][root][INFO] - Training Epoch: 1/2, step 559/54251 completed (loss: 0.41747310757637024, acc: 1.0)
[2024-11-03 04:30:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:11][root][INFO] - Training Epoch: 1/2, step 560/54251 completed (loss: 1.1224538087844849, acc: 0.7894737124443054)
[2024-11-03 04:30:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:12][root][INFO] - Training Epoch: 1/2, step 561/54251 completed (loss: 2.417799711227417, acc: 0.5333333611488342)
[2024-11-03 04:30:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:12][root][INFO] - Training Epoch: 1/2, step 562/54251 completed (loss: 0.8407188653945923, acc: 0.78125)
[2024-11-03 04:30:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:13][root][INFO] - Training Epoch: 1/2, step 563/54251 completed (loss: 0.45509397983551025, acc: 0.8333333134651184)
[2024-11-03 04:30:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:13][root][INFO] - Training Epoch: 1/2, step 564/54251 completed (loss: 1.1026538610458374, acc: 0.8333333134651184)
[2024-11-03 04:30:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:13][root][INFO] - Training Epoch: 1/2, step 565/54251 completed (loss: 0.6321327686309814, acc: 0.9230769276618958)
[2024-11-03 04:30:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:14][root][INFO] - Training Epoch: 1/2, step 566/54251 completed (loss: 1.7504152059555054, acc: 0.6000000238418579)
[2024-11-03 04:30:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:14][root][INFO] - Training Epoch: 1/2, step 567/54251 completed (loss: 0.848414957523346, acc: 0.8695651888847351)
[2024-11-03 04:30:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:15][root][INFO] - Training Epoch: 1/2, step 568/54251 completed (loss: 0.21317307651042938, acc: 1.0)
[2024-11-03 04:30:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:15][root][INFO] - Training Epoch: 1/2, step 569/54251 completed (loss: 1.5372501611709595, acc: 0.375)
[2024-11-03 04:30:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:16][root][INFO] - Training Epoch: 1/2, step 570/54251 completed (loss: 1.5550405979156494, acc: 0.6538461446762085)
[2024-11-03 04:30:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:16][root][INFO] - Training Epoch: 1/2, step 571/54251 completed (loss: 2.729795455932617, acc: 0.4528301954269409)
[2024-11-03 04:30:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:17][root][INFO] - Training Epoch: 1/2, step 572/54251 completed (loss: 0.6309252381324768, acc: 0.8709677457809448)
[2024-11-03 04:30:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:17][root][INFO] - Training Epoch: 1/2, step 573/54251 completed (loss: 3.042745351791382, acc: 0.375)
[2024-11-03 04:30:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:18][root][INFO] - Training Epoch: 1/2, step 574/54251 completed (loss: 1.1763672828674316, acc: 0.800000011920929)
[2024-11-03 04:30:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:18][root][INFO] - Training Epoch: 1/2, step 575/54251 completed (loss: 1.7858437299728394, acc: 0.529411792755127)
[2024-11-03 04:30:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:19][root][INFO] - Training Epoch: 1/2, step 576/54251 completed (loss: 2.018795967102051, acc: 0.5799999833106995)
[2024-11-03 04:30:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:19][root][INFO] - Training Epoch: 1/2, step 577/54251 completed (loss: 1.8886442184448242, acc: 0.6206896305084229)
[2024-11-03 04:30:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:20][root][INFO] - Training Epoch: 1/2, step 578/54251 completed (loss: 0.32827553153038025, acc: 0.9180327653884888)
[2024-11-03 04:30:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:20][root][INFO] - Training Epoch: 1/2, step 579/54251 completed (loss: 1.4768955707550049, acc: 0.7272727489471436)
[2024-11-03 04:30:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:21][root][INFO] - Training Epoch: 1/2, step 580/54251 completed (loss: 1.827176809310913, acc: 0.7142857313156128)
[2024-11-03 04:30:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:21][root][INFO] - Training Epoch: 1/2, step 581/54251 completed (loss: 2.0987696647644043, acc: 0.692307710647583)
[2024-11-03 04:30:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:22][root][INFO] - Training Epoch: 1/2, step 582/54251 completed (loss: 1.8066625595092773, acc: 0.6470588445663452)
[2024-11-03 04:30:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:22][root][INFO] - Training Epoch: 1/2, step 583/54251 completed (loss: 0.6938931941986084, acc: 0.8285714387893677)
[2024-11-03 04:30:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:23][root][INFO] - Training Epoch: 1/2, step 584/54251 completed (loss: 0.8575481176376343, acc: 0.9090909361839294)
[2024-11-03 04:30:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:23][root][INFO] - Training Epoch: 1/2, step 585/54251 completed (loss: 0.7060582041740417, acc: 0.8461538553237915)
[2024-11-03 04:30:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:24][root][INFO] - Training Epoch: 1/2, step 586/54251 completed (loss: 0.5896110534667969, acc: 0.8333333134651184)
[2024-11-03 04:30:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:25][root][INFO] - Training Epoch: 1/2, step 587/54251 completed (loss: 2.984250545501709, acc: 0.4137931168079376)
[2024-11-03 04:30:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:25][root][INFO] - Training Epoch: 1/2, step 588/54251 completed (loss: 0.7808685302734375, acc: 0.8181818127632141)
[2024-11-03 04:30:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:26][root][INFO] - Training Epoch: 1/2, step 589/54251 completed (loss: 0.8595473170280457, acc: 0.7575757503509521)
[2024-11-03 04:30:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:26][root][INFO] - Training Epoch: 1/2, step 590/54251 completed (loss: 0.25368747115135193, acc: 0.9375)
[2024-11-03 04:30:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:27][root][INFO] - Training Epoch: 1/2, step 591/54251 completed (loss: 2.6447718143463135, acc: 0.46875)
[2024-11-03 04:30:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:27][root][INFO] - Training Epoch: 1/2, step 592/54251 completed (loss: 2.4471335411071777, acc: 0.5714285969734192)
[2024-11-03 04:30:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:28][root][INFO] - Training Epoch: 1/2, step 593/54251 completed (loss: 1.5191956758499146, acc: 0.7333333492279053)
[2024-11-03 04:30:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:28][root][INFO] - Training Epoch: 1/2, step 594/54251 completed (loss: 1.5762478113174438, acc: 0.699999988079071)
[2024-11-03 04:30:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:29][root][INFO] - Training Epoch: 1/2, step 595/54251 completed (loss: 0.6765159964561462, acc: 0.8387096524238586)
[2024-11-03 04:30:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:29][root][INFO] - Training Epoch: 1/2, step 596/54251 completed (loss: 1.2157318592071533, acc: 0.800000011920929)
[2024-11-03 04:30:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:30][root][INFO] - Training Epoch: 1/2, step 597/54251 completed (loss: 3.075443983078003, acc: 0.5625)
[2024-11-03 04:30:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:30][root][INFO] - Training Epoch: 1/2, step 598/54251 completed (loss: 1.10732901096344, acc: 0.7837837934494019)
[2024-11-03 04:30:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:31][root][INFO] - Training Epoch: 1/2, step 599/54251 completed (loss: 2.465442657470703, acc: 0.5581395626068115)
[2024-11-03 04:30:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:31][root][INFO] - Training Epoch: 1/2, step 600/54251 completed (loss: 1.0548495054244995, acc: 0.800000011920929)
[2024-11-03 04:30:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:32][root][INFO] - Training Epoch: 1/2, step 601/54251 completed (loss: 1.336559534072876, acc: 0.7575757503509521)
[2024-11-03 04:30:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:32][root][INFO] - Training Epoch: 1/2, step 602/54251 completed (loss: 2.378077268600464, acc: 0.6000000238418579)
[2024-11-03 04:30:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:33][root][INFO] - Training Epoch: 1/2, step 603/54251 completed (loss: 1.906217098236084, acc: 0.5833333134651184)
[2024-11-03 04:30:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:33][root][INFO] - Training Epoch: 1/2, step 604/54251 completed (loss: 0.4443216919898987, acc: 0.9411764740943909)
[2024-11-03 04:30:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:34][root][INFO] - Training Epoch: 1/2, step 605/54251 completed (loss: 1.972800850868225, acc: 0.5)
[2024-11-03 04:30:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:34][root][INFO] - Training Epoch: 1/2, step 606/54251 completed (loss: 0.4350079298019409, acc: 0.9032257795333862)
[2024-11-03 04:30:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:35][root][INFO] - Training Epoch: 1/2, step 607/54251 completed (loss: 2.454108715057373, acc: 0.46875)
[2024-11-03 04:30:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:35][root][INFO] - Training Epoch: 1/2, step 608/54251 completed (loss: 1.0123471021652222, acc: 0.7804877758026123)
[2024-11-03 04:30:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:36][root][INFO] - Training Epoch: 1/2, step 609/54251 completed (loss: 1.0096721649169922, acc: 0.7567567825317383)
[2024-11-03 04:30:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:36][root][INFO] - Training Epoch: 1/2, step 610/54251 completed (loss: 0.8636800646781921, acc: 0.8571428656578064)
[2024-11-03 04:30:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:37][root][INFO] - Training Epoch: 1/2, step 611/54251 completed (loss: 1.0518591403961182, acc: 0.7916666865348816)
[2024-11-03 04:30:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:37][root][INFO] - Training Epoch: 1/2, step 612/54251 completed (loss: 0.9388104677200317, acc: 0.8500000238418579)
[2024-11-03 04:30:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:38][root][INFO] - Training Epoch: 1/2, step 613/54251 completed (loss: 1.4211479425430298, acc: 0.7179487347602844)
[2024-11-03 04:30:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:38][root][INFO] - Training Epoch: 1/2, step 614/54251 completed (loss: 2.693830728530884, acc: 0.5833333134651184)
[2024-11-03 04:30:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:39][root][INFO] - Training Epoch: 1/2, step 615/54251 completed (loss: 0.7337709069252014, acc: 0.8333333134651184)
[2024-11-03 04:30:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:39][root][INFO] - Training Epoch: 1/2, step 616/54251 completed (loss: 2.797747850418091, acc: 0.6000000238418579)
[2024-11-03 04:30:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:40][root][INFO] - Training Epoch: 1/2, step 617/54251 completed (loss: 3.0347847938537598, acc: 0.3684210479259491)
[2024-11-03 04:30:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:40][root][INFO] - Training Epoch: 1/2, step 618/54251 completed (loss: 2.5447194576263428, acc: 0.47058823704719543)
[2024-11-03 04:30:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:41][root][INFO] - Training Epoch: 1/2, step 619/54251 completed (loss: 0.9627949595451355, acc: 0.800000011920929)
[2024-11-03 04:30:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:41][root][INFO] - Training Epoch: 1/2, step 620/54251 completed (loss: 0.573219895362854, acc: 0.8399999737739563)
[2024-11-03 04:30:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:42][root][INFO] - Training Epoch: 1/2, step 621/54251 completed (loss: 0.5516173839569092, acc: 0.8461538553237915)
[2024-11-03 04:30:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:42][root][INFO] - Training Epoch: 1/2, step 622/54251 completed (loss: 3.3210558891296387, acc: 0.4399999976158142)
[2024-11-03 04:30:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:43][root][INFO] - Training Epoch: 1/2, step 623/54251 completed (loss: 0.8617420792579651, acc: 0.9333333373069763)
[2024-11-03 04:30:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:43][root][INFO] - Training Epoch: 1/2, step 624/54251 completed (loss: 1.2638473510742188, acc: 0.75)
[2024-11-03 04:30:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:44][root][INFO] - Training Epoch: 1/2, step 625/54251 completed (loss: 0.7512675523757935, acc: 0.875)
[2024-11-03 04:30:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:44][root][INFO] - Training Epoch: 1/2, step 626/54251 completed (loss: 0.44652336835861206, acc: 0.9200000166893005)
[2024-11-03 04:30:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:45][root][INFO] - Training Epoch: 1/2, step 627/54251 completed (loss: 1.229482650756836, acc: 0.692307710647583)
[2024-11-03 04:30:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:45][root][INFO] - Training Epoch: 1/2, step 628/54251 completed (loss: 0.4123751223087311, acc: 0.8888888955116272)
[2024-11-03 04:30:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:46][root][INFO] - Training Epoch: 1/2, step 629/54251 completed (loss: 0.6387702226638794, acc: 0.7749999761581421)
[2024-11-03 04:30:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:46][root][INFO] - Training Epoch: 1/2, step 630/54251 completed (loss: 1.8787105083465576, acc: 0.6000000238418579)
[2024-11-03 04:30:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:47][root][INFO] - Training Epoch: 1/2, step 631/54251 completed (loss: 0.9896686673164368, acc: 0.7674418687820435)
[2024-11-03 04:30:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:47][root][INFO] - Training Epoch: 1/2, step 632/54251 completed (loss: 0.7185966968536377, acc: 0.8333333134651184)
[2024-11-03 04:30:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:48][root][INFO] - Training Epoch: 1/2, step 633/54251 completed (loss: 3.5814738273620605, acc: 0.3888888955116272)
[2024-11-03 04:30:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:48][root][INFO] - Training Epoch: 1/2, step 634/54251 completed (loss: 0.46984344720840454, acc: 0.8571428656578064)
[2024-11-03 04:30:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:49][root][INFO] - Training Epoch: 1/2, step 635/54251 completed (loss: 0.7735968828201294, acc: 0.8461538553237915)
[2024-11-03 04:30:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:49][root][INFO] - Training Epoch: 1/2, step 636/54251 completed (loss: 0.4526377320289612, acc: 0.8823529481887817)
[2024-11-03 04:30:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:50][root][INFO] - Training Epoch: 1/2, step 637/54251 completed (loss: 3.1536142826080322, acc: 0.4166666567325592)
[2024-11-03 04:30:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:50][root][INFO] - Training Epoch: 1/2, step 638/54251 completed (loss: 1.272588849067688, acc: 0.797468364238739)
[2024-11-03 04:30:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:51][root][INFO] - Training Epoch: 1/2, step 639/54251 completed (loss: 1.065332055091858, acc: 0.8125)
[2024-11-03 04:30:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:51][root][INFO] - Training Epoch: 1/2, step 640/54251 completed (loss: 0.7940682768821716, acc: 0.8799999952316284)
[2024-11-03 04:30:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:52][root][INFO] - Training Epoch: 1/2, step 641/54251 completed (loss: 2.0622007846832275, acc: 0.6181818246841431)
[2024-11-03 04:30:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:52][root][INFO] - Training Epoch: 1/2, step 642/54251 completed (loss: 2.178205966949463, acc: 0.5263158082962036)
[2024-11-03 04:30:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:53][root][INFO] - Training Epoch: 1/2, step 643/54251 completed (loss: 0.528695285320282, acc: 0.8888888955116272)
[2024-11-03 04:30:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:53][root][INFO] - Training Epoch: 1/2, step 644/54251 completed (loss: 1.032101035118103, acc: 0.7894737124443054)
[2024-11-03 04:30:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:54][root][INFO] - Training Epoch: 1/2, step 645/54251 completed (loss: 0.97232586145401, acc: 0.7894737124443054)
[2024-11-03 04:30:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:54][root][INFO] - Training Epoch: 1/2, step 646/54251 completed (loss: 1.2287931442260742, acc: 0.8095238208770752)
[2024-11-03 04:30:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:55][root][INFO] - Training Epoch: 1/2, step 647/54251 completed (loss: 0.7489942908287048, acc: 0.8571428656578064)
[2024-11-03 04:30:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:55][root][INFO] - Training Epoch: 1/2, step 648/54251 completed (loss: 1.2544246912002563, acc: 0.7599999904632568)
[2024-11-03 04:30:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:56][root][INFO] - Training Epoch: 1/2, step 649/54251 completed (loss: 1.8753490447998047, acc: 0.7083333134651184)
[2024-11-03 04:30:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:56][root][INFO] - Training Epoch: 1/2, step 650/54251 completed (loss: 3.9298837184906006, acc: 0.3333333432674408)
[2024-11-03 04:30:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:57][root][INFO] - Training Epoch: 1/2, step 651/54251 completed (loss: 3.574812650680542, acc: 0.3333333432674408)
[2024-11-03 04:30:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:57][root][INFO] - Training Epoch: 1/2, step 652/54251 completed (loss: 1.547255039215088, acc: 0.75)
[2024-11-03 04:30:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:58][root][INFO] - Training Epoch: 1/2, step 653/54251 completed (loss: 1.4316133260726929, acc: 0.625)
[2024-11-03 04:30:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:58][root][INFO] - Training Epoch: 1/2, step 654/54251 completed (loss: 0.31605762243270874, acc: 0.931034505367279)
[2024-11-03 04:30:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:59][root][INFO] - Training Epoch: 1/2, step 655/54251 completed (loss: 1.3922319412231445, acc: 0.761904776096344)
[2024-11-03 04:30:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:30:59][root][INFO] - Training Epoch: 1/2, step 656/54251 completed (loss: 1.8635061979293823, acc: 0.6666666865348816)
[2024-11-03 04:30:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:00][root][INFO] - Training Epoch: 1/2, step 657/54251 completed (loss: 2.4472599029541016, acc: 0.529411792755127)
[2024-11-03 04:31:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:00][root][INFO] - Training Epoch: 1/2, step 658/54251 completed (loss: 2.2794198989868164, acc: 0.6666666865348816)
[2024-11-03 04:31:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:01][root][INFO] - Training Epoch: 1/2, step 659/54251 completed (loss: 0.9060847163200378, acc: 0.8571428656578064)
[2024-11-03 04:31:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:01][root][INFO] - Training Epoch: 1/2, step 660/54251 completed (loss: 2.1611499786376953, acc: 0.6315789222717285)
[2024-11-03 04:31:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:02][root][INFO] - Training Epoch: 1/2, step 661/54251 completed (loss: 3.181955575942993, acc: 0.5)
[2024-11-03 04:31:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:02][root][INFO] - Training Epoch: 1/2, step 662/54251 completed (loss: 0.9196969866752625, acc: 0.699999988079071)
[2024-11-03 04:31:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:02][root][INFO] - Training Epoch: 1/2, step 663/54251 completed (loss: 0.699712336063385, acc: 0.8181818127632141)
[2024-11-03 04:31:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:03][root][INFO] - Training Epoch: 1/2, step 664/54251 completed (loss: 0.7874243259429932, acc: 0.8518518805503845)
[2024-11-03 04:31:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:03][root][INFO] - Training Epoch: 1/2, step 665/54251 completed (loss: 1.4833850860595703, acc: 0.6842105388641357)
[2024-11-03 04:31:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:04][root][INFO] - Training Epoch: 1/2, step 666/54251 completed (loss: 0.966110348701477, acc: 0.800000011920929)
[2024-11-03 04:31:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:04][root][INFO] - Training Epoch: 1/2, step 667/54251 completed (loss: 1.3072525262832642, acc: 0.695652186870575)
[2024-11-03 04:31:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:05][root][INFO] - Training Epoch: 1/2, step 668/54251 completed (loss: 0.8105498552322388, acc: 0.8461538553237915)
[2024-11-03 04:31:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:06][root][INFO] - Training Epoch: 1/2, step 669/54251 completed (loss: 1.3781077861785889, acc: 0.6976743936538696)
[2024-11-03 04:31:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:06][root][INFO] - Training Epoch: 1/2, step 670/54251 completed (loss: 0.5394652485847473, acc: 0.8214285969734192)
[2024-11-03 04:31:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:07][root][INFO] - Training Epoch: 1/2, step 671/54251 completed (loss: 2.6714649200439453, acc: 0.5833333134651184)
[2024-11-03 04:31:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:07][root][INFO] - Training Epoch: 1/2, step 672/54251 completed (loss: 1.9079012870788574, acc: 0.6888889074325562)
[2024-11-03 04:31:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:08][root][INFO] - Training Epoch: 1/2, step 673/54251 completed (loss: 1.6380870342254639, acc: 0.6399999856948853)
[2024-11-03 04:31:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:08][root][INFO] - Training Epoch: 1/2, step 674/54251 completed (loss: 1.6512905359268188, acc: 0.6666666865348816)
[2024-11-03 04:31:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:09][root][INFO] - Training Epoch: 1/2, step 675/54251 completed (loss: 2.442800760269165, acc: 0.5384615659713745)
[2024-11-03 04:31:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:09][root][INFO] - Training Epoch: 1/2, step 676/54251 completed (loss: 1.4412542581558228, acc: 0.6000000238418579)
[2024-11-03 04:31:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:10][root][INFO] - Training Epoch: 1/2, step 677/54251 completed (loss: 0.7981578707695007, acc: 0.8333333134651184)
[2024-11-03 04:31:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:10][root][INFO] - Training Epoch: 1/2, step 678/54251 completed (loss: 1.2259167432785034, acc: 0.7368420958518982)
[2024-11-03 04:31:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:11][root][INFO] - Training Epoch: 1/2, step 679/54251 completed (loss: 0.6751097440719604, acc: 0.8571428656578064)
[2024-11-03 04:31:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:11][root][INFO] - Training Epoch: 1/2, step 680/54251 completed (loss: 0.778785765171051, acc: 0.8478260636329651)
[2024-11-03 04:31:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:12][root][INFO] - Training Epoch: 1/2, step 681/54251 completed (loss: 2.1271984577178955, acc: 0.6875)
[2024-11-03 04:31:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:12][root][INFO] - Training Epoch: 1/2, step 682/54251 completed (loss: 1.1020020246505737, acc: 0.6896551847457886)
[2024-11-03 04:31:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:13][root][INFO] - Training Epoch: 1/2, step 683/54251 completed (loss: 1.6156928539276123, acc: 0.7058823704719543)
[2024-11-03 04:31:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:13][root][INFO] - Training Epoch: 1/2, step 684/54251 completed (loss: 1.7323154211044312, acc: 0.6363636255264282)
[2024-11-03 04:31:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:14][root][INFO] - Training Epoch: 1/2, step 685/54251 completed (loss: 1.0986692905426025, acc: 0.75)
[2024-11-03 04:31:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:14][root][INFO] - Training Epoch: 1/2, step 686/54251 completed (loss: 4.254189491271973, acc: 0.23076923191547394)
[2024-11-03 04:31:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:15][root][INFO] - Training Epoch: 1/2, step 687/54251 completed (loss: 3.8980209827423096, acc: 0.3928571343421936)
[2024-11-03 04:31:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:15][root][INFO] - Training Epoch: 1/2, step 688/54251 completed (loss: 0.5412095189094543, acc: 0.8333333134651184)
[2024-11-03 04:31:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:16][root][INFO] - Training Epoch: 1/2, step 689/54251 completed (loss: 2.7181029319763184, acc: 0.4615384638309479)
[2024-11-03 04:31:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:16][root][INFO] - Training Epoch: 1/2, step 690/54251 completed (loss: 2.9078609943389893, acc: 0.38461539149284363)
[2024-11-03 04:31:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:17][root][INFO] - Training Epoch: 1/2, step 691/54251 completed (loss: 1.898597240447998, acc: 0.46666666865348816)
[2024-11-03 04:31:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:17][root][INFO] - Training Epoch: 1/2, step 692/54251 completed (loss: 1.2989798784255981, acc: 0.8333333134651184)
[2024-11-03 04:31:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:18][root][INFO] - Training Epoch: 1/2, step 693/54251 completed (loss: 0.5379768013954163, acc: 0.8999999761581421)
[2024-11-03 04:31:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:18][root][INFO] - Training Epoch: 1/2, step 694/54251 completed (loss: 3.5834522247314453, acc: 0.25)
[2024-11-03 04:31:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:19][root][INFO] - Training Epoch: 1/2, step 695/54251 completed (loss: 1.8507930040359497, acc: 0.7857142686843872)
[2024-11-03 04:31:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:19][root][INFO] - Training Epoch: 1/2, step 696/54251 completed (loss: 1.003272533416748, acc: 0.7954545617103577)
[2024-11-03 04:31:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:20][root][INFO] - Training Epoch: 1/2, step 697/54251 completed (loss: 0.7088523507118225, acc: 0.8181818127632141)
[2024-11-03 04:31:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:20][root][INFO] - Training Epoch: 1/2, step 698/54251 completed (loss: 0.5936656594276428, acc: 0.7894737124443054)
[2024-11-03 04:31:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:21][root][INFO] - Training Epoch: 1/2, step 699/54251 completed (loss: 0.6280747056007385, acc: 0.8421052694320679)
[2024-11-03 04:31:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:21][root][INFO] - Training Epoch: 1/2, step 700/54251 completed (loss: 0.7039294838905334, acc: 0.8918918967247009)
[2024-11-03 04:31:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:22][root][INFO] - Training Epoch: 1/2, step 701/54251 completed (loss: 1.7342162132263184, acc: 0.6363636255264282)
[2024-11-03 04:31:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:22][root][INFO] - Training Epoch: 1/2, step 702/54251 completed (loss: 2.0688066482543945, acc: 0.604651153087616)
[2024-11-03 04:31:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:23][root][INFO] - Training Epoch: 1/2, step 703/54251 completed (loss: 1.1404902935028076, acc: 0.7777777910232544)
[2024-11-03 04:31:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:23][root][INFO] - Training Epoch: 1/2, step 704/54251 completed (loss: 3.35459041595459, acc: 0.3870967626571655)
[2024-11-03 04:31:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:24][root][INFO] - Training Epoch: 1/2, step 705/54251 completed (loss: 0.9218000769615173, acc: 0.761904776096344)
[2024-11-03 04:31:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:24][root][INFO] - Training Epoch: 1/2, step 706/54251 completed (loss: 1.2744585275650024, acc: 0.75)
[2024-11-03 04:31:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:25][root][INFO] - Training Epoch: 1/2, step 707/54251 completed (loss: 0.659662127494812, acc: 0.8333333134651184)
[2024-11-03 04:31:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:25][root][INFO] - Training Epoch: 1/2, step 708/54251 completed (loss: 0.8393431901931763, acc: 0.8085106611251831)
[2024-11-03 04:31:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:26][root][INFO] - Training Epoch: 1/2, step 709/54251 completed (loss: 1.3634291887283325, acc: 0.6428571343421936)
[2024-11-03 04:31:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:26][root][INFO] - Training Epoch: 1/2, step 710/54251 completed (loss: 2.9203906059265137, acc: 0.5151515007019043)
[2024-11-03 04:31:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:27][root][INFO] - Training Epoch: 1/2, step 711/54251 completed (loss: 1.944881796836853, acc: 0.6000000238418579)
[2024-11-03 04:31:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:27][root][INFO] - Training Epoch: 1/2, step 712/54251 completed (loss: 1.992136836051941, acc: 0.6666666865348816)
[2024-11-03 04:31:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:28][root][INFO] - Training Epoch: 1/2, step 713/54251 completed (loss: 1.016266942024231, acc: 0.7727272510528564)
[2024-11-03 04:31:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:28][root][INFO] - Training Epoch: 1/2, step 714/54251 completed (loss: 0.5852049589157104, acc: 0.875)
[2024-11-03 04:31:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:29][root][INFO] - Training Epoch: 1/2, step 715/54251 completed (loss: 1.5816047191619873, acc: 0.6315789222717285)
[2024-11-03 04:31:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:29][root][INFO] - Training Epoch: 1/2, step 716/54251 completed (loss: 1.040289044380188, acc: 0.8399999737739563)
[2024-11-03 04:31:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:30][root][INFO] - Training Epoch: 1/2, step 717/54251 completed (loss: 0.38606497645378113, acc: 1.0)
[2024-11-03 04:31:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:30][root][INFO] - Training Epoch: 1/2, step 718/54251 completed (loss: 2.8255817890167236, acc: 0.375)
[2024-11-03 04:31:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:31][root][INFO] - Training Epoch: 1/2, step 719/54251 completed (loss: 1.3599610328674316, acc: 0.7575757503509521)
[2024-11-03 04:31:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:31][root][INFO] - Training Epoch: 1/2, step 720/54251 completed (loss: 0.2623007297515869, acc: 0.931034505367279)
[2024-11-03 04:31:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:32][root][INFO] - Training Epoch: 1/2, step 721/54251 completed (loss: 1.5324039459228516, acc: 0.6000000238418579)
[2024-11-03 04:31:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:32][root][INFO] - Training Epoch: 1/2, step 722/54251 completed (loss: 0.4235668480396271, acc: 0.9130434989929199)
[2024-11-03 04:31:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:33][root][INFO] - Training Epoch: 1/2, step 723/54251 completed (loss: 0.41872674226760864, acc: 0.9599999785423279)
[2024-11-03 04:31:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:33][root][INFO] - Training Epoch: 1/2, step 724/54251 completed (loss: 0.24261218309402466, acc: 0.9615384340286255)
[2024-11-03 04:31:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:34][root][INFO] - Training Epoch: 1/2, step 725/54251 completed (loss: 1.1838254928588867, acc: 0.7941176295280457)
[2024-11-03 04:31:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:34][root][INFO] - Training Epoch: 1/2, step 726/54251 completed (loss: 1.8805670738220215, acc: 0.6000000238418579)
[2024-11-03 04:31:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:35][root][INFO] - Training Epoch: 1/2, step 727/54251 completed (loss: 0.9026643633842468, acc: 0.800000011920929)
[2024-11-03 04:31:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:35][root][INFO] - Training Epoch: 1/2, step 728/54251 completed (loss: 0.8094069957733154, acc: 0.8461538553237915)
[2024-11-03 04:31:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:36][root][INFO] - Training Epoch: 1/2, step 729/54251 completed (loss: 0.8065131306648254, acc: 0.807692289352417)
[2024-11-03 04:31:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:36][root][INFO] - Training Epoch: 1/2, step 730/54251 completed (loss: 2.1258163452148438, acc: 0.5714285969734192)
[2024-11-03 04:31:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:37][root][INFO] - Training Epoch: 1/2, step 731/54251 completed (loss: 1.051257610321045, acc: 0.8139534592628479)
[2024-11-03 04:31:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:37][root][INFO] - Training Epoch: 1/2, step 732/54251 completed (loss: 1.4574354887008667, acc: 0.75)
[2024-11-03 04:31:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:38][root][INFO] - Training Epoch: 1/2, step 733/54251 completed (loss: 0.6945182085037231, acc: 0.8055555820465088)
[2024-11-03 04:31:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:38][root][INFO] - Training Epoch: 1/2, step 734/54251 completed (loss: 1.2041212320327759, acc: 0.7777777910232544)
[2024-11-03 04:31:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:39][root][INFO] - Training Epoch: 1/2, step 735/54251 completed (loss: 1.6198418140411377, acc: 0.699999988079071)
[2024-11-03 04:31:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:39][root][INFO] - Training Epoch: 1/2, step 736/54251 completed (loss: 2.1053905487060547, acc: 0.4285714328289032)
[2024-11-03 04:31:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:40][root][INFO] - Training Epoch: 1/2, step 737/54251 completed (loss: 0.5270421504974365, acc: 0.9444444179534912)
[2024-11-03 04:31:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:40][root][INFO] - Training Epoch: 1/2, step 738/54251 completed (loss: 0.9542257189750671, acc: 0.8181818127632141)
[2024-11-03 04:31:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:41][root][INFO] - Training Epoch: 1/2, step 739/54251 completed (loss: 1.8619613647460938, acc: 0.6315789222717285)
[2024-11-03 04:31:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:42][root][INFO] - Training Epoch: 1/2, step 740/54251 completed (loss: 1.1405529975891113, acc: 0.8500000238418579)
[2024-11-03 04:31:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:42][root][INFO] - Training Epoch: 1/2, step 741/54251 completed (loss: 0.19020265340805054, acc: 1.0)
[2024-11-03 04:31:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:43][root][INFO] - Training Epoch: 1/2, step 742/54251 completed (loss: 1.1579551696777344, acc: 0.692307710647583)
[2024-11-03 04:31:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:43][root][INFO] - Training Epoch: 1/2, step 743/54251 completed (loss: 1.1228704452514648, acc: 0.8095238208770752)
[2024-11-03 04:31:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:44][root][INFO] - Training Epoch: 1/2, step 744/54251 completed (loss: 1.4096972942352295, acc: 0.7200000286102295)
[2024-11-03 04:31:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:44][root][INFO] - Training Epoch: 1/2, step 745/54251 completed (loss: 1.043144702911377, acc: 0.6944444179534912)
[2024-11-03 04:31:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:45][root][INFO] - Training Epoch: 1/2, step 746/54251 completed (loss: 1.8269047737121582, acc: 0.5454545617103577)
[2024-11-03 04:31:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:45][root][INFO] - Training Epoch: 1/2, step 747/54251 completed (loss: 0.9769112467765808, acc: 0.8055555820465088)
[2024-11-03 04:31:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:45][root][INFO] - Training Epoch: 1/2, step 748/54251 completed (loss: 1.7387629747390747, acc: 0.6551724076271057)
[2024-11-03 04:31:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:46][root][INFO] - Training Epoch: 1/2, step 749/54251 completed (loss: 1.2572022676467896, acc: 0.8103448152542114)
[2024-11-03 04:31:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:46][root][INFO] - Training Epoch: 1/2, step 750/54251 completed (loss: 0.8738101124763489, acc: 0.6666666865348816)
[2024-11-03 04:31:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:47][root][INFO] - Training Epoch: 1/2, step 751/54251 completed (loss: 3.1472768783569336, acc: 0.40625)
[2024-11-03 04:31:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:47][root][INFO] - Training Epoch: 1/2, step 752/54251 completed (loss: 1.1920697689056396, acc: 0.7948718070983887)
[2024-11-03 04:31:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:48][root][INFO] - Training Epoch: 1/2, step 753/54251 completed (loss: 1.2764867544174194, acc: 0.5714285969734192)
[2024-11-03 04:31:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:48][root][INFO] - Training Epoch: 1/2, step 754/54251 completed (loss: 0.9584510326385498, acc: 0.800000011920929)
[2024-11-03 04:31:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:49][root][INFO] - Training Epoch: 1/2, step 755/54251 completed (loss: 0.6329599618911743, acc: 0.7894737124443054)
[2024-11-03 04:31:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:49][root][INFO] - Training Epoch: 1/2, step 756/54251 completed (loss: 0.34841686487197876, acc: 0.9200000166893005)
[2024-11-03 04:31:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:50][root][INFO] - Training Epoch: 1/2, step 757/54251 completed (loss: 0.5916111469268799, acc: 0.8518518805503845)
[2024-11-03 04:31:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:50][root][INFO] - Training Epoch: 1/2, step 758/54251 completed (loss: 1.5250107049942017, acc: 0.7241379022598267)
[2024-11-03 04:31:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:51][root][INFO] - Training Epoch: 1/2, step 759/54251 completed (loss: 0.8235057592391968, acc: 0.800000011920929)
[2024-11-03 04:31:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:51][root][INFO] - Training Epoch: 1/2, step 760/54251 completed (loss: 1.003585934638977, acc: 0.7777777910232544)
[2024-11-03 04:31:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:52][root][INFO] - Training Epoch: 1/2, step 761/54251 completed (loss: 1.8596820831298828, acc: 0.5)
[2024-11-03 04:31:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:52][root][INFO] - Training Epoch: 1/2, step 762/54251 completed (loss: 1.374269723892212, acc: 0.7692307829856873)
[2024-11-03 04:31:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:53][root][INFO] - Training Epoch: 1/2, step 763/54251 completed (loss: 1.013379693031311, acc: 0.7142857313156128)
[2024-11-03 04:31:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:53][root][INFO] - Training Epoch: 1/2, step 764/54251 completed (loss: 0.7365970611572266, acc: 0.8846153616905212)
[2024-11-03 04:31:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:54][root][INFO] - Training Epoch: 1/2, step 765/54251 completed (loss: 0.30942919850349426, acc: 0.95652174949646)
[2024-11-03 04:31:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:54][root][INFO] - Training Epoch: 1/2, step 766/54251 completed (loss: 0.6224181056022644, acc: 0.8837209343910217)
[2024-11-03 04:31:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:55][root][INFO] - Training Epoch: 1/2, step 767/54251 completed (loss: 0.15191026031970978, acc: 1.0)
[2024-11-03 04:31:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:55][root][INFO] - Training Epoch: 1/2, step 768/54251 completed (loss: 1.7458841800689697, acc: 0.6428571343421936)
[2024-11-03 04:31:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:56][root][INFO] - Training Epoch: 1/2, step 769/54251 completed (loss: 0.8808034658432007, acc: 0.875)
[2024-11-03 04:31:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:56][root][INFO] - Training Epoch: 1/2, step 770/54251 completed (loss: 3.1029789447784424, acc: 0.42105263471603394)
[2024-11-03 04:31:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:57][root][INFO] - Training Epoch: 1/2, step 771/54251 completed (loss: 0.7591941356658936, acc: 0.8181818127632141)
[2024-11-03 04:31:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:57][root][INFO] - Training Epoch: 1/2, step 772/54251 completed (loss: 0.7975394129753113, acc: 0.7878788113594055)
[2024-11-03 04:31:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:58][root][INFO] - Training Epoch: 1/2, step 773/54251 completed (loss: 1.2623482942581177, acc: 0.7222222089767456)
[2024-11-03 04:31:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:58][root][INFO] - Training Epoch: 1/2, step 774/54251 completed (loss: 0.563290536403656, acc: 0.8823529481887817)
[2024-11-03 04:31:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:59][root][INFO] - Training Epoch: 1/2, step 775/54251 completed (loss: 0.5301288366317749, acc: 0.9090909361839294)
[2024-11-03 04:31:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:31:59][root][INFO] - Training Epoch: 1/2, step 776/54251 completed (loss: 0.5259535312652588, acc: 0.8947368264198303)
[2024-11-03 04:31:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:00][root][INFO] - Training Epoch: 1/2, step 777/54251 completed (loss: 1.158822774887085, acc: 0.7142857313156128)
[2024-11-03 04:32:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:00][root][INFO] - Training Epoch: 1/2, step 778/54251 completed (loss: 0.253174364566803, acc: 0.9512194991111755)
[2024-11-03 04:32:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:01][root][INFO] - Training Epoch: 1/2, step 779/54251 completed (loss: 0.38290926814079285, acc: 0.8500000238418579)
[2024-11-03 04:32:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:01][root][INFO] - Training Epoch: 1/2, step 780/54251 completed (loss: 1.1400399208068848, acc: 0.8333333134651184)
[2024-11-03 04:32:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:02][root][INFO] - Training Epoch: 1/2, step 781/54251 completed (loss: 2.809357166290283, acc: 0.4000000059604645)
[2024-11-03 04:32:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:02][root][INFO] - Training Epoch: 1/2, step 782/54251 completed (loss: 0.5124458074569702, acc: 0.9230769276618958)
[2024-11-03 04:32:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:03][root][INFO] - Training Epoch: 1/2, step 783/54251 completed (loss: 1.498056173324585, acc: 0.6666666865348816)
[2024-11-03 04:32:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:03][root][INFO] - Training Epoch: 1/2, step 784/54251 completed (loss: 1.0218864679336548, acc: 0.8148148059844971)
[2024-11-03 04:32:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:04][root][INFO] - Training Epoch: 1/2, step 785/54251 completed (loss: 0.9333956837654114, acc: 0.6000000238418579)
[2024-11-03 04:32:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:04][root][INFO] - Training Epoch: 1/2, step 786/54251 completed (loss: 0.32670873403549194, acc: 0.9444444179534912)
[2024-11-03 04:32:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:05][root][INFO] - Training Epoch: 1/2, step 787/54251 completed (loss: 0.7219918966293335, acc: 0.8799999952316284)
[2024-11-03 04:32:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:05][root][INFO] - Training Epoch: 1/2, step 788/54251 completed (loss: 0.9107462167739868, acc: 0.7931034564971924)
[2024-11-03 04:32:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:06][root][INFO] - Training Epoch: 1/2, step 789/54251 completed (loss: 1.6803375482559204, acc: 0.695652186870575)
[2024-11-03 04:32:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:06][root][INFO] - Training Epoch: 1/2, step 790/54251 completed (loss: 1.7004013061523438, acc: 0.6842105388641357)
[2024-11-03 04:32:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:07][root][INFO] - Training Epoch: 1/2, step 791/54251 completed (loss: 0.21601605415344238, acc: 1.0)
[2024-11-03 04:32:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:07][root][INFO] - Training Epoch: 1/2, step 792/54251 completed (loss: 0.5081753134727478, acc: 0.8857142925262451)
[2024-11-03 04:32:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:08][root][INFO] - Training Epoch: 1/2, step 793/54251 completed (loss: 0.446438729763031, acc: 0.949999988079071)
[2024-11-03 04:32:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:08][root][INFO] - Training Epoch: 1/2, step 794/54251 completed (loss: 1.0432343482971191, acc: 0.7777777910232544)
[2024-11-03 04:32:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:09][root][INFO] - Training Epoch: 1/2, step 795/54251 completed (loss: 0.5885874629020691, acc: 0.7272727489471436)
[2024-11-03 04:32:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:09][root][INFO] - Training Epoch: 1/2, step 796/54251 completed (loss: 2.0725066661834717, acc: 0.7142857313156128)
[2024-11-03 04:32:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:10][root][INFO] - Training Epoch: 1/2, step 797/54251 completed (loss: 0.2536335289478302, acc: 1.0)
[2024-11-03 04:32:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:10][root][INFO] - Training Epoch: 1/2, step 798/54251 completed (loss: 0.7173631191253662, acc: 0.8793103694915771)
[2024-11-03 04:32:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:11][root][INFO] - Training Epoch: 1/2, step 799/54251 completed (loss: 0.9350835680961609, acc: 0.75)
[2024-11-03 04:32:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:11][root][INFO] - Training Epoch: 1/2, step 800/54251 completed (loss: 2.8841183185577393, acc: 0.44999998807907104)
[2024-11-03 04:32:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:12][root][INFO] - Training Epoch: 1/2, step 801/54251 completed (loss: 0.4314006567001343, acc: 0.8333333134651184)
[2024-11-03 04:32:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:12][root][INFO] - Training Epoch: 1/2, step 802/54251 completed (loss: 0.5173155665397644, acc: 0.9333333373069763)
[2024-11-03 04:32:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:13][root][INFO] - Training Epoch: 1/2, step 803/54251 completed (loss: 1.7488152980804443, acc: 0.774193525314331)
[2024-11-03 04:32:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:13][root][INFO] - Training Epoch: 1/2, step 804/54251 completed (loss: 1.624753475189209, acc: 0.7241379022598267)
[2024-11-03 04:32:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:14][root][INFO] - Training Epoch: 1/2, step 805/54251 completed (loss: 3.021939516067505, acc: 0.3571428656578064)
[2024-11-03 04:32:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:14][root][INFO] - Training Epoch: 1/2, step 806/54251 completed (loss: 0.967485785484314, acc: 0.800000011920929)
[2024-11-03 04:32:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:15][root][INFO] - Training Epoch: 1/2, step 807/54251 completed (loss: 1.0855176448822021, acc: 0.800000011920929)
[2024-11-03 04:32:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:15][root][INFO] - Training Epoch: 1/2, step 808/54251 completed (loss: 1.4800184965133667, acc: 0.6000000238418579)
[2024-11-03 04:32:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:15][root][INFO] - Training Epoch: 1/2, step 809/54251 completed (loss: 4.302602767944336, acc: 0.375)
[2024-11-03 04:32:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:16][root][INFO] - Training Epoch: 1/2, step 810/54251 completed (loss: 0.9926388263702393, acc: 0.7692307829856873)
[2024-11-03 04:32:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:16][root][INFO] - Training Epoch: 1/2, step 811/54251 completed (loss: 0.9537296891212463, acc: 0.7346938848495483)
[2024-11-03 04:32:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:17][root][INFO] - Training Epoch: 1/2, step 812/54251 completed (loss: 0.7860165238380432, acc: 0.8409090638160706)
[2024-11-03 04:32:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:17][root][INFO] - Training Epoch: 1/2, step 813/54251 completed (loss: 0.557398796081543, acc: 0.8181818127632141)
[2024-11-03 04:32:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:18][root][INFO] - Training Epoch: 1/2, step 814/54251 completed (loss: 0.3450065851211548, acc: 1.0)
[2024-11-03 04:32:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:18][root][INFO] - Training Epoch: 1/2, step 815/54251 completed (loss: 2.6336207389831543, acc: 0.2857142984867096)
[2024-11-03 04:32:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:19][root][INFO] - Training Epoch: 1/2, step 816/54251 completed (loss: 1.3881473541259766, acc: 0.692307710647583)
[2024-11-03 04:32:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:19][root][INFO] - Training Epoch: 1/2, step 817/54251 completed (loss: 1.7817107439041138, acc: 0.6818181872367859)
[2024-11-03 04:32:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:20][root][INFO] - Training Epoch: 1/2, step 818/54251 completed (loss: 1.4598422050476074, acc: 0.6470588445663452)
[2024-11-03 04:32:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:20][root][INFO] - Training Epoch: 1/2, step 819/54251 completed (loss: 1.5010855197906494, acc: 0.7241379022598267)
[2024-11-03 04:32:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:21][root][INFO] - Training Epoch: 1/2, step 820/54251 completed (loss: 1.6647796630859375, acc: 0.7142857313156128)
[2024-11-03 04:32:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:21][root][INFO] - Training Epoch: 1/2, step 821/54251 completed (loss: 1.5564662218093872, acc: 0.75)
[2024-11-03 04:32:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:22][root][INFO] - Training Epoch: 1/2, step 822/54251 completed (loss: 0.5478642582893372, acc: 0.9166666865348816)
[2024-11-03 04:32:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:22][root][INFO] - Training Epoch: 1/2, step 823/54251 completed (loss: 1.419501781463623, acc: 0.7419354915618896)
[2024-11-03 04:32:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:23][root][INFO] - Training Epoch: 1/2, step 824/54251 completed (loss: 2.1232378482818604, acc: 0.4000000059604645)
[2024-11-03 04:32:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:23][root][INFO] - Training Epoch: 1/2, step 825/54251 completed (loss: 1.885353922843933, acc: 0.6666666865348816)
[2024-11-03 04:32:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:24][root][INFO] - Training Epoch: 1/2, step 826/54251 completed (loss: 1.1753836870193481, acc: 0.760869562625885)
[2024-11-03 04:32:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:24][root][INFO] - Training Epoch: 1/2, step 827/54251 completed (loss: 1.1244148015975952, acc: 0.7272727489471436)
[2024-11-03 04:32:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:25][root][INFO] - Training Epoch: 1/2, step 828/54251 completed (loss: 0.5026718378067017, acc: 0.8999999761581421)
[2024-11-03 04:32:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:25][root][INFO] - Training Epoch: 1/2, step 829/54251 completed (loss: 1.8965706825256348, acc: 0.6666666865348816)
[2024-11-03 04:32:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:26][root][INFO] - Training Epoch: 1/2, step 830/54251 completed (loss: 1.8031857013702393, acc: 0.7333333492279053)
[2024-11-03 04:32:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:26][root][INFO] - Training Epoch: 1/2, step 831/54251 completed (loss: 1.0173147916793823, acc: 0.7142857313156128)
[2024-11-03 04:32:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:27][root][INFO] - Training Epoch: 1/2, step 832/54251 completed (loss: 0.5009360313415527, acc: 0.8799999952316284)
[2024-11-03 04:32:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:27][root][INFO] - Training Epoch: 1/2, step 833/54251 completed (loss: 0.5284510850906372, acc: 0.8823529481887817)
[2024-11-03 04:32:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:28][root][INFO] - Training Epoch: 1/2, step 834/54251 completed (loss: 0.3393504321575165, acc: 0.949999988079071)
[2024-11-03 04:32:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:28][root][INFO] - Training Epoch: 1/2, step 835/54251 completed (loss: 0.39331308007240295, acc: 0.8571428656578064)
[2024-11-03 04:32:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:29][root][INFO] - Training Epoch: 1/2, step 836/54251 completed (loss: 1.593079686164856, acc: 0.7599999904632568)
[2024-11-03 04:32:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:29][root][INFO] - Training Epoch: 1/2, step 837/54251 completed (loss: 1.4367544651031494, acc: 0.692307710647583)
[2024-11-03 04:32:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:30][root][INFO] - Training Epoch: 1/2, step 838/54251 completed (loss: 0.38393086194992065, acc: 0.875)
[2024-11-03 04:32:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:30][root][INFO] - Training Epoch: 1/2, step 839/54251 completed (loss: 0.8674593567848206, acc: 0.800000011920929)
[2024-11-03 04:32:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:31][root][INFO] - Training Epoch: 1/2, step 840/54251 completed (loss: 1.3593870401382446, acc: 0.75)
[2024-11-03 04:32:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:31][root][INFO] - Training Epoch: 1/2, step 841/54251 completed (loss: 0.8071573972702026, acc: 0.8684210777282715)
[2024-11-03 04:32:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:32][root][INFO] - Training Epoch: 1/2, step 842/54251 completed (loss: 0.7860787510871887, acc: 0.8500000238418579)
[2024-11-03 04:32:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:32][root][INFO] - Training Epoch: 1/2, step 843/54251 completed (loss: 0.1379365175962448, acc: 1.0)
[2024-11-03 04:32:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:33][root][INFO] - Training Epoch: 1/2, step 844/54251 completed (loss: 1.0314265489578247, acc: 0.9090909361839294)
[2024-11-03 04:32:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:33][root][INFO] - Training Epoch: 1/2, step 845/54251 completed (loss: 0.8589491248130798, acc: 0.7058823704719543)
[2024-11-03 04:32:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:34][root][INFO] - Training Epoch: 1/2, step 846/54251 completed (loss: 0.6341171860694885, acc: 0.9200000166893005)
[2024-11-03 04:32:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:34][root][INFO] - Training Epoch: 1/2, step 847/54251 completed (loss: 1.9836057424545288, acc: 0.6666666865348816)
[2024-11-03 04:32:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:35][root][INFO] - Training Epoch: 1/2, step 848/54251 completed (loss: 0.7583690881729126, acc: 0.8913043737411499)
[2024-11-03 04:32:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:35][root][INFO] - Training Epoch: 1/2, step 849/54251 completed (loss: 0.7133994698524475, acc: 0.8846153616905212)
[2024-11-03 04:32:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:36][root][INFO] - Training Epoch: 1/2, step 850/54251 completed (loss: 0.6804883480072021, acc: 0.8518518805503845)
[2024-11-03 04:32:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:36][root][INFO] - Training Epoch: 1/2, step 851/54251 completed (loss: 0.8893740177154541, acc: 0.6666666865348816)
[2024-11-03 04:32:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:37][root][INFO] - Training Epoch: 1/2, step 852/54251 completed (loss: 0.9673569202423096, acc: 0.8070175647735596)
[2024-11-03 04:32:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:37][root][INFO] - Training Epoch: 1/2, step 853/54251 completed (loss: 0.6317366361618042, acc: 0.75)
[2024-11-03 04:32:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:38][root][INFO] - Training Epoch: 1/2, step 854/54251 completed (loss: 2.895372152328491, acc: 0.39393940567970276)
[2024-11-03 04:32:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:38][root][INFO] - Training Epoch: 1/2, step 855/54251 completed (loss: 0.7208373546600342, acc: 0.875)
[2024-11-03 04:32:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:39][root][INFO] - Training Epoch: 1/2, step 856/54251 completed (loss: 0.4320088326931, acc: 0.8333333134651184)
[2024-11-03 04:32:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:39][root][INFO] - Training Epoch: 1/2, step 857/54251 completed (loss: 1.6566362380981445, acc: 0.7250000238418579)
[2024-11-03 04:32:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:40][root][INFO] - Training Epoch: 1/2, step 858/54251 completed (loss: 1.7016587257385254, acc: 0.6363636255264282)
[2024-11-03 04:32:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:40][root][INFO] - Training Epoch: 1/2, step 859/54251 completed (loss: 1.0702952146530151, acc: 0.8125)
[2024-11-03 04:32:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:41][root][INFO] - Training Epoch: 1/2, step 860/54251 completed (loss: 0.7364465594291687, acc: 0.9090909361839294)
[2024-11-03 04:32:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:41][root][INFO] - Training Epoch: 1/2, step 861/54251 completed (loss: 1.4620814323425293, acc: 0.6111111044883728)
[2024-11-03 04:32:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:42][root][INFO] - Training Epoch: 1/2, step 862/54251 completed (loss: 1.9273957014083862, acc: 0.6279069781303406)
[2024-11-03 04:32:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:42][root][INFO] - Training Epoch: 1/2, step 863/54251 completed (loss: 2.3378303050994873, acc: 0.6521739363670349)
[2024-11-03 04:32:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:43][root][INFO] - Training Epoch: 1/2, step 864/54251 completed (loss: 0.7750828266143799, acc: 0.800000011920929)
[2024-11-03 04:32:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:43][root][INFO] - Training Epoch: 1/2, step 865/54251 completed (loss: 0.5662208795547485, acc: 0.9473684430122375)
[2024-11-03 04:32:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:44][root][INFO] - Training Epoch: 1/2, step 866/54251 completed (loss: 0.8838708996772766, acc: 0.6666666865348816)
[2024-11-03 04:32:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:44][root][INFO] - Training Epoch: 1/2, step 867/54251 completed (loss: 1.7847354412078857, acc: 0.692307710647583)
[2024-11-03 04:32:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:45][root][INFO] - Training Epoch: 1/2, step 868/54251 completed (loss: 0.895045280456543, acc: 0.8205128312110901)
[2024-11-03 04:32:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:45][root][INFO] - Training Epoch: 1/2, step 869/54251 completed (loss: 0.3817354142665863, acc: 0.9333333373069763)
[2024-11-03 04:32:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:46][root][INFO] - Training Epoch: 1/2, step 870/54251 completed (loss: 1.303580641746521, acc: 0.6470588445663452)
[2024-11-03 04:32:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:46][root][INFO] - Training Epoch: 1/2, step 871/54251 completed (loss: 1.0991401672363281, acc: 0.8064516186714172)
[2024-11-03 04:32:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:47][root][INFO] - Training Epoch: 1/2, step 872/54251 completed (loss: 0.9886433482170105, acc: 0.7692307829856873)
[2024-11-03 04:32:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:47][root][INFO] - Training Epoch: 1/2, step 873/54251 completed (loss: 1.399720311164856, acc: 0.7586206793785095)
[2024-11-03 04:32:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:48][root][INFO] - Training Epoch: 1/2, step 874/54251 completed (loss: 0.6914205551147461, acc: 0.807692289352417)
[2024-11-03 04:32:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:48][root][INFO] - Training Epoch: 1/2, step 875/54251 completed (loss: 0.594168484210968, acc: 0.8421052694320679)
[2024-11-03 04:32:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:49][root][INFO] - Training Epoch: 1/2, step 876/54251 completed (loss: 2.274648904800415, acc: 0.5909090638160706)
[2024-11-03 04:32:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:49][root][INFO] - Training Epoch: 1/2, step 877/54251 completed (loss: 0.7579618692398071, acc: 0.8108108043670654)
[2024-11-03 04:32:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:50][root][INFO] - Training Epoch: 1/2, step 878/54251 completed (loss: 3.0567307472229004, acc: 0.6153846383094788)
[2024-11-03 04:32:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:50][root][INFO] - Training Epoch: 1/2, step 879/54251 completed (loss: 0.45584937930107117, acc: 0.8461538553237915)
[2024-11-03 04:32:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:51][root][INFO] - Training Epoch: 1/2, step 880/54251 completed (loss: 1.5286078453063965, acc: 0.6818181872367859)
[2024-11-03 04:32:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:51][root][INFO] - Training Epoch: 1/2, step 881/54251 completed (loss: 0.9832821488380432, acc: 0.800000011920929)
[2024-11-03 04:32:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:52][root][INFO] - Training Epoch: 1/2, step 882/54251 completed (loss: 2.77113938331604, acc: 0.4444444477558136)
[2024-11-03 04:32:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:52][root][INFO] - Training Epoch: 1/2, step 883/54251 completed (loss: 0.7067046165466309, acc: 0.875)
[2024-11-03 04:32:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:53][root][INFO] - Training Epoch: 1/2, step 884/54251 completed (loss: 1.6923398971557617, acc: 0.6000000238418579)
[2024-11-03 04:32:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:53][root][INFO] - Training Epoch: 1/2, step 885/54251 completed (loss: 1.503289818763733, acc: 0.75)
[2024-11-03 04:32:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:54][root][INFO] - Training Epoch: 1/2, step 886/54251 completed (loss: 0.7278160452842712, acc: 0.8139534592628479)
[2024-11-03 04:32:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:54][root][INFO] - Training Epoch: 1/2, step 887/54251 completed (loss: 0.19367660582065582, acc: 1.0)
[2024-11-03 04:32:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:55][root][INFO] - Training Epoch: 1/2, step 888/54251 completed (loss: 0.5936061143875122, acc: 0.8461538553237915)
[2024-11-03 04:32:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:55][root][INFO] - Training Epoch: 1/2, step 889/54251 completed (loss: 2.8567681312561035, acc: 0.4000000059604645)
[2024-11-03 04:32:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:56][root][INFO] - Training Epoch: 1/2, step 890/54251 completed (loss: 1.5172066688537598, acc: 0.7222222089767456)
[2024-11-03 04:32:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:56][root][INFO] - Training Epoch: 1/2, step 891/54251 completed (loss: 0.9634569883346558, acc: 0.75)
[2024-11-03 04:32:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:57][root][INFO] - Training Epoch: 1/2, step 892/54251 completed (loss: 0.9092047214508057, acc: 0.7727272510528564)
[2024-11-03 04:32:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:57][root][INFO] - Training Epoch: 1/2, step 893/54251 completed (loss: 1.5133970975875854, acc: 0.6153846383094788)
[2024-11-03 04:32:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:58][root][INFO] - Training Epoch: 1/2, step 894/54251 completed (loss: 2.0471110343933105, acc: 0.7027027010917664)
[2024-11-03 04:32:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:59][root][INFO] - Training Epoch: 1/2, step 895/54251 completed (loss: 0.7869936227798462, acc: 0.78125)
[2024-11-03 04:32:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:32:59][root][INFO] - Training Epoch: 1/2, step 896/54251 completed (loss: 1.7361761331558228, acc: 0.6842105388641357)
[2024-11-03 04:32:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:00][root][INFO] - Training Epoch: 1/2, step 897/54251 completed (loss: 1.5163767337799072, acc: 0.71875)
[2024-11-03 04:33:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:00][root][INFO] - Training Epoch: 1/2, step 898/54251 completed (loss: 1.706626057624817, acc: 0.7333333492279053)
[2024-11-03 04:33:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:01][root][INFO] - Training Epoch: 1/2, step 899/54251 completed (loss: 0.6470174789428711, acc: 0.875)
[2024-11-03 04:33:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:01][root][INFO] - Training Epoch: 1/2, step 900/54251 completed (loss: 1.6413651704788208, acc: 0.7142857313156128)
[2024-11-03 04:33:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:02][root][INFO] - Training Epoch: 1/2, step 901/54251 completed (loss: 0.5274109840393066, acc: 0.75)
[2024-11-03 04:33:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:02][root][INFO] - Training Epoch: 1/2, step 902/54251 completed (loss: 0.40719524025917053, acc: 1.0)
[2024-11-03 04:33:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:03][root][INFO] - Training Epoch: 1/2, step 903/54251 completed (loss: 1.01710844039917, acc: 0.8372092843055725)
[2024-11-03 04:33:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:03][root][INFO] - Training Epoch: 1/2, step 904/54251 completed (loss: 1.4618879556655884, acc: 0.7666666507720947)
[2024-11-03 04:33:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:04][root][INFO] - Training Epoch: 1/2, step 905/54251 completed (loss: 0.7976809144020081, acc: 0.8095238208770752)
[2024-11-03 04:33:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:04][root][INFO] - Training Epoch: 1/2, step 906/54251 completed (loss: 0.4121490716934204, acc: 0.875)
[2024-11-03 04:33:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:05][root][INFO] - Training Epoch: 1/2, step 907/54251 completed (loss: 1.144478678703308, acc: 0.760869562625885)
[2024-11-03 04:33:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:05][root][INFO] - Training Epoch: 1/2, step 908/54251 completed (loss: 0.4231213927268982, acc: 0.875)
[2024-11-03 04:33:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:06][root][INFO] - Training Epoch: 1/2, step 909/54251 completed (loss: 3.013497829437256, acc: 0.2857142984867096)
[2024-11-03 04:33:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:06][root][INFO] - Training Epoch: 1/2, step 910/54251 completed (loss: 1.1152441501617432, acc: 0.7333333492279053)
[2024-11-03 04:33:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:07][root][INFO] - Training Epoch: 1/2, step 911/54251 completed (loss: 1.438727617263794, acc: 0.6521739363670349)
[2024-11-03 04:33:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:07][root][INFO] - Training Epoch: 1/2, step 912/54251 completed (loss: 1.14022958278656, acc: 0.800000011920929)
[2024-11-03 04:33:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:07][root][INFO] - Training Epoch: 1/2, step 913/54251 completed (loss: 0.1913347840309143, acc: 0.9166666865348816)
[2024-11-03 04:33:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:08][root][INFO] - Training Epoch: 1/2, step 914/54251 completed (loss: 0.35083654522895813, acc: 0.9583333134651184)
[2024-11-03 04:33:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:08][root][INFO] - Training Epoch: 1/2, step 915/54251 completed (loss: 0.7373296618461609, acc: 0.837837815284729)
[2024-11-03 04:33:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:09][root][INFO] - Training Epoch: 1/2, step 916/54251 completed (loss: 1.730430006980896, acc: 0.6666666865348816)
[2024-11-03 04:33:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:09][root][INFO] - Training Epoch: 1/2, step 917/54251 completed (loss: 2.993088722229004, acc: 0.43478259444236755)
[2024-11-03 04:33:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:10][root][INFO] - Training Epoch: 1/2, step 918/54251 completed (loss: 0.6046057939529419, acc: 0.8636363744735718)
[2024-11-03 04:33:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:10][root][INFO] - Training Epoch: 1/2, step 919/54251 completed (loss: 1.0314592123031616, acc: 0.7872340679168701)
[2024-11-03 04:33:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:11][root][INFO] - Training Epoch: 1/2, step 920/54251 completed (loss: 0.2767106592655182, acc: 0.9166666865348816)
[2024-11-03 04:33:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:11][root][INFO] - Training Epoch: 1/2, step 921/54251 completed (loss: 2.103827953338623, acc: 0.6206896305084229)
[2024-11-03 04:33:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:12][root][INFO] - Training Epoch: 1/2, step 922/54251 completed (loss: 1.3440660238265991, acc: 0.8399999737739563)
[2024-11-03 04:33:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:12][root][INFO] - Training Epoch: 1/2, step 923/54251 completed (loss: 0.6935964226722717, acc: 0.7777777910232544)
[2024-11-03 04:33:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:13][root][INFO] - Training Epoch: 1/2, step 924/54251 completed (loss: 1.2496737241744995, acc: 0.7307692170143127)
[2024-11-03 04:33:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:13][root][INFO] - Training Epoch: 1/2, step 925/54251 completed (loss: 1.2762740850448608, acc: 0.800000011920929)
[2024-11-03 04:33:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:14][root][INFO] - Training Epoch: 1/2, step 926/54251 completed (loss: 1.5548677444458008, acc: 0.5789473652839661)
[2024-11-03 04:33:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:14][root][INFO] - Training Epoch: 1/2, step 927/54251 completed (loss: 0.11356071382761002, acc: 1.0)
[2024-11-03 04:33:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:15][root][INFO] - Training Epoch: 1/2, step 928/54251 completed (loss: 1.4296772480010986, acc: 0.71875)
[2024-11-03 04:33:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:15][root][INFO] - Training Epoch: 1/2, step 929/54251 completed (loss: 1.5013338327407837, acc: 0.7857142686843872)
[2024-11-03 04:33:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:16][root][INFO] - Training Epoch: 1/2, step 930/54251 completed (loss: 0.24807558953762054, acc: 0.9333333373069763)
[2024-11-03 04:33:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:16][root][INFO] - Training Epoch: 1/2, step 931/54251 completed (loss: 3.1105868816375732, acc: 0.4736842215061188)
[2024-11-03 04:33:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:17][root][INFO] - Training Epoch: 1/2, step 932/54251 completed (loss: 0.8247038722038269, acc: 0.8333333134651184)
[2024-11-03 04:33:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:17][root][INFO] - Training Epoch: 1/2, step 933/54251 completed (loss: 1.3411203622817993, acc: 0.75)
[2024-11-03 04:33:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:18][root][INFO] - Training Epoch: 1/2, step 934/54251 completed (loss: 0.8235974311828613, acc: 0.7714285850524902)
[2024-11-03 04:33:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:18][root][INFO] - Training Epoch: 1/2, step 935/54251 completed (loss: 0.8535892963409424, acc: 0.800000011920929)
[2024-11-03 04:33:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:19][root][INFO] - Training Epoch: 1/2, step 936/54251 completed (loss: 0.22452287375926971, acc: 0.9259259104728699)
[2024-11-03 04:33:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:19][root][INFO] - Training Epoch: 1/2, step 937/54251 completed (loss: 0.9867602586746216, acc: 0.7222222089767456)
[2024-11-03 04:33:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:20][root][INFO] - Training Epoch: 1/2, step 938/54251 completed (loss: 1.279908537864685, acc: 0.75)
[2024-11-03 04:33:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:20][root][INFO] - Training Epoch: 1/2, step 939/54251 completed (loss: 0.7502339482307434, acc: 0.8500000238418579)
[2024-11-03 04:33:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:21][root][INFO] - Training Epoch: 1/2, step 940/54251 completed (loss: 4.535759925842285, acc: 0.3076923191547394)
[2024-11-03 04:33:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:21][root][INFO] - Training Epoch: 1/2, step 941/54251 completed (loss: 0.4846668243408203, acc: 1.0)
[2024-11-03 04:33:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:22][root][INFO] - Training Epoch: 1/2, step 942/54251 completed (loss: 0.19541478157043457, acc: 1.0)
[2024-11-03 04:33:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:22][root][INFO] - Training Epoch: 1/2, step 943/54251 completed (loss: 0.7751563191413879, acc: 0.8775510191917419)
[2024-11-03 04:33:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:23][root][INFO] - Training Epoch: 1/2, step 944/54251 completed (loss: 1.11068856716156, acc: 0.7727272510528564)
[2024-11-03 04:33:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:23][root][INFO] - Training Epoch: 1/2, step 945/54251 completed (loss: 0.4461040794849396, acc: 0.9130434989929199)
[2024-11-03 04:33:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:24][root][INFO] - Training Epoch: 1/2, step 946/54251 completed (loss: 0.9680376052856445, acc: 0.800000011920929)
[2024-11-03 04:33:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:24][root][INFO] - Training Epoch: 1/2, step 947/54251 completed (loss: 0.880763590335846, acc: 0.800000011920929)
[2024-11-03 04:33:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:25][root][INFO] - Training Epoch: 1/2, step 948/54251 completed (loss: 0.7147483229637146, acc: 0.8372092843055725)
[2024-11-03 04:33:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:25][root][INFO] - Training Epoch: 1/2, step 949/54251 completed (loss: 0.8911604881286621, acc: 0.75)
[2024-11-03 04:33:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:26][root][INFO] - Training Epoch: 1/2, step 950/54251 completed (loss: 0.46623584628105164, acc: 0.8399999737739563)
[2024-11-03 04:33:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:26][root][INFO] - Training Epoch: 1/2, step 951/54251 completed (loss: 1.537642002105713, acc: 0.6666666865348816)
[2024-11-03 04:33:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:27][root][INFO] - Training Epoch: 1/2, step 952/54251 completed (loss: 1.0409208536148071, acc: 0.8055555820465088)
[2024-11-03 04:33:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:27][root][INFO] - Training Epoch: 1/2, step 953/54251 completed (loss: 3.2668519020080566, acc: 0.4736842215061188)
[2024-11-03 04:33:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:28][root][INFO] - Training Epoch: 1/2, step 954/54251 completed (loss: 1.7227981090545654, acc: 0.7407407164573669)
[2024-11-03 04:33:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:28][root][INFO] - Training Epoch: 1/2, step 955/54251 completed (loss: 1.0866203308105469, acc: 0.75)
[2024-11-03 04:33:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:29][root][INFO] - Training Epoch: 1/2, step 956/54251 completed (loss: 1.2810457944869995, acc: 0.7241379022598267)
[2024-11-03 04:33:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:29][root][INFO] - Training Epoch: 1/2, step 957/54251 completed (loss: 0.8752654790878296, acc: 0.8333333134651184)
[2024-11-03 04:33:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:30][root][INFO] - Training Epoch: 1/2, step 958/54251 completed (loss: 1.291908860206604, acc: 0.699999988079071)
[2024-11-03 04:33:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:30][root][INFO] - Training Epoch: 1/2, step 959/54251 completed (loss: 1.7307144403457642, acc: 0.6944444179534912)
[2024-11-03 04:33:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:31][root][INFO] - Training Epoch: 1/2, step 960/54251 completed (loss: 0.26894617080688477, acc: 0.9642857313156128)
[2024-11-03 04:33:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:31][root][INFO] - Training Epoch: 1/2, step 961/54251 completed (loss: 1.5242247581481934, acc: 0.375)
[2024-11-03 04:33:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:32][root][INFO] - Training Epoch: 1/2, step 962/54251 completed (loss: 1.6614254713058472, acc: 0.7777777910232544)
[2024-11-03 04:33:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:32][root][INFO] - Training Epoch: 1/2, step 963/54251 completed (loss: 0.8961743712425232, acc: 0.8444444537162781)
[2024-11-03 04:33:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:33][root][INFO] - Training Epoch: 1/2, step 964/54251 completed (loss: 1.3431624174118042, acc: 0.7037037014961243)
[2024-11-03 04:33:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:33][root][INFO] - Training Epoch: 1/2, step 965/54251 completed (loss: 2.2501044273376465, acc: 0.523809552192688)
[2024-11-03 04:33:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:34][root][INFO] - Training Epoch: 1/2, step 966/54251 completed (loss: 0.37026894092559814, acc: 0.8181818127632141)
[2024-11-03 04:33:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:34][root][INFO] - Training Epoch: 1/2, step 967/54251 completed (loss: 0.9171839356422424, acc: 0.837837815284729)
[2024-11-03 04:33:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:35][root][INFO] - Training Epoch: 1/2, step 968/54251 completed (loss: 0.3900515139102936, acc: 0.9444444179534912)
[2024-11-03 04:33:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:35][root][INFO] - Training Epoch: 1/2, step 969/54251 completed (loss: 0.6175206899642944, acc: 0.7142857313156128)
[2024-11-03 04:33:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:36][root][INFO] - Training Epoch: 1/2, step 970/54251 completed (loss: 0.6746454834938049, acc: 0.8181818127632141)
[2024-11-03 04:33:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:36][root][INFO] - Training Epoch: 1/2, step 971/54251 completed (loss: 0.9639098048210144, acc: 0.8620689511299133)
[2024-11-03 04:33:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:37][root][INFO] - Training Epoch: 1/2, step 972/54251 completed (loss: 1.5672281980514526, acc: 0.7142857313156128)
[2024-11-03 04:33:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:37][root][INFO] - Training Epoch: 1/2, step 973/54251 completed (loss: 0.2522774040699005, acc: 1.0)
[2024-11-03 04:33:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:38][root][INFO] - Training Epoch: 1/2, step 974/54251 completed (loss: 3.743759870529175, acc: 0.3333333432674408)
[2024-11-03 04:33:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:38][root][INFO] - Training Epoch: 1/2, step 975/54251 completed (loss: 0.3219258189201355, acc: 0.9019607901573181)
[2024-11-03 04:33:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:38][root][INFO] - Training Epoch: 1/2, step 976/54251 completed (loss: 1.1996243000030518, acc: 0.75)
[2024-11-03 04:33:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:39][root][INFO] - Training Epoch: 1/2, step 977/54251 completed (loss: 0.8840749859809875, acc: 0.8510638475418091)
[2024-11-03 04:33:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:39][root][INFO] - Training Epoch: 1/2, step 978/54251 completed (loss: 2.3715062141418457, acc: 0.6153846383094788)
[2024-11-03 04:33:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:40][root][INFO] - Training Epoch: 1/2, step 979/54251 completed (loss: 2.6792800426483154, acc: 0.5714285969734192)
[2024-11-03 04:33:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:40][root][INFO] - Training Epoch: 1/2, step 980/54251 completed (loss: 1.5024137496948242, acc: 0.7435897588729858)
[2024-11-03 04:33:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:41][root][INFO] - Training Epoch: 1/2, step 981/54251 completed (loss: 1.5354934930801392, acc: 0.6363636255264282)
[2024-11-03 04:33:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:41][root][INFO] - Training Epoch: 1/2, step 982/54251 completed (loss: 1.1444510221481323, acc: 0.7272727489471436)
[2024-11-03 04:33:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:42][root][INFO] - Training Epoch: 1/2, step 983/54251 completed (loss: 0.7572900056838989, acc: 0.875)
[2024-11-03 04:33:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:42][root][INFO] - Training Epoch: 1/2, step 984/54251 completed (loss: 1.3808976411819458, acc: 0.8235294222831726)
[2024-11-03 04:33:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:43][root][INFO] - Training Epoch: 1/2, step 985/54251 completed (loss: 1.6084730625152588, acc: 0.7234042286872864)
[2024-11-03 04:33:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:43][root][INFO] - Training Epoch: 1/2, step 986/54251 completed (loss: 1.3856604099273682, acc: 0.6818181872367859)
[2024-11-03 04:33:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:44][root][INFO] - Training Epoch: 1/2, step 987/54251 completed (loss: 0.525672972202301, acc: 0.875)
[2024-11-03 04:33:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:44][root][INFO] - Training Epoch: 1/2, step 988/54251 completed (loss: 1.7567846775054932, acc: 0.5882353186607361)
[2024-11-03 04:33:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:45][root][INFO] - Training Epoch: 1/2, step 989/54251 completed (loss: 2.2389798164367676, acc: 0.4545454680919647)
[2024-11-03 04:33:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:45][root][INFO] - Training Epoch: 1/2, step 990/54251 completed (loss: 0.27352768182754517, acc: 0.9166666865348816)
[2024-11-03 04:33:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:46][root][INFO] - Training Epoch: 1/2, step 991/54251 completed (loss: 1.2164052724838257, acc: 0.75)
[2024-11-03 04:33:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:46][root][INFO] - Training Epoch: 1/2, step 992/54251 completed (loss: 1.0468801259994507, acc: 0.8064516186714172)
[2024-11-03 04:33:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:47][root][INFO] - Training Epoch: 1/2, step 993/54251 completed (loss: 2.9447672367095947, acc: 0.5555555820465088)
[2024-11-03 04:33:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:47][root][INFO] - Training Epoch: 1/2, step 994/54251 completed (loss: 1.2012050151824951, acc: 0.7027027010917664)
[2024-11-03 04:33:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:48][root][INFO] - Training Epoch: 1/2, step 995/54251 completed (loss: 0.544721245765686, acc: 0.8965517282485962)
[2024-11-03 04:33:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:48][root][INFO] - Training Epoch: 1/2, step 996/54251 completed (loss: 1.8970730304718018, acc: 0.59375)
[2024-11-03 04:33:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:49][root][INFO] - Training Epoch: 1/2, step 997/54251 completed (loss: 0.29480576515197754, acc: 0.9285714030265808)
[2024-11-03 04:33:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:49][root][INFO] - Training Epoch: 1/2, step 998/54251 completed (loss: 0.6906206011772156, acc: 0.8421052694320679)
[2024-11-03 04:33:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:50][root][INFO] - Training Epoch: 1/2, step 999/54251 completed (loss: 1.553505778312683, acc: 0.7441860437393188)
[2024-11-03 04:33:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:50][root][INFO] - Training Epoch: 1/2, step 1000/54251 completed (loss: 1.3171218633651733, acc: 0.7580645084381104)
[2024-11-03 04:33:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:51][root][INFO] - Training Epoch: 1/2, step 1001/54251 completed (loss: 1.1382883787155151, acc: 0.8181818127632141)
[2024-11-03 04:33:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:51][root][INFO] - Training Epoch: 1/2, step 1002/54251 completed (loss: 1.6795475482940674, acc: 0.7777777910232544)
[2024-11-03 04:33:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:52][root][INFO] - Training Epoch: 1/2, step 1003/54251 completed (loss: 0.9923192262649536, acc: 0.8333333134651184)
[2024-11-03 04:33:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:52][root][INFO] - Training Epoch: 1/2, step 1004/54251 completed (loss: 0.8893953561782837, acc: 0.8536585569381714)
[2024-11-03 04:33:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:53][root][INFO] - Training Epoch: 1/2, step 1005/54251 completed (loss: 0.6635035276412964, acc: 0.8620689511299133)
[2024-11-03 04:33:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:53][root][INFO] - Training Epoch: 1/2, step 1006/54251 completed (loss: 0.5170676112174988, acc: 0.9166666865348816)
[2024-11-03 04:33:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:54][root][INFO] - Training Epoch: 1/2, step 1007/54251 completed (loss: 1.3151136636734009, acc: 0.625)
[2024-11-03 04:33:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:54][root][INFO] - Training Epoch: 1/2, step 1008/54251 completed (loss: 0.703196108341217, acc: 0.9090909361839294)
[2024-11-03 04:33:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:55][root][INFO] - Training Epoch: 1/2, step 1009/54251 completed (loss: 0.21320368349552155, acc: 0.9166666865348816)
[2024-11-03 04:33:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:55][root][INFO] - Training Epoch: 1/2, step 1010/54251 completed (loss: 0.6749605536460876, acc: 0.7142857313156128)
[2024-11-03 04:33:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:56][root][INFO] - Training Epoch: 1/2, step 1011/54251 completed (loss: 0.45736876130104065, acc: 0.9375)
[2024-11-03 04:33:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:56][root][INFO] - Training Epoch: 1/2, step 1012/54251 completed (loss: 0.7110052108764648, acc: 0.800000011920929)
[2024-11-03 04:33:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:57][root][INFO] - Training Epoch: 1/2, step 1013/54251 completed (loss: 0.6657209396362305, acc: 0.9285714030265808)
[2024-11-03 04:33:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:57][root][INFO] - Training Epoch: 1/2, step 1014/54251 completed (loss: 1.5176926851272583, acc: 0.698113203048706)
[2024-11-03 04:33:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:58][root][INFO] - Training Epoch: 1/2, step 1015/54251 completed (loss: 0.9313677549362183, acc: 0.807692289352417)
[2024-11-03 04:33:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:58][root][INFO] - Training Epoch: 1/2, step 1016/54251 completed (loss: 1.3304089307785034, acc: 0.7575757503509521)
[2024-11-03 04:33:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:59][root][INFO] - Training Epoch: 1/2, step 1017/54251 completed (loss: 0.397196888923645, acc: 0.8181818127632141)
[2024-11-03 04:33:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:33:59][root][INFO] - Training Epoch: 1/2, step 1018/54251 completed (loss: 3.5160276889801025, acc: 0.38461539149284363)
[2024-11-03 04:33:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:00][root][INFO] - Training Epoch: 1/2, step 1019/54251 completed (loss: 0.571860134601593, acc: 0.9333333373069763)
[2024-11-03 04:34:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:00][root][INFO] - Training Epoch: 1/2, step 1020/54251 completed (loss: 1.496633768081665, acc: 0.7142857313156128)
[2024-11-03 04:34:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:01][root][INFO] - Training Epoch: 1/2, step 1021/54251 completed (loss: 1.871921420097351, acc: 0.6428571343421936)
[2024-11-03 04:34:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:01][root][INFO] - Training Epoch: 1/2, step 1022/54251 completed (loss: 1.5511503219604492, acc: 0.6969696879386902)
[2024-11-03 04:34:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:02][root][INFO] - Training Epoch: 1/2, step 1023/54251 completed (loss: 1.1021226644515991, acc: 0.807692289352417)
[2024-11-03 04:34:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:02][root][INFO] - Training Epoch: 1/2, step 1024/54251 completed (loss: 0.644452691078186, acc: 0.8399999737739563)
[2024-11-03 04:34:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:03][root][INFO] - Training Epoch: 1/2, step 1025/54251 completed (loss: 2.9768178462982178, acc: 0.38461539149284363)
[2024-11-03 04:34:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:03][root][INFO] - Training Epoch: 1/2, step 1026/54251 completed (loss: 0.5472041964530945, acc: 0.8399999737739563)
[2024-11-03 04:34:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:04][root][INFO] - Training Epoch: 1/2, step 1027/54251 completed (loss: 0.577659547328949, acc: 0.9069767594337463)
[2024-11-03 04:34:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:04][root][INFO] - Training Epoch: 1/2, step 1028/54251 completed (loss: 0.7584969401359558, acc: 0.800000011920929)
[2024-11-03 04:34:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:05][root][INFO] - Training Epoch: 1/2, step 1029/54251 completed (loss: 0.38830462098121643, acc: 0.9411764740943909)
[2024-11-03 04:34:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:05][root][INFO] - Training Epoch: 1/2, step 1030/54251 completed (loss: 0.5379108786582947, acc: 0.8813559412956238)
[2024-11-03 04:34:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:05][root][INFO] - Training Epoch: 1/2, step 1031/54251 completed (loss: 0.4532712697982788, acc: 0.8717948794364929)
[2024-11-03 04:34:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:06][root][INFO] - Training Epoch: 1/2, step 1032/54251 completed (loss: 1.4852674007415771, acc: 0.6538461446762085)
[2024-11-03 04:34:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:07][root][INFO] - Training Epoch: 1/2, step 1033/54251 completed (loss: 0.7126696705818176, acc: 0.8387096524238586)
[2024-11-03 04:34:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:07][root][INFO] - Training Epoch: 1/2, step 1034/54251 completed (loss: 0.5493777990341187, acc: 0.843137264251709)
[2024-11-03 04:34:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:08][root][INFO] - Training Epoch: 1/2, step 1035/54251 completed (loss: 2.0863287448883057, acc: 0.5454545617103577)
[2024-11-03 04:34:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:08][root][INFO] - Training Epoch: 1/2, step 1036/54251 completed (loss: 0.7019131779670715, acc: 0.8666666746139526)
[2024-11-03 04:34:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:09][root][INFO] - Training Epoch: 1/2, step 1037/54251 completed (loss: 1.3390287160873413, acc: 0.7777777910232544)
[2024-11-03 04:34:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:09][root][INFO] - Training Epoch: 1/2, step 1038/54251 completed (loss: 0.3297853469848633, acc: 0.8888888955116272)
[2024-11-03 04:34:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:09][root][INFO] - Training Epoch: 1/2, step 1039/54251 completed (loss: 0.3019741177558899, acc: 0.9487179517745972)
[2024-11-03 04:34:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:10][root][INFO] - Training Epoch: 1/2, step 1040/54251 completed (loss: 0.6196118593215942, acc: 0.8461538553237915)
[2024-11-03 04:34:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:10][root][INFO] - Training Epoch: 1/2, step 1041/54251 completed (loss: 0.9982849955558777, acc: 0.7368420958518982)
[2024-11-03 04:34:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:11][root][INFO] - Training Epoch: 1/2, step 1042/54251 completed (loss: 0.5693520307540894, acc: 0.8695651888847351)
[2024-11-03 04:34:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:11][root][INFO] - Training Epoch: 1/2, step 1043/54251 completed (loss: 2.096661329269409, acc: 0.5833333134651184)
[2024-11-03 04:34:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:12][root][INFO] - Training Epoch: 1/2, step 1044/54251 completed (loss: 2.5049948692321777, acc: 0.5)
[2024-11-03 04:34:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:12][root][INFO] - Training Epoch: 1/2, step 1045/54251 completed (loss: 0.04699988290667534, acc: 1.0)
[2024-11-03 04:34:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:13][root][INFO] - Training Epoch: 1/2, step 1046/54251 completed (loss: 1.1891900300979614, acc: 0.75)
[2024-11-03 04:34:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:13][root][INFO] - Training Epoch: 1/2, step 1047/54251 completed (loss: 4.654114723205566, acc: 0.3333333432674408)
[2024-11-03 04:34:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:14][root][INFO] - Training Epoch: 1/2, step 1048/54251 completed (loss: 1.5338313579559326, acc: 0.5714285969734192)
[2024-11-03 04:34:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:14][root][INFO] - Training Epoch: 1/2, step 1049/54251 completed (loss: 0.4013527035713196, acc: 0.9375)
[2024-11-03 04:34:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:15][root][INFO] - Training Epoch: 1/2, step 1050/54251 completed (loss: 0.40389299392700195, acc: 0.8500000238418579)
[2024-11-03 04:34:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:15][root][INFO] - Training Epoch: 1/2, step 1051/54251 completed (loss: 1.5422141551971436, acc: 0.761904776096344)
[2024-11-03 04:34:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:16][root][INFO] - Training Epoch: 1/2, step 1052/54251 completed (loss: 0.9249643683433533, acc: 0.875)
[2024-11-03 04:34:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:16][root][INFO] - Training Epoch: 1/2, step 1053/54251 completed (loss: 0.09809721261262894, acc: 1.0)
[2024-11-03 04:34:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:17][root][INFO] - Training Epoch: 1/2, step 1054/54251 completed (loss: 0.686720073223114, acc: 0.8918918967247009)
[2024-11-03 04:34:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:17][root][INFO] - Training Epoch: 1/2, step 1055/54251 completed (loss: 2.6836419105529785, acc: 0.42105263471603394)
[2024-11-03 04:34:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:18][root][INFO] - Training Epoch: 1/2, step 1056/54251 completed (loss: 0.8680962324142456, acc: 0.8260869383811951)
[2024-11-03 04:34:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:18][root][INFO] - Training Epoch: 1/2, step 1057/54251 completed (loss: 0.31223049759864807, acc: 0.95652174949646)
[2024-11-03 04:34:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:19][root][INFO] - Training Epoch: 1/2, step 1058/54251 completed (loss: 1.1590505838394165, acc: 0.6000000238418579)
[2024-11-03 04:34:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:19][root][INFO] - Training Epoch: 1/2, step 1059/54251 completed (loss: 0.8418896198272705, acc: 0.8333333134651184)
[2024-11-03 04:34:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:20][root][INFO] - Training Epoch: 1/2, step 1060/54251 completed (loss: 1.3461490869522095, acc: 0.75)
[2024-11-03 04:34:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:20][root][INFO] - Training Epoch: 1/2, step 1061/54251 completed (loss: 0.5182279944419861, acc: 0.9032257795333862)
[2024-11-03 04:34:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:21][root][INFO] - Training Epoch: 1/2, step 1062/54251 completed (loss: 0.736112117767334, acc: 0.8529411554336548)
[2024-11-03 04:34:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:21][root][INFO] - Training Epoch: 1/2, step 1063/54251 completed (loss: 0.9421133995056152, acc: 0.7647058963775635)
[2024-11-03 04:34:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:22][root][INFO] - Training Epoch: 1/2, step 1064/54251 completed (loss: 0.6267104744911194, acc: 0.8571428656578064)
[2024-11-03 04:34:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:22][root][INFO] - Training Epoch: 1/2, step 1065/54251 completed (loss: 1.1905977725982666, acc: 0.7200000286102295)
[2024-11-03 04:34:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:23][root][INFO] - Training Epoch: 1/2, step 1066/54251 completed (loss: 0.9135355353355408, acc: 0.800000011920929)
[2024-11-03 04:34:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:23][root][INFO] - Training Epoch: 1/2, step 1067/54251 completed (loss: 0.32552221417427063, acc: 0.8333333134651184)
[2024-11-03 04:34:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:24][root][INFO] - Training Epoch: 1/2, step 1068/54251 completed (loss: 1.4236897230148315, acc: 0.7931034564971924)
[2024-11-03 04:34:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:24][root][INFO] - Training Epoch: 1/2, step 1069/54251 completed (loss: 3.5704400539398193, acc: 0.3076923191547394)
[2024-11-03 04:34:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:25][root][INFO] - Training Epoch: 1/2, step 1070/54251 completed (loss: 3.2986900806427, acc: 0.29411765933036804)
[2024-11-03 04:34:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:25][root][INFO] - Training Epoch: 1/2, step 1071/54251 completed (loss: 0.7815411686897278, acc: 0.7948718070983887)
[2024-11-03 04:34:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:26][root][INFO] - Training Epoch: 1/2, step 1072/54251 completed (loss: 0.9880326986312866, acc: 0.625)
[2024-11-03 04:34:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:26][root][INFO] - Training Epoch: 1/2, step 1073/54251 completed (loss: 0.4539647400379181, acc: 0.9545454382896423)
[2024-11-03 04:34:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:27][root][INFO] - Training Epoch: 1/2, step 1074/54251 completed (loss: 0.938209056854248, acc: 0.8500000238418579)
[2024-11-03 04:34:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:27][root][INFO] - Training Epoch: 1/2, step 1075/54251 completed (loss: 0.8759708404541016, acc: 0.8461538553237915)
[2024-11-03 04:34:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:28][root][INFO] - Training Epoch: 1/2, step 1076/54251 completed (loss: 0.8626142740249634, acc: 0.8055555820465088)
[2024-11-03 04:34:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:28][root][INFO] - Training Epoch: 1/2, step 1077/54251 completed (loss: 1.5544298887252808, acc: 0.6000000238418579)
[2024-11-03 04:34:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:29][root][INFO] - Training Epoch: 1/2, step 1078/54251 completed (loss: 1.216944694519043, acc: 0.7272727489471436)
[2024-11-03 04:34:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:29][root][INFO] - Training Epoch: 1/2, step 1079/54251 completed (loss: 1.3231209516525269, acc: 0.7058823704719543)
[2024-11-03 04:34:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:30][root][INFO] - Training Epoch: 1/2, step 1080/54251 completed (loss: 1.6996883153915405, acc: 0.7551020383834839)
[2024-11-03 04:34:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:30][root][INFO] - Training Epoch: 1/2, step 1081/54251 completed (loss: 1.009936809539795, acc: 0.7599999904632568)
[2024-11-03 04:34:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:31][root][INFO] - Training Epoch: 1/2, step 1082/54251 completed (loss: 1.0937288999557495, acc: 0.8125)
[2024-11-03 04:34:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:31][root][INFO] - Training Epoch: 1/2, step 1083/54251 completed (loss: 1.4494041204452515, acc: 0.7368420958518982)
[2024-11-03 04:34:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:32][root][INFO] - Training Epoch: 1/2, step 1084/54251 completed (loss: 1.5664807558059692, acc: 0.75)
[2024-11-03 04:34:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:32][root][INFO] - Training Epoch: 1/2, step 1085/54251 completed (loss: 0.32519781589508057, acc: 0.9473684430122375)
[2024-11-03 04:34:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:33][root][INFO] - Training Epoch: 1/2, step 1086/54251 completed (loss: 1.3407949209213257, acc: 0.738095223903656)
[2024-11-03 04:34:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:33][root][INFO] - Training Epoch: 1/2, step 1087/54251 completed (loss: 1.5667695999145508, acc: 0.5625)
[2024-11-03 04:34:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:34][root][INFO] - Training Epoch: 1/2, step 1088/54251 completed (loss: 1.6284124851226807, acc: 0.6000000238418579)
[2024-11-03 04:34:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:34][root][INFO] - Training Epoch: 1/2, step 1089/54251 completed (loss: 1.924897313117981, acc: 0.4761904776096344)
[2024-11-03 04:34:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:35][root][INFO] - Training Epoch: 1/2, step 1090/54251 completed (loss: 1.3257336616516113, acc: 0.739130437374115)
[2024-11-03 04:34:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:35][root][INFO] - Training Epoch: 1/2, step 1091/54251 completed (loss: 2.4495816230773926, acc: 0.5185185074806213)
[2024-11-03 04:34:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:36][root][INFO] - Training Epoch: 1/2, step 1092/54251 completed (loss: 1.0937095880508423, acc: 0.8333333134651184)
[2024-11-03 04:34:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:36][root][INFO] - Training Epoch: 1/2, step 1093/54251 completed (loss: 1.4998022317886353, acc: 0.625)
[2024-11-03 04:34:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:37][root][INFO] - Training Epoch: 1/2, step 1094/54251 completed (loss: 0.9210923314094543, acc: 0.8095238208770752)
[2024-11-03 04:34:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:37][root][INFO] - Training Epoch: 1/2, step 1095/54251 completed (loss: 0.3458223342895508, acc: 0.95652174949646)
[2024-11-03 04:34:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:38][root][INFO] - Training Epoch: 1/2, step 1096/54251 completed (loss: 1.6631826162338257, acc: 0.6486486196517944)
[2024-11-03 04:34:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:38][root][INFO] - Training Epoch: 1/2, step 1097/54251 completed (loss: 0.5595779418945312, acc: 0.9090909361839294)
[2024-11-03 04:34:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:39][root][INFO] - Training Epoch: 1/2, step 1098/54251 completed (loss: 3.994533061981201, acc: 0.23999999463558197)
[2024-11-03 04:34:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:39][root][INFO] - Training Epoch: 1/2, step 1099/54251 completed (loss: 0.4754774570465088, acc: 0.8974359035491943)
[2024-11-03 04:34:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:40][root][INFO] - Training Epoch: 1/2, step 1100/54251 completed (loss: 0.7378376126289368, acc: 0.7142857313156128)
[2024-11-03 04:34:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:40][root][INFO] - Training Epoch: 1/2, step 1101/54251 completed (loss: 1.2545839548110962, acc: 0.7222222089767456)
[2024-11-03 04:34:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:41][root][INFO] - Training Epoch: 1/2, step 1102/54251 completed (loss: 0.5402206778526306, acc: 0.8421052694320679)
[2024-11-03 04:34:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:41][root][INFO] - Training Epoch: 1/2, step 1103/54251 completed (loss: 0.6262457966804504, acc: 0.8888888955116272)
[2024-11-03 04:34:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:42][root][INFO] - Training Epoch: 1/2, step 1104/54251 completed (loss: 0.6377593278884888, acc: 0.8571428656578064)
[2024-11-03 04:34:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:42][root][INFO] - Training Epoch: 1/2, step 1105/54251 completed (loss: 0.9980776906013489, acc: 0.7333333492279053)
[2024-11-03 04:34:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:43][root][INFO] - Training Epoch: 1/2, step 1106/54251 completed (loss: 1.237610101699829, acc: 0.9333333373069763)
[2024-11-03 04:34:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:43][root][INFO] - Training Epoch: 1/2, step 1107/54251 completed (loss: 1.0138177871704102, acc: 0.9444444179534912)
[2024-11-03 04:34:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:44][root][INFO] - Training Epoch: 1/2, step 1108/54251 completed (loss: 1.2776600122451782, acc: 0.7419354915618896)
[2024-11-03 04:34:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:44][root][INFO] - Training Epoch: 1/2, step 1109/54251 completed (loss: 0.960852324962616, acc: 0.7857142686843872)
[2024-11-03 04:34:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:45][root][INFO] - Training Epoch: 1/2, step 1110/54251 completed (loss: 1.3189300298690796, acc: 0.7222222089767456)
[2024-11-03 04:34:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:45][root][INFO] - Training Epoch: 1/2, step 1111/54251 completed (loss: 1.831545114517212, acc: 0.4000000059604645)
[2024-11-03 04:34:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:46][root][INFO] - Training Epoch: 1/2, step 1112/54251 completed (loss: 0.491852730512619, acc: 0.9230769276618958)
[2024-11-03 04:34:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:46][root][INFO] - Training Epoch: 1/2, step 1113/54251 completed (loss: 0.4486364424228668, acc: 0.8571428656578064)
[2024-11-03 04:34:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:47][root][INFO] - Training Epoch: 1/2, step 1114/54251 completed (loss: 0.2865220606327057, acc: 0.9130434989929199)
[2024-11-03 04:34:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:47][root][INFO] - Training Epoch: 1/2, step 1115/54251 completed (loss: 0.9950875639915466, acc: 0.7674418687820435)
[2024-11-03 04:34:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:48][root][INFO] - Training Epoch: 1/2, step 1116/54251 completed (loss: 0.8151156902313232, acc: 0.8292682766914368)
[2024-11-03 04:34:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:48][root][INFO] - Training Epoch: 1/2, step 1117/54251 completed (loss: 1.0978561639785767, acc: 0.800000011920929)
[2024-11-03 04:34:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:49][root][INFO] - Training Epoch: 1/2, step 1118/54251 completed (loss: 1.245784044265747, acc: 0.6000000238418579)
[2024-11-03 04:34:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:49][root][INFO] - Training Epoch: 1/2, step 1119/54251 completed (loss: 0.6668816208839417, acc: 0.8636363744735718)
[2024-11-03 04:34:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:50][root][INFO] - Training Epoch: 1/2, step 1120/54251 completed (loss: 0.9324398040771484, acc: 0.8541666865348816)
[2024-11-03 04:34:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:50][root][INFO] - Training Epoch: 1/2, step 1121/54251 completed (loss: 0.7236810326576233, acc: 0.8181818127632141)
[2024-11-03 04:34:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:51][root][INFO] - Training Epoch: 1/2, step 1122/54251 completed (loss: 0.6287605166435242, acc: 0.8541666865348816)
[2024-11-03 04:34:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:51][root][INFO] - Training Epoch: 1/2, step 1123/54251 completed (loss: 0.6858579516410828, acc: 0.8999999761581421)
[2024-11-03 04:34:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:52][root][INFO] - Training Epoch: 1/2, step 1124/54251 completed (loss: 1.057633876800537, acc: 0.7894737124443054)
[2024-11-03 04:34:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:52][root][INFO] - Training Epoch: 1/2, step 1125/54251 completed (loss: 0.8403772115707397, acc: 0.8367347121238708)
[2024-11-03 04:34:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:53][root][INFO] - Training Epoch: 1/2, step 1126/54251 completed (loss: 1.1147757768630981, acc: 0.800000011920929)
[2024-11-03 04:34:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:53][root][INFO] - Training Epoch: 1/2, step 1127/54251 completed (loss: 3.197375535964966, acc: 0.5)
[2024-11-03 04:34:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:54][root][INFO] - Training Epoch: 1/2, step 1128/54251 completed (loss: 1.786346197128296, acc: 0.7027027010917664)
[2024-11-03 04:34:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:54][root][INFO] - Training Epoch: 1/2, step 1129/54251 completed (loss: 0.6993594169616699, acc: 0.9024389982223511)
[2024-11-03 04:34:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:55][root][INFO] - Training Epoch: 1/2, step 1130/54251 completed (loss: 0.9780105352401733, acc: 0.6666666865348816)
[2024-11-03 04:34:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:55][root][INFO] - Training Epoch: 1/2, step 1131/54251 completed (loss: 1.168959617614746, acc: 0.7142857313156128)
[2024-11-03 04:34:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:56][root][INFO] - Training Epoch: 1/2, step 1132/54251 completed (loss: 2.968796730041504, acc: 0.5555555820465088)
[2024-11-03 04:34:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:56][root][INFO] - Training Epoch: 1/2, step 1133/54251 completed (loss: 2.015031337738037, acc: 0.6111111044883728)
[2024-11-03 04:34:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:57][root][INFO] - Training Epoch: 1/2, step 1134/54251 completed (loss: 1.3380757570266724, acc: 0.7777777910232544)
[2024-11-03 04:34:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:57][root][INFO] - Training Epoch: 1/2, step 1135/54251 completed (loss: 0.814781904220581, acc: 0.8461538553237915)
[2024-11-03 04:34:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:58][root][INFO] - Training Epoch: 1/2, step 1136/54251 completed (loss: 0.43977025151252747, acc: 0.9166666865348816)
[2024-11-03 04:34:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:58][root][INFO] - Training Epoch: 1/2, step 1137/54251 completed (loss: 1.0074877738952637, acc: 0.8148148059844971)
[2024-11-03 04:34:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:59][root][INFO] - Training Epoch: 1/2, step 1138/54251 completed (loss: 1.422629952430725, acc: 0.7837837934494019)
[2024-11-03 04:34:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:59][root][INFO] - Training Epoch: 1/2, step 1139/54251 completed (loss: 1.369741678237915, acc: 0.7631579041481018)
[2024-11-03 04:34:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:34:59][root][INFO] - Training Epoch: 1/2, step 1140/54251 completed (loss: 0.9973664283752441, acc: 0.7142857313156128)
[2024-11-03 04:35:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:00][root][INFO] - Training Epoch: 1/2, step 1141/54251 completed (loss: 1.3735891580581665, acc: 0.7777777910232544)
[2024-11-03 04:35:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:00][root][INFO] - Training Epoch: 1/2, step 1142/54251 completed (loss: 0.5263563394546509, acc: 0.8936170339584351)
[2024-11-03 04:35:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:01][root][INFO] - Training Epoch: 1/2, step 1143/54251 completed (loss: 1.1045992374420166, acc: 0.7692307829856873)
[2024-11-03 04:35:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:01][root][INFO] - Training Epoch: 1/2, step 1144/54251 completed (loss: 0.5444046258926392, acc: 0.8999999761581421)
[2024-11-03 04:35:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:02][root][INFO] - Training Epoch: 1/2, step 1145/54251 completed (loss: 1.5779613256454468, acc: 0.7142857313156128)
[2024-11-03 04:35:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:02][root][INFO] - Training Epoch: 1/2, step 1146/54251 completed (loss: 0.7646076679229736, acc: 0.8666666746139526)
[2024-11-03 04:35:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:03][root][INFO] - Training Epoch: 1/2, step 1147/54251 completed (loss: 1.9921091794967651, acc: 0.6842105388641357)
[2024-11-03 04:35:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:03][root][INFO] - Training Epoch: 1/2, step 1148/54251 completed (loss: 1.8281580209732056, acc: 0.6086956262588501)
[2024-11-03 04:35:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:04][root][INFO] - Training Epoch: 1/2, step 1149/54251 completed (loss: 1.197885274887085, acc: 0.6875)
[2024-11-03 04:35:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:04][root][INFO] - Training Epoch: 1/2, step 1150/54251 completed (loss: 1.7010990381240845, acc: 0.6428571343421936)
[2024-11-03 04:35:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:05][root][INFO] - Training Epoch: 1/2, step 1151/54251 completed (loss: 0.9125621914863586, acc: 0.7931034564971924)
[2024-11-03 04:35:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:05][root][INFO] - Training Epoch: 1/2, step 1152/54251 completed (loss: 0.31289663910865784, acc: 0.90625)
[2024-11-03 04:35:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:06][root][INFO] - Training Epoch: 1/2, step 1153/54251 completed (loss: 1.5298101902008057, acc: 0.7272727489471436)
[2024-11-03 04:35:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:06][root][INFO] - Training Epoch: 1/2, step 1154/54251 completed (loss: 2.0269970893859863, acc: 0.5384615659713745)
[2024-11-03 04:35:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:07][root][INFO] - Training Epoch: 1/2, step 1155/54251 completed (loss: 2.0685479640960693, acc: 0.6296296119689941)
[2024-11-03 04:35:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:07][root][INFO] - Training Epoch: 1/2, step 1156/54251 completed (loss: 0.5752715468406677, acc: 0.8571428656578064)
[2024-11-03 04:35:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:08][root][INFO] - Training Epoch: 1/2, step 1157/54251 completed (loss: 0.6583895087242126, acc: 0.8529411554336548)
[2024-11-03 04:35:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:08][root][INFO] - Training Epoch: 1/2, step 1158/54251 completed (loss: 1.7179746627807617, acc: 0.6000000238418579)
[2024-11-03 04:35:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:09][root][INFO] - Training Epoch: 1/2, step 1159/54251 completed (loss: 0.36260902881622314, acc: 0.9090909361839294)
[2024-11-03 04:35:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:09][root][INFO] - Training Epoch: 1/2, step 1160/54251 completed (loss: 1.7899171113967896, acc: 0.7142857313156128)
[2024-11-03 04:35:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:10][root][INFO] - Training Epoch: 1/2, step 1161/54251 completed (loss: 0.286884605884552, acc: 0.930232584476471)
[2024-11-03 04:35:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:10][root][INFO] - Training Epoch: 1/2, step 1162/54251 completed (loss: 0.8869892358779907, acc: 0.8125)
[2024-11-03 04:35:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:11][root][INFO] - Training Epoch: 1/2, step 1163/54251 completed (loss: 0.041509270668029785, acc: 1.0)
[2024-11-03 04:35:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:11][root][INFO] - Training Epoch: 1/2, step 1164/54251 completed (loss: 1.8353246450424194, acc: 0.5833333134651184)
[2024-11-03 04:35:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:12][root][INFO] - Training Epoch: 1/2, step 1165/54251 completed (loss: 1.067577838897705, acc: 0.7333333492279053)
[2024-11-03 04:35:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:12][root][INFO] - Training Epoch: 1/2, step 1166/54251 completed (loss: 1.103061318397522, acc: 0.7882353067398071)
[2024-11-03 04:35:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:13][root][INFO] - Training Epoch: 1/2, step 1167/54251 completed (loss: 2.2317798137664795, acc: 0.3333333432674408)
[2024-11-03 04:35:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:13][root][INFO] - Training Epoch: 1/2, step 1168/54251 completed (loss: 1.444887638092041, acc: 0.699999988079071)
[2024-11-03 04:35:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:14][root][INFO] - Training Epoch: 1/2, step 1169/54251 completed (loss: 1.6133536100387573, acc: 0.6363636255264282)
[2024-11-03 04:35:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:14][root][INFO] - Training Epoch: 1/2, step 1170/54251 completed (loss: 0.47624659538269043, acc: 0.930232584476471)
[2024-11-03 04:35:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:15][root][INFO] - Training Epoch: 1/2, step 1171/54251 completed (loss: 0.8536242246627808, acc: 0.699999988079071)
[2024-11-03 04:35:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:15][root][INFO] - Training Epoch: 1/2, step 1172/54251 completed (loss: 1.3603464365005493, acc: 0.75)
[2024-11-03 04:35:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:16][root][INFO] - Training Epoch: 1/2, step 1173/54251 completed (loss: 0.9093997478485107, acc: 0.7948718070983887)
[2024-11-03 04:35:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:16][root][INFO] - Training Epoch: 1/2, step 1174/54251 completed (loss: 0.4674180746078491, acc: 0.9090909361839294)
[2024-11-03 04:35:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:17][root][INFO] - Training Epoch: 1/2, step 1175/54251 completed (loss: 2.059546709060669, acc: 0.5416666865348816)
[2024-11-03 04:35:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:17][root][INFO] - Training Epoch: 1/2, step 1176/54251 completed (loss: 1.4540073871612549, acc: 0.6363636255264282)
[2024-11-03 04:35:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:18][root][INFO] - Training Epoch: 1/2, step 1177/54251 completed (loss: 2.98919415473938, acc: 0.5882353186607361)
[2024-11-03 04:35:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:18][root][INFO] - Training Epoch: 1/2, step 1178/54251 completed (loss: 0.30614718794822693, acc: 0.9411764740943909)
[2024-11-03 04:35:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:19][root][INFO] - Training Epoch: 1/2, step 1179/54251 completed (loss: 0.5916640162467957, acc: 0.8627451062202454)
[2024-11-03 04:35:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:19][root][INFO] - Training Epoch: 1/2, step 1180/54251 completed (loss: 1.6090871095657349, acc: 0.6551724076271057)
[2024-11-03 04:35:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:20][root][INFO] - Training Epoch: 1/2, step 1181/54251 completed (loss: 0.560863733291626, acc: 0.8999999761581421)
[2024-11-03 04:35:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:20][root][INFO] - Training Epoch: 1/2, step 1182/54251 completed (loss: 0.8824737071990967, acc: 0.8181818127632141)
[2024-11-03 04:35:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:21][root][INFO] - Training Epoch: 1/2, step 1183/54251 completed (loss: 1.5492475032806396, acc: 0.75)
[2024-11-03 04:35:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:21][root][INFO] - Training Epoch: 1/2, step 1184/54251 completed (loss: 0.37300553917884827, acc: 0.918367326259613)
[2024-11-03 04:35:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:22][root][INFO] - Training Epoch: 1/2, step 1185/54251 completed (loss: 0.3255694508552551, acc: 0.9333333373069763)
[2024-11-03 04:35:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:22][root][INFO] - Training Epoch: 1/2, step 1186/54251 completed (loss: 0.5306172966957092, acc: 0.8333333134651184)
[2024-11-03 04:35:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:23][root][INFO] - Training Epoch: 1/2, step 1187/54251 completed (loss: 1.5070377588272095, acc: 0.7083333134651184)
[2024-11-03 04:35:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:23][root][INFO] - Training Epoch: 1/2, step 1188/54251 completed (loss: 0.7988724112510681, acc: 0.7142857313156128)
[2024-11-03 04:35:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:24][root][INFO] - Training Epoch: 1/2, step 1189/54251 completed (loss: 0.5680132508277893, acc: 0.8974359035491943)
[2024-11-03 04:35:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:24][root][INFO] - Training Epoch: 1/2, step 1190/54251 completed (loss: 2.4851431846618652, acc: 0.6000000238418579)
[2024-11-03 04:35:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:25][root][INFO] - Training Epoch: 1/2, step 1191/54251 completed (loss: 0.2623666524887085, acc: 0.9722222089767456)
[2024-11-03 04:35:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:25][root][INFO] - Training Epoch: 1/2, step 1192/54251 completed (loss: 0.8721564412117004, acc: 0.8399999737739563)
[2024-11-03 04:35:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:26][root][INFO] - Training Epoch: 1/2, step 1193/54251 completed (loss: 1.1683825254440308, acc: 0.7272727489471436)
[2024-11-03 04:35:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:26][root][INFO] - Training Epoch: 1/2, step 1194/54251 completed (loss: 0.6542951464653015, acc: 0.8727272748947144)
[2024-11-03 04:35:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:27][root][INFO] - Training Epoch: 1/2, step 1195/54251 completed (loss: 2.391693592071533, acc: 0.5)
[2024-11-03 04:35:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:27][root][INFO] - Training Epoch: 1/2, step 1196/54251 completed (loss: 1.604340672492981, acc: 0.6666666865348816)
[2024-11-03 04:35:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:28][root][INFO] - Training Epoch: 1/2, step 1197/54251 completed (loss: 2.4053375720977783, acc: 0.6000000238418579)
[2024-11-03 04:35:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:28][root][INFO] - Training Epoch: 1/2, step 1198/54251 completed (loss: 1.0756059885025024, acc: 0.7894737124443054)
[2024-11-03 04:35:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:29][root][INFO] - Training Epoch: 1/2, step 1199/54251 completed (loss: 1.5508012771606445, acc: 0.695652186870575)
[2024-11-03 04:35:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:29][root][INFO] - Training Epoch: 1/2, step 1200/54251 completed (loss: 1.4706048965454102, acc: 0.6857143044471741)
[2024-11-03 04:35:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:30][root][INFO] - Training Epoch: 1/2, step 1201/54251 completed (loss: 1.2684541940689087, acc: 0.6969696879386902)
[2024-11-03 04:35:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:30][root][INFO] - Training Epoch: 1/2, step 1202/54251 completed (loss: 1.1561195850372314, acc: 0.75)
[2024-11-03 04:35:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:31][root][INFO] - Training Epoch: 1/2, step 1203/54251 completed (loss: 0.873120129108429, acc: 0.84375)
[2024-11-03 04:35:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:31][root][INFO] - Training Epoch: 1/2, step 1204/54251 completed (loss: 0.38252848386764526, acc: 0.949999988079071)
[2024-11-03 04:35:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:32][root][INFO] - Training Epoch: 1/2, step 1205/54251 completed (loss: 1.3680598735809326, acc: 0.7142857313156128)
[2024-11-03 04:35:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:32][root][INFO] - Training Epoch: 1/2, step 1206/54251 completed (loss: 1.7342891693115234, acc: 0.6818181872367859)
[2024-11-03 04:35:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:33][root][INFO] - Training Epoch: 1/2, step 1207/54251 completed (loss: 0.7440683841705322, acc: 0.795918345451355)
[2024-11-03 04:35:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:33][root][INFO] - Training Epoch: 1/2, step 1208/54251 completed (loss: 1.0402743816375732, acc: 0.5714285969734192)
[2024-11-03 04:35:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:34][root][INFO] - Training Epoch: 1/2, step 1209/54251 completed (loss: 0.7901515960693359, acc: 0.7878788113594055)
[2024-11-03 04:35:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:34][root][INFO] - Training Epoch: 1/2, step 1210/54251 completed (loss: 3.002913475036621, acc: 0.6111111044883728)
[2024-11-03 04:35:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:35][root][INFO] - Training Epoch: 1/2, step 1211/54251 completed (loss: 1.5566251277923584, acc: 0.7333333492279053)
[2024-11-03 04:35:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:35][root][INFO] - Training Epoch: 1/2, step 1212/54251 completed (loss: 1.4208652973175049, acc: 0.5652173757553101)
[2024-11-03 04:35:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:36][root][INFO] - Training Epoch: 1/2, step 1213/54251 completed (loss: 0.9007642865180969, acc: 0.8214285969734192)
[2024-11-03 04:35:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:36][root][INFO] - Training Epoch: 1/2, step 1214/54251 completed (loss: 0.5811401605606079, acc: 0.800000011920929)
[2024-11-03 04:35:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:37][root][INFO] - Training Epoch: 1/2, step 1215/54251 completed (loss: 0.8420047760009766, acc: 0.8181818127632141)
[2024-11-03 04:35:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:37][root][INFO] - Training Epoch: 1/2, step 1216/54251 completed (loss: 0.8495714068412781, acc: 0.6521739363670349)
[2024-11-03 04:35:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:38][root][INFO] - Training Epoch: 1/2, step 1217/54251 completed (loss: 0.414898157119751, acc: 0.8333333134651184)
[2024-11-03 04:35:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:38][root][INFO] - Training Epoch: 1/2, step 1218/54251 completed (loss: 0.7684699892997742, acc: 0.75)
[2024-11-03 04:35:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:39][root][INFO] - Training Epoch: 1/2, step 1219/54251 completed (loss: 1.9922399520874023, acc: 0.7058823704719543)
[2024-11-03 04:35:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:39][root][INFO] - Training Epoch: 1/2, step 1220/54251 completed (loss: 1.2235345840454102, acc: 0.7352941036224365)
[2024-11-03 04:35:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:40][root][INFO] - Training Epoch: 1/2, step 1221/54251 completed (loss: 1.488624930381775, acc: 0.6896551847457886)
[2024-11-03 04:35:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:40][root][INFO] - Training Epoch: 1/2, step 1222/54251 completed (loss: 1.6798839569091797, acc: 0.5882353186607361)
[2024-11-03 04:35:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:41][root][INFO] - Training Epoch: 1/2, step 1223/54251 completed (loss: 0.5851960778236389, acc: 0.875)
[2024-11-03 04:35:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:41][root][INFO] - Training Epoch: 1/2, step 1224/54251 completed (loss: 0.7982702851295471, acc: 0.8571428656578064)
[2024-11-03 04:35:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:42][root][INFO] - Training Epoch: 1/2, step 1225/54251 completed (loss: 1.859621524810791, acc: 0.5789473652839661)
[2024-11-03 04:35:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:42][root][INFO] - Training Epoch: 1/2, step 1226/54251 completed (loss: 0.696471631526947, acc: 0.8732394576072693)
[2024-11-03 04:35:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:43][root][INFO] - Training Epoch: 1/2, step 1227/54251 completed (loss: 0.1587028056383133, acc: 0.8999999761581421)
[2024-11-03 04:35:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:43][root][INFO] - Training Epoch: 1/2, step 1228/54251 completed (loss: 0.32046934962272644, acc: 0.9615384340286255)
[2024-11-03 04:35:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:44][root][INFO] - Training Epoch: 1/2, step 1229/54251 completed (loss: 0.5745645761489868, acc: 0.8947368264198303)
[2024-11-03 04:35:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:44][root][INFO] - Training Epoch: 1/2, step 1230/54251 completed (loss: 1.469164252281189, acc: 0.7272727489471436)
[2024-11-03 04:35:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:45][root][INFO] - Training Epoch: 1/2, step 1231/54251 completed (loss: 0.9970183372497559, acc: 0.84375)
[2024-11-03 04:35:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:45][root][INFO] - Training Epoch: 1/2, step 1232/54251 completed (loss: 0.5149887800216675, acc: 0.9166666865348816)
[2024-11-03 04:35:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:46][root][INFO] - Training Epoch: 1/2, step 1233/54251 completed (loss: 2.0494203567504883, acc: 0.6000000238418579)
[2024-11-03 04:35:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:46][root][INFO] - Training Epoch: 1/2, step 1234/54251 completed (loss: 2.961869955062866, acc: 0.5333333611488342)
[2024-11-03 04:35:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:47][root][INFO] - Training Epoch: 1/2, step 1235/54251 completed (loss: 1.9545093774795532, acc: 0.7575757503509521)
[2024-11-03 04:35:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:47][root][INFO] - Training Epoch: 1/2, step 1236/54251 completed (loss: 0.9408623576164246, acc: 0.7777777910232544)
[2024-11-03 04:35:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:48][root][INFO] - Training Epoch: 1/2, step 1237/54251 completed (loss: 1.16279137134552, acc: 0.6666666865348816)
[2024-11-03 04:35:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:48][root][INFO] - Training Epoch: 1/2, step 1238/54251 completed (loss: 0.4815734922885895, acc: 0.8695651888847351)
[2024-11-03 04:35:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:49][root][INFO] - Training Epoch: 1/2, step 1239/54251 completed (loss: 1.6857023239135742, acc: 0.6666666865348816)
[2024-11-03 04:35:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:49][root][INFO] - Training Epoch: 1/2, step 1240/54251 completed (loss: 0.35754260420799255, acc: 0.875)
[2024-11-03 04:35:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:49][root][INFO] - Training Epoch: 1/2, step 1241/54251 completed (loss: 0.21797458827495575, acc: 0.970588207244873)
[2024-11-03 04:35:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:50][root][INFO] - Training Epoch: 1/2, step 1242/54251 completed (loss: 0.7428798079490662, acc: 0.7222222089767456)
[2024-11-03 04:35:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:50][root][INFO] - Training Epoch: 1/2, step 1243/54251 completed (loss: 0.43139103055000305, acc: 0.9259259104728699)
[2024-11-03 04:35:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:51][root][INFO] - Training Epoch: 1/2, step 1244/54251 completed (loss: 1.04927659034729, acc: 0.7254902124404907)
[2024-11-03 04:35:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:51][root][INFO] - Training Epoch: 1/2, step 1245/54251 completed (loss: 1.226987361907959, acc: 0.7777777910232544)
[2024-11-03 04:35:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:52][root][INFO] - Training Epoch: 1/2, step 1246/54251 completed (loss: 0.7309125661849976, acc: 0.824999988079071)
[2024-11-03 04:35:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:52][root][INFO] - Training Epoch: 1/2, step 1247/54251 completed (loss: 0.3232536017894745, acc: 0.9473684430122375)
[2024-11-03 04:35:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:53][root][INFO] - Training Epoch: 1/2, step 1248/54251 completed (loss: 0.5542964935302734, acc: 0.8333333134651184)
[2024-11-03 04:35:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:53][root][INFO] - Training Epoch: 1/2, step 1249/54251 completed (loss: 0.9821575284004211, acc: 0.800000011920929)
[2024-11-03 04:35:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:54][root][INFO] - Training Epoch: 1/2, step 1250/54251 completed (loss: 0.8751275539398193, acc: 0.8333333134651184)
[2024-11-03 04:35:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:54][root][INFO] - Training Epoch: 1/2, step 1251/54251 completed (loss: 0.5498732924461365, acc: 0.8769230842590332)
[2024-11-03 04:35:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:55][root][INFO] - Training Epoch: 1/2, step 1252/54251 completed (loss: 0.6168045401573181, acc: 0.8518518805503845)
[2024-11-03 04:35:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:55][root][INFO] - Training Epoch: 1/2, step 1253/54251 completed (loss: 1.8767714500427246, acc: 0.6363636255264282)
[2024-11-03 04:35:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:56][root][INFO] - Training Epoch: 1/2, step 1254/54251 completed (loss: 0.8554716110229492, acc: 0.8333333134651184)
[2024-11-03 04:35:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:56][root][INFO] - Training Epoch: 1/2, step 1255/54251 completed (loss: 0.9254878759384155, acc: 0.75)
[2024-11-03 04:35:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:57][root][INFO] - Training Epoch: 1/2, step 1256/54251 completed (loss: 0.04917970299720764, acc: 1.0)
[2024-11-03 04:35:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:57][root][INFO] - Training Epoch: 1/2, step 1257/54251 completed (loss: 1.4069664478302002, acc: 0.6363636255264282)
[2024-11-03 04:35:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:58][root][INFO] - Training Epoch: 1/2, step 1258/54251 completed (loss: 0.395952969789505, acc: 0.9545454382896423)
[2024-11-03 04:35:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:58][root][INFO] - Training Epoch: 1/2, step 1259/54251 completed (loss: 0.9111394286155701, acc: 0.7272727489471436)
[2024-11-03 04:35:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:59][root][INFO] - Training Epoch: 1/2, step 1260/54251 completed (loss: 1.008023738861084, acc: 0.625)
[2024-11-03 04:35:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:35:59][root][INFO] - Training Epoch: 1/2, step 1261/54251 completed (loss: 1.213779091835022, acc: 0.5833333134651184)
[2024-11-03 04:35:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:00][root][INFO] - Training Epoch: 1/2, step 1262/54251 completed (loss: 1.1864287853240967, acc: 0.8333333134651184)
[2024-11-03 04:36:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:00][root][INFO] - Training Epoch: 1/2, step 1263/54251 completed (loss: 1.8568620681762695, acc: 0.75)
[2024-11-03 04:36:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:01][root][INFO] - Training Epoch: 1/2, step 1264/54251 completed (loss: 0.23673619329929352, acc: 1.0)
[2024-11-03 04:36:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:01][root][INFO] - Training Epoch: 1/2, step 1265/54251 completed (loss: 0.491650253534317, acc: 0.8235294222831726)
[2024-11-03 04:36:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:02][root][INFO] - Training Epoch: 1/2, step 1266/54251 completed (loss: 0.7054125666618347, acc: 0.8461538553237915)
[2024-11-03 04:36:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:02][root][INFO] - Training Epoch: 1/2, step 1267/54251 completed (loss: 0.2431371808052063, acc: 0.9583333134651184)
[2024-11-03 04:36:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:03][root][INFO] - Training Epoch: 1/2, step 1268/54251 completed (loss: 0.34232833981513977, acc: 0.8799999952316284)
[2024-11-03 04:36:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:03][root][INFO] - Training Epoch: 1/2, step 1269/54251 completed (loss: 0.6631104946136475, acc: 0.8648648858070374)
[2024-11-03 04:36:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:04][root][INFO] - Training Epoch: 1/2, step 1270/54251 completed (loss: 1.1368201971054077, acc: 0.75)
[2024-11-03 04:36:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:04][root][INFO] - Training Epoch: 1/2, step 1271/54251 completed (loss: 1.375982642173767, acc: 0.7586206793785095)
[2024-11-03 04:36:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:05][root][INFO] - Training Epoch: 1/2, step 1272/54251 completed (loss: 0.8353545665740967, acc: 0.7727272510528564)
[2024-11-03 04:36:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:05][root][INFO] - Training Epoch: 1/2, step 1273/54251 completed (loss: 0.535585343837738, acc: 0.9411764740943909)
[2024-11-03 04:36:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:06][root][INFO] - Training Epoch: 1/2, step 1274/54251 completed (loss: 1.6267880201339722, acc: 0.6865671873092651)
[2024-11-03 04:36:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:06][root][INFO] - Training Epoch: 1/2, step 1275/54251 completed (loss: 0.20481765270233154, acc: 1.0)
[2024-11-03 04:36:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:07][root][INFO] - Training Epoch: 1/2, step 1276/54251 completed (loss: 1.5481953620910645, acc: 0.47058823704719543)
[2024-11-03 04:36:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:07][root][INFO] - Training Epoch: 1/2, step 1277/54251 completed (loss: 0.8603079915046692, acc: 0.8372092843055725)
[2024-11-03 04:36:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:08][root][INFO] - Training Epoch: 1/2, step 1278/54251 completed (loss: 0.5486024022102356, acc: 0.800000011920929)
[2024-11-03 04:36:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:08][root][INFO] - Training Epoch: 1/2, step 1279/54251 completed (loss: 2.2672579288482666, acc: 0.7272727489471436)
[2024-11-03 04:36:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:09][root][INFO] - Training Epoch: 1/2, step 1280/54251 completed (loss: 0.974621057510376, acc: 0.800000011920929)
[2024-11-03 04:36:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:09][root][INFO] - Training Epoch: 1/2, step 1281/54251 completed (loss: 1.1290767192840576, acc: 0.7179487347602844)
[2024-11-03 04:36:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:10][root][INFO] - Training Epoch: 1/2, step 1282/54251 completed (loss: 1.342002272605896, acc: 0.75)
[2024-11-03 04:36:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:10][root][INFO] - Training Epoch: 1/2, step 1283/54251 completed (loss: 1.2645106315612793, acc: 0.8125)
[2024-11-03 04:36:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:11][root][INFO] - Training Epoch: 1/2, step 1284/54251 completed (loss: 0.2782382667064667, acc: 0.9166666865348816)
[2024-11-03 04:36:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:11][root][INFO] - Training Epoch: 1/2, step 1285/54251 completed (loss: 1.2606369256973267, acc: 0.7407407164573669)
[2024-11-03 04:36:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:12][root][INFO] - Training Epoch: 1/2, step 1286/54251 completed (loss: 1.7556936740875244, acc: 0.6451612710952759)
[2024-11-03 04:36:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:12][root][INFO] - Training Epoch: 1/2, step 1287/54251 completed (loss: 0.2622947692871094, acc: 0.9090909361839294)
[2024-11-03 04:36:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:13][root][INFO] - Training Epoch: 1/2, step 1288/54251 completed (loss: 0.6000388860702515, acc: 0.8857142925262451)
[2024-11-03 04:36:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:13][root][INFO] - Training Epoch: 1/2, step 1289/54251 completed (loss: 0.75154048204422, acc: 0.7777777910232544)
[2024-11-03 04:36:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:14][root][INFO] - Training Epoch: 1/2, step 1290/54251 completed (loss: 1.91067373752594, acc: 0.5555555820465088)
[2024-11-03 04:36:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:14][root][INFO] - Training Epoch: 1/2, step 1291/54251 completed (loss: 1.2720253467559814, acc: 0.692307710647583)
[2024-11-03 04:36:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:15][root][INFO] - Training Epoch: 1/2, step 1292/54251 completed (loss: 0.7326200008392334, acc: 0.75)
[2024-11-03 04:36:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:15][root][INFO] - Training Epoch: 1/2, step 1293/54251 completed (loss: 1.1664478778839111, acc: 0.8260869383811951)
[2024-11-03 04:36:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:16][root][INFO] - Training Epoch: 1/2, step 1294/54251 completed (loss: 0.7065485119819641, acc: 0.8684210777282715)
[2024-11-03 04:36:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:16][root][INFO] - Training Epoch: 1/2, step 1295/54251 completed (loss: 2.129776954650879, acc: 0.692307710647583)
[2024-11-03 04:36:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:17][root][INFO] - Training Epoch: 1/2, step 1296/54251 completed (loss: 0.8524006009101868, acc: 0.7804877758026123)
[2024-11-03 04:36:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:17][root][INFO] - Training Epoch: 1/2, step 1297/54251 completed (loss: 1.0810210704803467, acc: 0.7027027010917664)
[2024-11-03 04:36:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:18][root][INFO] - Training Epoch: 1/2, step 1298/54251 completed (loss: 2.3819947242736816, acc: 0.5555555820465088)
[2024-11-03 04:36:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:18][root][INFO] - Training Epoch: 1/2, step 1299/54251 completed (loss: 0.7436932921409607, acc: 0.8947368264198303)
[2024-11-03 04:36:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:19][root][INFO] - Training Epoch: 1/2, step 1300/54251 completed (loss: 0.8990516066551208, acc: 0.8163265585899353)
[2024-11-03 04:36:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:19][root][INFO] - Training Epoch: 1/2, step 1301/54251 completed (loss: 0.5598064064979553, acc: 0.8571428656578064)
[2024-11-03 04:36:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:20][root][INFO] - Training Epoch: 1/2, step 1302/54251 completed (loss: 1.7732820510864258, acc: 0.6000000238418579)
[2024-11-03 04:36:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:20][root][INFO] - Training Epoch: 1/2, step 1303/54251 completed (loss: 0.3480377793312073, acc: 0.8999999761581421)
[2024-11-03 04:36:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:21][root][INFO] - Training Epoch: 1/2, step 1304/54251 completed (loss: 0.5532422065734863, acc: 0.8888888955116272)
[2024-11-03 04:36:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:21][root][INFO] - Training Epoch: 1/2, step 1305/54251 completed (loss: 1.3757939338684082, acc: 0.6666666865348816)
[2024-11-03 04:36:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:22][root][INFO] - Training Epoch: 1/2, step 1306/54251 completed (loss: 2.6816213130950928, acc: 0.3913043439388275)
[2024-11-03 04:36:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:22][root][INFO] - Training Epoch: 1/2, step 1307/54251 completed (loss: 0.7463518381118774, acc: 0.7857142686843872)
[2024-11-03 04:36:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:23][root][INFO] - Training Epoch: 1/2, step 1308/54251 completed (loss: 0.7155742645263672, acc: 0.875)
[2024-11-03 04:36:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:23][root][INFO] - Training Epoch: 1/2, step 1309/54251 completed (loss: 1.3845120668411255, acc: 0.7368420958518982)
[2024-11-03 04:36:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:24][root][INFO] - Training Epoch: 1/2, step 1310/54251 completed (loss: 1.4326679706573486, acc: 0.7142857313156128)
[2024-11-03 04:36:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:24][root][INFO] - Training Epoch: 1/2, step 1311/54251 completed (loss: 3.1368556022644043, acc: 0.23529411852359772)
[2024-11-03 04:36:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:25][root][INFO] - Training Epoch: 1/2, step 1312/54251 completed (loss: 0.2644837498664856, acc: 0.9285714030265808)
[2024-11-03 04:36:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:25][root][INFO] - Training Epoch: 1/2, step 1313/54251 completed (loss: 0.93414306640625, acc: 0.75)
[2024-11-03 04:36:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:26][root][INFO] - Training Epoch: 1/2, step 1314/54251 completed (loss: 0.3551734685897827, acc: 1.0)
[2024-11-03 04:36:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:26][root][INFO] - Training Epoch: 1/2, step 1315/54251 completed (loss: 1.3037034273147583, acc: 0.7777777910232544)
[2024-11-03 04:36:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:27][root][INFO] - Training Epoch: 1/2, step 1316/54251 completed (loss: 2.9268078804016113, acc: 0.3076923191547394)
[2024-11-03 04:36:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:27][root][INFO] - Training Epoch: 1/2, step 1317/54251 completed (loss: 1.0284271240234375, acc: 0.8947368264198303)
[2024-11-03 04:36:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:28][root][INFO] - Training Epoch: 1/2, step 1318/54251 completed (loss: 2.5721209049224854, acc: 0.5199999809265137)
[2024-11-03 04:36:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:28][root][INFO] - Training Epoch: 1/2, step 1319/54251 completed (loss: 0.499540776014328, acc: 0.8571428656578064)
[2024-11-03 04:36:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:29][root][INFO] - Training Epoch: 1/2, step 1320/54251 completed (loss: 0.6114634275436401, acc: 0.9047619104385376)
[2024-11-03 04:36:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:29][root][INFO] - Training Epoch: 1/2, step 1321/54251 completed (loss: 0.6274106502532959, acc: 0.875)
[2024-11-03 04:36:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:30][root][INFO] - Training Epoch: 1/2, step 1322/54251 completed (loss: 0.3230641484260559, acc: 0.9285714030265808)
[2024-11-03 04:36:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:30][root][INFO] - Training Epoch: 1/2, step 1323/54251 completed (loss: 1.3553410768508911, acc: 0.75)
[2024-11-03 04:36:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:31][root][INFO] - Training Epoch: 1/2, step 1324/54251 completed (loss: 0.5409735441207886, acc: 0.7777777910232544)
[2024-11-03 04:36:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:31][root][INFO] - Training Epoch: 1/2, step 1325/54251 completed (loss: 0.5193027853965759, acc: 0.8823529481887817)
[2024-11-03 04:36:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:32][root][INFO] - Training Epoch: 1/2, step 1326/54251 completed (loss: 0.6990574598312378, acc: 0.7419354915618896)
[2024-11-03 04:36:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:32][root][INFO] - Training Epoch: 1/2, step 1327/54251 completed (loss: 1.195233941078186, acc: 0.8235294222831726)
[2024-11-03 04:36:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:33][root][INFO] - Training Epoch: 1/2, step 1328/54251 completed (loss: 0.25128084421157837, acc: 1.0)
[2024-11-03 04:36:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:33][root][INFO] - Training Epoch: 1/2, step 1329/54251 completed (loss: 2.310135841369629, acc: 0.5263158082962036)
[2024-11-03 04:36:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:34][root][INFO] - Training Epoch: 1/2, step 1330/54251 completed (loss: 3.717802047729492, acc: 0.1666666716337204)
[2024-11-03 04:36:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:34][root][INFO] - Training Epoch: 1/2, step 1331/54251 completed (loss: 1.315487027168274, acc: 0.774193525314331)
[2024-11-03 04:36:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:35][root][INFO] - Training Epoch: 1/2, step 1332/54251 completed (loss: 1.6130121946334839, acc: 0.6666666865348816)
[2024-11-03 04:36:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:35][root][INFO] - Training Epoch: 1/2, step 1333/54251 completed (loss: 1.0423190593719482, acc: 0.837837815284729)
[2024-11-03 04:36:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:36][root][INFO] - Training Epoch: 1/2, step 1334/54251 completed (loss: 0.9671746492385864, acc: 0.6000000238418579)
[2024-11-03 04:36:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:36][root][INFO] - Training Epoch: 1/2, step 1335/54251 completed (loss: 0.6980293989181519, acc: 0.800000011920929)
[2024-11-03 04:36:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:37][root][INFO] - Training Epoch: 1/2, step 1336/54251 completed (loss: 2.256279468536377, acc: 0.5)
[2024-11-03 04:36:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:37][root][INFO] - Training Epoch: 1/2, step 1337/54251 completed (loss: 0.7613330483436584, acc: 0.8387096524238586)
[2024-11-03 04:36:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:38][root][INFO] - Training Epoch: 1/2, step 1338/54251 completed (loss: 1.0259637832641602, acc: 0.7843137383460999)
[2024-11-03 04:36:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:38][root][INFO] - Training Epoch: 1/2, step 1339/54251 completed (loss: 0.5778250098228455, acc: 0.8333333134651184)
[2024-11-03 04:36:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:39][root][INFO] - Training Epoch: 1/2, step 1340/54251 completed (loss: 0.8452451825141907, acc: 0.8235294222831726)
[2024-11-03 04:36:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:39][root][INFO] - Training Epoch: 1/2, step 1341/54251 completed (loss: 1.0206443071365356, acc: 0.7142857313156128)
[2024-11-03 04:36:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:40][root][INFO] - Training Epoch: 1/2, step 1342/54251 completed (loss: 2.1238155364990234, acc: 0.6097561120986938)
[2024-11-03 04:36:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:40][root][INFO] - Training Epoch: 1/2, step 1343/54251 completed (loss: 0.2045326828956604, acc: 0.9772727489471436)
[2024-11-03 04:36:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:41][root][INFO] - Training Epoch: 1/2, step 1344/54251 completed (loss: 2.1550309658050537, acc: 0.6666666865348816)
[2024-11-03 04:36:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:41][root][INFO] - Training Epoch: 1/2, step 1345/54251 completed (loss: 0.14827409386634827, acc: 1.0)
[2024-11-03 04:36:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:42][root][INFO] - Training Epoch: 1/2, step 1346/54251 completed (loss: 1.5300445556640625, acc: 0.5)
[2024-11-03 04:36:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:42][root][INFO] - Training Epoch: 1/2, step 1347/54251 completed (loss: 2.071535110473633, acc: 0.6410256624221802)
[2024-11-03 04:36:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:43][root][INFO] - Training Epoch: 1/2, step 1348/54251 completed (loss: 0.8998570442199707, acc: 0.699999988079071)
[2024-11-03 04:36:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:43][root][INFO] - Training Epoch: 1/2, step 1349/54251 completed (loss: 1.1319152116775513, acc: 0.875)
[2024-11-03 04:36:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:44][root][INFO] - Training Epoch: 1/2, step 1350/54251 completed (loss: 3.616419553756714, acc: 0.4000000059604645)
[2024-11-03 04:36:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:44][root][INFO] - Training Epoch: 1/2, step 1351/54251 completed (loss: 2.379607915878296, acc: 0.5813953280448914)
[2024-11-03 04:36:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:45][root][INFO] - Training Epoch: 1/2, step 1352/54251 completed (loss: 1.6050747632980347, acc: 0.5714285969734192)
[2024-11-03 04:36:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:45][root][INFO] - Training Epoch: 1/2, step 1353/54251 completed (loss: 1.2599788904190063, acc: 0.7777777910232544)
[2024-11-03 04:36:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:46][root][INFO] - Training Epoch: 1/2, step 1354/54251 completed (loss: 0.3707677125930786, acc: 0.95652174949646)
[2024-11-03 04:36:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:46][root][INFO] - Training Epoch: 1/2, step 1355/54251 completed (loss: 0.037126991897821426, acc: 1.0)
[2024-11-03 04:36:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:47][root][INFO] - Training Epoch: 1/2, step 1356/54251 completed (loss: 0.7681180834770203, acc: 0.9047619104385376)
[2024-11-03 04:36:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:47][root][INFO] - Training Epoch: 1/2, step 1357/54251 completed (loss: 1.227637767791748, acc: 0.7727272510528564)
[2024-11-03 04:36:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:48][root][INFO] - Training Epoch: 1/2, step 1358/54251 completed (loss: 1.645521879196167, acc: 0.6111111044883728)
[2024-11-03 04:36:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:48][root][INFO] - Training Epoch: 1/2, step 1359/54251 completed (loss: 1.1827186346054077, acc: 0.7916666865348816)
[2024-11-03 04:36:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:49][root][INFO] - Training Epoch: 1/2, step 1360/54251 completed (loss: 0.5937069058418274, acc: 0.9166666865348816)
[2024-11-03 04:36:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:49][root][INFO] - Training Epoch: 1/2, step 1361/54251 completed (loss: 1.1746152639389038, acc: 0.7777777910232544)
[2024-11-03 04:36:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:50][root][INFO] - Training Epoch: 1/2, step 1362/54251 completed (loss: 0.6748173832893372, acc: 0.8644067645072937)
[2024-11-03 04:36:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:50][root][INFO] - Training Epoch: 1/2, step 1363/54251 completed (loss: 2.2872116565704346, acc: 0.5)
[2024-11-03 04:36:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:51][root][INFO] - Training Epoch: 1/2, step 1364/54251 completed (loss: 0.6676105260848999, acc: 0.8695651888847351)
[2024-11-03 04:36:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:51][root][INFO] - Training Epoch: 1/2, step 1365/54251 completed (loss: 0.1336708515882492, acc: 1.0)
[2024-11-03 04:36:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:52][root][INFO] - Training Epoch: 1/2, step 1366/54251 completed (loss: 0.29953303933143616, acc: 0.9629629850387573)
[2024-11-03 04:36:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:52][root][INFO] - Training Epoch: 1/2, step 1367/54251 completed (loss: 1.8217922449111938, acc: 0.6428571343421936)
[2024-11-03 04:36:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:53][root][INFO] - Training Epoch: 1/2, step 1368/54251 completed (loss: 2.8964757919311523, acc: 0.47058823704719543)
[2024-11-03 04:36:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:53][root][INFO] - Training Epoch: 1/2, step 1369/54251 completed (loss: 2.25944447517395, acc: 0.625)
[2024-11-03 04:36:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:53][root][INFO] - Training Epoch: 1/2, step 1370/54251 completed (loss: 0.2393120378255844, acc: 0.9512194991111755)
[2024-11-03 04:36:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:54][root][INFO] - Training Epoch: 1/2, step 1371/54251 completed (loss: 2.694305419921875, acc: 0.4482758641242981)
[2024-11-03 04:36:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:54][root][INFO] - Training Epoch: 1/2, step 1372/54251 completed (loss: 0.9081064462661743, acc: 0.7419354915618896)
[2024-11-03 04:36:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:55][root][INFO] - Training Epoch: 1/2, step 1373/54251 completed (loss: 1.5284149646759033, acc: 0.6153846383094788)
[2024-11-03 04:36:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:56][root][INFO] - Training Epoch: 1/2, step 1374/54251 completed (loss: 0.8681932091712952, acc: 0.7333333492279053)
[2024-11-03 04:36:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:56][root][INFO] - Training Epoch: 1/2, step 1375/54251 completed (loss: 1.172817587852478, acc: 0.8636363744735718)
[2024-11-03 04:36:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:56][root][INFO] - Training Epoch: 1/2, step 1376/54251 completed (loss: 1.6529706716537476, acc: 0.7142857313156128)
[2024-11-03 04:36:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:57][root][INFO] - Training Epoch: 1/2, step 1377/54251 completed (loss: 3.0402934551239014, acc: 0.4054054021835327)
[2024-11-03 04:36:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:57][root][INFO] - Training Epoch: 1/2, step 1378/54251 completed (loss: 1.6271119117736816, acc: 0.6666666865348816)
[2024-11-03 04:36:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:58][root][INFO] - Training Epoch: 1/2, step 1379/54251 completed (loss: 2.7172605991363525, acc: 0.5185185074806213)
[2024-11-03 04:36:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:59][root][INFO] - Training Epoch: 1/2, step 1380/54251 completed (loss: 1.2949458360671997, acc: 0.6944444179534912)
[2024-11-03 04:36:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:36:59][root][INFO] - Training Epoch: 1/2, step 1381/54251 completed (loss: 0.6022481322288513, acc: 0.7857142686843872)
[2024-11-03 04:36:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:00][root][INFO] - Training Epoch: 1/2, step 1382/54251 completed (loss: 1.1052404642105103, acc: 0.7222222089767456)
[2024-11-03 04:37:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:00][root][INFO] - Training Epoch: 1/2, step 1383/54251 completed (loss: 0.8423654437065125, acc: 0.75)
[2024-11-03 04:37:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:01][root][INFO] - Training Epoch: 1/2, step 1384/54251 completed (loss: 0.8364837169647217, acc: 0.8409090638160706)
[2024-11-03 04:37:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:01][root][INFO] - Training Epoch: 1/2, step 1385/54251 completed (loss: 1.6587975025177002, acc: 0.6000000238418579)
[2024-11-03 04:37:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:02][root][INFO] - Training Epoch: 1/2, step 1386/54251 completed (loss: 1.3741703033447266, acc: 0.6363636255264282)
[2024-11-03 04:37:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:02][root][INFO] - Training Epoch: 1/2, step 1387/54251 completed (loss: 0.266633540391922, acc: 0.9375)
[2024-11-03 04:37:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:03][root][INFO] - Training Epoch: 1/2, step 1388/54251 completed (loss: 1.7177883386611938, acc: 0.7777777910232544)
[2024-11-03 04:37:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:03][root][INFO] - Training Epoch: 1/2, step 1389/54251 completed (loss: 1.277532696723938, acc: 0.75)
[2024-11-03 04:37:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:04][root][INFO] - Training Epoch: 1/2, step 1390/54251 completed (loss: 0.9309480786323547, acc: 0.8571428656578064)
[2024-11-03 04:37:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:04][root][INFO] - Training Epoch: 1/2, step 1391/54251 completed (loss: 0.0329836942255497, acc: 1.0)
[2024-11-03 04:37:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:05][root][INFO] - Training Epoch: 1/2, step 1392/54251 completed (loss: 0.6259608864784241, acc: 0.8846153616905212)
[2024-11-03 04:37:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:05][root][INFO] - Training Epoch: 1/2, step 1393/54251 completed (loss: 0.5171860456466675, acc: 0.875)
[2024-11-03 04:37:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:06][root][INFO] - Training Epoch: 1/2, step 1394/54251 completed (loss: 1.905828595161438, acc: 0.5714285969734192)
[2024-11-03 04:37:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:06][root][INFO] - Training Epoch: 1/2, step 1395/54251 completed (loss: 0.57798832654953, acc: 0.824999988079071)
[2024-11-03 04:37:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:07][root][INFO] - Training Epoch: 1/2, step 1396/54251 completed (loss: 0.5534002780914307, acc: 0.9090909361839294)
[2024-11-03 04:37:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:07][root][INFO] - Training Epoch: 1/2, step 1397/54251 completed (loss: 1.1493351459503174, acc: 0.6666666865348816)
[2024-11-03 04:37:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:08][root][INFO] - Training Epoch: 1/2, step 1398/54251 completed (loss: 2.4681382179260254, acc: 0.517241358757019)
[2024-11-03 04:37:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:08][root][INFO] - Training Epoch: 1/2, step 1399/54251 completed (loss: 2.6019768714904785, acc: 0.5)
[2024-11-03 04:37:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:09][root][INFO] - Training Epoch: 1/2, step 1400/54251 completed (loss: 0.5933310389518738, acc: 0.875)
[2024-11-03 04:37:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:09][root][INFO] - Training Epoch: 1/2, step 1401/54251 completed (loss: 0.5134822726249695, acc: 0.8947368264198303)
[2024-11-03 04:37:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:10][root][INFO] - Training Epoch: 1/2, step 1402/54251 completed (loss: 1.867913007736206, acc: 0.6470588445663452)
[2024-11-03 04:37:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:10][root][INFO] - Training Epoch: 1/2, step 1403/54251 completed (loss: 0.5932116508483887, acc: 0.8684210777282715)
[2024-11-03 04:37:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:11][root][INFO] - Training Epoch: 1/2, step 1404/54251 completed (loss: 1.2620950937271118, acc: 0.75)
[2024-11-03 04:37:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:11][root][INFO] - Training Epoch: 1/2, step 1405/54251 completed (loss: 2.164947032928467, acc: 0.4444444477558136)
[2024-11-03 04:37:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:12][root][INFO] - Training Epoch: 1/2, step 1406/54251 completed (loss: 0.9323540925979614, acc: 0.7777777910232544)
[2024-11-03 04:37:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:12][root][INFO] - Training Epoch: 1/2, step 1407/54251 completed (loss: 1.3577390909194946, acc: 0.6800000071525574)
[2024-11-03 04:37:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:13][root][INFO] - Training Epoch: 1/2, step 1408/54251 completed (loss: 1.1394809484481812, acc: 0.8333333134651184)
[2024-11-03 04:37:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:13][root][INFO] - Training Epoch: 1/2, step 1409/54251 completed (loss: 1.2698864936828613, acc: 0.7241379022598267)
[2024-11-03 04:37:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:14][root][INFO] - Training Epoch: 1/2, step 1410/54251 completed (loss: 1.7173678874969482, acc: 0.692307710647583)
[2024-11-03 04:37:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:14][root][INFO] - Training Epoch: 1/2, step 1411/54251 completed (loss: 1.0001749992370605, acc: 0.8484848737716675)
[2024-11-03 04:37:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:15][root][INFO] - Training Epoch: 1/2, step 1412/54251 completed (loss: 2.5278100967407227, acc: 0.5116279125213623)
[2024-11-03 04:37:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:15][root][INFO] - Training Epoch: 1/2, step 1413/54251 completed (loss: 1.688614010810852, acc: 0.6607142686843872)
[2024-11-03 04:37:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:16][root][INFO] - Training Epoch: 1/2, step 1414/54251 completed (loss: 0.6151629686355591, acc: 0.8636363744735718)
[2024-11-03 04:37:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:16][root][INFO] - Training Epoch: 1/2, step 1415/54251 completed (loss: 0.26820969581604004, acc: 1.0)
[2024-11-03 04:37:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:17][root][INFO] - Training Epoch: 1/2, step 1416/54251 completed (loss: 1.2214710712432861, acc: 0.75)
[2024-11-03 04:37:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:17][root][INFO] - Training Epoch: 1/2, step 1417/54251 completed (loss: 1.9729914665222168, acc: 0.6875)
[2024-11-03 04:37:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:18][root][INFO] - Training Epoch: 1/2, step 1418/54251 completed (loss: 0.9342546463012695, acc: 0.8095238208770752)
[2024-11-03 04:37:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:18][root][INFO] - Training Epoch: 1/2, step 1419/54251 completed (loss: 1.8298077583312988, acc: 0.5)
[2024-11-03 04:37:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:19][root][INFO] - Training Epoch: 1/2, step 1420/54251 completed (loss: 1.5086060762405396, acc: 0.6808510422706604)
[2024-11-03 04:37:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:19][root][INFO] - Training Epoch: 1/2, step 1421/54251 completed (loss: 1.7097247838974, acc: 0.5)
[2024-11-03 04:37:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:19][root][INFO] - Training Epoch: 1/2, step 1422/54251 completed (loss: 2.438166618347168, acc: 0.5199999809265137)
[2024-11-03 04:37:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:20][root][INFO] - Training Epoch: 1/2, step 1423/54251 completed (loss: 0.5222674608230591, acc: 0.8666666746139526)
[2024-11-03 04:37:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:20][root][INFO] - Training Epoch: 1/2, step 1424/54251 completed (loss: 0.8898581266403198, acc: 0.7307692170143127)
[2024-11-03 04:37:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:21][root][INFO] - Training Epoch: 1/2, step 1425/54251 completed (loss: 0.38371533155441284, acc: 0.8999999761581421)
[2024-11-03 04:37:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:21][root][INFO] - Training Epoch: 1/2, step 1426/54251 completed (loss: 0.28012168407440186, acc: 1.0)
[2024-11-03 04:37:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:22][root][INFO] - Training Epoch: 1/2, step 1427/54251 completed (loss: 0.4638480246067047, acc: 0.9354838728904724)
[2024-11-03 04:37:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:22][root][INFO] - Training Epoch: 1/2, step 1428/54251 completed (loss: 3.0383265018463135, acc: 0.5909090638160706)
[2024-11-03 04:37:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:23][root][INFO] - Training Epoch: 1/2, step 1429/54251 completed (loss: 2.2295756340026855, acc: 0.5555555820465088)
[2024-11-03 04:37:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:23][root][INFO] - Training Epoch: 1/2, step 1430/54251 completed (loss: 2.773043632507324, acc: 0.3181818127632141)
[2024-11-03 04:37:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:24][root][INFO] - Training Epoch: 1/2, step 1431/54251 completed (loss: 1.5183185338974, acc: 0.6875)
[2024-11-03 04:37:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:24][root][INFO] - Training Epoch: 1/2, step 1432/54251 completed (loss: 1.2647231817245483, acc: 0.75)
[2024-11-03 04:37:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:25][root][INFO] - Training Epoch: 1/2, step 1433/54251 completed (loss: 1.0175522565841675, acc: 0.8500000238418579)
[2024-11-03 04:37:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:25][root][INFO] - Training Epoch: 1/2, step 1434/54251 completed (loss: 0.6926071047782898, acc: 0.8444444537162781)
[2024-11-03 04:37:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:26][root][INFO] - Training Epoch: 1/2, step 1435/54251 completed (loss: 0.9794787168502808, acc: 0.7209302186965942)
[2024-11-03 04:37:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:26][root][INFO] - Training Epoch: 1/2, step 1436/54251 completed (loss: 0.12635985016822815, acc: 1.0)
[2024-11-03 04:37:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:27][root][INFO] - Training Epoch: 1/2, step 1437/54251 completed (loss: 0.7669351100921631, acc: 0.8125)
[2024-11-03 04:37:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:27][root][INFO] - Training Epoch: 1/2, step 1438/54251 completed (loss: 1.999758005142212, acc: 0.4000000059604645)
[2024-11-03 04:37:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:28][root][INFO] - Training Epoch: 1/2, step 1439/54251 completed (loss: 0.14961740374565125, acc: 0.9615384340286255)
[2024-11-03 04:37:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:28][root][INFO] - Training Epoch: 1/2, step 1440/54251 completed (loss: 1.946699857711792, acc: 0.625)
[2024-11-03 04:37:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:29][root][INFO] - Training Epoch: 1/2, step 1441/54251 completed (loss: 0.4288577437400818, acc: 0.8709677457809448)
[2024-11-03 04:37:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:29][root][INFO] - Training Epoch: 1/2, step 1442/54251 completed (loss: 1.4998208284378052, acc: 0.6470588445663452)
[2024-11-03 04:37:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:30][root][INFO] - Training Epoch: 1/2, step 1443/54251 completed (loss: 2.928619623184204, acc: 0.5)
[2024-11-03 04:37:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:30][root][INFO] - Training Epoch: 1/2, step 1444/54251 completed (loss: 1.1990857124328613, acc: 0.7692307829856873)
[2024-11-03 04:37:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:31][root][INFO] - Training Epoch: 1/2, step 1445/54251 completed (loss: 2.2281293869018555, acc: 0.5)
[2024-11-03 04:37:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:31][root][INFO] - Training Epoch: 1/2, step 1446/54251 completed (loss: 0.5410929918289185, acc: 0.8947368264198303)
[2024-11-03 04:37:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:32][root][INFO] - Training Epoch: 1/2, step 1447/54251 completed (loss: 0.5945510864257812, acc: 0.8529411554336548)
[2024-11-03 04:37:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:32][root][INFO] - Training Epoch: 1/2, step 1448/54251 completed (loss: 1.3174642324447632, acc: 0.7169811129570007)
[2024-11-03 04:37:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:33][root][INFO] - Training Epoch: 1/2, step 1449/54251 completed (loss: 3.2862324714660645, acc: 0.6000000238418579)
[2024-11-03 04:37:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:33][root][INFO] - Training Epoch: 1/2, step 1450/54251 completed (loss: 0.4911203384399414, acc: 0.9333333373069763)
[2024-11-03 04:37:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:34][root][INFO] - Training Epoch: 1/2, step 1451/54251 completed (loss: 1.899627923965454, acc: 0.5789473652839661)
[2024-11-03 04:37:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:34][root][INFO] - Training Epoch: 1/2, step 1452/54251 completed (loss: 0.6077461242675781, acc: 0.7272727489471436)
[2024-11-03 04:37:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:35][root][INFO] - Training Epoch: 1/2, step 1453/54251 completed (loss: 0.953613817691803, acc: 0.75)
[2024-11-03 04:37:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:35][root][INFO] - Training Epoch: 1/2, step 1454/54251 completed (loss: 1.2093056440353394, acc: 0.761904776096344)
[2024-11-03 04:37:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:36][root][INFO] - Training Epoch: 1/2, step 1455/54251 completed (loss: 0.34933969378471375, acc: 0.8333333134651184)
[2024-11-03 04:37:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:36][root][INFO] - Training Epoch: 1/2, step 1456/54251 completed (loss: 2.9970693588256836, acc: 0.3461538553237915)
[2024-11-03 04:37:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:37][root][INFO] - Training Epoch: 1/2, step 1457/54251 completed (loss: 0.044136419892311096, acc: 1.0)
[2024-11-03 04:37:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:37][root][INFO] - Training Epoch: 1/2, step 1458/54251 completed (loss: 0.19199472665786743, acc: 1.0)
[2024-11-03 04:37:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:38][root][INFO] - Training Epoch: 1/2, step 1459/54251 completed (loss: 1.2274925708770752, acc: 0.625)
[2024-11-03 04:37:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:38][root][INFO] - Training Epoch: 1/2, step 1460/54251 completed (loss: 0.5176652669906616, acc: 0.8571428656578064)
[2024-11-03 04:37:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:39][root][INFO] - Training Epoch: 1/2, step 1461/54251 completed (loss: 0.7760183811187744, acc: 0.8695651888847351)
[2024-11-03 04:37:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:39][root][INFO] - Training Epoch: 1/2, step 1462/54251 completed (loss: 0.5654917359352112, acc: 0.9047619104385376)
[2024-11-03 04:37:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:40][root][INFO] - Training Epoch: 1/2, step 1463/54251 completed (loss: 2.106837511062622, acc: 0.5)
[2024-11-03 04:37:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:40][root][INFO] - Training Epoch: 1/2, step 1464/54251 completed (loss: 1.2114416360855103, acc: 0.7567567825317383)
[2024-11-03 04:37:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:41][root][INFO] - Training Epoch: 1/2, step 1465/54251 completed (loss: 2.4931952953338623, acc: 0.5333333611488342)
[2024-11-03 04:37:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:41][root][INFO] - Training Epoch: 1/2, step 1466/54251 completed (loss: 3.4926819801330566, acc: 0.5555555820465088)
[2024-11-03 04:37:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:42][root][INFO] - Training Epoch: 1/2, step 1467/54251 completed (loss: 1.1453166007995605, acc: 0.75)
[2024-11-03 04:37:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:42][root][INFO] - Training Epoch: 1/2, step 1468/54251 completed (loss: 0.22371307015419006, acc: 0.9333333373069763)
[2024-11-03 04:37:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:43][root][INFO] - Training Epoch: 1/2, step 1469/54251 completed (loss: 1.8883285522460938, acc: 0.6060606241226196)
[2024-11-03 04:37:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:43][root][INFO] - Training Epoch: 1/2, step 1470/54251 completed (loss: 0.9310638904571533, acc: 0.8055555820465088)
[2024-11-03 04:37:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:44][root][INFO] - Training Epoch: 1/2, step 1471/54251 completed (loss: 0.2284258008003235, acc: 1.0)
[2024-11-03 04:37:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:44][root][INFO] - Training Epoch: 1/2, step 1472/54251 completed (loss: 0.8712708353996277, acc: 0.779411792755127)
[2024-11-03 04:37:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:45][root][INFO] - Training Epoch: 1/2, step 1473/54251 completed (loss: 0.6395216584205627, acc: 0.8275862336158752)
[2024-11-03 04:37:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:45][root][INFO] - Training Epoch: 1/2, step 1474/54251 completed (loss: 1.7111221551895142, acc: 0.7435897588729858)
[2024-11-03 04:37:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:46][root][INFO] - Training Epoch: 1/2, step 1475/54251 completed (loss: 2.732534170150757, acc: 0.3636363744735718)
[2024-11-03 04:37:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:46][root][INFO] - Training Epoch: 1/2, step 1476/54251 completed (loss: 1.0172576904296875, acc: 0.7777777910232544)
[2024-11-03 04:37:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:47][root][INFO] - Training Epoch: 1/2, step 1477/54251 completed (loss: 1.0460138320922852, acc: 0.774193525314331)
[2024-11-03 04:37:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:47][root][INFO] - Training Epoch: 1/2, step 1478/54251 completed (loss: 3.3730928897857666, acc: 0.375)
[2024-11-03 04:37:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:48][root][INFO] - Training Epoch: 1/2, step 1479/54251 completed (loss: 0.880379855632782, acc: 0.8500000238418579)
[2024-11-03 04:37:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:48][root][INFO] - Training Epoch: 1/2, step 1480/54251 completed (loss: 1.844123125076294, acc: 0.3499999940395355)
[2024-11-03 04:37:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:49][root][INFO] - Training Epoch: 1/2, step 1481/54251 completed (loss: 0.8389444351196289, acc: 0.800000011920929)
[2024-11-03 04:37:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:49][root][INFO] - Training Epoch: 1/2, step 1482/54251 completed (loss: 0.3081093430519104, acc: 0.9714285731315613)
[2024-11-03 04:37:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:50][root][INFO] - Training Epoch: 1/2, step 1483/54251 completed (loss: 0.9997202754020691, acc: 0.800000011920929)
[2024-11-03 04:37:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:50][root][INFO] - Training Epoch: 1/2, step 1484/54251 completed (loss: 0.27781757712364197, acc: 0.8888888955116272)
[2024-11-03 04:37:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:51][root][INFO] - Training Epoch: 1/2, step 1485/54251 completed (loss: 2.4963464736938477, acc: 0.4137931168079376)
[2024-11-03 04:37:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:51][root][INFO] - Training Epoch: 1/2, step 1486/54251 completed (loss: 1.109489917755127, acc: 0.6666666865348816)
[2024-11-03 04:37:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:52][root][INFO] - Training Epoch: 1/2, step 1487/54251 completed (loss: 0.14444908499717712, acc: 1.0)
[2024-11-03 04:37:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:52][root][INFO] - Training Epoch: 1/2, step 1488/54251 completed (loss: 0.37045857310295105, acc: 0.9259259104728699)
[2024-11-03 04:37:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:52][root][INFO] - Training Epoch: 1/2, step 1489/54251 completed (loss: 1.4110676050186157, acc: 0.7317073345184326)
[2024-11-03 04:37:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:53][root][INFO] - Training Epoch: 1/2, step 1490/54251 completed (loss: 1.2728737592697144, acc: 0.7407407164573669)
[2024-11-03 04:37:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:53][root][INFO] - Training Epoch: 1/2, step 1491/54251 completed (loss: 1.7361812591552734, acc: 0.5555555820465088)
[2024-11-03 04:37:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:54][root][INFO] - Training Epoch: 1/2, step 1492/54251 completed (loss: 1.8903110027313232, acc: 0.6875)
[2024-11-03 04:37:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:54][root][INFO] - Training Epoch: 1/2, step 1493/54251 completed (loss: 2.2461955547332764, acc: 0.4545454680919647)
[2024-11-03 04:37:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:55][root][INFO] - Training Epoch: 1/2, step 1494/54251 completed (loss: 3.0209999084472656, acc: 0.29411765933036804)
[2024-11-03 04:37:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:55][root][INFO] - Training Epoch: 1/2, step 1495/54251 completed (loss: 3.375300407409668, acc: 0.3199999928474426)
[2024-11-03 04:37:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:56][root][INFO] - Training Epoch: 1/2, step 1496/54251 completed (loss: 1.1146576404571533, acc: 0.6000000238418579)
[2024-11-03 04:37:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:56][root][INFO] - Training Epoch: 1/2, step 1497/54251 completed (loss: 0.4027565121650696, acc: 0.8571428656578064)
[2024-11-03 04:37:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:57][root][INFO] - Training Epoch: 1/2, step 1498/54251 completed (loss: 1.060333013534546, acc: 0.800000011920929)
[2024-11-03 04:37:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:57][root][INFO] - Training Epoch: 1/2, step 1499/54251 completed (loss: 1.586167812347412, acc: 0.6666666865348816)
[2024-11-03 04:37:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:58][root][INFO] - Training Epoch: 1/2, step 1500/54251 completed (loss: 0.728341817855835, acc: 0.8983050584793091)
[2024-11-03 04:37:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:58][root][INFO] - Training Epoch: 1/2, step 1501/54251 completed (loss: 0.5776606798171997, acc: 0.8275862336158752)
[2024-11-03 04:37:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:59][root][INFO] - Training Epoch: 1/2, step 1502/54251 completed (loss: 1.5669491291046143, acc: 0.6511628031730652)
[2024-11-03 04:37:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:37:59][root][INFO] - Training Epoch: 1/2, step 1503/54251 completed (loss: 1.7963078022003174, acc: 0.625)
[2024-11-03 04:38:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:00][root][INFO] - Training Epoch: 1/2, step 1504/54251 completed (loss: 0.8409956693649292, acc: 0.6000000238418579)
[2024-11-03 04:38:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:00][root][INFO] - Training Epoch: 1/2, step 1505/54251 completed (loss: 2.3969671726226807, acc: 0.4545454680919647)
[2024-11-03 04:38:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:01][root][INFO] - Training Epoch: 1/2, step 1506/54251 completed (loss: 0.6631067395210266, acc: 0.8780487775802612)
[2024-11-03 04:38:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:01][root][INFO] - Training Epoch: 1/2, step 1507/54251 completed (loss: 0.6902281641960144, acc: 0.8787878751754761)
[2024-11-03 04:38:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:02][root][INFO] - Training Epoch: 1/2, step 1508/54251 completed (loss: 1.4373329877853394, acc: 0.6904761791229248)
[2024-11-03 04:38:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:02][root][INFO] - Training Epoch: 1/2, step 1509/54251 completed (loss: 1.2569574117660522, acc: 0.7659574747085571)
[2024-11-03 04:38:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:03][root][INFO] - Training Epoch: 1/2, step 1510/54251 completed (loss: 1.0550321340560913, acc: 0.5)
[2024-11-03 04:38:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:03][root][INFO] - Training Epoch: 1/2, step 1511/54251 completed (loss: 1.7163649797439575, acc: 0.6470588445663452)
[2024-11-03 04:38:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:04][root][INFO] - Training Epoch: 1/2, step 1512/54251 completed (loss: 0.9164161086082458, acc: 0.8181818127632141)
[2024-11-03 04:38:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:04][root][INFO] - Training Epoch: 1/2, step 1513/54251 completed (loss: 0.37722834944725037, acc: 0.9032257795333862)
[2024-11-03 04:38:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:05][root][INFO] - Training Epoch: 1/2, step 1514/54251 completed (loss: 0.49717649817466736, acc: 0.8333333134651184)
[2024-11-03 04:38:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:06][root][INFO] - Training Epoch: 1/2, step 1515/54251 completed (loss: 0.9482101798057556, acc: 0.7142857313156128)
[2024-11-03 04:38:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:06][root][INFO] - Training Epoch: 1/2, step 1516/54251 completed (loss: 1.057527780532837, acc: 0.7916666865348816)
[2024-11-03 04:38:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:07][root][INFO] - Training Epoch: 1/2, step 1517/54251 completed (loss: 1.6021151542663574, acc: 0.7631579041481018)
[2024-11-03 04:38:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:07][root][INFO] - Training Epoch: 1/2, step 1518/54251 completed (loss: 1.288317084312439, acc: 0.7580645084381104)
[2024-11-03 04:38:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:08][root][INFO] - Training Epoch: 1/2, step 1519/54251 completed (loss: 0.9141576886177063, acc: 0.7916666865348816)
[2024-11-03 04:38:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:08][root][INFO] - Training Epoch: 1/2, step 1520/54251 completed (loss: 1.0032367706298828, acc: 0.75)
[2024-11-03 04:38:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:09][root][INFO] - Training Epoch: 1/2, step 1521/54251 completed (loss: 0.08508990705013275, acc: 1.0)
[2024-11-03 04:38:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:09][root][INFO] - Training Epoch: 1/2, step 1522/54251 completed (loss: 1.4078545570373535, acc: 0.6666666865348816)
[2024-11-03 04:38:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:10][root][INFO] - Training Epoch: 1/2, step 1523/54251 completed (loss: 2.8471996784210205, acc: 0.38235294818878174)
[2024-11-03 04:38:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:10][root][INFO] - Training Epoch: 1/2, step 1524/54251 completed (loss: 1.866028070449829, acc: 0.5263158082962036)
[2024-11-03 04:38:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:11][root][INFO] - Training Epoch: 1/2, step 1525/54251 completed (loss: 0.9230408072471619, acc: 0.7692307829856873)
[2024-11-03 04:38:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:11][root][INFO] - Training Epoch: 1/2, step 1526/54251 completed (loss: 1.071091890335083, acc: 0.8181818127632141)
[2024-11-03 04:38:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:11][root][INFO] - Training Epoch: 1/2, step 1527/54251 completed (loss: 1.8165334463119507, acc: 0.625)
[2024-11-03 04:38:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:12][root][INFO] - Training Epoch: 1/2, step 1528/54251 completed (loss: 0.19702935218811035, acc: 0.9428571462631226)
[2024-11-03 04:38:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:12][root][INFO] - Training Epoch: 1/2, step 1529/54251 completed (loss: 1.878252387046814, acc: 0.625)
[2024-11-03 04:38:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:13][root][INFO] - Training Epoch: 1/2, step 1530/54251 completed (loss: 1.3381329774856567, acc: 0.6428571343421936)
[2024-11-03 04:38:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:13][root][INFO] - Training Epoch: 1/2, step 1531/54251 completed (loss: 3.567567825317383, acc: 0.37037035822868347)
[2024-11-03 04:38:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:14][root][INFO] - Training Epoch: 1/2, step 1532/54251 completed (loss: 0.3535849153995514, acc: 0.8999999761581421)
[2024-11-03 04:38:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:14][root][INFO] - Training Epoch: 1/2, step 1533/54251 completed (loss: 1.979475975036621, acc: 0.4000000059604645)
[2024-11-03 04:38:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:15][root][INFO] - Training Epoch: 1/2, step 1534/54251 completed (loss: 1.2211788892745972, acc: 0.6857143044471741)
[2024-11-03 04:38:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:15][root][INFO] - Training Epoch: 1/2, step 1535/54251 completed (loss: 0.7775131464004517, acc: 0.8823529481887817)
[2024-11-03 04:38:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:16][root][INFO] - Training Epoch: 1/2, step 1536/54251 completed (loss: 0.43024829030036926, acc: 0.8181818127632141)
[2024-11-03 04:38:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:16][root][INFO] - Training Epoch: 1/2, step 1537/54251 completed (loss: 0.9533353447914124, acc: 0.7647058963775635)
[2024-11-03 04:38:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:17][root][INFO] - Training Epoch: 1/2, step 1538/54251 completed (loss: 0.5688745975494385, acc: 0.875)
[2024-11-03 04:38:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:17][root][INFO] - Training Epoch: 1/2, step 1539/54251 completed (loss: 0.6481825709342957, acc: 0.9259259104728699)
[2024-11-03 04:38:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:18][root][INFO] - Training Epoch: 1/2, step 1540/54251 completed (loss: 1.2387486696243286, acc: 0.7200000286102295)
[2024-11-03 04:38:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:18][root][INFO] - Training Epoch: 1/2, step 1541/54251 completed (loss: 1.3371890783309937, acc: 0.7096773982048035)
[2024-11-03 04:38:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:19][root][INFO] - Training Epoch: 1/2, step 1542/54251 completed (loss: 0.5834489464759827, acc: 0.8461538553237915)
[2024-11-03 04:38:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:19][root][INFO] - Training Epoch: 1/2, step 1543/54251 completed (loss: 1.0921119451522827, acc: 0.6842105388641357)
[2024-11-03 04:38:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:20][root][INFO] - Training Epoch: 1/2, step 1544/54251 completed (loss: 0.529438853263855, acc: 0.8500000238418579)
[2024-11-03 04:38:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:20][root][INFO] - Training Epoch: 1/2, step 1545/54251 completed (loss: 1.5084280967712402, acc: 0.6666666865348816)
[2024-11-03 04:38:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:21][root][INFO] - Training Epoch: 1/2, step 1546/54251 completed (loss: 0.5750085115432739, acc: 0.9259259104728699)
[2024-11-03 04:38:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:21][root][INFO] - Training Epoch: 1/2, step 1547/54251 completed (loss: 2.2122247219085693, acc: 0.6666666865348816)
[2024-11-03 04:38:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:22][root][INFO] - Training Epoch: 1/2, step 1548/54251 completed (loss: 1.2054647207260132, acc: 0.7083333134651184)
[2024-11-03 04:38:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:22][root][INFO] - Training Epoch: 1/2, step 1549/54251 completed (loss: 0.682263970375061, acc: 0.8888888955116272)
[2024-11-03 04:38:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:23][root][INFO] - Training Epoch: 1/2, step 1550/54251 completed (loss: 0.5284715890884399, acc: 0.8965517282485962)
[2024-11-03 04:38:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:23][root][INFO] - Training Epoch: 1/2, step 1551/54251 completed (loss: 0.6621665358543396, acc: 0.9090909361839294)
[2024-11-03 04:38:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:24][root][INFO] - Training Epoch: 1/2, step 1552/54251 completed (loss: 1.0137616395950317, acc: 0.75)
[2024-11-03 04:38:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:24][root][INFO] - Training Epoch: 1/2, step 1553/54251 completed (loss: 0.8603391647338867, acc: 0.7857142686843872)
[2024-11-03 04:38:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:25][root][INFO] - Training Epoch: 1/2, step 1554/54251 completed (loss: 0.7692282795906067, acc: 0.8846153616905212)
[2024-11-03 04:38:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:25][root][INFO] - Training Epoch: 1/2, step 1555/54251 completed (loss: 0.7727177739143372, acc: 0.8333333134651184)
[2024-11-03 04:38:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:26][root][INFO] - Training Epoch: 1/2, step 1556/54251 completed (loss: 0.9952632784843445, acc: 0.8064516186714172)
[2024-11-03 04:38:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:26][root][INFO] - Training Epoch: 1/2, step 1557/54251 completed (loss: 1.006178379058838, acc: 0.7567567825317383)
[2024-11-03 04:38:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:27][root][INFO] - Training Epoch: 1/2, step 1558/54251 completed (loss: 0.8995383381843567, acc: 0.9047619104385376)
[2024-11-03 04:38:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:27][root][INFO] - Training Epoch: 1/2, step 1559/54251 completed (loss: 0.8236134052276611, acc: 0.8409090638160706)
[2024-11-03 04:38:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:28][root][INFO] - Training Epoch: 1/2, step 1560/54251 completed (loss: 0.4538915455341339, acc: 0.8333333134651184)
[2024-11-03 04:38:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:28][root][INFO] - Training Epoch: 1/2, step 1561/54251 completed (loss: 1.0359060764312744, acc: 0.7058823704719543)
[2024-11-03 04:38:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:29][root][INFO] - Training Epoch: 1/2, step 1562/54251 completed (loss: 1.5461620092391968, acc: 0.625)
[2024-11-03 04:38:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:29][root][INFO] - Training Epoch: 1/2, step 1563/54251 completed (loss: 1.0481489896774292, acc: 0.75)
[2024-11-03 04:38:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:30][root][INFO] - Training Epoch: 1/2, step 1564/54251 completed (loss: 3.1913490295410156, acc: 0.4545454680919647)
[2024-11-03 04:38:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:30][root][INFO] - Training Epoch: 1/2, step 1565/54251 completed (loss: 2.63287353515625, acc: 0.4375)
[2024-11-03 04:38:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:31][root][INFO] - Training Epoch: 1/2, step 1566/54251 completed (loss: 2.3469793796539307, acc: 0.5833333134651184)
[2024-11-03 04:38:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:31][root][INFO] - Training Epoch: 1/2, step 1567/54251 completed (loss: 1.8495827913284302, acc: 0.6739130616188049)
[2024-11-03 04:38:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:32][root][INFO] - Training Epoch: 1/2, step 1568/54251 completed (loss: 1.438062310218811, acc: 0.7058823704719543)
[2024-11-03 04:38:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:32][root][INFO] - Training Epoch: 1/2, step 1569/54251 completed (loss: 0.6540239453315735, acc: 0.7272727489471436)
[2024-11-03 04:38:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:33][root][INFO] - Training Epoch: 1/2, step 1570/54251 completed (loss: 1.255234956741333, acc: 0.800000011920929)
[2024-11-03 04:38:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:33][root][INFO] - Training Epoch: 1/2, step 1571/54251 completed (loss: 0.25335338711738586, acc: 0.9545454382896423)
[2024-11-03 04:38:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:34][root][INFO] - Training Epoch: 1/2, step 1572/54251 completed (loss: 0.5726401805877686, acc: 0.8918918967247009)
[2024-11-03 04:38:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:34][root][INFO] - Training Epoch: 1/2, step 1573/54251 completed (loss: 2.277135133743286, acc: 0.6000000238418579)
[2024-11-03 04:38:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:35][root][INFO] - Training Epoch: 1/2, step 1574/54251 completed (loss: 2.4013640880584717, acc: 0.5600000023841858)
[2024-11-03 04:38:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:35][root][INFO] - Training Epoch: 1/2, step 1575/54251 completed (loss: 1.3246773481369019, acc: 0.7222222089767456)
[2024-11-03 04:38:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:36][root][INFO] - Training Epoch: 1/2, step 1576/54251 completed (loss: 0.5358749032020569, acc: 0.8571428656578064)
[2024-11-03 04:38:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:36][root][INFO] - Training Epoch: 1/2, step 1577/54251 completed (loss: 0.7806076407432556, acc: 0.8571428656578064)
[2024-11-03 04:38:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:37][root][INFO] - Training Epoch: 1/2, step 1578/54251 completed (loss: 1.4786875247955322, acc: 0.7352941036224365)
[2024-11-03 04:38:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:37][root][INFO] - Training Epoch: 1/2, step 1579/54251 completed (loss: 1.235973596572876, acc: 0.8571428656578064)
[2024-11-03 04:38:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:38][root][INFO] - Training Epoch: 1/2, step 1580/54251 completed (loss: 1.2854788303375244, acc: 0.7307692170143127)
[2024-11-03 04:38:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:38][root][INFO] - Training Epoch: 1/2, step 1581/54251 completed (loss: 0.7204297780990601, acc: 0.8823529481887817)
[2024-11-03 04:38:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:39][root][INFO] - Training Epoch: 1/2, step 1582/54251 completed (loss: 0.4918399751186371, acc: 0.8947368264198303)
[2024-11-03 04:38:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:39][root][INFO] - Training Epoch: 1/2, step 1583/54251 completed (loss: 0.8249069452285767, acc: 0.800000011920929)
[2024-11-03 04:38:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:40][root][INFO] - Training Epoch: 1/2, step 1584/54251 completed (loss: 1.409327745437622, acc: 0.7407407164573669)
[2024-11-03 04:38:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:40][root][INFO] - Training Epoch: 1/2, step 1585/54251 completed (loss: 1.3079975843429565, acc: 0.7428571581840515)
[2024-11-03 04:38:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:41][root][INFO] - Training Epoch: 1/2, step 1586/54251 completed (loss: 1.3929638862609863, acc: 0.6470588445663452)
[2024-11-03 04:38:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:41][root][INFO] - Training Epoch: 1/2, step 1587/54251 completed (loss: 1.164232611656189, acc: 0.75)
[2024-11-03 04:38:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:42][root][INFO] - Training Epoch: 1/2, step 1588/54251 completed (loss: 1.4550174474716187, acc: 0.6363636255264282)
[2024-11-03 04:38:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:42][root][INFO] - Training Epoch: 1/2, step 1589/54251 completed (loss: 1.165587067604065, acc: 0.6153846383094788)
[2024-11-03 04:38:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:43][root][INFO] - Training Epoch: 1/2, step 1590/54251 completed (loss: 1.50754714012146, acc: 0.6785714030265808)
[2024-11-03 04:38:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:43][root][INFO] - Training Epoch: 1/2, step 1591/54251 completed (loss: 0.5399013161659241, acc: 0.84375)
[2024-11-03 04:38:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:44][root][INFO] - Training Epoch: 1/2, step 1592/54251 completed (loss: 1.4099334478378296, acc: 0.7407407164573669)
[2024-11-03 04:38:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:44][root][INFO] - Training Epoch: 1/2, step 1593/54251 completed (loss: 1.6656591892242432, acc: 0.5714285969734192)
[2024-11-03 04:38:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:45][root][INFO] - Training Epoch: 1/2, step 1594/54251 completed (loss: 2.510577440261841, acc: 0.6000000238418579)
[2024-11-03 04:38:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:45][root][INFO] - Training Epoch: 1/2, step 1595/54251 completed (loss: 0.899739682674408, acc: 0.875)
[2024-11-03 04:38:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:46][root][INFO] - Training Epoch: 1/2, step 1596/54251 completed (loss: 0.8885497450828552, acc: 0.8125)
[2024-11-03 04:38:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:46][root][INFO] - Training Epoch: 1/2, step 1597/54251 completed (loss: 2.775758981704712, acc: 0.4615384638309479)
[2024-11-03 04:38:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:47][root][INFO] - Training Epoch: 1/2, step 1598/54251 completed (loss: 1.1023305654525757, acc: 0.7916666865348816)
[2024-11-03 04:38:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:47][root][INFO] - Training Epoch: 1/2, step 1599/54251 completed (loss: 0.2320050448179245, acc: 0.9411764740943909)
[2024-11-03 04:38:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:48][root][INFO] - Training Epoch: 1/2, step 1600/54251 completed (loss: 0.5929528474807739, acc: 0.8695651888847351)
[2024-11-03 04:38:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:48][root][INFO] - Training Epoch: 1/2, step 1601/54251 completed (loss: 0.7082163691520691, acc: 0.9090909361839294)
[2024-11-03 04:38:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:48][root][INFO] - Training Epoch: 1/2, step 1602/54251 completed (loss: 1.9738961458206177, acc: 0.6875)
[2024-11-03 04:38:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:49][root][INFO] - Training Epoch: 1/2, step 1603/54251 completed (loss: 1.0902540683746338, acc: 0.7916666865348816)
[2024-11-03 04:38:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:49][root][INFO] - Training Epoch: 1/2, step 1604/54251 completed (loss: 1.4687542915344238, acc: 0.7260273694992065)
[2024-11-03 04:38:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:50][root][INFO] - Training Epoch: 1/2, step 1605/54251 completed (loss: 0.9305709600448608, acc: 0.800000011920929)
[2024-11-03 04:38:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:50][root][INFO] - Training Epoch: 1/2, step 1606/54251 completed (loss: 1.7988231182098389, acc: 0.6000000238418579)
[2024-11-03 04:38:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:51][root][INFO] - Training Epoch: 1/2, step 1607/54251 completed (loss: 0.7678502202033997, acc: 0.75)
[2024-11-03 04:38:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:51][root][INFO] - Training Epoch: 1/2, step 1608/54251 completed (loss: 2.1422688961029053, acc: 0.6666666865348816)
[2024-11-03 04:38:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:52][root][INFO] - Training Epoch: 1/2, step 1609/54251 completed (loss: 1.091132640838623, acc: 0.6875)
[2024-11-03 04:38:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:52][root][INFO] - Training Epoch: 1/2, step 1610/54251 completed (loss: 1.3997588157653809, acc: 0.699999988079071)
[2024-11-03 04:38:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:53][root][INFO] - Training Epoch: 1/2, step 1611/54251 completed (loss: 1.2710516452789307, acc: 0.8181818127632141)
[2024-11-03 04:38:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:53][root][INFO] - Training Epoch: 1/2, step 1612/54251 completed (loss: 1.1288706064224243, acc: 0.7142857313156128)
[2024-11-03 04:38:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:54][root][INFO] - Training Epoch: 1/2, step 1613/54251 completed (loss: 0.6104768514633179, acc: 0.875)
[2024-11-03 04:38:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:55][root][INFO] - Training Epoch: 1/2, step 1614/54251 completed (loss: 2.701401472091675, acc: 0.3448275923728943)
[2024-11-03 04:38:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:55][root][INFO] - Training Epoch: 1/2, step 1615/54251 completed (loss: 3.2439448833465576, acc: 0.52173912525177)
[2024-11-03 04:38:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:56][root][INFO] - Training Epoch: 1/2, step 1616/54251 completed (loss: 1.0712764263153076, acc: 0.7692307829856873)
[2024-11-03 04:38:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:56][root][INFO] - Training Epoch: 1/2, step 1617/54251 completed (loss: 0.7270250916481018, acc: 0.7804877758026123)
[2024-11-03 04:38:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:57][root][INFO] - Training Epoch: 1/2, step 1618/54251 completed (loss: 0.8243356943130493, acc: 0.7368420958518982)
[2024-11-03 04:38:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:57][root][INFO] - Training Epoch: 1/2, step 1619/54251 completed (loss: 1.896904706954956, acc: 0.5714285969734192)
[2024-11-03 04:38:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:58][root][INFO] - Training Epoch: 1/2, step 1620/54251 completed (loss: 2.200230121612549, acc: 0.6000000238418579)
[2024-11-03 04:38:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:58][root][INFO] - Training Epoch: 1/2, step 1621/54251 completed (loss: 3.2410812377929688, acc: 0.30000001192092896)
[2024-11-03 04:38:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:59][root][INFO] - Training Epoch: 1/2, step 1622/54251 completed (loss: 1.2895337343215942, acc: 0.7222222089767456)
[2024-11-03 04:38:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:38:59][root][INFO] - Training Epoch: 1/2, step 1623/54251 completed (loss: 0.9659554958343506, acc: 0.800000011920929)
[2024-11-03 04:38:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:00][root][INFO] - Training Epoch: 1/2, step 1624/54251 completed (loss: 0.9488624930381775, acc: 0.6666666865348816)
[2024-11-03 04:39:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:00][root][INFO] - Training Epoch: 1/2, step 1625/54251 completed (loss: 0.5312322378158569, acc: 0.8888888955116272)
[2024-11-03 04:39:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:01][root][INFO] - Training Epoch: 1/2, step 1626/54251 completed (loss: 2.2350618839263916, acc: 0.625)
[2024-11-03 04:39:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:01][root][INFO] - Training Epoch: 1/2, step 1627/54251 completed (loss: 1.2129952907562256, acc: 0.7857142686843872)
[2024-11-03 04:39:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:02][root][INFO] - Training Epoch: 1/2, step 1628/54251 completed (loss: 0.942864179611206, acc: 0.7727272510528564)
[2024-11-03 04:39:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:02][root][INFO] - Training Epoch: 1/2, step 1629/54251 completed (loss: 1.2065719366073608, acc: 0.6315789222717285)
[2024-11-03 04:39:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:03][root][INFO] - Training Epoch: 1/2, step 1630/54251 completed (loss: 1.9341946840286255, acc: 0.5)
[2024-11-03 04:39:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:03][root][INFO] - Training Epoch: 1/2, step 1631/54251 completed (loss: 1.8211722373962402, acc: 0.6666666865348816)
[2024-11-03 04:39:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:03][root][INFO] - Training Epoch: 1/2, step 1632/54251 completed (loss: 1.4609912633895874, acc: 0.7446808218955994)
[2024-11-03 04:39:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:04][root][INFO] - Training Epoch: 1/2, step 1633/54251 completed (loss: 1.6347895860671997, acc: 0.6545454263687134)
[2024-11-03 04:39:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:04][root][INFO] - Training Epoch: 1/2, step 1634/54251 completed (loss: 1.0151700973510742, acc: 0.7941176295280457)
[2024-11-03 04:39:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:05][root][INFO] - Training Epoch: 1/2, step 1635/54251 completed (loss: 2.6810874938964844, acc: 0.5)
[2024-11-03 04:39:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:05][root][INFO] - Training Epoch: 1/2, step 1636/54251 completed (loss: 4.164675712585449, acc: 0.29411765933036804)
[2024-11-03 04:39:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:06][root][INFO] - Training Epoch: 1/2, step 1637/54251 completed (loss: 0.6970013976097107, acc: 0.9032257795333862)
[2024-11-03 04:39:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:07][root][INFO] - Training Epoch: 1/2, step 1638/54251 completed (loss: 0.1734076887369156, acc: 1.0)
[2024-11-03 04:39:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:07][root][INFO] - Training Epoch: 1/2, step 1639/54251 completed (loss: 0.4262949824333191, acc: 0.8918918967247009)
[2024-11-03 04:39:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:07][root][INFO] - Training Epoch: 1/2, step 1640/54251 completed (loss: 0.6346390843391418, acc: 0.8333333134651184)
[2024-11-03 04:39:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:08][root][INFO] - Training Epoch: 1/2, step 1641/54251 completed (loss: 1.4723798036575317, acc: 0.7058823704719543)
[2024-11-03 04:39:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:08][root][INFO] - Training Epoch: 1/2, step 1642/54251 completed (loss: 1.3400826454162598, acc: 0.675000011920929)
[2024-11-03 04:39:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:09][root][INFO] - Training Epoch: 1/2, step 1643/54251 completed (loss: 1.317767858505249, acc: 0.800000011920929)
[2024-11-03 04:39:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:09][root][INFO] - Training Epoch: 1/2, step 1644/54251 completed (loss: 0.7860558032989502, acc: 0.8148148059844971)
[2024-11-03 04:39:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:10][root][INFO] - Training Epoch: 1/2, step 1645/54251 completed (loss: 0.9213421940803528, acc: 0.7941176295280457)
[2024-11-03 04:39:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:10][root][INFO] - Training Epoch: 1/2, step 1646/54251 completed (loss: 0.5660783648490906, acc: 0.9130434989929199)
[2024-11-03 04:39:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:11][root][INFO] - Training Epoch: 1/2, step 1647/54251 completed (loss: 0.6721357703208923, acc: 0.75)
[2024-11-03 04:39:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:11][root][INFO] - Training Epoch: 1/2, step 1648/54251 completed (loss: 1.1587437391281128, acc: 0.7692307829856873)
[2024-11-03 04:39:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:12][root][INFO] - Training Epoch: 1/2, step 1649/54251 completed (loss: 1.1938918828964233, acc: 0.782608687877655)
[2024-11-03 04:39:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:12][root][INFO] - Training Epoch: 1/2, step 1650/54251 completed (loss: 1.0956202745437622, acc: 0.7234042286872864)
[2024-11-03 04:39:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:13][root][INFO] - Training Epoch: 1/2, step 1651/54251 completed (loss: 1.4081875085830688, acc: 0.7272727489471436)
[2024-11-03 04:39:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:13][root][INFO] - Training Epoch: 1/2, step 1652/54251 completed (loss: 2.0194435119628906, acc: 0.6470588445663452)
[2024-11-03 04:39:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:14][root][INFO] - Training Epoch: 1/2, step 1653/54251 completed (loss: 1.1200854778289795, acc: 0.7599999904632568)
[2024-11-03 04:39:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:14][root][INFO] - Training Epoch: 1/2, step 1654/54251 completed (loss: 1.5955331325531006, acc: 0.75)
[2024-11-03 04:39:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:15][root][INFO] - Training Epoch: 1/2, step 1655/54251 completed (loss: 2.7906057834625244, acc: 0.47058823704719543)
[2024-11-03 04:39:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:15][root][INFO] - Training Epoch: 1/2, step 1656/54251 completed (loss: 1.0820372104644775, acc: 0.800000011920929)
[2024-11-03 04:39:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:16][root][INFO] - Training Epoch: 1/2, step 1657/54251 completed (loss: 2.0717685222625732, acc: 0.5)
[2024-11-03 04:39:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:16][root][INFO] - Training Epoch: 1/2, step 1658/54251 completed (loss: 1.7332732677459717, acc: 0.5)
[2024-11-03 04:39:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:17][root][INFO] - Training Epoch: 1/2, step 1659/54251 completed (loss: 0.7823125720024109, acc: 0.8965517282485962)
[2024-11-03 04:39:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:17][root][INFO] - Training Epoch: 1/2, step 1660/54251 completed (loss: 0.5335375070571899, acc: 0.8285714387893677)
[2024-11-03 04:39:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:18][root][INFO] - Training Epoch: 1/2, step 1661/54251 completed (loss: 2.165792465209961, acc: 0.5)
[2024-11-03 04:39:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:18][root][INFO] - Training Epoch: 1/2, step 1662/54251 completed (loss: 0.3266926407814026, acc: 0.8999999761581421)
[2024-11-03 04:39:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:19][root][INFO] - Training Epoch: 1/2, step 1663/54251 completed (loss: 0.7513437867164612, acc: 0.8799999952316284)
[2024-11-03 04:39:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:19][root][INFO] - Training Epoch: 1/2, step 1664/54251 completed (loss: 3.116720676422119, acc: 0.44999998807907104)
[2024-11-03 04:39:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:20][root][INFO] - Training Epoch: 1/2, step 1665/54251 completed (loss: 1.7472058534622192, acc: 0.625)
[2024-11-03 04:39:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:20][root][INFO] - Training Epoch: 1/2, step 1666/54251 completed (loss: 1.0993261337280273, acc: 0.7777777910232544)
[2024-11-03 04:39:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:21][root][INFO] - Training Epoch: 1/2, step 1667/54251 completed (loss: 2.1844890117645264, acc: 0.6078431606292725)
[2024-11-03 04:39:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:21][root][INFO] - Training Epoch: 1/2, step 1668/54251 completed (loss: 0.2726000249385834, acc: 0.8571428656578064)
[2024-11-03 04:39:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:22][root][INFO] - Training Epoch: 1/2, step 1669/54251 completed (loss: 0.1430814266204834, acc: 0.9743589758872986)
[2024-11-03 04:39:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:22][root][INFO] - Training Epoch: 1/2, step 1670/54251 completed (loss: 0.7384111285209656, acc: 0.8421052694320679)
[2024-11-03 04:39:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:23][root][INFO] - Training Epoch: 1/2, step 1671/54251 completed (loss: 1.3517941236495972, acc: 0.7222222089767456)
[2024-11-03 04:39:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:23][root][INFO] - Training Epoch: 1/2, step 1672/54251 completed (loss: 1.4710930585861206, acc: 0.6000000238418579)
[2024-11-03 04:39:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:24][root][INFO] - Training Epoch: 1/2, step 1673/54251 completed (loss: 1.1489579677581787, acc: 0.800000011920929)
[2024-11-03 04:39:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:24][root][INFO] - Training Epoch: 1/2, step 1674/54251 completed (loss: 0.28752803802490234, acc: 0.9230769276618958)
[2024-11-03 04:39:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:25][root][INFO] - Training Epoch: 1/2, step 1675/54251 completed (loss: 1.4818809032440186, acc: 0.6363636255264282)
[2024-11-03 04:39:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:25][root][INFO] - Training Epoch: 1/2, step 1676/54251 completed (loss: 2.9375264644622803, acc: 0.4444444477558136)
[2024-11-03 04:39:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:26][root][INFO] - Training Epoch: 1/2, step 1677/54251 completed (loss: 0.8004776835441589, acc: 0.8421052694320679)
[2024-11-03 04:39:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:26][root][INFO] - Training Epoch: 1/2, step 1678/54251 completed (loss: 0.11832010746002197, acc: 1.0)
[2024-11-03 04:39:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:27][root][INFO] - Training Epoch: 1/2, step 1679/54251 completed (loss: 2.763763666152954, acc: 0.5116279125213623)
[2024-11-03 04:39:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:27][root][INFO] - Training Epoch: 1/2, step 1680/54251 completed (loss: 0.4563162326812744, acc: 0.9047619104385376)
[2024-11-03 04:39:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:28][root][INFO] - Training Epoch: 1/2, step 1681/54251 completed (loss: 1.9965864419937134, acc: 0.625)
[2024-11-03 04:39:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:28][root][INFO] - Training Epoch: 1/2, step 1682/54251 completed (loss: 0.6552730798721313, acc: 0.8666666746139526)
[2024-11-03 04:39:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:29][root][INFO] - Training Epoch: 1/2, step 1683/54251 completed (loss: 2.11588454246521, acc: 0.6470588445663452)
[2024-11-03 04:39:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:29][root][INFO] - Training Epoch: 1/2, step 1684/54251 completed (loss: 3.6017038822174072, acc: 0.3333333432674408)
[2024-11-03 04:39:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:30][root][INFO] - Training Epoch: 1/2, step 1685/54251 completed (loss: 0.869286835193634, acc: 0.8620689511299133)
[2024-11-03 04:39:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:30][root][INFO] - Training Epoch: 1/2, step 1686/54251 completed (loss: 0.5109596252441406, acc: 0.875)
[2024-11-03 04:39:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:31][root][INFO] - Training Epoch: 1/2, step 1687/54251 completed (loss: 1.1323546171188354, acc: 0.7692307829856873)
[2024-11-03 04:39:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:31][root][INFO] - Training Epoch: 1/2, step 1688/54251 completed (loss: 0.20131205022335052, acc: 0.9090909361839294)
[2024-11-03 04:39:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:32][root][INFO] - Training Epoch: 1/2, step 1689/54251 completed (loss: 2.5240478515625, acc: 0.5)
[2024-11-03 04:39:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:32][root][INFO] - Training Epoch: 1/2, step 1690/54251 completed (loss: 2.016141414642334, acc: 0.6521739363670349)
[2024-11-03 04:39:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:33][root][INFO] - Training Epoch: 1/2, step 1691/54251 completed (loss: 1.397353172302246, acc: 0.625)
[2024-11-03 04:39:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:33][root][INFO] - Training Epoch: 1/2, step 1692/54251 completed (loss: 1.9763556718826294, acc: 0.6666666865348816)
[2024-11-03 04:39:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:34][root][INFO] - Training Epoch: 1/2, step 1693/54251 completed (loss: 0.24060846865177155, acc: 1.0)
[2024-11-03 04:39:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:34][root][INFO] - Training Epoch: 1/2, step 1694/54251 completed (loss: 0.6896049380302429, acc: 0.8604651093482971)
[2024-11-03 04:39:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:35][root][INFO] - Training Epoch: 1/2, step 1695/54251 completed (loss: 1.7609139680862427, acc: 0.6666666865348816)
[2024-11-03 04:39:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:35][root][INFO] - Training Epoch: 1/2, step 1696/54251 completed (loss: 0.8036567568778992, acc: 0.6666666865348816)
[2024-11-03 04:39:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:36][root][INFO] - Training Epoch: 1/2, step 1697/54251 completed (loss: 2.973361015319824, acc: 0.43589743971824646)
[2024-11-03 04:39:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:36][root][INFO] - Training Epoch: 1/2, step 1698/54251 completed (loss: 3.881718158721924, acc: 0.3333333432674408)
[2024-11-03 04:39:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:37][root][INFO] - Training Epoch: 1/2, step 1699/54251 completed (loss: 1.1660975217819214, acc: 0.7884615659713745)
[2024-11-03 04:39:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:37][root][INFO] - Training Epoch: 1/2, step 1700/54251 completed (loss: 1.6833893060684204, acc: 0.7142857313156128)
[2024-11-03 04:39:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:38][root][INFO] - Training Epoch: 1/2, step 1701/54251 completed (loss: 3.3060405254364014, acc: 0.37931033968925476)
[2024-11-03 04:39:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:38][root][INFO] - Training Epoch: 1/2, step 1702/54251 completed (loss: 0.3842534124851227, acc: 0.9047619104385376)
[2024-11-03 04:39:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:39][root][INFO] - Training Epoch: 1/2, step 1703/54251 completed (loss: 2.596757411956787, acc: 0.3888888955116272)
[2024-11-03 04:39:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:39][root][INFO] - Training Epoch: 1/2, step 1704/54251 completed (loss: 0.9713597297668457, acc: 0.8235294222831726)
[2024-11-03 04:39:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:40][root][INFO] - Training Epoch: 1/2, step 1705/54251 completed (loss: 1.878123164176941, acc: 0.6410256624221802)
[2024-11-03 04:39:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:40][root][INFO] - Training Epoch: 1/2, step 1706/54251 completed (loss: 1.5364341735839844, acc: 0.7200000286102295)
[2024-11-03 04:39:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:41][root][INFO] - Training Epoch: 1/2, step 1707/54251 completed (loss: 1.7480318546295166, acc: 0.6000000238418579)
[2024-11-03 04:39:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:41][root][INFO] - Training Epoch: 1/2, step 1708/54251 completed (loss: 1.0628880262374878, acc: 0.7407407164573669)
[2024-11-03 04:39:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:42][root][INFO] - Training Epoch: 1/2, step 1709/54251 completed (loss: 1.6450597047805786, acc: 0.6842105388641357)
[2024-11-03 04:39:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:42][root][INFO] - Training Epoch: 1/2, step 1710/54251 completed (loss: 1.7486261129379272, acc: 0.5416666865348816)
[2024-11-03 04:39:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:43][root][INFO] - Training Epoch: 1/2, step 1711/54251 completed (loss: 3.722507953643799, acc: 0.2142857164144516)
[2024-11-03 04:39:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:43][root][INFO] - Training Epoch: 1/2, step 1712/54251 completed (loss: 0.4037248492240906, acc: 0.9200000166893005)
[2024-11-03 04:39:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:44][root][INFO] - Training Epoch: 1/2, step 1713/54251 completed (loss: 0.9215621948242188, acc: 0.8260869383811951)
[2024-11-03 04:39:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:44][root][INFO] - Training Epoch: 1/2, step 1714/54251 completed (loss: 1.10709547996521, acc: 0.7352941036224365)
[2024-11-03 04:39:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:45][root][INFO] - Training Epoch: 1/2, step 1715/54251 completed (loss: 1.9350680112838745, acc: 0.6428571343421936)
[2024-11-03 04:39:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:45][root][INFO] - Training Epoch: 1/2, step 1716/54251 completed (loss: 0.9309484362602234, acc: 0.800000011920929)
[2024-11-03 04:39:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:46][root][INFO] - Training Epoch: 1/2, step 1717/54251 completed (loss: 0.5984306931495667, acc: 0.9411764740943909)
[2024-11-03 04:39:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:46][root][INFO] - Training Epoch: 1/2, step 1718/54251 completed (loss: 0.9474525451660156, acc: 0.6842105388641357)
[2024-11-03 04:39:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:47][root][INFO] - Training Epoch: 1/2, step 1719/54251 completed (loss: 2.3596999645233154, acc: 0.6666666865348816)
[2024-11-03 04:39:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:48][root][INFO] - Training Epoch: 1/2, step 1720/54251 completed (loss: 1.063092827796936, acc: 0.8571428656578064)
[2024-11-03 04:39:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:48][root][INFO] - Training Epoch: 1/2, step 1721/54251 completed (loss: 1.286224603652954, acc: 0.7575757503509521)
[2024-11-03 04:39:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:49][root][INFO] - Training Epoch: 1/2, step 1722/54251 completed (loss: 3.138004779815674, acc: 0.2857142984867096)
[2024-11-03 04:39:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:49][root][INFO] - Training Epoch: 1/2, step 1723/54251 completed (loss: 1.8987525701522827, acc: 0.5)
[2024-11-03 04:39:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:50][root][INFO] - Training Epoch: 1/2, step 1724/54251 completed (loss: 1.921423077583313, acc: 0.6666666865348816)
[2024-11-03 04:39:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:50][root][INFO] - Training Epoch: 1/2, step 1725/54251 completed (loss: 1.1704448461532593, acc: 0.7083333134651184)
[2024-11-03 04:39:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:51][root][INFO] - Training Epoch: 1/2, step 1726/54251 completed (loss: 0.7134760618209839, acc: 0.8461538553237915)
[2024-11-03 04:39:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:51][root][INFO] - Training Epoch: 1/2, step 1727/54251 completed (loss: 0.8381102085113525, acc: 0.8333333134651184)
[2024-11-03 04:39:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:52][root][INFO] - Training Epoch: 1/2, step 1728/54251 completed (loss: 0.5669747591018677, acc: 0.875)
[2024-11-03 04:39:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:52][root][INFO] - Training Epoch: 1/2, step 1729/54251 completed (loss: 0.9839023947715759, acc: 0.8333333134651184)
[2024-11-03 04:39:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:53][root][INFO] - Training Epoch: 1/2, step 1730/54251 completed (loss: 0.3956635892391205, acc: 0.8695651888847351)
[2024-11-03 04:39:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:53][root][INFO] - Training Epoch: 1/2, step 1731/54251 completed (loss: 1.075402021408081, acc: 0.7142857313156128)
[2024-11-03 04:39:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:54][root][INFO] - Training Epoch: 1/2, step 1732/54251 completed (loss: 0.6185272336006165, acc: 0.9032257795333862)
[2024-11-03 04:39:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:54][root][INFO] - Training Epoch: 1/2, step 1733/54251 completed (loss: 1.5348445177078247, acc: 0.7142857313156128)
[2024-11-03 04:39:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:55][root][INFO] - Training Epoch: 1/2, step 1734/54251 completed (loss: 2.7281298637390137, acc: 0.4444444477558136)
[2024-11-03 04:39:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:55][root][INFO] - Training Epoch: 1/2, step 1735/54251 completed (loss: 0.05441990867257118, acc: 1.0)
[2024-11-03 04:39:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:56][root][INFO] - Training Epoch: 1/2, step 1736/54251 completed (loss: 3.0136194229125977, acc: 0.5)
[2024-11-03 04:39:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:56][root][INFO] - Training Epoch: 1/2, step 1737/54251 completed (loss: 0.1308254897594452, acc: 0.9729729890823364)
[2024-11-03 04:39:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:57][root][INFO] - Training Epoch: 1/2, step 1738/54251 completed (loss: 0.6476362347602844, acc: 0.8222222328186035)
[2024-11-03 04:39:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:57][root][INFO] - Training Epoch: 1/2, step 1739/54251 completed (loss: 0.9505371451377869, acc: 0.8947368264198303)
[2024-11-03 04:39:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:58][root][INFO] - Training Epoch: 1/2, step 1740/54251 completed (loss: 0.8342294096946716, acc: 0.8461538553237915)
[2024-11-03 04:39:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:58][root][INFO] - Training Epoch: 1/2, step 1741/54251 completed (loss: 2.516880750656128, acc: 0.4000000059604645)
[2024-11-03 04:39:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:59][root][INFO] - Training Epoch: 1/2, step 1742/54251 completed (loss: 0.3394522964954376, acc: 0.9333333373069763)
[2024-11-03 04:39:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:39:59][root][INFO] - Training Epoch: 1/2, step 1743/54251 completed (loss: 0.1209423691034317, acc: 0.949999988079071)
[2024-11-03 04:39:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:40:00][root][INFO] - Training Epoch: 1/2, step 1744/54251 completed (loss: 1.9398434162139893, acc: 0.6888889074325562)
[2024-11-03 04:40:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:40:00][root][INFO] - Training Epoch: 1/2, step 1745/54251 completed (loss: 0.4464832544326782, acc: 0.8333333134651184)
[2024-11-03 04:40:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:40:01][root][INFO] - Training Epoch: 1/2, step 1746/54251 completed (loss: 1.8203485012054443, acc: 0.7179487347602844)
[2024-11-03 04:40:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:40:01][root][INFO] - Training Epoch: 1/2, step 1747/54251 completed (loss: 0.6408071517944336, acc: 0.8235294222831726)
[2024-11-03 04:40:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:40:02][root][INFO] - Training Epoch: 1/2, step 1748/54251 completed (loss: 0.8267828226089478, acc: 0.875)
[2024-11-03 04:40:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:40:02][root][INFO] - Training Epoch: 1/2, step 1749/54251 completed (loss: 0.7901591658592224, acc: 0.8055555820465088)
[2024-11-03 04:40:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:40:03][root][INFO] - Training Epoch: 1/2, step 1750/54251 completed (loss: 1.4809714555740356, acc: 0.6785714030265808)
[2024-11-03 04:40:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:40:03][root][INFO] - Training Epoch: 1/2, step 1751/54251 completed (loss: 1.810070514678955, acc: 0.6111111044883728)
[2024-11-03 04:40:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:40:04][root][INFO] - Training Epoch: 1/2, step 1752/54251 completed (loss: 0.5666706562042236, acc: 0.8636363744735718)
[2024-11-03 04:40:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-03 04:40:04][root][INFO] - Training Epoch: 1/2, step 1753/54251 completed (loss: 0.4365710914134979, acc: 0.9230769276618958)
[2024-11-03 04:40:04][slam_llm.models.slam_model][INFO] - modality encoder
Selected latest checkpoint by epoch: 
No checkpoint found in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_nbest_whisper_TinyLlama_linear_peft_separate
ckpt_folder /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_nbest_whisper_TinyLlama_linear_peft_separate/
[2024-11-03 04:40:33][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_nbest_whisper_TinyLlama_linear_peft_separate', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False}
[2024-11-03 04:40:33][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-11-03 04:40:33][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'TinyLlama', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/TinyLlama-1.1B-Chat-v1.0', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'whisper', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Whisper/large-v3.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-11-03 04:40:55][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2024-11-03 04:40:55][slam_llm.utils.train_utils][INFO] - --> whisper has 635.04896 Million params

[2024-11-03 04:40:55][slam_llm.utils.train_utils][INFO] - --> Module whisper
[2024-11-03 04:40:55][slam_llm.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2024-11-03 04:41:00][slam_llm.utils.train_utils][INFO] - --> Module TinyLlama
[2024-11-03 04:41:00][slam_llm.utils.train_utils][INFO] - --> TinyLlama has 1100.048384 Million params

[2024-11-03 04:41:00][slam_llm.models.slam_model][INFO] - setup peft...
trainable params: 6,307,840 || all params: 1,106,356,224 || trainable%: 0.570145479653396
[2024-11-03 04:41:01][slam_llm.utils.train_utils][INFO] - --> Module TinyLlama
[2024-11-03 04:41:01][slam_llm.utils.train_utils][INFO] - --> TinyLlama has 6.30784 Million params

[2024-11-03 04:41:01][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-11-03 04:41:01][slam_llm.utils.train_utils][INFO] - --> linear has 17.3056 Million params

[2024-11-03 04:41:01][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_nbest_whisper_TinyLlama_linear_peft_separate//model.pt
No GT file matching pattern '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_nbest_whisper_TinyLlama_linear_peft_separate/decode_test_beam4_*_gt' found.
