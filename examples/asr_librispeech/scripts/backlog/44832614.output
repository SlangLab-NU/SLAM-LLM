Using dataset file: src/slam_llm/datasets/speech_dataset.py:get_speech_dataset
speech encoder name: wavlm
speech encoder path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt
speech encoder2 name: w2v2
speech encoder2 path: vitouphy/wav2vec2-xls-r-300m-timit-phoneme
llm_path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/TinyLlama-1.1B-Chat-v1.0
Identifier: librispeech-100_phoneme_only_wavlm_TinyLlama_dual_phoneme_freeze
use_peft: true
use_fp16: true
Final identifier: librispeech-100_phoneme_only_wavlm_TinyLlama_dual_peft
ckpt_folder: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_only_wavlm_TinyLlama_dual_peft/
Resume epoch: 1
Resume step: 0
[2024-10-22 06:13:47][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_phoneme_only_wavlm_TinyLlama_dual_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': False}
[2024-10-22 06:13:47][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-10-22 06:13:47][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'TinyLlama', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/TinyLlama-1.1B-Chat-v1.0', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'dual', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': 'w2v2', 'encoder2_dim': 1024, 'encoder2_path': 'vitouphy/wav2vec2-xls-r-300m-timit-phoneme'}
[2024-10-22 06:13:47][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_phoneme_only_wavlm_TinyLlama_dual_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-10-22_06-13-46.txt', 'log_interval': 5}
[2024-10-22 06:14:06][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-10-22 06:14:12][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-10-22 06:14:12][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-10-22 06:14:12][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-10-22 06:14:12][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-10-22 06:14:15][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2024-10-22 06:14:15][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2024-10-22 06:14:15][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2024-10-22 06:14:15][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2024-10-22 06:14:21][slam_llm.utils.train_utils][INFO] - --> Module TinyLlama
[2024-10-22 06:14:21][slam_llm.utils.train_utils][INFO] - --> TinyLlama has 1100.048384 Million params

[2024-10-22 06:14:21][slam_llm.models.slam_model][INFO] - setup peft...
trainable params: 6,307,840 || all params: 1,106,356,224 || trainable%: 0.570145479653396
[2024-10-22 06:14:21][slam_llm.utils.train_utils][INFO] - --> Module TinyLlama
[2024-10-22 06:14:21][slam_llm.utils.train_utils][INFO] - --> TinyLlama has 6.30784 Million params

[2024-10-22 06:14:21][slam_llm.utils.train_utils][INFO] - --> Module dual
[2024-10-22 06:14:21][slam_llm.utils.train_utils][INFO] - --> dual has 25.16992 Million params

[2024-10-22 06:14:21][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-10-22 06:14:21][slam_llm.utils.train_utils][INFO] - --> asr has 346.91648 Million params

[2024-10-22 06:14:24][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme_only/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100_phoneme_only/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': 'Transcribe speech to text. ', 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-10-22 06:14:25][root][INFO] - --> Training Set Length = 28539
[2024-10-22 06:14:25][root][INFO] - --> Validation Set Length = 2703
[2024-10-22 06:14:25][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-10-22 06:14:25][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-10-22 06:14:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:28][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-10-22 06:14:28][root][INFO] - Training Epoch: 1/2, step 0/7134 completed (loss: 3.165562868118286, acc: 0.29223179817199707)
[2024-10-22 06:14:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:29][root][INFO] - Training Epoch: 1/2, step 1/7134 completed (loss: 3.1992642879486084, acc: 0.2731376886367798)
[2024-10-22 06:14:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:30][root][INFO] - Training Epoch: 1/2, step 2/7134 completed (loss: 3.067305088043213, acc: 0.32932165265083313)
[2024-10-22 06:14:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:30][root][INFO] - Training Epoch: 1/2, step 3/7134 completed (loss: 3.076122999191284, acc: 0.31492841243743896)
[2024-10-22 06:14:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:31][root][INFO] - Training Epoch: 1/2, step 4/7134 completed (loss: 3.034223794937134, acc: 0.31903189420700073)
[2024-10-22 06:14:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:32][root][INFO] - Training Epoch: 1/2, step 5/7134 completed (loss: 3.0125253200531006, acc: 0.301554411649704)
[2024-10-22 06:14:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:32][root][INFO] - Training Epoch: 1/2, step 6/7134 completed (loss: 3.1023783683776855, acc: 0.2973684072494507)
[2024-10-22 06:14:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:33][root][INFO] - Training Epoch: 1/2, step 7/7134 completed (loss: 3.100180149078369, acc: 0.29949238896369934)
[2024-10-22 06:14:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:34][root][INFO] - Training Epoch: 1/2, step 8/7134 completed (loss: 3.1317453384399414, acc: 0.28762543201446533)
[2024-10-22 06:14:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:34][root][INFO] - Training Epoch: 1/2, step 9/7134 completed (loss: 3.164870500564575, acc: 0.28316327929496765)
[2024-10-22 06:14:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:35][root][INFO] - Training Epoch: 1/2, step 10/7134 completed (loss: 3.081955671310425, acc: 0.31264108419418335)
[2024-10-22 06:14:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:35][root][INFO] - Training Epoch: 1/2, step 11/7134 completed (loss: 3.1020801067352295, acc: 0.30630630254745483)
[2024-10-22 06:14:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:36][root][INFO] - Training Epoch: 1/2, step 12/7134 completed (loss: 2.838782787322998, acc: 0.3604277968406677)
[2024-10-22 06:14:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:37][root][INFO] - Training Epoch: 1/2, step 13/7134 completed (loss: 3.0311923027038574, acc: 0.3160220980644226)
[2024-10-22 06:14:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:37][root][INFO] - Training Epoch: 1/2, step 14/7134 completed (loss: 3.1000566482543945, acc: 0.2924138009548187)
[2024-10-22 06:14:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:38][root][INFO] - Training Epoch: 1/2, step 15/7134 completed (loss: 3.0494208335876465, acc: 0.2881355881690979)
[2024-10-22 06:14:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:39][root][INFO] - Training Epoch: 1/2, step 16/7134 completed (loss: 3.02929949760437, acc: 0.30706074833869934)
[2024-10-22 06:14:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:39][root][INFO] - Training Epoch: 1/2, step 17/7134 completed (loss: 3.2404818534851074, acc: 0.2483801245689392)
[2024-10-22 06:14:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:40][root][INFO] - Training Epoch: 1/2, step 18/7134 completed (loss: 2.83168363571167, acc: 0.313142865896225)
[2024-10-22 06:14:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:40][root][INFO] - Training Epoch: 1/2, step 19/7134 completed (loss: 2.916807174682617, acc: 0.3079470098018646)
[2024-10-22 06:14:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:41][root][INFO] - Training Epoch: 1/2, step 20/7134 completed (loss: 2.911351203918457, acc: 0.3351007401943207)
[2024-10-22 06:14:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:42][root][INFO] - Training Epoch: 1/2, step 21/7134 completed (loss: 2.8304874897003174, acc: 0.31115880608558655)
[2024-10-22 06:14:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:42][root][INFO] - Training Epoch: 1/2, step 22/7134 completed (loss: 2.767014265060425, acc: 0.34069767594337463)
[2024-10-22 06:14:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:43][root][INFO] - Training Epoch: 1/2, step 23/7134 completed (loss: 2.6982040405273438, acc: 0.3411371111869812)
[2024-10-22 06:14:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:43][root][INFO] - Training Epoch: 1/2, step 24/7134 completed (loss: 2.8611316680908203, acc: 0.32175925374031067)
[2024-10-22 06:14:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:44][root][INFO] - Training Epoch: 1/2, step 25/7134 completed (loss: 2.7604658603668213, acc: 0.3363533318042755)
[2024-10-22 06:14:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:45][root][INFO] - Training Epoch: 1/2, step 26/7134 completed (loss: 2.9129092693328857, acc: 0.2846890091896057)
[2024-10-22 06:14:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:45][root][INFO] - Training Epoch: 1/2, step 27/7134 completed (loss: 2.8934834003448486, acc: 0.3189964294433594)
[2024-10-22 06:14:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:46][root][INFO] - Training Epoch: 1/2, step 28/7134 completed (loss: 2.8485565185546875, acc: 0.32239383459091187)
[2024-10-22 06:14:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:47][root][INFO] - Training Epoch: 1/2, step 29/7134 completed (loss: 2.741074562072754, acc: 0.3422519564628601)
[2024-10-22 06:14:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:47][root][INFO] - Training Epoch: 1/2, step 30/7134 completed (loss: 2.813159465789795, acc: 0.3213321268558502)
[2024-10-22 06:14:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:48][root][INFO] - Training Epoch: 1/2, step 31/7134 completed (loss: 2.8038113117218018, acc: 0.33417296409606934)
[2024-10-22 06:14:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:49][root][INFO] - Training Epoch: 1/2, step 32/7134 completed (loss: 2.7841596603393555, acc: 0.3316115736961365)
[2024-10-22 06:14:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:49][root][INFO] - Training Epoch: 1/2, step 33/7134 completed (loss: 3.026071548461914, acc: 0.2945990264415741)
[2024-10-22 06:14:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:50][root][INFO] - Training Epoch: 1/2, step 34/7134 completed (loss: 2.786033868789673, acc: 0.34237605333328247)
[2024-10-22 06:14:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:51][root][INFO] - Training Epoch: 1/2, step 35/7134 completed (loss: 2.717900037765503, acc: 0.3512269854545593)
[2024-10-22 06:14:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:51][root][INFO] - Training Epoch: 1/2, step 36/7134 completed (loss: 2.7168922424316406, acc: 0.356589138507843)
[2024-10-22 06:14:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:52][root][INFO] - Training Epoch: 1/2, step 37/7134 completed (loss: 2.783539056777954, acc: 0.3219316005706787)
[2024-10-22 06:14:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:53][root][INFO] - Training Epoch: 1/2, step 38/7134 completed (loss: 2.791815757751465, acc: 0.32384341955184937)
[2024-10-22 06:14:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:53][root][INFO] - Training Epoch: 1/2, step 39/7134 completed (loss: 2.7358782291412354, acc: 0.33191490173339844)
[2024-10-22 06:14:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:54][root][INFO] - Training Epoch: 1/2, step 40/7134 completed (loss: 2.9640614986419678, acc: 0.3014184534549713)
[2024-10-22 06:14:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:54][root][INFO] - Training Epoch: 1/2, step 41/7134 completed (loss: 2.6844558715820312, acc: 0.32783278822898865)
[2024-10-22 06:14:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:55][root][INFO] - Training Epoch: 1/2, step 42/7134 completed (loss: 2.791909694671631, acc: 0.32486188411712646)
[2024-10-22 06:14:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:56][root][INFO] - Training Epoch: 1/2, step 43/7134 completed (loss: 2.6729557514190674, acc: 0.33264675736427307)
[2024-10-22 06:14:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:56][root][INFO] - Training Epoch: 1/2, step 44/7134 completed (loss: 2.705242156982422, acc: 0.3329949378967285)
[2024-10-22 06:14:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:57][root][INFO] - Training Epoch: 1/2, step 45/7134 completed (loss: 2.6031668186187744, acc: 0.35207611322402954)
[2024-10-22 06:14:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:57][root][INFO] - Training Epoch: 1/2, step 46/7134 completed (loss: 2.725241184234619, acc: 0.3269639015197754)
[2024-10-22 06:14:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:58][root][INFO] - Training Epoch: 1/2, step 47/7134 completed (loss: 2.622265338897705, acc: 0.35321101546287537)
[2024-10-22 06:14:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:14:59][root][INFO] - Training Epoch: 1/2, step 48/7134 completed (loss: 2.6051700115203857, acc: 0.3683737516403198)
[2024-10-22 06:14:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:00][root][INFO] - Training Epoch: 1/2, step 49/7134 completed (loss: 2.712782144546509, acc: 0.3210010826587677)
[2024-10-22 06:15:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:00][root][INFO] - Training Epoch: 1/2, step 50/7134 completed (loss: 2.65814208984375, acc: 0.3510737717151642)
[2024-10-22 06:15:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:01][root][INFO] - Training Epoch: 1/2, step 51/7134 completed (loss: 2.6676857471466064, acc: 0.3380855321884155)
[2024-10-22 06:15:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:01][root][INFO] - Training Epoch: 1/2, step 52/7134 completed (loss: 2.7301950454711914, acc: 0.3177691400051117)
[2024-10-22 06:15:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:02][root][INFO] - Training Epoch: 1/2, step 53/7134 completed (loss: 2.6547505855560303, acc: 0.34443289041519165)
[2024-10-22 06:15:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:03][root][INFO] - Training Epoch: 1/2, step 54/7134 completed (loss: 2.5675153732299805, acc: 0.35977858304977417)
[2024-10-22 06:15:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:03][root][INFO] - Training Epoch: 1/2, step 55/7134 completed (loss: 2.7315709590911865, acc: 0.3229166567325592)
[2024-10-22 06:15:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:04][root][INFO] - Training Epoch: 1/2, step 56/7134 completed (loss: 2.777900218963623, acc: 0.3129548728466034)
[2024-10-22 06:15:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:05][root][INFO] - Training Epoch: 1/2, step 57/7134 completed (loss: 2.5916221141815186, acc: 0.3574926555156708)
[2024-10-22 06:15:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:05][root][INFO] - Training Epoch: 1/2, step 58/7134 completed (loss: 2.6116576194763184, acc: 0.36045312881469727)
[2024-10-22 06:15:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:06][root][INFO] - Training Epoch: 1/2, step 59/7134 completed (loss: 2.4918205738067627, acc: 0.38983049988746643)
[2024-10-22 06:15:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:07][root][INFO] - Training Epoch: 1/2, step 60/7134 completed (loss: 2.626425266265869, acc: 0.32174888253211975)
[2024-10-22 06:15:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:07][root][INFO] - Training Epoch: 1/2, step 61/7134 completed (loss: 2.547649383544922, acc: 0.3641618490219116)
[2024-10-22 06:15:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:08][root][INFO] - Training Epoch: 1/2, step 62/7134 completed (loss: 2.6143746376037598, acc: 0.3501513600349426)
[2024-10-22 06:15:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:08][root][INFO] - Training Epoch: 1/2, step 63/7134 completed (loss: 2.56648850440979, acc: 0.36673346161842346)
[2024-10-22 06:15:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:09][root][INFO] - Training Epoch: 1/2, step 64/7134 completed (loss: 2.5274810791015625, acc: 0.35638296604156494)
[2024-10-22 06:15:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:10][root][INFO] - Training Epoch: 1/2, step 65/7134 completed (loss: 2.6170217990875244, acc: 0.3415112793445587)
[2024-10-22 06:15:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:10][root][INFO] - Training Epoch: 1/2, step 66/7134 completed (loss: 2.7412405014038086, acc: 0.33096590638160706)
[2024-10-22 06:15:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:11][root][INFO] - Training Epoch: 1/2, step 67/7134 completed (loss: 2.5471231937408447, acc: 0.3517169654369354)
[2024-10-22 06:15:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:12][root][INFO] - Training Epoch: 1/2, step 68/7134 completed (loss: 2.5764851570129395, acc: 0.33705583214759827)
[2024-10-22 06:15:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:12][root][INFO] - Training Epoch: 1/2, step 69/7134 completed (loss: 2.4304137229919434, acc: 0.3729308545589447)
[2024-10-22 06:15:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:13][root][INFO] - Training Epoch: 1/2, step 70/7134 completed (loss: 2.570866584777832, acc: 0.3443526029586792)
[2024-10-22 06:15:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:14][root][INFO] - Training Epoch: 1/2, step 71/7134 completed (loss: 2.5776336193084717, acc: 0.340832382440567)
[2024-10-22 06:15:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:14][root][INFO] - Training Epoch: 1/2, step 72/7134 completed (loss: 2.555743932723999, acc: 0.3525179922580719)
[2024-10-22 06:15:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:15][root][INFO] - Training Epoch: 1/2, step 73/7134 completed (loss: 2.5401437282562256, acc: 0.35155412554740906)
[2024-10-22 06:15:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:15][root][INFO] - Training Epoch: 1/2, step 74/7134 completed (loss: 2.5871434211730957, acc: 0.33782267570495605)
[2024-10-22 06:15:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:16][root][INFO] - Training Epoch: 1/2, step 75/7134 completed (loss: 2.6024374961853027, acc: 0.3309091031551361)
[2024-10-22 06:15:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:17][root][INFO] - Training Epoch: 1/2, step 76/7134 completed (loss: 2.5021395683288574, acc: 0.35577890276908875)
[2024-10-22 06:15:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:17][root][INFO] - Training Epoch: 1/2, step 77/7134 completed (loss: 2.3794307708740234, acc: 0.39243027567863464)
[2024-10-22 06:15:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:18][root][INFO] - Training Epoch: 1/2, step 78/7134 completed (loss: 2.4352848529815674, acc: 0.3877805471420288)
[2024-10-22 06:15:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:19][root][INFO] - Training Epoch: 1/2, step 79/7134 completed (loss: 2.4707860946655273, acc: 0.37995049357414246)
[2024-10-22 06:15:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:19][root][INFO] - Training Epoch: 1/2, step 80/7134 completed (loss: 2.46891713142395, acc: 0.3512658178806305)
[2024-10-22 06:15:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:20][root][INFO] - Training Epoch: 1/2, step 81/7134 completed (loss: 2.4182066917419434, acc: 0.3759162425994873)
[2024-10-22 06:15:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:21][root][INFO] - Training Epoch: 1/2, step 82/7134 completed (loss: 2.369401216506958, acc: 0.3823870122432709)
[2024-10-22 06:15:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:21][root][INFO] - Training Epoch: 1/2, step 83/7134 completed (loss: 2.430598735809326, acc: 0.3661538362503052)
[2024-10-22 06:15:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:22][root][INFO] - Training Epoch: 1/2, step 84/7134 completed (loss: 2.44655442237854, acc: 0.3980582654476166)
[2024-10-22 06:15:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:23][root][INFO] - Training Epoch: 1/2, step 85/7134 completed (loss: 2.56040358543396, acc: 0.3466666638851166)
[2024-10-22 06:15:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:23][root][INFO] - Training Epoch: 1/2, step 86/7134 completed (loss: 2.5337579250335693, acc: 0.3543599247932434)
[2024-10-22 06:15:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:24][root][INFO] - Training Epoch: 1/2, step 87/7134 completed (loss: 2.402329921722412, acc: 0.3646080791950226)
[2024-10-22 06:15:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:24][root][INFO] - Training Epoch: 1/2, step 88/7134 completed (loss: 2.4486594200134277, acc: 0.3572216033935547)
[2024-10-22 06:15:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:25][root][INFO] - Training Epoch: 1/2, step 89/7134 completed (loss: 2.349071502685547, acc: 0.3915724456310272)
[2024-10-22 06:15:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:26][root][INFO] - Training Epoch: 1/2, step 90/7134 completed (loss: 2.4437294006347656, acc: 0.3618784546852112)
[2024-10-22 06:15:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:26][root][INFO] - Training Epoch: 1/2, step 91/7134 completed (loss: 2.456624984741211, acc: 0.3531300127506256)
[2024-10-22 06:15:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:27][root][INFO] - Training Epoch: 1/2, step 92/7134 completed (loss: 2.3970704078674316, acc: 0.37235227227211)
[2024-10-22 06:15:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:28][root][INFO] - Training Epoch: 1/2, step 93/7134 completed (loss: 2.34804368019104, acc: 0.3679558038711548)
[2024-10-22 06:15:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:28][root][INFO] - Training Epoch: 1/2, step 94/7134 completed (loss: 2.4117658138275146, acc: 0.36745887994766235)
[2024-10-22 06:15:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:29][root][INFO] - Training Epoch: 1/2, step 95/7134 completed (loss: 2.2926414012908936, acc: 0.3907022774219513)
[2024-10-22 06:15:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:29][root][INFO] - Training Epoch: 1/2, step 96/7134 completed (loss: 2.4353811740875244, acc: 0.35608309507369995)
[2024-10-22 06:15:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:30][root][INFO] - Training Epoch: 1/2, step 97/7134 completed (loss: 2.670909881591797, acc: 0.25668448209762573)
[2024-10-22 06:15:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:30][root][INFO] - Training Epoch: 1/2, step 98/7134 completed (loss: 2.3868558406829834, acc: 0.36222508549690247)
[2024-10-22 06:15:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:31][root][INFO] - Training Epoch: 1/2, step 99/7134 completed (loss: 2.2956531047821045, acc: 0.37444934248924255)
[2024-10-22 06:15:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:32][root][INFO] - Training Epoch: 1/2, step 100/7134 completed (loss: 2.2478952407836914, acc: 0.385729044675827)
[2024-10-22 06:15:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:32][root][INFO] - Training Epoch: 1/2, step 101/7134 completed (loss: 2.3312737941741943, acc: 0.3687663972377777)
[2024-10-22 06:15:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:33][root][INFO] - Training Epoch: 1/2, step 102/7134 completed (loss: 2.2333147525787354, acc: 0.3897131681442261)
[2024-10-22 06:15:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:33][root][INFO] - Training Epoch: 1/2, step 103/7134 completed (loss: 2.3173322677612305, acc: 0.3512064218521118)
[2024-10-22 06:15:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:34][root][INFO] - Training Epoch: 1/2, step 104/7134 completed (loss: 2.289891004562378, acc: 0.39371979236602783)
[2024-10-22 06:15:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:35][root][INFO] - Training Epoch: 1/2, step 105/7134 completed (loss: 2.1562397480010986, acc: 0.3994743824005127)
[2024-10-22 06:15:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:35][root][INFO] - Training Epoch: 1/2, step 106/7134 completed (loss: 2.155258893966675, acc: 0.4211045503616333)
[2024-10-22 06:15:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:36][root][INFO] - Training Epoch: 1/2, step 107/7134 completed (loss: 2.179641008377075, acc: 0.42550790309906006)
[2024-10-22 06:15:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:37][root][INFO] - Training Epoch: 1/2, step 108/7134 completed (loss: 2.060636281967163, acc: 0.416587233543396)
[2024-10-22 06:15:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:37][root][INFO] - Training Epoch: 1/2, step 109/7134 completed (loss: 2.228410005569458, acc: 0.375)
[2024-10-22 06:15:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:38][root][INFO] - Training Epoch: 1/2, step 110/7134 completed (loss: 1.9999643564224243, acc: 0.44052043557167053)
[2024-10-22 06:15:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:38][root][INFO] - Training Epoch: 1/2, step 111/7134 completed (loss: 2.102680206298828, acc: 0.4333333373069763)
[2024-10-22 06:15:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:39][root][INFO] - Training Epoch: 1/2, step 112/7134 completed (loss: 2.146969795227051, acc: 0.39042821526527405)
[2024-10-22 06:15:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:40][root][INFO] - Training Epoch: 1/2, step 113/7134 completed (loss: 2.0393691062927246, acc: 0.42405709624290466)
[2024-10-22 06:15:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:40][root][INFO] - Training Epoch: 1/2, step 114/7134 completed (loss: 2.1410629749298096, acc: 0.4225500524044037)
[2024-10-22 06:15:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:41][root][INFO] - Training Epoch: 1/2, step 115/7134 completed (loss: 2.2635655403137207, acc: 0.38274335861206055)
[2024-10-22 06:15:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:41][root][INFO] - Training Epoch: 1/2, step 116/7134 completed (loss: 2.0412511825561523, acc: 0.4161260426044464)
[2024-10-22 06:15:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:42][root][INFO] - Training Epoch: 1/2, step 117/7134 completed (loss: 2.0381240844726562, acc: 0.4497816562652588)
[2024-10-22 06:15:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:43][root][INFO] - Training Epoch: 1/2, step 118/7134 completed (loss: 2.0392417907714844, acc: 0.43421053886413574)
[2024-10-22 06:15:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:43][root][INFO] - Training Epoch: 1/2, step 119/7134 completed (loss: 2.0877411365509033, acc: 0.43256261944770813)
[2024-10-22 06:15:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:44][root][INFO] - Training Epoch: 1/2, step 120/7134 completed (loss: 2.083179473876953, acc: 0.4212721586227417)
[2024-10-22 06:15:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:45][root][INFO] - Training Epoch: 1/2, step 121/7134 completed (loss: 2.0169408321380615, acc: 0.4358430504798889)
[2024-10-22 06:15:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:45][root][INFO] - Training Epoch: 1/2, step 122/7134 completed (loss: 1.945985198020935, acc: 0.45083680748939514)
[2024-10-22 06:15:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:46][root][INFO] - Training Epoch: 1/2, step 123/7134 completed (loss: 2.0096771717071533, acc: 0.4305882453918457)
[2024-10-22 06:15:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:46][root][INFO] - Training Epoch: 1/2, step 124/7134 completed (loss: 2.071782350540161, acc: 0.426075279712677)
[2024-10-22 06:15:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:47][root][INFO] - Training Epoch: 1/2, step 125/7134 completed (loss: 1.9885889291763306, acc: 0.446601927280426)
[2024-10-22 06:15:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:48][root][INFO] - Training Epoch: 1/2, step 126/7134 completed (loss: 2.0047709941864014, acc: 0.4077163636684418)
[2024-10-22 06:15:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:48][root][INFO] - Training Epoch: 1/2, step 127/7134 completed (loss: 1.92897629737854, acc: 0.4545454680919647)
[2024-10-22 06:15:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:49][root][INFO] - Training Epoch: 1/2, step 128/7134 completed (loss: 1.9367306232452393, acc: 0.4344637989997864)
[2024-10-22 06:15:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:50][root][INFO] - Training Epoch: 1/2, step 129/7134 completed (loss: 2.0750975608825684, acc: 0.3972468078136444)
[2024-10-22 06:15:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:50][root][INFO] - Training Epoch: 1/2, step 130/7134 completed (loss: 1.9249380826950073, acc: 0.44742268323898315)
[2024-10-22 06:15:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:51][root][INFO] - Training Epoch: 1/2, step 131/7134 completed (loss: 1.8714953660964966, acc: 0.44514769315719604)
[2024-10-22 06:15:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:52][root][INFO] - Training Epoch: 1/2, step 132/7134 completed (loss: 2.048539876937866, acc: 0.42111507058143616)
[2024-10-22 06:15:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:52][root][INFO] - Training Epoch: 1/2, step 133/7134 completed (loss: 2.020784854888916, acc: 0.40799999237060547)
[2024-10-22 06:15:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:53][root][INFO] - Training Epoch: 1/2, step 134/7134 completed (loss: 1.9925282001495361, acc: 0.4149855971336365)
[2024-10-22 06:15:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:53][root][INFO] - Training Epoch: 1/2, step 135/7134 completed (loss: 1.897261381149292, acc: 0.4409937858581543)
[2024-10-22 06:15:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:54][root][INFO] - Training Epoch: 1/2, step 136/7134 completed (loss: 1.8967573642730713, acc: 0.43342775106430054)
[2024-10-22 06:15:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:55][root][INFO] - Training Epoch: 1/2, step 137/7134 completed (loss: 1.952658772468567, acc: 0.42359769344329834)
[2024-10-22 06:15:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:55][root][INFO] - Training Epoch: 1/2, step 138/7134 completed (loss: 1.9019442796707153, acc: 0.43478259444236755)
[2024-10-22 06:15:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:56][root][INFO] - Training Epoch: 1/2, step 139/7134 completed (loss: 1.9248350858688354, acc: 0.4194214940071106)
[2024-10-22 06:15:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:57][root][INFO] - Training Epoch: 1/2, step 140/7134 completed (loss: 2.039654493331909, acc: 0.4106280207633972)
[2024-10-22 06:15:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:57][root][INFO] - Training Epoch: 1/2, step 141/7134 completed (loss: 1.8982441425323486, acc: 0.4444444477558136)
[2024-10-22 06:15:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:58][root][INFO] - Training Epoch: 1/2, step 142/7134 completed (loss: 1.9314839839935303, acc: 0.4485049843788147)
[2024-10-22 06:15:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:59][root][INFO] - Training Epoch: 1/2, step 143/7134 completed (loss: 1.8664906024932861, acc: 0.46848738193511963)
[2024-10-22 06:15:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:15:59][root][INFO] - Training Epoch: 1/2, step 144/7134 completed (loss: 1.8307349681854248, acc: 0.4738903343677521)
[2024-10-22 06:15:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:00][root][INFO] - Training Epoch: 1/2, step 145/7134 completed (loss: 1.9381159543991089, acc: 0.4456886947154999)
[2024-10-22 06:16:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:01][root][INFO] - Training Epoch: 1/2, step 146/7134 completed (loss: 1.9466620683670044, acc: 0.4401858448982239)
[2024-10-22 06:16:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:01][root][INFO] - Training Epoch: 1/2, step 147/7134 completed (loss: 1.8774181604385376, acc: 0.46463245153427124)
[2024-10-22 06:16:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:02][root][INFO] - Training Epoch: 1/2, step 148/7134 completed (loss: 2.0073230266571045, acc: 0.4367816150188446)
[2024-10-22 06:16:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:02][root][INFO] - Training Epoch: 1/2, step 149/7134 completed (loss: 1.8148658275604248, acc: 0.4642487168312073)
[2024-10-22 06:16:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:03][root][INFO] - Training Epoch: 1/2, step 150/7134 completed (loss: 1.9273942708969116, acc: 0.4485684037208557)
[2024-10-22 06:16:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:04][root][INFO] - Training Epoch: 1/2, step 151/7134 completed (loss: 1.9461939334869385, acc: 0.44260701537132263)
[2024-10-22 06:16:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:04][root][INFO] - Training Epoch: 1/2, step 152/7134 completed (loss: 1.8688377141952515, acc: 0.45288196206092834)
[2024-10-22 06:16:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:05][root][INFO] - Training Epoch: 1/2, step 153/7134 completed (loss: 1.9228707551956177, acc: 0.44130924344062805)
[2024-10-22 06:16:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:05][root][INFO] - Training Epoch: 1/2, step 154/7134 completed (loss: 1.9505889415740967, acc: 0.4432234466075897)
[2024-10-22 06:16:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:06][root][INFO] - Training Epoch: 1/2, step 155/7134 completed (loss: 1.9220788478851318, acc: 0.43492063879966736)
[2024-10-22 06:16:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:07][root][INFO] - Training Epoch: 1/2, step 156/7134 completed (loss: 1.804231882095337, acc: 0.45597776770591736)
[2024-10-22 06:16:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:07][root][INFO] - Training Epoch: 1/2, step 157/7134 completed (loss: 1.8773280382156372, acc: 0.47029703855514526)
[2024-10-22 06:16:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:08][root][INFO] - Training Epoch: 1/2, step 158/7134 completed (loss: 1.7866766452789307, acc: 0.4745057225227356)
[2024-10-22 06:16:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:09][root][INFO] - Training Epoch: 1/2, step 159/7134 completed (loss: 1.8428417444229126, acc: 0.4785631597042084)
[2024-10-22 06:16:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:09][root][INFO] - Training Epoch: 1/2, step 160/7134 completed (loss: 1.9041974544525146, acc: 0.4375)
[2024-10-22 06:16:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:10][root][INFO] - Training Epoch: 1/2, step 161/7134 completed (loss: 1.833213210105896, acc: 0.47575056552886963)
[2024-10-22 06:16:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:10][root][INFO] - Training Epoch: 1/2, step 162/7134 completed (loss: 1.9299309253692627, acc: 0.43661972880363464)
[2024-10-22 06:16:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:11][root][INFO] - Training Epoch: 1/2, step 163/7134 completed (loss: 1.7877644300460815, acc: 0.46341463923454285)
[2024-10-22 06:16:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:11][root][INFO] - Training Epoch: 1/2, step 164/7134 completed (loss: 1.8158636093139648, acc: 0.4830508530139923)
[2024-10-22 06:16:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:12][root][INFO] - Training Epoch: 1/2, step 165/7134 completed (loss: 1.7829124927520752, acc: 0.4671669900417328)
[2024-10-22 06:16:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:12][root][INFO] - Training Epoch: 1/2, step 166/7134 completed (loss: 1.7181336879730225, acc: 0.5186915993690491)
[2024-10-22 06:16:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:13][root][INFO] - Training Epoch: 1/2, step 167/7134 completed (loss: 2.0018725395202637, acc: 0.4147398769855499)
[2024-10-22 06:16:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:13][root][INFO] - Training Epoch: 1/2, step 168/7134 completed (loss: 2.365248680114746, acc: 0.342192679643631)
[2024-10-22 06:16:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:14][root][INFO] - Training Epoch: 1/2, step 169/7134 completed (loss: 1.999047875404358, acc: 0.4112149477005005)
[2024-10-22 06:16:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:14][root][INFO] - Training Epoch: 1/2, step 170/7134 completed (loss: 2.0222463607788086, acc: 0.4267912805080414)
[2024-10-22 06:16:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:15][root][INFO] - Training Epoch: 1/2, step 171/7134 completed (loss: 1.956496000289917, acc: 0.42276424169540405)
[2024-10-22 06:16:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:15][root][INFO] - Training Epoch: 1/2, step 172/7134 completed (loss: 2.043747663497925, acc: 0.42239686846733093)
[2024-10-22 06:16:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:16][root][INFO] - Training Epoch: 1/2, step 173/7134 completed (loss: 1.9564787149429321, acc: 0.3989361822605133)
[2024-10-22 06:16:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:16][root][INFO] - Training Epoch: 1/2, step 174/7134 completed (loss: 2.0428812503814697, acc: 0.4301675856113434)
[2024-10-22 06:16:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:17][root][INFO] - Training Epoch: 1/2, step 175/7134 completed (loss: 1.9772841930389404, acc: 0.41262850165367126)
[2024-10-22 06:16:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:18][root][INFO] - Training Epoch: 1/2, step 176/7134 completed (loss: 1.9355695247650146, acc: 0.433295339345932)
[2024-10-22 06:16:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:18][root][INFO] - Training Epoch: 1/2, step 177/7134 completed (loss: 1.898189663887024, acc: 0.4517543911933899)
[2024-10-22 06:16:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:19][root][INFO] - Training Epoch: 1/2, step 178/7134 completed (loss: 1.9606765508651733, acc: 0.44272446632385254)
[2024-10-22 06:16:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:19][root][INFO] - Training Epoch: 1/2, step 179/7134 completed (loss: 1.846651315689087, acc: 0.46687209606170654)
[2024-10-22 06:16:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:20][root][INFO] - Training Epoch: 1/2, step 180/7134 completed (loss: 1.9560229778289795, acc: 0.41803279519081116)
[2024-10-22 06:16:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:21][root][INFO] - Training Epoch: 1/2, step 181/7134 completed (loss: 1.869439721107483, acc: 0.4465212821960449)
[2024-10-22 06:16:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:21][root][INFO] - Training Epoch: 1/2, step 182/7134 completed (loss: 1.8951958417892456, acc: 0.43609756231307983)
[2024-10-22 06:16:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:22][root][INFO] - Training Epoch: 1/2, step 183/7134 completed (loss: 1.873002290725708, acc: 0.43213897943496704)
[2024-10-22 06:16:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:22][root][INFO] - Training Epoch: 1/2, step 184/7134 completed (loss: 1.815754771232605, acc: 0.4651162922382355)
[2024-10-22 06:16:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:23][root][INFO] - Training Epoch: 1/2, step 185/7134 completed (loss: 1.7243093252182007, acc: 0.4729119539260864)
[2024-10-22 06:16:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:24][root][INFO] - Training Epoch: 1/2, step 186/7134 completed (loss: 1.8932185173034668, acc: 0.4413265287876129)
[2024-10-22 06:16:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:24][root][INFO] - Training Epoch: 1/2, step 187/7134 completed (loss: 1.8455264568328857, acc: 0.4631696343421936)
[2024-10-22 06:16:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:25][root][INFO] - Training Epoch: 1/2, step 188/7134 completed (loss: 1.7784545421600342, acc: 0.45274725556373596)
[2024-10-22 06:16:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:26][root][INFO] - Training Epoch: 1/2, step 189/7134 completed (loss: 1.9394086599349976, acc: 0.421875)
[2024-10-22 06:16:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:26][root][INFO] - Training Epoch: 1/2, step 190/7134 completed (loss: 1.8497729301452637, acc: 0.45488256216049194)
[2024-10-22 06:16:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:27][root][INFO] - Training Epoch: 1/2, step 191/7134 completed (loss: 1.8912428617477417, acc: 0.46507665514945984)
[2024-10-22 06:16:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:27][root][INFO] - Training Epoch: 1/2, step 192/7134 completed (loss: 1.7594858407974243, acc: 0.47708895802497864)
[2024-10-22 06:16:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:28][root][INFO] - Training Epoch: 1/2, step 193/7134 completed (loss: 1.823196530342102, acc: 0.4654427766799927)
[2024-10-22 06:16:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:29][root][INFO] - Training Epoch: 1/2, step 194/7134 completed (loss: 1.8540325164794922, acc: 0.4440639317035675)
[2024-10-22 06:16:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:29][root][INFO] - Training Epoch: 1/2, step 195/7134 completed (loss: 1.843614101409912, acc: 0.4360699951648712)
[2024-10-22 06:16:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:30][root][INFO] - Training Epoch: 1/2, step 196/7134 completed (loss: 1.8328955173492432, acc: 0.4507042169570923)
[2024-10-22 06:16:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:31][root][INFO] - Training Epoch: 1/2, step 197/7134 completed (loss: 1.767730951309204, acc: 0.4943438768386841)
[2024-10-22 06:16:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:31][root][INFO] - Training Epoch: 1/2, step 198/7134 completed (loss: 1.8048235177993774, acc: 0.44795918464660645)
[2024-10-22 06:16:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:32][root][INFO] - Training Epoch: 1/2, step 199/7134 completed (loss: 1.895599126815796, acc: 0.445609450340271)
[2024-10-22 06:16:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:32][root][INFO] - Training Epoch: 1/2, step 200/7134 completed (loss: 1.782816767692566, acc: 0.4789643883705139)
[2024-10-22 06:16:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:33][root][INFO] - Training Epoch: 1/2, step 201/7134 completed (loss: 1.7895750999450684, acc: 0.4895947277545929)
[2024-10-22 06:16:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:34][root][INFO] - Training Epoch: 1/2, step 202/7134 completed (loss: 1.8017535209655762, acc: 0.45485326647758484)
[2024-10-22 06:16:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:34][root][INFO] - Training Epoch: 1/2, step 203/7134 completed (loss: 1.7891031503677368, acc: 0.46840959787368774)
[2024-10-22 06:16:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:35][root][INFO] - Training Epoch: 1/2, step 204/7134 completed (loss: 1.7894525527954102, acc: 0.4644607901573181)
[2024-10-22 06:16:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:36][root][INFO] - Training Epoch: 1/2, step 205/7134 completed (loss: 1.7925941944122314, acc: 0.43821391463279724)
[2024-10-22 06:16:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:36][root][INFO] - Training Epoch: 1/2, step 206/7134 completed (loss: 1.7878539562225342, acc: 0.45407503843307495)
[2024-10-22 06:16:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:37][root][INFO] - Training Epoch: 1/2, step 207/7134 completed (loss: 1.8051836490631104, acc: 0.4602510333061218)
[2024-10-22 06:16:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:37][root][INFO] - Training Epoch: 1/2, step 208/7134 completed (loss: 1.8630130290985107, acc: 0.43471336364746094)
[2024-10-22 06:16:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:38][root][INFO] - Training Epoch: 1/2, step 209/7134 completed (loss: 1.8361318111419678, acc: 0.43917524814605713)
[2024-10-22 06:16:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:39][root][INFO] - Training Epoch: 1/2, step 210/7134 completed (loss: 1.713046908378601, acc: 0.48513901233673096)
[2024-10-22 06:16:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:39][root][INFO] - Training Epoch: 1/2, step 211/7134 completed (loss: 1.8163851499557495, acc: 0.4566929042339325)
[2024-10-22 06:16:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:40][root][INFO] - Training Epoch: 1/2, step 212/7134 completed (loss: 1.8867062330245972, acc: 0.4187604784965515)
[2024-10-22 06:16:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:40][root][INFO] - Training Epoch: 1/2, step 213/7134 completed (loss: 1.757708191871643, acc: 0.46981626749038696)
[2024-10-22 06:16:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:41][root][INFO] - Training Epoch: 1/2, step 214/7134 completed (loss: 1.8481225967407227, acc: 0.446208119392395)
[2024-10-22 06:16:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:42][root][INFO] - Training Epoch: 1/2, step 215/7134 completed (loss: 1.8202178478240967, acc: 0.45389050245285034)
[2024-10-22 06:16:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:42][root][INFO] - Training Epoch: 1/2, step 216/7134 completed (loss: 1.7042192220687866, acc: 0.47508305311203003)
[2024-10-22 06:16:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:43][root][INFO] - Training Epoch: 1/2, step 217/7134 completed (loss: 1.6787941455841064, acc: 0.5089820623397827)
[2024-10-22 06:16:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:43][root][INFO] - Training Epoch: 1/2, step 218/7134 completed (loss: 1.640013337135315, acc: 0.5020120739936829)
[2024-10-22 06:16:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:44][root][INFO] - Training Epoch: 1/2, step 219/7134 completed (loss: 1.8868465423583984, acc: 0.43225806951522827)
[2024-10-22 06:16:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:45][root][INFO] - Training Epoch: 1/2, step 220/7134 completed (loss: 1.662927508354187, acc: 0.47833332419395447)
[2024-10-22 06:16:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:45][root][INFO] - Training Epoch: 1/2, step 221/7134 completed (loss: 1.715610384941101, acc: 0.4922155737876892)
[2024-10-22 06:16:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:46][root][INFO] - Training Epoch: 1/2, step 222/7134 completed (loss: 1.7568354606628418, acc: 0.46048471331596375)
[2024-10-22 06:16:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:47][root][INFO] - Training Epoch: 1/2, step 223/7134 completed (loss: 1.8129643201828003, acc: 0.4618644118309021)
[2024-10-22 06:16:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:47][root][INFO] - Training Epoch: 1/2, step 224/7134 completed (loss: 1.8664170503616333, acc: 0.437238484621048)
[2024-10-22 06:16:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:48][root][INFO] - Training Epoch: 1/2, step 225/7134 completed (loss: 1.7573915719985962, acc: 0.4886597990989685)
[2024-10-22 06:16:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:48][root][INFO] - Training Epoch: 1/2, step 226/7134 completed (loss: 1.8198455572128296, acc: 0.4590325653553009)
[2024-10-22 06:16:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:49][root][INFO] - Training Epoch: 1/2, step 227/7134 completed (loss: 1.8242493867874146, acc: 0.4444444477558136)
[2024-10-22 06:16:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:50][root][INFO] - Training Epoch: 1/2, step 228/7134 completed (loss: 1.8159687519073486, acc: 0.4535840153694153)
[2024-10-22 06:16:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:50][root][INFO] - Training Epoch: 1/2, step 229/7134 completed (loss: 1.8204636573791504, acc: 0.4380081295967102)
[2024-10-22 06:16:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:51][root][INFO] - Training Epoch: 1/2, step 230/7134 completed (loss: 1.755160927772522, acc: 0.4642147123813629)
[2024-10-22 06:16:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:52][root][INFO] - Training Epoch: 1/2, step 231/7134 completed (loss: 1.7454771995544434, acc: 0.473763108253479)
[2024-10-22 06:16:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:52][root][INFO] - Training Epoch: 1/2, step 232/7134 completed (loss: 1.7332477569580078, acc: 0.48361730575561523)
[2024-10-22 06:16:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:53][root][INFO] - Training Epoch: 1/2, step 233/7134 completed (loss: 1.8021937608718872, acc: 0.46649810671806335)
[2024-10-22 06:16:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:53][root][INFO] - Training Epoch: 1/2, step 234/7134 completed (loss: 1.7657227516174316, acc: 0.4539385735988617)
[2024-10-22 06:16:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:54][root][INFO] - Training Epoch: 1/2, step 235/7134 completed (loss: 1.7012189626693726, acc: 0.471783310174942)
[2024-10-22 06:16:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:55][root][INFO] - Training Epoch: 1/2, step 236/7134 completed (loss: 1.7279269695281982, acc: 0.4655172526836395)
[2024-10-22 06:16:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:55][root][INFO] - Training Epoch: 1/2, step 237/7134 completed (loss: 1.7674391269683838, acc: 0.47037914395332336)
[2024-10-22 06:16:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:56][root][INFO] - Training Epoch: 1/2, step 238/7134 completed (loss: 1.6636083126068115, acc: 0.5080057978630066)
[2024-10-22 06:16:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:56][root][INFO] - Training Epoch: 1/2, step 239/7134 completed (loss: 1.8044604063034058, acc: 0.46205732226371765)
[2024-10-22 06:16:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:57][root][INFO] - Training Epoch: 1/2, step 240/7134 completed (loss: 1.7006847858428955, acc: 0.4852941036224365)
[2024-10-22 06:16:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:58][root][INFO] - Training Epoch: 1/2, step 241/7134 completed (loss: 1.7187730073928833, acc: 0.48805031180381775)
[2024-10-22 06:16:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:58][root][INFO] - Training Epoch: 1/2, step 242/7134 completed (loss: 1.7418876886367798, acc: 0.4726775884628296)
[2024-10-22 06:16:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:59][root][INFO] - Training Epoch: 1/2, step 243/7134 completed (loss: 1.7711048126220703, acc: 0.4697173535823822)
[2024-10-22 06:16:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:16:59][root][INFO] - Training Epoch: 1/2, step 244/7134 completed (loss: 1.6696655750274658, acc: 0.49761903285980225)
[2024-10-22 06:17:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:00][root][INFO] - Training Epoch: 1/2, step 245/7134 completed (loss: 1.7125688791275024, acc: 0.4750692546367645)
[2024-10-22 06:17:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:00][root][INFO] - Training Epoch: 1/2, step 246/7134 completed (loss: 1.6997860670089722, acc: 0.48124998807907104)
[2024-10-22 06:17:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:01][root][INFO] - Training Epoch: 1/2, step 247/7134 completed (loss: 1.6715706586837769, acc: 0.5007153153419495)
[2024-10-22 06:17:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:02][root][INFO] - Training Epoch: 1/2, step 248/7134 completed (loss: 1.6382043361663818, acc: 0.5069337487220764)
[2024-10-22 06:17:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:02][root][INFO] - Training Epoch: 1/2, step 249/7134 completed (loss: 1.6593564748764038, acc: 0.5322245359420776)
[2024-10-22 06:17:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:03][root][INFO] - Training Epoch: 1/2, step 250/7134 completed (loss: 1.7791259288787842, acc: 0.4819875657558441)
[2024-10-22 06:17:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:03][root][INFO] - Training Epoch: 1/2, step 251/7134 completed (loss: 1.6505000591278076, acc: 0.5033467411994934)
[2024-10-22 06:17:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:04][root][INFO] - Training Epoch: 1/2, step 252/7134 completed (loss: 1.7479246854782104, acc: 0.46928104758262634)
[2024-10-22 06:17:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:05][root][INFO] - Training Epoch: 1/2, step 253/7134 completed (loss: 1.713419795036316, acc: 0.4620887041091919)
[2024-10-22 06:17:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:05][root][INFO] - Training Epoch: 1/2, step 254/7134 completed (loss: 1.7147893905639648, acc: 0.4650499224662781)
[2024-10-22 06:17:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:06][root][INFO] - Training Epoch: 1/2, step 255/7134 completed (loss: 1.691406488418579, acc: 0.4759671688079834)
[2024-10-22 06:17:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:06][root][INFO] - Training Epoch: 1/2, step 256/7134 completed (loss: 1.8186688423156738, acc: 0.4727272689342499)
[2024-10-22 06:17:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:07][root][INFO] - Training Epoch: 1/2, step 257/7134 completed (loss: 1.6760826110839844, acc: 0.48426151275634766)
[2024-10-22 06:17:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:08][root][INFO] - Training Epoch: 1/2, step 258/7134 completed (loss: 1.7101815938949585, acc: 0.4934554994106293)
[2024-10-22 06:17:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:08][root][INFO] - Training Epoch: 1/2, step 259/7134 completed (loss: 1.7141278982162476, acc: 0.47564101219177246)
[2024-10-22 06:17:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:09][root][INFO] - Training Epoch: 1/2, step 260/7134 completed (loss: 1.7028642892837524, acc: 0.4897400736808777)
[2024-10-22 06:17:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:09][root][INFO] - Training Epoch: 1/2, step 261/7134 completed (loss: 1.7183654308319092, acc: 0.49508196115493774)
[2024-10-22 06:17:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:10][root][INFO] - Training Epoch: 1/2, step 262/7134 completed (loss: 1.7553378343582153, acc: 0.4611259996891022)
[2024-10-22 06:17:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:11][root][INFO] - Training Epoch: 1/2, step 263/7134 completed (loss: 1.7300773859024048, acc: 0.47949525713920593)
[2024-10-22 06:17:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:11][root][INFO] - Training Epoch: 1/2, step 264/7134 completed (loss: 1.7206487655639648, acc: 0.4720670282840729)
[2024-10-22 06:17:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:12][root][INFO] - Training Epoch: 1/2, step 265/7134 completed (loss: 1.6778901815414429, acc: 0.48673468828201294)
[2024-10-22 06:17:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:12][root][INFO] - Training Epoch: 1/2, step 266/7134 completed (loss: 1.6695173978805542, acc: 0.47194111347198486)
[2024-10-22 06:17:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:13][root][INFO] - Training Epoch: 1/2, step 267/7134 completed (loss: 1.674992561340332, acc: 0.49954667687416077)
[2024-10-22 06:17:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:14][root][INFO] - Training Epoch: 1/2, step 268/7134 completed (loss: 1.6935222148895264, acc: 0.4827945828437805)
[2024-10-22 06:17:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:14][root][INFO] - Training Epoch: 1/2, step 269/7134 completed (loss: 1.705437183380127, acc: 0.4756637215614319)
[2024-10-22 06:17:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:15][root][INFO] - Training Epoch: 1/2, step 270/7134 completed (loss: 1.5821739435195923, acc: 0.5140514969825745)
[2024-10-22 06:17:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:16][root][INFO] - Training Epoch: 1/2, step 271/7134 completed (loss: 1.6559065580368042, acc: 0.5095477104187012)
[2024-10-22 06:17:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:16][root][INFO] - Training Epoch: 1/2, step 272/7134 completed (loss: 1.7193028926849365, acc: 0.4918200373649597)
[2024-10-22 06:17:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:17][root][INFO] - Training Epoch: 1/2, step 273/7134 completed (loss: 1.5464544296264648, acc: 0.5114068388938904)
[2024-10-22 06:17:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:18][root][INFO] - Training Epoch: 1/2, step 274/7134 completed (loss: 1.6571954488754272, acc: 0.5038759708404541)
[2024-10-22 06:17:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:18][root][INFO] - Training Epoch: 1/2, step 275/7134 completed (loss: 1.6121665239334106, acc: 0.4935779869556427)
[2024-10-22 06:17:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:19][root][INFO] - Training Epoch: 1/2, step 276/7134 completed (loss: 1.613130807876587, acc: 0.5129434466362)
[2024-10-22 06:17:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:19][root][INFO] - Training Epoch: 1/2, step 277/7134 completed (loss: 1.6995010375976562, acc: 0.48106446862220764)
[2024-10-22 06:17:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:20][root][INFO] - Training Epoch: 1/2, step 278/7134 completed (loss: 1.7090479135513306, acc: 0.4655703902244568)
[2024-10-22 06:17:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:21][root][INFO] - Training Epoch: 1/2, step 279/7134 completed (loss: 1.666058897972107, acc: 0.48640167713165283)
[2024-10-22 06:17:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:21][root][INFO] - Training Epoch: 1/2, step 280/7134 completed (loss: 1.6777663230895996, acc: 0.4965229630470276)
[2024-10-22 06:17:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:22][root][INFO] - Training Epoch: 1/2, step 281/7134 completed (loss: 1.651629090309143, acc: 0.5039494633674622)
[2024-10-22 06:17:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:23][root][INFO] - Training Epoch: 1/2, step 282/7134 completed (loss: 1.763288974761963, acc: 0.47225648164749146)
[2024-10-22 06:17:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:23][root][INFO] - Training Epoch: 1/2, step 283/7134 completed (loss: 1.769241213798523, acc: 0.4623955488204956)
[2024-10-22 06:17:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:24][root][INFO] - Training Epoch: 1/2, step 284/7134 completed (loss: 1.7507705688476562, acc: 0.46916890144348145)
[2024-10-22 06:17:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:24][root][INFO] - Training Epoch: 1/2, step 285/7134 completed (loss: 1.6884644031524658, acc: 0.47092199325561523)
[2024-10-22 06:17:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:25][root][INFO] - Training Epoch: 1/2, step 286/7134 completed (loss: 1.674798846244812, acc: 0.49715909361839294)
[2024-10-22 06:17:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:25][root][INFO] - Training Epoch: 1/2, step 287/7134 completed (loss: 1.6462582349777222, acc: 0.4865211844444275)
[2024-10-22 06:17:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:26][root][INFO] - Training Epoch: 1/2, step 288/7134 completed (loss: 1.6868841648101807, acc: 0.49344977736473083)
[2024-10-22 06:17:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:27][root][INFO] - Training Epoch: 1/2, step 289/7134 completed (loss: 1.6774743795394897, acc: 0.5007215142250061)
[2024-10-22 06:17:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:27][root][INFO] - Training Epoch: 1/2, step 290/7134 completed (loss: 1.653685450553894, acc: 0.5184744000434875)
[2024-10-22 06:17:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:28][root][INFO] - Training Epoch: 1/2, step 291/7134 completed (loss: 1.6384248733520508, acc: 0.5287206172943115)
[2024-10-22 06:17:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:29][root][INFO] - Training Epoch: 1/2, step 292/7134 completed (loss: 1.844451904296875, acc: 0.4536585509777069)
[2024-10-22 06:17:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:29][root][INFO] - Training Epoch: 1/2, step 293/7134 completed (loss: 1.6394755840301514, acc: 0.5046584010124207)
[2024-10-22 06:17:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:30][root][INFO] - Training Epoch: 1/2, step 294/7134 completed (loss: 1.5965209007263184, acc: 0.5116279125213623)
[2024-10-22 06:17:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:30][root][INFO] - Training Epoch: 1/2, step 295/7134 completed (loss: 1.624827265739441, acc: 0.5127516984939575)
[2024-10-22 06:17:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:31][root][INFO] - Training Epoch: 1/2, step 296/7134 completed (loss: 1.566583275794983, acc: 0.5276073813438416)
[2024-10-22 06:17:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:32][root][INFO] - Training Epoch: 1/2, step 297/7134 completed (loss: 1.7082256078720093, acc: 0.5)
[2024-10-22 06:17:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:32][root][INFO] - Training Epoch: 1/2, step 298/7134 completed (loss: 1.7299535274505615, acc: 0.4610389471054077)
[2024-10-22 06:17:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:33][root][INFO] - Training Epoch: 1/2, step 299/7134 completed (loss: 1.6671147346496582, acc: 0.47653430700302124)
[2024-10-22 06:17:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:33][root][INFO] - Training Epoch: 1/2, step 300/7134 completed (loss: 1.479183316230774, acc: 0.5521628260612488)
[2024-10-22 06:17:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:34][root][INFO] - Training Epoch: 1/2, step 301/7134 completed (loss: 1.6045966148376465, acc: 0.5186020135879517)
[2024-10-22 06:17:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:35][root][INFO] - Training Epoch: 1/2, step 302/7134 completed (loss: 1.745599627494812, acc: 0.486821711063385)
[2024-10-22 06:17:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:35][root][INFO] - Training Epoch: 1/2, step 303/7134 completed (loss: 1.7043538093566895, acc: 0.48923078179359436)
[2024-10-22 06:17:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:36][root][INFO] - Training Epoch: 1/2, step 304/7134 completed (loss: 1.7375067472457886, acc: 0.46536144614219666)
[2024-10-22 06:17:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:36][root][INFO] - Training Epoch: 1/2, step 305/7134 completed (loss: 1.62199866771698, acc: 0.5145754218101501)
[2024-10-22 06:17:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:37][root][INFO] - Training Epoch: 1/2, step 306/7134 completed (loss: 1.6519032716751099, acc: 0.46824225783348083)
[2024-10-22 06:17:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:38][root][INFO] - Training Epoch: 1/2, step 307/7134 completed (loss: 1.6859540939331055, acc: 0.47694525122642517)
[2024-10-22 06:17:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:38][root][INFO] - Training Epoch: 1/2, step 308/7134 completed (loss: 1.5943162441253662, acc: 0.5104438662528992)
[2024-10-22 06:17:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:39][root][INFO] - Training Epoch: 1/2, step 309/7134 completed (loss: 1.6482653617858887, acc: 0.49444442987442017)
[2024-10-22 06:17:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:40][root][INFO] - Training Epoch: 1/2, step 310/7134 completed (loss: 1.5900148153305054, acc: 0.525581419467926)
[2024-10-22 06:17:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:40][root][INFO] - Training Epoch: 1/2, step 311/7134 completed (loss: 1.5973231792449951, acc: 0.5118898749351501)
[2024-10-22 06:17:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:41][root][INFO] - Training Epoch: 1/2, step 312/7134 completed (loss: 1.5067318677902222, acc: 0.5405777096748352)
[2024-10-22 06:17:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:41][root][INFO] - Training Epoch: 1/2, step 313/7134 completed (loss: 1.5368467569351196, acc: 0.5513888597488403)
[2024-10-22 06:17:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:42][root][INFO] - Training Epoch: 1/2, step 314/7134 completed (loss: 1.4886445999145508, acc: 0.5458996295928955)
[2024-10-22 06:17:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:43][root][INFO] - Training Epoch: 1/2, step 315/7134 completed (loss: 1.516789436340332, acc: 0.5440414547920227)
[2024-10-22 06:17:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:43][root][INFO] - Training Epoch: 1/2, step 316/7134 completed (loss: 1.6077849864959717, acc: 0.5118880867958069)
[2024-10-22 06:17:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:44][root][INFO] - Training Epoch: 1/2, step 317/7134 completed (loss: 1.5486007928848267, acc: 0.5336179137229919)
[2024-10-22 06:17:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:44][root][INFO] - Training Epoch: 1/2, step 318/7134 completed (loss: 1.7258963584899902, acc: 0.4921259880065918)
[2024-10-22 06:17:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:45][root][INFO] - Training Epoch: 1/2, step 319/7134 completed (loss: 1.7838765382766724, acc: 0.46979865431785583)
[2024-10-22 06:17:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:46][root][INFO] - Training Epoch: 1/2, step 320/7134 completed (loss: 1.5977935791015625, acc: 0.5270880460739136)
[2024-10-22 06:17:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:46][root][INFO] - Training Epoch: 1/2, step 321/7134 completed (loss: 1.7152125835418701, acc: 0.4761410653591156)
[2024-10-22 06:17:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:47][root][INFO] - Training Epoch: 1/2, step 322/7134 completed (loss: 1.762748122215271, acc: 0.47868454456329346)
[2024-10-22 06:17:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:48][root][INFO] - Training Epoch: 1/2, step 323/7134 completed (loss: 1.7614344358444214, acc: 0.46542826294898987)
[2024-10-22 06:17:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:48][root][INFO] - Training Epoch: 1/2, step 324/7134 completed (loss: 1.6848379373550415, acc: 0.4926062822341919)
[2024-10-22 06:17:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:49][root][INFO] - Training Epoch: 1/2, step 325/7134 completed (loss: 1.645174503326416, acc: 0.5045778155326843)
[2024-10-22 06:17:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:49][root][INFO] - Training Epoch: 1/2, step 326/7134 completed (loss: 1.615766167640686, acc: 0.5266731381416321)
[2024-10-22 06:17:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:50][root][INFO] - Training Epoch: 1/2, step 327/7134 completed (loss: 1.6767557859420776, acc: 0.48138055205345154)
[2024-10-22 06:17:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:51][root][INFO] - Training Epoch: 1/2, step 328/7134 completed (loss: 1.629616618156433, acc: 0.5112960934638977)
[2024-10-22 06:17:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:51][root][INFO] - Training Epoch: 1/2, step 329/7134 completed (loss: 1.6180469989776611, acc: 0.5162523984909058)
[2024-10-22 06:17:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:52][root][INFO] - Training Epoch: 1/2, step 330/7134 completed (loss: 1.638923168182373, acc: 0.5016025900840759)
[2024-10-22 06:17:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:53][root][INFO] - Training Epoch: 1/2, step 331/7134 completed (loss: 1.6275880336761475, acc: 0.5058929920196533)
[2024-10-22 06:17:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:53][root][INFO] - Training Epoch: 1/2, step 332/7134 completed (loss: 1.5849844217300415, acc: 0.5043394565582275)
[2024-10-22 06:17:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:54][root][INFO] - Training Epoch: 1/2, step 333/7134 completed (loss: 1.6781123876571655, acc: 0.5077071189880371)
[2024-10-22 06:17:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:55][root][INFO] - Training Epoch: 1/2, step 334/7134 completed (loss: 1.6504253149032593, acc: 0.47756728529930115)
[2024-10-22 06:17:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:55][root][INFO] - Training Epoch: 1/2, step 335/7134 completed (loss: 1.6160637140274048, acc: 0.5046838521957397)
[2024-10-22 06:17:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:56][root][INFO] - Training Epoch: 1/2, step 336/7134 completed (loss: 1.6068665981292725, acc: 0.5062082409858704)
[2024-10-22 06:17:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:57][root][INFO] - Training Epoch: 1/2, step 337/7134 completed (loss: 1.6962392330169678, acc: 0.496886670589447)
[2024-10-22 06:17:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:57][root][INFO] - Training Epoch: 1/2, step 338/7134 completed (loss: 1.6260052919387817, acc: 0.501024603843689)
[2024-10-22 06:17:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:58][root][INFO] - Training Epoch: 1/2, step 339/7134 completed (loss: 1.6164820194244385, acc: 0.4883485436439514)
[2024-10-22 06:17:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:58][root][INFO] - Training Epoch: 1/2, step 340/7134 completed (loss: 1.6977896690368652, acc: 0.476673424243927)
[2024-10-22 06:17:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:17:59][root][INFO] - Training Epoch: 1/2, step 341/7134 completed (loss: 1.5659128427505493, acc: 0.5065723061561584)
[2024-10-22 06:17:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:00][root][INFO] - Training Epoch: 1/2, step 342/7134 completed (loss: 1.6416720151901245, acc: 0.5042944550514221)
[2024-10-22 06:18:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:00][root][INFO] - Training Epoch: 1/2, step 343/7134 completed (loss: 1.730292558670044, acc: 0.4810892641544342)
[2024-10-22 06:18:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:01][root][INFO] - Training Epoch: 1/2, step 344/7134 completed (loss: 1.6387836933135986, acc: 0.48458150029182434)
[2024-10-22 06:18:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:01][root][INFO] - Training Epoch: 1/2, step 345/7134 completed (loss: 1.6641889810562134, acc: 0.4927953779697418)
[2024-10-22 06:18:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:02][root][INFO] - Training Epoch: 1/2, step 346/7134 completed (loss: 1.5731163024902344, acc: 0.5006451606750488)
[2024-10-22 06:18:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:03][root][INFO] - Training Epoch: 1/2, step 347/7134 completed (loss: 1.6577986478805542, acc: 0.49213483929634094)
[2024-10-22 06:18:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:03][root][INFO] - Training Epoch: 1/2, step 348/7134 completed (loss: 1.5707751512527466, acc: 0.514161229133606)
[2024-10-22 06:18:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:04][root][INFO] - Training Epoch: 1/2, step 349/7134 completed (loss: 1.612044334411621, acc: 0.4935205280780792)
[2024-10-22 06:18:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:05][root][INFO] - Training Epoch: 1/2, step 350/7134 completed (loss: 1.6114180088043213, acc: 0.5019120573997498)
[2024-10-22 06:18:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:05][root][INFO] - Training Epoch: 1/2, step 351/7134 completed (loss: 1.6568934917449951, acc: 0.4989648163318634)
[2024-10-22 06:18:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:06][root][INFO] - Training Epoch: 1/2, step 352/7134 completed (loss: 1.5309642553329468, acc: 0.5211726427078247)
[2024-10-22 06:18:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:07][root][INFO] - Training Epoch: 1/2, step 353/7134 completed (loss: 1.5430569648742676, acc: 0.5118534564971924)
[2024-10-22 06:18:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:07][root][INFO] - Training Epoch: 1/2, step 354/7134 completed (loss: 1.5523141622543335, acc: 0.5195895433425903)
[2024-10-22 06:18:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:08][root][INFO] - Training Epoch: 1/2, step 355/7134 completed (loss: 1.680026650428772, acc: 0.4749999940395355)
[2024-10-22 06:18:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:08][root][INFO] - Training Epoch: 1/2, step 356/7134 completed (loss: 1.6164257526397705, acc: 0.5149572491645813)
[2024-10-22 06:18:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:09][root][INFO] - Training Epoch: 1/2, step 357/7134 completed (loss: 1.6075029373168945, acc: 0.5036420226097107)
[2024-10-22 06:18:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:10][root][INFO] - Training Epoch: 1/2, step 358/7134 completed (loss: 1.5854603052139282, acc: 0.5127919912338257)
[2024-10-22 06:18:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:10][root][INFO] - Training Epoch: 1/2, step 359/7134 completed (loss: 1.5939863920211792, acc: 0.5027563571929932)
[2024-10-22 06:18:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:11][root][INFO] - Training Epoch: 1/2, step 360/7134 completed (loss: 1.570737600326538, acc: 0.5214723944664001)
[2024-10-22 06:18:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:12][root][INFO] - Training Epoch: 1/2, step 361/7134 completed (loss: 1.578792691230774, acc: 0.5227272510528564)
[2024-10-22 06:18:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:12][root][INFO] - Training Epoch: 1/2, step 362/7134 completed (loss: 1.6092935800552368, acc: 0.5065868496894836)
[2024-10-22 06:18:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:13][root][INFO] - Training Epoch: 1/2, step 363/7134 completed (loss: 1.601670503616333, acc: 0.4968220293521881)
[2024-10-22 06:18:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:13][root][INFO] - Training Epoch: 1/2, step 364/7134 completed (loss: 1.6164257526397705, acc: 0.5142315030097961)
[2024-10-22 06:18:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:14][root][INFO] - Training Epoch: 1/2, step 365/7134 completed (loss: 1.58138906955719, acc: 0.5129943490028381)
[2024-10-22 06:18:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:15][root][INFO] - Training Epoch: 1/2, step 366/7134 completed (loss: 1.6092243194580078, acc: 0.5236876010894775)
[2024-10-22 06:18:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:15][root][INFO] - Training Epoch: 1/2, step 367/7134 completed (loss: 1.5555140972137451, acc: 0.5432350039482117)
[2024-10-22 06:18:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:16][root][INFO] - Training Epoch: 1/2, step 368/7134 completed (loss: 1.48924720287323, acc: 0.5566037893295288)
[2024-10-22 06:18:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:17][root][INFO] - Training Epoch: 1/2, step 369/7134 completed (loss: 1.5759775638580322, acc: 0.5329268574714661)
[2024-10-22 06:18:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:17][root][INFO] - Training Epoch: 1/2, step 370/7134 completed (loss: 1.6065335273742676, acc: 0.5011764764785767)
[2024-10-22 06:18:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:18][root][INFO] - Training Epoch: 1/2, step 371/7134 completed (loss: 1.5444023609161377, acc: 0.5024630427360535)
[2024-10-22 06:18:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:18][root][INFO] - Training Epoch: 1/2, step 372/7134 completed (loss: 1.5564273595809937, acc: 0.5306859016418457)
[2024-10-22 06:18:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:19][root][INFO] - Training Epoch: 1/2, step 373/7134 completed (loss: 1.5360701084136963, acc: 0.5271411538124084)
[2024-10-22 06:18:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:20][root][INFO] - Training Epoch: 1/2, step 374/7134 completed (loss: 1.5159072875976562, acc: 0.530718982219696)
[2024-10-22 06:18:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:20][root][INFO] - Training Epoch: 1/2, step 375/7134 completed (loss: 1.5363960266113281, acc: 0.5276873111724854)
[2024-10-22 06:18:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:21][root][INFO] - Training Epoch: 1/2, step 376/7134 completed (loss: 1.5993101596832275, acc: 0.5168918967247009)
[2024-10-22 06:18:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:21][root][INFO] - Training Epoch: 1/2, step 377/7134 completed (loss: 1.5485018491744995, acc: 0.5204872488975525)
[2024-10-22 06:18:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:22][root][INFO] - Training Epoch: 1/2, step 378/7134 completed (loss: 1.617121696472168, acc: 0.5099778175354004)
[2024-10-22 06:18:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:23][root][INFO] - Training Epoch: 1/2, step 379/7134 completed (loss: 1.5095233917236328, acc: 0.5439838171005249)
[2024-10-22 06:18:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:23][root][INFO] - Training Epoch: 1/2, step 380/7134 completed (loss: 1.6507320404052734, acc: 0.4952681362628937)
[2024-10-22 06:18:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:24][root][INFO] - Training Epoch: 1/2, step 381/7134 completed (loss: 1.553277611732483, acc: 0.5015608668327332)
[2024-10-22 06:18:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:25][root][INFO] - Training Epoch: 1/2, step 382/7134 completed (loss: 1.5940223932266235, acc: 0.5343035459518433)
[2024-10-22 06:18:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:25][root][INFO] - Training Epoch: 1/2, step 383/7134 completed (loss: 1.5272088050842285, acc: 0.5511450171470642)
[2024-10-22 06:18:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:26][root][INFO] - Training Epoch: 1/2, step 384/7134 completed (loss: 1.6008695363998413, acc: 0.507777750492096)
[2024-10-22 06:18:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:26][root][INFO] - Training Epoch: 1/2, step 385/7134 completed (loss: 1.4773272275924683, acc: 0.5372945666313171)
[2024-10-22 06:18:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:27][root][INFO] - Training Epoch: 1/2, step 386/7134 completed (loss: 1.493154525756836, acc: 0.5514950156211853)
[2024-10-22 06:18:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:27][root][INFO] - Training Epoch: 1/2, step 387/7134 completed (loss: 1.516387701034546, acc: 0.5303738117218018)
[2024-10-22 06:18:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:28][root][INFO] - Training Epoch: 1/2, step 388/7134 completed (loss: 1.512282133102417, acc: 0.5373699069023132)
[2024-10-22 06:18:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:29][root][INFO] - Training Epoch: 1/2, step 389/7134 completed (loss: 1.5230895280838013, acc: 0.5411899089813232)
[2024-10-22 06:18:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:29][root][INFO] - Training Epoch: 1/2, step 390/7134 completed (loss: 1.5090738534927368, acc: 0.5411140322685242)
[2024-10-22 06:18:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:30][root][INFO] - Training Epoch: 1/2, step 391/7134 completed (loss: 1.4797073602676392, acc: 0.5613079071044922)
[2024-10-22 06:18:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:30][root][INFO] - Training Epoch: 1/2, step 392/7134 completed (loss: 1.4538700580596924, acc: 0.5471698045730591)
[2024-10-22 06:18:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:31][root][INFO] - Training Epoch: 1/2, step 393/7134 completed (loss: 1.5434008836746216, acc: 0.5305216312408447)
[2024-10-22 06:18:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:32][root][INFO] - Training Epoch: 1/2, step 394/7134 completed (loss: 1.4452321529388428, acc: 0.5416666865348816)
[2024-10-22 06:18:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:32][root][INFO] - Training Epoch: 1/2, step 395/7134 completed (loss: 1.4189586639404297, acc: 0.577850878238678)
[2024-10-22 06:18:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:33][root][INFO] - Training Epoch: 1/2, step 396/7134 completed (loss: 1.484587550163269, acc: 0.5581395626068115)
[2024-10-22 06:18:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:34][root][INFO] - Training Epoch: 1/2, step 397/7134 completed (loss: 1.5611611604690552, acc: 0.5264865159988403)
[2024-10-22 06:18:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:34][root][INFO] - Training Epoch: 1/2, step 398/7134 completed (loss: 1.409379005432129, acc: 0.5758218169212341)
[2024-10-22 06:18:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:35][root][INFO] - Training Epoch: 1/2, step 399/7134 completed (loss: 1.4619172811508179, acc: 0.5744966268539429)
[2024-10-22 06:18:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:35][root][INFO] - Training Epoch: 1/2, step 400/7134 completed (loss: 1.7356430292129517, acc: 0.4848851263523102)
[2024-10-22 06:18:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:36][root][INFO] - Training Epoch: 1/2, step 401/7134 completed (loss: 1.5274229049682617, acc: 0.5208747386932373)
[2024-10-22 06:18:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:37][root][INFO] - Training Epoch: 1/2, step 402/7134 completed (loss: 1.5602521896362305, acc: 0.5442522764205933)
[2024-10-22 06:18:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:37][root][INFO] - Training Epoch: 1/2, step 403/7134 completed (loss: 1.472855806350708, acc: 0.5553662776947021)
[2024-10-22 06:18:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:38][root][INFO] - Training Epoch: 1/2, step 404/7134 completed (loss: 1.5578516721725464, acc: 0.5325077176094055)
[2024-10-22 06:18:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:39][root][INFO] - Training Epoch: 1/2, step 405/7134 completed (loss: 1.5528767108917236, acc: 0.5355805158615112)
[2024-10-22 06:18:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:39][root][INFO] - Training Epoch: 1/2, step 406/7134 completed (loss: 1.522761583328247, acc: 0.5541022419929504)
[2024-10-22 06:18:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:40][root][INFO] - Training Epoch: 1/2, step 407/7134 completed (loss: 1.5883162021636963, acc: 0.4965035021305084)
[2024-10-22 06:18:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:40][root][INFO] - Training Epoch: 1/2, step 408/7134 completed (loss: 1.5982937812805176, acc: 0.5210946202278137)
[2024-10-22 06:18:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:41][root][INFO] - Training Epoch: 1/2, step 409/7134 completed (loss: 1.50525963306427, acc: 0.5355355143547058)
[2024-10-22 06:18:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:42][root][INFO] - Training Epoch: 1/2, step 410/7134 completed (loss: 1.5942111015319824, acc: 0.512758195400238)
[2024-10-22 06:18:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:42][root][INFO] - Training Epoch: 1/2, step 411/7134 completed (loss: 1.5856488943099976, acc: 0.5285848379135132)
[2024-10-22 06:18:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:43][root][INFO] - Training Epoch: 1/2, step 412/7134 completed (loss: 1.544368028640747, acc: 0.517241358757019)
[2024-10-22 06:18:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:44][root][INFO] - Training Epoch: 1/2, step 413/7134 completed (loss: 1.5982351303100586, acc: 0.5226781964302063)
[2024-10-22 06:18:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:44][root][INFO] - Training Epoch: 1/2, step 414/7134 completed (loss: 1.535826325416565, acc: 0.5225118398666382)
[2024-10-22 06:18:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:45][root][INFO] - Training Epoch: 1/2, step 415/7134 completed (loss: 1.5301358699798584, acc: 0.5189393758773804)
[2024-10-22 06:18:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:46][root][INFO] - Training Epoch: 1/2, step 416/7134 completed (loss: 1.490100622177124, acc: 0.5324926972389221)
[2024-10-22 06:18:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:46][root][INFO] - Training Epoch: 1/2, step 417/7134 completed (loss: 1.557311773300171, acc: 0.5272331237792969)
[2024-10-22 06:18:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:47][root][INFO] - Training Epoch: 1/2, step 418/7134 completed (loss: 1.5430797338485718, acc: 0.5300187468528748)
[2024-10-22 06:18:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:48][root][INFO] - Training Epoch: 1/2, step 419/7134 completed (loss: 1.484432578086853, acc: 0.5431727170944214)
[2024-10-22 06:18:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:48][root][INFO] - Training Epoch: 1/2, step 420/7134 completed (loss: 1.5035974979400635, acc: 0.5530201196670532)
[2024-10-22 06:18:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:49][root][INFO] - Training Epoch: 1/2, step 421/7134 completed (loss: 1.5161619186401367, acc: 0.5255570411682129)
[2024-10-22 06:18:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:49][root][INFO] - Training Epoch: 1/2, step 422/7134 completed (loss: 1.3606473207473755, acc: 0.559382438659668)
[2024-10-22 06:18:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:50][root][INFO] - Training Epoch: 1/2, step 423/7134 completed (loss: 1.4635162353515625, acc: 0.5374706983566284)
[2024-10-22 06:18:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:51][root][INFO] - Training Epoch: 1/2, step 424/7134 completed (loss: 1.4580429792404175, acc: 0.5475578308105469)
[2024-10-22 06:18:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:51][root][INFO] - Training Epoch: 1/2, step 425/7134 completed (loss: 1.3718006610870361, acc: 0.5709219574928284)
[2024-10-22 06:18:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:52][root][INFO] - Training Epoch: 1/2, step 426/7134 completed (loss: 1.4407117366790771, acc: 0.5414798259735107)
[2024-10-22 06:18:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:52][root][INFO] - Training Epoch: 1/2, step 427/7134 completed (loss: 1.4899194240570068, acc: 0.5323740839958191)
[2024-10-22 06:18:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:53][root][INFO] - Training Epoch: 1/2, step 428/7134 completed (loss: 1.4807534217834473, acc: 0.5408653616905212)
[2024-10-22 06:18:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:54][root][INFO] - Training Epoch: 1/2, step 429/7134 completed (loss: 1.4776257276535034, acc: 0.5681818127632141)
[2024-10-22 06:18:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:54][root][INFO] - Training Epoch: 1/2, step 430/7134 completed (loss: 1.5014444589614868, acc: 0.5339470505714417)
[2024-10-22 06:18:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:55][root][INFO] - Training Epoch: 1/2, step 431/7134 completed (loss: 1.4848750829696655, acc: 0.5122235417366028)
[2024-10-22 06:18:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:55][root][INFO] - Training Epoch: 1/2, step 432/7134 completed (loss: 1.5065522193908691, acc: 0.5454545617103577)
[2024-10-22 06:18:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:56][root][INFO] - Training Epoch: 1/2, step 433/7134 completed (loss: 1.3266180753707886, acc: 0.5835164785385132)
[2024-10-22 06:18:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:57][root][INFO] - Training Epoch: 1/2, step 434/7134 completed (loss: 1.4663830995559692, acc: 0.5488810539245605)
[2024-10-22 06:18:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:57][root][INFO] - Training Epoch: 1/2, step 435/7134 completed (loss: 1.5058636665344238, acc: 0.5148741602897644)
[2024-10-22 06:18:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:58][root][INFO] - Training Epoch: 1/2, step 436/7134 completed (loss: 1.3891308307647705, acc: 0.5562499761581421)
[2024-10-22 06:18:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:58][root][INFO] - Training Epoch: 1/2, step 437/7134 completed (loss: 1.4029302597045898, acc: 0.5578034520149231)
[2024-10-22 06:18:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:18:59][root][INFO] - Training Epoch: 1/2, step 438/7134 completed (loss: 1.4516067504882812, acc: 0.5749613642692566)
[2024-10-22 06:18:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:00][root][INFO] - Training Epoch: 1/2, step 439/7134 completed (loss: 1.5802549123764038, acc: 0.5278350710868835)
[2024-10-22 06:19:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:00][root][INFO] - Training Epoch: 1/2, step 440/7134 completed (loss: 1.5759129524230957, acc: 0.5253772139549255)
[2024-10-22 06:19:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:01][root][INFO] - Training Epoch: 1/2, step 441/7134 completed (loss: 1.4670230150222778, acc: 0.5754716992378235)
[2024-10-22 06:19:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:01][root][INFO] - Training Epoch: 1/2, step 442/7134 completed (loss: 1.3432345390319824, acc: 0.582335352897644)
[2024-10-22 06:19:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:02][root][INFO] - Training Epoch: 1/2, step 443/7134 completed (loss: 1.5322961807250977, acc: 0.5149999856948853)
[2024-10-22 06:19:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:03][root][INFO] - Training Epoch: 1/2, step 444/7134 completed (loss: 1.475551962852478, acc: 0.5388813018798828)
[2024-10-22 06:19:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:03][root][INFO] - Training Epoch: 1/2, step 445/7134 completed (loss: 1.4675133228302002, acc: 0.5250875353813171)
[2024-10-22 06:19:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:04][root][INFO] - Training Epoch: 1/2, step 446/7134 completed (loss: 1.5053584575653076, acc: 0.5318436026573181)
[2024-10-22 06:19:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:04][root][INFO] - Training Epoch: 1/2, step 447/7134 completed (loss: 1.515010118484497, acc: 0.5427631735801697)
[2024-10-22 06:19:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:05][root][INFO] - Training Epoch: 1/2, step 448/7134 completed (loss: 1.5579532384872437, acc: 0.5291709303855896)
[2024-10-22 06:19:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:06][root][INFO] - Training Epoch: 1/2, step 449/7134 completed (loss: 1.5301448106765747, acc: 0.515709638595581)
[2024-10-22 06:19:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:06][root][INFO] - Training Epoch: 1/2, step 450/7134 completed (loss: 1.5323814153671265, acc: 0.5286195278167725)
[2024-10-22 06:19:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:07][root][INFO] - Training Epoch: 1/2, step 451/7134 completed (loss: 1.5280014276504517, acc: 0.5422138571739197)
[2024-10-22 06:19:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:08][root][INFO] - Training Epoch: 1/2, step 452/7134 completed (loss: 1.635194182395935, acc: 0.5083240866661072)
[2024-10-22 06:19:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:08][root][INFO] - Training Epoch: 1/2, step 453/7134 completed (loss: 1.4916679859161377, acc: 0.522827684879303)
[2024-10-22 06:19:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:09][root][INFO] - Training Epoch: 1/2, step 454/7134 completed (loss: 1.4593225717544556, acc: 0.5567010045051575)
[2024-10-22 06:19:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:10][root][INFO] - Training Epoch: 1/2, step 455/7134 completed (loss: 1.5908554792404175, acc: 0.5067920684814453)
[2024-10-22 06:19:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:10][root][INFO] - Training Epoch: 1/2, step 456/7134 completed (loss: 1.494024634361267, acc: 0.49436935782432556)
[2024-10-22 06:19:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:11][root][INFO] - Training Epoch: 1/2, step 457/7134 completed (loss: 1.5914069414138794, acc: 0.49800264835357666)
[2024-10-22 06:19:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:11][root][INFO] - Training Epoch: 1/2, step 458/7134 completed (loss: 1.6612796783447266, acc: 0.48613375425338745)
[2024-10-22 06:19:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:12][root][INFO] - Training Epoch: 1/2, step 459/7134 completed (loss: 1.6025384664535522, acc: 0.4941314458847046)
[2024-10-22 06:19:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:13][root][INFO] - Training Epoch: 1/2, step 460/7134 completed (loss: 1.4802308082580566, acc: 0.5355805158615112)
[2024-10-22 06:19:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:13][root][INFO] - Training Epoch: 1/2, step 461/7134 completed (loss: 1.5865706205368042, acc: 0.4919540286064148)
[2024-10-22 06:19:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:14][root][INFO] - Training Epoch: 1/2, step 462/7134 completed (loss: 1.4589637517929077, acc: 0.5427509546279907)
[2024-10-22 06:19:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:15][root][INFO] - Training Epoch: 1/2, step 463/7134 completed (loss: 1.6485633850097656, acc: 0.505091667175293)
[2024-10-22 06:19:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:15][root][INFO] - Training Epoch: 1/2, step 464/7134 completed (loss: 1.5628623962402344, acc: 0.4954023063182831)
[2024-10-22 06:19:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:16][root][INFO] - Training Epoch: 1/2, step 465/7134 completed (loss: 1.5597319602966309, acc: 0.5235602259635925)
[2024-10-22 06:19:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:16][root][INFO] - Training Epoch: 1/2, step 466/7134 completed (loss: 1.571378231048584, acc: 0.5051975250244141)
[2024-10-22 06:19:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:17][root][INFO] - Training Epoch: 1/2, step 467/7134 completed (loss: 1.5507968664169312, acc: 0.5229110717773438)
[2024-10-22 06:19:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:18][root][INFO] - Training Epoch: 1/2, step 468/7134 completed (loss: 1.6049789190292358, acc: 0.5102702975273132)
[2024-10-22 06:19:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:18][root][INFO] - Training Epoch: 1/2, step 469/7134 completed (loss: 1.6077631711959839, acc: 0.5202780961990356)
[2024-10-22 06:19:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:19][root][INFO] - Training Epoch: 1/2, step 470/7134 completed (loss: 1.5971531867980957, acc: 0.5197861194610596)
[2024-10-22 06:19:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:19][root][INFO] - Training Epoch: 1/2, step 471/7134 completed (loss: 1.531558871269226, acc: 0.5170454382896423)
[2024-10-22 06:19:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:20][root][INFO] - Training Epoch: 1/2, step 472/7134 completed (loss: 1.5428366661071777, acc: 0.5309218168258667)
[2024-10-22 06:19:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:21][root][INFO] - Training Epoch: 1/2, step 473/7134 completed (loss: 1.564436674118042, acc: 0.5068663954734802)
[2024-10-22 06:19:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:21][root][INFO] - Training Epoch: 1/2, step 474/7134 completed (loss: 1.5903323888778687, acc: 0.5219665169715881)
[2024-10-22 06:19:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:22][root][INFO] - Training Epoch: 1/2, step 475/7134 completed (loss: 1.5252435207366943, acc: 0.5260718464851379)
[2024-10-22 06:19:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:23][root][INFO] - Training Epoch: 1/2, step 476/7134 completed (loss: 1.5686832666397095, acc: 0.5213963985443115)
[2024-10-22 06:19:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:23][root][INFO] - Training Epoch: 1/2, step 477/7134 completed (loss: 1.5389173030853271, acc: 0.5174081325531006)
[2024-10-22 06:19:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:24][root][INFO] - Training Epoch: 1/2, step 478/7134 completed (loss: 1.5336095094680786, acc: 0.5416666865348816)
[2024-10-22 06:19:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:24][root][INFO] - Training Epoch: 1/2, step 479/7134 completed (loss: 1.5058764219284058, acc: 0.5278093218803406)
[2024-10-22 06:19:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:25][root][INFO] - Training Epoch: 1/2, step 480/7134 completed (loss: 1.5182466506958008, acc: 0.5227007865905762)
[2024-10-22 06:19:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:26][root][INFO] - Training Epoch: 1/2, step 481/7134 completed (loss: 1.548520803451538, acc: 0.5358255505561829)
[2024-10-22 06:19:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:26][root][INFO] - Training Epoch: 1/2, step 482/7134 completed (loss: 1.5132579803466797, acc: 0.5416191816329956)
[2024-10-22 06:19:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:27][root][INFO] - Training Epoch: 1/2, step 483/7134 completed (loss: 1.483284592628479, acc: 0.5386119484901428)
[2024-10-22 06:19:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:27][root][INFO] - Training Epoch: 1/2, step 484/7134 completed (loss: 1.605282187461853, acc: 0.4994606375694275)
[2024-10-22 06:19:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:28][root][INFO] - Training Epoch: 1/2, step 485/7134 completed (loss: 1.494517207145691, acc: 0.5349693298339844)
[2024-10-22 06:19:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:29][root][INFO] - Training Epoch: 1/2, step 486/7134 completed (loss: 1.5627065896987915, acc: 0.5283505320549011)
[2024-10-22 06:19:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:29][root][INFO] - Training Epoch: 1/2, step 487/7134 completed (loss: 1.5586748123168945, acc: 0.5283018946647644)
[2024-10-22 06:19:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:30][root][INFO] - Training Epoch: 1/2, step 488/7134 completed (loss: 1.570281982421875, acc: 0.5036389827728271)
[2024-10-22 06:19:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:30][root][INFO] - Training Epoch: 1/2, step 489/7134 completed (loss: 1.512070655822754, acc: 0.5192562937736511)
[2024-10-22 06:19:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:31][root][INFO] - Training Epoch: 1/2, step 490/7134 completed (loss: 1.4270172119140625, acc: 0.5842217206954956)
[2024-10-22 06:19:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:32][root][INFO] - Training Epoch: 1/2, step 491/7134 completed (loss: 1.598122239112854, acc: 0.5080645084381104)
[2024-10-22 06:19:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:32][root][INFO] - Training Epoch: 1/2, step 492/7134 completed (loss: 1.4647160768508911, acc: 0.526576042175293)
[2024-10-22 06:19:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:33][root][INFO] - Training Epoch: 1/2, step 493/7134 completed (loss: 1.5334409475326538, acc: 0.5252873301506042)
[2024-10-22 06:19:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:33][root][INFO] - Training Epoch: 1/2, step 494/7134 completed (loss: 1.4967299699783325, acc: 0.5415617227554321)
[2024-10-22 06:19:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:34][root][INFO] - Training Epoch: 1/2, step 495/7134 completed (loss: 1.545760989189148, acc: 0.525581419467926)
[2024-10-22 06:19:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:34][root][INFO] - Training Epoch: 1/2, step 496/7134 completed (loss: 1.5352282524108887, acc: 0.5296609997749329)
[2024-10-22 06:19:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:35][root][INFO] - Training Epoch: 1/2, step 497/7134 completed (loss: 1.576287865638733, acc: 0.5173978805541992)
[2024-10-22 06:19:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:36][root][INFO] - Training Epoch: 1/2, step 498/7134 completed (loss: 1.5031574964523315, acc: 0.5191816091537476)
[2024-10-22 06:19:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:36][root][INFO] - Training Epoch: 1/2, step 499/7134 completed (loss: 1.4608453512191772, acc: 0.5488474369049072)
[2024-10-22 06:19:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:37][root][INFO] - Training Epoch: 1/2, step 500/7134 completed (loss: 1.4906946420669556, acc: 0.523809552192688)
[2024-10-22 06:19:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:38][root][INFO] - Training Epoch: 1/2, step 501/7134 completed (loss: 1.5553330183029175, acc: 0.5132743120193481)
[2024-10-22 06:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:38][root][INFO] - Training Epoch: 1/2, step 502/7134 completed (loss: 1.420623779296875, acc: 0.54334557056427)
[2024-10-22 06:19:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:39][root][INFO] - Training Epoch: 1/2, step 503/7134 completed (loss: 1.505889654159546, acc: 0.5211267471313477)
[2024-10-22 06:19:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:39][root][INFO] - Training Epoch: 1/2, step 504/7134 completed (loss: 1.5331796407699585, acc: 0.5005649924278259)
[2024-10-22 06:19:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:40][root][INFO] - Training Epoch: 1/2, step 505/7134 completed (loss: 1.4815655946731567, acc: 0.5211864113807678)
[2024-10-22 06:19:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:41][root][INFO] - Training Epoch: 1/2, step 506/7134 completed (loss: 1.494682788848877, acc: 0.5349544286727905)
[2024-10-22 06:19:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:41][root][INFO] - Training Epoch: 1/2, step 507/7134 completed (loss: 1.4505338668823242, acc: 0.5514705777168274)
[2024-10-22 06:19:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:42][root][INFO] - Training Epoch: 1/2, step 508/7134 completed (loss: 1.526836633682251, acc: 0.5258525609970093)
[2024-10-22 06:19:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:43][root][INFO] - Training Epoch: 1/2, step 509/7134 completed (loss: 1.566718578338623, acc: 0.5142857432365417)
[2024-10-22 06:19:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:43][root][INFO] - Training Epoch: 1/2, step 510/7134 completed (loss: 1.6399184465408325, acc: 0.5246179699897766)
[2024-10-22 06:19:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:44][root][INFO] - Training Epoch: 1/2, step 511/7134 completed (loss: 1.5841776132583618, acc: 0.52173912525177)
[2024-10-22 06:19:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:44][root][INFO] - Training Epoch: 1/2, step 512/7134 completed (loss: 1.5178511142730713, acc: 0.5231260061264038)
[2024-10-22 06:19:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:45][root][INFO] - Training Epoch: 1/2, step 513/7134 completed (loss: 1.4484853744506836, acc: 0.5519125461578369)
[2024-10-22 06:19:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:45][root][INFO] - Training Epoch: 1/2, step 514/7134 completed (loss: 1.4569097757339478, acc: 0.5511810779571533)
[2024-10-22 06:19:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:46][root][INFO] - Training Epoch: 1/2, step 515/7134 completed (loss: 1.4580793380737305, acc: 0.5486425161361694)
[2024-10-22 06:19:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:46][root][INFO] - Training Epoch: 1/2, step 516/7134 completed (loss: 1.4036989212036133, acc: 0.5545454621315002)
[2024-10-22 06:19:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:47][root][INFO] - Training Epoch: 1/2, step 517/7134 completed (loss: 1.5655701160430908, acc: 0.5152838230133057)
[2024-10-22 06:19:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:48][root][INFO] - Training Epoch: 1/2, step 518/7134 completed (loss: 1.4653407335281372, acc: 0.5563463568687439)
[2024-10-22 06:19:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:48][root][INFO] - Training Epoch: 1/2, step 519/7134 completed (loss: 1.5336767435073853, acc: 0.5264026522636414)
[2024-10-22 06:19:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:49][root][INFO] - Training Epoch: 1/2, step 520/7134 completed (loss: 1.5175457000732422, acc: 0.529860258102417)
[2024-10-22 06:19:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:49][root][INFO] - Training Epoch: 1/2, step 521/7134 completed (loss: 1.5267765522003174, acc: 0.5177610516548157)
[2024-10-22 06:19:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:50][root][INFO] - Training Epoch: 1/2, step 522/7134 completed (loss: 1.4539114236831665, acc: 0.5446622967720032)
[2024-10-22 06:19:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:51][root][INFO] - Training Epoch: 1/2, step 523/7134 completed (loss: 1.4329569339752197, acc: 0.5529953837394714)
[2024-10-22 06:19:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:51][root][INFO] - Training Epoch: 1/2, step 524/7134 completed (loss: 1.458234190940857, acc: 0.5466237664222717)
[2024-10-22 06:19:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:52][root][INFO] - Training Epoch: 1/2, step 525/7134 completed (loss: 1.4577082395553589, acc: 0.5399515628814697)
[2024-10-22 06:19:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:53][root][INFO] - Training Epoch: 1/2, step 526/7134 completed (loss: 1.5222463607788086, acc: 0.5298013091087341)
[2024-10-22 06:19:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:53][root][INFO] - Training Epoch: 1/2, step 527/7134 completed (loss: 1.488525390625, acc: 0.5317220687866211)
[2024-10-22 06:19:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:54][root][INFO] - Training Epoch: 1/2, step 528/7134 completed (loss: 1.4421918392181396, acc: 0.5297906398773193)
[2024-10-22 06:19:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:55][root][INFO] - Training Epoch: 1/2, step 529/7134 completed (loss: 1.498664379119873, acc: 0.5159642696380615)
[2024-10-22 06:19:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:55][root][INFO] - Training Epoch: 1/2, step 530/7134 completed (loss: 1.485203742980957, acc: 0.555084764957428)
[2024-10-22 06:19:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:56][root][INFO] - Training Epoch: 1/2, step 531/7134 completed (loss: 1.3545844554901123, acc: 0.5834445953369141)
[2024-10-22 06:19:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:56][root][INFO] - Training Epoch: 1/2, step 532/7134 completed (loss: 1.4480955600738525, acc: 0.5520133972167969)
[2024-10-22 06:19:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:57][root][INFO] - Training Epoch: 1/2, step 533/7134 completed (loss: 1.433542251586914, acc: 0.5474254488945007)
[2024-10-22 06:19:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:58][root][INFO] - Training Epoch: 1/2, step 534/7134 completed (loss: 1.387873888015747, acc: 0.5493420958518982)
[2024-10-22 06:19:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:58][root][INFO] - Training Epoch: 1/2, step 535/7134 completed (loss: 1.5129119157791138, acc: 0.5528571605682373)
[2024-10-22 06:19:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:59][root][INFO] - Training Epoch: 1/2, step 536/7134 completed (loss: 1.484199047088623, acc: 0.5388180613517761)
[2024-10-22 06:19:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:19:59][root][INFO] - Training Epoch: 1/2, step 537/7134 completed (loss: 1.5357272624969482, acc: 0.5297619104385376)
[2024-10-22 06:20:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:00][root][INFO] - Training Epoch: 1/2, step 538/7134 completed (loss: 1.502881646156311, acc: 0.5442424416542053)
[2024-10-22 06:20:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:01][root][INFO] - Training Epoch: 1/2, step 539/7134 completed (loss: 1.6032087802886963, acc: 0.49862638115882874)
[2024-10-22 06:20:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:01][root][INFO] - Training Epoch: 1/2, step 540/7134 completed (loss: 1.6394325494766235, acc: 0.4925619959831238)
[2024-10-22 06:20:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:02][root][INFO] - Training Epoch: 1/2, step 541/7134 completed (loss: 1.6244871616363525, acc: 0.5199999809265137)
[2024-10-22 06:20:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:02][root][INFO] - Training Epoch: 1/2, step 542/7134 completed (loss: 1.6681791543960571, acc: 0.45643940567970276)
[2024-10-22 06:20:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:03][root][INFO] - Training Epoch: 1/2, step 543/7134 completed (loss: 1.5985140800476074, acc: 0.5262411236763)
[2024-10-22 06:20:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:03][root][INFO] - Training Epoch: 1/2, step 544/7134 completed (loss: 1.6252425909042358, acc: 0.5)
[2024-10-22 06:20:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:04][root][INFO] - Training Epoch: 1/2, step 545/7134 completed (loss: 1.6486625671386719, acc: 0.512385904788971)
[2024-10-22 06:20:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:05][root][INFO] - Training Epoch: 1/2, step 546/7134 completed (loss: 1.6633633375167847, acc: 0.5103969573974609)
[2024-10-22 06:20:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:05][root][INFO] - Training Epoch: 1/2, step 547/7134 completed (loss: 1.521065592765808, acc: 0.5162790417671204)
[2024-10-22 06:20:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:06][root][INFO] - Training Epoch: 1/2, step 548/7134 completed (loss: 1.555613398551941, acc: 0.5093361139297485)
[2024-10-22 06:20:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:07][root][INFO] - Training Epoch: 1/2, step 549/7134 completed (loss: 1.5847845077514648, acc: 0.5177478790283203)
[2024-10-22 06:20:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:07][root][INFO] - Training Epoch: 1/2, step 550/7134 completed (loss: 1.6341514587402344, acc: 0.502754807472229)
[2024-10-22 06:20:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:08][root][INFO] - Training Epoch: 1/2, step 551/7134 completed (loss: 1.5831341743469238, acc: 0.5065885782241821)
[2024-10-22 06:20:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:08][root][INFO] - Training Epoch: 1/2, step 552/7134 completed (loss: 1.4673807621002197, acc: 0.5601750612258911)
[2024-10-22 06:20:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:09][root][INFO] - Training Epoch: 1/2, step 553/7134 completed (loss: 1.4811062812805176, acc: 0.5405872464179993)
[2024-10-22 06:20:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:09][root][INFO] - Training Epoch: 1/2, step 554/7134 completed (loss: 1.4918993711471558, acc: 0.5244988799095154)
[2024-10-22 06:20:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:10][root][INFO] - Training Epoch: 1/2, step 555/7134 completed (loss: 1.554408073425293, acc: 0.5179677605628967)
[2024-10-22 06:20:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:11][root][INFO] - Training Epoch: 1/2, step 556/7134 completed (loss: 1.3854336738586426, acc: 0.5689085125923157)
[2024-10-22 06:20:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:11][root][INFO] - Training Epoch: 1/2, step 557/7134 completed (loss: 1.5663940906524658, acc: 0.5292553305625916)
[2024-10-22 06:20:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:12][root][INFO] - Training Epoch: 1/2, step 558/7134 completed (loss: 1.5084185600280762, acc: 0.5280898809432983)
[2024-10-22 06:20:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:12][root][INFO] - Training Epoch: 1/2, step 559/7134 completed (loss: 1.563072681427002, acc: 0.5251716375350952)
[2024-10-22 06:20:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:13][root][INFO] - Training Epoch: 1/2, step 560/7134 completed (loss: 1.5030754804611206, acc: 0.525874137878418)
[2024-10-22 06:20:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:14][root][INFO] - Training Epoch: 1/2, step 561/7134 completed (loss: 1.465531587600708, acc: 0.5468127727508545)
[2024-10-22 06:20:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:14][root][INFO] - Training Epoch: 1/2, step 562/7134 completed (loss: 1.4220705032348633, acc: 0.5702479481697083)
[2024-10-22 06:20:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:15][root][INFO] - Training Epoch: 1/2, step 563/7134 completed (loss: 1.5356661081314087, acc: 0.5356695652008057)
[2024-10-22 06:20:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:16][root][INFO] - Training Epoch: 1/2, step 564/7134 completed (loss: 1.4966627359390259, acc: 0.53125)
[2024-10-22 06:20:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:16][root][INFO] - Training Epoch: 1/2, step 565/7134 completed (loss: 1.4226006269454956, acc: 0.5507246255874634)
[2024-10-22 06:20:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:17][root][INFO] - Training Epoch: 1/2, step 566/7134 completed (loss: 1.5853331089019775, acc: 0.4944649338722229)
[2024-10-22 06:20:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:17][root][INFO] - Training Epoch: 1/2, step 567/7134 completed (loss: 1.6104567050933838, acc: 0.5132158398628235)
[2024-10-22 06:20:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:18][root][INFO] - Training Epoch: 1/2, step 568/7134 completed (loss: 1.4860705137252808, acc: 0.550000011920929)
[2024-10-22 06:20:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:18][root][INFO] - Training Epoch: 1/2, step 569/7134 completed (loss: 1.5181818008422852, acc: 0.5344655513763428)
[2024-10-22 06:20:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:19][root][INFO] - Training Epoch: 1/2, step 570/7134 completed (loss: 1.5119928121566772, acc: 0.5456238389015198)
[2024-10-22 06:20:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:20][root][INFO] - Training Epoch: 1/2, step 571/7134 completed (loss: 1.6013942956924438, acc: 0.48503610491752625)
[2024-10-22 06:20:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:20][root][INFO] - Training Epoch: 1/2, step 572/7134 completed (loss: 1.4971823692321777, acc: 0.5311203598976135)
[2024-10-22 06:20:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:21][root][INFO] - Training Epoch: 1/2, step 573/7134 completed (loss: 1.5711796283721924, acc: 0.5047120451927185)
[2024-10-22 06:20:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:22][root][INFO] - Training Epoch: 1/2, step 574/7134 completed (loss: 1.5340911149978638, acc: 0.5313807725906372)
[2024-10-22 06:20:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:22][root][INFO] - Training Epoch: 1/2, step 575/7134 completed (loss: 1.5508943796157837, acc: 0.527368426322937)
[2024-10-22 06:20:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:23][root][INFO] - Training Epoch: 1/2, step 576/7134 completed (loss: 1.4624841213226318, acc: 0.5256797671318054)
[2024-10-22 06:20:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:23][root][INFO] - Training Epoch: 1/2, step 577/7134 completed (loss: 1.5697664022445679, acc: 0.5116279125213623)
[2024-10-22 06:20:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:24][root][INFO] - Training Epoch: 1/2, step 578/7134 completed (loss: 1.516175627708435, acc: 0.5297450423240662)
[2024-10-22 06:20:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:25][root][INFO] - Training Epoch: 1/2, step 579/7134 completed (loss: 1.605814814567566, acc: 0.5243019461631775)
[2024-10-22 06:20:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:25][root][INFO] - Training Epoch: 1/2, step 580/7134 completed (loss: 1.5666053295135498, acc: 0.5179487466812134)
[2024-10-22 06:20:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:26][root][INFO] - Training Epoch: 1/2, step 581/7134 completed (loss: 1.4980804920196533, acc: 0.5455543398857117)
[2024-10-22 06:20:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:27][root][INFO] - Training Epoch: 1/2, step 582/7134 completed (loss: 1.6005043983459473, acc: 0.4955577552318573)
[2024-10-22 06:20:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:27][root][INFO] - Training Epoch: 1/2, step 583/7134 completed (loss: 1.5360370874404907, acc: 0.5245559215545654)
[2024-10-22 06:20:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:28][root][INFO] - Training Epoch: 1/2, step 584/7134 completed (loss: 1.521431803703308, acc: 0.5240848064422607)
[2024-10-22 06:20:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:28][root][INFO] - Training Epoch: 1/2, step 585/7134 completed (loss: 1.5143839120864868, acc: 0.5307692289352417)
[2024-10-22 06:20:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:29][root][INFO] - Training Epoch: 1/2, step 586/7134 completed (loss: 1.4572571516036987, acc: 0.5519013404846191)
[2024-10-22 06:20:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:30][root][INFO] - Training Epoch: 1/2, step 587/7134 completed (loss: 1.4246515035629272, acc: 0.5435222387313843)
[2024-10-22 06:20:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:30][root][INFO] - Training Epoch: 1/2, step 588/7134 completed (loss: 1.4859285354614258, acc: 0.5465995073318481)
[2024-10-22 06:20:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:31][root][INFO] - Training Epoch: 1/2, step 589/7134 completed (loss: 1.5362768173217773, acc: 0.5054282546043396)
[2024-10-22 06:20:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:32][root][INFO] - Training Epoch: 1/2, step 590/7134 completed (loss: 1.458443522453308, acc: 0.5476772785186768)
[2024-10-22 06:20:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:32][root][INFO] - Training Epoch: 1/2, step 591/7134 completed (loss: 1.470432162284851, acc: 0.538385808467865)
[2024-10-22 06:20:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:33][root][INFO] - Training Epoch: 1/2, step 592/7134 completed (loss: 1.4653271436691284, acc: 0.5404858589172363)
[2024-10-22 06:20:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:33][root][INFO] - Training Epoch: 1/2, step 593/7134 completed (loss: 1.4300822019577026, acc: 0.5486630797386169)
[2024-10-22 06:20:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:34][root][INFO] - Training Epoch: 1/2, step 594/7134 completed (loss: 1.4194048643112183, acc: 0.5708622336387634)
[2024-10-22 06:20:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:35][root][INFO] - Training Epoch: 1/2, step 595/7134 completed (loss: 1.4282807111740112, acc: 0.5402414202690125)
[2024-10-22 06:20:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:35][root][INFO] - Training Epoch: 1/2, step 596/7134 completed (loss: 1.4569984674453735, acc: 0.5494393706321716)
[2024-10-22 06:20:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:36][root][INFO] - Training Epoch: 1/2, step 597/7134 completed (loss: 1.4280177354812622, acc: 0.5338189601898193)
[2024-10-22 06:20:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:37][root][INFO] - Training Epoch: 1/2, step 598/7134 completed (loss: 1.4964008331298828, acc: 0.5309446454048157)
[2024-10-22 06:20:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:37][root][INFO] - Training Epoch: 1/2, step 599/7134 completed (loss: 1.3968979120254517, acc: 0.5603960156440735)
[2024-10-22 06:20:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:38][root][INFO] - Training Epoch: 1/2, step 600/7134 completed (loss: 1.459431767463684, acc: 0.5496183037757874)
[2024-10-22 06:20:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:39][root][INFO] - Training Epoch: 1/2, step 601/7134 completed (loss: 1.4482582807540894, acc: 0.5382096171379089)
[2024-10-22 06:20:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:39][root][INFO] - Training Epoch: 1/2, step 602/7134 completed (loss: 1.3877041339874268, acc: 0.5715579986572266)
[2024-10-22 06:20:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:40][root][INFO] - Training Epoch: 1/2, step 603/7134 completed (loss: 1.4443707466125488, acc: 0.5471311211585999)
[2024-10-22 06:20:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:40][root][INFO] - Training Epoch: 1/2, step 604/7134 completed (loss: 1.4654932022094727, acc: 0.5322391390800476)
[2024-10-22 06:20:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:41][root][INFO] - Training Epoch: 1/2, step 605/7134 completed (loss: 1.397993803024292, acc: 0.5616016387939453)
[2024-10-22 06:20:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:42][root][INFO] - Training Epoch: 1/2, step 606/7134 completed (loss: 1.4639439582824707, acc: 0.5401015281677246)
[2024-10-22 06:20:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:42][root][INFO] - Training Epoch: 1/2, step 607/7134 completed (loss: 1.4488872289657593, acc: 0.5447598099708557)
[2024-10-22 06:20:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:43][root][INFO] - Training Epoch: 1/2, step 608/7134 completed (loss: 1.3765026330947876, acc: 0.5480572581291199)
[2024-10-22 06:20:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:44][root][INFO] - Training Epoch: 1/2, step 609/7134 completed (loss: 1.5150556564331055, acc: 0.5186915993690491)
[2024-10-22 06:20:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:44][root][INFO] - Training Epoch: 1/2, step 610/7134 completed (loss: 1.4526069164276123, acc: 0.5454545617103577)
[2024-10-22 06:20:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:45][root][INFO] - Training Epoch: 1/2, step 611/7134 completed (loss: 1.4150879383087158, acc: 0.5626204013824463)
[2024-10-22 06:20:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:45][root][INFO] - Training Epoch: 1/2, step 612/7134 completed (loss: 1.4742481708526611, acc: 0.536430835723877)
[2024-10-22 06:20:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:46][root][INFO] - Training Epoch: 1/2, step 613/7134 completed (loss: 1.3826680183410645, acc: 0.5591798424720764)
[2024-10-22 06:20:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:47][root][INFO] - Training Epoch: 1/2, step 614/7134 completed (loss: 1.4293065071105957, acc: 0.5606468915939331)
[2024-10-22 06:20:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:47][root][INFO] - Training Epoch: 1/2, step 615/7134 completed (loss: 1.4158519506454468, acc: 0.5563241243362427)
[2024-10-22 06:20:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:48][root][INFO] - Training Epoch: 1/2, step 616/7134 completed (loss: 1.4039775133132935, acc: 0.5572587847709656)
[2024-10-22 06:20:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:49][root][INFO] - Training Epoch: 1/2, step 617/7134 completed (loss: 1.3283469676971436, acc: 0.5727272629737854)
[2024-10-22 06:20:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:49][root][INFO] - Training Epoch: 1/2, step 618/7134 completed (loss: 1.372117519378662, acc: 0.561965823173523)
[2024-10-22 06:20:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:50][root][INFO] - Training Epoch: 1/2, step 619/7134 completed (loss: 1.4734607934951782, acc: 0.5482314825057983)
[2024-10-22 06:20:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:50][root][INFO] - Training Epoch: 1/2, step 620/7134 completed (loss: 1.411948323249817, acc: 0.558080792427063)
[2024-10-22 06:20:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:51][root][INFO] - Training Epoch: 1/2, step 621/7134 completed (loss: 1.5171253681182861, acc: 0.5362318754196167)
[2024-10-22 06:20:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:52][root][INFO] - Training Epoch: 1/2, step 622/7134 completed (loss: 1.420697569847107, acc: 0.5349099040031433)
[2024-10-22 06:20:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:52][root][INFO] - Training Epoch: 1/2, step 623/7134 completed (loss: 1.3686144351959229, acc: 0.5995500683784485)
[2024-10-22 06:20:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:53][root][INFO] - Training Epoch: 1/2, step 624/7134 completed (loss: 1.4510914087295532, acc: 0.5520945191383362)
[2024-10-22 06:20:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:54][root][INFO] - Training Epoch: 1/2, step 625/7134 completed (loss: 1.4031428098678589, acc: 0.5511482357978821)
[2024-10-22 06:20:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:54][root][INFO] - Training Epoch: 1/2, step 626/7134 completed (loss: 1.5290167331695557, acc: 0.5332428812980652)
[2024-10-22 06:20:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:55][root][INFO] - Training Epoch: 1/2, step 627/7134 completed (loss: 1.4435510635375977, acc: 0.5374706983566284)
[2024-10-22 06:20:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:55][root][INFO] - Training Epoch: 1/2, step 628/7134 completed (loss: 1.5076192617416382, acc: 0.5442478060722351)
[2024-10-22 06:20:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:56][root][INFO] - Training Epoch: 1/2, step 629/7134 completed (loss: 1.4956748485565186, acc: 0.5272108912467957)
[2024-10-22 06:20:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:57][root][INFO] - Training Epoch: 1/2, step 630/7134 completed (loss: 1.523737907409668, acc: 0.5320715308189392)
[2024-10-22 06:20:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:57][root][INFO] - Training Epoch: 1/2, step 631/7134 completed (loss: 1.404198408126831, acc: 0.554736852645874)
[2024-10-22 06:20:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:58][root][INFO] - Training Epoch: 1/2, step 632/7134 completed (loss: 1.5475115776062012, acc: 0.5241830348968506)
[2024-10-22 06:20:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:58][root][INFO] - Training Epoch: 1/2, step 633/7134 completed (loss: 1.4716105461120605, acc: 0.5684695243835449)
[2024-10-22 06:20:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:20:59][root][INFO] - Training Epoch: 1/2, step 634/7134 completed (loss: 1.446295142173767, acc: 0.5531914830207825)
[2024-10-22 06:20:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:00][root][INFO] - Training Epoch: 1/2, step 635/7134 completed (loss: 1.4629265069961548, acc: 0.5529131889343262)
[2024-10-22 06:21:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:00][root][INFO] - Training Epoch: 1/2, step 636/7134 completed (loss: 1.4459019899368286, acc: 0.5515743494033813)
[2024-10-22 06:21:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:01][root][INFO] - Training Epoch: 1/2, step 637/7134 completed (loss: 1.3713138103485107, acc: 0.5800293684005737)
[2024-10-22 06:21:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:01][root][INFO] - Training Epoch: 1/2, step 638/7134 completed (loss: 1.4499183893203735, acc: 0.5428571701049805)
[2024-10-22 06:21:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:02][root][INFO] - Training Epoch: 1/2, step 639/7134 completed (loss: 1.3761146068572998, acc: 0.5718050003051758)
[2024-10-22 06:21:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:03][root][INFO] - Training Epoch: 1/2, step 640/7134 completed (loss: 1.451067328453064, acc: 0.5498575568199158)
[2024-10-22 06:21:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:03][root][INFO] - Training Epoch: 1/2, step 641/7134 completed (loss: 1.4021035432815552, acc: 0.5571808218955994)
[2024-10-22 06:21:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:04][root][INFO] - Training Epoch: 1/2, step 642/7134 completed (loss: 1.338456153869629, acc: 0.5699067711830139)
[2024-10-22 06:21:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:04][root][INFO] - Training Epoch: 1/2, step 643/7134 completed (loss: 1.398269534111023, acc: 0.5645161271095276)
[2024-10-22 06:21:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:05][root][INFO] - Training Epoch: 1/2, step 644/7134 completed (loss: 1.4145861864089966, acc: 0.560490071773529)
[2024-10-22 06:21:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:06][root][INFO] - Training Epoch: 1/2, step 645/7134 completed (loss: 1.4227575063705444, acc: 0.5396174788475037)
[2024-10-22 06:21:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:06][root][INFO] - Training Epoch: 1/2, step 646/7134 completed (loss: 1.4151623249053955, acc: 0.5350553393363953)
[2024-10-22 06:21:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:07][root][INFO] - Training Epoch: 1/2, step 647/7134 completed (loss: 1.3637946844100952, acc: 0.5818673968315125)
[2024-10-22 06:21:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:07][root][INFO] - Training Epoch: 1/2, step 648/7134 completed (loss: 1.6304609775543213, acc: 0.5107296109199524)
[2024-10-22 06:21:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:08][root][INFO] - Training Epoch: 1/2, step 649/7134 completed (loss: 1.476865530014038, acc: 0.5714285969734192)
[2024-10-22 06:21:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:09][root][INFO] - Training Epoch: 1/2, step 650/7134 completed (loss: 1.5423510074615479, acc: 0.5164557099342346)
[2024-10-22 06:21:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:09][root][INFO] - Training Epoch: 1/2, step 651/7134 completed (loss: 1.6494324207305908, acc: 0.5234568119049072)
[2024-10-22 06:21:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:10][root][INFO] - Training Epoch: 1/2, step 652/7134 completed (loss: 1.452813982963562, acc: 0.5440977215766907)
[2024-10-22 06:21:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:10][root][INFO] - Training Epoch: 1/2, step 653/7134 completed (loss: 1.4828269481658936, acc: 0.5563139915466309)
[2024-10-22 06:21:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:11][root][INFO] - Training Epoch: 1/2, step 654/7134 completed (loss: 1.4609612226486206, acc: 0.5347222089767456)
[2024-10-22 06:21:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:12][root][INFO] - Training Epoch: 1/2, step 655/7134 completed (loss: 1.4722528457641602, acc: 0.545597493648529)
[2024-10-22 06:21:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:12][root][INFO] - Training Epoch: 1/2, step 656/7134 completed (loss: 1.4298828840255737, acc: 0.5454545617103577)
[2024-10-22 06:21:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:13][root][INFO] - Training Epoch: 1/2, step 657/7134 completed (loss: 1.4353687763214111, acc: 0.5492228269577026)
[2024-10-22 06:21:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:13][root][INFO] - Training Epoch: 1/2, step 658/7134 completed (loss: 1.359514832496643, acc: 0.5718849897384644)
[2024-10-22 06:21:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:14][root][INFO] - Training Epoch: 1/2, step 659/7134 completed (loss: 1.3696879148483276, acc: 0.5780141949653625)
[2024-10-22 06:21:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:15][root][INFO] - Training Epoch: 1/2, step 660/7134 completed (loss: 1.5219954252243042, acc: 0.5495283007621765)
[2024-10-22 06:21:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:15][root][INFO] - Training Epoch: 1/2, step 661/7134 completed (loss: 1.4948458671569824, acc: 0.5312232971191406)
[2024-10-22 06:21:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:16][root][INFO] - Training Epoch: 1/2, step 662/7134 completed (loss: 1.4226418733596802, acc: 0.5581140518188477)
[2024-10-22 06:21:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:17][root][INFO] - Training Epoch: 1/2, step 663/7134 completed (loss: 1.4804328680038452, acc: 0.5431654453277588)
[2024-10-22 06:21:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:17][root][INFO] - Training Epoch: 1/2, step 664/7134 completed (loss: 1.3785845041275024, acc: 0.5664893388748169)
[2024-10-22 06:21:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:18][root][INFO] - Training Epoch: 1/2, step 665/7134 completed (loss: 1.443658709526062, acc: 0.5687974095344543)
[2024-10-22 06:21:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:19][root][INFO] - Training Epoch: 1/2, step 666/7134 completed (loss: 1.4394712448120117, acc: 0.5389754772186279)
[2024-10-22 06:21:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:19][root][INFO] - Training Epoch: 1/2, step 667/7134 completed (loss: 1.4331896305084229, acc: 0.5596221685409546)
[2024-10-22 06:21:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:20][root][INFO] - Training Epoch: 1/2, step 668/7134 completed (loss: 1.334836483001709, acc: 0.5763052105903625)
[2024-10-22 06:21:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:21][root][INFO] - Training Epoch: 1/2, step 669/7134 completed (loss: 1.359338641166687, acc: 0.5931108593940735)
[2024-10-22 06:21:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:21][root][INFO] - Training Epoch: 1/2, step 670/7134 completed (loss: 1.4763985872268677, acc: 0.5446950793266296)
[2024-10-22 06:21:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:22][root][INFO] - Training Epoch: 1/2, step 671/7134 completed (loss: 1.5218349695205688, acc: 0.5374677181243896)
[2024-10-22 06:21:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:23][root][INFO] - Training Epoch: 1/2, step 672/7134 completed (loss: 1.3527207374572754, acc: 0.5760478973388672)
[2024-10-22 06:21:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:23][root][INFO] - Training Epoch: 1/2, step 673/7134 completed (loss: 1.4619024991989136, acc: 0.5426587462425232)
[2024-10-22 06:21:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:24][root][INFO] - Training Epoch: 1/2, step 674/7134 completed (loss: 1.395256519317627, acc: 0.5745192170143127)
[2024-10-22 06:21:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:25][root][INFO] - Training Epoch: 1/2, step 675/7134 completed (loss: 1.3501383066177368, acc: 0.5747950673103333)
[2024-10-22 06:21:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:25][root][INFO] - Training Epoch: 1/2, step 676/7134 completed (loss: 1.3927215337753296, acc: 0.5787965655326843)
[2024-10-22 06:21:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:26][root][INFO] - Training Epoch: 1/2, step 677/7134 completed (loss: 1.3025685548782349, acc: 0.5875763893127441)
[2024-10-22 06:21:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:27][root][INFO] - Training Epoch: 1/2, step 678/7134 completed (loss: 1.3909130096435547, acc: 0.5795698761940002)
[2024-10-22 06:21:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:27][root][INFO] - Training Epoch: 1/2, step 679/7134 completed (loss: 1.4242558479309082, acc: 0.5663026571273804)
[2024-10-22 06:21:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:28][root][INFO] - Training Epoch: 1/2, step 680/7134 completed (loss: 1.3936916589736938, acc: 0.5599104166030884)
[2024-10-22 06:21:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:28][root][INFO] - Training Epoch: 1/2, step 681/7134 completed (loss: 1.3298230171203613, acc: 0.5694849491119385)
[2024-10-22 06:21:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:29][root][INFO] - Training Epoch: 1/2, step 682/7134 completed (loss: 1.3080953359603882, acc: 0.5864055156707764)
[2024-10-22 06:21:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:30][root][INFO] - Training Epoch: 1/2, step 683/7134 completed (loss: 1.4256671667099, acc: 0.5602678656578064)
[2024-10-22 06:21:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:30][root][INFO] - Training Epoch: 1/2, step 684/7134 completed (loss: 1.4782248735427856, acc: 0.5470383167266846)
[2024-10-22 06:21:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:31][root][INFO] - Training Epoch: 1/2, step 685/7134 completed (loss: 1.4498109817504883, acc: 0.5742971897125244)
[2024-10-22 06:21:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:32][root][INFO] - Training Epoch: 1/2, step 686/7134 completed (loss: 1.2860689163208008, acc: 0.5870967507362366)
[2024-10-22 06:21:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:32][root][INFO] - Training Epoch: 1/2, step 687/7134 completed (loss: 1.4735625982284546, acc: 0.5494505763053894)
[2024-10-22 06:21:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:33][root][INFO] - Training Epoch: 1/2, step 688/7134 completed (loss: 1.365888237953186, acc: 0.5760095119476318)
[2024-10-22 06:21:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:33][root][INFO] - Training Epoch: 1/2, step 689/7134 completed (loss: 1.3962562084197998, acc: 0.5897436141967773)
[2024-10-22 06:21:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:34][root][INFO] - Training Epoch: 1/2, step 690/7134 completed (loss: 1.4362714290618896, acc: 0.5690954923629761)
[2024-10-22 06:21:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:35][root][INFO] - Training Epoch: 1/2, step 691/7134 completed (loss: 1.5288060903549194, acc: 0.5249999761581421)
[2024-10-22 06:21:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:35][root][INFO] - Training Epoch: 1/2, step 692/7134 completed (loss: 1.467950463294983, acc: 0.5381355881690979)
[2024-10-22 06:21:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:36][root][INFO] - Training Epoch: 1/2, step 693/7134 completed (loss: 1.4484550952911377, acc: 0.5445292592048645)
[2024-10-22 06:21:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:36][root][INFO] - Training Epoch: 1/2, step 694/7134 completed (loss: 1.484635353088379, acc: 0.5514450669288635)
[2024-10-22 06:21:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:37][root][INFO] - Training Epoch: 1/2, step 695/7134 completed (loss: 1.545310616493225, acc: 0.5361527800559998)
[2024-10-22 06:21:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:38][root][INFO] - Training Epoch: 1/2, step 696/7134 completed (loss: 1.5107146501541138, acc: 0.5235602259635925)
[2024-10-22 06:21:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:38][root][INFO] - Training Epoch: 1/2, step 697/7134 completed (loss: 1.3843833208084106, acc: 0.5707364082336426)
[2024-10-22 06:21:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:39][root][INFO] - Training Epoch: 1/2, step 698/7134 completed (loss: 1.4746795892715454, acc: 0.5394737124443054)
[2024-10-22 06:21:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:40][root][INFO] - Training Epoch: 1/2, step 699/7134 completed (loss: 1.4806172847747803, acc: 0.5572139024734497)
[2024-10-22 06:21:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:40][root][INFO] - Training Epoch: 1/2, step 700/7134 completed (loss: 1.54104483127594, acc: 0.48430493474006653)
[2024-10-22 06:21:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:41][root][INFO] - Training Epoch: 1/2, step 701/7134 completed (loss: 1.5117547512054443, acc: 0.5384615659713745)
[2024-10-22 06:21:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:41][root][INFO] - Training Epoch: 1/2, step 702/7134 completed (loss: 1.4702445268630981, acc: 0.5514612197875977)
[2024-10-22 06:21:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:42][root][INFO] - Training Epoch: 1/2, step 703/7134 completed (loss: 1.4801133871078491, acc: 0.546875)
[2024-10-22 06:21:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:43][root][INFO] - Training Epoch: 1/2, step 704/7134 completed (loss: 1.4578020572662354, acc: 0.5548853874206543)
[2024-10-22 06:21:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:43][root][INFO] - Training Epoch: 1/2, step 705/7134 completed (loss: 1.4359807968139648, acc: 0.5590277910232544)
[2024-10-22 06:21:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:44][root][INFO] - Training Epoch: 1/2, step 706/7134 completed (loss: 1.327748417854309, acc: 0.5764604806900024)
[2024-10-22 06:21:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:45][root][INFO] - Training Epoch: 1/2, step 707/7134 completed (loss: 1.449152946472168, acc: 0.5420650243759155)
[2024-10-22 06:21:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:45][root][INFO] - Training Epoch: 1/2, step 708/7134 completed (loss: 1.3673372268676758, acc: 0.5796545147895813)
[2024-10-22 06:21:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:46][root][INFO] - Training Epoch: 1/2, step 709/7134 completed (loss: 1.3542895317077637, acc: 0.5832558274269104)
[2024-10-22 06:21:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:47][root][INFO] - Training Epoch: 1/2, step 710/7134 completed (loss: 1.35683012008667, acc: 0.5714285969734192)
[2024-10-22 06:21:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:47][root][INFO] - Training Epoch: 1/2, step 711/7134 completed (loss: 1.3052078485488892, acc: 0.5811966061592102)
[2024-10-22 06:21:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:48][root][INFO] - Training Epoch: 1/2, step 712/7134 completed (loss: 1.2955507040023804, acc: 0.5781853199005127)
[2024-10-22 06:21:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:48][root][INFO] - Training Epoch: 1/2, step 713/7134 completed (loss: 1.3493356704711914, acc: 0.5605095624923706)
[2024-10-22 06:21:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:49][root][INFO] - Training Epoch: 1/2, step 714/7134 completed (loss: 1.4561073780059814, acc: 0.560693621635437)
[2024-10-22 06:21:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:50][root][INFO] - Training Epoch: 1/2, step 715/7134 completed (loss: 1.3307218551635742, acc: 0.5746352672576904)
[2024-10-22 06:21:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:50][root][INFO] - Training Epoch: 1/2, step 716/7134 completed (loss: 1.3268414735794067, acc: 0.5831792950630188)
[2024-10-22 06:21:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:51][root][INFO] - Training Epoch: 1/2, step 717/7134 completed (loss: 1.3615301847457886, acc: 0.5720081329345703)
[2024-10-22 06:21:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:51][root][INFO] - Training Epoch: 1/2, step 718/7134 completed (loss: 1.334319829940796, acc: 0.5800203680992126)
[2024-10-22 06:21:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:52][root][INFO] - Training Epoch: 1/2, step 719/7134 completed (loss: 1.2733649015426636, acc: 0.5860655903816223)
[2024-10-22 06:21:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:53][root][INFO] - Training Epoch: 1/2, step 720/7134 completed (loss: 1.3503329753875732, acc: 0.5980099439620972)
[2024-10-22 06:21:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:53][root][INFO] - Training Epoch: 1/2, step 721/7134 completed (loss: 1.3565490245819092, acc: 0.5696465969085693)
[2024-10-22 06:21:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:54][root][INFO] - Training Epoch: 1/2, step 722/7134 completed (loss: 1.3860620260238647, acc: 0.5664793848991394)
[2024-10-22 06:21:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:55][root][INFO] - Training Epoch: 1/2, step 723/7134 completed (loss: 1.3820945024490356, acc: 0.568932056427002)
[2024-10-22 06:21:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:55][root][INFO] - Training Epoch: 1/2, step 724/7134 completed (loss: 1.3673170804977417, acc: 0.5804274678230286)
[2024-10-22 06:21:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:56][root][INFO] - Training Epoch: 1/2, step 725/7134 completed (loss: 1.2630661725997925, acc: 0.604651153087616)
[2024-10-22 06:21:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:56][root][INFO] - Training Epoch: 1/2, step 726/7134 completed (loss: 1.1902137994766235, acc: 0.6152125000953674)
[2024-10-22 06:21:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:57][root][INFO] - Training Epoch: 1/2, step 727/7134 completed (loss: 1.284647822380066, acc: 0.5939674973487854)
[2024-10-22 06:21:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:58][root][INFO] - Training Epoch: 1/2, step 728/7134 completed (loss: 1.313372015953064, acc: 0.58370041847229)
[2024-10-22 06:21:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:58][root][INFO] - Training Epoch: 1/2, step 729/7134 completed (loss: 1.3462697267532349, acc: 0.586980938911438)
[2024-10-22 06:21:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:21:59][root][INFO] - Training Epoch: 1/2, step 730/7134 completed (loss: 1.2869646549224854, acc: 0.5925925970077515)
[2024-10-22 06:21:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:00][root][INFO] - Training Epoch: 1/2, step 731/7134 completed (loss: 1.1535612344741821, acc: 0.626849889755249)
[2024-10-22 06:22:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:00][root][INFO] - Training Epoch: 1/2, step 732/7134 completed (loss: 1.5317306518554688, acc: 0.5187406539916992)
[2024-10-22 06:22:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:01][root][INFO] - Training Epoch: 1/2, step 733/7134 completed (loss: 1.413126826286316, acc: 0.5466101765632629)
[2024-10-22 06:22:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:01][root][INFO] - Training Epoch: 1/2, step 734/7134 completed (loss: 1.361055612564087, acc: 0.5521091818809509)
[2024-10-22 06:22:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:02][root][INFO] - Training Epoch: 1/2, step 735/7134 completed (loss: 1.3675252199172974, acc: 0.5734354853630066)
[2024-10-22 06:22:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:03][root][INFO] - Training Epoch: 1/2, step 736/7134 completed (loss: 1.3788070678710938, acc: 0.572898805141449)
[2024-10-22 06:22:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:03][root][INFO] - Training Epoch: 1/2, step 737/7134 completed (loss: 1.39487624168396, acc: 0.5853269696235657)
[2024-10-22 06:22:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:04][root][INFO] - Training Epoch: 1/2, step 738/7134 completed (loss: 1.4176008701324463, acc: 0.550632894039154)
[2024-10-22 06:22:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:04][root][INFO] - Training Epoch: 1/2, step 739/7134 completed (loss: 1.438549518585205, acc: 0.537010133266449)
[2024-10-22 06:22:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:05][root][INFO] - Training Epoch: 1/2, step 740/7134 completed (loss: 1.3628629446029663, acc: 0.5880861878395081)
[2024-10-22 06:22:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:05][root][INFO] - Training Epoch: 1/2, step 741/7134 completed (loss: 1.4077355861663818, acc: 0.552598237991333)
[2024-10-22 06:22:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:06][root][INFO] - Training Epoch: 1/2, step 742/7134 completed (loss: 1.2705743312835693, acc: 0.6077440977096558)
[2024-10-22 06:22:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:07][root][INFO] - Training Epoch: 1/2, step 743/7134 completed (loss: 1.2976431846618652, acc: 0.5761511325836182)
[2024-10-22 06:22:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:07][root][INFO] - Training Epoch: 1/2, step 744/7134 completed (loss: 1.3740636110305786, acc: 0.5585874915122986)
[2024-10-22 06:22:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:08][root][INFO] - Training Epoch: 1/2, step 745/7134 completed (loss: 1.306949496269226, acc: 0.6014235019683838)
[2024-10-22 06:22:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:08][root][INFO] - Training Epoch: 1/2, step 746/7134 completed (loss: 1.398776888847351, acc: 0.5673575401306152)
[2024-10-22 06:22:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:09][root][INFO] - Training Epoch: 1/2, step 747/7134 completed (loss: 1.411008596420288, acc: 0.5417218804359436)
[2024-10-22 06:22:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:10][root][INFO] - Training Epoch: 1/2, step 748/7134 completed (loss: 1.4162828922271729, acc: 0.5669856667518616)
[2024-10-22 06:22:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:10][root][INFO] - Training Epoch: 1/2, step 749/7134 completed (loss: 1.3693211078643799, acc: 0.5785877108573914)
[2024-10-22 06:22:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:11][root][INFO] - Training Epoch: 1/2, step 750/7134 completed (loss: 1.3132058382034302, acc: 0.5911681056022644)
[2024-10-22 06:22:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:12][root][INFO] - Training Epoch: 1/2, step 751/7134 completed (loss: 1.4537255764007568, acc: 0.528610348701477)
[2024-10-22 06:22:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:12][root][INFO] - Training Epoch: 1/2, step 752/7134 completed (loss: 1.4707832336425781, acc: 0.5529412031173706)
[2024-10-22 06:22:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:13][root][INFO] - Training Epoch: 1/2, step 753/7134 completed (loss: 1.4122971296310425, acc: 0.5591397881507874)
[2024-10-22 06:22:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:13][root][INFO] - Training Epoch: 1/2, step 754/7134 completed (loss: 1.2182663679122925, acc: 0.6291866302490234)
[2024-10-22 06:22:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:14][root][INFO] - Training Epoch: 1/2, step 755/7134 completed (loss: 1.2609314918518066, acc: 0.6185566782951355)
[2024-10-22 06:22:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:14][root][INFO] - Training Epoch: 1/2, step 756/7134 completed (loss: 1.322405219078064, acc: 0.6085672378540039)
[2024-10-22 06:22:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:15][root][INFO] - Training Epoch: 1/2, step 757/7134 completed (loss: 1.2898449897766113, acc: 0.6018518805503845)
[2024-10-22 06:22:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:16][root][INFO] - Training Epoch: 1/2, step 758/7134 completed (loss: 1.2958652973175049, acc: 0.5792349576950073)
[2024-10-22 06:22:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:16][root][INFO] - Training Epoch: 1/2, step 759/7134 completed (loss: 1.3561389446258545, acc: 0.5817901492118835)
[2024-10-22 06:22:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:17][root][INFO] - Training Epoch: 1/2, step 760/7134 completed (loss: 1.349897861480713, acc: 0.5809524059295654)
[2024-10-22 06:22:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:17][root][INFO] - Training Epoch: 1/2, step 761/7134 completed (loss: 1.467534065246582, acc: 0.5407407283782959)
[2024-10-22 06:22:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:18][root][INFO] - Training Epoch: 1/2, step 762/7134 completed (loss: 1.5295298099517822, acc: 0.5414908528327942)
[2024-10-22 06:22:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:18][root][INFO] - Training Epoch: 1/2, step 763/7134 completed (loss: 1.4263147115707397, acc: 0.5668380260467529)
[2024-10-22 06:22:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:19][root][INFO] - Training Epoch: 1/2, step 764/7134 completed (loss: 1.2843347787857056, acc: 0.5918827652931213)
[2024-10-22 06:22:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:20][root][INFO] - Training Epoch: 1/2, step 765/7134 completed (loss: 1.3093668222427368, acc: 0.5870588421821594)
[2024-10-22 06:22:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:20][root][INFO] - Training Epoch: 1/2, step 766/7134 completed (loss: 1.3475232124328613, acc: 0.5674418807029724)
[2024-10-22 06:22:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:21][root][INFO] - Training Epoch: 1/2, step 767/7134 completed (loss: 1.305769920349121, acc: 0.5849710702896118)
[2024-10-22 06:22:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:22][root][INFO] - Training Epoch: 1/2, step 768/7134 completed (loss: 1.393023133277893, acc: 0.5841694474220276)
[2024-10-22 06:22:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:22][root][INFO] - Training Epoch: 1/2, step 769/7134 completed (loss: 1.3235557079315186, acc: 0.581632673740387)
[2024-10-22 06:22:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:23][root][INFO] - Training Epoch: 1/2, step 770/7134 completed (loss: 1.4051754474639893, acc: 0.5756097435951233)
[2024-10-22 06:22:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:23][root][INFO] - Training Epoch: 1/2, step 771/7134 completed (loss: 1.4251171350479126, acc: 0.5718749761581421)
[2024-10-22 06:22:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:24][root][INFO] - Training Epoch: 1/2, step 772/7134 completed (loss: 1.442097544670105, acc: 0.5605858564376831)
[2024-10-22 06:22:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:24][root][INFO] - Training Epoch: 1/2, step 773/7134 completed (loss: 1.3001593351364136, acc: 0.5916666388511658)
[2024-10-22 06:22:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:25][root][INFO] - Training Epoch: 1/2, step 774/7134 completed (loss: 1.3404724597930908, acc: 0.5851351618766785)
[2024-10-22 06:22:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:26][root][INFO] - Training Epoch: 1/2, step 775/7134 completed (loss: 1.351570725440979, acc: 0.5732899308204651)
[2024-10-22 06:22:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:26][root][INFO] - Training Epoch: 1/2, step 776/7134 completed (loss: 1.238267183303833, acc: 0.6045130491256714)
[2024-10-22 06:22:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:27][root][INFO] - Training Epoch: 1/2, step 777/7134 completed (loss: 1.2659085988998413, acc: 0.5918367505073547)
[2024-10-22 06:22:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:27][root][INFO] - Training Epoch: 1/2, step 778/7134 completed (loss: 1.338085412979126, acc: 0.5841968655586243)
[2024-10-22 06:22:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:28][root][INFO] - Training Epoch: 1/2, step 779/7134 completed (loss: 1.3446470499038696, acc: 0.5702671408653259)
[2024-10-22 06:22:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:29][root][INFO] - Training Epoch: 1/2, step 780/7134 completed (loss: 1.4840571880340576, acc: 0.5329280495643616)
[2024-10-22 06:22:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:29][root][INFO] - Training Epoch: 1/2, step 781/7134 completed (loss: 1.3683881759643555, acc: 0.5655577182769775)
[2024-10-22 06:22:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:30][root][INFO] - Training Epoch: 1/2, step 782/7134 completed (loss: 1.4321343898773193, acc: 0.548638105392456)
[2024-10-22 06:22:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:31][root][INFO] - Training Epoch: 1/2, step 783/7134 completed (loss: 1.439208745956421, acc: 0.5659397840499878)
[2024-10-22 06:22:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:31][root][INFO] - Training Epoch: 1/2, step 784/7134 completed (loss: 1.2884694337844849, acc: 0.588686466217041)
[2024-10-22 06:22:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:32][root][INFO] - Training Epoch: 1/2, step 785/7134 completed (loss: 1.4695985317230225, acc: 0.5501354932785034)
[2024-10-22 06:22:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:32][root][INFO] - Training Epoch: 1/2, step 786/7134 completed (loss: 1.354963779449463, acc: 0.5632715821266174)
[2024-10-22 06:22:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:33][root][INFO] - Training Epoch: 1/2, step 787/7134 completed (loss: 1.3504140377044678, acc: 0.5720653533935547)
[2024-10-22 06:22:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:34][root][INFO] - Training Epoch: 1/2, step 788/7134 completed (loss: 1.318234920501709, acc: 0.5969447493553162)
[2024-10-22 06:22:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:34][root][INFO] - Training Epoch: 1/2, step 789/7134 completed (loss: 1.399019718170166, acc: 0.5866189002990723)
[2024-10-22 06:22:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:35][root][INFO] - Training Epoch: 1/2, step 790/7134 completed (loss: 1.3898212909698486, acc: 0.563829779624939)
[2024-10-22 06:22:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:35][root][INFO] - Training Epoch: 1/2, step 791/7134 completed (loss: 1.2821638584136963, acc: 0.5913312435150146)
[2024-10-22 06:22:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:36][root][INFO] - Training Epoch: 1/2, step 792/7134 completed (loss: 1.3340122699737549, acc: 0.5956678986549377)
[2024-10-22 06:22:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:36][root][INFO] - Training Epoch: 1/2, step 793/7134 completed (loss: 1.28250253200531, acc: 0.6071842312812805)
[2024-10-22 06:22:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:37][root][INFO] - Training Epoch: 1/2, step 794/7134 completed (loss: 1.2138869762420654, acc: 0.6238532066345215)
[2024-10-22 06:22:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:38][root][INFO] - Training Epoch: 1/2, step 795/7134 completed (loss: 1.4216561317443848, acc: 0.5742574334144592)
[2024-10-22 06:22:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:38][root][INFO] - Training Epoch: 1/2, step 796/7134 completed (loss: 1.3663599491119385, acc: 0.5948103666305542)
[2024-10-22 06:22:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:39][root][INFO] - Training Epoch: 1/2, step 797/7134 completed (loss: 1.2894781827926636, acc: 0.5909090638160706)
[2024-10-22 06:22:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:39][root][INFO] - Training Epoch: 1/2, step 798/7134 completed (loss: 1.1940897703170776, acc: 0.6196318864822388)
[2024-10-22 06:22:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:40][root][INFO] - Training Epoch: 1/2, step 799/7134 completed (loss: 1.2787187099456787, acc: 0.5904436707496643)
[2024-10-22 06:22:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:40][root][INFO] - Training Epoch: 1/2, step 800/7134 completed (loss: 1.367217779159546, acc: 0.5861027240753174)
[2024-10-22 06:22:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:41][root][INFO] - Training Epoch: 1/2, step 801/7134 completed (loss: 1.4141910076141357, acc: 0.5840597748756409)
[2024-10-22 06:22:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:42][root][INFO] - Training Epoch: 1/2, step 802/7134 completed (loss: 1.3830825090408325, acc: 0.5802781581878662)
[2024-10-22 06:22:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:42][root][INFO] - Training Epoch: 1/2, step 803/7134 completed (loss: 1.4302338361740112, acc: 0.5329428911209106)
[2024-10-22 06:22:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:43][root][INFO] - Training Epoch: 1/2, step 804/7134 completed (loss: 1.4723135232925415, acc: 0.5199999809265137)
[2024-10-22 06:22:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:43][root][INFO] - Training Epoch: 1/2, step 805/7134 completed (loss: 1.5216625928878784, acc: 0.5235294103622437)
[2024-10-22 06:22:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:44][root][INFO] - Training Epoch: 1/2, step 806/7134 completed (loss: 1.3561135530471802, acc: 0.5685840845108032)
[2024-10-22 06:22:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:45][root][INFO] - Training Epoch: 1/2, step 807/7134 completed (loss: 1.378475546836853, acc: 0.5753816962242126)
[2024-10-22 06:22:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:45][root][INFO] - Training Epoch: 1/2, step 808/7134 completed (loss: 1.3705847263336182, acc: 0.577545166015625)
[2024-10-22 06:22:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:46][root][INFO] - Training Epoch: 1/2, step 809/7134 completed (loss: 1.3723889589309692, acc: 0.5511627793312073)
[2024-10-22 06:22:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:46][root][INFO] - Training Epoch: 1/2, step 810/7134 completed (loss: 1.2820194959640503, acc: 0.5780590772628784)
[2024-10-22 06:22:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:47][root][INFO] - Training Epoch: 1/2, step 811/7134 completed (loss: 1.3414561748504639, acc: 0.584144651889801)
[2024-10-22 06:22:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:48][root][INFO] - Training Epoch: 1/2, step 812/7134 completed (loss: 1.3817087411880493, acc: 0.568431556224823)
[2024-10-22 06:22:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:48][root][INFO] - Training Epoch: 1/2, step 813/7134 completed (loss: 1.391526222229004, acc: 0.5757225155830383)
[2024-10-22 06:22:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:49][root][INFO] - Training Epoch: 1/2, step 814/7134 completed (loss: 1.3556150197982788, acc: 0.5698152184486389)
[2024-10-22 06:22:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:49][root][INFO] - Training Epoch: 1/2, step 815/7134 completed (loss: 1.2862329483032227, acc: 0.6031941175460815)
[2024-10-22 06:22:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:50][root][INFO] - Training Epoch: 1/2, step 816/7134 completed (loss: 1.423638105392456, acc: 0.5498652458190918)
[2024-10-22 06:22:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:51][root][INFO] - Training Epoch: 1/2, step 817/7134 completed (loss: 1.4151853322982788, acc: 0.5499276518821716)
[2024-10-22 06:22:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:51][root][INFO] - Training Epoch: 1/2, step 818/7134 completed (loss: 1.4225914478302002, acc: 0.5622435212135315)
[2024-10-22 06:22:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:52][root][INFO] - Training Epoch: 1/2, step 819/7134 completed (loss: 1.4546688795089722, acc: 0.5736433863639832)
[2024-10-22 06:22:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:53][root][INFO] - Training Epoch: 1/2, step 820/7134 completed (loss: 1.367092251777649, acc: 0.5742331147193909)
[2024-10-22 06:22:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:53][root][INFO] - Training Epoch: 1/2, step 821/7134 completed (loss: 1.3380385637283325, acc: 0.581270158290863)
[2024-10-22 06:22:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:54][root][INFO] - Training Epoch: 1/2, step 822/7134 completed (loss: 1.282709002494812, acc: 0.5990098714828491)
[2024-10-22 06:22:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:54][root][INFO] - Training Epoch: 1/2, step 823/7134 completed (loss: 1.3842670917510986, acc: 0.5555555820465088)
[2024-10-22 06:22:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:55][root][INFO] - Training Epoch: 1/2, step 824/7134 completed (loss: 1.5470170974731445, acc: 0.5129310488700867)
[2024-10-22 06:22:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:56][root][INFO] - Training Epoch: 1/2, step 825/7134 completed (loss: 1.4314203262329102, acc: 0.5492063760757446)
[2024-10-22 06:22:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:56][root][INFO] - Training Epoch: 1/2, step 826/7134 completed (loss: 1.3069359064102173, acc: 0.5886752009391785)
[2024-10-22 06:22:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:57][root][INFO] - Training Epoch: 1/2, step 827/7134 completed (loss: 1.462024211883545, acc: 0.5506792068481445)
[2024-10-22 06:22:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:58][root][INFO] - Training Epoch: 1/2, step 828/7134 completed (loss: 1.499508023262024, acc: 0.5282308459281921)
[2024-10-22 06:22:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:58][root][INFO] - Training Epoch: 1/2, step 829/7134 completed (loss: 1.4069830179214478, acc: 0.5735849142074585)
[2024-10-22 06:22:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:59][root][INFO] - Training Epoch: 1/2, step 830/7134 completed (loss: 1.3278001546859741, acc: 0.5680628418922424)
[2024-10-22 06:22:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:22:59][root][INFO] - Training Epoch: 1/2, step 831/7134 completed (loss: 1.2961610555648804, acc: 0.593406617641449)
[2024-10-22 06:23:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:00][root][INFO] - Training Epoch: 1/2, step 832/7134 completed (loss: 1.459392786026001, acc: 0.5482993125915527)
[2024-10-22 06:23:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:01][root][INFO] - Training Epoch: 1/2, step 833/7134 completed (loss: 1.3832805156707764, acc: 0.575419008731842)
[2024-10-22 06:23:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:01][root][INFO] - Training Epoch: 1/2, step 834/7134 completed (loss: 1.379891276359558, acc: 0.557823121547699)
[2024-10-22 06:23:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:02][root][INFO] - Training Epoch: 1/2, step 835/7134 completed (loss: 1.3673306703567505, acc: 0.5709534287452698)
[2024-10-22 06:23:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:03][root][INFO] - Training Epoch: 1/2, step 836/7134 completed (loss: 1.2722278833389282, acc: 0.6184331774711609)
[2024-10-22 06:23:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:03][root][INFO] - Training Epoch: 1/2, step 837/7134 completed (loss: 1.2722574472427368, acc: 0.598705530166626)
[2024-10-22 06:23:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:04][root][INFO] - Training Epoch: 1/2, step 838/7134 completed (loss: 1.3712084293365479, acc: 0.5678392052650452)
[2024-10-22 06:23:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:05][root][INFO] - Training Epoch: 1/2, step 839/7134 completed (loss: 1.307159662246704, acc: 0.5977229475975037)
[2024-10-22 06:23:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:05][root][INFO] - Training Epoch: 1/2, step 840/7134 completed (loss: 1.3516182899475098, acc: 0.5726969838142395)
[2024-10-22 06:23:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:06][root][INFO] - Training Epoch: 1/2, step 841/7134 completed (loss: 1.4947919845581055, acc: 0.5472127199172974)
[2024-10-22 06:23:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:06][root][INFO] - Training Epoch: 1/2, step 842/7134 completed (loss: 1.322348952293396, acc: 0.5963003039360046)
[2024-10-22 06:23:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:07][root][INFO] - Training Epoch: 1/2, step 843/7134 completed (loss: 1.3493038415908813, acc: 0.5913140177726746)
[2024-10-22 06:23:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:08][root][INFO] - Training Epoch: 1/2, step 844/7134 completed (loss: 1.3216562271118164, acc: 0.5965130925178528)
[2024-10-22 06:23:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:08][root][INFO] - Training Epoch: 1/2, step 845/7134 completed (loss: 1.3747082948684692, acc: 0.609375)
[2024-10-22 06:23:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:09][root][INFO] - Training Epoch: 1/2, step 846/7134 completed (loss: 1.3635550737380981, acc: 0.5819672346115112)
[2024-10-22 06:23:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:09][root][INFO] - Training Epoch: 1/2, step 847/7134 completed (loss: 1.4685972929000854, acc: 0.556690514087677)
[2024-10-22 06:23:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:10][root][INFO] - Training Epoch: 1/2, step 848/7134 completed (loss: 1.478916883468628, acc: 0.5404040217399597)
[2024-10-22 06:23:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:11][root][INFO] - Training Epoch: 1/2, step 849/7134 completed (loss: 1.4644396305084229, acc: 0.560546875)
[2024-10-22 06:23:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:11][root][INFO] - Training Epoch: 1/2, step 850/7134 completed (loss: 1.340649962425232, acc: 0.5933831334114075)
[2024-10-22 06:23:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:12][root][INFO] - Training Epoch: 1/2, step 851/7134 completed (loss: 1.3447970151901245, acc: 0.5724790096282959)
[2024-10-22 06:23:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:13][root][INFO] - Training Epoch: 1/2, step 852/7134 completed (loss: 1.2965328693389893, acc: 0.5982142686843872)
[2024-10-22 06:23:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:13][root][INFO] - Training Epoch: 1/2, step 853/7134 completed (loss: 1.3263235092163086, acc: 0.5861767530441284)
[2024-10-22 06:23:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:14][root][INFO] - Training Epoch: 1/2, step 854/7134 completed (loss: 1.3491610288619995, acc: 0.5594887137413025)
[2024-10-22 06:23:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:15][root][INFO] - Training Epoch: 1/2, step 855/7134 completed (loss: 1.329041838645935, acc: 0.5949485301971436)
[2024-10-22 06:23:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:15][root][INFO] - Training Epoch: 1/2, step 856/7134 completed (loss: 1.362937569618225, acc: 0.5895450115203857)
[2024-10-22 06:23:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:16][root][INFO] - Training Epoch: 1/2, step 857/7134 completed (loss: 1.3456422090530396, acc: 0.589411735534668)
[2024-10-22 06:23:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:16][root][INFO] - Training Epoch: 1/2, step 858/7134 completed (loss: 1.4025158882141113, acc: 0.5656862854957581)
[2024-10-22 06:23:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:17][root][INFO] - Training Epoch: 1/2, step 859/7134 completed (loss: 1.5354501008987427, acc: 0.5100095272064209)
[2024-10-22 06:23:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:18][root][INFO] - Training Epoch: 1/2, step 860/7134 completed (loss: 1.4434101581573486, acc: 0.5458248257637024)
[2024-10-22 06:23:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:18][root][INFO] - Training Epoch: 1/2, step 861/7134 completed (loss: 1.3896756172180176, acc: 0.569609522819519)
[2024-10-22 06:23:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:19][root][INFO] - Training Epoch: 1/2, step 862/7134 completed (loss: 1.4948465824127197, acc: 0.5499524474143982)
[2024-10-22 06:23:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:20][root][INFO] - Training Epoch: 1/2, step 863/7134 completed (loss: 1.4318358898162842, acc: 0.5493087768554688)
[2024-10-22 06:23:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:20][root][INFO] - Training Epoch: 1/2, step 864/7134 completed (loss: 1.4434491395950317, acc: 0.5368272066116333)
[2024-10-22 06:23:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:21][root][INFO] - Training Epoch: 1/2, step 865/7134 completed (loss: 1.4306328296661377, acc: 0.5718390941619873)
[2024-10-22 06:23:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:22][root][INFO] - Training Epoch: 1/2, step 866/7134 completed (loss: 1.5261528491973877, acc: 0.5052878856658936)
[2024-10-22 06:23:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:22][root][INFO] - Training Epoch: 1/2, step 867/7134 completed (loss: 1.5099787712097168, acc: 0.5059880018234253)
[2024-10-22 06:23:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:23][root][INFO] - Training Epoch: 1/2, step 868/7134 completed (loss: 1.4674086570739746, acc: 0.5416238307952881)
[2024-10-22 06:23:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:23][root][INFO] - Training Epoch: 1/2, step 869/7134 completed (loss: 1.5171489715576172, acc: 0.529411792755127)
[2024-10-22 06:23:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:24][root][INFO] - Training Epoch: 1/2, step 870/7134 completed (loss: 1.3359836339950562, acc: 0.5801937580108643)
[2024-10-22 06:23:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:25][root][INFO] - Training Epoch: 1/2, step 871/7134 completed (loss: 1.4392081499099731, acc: 0.5716162919998169)
[2024-10-22 06:23:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:25][root][INFO] - Training Epoch: 1/2, step 872/7134 completed (loss: 1.3216239213943481, acc: 0.5763975381851196)
[2024-10-22 06:23:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:26][root][INFO] - Training Epoch: 1/2, step 873/7134 completed (loss: 1.2524213790893555, acc: 0.594298243522644)
[2024-10-22 06:23:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:26][root][INFO] - Training Epoch: 1/2, step 874/7134 completed (loss: 1.3751132488250732, acc: 0.5596556067466736)
[2024-10-22 06:23:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:27][root][INFO] - Training Epoch: 1/2, step 875/7134 completed (loss: 1.3074733018875122, acc: 0.5785877108573914)
[2024-10-22 06:23:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:28][root][INFO] - Training Epoch: 1/2, step 876/7134 completed (loss: 1.2026180028915405, acc: 0.6255707740783691)
[2024-10-22 06:23:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:28][root][INFO] - Training Epoch: 1/2, step 877/7134 completed (loss: 1.3252859115600586, acc: 0.5764828324317932)
[2024-10-22 06:23:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:29][root][INFO] - Training Epoch: 1/2, step 878/7134 completed (loss: 1.4162033796310425, acc: 0.5588235259056091)
[2024-10-22 06:23:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:30][root][INFO] - Training Epoch: 1/2, step 879/7134 completed (loss: 1.3030942678451538, acc: 0.5861271619796753)
[2024-10-22 06:23:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:30][root][INFO] - Training Epoch: 1/2, step 880/7134 completed (loss: 1.300623893737793, acc: 0.5983981490135193)
[2024-10-22 06:23:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:31][root][INFO] - Training Epoch: 1/2, step 881/7134 completed (loss: 1.3980014324188232, acc: 0.5741626620292664)
[2024-10-22 06:23:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:31][root][INFO] - Training Epoch: 1/2, step 882/7134 completed (loss: 1.3743259906768799, acc: 0.5659574270248413)
[2024-10-22 06:23:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:32][root][INFO] - Training Epoch: 1/2, step 883/7134 completed (loss: 1.4989863634109497, acc: 0.5414634346961975)
[2024-10-22 06:23:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:32][root][INFO] - Training Epoch: 1/2, step 884/7134 completed (loss: 1.3981648683547974, acc: 0.5615550875663757)
[2024-10-22 06:23:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:33][root][INFO] - Training Epoch: 1/2, step 885/7134 completed (loss: 1.3327655792236328, acc: 0.5958904027938843)
[2024-10-22 06:23:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:34][root][INFO] - Training Epoch: 1/2, step 886/7134 completed (loss: 1.394187092781067, acc: 0.565625011920929)
[2024-10-22 06:23:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:34][root][INFO] - Training Epoch: 1/2, step 887/7134 completed (loss: 1.433410406112671, acc: 0.5593705177307129)
[2024-10-22 06:23:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:35][root][INFO] - Training Epoch: 1/2, step 888/7134 completed (loss: 1.356390357017517, acc: 0.569495677947998)
[2024-10-22 06:23:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:35][root][INFO] - Training Epoch: 1/2, step 889/7134 completed (loss: 1.4178268909454346, acc: 0.5428571701049805)
[2024-10-22 06:23:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:36][root][INFO] - Training Epoch: 1/2, step 890/7134 completed (loss: 1.4271467924118042, acc: 0.5683355927467346)
[2024-10-22 06:23:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:37][root][INFO] - Training Epoch: 1/2, step 891/7134 completed (loss: 1.331502914428711, acc: 0.5611353516578674)
[2024-10-22 06:23:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:37][root][INFO] - Training Epoch: 1/2, step 892/7134 completed (loss: 1.396681785583496, acc: 0.5507075190544128)
[2024-10-22 06:23:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:38][root][INFO] - Training Epoch: 1/2, step 893/7134 completed (loss: 1.3759384155273438, acc: 0.5600000023841858)
[2024-10-22 06:23:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:38][root][INFO] - Training Epoch: 1/2, step 894/7134 completed (loss: 1.3048126697540283, acc: 0.5980176329612732)
[2024-10-22 06:23:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:39][root][INFO] - Training Epoch: 1/2, step 895/7134 completed (loss: 1.2694847583770752, acc: 0.5976095795631409)
[2024-10-22 06:23:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:40][root][INFO] - Training Epoch: 1/2, step 896/7134 completed (loss: 1.355708122253418, acc: 0.589085042476654)
[2024-10-22 06:23:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:40][root][INFO] - Training Epoch: 1/2, step 897/7134 completed (loss: 1.3531103134155273, acc: 0.5775577425956726)
[2024-10-22 06:23:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:41][root][INFO] - Training Epoch: 1/2, step 898/7134 completed (loss: 1.4220309257507324, acc: 0.5509999990463257)
[2024-10-22 06:23:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:42][root][INFO] - Training Epoch: 1/2, step 899/7134 completed (loss: 1.4123337268829346, acc: 0.5616580247879028)
[2024-10-22 06:23:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:42][root][INFO] - Training Epoch: 1/2, step 900/7134 completed (loss: 1.4533442258834839, acc: 0.5357142686843872)
[2024-10-22 06:23:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:43][root][INFO] - Training Epoch: 1/2, step 901/7134 completed (loss: 1.427884578704834, acc: 0.5400213599205017)
[2024-10-22 06:23:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:43][root][INFO] - Training Epoch: 1/2, step 902/7134 completed (loss: 1.3320157527923584, acc: 0.583429217338562)
[2024-10-22 06:23:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:44][root][INFO] - Training Epoch: 1/2, step 903/7134 completed (loss: 1.3583004474639893, acc: 0.567276656627655)
[2024-10-22 06:23:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:45][root][INFO] - Training Epoch: 1/2, step 904/7134 completed (loss: 1.3437906503677368, acc: 0.582105278968811)
[2024-10-22 06:23:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:45][root][INFO] - Training Epoch: 1/2, step 905/7134 completed (loss: 1.2999356985092163, acc: 0.5962800979614258)
[2024-10-22 06:23:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:46][root][INFO] - Training Epoch: 1/2, step 906/7134 completed (loss: 1.3740702867507935, acc: 0.5620915293693542)
[2024-10-22 06:23:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:47][root][INFO] - Training Epoch: 1/2, step 907/7134 completed (loss: 1.3988887071609497, acc: 0.5441176295280457)
[2024-10-22 06:23:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:47][root][INFO] - Training Epoch: 1/2, step 908/7134 completed (loss: 1.393046498298645, acc: 0.5533472895622253)
[2024-10-22 06:23:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:48][root][INFO] - Training Epoch: 1/2, step 909/7134 completed (loss: 1.39985990524292, acc: 0.5823096036911011)
[2024-10-22 06:23:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:48][root][INFO] - Training Epoch: 1/2, step 910/7134 completed (loss: 1.4658596515655518, acc: 0.5471898317337036)
[2024-10-22 06:23:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:49][root][INFO] - Training Epoch: 1/2, step 911/7134 completed (loss: 1.434922456741333, acc: 0.5542986392974854)
[2024-10-22 06:23:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:50][root][INFO] - Training Epoch: 1/2, step 912/7134 completed (loss: 1.3417226076126099, acc: 0.5904095768928528)
[2024-10-22 06:23:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:50][root][INFO] - Training Epoch: 1/2, step 913/7134 completed (loss: 1.4292658567428589, acc: 0.556352436542511)
[2024-10-22 06:23:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:51][root][INFO] - Training Epoch: 1/2, step 914/7134 completed (loss: 1.3620964288711548, acc: 0.5653964877128601)
[2024-10-22 06:23:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:51][root][INFO] - Training Epoch: 1/2, step 915/7134 completed (loss: 1.4786614179611206, acc: 0.5554123520851135)
[2024-10-22 06:23:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:52][root][INFO] - Training Epoch: 1/2, step 916/7134 completed (loss: 1.3439314365386963, acc: 0.6016597747802734)
[2024-10-22 06:23:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:53][root][INFO] - Training Epoch: 1/2, step 917/7134 completed (loss: 1.369343638420105, acc: 0.5805288553237915)
[2024-10-22 06:23:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:53][root][INFO] - Training Epoch: 1/2, step 918/7134 completed (loss: 1.279179334640503, acc: 0.588739275932312)
[2024-10-22 06:23:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:54][root][INFO] - Training Epoch: 1/2, step 919/7134 completed (loss: 1.2808490991592407, acc: 0.6116279363632202)
[2024-10-22 06:23:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:54][root][INFO] - Training Epoch: 1/2, step 920/7134 completed (loss: 1.3482013940811157, acc: 0.5946248769760132)
[2024-10-22 06:23:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:55][root][INFO] - Training Epoch: 1/2, step 921/7134 completed (loss: 1.346451997756958, acc: 0.583065390586853)
[2024-10-22 06:23:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:56][root][INFO] - Training Epoch: 1/2, step 922/7134 completed (loss: 1.4194015264511108, acc: 0.5506666898727417)
[2024-10-22 06:23:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:56][root][INFO] - Training Epoch: 1/2, step 923/7134 completed (loss: 1.3637588024139404, acc: 0.5715800523757935)
[2024-10-22 06:23:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:57][root][INFO] - Training Epoch: 1/2, step 924/7134 completed (loss: 1.282701015472412, acc: 0.5818882584571838)
[2024-10-22 06:23:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:58][root][INFO] - Training Epoch: 1/2, step 925/7134 completed (loss: 1.3231406211853027, acc: 0.5949214100837708)
[2024-10-22 06:23:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:58][root][INFO] - Training Epoch: 1/2, step 926/7134 completed (loss: 1.310532569885254, acc: 0.5981873273849487)
[2024-10-22 06:23:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:23:59][root][INFO] - Training Epoch: 1/2, step 927/7134 completed (loss: 1.2583478689193726, acc: 0.6152832508087158)
[2024-10-22 06:23:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:00][root][INFO] - Training Epoch: 1/2, step 928/7134 completed (loss: 1.2955008745193481, acc: 0.587579607963562)
[2024-10-22 06:24:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:00][root][INFO] - Training Epoch: 1/2, step 929/7134 completed (loss: 1.2975547313690186, acc: 0.6104868650436401)
[2024-10-22 06:24:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:01][root][INFO] - Training Epoch: 1/2, step 930/7134 completed (loss: 1.324364423751831, acc: 0.6016393303871155)
[2024-10-22 06:24:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:01][root][INFO] - Training Epoch: 1/2, step 931/7134 completed (loss: 1.3210591077804565, acc: 0.596017062664032)
[2024-10-22 06:24:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:02][root][INFO] - Training Epoch: 1/2, step 932/7134 completed (loss: 1.3564976453781128, acc: 0.5819672346115112)
[2024-10-22 06:24:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:02][root][INFO] - Training Epoch: 1/2, step 933/7134 completed (loss: 1.4005776643753052, acc: 0.5730336904525757)
[2024-10-22 06:24:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:03][root][INFO] - Training Epoch: 1/2, step 934/7134 completed (loss: 1.3448437452316284, acc: 0.5771248936653137)
[2024-10-22 06:24:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:04][root][INFO] - Training Epoch: 1/2, step 935/7134 completed (loss: 1.3157566785812378, acc: 0.6007957458496094)
[2024-10-22 06:24:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:04][root][INFO] - Training Epoch: 1/2, step 936/7134 completed (loss: 1.335882544517517, acc: 0.5821529626846313)
[2024-10-22 06:24:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:05][root][INFO] - Training Epoch: 1/2, step 937/7134 completed (loss: 1.3344767093658447, acc: 0.5865921974182129)
[2024-10-22 06:24:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:05][root][INFO] - Training Epoch: 1/2, step 938/7134 completed (loss: 1.3112728595733643, acc: 0.6029748320579529)
[2024-10-22 06:24:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:06][root][INFO] - Training Epoch: 1/2, step 939/7134 completed (loss: 1.4194952249526978, acc: 0.5730478763580322)
[2024-10-22 06:24:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:07][root][INFO] - Training Epoch: 1/2, step 940/7134 completed (loss: 1.3571873903274536, acc: 0.5955967307090759)
[2024-10-22 06:24:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:07][root][INFO] - Training Epoch: 1/2, step 941/7134 completed (loss: 1.1894861459732056, acc: 0.6386463046073914)
[2024-10-22 06:24:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:08][root][INFO] - Training Epoch: 1/2, step 942/7134 completed (loss: 1.3235920667648315, acc: 0.5917646884918213)
[2024-10-22 06:24:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:09][root][INFO] - Training Epoch: 1/2, step 943/7134 completed (loss: 1.3057891130447388, acc: 0.6022031903266907)
[2024-10-22 06:24:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:09][root][INFO] - Training Epoch: 1/2, step 944/7134 completed (loss: 1.3596891164779663, acc: 0.5700483322143555)
[2024-10-22 06:24:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:10][root][INFO] - Training Epoch: 1/2, step 945/7134 completed (loss: 1.39443039894104, acc: 0.5857461094856262)
[2024-10-22 06:24:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:10][root][INFO] - Training Epoch: 1/2, step 946/7134 completed (loss: 1.3272076845169067, acc: 0.5969125032424927)
[2024-10-22 06:24:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:11][root][INFO] - Training Epoch: 1/2, step 947/7134 completed (loss: 1.316764235496521, acc: 0.5974576473236084)
[2024-10-22 06:24:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:11][root][INFO] - Training Epoch: 1/2, step 948/7134 completed (loss: 1.3224117755889893, acc: 0.5913621187210083)
[2024-10-22 06:24:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:12][root][INFO] - Training Epoch: 1/2, step 949/7134 completed (loss: 1.2880113124847412, acc: 0.6109215021133423)
[2024-10-22 06:24:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:13][root][INFO] - Training Epoch: 1/2, step 950/7134 completed (loss: 1.202849268913269, acc: 0.6265508532524109)
[2024-10-22 06:24:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:13][root][INFO] - Training Epoch: 1/2, step 951/7134 completed (loss: 1.2982689142227173, acc: 0.6077032685279846)
[2024-10-22 06:24:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:14][root][INFO] - Training Epoch: 1/2, step 952/7134 completed (loss: 1.4297130107879639, acc: 0.5644090175628662)
[2024-10-22 06:24:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:15][root][INFO] - Training Epoch: 1/2, step 953/7134 completed (loss: 1.4281418323516846, acc: 0.5762376189231873)
[2024-10-22 06:24:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:15][root][INFO] - Training Epoch: 1/2, step 954/7134 completed (loss: 1.367964744567871, acc: 0.5889281630516052)
[2024-10-22 06:24:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:16][root][INFO] - Training Epoch: 1/2, step 955/7134 completed (loss: 1.3676332235336304, acc: 0.584566593170166)
[2024-10-22 06:24:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:16][root][INFO] - Training Epoch: 1/2, step 956/7134 completed (loss: 1.4022220373153687, acc: 0.5615234375)
[2024-10-22 06:24:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:17][root][INFO] - Training Epoch: 1/2, step 957/7134 completed (loss: 1.2784217596054077, acc: 0.5996310114860535)
[2024-10-22 06:24:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:18][root][INFO] - Training Epoch: 1/2, step 958/7134 completed (loss: 1.4298958778381348, acc: 0.5658682584762573)
[2024-10-22 06:24:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:18][root][INFO] - Training Epoch: 1/2, step 959/7134 completed (loss: 1.4667072296142578, acc: 0.5435952544212341)
[2024-10-22 06:24:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:19][root][INFO] - Training Epoch: 1/2, step 960/7134 completed (loss: 1.4574759006500244, acc: 0.5540334582328796)
[2024-10-22 06:24:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:20][root][INFO] - Training Epoch: 1/2, step 961/7134 completed (loss: 1.3699724674224854, acc: 0.5618945360183716)
[2024-10-22 06:24:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:20][root][INFO] - Training Epoch: 1/2, step 962/7134 completed (loss: 1.3262919187545776, acc: 0.570165753364563)
[2024-10-22 06:24:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:21][root][INFO] - Training Epoch: 1/2, step 963/7134 completed (loss: 1.384835124015808, acc: 0.5584256052970886)
[2024-10-22 06:24:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:21][root][INFO] - Training Epoch: 1/2, step 964/7134 completed (loss: 1.4150371551513672, acc: 0.5657894611358643)
[2024-10-22 06:24:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:22][root][INFO] - Training Epoch: 1/2, step 965/7134 completed (loss: 1.3496688604354858, acc: 0.5807909369468689)
[2024-10-22 06:24:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:23][root][INFO] - Training Epoch: 1/2, step 966/7134 completed (loss: 1.2977575063705444, acc: 0.5788079500198364)
[2024-10-22 06:24:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:23][root][INFO] - Training Epoch: 1/2, step 967/7134 completed (loss: 1.3455555438995361, acc: 0.5899122953414917)
[2024-10-22 06:24:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:24][root][INFO] - Training Epoch: 1/2, step 968/7134 completed (loss: 1.385903000831604, acc: 0.5838709473609924)
[2024-10-22 06:24:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:24][root][INFO] - Training Epoch: 1/2, step 969/7134 completed (loss: 1.4412918090820312, acc: 0.5371498465538025)
[2024-10-22 06:24:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:25][root][INFO] - Training Epoch: 1/2, step 970/7134 completed (loss: 1.3364150524139404, acc: 0.5935084819793701)
[2024-10-22 06:24:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:26][root][INFO] - Training Epoch: 1/2, step 971/7134 completed (loss: 1.3937627077102661, acc: 0.5680000185966492)
[2024-10-22 06:24:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:26][root][INFO] - Training Epoch: 1/2, step 972/7134 completed (loss: 1.40626060962677, acc: 0.5544651746749878)
[2024-10-22 06:24:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:27][root][INFO] - Training Epoch: 1/2, step 973/7134 completed (loss: 1.3816453218460083, acc: 0.5817452073097229)
[2024-10-22 06:24:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:28][root][INFO] - Training Epoch: 1/2, step 974/7134 completed (loss: 1.3762353658676147, acc: 0.5734767317771912)
[2024-10-22 06:24:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:28][root][INFO] - Training Epoch: 1/2, step 975/7134 completed (loss: 1.4906271696090698, acc: 0.5555555820465088)
[2024-10-22 06:24:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:29][root][INFO] - Training Epoch: 1/2, step 976/7134 completed (loss: 1.3650927543640137, acc: 0.565432071685791)
[2024-10-22 06:24:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:29][root][INFO] - Training Epoch: 1/2, step 977/7134 completed (loss: 1.4328513145446777, acc: 0.5606641173362732)
[2024-10-22 06:24:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:30][root][INFO] - Training Epoch: 1/2, step 978/7134 completed (loss: 1.3177953958511353, acc: 0.5665071606636047)
[2024-10-22 06:24:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:31][root][INFO] - Training Epoch: 1/2, step 979/7134 completed (loss: 1.3598182201385498, acc: 0.5590128898620605)
[2024-10-22 06:24:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:31][root][INFO] - Training Epoch: 1/2, step 980/7134 completed (loss: 1.3644849061965942, acc: 0.5891625881195068)
[2024-10-22 06:24:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:32][root][INFO] - Training Epoch: 1/2, step 981/7134 completed (loss: 1.4675043821334839, acc: 0.53515625)
[2024-10-22 06:24:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:32][root][INFO] - Training Epoch: 1/2, step 982/7134 completed (loss: 1.3193224668502808, acc: 0.5830546021461487)
[2024-10-22 06:24:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:33][root][INFO] - Training Epoch: 1/2, step 983/7134 completed (loss: 1.3490337133407593, acc: 0.5670391321182251)
[2024-10-22 06:24:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:34][root][INFO] - Training Epoch: 1/2, step 984/7134 completed (loss: 1.2603940963745117, acc: 0.6087591052055359)
[2024-10-22 06:24:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:34][root][INFO] - Training Epoch: 1/2, step 985/7134 completed (loss: 1.2046006917953491, acc: 0.6315250992774963)
[2024-10-22 06:24:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:35][root][INFO] - Training Epoch: 1/2, step 986/7134 completed (loss: 1.2994638681411743, acc: 0.614689290523529)
[2024-10-22 06:24:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:35][root][INFO] - Training Epoch: 1/2, step 987/7134 completed (loss: 1.2485542297363281, acc: 0.6304348111152649)
[2024-10-22 06:24:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:36][root][INFO] - Training Epoch: 1/2, step 988/7134 completed (loss: 1.4608871936798096, acc: 0.5577777624130249)
[2024-10-22 06:24:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:37][root][INFO] - Training Epoch: 1/2, step 989/7134 completed (loss: 1.4448591470718384, acc: 0.5648351907730103)
[2024-10-22 06:24:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:37][root][INFO] - Training Epoch: 1/2, step 990/7134 completed (loss: 1.495914340019226, acc: 0.5600814819335938)
[2024-10-22 06:24:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:38][root][INFO] - Training Epoch: 1/2, step 991/7134 completed (loss: 1.507849931716919, acc: 0.5336721539497375)
[2024-10-22 06:24:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:39][root][INFO] - Training Epoch: 1/2, step 992/7134 completed (loss: 1.4509382247924805, acc: 0.5304622054100037)
[2024-10-22 06:24:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:39][root][INFO] - Training Epoch: 1/2, step 993/7134 completed (loss: 1.4798635244369507, acc: 0.5410053133964539)
[2024-10-22 06:24:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:40][root][INFO] - Training Epoch: 1/2, step 994/7134 completed (loss: 1.3808797597885132, acc: 0.5665748119354248)
[2024-10-22 06:24:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:40][root][INFO] - Training Epoch: 1/2, step 995/7134 completed (loss: 1.4377721548080444, acc: 0.5784190893173218)
[2024-10-22 06:24:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:41][root][INFO] - Training Epoch: 1/2, step 996/7134 completed (loss: 1.4547185897827148, acc: 0.5599547624588013)
[2024-10-22 06:24:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:42][root][INFO] - Training Epoch: 1/2, step 997/7134 completed (loss: 1.4339145421981812, acc: 0.554641604423523)
[2024-10-22 06:24:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:42][root][INFO] - Training Epoch: 1/2, step 998/7134 completed (loss: 1.3908815383911133, acc: 0.5560640692710876)
[2024-10-22 06:24:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:43][root][INFO] - Training Epoch: 1/2, step 999/7134 completed (loss: 1.391581416130066, acc: 0.5643274784088135)
[2024-10-22 06:24:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:24:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:25:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:26:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:27:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:28:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:29:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:49][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:50][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:51][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:52][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:53][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:54][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:55][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:56][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:57][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:58][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:30:59][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:00][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:01][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:02][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:03][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:04][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:05][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:06][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:07][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:08][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:09][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:10][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:11][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:12][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:13][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:14][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:15][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:16][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:17][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:18][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:19][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:20][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:21][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:22][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:23][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:24][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:25][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:26][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:27][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:28][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:29][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:30][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:31][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:32][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:33][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:34][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:35][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:36][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:37][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:38][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:39][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:40][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:41][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:42][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:43][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:44][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:45][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:46][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:47][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:48][slam_llm.models.slam_model][INFO] - modality encoder
[2024-10-22 06:31:49][slam_llm.models.slam_model][INFO] - modality encod