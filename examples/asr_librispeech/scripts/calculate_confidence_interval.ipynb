{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "ci_before = proportion_confint(errors_before, 3033, method='wilson')\n",
    "ci_after = proportion_confint(errors_after, 3033, method='wilson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean WER: 0.0500\n",
      "95% Confidence Interval: (0.0000, 0.1500)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from jiwer import wer\n",
    "\n",
    "def bootstrap_ci(data, num_bootstrap=1000, ci=95):\n",
    "    \"\"\"\n",
    "    Compute the confidence interval for the mean using bootstrap resampling.\n",
    "    \n",
    "    Parameters:\n",
    "        data (list or array): List of evaluation metric values (e.g., WER for each sample)\n",
    "        num_bootstrap (int): Number of bootstrap iterations (default: 1000)\n",
    "        ci (float): Confidence level percentage (default: 95 for a 95% CI)\n",
    "        \n",
    "    Returns:\n",
    "        lower_bound, upper_bound: Lower and upper bounds of the confidence interval.\n",
    "    \"\"\"\n",
    "    boot_means = []\n",
    "    n = len(data)\n",
    "    for _ in range(num_bootstrap):\n",
    "        sample = np.random.choice(data, size=n, replace=True)\n",
    "        boot_means.append(np.mean(sample))\n",
    "    lower_bound = np.percentile(boot_means, (100 - ci) / 2)\n",
    "    upper_bound = np.percentile(boot_means, 100 - (100 - ci) / 2)\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Example: ASR inference results (predictions) and ground truth transcripts\n",
    "predictions = [\n",
    "    \"this is a test sentence\",\n",
    "    \"another test sentence\",\n",
    "    \"hello world\",\n",
    "    \"speech recognition is challenging\",\n",
    "    \"openai chatgpt is great\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    \"this is test sentence\",\n",
    "    \"another test sentence\",\n",
    "    \"hello world\",\n",
    "    \"speech recognition is challenging\",\n",
    "    \"openai chatgpt is great\"\n",
    "]\n",
    "\n",
    "# Compute WER for each sample using jiwer\n",
    "wer_list = []\n",
    "for ref, hyp in zip(ground_truths, predictions):\n",
    "    error = wer(ref, hyp)\n",
    "    wer_list.append(error)\n",
    "\n",
    "mean_wer = np.mean(wer_list)\n",
    "ci_lower, ci_upper = bootstrap_ci(wer_list, num_bootstrap=10000, ci=95)\n",
    "\n",
    "print(f\"Mean WER: {mean_wer:.4f}\")\n",
    "print(f\"95% Confidence Interval: ({ci_lower:.4f}, {ci_upper:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 12.83 ± 40.98\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def calculate_confidence_interval(data, confidence_level=0.95):\n",
    "    # Calculate sample mean and standard deviation\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data, ddof=1)  # Use sample standard deviation\n",
    "    n = len(data)\n",
    "    \n",
    "    # Calculate standard error\n",
    "    standard_error = std_dev / np.sqrt(n)\n",
    "    \n",
    "    # Calculate t-distribution critical value\n",
    "    t_critical = stats.t.ppf((1 + confidence_level) / 2, df=n - 1)\n",
    "    \n",
    "    # Calculate margin of error\n",
    "    margin_of_error = t_critical * standard_error\n",
    "    \n",
    "    # Return mean and margin of error\n",
    "    return mean, margin_of_error\n",
    "\n",
    "# Input two experimental results\n",
    "data = [9.61, 16.06]  # Example data\n",
    "\n",
    "# Calculate 95% confidence interval\n",
    "mean, margin_of_error = calculate_confidence_interval(data)\n",
    "print(f\"Result: {mean:.2f} ± {margin_of_error:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
