Thu Jan 30 01:49:33 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla V100-SXM2-32GB           Off | 00000000:3B:00.0 Off |                    0 |
| N/A   36C    P0              55W / 300W |      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
/work/van-speech-nlp/jindaznb/slamenv/bin/python
task_flag: all
encoder_config: w2p-wavlm-dual
num_epochs: 2
batch_size_training: 2
train_data_folder: ami_ec
test_data_folder: ami_ec
use_peft: false
seed: 
llm_name: llama32_1b
debug: 
test_run: 
freeze_encoder: true
eval_ckpt: best
encoder_projector: linear
encoder_projector_ds_rate: 5
save_embedding: false
projector_transfer_learning: false
transfer_data_folder: 
----------
----------
Final identifier: ami_ec_wavlm_llama32_1b_dual_freeze_llm
No checkpoint found in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_ec_wavlm_llama32_1b_dual_freeze_llm
ckpt_folder: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_ec_wavlm_llama32_1b_dual_freeze_llm/
Resume epoch: 1
Resume step: 0
[2025-01-30 01:50:09][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 2, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 2, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_ec_wavlm_llama32_1b_dual_freeze_llm', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': False}
[2025-01-30 01:50:09][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-01-30 01:50:09][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'dual', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': 'w2v2', 'encoder2_dim': 1024, 'encoder2_path': 'vitouphy/wav2vec2-xls-r-300m-timit-phoneme', 'identifier': 'ami_ec_wavlm_llama32_1b_dual_freeze_llm'}
[2025-01-30 01:50:09][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'ami_ec_wavlm_llama32_1b_dual_freeze_llm', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2025-01-30_01-50-09.txt', 'log_interval': 5}
wandb: Currently logged in as: jindaz (jindaz-work). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log/wandb/run-20250130_015012-t9r7v2wn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ami_ec_wavlm_llama32_1b_dual_freeze_llm
wandb: ⭐️ View project at https://wandb.ai/jindaz-work/SLAM-LLM
wandb: 🚀 View run at https://wandb.ai/jindaz-work/SLAM-LLM/runs/t9r7v2wn
[2025-01-30 01:50:33][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.
  warnings.warn("torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.")
[2025-01-30 01:50:38][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-01-30 01:50:38][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-01-30 01:50:38][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-01-30 01:50:38][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-01-30 01:50:40][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-01-30 01:50:40][slam_llm.utils.train_utils][INFO] - --> w2v2 has 315.43872 Million params

[2025-01-30 01:50:40][slam_llm.utils.train_utils][INFO] - --> Module w2v2
[2025-01-30 01:50:40][slam_llm.utils.train_utils][INFO] - --> w2v2 has 0.0 Million params

[2025-01-30 01:50:48][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-01-30 01:50:48][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-01-30 01:50:48][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-01-30 01:50:48][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 0.0 Million params

[2025-01-30 01:50:48][slam_llm.utils.train_utils][INFO] - --> Module dual
[2025-01-30 01:50:48][slam_llm.utils.train_utils][INFO] - --> dual has 25.16992 Million params

[2025-01-30 01:50:48][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-01-30 01:50:48][slam_llm.utils.train_utils][INFO] - --> asr has 25.16992 Million params

[2025-01-30 01:50:52][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_ec/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_ec/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-01-30 01:50:55][root][INFO] - --> Training Set Length = 107898
[2025-01-30 01:50:55][root][INFO] - --> Validation Set Length = 8351
[2025-01-30 01:50:55][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2025-01-30 01:50:55][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(

Training Epoch: 1:   0%|[34m          [0m| 0/53949 [00:00<?, ?it/s]/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
[2025-01-30 01:50:58][slam_llm.models.slam_model][INFO] - modality encoderdualdualdualdual
Error executing job with overrides: ['++model_config.llm_name=llama32_1b', '++model_config.llm_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', '++model_config.llm_dim=2048', '++model_config.encoder_name=wavlm', '++model_config.normalize=true', '++dataset_config.normalize=true', '++model_config.encoder_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', '++model_config.encoder2_name=w2v2', '++model_config.encoder2_path=vitouphy/wav2vec2-xls-r-300m-timit-phoneme', '++model_config.encoder_dim=1024', '++model_config.encoder_projector=dual', '++model_config.encoder_projector_ds_rate=5', '++model_config.identifier=ami_ec_wavlm_llama32_1b_dual_linear_freeze_llm', '++dataset_config.dataset=speech_dataset', '++dataset_config.train_data_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_ec/train.jsonl', '++dataset_config.file=src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', '++dataset_config.val_data_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_ec/validation.jsonl', '++dataset_config.input_type=raw', '++train_config.model_name=asr', '++train_config.num_epochs=2', '++train_config.freeze_encoder=true', '++train_config.freeze_encoder2=true', '++train_config.freeze_llm=true', '++train_config.batching_strategy=custom', '++train_config.warmup_steps=1000', '++train_config.total_steps=100000', '++train_config.lr=1e-4', '++train_config.validation_interval=3000', '++train_config.batch_size_training=2', '++train_config.val_batch_size=2', '++train_config.num_workers_dataloader=1', '++train_config.output_dir=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_ec_wavlm_llama32_1b_dual_linear_freeze_llm', '++train_config.use_fp16=true', '++train_config.use_peft=false', '++train_config.resume_epoch=1', '++train_config.resume_step=0', '++log_config.use_wandb=true', '++log_config.wandb_exp_name=ami_ec_wavlm_llama32_1b_dual_linear_freeze_llm', '++dataset_config.input_type=raw']
Traceback (most recent call last):
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/examples/asr_librispeech/finetune_asr.py", line 56, in <module>
    main_hydra()
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/core/utils.py", line 261, in return_value
    raise self._return_value
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/core/utils.py", line 187, in run_job
    ret.return_value = task_function(task_cfg)
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/examples/asr_librispeech/finetune_asr.py", line 52, in main_hydra
    train(kwargs)
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/src/slam_llm/pipeline/finetune.py", line 271, in main
    results = train(
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/src/slam_llm/utils/train_utils.py", line 136, in train
    scaler.scale(loss).backward()
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
wandb: - 0.007 MB of 0.007 MB uploaded
wandb: \ 0.007 MB of 0.029 MB uploaded
wandb: | 0.029 MB of 0.029 MB uploaded
wandb: 
wandb: Run history:
wandb: train_inner/train_inner_accuracy ▁
wandb:     train_inner/train_inner_loss ▁
wandb: 
wandb: Run summary:dual
wandb: train_inner/train_inner_accuracy 0.4375
wandb:     train_inner/train_inner_loss 4.23766
wandb: 
wandb: 🚀 View run ami_ec_wavlm_llama32_1b_dual_linear_freeze_llm at: https://wandb.ai/jindaz-work/SLAM-LLM/runs/t9r7v2wn
wandb: ⭐️ View project at: https://wandb.ai/jindaz-work/SLAM-LLM
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./out/log/wandb_log/wandb/run-20250130_015012-t9r7v2wn/logsdual
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
No checkpoints with loss found. Selecting the checkpoint with the latest epoch and step.
Selected checkpoint with latest epoch and step: 
No checkpoint found in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_ec_wavlm_llama32_1b_dual_linear_freeze_llm
