/work/van-speech-nlp/jindaznb/slamenv/bin/python
task_flag: all
encoder_config: wavlm-mono
num_epochs: 2
batch_size_training: 1
train_data_folder: ami_ec
test_data_folder: ami_ec
use_peft: true
seed: 
llm_name: llama32_1b
debug: 
test_run: 
freeze_encoder: true
eval_ckpt: best
encoder_projector: linear
encoder_projector_ds_rate: 5
save_embedding: false
projector_transfer_learning: false
transfer_data_folder: 
----------
----------
Final identifier: ami_ec_wavlm_llama32_1b_linear_peft
No checkpoint found in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_ec_wavlm_llama32_1b_linear_peft
ckpt_folder: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_ec_wavlm_llama32_1b_linear_peft/
Resume epoch: 1
Resume step: 0
[2025-01-30 01:51:30][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 1, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 1, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_ec_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': False}
[2025-01-30 01:51:30][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-01-30 01:51:30][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'ami_ec_wavlm_llama32_1b_linear_peft'}
[2025-01-30 01:51:30][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'ami_ec_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2025-01-30_01-51-30.txt', 'log_interval': 5}
wandb: Currently logged in as: jindaz (jindaz-work). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log/wandb/run-20250130_015132-hektlxd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ami_ec_wavlm_llama32_1b_linear_peft
wandb: â­ï¸ View project at https://wandb.ai/jindaz-work/SLAM-LLM
wandb: ðŸš€ View run at https://wandb.ai/jindaz-work/SLAM-LLM/runs/hektlxd4
[2025-01-30 01:51:52][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.
  warnings.warn("torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.")
[2025-01-30 01:51:57][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-01-30 01:51:57][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-01-30 01:51:57][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-01-30 01:51:57][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-01-30 01:52:03][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-01-30 01:52:03][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-01-30 01:52:03][slam_llm.models.slam_model][INFO] - setup peft...
trainable params: 5,636,096 || all params: 1,241,450,496 || trainable%: 0.4539928106807088
[2025-01-30 01:52:03][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-01-30 01:52:03][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-01-30 01:52:04][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-01-30 01:52:04][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2025-01-30 01:52:04][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-01-30 01:52:04][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2025-01-30 01:52:06][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_ec/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_ec/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-01-30 01:52:09][root][INFO] - --> Training Set Length = 107898
[2025-01-30 01:52:09][root][INFO] - --> Validation Set Length = 8351
[2025-01-30 01:52:09][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2025-01-30 01:52:09][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 1:   0%|[34m          [0m| 0/107898 [00:00<?, ?it/s]/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
[2025-01-30 01:52:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 1/107898 [00:02<67:08:08,  2.24s/it][2025-01-30 01:52:12][root][INFO] - Training Epoch: 1/2, step 0/107898 completed (loss: 3.0186076164245605, acc: 0.5)
[2025-01-30 01:52:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 2/107898 [00:02<33:22:42,  1.11s/it][2025-01-30 01:52:12][root][INFO] - Training Epoch: 1/2, step 1/107898 completed (loss: 8.255044937133789, acc: 0.1666666716337204)
[2025-01-30 01:52:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 3/107898 [00:02<22:43:16,  1.32it/s][2025-01-30 01:52:12][root][INFO] - Training Epoch: 1/2, step 2/107898 completed (loss: 7.43020486831665, acc: 0.0)
[2025-01-30 01:52:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 4/107898 [00:03<19:17:15,  1.55it/s][2025-01-30 01:52:13][root][INFO] - Training Epoch: 1/2, step 3/107898 completed (loss: 2.5532708168029785, acc: 0.6666666865348816)
[2025-01-30 01:52:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 5/107898 [00:03<15:02:55,  1.99it/s][2025-01-30 01:52:13][root][INFO] - Training Epoch: 1/2, step 4/107898 completed (loss: 10.002933502197266, acc: 0.0)
[2025-01-30 01:52:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 6/107898 [00:03<13:25:29,  2.23it/s][2025-01-30 01:52:13][root][INFO] - Training Epoch: 1/2, step 5/107898 completed (loss: 6.788373947143555, acc: 0.0)
[2025-01-30 01:52:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 7/107898 [00:04<12:28:38,  2.40it/s][2025-01-30 01:52:14][root][INFO] - Training Epoch: 1/2, step 6/107898 completed (loss: 3.8484482765197754, acc: 0.4000000059604645)
[2025-01-30 01:52:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 8/107898 [00:04<12:09:37,  2.46it/s][2025-01-30 01:52:14][root][INFO] - Training Epoch: 1/2, step 7/107898 completed (loss: 2.805820941925049, acc: 0.7037037014961243)
[2025-01-30 01:52:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 9/107898 [00:05<11:31:57,  2.60it/s][2025-01-30 01:52:14][root][INFO] - Training Epoch: 1/2, step 8/107898 completed (loss: 1.6534172296524048, acc: 0.7407407164573669)
[2025-01-30 01:52:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 10/107898 [00:05<11:00:22,  2.72it/s][2025-01-30 01:52:15][root][INFO] - Training Epoch: 1/2, step 9/107898 completed (loss: 1.8160206079483032, acc: 0.7200000286102295)
[2025-01-30 01:52:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 11/107898 [00:05<11:03:51,  2.71it/s][2025-01-30 01:52:15][root][INFO] - Training Epoch: 1/2, step 10/107898 completed (loss: 3.3079497814178467, acc: 0.5)
[2025-01-30 01:52:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 12/107898 [00:06<10:42:56,  2.80it/s][2025-01-30 01:52:15][root][INFO] - Training Epoch: 1/2, step 11/107898 completed (loss: 2.276681900024414, acc: 0.5789473652839661)
[2025-01-30 01:52:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 13/107898 [00:06<10:51:17,  2.76it/s][2025-01-30 01:52:16][root][INFO] - Training Epoch: 1/2, step 12/107898 completed (loss: 2.252293348312378, acc: 0.8181818127632141)
[2025-01-30 01:52:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 14/107898 [00:06<10:20:34,  2.90it/s][2025-01-30 01:52:16][root][INFO] - Training Epoch: 1/2, step 13/107898 completed (loss: 4.958630084991455, acc: 0.2857142984867096)
[2025-01-30 01:52:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 15/107898 [00:07<10:23:32,  2.88it/s][2025-01-30 01:52:16][root][INFO] - Training Epoch: 1/2, step 14/107898 completed (loss: 2.3587512969970703, acc: 0.529411792755127)
[2025-01-30 01:52:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 16/107898 [00:07<9:47:56,  3.06it/s] [2025-01-30 01:52:17][root][INFO] - Training Epoch: 1/2, step 15/107898 completed (loss: 1.4132626056671143, acc: 0.7333333492279053)
[2025-01-30 01:52:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 17/107898 [00:07<9:43:54,  3.08it/s][2025-01-30 01:52:17][root][INFO] - Training Epoch: 1/2, step 16/107898 completed (loss: 2.087310314178467, acc: 0.7333333492279053)
[2025-01-30 01:52:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 18/107898 [00:08<9:50:59,  3.04it/s][2025-01-30 01:52:17][root][INFO] - Training Epoch: 1/2, step 17/107898 completed (loss: 3.7954108715057373, acc: 0.5)
[2025-01-30 01:52:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 19/107898 [00:08<9:48:28,  3.06it/s][2025-01-30 01:52:18][root][INFO] - Training Epoch: 1/2, step 18/107898 completed (loss: 7.909713268280029, acc: 0.0)
[2025-01-30 01:52:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 20/107898 [00:08<9:40:49,  3.10it/s][2025-01-30 01:52:18][root][INFO] - Training Epoch: 1/2, step 19/107898 completed (loss: 2.6467161178588867, acc: 0.6666666865348816)
[2025-01-30 01:52:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 21/107898 [00:09<9:45:51,  3.07it/s][2025-01-30 01:52:18][root][INFO] - Training Epoch: 1/2, step 20/107898 completed (loss: 2.807607650756836, acc: 0.6000000238418579)
[2025-01-30 01:52:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 22/107898 [00:09<9:47:04,  3.06it/s][2025-01-30 01:52:19][root][INFO] - Training Epoch: 1/2, step 21/107898 completed (loss: 4.0252885818481445, acc: 0.5)
[2025-01-30 01:52:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 23/107898 [00:09<10:01:57,  2.99it/s][2025-01-30 01:52:19][root][INFO] - Training Epoch: 1/2, step 22/107898 completed (loss: 3.0470290184020996, acc: 0.6000000238418579)
[2025-01-30 01:52:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 24/107898 [00:09<9:47:44,  3.06it/s] [2025-01-30 01:52:19][root][INFO] - Training Epoch: 1/2, step 23/107898 completed (loss: 8.832015037536621, acc: 0.0)
[2025-01-30 01:52:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 25/107898 [00:10<9:56:11,  3.02it/s][2025-01-30 01:52:20][root][INFO] - Training Epoch: 1/2, step 24/107898 completed (loss: 2.8657631874084473, acc: 0.529411792755127)
[2025-01-30 01:52:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 26/107898 [00:10<11:28:05,  2.61it/s][2025-01-30 01:52:20][root][INFO] - Training Epoch: 1/2, step 25/107898 completed (loss: 5.788084030151367, acc: 0.0)
[2025-01-30 01:52:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 27/107898 [00:11<11:31:25,  2.60it/s][2025-01-30 01:52:21][root][INFO] - Training Epoch: 1/2, step 26/107898 completed (loss: 5.3232421875, acc: 0.0)
[2025-01-30 01:52:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 28/107898 [00:11<11:16:22,  2.66it/s][2025-01-30 01:52:21][root][INFO] - Training Epoch: 1/2, step 27/107898 completed (loss: 7.7739081382751465, acc: 0.0)
[2025-01-30 01:52:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 29/107898 [00:11<10:50:11,  2.77it/s][2025-01-30 01:52:21][root][INFO] - Training Epoch: 1/2, step 28/107898 completed (loss: 4.042644500732422, acc: 0.3333333432674408)
[2025-01-30 01:52:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 30/107898 [00:12<10:47:01,  2.78it/s][2025-01-30 01:52:22][root][INFO] - Training Epoch: 1/2, step 29/107898 completed (loss: 2.0394368171691895, acc: 0.6000000238418579)
[2025-01-30 01:52:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 31/107898 [00:12<10:32:09,  2.84it/s][2025-01-30 01:52:22][root][INFO] - Training Epoch: 1/2, step 30/107898 completed (loss: 2.173410177230835, acc: 0.7272727489471436)
[2025-01-30 01:52:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 32/107898 [00:12<10:18:33,  2.91it/s][2025-01-30 01:52:22][root][INFO] - Training Epoch: 1/2, step 31/107898 completed (loss: 3.444577693939209, acc: 0.4000000059604645)
[2025-01-30 01:52:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 33/107898 [00:13<10:02:07,  2.99it/s][2025-01-30 01:52:23][root][INFO] - Training Epoch: 1/2, step 32/107898 completed (loss: 2.3710520267486572, acc: 0.6521739363670349)
[2025-01-30 01:52:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 34/107898 [00:13<10:01:01,  2.99it/s][2025-01-30 01:52:23][root][INFO] - Training Epoch: 1/2, step 33/107898 completed (loss: 6.685047149658203, acc: 0.25)
[2025-01-30 01:52:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 35/107898 [00:13<10:42:22,  2.80it/s][2025-01-30 01:52:23][root][INFO] - Training Epoch: 1/2, step 34/107898 completed (loss: 4.122760772705078, acc: 0.20000000298023224)
[2025-01-30 01:52:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 36/107898 [00:14<10:40:23,  2.81it/s][2025-01-30 01:52:24][root][INFO] - Training Epoch: 1/2, step 35/107898 completed (loss: 6.247374534606934, acc: 0.20000000298023224)
[2025-01-30 01:52:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 37/107898 [00:14<10:27:14,  2.87it/s][2025-01-30 01:52:24][root][INFO] - Training Epoch: 1/2, step 36/107898 completed (loss: 2.2213430404663086, acc: 0.4545454680919647)
[2025-01-30 01:52:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 38/107898 [00:15<10:19:30,  2.90it/s][2025-01-30 01:52:24][root][INFO] - Training Epoch: 1/2, step 37/107898 completed (loss: 2.7355594635009766, acc: 0.5)
[2025-01-30 01:52:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 39/107898 [00:15<10:19:26,  2.90it/s][2025-01-30 01:52:25][root][INFO] - Training Epoch: 1/2, step 38/107898 completed (loss: 1.7239131927490234, acc: 0.6153846383094788)
[2025-01-30 01:52:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 40/107898 [00:15<10:42:17,  2.80it/s][2025-01-30 01:52:25][root][INFO] - Training Epoch: 1/2, step 39/107898 completed (loss: 9.644201278686523, acc: 0.0)
[2025-01-30 01:52:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 41/107898 [00:16<10:24:07,  2.88it/s][2025-01-30 01:52:25][root][INFO] - Training Epoch: 1/2, step 40/107898 completed (loss: 5.915209770202637, acc: 0.0)
[2025-01-30 01:52:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 42/107898 [00:16<10:17:31,  2.91it/s][2025-01-30 01:52:26][root][INFO] - Training Epoch: 1/2, step 41/107898 completed (loss: 10.782958984375, acc: 0.0)
[2025-01-30 01:52:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 43/107898 [00:16<10:19:12,  2.90it/s][2025-01-30 01:52:26][root][INFO] - Training Epoch: 1/2, step 42/107898 completed (loss: 1.6834990978240967, acc: 0.5882353186607361)
[2025-01-30 01:52:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 44/107898 [00:17<10:26:05,  2.87it/s][2025-01-30 01:52:26][root][INFO] - Training Epoch: 1/2, step 43/107898 completed (loss: 8.100184440612793, acc: 0.0)
[2025-01-30 01:52:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 45/107898 [00:17<10:02:34,  2.98it/s][2025-01-30 01:52:27][root][INFO] - Training Epoch: 1/2, step 44/107898 completed (loss: 4.791460990905762, acc: 0.4000000059604645)
[2025-01-30 01:52:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 46/107898 [00:17<9:57:07,  3.01it/s] [2025-01-30 01:52:27][root][INFO] - Training Epoch: 1/2, step 45/107898 completed (loss: 2.0106427669525146, acc: 0.7272727489471436)
[2025-01-30 01:52:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 47/107898 [00:18<9:54:28,  3.02it/s][2025-01-30 01:52:27][root][INFO] - Training Epoch: 1/2, step 46/107898 completed (loss: 2.836700677871704, acc: 0.6363636255264282)
[2025-01-30 01:52:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 48/107898 [00:18<9:40:56,  3.09it/s][2025-01-30 01:52:28][root][INFO] - Training Epoch: 1/2, step 47/107898 completed (loss: 9.251535415649414, acc: 0.0)
[2025-01-30 01:52:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 49/107898 [00:18<9:25:38,  3.18it/s][2025-01-30 01:52:28][root][INFO] - Training Epoch: 1/2, step 48/107898 completed (loss: 2.4404189586639404, acc: 0.6764705777168274)
[2025-01-30 01:52:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 50/107898 [00:18<9:27:49,  3.17it/s][2025-01-30 01:52:28][root][INFO] - Training Epoch: 1/2, step 49/107898 completed (loss: 1.477877140045166, acc: 0.7272727489471436)
[2025-01-30 01:52:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 51/107898 [00:19<10:15:04,  2.92it/s][2025-01-30 01:52:29][root][INFO] - Training Epoch: 1/2, step 50/107898 completed (loss: 4.742873668670654, acc: 0.42105263471603394)
[2025-01-30 01:52:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 52/107898 [00:19<10:03:52,  2.98it/s][2025-01-30 01:52:29][root][INFO] - Training Epoch: 1/2, step 51/107898 completed (loss: 7.859074115753174, acc: 0.0)
[2025-01-30 01:52:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 53/107898 [00:20<9:56:39,  3.01it/s] [2025-01-30 01:52:29][root][INFO] - Training Epoch: 1/2, step 52/107898 completed (loss: 3.16782546043396, acc: 0.4166666567325592)
[2025-01-30 01:52:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 54/107898 [00:20<10:01:48,  2.99it/s][2025-01-30 01:52:30][root][INFO] - Training Epoch: 1/2, step 53/107898 completed (loss: 2.937830924987793, acc: 0.5588235259056091)
[2025-01-30 01:52:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 55/107898 [00:20<10:09:01,  2.95it/s][2025-01-30 01:52:30][root][INFO] - Training Epoch: 1/2, step 54/107898 completed (loss: 3.5007054805755615, acc: 0.5454545617103577)
[2025-01-30 01:52:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 56/107898 [00:21<10:18:34,  2.91it/s][2025-01-30 01:52:30][root][INFO] - Training Epoch: 1/2, step 55/107898 completed (loss: 2.108935594558716, acc: 0.4285714328289032)
[2025-01-30 01:52:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 57/107898 [00:21<10:08:08,  2.96it/s][2025-01-30 01:52:31][root][INFO] - Training Epoch: 1/2, step 56/107898 completed (loss: 2.180359125137329, acc: 0.5)
[2025-01-30 01:52:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 58/107898 [00:21<10:06:36,  2.96it/s][2025-01-30 01:52:31][root][INFO] - Training Epoch: 1/2, step 57/107898 completed (loss: 1.141207218170166, acc: 0.625)
[2025-01-30 01:52:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 59/107898 [00:22<10:19:34,  2.90it/s][2025-01-30 01:52:31][root][INFO] - Training Epoch: 1/2, step 58/107898 completed (loss: 2.6395761966705322, acc: 0.692307710647583)
[2025-01-30 01:52:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 60/107898 [00:22<9:47:44,  3.06it/s] [2025-01-30 01:52:32][root][INFO] - Training Epoch: 1/2, step 59/107898 completed (loss: 7.253211498260498, acc: 0.0)
[2025-01-30 01:52:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 61/107898 [00:22<9:43:27,  3.08it/s][2025-01-30 01:52:32][root][INFO] - Training Epoch: 1/2, step 60/107898 completed (loss: 4.887439250946045, acc: 0.25)
[2025-01-30 01:52:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 62/107898 [00:23<9:44:00,  3.08it/s][2025-01-30 01:52:32][root][INFO] - Training Epoch: 1/2, step 61/107898 completed (loss: 3.03115177154541, acc: 0.5333333611488342)
[2025-01-30 01:52:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 63/107898 [00:23<9:45:49,  3.07it/s][2025-01-30 01:52:33][root][INFO] - Training Epoch: 1/2, step 62/107898 completed (loss: 1.5202507972717285, acc: 0.8181818127632141)
[2025-01-30 01:52:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 64/107898 [00:23<9:55:31,  3.02it/s][2025-01-30 01:52:33][root][INFO] - Training Epoch: 1/2, step 63/107898 completed (loss: 8.252882957458496, acc: 0.0)
[2025-01-30 01:52:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 65/107898 [00:24<9:53:25,  3.03it/s][2025-01-30 01:52:33][root][INFO] - Training Epoch: 1/2, step 64/107898 completed (loss: 4.414432525634766, acc: 0.4000000059604645)
[2025-01-30 01:52:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 66/107898 [00:24<10:07:38,  2.96it/s][2025-01-30 01:52:34][root][INFO] - Training Epoch: 1/2, step 65/107898 completed (loss: 2.4590578079223633, acc: 0.6666666865348816)
[2025-01-30 01:52:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 67/107898 [00:24<10:08:18,  2.95it/s][2025-01-30 01:52:34][root][INFO] - Training Epoch: 1/2, step 66/107898 completed (loss: 3.2245118618011475, acc: 0.3636363744735718)
[2025-01-30 01:52:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 68/107898 [00:25<10:14:14,  2.93it/s][2025-01-30 01:52:34][root][INFO] - Training Epoch: 1/2, step 67/107898 completed (loss: 0.8891868591308594, acc: 0.8260869383811951)
[2025-01-30 01:52:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 69/107898 [00:25<10:53:17,  2.75it/s][2025-01-30 01:52:35][root][INFO] - Training Epoch: 1/2, step 68/107898 completed (loss: 3.2960832118988037, acc: 0.5)
[2025-01-30 01:52:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 70/107898 [00:25<11:06:24,  2.70it/s][2025-01-30 01:52:35][root][INFO] - Training Epoch: 1/2, step 69/107898 completed (loss: 1.0440107583999634, acc: 0.8387096524238586)
[2025-01-30 01:52:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 71/107898 [00:26<10:44:57,  2.79it/s][2025-01-30 01:52:35][root][INFO] - Training Epoch: 1/2, step 70/107898 completed (loss: 2.099743604660034, acc: 0.6071428656578064)
[2025-01-30 01:52:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 72/107898 [00:26<10:04:17,  2.97it/s][2025-01-30 01:52:36][root][INFO] - Training Epoch: 1/2, step 71/107898 completed (loss: 5.170403003692627, acc: 0.0)
[2025-01-30 01:52:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 73/107898 [00:26<9:46:20,  3.06it/s] [2025-01-30 01:52:36][root][INFO] - Training Epoch: 1/2, step 72/107898 completed (loss: 1.455842137336731, acc: 0.8333333134651184)
[2025-01-30 01:52:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 74/107898 [00:27<10:05:15,  2.97it/s][2025-01-30 01:52:36][root][INFO] - Training Epoch: 1/2, step 73/107898 completed (loss: 3.272825002670288, acc: 0.3333333432674408)
[2025-01-30 01:52:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 75/107898 [00:27<10:15:18,  2.92it/s][2025-01-30 01:52:37][root][INFO] - Training Epoch: 1/2, step 74/107898 completed (loss: 1.645450234413147, acc: 0.800000011920929)
[2025-01-30 01:52:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 76/107898 [00:27<10:15:04,  2.92it/s][2025-01-30 01:52:37][root][INFO] - Training Epoch: 1/2, step 75/107898 completed (loss: 2.2652676105499268, acc: 0.692307710647583)
[2025-01-30 01:52:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 77/107898 [00:28<10:38:00,  2.82it/s][2025-01-30 01:52:38][root][INFO] - Training Epoch: 1/2, step 76/107898 completed (loss: 2.0660712718963623, acc: 0.800000011920929)
[2025-01-30 01:52:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 78/107898 [00:28<10:14:58,  2.92it/s][2025-01-30 01:52:38][root][INFO] - Training Epoch: 1/2, step 77/107898 completed (loss: 4.209298610687256, acc: 0.5)
[2025-01-30 01:52:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 79/107898 [00:28<10:27:29,  2.86it/s][2025-01-30 01:52:38][root][INFO] - Training Epoch: 1/2, step 78/107898 completed (loss: 5.418291091918945, acc: 0.0)
[2025-01-30 01:52:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 80/107898 [00:29<10:22:18,  2.89it/s][2025-01-30 01:52:39][root][INFO] - Training Epoch: 1/2, step 79/107898 completed (loss: 5.925883769989014, acc: 0.20000000298023224)
[2025-01-30 01:52:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 81/107898 [00:29<10:24:19,  2.88it/s][2025-01-30 01:52:39][root][INFO] - Training Epoch: 1/2, step 80/107898 completed (loss: 1.7989104986190796, acc: 0.6000000238418579)
[2025-01-30 01:52:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 82/107898 [00:29<10:18:13,  2.91it/s][2025-01-30 01:52:39][root][INFO] - Training Epoch: 1/2, step 81/107898 completed (loss: 5.056497573852539, acc: 0.0)
[2025-01-30 01:52:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 83/107898 [00:30<10:33:39,  2.84it/s][2025-01-30 01:52:40][root][INFO] - Training Epoch: 1/2, step 82/107898 completed (loss: 1.8158562183380127, acc: 0.75)
[2025-01-30 01:52:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 84/107898 [00:30<10:57:20,  2.73it/s][2025-01-30 01:52:40][root][INFO] - Training Epoch: 1/2, step 83/107898 completed (loss: 0.5812321901321411, acc: 0.949999988079071)
[2025-01-30 01:52:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 85/107898 [00:31<10:39:46,  2.81it/s][2025-01-30 01:52:40][root][INFO] - Training Epoch: 1/2, step 84/107898 completed (loss: 1.2362422943115234, acc: 0.6666666865348816)
[2025-01-30 01:52:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 86/107898 [00:31<10:06:28,  2.96it/s][2025-01-30 01:52:41][root][INFO] - Training Epoch: 1/2, step 85/107898 completed (loss: 2.079030752182007, acc: 0.6111111044883728)
[2025-01-30 01:52:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 87/107898 [00:31<10:00:46,  2.99it/s][2025-01-30 01:52:41][root][INFO] - Training Epoch: 1/2, step 86/107898 completed (loss: 1.6182228326797485, acc: 0.7777777910232544)
[2025-01-30 01:52:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 88/107898 [00:31<9:52:20,  3.03it/s] [2025-01-30 01:52:41][root][INFO] - Training Epoch: 1/2, step 87/107898 completed (loss: 1.8749041557312012, acc: 0.75)
[2025-01-30 01:52:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 89/107898 [00:32<9:52:40,  3.03it/s][2025-01-30 01:52:42][root][INFO] - Training Epoch: 1/2, step 88/107898 completed (loss: 2.5093908309936523, acc: 0.5833333134651184)
[2025-01-30 01:52:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 90/107898 [00:32<10:04:47,  2.97it/s][2025-01-30 01:52:42][root][INFO] - Training Epoch: 1/2, step 89/107898 completed (loss: 1.024161696434021, acc: 0.75)
[2025-01-30 01:52:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 91/107898 [00:32<10:00:17,  2.99it/s][2025-01-30 01:52:42][root][INFO] - Training Epoch: 1/2, step 90/107898 completed (loss: 1.7404017448425293, acc: 0.8888888955116272)
[2025-01-30 01:52:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 92/107898 [00:33<9:40:46,  3.09it/s] [2025-01-30 01:52:43][root][INFO] - Training Epoch: 1/2, step 91/107898 completed (loss: 8.234930038452148, acc: 0.25)
[2025-01-30 01:52:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 93/107898 [00:33<9:28:37,  3.16it/s][2025-01-30 01:52:43][root][INFO] - Training Epoch: 1/2, step 92/107898 completed (loss: 3.6404905319213867, acc: 0.5)
[2025-01-30 01:52:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 94/107898 [00:33<9:39:20,  3.10it/s][2025-01-30 01:52:43][root][INFO] - Training Epoch: 1/2, step 93/107898 completed (loss: 0.5643802285194397, acc: 0.8823529481887817)
[2025-01-30 01:52:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 95/107898 [00:34<9:37:42,  3.11it/s][2025-01-30 01:52:44][root][INFO] - Training Epoch: 1/2, step 94/107898 completed (loss: 3.1524412631988525, acc: 0.0)
[2025-01-30 01:52:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 96/107898 [00:34<9:39:23,  3.10it/s][2025-01-30 01:52:44][root][INFO] - Training Epoch: 1/2, step 95/107898 completed (loss: 4.757067680358887, acc: 0.3333333432674408)
[2025-01-30 01:52:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 97/107898 [00:34<9:46:00,  3.07it/s][2025-01-30 01:52:44][root][INFO] - Training Epoch: 1/2, step 96/107898 completed (loss: 3.29597544670105, acc: 0.46666666865348816)
[2025-01-30 01:52:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 98/107898 [00:35<9:40:39,  3.09it/s][2025-01-30 01:52:45][root][INFO] - Training Epoch: 1/2, step 97/107898 completed (loss: 4.337167739868164, acc: 0.5)
[2025-01-30 01:52:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 99/107898 [00:35<9:36:36,  3.12it/s][2025-01-30 01:52:45][root][INFO] - Training Epoch: 1/2, step 98/107898 completed (loss: 4.454709529876709, acc: 0.5)
[2025-01-30 01:52:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 100/107898 [00:35<9:48:03,  3.06it/s][2025-01-30 01:52:45][root][INFO] - Training Epoch: 1/2, step 99/107898 completed (loss: 1.043522834777832, acc: 0.7692307829856873)
[2025-01-30 01:52:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 101/107898 [00:36<9:28:56,  3.16it/s][2025-01-30 01:52:45][root][INFO] - Training Epoch: 1/2, step 100/107898 completed (loss: 3.521148443222046, acc: 0.6666666865348816)
[2025-01-30 01:52:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 102/107898 [00:36<9:57:02,  3.01it/s][2025-01-30 01:52:46][root][INFO] - Training Epoch: 1/2, step 101/107898 completed (loss: 2.3030877113342285, acc: 0.0)
[2025-01-30 01:52:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 103/107898 [00:36<10:15:33,  2.92it/s][2025-01-30 01:52:46][root][INFO] - Training Epoch: 1/2, step 102/107898 completed (loss: 1.7094491720199585, acc: 0.625)
[2025-01-30 01:52:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 104/107898 [00:37<10:20:36,  2.89it/s][2025-01-30 01:52:47][root][INFO] - Training Epoch: 1/2, step 103/107898 completed (loss: 4.15989351272583, acc: 0.6666666865348816)
[2025-01-30 01:52:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 105/107898 [00:37<10:26:08,  2.87it/s][2025-01-30 01:52:47][root][INFO] - Training Epoch: 1/2, step 104/107898 completed (loss: 2.611910104751587, acc: 0.3333333432674408)
[2025-01-30 01:52:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 106/107898 [00:37<10:26:37,  2.87it/s][2025-01-30 01:52:47][root][INFO] - Training Epoch: 1/2, step 105/107898 completed (loss: 0.8695874810218811, acc: 0.7931034564971924)
[2025-01-30 01:52:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 107/107898 [00:38<10:10:08,  2.94it/s][2025-01-30 01:52:48][root][INFO] - Training Epoch: 1/2, step 106/107898 completed (loss: 2.4706718921661377, acc: 0.6857143044471741)
[2025-01-30 01:52:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 108/107898 [00:38<9:48:10,  3.05it/s] [2025-01-30 01:52:48][root][INFO] - Training Epoch: 1/2, step 107/107898 completed (loss: 2.6450092792510986, acc: 0.5)
[2025-01-30 01:52:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 109/107898 [00:38<9:46:01,  3.07it/s][2025-01-30 01:52:48][root][INFO] - Training Epoch: 1/2, step 108/107898 completed (loss: 1.1928436756134033, acc: 0.75)
[2025-01-30 01:52:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 110/107898 [00:39<9:43:14,  3.08it/s][2025-01-30 01:52:49][root][INFO] - Training Epoch: 1/2, step 109/107898 completed (loss: 0.1394093632698059, acc: 1.0)
[2025-01-30 01:52:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 111/107898 [00:39<9:46:36,  3.06it/s][2025-01-30 01:52:49][root][INFO] - Training Epoch: 1/2, step 110/107898 completed (loss: 1.9289395809173584, acc: 0.800000011920929)
[2025-01-30 01:52:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 112/107898 [00:39<9:32:19,  3.14it/s][2025-01-30 01:52:49][root][INFO] - Training Epoch: 1/2, step 111/107898 completed (loss: 1.977983832359314, acc: 0.5)
[2025-01-30 01:52:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 113/107898 [00:40<9:35:35,  3.12it/s][2025-01-30 01:52:49][root][INFO] - Training Epoch: 1/2, step 112/107898 completed (loss: 1.5596015453338623, acc: 0.6499999761581421)
[2025-01-30 01:52:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 114/107898 [00:40<9:35:28,  3.12it/s][2025-01-30 01:52:50][root][INFO] - Training Epoch: 1/2, step 113/107898 completed (loss: 0.9973809123039246, acc: 0.7222222089767456)
[2025-01-30 01:52:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 115/107898 [00:40<9:37:16,  3.11it/s][2025-01-30 01:52:50][root][INFO] - Training Epoch: 1/2, step 114/107898 completed (loss: 2.8303651809692383, acc: 0.6666666865348816)
[2025-01-30 01:52:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 116/107898 [00:41<9:51:22,  3.04it/s][2025-01-30 01:52:50][root][INFO] - Training Epoch: 1/2, step 115/107898 completed (loss: 1.6460299491882324, acc: 0.5)
[2025-01-30 01:52:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 117/107898 [00:41<9:54:12,  3.02it/s][2025-01-30 01:52:51][root][INFO] - Training Epoch: 1/2, step 116/107898 completed (loss: 2.8740525245666504, acc: 0.375)
[2025-01-30 01:52:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 118/107898 [00:41<10:02:05,  2.98it/s][2025-01-30 01:52:51][root][INFO] - Training Epoch: 1/2, step 117/107898 completed (loss: 0.26803073287010193, acc: 0.95652174949646)
[2025-01-30 01:52:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 119/107898 [00:42<9:57:16,  3.01it/s] [2025-01-30 01:52:51][root][INFO] - Training Epoch: 1/2, step 118/107898 completed (loss: 1.3763924837112427, acc: 0.8461538553237915)
[2025-01-30 01:52:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 120/107898 [00:42<10:12:37,  2.93it/s][2025-01-30 01:52:52][root][INFO] - Training Epoch: 1/2, step 119/107898 completed (loss: 2.8500664234161377, acc: 0.5555555820465088)
[2025-01-30 01:52:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 121/107898 [00:42<10:06:04,  2.96it/s][2025-01-30 01:52:52][root][INFO] - Training Epoch: 1/2, step 120/107898 completed (loss: 1.9930692911148071, acc: 0.6666666865348816)
[2025-01-30 01:52:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 122/107898 [00:43<9:55:14,  3.02it/s] [2025-01-30 01:52:52][root][INFO] - Training Epoch: 1/2, step 121/107898 completed (loss: 0.4786720871925354, acc: 0.8888888955116272)
[2025-01-30 01:52:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 123/107898 [00:43<10:17:11,  2.91it/s][2025-01-30 01:52:53][root][INFO] - Training Epoch: 1/2, step 122/107898 completed (loss: 6.244940757751465, acc: 0.0)
[2025-01-30 01:52:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 124/107898 [00:43<10:29:51,  2.85it/s][2025-01-30 01:52:53][root][INFO] - Training Epoch: 1/2, step 123/107898 completed (loss: 0.9051567316055298, acc: 0.8571428656578064)
[2025-01-30 01:52:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 125/107898 [00:44<9:59:08,  3.00it/s] [2025-01-30 01:52:54][root][INFO] - Training Epoch: 1/2, step 124/107898 completed (loss: 7.161552429199219, acc: 0.0)
[2025-01-30 01:52:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 126/107898 [00:44<9:53:44,  3.03it/s][2025-01-30 01:52:54][root][INFO] - Training Epoch: 1/2, step 125/107898 completed (loss: 1.7434377670288086, acc: 0.5)
[2025-01-30 01:52:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 127/107898 [00:44<9:35:36,  3.12it/s][2025-01-30 01:52:54][root][INFO] - Training Epoch: 1/2, step 126/107898 completed (loss: 4.467616081237793, acc: 0.09090909361839294)
[2025-01-30 01:52:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 128/107898 [00:45<9:48:05,  3.05it/s][2025-01-30 01:52:54][root][INFO] - Training Epoch: 1/2, step 127/107898 completed (loss: 1.1253310441970825, acc: 0.6666666865348816)
[2025-01-30 01:52:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 129/107898 [00:45<9:57:42,  3.01it/s][2025-01-30 01:52:55][root][INFO] - Training Epoch: 1/2, step 128/107898 completed (loss: 3.9998040199279785, acc: 0.2857142984867096)
[2025-01-30 01:52:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 130/107898 [00:45<9:48:32,  3.05it/s][2025-01-30 01:52:55][root][INFO] - Training Epoch: 1/2, step 129/107898 completed (loss: 0.3789755702018738, acc: 1.0)
[2025-01-30 01:52:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 131/107898 [00:46<9:46:57,  3.06it/s][2025-01-30 01:52:55][root][INFO] - Training Epoch: 1/2, step 130/107898 completed (loss: 1.0301672220230103, acc: 0.782608687877655)
[2025-01-30 01:52:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 132/107898 [00:46<9:46:15,  3.06it/s][2025-01-30 01:52:56][root][INFO] - Training Epoch: 1/2, step 131/107898 completed (loss: 1.8079276084899902, acc: 0.7333333492279053)
[2025-01-30 01:52:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 133/107898 [00:46<9:52:42,  3.03it/s][2025-01-30 01:52:56][root][INFO] - Training Epoch: 1/2, step 132/107898 completed (loss: 2.0525989532470703, acc: 0.5)
[2025-01-30 01:52:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 134/107898 [00:47<10:01:52,  2.98it/s][2025-01-30 01:52:56][root][INFO] - Training Epoch: 1/2, step 133/107898 completed (loss: 2.2290241718292236, acc: 0.6666666865348816)
[2025-01-30 01:52:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 135/107898 [00:47<9:59:11,  3.00it/s] [2025-01-30 01:52:57][root][INFO] - Training Epoch: 1/2, step 134/107898 completed (loss: 2.795294761657715, acc: 0.5384615659713745)
[2025-01-30 01:52:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 136/107898 [00:47<9:52:21,  3.03it/s][2025-01-30 01:52:57][root][INFO] - Training Epoch: 1/2, step 135/107898 completed (loss: 1.9702996015548706, acc: 0.6666666865348816)
[2025-01-30 01:52:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 137/107898 [00:48<9:46:14,  3.06it/s][2025-01-30 01:52:57][root][INFO] - Training Epoch: 1/2, step 136/107898 completed (loss: 1.598588466644287, acc: 0.6666666865348816)
[2025-01-30 01:52:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 138/107898 [00:48<9:49:23,  3.05it/s][2025-01-30 01:52:58][root][INFO] - Training Epoch: 1/2, step 137/107898 completed (loss: 1.390202522277832, acc: 0.5)
[2025-01-30 01:52:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 139/107898 [00:48<9:48:27,  3.05it/s][2025-01-30 01:52:58][root][INFO] - Training Epoch: 1/2, step 138/107898 completed (loss: 3.9651265144348145, acc: 0.4444444477558136)
[2025-01-30 01:52:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 140/107898 [00:49<9:44:15,  3.07it/s][2025-01-30 01:52:58][root][INFO] - Training Epoch: 1/2, step 139/107898 completed (loss: 2.1591410636901855, acc: 0.6499999761581421)
[2025-01-30 01:52:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 141/107898 [00:49<10:16:35,  2.91it/s][2025-01-30 01:52:59][root][INFO] - Training Epoch: 1/2, step 140/107898 completed (loss: 1.6895862817764282, acc: 0.7142857313156128)
[2025-01-30 01:52:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 142/107898 [00:49<10:14:03,  2.92it/s][2025-01-30 01:52:59][root][INFO] - Training Epoch: 1/2, step 141/107898 completed (loss: 2.4278852939605713, acc: 0.3333333432674408)
[2025-01-30 01:52:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 143/107898 [00:50<10:18:15,  2.90it/s][2025-01-30 01:52:59][root][INFO] - Training Epoch: 1/2, step 142/107898 completed (loss: 1.5155738592147827, acc: 0.6428571343421936)
[2025-01-30 01:53:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 144/107898 [00:50<10:19:29,  2.90it/s][2025-01-30 01:53:00][root][INFO] - Training Epoch: 1/2, step 143/107898 completed (loss: 3.2934892177581787, acc: 0.5)
[2025-01-30 01:53:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 145/107898 [00:50<10:39:10,  2.81it/s][2025-01-30 01:53:00][root][INFO] - Training Epoch: 1/2, step 144/107898 completed (loss: 0.4728429913520813, acc: 1.0)
[2025-01-30 01:53:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 146/107898 [00:51<10:50:30,  2.76it/s][2025-01-30 01:53:01][root][INFO] - Training Epoch: 1/2, step 145/107898 completed (loss: 1.8423172235488892, acc: 0.6000000238418579)
[2025-01-30 01:53:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 147/107898 [00:51<10:31:41,  2.84it/s][2025-01-30 01:53:01][root][INFO] - Training Epoch: 1/2, step 146/107898 completed (loss: 5.274574279785156, acc: 0.5)
[2025-01-30 01:53:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 148/107898 [00:51<10:10:03,  2.94it/s][2025-01-30 01:53:01][root][INFO] - Training Epoch: 1/2, step 147/107898 completed (loss: 1.0623658895492554, acc: 0.5)
[2025-01-30 01:53:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 149/107898 [00:52<10:03:43,  2.97it/s][2025-01-30 01:53:02][root][INFO] - Training Epoch: 1/2, step 148/107898 completed (loss: 2.321624279022217, acc: 0.5714285969734192)
[2025-01-30 01:53:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 150/107898 [00:52<10:01:00,  2.99it/s][2025-01-30 01:53:02][root][INFO] - Training Epoch: 1/2, step 149/107898 completed (loss: 1.1748309135437012, acc: 0.6666666865348816)
[2025-01-30 01:53:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 151/107898 [00:52<9:44:55,  3.07it/s] [2025-01-30 01:53:02][root][INFO] - Training Epoch: 1/2, step 150/107898 completed (loss: 1.4078788757324219, acc: 0.6666666865348816)
[2025-01-30 01:53:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 152/107898 [00:53<9:30:01,  3.15it/s][2025-01-30 01:53:02][root][INFO] - Training Epoch: 1/2, step 151/107898 completed (loss: 0.22261092066764832, acc: 1.0)
[2025-01-30 01:53:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 153/107898 [00:53<9:43:00,  3.08it/s][2025-01-30 01:53:03][root][INFO] - Training Epoch: 1/2, step 152/107898 completed (loss: 0.8791174292564392, acc: 0.7647058963775635)
[2025-01-30 01:53:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 154/107898 [00:53<9:44:04,  3.07it/s][2025-01-30 01:53:03][root][INFO] - Training Epoch: 1/2, step 153/107898 completed (loss: 2.401639699935913, acc: 0.5)
[2025-01-30 01:53:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 155/107898 [00:54<9:41:53,  3.09it/s][2025-01-30 01:53:03][root][INFO] - Training Epoch: 1/2, step 154/107898 completed (loss: 5.787583351135254, acc: 0.20000000298023224)
[2025-01-30 01:53:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 156/107898 [00:54<9:46:10,  3.06it/s][2025-01-30 01:53:04][root][INFO] - Training Epoch: 1/2, step 155/107898 completed (loss: 0.6242291927337646, acc: 1.0)
[2025-01-30 01:53:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 157/107898 [00:54<10:05:18,  2.97it/s][2025-01-30 01:53:04][root][INFO] - Training Epoch: 1/2, step 156/107898 completed (loss: 4.678946495056152, acc: 0.20000000298023224)
[2025-01-30 01:53:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 158/107898 [00:55<10:14:11,  2.92it/s][2025-01-30 01:53:05][root][INFO] - Training Epoch: 1/2, step 157/107898 completed (loss: 4.339270114898682, acc: 0.4444444477558136)
[2025-01-30 01:53:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 159/107898 [00:55<9:54:45,  3.02it/s] [2025-01-30 01:53:05][root][INFO] - Training Epoch: 1/2, step 158/107898 completed (loss: 2.2026026248931885, acc: 0.7333333492279053)
[2025-01-30 01:53:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 160/107898 [00:55<9:38:58,  3.10it/s][2025-01-30 01:53:05][root][INFO] - Training Epoch: 1/2, step 159/107898 completed (loss: 0.9317244291305542, acc: 0.875)
[2025-01-30 01:53:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 161/107898 [00:56<9:34:53,  3.12it/s][2025-01-30 01:53:05][root][INFO] - Training Epoch: 1/2, step 160/107898 completed (loss: 0.14910542964935303, acc: 1.0)
[2025-01-30 01:53:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 162/107898 [00:56<9:17:51,  3.22it/s][2025-01-30 01:53:06][root][INFO] - Training Epoch: 1/2, step 161/107898 completed (loss: 3.764563798904419, acc: 0.3333333432674408)
[2025-01-30 01:53:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 163/107898 [00:56<9:26:12,  3.17it/s][2025-01-30 01:53:06][root][INFO] - Training Epoch: 1/2, step 162/107898 completed (loss: 0.3736051023006439, acc: 0.8125)
[2025-01-30 01:53:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 164/107898 [00:57<9:39:25,  3.10it/s][2025-01-30 01:53:06][root][INFO] - Training Epoch: 1/2, step 163/107898 completed (loss: 0.1284025013446808, acc: 1.0)
[2025-01-30 01:53:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 165/107898 [00:57<9:48:33,  3.05it/s][2025-01-30 01:53:07][root][INFO] - Training Epoch: 1/2, step 164/107898 completed (loss: 0.07421194016933441, acc: 1.0)
[2025-01-30 01:53:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 166/107898 [00:57<9:38:52,  3.10it/s][2025-01-30 01:53:07][root][INFO] - Training Epoch: 1/2, step 165/107898 completed (loss: 1.986485242843628, acc: 0.25)
[2025-01-30 01:53:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 167/107898 [00:58<9:54:53,  3.02it/s][2025-01-30 01:53:07][root][INFO] - Training Epoch: 1/2, step 166/107898 completed (loss: 0.9302954077720642, acc: 0.6666666865348816)
[2025-01-30 01:53:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 168/107898 [00:58<10:08:38,  2.95it/s][2025-01-30 01:53:08][root][INFO] - Training Epoch: 1/2, step 167/107898 completed (loss: 1.6789370775222778, acc: 0.7894737124443054)
[2025-01-30 01:53:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 169/107898 [00:58<9:59:47,  2.99it/s] [2025-01-30 01:53:08][root][INFO] - Training Epoch: 1/2, step 168/107898 completed (loss: 2.7061474323272705, acc: 0.5454545617103577)
[2025-01-30 01:53:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 170/107898 [00:59<9:44:02,  3.07it/s][2025-01-30 01:53:08][root][INFO] - Training Epoch: 1/2, step 169/107898 completed (loss: 2.5712807178497314, acc: 0.4000000059604645)
[2025-01-30 01:53:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 171/107898 [00:59<9:35:20,  3.12it/s][2025-01-30 01:53:09][root][INFO] - Training Epoch: 1/2, step 170/107898 completed (loss: 2.955225944519043, acc: 0.5)
[2025-01-30 01:53:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 172/107898 [00:59<9:37:43,  3.11it/s][2025-01-30 01:53:09][root][INFO] - Training Epoch: 1/2, step 171/107898 completed (loss: 0.14114916324615479, acc: 1.0)
[2025-01-30 01:53:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 173/107898 [01:00<9:44:02,  3.07it/s][2025-01-30 01:53:09][root][INFO] - Training Epoch: 1/2, step 172/107898 completed (loss: 0.5784210562705994, acc: 0.8571428656578064)
[2025-01-30 01:53:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 174/107898 [01:00<9:42:15,  3.08it/s][2025-01-30 01:53:10][root][INFO] - Training Epoch: 1/2, step 173/107898 completed (loss: 0.5268881320953369, acc: 0.8571428656578064)
[2025-01-30 01:53:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 175/107898 [01:00<9:51:52,  3.03it/s][2025-01-30 01:53:10][root][INFO] - Training Epoch: 1/2, step 174/107898 completed (loss: 1.8542298078536987, acc: 0.6896551847457886)
[2025-01-30 01:53:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 176/107898 [01:01<9:47:41,  3.05it/s][2025-01-30 01:53:10][root][INFO] - Training Epoch: 1/2, step 175/107898 completed (loss: 0.1580830216407776, acc: 1.0)
[2025-01-30 01:53:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 177/107898 [01:01<9:49:08,  3.05it/s][2025-01-30 01:53:11][root][INFO] - Training Epoch: 1/2, step 176/107898 completed (loss: 0.9374637007713318, acc: 0.8181818127632141)
[2025-01-30 01:53:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 178/107898 [01:01<9:46:55,  3.06it/s][2025-01-30 01:53:11][root][INFO] - Training Epoch: 1/2, step 177/107898 completed (loss: 6.251004695892334, acc: 0.3333333432674408)
[2025-01-30 01:53:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 179/107898 [01:02<9:37:12,  3.11it/s][2025-01-30 01:53:11][root][INFO] - Training Epoch: 1/2, step 178/107898 completed (loss: 0.5425764918327332, acc: 1.0)
[2025-01-30 01:53:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 180/107898 [01:02<9:51:31,  3.04it/s][2025-01-30 01:53:12][root][INFO] - Training Epoch: 1/2, step 179/107898 completed (loss: 1.63898503780365, acc: 0.6842105388641357)
[2025-01-30 01:53:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 181/107898 [01:02<9:53:06,  3.03it/s][2025-01-30 01:53:12][root][INFO] - Training Epoch: 1/2, step 180/107898 completed (loss: 0.4222531318664551, acc: 0.875)
[2025-01-30 01:53:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 182/107898 [01:03<9:47:49,  3.05it/s][2025-01-30 01:53:12][root][INFO] - Training Epoch: 1/2, step 181/107898 completed (loss: 1.236243724822998, acc: 0.8888888955116272)
[2025-01-30 01:53:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 183/107898 [01:03<9:41:55,  3.09it/s][2025-01-30 01:53:13][root][INFO] - Training Epoch: 1/2, step 182/107898 completed (loss: 0.9337219595909119, acc: 0.8333333134651184)
[2025-01-30 01:53:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 184/107898 [01:03<9:37:51,  3.11it/s][2025-01-30 01:53:13][root][INFO] - Training Epoch: 1/2, step 183/107898 completed (loss: 0.6053851842880249, acc: 0.800000011920929)
[2025-01-30 01:53:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 185/107898 [01:03<9:39:15,  3.10it/s][2025-01-30 01:53:13][root][INFO] - Training Epoch: 1/2, step 184/107898 completed (loss: 1.6738100051879883, acc: 0.75)
[2025-01-30 01:53:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 186/107898 [01:04<9:40:19,  3.09it/s][2025-01-30 01:53:14][root][INFO] - Training Epoch: 1/2, step 185/107898 completed (loss: 0.44467058777809143, acc: 0.8125)
[2025-01-30 01:53:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 187/107898 [01:04<9:23:49,  3.18it/s][2025-01-30 01:53:14][root][INFO] - Training Epoch: 1/2, step 186/107898 completed (loss: 2.372743844985962, acc: 0.6666666865348816)
[2025-01-30 01:53:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 188/107898 [01:04<9:14:03,  3.24it/s][2025-01-30 01:53:14][root][INFO] - Training Epoch: 1/2, step 187/107898 completed (loss: 1.242871642112732, acc: 0.5)
[2025-01-30 01:53:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 189/107898 [01:05<9:22:44,  3.19it/s][2025-01-30 01:53:15][root][INFO] - Training Epoch: 1/2, step 188/107898 completed (loss: 0.129074826836586, acc: 1.0)
[2025-01-30 01:53:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 190/107898 [01:05<9:22:38,  3.19it/s][2025-01-30 01:53:15][root][INFO] - Training Epoch: 1/2, step 189/107898 completed (loss: 1.039931297302246, acc: 0.800000011920929)
[2025-01-30 01:53:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 191/107898 [01:05<9:23:31,  3.19it/s][2025-01-30 01:53:15][root][INFO] - Training Epoch: 1/2, step 190/107898 completed (loss: 1.5528229475021362, acc: 0.75)
[2025-01-30 01:53:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 192/107898 [01:06<9:35:15,  3.12it/s][2025-01-30 01:53:15][root][INFO] - Training Epoch: 1/2, step 191/107898 completed (loss: 0.7303261160850525, acc: 0.7272727489471436)
[2025-01-30 01:53:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 193/107898 [01:06<9:56:51,  3.01it/s][2025-01-30 01:53:16][root][INFO] - Training Epoch: 1/2, step 192/107898 completed (loss: 0.46208688616752625, acc: 0.8867924809455872)
[2025-01-30 01:53:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 194/107898 [01:06<10:00:43,  2.99it/s][2025-01-30 01:53:16][root][INFO] - Training Epoch: 1/2, step 193/107898 completed (loss: 1.4527406692504883, acc: 0.6842105388641357)
[2025-01-30 01:53:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 195/107898 [01:07<9:39:08,  3.10it/s] [2025-01-30 01:53:16][root][INFO] - Training Epoch: 1/2, step 194/107898 completed (loss: 0.8838287591934204, acc: 0.7272727489471436)
[2025-01-30 01:53:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 196/107898 [01:07<9:36:44,  3.11it/s][2025-01-30 01:53:17][root][INFO] - Training Epoch: 1/2, step 195/107898 completed (loss: 4.6158623695373535, acc: 0.1111111119389534)
[2025-01-30 01:53:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 197/107898 [01:07<9:23:41,  3.18it/s][2025-01-30 01:53:17][root][INFO] - Training Epoch: 1/2, step 196/107898 completed (loss: 2.8792760372161865, acc: 0.5)
[2025-01-30 01:53:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 198/107898 [01:08<9:29:11,  3.15it/s][2025-01-30 01:53:17][root][INFO] - Training Epoch: 1/2, step 197/107898 completed (loss: 0.647352933883667, acc: 0.75)
[2025-01-30 01:53:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 199/107898 [01:08<9:21:43,  3.20it/s][2025-01-30 01:53:18][root][INFO] - Training Epoch: 1/2, step 198/107898 completed (loss: 0.09084439277648926, acc: 1.0)
[2025-01-30 01:53:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 200/107898 [01:08<9:40:21,  3.09it/s][2025-01-30 01:53:18][root][INFO] - Training Epoch: 1/2, step 199/107898 completed (loss: 2.2502148151397705, acc: 0.5)
[2025-01-30 01:53:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 201/107898 [01:09<9:34:39,  3.12it/s][2025-01-30 01:53:18][root][INFO] - Training Epoch: 1/2, step 200/107898 completed (loss: 0.9386922121047974, acc: 1.0)
[2025-01-30 01:53:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 202/107898 [01:09<9:35:59,  3.12it/s][2025-01-30 01:53:19][root][INFO] - Training Epoch: 1/2, step 201/107898 completed (loss: 5.043549060821533, acc: 0.2857142984867096)
[2025-01-30 01:53:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 203/107898 [01:09<9:25:05,  3.18it/s][2025-01-30 01:53:19][root][INFO] - Training Epoch: 1/2, step 202/107898 completed (loss: 1.422532320022583, acc: 0.6000000238418579)
[2025-01-30 01:53:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 204/107898 [01:10<9:17:46,  3.22it/s][2025-01-30 01:53:19][root][INFO] - Training Epoch: 1/2, step 203/107898 completed (loss: 0.8290010690689087, acc: 0.5)
[2025-01-30 01:53:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 205/107898 [01:10<9:26:22,  3.17it/s][2025-01-30 01:53:20][root][INFO] - Training Epoch: 1/2, step 204/107898 completed (loss: 8.717306137084961, acc: 0.0)
[2025-01-30 01:53:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 206/107898 [01:10<9:33:49,  3.13it/s][2025-01-30 01:53:20][root][INFO] - Training Epoch: 1/2, step 205/107898 completed (loss: 0.8896336555480957, acc: 0.6666666865348816)
[2025-01-30 01:53:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 207/107898 [01:10<9:21:02,  3.20it/s][2025-01-30 01:53:20][root][INFO] - Training Epoch: 1/2, step 206/107898 completed (loss: 3.6864981651306152, acc: 0.5)
[2025-01-30 01:53:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 208/107898 [01:11<9:00:46,  3.32it/s][2025-01-30 01:53:21][root][INFO] - Training Epoch: 1/2, step 207/107898 completed (loss: 1.4975471496582031, acc: 0.7272727489471436)
[2025-01-30 01:53:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 209/107898 [01:11<8:59:03,  3.33it/s][2025-01-30 01:53:21][root][INFO] - Training Epoch: 1/2, step 208/107898 completed (loss: 1.507530927658081, acc: 0.695652186870575)
[2025-01-30 01:53:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 210/107898 [01:11<8:55:08,  3.35it/s][2025-01-30 01:53:21][root][INFO] - Training Epoch: 1/2, step 209/107898 completed (loss: 1.1210609674453735, acc: 0.3333333432674408)
[2025-01-30 01:53:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 211/107898 [01:12<8:56:49,  3.34it/s][2025-01-30 01:53:21][root][INFO] - Training Epoch: 1/2, step 210/107898 completed (loss: 0.5420028567314148, acc: 0.5)
[2025-01-30 01:53:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 212/107898 [01:12<9:16:04,  3.23it/s][2025-01-30 01:53:22][root][INFO] - Training Epoch: 1/2, step 211/107898 completed (loss: 0.39009425044059753, acc: 0.8620689511299133)
[2025-01-30 01:53:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 213/107898 [01:12<9:19:16,  3.21it/s][2025-01-30 01:53:22][root][INFO] - Training Epoch: 1/2, step 212/107898 completed (loss: 0.4974503815174103, acc: 0.8620689511299133)
[2025-01-30 01:53:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 214/107898 [01:13<9:16:41,  3.22it/s][2025-01-30 01:53:22][root][INFO] - Training Epoch: 1/2, step 213/107898 completed (loss: 0.18911342322826385, acc: 1.0)
[2025-01-30 01:53:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 215/107898 [01:13<9:26:01,  3.17it/s][2025-01-30 01:53:23][root][INFO] - Training Epoch: 1/2, step 214/107898 completed (loss: 0.7094551920890808, acc: 0.9047619104385376)
[2025-01-30 01:53:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 216/107898 [01:13<9:30:02,  3.15it/s][2025-01-30 01:53:23][root][INFO] - Training Epoch: 1/2, step 215/107898 completed (loss: 0.27221059799194336, acc: 1.0)
[2025-01-30 01:53:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 217/107898 [01:14<9:24:14,  3.18it/s][2025-01-30 01:53:23][root][INFO] - Training Epoch: 1/2, step 216/107898 completed (loss: 0.07799195498228073, acc: 1.0)
[2025-01-30 01:53:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 218/107898 [01:14<9:45:39,  3.06it/s][2025-01-30 01:53:24][root][INFO] - Training Epoch: 1/2, step 217/107898 completed (loss: 2.420902729034424, acc: 0.5)
[2025-01-30 01:53:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 219/107898 [01:14<10:18:12,  2.90it/s][2025-01-30 01:53:24][root][INFO] - Training Epoch: 1/2, step 218/107898 completed (loss: 1.611756443977356, acc: 0.6666666865348816)
[2025-01-30 01:53:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 220/107898 [01:15<10:19:38,  2.90it/s][2025-01-30 01:53:24][root][INFO] - Training Epoch: 1/2, step 219/107898 completed (loss: 1.6143510341644287, acc: 0.692307710647583)
[2025-01-30 01:53:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 221/107898 [01:15<10:00:34,  2.99it/s][2025-01-30 01:53:25][root][INFO] - Training Epoch: 1/2, step 220/107898 completed (loss: 1.7358601093292236, acc: 0.5555555820465088)
[2025-01-30 01:53:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 222/107898 [01:15<9:34:30,  3.12it/s] [2025-01-30 01:53:25][root][INFO] - Training Epoch: 1/2, step 221/107898 completed (loss: 1.0210278034210205, acc: 0.75)
[2025-01-30 01:53:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 223/107898 [01:16<9:56:19,  3.01it/s][2025-01-30 01:53:25][root][INFO] - Training Epoch: 1/2, step 222/107898 completed (loss: 0.7736690640449524, acc: 0.800000011920929)
[2025-01-30 01:53:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 224/107898 [01:16<9:33:06,  3.13it/s][2025-01-30 01:53:26][root][INFO] - Training Epoch: 1/2, step 223/107898 completed (loss: 0.7796120047569275, acc: 0.6666666865348816)
[2025-01-30 01:53:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 225/107898 [01:16<9:51:25,  3.03it/s][2025-01-30 01:53:26][root][INFO] - Training Epoch: 1/2, step 224/107898 completed (loss: 3.086967945098877, acc: 0.5)
[2025-01-30 01:53:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 226/107898 [01:17<10:09:51,  2.94it/s][2025-01-30 01:53:26][root][INFO] - Training Epoch: 1/2, step 225/107898 completed (loss: 2.687225103378296, acc: 0.625)
[2025-01-30 01:53:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 227/107898 [01:17<10:19:10,  2.90it/s][2025-01-30 01:53:27][root][INFO] - Training Epoch: 1/2, step 226/107898 completed (loss: 1.469502568244934, acc: 0.6666666865348816)
[2025-01-30 01:53:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 228/107898 [01:17<10:16:50,  2.91it/s][2025-01-30 01:53:27][root][INFO] - Training Epoch: 1/2, step 227/107898 completed (loss: 5.881032466888428, acc: 0.125)
[2025-01-30 01:53:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 229/107898 [01:18<10:29:07,  2.85it/s][2025-01-30 01:53:27][root][INFO] - Training Epoch: 1/2, step 228/107898 completed (loss: 1.4743390083312988, acc: 0.6000000238418579)
[2025-01-30 01:53:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 230/107898 [01:18<10:25:46,  2.87it/s][2025-01-30 01:53:28][root][INFO] - Training Epoch: 1/2, step 229/107898 completed (loss: 0.40836912393569946, acc: 1.0)
[2025-01-30 01:53:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 231/107898 [01:18<10:32:19,  2.84it/s][2025-01-30 01:53:28][root][INFO] - Training Epoch: 1/2, step 230/107898 completed (loss: 0.37265047430992126, acc: 0.6666666865348816)
[2025-01-30 01:53:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 232/107898 [01:19<10:20:32,  2.89it/s][2025-01-30 01:53:28][root][INFO] - Training Epoch: 1/2, step 231/107898 completed (loss: 0.46604251861572266, acc: 0.8695651888847351)
[2025-01-30 01:53:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 233/107898 [01:19<9:53:46,  3.02it/s] [2025-01-30 01:53:29][root][INFO] - Training Epoch: 1/2, step 232/107898 completed (loss: 3.873296022415161, acc: 0.4285714328289032)
[2025-01-30 01:53:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 234/107898 [01:19<9:47:48,  3.05it/s][2025-01-30 01:53:29][root][INFO] - Training Epoch: 1/2, step 233/107898 completed (loss: 1.9357420206069946, acc: 0.7368420958518982)
[2025-01-30 01:53:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 235/107898 [01:20<9:42:04,  3.08it/s][2025-01-30 01:53:29][root][INFO] - Training Epoch: 1/2, step 234/107898 completed (loss: 2.0414671897888184, acc: 0.5714285969734192)
[2025-01-30 01:53:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 236/107898 [01:20<9:32:36,  3.13it/s][2025-01-30 01:53:30][root][INFO] - Training Epoch: 1/2, step 235/107898 completed (loss: 0.06220794469118118, acc: 1.0)
[2025-01-30 01:53:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 237/107898 [01:20<9:31:19,  3.14it/s][2025-01-30 01:53:30][root][INFO] - Training Epoch: 1/2, step 236/107898 completed (loss: 1.8387326002120972, acc: 0.6666666865348816)
[2025-01-30 01:53:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 238/107898 [01:21<9:27:41,  3.16it/s][2025-01-30 01:53:30][root][INFO] - Training Epoch: 1/2, step 237/107898 completed (loss: 3.8975162506103516, acc: 0.125)
[2025-01-30 01:53:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 239/107898 [01:21<9:15:37,  3.23it/s][2025-01-30 01:53:31][root][INFO] - Training Epoch: 1/2, step 238/107898 completed (loss: 4.513991832733154, acc: 0.3333333432674408)
[2025-01-30 01:53:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 240/107898 [01:21<9:14:48,  3.23it/s][2025-01-30 01:53:31][root][INFO] - Training Epoch: 1/2, step 239/107898 completed (loss: 2.0459883213043213, acc: 0.6666666865348816)
[2025-01-30 01:53:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 241/107898 [01:21<9:19:06,  3.21it/s][2025-01-30 01:53:31][root][INFO] - Training Epoch: 1/2, step 240/107898 completed (loss: 0.3950978219509125, acc: 1.0)
[2025-01-30 01:53:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 242/107898 [01:22<9:25:03,  3.18it/s][2025-01-30 01:53:32][root][INFO] - Training Epoch: 1/2, step 241/107898 completed (loss: 0.4462450444698334, acc: 1.0)
[2025-01-30 01:53:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 243/107898 [01:22<9:37:40,  3.11it/s][2025-01-30 01:53:32][root][INFO] - Training Epoch: 1/2, step 242/107898 completed (loss: 1.3274977207183838, acc: 0.7692307829856873)
[2025-01-30 01:53:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 244/107898 [01:22<9:40:02,  3.09it/s][2025-01-30 01:53:32][root][INFO] - Training Epoch: 1/2, step 243/107898 completed (loss: 0.7995189428329468, acc: 0.800000011920929)
[2025-01-30 01:53:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 245/107898 [01:23<9:51:37,  3.03it/s][2025-01-30 01:53:33][root][INFO] - Training Epoch: 1/2, step 244/107898 completed (loss: 1.3499767780303955, acc: 0.7931034564971924)
[2025-01-30 01:53:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 246/107898 [01:23<10:00:41,  2.99it/s][2025-01-30 01:53:33][root][INFO] - Training Epoch: 1/2, step 245/107898 completed (loss: 1.1472721099853516, acc: 0.7666666507720947)
[2025-01-30 01:53:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 247/107898 [01:23<10:00:34,  2.99it/s][2025-01-30 01:53:33][root][INFO] - Training Epoch: 1/2, step 246/107898 completed (loss: 0.43592551350593567, acc: 0.9333333373069763)
[2025-01-30 01:53:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 248/107898 [01:24<9:42:54,  3.08it/s] [2025-01-30 01:53:34][root][INFO] - Training Epoch: 1/2, step 247/107898 completed (loss: 2.922281503677368, acc: 0.3636363744735718)
[2025-01-30 01:53:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 249/107898 [01:24<9:54:24,  3.02it/s][2025-01-30 01:53:34][root][INFO] - Training Epoch: 1/2, step 248/107898 completed (loss: 1.3724600076675415, acc: 0.5)
[2025-01-30 01:53:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 250/107898 [01:24<10:02:59,  2.98it/s][2025-01-30 01:53:34][root][INFO] - Training Epoch: 1/2, step 249/107898 completed (loss: 1.994547724723816, acc: 0.75)
[2025-01-30 01:53:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 251/107898 [01:25<10:10:04,  2.94it/s][2025-01-30 01:53:35][root][INFO] - Training Epoch: 1/2, step 250/107898 completed (loss: 0.830946147441864, acc: 0.6666666865348816)
[2025-01-30 01:53:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 252/107898 [01:25<10:20:55,  2.89it/s][2025-01-30 01:53:35][root][INFO] - Training Epoch: 1/2, step 251/107898 completed (loss: 1.5275888442993164, acc: 0.65625)
[2025-01-30 01:53:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 253/107898 [01:26<10:17:17,  2.91it/s][2025-01-30 01:53:35][root][INFO] - Training Epoch: 1/2, step 252/107898 completed (loss: 1.4421228170394897, acc: 0.4285714328289032)
[2025-01-30 01:53:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 254/107898 [01:26<10:02:05,  2.98it/s][2025-01-30 01:53:36][root][INFO] - Training Epoch: 1/2, step 253/107898 completed (loss: 3.2462596893310547, acc: 0.25)
[2025-01-30 01:53:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 255/107898 [01:26<10:27:35,  2.86it/s][2025-01-30 01:53:36][root][INFO] - Training Epoch: 1/2, step 254/107898 completed (loss: 4.38803243637085, acc: 0.2666666805744171)
[2025-01-30 01:53:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 256/107898 [01:27<10:14:59,  2.92it/s][2025-01-30 01:53:36][root][INFO] - Training Epoch: 1/2, step 255/107898 completed (loss: 4.970506191253662, acc: 0.0)
[2025-01-30 01:53:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 257/107898 [01:27<10:10:07,  2.94it/s][2025-01-30 01:53:37][root][INFO] - Training Epoch: 1/2, step 256/107898 completed (loss: 0.20163831114768982, acc: 1.0)
[2025-01-30 01:53:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 258/107898 [01:27<10:00:57,  2.99it/s][2025-01-30 01:53:37][root][INFO] - Training Epoch: 1/2, step 257/107898 completed (loss: 1.1137357950210571, acc: 0.6000000238418579)
[2025-01-30 01:53:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 259/107898 [01:28<10:05:37,  2.96it/s][2025-01-30 01:53:37][root][INFO] - Training Epoch: 1/2, step 258/107898 completed (loss: 0.2129075825214386, acc: 1.0)
[2025-01-30 01:53:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 260/107898 [01:28<10:15:29,  2.91it/s][2025-01-30 01:53:38][root][INFO] - Training Epoch: 1/2, step 259/107898 completed (loss: 1.1749354600906372, acc: 0.6666666865348816)
[2025-01-30 01:53:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 261/107898 [01:28<10:25:20,  2.87it/s][2025-01-30 01:53:38][root][INFO] - Training Epoch: 1/2, step 260/107898 completed (loss: 3.1524484157562256, acc: 0.4838709533214569)
[2025-01-30 01:53:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 262/107898 [01:29<10:04:00,  2.97it/s][2025-01-30 01:53:38][root][INFO] - Training Epoch: 1/2, step 261/107898 completed (loss: 2.5458080768585205, acc: 0.7142857313156128)
[2025-01-30 01:53:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 263/107898 [01:29<9:40:15,  3.09it/s] [2025-01-30 01:53:39][root][INFO] - Training Epoch: 1/2, step 262/107898 completed (loss: 1.8451675176620483, acc: 0.5)
[2025-01-30 01:53:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 264/107898 [01:29<9:22:11,  3.19it/s][2025-01-30 01:53:39][root][INFO] - Training Epoch: 1/2, step 263/107898 completed (loss: 2.741011381149292, acc: 0.4615384638309479)
[2025-01-30 01:53:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 265/107898 [01:29<9:00:45,  3.32it/s][2025-01-30 01:53:39][root][INFO] - Training Epoch: 1/2, step 264/107898 completed (loss: 1.9745657444000244, acc: 0.5)
[2025-01-30 01:53:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 266/107898 [01:30<9:27:38,  3.16it/s][2025-01-30 01:53:40][root][INFO] - Training Epoch: 1/2, step 265/107898 completed (loss: 1.5843863487243652, acc: 0.7200000286102295)
[2025-01-30 01:53:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 267/107898 [01:30<9:45:01,  3.07it/s][2025-01-30 01:53:40][root][INFO] - Training Epoch: 1/2, step 266/107898 completed (loss: 1.0108355283737183, acc: 0.8181818127632141)
[2025-01-30 01:53:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 268/107898 [01:30<9:37:01,  3.11it/s][2025-01-30 01:53:40][root][INFO] - Training Epoch: 1/2, step 267/107898 completed (loss: 0.5367226600646973, acc: 0.875)
[2025-01-30 01:53:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 269/107898 [01:31<9:48:06,  3.05it/s][2025-01-30 01:53:41][root][INFO] - Training Epoch: 1/2, step 268/107898 completed (loss: 2.946336507797241, acc: 0.6000000238418579)
[2025-01-30 01:53:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 270/107898 [01:31<10:00:30,  2.99it/s][2025-01-30 01:53:41][root][INFO] - Training Epoch: 1/2, step 269/107898 completed (loss: 0.393901526927948, acc: 1.0)
[2025-01-30 01:53:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 271/107898 [01:32<10:10:48,  2.94it/s][2025-01-30 01:53:41][root][INFO] - Training Epoch: 1/2, step 270/107898 completed (loss: 0.282703697681427, acc: 1.0)
[2025-01-30 01:53:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 272/107898 [01:32<10:11:01,  2.94it/s][2025-01-30 01:53:42][root][INFO] - Training Epoch: 1/2, step 271/107898 completed (loss: 0.060858141630887985, acc: 1.0)
[2025-01-30 01:53:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 273/107898 [01:32<9:36:50,  3.11it/s] [2025-01-30 01:53:42][root][INFO] - Training Epoch: 1/2, step 272/107898 completed (loss: 0.2953760325908661, acc: 1.0)
[2025-01-30 01:53:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 274/107898 [01:32<9:34:55,  3.12it/s][2025-01-30 01:53:42][root][INFO] - Training Epoch: 1/2, step 273/107898 completed (loss: 4.597739219665527, acc: 0.4000000059604645)
[2025-01-30 01:53:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 275/107898 [01:33<9:35:09,  3.12it/s][2025-01-30 01:53:43][root][INFO] - Training Epoch: 1/2, step 274/107898 completed (loss: 0.7943155765533447, acc: 0.8500000238418579)
[2025-01-30 01:53:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 276/107898 [01:33<9:41:03,  3.09it/s][2025-01-30 01:53:43][root][INFO] - Training Epoch: 1/2, step 275/107898 completed (loss: 3.311138868331909, acc: 0.5)
[2025-01-30 01:53:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 277/107898 [01:33<9:46:16,  3.06it/s][2025-01-30 01:53:43][root][INFO] - Training Epoch: 1/2, step 276/107898 completed (loss: 0.7298208475112915, acc: 0.7692307829856873)
[2025-01-30 01:53:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 278/107898 [01:34<9:36:08,  3.11it/s][2025-01-30 01:53:44][root][INFO] - Training Epoch: 1/2, step 277/107898 completed (loss: 3.8119099140167236, acc: 0.20000000298023224)
[2025-01-30 01:53:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 279/107898 [01:34<9:40:44,  3.09it/s][2025-01-30 01:53:44][root][INFO] - Training Epoch: 1/2, step 278/107898 completed (loss: 0.24630972743034363, acc: 1.0)
[2025-01-30 01:53:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 280/107898 [01:34<9:40:23,  3.09it/s][2025-01-30 01:53:44][root][INFO] - Training Epoch: 1/2, step 279/107898 completed (loss: 2.7895686626434326, acc: 0.7142857313156128)
[2025-01-30 01:53:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 281/107898 [01:35<9:30:54,  3.14it/s][2025-01-30 01:53:44][root][INFO] - Training Epoch: 1/2, step 280/107898 completed (loss: 1.562339425086975, acc: 0.5)
[2025-01-30 01:53:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 282/107898 [01:35<9:18:34,  3.21it/s][2025-01-30 01:53:45][root][INFO] - Training Epoch: 1/2, step 281/107898 completed (loss: 0.17510366439819336, acc: 1.0)
[2025-01-30 01:53:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 283/107898 [01:35<9:14:25,  3.24it/s][2025-01-30 01:53:45][root][INFO] - Training Epoch: 1/2, step 282/107898 completed (loss: 1.2169995307922363, acc: 0.800000011920929)
[2025-01-30 01:53:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 284/107898 [01:36<9:15:44,  3.23it/s][2025-01-30 01:53:45][root][INFO] - Training Epoch: 1/2, step 283/107898 completed (loss: 0.3250117599964142, acc: 1.0)
[2025-01-30 01:53:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 285/107898 [01:36<9:07:16,  3.28it/s][2025-01-30 01:53:46][root][INFO] - Training Epoch: 1/2, step 284/107898 completed (loss: 1.8267872333526611, acc: 0.6000000238418579)
[2025-01-30 01:53:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 286/107898 [01:36<9:18:19,  3.21it/s][2025-01-30 01:53:46][root][INFO] - Training Epoch: 1/2, step 285/107898 completed (loss: 0.632079541683197, acc: 0.7142857313156128)
[2025-01-30 01:53:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 287/107898 [01:37<9:15:15,  3.23it/s][2025-01-30 01:53:46][root][INFO] - Training Epoch: 1/2, step 286/107898 completed (loss: 1.4498757123947144, acc: 0.7272727489471436)
[2025-01-30 01:53:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 288/107898 [01:37<9:10:04,  3.26it/s][2025-01-30 01:53:47][root][INFO] - Training Epoch: 1/2, step 287/107898 completed (loss: 1.6980578899383545, acc: 0.692307710647583)
[2025-01-30 01:53:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 289/107898 [01:37<9:23:22,  3.18it/s][2025-01-30 01:53:47][root][INFO] - Training Epoch: 1/2, step 288/107898 completed (loss: 1.3740285634994507, acc: 0.550000011920929)
[2025-01-30 01:53:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 290/107898 [01:38<10:02:01,  2.98it/s][2025-01-30 01:53:47][root][INFO] - Training Epoch: 1/2, step 289/107898 completed (loss: 1.0533113479614258, acc: 0.625)
[2025-01-30 01:53:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 291/107898 [01:38<10:12:34,  2.93it/s][2025-01-30 01:53:48][root][INFO] - Training Epoch: 1/2, step 290/107898 completed (loss: 0.6113396286964417, acc: 0.9166666865348816)
[2025-01-30 01:53:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 292/107898 [01:38<10:05:20,  2.96it/s][2025-01-30 01:53:48][root][INFO] - Training Epoch: 1/2, step 291/107898 completed (loss: 1.6470597982406616, acc: 0.6190476417541504)
[2025-01-30 01:53:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 293/107898 [01:39<9:57:27,  3.00it/s] [2025-01-30 01:53:48][root][INFO] - Training Epoch: 1/2, step 292/107898 completed (loss: 1.350217580795288, acc: 0.7777777910232544)
[2025-01-30 01:53:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 294/107898 [01:39<9:44:51,  3.07it/s][2025-01-30 01:53:49][root][INFO] - Training Epoch: 1/2, step 293/107898 completed (loss: 0.08451724797487259, acc: 1.0)
[2025-01-30 01:53:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 295/107898 [01:39<9:41:27,  3.08it/s][2025-01-30 01:53:49][root][INFO] - Training Epoch: 1/2, step 294/107898 completed (loss: 3.530182361602783, acc: 0.5)
[2025-01-30 01:53:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 296/107898 [01:40<9:53:56,  3.02it/s][2025-01-30 01:53:49][root][INFO] - Training Epoch: 1/2, step 295/107898 completed (loss: 1.0653170347213745, acc: 0.5)
[2025-01-30 01:53:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 297/107898 [01:40<9:40:42,  3.09it/s][2025-01-30 01:53:50][root][INFO] - Training Epoch: 1/2, step 296/107898 completed (loss: 1.093103289604187, acc: 0.5)
[2025-01-30 01:53:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 298/107898 [01:40<9:25:29,  3.17it/s][2025-01-30 01:53:50][root][INFO] - Training Epoch: 1/2, step 297/107898 completed (loss: 0.147481769323349, acc: 1.0)
[2025-01-30 01:53:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 299/107898 [01:40<9:41:38,  3.08it/s][2025-01-30 01:53:50][root][INFO] - Training Epoch: 1/2, step 298/107898 completed (loss: 0.3121470510959625, acc: 0.9487179517745972)
[2025-01-30 01:53:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 300/107898 [01:41<9:29:38,  3.15it/s][2025-01-30 01:53:51][root][INFO] - Training Epoch: 1/2, step 299/107898 completed (loss: 3.6438751220703125, acc: 0.6666666865348816)
[2025-01-30 01:53:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 301/107898 [01:41<9:47:26,  3.05it/s][2025-01-30 01:53:51][root][INFO] - Training Epoch: 1/2, step 300/107898 completed (loss: 3.0915262699127197, acc: 0.25)
[2025-01-30 01:53:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 302/107898 [01:41<9:29:59,  3.15it/s][2025-01-30 01:53:51][root][INFO] - Training Epoch: 1/2, step 301/107898 completed (loss: 0.08679210394620895, acc: 1.0)
[2025-01-30 01:53:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 303/107898 [01:42<9:36:14,  3.11it/s][2025-01-30 01:53:52][root][INFO] - Training Epoch: 1/2, step 302/107898 completed (loss: 1.440568447113037, acc: 0.5)
[2025-01-30 01:53:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 304/107898 [01:42<9:45:58,  3.06it/s][2025-01-30 01:53:52][root][INFO] - Training Epoch: 1/2, step 303/107898 completed (loss: 0.5022356510162354, acc: 1.0)
[2025-01-30 01:53:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 305/107898 [01:42<9:50:28,  3.04it/s][2025-01-30 01:53:52][root][INFO] - Training Epoch: 1/2, step 304/107898 completed (loss: 1.6261478662490845, acc: 0.6666666865348816)
[2025-01-30 01:53:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 306/107898 [01:43<9:44:05,  3.07it/s][2025-01-30 01:53:53][root][INFO] - Training Epoch: 1/2, step 305/107898 completed (loss: 1.4829059839248657, acc: 0.7142857313156128)
[2025-01-30 01:53:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 307/107898 [01:43<9:51:47,  3.03it/s][2025-01-30 01:53:53][root][INFO] - Training Epoch: 1/2, step 306/107898 completed (loss: 0.8953470587730408, acc: 0.8285714387893677)
[2025-01-30 01:53:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 308/107898 [01:43<9:39:38,  3.09it/s][2025-01-30 01:53:53][root][INFO] - Training Epoch: 1/2, step 307/107898 completed (loss: 0.061000436544418335, acc: 1.0)
[2025-01-30 01:53:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 309/107898 [01:44<9:31:17,  3.14it/s][2025-01-30 01:53:53][root][INFO] - Training Epoch: 1/2, step 308/107898 completed (loss: 0.21688015758991241, acc: 1.0)
[2025-01-30 01:53:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 310/107898 [01:44<9:54:16,  3.02it/s][2025-01-30 01:53:54][root][INFO] - Training Epoch: 1/2, step 309/107898 completed (loss: 0.7624559998512268, acc: 1.0)
[2025-01-30 01:53:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 311/107898 [01:44<10:08:36,  2.95it/s][2025-01-30 01:53:54][root][INFO] - Training Epoch: 1/2, step 310/107898 completed (loss: 0.20574484765529633, acc: 1.0)
[2025-01-30 01:53:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 312/107898 [01:45<10:04:04,  2.97it/s][2025-01-30 01:53:55][root][INFO] - Training Epoch: 1/2, step 311/107898 completed (loss: 1.9347238540649414, acc: 0.6666666865348816)
[2025-01-30 01:53:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 313/107898 [01:45<10:10:28,  2.94it/s][2025-01-30 01:53:55][root][INFO] - Training Epoch: 1/2, step 312/107898 completed (loss: 0.0177377350628376, acc: 1.0)
[2025-01-30 01:53:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 314/107898 [01:45<10:11:43,  2.93it/s][2025-01-30 01:53:55][root][INFO] - Training Epoch: 1/2, step 313/107898 completed (loss: 4.6663594245910645, acc: 0.6666666865348816)
[2025-01-30 01:53:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 315/107898 [01:46<9:54:20,  3.02it/s] [2025-01-30 01:53:56][root][INFO] - Training Epoch: 1/2, step 314/107898 completed (loss: 1.6912200450897217, acc: 0.7333333492279053)
[2025-01-30 01:53:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 316/107898 [01:46<10:02:29,  2.98it/s][2025-01-30 01:53:56][root][INFO] - Training Epoch: 1/2, step 315/107898 completed (loss: 2.0128402709960938, acc: 0.6904761791229248)
[2025-01-30 01:53:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 317/107898 [01:46<10:16:59,  2.91it/s][2025-01-30 01:53:56][root][INFO] - Training Epoch: 1/2, step 316/107898 completed (loss: 1.5178579092025757, acc: 0.6666666865348816)
[2025-01-30 01:53:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 318/107898 [01:47<10:28:56,  2.85it/s][2025-01-30 01:53:57][root][INFO] - Training Epoch: 1/2, step 317/107898 completed (loss: 2.5300347805023193, acc: 0.6666666865348816)
[2025-01-30 01:53:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 319/107898 [01:47<10:18:48,  2.90it/s][2025-01-30 01:53:57][root][INFO] - Training Epoch: 1/2, step 318/107898 completed (loss: 1.7709273099899292, acc: 0.75)
[2025-01-30 01:53:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 320/107898 [01:47<10:08:49,  2.94it/s][2025-01-30 01:53:57][root][INFO] - Training Epoch: 1/2, step 319/107898 completed (loss: 0.7523394227027893, acc: 0.8181818127632141)
[2025-01-30 01:53:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 321/107898 [01:48<9:56:59,  3.00it/s] [2025-01-30 01:53:58][root][INFO] - Training Epoch: 1/2, step 320/107898 completed (loss: 1.5002386569976807, acc: 0.75)
[2025-01-30 01:53:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 322/107898 [01:48<9:50:45,  3.04it/s][2025-01-30 01:53:58][root][INFO] - Training Epoch: 1/2, step 321/107898 completed (loss: 0.2322898507118225, acc: 1.0)
[2025-01-30 01:53:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 323/107898 [01:49<10:34:43,  2.82it/s][2025-01-30 01:53:58][root][INFO] - Training Epoch: 1/2, step 322/107898 completed (loss: 1.0251580476760864, acc: 0.800000011920929)
[2025-01-30 01:53:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 324/107898 [01:49<10:30:04,  2.85it/s][2025-01-30 01:53:59][root][INFO] - Training Epoch: 1/2, step 323/107898 completed (loss: 0.08174075186252594, acc: 1.0)
[2025-01-30 01:53:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 325/107898 [01:49<10:14:29,  2.92it/s][2025-01-30 01:53:59][root][INFO] - Training Epoch: 1/2, step 324/107898 completed (loss: 2.1618425846099854, acc: 0.0)
[2025-01-30 01:53:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 326/107898 [01:50<10:12:36,  2.93it/s][2025-01-30 01:53:59][root][INFO] - Training Epoch: 1/2, step 325/107898 completed (loss: 1.0591456890106201, acc: 0.8695651888847351)
[2025-01-30 01:53:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 327/107898 [01:50<10:10:59,  2.93it/s][2025-01-30 01:54:00][root][INFO] - Training Epoch: 1/2, step 326/107898 completed (loss: 4.755277633666992, acc: 0.2222222238779068)
[2025-01-30 01:54:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 328/107898 [01:50<10:18:59,  2.90it/s][2025-01-30 01:54:00][root][INFO] - Training Epoch: 1/2, step 327/107898 completed (loss: 0.20680510997772217, acc: 1.0)
[2025-01-30 01:54:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 329/107898 [01:51<9:53:29,  3.02it/s] [2025-01-30 01:54:00][root][INFO] - Training Epoch: 1/2, step 328/107898 completed (loss: 0.6957626938819885, acc: 1.0)
[2025-01-30 01:54:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 330/107898 [01:51<10:18:18,  2.90it/s][2025-01-30 01:54:01][root][INFO] - Training Epoch: 1/2, step 329/107898 completed (loss: 0.1302843987941742, acc: 0.949999988079071)
[2025-01-30 01:54:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 331/107898 [01:51<10:22:50,  2.88it/s][2025-01-30 01:54:01][root][INFO] - Training Epoch: 1/2, step 330/107898 completed (loss: 1.0998122692108154, acc: 0.5)
[2025-01-30 01:54:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 332/107898 [01:52<10:28:10,  2.85it/s][2025-01-30 01:54:01][root][INFO] - Training Epoch: 1/2, step 331/107898 completed (loss: 0.8550525903701782, acc: 1.0)
[2025-01-30 01:54:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 333/107898 [01:52<10:22:16,  2.88it/s][2025-01-30 01:54:02][root][INFO] - Training Epoch: 1/2, step 332/107898 completed (loss: 0.9469630122184753, acc: 0.8260869383811951)
[2025-01-30 01:54:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 334/107898 [01:52<10:24:52,  2.87it/s][2025-01-30 01:54:02][root][INFO] - Training Epoch: 1/2, step 333/107898 completed (loss: 1.4351741075515747, acc: 0.6969696879386902)
[2025-01-30 01:54:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 335/107898 [01:53<9:59:12,  2.99it/s] [2025-01-30 01:54:02][root][INFO] - Training Epoch: 1/2, step 334/107898 completed (loss: 0.4621078372001648, acc: 0.75)
[2025-01-30 01:54:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 336/107898 [01:53<10:01:58,  2.98it/s][2025-01-30 01:54:03][root][INFO] - Training Epoch: 1/2, step 335/107898 completed (loss: 3.084052562713623, acc: 0.5)
[2025-01-30 01:54:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 337/107898 [01:53<10:00:57,  2.98it/s][2025-01-30 01:54:03][root][INFO] - Training Epoch: 1/2, step 336/107898 completed (loss: 0.991226315498352, acc: 0.8500000238418579)
[2025-01-30 01:54:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 338/107898 [01:54<9:35:33,  3.11it/s] [2025-01-30 01:54:03][root][INFO] - Training Epoch: 1/2, step 337/107898 completed (loss: 0.5832263231277466, acc: 0.9375)
[2025-01-30 01:54:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 339/107898 [01:54<11:16:43,  2.65it/s][2025-01-30 01:54:04][root][INFO] - Training Epoch: 1/2, step 338/107898 completed (loss: 0.010325291194021702, acc: 1.0)
[2025-01-30 01:54:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 340/107898 [01:54<11:03:35,  2.70it/s][2025-01-30 01:54:04][root][INFO] - Training Epoch: 1/2, step 339/107898 completed (loss: 0.3174546957015991, acc: 0.8333333134651184)
[2025-01-30 01:54:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 341/107898 [01:55<10:35:52,  2.82it/s][2025-01-30 01:54:05][root][INFO] - Training Epoch: 1/2, step 340/107898 completed (loss: 3.7766315937042236, acc: 0.5)
[2025-01-30 01:54:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 342/107898 [01:55<10:26:38,  2.86it/s][2025-01-30 01:54:05][root][INFO] - Training Epoch: 1/2, step 341/107898 completed (loss: 0.7369847893714905, acc: 0.8333333134651184)
[2025-01-30 01:54:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 343/107898 [01:55<10:06:38,  2.95it/s][2025-01-30 01:54:05][root][INFO] - Training Epoch: 1/2, step 342/107898 completed (loss: 3.0791728496551514, acc: 0.3913043439388275)
[2025-01-30 01:54:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 344/107898 [01:56<10:31:41,  2.84it/s][2025-01-30 01:54:06][root][INFO] - Training Epoch: 1/2, step 343/107898 completed (loss: 1.4894218444824219, acc: 0.5555555820465088)
[2025-01-30 01:54:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 345/107898 [01:56<10:20:02,  2.89it/s][2025-01-30 01:54:06][root][INFO] - Training Epoch: 1/2, step 344/107898 completed (loss: 2.1701605319976807, acc: 0.6153846383094788)
[2025-01-30 01:54:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 346/107898 [01:56<10:11:12,  2.93it/s][2025-01-30 01:54:06][root][INFO] - Training Epoch: 1/2, step 345/107898 completed (loss: 1.229992151260376, acc: 0.6666666865348816)
[2025-01-30 01:54:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 347/107898 [01:57<10:01:28,  2.98it/s][2025-01-30 01:54:07][root][INFO] - Training Epoch: 1/2, step 346/107898 completed (loss: 1.5135186910629272, acc: 0.7307692170143127)
[2025-01-30 01:54:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 348/107898 [01:57<10:05:51,  2.96it/s][2025-01-30 01:54:07][root][INFO] - Training Epoch: 1/2, step 347/107898 completed (loss: 0.392175555229187, acc: 0.8181818127632141)
[2025-01-30 01:54:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 349/107898 [01:57<10:10:43,  2.94it/s][2025-01-30 01:54:07][root][INFO] - Training Epoch: 1/2, step 348/107898 completed (loss: 1.12899649143219, acc: 0.8260869383811951)
[2025-01-30 01:54:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 350/107898 [01:58<10:22:58,  2.88it/s][2025-01-30 01:54:08][root][INFO] - Training Epoch: 1/2, step 349/107898 completed (loss: 1.2482807636260986, acc: 0.6000000238418579)
[2025-01-30 01:54:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 351/107898 [01:58<10:51:54,  2.75it/s][2025-01-30 01:54:08][root][INFO] - Training Epoch: 1/2, step 350/107898 completed (loss: 2.9063661098480225, acc: 0.5)
[2025-01-30 01:54:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 352/107898 [01:59<10:23:51,  2.87it/s][2025-01-30 01:54:08][root][INFO] - Training Epoch: 1/2, step 351/107898 completed (loss: 5.171153545379639, acc: 0.0)
[2025-01-30 01:54:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 353/107898 [01:59<10:06:40,  2.95it/s][2025-01-30 01:54:09][root][INFO] - Training Epoch: 1/2, step 352/107898 completed (loss: 0.7307846546173096, acc: 0.8461538553237915)
[2025-01-30 01:54:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 354/107898 [01:59<9:39:25,  3.09it/s] [2025-01-30 01:54:09][root][INFO] - Training Epoch: 1/2, step 353/107898 completed (loss: 2.6540400981903076, acc: 0.6666666865348816)
[2025-01-30 01:54:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 355/107898 [01:59<9:52:22,  3.03it/s][2025-01-30 01:54:09][root][INFO] - Training Epoch: 1/2, step 354/107898 completed (loss: 1.9384074211120605, acc: 0.5555555820465088)
[2025-01-30 01:54:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 356/107898 [02:00<10:03:13,  2.97it/s][2025-01-30 01:54:10][root][INFO] - Training Epoch: 1/2, step 355/107898 completed (loss: 0.006655991077423096, acc: 1.0)
[2025-01-30 01:54:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 357/107898 [02:00<10:10:16,  2.94it/s][2025-01-30 01:54:10][root][INFO] - Training Epoch: 1/2, step 356/107898 completed (loss: 5.751275539398193, acc: 0.1428571492433548)
[2025-01-30 01:54:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 358/107898 [02:00<9:31:45,  3.13it/s] [2025-01-30 01:54:10][root][INFO] - Training Epoch: 1/2, step 357/107898 completed (loss: 1.3824125528335571, acc: 0.6666666865348816)
[2025-01-30 01:54:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 359/107898 [02:01<9:15:43,  3.23it/s][2025-01-30 01:54:11][root][INFO] - Training Epoch: 1/2, step 358/107898 completed (loss: 2.845679521560669, acc: 0.6666666865348816)
[2025-01-30 01:54:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 360/107898 [02:01<9:08:55,  3.27it/s][2025-01-30 01:54:11][root][INFO] - Training Epoch: 1/2, step 359/107898 completed (loss: 1.0694140195846558, acc: 0.8999999761581421)
[2025-01-30 01:54:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 361/107898 [02:01<9:18:25,  3.21it/s][2025-01-30 01:54:11][root][INFO] - Training Epoch: 1/2, step 360/107898 completed (loss: 1.8533660173416138, acc: 0.5909090638160706)
[2025-01-30 01:54:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 362/107898 [02:02<9:10:53,  3.25it/s][2025-01-30 01:54:11][root][INFO] - Training Epoch: 1/2, step 361/107898 completed (loss: 1.8579615354537964, acc: 0.5625)
[2025-01-30 01:54:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 363/107898 [02:02<9:32:00,  3.13it/s][2025-01-30 01:54:12][root][INFO] - Training Epoch: 1/2, step 362/107898 completed (loss: 0.011553160846233368, acc: 1.0)
[2025-01-30 01:54:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 364/107898 [02:02<9:30:29,  3.14it/s][2025-01-30 01:54:12][root][INFO] - Training Epoch: 1/2, step 363/107898 completed (loss: 2.3119125366210938, acc: 0.5862069129943848)
[2025-01-30 01:54:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 365/107898 [02:03<10:01:12,  2.98it/s][2025-01-30 01:54:12][root][INFO] - Training Epoch: 1/2, step 364/107898 completed (loss: 2.5865519046783447, acc: 0.5714285969734192)
[2025-01-30 01:54:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 366/107898 [02:03<9:58:32,  2.99it/s] [2025-01-30 01:54:13][root][INFO] - Training Epoch: 1/2, step 365/107898 completed (loss: 0.19056597352027893, acc: 1.0)
[2025-01-30 01:54:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 367/107898 [02:03<10:10:59,  2.93it/s][2025-01-30 01:54:13][root][INFO] - Training Epoch: 1/2, step 366/107898 completed (loss: 0.33120739459991455, acc: 1.0)
[2025-01-30 01:54:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 368/107898 [02:04<10:07:33,  2.95it/s][2025-01-30 01:54:14][root][INFO] - Training Epoch: 1/2, step 367/107898 completed (loss: 1.6187777519226074, acc: 0.7209302186965942)
[2025-01-30 01:54:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 369/107898 [02:04<10:30:08,  2.84it/s][2025-01-30 01:54:14][root][INFO] - Training Epoch: 1/2, step 368/107898 completed (loss: 0.9565891623497009, acc: 0.8148148059844971)
[2025-01-30 01:54:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 370/107898 [02:04<10:33:17,  2.83it/s][2025-01-30 01:54:14][root][INFO] - Training Epoch: 1/2, step 369/107898 completed (loss: 1.864653468132019, acc: 0.6666666865348816)
[2025-01-30 01:54:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 371/107898 [02:05<10:34:45,  2.82it/s][2025-01-30 01:54:15][root][INFO] - Training Epoch: 1/2, step 370/107898 completed (loss: 1.2440181970596313, acc: 0.8333333134651184)
[2025-01-30 01:54:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 372/107898 [02:05<10:25:19,  2.87it/s][2025-01-30 01:54:15][root][INFO] - Training Epoch: 1/2, step 371/107898 completed (loss: 1.3512680530548096, acc: 0.5714285969734192)
[2025-01-30 01:54:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 373/107898 [02:05<10:18:30,  2.90it/s][2025-01-30 01:54:15][root][INFO] - Training Epoch: 1/2, step 372/107898 completed (loss: 3.988149404525757, acc: 0.5)
[2025-01-30 01:54:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 374/107898 [02:06<10:08:33,  2.94it/s][2025-01-30 01:54:16][root][INFO] - Training Epoch: 1/2, step 373/107898 completed (loss: 3.3678648471832275, acc: 0.5)
[2025-01-30 01:54:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 375/107898 [02:06<10:15:00,  2.91it/s][2025-01-30 01:54:16][root][INFO] - Training Epoch: 1/2, step 374/107898 completed (loss: 0.254381388425827, acc: 0.9230769276618958)
[2025-01-30 01:54:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 376/107898 [02:06<9:44:01,  3.07it/s] [2025-01-30 01:54:16][root][INFO] - Training Epoch: 1/2, step 375/107898 completed (loss: 0.579899787902832, acc: 0.6666666865348816)
[2025-01-30 01:54:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 377/107898 [02:07<9:28:20,  3.15it/s][2025-01-30 01:54:17][root][INFO] - Training Epoch: 1/2, step 376/107898 completed (loss: 0.03831721469759941, acc: 1.0)
[2025-01-30 01:54:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 378/107898 [02:07<9:24:11,  3.18it/s][2025-01-30 01:54:17][root][INFO] - Training Epoch: 1/2, step 377/107898 completed (loss: 0.38703256845474243, acc: 1.0)
[2025-01-30 01:54:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 379/107898 [02:07<9:37:05,  3.11it/s][2025-01-30 01:54:17][root][INFO] - Training Epoch: 1/2, step 378/107898 completed (loss: 4.679474830627441, acc: 0.2083333283662796)
[2025-01-30 01:54:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 380/107898 [02:08<9:39:51,  3.09it/s][2025-01-30 01:54:18][root][INFO] - Training Epoch: 1/2, step 379/107898 completed (loss: 0.8815774917602539, acc: 0.75)
[2025-01-30 01:54:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 381/107898 [02:08<9:30:58,  3.14it/s][2025-01-30 01:54:18][root][INFO] - Training Epoch: 1/2, step 380/107898 completed (loss: 2.1600699424743652, acc: 0.5)
[2025-01-30 01:54:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 382/107898 [02:08<9:34:33,  3.12it/s][2025-01-30 01:54:18][root][INFO] - Training Epoch: 1/2, step 381/107898 completed (loss: 1.1899008750915527, acc: 0.75)
[2025-01-30 01:54:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 383/107898 [02:09<9:45:52,  3.06it/s][2025-01-30 01:54:18][root][INFO] - Training Epoch: 1/2, step 382/107898 completed (loss: 1.3160125017166138, acc: 0.6666666865348816)
[2025-01-30 01:54:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 384/107898 [02:09<9:51:29,  3.03it/s][2025-01-30 01:54:19][root][INFO] - Training Epoch: 1/2, step 383/107898 completed (loss: 1.2386924028396606, acc: 0.6363636255264282)
[2025-01-30 01:54:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 385/107898 [02:09<9:34:47,  3.12it/s][2025-01-30 01:54:19][root][INFO] - Training Epoch: 1/2, step 384/107898 completed (loss: 0.20379948616027832, acc: 0.9285714030265808)
[2025-01-30 01:54:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 386/107898 [02:10<9:23:41,  3.18it/s][2025-01-30 01:54:19][root][INFO] - Training Epoch: 1/2, step 385/107898 completed (loss: 2.094956636428833, acc: 0.6666666865348816)
[2025-01-30 01:54:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 387/107898 [02:10<9:14:10,  3.23it/s][2025-01-30 01:54:20][root][INFO] - Training Epoch: 1/2, step 386/107898 completed (loss: 2.26727032661438, acc: 0.6153846383094788)
[2025-01-30 01:54:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 388/107898 [02:10<9:31:27,  3.14it/s][2025-01-30 01:54:20][root][INFO] - Training Epoch: 1/2, step 387/107898 completed (loss: 4.3101806640625, acc: 0.0)
[2025-01-30 01:54:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 389/107898 [02:11<9:35:29,  3.11it/s][2025-01-30 01:54:20][root][INFO] - Training Epoch: 1/2, step 388/107898 completed (loss: 0.7021946907043457, acc: 1.0)
[2025-01-30 01:54:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 390/107898 [02:11<9:38:37,  3.10it/s][2025-01-30 01:54:21][root][INFO] - Training Epoch: 1/2, step 389/107898 completed (loss: 2.008606433868408, acc: 0.3333333432674408)
[2025-01-30 01:54:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 391/107898 [02:11<10:06:39,  2.95it/s][2025-01-30 01:54:21][root][INFO] - Training Epoch: 1/2, step 390/107898 completed (loss: 1.8317276239395142, acc: 0.6666666865348816)
[2025-01-30 01:54:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 392/107898 [02:12<10:09:21,  2.94it/s][2025-01-30 01:54:21][root][INFO] - Training Epoch: 1/2, step 391/107898 completed (loss: 4.566584587097168, acc: 0.0714285746216774)
[2025-01-30 01:54:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 393/107898 [02:12<9:45:19,  3.06it/s] [2025-01-30 01:54:22][root][INFO] - Training Epoch: 1/2, step 392/107898 completed (loss: 0.4064197242259979, acc: 1.0)
[2025-01-30 01:54:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 394/107898 [02:12<10:00:35,  2.98it/s][2025-01-30 01:54:22][root][INFO] - Training Epoch: 1/2, step 393/107898 completed (loss: 1.814090609550476, acc: 0.3333333432674408)
[2025-01-30 01:54:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 395/107898 [02:13<10:03:33,  2.97it/s][2025-01-30 01:54:22][root][INFO] - Training Epoch: 1/2, step 394/107898 completed (loss: 3.747375726699829, acc: 0.3333333432674408)
[2025-01-30 01:54:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 396/107898 [02:13<10:10:33,  2.93it/s][2025-01-30 01:54:23][root][INFO] - Training Epoch: 1/2, step 395/107898 completed (loss: 1.001347541809082, acc: 0.7777777910232544)
[2025-01-30 01:54:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 397/107898 [02:13<10:11:21,  2.93it/s][2025-01-30 01:54:23][root][INFO] - Training Epoch: 1/2, step 396/107898 completed (loss: 0.8842003345489502, acc: 0.807692289352417)
[2025-01-30 01:54:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 398/107898 [02:14<9:27:02,  3.16it/s] [2025-01-30 01:54:23][root][INFO] - Training Epoch: 1/2, step 397/107898 completed (loss: 0.8077576756477356, acc: 0.761904776096344)
[2025-01-30 01:54:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 399/107898 [02:14<9:42:54,  3.07it/s][2025-01-30 01:54:24][root][INFO] - Training Epoch: 1/2, step 398/107898 completed (loss: 3.538588523864746, acc: 0.5)
[2025-01-30 01:54:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 400/107898 [02:14<9:31:45,  3.13it/s][2025-01-30 01:54:24][root][INFO] - Training Epoch: 1/2, step 399/107898 completed (loss: 2.7794342041015625, acc: 0.4285714328289032)
[2025-01-30 01:54:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 401/107898 [02:15<9:31:27,  3.14it/s][2025-01-30 01:54:24][root][INFO] - Training Epoch: 1/2, step 400/107898 completed (loss: 1.8739023208618164, acc: 0.8125)
[2025-01-30 01:54:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 402/107898 [02:15<9:24:48,  3.17it/s][2025-01-30 01:54:25][root][INFO] - Training Epoch: 1/2, step 401/107898 completed (loss: 2.1133015155792236, acc: 0.5)
[2025-01-30 01:54:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 403/107898 [02:15<9:23:01,  3.18it/s][2025-01-30 01:54:25][root][INFO] - Training Epoch: 1/2, step 402/107898 completed (loss: 0.7359944581985474, acc: 0.9230769276618958)
[2025-01-30 01:54:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 404/107898 [02:16<9:25:55,  3.17it/s][2025-01-30 01:54:25][root][INFO] - Training Epoch: 1/2, step 403/107898 completed (loss: 0.5536593198776245, acc: 0.8636363744735718)
[2025-01-30 01:54:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 405/107898 [02:16<9:09:15,  3.26it/s][2025-01-30 01:54:26][root][INFO] - Training Epoch: 1/2, step 404/107898 completed (loss: 2.4184682369232178, acc: 0.6666666865348816)
[2025-01-30 01:54:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 406/107898 [02:16<9:07:25,  3.27it/s][2025-01-30 01:54:26][root][INFO] - Training Epoch: 1/2, step 405/107898 completed (loss: 0.0055540455505251884, acc: 1.0)
[2025-01-30 01:54:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 407/107898 [02:16<9:12:21,  3.24it/s][2025-01-30 01:54:26][root][INFO] - Training Epoch: 1/2, step 406/107898 completed (loss: 0.048475123941898346, acc: 1.0)
[2025-01-30 01:54:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 408/107898 [02:17<8:57:33,  3.33it/s][2025-01-30 01:54:26][root][INFO] - Training Epoch: 1/2, step 407/107898 completed (loss: 0.048716530203819275, acc: 1.0)
[2025-01-30 01:54:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 409/107898 [02:17<8:55:27,  3.35it/s][2025-01-30 01:54:27][root][INFO] - Training Epoch: 1/2, step 408/107898 completed (loss: 0.3799654543399811, acc: 1.0)
[2025-01-30 01:54:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 410/107898 [02:17<9:04:11,  3.29it/s][2025-01-30 01:54:27][root][INFO] - Training Epoch: 1/2, step 409/107898 completed (loss: 2.56191086769104, acc: 0.3333333432674408)
[2025-01-30 01:54:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 411/107898 [02:18<9:49:32,  3.04it/s][2025-01-30 01:54:27][root][INFO] - Training Epoch: 1/2, step 410/107898 completed (loss: 0.04099177569150925, acc: 1.0)
[2025-01-30 01:54:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 412/107898 [02:18<10:05:27,  2.96it/s][2025-01-30 01:54:28][root][INFO] - Training Epoch: 1/2, step 411/107898 completed (loss: 0.4148874282836914, acc: 0.95652174949646)
[2025-01-30 01:54:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 413/107898 [02:18<10:00:01,  2.99it/s][2025-01-30 01:54:28][root][INFO] - Training Epoch: 1/2, step 412/107898 completed (loss: 2.4846863746643066, acc: 0.5185185074806213)
[2025-01-30 01:54:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 414/107898 [02:19<9:50:46,  3.03it/s] [2025-01-30 01:54:28][root][INFO] - Training Epoch: 1/2, step 413/107898 completed (loss: 0.5144473314285278, acc: 0.800000011920929)
[2025-01-30 01:54:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 415/107898 [02:19<10:05:21,  2.96it/s][2025-01-30 01:54:29][root][INFO] - Training Epoch: 1/2, step 414/107898 completed (loss: 1.5744572877883911, acc: 0.6000000238418579)
[2025-01-30 01:54:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 416/107898 [02:19<9:40:29,  3.09it/s] [2025-01-30 01:54:29][root][INFO] - Training Epoch: 1/2, step 415/107898 completed (loss: 2.998971700668335, acc: 0.4285714328289032)
[2025-01-30 01:54:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 417/107898 [02:20<9:33:45,  3.12it/s][2025-01-30 01:54:29][root][INFO] - Training Epoch: 1/2, step 416/107898 completed (loss: 1.9909114837646484, acc: 0.5)
[2025-01-30 01:54:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 418/107898 [02:20<9:43:19,  3.07it/s][2025-01-30 01:54:30][root][INFO] - Training Epoch: 1/2, step 417/107898 completed (loss: 0.44703730940818787, acc: 1.0)
[2025-01-30 01:54:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 419/107898 [02:20<10:10:57,  2.93it/s][2025-01-30 01:54:30][root][INFO] - Training Epoch: 1/2, step 418/107898 completed (loss: 1.8200005292892456, acc: 0.75)
[2025-01-30 01:54:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 420/107898 [02:21<10:01:53,  2.98it/s][2025-01-30 01:54:30][root][INFO] - Training Epoch: 1/2, step 419/107898 completed (loss: 1.5030889511108398, acc: 0.8260869383811951)
[2025-01-30 01:54:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 421/107898 [02:21<10:12:47,  2.92it/s][2025-01-30 01:54:31][root][INFO] - Training Epoch: 1/2, step 420/107898 completed (loss: 1.7982934713363647, acc: 0.6666666865348816)
[2025-01-30 01:54:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 422/107898 [02:21<10:33:47,  2.83it/s][2025-01-30 01:54:31][root][INFO] - Training Epoch: 1/2, step 421/107898 completed (loss: 6.228850841522217, acc: 0.10000000149011612)
[2025-01-30 01:54:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 423/107898 [02:22<10:20:00,  2.89it/s][2025-01-30 01:54:32][root][INFO] - Training Epoch: 1/2, step 422/107898 completed (loss: 1.613756537437439, acc: 0.6000000238418579)
[2025-01-30 01:54:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 424/107898 [02:22<10:11:29,  2.93it/s][2025-01-30 01:54:32][root][INFO] - Training Epoch: 1/2, step 423/107898 completed (loss: 0.4609212577342987, acc: 0.8823529481887817)
[2025-01-30 01:54:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 425/107898 [02:22<10:04:29,  2.96it/s][2025-01-30 01:54:32][root][INFO] - Training Epoch: 1/2, step 424/107898 completed (loss: 0.5475953817367554, acc: 0.7777777910232544)
[2025-01-30 01:54:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 426/107898 [02:23<10:01:08,  2.98it/s][2025-01-30 01:54:33][root][INFO] - Training Epoch: 1/2, step 425/107898 completed (loss: 2.9961864948272705, acc: 0.4444444477558136)
[2025-01-30 01:54:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 427/107898 [02:23<10:11:56,  2.93it/s][2025-01-30 01:54:33][root][INFO] - Training Epoch: 1/2, step 426/107898 completed (loss: 0.7561080455780029, acc: 0.9166666865348816)
[2025-01-30 01:54:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 428/107898 [02:23<9:44:17,  3.07it/s] [2025-01-30 01:54:33][root][INFO] - Training Epoch: 1/2, step 427/107898 completed (loss: 2.283766984939575, acc: 0.5789473652839661)
[2025-01-30 01:54:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 429/107898 [02:24<9:25:40,  3.17it/s][2025-01-30 01:54:33][root][INFO] - Training Epoch: 1/2, step 428/107898 completed (loss: 1.1859508752822876, acc: 0.5)
[2025-01-30 01:54:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 430/107898 [02:24<9:41:19,  3.08it/s][2025-01-30 01:54:34][root][INFO] - Training Epoch: 1/2, step 429/107898 completed (loss: 1.4721647500991821, acc: 0.7857142686843872)
[2025-01-30 01:54:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 431/107898 [02:24<10:05:16,  2.96it/s][2025-01-30 01:54:34][root][INFO] - Training Epoch: 1/2, step 430/107898 completed (loss: 2.867595911026001, acc: 0.5)
[2025-01-30 01:54:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 432/107898 [02:25<10:06:26,  2.95it/s][2025-01-30 01:54:35][root][INFO] - Training Epoch: 1/2, step 431/107898 completed (loss: 1.9939543008804321, acc: 0.7200000286102295)
[2025-01-30 01:54:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 433/107898 [02:25<9:53:40,  3.02it/s] [2025-01-30 01:54:35][root][INFO] - Training Epoch: 1/2, step 432/107898 completed (loss: 0.00942990928888321, acc: 1.0)
[2025-01-30 01:54:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 434/107898 [02:25<9:46:56,  3.05it/s][2025-01-30 01:54:35][root][INFO] - Training Epoch: 1/2, step 433/107898 completed (loss: 3.5678093433380127, acc: 0.3333333432674408)
[2025-01-30 01:54:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 435/107898 [02:26<9:31:51,  3.13it/s][2025-01-30 01:54:35][root][INFO] - Training Epoch: 1/2, step 434/107898 completed (loss: 0.016462402418255806, acc: 1.0)
[2025-01-30 01:54:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 436/107898 [02:26<9:32:16,  3.13it/s][2025-01-30 01:54:36][root][INFO] - Training Epoch: 1/2, step 435/107898 completed (loss: 0.4909687936306, acc: 0.8571428656578064)
[2025-01-30 01:54:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 437/107898 [02:26<9:27:52,  3.15it/s][2025-01-30 01:54:36][root][INFO] - Training Epoch: 1/2, step 436/107898 completed (loss: 0.4917130470275879, acc: 0.800000011920929)
[2025-01-30 01:54:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 438/107898 [02:27<9:19:06,  3.20it/s][2025-01-30 01:54:36][root][INFO] - Training Epoch: 1/2, step 437/107898 completed (loss: 3.986870527267456, acc: 0.0)
[2025-01-30 01:54:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 439/107898 [02:27<9:16:30,  3.22it/s][2025-01-30 01:54:37][root][INFO] - Training Epoch: 1/2, step 438/107898 completed (loss: 2.38979172706604, acc: 0.5)
[2025-01-30 01:54:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 440/107898 [02:27<9:20:02,  3.20it/s][2025-01-30 01:54:37][root][INFO] - Training Epoch: 1/2, step 439/107898 completed (loss: 0.013372547924518585, acc: 1.0)
[2025-01-30 01:54:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 441/107898 [02:28<9:53:56,  3.02it/s][2025-01-30 01:54:37][root][INFO] - Training Epoch: 1/2, step 440/107898 completed (loss: 2.570439100265503, acc: 0.5714285969734192)
[2025-01-30 01:54:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 442/107898 [02:28<10:03:21,  2.97it/s][2025-01-30 01:54:38][root][INFO] - Training Epoch: 1/2, step 441/107898 completed (loss: 4.221628189086914, acc: 0.47999998927116394)
[2025-01-30 01:54:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 443/107898 [02:28<10:22:15,  2.88it/s][2025-01-30 01:54:38][root][INFO] - Training Epoch: 1/2, step 442/107898 completed (loss: 0.5093970894813538, acc: 0.8823529481887817)
[2025-01-30 01:54:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 444/107898 [02:29<10:16:07,  2.91it/s][2025-01-30 01:54:38][root][INFO] - Training Epoch: 1/2, step 443/107898 completed (loss: 2.9722161293029785, acc: 0.5)
[2025-01-30 01:54:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 445/107898 [02:29<9:52:37,  3.02it/s] [2025-01-30 01:54:39][root][INFO] - Training Epoch: 1/2, step 444/107898 completed (loss: 0.5312325358390808, acc: 0.800000011920929)
[2025-01-30 01:54:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 446/107898 [02:29<10:11:06,  2.93it/s][2025-01-30 01:54:39][root][INFO] - Training Epoch: 1/2, step 445/107898 completed (loss: 0.8719757795333862, acc: 0.8148148059844971)
[2025-01-30 01:54:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 447/107898 [02:30<9:56:54,  3.00it/s] [2025-01-30 01:54:39][root][INFO] - Training Epoch: 1/2, step 446/107898 completed (loss: 1.8168364763259888, acc: 0.7894737124443054)
[2025-01-30 01:54:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 448/107898 [02:30<9:46:05,  3.06it/s][2025-01-30 01:54:40][root][INFO] - Training Epoch: 1/2, step 447/107898 completed (loss: 0.10829049348831177, acc: 1.0)
[2025-01-30 01:54:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 449/107898 [02:30<9:56:08,  3.00it/s][2025-01-30 01:54:40][root][INFO] - Training Epoch: 1/2, step 448/107898 completed (loss: 2.4091475009918213, acc: 0.5625)
[2025-01-30 01:54:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 450/107898 [02:31<10:10:25,  2.93it/s][2025-01-30 01:54:40][root][INFO] - Training Epoch: 1/2, step 449/107898 completed (loss: 2.366065740585327, acc: 0.4285714328289032)
[2025-01-30 01:54:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 451/107898 [02:31<10:10:49,  2.93it/s][2025-01-30 01:54:41][root][INFO] - Training Epoch: 1/2, step 450/107898 completed (loss: 0.5983469486236572, acc: 0.9047619104385376)
[2025-01-30 01:54:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 452/107898 [02:31<10:10:25,  2.93it/s][2025-01-30 01:54:41][root][INFO] - Training Epoch: 1/2, step 451/107898 completed (loss: 1.4342211484909058, acc: 0.7058823704719543)
[2025-01-30 01:54:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 453/107898 [02:32<9:46:02,  3.06it/s] [2025-01-30 01:54:41][root][INFO] - Training Epoch: 1/2, step 452/107898 completed (loss: 0.9296095967292786, acc: 0.5)
[2025-01-30 01:54:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 454/107898 [02:32<9:31:23,  3.13it/s][2025-01-30 01:54:42][root][INFO] - Training Epoch: 1/2, step 453/107898 completed (loss: 0.040482088923454285, acc: 1.0)
[2025-01-30 01:54:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 455/107898 [02:32<9:50:00,  3.04it/s][2025-01-30 01:54:42][root][INFO] - Training Epoch: 1/2, step 454/107898 completed (loss: 2.3156843185424805, acc: 0.5384615659713745)
[2025-01-30 01:54:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 456/107898 [02:33<9:40:22,  3.09it/s][2025-01-30 01:54:42][root][INFO] - Training Epoch: 1/2, step 455/107898 completed (loss: 0.3035656809806824, acc: 1.0)
[2025-01-30 01:54:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 457/107898 [02:33<9:31:45,  3.13it/s][2025-01-30 01:54:43][root][INFO] - Training Epoch: 1/2, step 456/107898 completed (loss: 0.056671157479286194, acc: 1.0)
[2025-01-30 01:54:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 458/107898 [02:33<9:26:30,  3.16it/s][2025-01-30 01:54:43][root][INFO] - Training Epoch: 1/2, step 457/107898 completed (loss: 2.3727173805236816, acc: 0.529411792755127)
[2025-01-30 01:54:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 459/107898 [02:34<9:20:08,  3.20it/s][2025-01-30 01:54:43][root][INFO] - Training Epoch: 1/2, step 458/107898 completed (loss: 1.3944092988967896, acc: 0.5)
[2025-01-30 01:54:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 460/107898 [02:34<9:18:08,  3.21it/s][2025-01-30 01:54:44][root][INFO] - Training Epoch: 1/2, step 459/107898 completed (loss: 0.024835102260112762, acc: 1.0)
[2025-01-30 01:54:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 461/107898 [02:34<9:18:18,  3.21it/s][2025-01-30 01:54:44][root][INFO] - Training Epoch: 1/2, step 460/107898 completed (loss: 0.1737380474805832, acc: 1.0)
[2025-01-30 01:54:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 462/107898 [02:34<9:25:27,  3.17it/s][2025-01-30 01:54:44][root][INFO] - Training Epoch: 1/2, step 461/107898 completed (loss: 0.9379787445068359, acc: 0.8500000238418579)
[2025-01-30 01:54:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 463/107898 [02:35<9:26:16,  3.16it/s][2025-01-30 01:54:45][root][INFO] - Training Epoch: 1/2, step 462/107898 completed (loss: 2.285555601119995, acc: 0.5)
[2025-01-30 01:54:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 464/107898 [02:35<9:29:14,  3.15it/s][2025-01-30 01:54:45][root][INFO] - Training Epoch: 1/2, step 463/107898 completed (loss: 0.4695155918598175, acc: 0.8947368264198303)
[2025-01-30 01:54:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 465/107898 [02:35<9:40:26,  3.08it/s][2025-01-30 01:54:45][root][INFO] - Training Epoch: 1/2, step 464/107898 completed (loss: 2.6215007305145264, acc: 0.25)
[2025-01-30 01:54:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 466/107898 [02:36<9:33:32,  3.12it/s][2025-01-30 01:54:46][root][INFO] - Training Epoch: 1/2, step 465/107898 completed (loss: 0.7838481664657593, acc: 0.7777777910232544)
[2025-01-30 01:54:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 467/107898 [02:36<9:17:55,  3.21it/s][2025-01-30 01:54:46][root][INFO] - Training Epoch: 1/2, step 466/107898 completed (loss: 1.0844709873199463, acc: 0.8333333134651184)
[2025-01-30 01:54:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 468/107898 [02:36<9:20:35,  3.19it/s][2025-01-30 01:54:46][root][INFO] - Training Epoch: 1/2, step 467/107898 completed (loss: 0.03364795818924904, acc: 1.0)
[2025-01-30 01:54:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 469/107898 [02:37<9:30:40,  3.14it/s][2025-01-30 01:54:46][root][INFO] - Training Epoch: 1/2, step 468/107898 completed (loss: 1.5832666158676147, acc: 0.6666666865348816)
[2025-01-30 01:54:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 470/107898 [02:37<9:43:16,  3.07it/s][2025-01-30 01:54:47][root][INFO] - Training Epoch: 1/2, step 469/107898 completed (loss: 0.8645257353782654, acc: 1.0)
[2025-01-30 01:54:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 471/107898 [02:37<9:58:27,  2.99it/s][2025-01-30 01:54:47][root][INFO] - Training Epoch: 1/2, step 470/107898 completed (loss: 0.39994335174560547, acc: 0.9285714030265808)
[2025-01-30 01:54:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 472/107898 [02:38<9:43:36,  3.07it/s][2025-01-30 01:54:47][root][INFO] - Training Epoch: 1/2, step 471/107898 completed (loss: 0.015507569536566734, acc: 1.0)
[2025-01-30 01:54:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 473/107898 [02:38<9:27:54,  3.15it/s][2025-01-30 01:54:48][root][INFO] - Training Epoch: 1/2, step 472/107898 completed (loss: 0.01371069811284542, acc: 1.0)
[2025-01-30 01:54:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 474/107898 [02:38<9:48:19,  3.04it/s][2025-01-30 01:54:48][root][INFO] - Training Epoch: 1/2, step 473/107898 completed (loss: 0.030068468302488327, acc: 1.0)
[2025-01-30 01:54:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 475/107898 [02:39<9:40:32,  3.08it/s][2025-01-30 01:54:48][root][INFO] - Training Epoch: 1/2, step 474/107898 completed (loss: 1.8376517295837402, acc: 0.5)
[2025-01-30 01:54:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 476/107898 [02:39<9:33:07,  3.12it/s][2025-01-30 01:54:49][root][INFO] - Training Epoch: 1/2, step 475/107898 completed (loss: 4.2197041511535645, acc: 0.3076923191547394)
[2025-01-30 01:54:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 477/107898 [02:39<9:30:02,  3.14it/s][2025-01-30 01:54:49][root][INFO] - Training Epoch: 1/2, step 476/107898 completed (loss: 1.4388799667358398, acc: 0.5)
[2025-01-30 01:54:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 478/107898 [02:40<9:22:13,  3.18it/s][2025-01-30 01:54:49][root][INFO] - Training Epoch: 1/2, step 477/107898 completed (loss: 1.6918078660964966, acc: 0.625)
[2025-01-30 01:54:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 479/107898 [02:40<9:10:37,  3.25it/s][2025-01-30 01:54:50][root][INFO] - Training Epoch: 1/2, step 478/107898 completed (loss: 0.012908343225717545, acc: 1.0)
[2025-01-30 01:54:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 480/107898 [02:40<9:06:36,  3.28it/s][2025-01-30 01:54:50][root][INFO] - Training Epoch: 1/2, step 479/107898 completed (loss: 4.569874286651611, acc: 0.3333333432674408)
[2025-01-30 01:54:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 481/107898 [02:41<9:25:04,  3.17it/s][2025-01-30 01:54:50][root][INFO] - Training Epoch: 1/2, step 480/107898 completed (loss: 1.469705581665039, acc: 0.7142857313156128)
[2025-01-30 01:54:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 482/107898 [02:41<9:13:08,  3.24it/s][2025-01-30 01:54:51][root][INFO] - Training Epoch: 1/2, step 481/107898 completed (loss: 0.9395885467529297, acc: 0.5)
[2025-01-30 01:54:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 483/107898 [02:41<9:26:10,  3.16it/s][2025-01-30 01:54:51][root][INFO] - Training Epoch: 1/2, step 482/107898 completed (loss: 1.8877328634262085, acc: 0.6842105388641357)
[2025-01-30 01:54:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 484/107898 [02:41<9:32:53,  3.12it/s][2025-01-30 01:54:51][root][INFO] - Training Epoch: 1/2, step 483/107898 completed (loss: 2.904177188873291, acc: 0.6666666865348816)
[2025-01-30 01:54:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 485/107898 [02:42<9:42:00,  3.08it/s][2025-01-30 01:54:52][root][INFO] - Training Epoch: 1/2, step 484/107898 completed (loss: 0.4283575713634491, acc: 0.9166666865348816)
[2025-01-30 01:54:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 486/107898 [02:42<9:49:01,  3.04it/s][2025-01-30 01:54:52][root][INFO] - Training Epoch: 1/2, step 485/107898 completed (loss: 0.04888027161359787, acc: 1.0)
[2025-01-30 01:54:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 487/107898 [02:42<9:38:37,  3.09it/s][2025-01-30 01:54:52][root][INFO] - Training Epoch: 1/2, step 486/107898 completed (loss: 0.11469583958387375, acc: 1.0)
[2025-01-30 01:54:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 488/107898 [02:43<9:49:42,  3.04it/s][2025-01-30 01:54:53][root][INFO] - Training Epoch: 1/2, step 487/107898 completed (loss: 0.49419620633125305, acc: 0.7272727489471436)
[2025-01-30 01:54:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 489/107898 [02:43<9:54:21,  3.01it/s][2025-01-30 01:54:53][root][INFO] - Training Epoch: 1/2, step 488/107898 completed (loss: 3.726797580718994, acc: 0.4000000059604645)
[2025-01-30 01:54:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 490/107898 [02:43<9:54:45,  3.01it/s][2025-01-30 01:54:53][root][INFO] - Training Epoch: 1/2, step 489/107898 completed (loss: 0.42159998416900635, acc: 1.0)
[2025-01-30 01:54:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 491/107898 [02:44<9:35:40,  3.11it/s][2025-01-30 01:54:54][root][INFO] - Training Epoch: 1/2, step 490/107898 completed (loss: 0.4797515571117401, acc: 0.9090909361839294)
[2025-01-30 01:54:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 492/107898 [02:44<9:28:13,  3.15it/s][2025-01-30 01:54:54][root][INFO] - Training Epoch: 1/2, step 491/107898 completed (loss: 0.2802806496620178, acc: 1.0)
[2025-01-30 01:54:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 493/107898 [02:44<9:24:26,  3.17it/s][2025-01-30 01:54:54][root][INFO] - Training Epoch: 1/2, step 492/107898 completed (loss: 0.6468972563743591, acc: 0.75)
[2025-01-30 01:54:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 494/107898 [02:45<9:13:24,  3.23it/s][2025-01-30 01:54:54][root][INFO] - Training Epoch: 1/2, step 493/107898 completed (loss: 1.6385239362716675, acc: 0.625)
[2025-01-30 01:54:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 495/107898 [02:45<9:16:38,  3.22it/s][2025-01-30 01:54:55][root][INFO] - Training Epoch: 1/2, step 494/107898 completed (loss: 1.8009368181228638, acc: 0.6470588445663452)
[2025-01-30 01:54:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 496/107898 [02:45<9:25:34,  3.17it/s][2025-01-30 01:54:55][root][INFO] - Training Epoch: 1/2, step 495/107898 completed (loss: 1.057076334953308, acc: 0.75)
[2025-01-30 01:54:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 497/107898 [02:46<9:35:00,  3.11it/s][2025-01-30 01:54:55][root][INFO] - Training Epoch: 1/2, step 496/107898 completed (loss: 0.11911813169717789, acc: 1.0)
[2025-01-30 01:54:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 498/107898 [02:46<9:44:34,  3.06it/s][2025-01-30 01:54:56][root][INFO] - Training Epoch: 1/2, step 497/107898 completed (loss: 1.6205962896347046, acc: 0.7368420958518982)
[2025-01-30 01:54:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 499/107898 [02:46<9:48:41,  3.04it/s][2025-01-30 01:54:56][root][INFO] - Training Epoch: 1/2, step 498/107898 completed (loss: 2.16015625, acc: 0.5625)
[2025-01-30 01:54:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 500/107898 [02:47<9:38:04,  3.10it/s][2025-01-30 01:54:56][root][INFO] - Training Epoch: 1/2, step 499/107898 completed (loss: 0.02804575487971306, acc: 1.0)
[2025-01-30 01:54:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 501/107898 [02:47<9:33:48,  3.12it/s][2025-01-30 01:54:57][root][INFO] - Training Epoch: 1/2, step 500/107898 completed (loss: 3.251662254333496, acc: 0.5)
[2025-01-30 01:54:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 502/107898 [02:47<9:33:24,  3.12it/s][2025-01-30 01:54:57][root][INFO] - Training Epoch: 1/2, step 501/107898 completed (loss: 1.22174072265625, acc: 0.692307710647583)
[2025-01-30 01:54:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 503/107898 [02:48<9:42:13,  3.07it/s][2025-01-30 01:54:57][root][INFO] - Training Epoch: 1/2, step 502/107898 completed (loss: 0.7212109565734863, acc: 0.8518518805503845)
[2025-01-30 01:54:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 504/107898 [02:48<9:27:01,  3.16it/s][2025-01-30 01:54:58][root][INFO] - Training Epoch: 1/2, step 503/107898 completed (loss: 1.4167344570159912, acc: 0.5714285969734192)
[2025-01-30 01:54:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 505/107898 [02:48<9:34:42,  3.11it/s][2025-01-30 01:54:58][root][INFO] - Training Epoch: 1/2, step 504/107898 completed (loss: 0.01327497698366642, acc: 1.0)
[2025-01-30 01:54:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 506/107898 [02:49<9:37:44,  3.10it/s][2025-01-30 01:54:58][root][INFO] - Training Epoch: 1/2, step 505/107898 completed (loss: 0.5371699929237366, acc: 0.9166666865348816)
[2025-01-30 01:54:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 507/107898 [02:49<9:27:30,  3.15it/s][2025-01-30 01:54:59][root][INFO] - Training Epoch: 1/2, step 506/107898 completed (loss: 0.12202820181846619, acc: 1.0)
[2025-01-30 01:54:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 508/107898 [02:49<9:16:30,  3.22it/s][2025-01-30 01:54:59][root][INFO] - Training Epoch: 1/2, step 507/107898 completed (loss: 0.5925269722938538, acc: 0.800000011920929)
[2025-01-30 01:54:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 509/107898 [02:50<9:22:59,  3.18it/s][2025-01-30 01:54:59][root][INFO] - Training Epoch: 1/2, step 508/107898 completed (loss: 0.25249114632606506, acc: 1.0)
[2025-01-30 01:54:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 510/107898 [02:50<9:34:12,  3.12it/s][2025-01-30 01:55:00][root][INFO] - Training Epoch: 1/2, step 509/107898 completed (loss: 0.8655372858047485, acc: 0.8571428656578064)
[2025-01-30 01:55:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 511/107898 [02:50<9:53:44,  3.01it/s][2025-01-30 01:55:00][root][INFO] - Training Epoch: 1/2, step 510/107898 completed (loss: 1.0281636714935303, acc: 0.7878788113594055)
[2025-01-30 01:55:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 512/107898 [02:51<9:45:33,  3.06it/s][2025-01-30 01:55:00][root][INFO] - Training Epoch: 1/2, step 511/107898 completed (loss: 1.0579699277877808, acc: 0.7142857313156128)
[2025-01-30 01:55:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 513/107898 [02:51<9:41:44,  3.08it/s][2025-01-30 01:55:01][root][INFO] - Training Epoch: 1/2, step 512/107898 completed (loss: 0.9800522327423096, acc: 0.7916666865348816)
[2025-01-30 01:55:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 514/107898 [02:51<9:45:17,  3.06it/s][2025-01-30 01:55:01][root][INFO] - Training Epoch: 1/2, step 513/107898 completed (loss: 1.110737681388855, acc: 0.5)
[2025-01-30 01:55:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 515/107898 [02:51<9:41:58,  3.08it/s][2025-01-30 01:55:01][root][INFO] - Training Epoch: 1/2, step 514/107898 completed (loss: 1.2900011539459229, acc: 0.625)
[2025-01-30 01:55:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 516/107898 [02:52<9:29:04,  3.14it/s][2025-01-30 01:55:02][root][INFO] - Training Epoch: 1/2, step 515/107898 completed (loss: 0.007916637696325779, acc: 1.0)
[2025-01-30 01:55:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 517/107898 [02:52<9:18:38,  3.20it/s][2025-01-30 01:55:02][root][INFO] - Training Epoch: 1/2, step 516/107898 completed (loss: 0.01454534288495779, acc: 1.0)
[2025-01-30 01:55:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 518/107898 [02:52<9:16:33,  3.22it/s][2025-01-30 01:55:02][root][INFO] - Training Epoch: 1/2, step 517/107898 completed (loss: 1.8121471405029297, acc: 0.46666666865348816)
[2025-01-30 01:55:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 519/107898 [02:53<9:11:07,  3.25it/s][2025-01-30 01:55:02][root][INFO] - Training Epoch: 1/2, step 518/107898 completed (loss: 0.003823226783424616, acc: 1.0)
[2025-01-30 01:55:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 520/107898 [02:53<9:15:47,  3.22it/s][2025-01-30 01:55:03][root][INFO] - Training Epoch: 1/2, step 519/107898 completed (loss: 1.4103913307189941, acc: 0.7586206793785095)
[2025-01-30 01:55:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 521/107898 [02:53<9:12:20,  3.24it/s][2025-01-30 01:55:03][root][INFO] - Training Epoch: 1/2, step 520/107898 completed (loss: 0.15217679738998413, acc: 1.0)
[2025-01-30 01:55:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 522/107898 [02:54<9:02:47,  3.30it/s][2025-01-30 01:55:03][root][INFO] - Training Epoch: 1/2, step 521/107898 completed (loss: 2.6008362770080566, acc: 0.5)
[2025-01-30 01:55:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 523/107898 [02:54<9:11:55,  3.24it/s][2025-01-30 01:55:04][root][INFO] - Training Epoch: 1/2, step 522/107898 completed (loss: 0.9350877404212952, acc: 0.875)
[2025-01-30 01:55:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 524/107898 [02:54<9:20:02,  3.20it/s][2025-01-30 01:55:04][root][INFO] - Training Epoch: 1/2, step 523/107898 completed (loss: 1.2083489894866943, acc: 0.7272727489471436)
[2025-01-30 01:55:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 525/107898 [02:55<9:01:16,  3.31it/s][2025-01-30 01:55:04][root][INFO] - Training Epoch: 1/2, step 524/107898 completed (loss: 7.089754104614258, acc: 0.0)
[2025-01-30 01:55:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 526/107898 [02:55<9:11:13,  3.25it/s][2025-01-30 01:55:05][root][INFO] - Training Epoch: 1/2, step 525/107898 completed (loss: 1.775933027267456, acc: 0.6666666865348816)
[2025-01-30 01:55:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 527/107898 [02:55<9:08:56,  3.26it/s][2025-01-30 01:55:05][root][INFO] - Training Epoch: 1/2, step 526/107898 completed (loss: 0.01329490914940834, acc: 1.0)
[2025-01-30 01:55:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 528/107898 [02:56<9:40:16,  3.08it/s][2025-01-30 01:55:05][root][INFO] - Training Epoch: 1/2, step 527/107898 completed (loss: 1.4759411811828613, acc: 0.5)
[2025-01-30 01:55:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 529/107898 [02:56<9:48:21,  3.04it/s][2025-01-30 01:55:06][root][INFO] - Training Epoch: 1/2, step 528/107898 completed (loss: 3.881108522415161, acc: 0.20000000298023224)
[2025-01-30 01:55:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 530/107898 [02:56<9:36:02,  3.11it/s][2025-01-30 01:55:06][root][INFO] - Training Epoch: 1/2, step 529/107898 completed (loss: 1.5115394592285156, acc: 0.6153846383094788)
[2025-01-30 01:55:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 531/107898 [02:56<9:23:01,  3.18it/s][2025-01-30 01:55:06][root][INFO] - Training Epoch: 1/2, step 530/107898 completed (loss: 2.650296211242676, acc: 0.3333333432674408)
[2025-01-30 01:55:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 532/107898 [02:57<9:10:29,  3.25it/s][2025-01-30 01:55:07][root][INFO] - Training Epoch: 1/2, step 531/107898 completed (loss: 0.00436799880117178, acc: 1.0)
[2025-01-30 01:55:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 533/107898 [02:57<9:06:09,  3.28it/s][2025-01-30 01:55:07][root][INFO] - Training Epoch: 1/2, step 532/107898 completed (loss: 0.0038406408857554197, acc: 1.0)
[2025-01-30 01:55:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 534/107898 [02:57<9:15:32,  3.22it/s][2025-01-30 01:55:07][root][INFO] - Training Epoch: 1/2, step 533/107898 completed (loss: 0.05941738560795784, acc: 1.0)
[2025-01-30 01:55:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 535/107898 [02:58<9:13:31,  3.23it/s][2025-01-30 01:55:07][root][INFO] - Training Epoch: 1/2, step 534/107898 completed (loss: 1.139107584953308, acc: 0.75)
[2025-01-30 01:55:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 536/107898 [02:58<9:21:39,  3.19it/s][2025-01-30 01:55:08][root][INFO] - Training Epoch: 1/2, step 535/107898 completed (loss: 0.11866400390863419, acc: 1.0)
[2025-01-30 01:55:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 537/107898 [02:58<9:08:38,  3.26it/s][2025-01-30 01:55:08][root][INFO] - Training Epoch: 1/2, step 536/107898 completed (loss: 0.42671072483062744, acc: 0.8888888955116272)
[2025-01-30 01:55:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 538/107898 [02:59<9:01:56,  3.30it/s][2025-01-30 01:55:08][root][INFO] - Training Epoch: 1/2, step 537/107898 completed (loss: 3.4572620391845703, acc: 0.4000000059604645)
[2025-01-30 01:55:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   0%|[34m          [0m| 539/107898 [02:59<9:07:50,  3.27it/s][2025-01-30 01:55:09][root][INFO] - Training Epoch: 1/2, step 538/107898 completed (loss: 2.4272499084472656, acc: 0.6666666865348816)
[2025-01-30 01:55:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 540/107898 [02:59<9:25:30,  3.16it/s][2025-01-30 01:55:09][root][INFO] - Training Epoch: 1/2, step 539/107898 completed (loss: 0.6168182492256165, acc: 0.9130434989929199)
[2025-01-30 01:55:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 541/107898 [03:00<9:26:46,  3.16it/s][2025-01-30 01:55:09][root][INFO] - Training Epoch: 1/2, step 540/107898 completed (loss: 2.305981397628784, acc: 0.625)
[2025-01-30 01:55:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 542/107898 [03:00<9:27:38,  3.15it/s][2025-01-30 01:55:10][root][INFO] - Training Epoch: 1/2, step 541/107898 completed (loss: 1.4279502630233765, acc: 0.5)
[2025-01-30 01:55:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 543/107898 [03:00<9:49:29,  3.04it/s][2025-01-30 01:55:10][root][INFO] - Training Epoch: 1/2, step 542/107898 completed (loss: 1.0104988813400269, acc: 1.0)
[2025-01-30 01:55:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 544/107898 [03:01<10:03:55,  2.96it/s][2025-01-30 01:55:10][root][INFO] - Training Epoch: 1/2, step 543/107898 completed (loss: 2.67392897605896, acc: 0.5909090638160706)
[2025-01-30 01:55:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 545/107898 [03:01<9:43:17,  3.07it/s] [2025-01-30 01:55:11][root][INFO] - Training Epoch: 1/2, step 544/107898 completed (loss: 0.01515866070985794, acc: 1.0)
[2025-01-30 01:55:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 546/107898 [03:01<9:31:08,  3.13it/s][2025-01-30 01:55:11][root][INFO] - Training Epoch: 1/2, step 545/107898 completed (loss: 0.004637352656573057, acc: 1.0)
[2025-01-30 01:55:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 547/107898 [03:01<9:19:13,  3.20it/s][2025-01-30 01:55:11][root][INFO] - Training Epoch: 1/2, step 546/107898 completed (loss: 1.0943936109542847, acc: 0.8214285969734192)
[2025-01-30 01:55:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 548/107898 [03:02<9:39:14,  3.09it/s][2025-01-30 01:55:12][root][INFO] - Training Epoch: 1/2, step 547/107898 completed (loss: 0.9305702447891235, acc: 0.7272727489471436)
[2025-01-30 01:55:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 549/107898 [03:02<9:36:17,  3.10it/s][2025-01-30 01:55:12][root][INFO] - Training Epoch: 1/2, step 548/107898 completed (loss: 0.023271700367331505, acc: 1.0)
[2025-01-30 01:55:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 550/107898 [03:02<9:30:30,  3.14it/s][2025-01-30 01:55:12][root][INFO] - Training Epoch: 1/2, step 549/107898 completed (loss: 0.1791723221540451, acc: 1.0)
[2025-01-30 01:55:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 551/107898 [03:03<9:59:25,  2.98it/s][2025-01-30 01:55:13][root][INFO] - Training Epoch: 1/2, step 550/107898 completed (loss: 0.08073970675468445, acc: 1.0)
[2025-01-30 01:55:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 552/107898 [03:03<10:05:32,  2.95it/s][2025-01-30 01:55:13][root][INFO] - Training Epoch: 1/2, step 551/107898 completed (loss: 1.125045657157898, acc: 0.75)
[2025-01-30 01:55:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 553/107898 [03:03<9:39:01,  3.09it/s] [2025-01-30 01:55:13][root][INFO] - Training Epoch: 1/2, step 552/107898 completed (loss: 2.50464129447937, acc: 0.4444444477558136)
[2025-01-30 01:55:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 554/107898 [03:04<9:34:53,  3.11it/s][2025-01-30 01:55:14][root][INFO] - Training Epoch: 1/2, step 553/107898 completed (loss: 1.1447851657867432, acc: 0.692307710647583)
[2025-01-30 01:55:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 555/107898 [03:04<9:47:37,  3.04it/s][2025-01-30 01:55:14][root][INFO] - Training Epoch: 1/2, step 554/107898 completed (loss: 1.4324138164520264, acc: 0.7692307829856873)
[2025-01-30 01:55:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 556/107898 [03:04<9:24:48,  3.17it/s][2025-01-30 01:55:14][root][INFO] - Training Epoch: 1/2, step 555/107898 completed (loss: 0.9060177803039551, acc: 0.8125)
[2025-01-30 01:55:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 557/107898 [03:05<9:12:11,  3.24it/s][2025-01-30 01:55:15][root][INFO] - Training Epoch: 1/2, step 556/107898 completed (loss: 0.47087720036506653, acc: 1.0)
[2025-01-30 01:55:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 558/107898 [03:05<8:59:10,  3.32it/s][2025-01-30 01:55:15][root][INFO] - Training Epoch: 1/2, step 557/107898 completed (loss: 1.1798573732376099, acc: 0.5)
[2025-01-30 01:55:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 559/107898 [03:05<9:01:21,  3.30it/s][2025-01-30 01:55:15][root][INFO] - Training Epoch: 1/2, step 558/107898 completed (loss: 1.67145574092865, acc: 0.5)
[2025-01-30 01:55:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 560/107898 [03:06<9:24:27,  3.17it/s][2025-01-30 01:55:15][root][INFO] - Training Epoch: 1/2, step 559/107898 completed (loss: 1.6182018518447876, acc: 0.699999988079071)
[2025-01-30 01:55:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 561/107898 [03:06<9:25:30,  3.16it/s][2025-01-30 01:55:16][root][INFO] - Training Epoch: 1/2, step 560/107898 completed (loss: 0.012727377936244011, acc: 1.0)
[2025-01-30 01:55:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 562/107898 [03:06<9:57:10,  3.00it/s][2025-01-30 01:55:16][root][INFO] - Training Epoch: 1/2, step 561/107898 completed (loss: 0.05462437868118286, acc: 1.0)
[2025-01-30 01:55:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 563/107898 [03:07<10:15:04,  2.91it/s][2025-01-30 01:55:17][root][INFO] - Training Epoch: 1/2, step 562/107898 completed (loss: 0.009309958666563034, acc: 1.0)
[2025-01-30 01:55:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 564/107898 [03:07<10:09:33,  2.93it/s][2025-01-30 01:55:17][root][INFO] - Training Epoch: 1/2, step 563/107898 completed (loss: 1.3675843477249146, acc: 0.5)
[2025-01-30 01:55:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 565/107898 [03:07<10:08:32,  2.94it/s][2025-01-30 01:55:17][root][INFO] - Training Epoch: 1/2, step 564/107898 completed (loss: 2.705618381500244, acc: 0.5333333611488342)
[2025-01-30 01:55:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 566/107898 [03:08<10:36:22,  2.81it/s][2025-01-30 01:55:18][root][INFO] - Training Epoch: 1/2, step 565/107898 completed (loss: 0.25864744186401367, acc: 0.8888888955116272)
[2025-01-30 01:55:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 567/107898 [03:08<10:35:50,  2.81it/s][2025-01-30 01:55:18][root][INFO] - Training Epoch: 1/2, step 566/107898 completed (loss: 4.487033367156982, acc: 0.125)
[2025-01-30 01:55:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 568/107898 [03:08<10:29:29,  2.84it/s][2025-01-30 01:55:18][root][INFO] - Training Epoch: 1/2, step 567/107898 completed (loss: 0.11404022574424744, acc: 1.0)
[2025-01-30 01:55:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 569/107898 [03:09<10:37:55,  2.80it/s][2025-01-30 01:55:19][root][INFO] - Training Epoch: 1/2, step 568/107898 completed (loss: 0.8301869034767151, acc: 0.8181818127632141)
[2025-01-30 01:55:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 570/107898 [03:09<10:27:40,  2.85it/s][2025-01-30 01:55:19][root][INFO] - Training Epoch: 1/2, step 569/107898 completed (loss: 2.113705635070801, acc: 0.5)
[2025-01-30 01:55:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 571/107898 [03:10<10:13:54,  2.91it/s][2025-01-30 01:55:19][root][INFO] - Training Epoch: 1/2, step 570/107898 completed (loss: 1.4889341592788696, acc: 0.7142857313156128)
[2025-01-30 01:55:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 572/107898 [03:10<10:05:40,  2.95it/s][2025-01-30 01:55:20][root][INFO] - Training Epoch: 1/2, step 571/107898 completed (loss: 1.7280281782150269, acc: 0.4545454680919647)
[2025-01-30 01:55:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 573/107898 [03:10<10:04:33,  2.96it/s][2025-01-30 01:55:20][root][INFO] - Training Epoch: 1/2, step 572/107898 completed (loss: 1.7271329164505005, acc: 0.6666666865348816)
[2025-01-30 01:55:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 574/107898 [03:10<9:46:36,  3.05it/s] [2025-01-30 01:55:20][root][INFO] - Training Epoch: 1/2, step 573/107898 completed (loss: 3.2651526927948, acc: 0.4444444477558136)
[2025-01-30 01:55:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 575/107898 [03:11<9:35:45,  3.11it/s][2025-01-30 01:55:21][root][INFO] - Training Epoch: 1/2, step 574/107898 completed (loss: 2.446812868118286, acc: 0.6666666865348816)
[2025-01-30 01:55:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 576/107898 [03:11<9:54:04,  3.01it/s][2025-01-30 01:55:21][root][INFO] - Training Epoch: 1/2, step 575/107898 completed (loss: 1.047472596168518, acc: 0.875)
[2025-01-30 01:55:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 577/107898 [03:11<9:51:11,  3.03it/s][2025-01-30 01:55:21][root][INFO] - Training Epoch: 1/2, step 576/107898 completed (loss: 1.1118110418319702, acc: 0.8461538553237915)
[2025-01-30 01:55:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 578/107898 [03:12<9:31:53,  3.13it/s][2025-01-30 01:55:22][root][INFO] - Training Epoch: 1/2, step 577/107898 completed (loss: 1.0661495923995972, acc: 0.8181818127632141)
[2025-01-30 01:55:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 579/107898 [03:12<9:26:53,  3.16it/s][2025-01-30 01:55:22][root][INFO] - Training Epoch: 1/2, step 578/107898 completed (loss: 0.3928653597831726, acc: 0.8965517282485962)
[2025-01-30 01:55:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 580/107898 [03:12<9:53:04,  3.02it/s][2025-01-30 01:55:22][root][INFO] - Training Epoch: 1/2, step 579/107898 completed (loss: 0.8623437881469727, acc: 0.807692289352417)
[2025-01-30 01:55:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 581/107898 [03:13<10:12:32,  2.92it/s][2025-01-30 01:55:23][root][INFO] - Training Epoch: 1/2, step 580/107898 completed (loss: 0.2546776235103607, acc: 1.0)
[2025-01-30 01:55:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 582/107898 [03:13<10:16:54,  2.90it/s][2025-01-30 01:55:23][root][INFO] - Training Epoch: 1/2, step 581/107898 completed (loss: 1.644107699394226, acc: 0.6785714030265808)
[2025-01-30 01:55:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 583/107898 [03:13<9:54:50,  3.01it/s] [2025-01-30 01:55:23][root][INFO] - Training Epoch: 1/2, step 582/107898 completed (loss: 0.9007788896560669, acc: 0.7777777910232544)
[2025-01-30 01:55:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 584/107898 [03:14<9:44:42,  3.06it/s][2025-01-30 01:55:24][root][INFO] - Training Epoch: 1/2, step 583/107898 completed (loss: 3.8718295097351074, acc: 0.3333333432674408)
[2025-01-30 01:55:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 585/107898 [03:14<10:01:31,  2.97it/s][2025-01-30 01:55:24][root][INFO] - Training Epoch: 1/2, step 584/107898 completed (loss: 0.6078975796699524, acc: 0.75)
[2025-01-30 01:55:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 586/107898 [03:14<9:59:04,  2.99it/s] [2025-01-30 01:55:24][root][INFO] - Training Epoch: 1/2, step 585/107898 completed (loss: 1.3992172479629517, acc: 0.699999988079071)
[2025-01-30 01:55:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 587/107898 [03:15<9:41:17,  3.08it/s][2025-01-30 01:55:25][root][INFO] - Training Epoch: 1/2, step 586/107898 completed (loss: 3.8995516300201416, acc: 0.3333333432674408)
[2025-01-30 01:55:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 588/107898 [03:15<9:46:50,  3.05it/s][2025-01-30 01:55:25][root][INFO] - Training Epoch: 1/2, step 587/107898 completed (loss: 0.16502878069877625, acc: 1.0)
[2025-01-30 01:55:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 589/107898 [03:15<9:33:14,  3.12it/s][2025-01-30 01:55:25][root][INFO] - Training Epoch: 1/2, step 588/107898 completed (loss: 0.8175007700920105, acc: 0.6666666865348816)
[2025-01-30 01:55:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 590/107898 [03:16<9:25:19,  3.16it/s][2025-01-30 01:55:26][root][INFO] - Training Epoch: 1/2, step 589/107898 completed (loss: 0.023529725149273872, acc: 1.0)
[2025-01-30 01:55:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 591/107898 [03:16<9:19:05,  3.20it/s][2025-01-30 01:55:26][root][INFO] - Training Epoch: 1/2, step 590/107898 completed (loss: 0.7330818772315979, acc: 0.8333333134651184)
[2025-01-30 01:55:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 592/107898 [03:16<9:08:22,  3.26it/s][2025-01-30 01:55:26][root][INFO] - Training Epoch: 1/2, step 591/107898 completed (loss: 0.02512008510529995, acc: 1.0)
[2025-01-30 01:55:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 593/107898 [03:17<10:00:18,  2.98it/s][2025-01-30 01:55:27][root][INFO] - Training Epoch: 1/2, step 592/107898 completed (loss: 3.115755081176758, acc: 0.4375)
[2025-01-30 01:55:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 594/107898 [03:17<10:09:33,  2.93it/s][2025-01-30 01:55:27][root][INFO] - Training Epoch: 1/2, step 593/107898 completed (loss: 1.1411030292510986, acc: 0.7857142686843872)
[2025-01-30 01:55:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 595/107898 [03:17<9:44:12,  3.06it/s] [2025-01-30 01:55:27][root][INFO] - Training Epoch: 1/2, step 594/107898 completed (loss: 3.9713144302368164, acc: 0.0)
[2025-01-30 01:55:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 596/107898 [03:18<9:07:45,  3.26it/s][2025-01-30 01:55:27][root][INFO] - Training Epoch: 1/2, step 595/107898 completed (loss: 0.05936150625348091, acc: 1.0)
[2025-01-30 01:55:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 597/107898 [03:18<8:38:05,  3.45it/s][2025-01-30 01:55:28][root][INFO] - Training Epoch: 1/2, step 596/107898 completed (loss: 1.0241808891296387, acc: 0.6000000238418579)
[2025-01-30 01:55:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 598/107898 [03:18<9:11:22,  3.24it/s][2025-01-30 01:55:28][root][INFO] - Training Epoch: 1/2, step 597/107898 completed (loss: 0.2130603790283203, acc: 1.0)
[2025-01-30 01:55:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 599/107898 [03:19<9:14:51,  3.22it/s][2025-01-30 01:55:28][root][INFO] - Training Epoch: 1/2, step 598/107898 completed (loss: 0.45149868726730347, acc: 1.0)
[2025-01-30 01:55:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 600/107898 [03:19<8:55:21,  3.34it/s][2025-01-30 01:55:29][root][INFO] - Training Epoch: 1/2, step 599/107898 completed (loss: 0.03207595273852348, acc: 1.0)
[2025-01-30 01:55:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 601/107898 [03:19<9:24:46,  3.17it/s][2025-01-30 01:55:29][root][INFO] - Training Epoch: 1/2, step 600/107898 completed (loss: 0.03350594639778137, acc: 1.0)
[2025-01-30 01:55:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 602/107898 [03:20<9:42:11,  3.07it/s][2025-01-30 01:55:29][root][INFO] - Training Epoch: 1/2, step 601/107898 completed (loss: 1.4551316499710083, acc: 0.5)
[2025-01-30 01:55:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 603/107898 [03:20<9:56:00,  3.00it/s][2025-01-30 01:55:30][root][INFO] - Training Epoch: 1/2, step 602/107898 completed (loss: 1.5590417385101318, acc: 0.761904776096344)
[2025-01-30 01:55:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 604/107898 [03:20<10:07:43,  2.94it/s][2025-01-30 01:55:30][root][INFO] - Training Epoch: 1/2, step 603/107898 completed (loss: 0.971490204334259, acc: 0.6666666865348816)
[2025-01-30 01:55:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 605/107898 [03:21<9:54:23,  3.01it/s] [2025-01-30 01:55:30][root][INFO] - Training Epoch: 1/2, step 604/107898 completed (loss: 0.05644072964787483, acc: 1.0)
[2025-01-30 01:55:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 606/107898 [03:21<10:17:22,  2.90it/s][2025-01-30 01:55:31][root][INFO] - Training Epoch: 1/2, step 605/107898 completed (loss: 0.9563449621200562, acc: 0.7777777910232544)
[2025-01-30 01:55:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 607/107898 [03:21<9:50:34,  3.03it/s] [2025-01-30 01:55:31][root][INFO] - Training Epoch: 1/2, step 606/107898 completed (loss: 1.209160566329956, acc: 0.7272727489471436)
[2025-01-30 01:55:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 608/107898 [03:22<10:06:42,  2.95it/s][2025-01-30 01:55:31][root][INFO] - Training Epoch: 1/2, step 607/107898 completed (loss: 4.129446983337402, acc: 0.375)
[2025-01-30 01:55:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 609/107898 [03:22<10:18:41,  2.89it/s][2025-01-30 01:55:32][root][INFO] - Training Epoch: 1/2, step 608/107898 completed (loss: 0.291930228471756, acc: 0.8999999761581421)
[2025-01-30 01:55:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 610/107898 [03:22<9:54:41,  3.01it/s] [2025-01-30 01:55:32][root][INFO] - Training Epoch: 1/2, step 609/107898 completed (loss: 0.8981738090515137, acc: 0.75)
[2025-01-30 01:55:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 611/107898 [03:23<10:09:58,  2.93it/s][2025-01-30 01:55:32][root][INFO] - Training Epoch: 1/2, step 610/107898 completed (loss: 0.5472619533538818, acc: 0.8333333134651184)
[2025-01-30 01:55:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 612/107898 [03:23<10:16:16,  2.90it/s][2025-01-30 01:55:33][root][INFO] - Training Epoch: 1/2, step 611/107898 completed (loss: 0.08379781246185303, acc: 1.0)
[2025-01-30 01:55:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 613/107898 [03:23<10:29:07,  2.84it/s][2025-01-30 01:55:33][root][INFO] - Training Epoch: 1/2, step 612/107898 completed (loss: 1.4977693557739258, acc: 0.7037037014961243)
[2025-01-30 01:55:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 614/107898 [03:24<10:05:00,  2.96it/s][2025-01-30 01:55:33][root][INFO] - Training Epoch: 1/2, step 613/107898 completed (loss: 1.9753856658935547, acc: 0.6111111044883728)
[2025-01-30 01:55:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 615/107898 [03:24<10:30:18,  2.84it/s][2025-01-30 01:55:34][root][INFO] - Training Epoch: 1/2, step 614/107898 completed (loss: 1.7524904012680054, acc: 0.6111111044883728)
[2025-01-30 01:55:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 616/107898 [03:24<10:00:11,  2.98it/s][2025-01-30 01:55:34][root][INFO] - Training Epoch: 1/2, step 615/107898 completed (loss: 0.043747466057538986, acc: 1.0)
[2025-01-30 01:55:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 617/107898 [03:25<10:03:10,  2.96it/s][2025-01-30 01:55:34][root][INFO] - Training Epoch: 1/2, step 616/107898 completed (loss: 1.2055829763412476, acc: 0.5)
[2025-01-30 01:55:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 618/107898 [03:25<10:09:16,  2.93it/s][2025-01-30 01:55:35][root][INFO] - Training Epoch: 1/2, step 617/107898 completed (loss: 2.1835591793060303, acc: 0.5555555820465088)
[2025-01-30 01:55:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 619/107898 [03:25<9:57:11,  2.99it/s] [2025-01-30 01:55:35][root][INFO] - Training Epoch: 1/2, step 618/107898 completed (loss: 0.011613754555583, acc: 1.0)
[2025-01-30 01:55:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 620/107898 [03:26<9:48:47,  3.04it/s][2025-01-30 01:55:35][root][INFO] - Training Epoch: 1/2, step 619/107898 completed (loss: 2.0011253356933594, acc: 0.5714285969734192)
[2025-01-30 01:55:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 621/107898 [03:26<9:34:13,  3.11it/s][2025-01-30 01:55:36][root][INFO] - Training Epoch: 1/2, step 620/107898 completed (loss: 0.8818857669830322, acc: 0.75)
[2025-01-30 01:55:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 622/107898 [03:26<9:16:10,  3.21it/s][2025-01-30 01:55:36][root][INFO] - Training Epoch: 1/2, step 621/107898 completed (loss: 3.2920238971710205, acc: 0.3333333432674408)
[2025-01-30 01:55:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 623/107898 [03:27<9:12:14,  3.24it/s][2025-01-30 01:55:36][root][INFO] - Training Epoch: 1/2, step 622/107898 completed (loss: 0.01597592979669571, acc: 1.0)
[2025-01-30 01:55:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 624/107898 [03:27<9:47:04,  3.05it/s][2025-01-30 01:55:37][root][INFO] - Training Epoch: 1/2, step 623/107898 completed (loss: 0.9132229685783386, acc: 0.7647058963775635)
[2025-01-30 01:55:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 625/107898 [03:27<9:53:36,  3.01it/s][2025-01-30 01:55:37][root][INFO] - Training Epoch: 1/2, step 624/107898 completed (loss: 2.02311635017395, acc: 0.6666666865348816)
[2025-01-30 01:55:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 626/107898 [03:28<10:02:03,  2.97it/s][2025-01-30 01:55:37][root][INFO] - Training Epoch: 1/2, step 625/107898 completed (loss: 0.2225450724363327, acc: 1.0)
[2025-01-30 01:55:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 627/107898 [03:28<9:42:03,  3.07it/s] [2025-01-30 01:55:38][root][INFO] - Training Epoch: 1/2, step 626/107898 completed (loss: 5.102532863616943, acc: 0.3125)
[2025-01-30 01:55:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 628/107898 [03:28<9:38:02,  3.09it/s][2025-01-30 01:55:38][root][INFO] - Training Epoch: 1/2, step 627/107898 completed (loss: 0.24994763731956482, acc: 1.0)
[2025-01-30 01:55:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 629/107898 [03:29<10:01:37,  2.97it/s][2025-01-30 01:55:38][root][INFO] - Training Epoch: 1/2, step 628/107898 completed (loss: 5.063967704772949, acc: 0.2142857164144516)
[2025-01-30 01:55:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 630/107898 [03:29<10:02:07,  2.97it/s][2025-01-30 01:55:39][root][INFO] - Training Epoch: 1/2, step 629/107898 completed (loss: 0.42025622725486755, acc: 1.0)
[2025-01-30 01:55:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 631/107898 [03:29<9:48:42,  3.04it/s] [2025-01-30 01:55:39][root][INFO] - Training Epoch: 1/2, step 630/107898 completed (loss: 1.2043696641921997, acc: 0.7333333492279053)
[2025-01-30 01:55:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 632/107898 [03:30<10:03:48,  2.96it/s][2025-01-30 01:55:39][root][INFO] - Training Epoch: 1/2, step 631/107898 completed (loss: 0.4332144856452942, acc: 1.0)
[2025-01-30 01:55:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 633/107898 [03:30<10:03:25,  2.96it/s][2025-01-30 01:55:40][root][INFO] - Training Epoch: 1/2, step 632/107898 completed (loss: 0.17692969739437103, acc: 1.0)
[2025-01-30 01:55:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 634/107898 [03:30<10:18:30,  2.89it/s][2025-01-30 01:55:40][root][INFO] - Training Epoch: 1/2, step 633/107898 completed (loss: 2.53493070602417, acc: 0.6666666865348816)
[2025-01-30 01:55:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 635/107898 [03:31<10:09:41,  2.93it/s][2025-01-30 01:55:40][root][INFO] - Training Epoch: 1/2, step 634/107898 completed (loss: 2.2212560176849365, acc: 0.625)
[2025-01-30 01:55:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 636/107898 [03:31<9:58:37,  2.99it/s] [2025-01-30 01:55:41][root][INFO] - Training Epoch: 1/2, step 635/107898 completed (loss: 2.3042142391204834, acc: 0.6190476417541504)
[2025-01-30 01:55:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 637/107898 [03:31<9:45:51,  3.05it/s][2025-01-30 01:55:41][root][INFO] - Training Epoch: 1/2, step 636/107898 completed (loss: 1.2192479372024536, acc: 0.7692307829856873)
[2025-01-30 01:55:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 638/107898 [03:32<9:25:56,  3.16it/s][2025-01-30 01:55:41][root][INFO] - Training Epoch: 1/2, step 637/107898 completed (loss: 0.07748478651046753, acc: 1.0)
[2025-01-30 01:55:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 639/107898 [03:32<9:30:57,  3.13it/s][2025-01-30 01:55:42][root][INFO] - Training Epoch: 1/2, step 638/107898 completed (loss: 2.583646297454834, acc: 0.6000000238418579)
[2025-01-30 01:55:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 640/107898 [03:32<9:26:58,  3.15it/s][2025-01-30 01:55:42][root][INFO] - Training Epoch: 1/2, step 639/107898 completed (loss: 0.24836750328540802, acc: 0.9473684430122375)
[2025-01-30 01:55:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 641/107898 [03:32<9:34:57,  3.11it/s][2025-01-30 01:55:42][root][INFO] - Training Epoch: 1/2, step 640/107898 completed (loss: 5.61504602432251, acc: 0.1666666716337204)
[2025-01-30 01:55:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 642/107898 [03:33<9:32:49,  3.12it/s][2025-01-30 01:55:43][root][INFO] - Training Epoch: 1/2, step 641/107898 completed (loss: 4.705295562744141, acc: 0.23529411852359772)
[2025-01-30 01:55:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 643/107898 [03:33<10:07:00,  2.94it/s][2025-01-30 01:55:43][root][INFO] - Training Epoch: 1/2, step 642/107898 completed (loss: 1.0402790307998657, acc: 0.7837837934494019)
[2025-01-30 01:55:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 644/107898 [03:34<10:06:17,  2.95it/s][2025-01-30 01:55:43][root][INFO] - Training Epoch: 1/2, step 643/107898 completed (loss: 0.2590380311012268, acc: 1.0)
[2025-01-30 01:55:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 645/107898 [03:34<9:52:17,  3.02it/s] [2025-01-30 01:55:44][root][INFO] - Training Epoch: 1/2, step 644/107898 completed (loss: 2.3002636432647705, acc: 0.4444444477558136)
[2025-01-30 01:55:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 646/107898 [03:34<9:50:58,  3.02it/s][2025-01-30 01:55:44][root][INFO] - Training Epoch: 1/2, step 645/107898 completed (loss: 0.3713564872741699, acc: 0.9230769276618958)
[2025-01-30 01:55:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 647/107898 [03:35<9:55:55,  3.00it/s][2025-01-30 01:55:44][root][INFO] - Training Epoch: 1/2, step 646/107898 completed (loss: 0.7877405285835266, acc: 0.8620689511299133)
[2025-01-30 01:55:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 648/107898 [03:35<9:47:06,  3.04it/s][2025-01-30 01:55:45][root][INFO] - Training Epoch: 1/2, step 647/107898 completed (loss: 2.473083257675171, acc: 0.75)
[2025-01-30 01:55:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 649/107898 [03:35<9:43:05,  3.07it/s][2025-01-30 01:55:45][root][INFO] - Training Epoch: 1/2, step 648/107898 completed (loss: 1.2583047151565552, acc: 0.8181818127632141)
[2025-01-30 01:55:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 650/107898 [03:35<9:40:23,  3.08it/s][2025-01-30 01:55:45][root][INFO] - Training Epoch: 1/2, step 649/107898 completed (loss: 3.8586502075195312, acc: 0.4117647111415863)
[2025-01-30 01:55:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 651/107898 [03:36<9:23:09,  3.17it/s][2025-01-30 01:55:46][root][INFO] - Training Epoch: 1/2, step 650/107898 completed (loss: 4.892885208129883, acc: 0.3333333432674408)
[2025-01-30 01:55:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 652/107898 [03:36<9:25:30,  3.16it/s][2025-01-30 01:55:46][root][INFO] - Training Epoch: 1/2, step 651/107898 completed (loss: 1.8579577207565308, acc: 0.6363636255264282)
[2025-01-30 01:55:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 653/107898 [03:36<9:18:52,  3.20it/s][2025-01-30 01:55:46][root][INFO] - Training Epoch: 1/2, step 652/107898 completed (loss: 0.6981899738311768, acc: 0.8888888955116272)
[2025-01-30 01:55:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 654/107898 [03:37<9:22:26,  3.18it/s][2025-01-30 01:55:47][root][INFO] - Training Epoch: 1/2, step 653/107898 completed (loss: 5.26073694229126, acc: 0.3333333432674408)
[2025-01-30 01:55:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 655/107898 [03:37<9:09:40,  3.25it/s][2025-01-30 01:55:47][root][INFO] - Training Epoch: 1/2, step 654/107898 completed (loss: 0.08621436357498169, acc: 1.0)
[2025-01-30 01:55:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 656/107898 [03:37<9:09:58,  3.25it/s][2025-01-30 01:55:47][root][INFO] - Training Epoch: 1/2, step 655/107898 completed (loss: 1.089477300643921, acc: 0.800000011920929)
[2025-01-30 01:55:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 657/107898 [03:38<9:35:37,  3.11it/s][2025-01-30 01:55:47][root][INFO] - Training Epoch: 1/2, step 656/107898 completed (loss: 1.8682774305343628, acc: 0.6666666865348816)
[2025-01-30 01:55:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 658/107898 [03:38<9:24:42,  3.17it/s][2025-01-30 01:55:48][root][INFO] - Training Epoch: 1/2, step 657/107898 completed (loss: 0.47868284583091736, acc: 0.9166666865348816)
[2025-01-30 01:55:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 659/107898 [03:38<9:40:37,  3.08it/s][2025-01-30 01:55:48][root][INFO] - Training Epoch: 1/2, step 658/107898 completed (loss: 0.6286637187004089, acc: 0.8571428656578064)
[2025-01-30 01:55:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 660/107898 [03:39<9:24:47,  3.16it/s][2025-01-30 01:55:48][root][INFO] - Training Epoch: 1/2, step 659/107898 completed (loss: 0.0264861062169075, acc: 1.0)
[2025-01-30 01:55:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 661/107898 [03:39<9:38:47,  3.09it/s][2025-01-30 01:55:49][root][INFO] - Training Epoch: 1/2, step 660/107898 completed (loss: 4.408801078796387, acc: 0.095238097012043)
[2025-01-30 01:55:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 662/107898 [03:39<9:51:16,  3.02it/s][2025-01-30 01:55:49][root][INFO] - Training Epoch: 1/2, step 661/107898 completed (loss: 0.7600537538528442, acc: 0.8181818127632141)
[2025-01-30 01:55:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 663/107898 [03:40<9:34:36,  3.11it/s][2025-01-30 01:55:49][root][INFO] - Training Epoch: 1/2, step 662/107898 completed (loss: 0.19377613067626953, acc: 0.9333333373069763)
[2025-01-30 01:55:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 664/107898 [03:40<9:27:58,  3.15it/s][2025-01-30 01:55:50][root][INFO] - Training Epoch: 1/2, step 663/107898 completed (loss: 5.002748966217041, acc: 0.3333333432674408)
[2025-01-30 01:55:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 665/107898 [03:40<9:35:29,  3.11it/s][2025-01-30 01:55:50][root][INFO] - Training Epoch: 1/2, step 664/107898 completed (loss: 2.645787000656128, acc: 0.5)
[2025-01-30 01:55:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 666/107898 [03:41<9:40:22,  3.08it/s][2025-01-30 01:55:50][root][INFO] - Training Epoch: 1/2, step 665/107898 completed (loss: 1.707414984703064, acc: 0.625)
[2025-01-30 01:55:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 667/107898 [03:41<9:37:36,  3.09it/s][2025-01-30 01:55:51][root][INFO] - Training Epoch: 1/2, step 666/107898 completed (loss: 0.5090155601501465, acc: 0.8965517282485962)
[2025-01-30 01:55:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 668/107898 [03:41<9:28:54,  3.14it/s][2025-01-30 01:55:51][root][INFO] - Training Epoch: 1/2, step 667/107898 completed (loss: 1.434368371963501, acc: 0.800000011920929)
[2025-01-30 01:55:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 669/107898 [03:42<9:45:34,  3.05it/s][2025-01-30 01:55:51][root][INFO] - Training Epoch: 1/2, step 668/107898 completed (loss: 1.7395497560501099, acc: 0.7333333492279053)
[2025-01-30 01:55:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 670/107898 [03:42<10:00:37,  2.98it/s][2025-01-30 01:55:52][root][INFO] - Training Epoch: 1/2, step 669/107898 completed (loss: 0.5074909925460815, acc: 0.875)
[2025-01-30 01:55:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 671/107898 [03:42<9:41:04,  3.08it/s] [2025-01-30 01:55:52][root][INFO] - Training Epoch: 1/2, step 670/107898 completed (loss: 4.280049800872803, acc: 0.3333333432674408)
[2025-01-30 01:55:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 672/107898 [03:43<9:55:25,  3.00it/s][2025-01-30 01:55:52][root][INFO] - Training Epoch: 1/2, step 671/107898 completed (loss: 4.502789497375488, acc: 0.25)
[2025-01-30 01:55:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 673/107898 [03:43<10:10:43,  2.93it/s][2025-01-30 01:55:53][root][INFO] - Training Epoch: 1/2, step 672/107898 completed (loss: 0.7898022532463074, acc: 0.8461538553237915)
[2025-01-30 01:55:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 674/107898 [03:43<9:56:35,  3.00it/s] [2025-01-30 01:55:53][root][INFO] - Training Epoch: 1/2, step 673/107898 completed (loss: 0.023384220898151398, acc: 1.0)
[2025-01-30 01:55:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 675/107898 [03:44<9:51:50,  3.02it/s][2025-01-30 01:55:53][root][INFO] - Training Epoch: 1/2, step 674/107898 completed (loss: 0.05266900360584259, acc: 1.0)
[2025-01-30 01:55:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 676/107898 [03:44<9:59:40,  2.98it/s][2025-01-30 01:55:54][root][INFO] - Training Epoch: 1/2, step 675/107898 completed (loss: 4.657806873321533, acc: 0.13333334028720856)
[2025-01-30 01:55:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 677/107898 [03:44<9:50:45,  3.02it/s][2025-01-30 01:55:54][root][INFO] - Training Epoch: 1/2, step 676/107898 completed (loss: 0.1521202027797699, acc: 1.0)
[2025-01-30 01:55:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 678/107898 [03:45<9:51:20,  3.02it/s][2025-01-30 01:55:54][root][INFO] - Training Epoch: 1/2, step 677/107898 completed (loss: 1.143393635749817, acc: 0.8181818127632141)
[2025-01-30 01:55:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 679/107898 [03:45<9:49:30,  3.03it/s][2025-01-30 01:55:55][root][INFO] - Training Epoch: 1/2, step 678/107898 completed (loss: 1.0711232423782349, acc: 0.9200000166893005)
[2025-01-30 01:55:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 680/107898 [03:45<9:51:39,  3.02it/s][2025-01-30 01:55:55][root][INFO] - Training Epoch: 1/2, step 679/107898 completed (loss: 4.5978217124938965, acc: 0.3529411852359772)
[2025-01-30 01:55:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 681/107898 [03:46<9:45:41,  3.05it/s][2025-01-30 01:55:55][root][INFO] - Training Epoch: 1/2, step 680/107898 completed (loss: 0.8719286322593689, acc: 0.8571428656578064)
[2025-01-30 01:55:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 682/107898 [03:46<9:32:19,  3.12it/s][2025-01-30 01:55:56][root][INFO] - Training Epoch: 1/2, step 681/107898 completed (loss: 2.8202877044677734, acc: 0.5714285969734192)
[2025-01-30 01:55:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 683/107898 [03:46<10:07:51,  2.94it/s][2025-01-30 01:55:56][root][INFO] - Training Epoch: 1/2, step 682/107898 completed (loss: 3.4896743297576904, acc: 0.3333333432674408)
[2025-01-30 01:55:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 684/107898 [03:47<10:09:26,  2.93it/s][2025-01-30 01:55:56][root][INFO] - Training Epoch: 1/2, step 683/107898 completed (loss: 0.6783323287963867, acc: 0.8484848737716675)
[2025-01-30 01:55:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 685/107898 [03:47<10:30:40,  2.83it/s][2025-01-30 01:55:57][root][INFO] - Training Epoch: 1/2, step 684/107898 completed (loss: 0.7513107061386108, acc: 0.8333333134651184)
[2025-01-30 01:55:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 686/107898 [03:47<10:10:26,  2.93it/s][2025-01-30 01:55:57][root][INFO] - Training Epoch: 1/2, step 685/107898 completed (loss: 2.4147191047668457, acc: 0.20000000298023224)
[2025-01-30 01:55:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 687/107898 [03:48<10:15:57,  2.90it/s][2025-01-30 01:55:57][root][INFO] - Training Epoch: 1/2, step 686/107898 completed (loss: 0.2416238933801651, acc: 1.0)
[2025-01-30 01:55:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 688/107898 [03:48<10:25:40,  2.86it/s][2025-01-30 01:55:58][root][INFO] - Training Epoch: 1/2, step 687/107898 completed (loss: 3.1552250385284424, acc: 0.1666666716337204)
[2025-01-30 01:55:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 689/107898 [03:48<10:34:30,  2.82it/s][2025-01-30 01:55:58][root][INFO] - Training Epoch: 1/2, step 688/107898 completed (loss: 3.8506643772125244, acc: 0.27272728085517883)
[2025-01-30 01:55:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 690/107898 [03:49<10:24:12,  2.86it/s][2025-01-30 01:55:58][root][INFO] - Training Epoch: 1/2, step 689/107898 completed (loss: 0.1567203253507614, acc: 1.0)
[2025-01-30 01:55:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 691/107898 [03:49<9:53:32,  3.01it/s] [2025-01-30 01:55:59][root][INFO] - Training Epoch: 1/2, step 690/107898 completed (loss: 0.35501599311828613, acc: 1.0)
[2025-01-30 01:55:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 692/107898 [03:49<10:09:21,  2.93it/s][2025-01-30 01:55:59][root][INFO] - Training Epoch: 1/2, step 691/107898 completed (loss: 4.844936370849609, acc: 0.0)
[2025-01-30 01:55:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 693/107898 [03:50<10:30:06,  2.84it/s][2025-01-30 01:56:00][root][INFO] - Training Epoch: 1/2, step 692/107898 completed (loss: 2.966174602508545, acc: 0.380952388048172)
[2025-01-30 01:56:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 694/107898 [03:50<10:23:16,  2.87it/s][2025-01-30 01:56:00][root][INFO] - Training Epoch: 1/2, step 693/107898 completed (loss: 2.268242835998535, acc: 0.4285714328289032)
[2025-01-30 01:56:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 695/107898 [03:50<10:29:38,  2.84it/s][2025-01-30 01:56:00][root][INFO] - Training Epoch: 1/2, step 694/107898 completed (loss: 2.5823745727539062, acc: 0.6666666865348816)
[2025-01-30 01:56:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 696/107898 [03:51<10:49:46,  2.75it/s][2025-01-30 01:56:01][root][INFO] - Training Epoch: 1/2, step 695/107898 completed (loss: 0.8328269720077515, acc: 0.8461538553237915)
[2025-01-30 01:56:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 697/107898 [03:51<10:41:59,  2.78it/s][2025-01-30 01:56:01][root][INFO] - Training Epoch: 1/2, step 696/107898 completed (loss: 0.13829894363880157, acc: 1.0)
[2025-01-30 01:56:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 698/107898 [03:51<10:27:05,  2.85it/s][2025-01-30 01:56:01][root][INFO] - Training Epoch: 1/2, step 697/107898 completed (loss: 0.10480832308530807, acc: 1.0)
[2025-01-30 01:56:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 699/107898 [03:52<10:17:28,  2.89it/s][2025-01-30 01:56:02][root][INFO] - Training Epoch: 1/2, step 698/107898 completed (loss: 0.07483755797147751, acc: 1.0)
[2025-01-30 01:56:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 700/107898 [03:52<10:06:17,  2.95it/s][2025-01-30 01:56:02][root][INFO] - Training Epoch: 1/2, step 699/107898 completed (loss: 0.4262153208255768, acc: 0.8888888955116272)
[2025-01-30 01:56:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 701/107898 [03:53<10:22:59,  2.87it/s][2025-01-30 01:56:02][root][INFO] - Training Epoch: 1/2, step 700/107898 completed (loss: 1.486397624015808, acc: 0.6842105388641357)
[2025-01-30 01:56:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 702/107898 [03:53<10:18:30,  2.89it/s][2025-01-30 01:56:03][root][INFO] - Training Epoch: 1/2, step 701/107898 completed (loss: 1.268230676651001, acc: 0.807692289352417)
[2025-01-30 01:56:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 703/107898 [03:53<10:00:02,  2.98it/s][2025-01-30 01:56:03][root][INFO] - Training Epoch: 1/2, step 702/107898 completed (loss: 0.3043515980243683, acc: 1.0)
[2025-01-30 01:56:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 704/107898 [03:53<9:26:17,  3.15it/s] [2025-01-30 01:56:03][root][INFO] - Training Epoch: 1/2, step 703/107898 completed (loss: 0.24368949234485626, acc: 1.0)
[2025-01-30 01:56:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 705/107898 [03:54<9:22:26,  3.18it/s][2025-01-30 01:56:04][root][INFO] - Training Epoch: 1/2, step 704/107898 completed (loss: 0.5349177122116089, acc: 1.0)
[2025-01-30 01:56:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 706/107898 [03:54<9:36:37,  3.10it/s][2025-01-30 01:56:04][root][INFO] - Training Epoch: 1/2, step 705/107898 completed (loss: 2.7723309993743896, acc: 0.6666666865348816)
[2025-01-30 01:56:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 707/107898 [03:54<9:36:41,  3.10it/s][2025-01-30 01:56:04][root][INFO] - Training Epoch: 1/2, step 706/107898 completed (loss: 0.1668701320886612, acc: 1.0)
[2025-01-30 01:56:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 708/107898 [03:55<9:23:31,  3.17it/s][2025-01-30 01:56:05][root][INFO] - Training Epoch: 1/2, step 707/107898 completed (loss: 5.459028720855713, acc: 0.5)
[2025-01-30 01:56:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 709/107898 [03:55<9:12:46,  3.23it/s][2025-01-30 01:56:05][root][INFO] - Training Epoch: 1/2, step 708/107898 completed (loss: 0.7777195572853088, acc: 0.5)
[2025-01-30 01:56:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 710/107898 [03:55<9:12:44,  3.23it/s][2025-01-30 01:56:05][root][INFO] - Training Epoch: 1/2, step 709/107898 completed (loss: 0.13878419995307922, acc: 1.0)
[2025-01-30 01:56:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 711/107898 [03:56<9:11:19,  3.24it/s][2025-01-30 01:56:05][root][INFO] - Training Epoch: 1/2, step 710/107898 completed (loss: 3.418440341949463, acc: 0.6000000238418579)
[2025-01-30 01:56:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 712/107898 [03:56<9:13:56,  3.22it/s][2025-01-30 01:56:06][root][INFO] - Training Epoch: 1/2, step 711/107898 completed (loss: 3.371403694152832, acc: 0.15789473056793213)
[2025-01-30 01:56:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 713/107898 [03:56<9:25:23,  3.16it/s][2025-01-30 01:56:06][root][INFO] - Training Epoch: 1/2, step 712/107898 completed (loss: 1.9319329261779785, acc: 0.6666666865348816)
[2025-01-30 01:56:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 714/107898 [03:56<8:32:46,  3.48it/s][2025-01-30 01:56:06][root][INFO] - Training Epoch: 1/2, step 713/107898 completed (loss: 1.5281277894973755, acc: 0.75)
[2025-01-30 01:56:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 715/107898 [03:57<8:35:40,  3.46it/s][2025-01-30 01:56:07][root][INFO] - Training Epoch: 1/2, step 714/107898 completed (loss: 1.4368557929992676, acc: 0.6666666865348816)
[2025-01-30 01:56:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 716/107898 [03:57<8:46:25,  3.39it/s][2025-01-30 01:56:07][root][INFO] - Training Epoch: 1/2, step 715/107898 completed (loss: 3.419856309890747, acc: 0.3636363744735718)
[2025-01-30 01:56:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 717/107898 [03:57<8:48:05,  3.38it/s][2025-01-30 01:56:07][root][INFO] - Training Epoch: 1/2, step 716/107898 completed (loss: 0.6507707834243774, acc: 0.8333333134651184)
[2025-01-30 01:56:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 718/107898 [03:58<8:52:53,  3.35it/s][2025-01-30 01:56:07][root][INFO] - Training Epoch: 1/2, step 717/107898 completed (loss: 1.8597890138626099, acc: 0.6842105388641357)
[2025-01-30 01:56:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 719/107898 [03:58<8:57:18,  3.32it/s][2025-01-30 01:56:08][root][INFO] - Training Epoch: 1/2, step 718/107898 completed (loss: 2.313680410385132, acc: 0.5833333134651184)
[2025-01-30 01:56:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 720/107898 [03:58<8:56:24,  3.33it/s][2025-01-30 01:56:08][root][INFO] - Training Epoch: 1/2, step 719/107898 completed (loss: 1.8329157829284668, acc: 0.5555555820465088)
[2025-01-30 01:56:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 721/107898 [03:59<9:06:34,  3.27it/s][2025-01-30 01:56:08][root][INFO] - Training Epoch: 1/2, step 720/107898 completed (loss: 0.8178573250770569, acc: 0.8333333134651184)
[2025-01-30 01:56:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 722/107898 [03:59<9:00:34,  3.30it/s][2025-01-30 01:56:09][root][INFO] - Training Epoch: 1/2, step 721/107898 completed (loss: 2.1647439002990723, acc: 0.5714285969734192)
[2025-01-30 01:56:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 723/107898 [03:59<8:51:11,  3.36it/s][2025-01-30 01:56:09][root][INFO] - Training Epoch: 1/2, step 722/107898 completed (loss: 0.28441092371940613, acc: 0.9090909361839294)
[2025-01-30 01:56:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 724/107898 [03:59<8:53:48,  3.35it/s][2025-01-30 01:56:09][root][INFO] - Training Epoch: 1/2, step 723/107898 completed (loss: 2.9149234294891357, acc: 0.4166666567325592)
[2025-01-30 01:56:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 725/107898 [04:00<9:00:47,  3.30it/s][2025-01-30 01:56:10][root][INFO] - Training Epoch: 1/2, step 724/107898 completed (loss: 2.537198066711426, acc: 0.4000000059604645)
[2025-01-30 01:56:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 726/107898 [04:00<9:08:32,  3.26it/s][2025-01-30 01:56:10][root][INFO] - Training Epoch: 1/2, step 725/107898 completed (loss: 1.169319987297058, acc: 0.8461538553237915)
[2025-01-30 01:56:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 727/107898 [04:00<9:25:42,  3.16it/s][2025-01-30 01:56:10][root][INFO] - Training Epoch: 1/2, step 726/107898 completed (loss: 1.445502758026123, acc: 0.5)
[2025-01-30 01:56:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 728/107898 [04:01<9:43:30,  3.06it/s][2025-01-30 01:56:11][root][INFO] - Training Epoch: 1/2, step 727/107898 completed (loss: 3.146289110183716, acc: 0.0)
[2025-01-30 01:56:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 729/107898 [04:01<9:57:01,  2.99it/s][2025-01-30 01:56:11][root][INFO] - Training Epoch: 1/2, step 728/107898 completed (loss: 0.6153965592384338, acc: 0.75)
[2025-01-30 01:56:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 730/107898 [04:02<9:56:49,  2.99it/s][2025-01-30 01:56:11][root][INFO] - Training Epoch: 1/2, step 729/107898 completed (loss: 0.04309377446770668, acc: 1.0)
[2025-01-30 01:56:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 731/107898 [04:02<10:01:59,  2.97it/s][2025-01-30 01:56:12][root][INFO] - Training Epoch: 1/2, step 730/107898 completed (loss: 0.7949607968330383, acc: 0.8421052694320679)
[2025-01-30 01:56:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 732/107898 [04:02<10:18:18,  2.89it/s][2025-01-30 01:56:12][root][INFO] - Training Epoch: 1/2, step 731/107898 completed (loss: 1.1034269332885742, acc: 0.7142857313156128)
[2025-01-30 01:56:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 733/107898 [04:03<10:21:35,  2.87it/s][2025-01-30 01:56:12][root][INFO] - Training Epoch: 1/2, step 732/107898 completed (loss: 0.09659522771835327, acc: 1.0)
[2025-01-30 01:56:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 734/107898 [04:03<10:05:59,  2.95it/s][2025-01-30 01:56:13][root][INFO] - Training Epoch: 1/2, step 733/107898 completed (loss: 1.4058531522750854, acc: 0.7857142686843872)
[2025-01-30 01:56:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 735/107898 [04:03<9:42:11,  3.07it/s] [2025-01-30 01:56:13][root][INFO] - Training Epoch: 1/2, step 734/107898 completed (loss: 0.010618743486702442, acc: 1.0)
[2025-01-30 01:56:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 736/107898 [04:03<9:36:08,  3.10it/s][2025-01-30 01:56:13][root][INFO] - Training Epoch: 1/2, step 735/107898 completed (loss: 1.698987603187561, acc: 0.5)
[2025-01-30 01:56:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 737/107898 [04:04<9:11:26,  3.24it/s][2025-01-30 01:56:14][root][INFO] - Training Epoch: 1/2, step 736/107898 completed (loss: 0.6570618748664856, acc: 0.875)
[2025-01-30 01:56:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 738/107898 [04:04<9:57:57,  2.99it/s][2025-01-30 01:56:14][root][INFO] - Training Epoch: 1/2, step 737/107898 completed (loss: 0.43346288800239563, acc: 0.8461538553237915)
[2025-01-30 01:56:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 739/107898 [04:04<9:53:16,  3.01it/s][2025-01-30 01:56:14][root][INFO] - Training Epoch: 1/2, step 738/107898 completed (loss: 2.008578300476074, acc: 0.6000000238418579)
[2025-01-30 01:56:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 740/107898 [04:05<9:43:21,  3.06it/s][2025-01-30 01:56:15][root][INFO] - Training Epoch: 1/2, step 739/107898 completed (loss: 1.314089298248291, acc: 0.8148148059844971)
[2025-01-30 01:56:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 741/107898 [04:05<9:34:33,  3.11it/s][2025-01-30 01:56:15][root][INFO] - Training Epoch: 1/2, step 740/107898 completed (loss: 0.007129911333322525, acc: 1.0)
[2025-01-30 01:56:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 742/107898 [04:05<9:38:22,  3.09it/s][2025-01-30 01:56:15][root][INFO] - Training Epoch: 1/2, step 741/107898 completed (loss: 0.1127626970410347, acc: 1.0)
[2025-01-30 01:56:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 743/107898 [04:06<9:16:55,  3.21it/s][2025-01-30 01:56:16][root][INFO] - Training Epoch: 1/2, step 742/107898 completed (loss: 5.8123369216918945, acc: 0.25)
[2025-01-30 01:56:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 744/107898 [04:06<8:41:09,  3.43it/s][2025-01-30 01:56:16][root][INFO] - Training Epoch: 1/2, step 743/107898 completed (loss: 1.6237658262252808, acc: 0.5)
[2025-01-30 01:56:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 745/107898 [04:06<9:02:20,  3.29it/s][2025-01-30 01:56:16][root][INFO] - Training Epoch: 1/2, step 744/107898 completed (loss: 3.5567848682403564, acc: 0.625)
[2025-01-30 01:56:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 746/107898 [04:07<8:56:14,  3.33it/s][2025-01-30 01:56:16][root][INFO] - Training Epoch: 1/2, step 745/107898 completed (loss: 0.6767861843109131, acc: 0.8333333134651184)
[2025-01-30 01:56:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 747/107898 [04:07<8:46:21,  3.39it/s][2025-01-30 01:56:17][root][INFO] - Training Epoch: 1/2, step 746/107898 completed (loss: 2.752668857574463, acc: 0.5)
[2025-01-30 01:56:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 748/107898 [04:07<9:03:26,  3.29it/s][2025-01-30 01:56:17][root][INFO] - Training Epoch: 1/2, step 747/107898 completed (loss: 0.4201619625091553, acc: 0.9166666865348816)
[2025-01-30 01:56:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 749/107898 [04:08<9:39:59,  3.08it/s][2025-01-30 01:56:17][root][INFO] - Training Epoch: 1/2, step 748/107898 completed (loss: 0.5848468542098999, acc: 0.8846153616905212)
[2025-01-30 01:56:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 750/107898 [04:08<9:46:52,  3.04it/s][2025-01-30 01:56:18][root][INFO] - Training Epoch: 1/2, step 749/107898 completed (loss: 0.33550864458084106, acc: 0.9130434989929199)
[2025-01-30 01:56:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 751/107898 [04:08<9:35:55,  3.10it/s][2025-01-30 01:56:18][root][INFO] - Training Epoch: 1/2, step 750/107898 completed (loss: 0.026405178010463715, acc: 1.0)
[2025-01-30 01:56:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 752/107898 [04:09<9:22:45,  3.17it/s][2025-01-30 01:56:18][root][INFO] - Training Epoch: 1/2, step 751/107898 completed (loss: 0.3635805547237396, acc: 0.8333333134651184)
[2025-01-30 01:56:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 753/107898 [04:09<9:18:18,  3.20it/s][2025-01-30 01:56:19][root][INFO] - Training Epoch: 1/2, step 752/107898 completed (loss: 0.01724989339709282, acc: 1.0)
[2025-01-30 01:56:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 754/107898 [04:09<9:43:01,  3.06it/s][2025-01-30 01:56:19][root][INFO] - Training Epoch: 1/2, step 753/107898 completed (loss: 0.5522962808609009, acc: 0.800000011920929)
[2025-01-30 01:56:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 755/107898 [04:10<9:46:25,  3.05it/s][2025-01-30 01:56:19][root][INFO] - Training Epoch: 1/2, step 754/107898 completed (loss: 1.2772960662841797, acc: 0.75)
[2025-01-30 01:56:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 756/107898 [04:10<9:49:26,  3.03it/s][2025-01-30 01:56:20][root][INFO] - Training Epoch: 1/2, step 755/107898 completed (loss: 0.6981595754623413, acc: 0.8709677457809448)
[2025-01-30 01:56:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 757/107898 [04:10<10:05:50,  2.95it/s][2025-01-30 01:56:20][root][INFO] - Training Epoch: 1/2, step 756/107898 completed (loss: 2.6754567623138428, acc: 0.6153846383094788)
[2025-01-30 01:56:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 758/107898 [04:11<10:19:46,  2.88it/s][2025-01-30 01:56:20][root][INFO] - Training Epoch: 1/2, step 757/107898 completed (loss: 0.05376449599862099, acc: 1.0)
[2025-01-30 01:56:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 759/107898 [04:11<10:24:10,  2.86it/s][2025-01-30 01:56:21][root][INFO] - Training Epoch: 1/2, step 758/107898 completed (loss: 0.07472961395978928, acc: 1.0)
[2025-01-30 01:56:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 760/107898 [04:11<10:18:42,  2.89it/s][2025-01-30 01:56:21][root][INFO] - Training Epoch: 1/2, step 759/107898 completed (loss: 0.5303140878677368, acc: 0.9333333373069763)
[2025-01-30 01:56:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 761/107898 [04:12<10:25:41,  2.85it/s][2025-01-30 01:56:21][root][INFO] - Training Epoch: 1/2, step 760/107898 completed (loss: 0.7768580317497253, acc: 0.8999999761581421)
[2025-01-30 01:56:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 762/107898 [04:12<10:10:53,  2.92it/s][2025-01-30 01:56:22][root][INFO] - Training Epoch: 1/2, step 761/107898 completed (loss: 3.5937230587005615, acc: 0.27272728085517883)
[2025-01-30 01:56:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 763/107898 [04:12<9:50:14,  3.03it/s] [2025-01-30 01:56:22][root][INFO] - Training Epoch: 1/2, step 762/107898 completed (loss: 1.059720754623413, acc: 0.8823529481887817)
[2025-01-30 01:56:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 764/107898 [04:13<10:23:18,  2.86it/s][2025-01-30 01:56:22][root][INFO] - Training Epoch: 1/2, step 763/107898 completed (loss: 0.9814572334289551, acc: 0.875)
[2025-01-30 01:56:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 765/107898 [04:13<10:27:35,  2.85it/s][2025-01-30 01:56:23][root][INFO] - Training Epoch: 1/2, step 764/107898 completed (loss: 1.6389602422714233, acc: 0.699999988079071)
[2025-01-30 01:56:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 766/107898 [04:13<9:44:30,  3.05it/s] [2025-01-30 01:56:23][root][INFO] - Training Epoch: 1/2, step 765/107898 completed (loss: 2.183720111846924, acc: 0.5555555820465088)
[2025-01-30 01:56:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 767/107898 [04:14<9:23:10,  3.17it/s][2025-01-30 01:56:23][root][INFO] - Training Epoch: 1/2, step 766/107898 completed (loss: 4.9312543869018555, acc: 0.0)
[2025-01-30 01:56:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 768/107898 [04:14<9:17:39,  3.20it/s][2025-01-30 01:56:24][root][INFO] - Training Epoch: 1/2, step 767/107898 completed (loss: 0.67567378282547, acc: 0.8571428656578064)
[2025-01-30 01:56:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 769/107898 [04:14<9:20:45,  3.18it/s][2025-01-30 01:56:24][root][INFO] - Training Epoch: 1/2, step 768/107898 completed (loss: 0.6895412802696228, acc: 0.8181818127632141)
[2025-01-30 01:56:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 770/107898 [04:14<8:46:36,  3.39it/s][2025-01-30 01:56:24][root][INFO] - Training Epoch: 1/2, step 769/107898 completed (loss: 1.7529098987579346, acc: 0.75)
[2025-01-30 01:56:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 771/107898 [04:15<8:47:06,  3.39it/s][2025-01-30 01:56:25][root][INFO] - Training Epoch: 1/2, step 770/107898 completed (loss: 0.03467962145805359, acc: 1.0)
[2025-01-30 01:56:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 772/107898 [04:15<8:47:45,  3.38it/s][2025-01-30 01:56:25][root][INFO] - Training Epoch: 1/2, step 771/107898 completed (loss: 1.1641108989715576, acc: 0.699999988079071)
[2025-01-30 01:56:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 773/107898 [04:15<8:50:16,  3.37it/s][2025-01-30 01:56:25][root][INFO] - Training Epoch: 1/2, step 772/107898 completed (loss: 0.11606110632419586, acc: 1.0)
[2025-01-30 01:56:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 774/107898 [04:16<9:10:09,  3.25it/s][2025-01-30 01:56:25][root][INFO] - Training Epoch: 1/2, step 773/107898 completed (loss: 5.072403430938721, acc: 0.5)
[2025-01-30 01:56:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 775/107898 [04:16<9:25:26,  3.16it/s][2025-01-30 01:56:26][root][INFO] - Training Epoch: 1/2, step 774/107898 completed (loss: 1.4393396377563477, acc: 0.7777777910232544)
[2025-01-30 01:56:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 776/107898 [04:16<9:33:29,  3.11it/s][2025-01-30 01:56:26][root][INFO] - Training Epoch: 1/2, step 775/107898 completed (loss: 0.7433843612670898, acc: 0.8571428656578064)
[2025-01-30 01:56:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 777/107898 [04:17<10:08:56,  2.93it/s][2025-01-30 01:56:27][root][INFO] - Training Epoch: 1/2, step 776/107898 completed (loss: 0.2999746799468994, acc: 0.9523809552192688)
[2025-01-30 01:56:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 778/107898 [04:17<10:17:28,  2.89it/s][2025-01-30 01:56:27][root][INFO] - Training Epoch: 1/2, step 777/107898 completed (loss: 3.5978074073791504, acc: 0.3125)
[2025-01-30 01:56:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 779/107898 [04:17<10:22:39,  2.87it/s][2025-01-30 01:56:27][root][INFO] - Training Epoch: 1/2, step 778/107898 completed (loss: 2.5426065921783447, acc: 0.75)
[2025-01-30 01:56:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 780/107898 [04:18<10:12:53,  2.91it/s][2025-01-30 01:56:28][root][INFO] - Training Epoch: 1/2, step 779/107898 completed (loss: 1.675246000289917, acc: 0.6428571343421936)
[2025-01-30 01:56:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 781/107898 [04:18<9:51:55,  3.02it/s] [2025-01-30 01:56:28][root][INFO] - Training Epoch: 1/2, step 780/107898 completed (loss: 1.7665249109268188, acc: 0.5)
[2025-01-30 01:56:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 782/107898 [04:18<9:12:07,  3.23it/s][2025-01-30 01:56:28][root][INFO] - Training Epoch: 1/2, step 781/107898 completed (loss: 2.951314687728882, acc: 0.5625)
[2025-01-30 01:56:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 783/107898 [04:19<9:14:44,  3.22it/s][2025-01-30 01:56:28][root][INFO] - Training Epoch: 1/2, step 782/107898 completed (loss: 0.058910176157951355, acc: 1.0)
[2025-01-30 01:56:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 784/107898 [04:19<9:07:27,  3.26it/s][2025-01-30 01:56:29][root][INFO] - Training Epoch: 1/2, step 783/107898 completed (loss: 1.0809555053710938, acc: 0.5)
[2025-01-30 01:56:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 785/107898 [04:19<9:23:21,  3.17it/s][2025-01-30 01:56:29][root][INFO] - Training Epoch: 1/2, step 784/107898 completed (loss: 0.5087209939956665, acc: 0.8837209343910217)
[2025-01-30 01:56:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 786/107898 [04:20<9:14:52,  3.22it/s][2025-01-30 01:56:29][root][INFO] - Training Epoch: 1/2, step 785/107898 completed (loss: 4.94004487991333, acc: 0.3333333432674408)
[2025-01-30 01:56:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 787/107898 [04:20<9:12:49,  3.23it/s][2025-01-30 01:56:30][root][INFO] - Training Epoch: 1/2, step 786/107898 completed (loss: 0.5868204236030579, acc: 0.8799999952316284)
[2025-01-30 01:56:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 788/107898 [04:20<9:37:06,  3.09it/s][2025-01-30 01:56:30][root][INFO] - Training Epoch: 1/2, step 787/107898 completed (loss: 2.586073875427246, acc: 0.5)
[2025-01-30 01:56:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 789/107898 [04:21<10:12:44,  2.91it/s][2025-01-30 01:56:30][root][INFO] - Training Epoch: 1/2, step 788/107898 completed (loss: 1.9310317039489746, acc: 0.6818181872367859)
[2025-01-30 01:56:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 790/107898 [04:21<9:54:14,  3.00it/s] [2025-01-30 01:56:31][root][INFO] - Training Epoch: 1/2, step 789/107898 completed (loss: 1.1769895553588867, acc: 0.7647058963775635)
[2025-01-30 01:56:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 791/107898 [04:21<10:06:49,  2.94it/s][2025-01-30 01:56:31][root][INFO] - Training Epoch: 1/2, step 790/107898 completed (loss: 1.3724663257598877, acc: 0.7857142686843872)
[2025-01-30 01:56:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 792/107898 [04:22<10:00:15,  2.97it/s][2025-01-30 01:56:31][root][INFO] - Training Epoch: 1/2, step 791/107898 completed (loss: 1.2994561195373535, acc: 0.6666666865348816)
[2025-01-30 01:56:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 793/107898 [04:22<9:54:36,  3.00it/s] [2025-01-30 01:56:32][root][INFO] - Training Epoch: 1/2, step 792/107898 completed (loss: 0.5694662928581238, acc: 0.8999999761581421)
[2025-01-30 01:56:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 794/107898 [04:22<10:25:43,  2.85it/s][2025-01-30 01:56:32][root][INFO] - Training Epoch: 1/2, step 793/107898 completed (loss: 1.3115626573562622, acc: 0.7692307829856873)
[2025-01-30 01:56:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 795/107898 [04:23<10:22:30,  2.87it/s][2025-01-30 01:56:32][root][INFO] - Training Epoch: 1/2, step 794/107898 completed (loss: 2.482515335083008, acc: 0.6666666865348816)
[2025-01-30 01:56:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 796/107898 [04:23<9:54:33,  3.00it/s] [2025-01-30 01:56:33][root][INFO] - Training Epoch: 1/2, step 795/107898 completed (loss: 4.143967151641846, acc: 0.0)
[2025-01-30 01:56:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 797/107898 [04:23<9:39:07,  3.08it/s][2025-01-30 01:56:33][root][INFO] - Training Epoch: 1/2, step 796/107898 completed (loss: 1.8320977687835693, acc: 0.6071428656578064)
[2025-01-30 01:56:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 798/107898 [04:24<9:31:03,  3.13it/s][2025-01-30 01:56:33][root][INFO] - Training Epoch: 1/2, step 797/107898 completed (loss: 0.8126028180122375, acc: 0.7142857313156128)
[2025-01-30 01:56:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 799/107898 [04:24<9:39:56,  3.08it/s][2025-01-30 01:56:34][root][INFO] - Training Epoch: 1/2, step 798/107898 completed (loss: 0.9770967364311218, acc: 0.75)
[2025-01-30 01:56:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 800/107898 [04:24<9:58:10,  2.98it/s][2025-01-30 01:56:34][root][INFO] - Training Epoch: 1/2, step 799/107898 completed (loss: 1.9244059324264526, acc: 0.6666666865348816)
[2025-01-30 01:56:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 801/107898 [04:25<9:47:35,  3.04it/s][2025-01-30 01:56:34][root][INFO] - Training Epoch: 1/2, step 800/107898 completed (loss: 0.5181171894073486, acc: 0.9090909361839294)
[2025-01-30 01:56:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 802/107898 [04:25<9:10:18,  3.24it/s][2025-01-30 01:56:35][root][INFO] - Training Epoch: 1/2, step 801/107898 completed (loss: 0.8208038806915283, acc: 0.6666666865348816)
[2025-01-30 01:56:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 803/107898 [04:25<9:00:43,  3.30it/s][2025-01-30 01:56:35][root][INFO] - Training Epoch: 1/2, step 802/107898 completed (loss: 1.38618004322052, acc: 0.8333333134651184)
[2025-01-30 01:56:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 804/107898 [04:25<8:59:31,  3.31it/s][2025-01-30 01:56:35][root][INFO] - Training Epoch: 1/2, step 803/107898 completed (loss: 5.814816474914551, acc: 0.20000000298023224)
[2025-01-30 01:56:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 805/107898 [04:26<8:42:16,  3.42it/s][2025-01-30 01:56:36][root][INFO] - Training Epoch: 1/2, step 804/107898 completed (loss: 2.0176901817321777, acc: 0.6153846383094788)
[2025-01-30 01:56:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 806/107898 [04:26<9:07:02,  3.26it/s][2025-01-30 01:56:36][root][INFO] - Training Epoch: 1/2, step 805/107898 completed (loss: 2.1063880920410156, acc: 0.5)
[2025-01-30 01:56:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 807/107898 [04:26<8:44:20,  3.40it/s][2025-01-30 01:56:36][root][INFO] - Training Epoch: 1/2, step 806/107898 completed (loss: 1.4687154293060303, acc: 0.7142857313156128)
[2025-01-30 01:56:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 808/107898 [04:27<9:27:45,  3.14it/s][2025-01-30 01:56:36][root][INFO] - Training Epoch: 1/2, step 807/107898 completed (loss: 1.3860793113708496, acc: 0.75)
[2025-01-30 01:56:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 809/107898 [04:27<9:37:52,  3.09it/s][2025-01-30 01:56:37][root][INFO] - Training Epoch: 1/2, step 808/107898 completed (loss: 0.8208724856376648, acc: 0.8421052694320679)
[2025-01-30 01:56:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 810/107898 [04:27<10:11:21,  2.92it/s][2025-01-30 01:56:37][root][INFO] - Training Epoch: 1/2, step 809/107898 completed (loss: 1.1640461683273315, acc: 0.7560975551605225)
[2025-01-30 01:56:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 811/107898 [04:28<10:48:33,  2.75it/s][2025-01-30 01:56:38][root][INFO] - Training Epoch: 1/2, step 810/107898 completed (loss: 1.6218526363372803, acc: 0.6111111044883728)
[2025-01-30 01:56:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 812/107898 [04:28<10:46:25,  2.76it/s][2025-01-30 01:56:38][root][INFO] - Training Epoch: 1/2, step 811/107898 completed (loss: 2.4619176387786865, acc: 0.5384615659713745)
[2025-01-30 01:56:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 813/107898 [04:29<10:33:13,  2.82it/s][2025-01-30 01:56:38][root][INFO] - Training Epoch: 1/2, step 812/107898 completed (loss: 0.8618590831756592, acc: 0.5)
[2025-01-30 01:56:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 814/107898 [04:29<10:19:16,  2.88it/s][2025-01-30 01:56:39][root][INFO] - Training Epoch: 1/2, step 813/107898 completed (loss: 0.13687987625598907, acc: 1.0)
[2025-01-30 01:56:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 815/107898 [04:29<10:37:53,  2.80it/s][2025-01-30 01:56:39][root][INFO] - Training Epoch: 1/2, step 814/107898 completed (loss: 2.4062416553497314, acc: 0.6190476417541504)
[2025-01-30 01:56:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 816/107898 [04:30<10:29:37,  2.83it/s][2025-01-30 01:56:39][root][INFO] - Training Epoch: 1/2, step 815/107898 completed (loss: 1.7857704162597656, acc: 0.5789473652839661)
[2025-01-30 01:56:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 817/107898 [04:30<10:05:12,  2.95it/s][2025-01-30 01:56:40][root][INFO] - Training Epoch: 1/2, step 816/107898 completed (loss: 0.7601833343505859, acc: 0.6666666865348816)
[2025-01-30 01:56:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 818/107898 [04:30<9:43:45,  3.06it/s] [2025-01-30 01:56:40][root][INFO] - Training Epoch: 1/2, step 817/107898 completed (loss: 0.092243492603302, acc: 1.0)
[2025-01-30 01:56:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 819/107898 [04:30<9:24:55,  3.16it/s][2025-01-30 01:56:40][root][INFO] - Training Epoch: 1/2, step 818/107898 completed (loss: 3.771883010864258, acc: 0.625)
[2025-01-30 01:56:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 820/107898 [04:31<9:23:08,  3.17it/s][2025-01-30 01:56:41][root][INFO] - Training Epoch: 1/2, step 819/107898 completed (loss: 3.22727632522583, acc: 0.5)
[2025-01-30 01:56:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 821/107898 [04:31<9:28:41,  3.14it/s][2025-01-30 01:56:41][root][INFO] - Training Epoch: 1/2, step 820/107898 completed (loss: 3.7786977291107178, acc: 0.3333333432674408)
[2025-01-30 01:56:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 822/107898 [04:31<9:18:03,  3.20it/s][2025-01-30 01:56:41][root][INFO] - Training Epoch: 1/2, step 821/107898 completed (loss: 1.4404046535491943, acc: 0.7142857313156128)
[2025-01-30 01:56:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 823/107898 [04:32<9:09:53,  3.25it/s][2025-01-30 01:56:42][root][INFO] - Training Epoch: 1/2, step 822/107898 completed (loss: 1.1280598640441895, acc: 0.7777777910232544)
[2025-01-30 01:56:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 824/107898 [04:32<9:17:06,  3.20it/s][2025-01-30 01:56:42][root][INFO] - Training Epoch: 1/2, step 823/107898 completed (loss: 2.2657124996185303, acc: 0.5)
[2025-01-30 01:56:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 825/107898 [04:32<9:54:58,  3.00it/s][2025-01-30 01:56:42][root][INFO] - Training Epoch: 1/2, step 824/107898 completed (loss: 1.6171811819076538, acc: 0.75)
[2025-01-30 01:56:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 826/107898 [04:33<9:43:43,  3.06it/s][2025-01-30 01:56:43][root][INFO] - Training Epoch: 1/2, step 825/107898 completed (loss: 0.5303552746772766, acc: 0.931034505367279)
[2025-01-30 01:56:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 827/107898 [04:33<9:44:14,  3.05it/s][2025-01-30 01:56:43][root][INFO] - Training Epoch: 1/2, step 826/107898 completed (loss: 1.909792423248291, acc: 0.5625)
[2025-01-30 01:56:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 828/107898 [04:33<9:45:02,  3.05it/s][2025-01-30 01:56:43][root][INFO] - Training Epoch: 1/2, step 827/107898 completed (loss: 0.3335736393928528, acc: 0.9130434989929199)
[2025-01-30 01:56:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 829/107898 [04:34<9:52:52,  3.01it/s][2025-01-30 01:56:44][root][INFO] - Training Epoch: 1/2, step 828/107898 completed (loss: 1.5562691688537598, acc: 0.6000000238418579)
[2025-01-30 01:56:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 830/107898 [04:34<10:01:59,  2.96it/s][2025-01-30 01:56:44][root][INFO] - Training Epoch: 1/2, step 829/107898 completed (loss: 0.4905308187007904, acc: 0.9285714030265808)
[2025-01-30 01:56:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 831/107898 [04:34<9:40:41,  3.07it/s] [2025-01-30 01:56:44][root][INFO] - Training Epoch: 1/2, step 830/107898 completed (loss: 0.31918561458587646, acc: 1.0)
[2025-01-30 01:56:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 832/107898 [04:35<9:41:01,  3.07it/s][2025-01-30 01:56:44][root][INFO] - Training Epoch: 1/2, step 831/107898 completed (loss: 1.1193456649780273, acc: 0.782608687877655)
[2025-01-30 01:56:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 833/107898 [04:35<9:18:52,  3.19it/s][2025-01-30 01:56:45][root][INFO] - Training Epoch: 1/2, step 832/107898 completed (loss: 2.5056495666503906, acc: 0.3333333432674408)
[2025-01-30 01:56:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 834/107898 [04:35<9:18:42,  3.19it/s][2025-01-30 01:56:45][root][INFO] - Training Epoch: 1/2, step 833/107898 completed (loss: 1.686313509941101, acc: 0.692307710647583)
[2025-01-30 01:56:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 835/107898 [04:36<9:20:56,  3.18it/s][2025-01-30 01:56:45][root][INFO] - Training Epoch: 1/2, step 834/107898 completed (loss: 1.5369377136230469, acc: 0.6666666865348816)
[2025-01-30 01:56:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 836/107898 [04:36<9:08:54,  3.25it/s][2025-01-30 01:56:46][root][INFO] - Training Epoch: 1/2, step 835/107898 completed (loss: 1.5326601266860962, acc: 0.5)
[2025-01-30 01:56:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 837/107898 [04:36<8:57:01,  3.32it/s][2025-01-30 01:56:46][root][INFO] - Training Epoch: 1/2, step 836/107898 completed (loss: 0.29482319951057434, acc: 0.8888888955116272)
[2025-01-30 01:56:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 838/107898 [04:36<8:52:30,  3.35it/s][2025-01-30 01:56:46][root][INFO] - Training Epoch: 1/2, step 837/107898 completed (loss: 1.898726224899292, acc: 0.6000000238418579)
[2025-01-30 01:56:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 839/107898 [04:37<9:10:37,  3.24it/s][2025-01-30 01:56:47][root][INFO] - Training Epoch: 1/2, step 838/107898 completed (loss: 1.233708381652832, acc: 0.699999988079071)
[2025-01-30 01:56:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 840/107898 [04:37<9:04:18,  3.28it/s][2025-01-30 01:56:47][root][INFO] - Training Epoch: 1/2, step 839/107898 completed (loss: 0.9649038314819336, acc: 0.800000011920929)
[2025-01-30 01:56:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 841/107898 [04:37<8:26:41,  3.52it/s][2025-01-30 01:56:47][root][INFO] - Training Epoch: 1/2, step 840/107898 completed (loss: 2.088632583618164, acc: 0.5)
[2025-01-30 01:56:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 842/107898 [04:38<8:45:30,  3.40it/s][2025-01-30 01:56:47][root][INFO] - Training Epoch: 1/2, step 841/107898 completed (loss: 2.6636674404144287, acc: 0.7142857313156128)
[2025-01-30 01:56:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 843/107898 [04:38<8:49:52,  3.37it/s][2025-01-30 01:56:48][root][INFO] - Training Epoch: 1/2, step 842/107898 completed (loss: 0.039338868111371994, acc: 1.0)
[2025-01-30 01:56:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 844/107898 [04:38<8:57:35,  3.32it/s][2025-01-30 01:56:48][root][INFO] - Training Epoch: 1/2, step 843/107898 completed (loss: 0.19785712659358978, acc: 1.0)
[2025-01-30 01:56:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 845/107898 [04:39<9:21:12,  3.18it/s][2025-01-30 01:56:48][root][INFO] - Training Epoch: 1/2, step 844/107898 completed (loss: 0.5999781489372253, acc: 0.8235294222831726)
[2025-01-30 01:56:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 846/107898 [04:39<9:15:31,  3.21it/s][2025-01-30 01:56:49][root][INFO] - Training Epoch: 1/2, step 845/107898 completed (loss: 0.4348571300506592, acc: 1.0)
[2025-01-30 01:56:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 847/107898 [04:39<9:06:29,  3.26it/s][2025-01-30 01:56:49][root][INFO] - Training Epoch: 1/2, step 846/107898 completed (loss: 2.746448040008545, acc: 0.6875)
[2025-01-30 01:56:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 848/107898 [04:40<9:18:35,  3.19it/s][2025-01-30 01:56:49][root][INFO] - Training Epoch: 1/2, step 847/107898 completed (loss: 3.100924015045166, acc: 0.36000001430511475)
[2025-01-30 01:56:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 849/107898 [04:40<9:14:37,  3.22it/s][2025-01-30 01:56:50][root][INFO] - Training Epoch: 1/2, step 848/107898 completed (loss: 1.9439691305160522, acc: 0.625)
[2025-01-30 01:56:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 850/107898 [04:40<9:32:33,  3.12it/s][2025-01-30 01:56:50][root][INFO] - Training Epoch: 1/2, step 849/107898 completed (loss: 1.643795132637024, acc: 0.5)
[2025-01-30 01:56:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 851/107898 [04:41<9:38:16,  3.09it/s][2025-01-30 01:56:50][root][INFO] - Training Epoch: 1/2, step 850/107898 completed (loss: 2.649613618850708, acc: 0.5454545617103577)
[2025-01-30 01:56:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 852/107898 [04:41<9:39:08,  3.08it/s][2025-01-30 01:56:51][root][INFO] - Training Epoch: 1/2, step 851/107898 completed (loss: 0.3127239942550659, acc: 0.8999999761581421)
[2025-01-30 01:56:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 853/107898 [04:41<9:37:09,  3.09it/s][2025-01-30 01:56:51][root][INFO] - Training Epoch: 1/2, step 852/107898 completed (loss: 1.5774083137512207, acc: 0.782608687877655)
[2025-01-30 01:56:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 854/107898 [04:42<9:32:52,  3.11it/s][2025-01-30 01:56:51][root][INFO] - Training Epoch: 1/2, step 853/107898 completed (loss: 0.4229363203048706, acc: 0.8666666746139526)
[2025-01-30 01:56:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 855/107898 [04:42<9:19:54,  3.19it/s][2025-01-30 01:56:52][root][INFO] - Training Epoch: 1/2, step 854/107898 completed (loss: 2.4063568115234375, acc: 0.375)
[2025-01-30 01:56:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 856/107898 [04:42<9:50:57,  3.02it/s][2025-01-30 01:56:52][root][INFO] - Training Epoch: 1/2, step 855/107898 completed (loss: 0.8065993785858154, acc: 0.7368420958518982)
[2025-01-30 01:56:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 857/107898 [04:43<9:52:11,  3.01it/s][2025-01-30 01:56:52][root][INFO] - Training Epoch: 1/2, step 856/107898 completed (loss: 1.7786070108413696, acc: 0.625)
[2025-01-30 01:56:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 858/107898 [04:43<9:59:38,  2.98it/s][2025-01-30 01:56:53][root][INFO] - Training Epoch: 1/2, step 857/107898 completed (loss: 1.5328667163848877, acc: 0.5)
[2025-01-30 01:56:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 859/107898 [04:43<10:00:17,  2.97it/s][2025-01-30 01:56:53][root][INFO] - Training Epoch: 1/2, step 858/107898 completed (loss: 0.588423490524292, acc: 0.8333333134651184)
[2025-01-30 01:56:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 860/107898 [04:44<10:06:39,  2.94it/s][2025-01-30 01:56:53][root][INFO] - Training Epoch: 1/2, step 859/107898 completed (loss: 0.7820961475372314, acc: 0.8125)
[2025-01-30 01:56:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 861/107898 [04:44<10:28:27,  2.84it/s][2025-01-30 01:56:54][root][INFO] - Training Epoch: 1/2, step 860/107898 completed (loss: 1.5780220031738281, acc: 0.6470588445663452)
[2025-01-30 01:56:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 862/107898 [04:44<10:32:42,  2.82it/s][2025-01-30 01:56:54][root][INFO] - Training Epoch: 1/2, step 861/107898 completed (loss: 3.9301047325134277, acc: 0.0)
[2025-01-30 01:56:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 863/107898 [04:45<10:33:27,  2.82it/s][2025-01-30 01:56:54][root][INFO] - Training Epoch: 1/2, step 862/107898 completed (loss: 3.0038092136383057, acc: 0.6666666865348816)
[2025-01-30 01:56:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 864/107898 [04:45<10:23:33,  2.86it/s][2025-01-30 01:56:55][root][INFO] - Training Epoch: 1/2, step 863/107898 completed (loss: 2.9240143299102783, acc: 0.4375)
[2025-01-30 01:56:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 865/107898 [04:45<10:30:30,  2.83it/s][2025-01-30 01:56:55][root][INFO] - Training Epoch: 1/2, step 864/107898 completed (loss: 0.23402416706085205, acc: 0.8999999761581421)
[2025-01-30 01:56:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 866/107898 [04:46<10:22:02,  2.87it/s][2025-01-30 01:56:55][root][INFO] - Training Epoch: 1/2, step 865/107898 completed (loss: 4.4210968017578125, acc: 0.3333333432674408)
[2025-01-30 01:56:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 867/107898 [04:46<10:14:28,  2.90it/s][2025-01-30 01:56:56][root][INFO] - Training Epoch: 1/2, step 866/107898 completed (loss: 1.774071455001831, acc: 0.5333333611488342)
[2025-01-30 01:56:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 868/107898 [04:46<10:09:34,  2.93it/s][2025-01-30 01:56:56][root][INFO] - Training Epoch: 1/2, step 867/107898 completed (loss: 1.2285315990447998, acc: 0.5454545617103577)
[2025-01-30 01:56:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 869/107898 [04:47<10:00:51,  2.97it/s][2025-01-30 01:56:56][root][INFO] - Training Epoch: 1/2, step 868/107898 completed (loss: 1.6019670963287354, acc: 0.6000000238418579)
[2025-01-30 01:56:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 870/107898 [04:47<9:41:56,  3.07it/s] [2025-01-30 01:56:57][root][INFO] - Training Epoch: 1/2, step 869/107898 completed (loss: 4.170604705810547, acc: 0.20588235557079315)
[2025-01-30 01:56:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 871/107898 [04:47<9:35:48,  3.10it/s][2025-01-30 01:56:57][root][INFO] - Training Epoch: 1/2, step 870/107898 completed (loss: 3.5442848205566406, acc: 0.44999998807907104)
[2025-01-30 01:56:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 872/107898 [04:48<9:45:09,  3.05it/s][2025-01-30 01:56:57][root][INFO] - Training Epoch: 1/2, step 871/107898 completed (loss: 2.370788097381592, acc: 0.47826087474823)
[2025-01-30 01:56:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 873/107898 [04:48<9:46:31,  3.04it/s][2025-01-30 01:56:58][root][INFO] - Training Epoch: 1/2, step 872/107898 completed (loss: 0.5613758563995361, acc: 0.8947368264198303)
[2025-01-30 01:56:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 874/107898 [04:48<9:31:26,  3.12it/s][2025-01-30 01:56:58][root][INFO] - Training Epoch: 1/2, step 873/107898 completed (loss: 0.9903298616409302, acc: 0.7142857313156128)
[2025-01-30 01:56:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 875/107898 [04:49<9:25:46,  3.15it/s][2025-01-30 01:56:58][root][INFO] - Training Epoch: 1/2, step 874/107898 completed (loss: 0.24630534648895264, acc: 1.0)
[2025-01-30 01:56:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 876/107898 [04:49<9:19:56,  3.19it/s][2025-01-30 01:56:59][root][INFO] - Training Epoch: 1/2, step 875/107898 completed (loss: 2.3517956733703613, acc: 0.4000000059604645)
[2025-01-30 01:56:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 877/107898 [04:49<9:41:09,  3.07it/s][2025-01-30 01:56:59][root][INFO] - Training Epoch: 1/2, step 876/107898 completed (loss: 0.9429352283477783, acc: 0.5)
[2025-01-30 01:56:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 878/107898 [04:50<9:47:19,  3.04it/s][2025-01-30 01:56:59][root][INFO] - Training Epoch: 1/2, step 877/107898 completed (loss: 0.18634173274040222, acc: 1.0)
[2025-01-30 01:56:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 879/107898 [04:50<9:33:57,  3.11it/s][2025-01-30 01:57:00][root][INFO] - Training Epoch: 1/2, step 878/107898 completed (loss: 3.4684841632843018, acc: 0.25)
[2025-01-30 01:57:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 880/107898 [04:50<10:30:43,  2.83it/s][2025-01-30 01:57:00][root][INFO] - Training Epoch: 1/2, step 879/107898 completed (loss: 2.1123337745666504, acc: 0.6315789222717285)
[2025-01-30 01:57:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 881/107898 [04:51<10:25:34,  2.85it/s][2025-01-30 01:57:00][root][INFO] - Training Epoch: 1/2, step 880/107898 completed (loss: 1.8473179340362549, acc: 0.5)
[2025-01-30 01:57:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 882/107898 [04:51<10:05:59,  2.94it/s][2025-01-30 01:57:01][root][INFO] - Training Epoch: 1/2, step 881/107898 completed (loss: 0.7088298797607422, acc: 0.8999999761581421)
[2025-01-30 01:57:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 883/107898 [04:51<9:50:40,  3.02it/s] [2025-01-30 01:57:01][root][INFO] - Training Epoch: 1/2, step 882/107898 completed (loss: 0.7045259475708008, acc: 0.8333333134651184)
[2025-01-30 01:57:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 884/107898 [04:52<9:57:13,  2.99it/s][2025-01-30 01:57:01][root][INFO] - Training Epoch: 1/2, step 883/107898 completed (loss: 0.21754010021686554, acc: 1.0)
[2025-01-30 01:57:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 885/107898 [04:52<10:26:28,  2.85it/s][2025-01-30 01:57:02][root][INFO] - Training Epoch: 1/2, step 884/107898 completed (loss: 0.41546088457107544, acc: 0.875)
[2025-01-30 01:57:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 886/107898 [04:52<10:25:19,  2.85it/s][2025-01-30 01:57:02][root][INFO] - Training Epoch: 1/2, step 885/107898 completed (loss: 0.3380712866783142, acc: 1.0)
[2025-01-30 01:57:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 887/107898 [04:53<10:37:16,  2.80it/s][2025-01-30 01:57:03][root][INFO] - Training Epoch: 1/2, step 886/107898 completed (loss: 0.7481686472892761, acc: 0.8709677457809448)
[2025-01-30 01:57:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 888/107898 [04:53<10:25:25,  2.85it/s][2025-01-30 01:57:03][root][INFO] - Training Epoch: 1/2, step 887/107898 completed (loss: 1.5515738725662231, acc: 0.7419354915618896)
[2025-01-30 01:57:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 889/107898 [04:53<10:02:32,  2.96it/s][2025-01-30 01:57:03][root][INFO] - Training Epoch: 1/2, step 888/107898 completed (loss: 0.6492404937744141, acc: 0.800000011920929)
[2025-01-30 01:57:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 890/107898 [04:54<9:52:29,  3.01it/s] [2025-01-30 01:57:03][root][INFO] - Training Epoch: 1/2, step 889/107898 completed (loss: 3.8282241821289062, acc: 0.09090909361839294)
[2025-01-30 01:57:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 891/107898 [04:54<10:13:20,  2.91it/s][2025-01-30 01:57:04][root][INFO] - Training Epoch: 1/2, step 890/107898 completed (loss: 0.8757879137992859, acc: 0.8275862336158752)
[2025-01-30 01:57:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 892/107898 [04:54<10:01:10,  2.97it/s][2025-01-30 01:57:04][root][INFO] - Training Epoch: 1/2, step 891/107898 completed (loss: 2.088122844696045, acc: 0.7777777910232544)
[2025-01-30 01:57:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 893/107898 [04:55<9:44:42,  3.05it/s] [2025-01-30 01:57:04][root][INFO] - Training Epoch: 1/2, step 892/107898 completed (loss: 1.1044650077819824, acc: 0.75)
[2025-01-30 01:57:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 894/107898 [04:55<9:54:26,  3.00it/s][2025-01-30 01:57:05][root][INFO] - Training Epoch: 1/2, step 893/107898 completed (loss: 0.7149744033813477, acc: 0.8285714387893677)
[2025-01-30 01:57:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 895/107898 [04:55<9:52:54,  3.01it/s][2025-01-30 01:57:05][root][INFO] - Training Epoch: 1/2, step 894/107898 completed (loss: 1.0603551864624023, acc: 0.75)
[2025-01-30 01:57:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 896/107898 [04:56<10:10:15,  2.92it/s][2025-01-30 01:57:06][root][INFO] - Training Epoch: 1/2, step 895/107898 completed (loss: 1.1170471906661987, acc: 0.8333333134651184)
[2025-01-30 01:57:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 897/107898 [04:56<9:41:04,  3.07it/s] [2025-01-30 01:57:06][root][INFO] - Training Epoch: 1/2, step 896/107898 completed (loss: 1.6545953750610352, acc: 0.5)
[2025-01-30 01:57:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 898/107898 [04:56<9:25:48,  3.15it/s][2025-01-30 01:57:06][root][INFO] - Training Epoch: 1/2, step 897/107898 completed (loss: 0.7640603184700012, acc: 0.7142857313156128)
[2025-01-30 01:57:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 899/107898 [04:57<9:33:59,  3.11it/s][2025-01-30 01:57:06][root][INFO] - Training Epoch: 1/2, step 898/107898 completed (loss: 1.9600193500518799, acc: 0.0)
[2025-01-30 01:57:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 900/107898 [04:57<9:30:13,  3.13it/s][2025-01-30 01:57:07][root][INFO] - Training Epoch: 1/2, step 899/107898 completed (loss: 0.7648352980613708, acc: 0.75)
[2025-01-30 01:57:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 901/107898 [04:57<9:34:13,  3.11it/s][2025-01-30 01:57:07][root][INFO] - Training Epoch: 1/2, step 900/107898 completed (loss: 2.9511168003082275, acc: 0.3333333432674408)
[2025-01-30 01:57:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 902/107898 [04:58<9:30:19,  3.13it/s][2025-01-30 01:57:07][root][INFO] - Training Epoch: 1/2, step 901/107898 completed (loss: 3.6249287128448486, acc: 0.3333333432674408)
[2025-01-30 01:57:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 903/107898 [04:58<9:40:43,  3.07it/s][2025-01-30 01:57:08][root][INFO] - Training Epoch: 1/2, step 902/107898 completed (loss: 1.5625098943710327, acc: 0.7272727489471436)
[2025-01-30 01:57:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 904/107898 [04:58<9:43:58,  3.05it/s][2025-01-30 01:57:08][root][INFO] - Training Epoch: 1/2, step 903/107898 completed (loss: 1.4034560918807983, acc: 0.625)
[2025-01-30 01:57:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 905/107898 [04:59<9:35:01,  3.10it/s][2025-01-30 01:57:08][root][INFO] - Training Epoch: 1/2, step 904/107898 completed (loss: 3.7594900131225586, acc: 0.3333333432674408)
[2025-01-30 01:57:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 906/107898 [04:59<9:53:32,  3.00it/s][2025-01-30 01:57:09][root][INFO] - Training Epoch: 1/2, step 905/107898 completed (loss: 3.28005051612854, acc: 0.4285714328289032)
[2025-01-30 01:57:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 907/107898 [04:59<9:50:17,  3.02it/s][2025-01-30 01:57:09][root][INFO] - Training Epoch: 1/2, step 906/107898 completed (loss: 1.6953600645065308, acc: 0.5789473652839661)
[2025-01-30 01:57:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 908/107898 [05:00<9:44:34,  3.05it/s][2025-01-30 01:57:09][root][INFO] - Training Epoch: 1/2, step 907/107898 completed (loss: 1.8077865839004517, acc: 0.6000000238418579)
[2025-01-30 01:57:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 909/107898 [05:00<9:37:35,  3.09it/s][2025-01-30 01:57:10][root][INFO] - Training Epoch: 1/2, step 908/107898 completed (loss: 1.3576314449310303, acc: 0.7692307829856873)
[2025-01-30 01:57:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 910/107898 [05:00<9:11:42,  3.23it/s][2025-01-30 01:57:10][root][INFO] - Training Epoch: 1/2, step 909/107898 completed (loss: 0.14070235192775726, acc: 1.0)
[2025-01-30 01:57:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 911/107898 [05:01<9:19:29,  3.19it/s][2025-01-30 01:57:10][root][INFO] - Training Epoch: 1/2, step 910/107898 completed (loss: 0.28605905175209045, acc: 1.0)
[2025-01-30 01:57:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 912/107898 [05:01<9:19:20,  3.19it/s][2025-01-30 01:57:11][root][INFO] - Training Epoch: 1/2, step 911/107898 completed (loss: 0.13159917294979095, acc: 1.0)
[2025-01-30 01:57:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 913/107898 [05:01<9:30:36,  3.12it/s][2025-01-30 01:57:11][root][INFO] - Training Epoch: 1/2, step 912/107898 completed (loss: 2.693997621536255, acc: 0.5555555820465088)
[2025-01-30 01:57:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 914/107898 [05:01<9:21:00,  3.18it/s][2025-01-30 01:57:11][root][INFO] - Training Epoch: 1/2, step 913/107898 completed (loss: 1.1521130800247192, acc: 0.6666666865348816)
[2025-01-30 01:57:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 915/107898 [05:02<9:44:03,  3.05it/s][2025-01-30 01:57:12][root][INFO] - Training Epoch: 1/2, step 914/107898 completed (loss: 1.536771297454834, acc: 0.7692307829856873)
[2025-01-30 01:57:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 916/107898 [05:02<10:09:15,  2.93it/s][2025-01-30 01:57:12][root][INFO] - Training Epoch: 1/2, step 915/107898 completed (loss: 2.0660815238952637, acc: 0.7037037014961243)
[2025-01-30 01:57:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 917/107898 [05:02<9:49:38,  3.02it/s] [2025-01-30 01:57:12][root][INFO] - Training Epoch: 1/2, step 916/107898 completed (loss: 2.120346784591675, acc: 0.6666666865348816)
[2025-01-30 01:57:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 918/107898 [05:03<9:40:24,  3.07it/s][2025-01-30 01:57:13][root][INFO] - Training Epoch: 1/2, step 917/107898 completed (loss: 3.8726625442504883, acc: 0.25)
[2025-01-30 01:57:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 919/107898 [05:03<9:29:02,  3.13it/s][2025-01-30 01:57:13][root][INFO] - Training Epoch: 1/2, step 918/107898 completed (loss: 0.5730468034744263, acc: 1.0)
[2025-01-30 01:57:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 920/107898 [05:03<9:25:13,  3.15it/s][2025-01-30 01:57:13][root][INFO] - Training Epoch: 1/2, step 919/107898 completed (loss: 0.3808242976665497, acc: 0.8947368264198303)
[2025-01-30 01:57:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 921/107898 [05:04<9:50:22,  3.02it/s][2025-01-30 01:57:14][root][INFO] - Training Epoch: 1/2, step 920/107898 completed (loss: 0.7103362679481506, acc: 0.807692289352417)
[2025-01-30 01:57:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 922/107898 [05:04<10:12:20,  2.91it/s][2025-01-30 01:57:14][root][INFO] - Training Epoch: 1/2, step 921/107898 completed (loss: 0.09309880435466766, acc: 1.0)
[2025-01-30 01:57:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 923/107898 [05:04<10:00:03,  2.97it/s][2025-01-30 01:57:14][root][INFO] - Training Epoch: 1/2, step 922/107898 completed (loss: 1.9438469409942627, acc: 0.5)
[2025-01-30 01:57:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 924/107898 [05:05<9:43:12,  3.06it/s] [2025-01-30 01:57:15][root][INFO] - Training Epoch: 1/2, step 923/107898 completed (loss: 1.287982702255249, acc: 0.7647058963775635)
[2025-01-30 01:57:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 925/107898 [05:05<9:31:41,  3.12it/s][2025-01-30 01:57:15][root][INFO] - Training Epoch: 1/2, step 924/107898 completed (loss: 1.0372662544250488, acc: 0.875)
[2025-01-30 01:57:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 926/107898 [05:05<9:24:30,  3.16it/s][2025-01-30 01:57:15][root][INFO] - Training Epoch: 1/2, step 925/107898 completed (loss: 0.23524336516857147, acc: 1.0)
[2025-01-30 01:57:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 927/107898 [05:06<9:12:58,  3.22it/s][2025-01-30 01:57:15][root][INFO] - Training Epoch: 1/2, step 926/107898 completed (loss: 0.1138996034860611, acc: 1.0)
[2025-01-30 01:57:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 928/107898 [05:06<9:40:04,  3.07it/s][2025-01-30 01:57:16][root][INFO] - Training Epoch: 1/2, step 927/107898 completed (loss: 3.942472219467163, acc: 0.3076923191547394)
[2025-01-30 01:57:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 929/107898 [05:06<9:54:21,  3.00it/s][2025-01-30 01:57:16][root][INFO] - Training Epoch: 1/2, step 928/107898 completed (loss: 2.4056506156921387, acc: 0.5)
[2025-01-30 01:57:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 930/107898 [05:07<10:00:17,  2.97it/s][2025-01-30 01:57:17][root][INFO] - Training Epoch: 1/2, step 929/107898 completed (loss: 0.06555111706256866, acc: 1.0)
[2025-01-30 01:57:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 931/107898 [05:07<10:02:22,  2.96it/s][2025-01-30 01:57:17][root][INFO] - Training Epoch: 1/2, step 930/107898 completed (loss: 3.183783769607544, acc: 0.3333333432674408)
[2025-01-30 01:57:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 932/107898 [05:07<10:09:24,  2.93it/s][2025-01-30 01:57:17][root][INFO] - Training Epoch: 1/2, step 931/107898 completed (loss: 1.0871084928512573, acc: 0.7857142686843872)
[2025-01-30 01:57:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 933/107898 [05:08<9:49:25,  3.02it/s] [2025-01-30 01:57:18][root][INFO] - Training Epoch: 1/2, step 932/107898 completed (loss: 0.04116472601890564, acc: 1.0)
[2025-01-30 01:57:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 934/107898 [05:08<9:41:47,  3.06it/s][2025-01-30 01:57:18][root][INFO] - Training Epoch: 1/2, step 933/107898 completed (loss: 1.6856536865234375, acc: 0.6666666865348816)
[2025-01-30 01:57:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 935/107898 [05:08<9:36:35,  3.09it/s][2025-01-30 01:57:18][root][INFO] - Training Epoch: 1/2, step 934/107898 completed (loss: 1.578078031539917, acc: 0.8571428656578064)
[2025-01-30 01:57:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 936/107898 [05:09<9:51:43,  3.01it/s][2025-01-30 01:57:19][root][INFO] - Training Epoch: 1/2, step 935/107898 completed (loss: 0.019460294395685196, acc: 1.0)
[2025-01-30 01:57:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 937/107898 [05:09<9:44:35,  3.05it/s][2025-01-30 01:57:19][root][INFO] - Training Epoch: 1/2, step 936/107898 completed (loss: 0.5868375897407532, acc: 0.75)
[2025-01-30 01:57:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 938/107898 [05:09<9:57:40,  2.98it/s][2025-01-30 01:57:19][root][INFO] - Training Epoch: 1/2, step 937/107898 completed (loss: 0.5282073616981506, acc: 0.8787878751754761)
[2025-01-30 01:57:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 939/107898 [05:10<10:05:34,  2.94it/s][2025-01-30 01:57:20][root][INFO] - Training Epoch: 1/2, step 938/107898 completed (loss: 0.100936159491539, acc: 1.0)
[2025-01-30 01:57:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 940/107898 [05:10<10:15:27,  2.90it/s][2025-01-30 01:57:20][root][INFO] - Training Epoch: 1/2, step 939/107898 completed (loss: 0.01062733307480812, acc: 1.0)
[2025-01-30 01:57:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 941/107898 [05:10<10:15:38,  2.90it/s][2025-01-30 01:57:20][root][INFO] - Training Epoch: 1/2, step 940/107898 completed (loss: 1.5024696588516235, acc: 0.5)
[2025-01-30 01:57:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 942/107898 [05:11<10:04:23,  2.95it/s][2025-01-30 01:57:21][root][INFO] - Training Epoch: 1/2, step 941/107898 completed (loss: 0.427948921918869, acc: 0.8571428656578064)
[2025-01-30 01:57:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 943/107898 [05:11<10:14:16,  2.90it/s][2025-01-30 01:57:21][root][INFO] - Training Epoch: 1/2, step 942/107898 completed (loss: 2.297415256500244, acc: 0.5454545617103577)
[2025-01-30 01:57:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 944/107898 [05:11<10:06:54,  2.94it/s][2025-01-30 01:57:21][root][INFO] - Training Epoch: 1/2, step 943/107898 completed (loss: 1.0967453718185425, acc: 0.7368420958518982)
[2025-01-30 01:57:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 945/107898 [05:12<9:57:09,  2.99it/s] [2025-01-30 01:57:22][root][INFO] - Training Epoch: 1/2, step 944/107898 completed (loss: 0.4788908362388611, acc: 0.8888888955116272)
[2025-01-30 01:57:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 946/107898 [05:12<10:00:41,  2.97it/s][2025-01-30 01:57:22][root][INFO] - Training Epoch: 1/2, step 945/107898 completed (loss: 0.9712066054344177, acc: 0.9230769276618958)
[2025-01-30 01:57:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 947/107898 [05:12<9:38:45,  3.08it/s] [2025-01-30 01:57:22][root][INFO] - Training Epoch: 1/2, step 946/107898 completed (loss: 1.0700774192810059, acc: 0.8181818127632141)
[2025-01-30 01:57:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 948/107898 [05:13<9:24:59,  3.15it/s][2025-01-30 01:57:23][root][INFO] - Training Epoch: 1/2, step 947/107898 completed (loss: 2.780712842941284, acc: 0.5)
[2025-01-30 01:57:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 949/107898 [05:13<9:19:54,  3.18it/s][2025-01-30 01:57:23][root][INFO] - Training Epoch: 1/2, step 948/107898 completed (loss: 3.432420492172241, acc: 0.1666666716337204)
[2025-01-30 01:57:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 950/107898 [05:13<9:23:20,  3.16it/s][2025-01-30 01:57:23][root][INFO] - Training Epoch: 1/2, step 949/107898 completed (loss: 0.8796680569648743, acc: 0.8333333134651184)
[2025-01-30 01:57:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 951/107898 [05:14<9:26:50,  3.14it/s][2025-01-30 01:57:23][root][INFO] - Training Epoch: 1/2, step 950/107898 completed (loss: 3.362694263458252, acc: 0.5)
[2025-01-30 01:57:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 952/107898 [05:14<9:47:37,  3.03it/s][2025-01-30 01:57:24][root][INFO] - Training Epoch: 1/2, step 951/107898 completed (loss: 0.40831440687179565, acc: 1.0)
[2025-01-30 01:57:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 953/107898 [05:14<9:45:46,  3.04it/s][2025-01-30 01:57:24][root][INFO] - Training Epoch: 1/2, step 952/107898 completed (loss: 0.6804920434951782, acc: 0.8999999761581421)
[2025-01-30 01:57:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 954/107898 [05:15<9:39:39,  3.07it/s][2025-01-30 01:57:24][root][INFO] - Training Epoch: 1/2, step 953/107898 completed (loss: 1.9130306243896484, acc: 0.5714285969734192)
[2025-01-30 01:57:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 955/107898 [05:15<9:29:08,  3.13it/s][2025-01-30 01:57:25][root][INFO] - Training Epoch: 1/2, step 954/107898 completed (loss: 3.18906307220459, acc: 0.375)
[2025-01-30 01:57:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 956/107898 [05:15<9:38:46,  3.08it/s][2025-01-30 01:57:25][root][INFO] - Training Epoch: 1/2, step 955/107898 completed (loss: 1.714414358139038, acc: 0.7142857313156128)
[2025-01-30 01:57:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 957/107898 [05:16<9:32:00,  3.12it/s][2025-01-30 01:57:25][root][INFO] - Training Epoch: 1/2, step 956/107898 completed (loss: 0.33212652802467346, acc: 0.8500000238418579)
[2025-01-30 01:57:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 958/107898 [05:16<9:32:34,  3.11it/s][2025-01-30 01:57:26][root][INFO] - Training Epoch: 1/2, step 957/107898 completed (loss: 0.6582797169685364, acc: 0.8333333134651184)
[2025-01-30 01:57:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 959/107898 [05:16<9:21:45,  3.17it/s][2025-01-30 01:57:26][root][INFO] - Training Epoch: 1/2, step 958/107898 completed (loss: 1.9436638355255127, acc: 0.6470588445663452)
[2025-01-30 01:57:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 960/107898 [05:17<9:15:08,  3.21it/s][2025-01-30 01:57:26][root][INFO] - Training Epoch: 1/2, step 959/107898 completed (loss: 1.0478969812393188, acc: 0.75)
[2025-01-30 01:57:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 961/107898 [05:17<9:16:16,  3.20it/s][2025-01-30 01:57:27][root][INFO] - Training Epoch: 1/2, step 960/107898 completed (loss: 4.859951019287109, acc: 0.5)
[2025-01-30 01:57:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 962/107898 [05:17<9:37:40,  3.09it/s][2025-01-30 01:57:27][root][INFO] - Training Epoch: 1/2, step 961/107898 completed (loss: 1.67661452293396, acc: 0.5)
[2025-01-30 01:57:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 963/107898 [05:18<9:51:27,  3.01it/s][2025-01-30 01:57:27][root][INFO] - Training Epoch: 1/2, step 962/107898 completed (loss: 2.3420093059539795, acc: 0.0)
[2025-01-30 01:57:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 964/107898 [05:18<9:54:33,  3.00it/s][2025-01-30 01:57:28][root][INFO] - Training Epoch: 1/2, step 963/107898 completed (loss: 3.1017463207244873, acc: 0.4545454680919647)
[2025-01-30 01:57:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 965/107898 [05:18<9:48:33,  3.03it/s][2025-01-30 01:57:28][root][INFO] - Training Epoch: 1/2, step 964/107898 completed (loss: 2.4507839679718018, acc: 0.3333333432674408)
[2025-01-30 01:57:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 966/107898 [05:19<9:50:15,  3.02it/s][2025-01-30 01:57:28][root][INFO] - Training Epoch: 1/2, step 965/107898 completed (loss: 5.246702194213867, acc: 0.3333333432674408)
[2025-01-30 01:57:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 967/107898 [05:19<10:07:03,  2.94it/s][2025-01-30 01:57:29][root][INFO] - Training Epoch: 1/2, step 966/107898 completed (loss: 1.7048048973083496, acc: 0.75)
[2025-01-30 01:57:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 968/107898 [05:19<10:00:06,  2.97it/s][2025-01-30 01:57:29][root][INFO] - Training Epoch: 1/2, step 967/107898 completed (loss: 0.4598924517631531, acc: 1.0)
[2025-01-30 01:57:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 969/107898 [05:20<9:49:52,  3.02it/s] [2025-01-30 01:57:29][root][INFO] - Training Epoch: 1/2, step 968/107898 completed (loss: 0.11828677356243134, acc: 1.0)
[2025-01-30 01:57:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 970/107898 [05:20<9:40:21,  3.07it/s][2025-01-30 01:57:30][root][INFO] - Training Epoch: 1/2, step 969/107898 completed (loss: 1.2295526266098022, acc: 0.8125)
[2025-01-30 01:57:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 971/107898 [05:20<9:32:16,  3.11it/s][2025-01-30 01:57:30][root][INFO] - Training Epoch: 1/2, step 970/107898 completed (loss: 0.09060164541006088, acc: 1.0)
[2025-01-30 01:57:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 972/107898 [05:21<9:25:41,  3.15it/s][2025-01-30 01:57:30][root][INFO] - Training Epoch: 1/2, step 971/107898 completed (loss: 1.1205638647079468, acc: 0.3333333432674408)
[2025-01-30 01:57:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 973/107898 [05:21<9:07:22,  3.26it/s][2025-01-30 01:57:31][root][INFO] - Training Epoch: 1/2, step 972/107898 completed (loss: 1.8838741779327393, acc: 0.5)
[2025-01-30 01:57:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 974/107898 [05:21<9:52:48,  3.01it/s][2025-01-30 01:57:31][root][INFO] - Training Epoch: 1/2, step 973/107898 completed (loss: 0.2681520879268646, acc: 0.9166666865348816)
[2025-01-30 01:57:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 975/107898 [05:21<9:42:09,  3.06it/s][2025-01-30 01:57:31][root][INFO] - Training Epoch: 1/2, step 974/107898 completed (loss: 0.19140034914016724, acc: 1.0)
[2025-01-30 01:57:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 976/107898 [05:22<9:53:32,  3.00it/s][2025-01-30 01:57:32][root][INFO] - Training Epoch: 1/2, step 975/107898 completed (loss: 1.2758270502090454, acc: 0.7894737124443054)
[2025-01-30 01:57:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 977/107898 [05:22<9:44:32,  3.05it/s][2025-01-30 01:57:32][root][INFO] - Training Epoch: 1/2, step 976/107898 completed (loss: 0.18452918529510498, acc: 1.0)
[2025-01-30 01:57:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 978/107898 [05:22<9:37:50,  3.08it/s][2025-01-30 01:57:32][root][INFO] - Training Epoch: 1/2, step 977/107898 completed (loss: 2.0671515464782715, acc: 0.5)
[2025-01-30 01:57:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 979/107898 [05:23<9:34:13,  3.10it/s][2025-01-30 01:57:33][root][INFO] - Training Epoch: 1/2, step 978/107898 completed (loss: 1.6472686529159546, acc: 0.5833333134651184)
[2025-01-30 01:57:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 980/107898 [05:23<9:36:55,  3.09it/s][2025-01-30 01:57:33][root][INFO] - Training Epoch: 1/2, step 979/107898 completed (loss: 7.474971771240234, acc: 0.0)
[2025-01-30 01:57:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 981/107898 [05:23<9:27:48,  3.14it/s][2025-01-30 01:57:33][root][INFO] - Training Epoch: 1/2, step 980/107898 completed (loss: 0.5740774273872375, acc: 1.0)
[2025-01-30 01:57:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 982/107898 [05:24<9:55:45,  2.99it/s][2025-01-30 01:57:34][root][INFO] - Training Epoch: 1/2, step 981/107898 completed (loss: 0.6595589518547058, acc: 0.7777777910232544)
[2025-01-30 01:57:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 983/107898 [05:24<10:17:25,  2.89it/s][2025-01-30 01:57:34][root][INFO] - Training Epoch: 1/2, step 982/107898 completed (loss: 4.033524513244629, acc: 0.375)
[2025-01-30 01:57:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 984/107898 [05:25<10:31:31,  2.82it/s][2025-01-30 01:57:34][root][INFO] - Training Epoch: 1/2, step 983/107898 completed (loss: 1.525139570236206, acc: 0.7027027010917664)
[2025-01-30 01:57:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 985/107898 [05:25<9:56:18,  2.99it/s] [2025-01-30 01:57:35][root][INFO] - Training Epoch: 1/2, step 984/107898 completed (loss: 1.2536532878875732, acc: 0.5)
[2025-01-30 01:57:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 986/107898 [05:25<9:45:39,  3.04it/s][2025-01-30 01:57:35][root][INFO] - Training Epoch: 1/2, step 985/107898 completed (loss: 0.3830990493297577, acc: 0.875)
[2025-01-30 01:57:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 987/107898 [05:25<9:50:38,  3.02it/s][2025-01-30 01:57:35][root][INFO] - Training Epoch: 1/2, step 986/107898 completed (loss: 0.7399103045463562, acc: 0.8275862336158752)
[2025-01-30 01:57:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 988/107898 [05:26<10:00:19,  2.97it/s][2025-01-30 01:57:36][root][INFO] - Training Epoch: 1/2, step 987/107898 completed (loss: 0.5986859202384949, acc: 0.6666666865348816)
[2025-01-30 01:57:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 989/107898 [05:26<10:12:08,  2.91it/s][2025-01-30 01:57:36][root][INFO] - Training Epoch: 1/2, step 988/107898 completed (loss: 3.051563262939453, acc: 0.5)
[2025-01-30 01:57:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 990/107898 [05:27<9:58:14,  2.98it/s] [2025-01-30 01:57:36][root][INFO] - Training Epoch: 1/2, step 989/107898 completed (loss: 4.008686542510986, acc: 0.4285714328289032)
[2025-01-30 01:57:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 991/107898 [05:27<9:58:33,  2.98it/s][2025-01-30 01:57:37][root][INFO] - Training Epoch: 1/2, step 990/107898 completed (loss: 0.2544524669647217, acc: 0.9230769276618958)
[2025-01-30 01:57:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 992/107898 [05:27<9:56:48,  2.99it/s][2025-01-30 01:57:37][root][INFO] - Training Epoch: 1/2, step 991/107898 completed (loss: 1.3795933723449707, acc: 0.695652186870575)
[2025-01-30 01:57:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 993/107898 [05:27<9:46:03,  3.04it/s][2025-01-30 01:57:37][root][INFO] - Training Epoch: 1/2, step 992/107898 completed (loss: 5.861927032470703, acc: 0.05882352963089943)
[2025-01-30 01:57:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 994/107898 [05:28<9:42:48,  3.06it/s][2025-01-30 01:57:38][root][INFO] - Training Epoch: 1/2, step 993/107898 completed (loss: 3.4391796588897705, acc: 0.23076923191547394)
[2025-01-30 01:57:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 995/107898 [05:28<9:40:44,  3.07it/s][2025-01-30 01:57:38][root][INFO] - Training Epoch: 1/2, step 994/107898 completed (loss: 1.145652174949646, acc: 0.8461538553237915)
[2025-01-30 01:57:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 996/107898 [05:28<9:23:39,  3.16it/s][2025-01-30 01:57:38][root][INFO] - Training Epoch: 1/2, step 995/107898 completed (loss: 3.8858418464660645, acc: 0.5)
[2025-01-30 01:57:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 997/107898 [05:29<9:36:27,  3.09it/s][2025-01-30 01:57:39][root][INFO] - Training Epoch: 1/2, step 996/107898 completed (loss: 2.0842819213867188, acc: 0.5454545617103577)
[2025-01-30 01:57:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 998/107898 [05:29<9:34:22,  3.10it/s][2025-01-30 01:57:39][root][INFO] - Training Epoch: 1/2, step 997/107898 completed (loss: 1.6243642568588257, acc: 0.7142857313156128)
[2025-01-30 01:57:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 999/107898 [05:29<9:27:30,  3.14it/s][2025-01-30 01:57:39][root][INFO] - Training Epoch: 1/2, step 998/107898 completed (loss: 0.2772948443889618, acc: 1.0)
[2025-01-30 01:57:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1000/107898 [05:30<9:19:27,  3.18it/s][2025-01-30 01:57:39][root][INFO] - Training Epoch: 1/2, step 999/107898 completed (loss: 1.6463788747787476, acc: 0.699999988079071)
[2025-01-30 01:57:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1001/107898 [05:30<9:29:42,  3.13it/s][2025-01-30 01:57:40][root][INFO] - Training Epoch: 1/2, step 1000/107898 completed (loss: 0.24592338502407074, acc: 0.9629629850387573)
[2025-01-30 01:57:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1002/107898 [05:30<9:33:17,  3.11it/s][2025-01-30 01:57:40][root][INFO] - Training Epoch: 1/2, step 1001/107898 completed (loss: 0.19782334566116333, acc: 0.9599999785423279)
[2025-01-30 01:57:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1003/107898 [05:31<9:23:24,  3.16it/s][2025-01-30 01:57:40][root][INFO] - Training Epoch: 1/2, step 1002/107898 completed (loss: 0.4735811948776245, acc: 0.9166666865348816)
[2025-01-30 01:57:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1004/107898 [05:31<8:52:24,  3.35it/s][2025-01-30 01:57:41][root][INFO] - Training Epoch: 1/2, step 1003/107898 completed (loss: 1.4945999383926392, acc: 0.5)
[2025-01-30 01:57:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1005/107898 [05:31<8:58:27,  3.31it/s][2025-01-30 01:57:41][root][INFO] - Training Epoch: 1/2, step 1004/107898 completed (loss: 0.16212722659111023, acc: 1.0)
[2025-01-30 01:57:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1006/107898 [05:32<9:00:35,  3.30it/s][2025-01-30 01:57:41][root][INFO] - Training Epoch: 1/2, step 1005/107898 completed (loss: 3.2198097705841064, acc: 0.4000000059604645)
[2025-01-30 01:57:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1007/107898 [05:32<9:25:15,  3.15it/s][2025-01-30 01:57:42][root][INFO] - Training Epoch: 1/2, step 1006/107898 completed (loss: 2.5822629928588867, acc: 0.6666666865348816)
[2025-01-30 01:57:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1008/107898 [05:32<9:46:36,  3.04it/s][2025-01-30 01:57:42][root][INFO] - Training Epoch: 1/2, step 1007/107898 completed (loss: 0.44546422362327576, acc: 0.5)
[2025-01-30 01:57:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1009/107898 [05:33<9:45:01,  3.05it/s][2025-01-30 01:57:42][root][INFO] - Training Epoch: 1/2, step 1008/107898 completed (loss: 0.45301154255867004, acc: 1.0)
[2025-01-30 01:57:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1010/107898 [05:33<10:17:37,  2.88it/s][2025-01-30 01:57:43][root][INFO] - Training Epoch: 1/2, step 1009/107898 completed (loss: 1.015140414237976, acc: 0.8333333134651184)
[2025-01-30 01:57:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1011/107898 [05:33<10:26:24,  2.84it/s][2025-01-30 01:57:43][root][INFO] - Training Epoch: 1/2, step 1010/107898 completed (loss: 1.6882315874099731, acc: 0.8333333134651184)
[2025-01-30 01:57:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1012/107898 [05:34<10:11:30,  2.91it/s][2025-01-30 01:57:43][root][INFO] - Training Epoch: 1/2, step 1011/107898 completed (loss: 2.996164083480835, acc: 0.6666666865348816)
[2025-01-30 01:57:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1013/107898 [05:34<9:50:22,  3.02it/s] [2025-01-30 01:57:44][root][INFO] - Training Epoch: 1/2, step 1012/107898 completed (loss: 0.681449830532074, acc: 0.875)
[2025-01-30 01:57:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1014/107898 [05:34<9:17:36,  3.19it/s][2025-01-30 01:57:44][root][INFO] - Training Epoch: 1/2, step 1013/107898 completed (loss: 2.3159537315368652, acc: 0.6000000238418579)
[2025-01-30 01:57:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1015/107898 [05:35<9:04:49,  3.27it/s][2025-01-30 01:57:44][root][INFO] - Training Epoch: 1/2, step 1014/107898 completed (loss: 1.2066271305084229, acc: 0.75)
[2025-01-30 01:57:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1016/107898 [05:35<9:02:32,  3.28it/s][2025-01-30 01:57:45][root][INFO] - Training Epoch: 1/2, step 1015/107898 completed (loss: 0.07194429636001587, acc: 1.0)
[2025-01-30 01:57:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1017/107898 [05:35<8:56:22,  3.32it/s][2025-01-30 01:57:45][root][INFO] - Training Epoch: 1/2, step 1016/107898 completed (loss: 1.1425431966781616, acc: 1.0)
[2025-01-30 01:57:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1018/107898 [05:35<9:13:51,  3.22it/s][2025-01-30 01:57:45][root][INFO] - Training Epoch: 1/2, step 1017/107898 completed (loss: 0.13372430205345154, acc: 1.0)
[2025-01-30 01:57:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1019/107898 [05:36<9:22:29,  3.17it/s][2025-01-30 01:57:46][root][INFO] - Training Epoch: 1/2, step 1018/107898 completed (loss: 1.2188063859939575, acc: 0.800000011920929)
[2025-01-30 01:57:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1020/107898 [05:36<9:19:32,  3.18it/s][2025-01-30 01:57:46][root][INFO] - Training Epoch: 1/2, step 1019/107898 completed (loss: 0.7828395366668701, acc: 0.6666666865348816)
[2025-01-30 01:57:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1021/107898 [05:36<9:32:39,  3.11it/s][2025-01-30 01:57:46][root][INFO] - Training Epoch: 1/2, step 1020/107898 completed (loss: 2.145297050476074, acc: 0.6666666865348816)
[2025-01-30 01:57:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1022/107898 [05:37<9:16:59,  3.20it/s][2025-01-30 01:57:47][root][INFO] - Training Epoch: 1/2, step 1021/107898 completed (loss: 1.0750961303710938, acc: 0.7777777910232544)
[2025-01-30 01:57:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1023/107898 [05:37<9:37:27,  3.08it/s][2025-01-30 01:57:47][root][INFO] - Training Epoch: 1/2, step 1022/107898 completed (loss: 1.18833327293396, acc: 0.8333333134651184)
[2025-01-30 01:57:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1024/107898 [05:37<9:41:48,  3.06it/s][2025-01-30 01:57:47][root][INFO] - Training Epoch: 1/2, step 1023/107898 completed (loss: 0.009892236441373825, acc: 1.0)
[2025-01-30 01:57:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1025/107898 [05:38<10:05:46,  2.94it/s][2025-01-30 01:57:48][root][INFO] - Training Epoch: 1/2, step 1024/107898 completed (loss: 1.1386339664459229, acc: 0.675000011920929)
[2025-01-30 01:57:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1026/107898 [05:38<9:44:18,  3.05it/s] [2025-01-30 01:57:48][root][INFO] - Training Epoch: 1/2, step 1025/107898 completed (loss: 0.31208497285842896, acc: 1.0)
[2025-01-30 01:57:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1027/107898 [05:38<9:57:26,  2.98it/s][2025-01-30 01:57:48][root][INFO] - Training Epoch: 1/2, step 1026/107898 completed (loss: 0.041977010667324066, acc: 1.0)
[2025-01-30 01:57:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1028/107898 [05:39<9:33:11,  3.11it/s][2025-01-30 01:57:48][root][INFO] - Training Epoch: 1/2, step 1027/107898 completed (loss: 0.8820196390151978, acc: 0.8571428656578064)
[2025-01-30 01:57:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1029/107898 [05:39<9:21:17,  3.17it/s][2025-01-30 01:57:49][root][INFO] - Training Epoch: 1/2, step 1028/107898 completed (loss: 0.005227817688137293, acc: 1.0)
[2025-01-30 01:57:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1030/107898 [05:39<9:42:09,  3.06it/s][2025-01-30 01:57:49][root][INFO] - Training Epoch: 1/2, step 1029/107898 completed (loss: 1.6961023807525635, acc: 0.6875)
[2025-01-30 01:57:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1031/107898 [05:40<10:00:42,  2.97it/s][2025-01-30 01:57:50][root][INFO] - Training Epoch: 1/2, step 1030/107898 completed (loss: 0.8402777314186096, acc: 0.7878788113594055)
[2025-01-30 01:57:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1032/107898 [05:40<9:59:17,  2.97it/s] [2025-01-30 01:57:50][root][INFO] - Training Epoch: 1/2, step 1031/107898 completed (loss: 0.006572085898369551, acc: 1.0)
[2025-01-30 01:57:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1033/107898 [05:40<9:55:57,  2.99it/s][2025-01-30 01:57:50][root][INFO] - Training Epoch: 1/2, step 1032/107898 completed (loss: 2.913870334625244, acc: 0.375)
[2025-01-30 01:57:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1034/107898 [05:41<10:12:20,  2.91it/s][2025-01-30 01:57:51][root][INFO] - Training Epoch: 1/2, step 1033/107898 completed (loss: 0.018176721408963203, acc: 1.0)
[2025-01-30 01:57:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1035/107898 [05:41<9:55:06,  2.99it/s] [2025-01-30 01:57:51][root][INFO] - Training Epoch: 1/2, step 1034/107898 completed (loss: 1.4277973175048828, acc: 0.692307710647583)
[2025-01-30 01:57:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1036/107898 [05:41<9:36:42,  3.09it/s][2025-01-30 01:57:51][root][INFO] - Training Epoch: 1/2, step 1035/107898 completed (loss: 0.09957046061754227, acc: 1.0)
[2025-01-30 01:57:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1037/107898 [05:42<9:30:46,  3.12it/s][2025-01-30 01:57:51][root][INFO] - Training Epoch: 1/2, step 1036/107898 completed (loss: 0.006154631730169058, acc: 1.0)
[2025-01-30 01:57:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1038/107898 [05:42<9:35:16,  3.10it/s][2025-01-30 01:57:52][root][INFO] - Training Epoch: 1/2, step 1037/107898 completed (loss: 0.5315825343132019, acc: 1.0)
[2025-01-30 01:57:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1039/107898 [05:42<9:41:24,  3.06it/s][2025-01-30 01:57:52][root][INFO] - Training Epoch: 1/2, step 1038/107898 completed (loss: 1.4912883043289185, acc: 0.800000011920929)
[2025-01-30 01:57:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1040/107898 [05:43<9:45:17,  3.04it/s][2025-01-30 01:57:52][root][INFO] - Training Epoch: 1/2, step 1039/107898 completed (loss: 1.5990604162216187, acc: 0.7333333492279053)
[2025-01-30 01:57:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1041/107898 [05:43<9:38:00,  3.08it/s][2025-01-30 01:57:53][root][INFO] - Training Epoch: 1/2, step 1040/107898 completed (loss: 1.840380311012268, acc: 0.5)
[2025-01-30 01:57:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1042/107898 [05:43<9:44:40,  3.05it/s][2025-01-30 01:57:53][root][INFO] - Training Epoch: 1/2, step 1041/107898 completed (loss: 0.7508777379989624, acc: 0.8888888955116272)
[2025-01-30 01:57:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1043/107898 [05:44<9:49:21,  3.02it/s][2025-01-30 01:57:53][root][INFO] - Training Epoch: 1/2, step 1042/107898 completed (loss: 1.5547797679901123, acc: 0.699999988079071)
[2025-01-30 01:57:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1044/107898 [05:44<9:54:58,  2.99it/s][2025-01-30 01:57:54][root][INFO] - Training Epoch: 1/2, step 1043/107898 completed (loss: 0.059529803693294525, acc: 1.0)
[2025-01-30 01:57:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1045/107898 [05:44<9:56:37,  2.98it/s][2025-01-30 01:57:54][root][INFO] - Training Epoch: 1/2, step 1044/107898 completed (loss: 0.415248304605484, acc: 0.8947368264198303)
[2025-01-30 01:57:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1046/107898 [05:45<9:57:17,  2.98it/s][2025-01-30 01:57:54][root][INFO] - Training Epoch: 1/2, step 1045/107898 completed (loss: 1.8012217283248901, acc: 0.6666666865348816)
[2025-01-30 01:57:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1047/107898 [05:45<9:50:33,  3.02it/s][2025-01-30 01:57:55][root][INFO] - Training Epoch: 1/2, step 1046/107898 completed (loss: 0.09011456370353699, acc: 1.0)
[2025-01-30 01:57:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1048/107898 [05:45<9:20:25,  3.18it/s][2025-01-30 01:57:55][root][INFO] - Training Epoch: 1/2, step 1047/107898 completed (loss: 2.2885704040527344, acc: 0.5)
[2025-01-30 01:57:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1049/107898 [05:46<9:12:44,  3.22it/s][2025-01-30 01:57:55][root][INFO] - Training Epoch: 1/2, step 1048/107898 completed (loss: 0.8761225938796997, acc: 0.75)
[2025-01-30 01:57:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1050/107898 [05:46<9:04:07,  3.27it/s][2025-01-30 01:57:56][root][INFO] - Training Epoch: 1/2, step 1049/107898 completed (loss: 0.009824627079069614, acc: 1.0)
[2025-01-30 01:57:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1051/107898 [05:46<9:11:00,  3.23it/s][2025-01-30 01:57:56][root][INFO] - Training Epoch: 1/2, step 1050/107898 completed (loss: 0.4402061104774475, acc: 0.9333333373069763)
[2025-01-30 01:57:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1052/107898 [05:46<9:06:07,  3.26it/s][2025-01-30 01:57:56][root][INFO] - Training Epoch: 1/2, step 1051/107898 completed (loss: 3.322378158569336, acc: 0.30000001192092896)
[2025-01-30 01:57:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1053/107898 [05:47<8:59:27,  3.30it/s][2025-01-30 01:57:57][root][INFO] - Training Epoch: 1/2, step 1052/107898 completed (loss: 0.010920739732682705, acc: 1.0)
[2025-01-30 01:57:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1054/107898 [05:47<9:05:10,  3.27it/s][2025-01-30 01:57:57][root][INFO] - Training Epoch: 1/2, step 1053/107898 completed (loss: 0.50938481092453, acc: 0.8500000238418579)
[2025-01-30 01:57:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1055/107898 [05:47<9:06:42,  3.26it/s][2025-01-30 01:57:57][root][INFO] - Training Epoch: 1/2, step 1054/107898 completed (loss: 1.3943400382995605, acc: 0.6000000238418579)
[2025-01-30 01:57:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1056/107898 [05:48<8:59:57,  3.30it/s][2025-01-30 01:57:57][root][INFO] - Training Epoch: 1/2, step 1055/107898 completed (loss: 0.1317981779575348, acc: 1.0)
[2025-01-30 01:57:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1057/107898 [05:48<9:02:23,  3.28it/s][2025-01-30 01:57:58][root][INFO] - Training Epoch: 1/2, step 1056/107898 completed (loss: 1.304686188697815, acc: 0.8333333134651184)
[2025-01-30 01:57:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1058/107898 [05:48<9:13:18,  3.22it/s][2025-01-30 01:57:58][root][INFO] - Training Epoch: 1/2, step 1057/107898 completed (loss: 1.207743763923645, acc: 0.8461538553237915)
[2025-01-30 01:57:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1059/107898 [05:49<9:19:22,  3.18it/s][2025-01-30 01:57:58][root][INFO] - Training Epoch: 1/2, step 1058/107898 completed (loss: 0.046781912446022034, acc: 1.0)
[2025-01-30 01:57:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1060/107898 [05:49<9:21:38,  3.17it/s][2025-01-30 01:57:59][root][INFO] - Training Epoch: 1/2, step 1059/107898 completed (loss: 0.1621706485748291, acc: 1.0)
[2025-01-30 01:57:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1061/107898 [05:49<9:28:50,  3.13it/s][2025-01-30 01:57:59][root][INFO] - Training Epoch: 1/2, step 1060/107898 completed (loss: 1.032355546951294, acc: 0.7692307829856873)
[2025-01-30 01:57:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1062/107898 [05:50<9:17:02,  3.20it/s][2025-01-30 01:57:59][root][INFO] - Training Epoch: 1/2, step 1061/107898 completed (loss: 2.072357177734375, acc: 0.5)
[2025-01-30 01:57:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1063/107898 [05:50<9:13:47,  3.22it/s][2025-01-30 01:58:00][root][INFO] - Training Epoch: 1/2, step 1062/107898 completed (loss: 0.1607833057641983, acc: 1.0)
[2025-01-30 01:58:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1064/107898 [05:50<9:09:35,  3.24it/s][2025-01-30 01:58:00][root][INFO] - Training Epoch: 1/2, step 1063/107898 completed (loss: 1.09660005569458, acc: 0.8947368264198303)
[2025-01-30 01:58:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1065/107898 [05:51<9:12:05,  3.23it/s][2025-01-30 01:58:00][root][INFO] - Training Epoch: 1/2, step 1064/107898 completed (loss: 0.5017770528793335, acc: 0.7142857313156128)
[2025-01-30 01:58:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1066/107898 [05:51<9:26:41,  3.14it/s][2025-01-30 01:58:01][root][INFO] - Training Epoch: 1/2, step 1065/107898 completed (loss: 1.3129386901855469, acc: 0.7599999904632568)
[2025-01-30 01:58:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1067/107898 [05:51<9:21:56,  3.17it/s][2025-01-30 01:58:01][root][INFO] - Training Epoch: 1/2, step 1066/107898 completed (loss: 2.0699269771575928, acc: 0.6153846383094788)
[2025-01-30 01:58:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1068/107898 [05:51<9:17:07,  3.20it/s][2025-01-30 01:58:01][root][INFO] - Training Epoch: 1/2, step 1067/107898 completed (loss: 0.5522089004516602, acc: 0.5)
[2025-01-30 01:58:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1069/107898 [05:52<9:15:34,  3.20it/s][2025-01-30 01:58:02][root][INFO] - Training Epoch: 1/2, step 1068/107898 completed (loss: 2.7689080238342285, acc: 0.2857142984867096)
[2025-01-30 01:58:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1070/107898 [05:52<8:54:47,  3.33it/s][2025-01-30 01:58:02][root][INFO] - Training Epoch: 1/2, step 1069/107898 completed (loss: 2.508084774017334, acc: 0.75)
[2025-01-30 01:58:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1071/107898 [05:52<9:03:37,  3.28it/s][2025-01-30 01:58:02][root][INFO] - Training Epoch: 1/2, step 1070/107898 completed (loss: 0.718090832233429, acc: 0.8399999737739563)
[2025-01-30 01:58:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1072/107898 [05:53<9:03:31,  3.28it/s][2025-01-30 01:58:02][root][INFO] - Training Epoch: 1/2, step 1071/107898 completed (loss: 6.6370368003845215, acc: 0.25)
[2025-01-30 01:58:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1073/107898 [05:53<9:28:51,  3.13it/s][2025-01-30 01:58:03][root][INFO] - Training Epoch: 1/2, step 1072/107898 completed (loss: 3.547837972640991, acc: 0.5)
[2025-01-30 01:58:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1074/107898 [05:53<9:41:45,  3.06it/s][2025-01-30 01:58:03][root][INFO] - Training Epoch: 1/2, step 1073/107898 completed (loss: 0.21651875972747803, acc: 0.9642857313156128)
[2025-01-30 01:58:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1075/107898 [05:54<9:43:34,  3.05it/s][2025-01-30 01:58:04][root][INFO] - Training Epoch: 1/2, step 1074/107898 completed (loss: 2.4045677185058594, acc: 0.5454545617103577)
[2025-01-30 01:58:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1076/107898 [05:54<9:30:37,  3.12it/s][2025-01-30 01:58:04][root][INFO] - Training Epoch: 1/2, step 1075/107898 completed (loss: 0.4717334806919098, acc: 0.9200000166893005)
[2025-01-30 01:58:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1077/107898 [05:54<9:25:14,  3.15it/s][2025-01-30 01:58:04][root][INFO] - Training Epoch: 1/2, step 1076/107898 completed (loss: 0.04389248043298721, acc: 1.0)
[2025-01-30 01:58:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1078/107898 [05:55<9:11:41,  3.23it/s][2025-01-30 01:58:04][root][INFO] - Training Epoch: 1/2, step 1077/107898 completed (loss: 1.327589988708496, acc: 0.75)
[2025-01-30 01:58:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1079/107898 [05:55<9:02:39,  3.28it/s][2025-01-30 01:58:05][root][INFO] - Training Epoch: 1/2, step 1078/107898 completed (loss: 0.7468433380126953, acc: 0.8571428656578064)
[2025-01-30 01:58:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1080/107898 [05:55<8:37:04,  3.44it/s][2025-01-30 01:58:05][root][INFO] - Training Epoch: 1/2, step 1079/107898 completed (loss: 3.497079610824585, acc: 0.5)
[2025-01-30 01:58:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1081/107898 [05:55<8:43:59,  3.40it/s][2025-01-30 01:58:05][root][INFO] - Training Epoch: 1/2, step 1080/107898 completed (loss: 1.8603127002716064, acc: 0.5)
[2025-01-30 01:58:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1082/107898 [05:56<8:53:29,  3.34it/s][2025-01-30 01:58:06][root][INFO] - Training Epoch: 1/2, step 1081/107898 completed (loss: 0.7622549533843994, acc: 0.7777777910232544)
[2025-01-30 01:58:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1083/107898 [05:56<8:55:04,  3.33it/s][2025-01-30 01:58:06][root][INFO] - Training Epoch: 1/2, step 1082/107898 completed (loss: 0.6159375309944153, acc: 1.0)
[2025-01-30 01:58:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1084/107898 [05:56<9:04:22,  3.27it/s][2025-01-30 01:58:06][root][INFO] - Training Epoch: 1/2, step 1083/107898 completed (loss: 3.3239552974700928, acc: 0.4285714328289032)
[2025-01-30 01:58:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1085/107898 [05:57<9:18:47,  3.19it/s][2025-01-30 01:58:07][root][INFO] - Training Epoch: 1/2, step 1084/107898 completed (loss: 1.4651988744735718, acc: 0.7272727489471436)
[2025-01-30 01:58:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1086/107898 [05:57<9:22:27,  3.17it/s][2025-01-30 01:58:07][root][INFO] - Training Epoch: 1/2, step 1085/107898 completed (loss: 2.3005900382995605, acc: 0.6000000238418579)
[2025-01-30 01:58:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1087/107898 [05:57<9:53:35,  3.00it/s][2025-01-30 01:58:07][root][INFO] - Training Epoch: 1/2, step 1086/107898 completed (loss: 2.843296766281128, acc: 0.20000000298023224)
[2025-01-30 01:58:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1088/107898 [05:58<9:44:23,  3.05it/s][2025-01-30 01:58:08][root][INFO] - Training Epoch: 1/2, step 1087/107898 completed (loss: 0.2639201879501343, acc: 1.0)
[2025-01-30 01:58:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1089/107898 [05:58<9:11:24,  3.23it/s][2025-01-30 01:58:08][root][INFO] - Training Epoch: 1/2, step 1088/107898 completed (loss: 0.7475035190582275, acc: 0.7931034564971924)
[2025-01-30 01:58:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1090/107898 [05:58<9:14:13,  3.21it/s][2025-01-30 01:58:08][root][INFO] - Training Epoch: 1/2, step 1089/107898 completed (loss: 2.732086420059204, acc: 0.5384615659713745)
[2025-01-30 01:58:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1091/107898 [05:59<9:12:28,  3.22it/s][2025-01-30 01:58:08][root][INFO] - Training Epoch: 1/2, step 1090/107898 completed (loss: 5.955711364746094, acc: 0.5)
[2025-01-30 01:58:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1092/107898 [05:59<9:04:24,  3.27it/s][2025-01-30 01:58:09][root][INFO] - Training Epoch: 1/2, step 1091/107898 completed (loss: 0.8309776186943054, acc: 0.8333333134651184)
[2025-01-30 01:58:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1093/107898 [05:59<9:05:34,  3.26it/s][2025-01-30 01:58:09][root][INFO] - Training Epoch: 1/2, step 1092/107898 completed (loss: 0.36097073554992676, acc: 0.875)
[2025-01-30 01:58:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1094/107898 [06:00<9:17:41,  3.19it/s][2025-01-30 01:58:09][root][INFO] - Training Epoch: 1/2, step 1093/107898 completed (loss: 1.2660630941390991, acc: 0.807692289352417)
[2025-01-30 01:58:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1095/107898 [06:00<9:26:11,  3.14it/s][2025-01-30 01:58:10][root][INFO] - Training Epoch: 1/2, step 1094/107898 completed (loss: 0.3715241253376007, acc: 1.0)
[2025-01-30 01:58:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1096/107898 [06:00<9:29:16,  3.13it/s][2025-01-30 01:58:10][root][INFO] - Training Epoch: 1/2, step 1095/107898 completed (loss: 0.5329541563987732, acc: 0.8666666746139526)
[2025-01-30 01:58:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1097/107898 [06:01<9:32:44,  3.11it/s][2025-01-30 01:58:10][root][INFO] - Training Epoch: 1/2, step 1096/107898 completed (loss: 0.667212724685669, acc: 0.8888888955116272)
[2025-01-30 01:58:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1098/107898 [06:01<9:22:52,  3.16it/s][2025-01-30 01:58:11][root][INFO] - Training Epoch: 1/2, step 1097/107898 completed (loss: 3.554877758026123, acc: 0.5)
[2025-01-30 01:58:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1099/107898 [06:01<9:30:44,  3.12it/s][2025-01-30 01:58:11][root][INFO] - Training Epoch: 1/2, step 1098/107898 completed (loss: 2.815070629119873, acc: 0.2857142984867096)
[2025-01-30 01:58:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1100/107898 [06:02<9:34:03,  3.10it/s][2025-01-30 01:58:11][root][INFO] - Training Epoch: 1/2, step 1099/107898 completed (loss: 0.20675599575042725, acc: 1.0)
[2025-01-30 01:58:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1101/107898 [06:02<9:48:47,  3.02it/s][2025-01-30 01:58:12][root][INFO] - Training Epoch: 1/2, step 1100/107898 completed (loss: 0.9755316376686096, acc: 0.7666666507720947)
[2025-01-30 01:58:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1102/107898 [06:02<9:38:22,  3.08it/s][2025-01-30 01:58:12][root][INFO] - Training Epoch: 1/2, step 1101/107898 completed (loss: 0.7349746227264404, acc: 0.5)
[2025-01-30 01:58:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1103/107898 [06:03<9:44:11,  3.05it/s][2025-01-30 01:58:12][root][INFO] - Training Epoch: 1/2, step 1102/107898 completed (loss: 1.0924183130264282, acc: 0.7631579041481018)
[2025-01-30 01:58:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1104/107898 [06:03<9:54:22,  2.99it/s][2025-01-30 01:58:13][root][INFO] - Training Epoch: 1/2, step 1103/107898 completed (loss: 0.8833802938461304, acc: 0.8666666746139526)
[2025-01-30 01:58:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1105/107898 [06:03<9:22:33,  3.16it/s][2025-01-30 01:58:13][root][INFO] - Training Epoch: 1/2, step 1104/107898 completed (loss: 2.4596774578094482, acc: 0.6666666865348816)
[2025-01-30 01:58:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1106/107898 [06:03<9:20:53,  3.17it/s][2025-01-30 01:58:13][root][INFO] - Training Epoch: 1/2, step 1105/107898 completed (loss: 1.862053632736206, acc: 0.5714285969734192)
[2025-01-30 01:58:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1107/107898 [06:04<9:10:27,  3.23it/s][2025-01-30 01:58:14][root][INFO] - Training Epoch: 1/2, step 1106/107898 completed (loss: 0.8273042440414429, acc: 0.75)
[2025-01-30 01:58:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1108/107898 [06:04<9:03:59,  3.27it/s][2025-01-30 01:58:14][root][INFO] - Training Epoch: 1/2, step 1107/107898 completed (loss: 1.0212119817733765, acc: 0.8999999761581421)
[2025-01-30 01:58:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1109/107898 [06:04<9:26:04,  3.14it/s][2025-01-30 01:58:14][root][INFO] - Training Epoch: 1/2, step 1108/107898 completed (loss: 0.1241210326552391, acc: 0.9444444179534912)
[2025-01-30 01:58:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1110/107898 [06:05<9:34:48,  3.10it/s][2025-01-30 01:58:15][root][INFO] - Training Epoch: 1/2, step 1109/107898 completed (loss: 0.8246194124221802, acc: 1.0)
[2025-01-30 01:58:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1111/107898 [06:05<10:02:55,  2.95it/s][2025-01-30 01:58:15][root][INFO] - Training Epoch: 1/2, step 1110/107898 completed (loss: 0.17545069754123688, acc: 1.0)
[2025-01-30 01:58:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1112/107898 [06:05<9:58:10,  2.98it/s] [2025-01-30 01:58:15][root][INFO] - Training Epoch: 1/2, step 1111/107898 completed (loss: 1.5404366254806519, acc: 0.75)
[2025-01-30 01:58:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1113/107898 [06:06<9:44:27,  3.05it/s][2025-01-30 01:58:16][root][INFO] - Training Epoch: 1/2, step 1112/107898 completed (loss: 2.6916682720184326, acc: 0.3333333432674408)
[2025-01-30 01:58:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1114/107898 [06:06<9:41:39,  3.06it/s][2025-01-30 01:58:16][root][INFO] - Training Epoch: 1/2, step 1113/107898 completed (loss: 0.9400092959403992, acc: 0.7647058963775635)
[2025-01-30 01:58:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1115/107898 [06:06<9:24:19,  3.15it/s][2025-01-30 01:58:16][root][INFO] - Training Epoch: 1/2, step 1114/107898 completed (loss: 1.8546581268310547, acc: 0.5)
[2025-01-30 01:58:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1116/107898 [06:07<9:16:21,  3.20it/s][2025-01-30 01:58:16][root][INFO] - Training Epoch: 1/2, step 1115/107898 completed (loss: 0.06500931084156036, acc: 1.0)
[2025-01-30 01:58:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1117/107898 [06:07<9:33:38,  3.10it/s][2025-01-30 01:58:17][root][INFO] - Training Epoch: 1/2, step 1116/107898 completed (loss: 0.8690550923347473, acc: 0.8571428656578064)
[2025-01-30 01:58:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1118/107898 [06:07<9:29:09,  3.13it/s][2025-01-30 01:58:17][root][INFO] - Training Epoch: 1/2, step 1117/107898 completed (loss: 2.6515119075775146, acc: 0.6666666865348816)
[2025-01-30 01:58:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1119/107898 [06:08<9:02:32,  3.28it/s][2025-01-30 01:58:17][root][INFO] - Training Epoch: 1/2, step 1118/107898 completed (loss: 3.13966965675354, acc: 0.3333333432674408)
[2025-01-30 01:58:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1120/107898 [06:08<8:56:45,  3.32it/s][2025-01-30 01:58:18][root][INFO] - Training Epoch: 1/2, step 1119/107898 completed (loss: 0.051670901477336884, acc: 1.0)
[2025-01-30 01:58:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1121/107898 [06:08<8:56:55,  3.31it/s][2025-01-30 01:58:18][root][INFO] - Training Epoch: 1/2, step 1120/107898 completed (loss: 1.9417201280593872, acc: 0.6666666865348816)
[2025-01-30 01:58:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1122/107898 [06:09<9:09:34,  3.24it/s][2025-01-30 01:58:18][root][INFO] - Training Epoch: 1/2, step 1121/107898 completed (loss: 0.49241331219673157, acc: 0.9230769276618958)
[2025-01-30 01:58:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1123/107898 [06:09<8:59:51,  3.30it/s][2025-01-30 01:58:19][root][INFO] - Training Epoch: 1/2, step 1122/107898 completed (loss: 0.0692707970738411, acc: 1.0)
[2025-01-30 01:58:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1124/107898 [06:09<9:18:15,  3.19it/s][2025-01-30 01:58:19][root][INFO] - Training Epoch: 1/2, step 1123/107898 completed (loss: 0.029016543179750443, acc: 1.0)
[2025-01-30 01:58:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1125/107898 [06:09<9:25:03,  3.15it/s][2025-01-30 01:58:19][root][INFO] - Training Epoch: 1/2, step 1124/107898 completed (loss: 1.628507375717163, acc: 0.7777777910232544)
[2025-01-30 01:58:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1126/107898 [06:10<9:30:58,  3.12it/s][2025-01-30 01:58:20][root][INFO] - Training Epoch: 1/2, step 1125/107898 completed (loss: 0.18046045303344727, acc: 1.0)
[2025-01-30 01:58:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1127/107898 [06:10<9:39:22,  3.07it/s][2025-01-30 01:58:20][root][INFO] - Training Epoch: 1/2, step 1126/107898 completed (loss: 0.7939650416374207, acc: 0.8888888955116272)
[2025-01-30 01:58:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1128/107898 [06:10<9:52:02,  3.01it/s][2025-01-30 01:58:20][root][INFO] - Training Epoch: 1/2, step 1127/107898 completed (loss: 0.6257004737854004, acc: 0.5)
[2025-01-30 01:58:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1129/107898 [06:11<10:01:33,  2.96it/s][2025-01-30 01:58:21][root][INFO] - Training Epoch: 1/2, step 1128/107898 completed (loss: 3.165184259414673, acc: 0.4285714328289032)
[2025-01-30 01:58:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1130/107898 [06:11<10:11:11,  2.91it/s][2025-01-30 01:58:21][root][INFO] - Training Epoch: 1/2, step 1129/107898 completed (loss: 1.173646092414856, acc: 0.7333333492279053)
[2025-01-30 01:58:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1131/107898 [06:12<10:12:11,  2.91it/s][2025-01-30 01:58:21][root][INFO] - Training Epoch: 1/2, step 1130/107898 completed (loss: 0.6874390840530396, acc: 0.8888888955116272)
[2025-01-30 01:58:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1132/107898 [06:12<9:48:08,  3.03it/s] [2025-01-30 01:58:22][root][INFO] - Training Epoch: 1/2, step 1131/107898 completed (loss: 1.6321548223495483, acc: 0.6666666865348816)
[2025-01-30 01:58:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1133/107898 [06:12<9:52:47,  3.00it/s][2025-01-30 01:58:22][root][INFO] - Training Epoch: 1/2, step 1132/107898 completed (loss: 0.08101795613765717, acc: 1.0)
[2025-01-30 01:58:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1134/107898 [06:13<10:07:51,  2.93it/s][2025-01-30 01:58:22][root][INFO] - Training Epoch: 1/2, step 1133/107898 completed (loss: 0.5114376544952393, acc: 1.0)
[2025-01-30 01:58:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1135/107898 [06:13<10:03:03,  2.95it/s][2025-01-30 01:58:23][root][INFO] - Training Epoch: 1/2, step 1134/107898 completed (loss: 2.4171977043151855, acc: 0.5)
[2025-01-30 01:58:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1136/107898 [06:13<10:15:10,  2.89it/s][2025-01-30 01:58:23][root][INFO] - Training Epoch: 1/2, step 1135/107898 completed (loss: 2.5351831912994385, acc: 0.3333333432674408)
[2025-01-30 01:58:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1137/107898 [06:14<10:22:51,  2.86it/s][2025-01-30 01:58:23][root][INFO] - Training Epoch: 1/2, step 1136/107898 completed (loss: 2.202298879623413, acc: 0.4615384638309479)
[2025-01-30 01:58:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1138/107898 [06:14<10:13:35,  2.90it/s][2025-01-30 01:58:24][root][INFO] - Training Epoch: 1/2, step 1137/107898 completed (loss: 0.25238025188446045, acc: 1.0)
[2025-01-30 01:58:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1139/107898 [06:14<10:16:12,  2.89it/s][2025-01-30 01:58:24][root][INFO] - Training Epoch: 1/2, step 1138/107898 completed (loss: 4.148787021636963, acc: 0.22580644488334656)
[2025-01-30 01:58:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1140/107898 [06:15<10:05:04,  2.94it/s][2025-01-30 01:58:24][root][INFO] - Training Epoch: 1/2, step 1139/107898 completed (loss: 1.2466521263122559, acc: 0.6666666865348816)
[2025-01-30 01:58:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1141/107898 [06:15<10:02:08,  2.95it/s][2025-01-30 01:58:25][root][INFO] - Training Epoch: 1/2, step 1140/107898 completed (loss: 0.04152389615774155, acc: 1.0)
[2025-01-30 01:58:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1142/107898 [06:15<10:00:45,  2.96it/s][2025-01-30 01:58:25][root][INFO] - Training Epoch: 1/2, step 1141/107898 completed (loss: 0.6054380536079407, acc: 0.8399999737739563)
[2025-01-30 01:58:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1143/107898 [06:16<9:44:52,  3.04it/s] [2025-01-30 01:58:25][root][INFO] - Training Epoch: 1/2, step 1142/107898 completed (loss: 2.4535293579101562, acc: 0.5555555820465088)
[2025-01-30 01:58:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1144/107898 [06:16<9:32:56,  3.11it/s][2025-01-30 01:58:26][root][INFO] - Training Epoch: 1/2, step 1143/107898 completed (loss: 3.8896989822387695, acc: 0.1538461595773697)
[2025-01-30 01:58:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1145/107898 [06:16<9:06:24,  3.26it/s][2025-01-30 01:58:26][root][INFO] - Training Epoch: 1/2, step 1144/107898 completed (loss: 0.6302221417427063, acc: 0.8333333134651184)
[2025-01-30 01:58:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1146/107898 [06:16<9:04:38,  3.27it/s][2025-01-30 01:58:26][root][INFO] - Training Epoch: 1/2, step 1145/107898 completed (loss: 1.3205885887145996, acc: 0.7647058963775635)
[2025-01-30 01:58:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1147/107898 [06:17<8:53:24,  3.34it/s][2025-01-30 01:58:27][root][INFO] - Training Epoch: 1/2, step 1146/107898 completed (loss: 1.7427191734313965, acc: 0.7692307829856873)
[2025-01-30 01:58:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1148/107898 [06:17<8:42:18,  3.41it/s][2025-01-30 01:58:27][root][INFO] - Training Epoch: 1/2, step 1147/107898 completed (loss: 0.10347171127796173, acc: 1.0)
[2025-01-30 01:58:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1149/107898 [06:17<8:38:55,  3.43it/s][2025-01-30 01:58:27][root][INFO] - Training Epoch: 1/2, step 1148/107898 completed (loss: 1.838584303855896, acc: 0.59375)
[2025-01-30 01:58:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1150/107898 [06:18<8:51:11,  3.35it/s][2025-01-30 01:58:27][root][INFO] - Training Epoch: 1/2, step 1149/107898 completed (loss: 2.3921711444854736, acc: 0.4375)
[2025-01-30 01:58:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1151/107898 [06:18<8:56:11,  3.32it/s][2025-01-30 01:58:28][root][INFO] - Training Epoch: 1/2, step 1150/107898 completed (loss: 1.8280067443847656, acc: 0.3333333432674408)
[2025-01-30 01:58:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1152/107898 [06:18<9:06:18,  3.26it/s][2025-01-30 01:58:28][root][INFO] - Training Epoch: 1/2, step 1151/107898 completed (loss: 1.8085452318191528, acc: 0.6363636255264282)
[2025-01-30 01:58:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1153/107898 [06:19<9:03:27,  3.27it/s][2025-01-30 01:58:28][root][INFO] - Training Epoch: 1/2, step 1152/107898 completed (loss: 0.06861700117588043, acc: 1.0)
[2025-01-30 01:58:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1154/107898 [06:19<9:20:34,  3.17it/s][2025-01-30 01:58:29][root][INFO] - Training Epoch: 1/2, step 1153/107898 completed (loss: 0.533823549747467, acc: 0.930232584476471)
[2025-01-30 01:58:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1155/107898 [06:19<9:51:59,  3.01it/s][2025-01-30 01:58:29][root][INFO] - Training Epoch: 1/2, step 1154/107898 completed (loss: 0.9321244955062866, acc: 0.800000011920929)
[2025-01-30 01:58:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1156/107898 [06:20<9:57:45,  2.98it/s][2025-01-30 01:58:29][root][INFO] - Training Epoch: 1/2, step 1155/107898 completed (loss: 2.822570562362671, acc: 0.5454545617103577)
[2025-01-30 01:58:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1157/107898 [06:20<10:12:43,  2.90it/s][2025-01-30 01:58:30][root][INFO] - Training Epoch: 1/2, step 1156/107898 completed (loss: 2.1140782833099365, acc: 0.5833333134651184)
[2025-01-30 01:58:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1158/107898 [06:20<10:25:21,  2.84it/s][2025-01-30 01:58:30][root][INFO] - Training Epoch: 1/2, step 1157/107898 completed (loss: 1.401712417602539, acc: 0.5)
[2025-01-30 01:58:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1159/107898 [06:21<10:22:38,  2.86it/s][2025-01-30 01:58:30][root][INFO] - Training Epoch: 1/2, step 1158/107898 completed (loss: 1.9880402088165283, acc: 0.6538461446762085)
[2025-01-30 01:58:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1160/107898 [06:21<10:25:12,  2.85it/s][2025-01-30 01:58:31][root][INFO] - Training Epoch: 1/2, step 1159/107898 completed (loss: 4.1026177406311035, acc: 0.4444444477558136)
[2025-01-30 01:58:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1161/107898 [06:21<10:14:06,  2.90it/s][2025-01-30 01:58:31][root][INFO] - Training Epoch: 1/2, step 1160/107898 completed (loss: 1.3382668495178223, acc: 0.8333333134651184)
[2025-01-30 01:58:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1162/107898 [06:22<9:58:19,  2.97it/s] [2025-01-30 01:58:31][root][INFO] - Training Epoch: 1/2, step 1161/107898 completed (loss: 3.430999279022217, acc: 0.4000000059604645)
[2025-01-30 01:58:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1163/107898 [06:22<10:09:42,  2.92it/s][2025-01-30 01:58:32][root][INFO] - Training Epoch: 1/2, step 1162/107898 completed (loss: 0.5846046209335327, acc: 0.8695651888847351)
[2025-01-30 01:58:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1164/107898 [06:22<10:05:45,  2.94it/s][2025-01-30 01:58:32][root][INFO] - Training Epoch: 1/2, step 1163/107898 completed (loss: 0.6789562106132507, acc: 0.6000000238418579)
[2025-01-30 01:58:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1165/107898 [06:23<10:21:49,  2.86it/s][2025-01-30 01:58:33][root][INFO] - Training Epoch: 1/2, step 1164/107898 completed (loss: 2.33718204498291, acc: 0.6666666865348816)
[2025-01-30 01:58:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1166/107898 [06:23<10:06:38,  2.93it/s][2025-01-30 01:58:33][root][INFO] - Training Epoch: 1/2, step 1165/107898 completed (loss: 1.203648567199707, acc: 0.6000000238418579)
[2025-01-30 01:58:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1167/107898 [06:23<9:57:36,  2.98it/s] [2025-01-30 01:58:33][root][INFO] - Training Epoch: 1/2, step 1166/107898 completed (loss: 0.2467712014913559, acc: 0.8823529481887817)
[2025-01-30 01:58:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1168/107898 [06:24<9:55:47,  2.99it/s][2025-01-30 01:58:34][root][INFO] - Training Epoch: 1/2, step 1167/107898 completed (loss: 0.8759335875511169, acc: 0.8571428656578064)
[2025-01-30 01:58:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1169/107898 [06:24<9:46:38,  3.03it/s][2025-01-30 01:58:34][root][INFO] - Training Epoch: 1/2, step 1168/107898 completed (loss: 0.2328833043575287, acc: 1.0)
[2025-01-30 01:58:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1170/107898 [06:24<9:24:53,  3.15it/s][2025-01-30 01:58:34][root][INFO] - Training Epoch: 1/2, step 1169/107898 completed (loss: 0.04795357584953308, acc: 1.0)
[2025-01-30 01:58:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1171/107898 [06:25<9:47:06,  3.03it/s][2025-01-30 01:58:34][root][INFO] - Training Epoch: 1/2, step 1170/107898 completed (loss: 1.058412790298462, acc: 0.7272727489471436)
[2025-01-30 01:58:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1172/107898 [06:25<9:57:45,  2.98it/s][2025-01-30 01:58:35][root][INFO] - Training Epoch: 1/2, step 1171/107898 completed (loss: 4.29749059677124, acc: 0.125)
[2025-01-30 01:58:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1173/107898 [06:25<9:35:28,  3.09it/s][2025-01-30 01:58:35][root][INFO] - Training Epoch: 1/2, step 1172/107898 completed (loss: 0.02680017612874508, acc: 1.0)
[2025-01-30 01:58:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1174/107898 [06:26<9:27:35,  3.13it/s][2025-01-30 01:58:35][root][INFO] - Training Epoch: 1/2, step 1173/107898 completed (loss: 1.02436363697052, acc: 0.800000011920929)
[2025-01-30 01:58:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1175/107898 [06:26<9:17:33,  3.19it/s][2025-01-30 01:58:36][root][INFO] - Training Epoch: 1/2, step 1174/107898 completed (loss: 1.0841012001037598, acc: 0.7333333492279053)
[2025-01-30 01:58:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1176/107898 [06:26<8:55:00,  3.32it/s][2025-01-30 01:58:36][root][INFO] - Training Epoch: 1/2, step 1175/107898 completed (loss: 0.40447482466697693, acc: 0.8125)
[2025-01-30 01:58:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1177/107898 [06:27<8:55:40,  3.32it/s][2025-01-30 01:58:36][root][INFO] - Training Epoch: 1/2, step 1176/107898 completed (loss: 0.21887050569057465, acc: 0.9230769276618958)
[2025-01-30 01:58:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1178/107898 [06:27<8:43:18,  3.40it/s][2025-01-30 01:58:37][root][INFO] - Training Epoch: 1/2, step 1177/107898 completed (loss: 0.5282652378082275, acc: 1.0)
[2025-01-30 01:58:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1179/107898 [06:27<9:01:13,  3.29it/s][2025-01-30 01:58:37][root][INFO] - Training Epoch: 1/2, step 1178/107898 completed (loss: 1.1946147680282593, acc: 0.5)
[2025-01-30 01:58:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1180/107898 [06:27<9:13:39,  3.21it/s][2025-01-30 01:58:37][root][INFO] - Training Epoch: 1/2, step 1179/107898 completed (loss: 3.1684420108795166, acc: 0.3199999928474426)
[2025-01-30 01:58:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1181/107898 [06:28<9:37:40,  3.08it/s][2025-01-30 01:58:38][root][INFO] - Training Epoch: 1/2, step 1180/107898 completed (loss: 2.279538154602051, acc: 0.4545454680919647)
[2025-01-30 01:58:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1182/107898 [06:28<10:01:42,  2.96it/s][2025-01-30 01:58:38][root][INFO] - Training Epoch: 1/2, step 1181/107898 completed (loss: 1.1064887046813965, acc: 0.5)
[2025-01-30 01:58:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1183/107898 [06:29<10:17:13,  2.88it/s][2025-01-30 01:58:38][root][INFO] - Training Epoch: 1/2, step 1182/107898 completed (loss: 0.03411499038338661, acc: 1.0)
[2025-01-30 01:58:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1184/107898 [06:29<10:16:15,  2.89it/s][2025-01-30 01:58:39][root][INFO] - Training Epoch: 1/2, step 1183/107898 completed (loss: 1.6078941822052002, acc: 0.699999988079071)
[2025-01-30 01:58:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1185/107898 [06:29<10:01:20,  2.96it/s][2025-01-30 01:58:39][root][INFO] - Training Epoch: 1/2, step 1184/107898 completed (loss: 1.6435356140136719, acc: 0.6470588445663452)
[2025-01-30 01:58:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1186/107898 [06:30<10:04:09,  2.94it/s][2025-01-30 01:58:39][root][INFO] - Training Epoch: 1/2, step 1185/107898 completed (loss: 0.10456322878599167, acc: 1.0)
[2025-01-30 01:58:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1187/107898 [06:30<9:52:47,  3.00it/s] [2025-01-30 01:58:40][root][INFO] - Training Epoch: 1/2, step 1186/107898 completed (loss: 0.04594637081027031, acc: 1.0)
[2025-01-30 01:58:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1188/107898 [06:30<10:12:51,  2.90it/s][2025-01-30 01:58:40][root][INFO] - Training Epoch: 1/2, step 1187/107898 completed (loss: 0.23798322677612305, acc: 0.9166666865348816)
[2025-01-30 01:58:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1189/107898 [06:31<9:58:53,  2.97it/s] [2025-01-30 01:58:40][root][INFO] - Training Epoch: 1/2, step 1188/107898 completed (loss: 0.03824187070131302, acc: 1.0)
[2025-01-30 01:58:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1190/107898 [06:31<10:11:23,  2.91it/s][2025-01-30 01:58:41][root][INFO] - Training Epoch: 1/2, step 1189/107898 completed (loss: 0.8800996541976929, acc: 1.0)
[2025-01-30 01:58:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1191/107898 [06:31<10:08:37,  2.92it/s][2025-01-30 01:58:41][root][INFO] - Training Epoch: 1/2, step 1190/107898 completed (loss: 2.6422066688537598, acc: 0.5)
[2025-01-30 01:58:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1192/107898 [06:32<9:53:44,  3.00it/s] [2025-01-30 01:58:41][root][INFO] - Training Epoch: 1/2, step 1191/107898 completed (loss: 4.732554912567139, acc: 0.3333333432674408)
[2025-01-30 01:58:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1193/107898 [06:32<10:02:57,  2.95it/s][2025-01-30 01:58:42][root][INFO] - Training Epoch: 1/2, step 1192/107898 completed (loss: 1.4902807474136353, acc: 0.75)
[2025-01-30 01:58:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1194/107898 [06:32<10:00:04,  2.96it/s][2025-01-30 01:58:42][root][INFO] - Training Epoch: 1/2, step 1193/107898 completed (loss: 0.7728367447853088, acc: 0.8823529481887817)
[2025-01-30 01:58:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1195/107898 [06:33<10:06:16,  2.93it/s][2025-01-30 01:58:42][root][INFO] - Training Epoch: 1/2, step 1194/107898 completed (loss: 4.323379039764404, acc: 0.27272728085517883)
[2025-01-30 01:58:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1196/107898 [06:33<10:13:36,  2.90it/s][2025-01-30 01:58:43][root][INFO] - Training Epoch: 1/2, step 1195/107898 completed (loss: 0.39706242084503174, acc: 0.9411764740943909)
[2025-01-30 01:58:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1197/107898 [06:33<9:44:04,  3.04it/s] [2025-01-30 01:58:43][root][INFO] - Training Epoch: 1/2, step 1196/107898 completed (loss: 0.3506219685077667, acc: 1.0)
[2025-01-30 01:58:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1198/107898 [06:34<9:52:00,  3.00it/s][2025-01-30 01:58:43][root][INFO] - Training Epoch: 1/2, step 1197/107898 completed (loss: 1.057432770729065, acc: 0.7894737124443054)
[2025-01-30 01:58:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1199/107898 [06:34<9:59:29,  2.97it/s][2025-01-30 01:58:44][root][INFO] - Training Epoch: 1/2, step 1198/107898 completed (loss: 0.06291847676038742, acc: 1.0)
[2025-01-30 01:58:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1200/107898 [06:34<10:08:30,  2.92it/s][2025-01-30 01:58:44][root][INFO] - Training Epoch: 1/2, step 1199/107898 completed (loss: 1.824257254600525, acc: 0.6363636255264282)
[2025-01-30 01:58:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1201/107898 [06:35<9:45:19,  3.04it/s] [2025-01-30 01:58:44][root][INFO] - Training Epoch: 1/2, step 1200/107898 completed (loss: 1.9935131072998047, acc: 0.625)
[2025-01-30 01:58:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1202/107898 [06:35<9:40:54,  3.06it/s][2025-01-30 01:58:45][root][INFO] - Training Epoch: 1/2, step 1201/107898 completed (loss: 2.989443302154541, acc: 0.5384615659713745)
[2025-01-30 01:58:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1203/107898 [06:35<9:31:32,  3.11it/s][2025-01-30 01:58:45][root][INFO] - Training Epoch: 1/2, step 1202/107898 completed (loss: 1.9288866519927979, acc: 0.7777777910232544)
[2025-01-30 01:58:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1204/107898 [06:36<9:28:20,  3.13it/s][2025-01-30 01:58:45][root][INFO] - Training Epoch: 1/2, step 1203/107898 completed (loss: 0.6911205649375916, acc: 1.0)
[2025-01-30 01:58:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1205/107898 [06:36<9:52:21,  3.00it/s][2025-01-30 01:58:46][root][INFO] - Training Epoch: 1/2, step 1204/107898 completed (loss: 0.814910888671875, acc: 0.8333333134651184)
[2025-01-30 01:58:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1206/107898 [06:36<9:56:42,  2.98it/s][2025-01-30 01:58:46][root][INFO] - Training Epoch: 1/2, step 1205/107898 completed (loss: 0.11625345796346664, acc: 1.0)
[2025-01-30 01:58:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1207/107898 [06:37<10:47:32,  2.75it/s][2025-01-30 01:58:46][root][INFO] - Training Epoch: 1/2, step 1206/107898 completed (loss: 0.4206153154373169, acc: 1.0)
[2025-01-30 01:58:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1208/107898 [06:37<10:08:26,  2.92it/s][2025-01-30 01:58:47][root][INFO] - Training Epoch: 1/2, step 1207/107898 completed (loss: 0.004778987728059292, acc: 1.0)
[2025-01-30 01:58:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1209/107898 [06:37<10:20:04,  2.87it/s][2025-01-30 01:58:47][root][INFO] - Training Epoch: 1/2, step 1208/107898 completed (loss: 0.12181563675403595, acc: 1.0)
[2025-01-30 01:58:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1210/107898 [06:38<10:39:28,  2.78it/s][2025-01-30 01:58:48][root][INFO] - Training Epoch: 1/2, step 1209/107898 completed (loss: 0.583173930644989, acc: 0.8888888955116272)
[2025-01-30 01:58:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1211/107898 [06:38<10:26:22,  2.84it/s][2025-01-30 01:58:48][root][INFO] - Training Epoch: 1/2, step 1210/107898 completed (loss: 1.8771659135818481, acc: 0.75)
[2025-01-30 01:58:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1212/107898 [06:38<10:32:44,  2.81it/s][2025-01-30 01:58:48][root][INFO] - Training Epoch: 1/2, step 1211/107898 completed (loss: 4.2480268478393555, acc: 0.25)
[2025-01-30 01:58:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1213/107898 [06:39<11:08:17,  2.66it/s][2025-01-30 01:58:49][root][INFO] - Training Epoch: 1/2, step 1212/107898 completed (loss: 0.8475697040557861, acc: 0.8387096524238586)
[2025-01-30 01:58:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1214/107898 [06:39<10:44:48,  2.76it/s][2025-01-30 01:58:49][root][INFO] - Training Epoch: 1/2, step 1213/107898 completed (loss: 2.0076839923858643, acc: 0.4285714328289032)
[2025-01-30 01:58:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1215/107898 [06:40<10:58:56,  2.70it/s][2025-01-30 01:58:49][root][INFO] - Training Epoch: 1/2, step 1214/107898 completed (loss: 0.9201905727386475, acc: 0.8064516186714172)
[2025-01-30 01:58:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1216/107898 [06:40<10:45:40,  2.75it/s][2025-01-30 01:58:50][root][INFO] - Training Epoch: 1/2, step 1215/107898 completed (loss: 0.006420878693461418, acc: 1.0)
[2025-01-30 01:58:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1217/107898 [06:40<10:29:27,  2.82it/s][2025-01-30 01:58:50][root][INFO] - Training Epoch: 1/2, step 1216/107898 completed (loss: 1.6065224409103394, acc: 0.6666666865348816)
[2025-01-30 01:58:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1218/107898 [06:41<10:18:38,  2.87it/s][2025-01-30 01:58:50][root][INFO] - Training Epoch: 1/2, step 1217/107898 completed (loss: 0.6878776550292969, acc: 0.5714285969734192)
[2025-01-30 01:58:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1219/107898 [06:41<9:59:41,  2.96it/s] [2025-01-30 01:58:51][root][INFO] - Training Epoch: 1/2, step 1218/107898 completed (loss: 1.1177661418914795, acc: 0.75)
[2025-01-30 01:58:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1220/107898 [06:41<9:38:48,  3.07it/s][2025-01-30 01:58:51][root][INFO] - Training Epoch: 1/2, step 1219/107898 completed (loss: 0.43266263604164124, acc: 0.9166666865348816)
[2025-01-30 01:58:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1221/107898 [06:41<9:31:24,  3.11it/s][2025-01-30 01:58:51][root][INFO] - Training Epoch: 1/2, step 1220/107898 completed (loss: 1.8707748651504517, acc: 0.7142857313156128)
[2025-01-30 01:58:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1222/107898 [06:42<9:16:55,  3.19it/s][2025-01-30 01:58:52][root][INFO] - Training Epoch: 1/2, step 1221/107898 completed (loss: 3.086557388305664, acc: 0.5)
[2025-01-30 01:58:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1223/107898 [06:42<9:51:00,  3.01it/s][2025-01-30 01:58:52][root][INFO] - Training Epoch: 1/2, step 1222/107898 completed (loss: 1.4433562755584717, acc: 0.7352941036224365)
[2025-01-30 01:58:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1224/107898 [06:43<10:09:51,  2.92it/s][2025-01-30 01:58:52][root][INFO] - Training Epoch: 1/2, step 1223/107898 completed (loss: 0.018947292119264603, acc: 1.0)
[2025-01-30 01:58:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1225/107898 [06:43<10:13:34,  2.90it/s][2025-01-30 01:58:53][root][INFO] - Training Epoch: 1/2, step 1224/107898 completed (loss: 4.510127067565918, acc: 0.375)
[2025-01-30 01:58:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1226/107898 [06:43<10:24:00,  2.85it/s][2025-01-30 01:58:53][root][INFO] - Training Epoch: 1/2, step 1225/107898 completed (loss: 0.056983936578035355, acc: 1.0)
[2025-01-30 01:58:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1227/107898 [06:44<10:12:34,  2.90it/s][2025-01-30 01:58:53][root][INFO] - Training Epoch: 1/2, step 1226/107898 completed (loss: 1.1367602348327637, acc: 0.5)
[2025-01-30 01:58:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1228/107898 [06:44<10:23:14,  2.85it/s][2025-01-30 01:58:54][root][INFO] - Training Epoch: 1/2, step 1227/107898 completed (loss: 0.29120662808418274, acc: 1.0)
[2025-01-30 01:58:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1229/107898 [06:44<10:11:45,  2.91it/s][2025-01-30 01:58:54][root][INFO] - Training Epoch: 1/2, step 1228/107898 completed (loss: 3.6969823837280273, acc: 0.529411792755127)
[2025-01-30 01:58:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1230/107898 [06:45<9:56:01,  2.98it/s] [2025-01-30 01:58:54][root][INFO] - Training Epoch: 1/2, step 1229/107898 completed (loss: 0.7307761907577515, acc: 0.5)
[2025-01-30 01:58:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1231/107898 [06:45<9:37:22,  3.08it/s][2025-01-30 01:58:55][root][INFO] - Training Epoch: 1/2, step 1230/107898 completed (loss: 4.17796516418457, acc: 0.23076923191547394)
[2025-01-30 01:58:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1232/107898 [06:45<9:29:25,  3.12it/s][2025-01-30 01:58:55][root][INFO] - Training Epoch: 1/2, step 1231/107898 completed (loss: 0.9031878113746643, acc: 0.8181818127632141)
[2025-01-30 01:58:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1233/107898 [06:46<9:39:36,  3.07it/s][2025-01-30 01:58:55][root][INFO] - Training Epoch: 1/2, step 1232/107898 completed (loss: 5.01154088973999, acc: 0.11764705926179886)
[2025-01-30 01:58:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1234/107898 [06:46<9:19:44,  3.18it/s][2025-01-30 01:58:56][root][INFO] - Training Epoch: 1/2, step 1233/107898 completed (loss: 1.041980266571045, acc: 0.8333333134651184)
[2025-01-30 01:58:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1235/107898 [06:46<9:17:58,  3.19it/s][2025-01-30 01:58:56][root][INFO] - Training Epoch: 1/2, step 1234/107898 completed (loss: 0.06604187935590744, acc: 1.0)
[2025-01-30 01:58:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1236/107898 [06:46<9:17:30,  3.19it/s][2025-01-30 01:58:56][root][INFO] - Training Epoch: 1/2, step 1235/107898 completed (loss: 0.0064762309193611145, acc: 1.0)
[2025-01-30 01:58:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1237/107898 [06:47<9:24:37,  3.15it/s][2025-01-30 01:58:57][root][INFO] - Training Epoch: 1/2, step 1236/107898 completed (loss: 0.7551433444023132, acc: 0.8095238208770752)
[2025-01-30 01:58:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1238/107898 [06:47<9:22:09,  3.16it/s][2025-01-30 01:58:57][root][INFO] - Training Epoch: 1/2, step 1237/107898 completed (loss: 0.02092302031815052, acc: 1.0)
[2025-01-30 01:58:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1239/107898 [06:47<9:32:30,  3.10it/s][2025-01-30 01:58:57][root][INFO] - Training Epoch: 1/2, step 1238/107898 completed (loss: 0.33101537823677063, acc: 1.0)
[2025-01-30 01:58:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1240/107898 [06:48<9:24:12,  3.15it/s][2025-01-30 01:58:58][root][INFO] - Training Epoch: 1/2, step 1239/107898 completed (loss: 2.079644203186035, acc: 0.5333333611488342)
[2025-01-30 01:58:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1241/107898 [06:48<9:20:11,  3.17it/s][2025-01-30 01:58:58][root][INFO] - Training Epoch: 1/2, step 1240/107898 completed (loss: 6.8692946434021, acc: 0.125)
[2025-01-30 01:58:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1242/107898 [06:48<9:09:17,  3.24it/s][2025-01-30 01:58:58][root][INFO] - Training Epoch: 1/2, step 1241/107898 completed (loss: 0.015690013766288757, acc: 1.0)
[2025-01-30 01:58:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1243/107898 [06:49<9:31:33,  3.11it/s][2025-01-30 01:58:58][root][INFO] - Training Epoch: 1/2, step 1242/107898 completed (loss: 1.043655276298523, acc: 0.9090909361839294)
[2025-01-30 01:58:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1244/107898 [06:49<9:39:00,  3.07it/s][2025-01-30 01:58:59][root][INFO] - Training Epoch: 1/2, step 1243/107898 completed (loss: 1.7015221118927002, acc: 0.75)
[2025-01-30 01:58:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1245/107898 [06:49<9:31:42,  3.11it/s][2025-01-30 01:58:59][root][INFO] - Training Epoch: 1/2, step 1244/107898 completed (loss: 0.3964616656303406, acc: 1.0)
[2025-01-30 01:58:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1246/107898 [06:50<9:40:00,  3.06it/s][2025-01-30 01:58:59][root][INFO] - Training Epoch: 1/2, step 1245/107898 completed (loss: 0.8794881105422974, acc: 0.8846153616905212)
[2025-01-30 01:59:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1247/107898 [06:50<9:24:39,  3.15it/s][2025-01-30 01:59:00][root][INFO] - Training Epoch: 1/2, step 1246/107898 completed (loss: 0.6070120930671692, acc: 0.8181818127632141)
[2025-01-30 01:59:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1248/107898 [06:50<9:19:39,  3.18it/s][2025-01-30 01:59:00][root][INFO] - Training Epoch: 1/2, step 1247/107898 completed (loss: 0.6084698438644409, acc: 0.8399999737739563)
[2025-01-30 01:59:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1249/107898 [06:51<9:17:49,  3.19it/s][2025-01-30 01:59:00][root][INFO] - Training Epoch: 1/2, step 1248/107898 completed (loss: 0.2964547872543335, acc: 0.9473684430122375)
[2025-01-30 01:59:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1250/107898 [06:51<9:06:45,  3.25it/s][2025-01-30 01:59:01][root][INFO] - Training Epoch: 1/2, step 1249/107898 completed (loss: 3.6473207473754883, acc: 0.5)
[2025-01-30 01:59:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1251/107898 [06:51<9:00:23,  3.29it/s][2025-01-30 01:59:01][root][INFO] - Training Epoch: 1/2, step 1250/107898 completed (loss: 1.4504057168960571, acc: 0.5555555820465088)
[2025-01-30 01:59:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1252/107898 [06:51<8:57:21,  3.31it/s][2025-01-30 01:59:01][root][INFO] - Training Epoch: 1/2, step 1251/107898 completed (loss: 0.7785176634788513, acc: 0.800000011920929)
[2025-01-30 01:59:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1253/107898 [06:52<9:14:37,  3.20it/s][2025-01-30 01:59:02][root][INFO] - Training Epoch: 1/2, step 1252/107898 completed (loss: 0.3102708160877228, acc: 0.9090909361839294)
[2025-01-30 01:59:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1254/107898 [06:52<9:30:51,  3.11it/s][2025-01-30 01:59:02][root][INFO] - Training Epoch: 1/2, step 1253/107898 completed (loss: 0.5537045001983643, acc: 0.8333333134651184)
[2025-01-30 01:59:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1255/107898 [06:52<9:31:53,  3.11it/s][2025-01-30 01:59:02][root][INFO] - Training Epoch: 1/2, step 1254/107898 completed (loss: 0.5596016645431519, acc: 0.875)
[2025-01-30 01:59:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1256/107898 [06:53<9:05:13,  3.26it/s][2025-01-30 01:59:03][root][INFO] - Training Epoch: 1/2, step 1255/107898 completed (loss: 0.8230646848678589, acc: 1.0)
[2025-01-30 01:59:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1257/107898 [06:53<9:32:34,  3.10it/s][2025-01-30 01:59:03][root][INFO] - Training Epoch: 1/2, step 1256/107898 completed (loss: 1.5793344974517822, acc: 0.75)
[2025-01-30 01:59:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1258/107898 [06:53<9:24:27,  3.15it/s][2025-01-30 01:59:03][root][INFO] - Training Epoch: 1/2, step 1257/107898 completed (loss: 1.588531494140625, acc: 0.6666666865348816)
[2025-01-30 01:59:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1259/107898 [06:54<9:27:37,  3.13it/s][2025-01-30 01:59:04][root][INFO] - Training Epoch: 1/2, step 1258/107898 completed (loss: 0.44748368859291077, acc: 0.9047619104385376)
[2025-01-30 01:59:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1260/107898 [06:54<9:46:05,  3.03it/s][2025-01-30 01:59:04][root][INFO] - Training Epoch: 1/2, step 1259/107898 completed (loss: 1.7832363843917847, acc: 0.5)
[2025-01-30 01:59:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1261/107898 [06:54<9:59:53,  2.96it/s][2025-01-30 01:59:04][root][INFO] - Training Epoch: 1/2, step 1260/107898 completed (loss: 0.2804892063140869, acc: 0.9583333134651184)
[2025-01-30 01:59:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1262/107898 [06:55<9:49:57,  3.01it/s][2025-01-30 01:59:05][root][INFO] - Training Epoch: 1/2, step 1261/107898 completed (loss: 4.276882648468018, acc: 0.2857142984867096)
[2025-01-30 01:59:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1263/107898 [06:55<10:14:12,  2.89it/s][2025-01-30 01:59:05][root][INFO] - Training Epoch: 1/2, step 1262/107898 completed (loss: 0.6916588544845581, acc: 1.0)
[2025-01-30 01:59:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1264/107898 [06:55<10:11:32,  2.91it/s][2025-01-30 01:59:05][root][INFO] - Training Epoch: 1/2, step 1263/107898 completed (loss: 0.01016706321388483, acc: 1.0)
[2025-01-30 01:59:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1265/107898 [06:56<10:48:46,  2.74it/s][2025-01-30 01:59:06][root][INFO] - Training Epoch: 1/2, step 1264/107898 completed (loss: 0.45737820863723755, acc: 0.8823529481887817)
[2025-01-30 01:59:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1266/107898 [06:56<10:09:18,  2.92it/s][2025-01-30 01:59:06][root][INFO] - Training Epoch: 1/2, step 1265/107898 completed (loss: 0.0817953571677208, acc: 1.0)
[2025-01-30 01:59:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1267/107898 [06:56<9:49:40,  3.01it/s] [2025-01-30 01:59:06][root][INFO] - Training Epoch: 1/2, step 1266/107898 completed (loss: 0.7710245847702026, acc: 0.7777777910232544)
[2025-01-30 01:59:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1268/107898 [06:57<9:35:44,  3.09it/s][2025-01-30 01:59:07][root][INFO] - Training Epoch: 1/2, step 1267/107898 completed (loss: 0.887222945690155, acc: 0.75)
[2025-01-30 01:59:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1269/107898 [06:57<9:49:59,  3.01it/s][2025-01-30 01:59:07][root][INFO] - Training Epoch: 1/2, step 1268/107898 completed (loss: 0.4205188751220703, acc: 0.9230769276618958)
[2025-01-30 01:59:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1270/107898 [06:57<9:42:47,  3.05it/s][2025-01-30 01:59:07][root][INFO] - Training Epoch: 1/2, step 1269/107898 completed (loss: 3.7026748657226562, acc: 0.2857142984867096)
[2025-01-30 01:59:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1271/107898 [06:58<9:39:02,  3.07it/s][2025-01-30 01:59:08][root][INFO] - Training Epoch: 1/2, step 1270/107898 completed (loss: 2.910419225692749, acc: 0.3333333432674408)
[2025-01-30 01:59:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1272/107898 [06:58<10:29:09,  2.82it/s][2025-01-30 01:59:08][root][INFO] - Training Epoch: 1/2, step 1271/107898 completed (loss: 1.4281705617904663, acc: 0.761904776096344)
[2025-01-30 01:59:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1273/107898 [06:59<10:32:07,  2.81it/s][2025-01-30 01:59:08][root][INFO] - Training Epoch: 1/2, step 1272/107898 completed (loss: 1.107107400894165, acc: 0.8181818127632141)
[2025-01-30 01:59:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1274/107898 [06:59<10:21:37,  2.86it/s][2025-01-30 01:59:09][root][INFO] - Training Epoch: 1/2, step 1273/107898 completed (loss: 0.8403787612915039, acc: 0.8461538553237915)
[2025-01-30 01:59:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1275/107898 [06:59<9:58:57,  2.97it/s] [2025-01-30 01:59:09][root][INFO] - Training Epoch: 1/2, step 1274/107898 completed (loss: 0.03830142691731453, acc: 1.0)
[2025-01-30 01:59:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1276/107898 [07:00<10:07:29,  2.93it/s][2025-01-30 01:59:09][root][INFO] - Training Epoch: 1/2, step 1275/107898 completed (loss: 0.36728909611701965, acc: 0.9230769276618958)
[2025-01-30 01:59:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1277/107898 [07:00<9:53:44,  2.99it/s] [2025-01-30 01:59:10][root][INFO] - Training Epoch: 1/2, step 1276/107898 completed (loss: 1.6899315118789673, acc: 0.625)
[2025-01-30 01:59:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1278/107898 [07:00<10:16:28,  2.88it/s][2025-01-30 01:59:10][root][INFO] - Training Epoch: 1/2, step 1277/107898 completed (loss: 2.0670619010925293, acc: 0.6896551847457886)
[2025-01-30 01:59:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1279/107898 [07:01<10:11:00,  2.91it/s][2025-01-30 01:59:10][root][INFO] - Training Epoch: 1/2, step 1278/107898 completed (loss: 1.8228662014007568, acc: 0.6190476417541504)
[2025-01-30 01:59:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1280/107898 [07:01<9:54:41,  2.99it/s] [2025-01-30 01:59:11][root][INFO] - Training Epoch: 1/2, step 1279/107898 completed (loss: 1.6199250221252441, acc: 0.6666666865348816)
[2025-01-30 01:59:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1281/107898 [07:01<9:46:18,  3.03it/s][2025-01-30 01:59:11][root][INFO] - Training Epoch: 1/2, step 1280/107898 completed (loss: 2.537815809249878, acc: 0.523809552192688)
[2025-01-30 01:59:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1282/107898 [07:02<10:00:04,  2.96it/s][2025-01-30 01:59:11][root][INFO] - Training Epoch: 1/2, step 1281/107898 completed (loss: 0.5209470391273499, acc: 0.8333333134651184)
[2025-01-30 01:59:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1283/107898 [07:02<10:22:32,  2.85it/s][2025-01-30 01:59:12][root][INFO] - Training Epoch: 1/2, step 1282/107898 completed (loss: 0.13632632791996002, acc: 1.0)
[2025-01-30 01:59:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1284/107898 [07:02<10:19:41,  2.87it/s][2025-01-30 01:59:12][root][INFO] - Training Epoch: 1/2, step 1283/107898 completed (loss: 0.8205626010894775, acc: 0.6666666865348816)
[2025-01-30 01:59:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1285/107898 [07:03<10:01:26,  2.95it/s][2025-01-30 01:59:12][root][INFO] - Training Epoch: 1/2, step 1284/107898 completed (loss: 1.232479453086853, acc: 0.7857142686843872)
[2025-01-30 01:59:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1286/107898 [07:03<9:45:44,  3.03it/s] [2025-01-30 01:59:13][root][INFO] - Training Epoch: 1/2, step 1285/107898 completed (loss: 0.5299063324928284, acc: 1.0)
[2025-01-30 01:59:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1287/107898 [07:03<9:57:06,  2.98it/s][2025-01-30 01:59:13][root][INFO] - Training Epoch: 1/2, step 1286/107898 completed (loss: 1.0540224313735962, acc: 0.8125)
[2025-01-30 01:59:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1288/107898 [07:04<9:45:56,  3.03it/s][2025-01-30 01:59:13][root][INFO] - Training Epoch: 1/2, step 1287/107898 completed (loss: 3.5342864990234375, acc: 0.5)
[2025-01-30 01:59:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1289/107898 [07:04<9:54:30,  2.99it/s][2025-01-30 01:59:14][root][INFO] - Training Epoch: 1/2, step 1288/107898 completed (loss: 0.9572641253471375, acc: 0.8684210777282715)
[2025-01-30 01:59:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1290/107898 [07:04<9:56:52,  2.98it/s][2025-01-30 01:59:14][root][INFO] - Training Epoch: 1/2, step 1289/107898 completed (loss: 0.6705726981163025, acc: 0.8461538553237915)
[2025-01-30 01:59:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1291/107898 [07:05<9:56:43,  2.98it/s][2025-01-30 01:59:14][root][INFO] - Training Epoch: 1/2, step 1290/107898 completed (loss: 0.5983226299285889, acc: 0.9444444179534912)
[2025-01-30 01:59:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1292/107898 [07:05<9:36:18,  3.08it/s][2025-01-30 01:59:15][root][INFO] - Training Epoch: 1/2, step 1291/107898 completed (loss: 1.430433750152588, acc: 0.7222222089767456)
[2025-01-30 01:59:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1293/107898 [07:05<9:41:10,  3.06it/s][2025-01-30 01:59:15][root][INFO] - Training Epoch: 1/2, step 1292/107898 completed (loss: 0.14936193823814392, acc: 1.0)
[2025-01-30 01:59:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1294/107898 [07:06<9:59:33,  2.96it/s][2025-01-30 01:59:15][root][INFO] - Training Epoch: 1/2, step 1293/107898 completed (loss: 0.9962614178657532, acc: 0.8181818127632141)
[2025-01-30 01:59:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1295/107898 [07:06<9:58:59,  2.97it/s][2025-01-30 01:59:16][root][INFO] - Training Epoch: 1/2, step 1294/107898 completed (loss: 1.9240349531173706, acc: 0.6666666865348816)
[2025-01-30 01:59:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1296/107898 [07:06<10:02:57,  2.95it/s][2025-01-30 01:59:16][root][INFO] - Training Epoch: 1/2, step 1295/107898 completed (loss: 5.2988104820251465, acc: 0.1764705926179886)
[2025-01-30 01:59:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1297/107898 [07:07<10:16:48,  2.88it/s][2025-01-30 01:59:16][root][INFO] - Training Epoch: 1/2, step 1296/107898 completed (loss: 2.1853959560394287, acc: 0.6666666865348816)
[2025-01-30 01:59:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1298/107898 [07:07<10:12:14,  2.90it/s][2025-01-30 01:59:17][root][INFO] - Training Epoch: 1/2, step 1297/107898 completed (loss: 3.894477128982544, acc: 0.0)
[2025-01-30 01:59:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1299/107898 [07:07<9:42:50,  3.05it/s] [2025-01-30 01:59:17][root][INFO] - Training Epoch: 1/2, step 1298/107898 completed (loss: 0.16411158442497253, acc: 1.0)
[2025-01-30 01:59:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1300/107898 [07:08<9:32:20,  3.10it/s][2025-01-30 01:59:17][root][INFO] - Training Epoch: 1/2, step 1299/107898 completed (loss: 1.3679277896881104, acc: 0.800000011920929)
[2025-01-30 01:59:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1301/107898 [07:08<9:48:49,  3.02it/s][2025-01-30 01:59:18][root][INFO] - Training Epoch: 1/2, step 1300/107898 completed (loss: 1.7360548973083496, acc: 0.5)
[2025-01-30 01:59:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1302/107898 [07:08<9:34:41,  3.09it/s][2025-01-30 01:59:18][root][INFO] - Training Epoch: 1/2, step 1301/107898 completed (loss: 0.8126690983772278, acc: 0.6666666865348816)
[2025-01-30 01:59:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1303/107898 [07:09<9:13:56,  3.21it/s][2025-01-30 01:59:18][root][INFO] - Training Epoch: 1/2, step 1302/107898 completed (loss: 2.305403470993042, acc: 0.6666666865348816)
[2025-01-30 01:59:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1304/107898 [07:09<9:15:21,  3.20it/s][2025-01-30 01:59:19][root][INFO] - Training Epoch: 1/2, step 1303/107898 completed (loss: 0.33337000012397766, acc: 0.9117646813392639)
[2025-01-30 01:59:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1305/107898 [07:09<9:14:57,  3.20it/s][2025-01-30 01:59:19][root][INFO] - Training Epoch: 1/2, step 1304/107898 completed (loss: 0.5165695548057556, acc: 0.875)
[2025-01-30 01:59:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1306/107898 [07:09<9:00:24,  3.29it/s][2025-01-30 01:59:19][root][INFO] - Training Epoch: 1/2, step 1305/107898 completed (loss: 3.5785014629364014, acc: 0.375)
[2025-01-30 01:59:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1307/107898 [07:10<9:29:00,  3.12it/s][2025-01-30 01:59:20][root][INFO] - Training Epoch: 1/2, step 1306/107898 completed (loss: 0.1287379264831543, acc: 1.0)
[2025-01-30 01:59:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1308/107898 [07:10<9:34:04,  3.09it/s][2025-01-30 01:59:20][root][INFO] - Training Epoch: 1/2, step 1307/107898 completed (loss: 0.9124511480331421, acc: 0.875)
[2025-01-30 01:59:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1309/107898 [07:10<9:26:50,  3.13it/s][2025-01-30 01:59:20][root][INFO] - Training Epoch: 1/2, step 1308/107898 completed (loss: 2.482436418533325, acc: 0.5)
[2025-01-30 01:59:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1310/107898 [07:11<9:21:59,  3.16it/s][2025-01-30 01:59:21][root][INFO] - Training Epoch: 1/2, step 1309/107898 completed (loss: 0.9902830123901367, acc: 0.6666666865348816)
[2025-01-30 01:59:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1311/107898 [07:11<9:19:45,  3.17it/s][2025-01-30 01:59:21][root][INFO] - Training Epoch: 1/2, step 1310/107898 completed (loss: 2.1601009368896484, acc: 0.5833333134651184)
[2025-01-30 01:59:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1312/107898 [07:11<9:05:19,  3.26it/s][2025-01-30 01:59:21][root][INFO] - Training Epoch: 1/2, step 1311/107898 completed (loss: 0.7168368697166443, acc: 1.0)
[2025-01-30 01:59:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1313/107898 [07:12<8:55:59,  3.31it/s][2025-01-30 01:59:21][root][INFO] - Training Epoch: 1/2, step 1312/107898 completed (loss: 2.517357349395752, acc: 0.6000000238418579)
[2025-01-30 01:59:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1314/107898 [07:12<8:58:36,  3.30it/s][2025-01-30 01:59:22][root][INFO] - Training Epoch: 1/2, step 1313/107898 completed (loss: 0.9047385454177856, acc: 0.8571428656578064)
[2025-01-30 01:59:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1315/107898 [07:12<9:27:13,  3.13it/s][2025-01-30 01:59:22][root][INFO] - Training Epoch: 1/2, step 1314/107898 completed (loss: 0.6727083325386047, acc: 0.6666666865348816)
[2025-01-30 01:59:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1316/107898 [07:13<9:38:50,  3.07it/s][2025-01-30 01:59:22][root][INFO] - Training Epoch: 1/2, step 1315/107898 completed (loss: 2.84230637550354, acc: 0.4285714328289032)
[2025-01-30 01:59:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1317/107898 [07:13<10:00:07,  2.96it/s][2025-01-30 01:59:23][root][INFO] - Training Epoch: 1/2, step 1316/107898 completed (loss: 1.8677668571472168, acc: 0.4444444477558136)
[2025-01-30 01:59:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1318/107898 [07:13<9:55:05,  2.98it/s] [2025-01-30 01:59:23][root][INFO] - Training Epoch: 1/2, step 1317/107898 completed (loss: 3.770185708999634, acc: 0.3333333432674408)
[2025-01-30 01:59:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1319/107898 [07:14<9:39:46,  3.06it/s][2025-01-30 01:59:23][root][INFO] - Training Epoch: 1/2, step 1318/107898 completed (loss: 0.16770091652870178, acc: 1.0)
[2025-01-30 01:59:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1320/107898 [07:14<9:27:45,  3.13it/s][2025-01-30 01:59:24][root][INFO] - Training Epoch: 1/2, step 1319/107898 completed (loss: 0.2862819731235504, acc: 1.0)
[2025-01-30 01:59:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1321/107898 [07:14<9:22:03,  3.16it/s][2025-01-30 01:59:24][root][INFO] - Training Epoch: 1/2, step 1320/107898 completed (loss: 1.21049964427948, acc: 0.800000011920929)
[2025-01-30 01:59:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1322/107898 [07:15<9:28:43,  3.12it/s][2025-01-30 01:59:24][root][INFO] - Training Epoch: 1/2, step 1321/107898 completed (loss: 0.8407080173492432, acc: 0.7647058963775635)
[2025-01-30 01:59:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1323/107898 [07:15<9:14:32,  3.20it/s][2025-01-30 01:59:25][root][INFO] - Training Epoch: 1/2, step 1322/107898 completed (loss: 0.11183438450098038, acc: 1.0)
[2025-01-30 01:59:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1324/107898 [07:15<9:41:28,  3.05it/s][2025-01-30 01:59:25][root][INFO] - Training Epoch: 1/2, step 1323/107898 completed (loss: 0.9377053380012512, acc: 0.800000011920929)
[2025-01-30 01:59:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1325/107898 [07:16<9:56:25,  2.98it/s][2025-01-30 01:59:25][root][INFO] - Training Epoch: 1/2, step 1324/107898 completed (loss: 0.7347331047058105, acc: 0.8500000238418579)
[2025-01-30 01:59:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1326/107898 [07:16<10:10:06,  2.91it/s][2025-01-30 01:59:26][root][INFO] - Training Epoch: 1/2, step 1325/107898 completed (loss: 4.166861534118652, acc: 0.0)
[2025-01-30 01:59:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1327/107898 [07:16<10:03:46,  2.94it/s][2025-01-30 01:59:26][root][INFO] - Training Epoch: 1/2, step 1326/107898 completed (loss: 1.179002046585083, acc: 0.692307710647583)
[2025-01-30 01:59:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1328/107898 [07:17<10:01:25,  2.95it/s][2025-01-30 01:59:26][root][INFO] - Training Epoch: 1/2, step 1327/107898 completed (loss: 1.4080007076263428, acc: 0.75)
[2025-01-30 01:59:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1329/107898 [07:17<9:41:22,  3.06it/s] [2025-01-30 01:59:27][root][INFO] - Training Epoch: 1/2, step 1328/107898 completed (loss: 0.895552933216095, acc: 0.8333333134651184)
[2025-01-30 01:59:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1330/107898 [07:17<9:26:35,  3.13it/s][2025-01-30 01:59:27][root][INFO] - Training Epoch: 1/2, step 1329/107898 completed (loss: 1.2149335145950317, acc: 0.7368420958518982)
[2025-01-30 01:59:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1331/107898 [07:18<9:37:13,  3.08it/s][2025-01-30 01:59:27][root][INFO] - Training Epoch: 1/2, step 1330/107898 completed (loss: 1.3264590501785278, acc: 0.5)
[2025-01-30 01:59:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1332/107898 [07:18<9:27:41,  3.13it/s][2025-01-30 01:59:28][root][INFO] - Training Epoch: 1/2, step 1331/107898 completed (loss: 0.4985560476779938, acc: 0.8999999761581421)
[2025-01-30 01:59:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1333/107898 [07:18<9:15:24,  3.20it/s][2025-01-30 01:59:28][root][INFO] - Training Epoch: 1/2, step 1332/107898 completed (loss: 3.147444725036621, acc: 0.5)
[2025-01-30 01:59:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1334/107898 [07:18<9:10:54,  3.22it/s][2025-01-30 01:59:28][root][INFO] - Training Epoch: 1/2, step 1333/107898 completed (loss: 1.4832491874694824, acc: 0.7083333134651184)
[2025-01-30 01:59:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1335/107898 [07:19<9:05:48,  3.25it/s][2025-01-30 01:59:29][root][INFO] - Training Epoch: 1/2, step 1334/107898 completed (loss: 1.1123477220535278, acc: 0.7142857313156128)
[2025-01-30 01:59:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1336/107898 [07:19<9:35:42,  3.08it/s][2025-01-30 01:59:29][root][INFO] - Training Epoch: 1/2, step 1335/107898 completed (loss: 0.7546900510787964, acc: 0.7692307829856873)
[2025-01-30 01:59:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1337/107898 [07:19<9:46:44,  3.03it/s][2025-01-30 01:59:29][root][INFO] - Training Epoch: 1/2, step 1336/107898 completed (loss: 0.28494104743003845, acc: 0.931034505367279)
[2025-01-30 01:59:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1338/107898 [07:20<9:34:39,  3.09it/s][2025-01-30 01:59:30][root][INFO] - Training Epoch: 1/2, step 1337/107898 completed (loss: 1.2292959690093994, acc: 0.5)
[2025-01-30 01:59:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1339/107898 [07:20<9:23:27,  3.15it/s][2025-01-30 01:59:30][root][INFO] - Training Epoch: 1/2, step 1338/107898 completed (loss: 3.8033413887023926, acc: 0.4285714328289032)
[2025-01-30 01:59:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1340/107898 [07:20<9:27:15,  3.13it/s][2025-01-30 01:59:30][root][INFO] - Training Epoch: 1/2, step 1339/107898 completed (loss: 1.9899511337280273, acc: 0.695652186870575)
[2025-01-30 01:59:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1341/107898 [07:21<9:41:26,  3.05it/s][2025-01-30 01:59:31][root][INFO] - Training Epoch: 1/2, step 1340/107898 completed (loss: 1.2989033460617065, acc: 0.7142857313156128)
[2025-01-30 01:59:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1342/107898 [07:21<9:31:46,  3.11it/s][2025-01-30 01:59:31][root][INFO] - Training Epoch: 1/2, step 1341/107898 completed (loss: 2.063361406326294, acc: 0.5789473652839661)
[2025-01-30 01:59:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1343/107898 [07:21<9:23:52,  3.15it/s][2025-01-30 01:59:31][root][INFO] - Training Epoch: 1/2, step 1342/107898 completed (loss: 0.1435408890247345, acc: 1.0)
[2025-01-30 01:59:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1344/107898 [07:22<9:07:24,  3.24it/s][2025-01-30 01:59:31][root][INFO] - Training Epoch: 1/2, step 1343/107898 completed (loss: 1.3153676986694336, acc: 0.75)
[2025-01-30 01:59:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1345/107898 [07:22<8:40:43,  3.41it/s][2025-01-30 01:59:32][root][INFO] - Training Epoch: 1/2, step 1344/107898 completed (loss: 1.921851396560669, acc: 0.75)
[2025-01-30 01:59:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1346/107898 [07:22<8:39:54,  3.42it/s][2025-01-30 01:59:32][root][INFO] - Training Epoch: 1/2, step 1345/107898 completed (loss: 0.07420088350772858, acc: 1.0)
[2025-01-30 01:59:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1347/107898 [07:23<9:08:25,  3.24it/s][2025-01-30 01:59:32][root][INFO] - Training Epoch: 1/2, step 1346/107898 completed (loss: 2.2077436447143555, acc: 0.5454545617103577)
[2025-01-30 01:59:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34m          [0m| 1348/107898 [07:23<9:08:59,  3.23it/s][2025-01-30 01:59:33][root][INFO] - Training Epoch: 1/2, step 1347/107898 completed (loss: 1.5597838163375854, acc: 0.5)
[2025-01-30 01:59:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1349/107898 [07:23<9:01:19,  3.28it/s][2025-01-30 01:59:33][root][INFO] - Training Epoch: 1/2, step 1348/107898 completed (loss: 0.5326675176620483, acc: 1.0)
[2025-01-30 01:59:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1350/107898 [07:24<9:31:29,  3.11it/s][2025-01-30 01:59:33][root][INFO] - Training Epoch: 1/2, step 1349/107898 completed (loss: 0.30471011996269226, acc: 0.9166666865348816)
[2025-01-30 01:59:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1351/107898 [07:24<9:41:46,  3.05it/s][2025-01-30 01:59:34][root][INFO] - Training Epoch: 1/2, step 1350/107898 completed (loss: 1.7125600576400757, acc: 0.699999988079071)
[2025-01-30 01:59:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1352/107898 [07:24<9:49:28,  3.01it/s][2025-01-30 01:59:34][root][INFO] - Training Epoch: 1/2, step 1351/107898 completed (loss: 3.1749823093414307, acc: 0.2857142984867096)
[2025-01-30 01:59:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1353/107898 [07:25<9:31:11,  3.11it/s][2025-01-30 01:59:34][root][INFO] - Training Epoch: 1/2, step 1352/107898 completed (loss: 0.5382579565048218, acc: 0.8999999761581421)
[2025-01-30 01:59:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1354/107898 [07:25<9:32:16,  3.10it/s][2025-01-30 01:59:35][root][INFO] - Training Epoch: 1/2, step 1353/107898 completed (loss: 1.0872223377227783, acc: 0.75)
[2025-01-30 01:59:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1355/107898 [07:25<9:38:44,  3.07it/s][2025-01-30 01:59:35][root][INFO] - Training Epoch: 1/2, step 1354/107898 completed (loss: 0.1282915621995926, acc: 1.0)
[2025-01-30 01:59:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1356/107898 [07:26<10:01:37,  2.95it/s][2025-01-30 01:59:35][root][INFO] - Training Epoch: 1/2, step 1355/107898 completed (loss: 0.3707873523235321, acc: 0.9285714030265808)
[2025-01-30 01:59:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1357/107898 [07:26<9:56:13,  2.98it/s] [2025-01-30 01:59:36][root][INFO] - Training Epoch: 1/2, step 1356/107898 completed (loss: 1.3486812114715576, acc: 0.7058823704719543)
[2025-01-30 01:59:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1358/107898 [07:26<9:40:27,  3.06it/s][2025-01-30 01:59:36][root][INFO] - Training Epoch: 1/2, step 1357/107898 completed (loss: 1.6249008178710938, acc: 0.6666666865348816)
[2025-01-30 01:59:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1359/107898 [07:26<9:26:44,  3.13it/s][2025-01-30 01:59:36][root][INFO] - Training Epoch: 1/2, step 1358/107898 completed (loss: 2.546455144882202, acc: 0.7272727489471436)
[2025-01-30 01:59:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1360/107898 [07:27<9:34:45,  3.09it/s][2025-01-30 01:59:37][root][INFO] - Training Epoch: 1/2, step 1359/107898 completed (loss: 1.0146875381469727, acc: 0.7599999904632568)
[2025-01-30 01:59:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1361/107898 [07:27<9:42:11,  3.05it/s][2025-01-30 01:59:37][root][INFO] - Training Epoch: 1/2, step 1360/107898 completed (loss: 0.09663480520248413, acc: 1.0)
[2025-01-30 01:59:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1362/107898 [07:28<9:59:45,  2.96it/s][2025-01-30 01:59:37][root][INFO] - Training Epoch: 1/2, step 1361/107898 completed (loss: 1.7528080940246582, acc: 0.7058823704719543)
[2025-01-30 01:59:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1363/107898 [07:28<10:08:33,  2.92it/s][2025-01-30 01:59:38][root][INFO] - Training Epoch: 1/2, step 1362/107898 completed (loss: 1.0990808010101318, acc: 0.8461538553237915)
[2025-01-30 01:59:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1364/107898 [07:28<10:13:02,  2.90it/s][2025-01-30 01:59:38][root][INFO] - Training Epoch: 1/2, step 1363/107898 completed (loss: 1.3832770586013794, acc: 0.5555555820465088)
[2025-01-30 01:59:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1365/107898 [07:29<10:08:18,  2.92it/s][2025-01-30 01:59:38][root][INFO] - Training Epoch: 1/2, step 1364/107898 completed (loss: 1.6869844198226929, acc: 0.75)
[2025-01-30 01:59:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1366/107898 [07:29<10:15:57,  2.88it/s][2025-01-30 01:59:39][root][INFO] - Training Epoch: 1/2, step 1365/107898 completed (loss: 0.7415701746940613, acc: 0.8235294222831726)
[2025-01-30 01:59:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1367/107898 [07:29<10:09:56,  2.91it/s][2025-01-30 01:59:39][root][INFO] - Training Epoch: 1/2, step 1366/107898 completed (loss: 0.014042017981410027, acc: 1.0)
[2025-01-30 01:59:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1368/107898 [07:30<10:09:36,  2.91it/s][2025-01-30 01:59:39][root][INFO] - Training Epoch: 1/2, step 1367/107898 completed (loss: 1.8333308696746826, acc: 0.5)
[2025-01-30 01:59:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1369/107898 [07:30<9:56:03,  2.98it/s] [2025-01-30 01:59:40][root][INFO] - Training Epoch: 1/2, step 1368/107898 completed (loss: 4.470879077911377, acc: 0.1818181872367859)
[2025-01-30 01:59:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1370/107898 [07:30<9:31:24,  3.11it/s][2025-01-30 01:59:40][root][INFO] - Training Epoch: 1/2, step 1369/107898 completed (loss: 0.06992386281490326, acc: 1.0)
[2025-01-30 01:59:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1371/107898 [07:30<9:21:11,  3.16it/s][2025-01-30 01:59:40][root][INFO] - Training Epoch: 1/2, step 1370/107898 completed (loss: 4.664425373077393, acc: 0.25)
[2025-01-30 01:59:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1372/107898 [07:31<9:04:17,  3.26it/s][2025-01-30 01:59:41][root][INFO] - Training Epoch: 1/2, step 1371/107898 completed (loss: 0.8593623638153076, acc: 0.3333333432674408)
[2025-01-30 01:59:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1373/107898 [07:31<9:00:34,  3.28it/s][2025-01-30 01:59:41][root][INFO] - Training Epoch: 1/2, step 1372/107898 completed (loss: 0.5836820602416992, acc: 0.5)
[2025-01-30 01:59:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1374/107898 [07:31<8:57:10,  3.31it/s][2025-01-30 01:59:41][root][INFO] - Training Epoch: 1/2, step 1373/107898 completed (loss: 1.5271711349487305, acc: 0.6666666865348816)
[2025-01-30 01:59:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1375/107898 [07:32<9:26:49,  3.13it/s][2025-01-30 01:59:42][root][INFO] - Training Epoch: 1/2, step 1374/107898 completed (loss: 3.0445477962493896, acc: 0.2857142984867096)
[2025-01-30 01:59:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1376/107898 [07:32<9:27:08,  3.13it/s][2025-01-30 01:59:42][root][INFO] - Training Epoch: 1/2, step 1375/107898 completed (loss: 2.6288692951202393, acc: 0.5555555820465088)
[2025-01-30 01:59:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1377/107898 [07:32<9:46:39,  3.03it/s][2025-01-30 01:59:42][root][INFO] - Training Epoch: 1/2, step 1376/107898 completed (loss: 1.8729184865951538, acc: 0.5)
[2025-01-30 01:59:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1378/107898 [07:33<9:47:49,  3.02it/s][2025-01-30 01:59:43][root][INFO] - Training Epoch: 1/2, step 1377/107898 completed (loss: 0.20432113111019135, acc: 1.0)
[2025-01-30 01:59:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1379/107898 [07:33<9:37:49,  3.07it/s][2025-01-30 01:59:43][root][INFO] - Training Epoch: 1/2, step 1378/107898 completed (loss: 1.7773633003234863, acc: 0.5384615659713745)
[2025-01-30 01:59:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1380/107898 [07:33<9:38:02,  3.07it/s][2025-01-30 01:59:43][root][INFO] - Training Epoch: 1/2, step 1379/107898 completed (loss: 1.822941541671753, acc: 0.875)
[2025-01-30 01:59:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1381/107898 [07:34<9:24:07,  3.15it/s][2025-01-30 01:59:43][root][INFO] - Training Epoch: 1/2, step 1380/107898 completed (loss: 0.6042311787605286, acc: 1.0)
[2025-01-30 01:59:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1382/107898 [07:34<9:20:59,  3.16it/s][2025-01-30 01:59:44][root][INFO] - Training Epoch: 1/2, step 1381/107898 completed (loss: 0.204231858253479, acc: 1.0)
[2025-01-30 01:59:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1383/107898 [07:34<9:17:02,  3.19it/s][2025-01-30 01:59:44][root][INFO] - Training Epoch: 1/2, step 1382/107898 completed (loss: 1.4793715476989746, acc: 0.8181818127632141)
[2025-01-30 01:59:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1384/107898 [07:35<9:36:17,  3.08it/s][2025-01-30 01:59:44][root][INFO] - Training Epoch: 1/2, step 1383/107898 completed (loss: 3.6910812854766846, acc: 0.3333333432674408)
[2025-01-30 01:59:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1385/107898 [07:35<9:41:28,  3.05it/s][2025-01-30 01:59:45][root][INFO] - Training Epoch: 1/2, step 1384/107898 completed (loss: 3.2225310802459717, acc: 0.4000000059604645)
[2025-01-30 01:59:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1386/107898 [07:35<9:47:49,  3.02it/s][2025-01-30 01:59:45][root][INFO] - Training Epoch: 1/2, step 1385/107898 completed (loss: 0.3151491582393646, acc: 1.0)
[2025-01-30 01:59:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1387/107898 [07:36<9:44:06,  3.04it/s][2025-01-30 01:59:45][root][INFO] - Training Epoch: 1/2, step 1386/107898 completed (loss: 2.4434549808502197, acc: 0.800000011920929)
[2025-01-30 01:59:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1388/107898 [07:36<9:29:39,  3.12it/s][2025-01-30 01:59:46][root][INFO] - Training Epoch: 1/2, step 1387/107898 completed (loss: 1.0893027782440186, acc: 0.6666666865348816)
[2025-01-30 01:59:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1389/107898 [07:36<9:38:56,  3.07it/s][2025-01-30 01:59:46][root][INFO] - Training Epoch: 1/2, step 1388/107898 completed (loss: 1.1023677587509155, acc: 0.8108108043670654)
[2025-01-30 01:59:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1390/107898 [07:37<9:44:01,  3.04it/s][2025-01-30 01:59:46][root][INFO] - Training Epoch: 1/2, step 1389/107898 completed (loss: 0.4698297381401062, acc: 0.75)
[2025-01-30 01:59:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1391/107898 [07:37<9:35:41,  3.08it/s][2025-01-30 01:59:47][root][INFO] - Training Epoch: 1/2, step 1390/107898 completed (loss: 0.010287276469171047, acc: 1.0)
[2025-01-30 01:59:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1392/107898 [07:37<9:31:24,  3.11it/s][2025-01-30 01:59:47][root][INFO] - Training Epoch: 1/2, step 1391/107898 completed (loss: 0.26704922318458557, acc: 1.0)
[2025-01-30 01:59:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1393/107898 [07:38<9:48:41,  3.02it/s][2025-01-30 01:59:47][root][INFO] - Training Epoch: 1/2, step 1392/107898 completed (loss: 0.5185065865516663, acc: 0.9230769276618958)
[2025-01-30 01:59:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1394/107898 [07:38<9:44:39,  3.04it/s][2025-01-30 01:59:48][root][INFO] - Training Epoch: 1/2, step 1393/107898 completed (loss: 0.6984445452690125, acc: 0.8571428656578064)
[2025-01-30 01:59:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1395/107898 [07:38<9:39:37,  3.06it/s][2025-01-30 01:59:48][root][INFO] - Training Epoch: 1/2, step 1394/107898 completed (loss: 0.005530056077986956, acc: 1.0)
[2025-01-30 01:59:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1396/107898 [07:39<9:45:09,  3.03it/s][2025-01-30 01:59:48][root][INFO] - Training Epoch: 1/2, step 1395/107898 completed (loss: 0.5809950232505798, acc: 0.8571428656578064)
[2025-01-30 01:59:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1397/107898 [07:39<9:37:55,  3.07it/s][2025-01-30 01:59:49][root][INFO] - Training Epoch: 1/2, step 1396/107898 completed (loss: 0.7941874265670776, acc: 0.8333333134651184)
[2025-01-30 01:59:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1398/107898 [07:39<9:27:19,  3.13it/s][2025-01-30 01:59:49][root][INFO] - Training Epoch: 1/2, step 1397/107898 completed (loss: 1.9011467695236206, acc: 0.625)
[2025-01-30 01:59:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1399/107898 [07:40<9:42:39,  3.05it/s][2025-01-30 01:59:49][root][INFO] - Training Epoch: 1/2, step 1398/107898 completed (loss: 0.006452376954257488, acc: 1.0)
[2025-01-30 01:59:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1400/107898 [07:40<9:53:34,  2.99it/s][2025-01-30 01:59:50][root][INFO] - Training Epoch: 1/2, step 1399/107898 completed (loss: 3.1110689640045166, acc: 0.375)
[2025-01-30 01:59:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1401/107898 [07:40<9:51:02,  3.00it/s][2025-01-30 01:59:50][root][INFO] - Training Epoch: 1/2, step 1400/107898 completed (loss: 1.546817421913147, acc: 0.7083333134651184)
[2025-01-30 01:59:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1402/107898 [07:41<9:21:16,  3.16it/s][2025-01-30 01:59:50][root][INFO] - Training Epoch: 1/2, step 1401/107898 completed (loss: 1.0459662675857544, acc: 0.5)
[2025-01-30 01:59:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1403/107898 [07:41<9:11:09,  3.22it/s][2025-01-30 01:59:51][root][INFO] - Training Epoch: 1/2, step 1402/107898 completed (loss: 1.3635362386703491, acc: 0.8333333134651184)
[2025-01-30 01:59:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1404/107898 [07:41<9:33:48,  3.09it/s][2025-01-30 01:59:51][root][INFO] - Training Epoch: 1/2, step 1403/107898 completed (loss: 2.748687505722046, acc: 0.4444444477558136)
[2025-01-30 01:59:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1405/107898 [07:42<9:46:46,  3.02it/s][2025-01-30 01:59:51][root][INFO] - Training Epoch: 1/2, step 1404/107898 completed (loss: 4.387930393218994, acc: 0.31578946113586426)
[2025-01-30 01:59:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1406/107898 [07:42<9:49:51,  3.01it/s][2025-01-30 01:59:52][root][INFO] - Training Epoch: 1/2, step 1405/107898 completed (loss: 0.9672259092330933, acc: 0.7777777910232544)
[2025-01-30 01:59:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1407/107898 [07:42<9:49:00,  3.01it/s][2025-01-30 01:59:52][root][INFO] - Training Epoch: 1/2, step 1406/107898 completed (loss: 1.1734578609466553, acc: 0.6666666865348816)
[2025-01-30 01:59:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1408/107898 [07:42<9:31:06,  3.11it/s][2025-01-30 01:59:52][root][INFO] - Training Epoch: 1/2, step 1407/107898 completed (loss: 0.582725465297699, acc: 0.875)
[2025-01-30 01:59:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1409/107898 [07:43<9:49:15,  3.01it/s][2025-01-30 01:59:53][root][INFO] - Training Epoch: 1/2, step 1408/107898 completed (loss: 2.037449359893799, acc: 0.6086956262588501)
[2025-01-30 01:59:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1410/107898 [07:43<9:45:08,  3.03it/s][2025-01-30 01:59:53][root][INFO] - Training Epoch: 1/2, step 1409/107898 completed (loss: 0.5762054920196533, acc: 0.8947368264198303)
[2025-01-30 01:59:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1411/107898 [07:43<9:29:25,  3.12it/s][2025-01-30 01:59:53][root][INFO] - Training Epoch: 1/2, step 1410/107898 completed (loss: 0.01645035482943058, acc: 1.0)
[2025-01-30 01:59:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1412/107898 [07:44<9:50:25,  3.01it/s][2025-01-30 01:59:54][root][INFO] - Training Epoch: 1/2, step 1411/107898 completed (loss: 1.167488694190979, acc: 0.7083333134651184)
[2025-01-30 01:59:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1413/107898 [07:44<9:50:52,  3.00it/s][2025-01-30 01:59:54][root][INFO] - Training Epoch: 1/2, step 1412/107898 completed (loss: 0.4928992986679077, acc: 0.8421052694320679)
[2025-01-30 01:59:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1414/107898 [07:44<9:55:14,  2.98it/s][2025-01-30 01:59:54][root][INFO] - Training Epoch: 1/2, step 1413/107898 completed (loss: 0.012451195158064365, acc: 1.0)
[2025-01-30 01:59:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1415/107898 [07:45<10:01:05,  2.95it/s][2025-01-30 01:59:55][root][INFO] - Training Epoch: 1/2, step 1414/107898 completed (loss: 2.0731422901153564, acc: 0.4444444477558136)
[2025-01-30 01:59:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1416/107898 [07:45<10:06:02,  2.93it/s][2025-01-30 01:59:55][root][INFO] - Training Epoch: 1/2, step 1415/107898 completed (loss: 1.0032448768615723, acc: 0.8666666746139526)
[2025-01-30 01:59:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1417/107898 [07:46<9:53:01,  2.99it/s] [2025-01-30 01:59:55][root][INFO] - Training Epoch: 1/2, step 1416/107898 completed (loss: 4.77066707611084, acc: 0.23529411852359772)
[2025-01-30 01:59:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1418/107898 [07:46<9:50:17,  3.01it/s][2025-01-30 01:59:56][root][INFO] - Training Epoch: 1/2, step 1417/107898 completed (loss: 2.1440377235412598, acc: 0.5714285969734192)
[2025-01-30 01:59:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1419/107898 [07:46<9:50:48,  3.00it/s][2025-01-30 01:59:56][root][INFO] - Training Epoch: 1/2, step 1418/107898 completed (loss: 1.8565750122070312, acc: 0.699999988079071)
[2025-01-30 01:59:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1420/107898 [07:46<9:49:28,  3.01it/s][2025-01-30 01:59:56][root][INFO] - Training Epoch: 1/2, step 1419/107898 completed (loss: 1.5248918533325195, acc: 0.6521739363670349)
[2025-01-30 01:59:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1421/107898 [07:47<10:07:09,  2.92it/s][2025-01-30 01:59:57][root][INFO] - Training Epoch: 1/2, step 1420/107898 completed (loss: 4.732419490814209, acc: 0.3333333432674408)
[2025-01-30 01:59:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1422/107898 [07:47<9:57:19,  2.97it/s] [2025-01-30 01:59:57][root][INFO] - Training Epoch: 1/2, step 1421/107898 completed (loss: 1.6623033285140991, acc: 0.7857142686843872)
[2025-01-30 01:59:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1423/107898 [07:47<9:43:16,  3.04it/s][2025-01-30 01:59:57][root][INFO] - Training Epoch: 1/2, step 1422/107898 completed (loss: 0.39655184745788574, acc: 1.0)
[2025-01-30 01:59:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1424/107898 [07:48<9:38:19,  3.07it/s][2025-01-30 01:59:58][root][INFO] - Training Epoch: 1/2, step 1423/107898 completed (loss: 0.2780010998249054, acc: 0.9166666865348816)
[2025-01-30 01:59:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1425/107898 [07:48<9:50:46,  3.00it/s][2025-01-30 01:59:58][root][INFO] - Training Epoch: 1/2, step 1424/107898 completed (loss: 1.8423395156860352, acc: 0.3333333432674408)
[2025-01-30 01:59:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1426/107898 [07:49<10:09:28,  2.91it/s][2025-01-30 01:59:58][root][INFO] - Training Epoch: 1/2, step 1425/107898 completed (loss: 2.0348060131073, acc: 0.5833333134651184)
[2025-01-30 01:59:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1427/107898 [07:49<10:07:26,  2.92it/s][2025-01-30 01:59:59][root][INFO] - Training Epoch: 1/2, step 1426/107898 completed (loss: 2.8861303329467773, acc: 0.3333333432674408)
[2025-01-30 01:59:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1428/107898 [07:49<10:19:16,  2.87it/s][2025-01-30 01:59:59][root][INFO] - Training Epoch: 1/2, step 1427/107898 completed (loss: 1.2369277477264404, acc: 0.800000011920929)
[2025-01-30 01:59:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1429/107898 [07:50<10:09:28,  2.91it/s][2025-01-30 01:59:59][root][INFO] - Training Epoch: 1/2, step 1428/107898 completed (loss: 0.2277788668870926, acc: 1.0)
[2025-01-30 01:59:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1430/107898 [07:50<10:19:22,  2.86it/s][2025-01-30 02:00:00][root][INFO] - Training Epoch: 1/2, step 1429/107898 completed (loss: 0.9586595892906189, acc: 0.0)
[2025-01-30 02:00:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1431/107898 [07:50<10:08:05,  2.92it/s][2025-01-30 02:00:00][root][INFO] - Training Epoch: 1/2, step 1430/107898 completed (loss: 0.1218724399805069, acc: 1.0)
[2025-01-30 02:00:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1432/107898 [07:51<10:01:56,  2.95it/s][2025-01-30 02:00:00][root][INFO] - Training Epoch: 1/2, step 1431/107898 completed (loss: 0.90737384557724, acc: 0.5)
[2025-01-30 02:00:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1433/107898 [07:51<9:53:39,  2.99it/s] [2025-01-30 02:00:01][root][INFO] - Training Epoch: 1/2, step 1432/107898 completed (loss: 3.531581401824951, acc: 0.23076923191547394)
[2025-01-30 02:00:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1434/107898 [07:51<9:49:13,  3.01it/s][2025-01-30 02:00:01][root][INFO] - Training Epoch: 1/2, step 1433/107898 completed (loss: 1.2805585861206055, acc: 0.7368420958518982)
[2025-01-30 02:00:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1435/107898 [07:52<10:09:07,  2.91it/s][2025-01-30 02:00:01][root][INFO] - Training Epoch: 1/2, step 1434/107898 completed (loss: 0.9348980784416199, acc: 0.7857142686843872)
[2025-01-30 02:00:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1436/107898 [07:52<10:19:41,  2.86it/s][2025-01-30 02:00:02][root][INFO] - Training Epoch: 1/2, step 1435/107898 completed (loss: 0.10127909481525421, acc: 1.0)
[2025-01-30 02:00:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1437/107898 [07:52<10:03:05,  2.94it/s][2025-01-30 02:00:02][root][INFO] - Training Epoch: 1/2, step 1436/107898 completed (loss: 0.9684212803840637, acc: 0.8888888955116272)
[2025-01-30 02:00:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1438/107898 [07:53<9:54:21,  2.99it/s] [2025-01-30 02:00:02][root][INFO] - Training Epoch: 1/2, step 1437/107898 completed (loss: 0.7675521373748779, acc: 0.800000011920929)
[2025-01-30 02:00:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1439/107898 [07:53<10:07:55,  2.92it/s][2025-01-30 02:00:03][root][INFO] - Training Epoch: 1/2, step 1438/107898 completed (loss: 2.869882822036743, acc: 0.25)
[2025-01-30 02:00:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1440/107898 [07:53<10:04:01,  2.94it/s][2025-01-30 02:00:03][root][INFO] - Training Epoch: 1/2, step 1439/107898 completed (loss: 0.2535002827644348, acc: 0.8947368264198303)
[2025-01-30 02:00:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1441/107898 [07:54<9:39:35,  3.06it/s] [2025-01-30 02:00:03][root][INFO] - Training Epoch: 1/2, step 1440/107898 completed (loss: 1.2134034633636475, acc: 0.75)
[2025-01-30 02:00:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1442/107898 [07:54<9:24:26,  3.14it/s][2025-01-30 02:00:04][root][INFO] - Training Epoch: 1/2, step 1441/107898 completed (loss: 0.10109368711709976, acc: 1.0)
[2025-01-30 02:00:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1443/107898 [07:54<9:16:11,  3.19it/s][2025-01-30 02:00:04][root][INFO] - Training Epoch: 1/2, step 1442/107898 completed (loss: 0.8296836018562317, acc: 0.8823529481887817)
[2025-01-30 02:00:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1444/107898 [07:55<9:12:47,  3.21it/s][2025-01-30 02:00:04][root][INFO] - Training Epoch: 1/2, step 1443/107898 completed (loss: 0.10757221281528473, acc: 1.0)
[2025-01-30 02:00:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1445/107898 [07:55<9:07:22,  3.24it/s][2025-01-30 02:00:05][root][INFO] - Training Epoch: 1/2, step 1444/107898 completed (loss: 0.2801345884799957, acc: 0.95652174949646)
[2025-01-30 02:00:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1446/107898 [07:55<9:10:18,  3.22it/s][2025-01-30 02:00:05][root][INFO] - Training Epoch: 1/2, step 1445/107898 completed (loss: 1.8179491758346558, acc: 0.6774193644523621)
[2025-01-30 02:00:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1447/107898 [07:55<9:25:57,  3.13it/s][2025-01-30 02:00:05][root][INFO] - Training Epoch: 1/2, step 1446/107898 completed (loss: 0.6105877161026001, acc: 0.8787878751754761)
[2025-01-30 02:00:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1448/107898 [07:56<9:25:58,  3.13it/s][2025-01-30 02:00:06][root][INFO] - Training Epoch: 1/2, step 1447/107898 completed (loss: 0.6686937808990479, acc: 0.7777777910232544)
[2025-01-30 02:00:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1449/107898 [07:56<9:34:47,  3.09it/s][2025-01-30 02:00:06][root][INFO] - Training Epoch: 1/2, step 1448/107898 completed (loss: 2.9995901584625244, acc: 0.5)
[2025-01-30 02:00:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1450/107898 [07:56<9:32:26,  3.10it/s][2025-01-30 02:00:06][root][INFO] - Training Epoch: 1/2, step 1449/107898 completed (loss: 0.7152831554412842, acc: 0.6666666865348816)
[2025-01-30 02:00:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1451/107898 [07:57<9:52:36,  2.99it/s][2025-01-30 02:00:07][root][INFO] - Training Epoch: 1/2, step 1450/107898 completed (loss: 1.238797903060913, acc: 0.7333333492279053)
[2025-01-30 02:00:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1452/107898 [07:57<9:44:37,  3.03it/s][2025-01-30 02:00:07][root][INFO] - Training Epoch: 1/2, step 1451/107898 completed (loss: 1.064476490020752, acc: 0.800000011920929)
[2025-01-30 02:00:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1453/107898 [07:57<9:39:06,  3.06it/s][2025-01-30 02:00:07][root][INFO] - Training Epoch: 1/2, step 1452/107898 completed (loss: 0.35585179924964905, acc: 1.0)
[2025-01-30 02:00:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1454/107898 [07:58<9:55:48,  2.98it/s][2025-01-30 02:00:08][root][INFO] - Training Epoch: 1/2, step 1453/107898 completed (loss: 2.6481094360351562, acc: 0.20000000298023224)
[2025-01-30 02:00:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1455/107898 [07:58<10:02:49,  2.94it/s][2025-01-30 02:00:08][root][INFO] - Training Epoch: 1/2, step 1454/107898 completed (loss: 0.48252391815185547, acc: 0.800000011920929)
[2025-01-30 02:00:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1456/107898 [07:59<10:34:47,  2.79it/s][2025-01-30 02:00:08][root][INFO] - Training Epoch: 1/2, step 1455/107898 completed (loss: 1.5290629863739014, acc: 0.6111111044883728)
[2025-01-30 02:00:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1457/107898 [07:59<10:39:59,  2.77it/s][2025-01-30 02:00:09][root][INFO] - Training Epoch: 1/2, step 1456/107898 completed (loss: 3.2926409244537354, acc: 0.3529411852359772)
[2025-01-30 02:00:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1458/107898 [07:59<10:34:54,  2.79it/s][2025-01-30 02:00:09][root][INFO] - Training Epoch: 1/2, step 1457/107898 completed (loss: 0.587471604347229, acc: 0.8799999952316284)
[2025-01-30 02:00:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1459/107898 [08:00<10:17:51,  2.87it/s][2025-01-30 02:00:09][root][INFO] - Training Epoch: 1/2, step 1458/107898 completed (loss: 1.980948567390442, acc: 0.7333333492279053)
[2025-01-30 02:00:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1460/107898 [08:00<9:56:45,  2.97it/s] [2025-01-30 02:00:10][root][INFO] - Training Epoch: 1/2, step 1459/107898 completed (loss: 0.2876882255077362, acc: 0.9583333134651184)
[2025-01-30 02:00:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1461/107898 [08:00<9:33:36,  3.09it/s][2025-01-30 02:00:10][root][INFO] - Training Epoch: 1/2, step 1460/107898 completed (loss: 3.024122714996338, acc: 0.5263158082962036)
[2025-01-30 02:00:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1462/107898 [08:01<9:48:43,  3.01it/s][2025-01-30 02:00:10][root][INFO] - Training Epoch: 1/2, step 1461/107898 completed (loss: 0.9427724480628967, acc: 0.7857142686843872)
[2025-01-30 02:00:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1463/107898 [08:01<9:51:27,  3.00it/s][2025-01-30 02:00:11][root][INFO] - Training Epoch: 1/2, step 1462/107898 completed (loss: 1.3809175491333008, acc: 0.6000000238418579)
[2025-01-30 02:00:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1464/107898 [08:01<9:48:28,  3.01it/s][2025-01-30 02:00:11][root][INFO] - Training Epoch: 1/2, step 1463/107898 completed (loss: 1.2632055282592773, acc: 0.8095238208770752)
[2025-01-30 02:00:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1465/107898 [08:02<9:58:16,  2.97it/s][2025-01-30 02:00:11][root][INFO] - Training Epoch: 1/2, step 1464/107898 completed (loss: 0.8789138197898865, acc: 1.0)
[2025-01-30 02:00:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1466/107898 [08:02<9:42:58,  3.04it/s][2025-01-30 02:00:12][root][INFO] - Training Epoch: 1/2, step 1465/107898 completed (loss: 1.3425209522247314, acc: 0.7142857313156128)
[2025-01-30 02:00:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1467/107898 [08:02<9:56:58,  2.97it/s][2025-01-30 02:00:12][root][INFO] - Training Epoch: 1/2, step 1466/107898 completed (loss: 3.660587787628174, acc: 0.5)
[2025-01-30 02:00:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1468/107898 [08:03<9:49:11,  3.01it/s][2025-01-30 02:00:12][root][INFO] - Training Epoch: 1/2, step 1467/107898 completed (loss: 1.9775441884994507, acc: 0.4285714328289032)
[2025-01-30 02:00:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1469/107898 [08:03<9:42:42,  3.04it/s][2025-01-30 02:00:13][root][INFO] - Training Epoch: 1/2, step 1468/107898 completed (loss: 2.6994826793670654, acc: 0.3571428656578064)
[2025-01-30 02:00:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1470/107898 [08:03<9:27:09,  3.13it/s][2025-01-30 02:00:13][root][INFO] - Training Epoch: 1/2, step 1469/107898 completed (loss: 0.09870713949203491, acc: 1.0)
[2025-01-30 02:00:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1471/107898 [08:03<9:19:38,  3.17it/s][2025-01-30 02:00:13][root][INFO] - Training Epoch: 1/2, step 1470/107898 completed (loss: 1.0846953392028809, acc: 0.8888888955116272)
[2025-01-30 02:00:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1472/107898 [08:04<9:39:51,  3.06it/s][2025-01-30 02:00:14][root][INFO] - Training Epoch: 1/2, step 1471/107898 completed (loss: 0.6113489270210266, acc: 0.8999999761581421)
[2025-01-30 02:00:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1473/107898 [08:04<9:50:27,  3.00it/s][2025-01-30 02:00:14][root][INFO] - Training Epoch: 1/2, step 1472/107898 completed (loss: 0.8175738453865051, acc: 0.8947368264198303)
[2025-01-30 02:00:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1474/107898 [08:04<9:33:20,  3.09it/s][2025-01-30 02:00:14][root][INFO] - Training Epoch: 1/2, step 1473/107898 completed (loss: 0.7388783693313599, acc: 0.6666666865348816)
[2025-01-30 02:00:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1475/107898 [08:05<9:25:00,  3.14it/s][2025-01-30 02:00:15][root][INFO] - Training Epoch: 1/2, step 1474/107898 completed (loss: 3.9020209312438965, acc: 0.375)
[2025-01-30 02:00:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1476/107898 [08:05<9:12:48,  3.21it/s][2025-01-30 02:00:15][root][INFO] - Training Epoch: 1/2, step 1475/107898 completed (loss: 0.4907820522785187, acc: 0.8571428656578064)
[2025-01-30 02:00:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1477/107898 [08:05<9:15:55,  3.19it/s][2025-01-30 02:00:15][root][INFO] - Training Epoch: 1/2, step 1476/107898 completed (loss: 1.7116398811340332, acc: 0.7272727489471436)
[2025-01-30 02:00:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1478/107898 [08:06<9:05:35,  3.25it/s][2025-01-30 02:00:15][root][INFO] - Training Epoch: 1/2, step 1477/107898 completed (loss: 0.0653662234544754, acc: 1.0)
[2025-01-30 02:00:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1479/107898 [08:06<9:08:56,  3.23it/s][2025-01-30 02:00:16][root][INFO] - Training Epoch: 1/2, step 1478/107898 completed (loss: 0.3211430311203003, acc: 1.0)
[2025-01-30 02:00:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1480/107898 [08:06<9:10:06,  3.22it/s][2025-01-30 02:00:16][root][INFO] - Training Epoch: 1/2, step 1479/107898 completed (loss: 0.9667092561721802, acc: 0.800000011920929)
[2025-01-30 02:00:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1481/107898 [08:07<9:05:28,  3.25it/s][2025-01-30 02:00:16][root][INFO] - Training Epoch: 1/2, step 1480/107898 completed (loss: 1.318663239479065, acc: 0.5)
[2025-01-30 02:00:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1482/107898 [08:07<9:34:03,  3.09it/s][2025-01-30 02:00:17][root][INFO] - Training Epoch: 1/2, step 1481/107898 completed (loss: 2.6197259426116943, acc: 0.3333333432674408)
[2025-01-30 02:00:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1483/107898 [08:07<9:54:05,  2.99it/s][2025-01-30 02:00:17][root][INFO] - Training Epoch: 1/2, step 1482/107898 completed (loss: 0.7832522392272949, acc: 0.90625)
[2025-01-30 02:00:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1484/107898 [08:08<10:08:19,  2.92it/s][2025-01-30 02:00:17][root][INFO] - Training Epoch: 1/2, step 1483/107898 completed (loss: 0.6258826851844788, acc: 0.8500000238418579)
[2025-01-30 02:00:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1485/107898 [08:08<10:15:33,  2.88it/s][2025-01-30 02:00:18][root][INFO] - Training Epoch: 1/2, step 1484/107898 completed (loss: 5.453047752380371, acc: 0.25)
[2025-01-30 02:00:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1486/107898 [08:08<10:06:47,  2.92it/s][2025-01-30 02:00:18][root][INFO] - Training Epoch: 1/2, step 1485/107898 completed (loss: 2.0708091259002686, acc: 0.6000000238418579)
[2025-01-30 02:00:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1487/107898 [08:09<10:18:31,  2.87it/s][2025-01-30 02:00:19][root][INFO] - Training Epoch: 1/2, step 1486/107898 completed (loss: 0.846771776676178, acc: 0.7666666507720947)
[2025-01-30 02:00:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1488/107898 [08:09<9:59:44,  2.96it/s] [2025-01-30 02:00:19][root][INFO] - Training Epoch: 1/2, step 1487/107898 completed (loss: 3.034299373626709, acc: 0.1428571492433548)
[2025-01-30 02:00:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1489/107898 [08:09<9:54:51,  2.98it/s][2025-01-30 02:00:19][root][INFO] - Training Epoch: 1/2, step 1488/107898 completed (loss: 0.02609710395336151, acc: 1.0)
[2025-01-30 02:00:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1490/107898 [08:10<9:41:42,  3.05it/s][2025-01-30 02:00:19][root][INFO] - Training Epoch: 1/2, step 1489/107898 completed (loss: 0.7735697031021118, acc: 0.8620689511299133)
[2025-01-30 02:00:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1491/107898 [08:10<9:28:53,  3.12it/s][2025-01-30 02:00:20][root][INFO] - Training Epoch: 1/2, step 1490/107898 completed (loss: 0.500677227973938, acc: 1.0)
[2025-01-30 02:00:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1492/107898 [08:10<9:31:39,  3.10it/s][2025-01-30 02:00:20][root][INFO] - Training Epoch: 1/2, step 1491/107898 completed (loss: 1.7924572229385376, acc: 0.6428571343421936)
[2025-01-30 02:00:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1493/107898 [08:11<9:15:58,  3.19it/s][2025-01-30 02:00:20][root][INFO] - Training Epoch: 1/2, step 1492/107898 completed (loss: 1.502490520477295, acc: 0.6363636255264282)
[2025-01-30 02:00:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1494/107898 [08:11<9:54:32,  2.98it/s][2025-01-30 02:00:21][root][INFO] - Training Epoch: 1/2, step 1493/107898 completed (loss: 1.8362038135528564, acc: 0.6666666865348816)
[2025-01-30 02:00:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1495/107898 [08:11<9:56:03,  2.98it/s][2025-01-30 02:00:21][root][INFO] - Training Epoch: 1/2, step 1494/107898 completed (loss: 0.8297667503356934, acc: 0.8518518805503845)
[2025-01-30 02:00:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1496/107898 [08:12<10:05:51,  2.93it/s][2025-01-30 02:00:21][root][INFO] - Training Epoch: 1/2, step 1495/107898 completed (loss: 0.39268574118614197, acc: 1.0)
[2025-01-30 02:00:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1497/107898 [08:12<9:57:58,  2.97it/s] [2025-01-30 02:00:22][root][INFO] - Training Epoch: 1/2, step 1496/107898 completed (loss: 0.9463750123977661, acc: 0.8571428656578064)
[2025-01-30 02:00:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1498/107898 [08:12<10:14:39,  2.89it/s][2025-01-30 02:00:22][root][INFO] - Training Epoch: 1/2, step 1497/107898 completed (loss: 1.237328290939331, acc: 0.699999988079071)
[2025-01-30 02:00:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1499/107898 [08:13<10:25:24,  2.84it/s][2025-01-30 02:00:23][root][INFO] - Training Epoch: 1/2, step 1498/107898 completed (loss: 4.5115742683410645, acc: 0.22727273404598236)
[2025-01-30 02:00:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1500/107898 [08:13<10:06:06,  2.93it/s][2025-01-30 02:00:23][root][INFO] - Training Epoch: 1/2, step 1499/107898 completed (loss: 1.0988800525665283, acc: 0.8421052694320679)
[2025-01-30 02:00:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1501/107898 [08:13<10:02:58,  2.94it/s][2025-01-30 02:00:23][root][INFO] - Training Epoch: 1/2, step 1500/107898 completed (loss: 1.2253764867782593, acc: 0.8125)
[2025-01-30 02:00:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1502/107898 [08:14<9:54:23,  2.98it/s] [2025-01-30 02:00:24][root][INFO] - Training Epoch: 1/2, step 1501/107898 completed (loss: 0.006573955528438091, acc: 1.0)
[2025-01-30 02:00:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1503/107898 [08:14<10:06:35,  2.92it/s][2025-01-30 02:00:24][root][INFO] - Training Epoch: 1/2, step 1502/107898 completed (loss: 2.4996824264526367, acc: 0.6666666865348816)
[2025-01-30 02:00:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1504/107898 [08:14<10:02:40,  2.94it/s][2025-01-30 02:00:24][root][INFO] - Training Epoch: 1/2, step 1503/107898 completed (loss: 2.351663112640381, acc: 0.5)
[2025-01-30 02:00:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1505/107898 [08:15<9:56:52,  2.97it/s] [2025-01-30 02:00:25][root][INFO] - Training Epoch: 1/2, step 1504/107898 completed (loss: 0.8633358478546143, acc: 0.8181818127632141)
[2025-01-30 02:00:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1506/107898 [08:15<9:54:48,  2.98it/s][2025-01-30 02:00:25][root][INFO] - Training Epoch: 1/2, step 1505/107898 completed (loss: 3.3262276649475098, acc: 0.0)
[2025-01-30 02:00:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1507/107898 [08:15<9:54:27,  2.98it/s][2025-01-30 02:00:25][root][INFO] - Training Epoch: 1/2, step 1506/107898 completed (loss: 0.452885240316391, acc: 0.800000011920929)
[2025-01-30 02:00:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1508/107898 [08:16<10:05:47,  2.93it/s][2025-01-30 02:00:26][root][INFO] - Training Epoch: 1/2, step 1507/107898 completed (loss: 0.31297874450683594, acc: 1.0)
[2025-01-30 02:00:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1509/107898 [08:16<9:57:44,  2.97it/s] [2025-01-30 02:00:26][root][INFO] - Training Epoch: 1/2, step 1508/107898 completed (loss: 0.4605279564857483, acc: 0.8888888955116272)
[2025-01-30 02:00:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1510/107898 [08:16<10:10:17,  2.91it/s][2025-01-30 02:00:26][root][INFO] - Training Epoch: 1/2, step 1509/107898 completed (loss: 0.43989166617393494, acc: 0.8571428656578064)
[2025-01-30 02:00:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1511/107898 [08:17<10:01:39,  2.95it/s][2025-01-30 02:00:27][root][INFO] - Training Epoch: 1/2, step 1510/107898 completed (loss: 1.5648974180221558, acc: 0.6666666865348816)
[2025-01-30 02:00:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1512/107898 [08:17<9:50:34,  3.00it/s] [2025-01-30 02:00:27][root][INFO] - Training Epoch: 1/2, step 1511/107898 completed (loss: 0.023306313902139664, acc: 1.0)
[2025-01-30 02:00:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1513/107898 [08:17<10:04:55,  2.93it/s][2025-01-30 02:00:27][root][INFO] - Training Epoch: 1/2, step 1512/107898 completed (loss: 1.6623473167419434, acc: 0.6800000071525574)
[2025-01-30 02:00:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1514/107898 [08:18<10:14:41,  2.88it/s][2025-01-30 02:00:28][root][INFO] - Training Epoch: 1/2, step 1513/107898 completed (loss: 2.636159658432007, acc: 0.5)
[2025-01-30 02:00:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1515/107898 [08:18<10:16:35,  2.88it/s][2025-01-30 02:00:28][root][INFO] - Training Epoch: 1/2, step 1514/107898 completed (loss: 0.5964366793632507, acc: 0.9166666865348816)
[2025-01-30 02:00:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1516/107898 [08:19<10:03:15,  2.94it/s][2025-01-30 02:00:28][root][INFO] - Training Epoch: 1/2, step 1515/107898 completed (loss: 0.4938924312591553, acc: 0.800000011920929)
[2025-01-30 02:00:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1517/107898 [08:19<10:11:29,  2.90it/s][2025-01-30 02:00:29][root][INFO] - Training Epoch: 1/2, step 1516/107898 completed (loss: 2.640434980392456, acc: 0.6666666865348816)
[2025-01-30 02:00:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1518/107898 [08:19<10:11:17,  2.90it/s][2025-01-30 02:00:29][root][INFO] - Training Epoch: 1/2, step 1517/107898 completed (loss: 1.5454192161560059, acc: 0.5)
[2025-01-30 02:00:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1519/107898 [08:20<9:49:24,  3.01it/s] [2025-01-30 02:00:29][root][INFO] - Training Epoch: 1/2, step 1518/107898 completed (loss: 2.114504814147949, acc: 0.5)
[2025-01-30 02:00:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1520/107898 [08:20<9:49:16,  3.01it/s][2025-01-30 02:00:30][root][INFO] - Training Epoch: 1/2, step 1519/107898 completed (loss: 1.0128008127212524, acc: 0.7142857313156128)
[2025-01-30 02:00:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1521/107898 [08:20<9:46:41,  3.02it/s][2025-01-30 02:00:30][root][INFO] - Training Epoch: 1/2, step 1520/107898 completed (loss: 1.227372646331787, acc: 0.800000011920929)
[2025-01-30 02:00:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1522/107898 [08:21<9:44:16,  3.03it/s][2025-01-30 02:00:30][root][INFO] - Training Epoch: 1/2, step 1521/107898 completed (loss: 1.620589256286621, acc: 0.5)
[2025-01-30 02:00:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1523/107898 [08:21<9:29:10,  3.11it/s][2025-01-30 02:00:31][root][INFO] - Training Epoch: 1/2, step 1522/107898 completed (loss: 0.25264906883239746, acc: 1.0)
[2025-01-30 02:00:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1524/107898 [08:21<9:37:04,  3.07it/s][2025-01-30 02:00:31][root][INFO] - Training Epoch: 1/2, step 1523/107898 completed (loss: 0.743442177772522, acc: 0.8636363744735718)
[2025-01-30 02:00:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1525/107898 [08:21<9:27:08,  3.13it/s][2025-01-30 02:00:31][root][INFO] - Training Epoch: 1/2, step 1524/107898 completed (loss: 0.06218690052628517, acc: 1.0)
[2025-01-30 02:00:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1526/107898 [08:22<9:15:08,  3.19it/s][2025-01-30 02:00:32][root][INFO] - Training Epoch: 1/2, step 1525/107898 completed (loss: 0.258588582277298, acc: 0.8823529481887817)
[2025-01-30 02:00:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1527/107898 [08:22<9:06:06,  3.25it/s][2025-01-30 02:00:32][root][INFO] - Training Epoch: 1/2, step 1526/107898 completed (loss: 0.32227855920791626, acc: 1.0)
[2025-01-30 02:00:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1528/107898 [08:22<9:40:14,  3.06it/s][2025-01-30 02:00:32][root][INFO] - Training Epoch: 1/2, step 1527/107898 completed (loss: 0.7852756381034851, acc: 0.875)
[2025-01-30 02:00:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1529/107898 [08:23<9:41:02,  3.05it/s][2025-01-30 02:00:33][root][INFO] - Training Epoch: 1/2, step 1528/107898 completed (loss: 0.27503499388694763, acc: 0.9411764740943909)
[2025-01-30 02:00:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1530/107898 [08:23<9:43:48,  3.04it/s][2025-01-30 02:00:33][root][INFO] - Training Epoch: 1/2, step 1529/107898 completed (loss: 0.09855582565069199, acc: 1.0)
[2025-01-30 02:00:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1531/107898 [08:23<9:18:38,  3.17it/s][2025-01-30 02:00:33][root][INFO] - Training Epoch: 1/2, step 1530/107898 completed (loss: 0.03667057678103447, acc: 1.0)
[2025-01-30 02:00:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1532/107898 [08:24<9:06:24,  3.24it/s][2025-01-30 02:00:33][root][INFO] - Training Epoch: 1/2, step 1531/107898 completed (loss: 2.2029221057891846, acc: 0.5)
[2025-01-30 02:00:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1533/107898 [08:24<9:24:46,  3.14it/s][2025-01-30 02:00:34][root][INFO] - Training Epoch: 1/2, step 1532/107898 completed (loss: 2.0606162548065186, acc: 0.7272727489471436)
[2025-01-30 02:00:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1534/107898 [08:24<9:32:03,  3.10it/s][2025-01-30 02:00:34][root][INFO] - Training Epoch: 1/2, step 1533/107898 completed (loss: 0.07362872362136841, acc: 1.0)
[2025-01-30 02:00:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1535/107898 [08:25<9:31:03,  3.10it/s][2025-01-30 02:00:34][root][INFO] - Training Epoch: 1/2, step 1534/107898 completed (loss: 0.5771254301071167, acc: 0.75)
[2025-01-30 02:00:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1536/107898 [08:25<9:50:09,  3.00it/s][2025-01-30 02:00:35][root][INFO] - Training Epoch: 1/2, step 1535/107898 completed (loss: 3.366917133331299, acc: 0.42307692766189575)
[2025-01-30 02:00:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1537/107898 [08:25<9:57:40,  2.97it/s][2025-01-30 02:00:35][root][INFO] - Training Epoch: 1/2, step 1536/107898 completed (loss: 3.448172092437744, acc: 0.5555555820465088)
[2025-01-30 02:00:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1538/107898 [08:26<9:44:12,  3.03it/s][2025-01-30 02:00:35][root][INFO] - Training Epoch: 1/2, step 1537/107898 completed (loss: 0.16286316514015198, acc: 1.0)
[2025-01-30 02:00:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1539/107898 [08:26<9:54:48,  2.98it/s][2025-01-30 02:00:36][root][INFO] - Training Epoch: 1/2, step 1538/107898 completed (loss: 1.1552470922470093, acc: 0.75)
[2025-01-30 02:00:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1540/107898 [08:26<9:40:13,  3.06it/s][2025-01-30 02:00:36][root][INFO] - Training Epoch: 1/2, step 1539/107898 completed (loss: 0.17320702970027924, acc: 1.0)
[2025-01-30 02:00:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1541/107898 [08:27<10:15:09,  2.88it/s][2025-01-30 02:00:37][root][INFO] - Training Epoch: 1/2, step 1540/107898 completed (loss: 1.2114564180374146, acc: 0.6086956262588501)
[2025-01-30 02:00:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1542/107898 [08:27<9:59:11,  2.96it/s] [2025-01-30 02:00:37][root][INFO] - Training Epoch: 1/2, step 1541/107898 completed (loss: 2.486978054046631, acc: 0.5714285969734192)
[2025-01-30 02:00:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1543/107898 [08:27<9:37:04,  3.07it/s][2025-01-30 02:00:37][root][INFO] - Training Epoch: 1/2, step 1542/107898 completed (loss: 0.4985276758670807, acc: 0.7777777910232544)
[2025-01-30 02:00:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1544/107898 [08:28<9:20:02,  3.17it/s][2025-01-30 02:00:37][root][INFO] - Training Epoch: 1/2, step 1543/107898 completed (loss: 0.4325881898403168, acc: 0.8181818127632141)
[2025-01-30 02:00:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1545/107898 [08:28<9:19:16,  3.17it/s][2025-01-30 02:00:38][root][INFO] - Training Epoch: 1/2, step 1544/107898 completed (loss: 0.07387953251600266, acc: 1.0)
[2025-01-30 02:00:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1546/107898 [08:28<9:46:17,  3.02it/s][2025-01-30 02:00:38][root][INFO] - Training Epoch: 1/2, step 1545/107898 completed (loss: 0.8809683322906494, acc: 0.8333333134651184)
[2025-01-30 02:00:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1547/107898 [08:29<9:52:23,  2.99it/s][2025-01-30 02:00:38][root][INFO] - Training Epoch: 1/2, step 1546/107898 completed (loss: 0.09975779056549072, acc: 1.0)
[2025-01-30 02:00:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1548/107898 [08:29<10:12:42,  2.89it/s][2025-01-30 02:00:39][root][INFO] - Training Epoch: 1/2, step 1547/107898 completed (loss: 0.44113820791244507, acc: 0.9285714030265808)
[2025-01-30 02:00:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1549/107898 [08:29<10:05:18,  2.93it/s][2025-01-30 02:00:39][root][INFO] - Training Epoch: 1/2, step 1548/107898 completed (loss: 0.6194545030593872, acc: 0.5)
[2025-01-30 02:00:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1550/107898 [08:30<10:08:19,  2.91it/s][2025-01-30 02:00:39][root][INFO] - Training Epoch: 1/2, step 1549/107898 completed (loss: 1.1281208992004395, acc: 0.7586206793785095)
[2025-01-30 02:00:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1551/107898 [08:30<10:12:54,  2.89it/s][2025-01-30 02:00:40][root][INFO] - Training Epoch: 1/2, step 1550/107898 completed (loss: 0.7462603449821472, acc: 0.75)
[2025-01-30 02:00:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1552/107898 [08:30<10:16:57,  2.87it/s][2025-01-30 02:00:40][root][INFO] - Training Epoch: 1/2, step 1551/107898 completed (loss: 0.5276471972465515, acc: 0.8333333134651184)
[2025-01-30 02:00:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1553/107898 [08:31<10:20:13,  2.86it/s][2025-01-30 02:00:41][root][INFO] - Training Epoch: 1/2, step 1552/107898 completed (loss: 0.17859865725040436, acc: 0.970588207244873)
[2025-01-30 02:00:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1554/107898 [08:31<10:00:43,  2.95it/s][2025-01-30 02:00:41][root][INFO] - Training Epoch: 1/2, step 1553/107898 completed (loss: 0.13150860369205475, acc: 0.9411764740943909)
[2025-01-30 02:00:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1555/107898 [08:31<9:58:34,  2.96it/s] [2025-01-30 02:00:41][root][INFO] - Training Epoch: 1/2, step 1554/107898 completed (loss: 1.3885846138000488, acc: 0.3333333432674408)
[2025-01-30 02:00:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1556/107898 [08:32<9:49:20,  3.01it/s][2025-01-30 02:00:42][root][INFO] - Training Epoch: 1/2, step 1555/107898 completed (loss: 0.01398218609392643, acc: 1.0)
[2025-01-30 02:00:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1557/107898 [08:32<10:09:45,  2.91it/s][2025-01-30 02:00:42][root][INFO] - Training Epoch: 1/2, step 1556/107898 completed (loss: 2.6696441173553467, acc: 0.6666666865348816)
[2025-01-30 02:00:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1558/107898 [08:32<10:23:17,  2.84it/s][2025-01-30 02:00:42][root][INFO] - Training Epoch: 1/2, step 1557/107898 completed (loss: 2.440833330154419, acc: 0.5454545617103577)
[2025-01-30 02:00:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1559/107898 [08:33<10:26:51,  2.83it/s][2025-01-30 02:00:43][root][INFO] - Training Epoch: 1/2, step 1558/107898 completed (loss: 3.6091930866241455, acc: 0.1666666716337204)
[2025-01-30 02:00:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1560/107898 [08:33<9:54:58,  2.98it/s] [2025-01-30 02:00:43][root][INFO] - Training Epoch: 1/2, step 1559/107898 completed (loss: 0.5782907605171204, acc: 0.8999999761581421)
[2025-01-30 02:00:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1561/107898 [08:33<9:35:50,  3.08it/s][2025-01-30 02:00:43][root][INFO] - Training Epoch: 1/2, step 1560/107898 completed (loss: 0.06316028535366058, acc: 1.0)
[2025-01-30 02:00:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1562/107898 [08:34<9:29:34,  3.11it/s][2025-01-30 02:00:44][root][INFO] - Training Epoch: 1/2, step 1561/107898 completed (loss: 3.5436575412750244, acc: 0.3636363744735718)
[2025-01-30 02:00:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1563/107898 [08:34<9:46:42,  3.02it/s][2025-01-30 02:00:44][root][INFO] - Training Epoch: 1/2, step 1562/107898 completed (loss: 0.20012705028057098, acc: 0.9333333373069763)
[2025-01-30 02:00:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1564/107898 [08:34<9:53:26,  2.99it/s][2025-01-30 02:00:44][root][INFO] - Training Epoch: 1/2, step 1563/107898 completed (loss: 5.6451287269592285, acc: 0.0)
[2025-01-30 02:00:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1565/107898 [08:35<9:45:54,  3.02it/s][2025-01-30 02:00:45][root][INFO] - Training Epoch: 1/2, step 1564/107898 completed (loss: 0.6880857944488525, acc: 0.8571428656578064)
[2025-01-30 02:00:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1566/107898 [08:35<9:44:12,  3.03it/s][2025-01-30 02:00:45][root][INFO] - Training Epoch: 1/2, step 1565/107898 completed (loss: 0.10118933767080307, acc: 1.0)
[2025-01-30 02:00:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1567/107898 [08:35<9:32:46,  3.09it/s][2025-01-30 02:00:45][root][INFO] - Training Epoch: 1/2, step 1566/107898 completed (loss: 0.4241642653942108, acc: 1.0)
[2025-01-30 02:00:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1568/107898 [08:36<9:34:14,  3.09it/s][2025-01-30 02:00:45][root][INFO] - Training Epoch: 1/2, step 1567/107898 completed (loss: 0.1263965666294098, acc: 1.0)
[2025-01-30 02:00:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1569/107898 [08:36<9:43:08,  3.04it/s][2025-01-30 02:00:46][root][INFO] - Training Epoch: 1/2, step 1568/107898 completed (loss: 0.33810460567474365, acc: 1.0)
[2025-01-30 02:00:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1570/107898 [08:36<9:43:24,  3.04it/s][2025-01-30 02:00:46][root][INFO] - Training Epoch: 1/2, step 1569/107898 completed (loss: 0.6633867621421814, acc: 0.8095238208770752)
[2025-01-30 02:00:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1571/107898 [08:37<10:09:54,  2.91it/s][2025-01-30 02:00:47][root][INFO] - Training Epoch: 1/2, step 1570/107898 completed (loss: 0.7397594451904297, acc: 0.8928571343421936)
[2025-01-30 02:00:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1572/107898 [08:37<10:20:25,  2.86it/s][2025-01-30 02:00:47][root][INFO] - Training Epoch: 1/2, step 1571/107898 completed (loss: 1.4895786046981812, acc: 0.5833333134651184)
[2025-01-30 02:00:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1573/107898 [08:37<10:07:33,  2.92it/s][2025-01-30 02:00:47][root][INFO] - Training Epoch: 1/2, step 1572/107898 completed (loss: 0.21618178486824036, acc: 0.9285714030265808)
[2025-01-30 02:00:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1574/107898 [08:38<10:03:57,  2.93it/s][2025-01-30 02:00:48][root][INFO] - Training Epoch: 1/2, step 1573/107898 completed (loss: 1.8269705772399902, acc: 0.6315789222717285)
[2025-01-30 02:00:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1575/107898 [08:38<9:55:39,  2.97it/s] [2025-01-30 02:00:48][root][INFO] - Training Epoch: 1/2, step 1574/107898 completed (loss: 0.018187187612056732, acc: 1.0)
[2025-01-30 02:00:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1576/107898 [08:38<9:51:59,  2.99it/s][2025-01-30 02:00:48][root][INFO] - Training Epoch: 1/2, step 1575/107898 completed (loss: 1.2652167081832886, acc: 0.8666666746139526)
[2025-01-30 02:00:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1577/107898 [08:39<9:42:56,  3.04it/s][2025-01-30 02:00:49][root][INFO] - Training Epoch: 1/2, step 1576/107898 completed (loss: 4.37710428237915, acc: 0.25)
[2025-01-30 02:00:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1578/107898 [08:39<10:10:36,  2.90it/s][2025-01-30 02:00:49][root][INFO] - Training Epoch: 1/2, step 1577/107898 completed (loss: 0.0833095833659172, acc: 1.0)
[2025-01-30 02:00:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1579/107898 [08:39<10:02:21,  2.94it/s][2025-01-30 02:00:49][root][INFO] - Training Epoch: 1/2, step 1578/107898 completed (loss: 0.12494944036006927, acc: 1.0)
[2025-01-30 02:00:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1580/107898 [08:40<10:13:18,  2.89it/s][2025-01-30 02:00:50][root][INFO] - Training Epoch: 1/2, step 1579/107898 completed (loss: 0.6406638026237488, acc: 0.9285714030265808)
[2025-01-30 02:00:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1581/107898 [08:40<9:46:33,  3.02it/s] [2025-01-30 02:00:50][root][INFO] - Training Epoch: 1/2, step 1580/107898 completed (loss: 0.5133891105651855, acc: 1.0)
[2025-01-30 02:00:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1582/107898 [08:40<9:40:32,  3.05it/s][2025-01-30 02:00:50][root][INFO] - Training Epoch: 1/2, step 1581/107898 completed (loss: 1.1536701917648315, acc: 0.75)
[2025-01-30 02:00:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1583/107898 [08:41<9:26:17,  3.13it/s][2025-01-30 02:00:51][root][INFO] - Training Epoch: 1/2, step 1582/107898 completed (loss: 0.09917029738426208, acc: 1.0)
[2025-01-30 02:00:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1584/107898 [08:41<9:03:00,  3.26it/s][2025-01-30 02:00:51][root][INFO] - Training Epoch: 1/2, step 1583/107898 completed (loss: 0.6450653672218323, acc: 0.8333333134651184)
[2025-01-30 02:00:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1585/107898 [08:41<8:54:54,  3.31it/s][2025-01-30 02:00:51][root][INFO] - Training Epoch: 1/2, step 1584/107898 completed (loss: 0.6800090074539185, acc: 1.0)
[2025-01-30 02:00:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1586/107898 [08:42<8:59:03,  3.29it/s][2025-01-30 02:00:51][root][INFO] - Training Epoch: 1/2, step 1585/107898 completed (loss: 0.9232476353645325, acc: 0.7142857313156128)
[2025-01-30 02:00:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1587/107898 [08:42<8:53:34,  3.32it/s][2025-01-30 02:00:52][root][INFO] - Training Epoch: 1/2, step 1586/107898 completed (loss: 0.7975894212722778, acc: 0.5)
[2025-01-30 02:00:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1588/107898 [08:42<8:58:27,  3.29it/s][2025-01-30 02:00:52][root][INFO] - Training Epoch: 1/2, step 1587/107898 completed (loss: 0.8894488215446472, acc: 0.5)
[2025-01-30 02:00:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1589/107898 [08:43<9:16:10,  3.19it/s][2025-01-30 02:00:52][root][INFO] - Training Epoch: 1/2, step 1588/107898 completed (loss: 3.134387254714966, acc: 0.6666666865348816)
[2025-01-30 02:00:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1590/107898 [08:43<9:21:28,  3.16it/s][2025-01-30 02:00:53][root][INFO] - Training Epoch: 1/2, step 1589/107898 completed (loss: 0.006773654371500015, acc: 1.0)
[2025-01-30 02:00:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1591/107898 [08:43<9:15:31,  3.19it/s][2025-01-30 02:00:53][root][INFO] - Training Epoch: 1/2, step 1590/107898 completed (loss: 0.02869592420756817, acc: 1.0)
[2025-01-30 02:00:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1592/107898 [08:44<9:25:12,  3.13it/s][2025-01-30 02:00:53][root][INFO] - Training Epoch: 1/2, step 1591/107898 completed (loss: 0.5546206831932068, acc: 0.9166666865348816)
[2025-01-30 02:00:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1593/107898 [08:44<9:29:23,  3.11it/s][2025-01-30 02:00:54][root][INFO] - Training Epoch: 1/2, step 1592/107898 completed (loss: 0.8033616542816162, acc: 0.8620689511299133)
[2025-01-30 02:00:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1594/107898 [08:44<9:20:57,  3.16it/s][2025-01-30 02:00:54][root][INFO] - Training Epoch: 1/2, step 1593/107898 completed (loss: 0.02252660132944584, acc: 1.0)
[2025-01-30 02:00:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1595/107898 [08:45<9:53:13,  2.99it/s][2025-01-30 02:00:54][root][INFO] - Training Epoch: 1/2, step 1594/107898 completed (loss: 0.8921539187431335, acc: 0.800000011920929)
[2025-01-30 02:00:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1596/107898 [08:45<9:50:22,  3.00it/s][2025-01-30 02:00:55][root][INFO] - Training Epoch: 1/2, step 1595/107898 completed (loss: 2.5639216899871826, acc: 0.6000000238418579)
[2025-01-30 02:00:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1597/107898 [08:45<10:03:18,  2.94it/s][2025-01-30 02:00:55][root][INFO] - Training Epoch: 1/2, step 1596/107898 completed (loss: 3.1602365970611572, acc: 0.2857142984867096)
[2025-01-30 02:00:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1598/107898 [08:46<9:52:01,  2.99it/s] [2025-01-30 02:00:55][root][INFO] - Training Epoch: 1/2, step 1597/107898 completed (loss: 0.250301718711853, acc: 1.0)
[2025-01-30 02:00:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1599/107898 [08:46<9:34:07,  3.09it/s][2025-01-30 02:00:56][root][INFO] - Training Epoch: 1/2, step 1598/107898 completed (loss: 0.01604827493429184, acc: 1.0)
[2025-01-30 02:00:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1600/107898 [08:46<9:41:15,  3.05it/s][2025-01-30 02:00:56][root][INFO] - Training Epoch: 1/2, step 1599/107898 completed (loss: 0.4904549717903137, acc: 0.9200000166893005)
[2025-01-30 02:00:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1601/107898 [08:47<9:55:12,  2.98it/s][2025-01-30 02:00:56][root][INFO] - Training Epoch: 1/2, step 1600/107898 completed (loss: 0.0358850322663784, acc: 1.0)
[2025-01-30 02:00:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1602/107898 [08:47<9:54:27,  2.98it/s][2025-01-30 02:00:57][root][INFO] - Training Epoch: 1/2, step 1601/107898 completed (loss: 1.5540910959243774, acc: 0.5714285969734192)
[2025-01-30 02:00:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1603/107898 [08:47<10:09:22,  2.91it/s][2025-01-30 02:00:57][root][INFO] - Training Epoch: 1/2, step 1602/107898 completed (loss: 1.8364553451538086, acc: 0.761904776096344)
[2025-01-30 02:00:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1604/107898 [08:48<9:59:39,  2.95it/s] [2025-01-30 02:00:57][root][INFO] - Training Epoch: 1/2, step 1603/107898 completed (loss: 1.2653685808181763, acc: 0.6666666865348816)
[2025-01-30 02:00:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1605/107898 [08:48<9:44:13,  3.03it/s][2025-01-30 02:00:58][root][INFO] - Training Epoch: 1/2, step 1604/107898 completed (loss: 1.3338040113449097, acc: 0.75)
[2025-01-30 02:00:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1606/107898 [08:48<9:36:15,  3.07it/s][2025-01-30 02:00:58][root][INFO] - Training Epoch: 1/2, step 1605/107898 completed (loss: 4.243231296539307, acc: 0.27272728085517883)
[2025-01-30 02:00:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1607/107898 [08:48<9:28:00,  3.12it/s][2025-01-30 02:00:58][root][INFO] - Training Epoch: 1/2, step 1606/107898 completed (loss: 0.5231314301490784, acc: 0.5)
[2025-01-30 02:00:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1608/107898 [08:49<9:34:12,  3.09it/s][2025-01-30 02:00:59][root][INFO] - Training Epoch: 1/2, step 1607/107898 completed (loss: 0.024439197033643723, acc: 1.0)
[2025-01-30 02:00:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1609/107898 [08:49<9:38:51,  3.06it/s][2025-01-30 02:00:59][root][INFO] - Training Epoch: 1/2, step 1608/107898 completed (loss: 2.031182050704956, acc: 0.5)
[2025-01-30 02:00:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1610/107898 [08:50<9:56:19,  2.97it/s][2025-01-30 02:00:59][root][INFO] - Training Epoch: 1/2, step 1609/107898 completed (loss: 1.4110749959945679, acc: 0.5)
[2025-01-30 02:00:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1611/107898 [08:50<10:04:01,  2.93it/s][2025-01-30 02:01:00][root][INFO] - Training Epoch: 1/2, step 1610/107898 completed (loss: 0.030677150934934616, acc: 1.0)
[2025-01-30 02:01:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1612/107898 [08:50<10:00:30,  2.95it/s][2025-01-30 02:01:00][root][INFO] - Training Epoch: 1/2, step 1611/107898 completed (loss: 0.03782092034816742, acc: 1.0)
[2025-01-30 02:01:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1613/107898 [08:51<10:00:12,  2.95it/s][2025-01-30 02:01:00][root][INFO] - Training Epoch: 1/2, step 1612/107898 completed (loss: 1.7618461847305298, acc: 0.6000000238418579)
[2025-01-30 02:01:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1614/107898 [08:51<10:00:24,  2.95it/s][2025-01-30 02:01:01][root][INFO] - Training Epoch: 1/2, step 1613/107898 completed (loss: 5.44717264175415, acc: 0.25)
[2025-01-30 02:01:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1615/107898 [08:51<10:01:45,  2.94it/s][2025-01-30 02:01:01][root][INFO] - Training Epoch: 1/2, step 1614/107898 completed (loss: 3.340325117111206, acc: 0.5)
[2025-01-30 02:01:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1616/107898 [08:52<9:58:59,  2.96it/s] [2025-01-30 02:01:01][root][INFO] - Training Epoch: 1/2, step 1615/107898 completed (loss: 1.3068736791610718, acc: 0.75)
[2025-01-30 02:01:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1617/107898 [08:52<10:09:18,  2.91it/s][2025-01-30 02:01:02][root][INFO] - Training Epoch: 1/2, step 1616/107898 completed (loss: 1.20729398727417, acc: 0.7333333492279053)
[2025-01-30 02:01:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   1%|[34mâ–         [0m| 1618/107898 [08:52<10:25:46,  2.83it/s][2025-01-30 02:01:02][root][INFO] - Training Epoch: 1/2, step 1617/107898 completed (loss: 0.9951888918876648, acc: 0.6875)
[2025-01-30 02:01:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1619/107898 [08:53<9:49:59,  3.00it/s] [2025-01-30 02:01:02][root][INFO] - Training Epoch: 1/2, step 1618/107898 completed (loss: 1.529273271560669, acc: 0.692307710647583)
[2025-01-30 02:01:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1620/107898 [08:53<9:42:10,  3.04it/s][2025-01-30 02:01:03][root][INFO] - Training Epoch: 1/2, step 1619/107898 completed (loss: 0.6549999117851257, acc: 0.8666666746139526)
[2025-01-30 02:01:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1621/107898 [08:53<9:33:28,  3.09it/s][2025-01-30 02:01:03][root][INFO] - Training Epoch: 1/2, step 1620/107898 completed (loss: 0.9014806151390076, acc: 0.8571428656578064)
[2025-01-30 02:01:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1622/107898 [08:53<9:17:34,  3.18it/s][2025-01-30 02:01:03][root][INFO] - Training Epoch: 1/2, step 1621/107898 completed (loss: 0.5236503481864929, acc: 0.8333333134651184)
[2025-01-30 02:01:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1623/107898 [08:54<8:49:17,  3.35it/s][2025-01-30 02:01:04][root][INFO] - Training Epoch: 1/2, step 1622/107898 completed (loss: 0.42710617184638977, acc: 0.8333333134651184)
[2025-01-30 02:01:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1624/107898 [08:54<8:46:53,  3.36it/s][2025-01-30 02:01:04][root][INFO] - Training Epoch: 1/2, step 1623/107898 completed (loss: 0.3126830756664276, acc: 1.0)
[2025-01-30 02:01:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1625/107898 [08:54<8:50:16,  3.34it/s][2025-01-30 02:01:04][root][INFO] - Training Epoch: 1/2, step 1624/107898 completed (loss: 0.9056001305580139, acc: 0.8333333134651184)
[2025-01-30 02:01:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1626/107898 [08:55<9:18:49,  3.17it/s][2025-01-30 02:01:04][root][INFO] - Training Epoch: 1/2, step 1625/107898 completed (loss: 5.00649356842041, acc: 0.0)
[2025-01-30 02:01:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1627/107898 [08:55<9:08:47,  3.23it/s][2025-01-30 02:01:05][root][INFO] - Training Epoch: 1/2, step 1626/107898 completed (loss: 1.634293794631958, acc: 0.25)
[2025-01-30 02:01:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1628/107898 [08:55<9:19:00,  3.17it/s][2025-01-30 02:01:05][root][INFO] - Training Epoch: 1/2, step 1627/107898 completed (loss: 0.9500765204429626, acc: 0.8181818127632141)
[2025-01-30 02:01:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1629/107898 [08:56<9:12:04,  3.21it/s][2025-01-30 02:01:05][root][INFO] - Training Epoch: 1/2, step 1628/107898 completed (loss: 7.373212814331055, acc: 0.5)
[2025-01-30 02:01:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1630/107898 [08:56<9:04:59,  3.25it/s][2025-01-30 02:01:06][root][INFO] - Training Epoch: 1/2, step 1629/107898 completed (loss: 0.5408723950386047, acc: 0.9230769276618958)
[2025-01-30 02:01:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1631/107898 [08:56<9:00:07,  3.28it/s][2025-01-30 02:01:06][root][INFO] - Training Epoch: 1/2, step 1630/107898 completed (loss: 5.250397682189941, acc: 0.4000000059604645)
[2025-01-30 02:01:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1632/107898 [08:57<9:01:15,  3.27it/s][2025-01-30 02:01:06][root][INFO] - Training Epoch: 1/2, step 1631/107898 completed (loss: 1.967117428779602, acc: 0.7272727489471436)
[2025-01-30 02:01:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1633/107898 [08:57<9:09:35,  3.22it/s][2025-01-30 02:01:07][root][INFO] - Training Epoch: 1/2, step 1632/107898 completed (loss: 0.07278335094451904, acc: 1.0)
[2025-01-30 02:01:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1634/107898 [08:57<9:28:11,  3.12it/s][2025-01-30 02:01:07][root][INFO] - Training Epoch: 1/2, step 1633/107898 completed (loss: 0.9920017123222351, acc: 0.8421052694320679)
[2025-01-30 02:01:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1635/107898 [08:58<9:41:31,  3.05it/s][2025-01-30 02:01:07][root][INFO] - Training Epoch: 1/2, step 1634/107898 completed (loss: 1.9177175760269165, acc: 0.7179487347602844)
[2025-01-30 02:01:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1636/107898 [08:58<9:25:32,  3.13it/s][2025-01-30 02:01:08][root][INFO] - Training Epoch: 1/2, step 1635/107898 completed (loss: 1.7629549503326416, acc: 0.6666666865348816)
[2025-01-30 02:01:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1637/107898 [08:58<9:22:23,  3.15it/s][2025-01-30 02:01:08][root][INFO] - Training Epoch: 1/2, step 1636/107898 completed (loss: 0.06280085444450378, acc: 1.0)
[2025-01-30 02:01:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1638/107898 [08:58<9:23:16,  3.14it/s][2025-01-30 02:01:08][root][INFO] - Training Epoch: 1/2, step 1637/107898 completed (loss: 2.0658926963806152, acc: 0.6666666865348816)
[2025-01-30 02:01:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1639/107898 [08:59<8:58:35,  3.29it/s][2025-01-30 02:01:09][root][INFO] - Training Epoch: 1/2, step 1638/107898 completed (loss: 1.220660924911499, acc: 1.0)
[2025-01-30 02:01:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1640/107898 [08:59<9:19:15,  3.17it/s][2025-01-30 02:01:09][root][INFO] - Training Epoch: 1/2, step 1639/107898 completed (loss: 0.7413055896759033, acc: 0.8181818127632141)
[2025-01-30 02:01:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1641/107898 [08:59<9:22:25,  3.15it/s][2025-01-30 02:01:09][root][INFO] - Training Epoch: 1/2, step 1640/107898 completed (loss: 0.6777923703193665, acc: 0.9047619104385376)
[2025-01-30 02:01:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1642/107898 [09:00<9:43:46,  3.03it/s][2025-01-30 02:01:10][root][INFO] - Training Epoch: 1/2, step 1641/107898 completed (loss: 2.9137027263641357, acc: 0.5)
[2025-01-30 02:01:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1643/107898 [09:00<9:52:50,  2.99it/s][2025-01-30 02:01:10][root][INFO] - Training Epoch: 1/2, step 1642/107898 completed (loss: 0.9922295212745667, acc: 0.8695651888847351)
[2025-01-30 02:01:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1644/107898 [09:00<9:35:16,  3.08it/s][2025-01-30 02:01:10][root][INFO] - Training Epoch: 1/2, step 1643/107898 completed (loss: 1.7272628545761108, acc: 0.5)
[2025-01-30 02:01:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1645/107898 [09:01<9:24:20,  3.14it/s][2025-01-30 02:01:11][root][INFO] - Training Epoch: 1/2, step 1644/107898 completed (loss: 0.10764382034540176, acc: 1.0)
[2025-01-30 02:01:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1646/107898 [09:01<9:24:11,  3.14it/s][2025-01-30 02:01:11][root][INFO] - Training Epoch: 1/2, step 1645/107898 completed (loss: 2.357755184173584, acc: 0.7142857313156128)
[2025-01-30 02:01:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1647/107898 [09:01<9:34:29,  3.08it/s][2025-01-30 02:01:11][root][INFO] - Training Epoch: 1/2, step 1646/107898 completed (loss: 0.18860110640525818, acc: 1.0)
[2025-01-30 02:01:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1648/107898 [09:02<9:31:37,  3.10it/s][2025-01-30 02:01:11][root][INFO] - Training Epoch: 1/2, step 1647/107898 completed (loss: 0.9233492612838745, acc: 0.8999999761581421)
[2025-01-30 02:01:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1649/107898 [09:02<9:21:01,  3.16it/s][2025-01-30 02:01:12][root][INFO] - Training Epoch: 1/2, step 1648/107898 completed (loss: 1.3910202980041504, acc: 0.7727272510528564)
[2025-01-30 02:01:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1650/107898 [09:02<9:14:23,  3.19it/s][2025-01-30 02:01:12][root][INFO] - Training Epoch: 1/2, step 1649/107898 completed (loss: 0.11491718888282776, acc: 1.0)
[2025-01-30 02:01:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1651/107898 [09:03<9:08:57,  3.23it/s][2025-01-30 02:01:12][root][INFO] - Training Epoch: 1/2, step 1650/107898 completed (loss: 1.2820849418640137, acc: 0.7368420958518982)
[2025-01-30 02:01:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1652/107898 [09:03<9:05:44,  3.24it/s][2025-01-30 02:01:13][root][INFO] - Training Epoch: 1/2, step 1651/107898 completed (loss: 0.47172075510025024, acc: 0.8571428656578064)
[2025-01-30 02:01:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1653/107898 [09:03<9:09:21,  3.22it/s][2025-01-30 02:01:13][root][INFO] - Training Epoch: 1/2, step 1652/107898 completed (loss: 0.6426225900650024, acc: 1.0)
[2025-01-30 02:01:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1654/107898 [09:04<9:05:26,  3.25it/s][2025-01-30 02:01:13][root][INFO] - Training Epoch: 1/2, step 1653/107898 completed (loss: 0.010896117426455021, acc: 1.0)
[2025-01-30 02:01:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1655/107898 [09:04<9:10:10,  3.22it/s][2025-01-30 02:01:14][root][INFO] - Training Epoch: 1/2, step 1654/107898 completed (loss: 2.0499539375305176, acc: 0.6666666865348816)
[2025-01-30 02:01:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1656/107898 [09:04<9:48:19,  3.01it/s][2025-01-30 02:01:14][root][INFO] - Training Epoch: 1/2, step 1655/107898 completed (loss: 1.5471726655960083, acc: 0.5)
[2025-01-30 02:01:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1657/107898 [09:05<10:06:31,  2.92it/s][2025-01-30 02:01:14][root][INFO] - Training Epoch: 1/2, step 1656/107898 completed (loss: 1.7320888042449951, acc: 0.7272727489471436)
[2025-01-30 02:01:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1658/107898 [09:05<9:56:56,  2.97it/s] [2025-01-30 02:01:15][root][INFO] - Training Epoch: 1/2, step 1657/107898 completed (loss: 1.875942587852478, acc: 0.5)
[2025-01-30 02:01:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1659/107898 [09:05<9:44:26,  3.03it/s][2025-01-30 02:01:15][root][INFO] - Training Epoch: 1/2, step 1658/107898 completed (loss: 0.2056819051504135, acc: 1.0)
[2025-01-30 02:01:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1660/107898 [09:06<9:19:40,  3.16it/s][2025-01-30 02:01:15][root][INFO] - Training Epoch: 1/2, step 1659/107898 completed (loss: 0.4890899658203125, acc: 0.8999999761581421)
[2025-01-30 02:01:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1661/107898 [09:06<9:12:30,  3.20it/s][2025-01-30 02:01:16][root][INFO] - Training Epoch: 1/2, step 1660/107898 completed (loss: 0.3820781707763672, acc: 0.9285714030265808)
[2025-01-30 02:01:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1662/107898 [09:06<9:05:54,  3.24it/s][2025-01-30 02:01:16][root][INFO] - Training Epoch: 1/2, step 1661/107898 completed (loss: 2.214550495147705, acc: 0.5)
[2025-01-30 02:01:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1663/107898 [09:06<9:09:54,  3.22it/s][2025-01-30 02:01:16][root][INFO] - Training Epoch: 1/2, step 1662/107898 completed (loss: 0.46986323595046997, acc: 0.8928571343421936)
[2025-01-30 02:01:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1664/107898 [09:07<9:02:04,  3.27it/s][2025-01-30 02:01:17][root][INFO] - Training Epoch: 1/2, step 1663/107898 completed (loss: 0.15160058438777924, acc: 1.0)
[2025-01-30 02:01:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1665/107898 [09:07<9:22:49,  3.15it/s][2025-01-30 02:01:17][root][INFO] - Training Epoch: 1/2, step 1664/107898 completed (loss: 0.2216169387102127, acc: 0.9411764740943909)
[2025-01-30 02:01:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1666/107898 [09:07<9:08:33,  3.23it/s][2025-01-30 02:01:17][root][INFO] - Training Epoch: 1/2, step 1665/107898 completed (loss: 1.477217674255371, acc: 0.5)
[2025-01-30 02:01:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1667/107898 [09:08<9:09:25,  3.22it/s][2025-01-30 02:01:17][root][INFO] - Training Epoch: 1/2, step 1666/107898 completed (loss: 0.38512659072875977, acc: 1.0)
[2025-01-30 02:01:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1668/107898 [09:08<9:17:42,  3.17it/s][2025-01-30 02:01:18][root][INFO] - Training Epoch: 1/2, step 1667/107898 completed (loss: 1.9209554195404053, acc: 0.6842105388641357)
[2025-01-30 02:01:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1669/107898 [09:08<9:31:29,  3.10it/s][2025-01-30 02:01:18][root][INFO] - Training Epoch: 1/2, step 1668/107898 completed (loss: 0.29112279415130615, acc: 1.0)
[2025-01-30 02:01:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1670/107898 [09:09<9:40:41,  3.05it/s][2025-01-30 02:01:18][root][INFO] - Training Epoch: 1/2, step 1669/107898 completed (loss: 0.616732656955719, acc: 0.800000011920929)
[2025-01-30 02:01:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1671/107898 [09:09<9:37:14,  3.07it/s][2025-01-30 02:01:19][root][INFO] - Training Epoch: 1/2, step 1670/107898 completed (loss: 1.7618639469146729, acc: 0.6666666865348816)
[2025-01-30 02:01:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1672/107898 [09:09<9:39:09,  3.06it/s][2025-01-30 02:01:19][root][INFO] - Training Epoch: 1/2, step 1671/107898 completed (loss: 1.3420294523239136, acc: 0.75)
[2025-01-30 02:01:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1673/107898 [09:10<9:14:37,  3.19it/s][2025-01-30 02:01:19][root][INFO] - Training Epoch: 1/2, step 1672/107898 completed (loss: 0.028971239924430847, acc: 1.0)
[2025-01-30 02:01:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1674/107898 [09:10<9:06:31,  3.24it/s][2025-01-30 02:01:20][root][INFO] - Training Epoch: 1/2, step 1673/107898 completed (loss: 0.6975018978118896, acc: 0.75)
[2025-01-30 02:01:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1675/107898 [09:10<9:03:41,  3.26it/s][2025-01-30 02:01:20][root][INFO] - Training Epoch: 1/2, step 1674/107898 completed (loss: 2.7039504051208496, acc: 0.5)
[2025-01-30 02:01:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1676/107898 [09:11<9:05:34,  3.24it/s][2025-01-30 02:01:20][root][INFO] - Training Epoch: 1/2, step 1675/107898 completed (loss: 0.6998571753501892, acc: 0.6666666865348816)
[2025-01-30 02:01:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1677/107898 [09:11<9:03:06,  3.26it/s][2025-01-30 02:01:21][root][INFO] - Training Epoch: 1/2, step 1676/107898 completed (loss: 1.2589635848999023, acc: 0.6428571343421936)
[2025-01-30 02:01:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1678/107898 [09:11<9:23:09,  3.14it/s][2025-01-30 02:01:21][root][INFO] - Training Epoch: 1/2, step 1677/107898 completed (loss: 0.9768108129501343, acc: 0.8095238208770752)
[2025-01-30 02:01:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1679/107898 [09:12<9:26:56,  3.12it/s][2025-01-30 02:01:21][root][INFO] - Training Epoch: 1/2, step 1678/107898 completed (loss: 0.893437922000885, acc: 0.9090909361839294)
[2025-01-30 02:01:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1680/107898 [09:12<9:20:13,  3.16it/s][2025-01-30 02:01:22][root][INFO] - Training Epoch: 1/2, step 1679/107898 completed (loss: 0.9856052398681641, acc: 0.8125)
[2025-01-30 02:01:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1681/107898 [09:12<9:13:38,  3.20it/s][2025-01-30 02:01:22][root][INFO] - Training Epoch: 1/2, step 1680/107898 completed (loss: 0.18188971281051636, acc: 1.0)
[2025-01-30 02:01:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1682/107898 [09:12<9:10:05,  3.22it/s][2025-01-30 02:01:22][root][INFO] - Training Epoch: 1/2, step 1681/107898 completed (loss: 0.1915876269340515, acc: 1.0)
[2025-01-30 02:01:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1683/107898 [09:13<9:30:49,  3.10it/s][2025-01-30 02:01:23][root][INFO] - Training Epoch: 1/2, step 1682/107898 completed (loss: 0.2000875025987625, acc: 0.9285714030265808)
[2025-01-30 02:01:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1684/107898 [09:13<9:32:57,  3.09it/s][2025-01-30 02:01:23][root][INFO] - Training Epoch: 1/2, step 1683/107898 completed (loss: 5.775437831878662, acc: 0.5)
[2025-01-30 02:01:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1685/107898 [09:13<9:09:08,  3.22it/s][2025-01-30 02:01:23][root][INFO] - Training Epoch: 1/2, step 1684/107898 completed (loss: 0.4148155152797699, acc: 0.875)
[2025-01-30 02:01:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1686/107898 [09:14<9:19:23,  3.16it/s][2025-01-30 02:01:24][root][INFO] - Training Epoch: 1/2, step 1685/107898 completed (loss: 0.9828876256942749, acc: 0.7692307829856873)
[2025-01-30 02:01:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1687/107898 [09:14<9:10:46,  3.21it/s][2025-01-30 02:01:24][root][INFO] - Training Epoch: 1/2, step 1686/107898 completed (loss: 0.8042155504226685, acc: 1.0)
[2025-01-30 02:01:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1688/107898 [09:14<9:46:28,  3.02it/s][2025-01-30 02:01:24][root][INFO] - Training Epoch: 1/2, step 1687/107898 completed (loss: 0.6118425130844116, acc: 0.8999999761581421)
[2025-01-30 02:01:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1689/107898 [09:15<9:59:34,  2.95it/s][2025-01-30 02:01:25][root][INFO] - Training Epoch: 1/2, step 1688/107898 completed (loss: 0.018786292523145676, acc: 1.0)
[2025-01-30 02:01:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1690/107898 [09:15<10:00:04,  2.95it/s][2025-01-30 02:01:25][root][INFO] - Training Epoch: 1/2, step 1689/107898 completed (loss: 1.969495177268982, acc: 0.800000011920929)
[2025-01-30 02:01:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1691/107898 [09:15<9:54:47,  2.98it/s] [2025-01-30 02:01:25][root][INFO] - Training Epoch: 1/2, step 1690/107898 completed (loss: 2.2952840328216553, acc: 0.75)
[2025-01-30 02:01:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1692/107898 [09:16<9:44:54,  3.03it/s][2025-01-30 02:01:26][root][INFO] - Training Epoch: 1/2, step 1691/107898 completed (loss: 1.5720643997192383, acc: 0.7368420958518982)
[2025-01-30 02:01:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1693/107898 [09:16<9:42:45,  3.04it/s][2025-01-30 02:01:26][root][INFO] - Training Epoch: 1/2, step 1692/107898 completed (loss: 0.45781633257865906, acc: 0.9166666865348816)
[2025-01-30 02:01:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1694/107898 [09:16<9:38:20,  3.06it/s][2025-01-30 02:01:26][root][INFO] - Training Epoch: 1/2, step 1693/107898 completed (loss: 0.013619696721434593, acc: 1.0)
[2025-01-30 02:01:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1695/107898 [09:17<9:49:55,  3.00it/s][2025-01-30 02:01:27][root][INFO] - Training Epoch: 1/2, step 1694/107898 completed (loss: 0.7492119073867798, acc: 0.9130434989929199)
[2025-01-30 02:01:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1696/107898 [09:17<9:31:09,  3.10it/s][2025-01-30 02:01:27][root][INFO] - Training Epoch: 1/2, step 1695/107898 completed (loss: 0.5368170142173767, acc: 0.8636363744735718)
[2025-01-30 02:01:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1697/107898 [09:17<9:39:43,  3.05it/s][2025-01-30 02:01:27][root][INFO] - Training Epoch: 1/2, step 1696/107898 completed (loss: 0.6353408098220825, acc: 0.5)
[2025-01-30 02:01:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1698/107898 [09:18<9:48:08,  3.01it/s][2025-01-30 02:01:27][root][INFO] - Training Epoch: 1/2, step 1697/107898 completed (loss: 0.8039760589599609, acc: 0.6666666865348816)
[2025-01-30 02:01:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1699/107898 [09:18<9:39:40,  3.05it/s][2025-01-30 02:01:28][root][INFO] - Training Epoch: 1/2, step 1698/107898 completed (loss: 0.7030382752418518, acc: 0.6666666865348816)
[2025-01-30 02:01:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1700/107898 [09:18<9:51:19,  2.99it/s][2025-01-30 02:01:28][root][INFO] - Training Epoch: 1/2, step 1699/107898 completed (loss: 0.8316949605941772, acc: 0.8181818127632141)
[2025-01-30 02:01:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1701/107898 [09:19<9:57:30,  2.96it/s][2025-01-30 02:01:29][root][INFO] - Training Epoch: 1/2, step 1700/107898 completed (loss: 1.3080588579177856, acc: 0.6818181872367859)
[2025-01-30 02:01:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1702/107898 [09:19<10:17:46,  2.86it/s][2025-01-30 02:01:29][root][INFO] - Training Epoch: 1/2, step 1701/107898 completed (loss: 0.8566637635231018, acc: 0.75)
[2025-01-30 02:01:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1703/107898 [09:19<10:15:09,  2.88it/s][2025-01-30 02:01:29][root][INFO] - Training Epoch: 1/2, step 1702/107898 completed (loss: 0.18921439349651337, acc: 1.0)
[2025-01-30 02:01:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1704/107898 [09:20<10:07:13,  2.91it/s][2025-01-30 02:01:30][root][INFO] - Training Epoch: 1/2, step 1703/107898 completed (loss: 0.02505285106599331, acc: 1.0)
[2025-01-30 02:01:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1705/107898 [09:20<10:01:50,  2.94it/s][2025-01-30 02:01:30][root][INFO] - Training Epoch: 1/2, step 1704/107898 completed (loss: 3.450629472732544, acc: 0.3928571343421936)
[2025-01-30 02:01:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1706/107898 [09:20<9:44:36,  3.03it/s] [2025-01-30 02:01:30][root][INFO] - Training Epoch: 1/2, step 1705/107898 completed (loss: 1.259021282196045, acc: 0.7368420958518982)
[2025-01-30 02:01:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1707/107898 [09:21<9:33:32,  3.09it/s][2025-01-30 02:01:31][root][INFO] - Training Epoch: 1/2, step 1706/107898 completed (loss: 0.3613973557949066, acc: 0.9166666865348816)
[2025-01-30 02:01:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1708/107898 [09:21<9:03:27,  3.26it/s][2025-01-30 02:01:31][root][INFO] - Training Epoch: 1/2, step 1707/107898 completed (loss: 1.1415694952011108, acc: 0.6666666865348816)
[2025-01-30 02:01:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1709/107898 [09:21<8:48:21,  3.35it/s][2025-01-30 02:01:31][root][INFO] - Training Epoch: 1/2, step 1708/107898 completed (loss: 0.13671934604644775, acc: 1.0)
[2025-01-30 02:01:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1710/107898 [09:22<8:33:44,  3.44it/s][2025-01-30 02:01:31][root][INFO] - Training Epoch: 1/2, step 1709/107898 completed (loss: 0.9192468523979187, acc: 0.9333333373069763)
[2025-01-30 02:01:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1711/107898 [09:22<9:03:21,  3.26it/s][2025-01-30 02:01:32][root][INFO] - Training Epoch: 1/2, step 1710/107898 completed (loss: 2.4497478008270264, acc: 0.5833333134651184)
[2025-01-30 02:01:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1712/107898 [09:22<9:00:07,  3.28it/s][2025-01-30 02:01:32][root][INFO] - Training Epoch: 1/2, step 1711/107898 completed (loss: 1.3057414293289185, acc: 0.6666666865348816)
[2025-01-30 02:01:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1713/107898 [09:23<9:27:49,  3.12it/s][2025-01-30 02:01:32][root][INFO] - Training Epoch: 1/2, step 1712/107898 completed (loss: 1.885698676109314, acc: 0.75)
[2025-01-30 02:01:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1714/107898 [09:23<9:22:41,  3.15it/s][2025-01-30 02:01:33][root][INFO] - Training Epoch: 1/2, step 1713/107898 completed (loss: 0.0495150126516819, acc: 1.0)
[2025-01-30 02:01:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1715/107898 [09:23<9:33:10,  3.09it/s][2025-01-30 02:01:33][root][INFO] - Training Epoch: 1/2, step 1714/107898 completed (loss: 1.1922165155410767, acc: 0.692307710647583)
[2025-01-30 02:01:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1716/107898 [09:23<9:19:36,  3.16it/s][2025-01-30 02:01:33][root][INFO] - Training Epoch: 1/2, step 1715/107898 completed (loss: 0.13257849216461182, acc: 1.0)
[2025-01-30 02:01:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1717/107898 [09:24<9:17:37,  3.17it/s][2025-01-30 02:01:34][root][INFO] - Training Epoch: 1/2, step 1716/107898 completed (loss: 1.1257060766220093, acc: 0.75)
[2025-01-30 02:01:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1718/107898 [09:24<9:05:08,  3.25it/s][2025-01-30 02:01:34][root][INFO] - Training Epoch: 1/2, step 1717/107898 completed (loss: 1.193016529083252, acc: 0.7333333492279053)
[2025-01-30 02:01:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1719/107898 [09:24<9:28:00,  3.12it/s][2025-01-30 02:01:34][root][INFO] - Training Epoch: 1/2, step 1718/107898 completed (loss: 1.5883597135543823, acc: 0.5)
[2025-01-30 02:01:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1720/107898 [09:25<9:16:19,  3.18it/s][2025-01-30 02:01:35][root][INFO] - Training Epoch: 1/2, step 1719/107898 completed (loss: 2.1516458988189697, acc: 0.6315789222717285)
[2025-01-30 02:01:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1721/107898 [09:25<9:13:30,  3.20it/s][2025-01-30 02:01:35][root][INFO] - Training Epoch: 1/2, step 1720/107898 completed (loss: 1.6131900548934937, acc: 0.5454545617103577)
[2025-01-30 02:01:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1722/107898 [09:25<9:21:38,  3.15it/s][2025-01-30 02:01:35][root][INFO] - Training Epoch: 1/2, step 1721/107898 completed (loss: 1.6469477415084839, acc: 0.8181818127632141)
[2025-01-30 02:01:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1723/107898 [09:26<9:47:13,  3.01it/s][2025-01-30 02:01:36][root][INFO] - Training Epoch: 1/2, step 1722/107898 completed (loss: 2.660942554473877, acc: 0.6363636255264282)
[2025-01-30 02:01:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1724/107898 [09:26<9:57:09,  2.96it/s][2025-01-30 02:01:36][root][INFO] - Training Epoch: 1/2, step 1723/107898 completed (loss: 0.5653139352798462, acc: 0.800000011920929)
[2025-01-30 02:01:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1725/107898 [09:26<10:03:50,  2.93it/s][2025-01-30 02:01:36][root][INFO] - Training Epoch: 1/2, step 1724/107898 completed (loss: 1.7194405794143677, acc: 0.6666666865348816)
[2025-01-30 02:01:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1726/107898 [09:27<10:12:37,  2.89it/s][2025-01-30 02:01:37][root][INFO] - Training Epoch: 1/2, step 1725/107898 completed (loss: 0.20814219117164612, acc: 1.0)
[2025-01-30 02:01:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1727/107898 [09:27<10:15:13,  2.88it/s][2025-01-30 02:01:37][root][INFO] - Training Epoch: 1/2, step 1726/107898 completed (loss: 0.889180600643158, acc: 0.9090909361839294)
[2025-01-30 02:01:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1728/107898 [09:27<9:52:46,  2.99it/s] [2025-01-30 02:01:37][root][INFO] - Training Epoch: 1/2, step 1727/107898 completed (loss: 0.43654003739356995, acc: 0.5)
[2025-01-30 02:01:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1729/107898 [09:28<10:09:48,  2.90it/s][2025-01-30 02:01:38][root][INFO] - Training Epoch: 1/2, step 1728/107898 completed (loss: 0.009566768072545528, acc: 1.0)
[2025-01-30 02:01:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1730/107898 [09:28<10:03:53,  2.93it/s][2025-01-30 02:01:38][root][INFO] - Training Epoch: 1/2, step 1729/107898 completed (loss: 0.9447750449180603, acc: 0.6666666865348816)
[2025-01-30 02:01:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1731/107898 [09:28<9:46:15,  3.02it/s] [2025-01-30 02:01:38][root][INFO] - Training Epoch: 1/2, step 1730/107898 completed (loss: 1.8595420122146606, acc: 0.6666666865348816)
[2025-01-30 02:01:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1732/107898 [09:29<9:33:47,  3.08it/s][2025-01-30 02:01:39][root][INFO] - Training Epoch: 1/2, step 1731/107898 completed (loss: 1.421291470527649, acc: 0.7037037014961243)
[2025-01-30 02:01:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1733/107898 [09:29<9:15:02,  3.19it/s][2025-01-30 02:01:39][root][INFO] - Training Epoch: 1/2, step 1732/107898 completed (loss: 0.20323507487773895, acc: 1.0)
[2025-01-30 02:01:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1734/107898 [09:29<9:13:26,  3.20it/s][2025-01-30 02:01:39][root][INFO] - Training Epoch: 1/2, step 1733/107898 completed (loss: 0.2949746251106262, acc: 0.9090909361839294)
[2025-01-30 02:01:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1735/107898 [09:30<8:44:15,  3.38it/s][2025-01-30 02:01:39][root][INFO] - Training Epoch: 1/2, step 1734/107898 completed (loss: 1.0355989933013916, acc: 0.5)
[2025-01-30 02:01:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1736/107898 [09:30<9:03:44,  3.25it/s][2025-01-30 02:01:40][root][INFO] - Training Epoch: 1/2, step 1735/107898 completed (loss: 1.069481611251831, acc: 0.8461538553237915)
[2025-01-30 02:01:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1737/107898 [09:30<8:53:39,  3.32it/s][2025-01-30 02:01:40][root][INFO] - Training Epoch: 1/2, step 1736/107898 completed (loss: 1.8736958503723145, acc: 0.6666666865348816)
[2025-01-30 02:01:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1738/107898 [09:31<8:58:46,  3.28it/s][2025-01-30 02:01:40][root][INFO] - Training Epoch: 1/2, step 1737/107898 completed (loss: 1.2018427848815918, acc: 0.807692289352417)
[2025-01-30 02:01:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1739/107898 [09:31<8:48:05,  3.35it/s][2025-01-30 02:01:41][root][INFO] - Training Epoch: 1/2, step 1738/107898 completed (loss: 0.017962491139769554, acc: 1.0)
[2025-01-30 02:01:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1740/107898 [09:31<8:53:41,  3.32it/s][2025-01-30 02:01:41][root][INFO] - Training Epoch: 1/2, step 1739/107898 completed (loss: 1.1440095901489258, acc: 0.800000011920929)
[2025-01-30 02:01:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1741/107898 [09:31<8:57:41,  3.29it/s][2025-01-30 02:01:41][root][INFO] - Training Epoch: 1/2, step 1740/107898 completed (loss: 1.9896396398544312, acc: 0.0)
[2025-01-30 02:01:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1742/107898 [09:32<9:30:14,  3.10it/s][2025-01-30 02:01:42][root][INFO] - Training Epoch: 1/2, step 1741/107898 completed (loss: 1.5279144048690796, acc: 0.8333333134651184)
[2025-01-30 02:01:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1743/107898 [09:32<9:29:32,  3.11it/s][2025-01-30 02:01:42][root][INFO] - Training Epoch: 1/2, step 1742/107898 completed (loss: 1.57205331325531, acc: 0.0)
[2025-01-30 02:01:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1744/107898 [09:33<9:50:21,  3.00it/s][2025-01-30 02:01:42][root][INFO] - Training Epoch: 1/2, step 1743/107898 completed (loss: 0.23058545589447021, acc: 1.0)
[2025-01-30 02:01:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1745/107898 [09:33<9:26:58,  3.12it/s][2025-01-30 02:01:43][root][INFO] - Training Epoch: 1/2, step 1744/107898 completed (loss: 0.6309005618095398, acc: 0.9166666865348816)
[2025-01-30 02:01:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1746/107898 [09:33<9:21:39,  3.15it/s][2025-01-30 02:01:43][root][INFO] - Training Epoch: 1/2, step 1745/107898 completed (loss: 0.4053579270839691, acc: 0.9090909361839294)
[2025-01-30 02:01:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1747/107898 [09:33<9:19:17,  3.16it/s][2025-01-30 02:01:43][root][INFO] - Training Epoch: 1/2, step 1746/107898 completed (loss: 0.8725616931915283, acc: 0.8333333134651184)
[2025-01-30 02:01:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1748/107898 [09:34<9:18:40,  3.17it/s][2025-01-30 02:01:44][root][INFO] - Training Epoch: 1/2, step 1747/107898 completed (loss: 2.7260615825653076, acc: 0.5)
[2025-01-30 02:01:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1749/107898 [09:34<9:41:13,  3.04it/s][2025-01-30 02:01:44][root][INFO] - Training Epoch: 1/2, step 1748/107898 completed (loss: 1.2680913209915161, acc: 0.6000000238418579)
[2025-01-30 02:01:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1750/107898 [09:34<9:38:10,  3.06it/s][2025-01-30 02:01:44][root][INFO] - Training Epoch: 1/2, step 1749/107898 completed (loss: 0.8694656491279602, acc: 0.800000011920929)
[2025-01-30 02:01:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1751/107898 [09:35<9:33:40,  3.08it/s][2025-01-30 02:01:45][root][INFO] - Training Epoch: 1/2, step 1750/107898 completed (loss: 0.5392076373100281, acc: 0.875)
[2025-01-30 02:01:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1752/107898 [09:35<9:24:09,  3.14it/s][2025-01-30 02:01:45][root][INFO] - Training Epoch: 1/2, step 1751/107898 completed (loss: 3.8400027751922607, acc: 0.5)
[2025-01-30 02:01:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1753/107898 [09:35<9:10:48,  3.21it/s][2025-01-30 02:01:45][root][INFO] - Training Epoch: 1/2, step 1752/107898 completed (loss: 0.9439972043037415, acc: 0.5)
[2025-01-30 02:01:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1754/107898 [09:36<8:49:30,  3.34it/s][2025-01-30 02:01:45][root][INFO] - Training Epoch: 1/2, step 1753/107898 completed (loss: 0.17728832364082336, acc: 1.0)
[2025-01-30 02:01:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1755/107898 [09:36<8:44:53,  3.37it/s][2025-01-30 02:01:46][root][INFO] - Training Epoch: 1/2, step 1754/107898 completed (loss: 0.19633962213993073, acc: 1.0)
[2025-01-30 02:01:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1756/107898 [09:36<8:47:25,  3.35it/s][2025-01-30 02:01:46][root][INFO] - Training Epoch: 1/2, step 1755/107898 completed (loss: 0.2767419219017029, acc: 0.8999999761581421)
[2025-01-30 02:01:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1757/107898 [09:37<9:08:40,  3.22it/s][2025-01-30 02:01:46][root][INFO] - Training Epoch: 1/2, step 1756/107898 completed (loss: 2.8736062049865723, acc: 0.44999998807907104)
[2025-01-30 02:01:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1758/107898 [09:37<9:03:13,  3.26it/s][2025-01-30 02:01:47][root][INFO] - Training Epoch: 1/2, step 1757/107898 completed (loss: 0.0015263822861015797, acc: 1.0)
[2025-01-30 02:01:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1759/107898 [09:37<8:38:31,  3.41it/s][2025-01-30 02:01:47][root][INFO] - Training Epoch: 1/2, step 1758/107898 completed (loss: 0.636962890625, acc: 0.8333333134651184)
[2025-01-30 02:01:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1760/107898 [09:37<8:26:32,  3.49it/s][2025-01-30 02:01:47][root][INFO] - Training Epoch: 1/2, step 1759/107898 completed (loss: 4.408515930175781, acc: 0.3333333432674408)
[2025-01-30 02:01:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1761/107898 [09:38<9:02:24,  3.26it/s][2025-01-30 02:01:48][root][INFO] - Training Epoch: 1/2, step 1760/107898 completed (loss: 0.0025982451625168324, acc: 1.0)
[2025-01-30 02:01:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1762/107898 [09:38<9:17:57,  3.17it/s][2025-01-30 02:01:48][root][INFO] - Training Epoch: 1/2, step 1761/107898 completed (loss: 1.2642335891723633, acc: 0.7142857313156128)
[2025-01-30 02:01:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1763/107898 [09:38<9:32:18,  3.09it/s][2025-01-30 02:01:48][root][INFO] - Training Epoch: 1/2, step 1762/107898 completed (loss: 0.16012108325958252, acc: 1.0)
[2025-01-30 02:01:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1764/107898 [09:39<9:34:29,  3.08it/s][2025-01-30 02:01:49][root][INFO] - Training Epoch: 1/2, step 1763/107898 completed (loss: 2.1859753131866455, acc: 0.5)
[2025-01-30 02:01:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1765/107898 [09:39<9:18:35,  3.17it/s][2025-01-30 02:01:49][root][INFO] - Training Epoch: 1/2, step 1764/107898 completed (loss: 0.02213173545897007, acc: 1.0)
[2025-01-30 02:01:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1766/107898 [09:39<9:34:26,  3.08it/s][2025-01-30 02:01:49][root][INFO] - Training Epoch: 1/2, step 1765/107898 completed (loss: 1.1622579097747803, acc: 0.9047619104385376)
[2025-01-30 02:01:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1767/107898 [09:40<9:30:48,  3.10it/s][2025-01-30 02:01:49][root][INFO] - Training Epoch: 1/2, step 1766/107898 completed (loss: 2.098449468612671, acc: 0.6315789222717285)
[2025-01-30 02:01:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1768/107898 [09:40<9:47:02,  3.01it/s][2025-01-30 02:01:50][root][INFO] - Training Epoch: 1/2, step 1767/107898 completed (loss: 1.0291340351104736, acc: 0.8999999761581421)
[2025-01-30 02:01:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1769/107898 [09:40<9:30:03,  3.10it/s][2025-01-30 02:01:50][root][INFO] - Training Epoch: 1/2, step 1768/107898 completed (loss: 0.7950029969215393, acc: 0.8064516186714172)
[2025-01-30 02:01:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1770/107898 [09:41<9:32:48,  3.09it/s][2025-01-30 02:01:50][root][INFO] - Training Epoch: 1/2, step 1769/107898 completed (loss: 0.10780102759599686, acc: 1.0)
[2025-01-30 02:01:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1771/107898 [09:41<9:19:30,  3.16it/s][2025-01-30 02:01:51][root][INFO] - Training Epoch: 1/2, step 1770/107898 completed (loss: 0.26111018657684326, acc: 1.0)
[2025-01-30 02:01:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1772/107898 [09:41<10:04:52,  2.92it/s][2025-01-30 02:01:51][root][INFO] - Training Epoch: 1/2, step 1771/107898 completed (loss: 1.0158106088638306, acc: 0.7931034564971924)
[2025-01-30 02:01:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1773/107898 [09:42<9:59:47,  2.95it/s] [2025-01-30 02:01:52][root][INFO] - Training Epoch: 1/2, step 1772/107898 completed (loss: 0.1493852436542511, acc: 1.0)
[2025-01-30 02:01:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1774/107898 [09:42<9:56:52,  2.96it/s][2025-01-30 02:01:52][root][INFO] - Training Epoch: 1/2, step 1773/107898 completed (loss: 0.12139903753995895, acc: 1.0)
[2025-01-30 02:01:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1775/107898 [09:42<9:53:03,  2.98it/s][2025-01-30 02:01:52][root][INFO] - Training Epoch: 1/2, step 1774/107898 completed (loss: 4.815698623657227, acc: 0.3333333432674408)
[2025-01-30 02:01:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1776/107898 [09:43<9:33:29,  3.08it/s][2025-01-30 02:01:52][root][INFO] - Training Epoch: 1/2, step 1775/107898 completed (loss: 1.998795986175537, acc: 0.5)
[2025-01-30 02:01:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1777/107898 [09:43<9:44:45,  3.02it/s][2025-01-30 02:01:53][root][INFO] - Training Epoch: 1/2, step 1776/107898 completed (loss: 1.219467043876648, acc: 0.8666666746139526)
[2025-01-30 02:01:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1778/107898 [09:43<9:47:13,  3.01it/s][2025-01-30 02:01:53][root][INFO] - Training Epoch: 1/2, step 1777/107898 completed (loss: 0.9320260882377625, acc: 0.8260869383811951)
[2025-01-30 02:01:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1779/107898 [09:44<9:44:51,  3.02it/s][2025-01-30 02:01:53][root][INFO] - Training Epoch: 1/2, step 1778/107898 completed (loss: 0.9189574122428894, acc: 0.7777777910232544)
[2025-01-30 02:01:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1780/107898 [09:44<9:48:46,  3.00it/s][2025-01-30 02:01:54][root][INFO] - Training Epoch: 1/2, step 1779/107898 completed (loss: 0.5516059994697571, acc: 0.8421052694320679)
[2025-01-30 02:01:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1781/107898 [09:44<9:26:09,  3.12it/s][2025-01-30 02:01:54][root][INFO] - Training Epoch: 1/2, step 1780/107898 completed (loss: 2.662468433380127, acc: 0.6666666865348816)
[2025-01-30 02:01:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1782/107898 [09:45<9:12:25,  3.20it/s][2025-01-30 02:01:54][root][INFO] - Training Epoch: 1/2, step 1781/107898 completed (loss: 0.9006466865539551, acc: 0.7142857313156128)
[2025-01-30 02:01:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1783/107898 [09:45<9:06:20,  3.24it/s][2025-01-30 02:01:55][root][INFO] - Training Epoch: 1/2, step 1782/107898 completed (loss: 2.2032861709594727, acc: 0.5)
[2025-01-30 02:01:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1784/107898 [09:45<9:04:44,  3.25it/s][2025-01-30 02:01:55][root][INFO] - Training Epoch: 1/2, step 1783/107898 completed (loss: 0.05730194225907326, acc: 1.0)
[2025-01-30 02:01:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1785/107898 [09:46<9:32:48,  3.09it/s][2025-01-30 02:01:55][root][INFO] - Training Epoch: 1/2, step 1784/107898 completed (loss: 2.065248966217041, acc: 0.5483871102333069)
[2025-01-30 02:01:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1786/107898 [09:46<9:58:59,  2.95it/s][2025-01-30 02:01:56][root][INFO] - Training Epoch: 1/2, step 1785/107898 completed (loss: 0.8000810146331787, acc: 0.8148148059844971)
[2025-01-30 02:01:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1787/107898 [09:46<9:45:54,  3.02it/s][2025-01-30 02:01:56][root][INFO] - Training Epoch: 1/2, step 1786/107898 completed (loss: 1.595977783203125, acc: 0.6666666865348816)
[2025-01-30 02:01:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1788/107898 [09:47<9:51:03,  2.99it/s][2025-01-30 02:01:56][root][INFO] - Training Epoch: 1/2, step 1787/107898 completed (loss: 0.37592604756355286, acc: 1.0)
[2025-01-30 02:01:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1789/107898 [09:47<10:22:14,  2.84it/s][2025-01-30 02:01:57][root][INFO] - Training Epoch: 1/2, step 1788/107898 completed (loss: 1.3920276165008545, acc: 0.5333333611488342)
[2025-01-30 02:01:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1790/107898 [09:47<10:12:44,  2.89it/s][2025-01-30 02:01:57][root][INFO] - Training Epoch: 1/2, step 1789/107898 completed (loss: 1.4339615106582642, acc: 0.75)
[2025-01-30 02:01:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1791/107898 [09:48<10:05:54,  2.92it/s][2025-01-30 02:01:57][root][INFO] - Training Epoch: 1/2, step 1790/107898 completed (loss: 2.2599382400512695, acc: 0.5)
[2025-01-30 02:01:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1792/107898 [09:48<9:57:58,  2.96it/s] [2025-01-30 02:01:58][root][INFO] - Training Epoch: 1/2, step 1791/107898 completed (loss: 0.9145634770393372, acc: 0.6666666865348816)
[2025-01-30 02:01:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1793/107898 [09:48<9:45:27,  3.02it/s][2025-01-30 02:01:58][root][INFO] - Training Epoch: 1/2, step 1792/107898 completed (loss: 2.0784153938293457, acc: 0.6000000238418579)
[2025-01-30 02:01:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1794/107898 [09:49<9:46:33,  3.01it/s][2025-01-30 02:01:58][root][INFO] - Training Epoch: 1/2, step 1793/107898 completed (loss: 0.012236392125487328, acc: 1.0)
[2025-01-30 02:01:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1795/107898 [09:49<9:37:23,  3.06it/s][2025-01-30 02:01:59][root][INFO] - Training Epoch: 1/2, step 1794/107898 completed (loss: 0.9723122119903564, acc: 0.6666666865348816)
[2025-01-30 02:01:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1796/107898 [09:49<9:29:48,  3.10it/s][2025-01-30 02:01:59][root][INFO] - Training Epoch: 1/2, step 1795/107898 completed (loss: 0.05201981961727142, acc: 1.0)
[2025-01-30 02:01:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1797/107898 [09:50<9:09:39,  3.22it/s][2025-01-30 02:01:59][root][INFO] - Training Epoch: 1/2, step 1796/107898 completed (loss: 2.8976569175720215, acc: 0.25)
[2025-01-30 02:01:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1798/107898 [09:50<9:08:03,  3.23it/s][2025-01-30 02:02:00][root][INFO] - Training Epoch: 1/2, step 1797/107898 completed (loss: 0.19251735508441925, acc: 1.0)
[2025-01-30 02:02:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1799/107898 [09:50<9:26:25,  3.12it/s][2025-01-30 02:02:00][root][INFO] - Training Epoch: 1/2, step 1798/107898 completed (loss: 0.0443023219704628, acc: 1.0)
[2025-01-30 02:02:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1800/107898 [09:51<9:30:13,  3.10it/s][2025-01-30 02:02:00][root][INFO] - Training Epoch: 1/2, step 1799/107898 completed (loss: 0.27926093339920044, acc: 1.0)
[2025-01-30 02:02:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1801/107898 [09:51<9:47:31,  3.01it/s][2025-01-30 02:02:01][root][INFO] - Training Epoch: 1/2, step 1800/107898 completed (loss: 0.045394908636808395, acc: 1.0)
[2025-01-30 02:02:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1802/107898 [09:51<9:55:07,  2.97it/s][2025-01-30 02:02:01][root][INFO] - Training Epoch: 1/2, step 1801/107898 completed (loss: 1.4731699228286743, acc: 0.7894737124443054)
[2025-01-30 02:02:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1803/107898 [09:52<10:00:06,  2.95it/s][2025-01-30 02:02:01][root][INFO] - Training Epoch: 1/2, step 1802/107898 completed (loss: 0.7577134966850281, acc: 0.8695651888847351)
[2025-01-30 02:02:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1804/107898 [09:52<9:46:01,  3.02it/s] [2025-01-30 02:02:02][root][INFO] - Training Epoch: 1/2, step 1803/107898 completed (loss: 1.9244643449783325, acc: 0.6666666865348816)
[2025-01-30 02:02:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1805/107898 [09:52<10:13:58,  2.88it/s][2025-01-30 02:02:02][root][INFO] - Training Epoch: 1/2, step 1804/107898 completed (loss: 1.1537104845046997, acc: 0.75)
[2025-01-30 02:02:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1806/107898 [09:53<10:06:48,  2.91it/s][2025-01-30 02:02:02][root][INFO] - Training Epoch: 1/2, step 1805/107898 completed (loss: 1.1266238689422607, acc: 0.6666666865348816)
[2025-01-30 02:02:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1807/107898 [09:53<10:22:10,  2.84it/s][2025-01-30 02:02:03][root][INFO] - Training Epoch: 1/2, step 1806/107898 completed (loss: 0.6767725944519043, acc: 0.8684210777282715)
[2025-01-30 02:02:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1808/107898 [09:53<10:01:01,  2.94it/s][2025-01-30 02:02:03][root][INFO] - Training Epoch: 1/2, step 1807/107898 completed (loss: 0.3682287931442261, acc: 0.875)
[2025-01-30 02:02:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1809/107898 [09:54<9:38:35,  3.06it/s] [2025-01-30 02:02:03][root][INFO] - Training Epoch: 1/2, step 1808/107898 completed (loss: 0.432750403881073, acc: 0.8571428656578064)
[2025-01-30 02:02:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1810/107898 [09:54<9:36:11,  3.07it/s][2025-01-30 02:02:04][root][INFO] - Training Epoch: 1/2, step 1809/107898 completed (loss: 0.8459623456001282, acc: 0.9090909361839294)
[2025-01-30 02:02:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1811/107898 [09:54<10:14:48,  2.88it/s][2025-01-30 02:02:04][root][INFO] - Training Epoch: 1/2, step 1810/107898 completed (loss: 1.0618388652801514, acc: 0.7777777910232544)
[2025-01-30 02:02:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1812/107898 [09:55<10:06:19,  2.92it/s][2025-01-30 02:02:04][root][INFO] - Training Epoch: 1/2, step 1811/107898 completed (loss: 0.032473620027303696, acc: 1.0)
[2025-01-30 02:02:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1813/107898 [09:55<10:11:46,  2.89it/s][2025-01-30 02:02:05][root][INFO] - Training Epoch: 1/2, step 1812/107898 completed (loss: 0.4387524127960205, acc: 0.6666666865348816)
[2025-01-30 02:02:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1814/107898 [09:55<10:02:14,  2.94it/s][2025-01-30 02:02:05][root][INFO] - Training Epoch: 1/2, step 1813/107898 completed (loss: 0.7363674640655518, acc: 0.5)
[2025-01-30 02:02:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1815/107898 [09:56<9:53:44,  2.98it/s] [2025-01-30 02:02:05][root][INFO] - Training Epoch: 1/2, step 1814/107898 completed (loss: 4.252972602844238, acc: 0.0)
[2025-01-30 02:02:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1816/107898 [09:56<9:42:49,  3.03it/s][2025-01-30 02:02:06][root][INFO] - Training Epoch: 1/2, step 1815/107898 completed (loss: 0.20109321177005768, acc: 1.0)
[2025-01-30 02:02:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1817/107898 [09:56<9:54:53,  2.97it/s][2025-01-30 02:02:06][root][INFO] - Training Epoch: 1/2, step 1816/107898 completed (loss: 2.171508312225342, acc: 0.6000000238418579)
[2025-01-30 02:02:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1818/107898 [09:57<9:55:50,  2.97it/s][2025-01-30 02:02:06][root][INFO] - Training Epoch: 1/2, step 1817/107898 completed (loss: 2.447645425796509, acc: 0.5714285969734192)
[2025-01-30 02:02:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1819/107898 [09:57<9:36:17,  3.07it/s][2025-01-30 02:02:07][root][INFO] - Training Epoch: 1/2, step 1818/107898 completed (loss: 0.9568399786949158, acc: 0.7692307829856873)
[2025-01-30 02:02:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1820/107898 [09:57<9:53:33,  2.98it/s][2025-01-30 02:02:07][root][INFO] - Training Epoch: 1/2, step 1819/107898 completed (loss: 1.401790976524353, acc: 0.75)
[2025-01-30 02:02:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1821/107898 [09:58<9:51:41,  2.99it/s][2025-01-30 02:02:07][root][INFO] - Training Epoch: 1/2, step 1820/107898 completed (loss: 1.5480337142944336, acc: 0.75)
[2025-01-30 02:02:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1822/107898 [09:58<9:45:27,  3.02it/s][2025-01-30 02:02:08][root][INFO] - Training Epoch: 1/2, step 1821/107898 completed (loss: 0.2606634199619293, acc: 0.800000011920929)
[2025-01-30 02:02:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1823/107898 [09:58<9:51:21,  2.99it/s][2025-01-30 02:02:08][root][INFO] - Training Epoch: 1/2, step 1822/107898 completed (loss: 0.03612383082509041, acc: 1.0)
[2025-01-30 02:02:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1824/107898 [09:59<9:50:31,  2.99it/s][2025-01-30 02:02:08][root][INFO] - Training Epoch: 1/2, step 1823/107898 completed (loss: 0.9614275097846985, acc: 0.800000011920929)
[2025-01-30 02:02:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1825/107898 [09:59<9:39:05,  3.05it/s][2025-01-30 02:02:09][root][INFO] - Training Epoch: 1/2, step 1824/107898 completed (loss: 0.18383729457855225, acc: 0.9411764740943909)
[2025-01-30 02:02:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1826/107898 [09:59<10:12:45,  2.89it/s][2025-01-30 02:02:09][root][INFO] - Training Epoch: 1/2, step 1825/107898 completed (loss: 1.599252700805664, acc: 0.6428571343421936)
[2025-01-30 02:02:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1827/107898 [10:00<10:29:54,  2.81it/s][2025-01-30 02:02:10][root][INFO] - Training Epoch: 1/2, step 1826/107898 completed (loss: 0.14947788417339325, acc: 1.0)
[2025-01-30 02:02:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1828/107898 [10:00<10:31:55,  2.80it/s][2025-01-30 02:02:10][root][INFO] - Training Epoch: 1/2, step 1827/107898 completed (loss: 2.9497997760772705, acc: 0.4166666567325592)
[2025-01-30 02:02:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1829/107898 [10:00<10:17:36,  2.86it/s][2025-01-30 02:02:10][root][INFO] - Training Epoch: 1/2, step 1828/107898 completed (loss: 0.8118473291397095, acc: 0.8500000238418579)
[2025-01-30 02:02:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1830/107898 [10:01<10:06:20,  2.92it/s][2025-01-30 02:02:11][root][INFO] - Training Epoch: 1/2, step 1829/107898 completed (loss: 3.9436371326446533, acc: 0.375)
[2025-01-30 02:02:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1831/107898 [10:01<10:10:26,  2.90it/s][2025-01-30 02:02:11][root][INFO] - Training Epoch: 1/2, step 1830/107898 completed (loss: 4.774200439453125, acc: 0.5)
[2025-01-30 02:02:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1832/107898 [10:01<10:08:12,  2.91it/s][2025-01-30 02:02:11][root][INFO] - Training Epoch: 1/2, step 1831/107898 completed (loss: 0.48082467913627625, acc: 0.8947368264198303)
[2025-01-30 02:02:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1833/107898 [10:02<9:53:32,  2.98it/s] [2025-01-30 02:02:12][root][INFO] - Training Epoch: 1/2, step 1832/107898 completed (loss: 0.14263513684272766, acc: 1.0)
[2025-01-30 02:02:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1834/107898 [10:02<9:59:25,  2.95it/s][2025-01-30 02:02:12][root][INFO] - Training Epoch: 1/2, step 1833/107898 completed (loss: 1.4543458223342896, acc: 0.75)
[2025-01-30 02:02:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1835/107898 [10:02<9:53:32,  2.98it/s][2025-01-30 02:02:12][root][INFO] - Training Epoch: 1/2, step 1834/107898 completed (loss: 0.13492855429649353, acc: 1.0)
[2025-01-30 02:02:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1836/107898 [10:03<9:52:54,  2.98it/s][2025-01-30 02:02:13][root][INFO] - Training Epoch: 1/2, step 1835/107898 completed (loss: 0.13084664940834045, acc: 1.0)
[2025-01-30 02:02:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1837/107898 [10:03<9:47:44,  3.01it/s][2025-01-30 02:02:13][root][INFO] - Training Epoch: 1/2, step 1836/107898 completed (loss: 0.05013497918844223, acc: 1.0)
[2025-01-30 02:02:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1838/107898 [10:03<9:51:52,  2.99it/s][2025-01-30 02:02:13][root][INFO] - Training Epoch: 1/2, step 1837/107898 completed (loss: 2.2743277549743652, acc: 0.625)
[2025-01-30 02:02:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1839/107898 [10:04<9:55:37,  2.97it/s][2025-01-30 02:02:14][root][INFO] - Training Epoch: 1/2, step 1838/107898 completed (loss: 2.826859712600708, acc: 0.5)
[2025-01-30 02:02:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1840/107898 [10:04<9:51:58,  2.99it/s][2025-01-30 02:02:14][root][INFO] - Training Epoch: 1/2, step 1839/107898 completed (loss: 1.587558388710022, acc: 0.7368420958518982)
[2025-01-30 02:02:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1841/107898 [10:04<9:55:54,  2.97it/s][2025-01-30 02:02:14][root][INFO] - Training Epoch: 1/2, step 1840/107898 completed (loss: 0.17438025772571564, acc: 1.0)
[2025-01-30 02:02:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1842/107898 [10:05<9:47:15,  3.01it/s][2025-01-30 02:02:15][root][INFO] - Training Epoch: 1/2, step 1841/107898 completed (loss: 1.1612623929977417, acc: 0.75)
[2025-01-30 02:02:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1843/107898 [10:05<9:29:20,  3.10it/s][2025-01-30 02:02:15][root][INFO] - Training Epoch: 1/2, step 1842/107898 completed (loss: 0.019629158079624176, acc: 1.0)
[2025-01-30 02:02:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1844/107898 [10:05<9:35:39,  3.07it/s][2025-01-30 02:02:15][root][INFO] - Training Epoch: 1/2, step 1843/107898 completed (loss: 1.347027063369751, acc: 0.699999988079071)
[2025-01-30 02:02:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1845/107898 [10:06<9:25:00,  3.13it/s][2025-01-30 02:02:15][root][INFO] - Training Epoch: 1/2, step 1844/107898 completed (loss: 0.4554979205131531, acc: 1.0)
[2025-01-30 02:02:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1846/107898 [10:06<9:22:40,  3.14it/s][2025-01-30 02:02:16][root][INFO] - Training Epoch: 1/2, step 1845/107898 completed (loss: 0.8156026601791382, acc: 0.8823529481887817)
[2025-01-30 02:02:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1847/107898 [10:06<9:12:32,  3.20it/s][2025-01-30 02:02:16][root][INFO] - Training Epoch: 1/2, step 1846/107898 completed (loss: 0.09550026059150696, acc: 1.0)
[2025-01-30 02:02:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1848/107898 [10:07<9:11:24,  3.21it/s][2025-01-30 02:02:16][root][INFO] - Training Epoch: 1/2, step 1847/107898 completed (loss: 0.10149157047271729, acc: 1.0)
[2025-01-30 02:02:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1849/107898 [10:07<9:07:44,  3.23it/s][2025-01-30 02:02:17][root][INFO] - Training Epoch: 1/2, step 1848/107898 completed (loss: 1.9597890377044678, acc: 0.6153846383094788)
[2025-01-30 02:02:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1850/107898 [10:07<9:07:21,  3.23it/s][2025-01-30 02:02:17][root][INFO] - Training Epoch: 1/2, step 1849/107898 completed (loss: 0.5031008124351501, acc: 1.0)
[2025-01-30 02:02:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1851/107898 [10:08<9:26:57,  3.12it/s][2025-01-30 02:02:17][root][INFO] - Training Epoch: 1/2, step 1850/107898 completed (loss: 0.24066099524497986, acc: 1.0)
[2025-01-30 02:02:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1852/107898 [10:08<9:24:39,  3.13it/s][2025-01-30 02:02:18][root][INFO] - Training Epoch: 1/2, step 1851/107898 completed (loss: 1.4805073738098145, acc: 0.7333333492279053)
[2025-01-30 02:02:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1853/107898 [10:08<9:14:56,  3.18it/s][2025-01-30 02:02:18][root][INFO] - Training Epoch: 1/2, step 1852/107898 completed (loss: 1.6756761074066162, acc: 0.692307710647583)
[2025-01-30 02:02:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1854/107898 [10:09<9:10:12,  3.21it/s][2025-01-30 02:02:18][root][INFO] - Training Epoch: 1/2, step 1853/107898 completed (loss: 4.679266929626465, acc: 0.3333333432674408)
[2025-01-30 02:02:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1855/107898 [10:09<9:14:39,  3.19it/s][2025-01-30 02:02:19][root][INFO] - Training Epoch: 1/2, step 1854/107898 completed (loss: 1.5175435543060303, acc: 0.75)
[2025-01-30 02:02:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1856/107898 [10:09<9:26:57,  3.12it/s][2025-01-30 02:02:19][root][INFO] - Training Epoch: 1/2, step 1855/107898 completed (loss: 0.26547515392303467, acc: 0.9090909361839294)
[2025-01-30 02:02:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1857/107898 [10:10<9:33:29,  3.08it/s][2025-01-30 02:02:19][root][INFO] - Training Epoch: 1/2, step 1856/107898 completed (loss: 0.14928779006004333, acc: 1.0)
[2025-01-30 02:02:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1858/107898 [10:10<9:51:29,  2.99it/s][2025-01-30 02:02:20][root][INFO] - Training Epoch: 1/2, step 1857/107898 completed (loss: 2.2456817626953125, acc: 0.6666666865348816)
[2025-01-30 02:02:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1859/107898 [10:10<10:04:31,  2.92it/s][2025-01-30 02:02:20][root][INFO] - Training Epoch: 1/2, step 1858/107898 completed (loss: 2.750993490219116, acc: 0.5333333611488342)
[2025-01-30 02:02:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1860/107898 [10:11<10:04:28,  2.92it/s][2025-01-30 02:02:20][root][INFO] - Training Epoch: 1/2, step 1859/107898 completed (loss: 1.193381667137146, acc: 0.6666666865348816)
[2025-01-30 02:02:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1861/107898 [10:11<9:50:54,  2.99it/s] [2025-01-30 02:02:21][root][INFO] - Training Epoch: 1/2, step 1860/107898 completed (loss: 0.25499990582466125, acc: 0.9090909361839294)
[2025-01-30 02:02:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1862/107898 [10:11<9:38:53,  3.05it/s][2025-01-30 02:02:21][root][INFO] - Training Epoch: 1/2, step 1861/107898 completed (loss: 4.240165710449219, acc: 0.6666666865348816)
[2025-01-30 02:02:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1863/107898 [10:12<9:39:14,  3.05it/s][2025-01-30 02:02:21][root][INFO] - Training Epoch: 1/2, step 1862/107898 completed (loss: 1.0456202030181885, acc: 0.7586206793785095)
[2025-01-30 02:02:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1864/107898 [10:12<9:28:18,  3.11it/s][2025-01-30 02:02:22][root][INFO] - Training Epoch: 1/2, step 1863/107898 completed (loss: 1.659988522529602, acc: 0.6666666865348816)
[2025-01-30 02:02:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1865/107898 [10:12<9:42:54,  3.03it/s][2025-01-30 02:02:22][root][INFO] - Training Epoch: 1/2, step 1864/107898 completed (loss: 0.674586832523346, acc: 0.8275862336158752)
[2025-01-30 02:02:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1866/107898 [10:13<10:07:22,  2.91it/s][2025-01-30 02:02:22][root][INFO] - Training Epoch: 1/2, step 1865/107898 completed (loss: 0.8202030062675476, acc: 0.7272727489471436)
[2025-01-30 02:02:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1867/107898 [10:13<9:56:48,  2.96it/s] [2025-01-30 02:02:23][root][INFO] - Training Epoch: 1/2, step 1866/107898 completed (loss: 0.0073529863730072975, acc: 1.0)
[2025-01-30 02:02:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1868/107898 [10:13<9:47:48,  3.01it/s][2025-01-30 02:02:23][root][INFO] - Training Epoch: 1/2, step 1867/107898 completed (loss: 0.11797074973583221, acc: 1.0)
[2025-01-30 02:02:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1869/107898 [10:14<9:40:34,  3.04it/s][2025-01-30 02:02:23][root][INFO] - Training Epoch: 1/2, step 1868/107898 completed (loss: 0.2161393165588379, acc: 0.9090909361839294)
[2025-01-30 02:02:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1870/107898 [10:14<9:45:06,  3.02it/s][2025-01-30 02:02:24][root][INFO] - Training Epoch: 1/2, step 1869/107898 completed (loss: 1.4269218444824219, acc: 0.5)
[2025-01-30 02:02:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1871/107898 [10:14<9:47:51,  3.01it/s][2025-01-30 02:02:24][root][INFO] - Training Epoch: 1/2, step 1870/107898 completed (loss: 1.5556344985961914, acc: 0.6666666865348816)
[2025-01-30 02:02:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1872/107898 [10:15<9:44:18,  3.02it/s][2025-01-30 02:02:24][root][INFO] - Training Epoch: 1/2, step 1871/107898 completed (loss: 1.288108468055725, acc: 0.8181818127632141)
[2025-01-30 02:02:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1873/107898 [10:15<10:05:02,  2.92it/s][2025-01-30 02:02:25][root][INFO] - Training Epoch: 1/2, step 1872/107898 completed (loss: 2.0149261951446533, acc: 0.6842105388641357)
[2025-01-30 02:02:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1874/107898 [10:15<10:01:39,  2.94it/s][2025-01-30 02:02:25][root][INFO] - Training Epoch: 1/2, step 1873/107898 completed (loss: 0.00985817052423954, acc: 1.0)
[2025-01-30 02:02:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1875/107898 [10:16<9:47:41,  3.01it/s] [2025-01-30 02:02:25][root][INFO] - Training Epoch: 1/2, step 1874/107898 completed (loss: 0.8071092963218689, acc: 0.8666666746139526)
[2025-01-30 02:02:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1876/107898 [10:16<9:43:33,  3.03it/s][2025-01-30 02:02:26][root][INFO] - Training Epoch: 1/2, step 1875/107898 completed (loss: 4.192778587341309, acc: 0.3333333432674408)
[2025-01-30 02:02:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1877/107898 [10:16<9:41:29,  3.04it/s][2025-01-30 02:02:26][root][INFO] - Training Epoch: 1/2, step 1876/107898 completed (loss: 4.838257312774658, acc: 0.2222222238779068)
[2025-01-30 02:02:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1878/107898 [10:17<9:37:38,  3.06it/s][2025-01-30 02:02:26][root][INFO] - Training Epoch: 1/2, step 1877/107898 completed (loss: 0.14742422103881836, acc: 1.0)
[2025-01-30 02:02:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1879/107898 [10:17<9:37:05,  3.06it/s][2025-01-30 02:02:27][root][INFO] - Training Epoch: 1/2, step 1878/107898 completed (loss: 0.2584075331687927, acc: 1.0)
[2025-01-30 02:02:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1880/107898 [10:17<10:04:22,  2.92it/s][2025-01-30 02:02:27][root][INFO] - Training Epoch: 1/2, step 1879/107898 completed (loss: 0.12821950018405914, acc: 1.0)
[2025-01-30 02:02:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1881/107898 [10:18<9:52:20,  2.98it/s] [2025-01-30 02:02:27][root][INFO] - Training Epoch: 1/2, step 1880/107898 completed (loss: 0.0383387990295887, acc: 1.0)
[2025-01-30 02:02:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1882/107898 [10:18<9:53:06,  2.98it/s][2025-01-30 02:02:28][root][INFO] - Training Epoch: 1/2, step 1881/107898 completed (loss: 0.309967577457428, acc: 0.95652174949646)
[2025-01-30 02:02:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1883/107898 [10:18<9:34:34,  3.08it/s][2025-01-30 02:02:28][root][INFO] - Training Epoch: 1/2, step 1882/107898 completed (loss: 0.7561560869216919, acc: 0.8846153616905212)
[2025-01-30 02:02:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1884/107898 [10:19<10:00:59,  2.94it/s][2025-01-30 02:02:28][root][INFO] - Training Epoch: 1/2, step 1883/107898 completed (loss: 0.951982855796814, acc: 0.8163265585899353)
[2025-01-30 02:02:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1885/107898 [10:19<9:42:07,  3.04it/s] [2025-01-30 02:02:29][root][INFO] - Training Epoch: 1/2, step 1884/107898 completed (loss: 1.1916675567626953, acc: 0.7857142686843872)
[2025-01-30 02:02:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1886/107898 [10:19<9:28:30,  3.11it/s][2025-01-30 02:02:29][root][INFO] - Training Epoch: 1/2, step 1885/107898 completed (loss: 0.015760235488414764, acc: 1.0)
[2025-01-30 02:02:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1887/107898 [10:20<9:48:17,  3.00it/s][2025-01-30 02:02:29][root][INFO] - Training Epoch: 1/2, step 1886/107898 completed (loss: 0.35376518964767456, acc: 0.930232584476471)
[2025-01-30 02:02:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1888/107898 [10:20<9:30:14,  3.10it/s][2025-01-30 02:02:30][root][INFO] - Training Epoch: 1/2, step 1887/107898 completed (loss: 2.304481029510498, acc: 0.5)
[2025-01-30 02:02:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1889/107898 [10:20<9:33:01,  3.08it/s][2025-01-30 02:02:30][root][INFO] - Training Epoch: 1/2, step 1888/107898 completed (loss: 0.2713542580604553, acc: 0.875)
[2025-01-30 02:02:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1890/107898 [10:20<9:47:43,  3.01it/s][2025-01-30 02:02:30][root][INFO] - Training Epoch: 1/2, step 1889/107898 completed (loss: 1.149499535560608, acc: 0.7142857313156128)
[2025-01-30 02:02:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1891/107898 [10:21<9:49:38,  3.00it/s][2025-01-30 02:02:31][root][INFO] - Training Epoch: 1/2, step 1890/107898 completed (loss: 0.7889866232872009, acc: 0.8571428656578064)
[2025-01-30 02:02:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1892/107898 [10:21<10:04:41,  2.92it/s][2025-01-30 02:02:31][root][INFO] - Training Epoch: 1/2, step 1891/107898 completed (loss: 0.612194299697876, acc: 0.8461538553237915)
[2025-01-30 02:02:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1893/107898 [10:22<9:49:53,  3.00it/s] [2025-01-30 02:02:31][root][INFO] - Training Epoch: 1/2, step 1892/107898 completed (loss: 0.6312887072563171, acc: 0.8571428656578064)
[2025-01-30 02:02:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1894/107898 [10:22<9:38:06,  3.06it/s][2025-01-30 02:02:32][root][INFO] - Training Epoch: 1/2, step 1893/107898 completed (loss: 1.9082698822021484, acc: 0.5)
[2025-01-30 02:02:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1895/107898 [10:22<9:46:11,  3.01it/s][2025-01-30 02:02:32][root][INFO] - Training Epoch: 1/2, step 1894/107898 completed (loss: 0.8358986973762512, acc: 0.8421052694320679)
[2025-01-30 02:02:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1896/107898 [10:22<9:28:31,  3.11it/s][2025-01-30 02:02:32][root][INFO] - Training Epoch: 1/2, step 1895/107898 completed (loss: 0.6900940537452698, acc: 0.75)
[2025-01-30 02:02:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1897/107898 [10:23<9:22:33,  3.14it/s][2025-01-30 02:02:33][root][INFO] - Training Epoch: 1/2, step 1896/107898 completed (loss: 0.4730571210384369, acc: 0.8999999761581421)
[2025-01-30 02:02:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1898/107898 [10:23<9:08:22,  3.22it/s][2025-01-30 02:02:33][root][INFO] - Training Epoch: 1/2, step 1897/107898 completed (loss: 2.964224100112915, acc: 0.0)
[2025-01-30 02:02:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1899/107898 [10:23<9:06:16,  3.23it/s][2025-01-30 02:02:33][root][INFO] - Training Epoch: 1/2, step 1898/107898 completed (loss: 1.7776685953140259, acc: 0.6190476417541504)
[2025-01-30 02:02:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1900/107898 [10:24<9:10:05,  3.21it/s][2025-01-30 02:02:33][root][INFO] - Training Epoch: 1/2, step 1899/107898 completed (loss: 1.0570021867752075, acc: 0.7647058963775635)
[2025-01-30 02:02:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1901/107898 [10:24<9:01:47,  3.26it/s][2025-01-30 02:02:34][root][INFO] - Training Epoch: 1/2, step 1900/107898 completed (loss: 1.01333749294281, acc: 0.8235294222831726)
[2025-01-30 02:02:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1902/107898 [10:24<9:32:42,  3.08it/s][2025-01-30 02:02:34][root][INFO] - Training Epoch: 1/2, step 1901/107898 completed (loss: 4.809001922607422, acc: 0.25)
[2025-01-30 02:02:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1903/107898 [10:25<9:29:00,  3.10it/s][2025-01-30 02:02:34][root][INFO] - Training Epoch: 1/2, step 1902/107898 completed (loss: 1.467736840248108, acc: 0.6666666865348816)
[2025-01-30 02:02:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1904/107898 [10:25<9:19:48,  3.16it/s][2025-01-30 02:02:35][root][INFO] - Training Epoch: 1/2, step 1903/107898 completed (loss: 6.618884563446045, acc: 0.5)
[2025-01-30 02:02:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1905/107898 [10:25<9:22:30,  3.14it/s][2025-01-30 02:02:35][root][INFO] - Training Epoch: 1/2, step 1904/107898 completed (loss: 1.657569169998169, acc: 0.761904776096344)
[2025-01-30 02:02:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1906/107898 [10:26<9:51:26,  2.99it/s][2025-01-30 02:02:35][root][INFO] - Training Epoch: 1/2, step 1905/107898 completed (loss: 2.4331142902374268, acc: 0.6666666865348816)
[2025-01-30 02:02:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1907/107898 [10:26<9:37:27,  3.06it/s][2025-01-30 02:02:36][root][INFO] - Training Epoch: 1/2, step 1906/107898 completed (loss: 0.6592528820037842, acc: 0.8999999761581421)
[2025-01-30 02:02:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1908/107898 [10:26<10:12:11,  2.89it/s][2025-01-30 02:02:36][root][INFO] - Training Epoch: 1/2, step 1907/107898 completed (loss: 1.1331621408462524, acc: 0.7916666865348816)
[2025-01-30 02:02:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1909/107898 [10:27<10:11:14,  2.89it/s][2025-01-30 02:02:36][root][INFO] - Training Epoch: 1/2, step 1908/107898 completed (loss: 1.138433575630188, acc: 0.6666666865348816)
[2025-01-30 02:02:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1910/107898 [10:27<9:55:06,  2.97it/s] [2025-01-30 02:02:37][root][INFO] - Training Epoch: 1/2, step 1909/107898 completed (loss: 1.3392131328582764, acc: 0.6666666865348816)
[2025-01-30 02:02:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1911/107898 [10:27<9:54:11,  2.97it/s][2025-01-30 02:02:37][root][INFO] - Training Epoch: 1/2, step 1910/107898 completed (loss: 0.7282583117485046, acc: 0.7916666865348816)
[2025-01-30 02:02:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1912/107898 [10:28<9:41:28,  3.04it/s][2025-01-30 02:02:37][root][INFO] - Training Epoch: 1/2, step 1911/107898 completed (loss: 0.46279627084732056, acc: 1.0)
[2025-01-30 02:02:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1913/107898 [10:28<9:26:00,  3.12it/s][2025-01-30 02:02:38][root][INFO] - Training Epoch: 1/2, step 1912/107898 completed (loss: 2.0458030700683594, acc: 0.5)
[2025-01-30 02:02:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1914/107898 [10:28<9:48:39,  3.00it/s][2025-01-30 02:02:38][root][INFO] - Training Epoch: 1/2, step 1913/107898 completed (loss: 2.183859348297119, acc: 0.6666666865348816)
[2025-01-30 02:02:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1915/107898 [10:29<9:47:35,  3.01it/s][2025-01-30 02:02:38][root][INFO] - Training Epoch: 1/2, step 1914/107898 completed (loss: 1.1417220830917358, acc: 0.692307710647583)
[2025-01-30 02:02:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1916/107898 [10:29<9:38:37,  3.05it/s][2025-01-30 02:02:39][root][INFO] - Training Epoch: 1/2, step 1915/107898 completed (loss: 0.4208229184150696, acc: 0.9130434989929199)
[2025-01-30 02:02:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1917/107898 [10:29<9:25:53,  3.12it/s][2025-01-30 02:02:39][root][INFO] - Training Epoch: 1/2, step 1916/107898 completed (loss: 0.8891755938529968, acc: 0.6666666865348816)
[2025-01-30 02:02:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1918/107898 [10:30<9:14:37,  3.18it/s][2025-01-30 02:02:39][root][INFO] - Training Epoch: 1/2, step 1917/107898 completed (loss: 1.0590213537216187, acc: 0.5)
[2025-01-30 02:02:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1919/107898 [10:30<9:10:28,  3.21it/s][2025-01-30 02:02:40][root][INFO] - Training Epoch: 1/2, step 1918/107898 completed (loss: 0.6790304183959961, acc: 1.0)
[2025-01-30 02:02:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1920/107898 [10:30<9:14:35,  3.18it/s][2025-01-30 02:02:40][root][INFO] - Training Epoch: 1/2, step 1919/107898 completed (loss: 3.2186098098754883, acc: 0.25)
[2025-01-30 02:02:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1921/107898 [10:31<9:25:21,  3.12it/s][2025-01-30 02:02:40][root][INFO] - Training Epoch: 1/2, step 1920/107898 completed (loss: 0.9918804168701172, acc: 0.8500000238418579)
[2025-01-30 02:02:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1922/107898 [10:31<9:32:24,  3.09it/s][2025-01-30 02:02:41][root][INFO] - Training Epoch: 1/2, step 1921/107898 completed (loss: 0.6751397252082825, acc: 0.8717948794364929)
[2025-01-30 02:02:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1923/107898 [10:31<8:59:56,  3.27it/s][2025-01-30 02:02:41][root][INFO] - Training Epoch: 1/2, step 1922/107898 completed (loss: 0.23641112446784973, acc: 1.0)
[2025-01-30 02:02:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1924/107898 [10:31<9:00:47,  3.27it/s][2025-01-30 02:02:41][root][INFO] - Training Epoch: 1/2, step 1923/107898 completed (loss: 1.3834010362625122, acc: 0.6666666865348816)
[2025-01-30 02:02:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1925/107898 [10:32<9:28:29,  3.11it/s][2025-01-30 02:02:42][root][INFO] - Training Epoch: 1/2, step 1924/107898 completed (loss: 1.404040813446045, acc: 0.625)
[2025-01-30 02:02:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1926/107898 [10:32<9:34:58,  3.07it/s][2025-01-30 02:02:42][root][INFO] - Training Epoch: 1/2, step 1925/107898 completed (loss: 2.804100275039673, acc: 0.3636363744735718)
[2025-01-30 02:02:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1927/107898 [10:32<9:22:15,  3.14it/s][2025-01-30 02:02:42][root][INFO] - Training Epoch: 1/2, step 1926/107898 completed (loss: 1.509385585784912, acc: 0.699999988079071)
[2025-01-30 02:02:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1928/107898 [10:33<9:33:48,  3.08it/s][2025-01-30 02:02:43][root][INFO] - Training Epoch: 1/2, step 1927/107898 completed (loss: 0.2368343025445938, acc: 0.875)
[2025-01-30 02:02:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1929/107898 [10:33<9:30:14,  3.10it/s][2025-01-30 02:02:43][root][INFO] - Training Epoch: 1/2, step 1928/107898 completed (loss: 0.17988288402557373, acc: 1.0)
[2025-01-30 02:02:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1930/107898 [10:33<9:35:10,  3.07it/s][2025-01-30 02:02:43][root][INFO] - Training Epoch: 1/2, step 1929/107898 completed (loss: 1.087484359741211, acc: 0.9333333373069763)
[2025-01-30 02:02:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1931/107898 [10:34<9:43:33,  3.03it/s][2025-01-30 02:02:44][root][INFO] - Training Epoch: 1/2, step 1930/107898 completed (loss: 0.474113792181015, acc: 0.8999999761581421)
[2025-01-30 02:02:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1932/107898 [10:34<9:29:16,  3.10it/s][2025-01-30 02:02:44][root][INFO] - Training Epoch: 1/2, step 1931/107898 completed (loss: 0.2912472188472748, acc: 1.0)
[2025-01-30 02:02:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1933/107898 [10:34<9:15:56,  3.18it/s][2025-01-30 02:02:44][root][INFO] - Training Epoch: 1/2, step 1932/107898 completed (loss: 0.18790173530578613, acc: 0.9333333373069763)
[2025-01-30 02:02:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1934/107898 [10:35<8:58:10,  3.28it/s][2025-01-30 02:02:44][root][INFO] - Training Epoch: 1/2, step 1933/107898 completed (loss: 0.47642841935157776, acc: 0.75)
[2025-01-30 02:02:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1935/107898 [10:35<8:56:45,  3.29it/s][2025-01-30 02:02:45][root][INFO] - Training Epoch: 1/2, step 1934/107898 completed (loss: 0.4785274565219879, acc: 0.8333333134651184)
[2025-01-30 02:02:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1936/107898 [10:35<8:56:01,  3.29it/s][2025-01-30 02:02:45][root][INFO] - Training Epoch: 1/2, step 1935/107898 completed (loss: 0.05951527878642082, acc: 1.0)
[2025-01-30 02:02:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1937/107898 [10:36<9:00:12,  3.27it/s][2025-01-30 02:02:45][root][INFO] - Training Epoch: 1/2, step 1936/107898 completed (loss: 1.1443272829055786, acc: 0.7142857313156128)
[2025-01-30 02:02:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1938/107898 [10:36<9:33:44,  3.08it/s][2025-01-30 02:02:46][root][INFO] - Training Epoch: 1/2, step 1937/107898 completed (loss: 1.1600407361984253, acc: 0.7333333492279053)
[2025-01-30 02:02:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1939/107898 [10:36<9:52:14,  2.98it/s][2025-01-30 02:02:46][root][INFO] - Training Epoch: 1/2, step 1938/107898 completed (loss: 0.5639238357543945, acc: 0.9230769276618958)
[2025-01-30 02:02:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1940/107898 [10:37<9:49:30,  3.00it/s][2025-01-30 02:02:46][root][INFO] - Training Epoch: 1/2, step 1939/107898 completed (loss: 2.1113829612731934, acc: 0.8333333134651184)
[2025-01-30 02:02:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1941/107898 [10:37<9:36:26,  3.06it/s][2025-01-30 02:02:47][root][INFO] - Training Epoch: 1/2, step 1940/107898 completed (loss: 2.0060722827911377, acc: 0.6111111044883728)
[2025-01-30 02:02:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1942/107898 [10:37<9:28:37,  3.11it/s][2025-01-30 02:02:47][root][INFO] - Training Epoch: 1/2, step 1941/107898 completed (loss: 0.14695727825164795, acc: 1.0)
[2025-01-30 02:02:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1943/107898 [10:38<9:44:42,  3.02it/s][2025-01-30 02:02:47][root][INFO] - Training Epoch: 1/2, step 1942/107898 completed (loss: 0.27099502086639404, acc: 0.9090909361839294)
[2025-01-30 02:02:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1944/107898 [10:38<9:31:40,  3.09it/s][2025-01-30 02:02:48][root][INFO] - Training Epoch: 1/2, step 1943/107898 completed (loss: 3.9802043437957764, acc: 0.25)
[2025-01-30 02:02:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1945/107898 [10:38<9:13:05,  3.19it/s][2025-01-30 02:02:48][root][INFO] - Training Epoch: 1/2, step 1944/107898 completed (loss: 2.4554903507232666, acc: 0.5)
[2025-01-30 02:02:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1946/107898 [10:39<9:18:33,  3.16it/s][2025-01-30 02:02:48][root][INFO] - Training Epoch: 1/2, step 1945/107898 completed (loss: 0.5221942663192749, acc: 0.8620689511299133)
[2025-01-30 02:02:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1947/107898 [10:39<9:09:34,  3.21it/s][2025-01-30 02:02:49][root][INFO] - Training Epoch: 1/2, step 1946/107898 completed (loss: 0.10425230115652084, acc: 1.0)
[2025-01-30 02:02:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1948/107898 [10:39<9:25:05,  3.12it/s][2025-01-30 02:02:49][root][INFO] - Training Epoch: 1/2, step 1947/107898 completed (loss: 1.7601919174194336, acc: 0.5)
[2025-01-30 02:02:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1949/107898 [10:40<9:44:06,  3.02it/s][2025-01-30 02:02:49][root][INFO] - Training Epoch: 1/2, step 1948/107898 completed (loss: 0.6893072724342346, acc: 0.9090909361839294)
[2025-01-30 02:02:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1950/107898 [10:40<9:56:36,  2.96it/s][2025-01-30 02:02:50][root][INFO] - Training Epoch: 1/2, step 1949/107898 completed (loss: 1.178909420967102, acc: 0.800000011920929)
[2025-01-30 02:02:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1951/107898 [10:40<10:07:17,  2.91it/s][2025-01-30 02:02:50][root][INFO] - Training Epoch: 1/2, step 1950/107898 completed (loss: 0.11009569466114044, acc: 1.0)
[2025-01-30 02:02:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1952/107898 [10:41<9:43:55,  3.02it/s] [2025-01-30 02:02:50][root][INFO] - Training Epoch: 1/2, step 1951/107898 completed (loss: 1.900469422340393, acc: 0.800000011920929)
[2025-01-30 02:02:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1953/107898 [10:41<9:29:15,  3.10it/s][2025-01-30 02:02:51][root][INFO] - Training Epoch: 1/2, step 1952/107898 completed (loss: 1.2000646591186523, acc: 0.0)
[2025-01-30 02:02:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1954/107898 [10:41<10:00:35,  2.94it/s][2025-01-30 02:02:51][root][INFO] - Training Epoch: 1/2, step 1953/107898 completed (loss: 2.78290057182312, acc: 0.5)
[2025-01-30 02:02:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1955/107898 [10:42<9:55:51,  2.96it/s] [2025-01-30 02:02:51][root][INFO] - Training Epoch: 1/2, step 1954/107898 completed (loss: 0.024362776428461075, acc: 1.0)
[2025-01-30 02:02:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1956/107898 [10:42<9:56:37,  2.96it/s][2025-01-30 02:02:52][root][INFO] - Training Epoch: 1/2, step 1955/107898 completed (loss: 1.758239507675171, acc: 0.6944444179534912)
[2025-01-30 02:02:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1957/107898 [10:42<9:33:43,  3.08it/s][2025-01-30 02:02:52][root][INFO] - Training Epoch: 1/2, step 1956/107898 completed (loss: 0.12955667078495026, acc: 1.0)
[2025-01-30 02:02:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1958/107898 [10:42<9:26:50,  3.11it/s][2025-01-30 02:02:52][root][INFO] - Training Epoch: 1/2, step 1957/107898 completed (loss: 3.4021613597869873, acc: 0.5)
[2025-01-30 02:02:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1959/107898 [10:43<9:22:48,  3.14it/s][2025-01-30 02:02:53][root][INFO] - Training Epoch: 1/2, step 1958/107898 completed (loss: 0.9538161158561707, acc: 0.8571428656578064)
[2025-01-30 02:02:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1960/107898 [10:43<9:30:44,  3.09it/s][2025-01-30 02:02:53][root][INFO] - Training Epoch: 1/2, step 1959/107898 completed (loss: 1.240552544593811, acc: 0.6666666865348816)
[2025-01-30 02:02:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1961/107898 [10:43<9:29:10,  3.10it/s][2025-01-30 02:02:53][root][INFO] - Training Epoch: 1/2, step 1960/107898 completed (loss: 1.1051981449127197, acc: 0.6666666865348816)
[2025-01-30 02:02:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1962/107898 [10:44<9:15:21,  3.18it/s][2025-01-30 02:02:54][root][INFO] - Training Epoch: 1/2, step 1961/107898 completed (loss: 0.8487564325332642, acc: 0.7142857313156128)
[2025-01-30 02:02:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1963/107898 [10:44<9:05:56,  3.23it/s][2025-01-30 02:02:54][root][INFO] - Training Epoch: 1/2, step 1962/107898 completed (loss: 0.7233918905258179, acc: 0.9130434989929199)
[2025-01-30 02:02:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1964/107898 [10:44<9:10:23,  3.21it/s][2025-01-30 02:02:54][root][INFO] - Training Epoch: 1/2, step 1963/107898 completed (loss: 2.043677806854248, acc: 0.7692307829856873)
[2025-01-30 02:02:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1965/107898 [10:45<9:23:50,  3.13it/s][2025-01-30 02:02:54][root][INFO] - Training Epoch: 1/2, step 1964/107898 completed (loss: 0.41445618867874146, acc: 0.5)
[2025-01-30 02:02:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1966/107898 [10:45<9:19:44,  3.15it/s][2025-01-30 02:02:55][root][INFO] - Training Epoch: 1/2, step 1965/107898 completed (loss: 1.4077097177505493, acc: 0.800000011920929)
[2025-01-30 02:02:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1967/107898 [10:45<9:20:25,  3.15it/s][2025-01-30 02:02:55][root][INFO] - Training Epoch: 1/2, step 1966/107898 completed (loss: 2.0227150917053223, acc: 0.6428571343421936)
[2025-01-30 02:02:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1968/107898 [10:46<10:02:45,  2.93it/s][2025-01-30 02:02:56][root][INFO] - Training Epoch: 1/2, step 1967/107898 completed (loss: 0.7600273489952087, acc: 0.774193525314331)
[2025-01-30 02:02:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1969/107898 [10:46<10:01:12,  2.94it/s][2025-01-30 02:02:56][root][INFO] - Training Epoch: 1/2, step 1968/107898 completed (loss: 3.231640577316284, acc: 0.4000000059604645)
[2025-01-30 02:02:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1970/107898 [10:46<10:17:02,  2.86it/s][2025-01-30 02:02:56][root][INFO] - Training Epoch: 1/2, step 1969/107898 completed (loss: 0.626062273979187, acc: 0.7777777910232544)
[2025-01-30 02:02:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1971/107898 [10:47<10:06:45,  2.91it/s][2025-01-30 02:02:57][root][INFO] - Training Epoch: 1/2, step 1970/107898 completed (loss: 0.3962724804878235, acc: 0.9090909361839294)
[2025-01-30 02:02:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1972/107898 [10:47<9:58:11,  2.95it/s] [2025-01-30 02:02:57][root][INFO] - Training Epoch: 1/2, step 1971/107898 completed (loss: 2.650786876678467, acc: 0.5)
[2025-01-30 02:02:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1973/107898 [10:47<9:57:43,  2.95it/s][2025-01-30 02:02:57][root][INFO] - Training Epoch: 1/2, step 1972/107898 completed (loss: 1.5010600090026855, acc: 0.6666666865348816)
[2025-01-30 02:02:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1974/107898 [10:48<9:45:01,  3.02it/s][2025-01-30 02:02:58][root][INFO] - Training Epoch: 1/2, step 1973/107898 completed (loss: 0.017369147390127182, acc: 1.0)
[2025-01-30 02:02:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1975/107898 [10:48<9:30:46,  3.09it/s][2025-01-30 02:02:58][root][INFO] - Training Epoch: 1/2, step 1974/107898 completed (loss: 3.3141050338745117, acc: 0.25)
[2025-01-30 02:02:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1976/107898 [10:48<9:14:42,  3.18it/s][2025-01-30 02:02:58][root][INFO] - Training Epoch: 1/2, step 1975/107898 completed (loss: 0.3400532305240631, acc: 0.8571428656578064)
[2025-01-30 02:02:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1977/107898 [10:49<9:24:21,  3.13it/s][2025-01-30 02:02:58][root][INFO] - Training Epoch: 1/2, step 1976/107898 completed (loss: 0.07114347815513611, acc: 1.0)
[2025-01-30 02:02:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1978/107898 [10:49<9:38:21,  3.05it/s][2025-01-30 02:02:59][root][INFO] - Training Epoch: 1/2, step 1977/107898 completed (loss: 1.3633003234863281, acc: 0.75)
[2025-01-30 02:02:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1979/107898 [10:49<9:32:29,  3.08it/s][2025-01-30 02:02:59][root][INFO] - Training Epoch: 1/2, step 1978/107898 completed (loss: 1.3467273712158203, acc: 0.7083333134651184)
[2025-01-30 02:02:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1980/107898 [10:50<9:17:52,  3.16it/s][2025-01-30 02:02:59][root][INFO] - Training Epoch: 1/2, step 1979/107898 completed (loss: 1.244896650314331, acc: 0.8461538553237915)
[2025-01-30 02:03:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1981/107898 [10:50<9:23:04,  3.14it/s][2025-01-30 02:03:00][root][INFO] - Training Epoch: 1/2, step 1980/107898 completed (loss: 0.023847855627536774, acc: 1.0)
[2025-01-30 02:03:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1982/107898 [10:50<9:18:30,  3.16it/s][2025-01-30 02:03:00][root][INFO] - Training Epoch: 1/2, step 1981/107898 completed (loss: 1.8607802391052246, acc: 0.6666666865348816)
[2025-01-30 02:03:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1983/107898 [10:51<9:43:36,  3.02it/s][2025-01-30 02:03:00][root][INFO] - Training Epoch: 1/2, step 1982/107898 completed (loss: 3.9305970668792725, acc: 0.3333333432674408)
[2025-01-30 02:03:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1984/107898 [10:51<9:52:56,  2.98it/s][2025-01-30 02:03:01][root][INFO] - Training Epoch: 1/2, step 1983/107898 completed (loss: 1.290191411972046, acc: 0.6785714030265808)
[2025-01-30 02:03:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1985/107898 [10:51<9:15:31,  3.18it/s][2025-01-30 02:03:01][root][INFO] - Training Epoch: 1/2, step 1984/107898 completed (loss: 0.06187242642045021, acc: 1.0)
[2025-01-30 02:03:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1986/107898 [10:52<9:18:31,  3.16it/s][2025-01-30 02:03:01][root][INFO] - Training Epoch: 1/2, step 1985/107898 completed (loss: 0.3599703013896942, acc: 0.9259259104728699)
[2025-01-30 02:03:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1987/107898 [10:52<9:06:46,  3.23it/s][2025-01-30 02:03:02][root][INFO] - Training Epoch: 1/2, step 1986/107898 completed (loss: 2.7873549461364746, acc: 0.5)
[2025-01-30 02:03:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1988/107898 [10:52<9:00:13,  3.27it/s][2025-01-30 02:03:02][root][INFO] - Training Epoch: 1/2, step 1987/107898 completed (loss: 1.860394835472107, acc: 0.550000011920929)
[2025-01-30 02:03:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1989/107898 [10:52<9:03:02,  3.25it/s][2025-01-30 02:03:02][root][INFO] - Training Epoch: 1/2, step 1988/107898 completed (loss: 2.37848162651062, acc: 0.625)
[2025-01-30 02:03:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1990/107898 [10:53<9:00:28,  3.27it/s][2025-01-30 02:03:03][root][INFO] - Training Epoch: 1/2, step 1989/107898 completed (loss: 0.11490823328495026, acc: 1.0)
[2025-01-30 02:03:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1991/107898 [10:53<9:29:47,  3.10it/s][2025-01-30 02:03:03][root][INFO] - Training Epoch: 1/2, step 1990/107898 completed (loss: 0.47200387716293335, acc: 1.0)
[2025-01-30 02:03:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1992/107898 [10:53<9:48:42,  3.00it/s][2025-01-30 02:03:03][root][INFO] - Training Epoch: 1/2, step 1991/107898 completed (loss: 0.6653822064399719, acc: 0.8666666746139526)
[2025-01-30 02:03:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1993/107898 [10:54<9:32:46,  3.08it/s][2025-01-30 02:03:04][root][INFO] - Training Epoch: 1/2, step 1992/107898 completed (loss: 0.009987312369048595, acc: 1.0)
[2025-01-30 02:03:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1994/107898 [10:54<9:37:09,  3.06it/s][2025-01-30 02:03:04][root][INFO] - Training Epoch: 1/2, step 1993/107898 completed (loss: 1.3885536193847656, acc: 0.692307710647583)
[2025-01-30 02:03:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1995/107898 [10:55<10:11:17,  2.89it/s][2025-01-30 02:03:04][root][INFO] - Training Epoch: 1/2, step 1994/107898 completed (loss: 1.6921732425689697, acc: 0.7142857313156128)
[2025-01-30 02:03:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1996/107898 [10:55<10:12:15,  2.88it/s][2025-01-30 02:03:05][root][INFO] - Training Epoch: 1/2, step 1995/107898 completed (loss: 1.5978144407272339, acc: 0.6739130616188049)
[2025-01-30 02:03:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1997/107898 [10:55<9:56:48,  2.96it/s] [2025-01-30 02:03:05][root][INFO] - Training Epoch: 1/2, step 1996/107898 completed (loss: 0.5907827615737915, acc: 0.8571428656578064)
[2025-01-30 02:03:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1998/107898 [10:55<9:39:18,  3.05it/s][2025-01-30 02:03:05][root][INFO] - Training Epoch: 1/2, step 1997/107898 completed (loss: 0.03708750009536743, acc: 1.0)
[2025-01-30 02:03:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 1999/107898 [10:56<9:21:12,  3.14it/s][2025-01-30 02:03:06][root][INFO] - Training Epoch: 1/2, step 1998/107898 completed (loss: 1.8104102611541748, acc: 0.5714285969734192)
[2025-01-30 02:03:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2000/107898 [10:56<9:08:34,  3.22it/s][2025-01-30 02:03:06][root][INFO] - Training Epoch: 1/2, step 1999/107898 completed (loss: 0.017686419188976288, acc: 1.0)
[2025-01-30 02:03:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2001/107898 [10:56<9:29:45,  3.10it/s][2025-01-30 02:03:06][root][INFO] - Training Epoch: 1/2, step 2000/107898 completed (loss: 2.0310370922088623, acc: 0.6666666865348816)
[2025-01-30 02:03:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2002/107898 [10:57<9:42:32,  3.03it/s][2025-01-30 02:03:07][root][INFO] - Training Epoch: 1/2, step 2001/107898 completed (loss: 0.013059263117611408, acc: 1.0)
[2025-01-30 02:03:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2003/107898 [10:57<9:40:22,  3.04it/s][2025-01-30 02:03:07][root][INFO] - Training Epoch: 1/2, step 2002/107898 completed (loss: 0.6170757412910461, acc: 0.8666666746139526)
[2025-01-30 02:03:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2004/107898 [10:57<9:44:55,  3.02it/s][2025-01-30 02:03:07][root][INFO] - Training Epoch: 1/2, step 2003/107898 completed (loss: 1.3011473417282104, acc: 0.7368420958518982)
[2025-01-30 02:03:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2005/107898 [10:58<9:34:41,  3.07it/s][2025-01-30 02:03:08][root][INFO] - Training Epoch: 1/2, step 2004/107898 completed (loss: 0.6368924379348755, acc: 0.8823529481887817)
[2025-01-30 02:03:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2006/107898 [10:58<9:20:30,  3.15it/s][2025-01-30 02:03:08][root][INFO] - Training Epoch: 1/2, step 2005/107898 completed (loss: 0.5111664533615112, acc: 0.875)
[2025-01-30 02:03:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2007/107898 [10:58<9:16:41,  3.17it/s][2025-01-30 02:03:08][root][INFO] - Training Epoch: 1/2, step 2006/107898 completed (loss: 0.8636857867240906, acc: 0.75)
[2025-01-30 02:03:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2008/107898 [10:59<9:04:00,  3.24it/s][2025-01-30 02:03:08][root][INFO] - Training Epoch: 1/2, step 2007/107898 completed (loss: 0.7472286224365234, acc: 0.875)
[2025-01-30 02:03:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2009/107898 [10:59<9:04:53,  3.24it/s][2025-01-30 02:03:09][root][INFO] - Training Epoch: 1/2, step 2008/107898 completed (loss: 0.0267992801964283, acc: 1.0)
[2025-01-30 02:03:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2010/107898 [10:59<9:06:37,  3.23it/s][2025-01-30 02:03:09][root][INFO] - Training Epoch: 1/2, step 2009/107898 completed (loss: 1.4455043077468872, acc: 0.6666666865348816)
[2025-01-30 02:03:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2011/107898 [11:00<8:59:12,  3.27it/s][2025-01-30 02:03:09][root][INFO] - Training Epoch: 1/2, step 2010/107898 completed (loss: 4.186761379241943, acc: 0.5)
[2025-01-30 02:03:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2012/107898 [11:00<9:06:40,  3.23it/s][2025-01-30 02:03:10][root][INFO] - Training Epoch: 1/2, step 2011/107898 completed (loss: 0.9633323550224304, acc: 0.8571428656578064)
[2025-01-30 02:03:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2013/107898 [11:00<9:45:27,  3.01it/s][2025-01-30 02:03:10][root][INFO] - Training Epoch: 1/2, step 2012/107898 completed (loss: 0.36523953080177307, acc: 0.9473684430122375)
[2025-01-30 02:03:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2014/107898 [11:01<9:57:15,  2.95it/s][2025-01-30 02:03:10][root][INFO] - Training Epoch: 1/2, step 2013/107898 completed (loss: 0.1573835164308548, acc: 0.95652174949646)
[2025-01-30 02:03:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2015/107898 [11:01<10:04:20,  2.92it/s][2025-01-30 02:03:11][root][INFO] - Training Epoch: 1/2, step 2014/107898 completed (loss: 0.2162153720855713, acc: 0.9545454382896423)
[2025-01-30 02:03:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2016/107898 [11:01<10:12:54,  2.88it/s][2025-01-30 02:03:11][root][INFO] - Training Epoch: 1/2, step 2015/107898 completed (loss: 0.2809630334377289, acc: 1.0)
[2025-01-30 02:03:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2017/107898 [11:02<9:52:13,  2.98it/s] [2025-01-30 02:03:11][root][INFO] - Training Epoch: 1/2, step 2016/107898 completed (loss: 0.376482218503952, acc: 1.0)
[2025-01-30 02:03:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2018/107898 [11:02<10:07:54,  2.90it/s][2025-01-30 02:03:12][root][INFO] - Training Epoch: 1/2, step 2017/107898 completed (loss: 0.022477636113762856, acc: 1.0)
[2025-01-30 02:03:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2019/107898 [11:02<9:43:16,  3.03it/s] [2025-01-30 02:03:12][root][INFO] - Training Epoch: 1/2, step 2018/107898 completed (loss: 0.7234554886817932, acc: 0.8333333134651184)
[2025-01-30 02:03:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2020/107898 [11:03<9:31:53,  3.09it/s][2025-01-30 02:03:12][root][INFO] - Training Epoch: 1/2, step 2019/107898 completed (loss: 0.41560235619544983, acc: 1.0)
[2025-01-30 02:03:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2021/107898 [11:03<9:19:12,  3.16it/s][2025-01-30 02:03:13][root][INFO] - Training Epoch: 1/2, step 2020/107898 completed (loss: 0.036152251064777374, acc: 1.0)
[2025-01-30 02:03:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2022/107898 [11:03<9:09:38,  3.21it/s][2025-01-30 02:03:13][root][INFO] - Training Epoch: 1/2, step 2021/107898 completed (loss: 0.5051485896110535, acc: 1.0)
[2025-01-30 02:03:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2023/107898 [11:04<9:07:02,  3.23it/s][2025-01-30 02:03:13][root][INFO] - Training Epoch: 1/2, step 2022/107898 completed (loss: 0.22633515298366547, acc: 0.9090909361839294)
[2025-01-30 02:03:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2024/107898 [11:04<9:45:21,  3.01it/s][2025-01-30 02:03:14][root][INFO] - Training Epoch: 1/2, step 2023/107898 completed (loss: 1.888252854347229, acc: 0.6585366129875183)
[2025-01-30 02:03:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2025/107898 [11:04<9:33:13,  3.08it/s][2025-01-30 02:03:14][root][INFO] - Training Epoch: 1/2, step 2024/107898 completed (loss: 0.1712317168712616, acc: 1.0)
[2025-01-30 02:03:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2026/107898 [11:05<9:20:37,  3.15it/s][2025-01-30 02:03:14][root][INFO] - Training Epoch: 1/2, step 2025/107898 completed (loss: 0.10620797425508499, acc: 1.0)
[2025-01-30 02:03:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2027/107898 [11:05<9:37:54,  3.05it/s][2025-01-30 02:03:15][root][INFO] - Training Epoch: 1/2, step 2026/107898 completed (loss: 1.3099600076675415, acc: 0.6875)
[2025-01-30 02:03:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2028/107898 [11:05<9:40:21,  3.04it/s][2025-01-30 02:03:15][root][INFO] - Training Epoch: 1/2, step 2027/107898 completed (loss: 0.8336078524589539, acc: 0.6666666865348816)
[2025-01-30 02:03:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2029/107898 [11:06<9:44:08,  3.02it/s][2025-01-30 02:03:15][root][INFO] - Training Epoch: 1/2, step 2028/107898 completed (loss: 1.633773684501648, acc: 0.7083333134651184)
[2025-01-30 02:03:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2030/107898 [11:06<9:24:32,  3.13it/s][2025-01-30 02:03:16][root][INFO] - Training Epoch: 1/2, step 2029/107898 completed (loss: 0.29471856355667114, acc: 1.0)
[2025-01-30 02:03:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2031/107898 [11:06<9:25:43,  3.12it/s][2025-01-30 02:03:16][root][INFO] - Training Epoch: 1/2, step 2030/107898 completed (loss: 0.24550041556358337, acc: 0.875)
[2025-01-30 02:03:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2032/107898 [11:06<9:27:39,  3.11it/s][2025-01-30 02:03:16][root][INFO] - Training Epoch: 1/2, step 2031/107898 completed (loss: 1.4834704399108887, acc: 0.3333333432674408)
[2025-01-30 02:03:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2033/107898 [11:07<9:33:06,  3.08it/s][2025-01-30 02:03:17][root][INFO] - Training Epoch: 1/2, step 2032/107898 completed (loss: 4.471035957336426, acc: 0.3333333432674408)
[2025-01-30 02:03:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2034/107898 [11:07<9:45:40,  3.01it/s][2025-01-30 02:03:17][root][INFO] - Training Epoch: 1/2, step 2033/107898 completed (loss: 4.365494251251221, acc: 0.5)
[2025-01-30 02:03:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2035/107898 [11:07<9:43:25,  3.02it/s][2025-01-30 02:03:17][root][INFO] - Training Epoch: 1/2, step 2034/107898 completed (loss: 0.18272751569747925, acc: 0.9090909361839294)
[2025-01-30 02:03:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2036/107898 [11:08<9:39:24,  3.05it/s][2025-01-30 02:03:18][root][INFO] - Training Epoch: 1/2, step 2035/107898 completed (loss: 1.3669058084487915, acc: 0.6153846383094788)
[2025-01-30 02:03:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2037/107898 [11:08<9:11:58,  3.20it/s][2025-01-30 02:03:18][root][INFO] - Training Epoch: 1/2, step 2036/107898 completed (loss: 2.8379769325256348, acc: 0.6000000238418579)
[2025-01-30 02:03:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2038/107898 [11:08<9:10:35,  3.20it/s][2025-01-30 02:03:18][root][INFO] - Training Epoch: 1/2, step 2037/107898 completed (loss: 0.06615425646305084, acc: 1.0)
[2025-01-30 02:03:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2039/107898 [11:09<9:27:11,  3.11it/s][2025-01-30 02:03:19][root][INFO] - Training Epoch: 1/2, step 2038/107898 completed (loss: 2.1003763675689697, acc: 0.6521739363670349)
[2025-01-30 02:03:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2040/107898 [11:09<9:24:39,  3.12it/s][2025-01-30 02:03:19][root][INFO] - Training Epoch: 1/2, step 2039/107898 completed (loss: 0.8322671055793762, acc: 0.6666666865348816)
[2025-01-30 02:03:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2041/107898 [11:09<9:28:21,  3.10it/s][2025-01-30 02:03:19][root][INFO] - Training Epoch: 1/2, step 2040/107898 completed (loss: 1.8336055278778076, acc: 0.6000000238418579)
[2025-01-30 02:03:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2042/107898 [11:10<9:54:32,  2.97it/s][2025-01-30 02:03:20][root][INFO] - Training Epoch: 1/2, step 2041/107898 completed (loss: 0.5921728610992432, acc: 0.807692289352417)
[2025-01-30 02:03:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2043/107898 [11:10<9:47:23,  3.00it/s][2025-01-30 02:03:20][root][INFO] - Training Epoch: 1/2, step 2042/107898 completed (loss: 1.5312309265136719, acc: 0.6842105388641357)
[2025-01-30 02:03:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2044/107898 [11:10<9:49:34,  2.99it/s][2025-01-30 02:03:20][root][INFO] - Training Epoch: 1/2, step 2043/107898 completed (loss: 0.736000657081604, acc: 0.699999988079071)
[2025-01-30 02:03:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2045/107898 [11:11<9:34:00,  3.07it/s][2025-01-30 02:03:21][root][INFO] - Training Epoch: 1/2, step 2044/107898 completed (loss: 1.0569742918014526, acc: 0.8181818127632141)
[2025-01-30 02:03:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2046/107898 [11:11<9:36:24,  3.06it/s][2025-01-30 02:03:21][root][INFO] - Training Epoch: 1/2, step 2045/107898 completed (loss: 0.3505178987979889, acc: 1.0)
[2025-01-30 02:03:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2047/107898 [11:11<9:27:11,  3.11it/s][2025-01-30 02:03:21][root][INFO] - Training Epoch: 1/2, step 2046/107898 completed (loss: 2.988477945327759, acc: 0.4444444477558136)
[2025-01-30 02:03:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2048/107898 [11:12<9:19:01,  3.16it/s][2025-01-30 02:03:21][root][INFO] - Training Epoch: 1/2, step 2047/107898 completed (loss: 0.5104783177375793, acc: 0.8571428656578064)
[2025-01-30 02:03:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2049/107898 [11:12<9:30:54,  3.09it/s][2025-01-30 02:03:22][root][INFO] - Training Epoch: 1/2, step 2048/107898 completed (loss: 0.02006075717508793, acc: 1.0)
[2025-01-30 02:03:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2050/107898 [11:12<9:32:13,  3.08it/s][2025-01-30 02:03:22][root][INFO] - Training Epoch: 1/2, step 2049/107898 completed (loss: 0.5949758887290955, acc: 0.9285714030265808)
[2025-01-30 02:03:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2051/107898 [11:13<9:20:40,  3.15it/s][2025-01-30 02:03:22][root][INFO] - Training Epoch: 1/2, step 2050/107898 completed (loss: 0.7162343263626099, acc: 0.9285714030265808)
[2025-01-30 02:03:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2052/107898 [11:13<9:42:04,  3.03it/s][2025-01-30 02:03:23][root][INFO] - Training Epoch: 1/2, step 2051/107898 completed (loss: 0.06360005587339401, acc: 1.0)
[2025-01-30 02:03:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2053/107898 [11:13<9:39:22,  3.04it/s][2025-01-30 02:03:23][root][INFO] - Training Epoch: 1/2, step 2052/107898 completed (loss: 0.7690863013267517, acc: 0.8148148059844971)
[2025-01-30 02:03:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2054/107898 [11:14<10:00:30,  2.94it/s][2025-01-30 02:03:23][root][INFO] - Training Epoch: 1/2, step 2053/107898 completed (loss: 0.38391000032424927, acc: 0.8846153616905212)
[2025-01-30 02:03:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2055/107898 [11:14<9:45:53,  3.01it/s] [2025-01-30 02:03:24][root][INFO] - Training Epoch: 1/2, step 2054/107898 completed (loss: 0.21786420047283173, acc: 0.95652174949646)
[2025-01-30 02:03:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2056/107898 [11:14<9:55:11,  2.96it/s][2025-01-30 02:03:24][root][INFO] - Training Epoch: 1/2, step 2055/107898 completed (loss: 0.41981545090675354, acc: 0.8666666746139526)
[2025-01-30 02:03:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2057/107898 [11:15<10:12:15,  2.88it/s][2025-01-30 02:03:25][root][INFO] - Training Epoch: 1/2, step 2056/107898 completed (loss: 0.6198306083679199, acc: 0.8947368264198303)
[2025-01-30 02:03:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2058/107898 [11:15<10:02:20,  2.93it/s][2025-01-30 02:03:25][root][INFO] - Training Epoch: 1/2, step 2057/107898 completed (loss: 0.6549457907676697, acc: 0.8666666746139526)
[2025-01-30 02:03:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2059/107898 [11:15<9:36:57,  3.06it/s] [2025-01-30 02:03:25][root][INFO] - Training Epoch: 1/2, step 2058/107898 completed (loss: 0.10819645971059799, acc: 1.0)
[2025-01-30 02:03:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2060/107898 [11:16<9:53:20,  2.97it/s][2025-01-30 02:03:25][root][INFO] - Training Epoch: 1/2, step 2059/107898 completed (loss: 1.7720345258712769, acc: 0.5806451439857483)
[2025-01-30 02:03:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2061/107898 [11:16<9:54:24,  2.97it/s][2025-01-30 02:03:26][root][INFO] - Training Epoch: 1/2, step 2060/107898 completed (loss: 0.9410337805747986, acc: 0.7222222089767456)
[2025-01-30 02:03:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2062/107898 [11:16<9:44:32,  3.02it/s][2025-01-30 02:03:26][root][INFO] - Training Epoch: 1/2, step 2061/107898 completed (loss: 1.173609972000122, acc: 0.7777777910232544)
[2025-01-30 02:03:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2063/107898 [11:17<9:53:20,  2.97it/s][2025-01-30 02:03:26][root][INFO] - Training Epoch: 1/2, step 2062/107898 completed (loss: 0.6244195699691772, acc: 0.8947368264198303)
[2025-01-30 02:03:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2064/107898 [11:17<9:51:28,  2.98it/s][2025-01-30 02:03:27][root][INFO] - Training Epoch: 1/2, step 2063/107898 completed (loss: 0.6242345571517944, acc: 0.8125)
[2025-01-30 02:03:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2065/107898 [11:17<9:56:24,  2.96it/s][2025-01-30 02:03:27][root][INFO] - Training Epoch: 1/2, step 2064/107898 completed (loss: 0.4888439476490021, acc: 0.9333333373069763)
[2025-01-30 02:03:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2066/107898 [11:18<10:02:20,  2.93it/s][2025-01-30 02:03:28][root][INFO] - Training Epoch: 1/2, step 2065/107898 completed (loss: 1.0824421644210815, acc: 0.6666666865348816)
[2025-01-30 02:03:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2067/107898 [11:18<10:17:26,  2.86it/s][2025-01-30 02:03:28][root][INFO] - Training Epoch: 1/2, step 2066/107898 completed (loss: 2.5287177562713623, acc: 0.5)
[2025-01-30 02:03:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2068/107898 [11:18<10:11:39,  2.88it/s][2025-01-30 02:03:28][root][INFO] - Training Epoch: 1/2, step 2067/107898 completed (loss: 0.03765321150422096, acc: 1.0)
[2025-01-30 02:03:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2069/107898 [11:19<9:57:36,  2.95it/s] [2025-01-30 02:03:29][root][INFO] - Training Epoch: 1/2, step 2068/107898 completed (loss: 1.158567190170288, acc: 0.699999988079071)
[2025-01-30 02:03:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2070/107898 [11:19<10:01:03,  2.93it/s][2025-01-30 02:03:29][root][INFO] - Training Epoch: 1/2, step 2069/107898 completed (loss: 1.2595428228378296, acc: 0.6666666865348816)
[2025-01-30 02:03:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2071/107898 [11:19<10:06:52,  2.91it/s][2025-01-30 02:03:29][root][INFO] - Training Epoch: 1/2, step 2070/107898 completed (loss: 1.8456947803497314, acc: 0.800000011920929)
[2025-01-30 02:03:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2072/107898 [11:20<9:49:34,  2.99it/s] [2025-01-30 02:03:30][root][INFO] - Training Epoch: 1/2, step 2071/107898 completed (loss: 0.04117793217301369, acc: 1.0)
[2025-01-30 02:03:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2073/107898 [11:20<9:36:39,  3.06it/s][2025-01-30 02:03:30][root][INFO] - Training Epoch: 1/2, step 2072/107898 completed (loss: 0.26775062084198, acc: 1.0)
[2025-01-30 02:03:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2074/107898 [11:20<9:48:21,  3.00it/s][2025-01-30 02:03:30][root][INFO] - Training Epoch: 1/2, step 2073/107898 completed (loss: 0.4159729778766632, acc: 0.939393937587738)
[2025-01-30 02:03:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2075/107898 [11:21<9:48:21,  3.00it/s][2025-01-30 02:03:31][root][INFO] - Training Epoch: 1/2, step 2074/107898 completed (loss: 0.009672665037214756, acc: 1.0)
[2025-01-30 02:03:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2076/107898 [11:21<9:50:25,  2.99it/s][2025-01-30 02:03:31][root][INFO] - Training Epoch: 1/2, step 2075/107898 completed (loss: 0.6628440022468567, acc: 0.8260869383811951)
[2025-01-30 02:03:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2077/107898 [11:21<10:02:14,  2.93it/s][2025-01-30 02:03:31][root][INFO] - Training Epoch: 1/2, step 2076/107898 completed (loss: 0.39964568614959717, acc: 0.9200000166893005)
[2025-01-30 02:03:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2078/107898 [11:22<10:12:57,  2.88it/s][2025-01-30 02:03:32][root][INFO] - Training Epoch: 1/2, step 2077/107898 completed (loss: 1.0044493675231934, acc: 0.8125)
[2025-01-30 02:03:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2079/107898 [11:22<10:05:14,  2.91it/s][2025-01-30 02:03:32][root][INFO] - Training Epoch: 1/2, step 2078/107898 completed (loss: 0.1576632559299469, acc: 1.0)
[2025-01-30 02:03:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2080/107898 [11:22<9:38:23,  3.05it/s] [2025-01-30 02:03:32][root][INFO] - Training Epoch: 1/2, step 2079/107898 completed (loss: 0.4858112335205078, acc: 0.8947368264198303)
[2025-01-30 02:03:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2081/107898 [11:23<9:24:54,  3.12it/s][2025-01-30 02:03:33][root][INFO] - Training Epoch: 1/2, step 2080/107898 completed (loss: 1.6581214666366577, acc: 0.5)
[2025-01-30 02:03:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2082/107898 [11:23<9:07:36,  3.22it/s][2025-01-30 02:03:33][root][INFO] - Training Epoch: 1/2, step 2081/107898 completed (loss: 1.153271198272705, acc: 0.0)
[2025-01-30 02:03:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2083/107898 [11:23<9:26:27,  3.11it/s][2025-01-30 02:03:33][root][INFO] - Training Epoch: 1/2, step 2082/107898 completed (loss: 1.875426173210144, acc: 0.5)
[2025-01-30 02:03:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2084/107898 [11:24<9:24:50,  3.12it/s][2025-01-30 02:03:33][root][INFO] - Training Epoch: 1/2, step 2083/107898 completed (loss: 3.5101985931396484, acc: 0.3333333432674408)
[2025-01-30 02:03:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2085/107898 [11:24<9:20:32,  3.15it/s][2025-01-30 02:03:34][root][INFO] - Training Epoch: 1/2, step 2084/107898 completed (loss: 0.022022049874067307, acc: 1.0)
[2025-01-30 02:03:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2086/107898 [11:24<9:23:45,  3.13it/s][2025-01-30 02:03:34][root][INFO] - Training Epoch: 1/2, step 2085/107898 completed (loss: 0.014472817070782185, acc: 1.0)
[2025-01-30 02:03:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2087/107898 [11:25<9:31:42,  3.08it/s][2025-01-30 02:03:34][root][INFO] - Training Epoch: 1/2, step 2086/107898 completed (loss: 1.483391523361206, acc: 0.6428571343421936)
[2025-01-30 02:03:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2088/107898 [11:25<9:23:22,  3.13it/s][2025-01-30 02:03:35][root][INFO] - Training Epoch: 1/2, step 2087/107898 completed (loss: 0.1328994780778885, acc: 1.0)
[2025-01-30 02:03:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2089/107898 [11:25<9:16:00,  3.17it/s][2025-01-30 02:03:35][root][INFO] - Training Epoch: 1/2, step 2088/107898 completed (loss: 0.1694605052471161, acc: 1.0)
[2025-01-30 02:03:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2090/107898 [11:26<9:10:46,  3.20it/s][2025-01-30 02:03:35][root][INFO] - Training Epoch: 1/2, step 2089/107898 completed (loss: 5.202857971191406, acc: 0.25)
[2025-01-30 02:03:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2091/107898 [11:26<9:04:54,  3.24it/s][2025-01-30 02:03:36][root][INFO] - Training Epoch: 1/2, step 2090/107898 completed (loss: 1.8872202634811401, acc: 0.3333333432674408)
[2025-01-30 02:03:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2092/107898 [11:26<9:04:07,  3.24it/s][2025-01-30 02:03:36][root][INFO] - Training Epoch: 1/2, step 2091/107898 completed (loss: 0.2985377609729767, acc: 1.0)
[2025-01-30 02:03:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2093/107898 [11:27<9:05:25,  3.23it/s][2025-01-30 02:03:36][root][INFO] - Training Epoch: 1/2, step 2092/107898 completed (loss: 0.011136803776025772, acc: 1.0)
[2025-01-30 02:03:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2094/107898 [11:27<8:59:18,  3.27it/s][2025-01-30 02:03:37][root][INFO] - Training Epoch: 1/2, step 2093/107898 completed (loss: 0.28822579979896545, acc: 0.9230769276618958)
[2025-01-30 02:03:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2095/107898 [11:27<9:15:43,  3.17it/s][2025-01-30 02:03:37][root][INFO] - Training Epoch: 1/2, step 2094/107898 completed (loss: 0.3015543818473816, acc: 0.8888888955116272)
[2025-01-30 02:03:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2096/107898 [11:27<9:27:24,  3.11it/s][2025-01-30 02:03:37][root][INFO] - Training Epoch: 1/2, step 2095/107898 completed (loss: 0.6665465831756592, acc: 1.0)
[2025-01-30 02:03:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2097/107898 [11:28<9:25:20,  3.12it/s][2025-01-30 02:03:38][root][INFO] - Training Epoch: 1/2, step 2096/107898 completed (loss: 0.011013654991984367, acc: 1.0)
[2025-01-30 02:03:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2098/107898 [11:28<9:25:34,  3.12it/s][2025-01-30 02:03:38][root][INFO] - Training Epoch: 1/2, step 2097/107898 completed (loss: 2.1463449001312256, acc: 0.6666666865348816)
[2025-01-30 02:03:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2099/107898 [11:28<9:31:03,  3.09it/s][2025-01-30 02:03:38][root][INFO] - Training Epoch: 1/2, step 2098/107898 completed (loss: 0.04749663546681404, acc: 1.0)
[2025-01-30 02:03:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2100/107898 [11:29<9:26:53,  3.11it/s][2025-01-30 02:03:39][root][INFO] - Training Epoch: 1/2, step 2099/107898 completed (loss: 0.9089590311050415, acc: 0.9230769276618958)
[2025-01-30 02:03:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2101/107898 [11:29<9:17:06,  3.17it/s][2025-01-30 02:03:39][root][INFO] - Training Epoch: 1/2, step 2100/107898 completed (loss: 0.01137605682015419, acc: 1.0)
[2025-01-30 02:03:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2102/107898 [11:29<9:01:17,  3.26it/s][2025-01-30 02:03:39][root][INFO] - Training Epoch: 1/2, step 2101/107898 completed (loss: 0.07447943836450577, acc: 1.0)
[2025-01-30 02:03:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2103/107898 [11:30<9:02:27,  3.25it/s][2025-01-30 02:03:39][root][INFO] - Training Epoch: 1/2, step 2102/107898 completed (loss: 0.8060165643692017, acc: 0.8095238208770752)
[2025-01-30 02:03:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2104/107898 [11:30<9:03:00,  3.25it/s][2025-01-30 02:03:40][root][INFO] - Training Epoch: 1/2, step 2103/107898 completed (loss: 0.5241956114768982, acc: 0.9166666865348816)
[2025-01-30 02:03:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2105/107898 [11:30<9:03:06,  3.25it/s][2025-01-30 02:03:40][root][INFO] - Training Epoch: 1/2, step 2104/107898 completed (loss: 3.8356287479400635, acc: 0.1666666716337204)
[2025-01-30 02:03:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2106/107898 [11:31<8:55:58,  3.29it/s][2025-01-30 02:03:40][root][INFO] - Training Epoch: 1/2, step 2105/107898 completed (loss: 1.194645643234253, acc: 0.7142857313156128)
[2025-01-30 02:03:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2107/107898 [11:31<9:00:07,  3.26it/s][2025-01-30 02:03:41][root][INFO] - Training Epoch: 1/2, step 2106/107898 completed (loss: 0.7799667119979858, acc: 0.5)
[2025-01-30 02:03:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2108/107898 [11:31<9:09:28,  3.21it/s][2025-01-30 02:03:41][root][INFO] - Training Epoch: 1/2, step 2107/107898 completed (loss: 0.8110427856445312, acc: 0.8947368264198303)
[2025-01-30 02:03:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2109/107898 [11:32<9:00:43,  3.26it/s][2025-01-30 02:03:41][root][INFO] - Training Epoch: 1/2, step 2108/107898 completed (loss: 0.303225040435791, acc: 0.9444444179534912)
[2025-01-30 02:03:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2110/107898 [11:32<8:59:51,  3.27it/s][2025-01-30 02:03:42][root][INFO] - Training Epoch: 1/2, step 2109/107898 completed (loss: 0.008947398513555527, acc: 1.0)
[2025-01-30 02:03:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2111/107898 [11:32<9:32:17,  3.08it/s][2025-01-30 02:03:42][root][INFO] - Training Epoch: 1/2, step 2110/107898 completed (loss: 0.0036628455854952335, acc: 1.0)
[2025-01-30 02:03:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2112/107898 [11:33<10:17:17,  2.86it/s][2025-01-30 02:03:42][root][INFO] - Training Epoch: 1/2, step 2111/107898 completed (loss: 1.3304170370101929, acc: 0.5)
[2025-01-30 02:03:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2113/107898 [11:33<10:06:39,  2.91it/s][2025-01-30 02:03:43][root][INFO] - Training Epoch: 1/2, step 2112/107898 completed (loss: 0.8641335964202881, acc: 0.7407407164573669)
[2025-01-30 02:03:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2114/107898 [11:33<10:21:31,  2.84it/s][2025-01-30 02:03:43][root][INFO] - Training Epoch: 1/2, step 2113/107898 completed (loss: 0.18013706803321838, acc: 1.0)
[2025-01-30 02:03:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2115/107898 [11:34<10:07:00,  2.90it/s][2025-01-30 02:03:43][root][INFO] - Training Epoch: 1/2, step 2114/107898 completed (loss: 6.862095832824707, acc: 0.25)
[2025-01-30 02:03:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2116/107898 [11:34<10:05:45,  2.91it/s][2025-01-30 02:03:44][root][INFO] - Training Epoch: 1/2, step 2115/107898 completed (loss: 0.29688864946365356, acc: 0.8695651888847351)
[2025-01-30 02:03:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2117/107898 [11:34<9:42:49,  3.02it/s] [2025-01-30 02:03:44][root][INFO] - Training Epoch: 1/2, step 2116/107898 completed (loss: 0.32290512323379517, acc: 0.9473684430122375)
[2025-01-30 02:03:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2118/107898 [11:35<9:21:14,  3.14it/s][2025-01-30 02:03:44][root][INFO] - Training Epoch: 1/2, step 2117/107898 completed (loss: 0.2384520322084427, acc: 0.8999999761581421)
[2025-01-30 02:03:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2119/107898 [11:35<9:07:13,  3.22it/s][2025-01-30 02:03:45][root][INFO] - Training Epoch: 1/2, step 2118/107898 completed (loss: 0.7062358856201172, acc: 0.8571428656578064)
[2025-01-30 02:03:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2120/107898 [11:35<9:05:48,  3.23it/s][2025-01-30 02:03:45][root][INFO] - Training Epoch: 1/2, step 2119/107898 completed (loss: 0.6767098903656006, acc: 0.8333333134651184)
[2025-01-30 02:03:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2121/107898 [11:35<9:15:54,  3.17it/s][2025-01-30 02:03:45][root][INFO] - Training Epoch: 1/2, step 2120/107898 completed (loss: 0.7041327953338623, acc: 0.5)
[2025-01-30 02:03:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2122/107898 [11:36<9:15:37,  3.17it/s][2025-01-30 02:03:46][root][INFO] - Training Epoch: 1/2, step 2121/107898 completed (loss: 0.7876158952713013, acc: 0.7857142686843872)
[2025-01-30 02:03:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2123/107898 [11:36<9:12:23,  3.19it/s][2025-01-30 02:03:46][root][INFO] - Training Epoch: 1/2, step 2122/107898 completed (loss: 3.2506511211395264, acc: 0.5)
[2025-01-30 02:03:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2124/107898 [11:36<9:04:39,  3.24it/s][2025-01-30 02:03:46][root][INFO] - Training Epoch: 1/2, step 2123/107898 completed (loss: 0.1407574862241745, acc: 1.0)
[2025-01-30 02:03:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2125/107898 [11:37<8:55:21,  3.29it/s][2025-01-30 02:03:46][root][INFO] - Training Epoch: 1/2, step 2124/107898 completed (loss: 1.9659345149993896, acc: 0.6666666865348816)
[2025-01-30 02:03:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2126/107898 [11:37<9:10:28,  3.20it/s][2025-01-30 02:03:47][root][INFO] - Training Epoch: 1/2, step 2125/107898 completed (loss: 0.806793212890625, acc: 0.800000011920929)
[2025-01-30 02:03:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2127/107898 [11:37<9:05:36,  3.23it/s][2025-01-30 02:03:47][root][INFO] - Training Epoch: 1/2, step 2126/107898 completed (loss: 0.24102407693862915, acc: 1.0)
[2025-01-30 02:03:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2128/107898 [11:38<9:00:35,  3.26it/s][2025-01-30 02:03:47][root][INFO] - Training Epoch: 1/2, step 2127/107898 completed (loss: 1.2228710651397705, acc: 0.7272727489471436)
[2025-01-30 02:03:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2129/107898 [11:38<8:50:43,  3.32it/s][2025-01-30 02:03:48][root][INFO] - Training Epoch: 1/2, step 2128/107898 completed (loss: 0.6152792572975159, acc: 0.6666666865348816)
[2025-01-30 02:03:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2130/107898 [11:38<9:19:36,  3.15it/s][2025-01-30 02:03:48][root][INFO] - Training Epoch: 1/2, step 2129/107898 completed (loss: 0.011871134862303734, acc: 1.0)
[2025-01-30 02:03:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2131/107898 [11:39<9:25:43,  3.12it/s][2025-01-30 02:03:48][root][INFO] - Training Epoch: 1/2, step 2130/107898 completed (loss: 2.113679885864258, acc: 0.6470588445663452)
[2025-01-30 02:03:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2132/107898 [11:39<9:27:50,  3.10it/s][2025-01-30 02:03:49][root][INFO] - Training Epoch: 1/2, step 2131/107898 completed (loss: 0.16090251505374908, acc: 1.0)
[2025-01-30 02:03:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2133/107898 [11:39<9:14:39,  3.18it/s][2025-01-30 02:03:49][root][INFO] - Training Epoch: 1/2, step 2132/107898 completed (loss: 2.2796738147735596, acc: 0.5)
[2025-01-30 02:03:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2134/107898 [11:40<9:07:21,  3.22it/s][2025-01-30 02:03:49][root][INFO] - Training Epoch: 1/2, step 2133/107898 completed (loss: 3.148092746734619, acc: 0.4444444477558136)
[2025-01-30 02:03:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2135/107898 [11:40<9:12:35,  3.19it/s][2025-01-30 02:03:50][root][INFO] - Training Epoch: 1/2, step 2134/107898 completed (loss: 3.446505308151245, acc: 0.1428571492433548)
[2025-01-30 02:03:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2136/107898 [11:40<9:06:11,  3.23it/s][2025-01-30 02:03:50][root][INFO] - Training Epoch: 1/2, step 2135/107898 completed (loss: 1.238405704498291, acc: 1.0)
[2025-01-30 02:03:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2137/107898 [11:40<8:54:12,  3.30it/s][2025-01-30 02:03:50][root][INFO] - Training Epoch: 1/2, step 2136/107898 completed (loss: 0.8780723214149475, acc: 0.782608687877655)
[2025-01-30 02:03:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2138/107898 [11:41<9:00:18,  3.26it/s][2025-01-30 02:03:51][root][INFO] - Training Epoch: 1/2, step 2137/107898 completed (loss: 0.5028479695320129, acc: 0.8571428656578064)
[2025-01-30 02:03:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2139/107898 [11:41<9:00:54,  3.26it/s][2025-01-30 02:03:51][root][INFO] - Training Epoch: 1/2, step 2138/107898 completed (loss: 1.3383997678756714, acc: 0.6666666865348816)
[2025-01-30 02:03:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2140/107898 [11:41<9:27:14,  3.11it/s][2025-01-30 02:03:51][root][INFO] - Training Epoch: 1/2, step 2139/107898 completed (loss: 0.2745535373687744, acc: 1.0)
[2025-01-30 02:03:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2141/107898 [11:42<9:35:28,  3.06it/s][2025-01-30 02:03:52][root][INFO] - Training Epoch: 1/2, step 2140/107898 completed (loss: 0.40149569511413574, acc: 0.8421052694320679)
[2025-01-30 02:03:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2142/107898 [11:42<9:30:34,  3.09it/s][2025-01-30 02:03:52][root][INFO] - Training Epoch: 1/2, step 2141/107898 completed (loss: 1.953694462776184, acc: 0.5)
[2025-01-30 02:03:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2143/107898 [11:42<9:23:40,  3.13it/s][2025-01-30 02:03:52][root][INFO] - Training Epoch: 1/2, step 2142/107898 completed (loss: 0.6226275563240051, acc: 0.875)
[2025-01-30 02:03:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2144/107898 [11:43<9:34:06,  3.07it/s][2025-01-30 02:03:53][root][INFO] - Training Epoch: 1/2, step 2143/107898 completed (loss: 1.8010443449020386, acc: 0.75)
[2025-01-30 02:03:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2145/107898 [11:43<9:44:49,  3.01it/s][2025-01-30 02:03:53][root][INFO] - Training Epoch: 1/2, step 2144/107898 completed (loss: 1.0413631200790405, acc: 0.7894737124443054)
[2025-01-30 02:03:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2146/107898 [11:43<9:34:07,  3.07it/s][2025-01-30 02:03:53][root][INFO] - Training Epoch: 1/2, step 2145/107898 completed (loss: 0.8474923968315125, acc: 0.800000011920929)
[2025-01-30 02:03:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2147/107898 [11:44<9:50:13,  2.99it/s][2025-01-30 02:03:54][root][INFO] - Training Epoch: 1/2, step 2146/107898 completed (loss: 3.213644504547119, acc: 0.20000000298023224)
[2025-01-30 02:03:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2148/107898 [11:44<9:59:04,  2.94it/s][2025-01-30 02:03:54][root][INFO] - Training Epoch: 1/2, step 2147/107898 completed (loss: 0.3723866939544678, acc: 0.9285714030265808)
[2025-01-30 02:03:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2149/107898 [11:44<9:40:40,  3.04it/s][2025-01-30 02:03:54][root][INFO] - Training Epoch: 1/2, step 2148/107898 completed (loss: 0.029916809871792793, acc: 1.0)
[2025-01-30 02:03:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2150/107898 [11:45<9:41:01,  3.03it/s][2025-01-30 02:03:55][root][INFO] - Training Epoch: 1/2, step 2149/107898 completed (loss: 3.080772876739502, acc: 0.2857142984867096)
[2025-01-30 02:03:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2151/107898 [11:45<9:48:13,  3.00it/s][2025-01-30 02:03:55][root][INFO] - Training Epoch: 1/2, step 2150/107898 completed (loss: 1.0854414701461792, acc: 0.7692307829856873)
[2025-01-30 02:03:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2152/107898 [11:45<9:50:47,  2.98it/s][2025-01-30 02:03:55][root][INFO] - Training Epoch: 1/2, step 2151/107898 completed (loss: 1.6073358058929443, acc: 0.6296296119689941)
[2025-01-30 02:03:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2153/107898 [11:46<9:51:12,  2.98it/s][2025-01-30 02:03:56][root][INFO] - Training Epoch: 1/2, step 2152/107898 completed (loss: 2.8584177494049072, acc: 0.4285714328289032)
[2025-01-30 02:03:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2154/107898 [11:46<9:43:42,  3.02it/s][2025-01-30 02:03:56][root][INFO] - Training Epoch: 1/2, step 2153/107898 completed (loss: 0.5923169255256653, acc: 0.7894737124443054)
[2025-01-30 02:03:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2155/107898 [11:46<9:53:41,  2.97it/s][2025-01-30 02:03:56][root][INFO] - Training Epoch: 1/2, step 2154/107898 completed (loss: 1.4054458141326904, acc: 0.7692307829856873)
[2025-01-30 02:03:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2156/107898 [11:47<9:27:24,  3.11it/s][2025-01-30 02:03:56][root][INFO] - Training Epoch: 1/2, step 2155/107898 completed (loss: 2.226398468017578, acc: 0.6521739363670349)
[2025-01-30 02:03:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2157/107898 [11:47<9:34:55,  3.07it/s][2025-01-30 02:03:57][root][INFO] - Training Epoch: 1/2, step 2156/107898 completed (loss: 0.8214466571807861, acc: 0.6666666865348816)
[2025-01-30 02:03:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2158/107898 [11:47<9:50:03,  2.99it/s][2025-01-30 02:03:57][root][INFO] - Training Epoch: 1/2, step 2157/107898 completed (loss: 0.9880338311195374, acc: 0.8181818127632141)
[2025-01-30 02:03:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2159/107898 [11:48<9:39:10,  3.04it/s][2025-01-30 02:03:57][root][INFO] - Training Epoch: 1/2, step 2158/107898 completed (loss: 0.4581305980682373, acc: 1.0)
[2025-01-30 02:03:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2160/107898 [11:48<9:45:31,  3.01it/s][2025-01-30 02:03:58][root][INFO] - Training Epoch: 1/2, step 2159/107898 completed (loss: 1.0443799495697021, acc: 0.8518518805503845)
[2025-01-30 02:03:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2161/107898 [11:48<9:53:16,  2.97it/s][2025-01-30 02:03:58][root][INFO] - Training Epoch: 1/2, step 2160/107898 completed (loss: 1.7813502550125122, acc: 0.7333333492279053)
[2025-01-30 02:03:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2162/107898 [11:49<9:49:37,  2.99it/s][2025-01-30 02:03:59][root][INFO] - Training Epoch: 1/2, step 2161/107898 completed (loss: 0.06563802808523178, acc: 1.0)
[2025-01-30 02:03:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2163/107898 [11:49<10:02:07,  2.93it/s][2025-01-30 02:03:59][root][INFO] - Training Epoch: 1/2, step 2162/107898 completed (loss: 1.8345441818237305, acc: 0.5714285969734192)
[2025-01-30 02:03:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2164/107898 [11:49<9:39:45,  3.04it/s] [2025-01-30 02:03:59][root][INFO] - Training Epoch: 1/2, step 2163/107898 completed (loss: 1.1358873844146729, acc: 0.7692307829856873)
[2025-01-30 02:03:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2165/107898 [11:50<9:26:22,  3.11it/s][2025-01-30 02:03:59][root][INFO] - Training Epoch: 1/2, step 2164/107898 completed (loss: 0.060752928256988525, acc: 1.0)
[2025-01-30 02:04:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2166/107898 [11:50<9:15:29,  3.17it/s][2025-01-30 02:04:00][root][INFO] - Training Epoch: 1/2, step 2165/107898 completed (loss: 0.27088233828544617, acc: 0.9285714030265808)
[2025-01-30 02:04:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2167/107898 [11:50<9:06:50,  3.22it/s][2025-01-30 02:04:00][root][INFO] - Training Epoch: 1/2, step 2166/107898 completed (loss: 1.161391258239746, acc: 0.807692289352417)
[2025-01-30 02:04:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2168/107898 [11:51<9:04:53,  3.23it/s][2025-01-30 02:04:00][root][INFO] - Training Epoch: 1/2, step 2167/107898 completed (loss: 1.386362910270691, acc: 0.7333333492279053)
[2025-01-30 02:04:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2169/107898 [11:51<8:59:01,  3.27it/s][2025-01-30 02:04:01][root][INFO] - Training Epoch: 1/2, step 2168/107898 completed (loss: 0.1692579835653305, acc: 1.0)
[2025-01-30 02:04:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2170/107898 [11:51<9:18:01,  3.16it/s][2025-01-30 02:04:01][root][INFO] - Training Epoch: 1/2, step 2169/107898 completed (loss: 2.8337695598602295, acc: 0.5555555820465088)
[2025-01-30 02:04:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2171/107898 [11:52<9:43:32,  3.02it/s][2025-01-30 02:04:01][root][INFO] - Training Epoch: 1/2, step 2170/107898 completed (loss: 2.75410795211792, acc: 0.0)
[2025-01-30 02:04:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2172/107898 [11:52<9:57:55,  2.95it/s][2025-01-30 02:04:02][root][INFO] - Training Epoch: 1/2, step 2171/107898 completed (loss: 0.04035933315753937, acc: 1.0)
[2025-01-30 02:04:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2173/107898 [11:52<9:43:37,  3.02it/s][2025-01-30 02:04:02][root][INFO] - Training Epoch: 1/2, step 2172/107898 completed (loss: 1.9207537174224854, acc: 0.625)
[2025-01-30 02:04:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2174/107898 [11:53<9:23:10,  3.13it/s][2025-01-30 02:04:02][root][INFO] - Training Epoch: 1/2, step 2173/107898 completed (loss: 1.5963441133499146, acc: 0.5)
[2025-01-30 02:04:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2175/107898 [11:53<9:20:23,  3.14it/s][2025-01-30 02:04:03][root][INFO] - Training Epoch: 1/2, step 2174/107898 completed (loss: 1.5410263538360596, acc: 0.6363636255264282)
[2025-01-30 02:04:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2176/107898 [11:53<9:27:27,  3.11it/s][2025-01-30 02:04:03][root][INFO] - Training Epoch: 1/2, step 2175/107898 completed (loss: 0.9434414505958557, acc: 0.7727272510528564)
[2025-01-30 02:04:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2177/107898 [11:54<9:39:24,  3.04it/s][2025-01-30 02:04:03][root][INFO] - Training Epoch: 1/2, step 2176/107898 completed (loss: 1.9395170211791992, acc: 0.5)
[2025-01-30 02:04:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2178/107898 [11:54<9:35:18,  3.06it/s][2025-01-30 02:04:04][root][INFO] - Training Epoch: 1/2, step 2177/107898 completed (loss: 3.049407720565796, acc: 0.5)
[2025-01-30 02:04:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2179/107898 [11:54<9:36:10,  3.06it/s][2025-01-30 02:04:04][root][INFO] - Training Epoch: 1/2, step 2178/107898 completed (loss: 0.12790179252624512, acc: 1.0)
[2025-01-30 02:04:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2180/107898 [11:55<9:31:11,  3.08it/s][2025-01-30 02:04:04][root][INFO] - Training Epoch: 1/2, step 2179/107898 completed (loss: 1.3479561805725098, acc: 0.6666666865348816)
[2025-01-30 02:04:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2181/107898 [11:55<9:25:02,  3.12it/s][2025-01-30 02:04:05][root][INFO] - Training Epoch: 1/2, step 2180/107898 completed (loss: 1.504608154296875, acc: 0.6111111044883728)
[2025-01-30 02:04:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2182/107898 [11:55<9:43:05,  3.02it/s][2025-01-30 02:04:05][root][INFO] - Training Epoch: 1/2, step 2181/107898 completed (loss: 1.149656891822815, acc: 0.699999988079071)
[2025-01-30 02:04:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2183/107898 [11:56<9:52:22,  2.97it/s][2025-01-30 02:04:05][root][INFO] - Training Epoch: 1/2, step 2182/107898 completed (loss: 2.246645927429199, acc: 0.6666666865348816)
[2025-01-30 02:04:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2184/107898 [11:56<9:40:00,  3.04it/s][2025-01-30 02:04:06][root][INFO] - Training Epoch: 1/2, step 2183/107898 completed (loss: 0.6290696859359741, acc: 0.8823529481887817)
[2025-01-30 02:04:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2185/107898 [11:56<10:00:12,  2.94it/s][2025-01-30 02:04:06][root][INFO] - Training Epoch: 1/2, step 2184/107898 completed (loss: 0.20918568968772888, acc: 0.9230769276618958)
[2025-01-30 02:04:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2186/107898 [11:57<9:58:04,  2.95it/s] [2025-01-30 02:04:06][root][INFO] - Training Epoch: 1/2, step 2185/107898 completed (loss: 0.6077601313591003, acc: 0.8999999761581421)
[2025-01-30 02:04:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2187/107898 [11:57<9:55:16,  2.96it/s][2025-01-30 02:04:07][root][INFO] - Training Epoch: 1/2, step 2186/107898 completed (loss: 1.3040990829467773, acc: 0.6499999761581421)
[2025-01-30 02:04:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2188/107898 [11:57<9:35:08,  3.06it/s][2025-01-30 02:04:07][root][INFO] - Training Epoch: 1/2, step 2187/107898 completed (loss: 1.9140490293502808, acc: 0.5882353186607361)
[2025-01-30 02:04:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2189/107898 [11:57<9:25:17,  3.12it/s][2025-01-30 02:04:07][root][INFO] - Training Epoch: 1/2, step 2188/107898 completed (loss: 0.03536531701683998, acc: 1.0)
[2025-01-30 02:04:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2190/107898 [11:58<9:29:29,  3.09it/s][2025-01-30 02:04:08][root][INFO] - Training Epoch: 1/2, step 2189/107898 completed (loss: 0.30309975147247314, acc: 0.9411764740943909)
[2025-01-30 02:04:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2191/107898 [11:58<9:37:25,  3.05it/s][2025-01-30 02:04:08][root][INFO] - Training Epoch: 1/2, step 2190/107898 completed (loss: 5.092317581176758, acc: 0.1818181872367859)
[2025-01-30 02:04:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2192/107898 [11:58<9:30:35,  3.09it/s][2025-01-30 02:04:08][root][INFO] - Training Epoch: 1/2, step 2191/107898 completed (loss: 0.008299944922327995, acc: 1.0)
[2025-01-30 02:04:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2193/107898 [11:59<9:49:18,  2.99it/s][2025-01-30 02:04:09][root][INFO] - Training Epoch: 1/2, step 2192/107898 completed (loss: 0.4463961720466614, acc: 0.8666666746139526)
[2025-01-30 02:04:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2194/107898 [11:59<9:51:18,  2.98it/s][2025-01-30 02:04:09][root][INFO] - Training Epoch: 1/2, step 2193/107898 completed (loss: 0.44286102056503296, acc: 0.9130434989929199)
[2025-01-30 02:04:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2195/107898 [11:59<9:29:42,  3.09it/s][2025-01-30 02:04:09][root][INFO] - Training Epoch: 1/2, step 2194/107898 completed (loss: 0.25725504755973816, acc: 1.0)
[2025-01-30 02:04:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2196/107898 [12:00<9:18:45,  3.15it/s][2025-01-30 02:04:10][root][INFO] - Training Epoch: 1/2, step 2195/107898 completed (loss: 1.7343240976333618, acc: 0.5)
[2025-01-30 02:04:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2197/107898 [12:00<9:02:20,  3.25it/s][2025-01-30 02:04:10][root][INFO] - Training Epoch: 1/2, step 2196/107898 completed (loss: 0.25070708990097046, acc: 0.6666666865348816)
[2025-01-30 02:04:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2198/107898 [12:00<9:08:53,  3.21it/s][2025-01-30 02:04:10][root][INFO] - Training Epoch: 1/2, step 2197/107898 completed (loss: 1.6128679513931274, acc: 0.6666666865348816)
[2025-01-30 02:04:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2199/107898 [12:01<9:17:56,  3.16it/s][2025-01-30 02:04:10][root][INFO] - Training Epoch: 1/2, step 2198/107898 completed (loss: 0.5162687301635742, acc: 0.6666666865348816)
[2025-01-30 02:04:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2200/107898 [12:01<9:51:52,  2.98it/s][2025-01-30 02:04:11][root][INFO] - Training Epoch: 1/2, step 2199/107898 completed (loss: 0.18217605352401733, acc: 0.9333333373069763)
[2025-01-30 02:04:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2201/107898 [12:01<9:43:20,  3.02it/s][2025-01-30 02:04:11][root][INFO] - Training Epoch: 1/2, step 2200/107898 completed (loss: 1.3389573097229004, acc: 0.8333333134651184)
[2025-01-30 02:04:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2202/107898 [12:02<9:40:21,  3.04it/s][2025-01-30 02:04:12][root][INFO] - Training Epoch: 1/2, step 2201/107898 completed (loss: 0.32324540615081787, acc: 0.8888888955116272)
[2025-01-30 02:04:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2203/107898 [12:02<9:54:25,  2.96it/s][2025-01-30 02:04:12][root][INFO] - Training Epoch: 1/2, step 2202/107898 completed (loss: 0.54569011926651, acc: 0.9166666865348816)
[2025-01-30 02:04:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2204/107898 [12:02<9:38:12,  3.05it/s][2025-01-30 02:04:12][root][INFO] - Training Epoch: 1/2, step 2203/107898 completed (loss: 0.7437352538108826, acc: 0.7916666865348816)
[2025-01-30 02:04:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2205/107898 [12:03<9:30:41,  3.09it/s][2025-01-30 02:04:12][root][INFO] - Training Epoch: 1/2, step 2204/107898 completed (loss: 1.2722620964050293, acc: 0.6666666865348816)
[2025-01-30 02:04:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2206/107898 [12:03<9:34:38,  3.07it/s][2025-01-30 02:04:13][root][INFO] - Training Epoch: 1/2, step 2205/107898 completed (loss: 0.07497205585241318, acc: 1.0)
[2025-01-30 02:04:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2207/107898 [12:03<9:15:46,  3.17it/s][2025-01-30 02:04:13][root][INFO] - Training Epoch: 1/2, step 2206/107898 completed (loss: 0.9899155497550964, acc: 0.5)
[2025-01-30 02:04:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2208/107898 [12:04<9:12:49,  3.19it/s][2025-01-30 02:04:13][root][INFO] - Training Epoch: 1/2, step 2207/107898 completed (loss: 1.5716429948806763, acc: 0.7272727489471436)
[2025-01-30 02:04:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2209/107898 [12:04<9:03:59,  3.24it/s][2025-01-30 02:04:14][root][INFO] - Training Epoch: 1/2, step 2208/107898 completed (loss: 0.04775987192988396, acc: 1.0)
[2025-01-30 02:04:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2210/107898 [12:04<8:54:28,  3.30it/s][2025-01-30 02:04:14][root][INFO] - Training Epoch: 1/2, step 2209/107898 completed (loss: 1.1468738317489624, acc: 0.8571428656578064)
[2025-01-30 02:04:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2211/107898 [12:05<8:55:57,  3.29it/s][2025-01-30 02:04:14][root][INFO] - Training Epoch: 1/2, step 2210/107898 completed (loss: 1.410862922668457, acc: 0.6666666865348816)
[2025-01-30 02:04:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2212/107898 [12:05<8:59:00,  3.27it/s][2025-01-30 02:04:15][root][INFO] - Training Epoch: 1/2, step 2211/107898 completed (loss: 0.1510857790708542, acc: 1.0)
[2025-01-30 02:04:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2213/107898 [12:05<9:08:25,  3.21it/s][2025-01-30 02:04:15][root][INFO] - Training Epoch: 1/2, step 2212/107898 completed (loss: 0.26615384221076965, acc: 1.0)
[2025-01-30 02:04:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2214/107898 [12:05<9:03:44,  3.24it/s][2025-01-30 02:04:15][root][INFO] - Training Epoch: 1/2, step 2213/107898 completed (loss: 0.6431624293327332, acc: 0.8333333134651184)
[2025-01-30 02:04:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2215/107898 [12:06<9:23:37,  3.13it/s][2025-01-30 02:04:16][root][INFO] - Training Epoch: 1/2, step 2214/107898 completed (loss: 1.119800329208374, acc: 0.7407407164573669)
[2025-01-30 02:04:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2216/107898 [12:06<9:11:11,  3.20it/s][2025-01-30 02:04:16][root][INFO] - Training Epoch: 1/2, step 2215/107898 completed (loss: 2.814664840698242, acc: 0.6666666865348816)
[2025-01-30 02:04:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2217/107898 [12:06<9:02:13,  3.25it/s][2025-01-30 02:04:16][root][INFO] - Training Epoch: 1/2, step 2216/107898 completed (loss: 0.8374262452125549, acc: 0.5)
[2025-01-30 02:04:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2218/107898 [12:07<9:23:35,  3.13it/s][2025-01-30 02:04:17][root][INFO] - Training Epoch: 1/2, step 2217/107898 completed (loss: 2.078733444213867, acc: 0.5)
[2025-01-30 02:04:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2219/107898 [12:07<9:27:01,  3.11it/s][2025-01-30 02:04:17][root][INFO] - Training Epoch: 1/2, step 2218/107898 completed (loss: 0.11701257526874542, acc: 0.9545454382896423)
[2025-01-30 02:04:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2220/107898 [12:07<9:15:14,  3.17it/s][2025-01-30 02:04:17][root][INFO] - Training Epoch: 1/2, step 2219/107898 completed (loss: 1.253891110420227, acc: 0.800000011920929)
[2025-01-30 02:04:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2221/107898 [12:08<9:14:34,  3.18it/s][2025-01-30 02:04:17][root][INFO] - Training Epoch: 1/2, step 2220/107898 completed (loss: 0.978512167930603, acc: 0.800000011920929)
[2025-01-30 02:04:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2222/107898 [12:08<9:02:41,  3.25it/s][2025-01-30 02:04:18][root][INFO] - Training Epoch: 1/2, step 2221/107898 completed (loss: 0.19000089168548584, acc: 0.9411764740943909)
[2025-01-30 02:04:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2223/107898 [12:08<9:31:21,  3.08it/s][2025-01-30 02:04:18][root][INFO] - Training Epoch: 1/2, step 2222/107898 completed (loss: 0.33515122532844543, acc: 0.9285714030265808)
[2025-01-30 02:04:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2224/107898 [12:09<9:38:08,  3.05it/s][2025-01-30 02:04:18][root][INFO] - Training Epoch: 1/2, step 2223/107898 completed (loss: 0.18905110657215118, acc: 0.8333333134651184)
[2025-01-30 02:04:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2225/107898 [12:09<9:44:32,  3.01it/s][2025-01-30 02:04:19][root][INFO] - Training Epoch: 1/2, step 2224/107898 completed (loss: 1.501307487487793, acc: 0.7058823704719543)
[2025-01-30 02:04:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2226/107898 [12:09<9:48:37,  2.99it/s][2025-01-30 02:04:19][root][INFO] - Training Epoch: 1/2, step 2225/107898 completed (loss: 0.6744134426116943, acc: 0.8636363744735718)
[2025-01-30 02:04:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2227/107898 [12:10<9:17:55,  3.16it/s][2025-01-30 02:04:19][root][INFO] - Training Epoch: 1/2, step 2226/107898 completed (loss: 0.491923451423645, acc: 0.8823529481887817)
[2025-01-30 02:04:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2228/107898 [12:10<9:23:58,  3.12it/s][2025-01-30 02:04:20][root][INFO] - Training Epoch: 1/2, step 2227/107898 completed (loss: 1.232587218284607, acc: 0.8095238208770752)
[2025-01-30 02:04:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2229/107898 [12:10<9:17:56,  3.16it/s][2025-01-30 02:04:20][root][INFO] - Training Epoch: 1/2, step 2228/107898 completed (loss: 1.444826602935791, acc: 0.6000000238418579)
[2025-01-30 02:04:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2230/107898 [12:11<9:00:57,  3.26it/s][2025-01-30 02:04:20][root][INFO] - Training Epoch: 1/2, step 2229/107898 completed (loss: 0.09163860231637955, acc: 1.0)
[2025-01-30 02:04:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2231/107898 [12:11<8:57:45,  3.27it/s][2025-01-30 02:04:21][root][INFO] - Training Epoch: 1/2, step 2230/107898 completed (loss: 1.697908639907837, acc: 0.0)
[2025-01-30 02:04:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2232/107898 [12:11<8:57:58,  3.27it/s][2025-01-30 02:04:21][root][INFO] - Training Epoch: 1/2, step 2231/107898 completed (loss: 0.3671486973762512, acc: 1.0)
[2025-01-30 02:04:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2233/107898 [12:11<8:57:40,  3.28it/s][2025-01-30 02:04:21][root][INFO] - Training Epoch: 1/2, step 2232/107898 completed (loss: 0.6220173835754395, acc: 0.7857142686843872)
[2025-01-30 02:04:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2234/107898 [12:12<9:07:32,  3.22it/s][2025-01-30 02:04:22][root][INFO] - Training Epoch: 1/2, step 2233/107898 completed (loss: 0.6409667134284973, acc: 0.8518518805503845)
[2025-01-30 02:04:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2235/107898 [12:12<8:59:56,  3.26it/s][2025-01-30 02:04:22][root][INFO] - Training Epoch: 1/2, step 2234/107898 completed (loss: 0.33598971366882324, acc: 0.875)
[2025-01-30 02:04:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2236/107898 [12:12<9:09:22,  3.21it/s][2025-01-30 02:04:22][root][INFO] - Training Epoch: 1/2, step 2235/107898 completed (loss: 1.3916034698486328, acc: 0.8333333134651184)
[2025-01-30 02:04:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2237/107898 [12:13<9:14:58,  3.17it/s][2025-01-30 02:04:23][root][INFO] - Training Epoch: 1/2, step 2236/107898 completed (loss: 0.49942588806152344, acc: 0.807692289352417)
[2025-01-30 02:04:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2238/107898 [12:13<9:02:28,  3.25it/s][2025-01-30 02:04:23][root][INFO] - Training Epoch: 1/2, step 2237/107898 completed (loss: 1.455603003501892, acc: 0.5)
[2025-01-30 02:04:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2239/107898 [12:13<8:58:11,  3.27it/s][2025-01-30 02:04:23][root][INFO] - Training Epoch: 1/2, step 2238/107898 completed (loss: 0.3110991418361664, acc: 0.8999999761581421)
[2025-01-30 02:04:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2240/107898 [12:14<9:07:13,  3.22it/s][2025-01-30 02:04:23][root][INFO] - Training Epoch: 1/2, step 2239/107898 completed (loss: 0.9024339914321899, acc: 0.807692289352417)
[2025-01-30 02:04:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2241/107898 [12:14<9:00:25,  3.26it/s][2025-01-30 02:04:24][root][INFO] - Training Epoch: 1/2, step 2240/107898 completed (loss: 0.06611556559801102, acc: 1.0)
[2025-01-30 02:04:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2242/107898 [12:14<9:02:19,  3.25it/s][2025-01-30 02:04:24][root][INFO] - Training Epoch: 1/2, step 2241/107898 completed (loss: 1.112243413925171, acc: 0.8235294222831726)
[2025-01-30 02:04:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2243/107898 [12:15<9:16:08,  3.17it/s][2025-01-30 02:04:24][root][INFO] - Training Epoch: 1/2, step 2242/107898 completed (loss: 1.1160081624984741, acc: 0.7647058963775635)
[2025-01-30 02:04:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2244/107898 [12:15<9:24:10,  3.12it/s][2025-01-30 02:04:25][root][INFO] - Training Epoch: 1/2, step 2243/107898 completed (loss: 0.36057788133621216, acc: 1.0)
[2025-01-30 02:04:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2245/107898 [12:15<9:25:13,  3.12it/s][2025-01-30 02:04:25][root][INFO] - Training Epoch: 1/2, step 2244/107898 completed (loss: 0.7953820824623108, acc: 0.8064516186714172)
[2025-01-30 02:04:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2246/107898 [12:16<9:32:04,  3.08it/s][2025-01-30 02:04:25][root][INFO] - Training Epoch: 1/2, step 2245/107898 completed (loss: 1.3289523124694824, acc: 0.6666666865348816)
[2025-01-30 02:04:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2247/107898 [12:16<9:47:00,  3.00it/s][2025-01-30 02:04:26][root][INFO] - Training Epoch: 1/2, step 2246/107898 completed (loss: 3.301764488220215, acc: 0.3333333432674408)
[2025-01-30 02:04:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2248/107898 [12:16<9:45:16,  3.01it/s][2025-01-30 02:04:26][root][INFO] - Training Epoch: 1/2, step 2247/107898 completed (loss: 3.0531208515167236, acc: 0.6666666865348816)
[2025-01-30 02:04:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2249/107898 [12:17<9:29:41,  3.09it/s][2025-01-30 02:04:26][root][INFO] - Training Epoch: 1/2, step 2248/107898 completed (loss: 2.5730178356170654, acc: 0.8333333134651184)
[2025-01-30 02:04:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2250/107898 [12:17<9:21:01,  3.14it/s][2025-01-30 02:04:27][root][INFO] - Training Epoch: 1/2, step 2249/107898 completed (loss: 3.351090669631958, acc: 0.3333333432674408)
[2025-01-30 02:04:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2251/107898 [12:17<9:44:05,  3.01it/s][2025-01-30 02:04:27][root][INFO] - Training Epoch: 1/2, step 2250/107898 completed (loss: 0.2466287463903427, acc: 1.0)
[2025-01-30 02:04:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2252/107898 [12:18<9:41:49,  3.03it/s][2025-01-30 02:04:27][root][INFO] - Training Epoch: 1/2, step 2251/107898 completed (loss: 2.5159389972686768, acc: 0.5555555820465088)
[2025-01-30 02:04:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2253/107898 [12:18<9:29:38,  3.09it/s][2025-01-30 02:04:28][root][INFO] - Training Epoch: 1/2, step 2252/107898 completed (loss: 5.627662181854248, acc: 0.25)
[2025-01-30 02:04:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2254/107898 [12:18<9:25:28,  3.11it/s][2025-01-30 02:04:28][root][INFO] - Training Epoch: 1/2, step 2253/107898 completed (loss: 0.27931174635887146, acc: 0.96875)
[2025-01-30 02:04:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2255/107898 [12:18<9:20:19,  3.14it/s][2025-01-30 02:04:28][root][INFO] - Training Epoch: 1/2, step 2254/107898 completed (loss: 0.6602362394332886, acc: 0.8571428656578064)
[2025-01-30 02:04:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2256/107898 [12:19<9:04:03,  3.24it/s][2025-01-30 02:04:29][root][INFO] - Training Epoch: 1/2, step 2255/107898 completed (loss: 2.500239372253418, acc: 0.5)
[2025-01-30 02:04:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2257/107898 [12:19<9:04:24,  3.23it/s][2025-01-30 02:04:29][root][INFO] - Training Epoch: 1/2, step 2256/107898 completed (loss: 1.66891348361969, acc: 0.625)
[2025-01-30 02:04:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2258/107898 [12:19<9:16:54,  3.16it/s][2025-01-30 02:04:29][root][INFO] - Training Epoch: 1/2, step 2257/107898 completed (loss: 0.3290645182132721, acc: 1.0)
[2025-01-30 02:04:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2259/107898 [12:20<9:25:10,  3.12it/s][2025-01-30 02:04:30][root][INFO] - Training Epoch: 1/2, step 2258/107898 completed (loss: 5.061346530914307, acc: 0.25)
[2025-01-30 02:04:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2260/107898 [12:20<9:26:29,  3.11it/s][2025-01-30 02:04:30][root][INFO] - Training Epoch: 1/2, step 2259/107898 completed (loss: 0.9503993988037109, acc: 0.800000011920929)
[2025-01-30 02:04:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2261/107898 [12:20<9:14:51,  3.17it/s][2025-01-30 02:04:30][root][INFO] - Training Epoch: 1/2, step 2260/107898 completed (loss: 1.3957353830337524, acc: 0.75)
[2025-01-30 02:04:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2262/107898 [12:21<9:20:33,  3.14it/s][2025-01-30 02:04:30][root][INFO] - Training Epoch: 1/2, step 2261/107898 completed (loss: 2.2227957248687744, acc: 0.5833333134651184)
[2025-01-30 02:04:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2263/107898 [12:21<9:08:11,  3.21it/s][2025-01-30 02:04:31][root][INFO] - Training Epoch: 1/2, step 2262/107898 completed (loss: 2.0457894802093506, acc: 0.7142857313156128)
[2025-01-30 02:04:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2264/107898 [12:21<9:12:16,  3.19it/s][2025-01-30 02:04:31][root][INFO] - Training Epoch: 1/2, step 2263/107898 completed (loss: 1.1990078687667847, acc: 0.807692289352417)
[2025-01-30 02:04:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2265/107898 [12:22<9:12:17,  3.19it/s][2025-01-30 02:04:31][root][INFO] - Training Epoch: 1/2, step 2264/107898 completed (loss: 1.2999324798583984, acc: 0.7142857313156128)
[2025-01-30 02:04:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2266/107898 [12:22<9:05:48,  3.23it/s][2025-01-30 02:04:32][root][INFO] - Training Epoch: 1/2, step 2265/107898 completed (loss: 0.5354200601577759, acc: 0.75)
[2025-01-30 02:04:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2267/107898 [12:22<9:04:33,  3.23it/s][2025-01-30 02:04:32][root][INFO] - Training Epoch: 1/2, step 2266/107898 completed (loss: 0.13698527216911316, acc: 1.0)
[2025-01-30 02:04:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2268/107898 [12:23<9:31:12,  3.08it/s][2025-01-30 02:04:32][root][INFO] - Training Epoch: 1/2, step 2267/107898 completed (loss: 0.6394613981246948, acc: 0.75)
[2025-01-30 02:04:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2269/107898 [12:23<9:50:38,  2.98it/s][2025-01-30 02:04:33][root][INFO] - Training Epoch: 1/2, step 2268/107898 completed (loss: 0.8129006624221802, acc: 0.8500000238418579)
[2025-01-30 02:04:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2270/107898 [12:23<9:37:12,  3.05it/s][2025-01-30 02:04:33][root][INFO] - Training Epoch: 1/2, step 2269/107898 completed (loss: 1.2458993196487427, acc: 0.8571428656578064)
[2025-01-30 02:04:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2271/107898 [12:24<9:29:02,  3.09it/s][2025-01-30 02:04:33][root][INFO] - Training Epoch: 1/2, step 2270/107898 completed (loss: 2.1610910892486572, acc: 0.6363636255264282)
[2025-01-30 02:04:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2272/107898 [12:24<9:32:26,  3.08it/s][2025-01-30 02:04:34][root][INFO] - Training Epoch: 1/2, step 2271/107898 completed (loss: 1.2353267669677734, acc: 0.8799999952316284)
[2025-01-30 02:04:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2273/107898 [12:24<9:28:26,  3.10it/s][2025-01-30 02:04:34][root][INFO] - Training Epoch: 1/2, step 2272/107898 completed (loss: 0.5983834266662598, acc: 0.8888888955116272)
[2025-01-30 02:04:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2274/107898 [12:25<9:43:15,  3.02it/s][2025-01-30 02:04:34][root][INFO] - Training Epoch: 1/2, step 2273/107898 completed (loss: 2.707127332687378, acc: 0.47058823704719543)
[2025-01-30 02:04:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2275/107898 [12:25<9:24:59,  3.12it/s][2025-01-30 02:04:35][root][INFO] - Training Epoch: 1/2, step 2274/107898 completed (loss: 0.4703705310821533, acc: 1.0)
[2025-01-30 02:04:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2276/107898 [12:25<9:27:17,  3.10it/s][2025-01-30 02:04:35][root][INFO] - Training Epoch: 1/2, step 2275/107898 completed (loss: 1.117193579673767, acc: 0.75)
[2025-01-30 02:04:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2277/107898 [12:26<9:22:41,  3.13it/s][2025-01-30 02:04:35][root][INFO] - Training Epoch: 1/2, step 2276/107898 completed (loss: 2.153488874435425, acc: 0.6666666865348816)
[2025-01-30 02:04:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2278/107898 [12:26<9:02:55,  3.24it/s][2025-01-30 02:04:36][root][INFO] - Training Epoch: 1/2, step 2277/107898 completed (loss: 0.5283454656600952, acc: 1.0)
[2025-01-30 02:04:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2279/107898 [12:26<9:39:16,  3.04it/s][2025-01-30 02:04:36][root][INFO] - Training Epoch: 1/2, step 2278/107898 completed (loss: 0.6019195914268494, acc: 0.8787878751754761)
[2025-01-30 02:04:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2280/107898 [12:26<9:27:27,  3.10it/s][2025-01-30 02:04:36][root][INFO] - Training Epoch: 1/2, step 2279/107898 completed (loss: 0.2564300000667572, acc: 0.9166666865348816)
[2025-01-30 02:04:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2281/107898 [12:27<9:20:59,  3.14it/s][2025-01-30 02:04:37][root][INFO] - Training Epoch: 1/2, step 2280/107898 completed (loss: 0.37068894505500793, acc: 0.9375)
[2025-01-30 02:04:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2282/107898 [12:27<9:18:58,  3.15it/s][2025-01-30 02:04:37][root][INFO] - Training Epoch: 1/2, step 2281/107898 completed (loss: 1.6259269714355469, acc: 0.699999988079071)
[2025-01-30 02:04:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2283/107898 [12:27<9:13:31,  3.18it/s][2025-01-30 02:04:37][root][INFO] - Training Epoch: 1/2, step 2282/107898 completed (loss: 1.141445279121399, acc: 0.7692307829856873)
[2025-01-30 02:04:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2284/107898 [12:28<9:12:56,  3.18it/s][2025-01-30 02:04:38][root][INFO] - Training Epoch: 1/2, step 2283/107898 completed (loss: 0.1004238948225975, acc: 1.0)
[2025-01-30 02:04:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2285/107898 [12:28<9:35:47,  3.06it/s][2025-01-30 02:04:38][root][INFO] - Training Epoch: 1/2, step 2284/107898 completed (loss: 1.883554458618164, acc: 0.800000011920929)
[2025-01-30 02:04:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2286/107898 [12:28<9:15:21,  3.17it/s][2025-01-30 02:04:38][root][INFO] - Training Epoch: 1/2, step 2285/107898 completed (loss: 0.19807907938957214, acc: 1.0)
[2025-01-30 02:04:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2287/107898 [12:29<9:34:46,  3.06it/s][2025-01-30 02:04:39][root][INFO] - Training Epoch: 1/2, step 2286/107898 completed (loss: 1.0571250915527344, acc: 0.9166666865348816)
[2025-01-30 02:04:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2288/107898 [12:29<9:41:23,  3.03it/s][2025-01-30 02:04:39][root][INFO] - Training Epoch: 1/2, step 2287/107898 completed (loss: 0.005101396236568689, acc: 1.0)
[2025-01-30 02:04:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2289/107898 [12:29<9:48:12,  2.99it/s][2025-01-30 02:04:39][root][INFO] - Training Epoch: 1/2, step 2288/107898 completed (loss: 0.1379975527524948, acc: 1.0)
[2025-01-30 02:04:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2290/107898 [12:30<9:49:42,  2.98it/s][2025-01-30 02:04:40][root][INFO] - Training Epoch: 1/2, step 2289/107898 completed (loss: 2.3636984825134277, acc: 0.6153846383094788)
[2025-01-30 02:04:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2291/107898 [12:30<9:44:16,  3.01it/s][2025-01-30 02:04:40][root][INFO] - Training Epoch: 1/2, step 2290/107898 completed (loss: 2.9568839073181152, acc: 0.4000000059604645)
[2025-01-30 02:04:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2292/107898 [12:30<9:31:01,  3.08it/s][2025-01-30 02:04:40][root][INFO] - Training Epoch: 1/2, step 2291/107898 completed (loss: 0.5798110961914062, acc: 0.8999999761581421)
[2025-01-30 02:04:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2293/107898 [12:31<9:14:02,  3.18it/s][2025-01-30 02:04:40][root][INFO] - Training Epoch: 1/2, step 2292/107898 completed (loss: 0.06452341377735138, acc: 1.0)
[2025-01-30 02:04:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2294/107898 [12:31<9:02:19,  3.25it/s][2025-01-30 02:04:41][root][INFO] - Training Epoch: 1/2, step 2293/107898 completed (loss: 1.1888203620910645, acc: 0.692307710647583)
[2025-01-30 02:04:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2295/107898 [12:31<8:57:15,  3.28it/s][2025-01-30 02:04:41][root][INFO] - Training Epoch: 1/2, step 2294/107898 completed (loss: 1.8479406833648682, acc: 0.75)
[2025-01-30 02:04:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2296/107898 [12:32<8:52:02,  3.31it/s][2025-01-30 02:04:41][root][INFO] - Training Epoch: 1/2, step 2295/107898 completed (loss: 1.5356806516647339, acc: 0.6666666865348816)
[2025-01-30 02:04:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2297/107898 [12:32<8:57:51,  3.27it/s][2025-01-30 02:04:42][root][INFO] - Training Epoch: 1/2, step 2296/107898 completed (loss: 0.8796827793121338, acc: 0.75)
[2025-01-30 02:04:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2298/107898 [12:32<8:59:28,  3.26it/s][2025-01-30 02:04:42][root][INFO] - Training Epoch: 1/2, step 2297/107898 completed (loss: 1.0549702644348145, acc: 0.7727272510528564)
[2025-01-30 02:04:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2299/107898 [12:33<9:07:27,  3.21it/s][2025-01-30 02:04:42][root][INFO] - Training Epoch: 1/2, step 2298/107898 completed (loss: 0.23230789601802826, acc: 0.9375)
[2025-01-30 02:04:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2300/107898 [12:33<8:57:54,  3.27it/s][2025-01-30 02:04:43][root][INFO] - Training Epoch: 1/2, step 2299/107898 completed (loss: 0.8070182800292969, acc: 0.75)
[2025-01-30 02:04:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2301/107898 [12:33<9:01:53,  3.25it/s][2025-01-30 02:04:43][root][INFO] - Training Epoch: 1/2, step 2300/107898 completed (loss: 0.862580418586731, acc: 0.8125)
[2025-01-30 02:04:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2302/107898 [12:33<9:08:27,  3.21it/s][2025-01-30 02:04:43][root][INFO] - Training Epoch: 1/2, step 2301/107898 completed (loss: 2.1761186122894287, acc: 0.5)
[2025-01-30 02:04:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2303/107898 [12:34<8:54:57,  3.29it/s][2025-01-30 02:04:44][root][INFO] - Training Epoch: 1/2, step 2302/107898 completed (loss: 3.4135982990264893, acc: 0.3333333432674408)
[2025-01-30 02:04:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2304/107898 [12:34<8:55:21,  3.29it/s][2025-01-30 02:04:44][root][INFO] - Training Epoch: 1/2, step 2303/107898 completed (loss: 2.9436113834381104, acc: 0.5)
[2025-01-30 02:04:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2305/107898 [12:34<9:00:42,  3.25it/s][2025-01-30 02:04:44][root][INFO] - Training Epoch: 1/2, step 2304/107898 completed (loss: 3.322105884552002, acc: 0.5)
[2025-01-30 02:04:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2306/107898 [12:35<9:30:18,  3.09it/s][2025-01-30 02:04:44][root][INFO] - Training Epoch: 1/2, step 2305/107898 completed (loss: 0.010957812890410423, acc: 1.0)
[2025-01-30 02:04:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2307/107898 [12:35<9:35:21,  3.06it/s][2025-01-30 02:04:45][root][INFO] - Training Epoch: 1/2, step 2306/107898 completed (loss: 0.6231945753097534, acc: 0.8461538553237915)
[2025-01-30 02:04:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2308/107898 [12:35<9:31:07,  3.08it/s][2025-01-30 02:04:45][root][INFO] - Training Epoch: 1/2, step 2307/107898 completed (loss: 0.9626286625862122, acc: 0.7857142686843872)
[2025-01-30 02:04:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2309/107898 [12:36<9:22:13,  3.13it/s][2025-01-30 02:04:45][root][INFO] - Training Epoch: 1/2, step 2308/107898 completed (loss: 0.731390655040741, acc: 0.800000011920929)
[2025-01-30 02:04:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2310/107898 [12:36<9:37:09,  3.05it/s][2025-01-30 02:04:46][root][INFO] - Training Epoch: 1/2, step 2309/107898 completed (loss: 0.07649893313646317, acc: 1.0)
[2025-01-30 02:04:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2311/107898 [12:36<9:43:29,  3.02it/s][2025-01-30 02:04:46][root][INFO] - Training Epoch: 1/2, step 2310/107898 completed (loss: 2.091773748397827, acc: 0.5333333611488342)
[2025-01-30 02:04:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2312/107898 [12:37<9:45:49,  3.00it/s][2025-01-30 02:04:46][root][INFO] - Training Epoch: 1/2, step 2311/107898 completed (loss: 1.4033613204956055, acc: 0.800000011920929)
[2025-01-30 02:04:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2313/107898 [12:37<9:33:26,  3.07it/s][2025-01-30 02:04:47][root][INFO] - Training Epoch: 1/2, step 2312/107898 completed (loss: 0.5247014760971069, acc: 0.6666666865348816)
[2025-01-30 02:04:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2314/107898 [12:37<9:57:10,  2.95it/s][2025-01-30 02:04:47][root][INFO] - Training Epoch: 1/2, step 2313/107898 completed (loss: 0.47974371910095215, acc: 0.8333333134651184)
[2025-01-30 02:04:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2315/107898 [12:38<9:44:42,  3.01it/s][2025-01-30 02:04:47][root][INFO] - Training Epoch: 1/2, step 2314/107898 completed (loss: 2.21450138092041, acc: 0.5)
[2025-01-30 02:04:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2316/107898 [12:38<9:33:18,  3.07it/s][2025-01-30 02:04:48][root][INFO] - Training Epoch: 1/2, step 2315/107898 completed (loss: 0.8213046789169312, acc: 0.75)
[2025-01-30 02:04:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2317/107898 [12:38<9:25:27,  3.11it/s][2025-01-30 02:04:48][root][INFO] - Training Epoch: 1/2, step 2316/107898 completed (loss: 0.2931164503097534, acc: 0.9666666388511658)
[2025-01-30 02:04:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2318/107898 [12:39<9:46:23,  3.00it/s][2025-01-30 02:04:48][root][INFO] - Training Epoch: 1/2, step 2317/107898 completed (loss: 0.45853787660598755, acc: 0.8999999761581421)
[2025-01-30 02:04:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2319/107898 [12:39<10:09:57,  2.88it/s][2025-01-30 02:04:49][root][INFO] - Training Epoch: 1/2, step 2318/107898 completed (loss: 1.2986689805984497, acc: 0.75)
[2025-01-30 02:04:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2320/107898 [12:39<10:21:08,  2.83it/s][2025-01-30 02:04:49][root][INFO] - Training Epoch: 1/2, step 2319/107898 completed (loss: 0.6599860191345215, acc: 0.8148148059844971)
[2025-01-30 02:04:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2321/107898 [12:40<9:56:18,  2.95it/s] [2025-01-30 02:04:50][root][INFO] - Training Epoch: 1/2, step 2320/107898 completed (loss: 0.01686546579003334, acc: 1.0)
[2025-01-30 02:04:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2322/107898 [12:40<9:39:11,  3.04it/s][2025-01-30 02:04:50][root][INFO] - Training Epoch: 1/2, step 2321/107898 completed (loss: 0.029143881052732468, acc: 1.0)
[2025-01-30 02:04:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2323/107898 [12:40<9:23:46,  3.12it/s][2025-01-30 02:04:50][root][INFO] - Training Epoch: 1/2, step 2322/107898 completed (loss: 1.0593191385269165, acc: 0.5)
[2025-01-30 02:04:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2324/107898 [12:41<9:32:54,  3.07it/s][2025-01-30 02:04:50][root][INFO] - Training Epoch: 1/2, step 2323/107898 completed (loss: 2.4475715160369873, acc: 0.5263158082962036)
[2025-01-30 02:04:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2325/107898 [12:41<9:29:40,  3.09it/s][2025-01-30 02:04:51][root][INFO] - Training Epoch: 1/2, step 2324/107898 completed (loss: 1.273419737815857, acc: 0.75)
[2025-01-30 02:04:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2326/107898 [12:41<9:40:11,  3.03it/s][2025-01-30 02:04:51][root][INFO] - Training Epoch: 1/2, step 2325/107898 completed (loss: 0.00839680153876543, acc: 1.0)
[2025-01-30 02:04:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2327/107898 [12:42<10:06:33,  2.90it/s][2025-01-30 02:04:51][root][INFO] - Training Epoch: 1/2, step 2326/107898 completed (loss: 1.1117403507232666, acc: 0.7868852615356445)
[2025-01-30 02:04:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2328/107898 [12:42<10:27:10,  2.81it/s][2025-01-30 02:04:52][root][INFO] - Training Epoch: 1/2, step 2327/107898 completed (loss: 0.8542696833610535, acc: 0.7647058963775635)
[2025-01-30 02:04:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2329/107898 [12:42<10:18:49,  2.84it/s][2025-01-30 02:04:52][root][INFO] - Training Epoch: 1/2, step 2328/107898 completed (loss: 2.565497875213623, acc: 0.3333333432674408)
[2025-01-30 02:04:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2330/107898 [12:43<9:53:14,  2.97it/s] [2025-01-30 02:04:53][root][INFO] - Training Epoch: 1/2, step 2329/107898 completed (loss: 2.6478068828582764, acc: 0.3333333432674408)
[2025-01-30 02:04:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2331/107898 [12:43<9:27:14,  3.10it/s][2025-01-30 02:04:53][root][INFO] - Training Epoch: 1/2, step 2330/107898 completed (loss: 1.75810968875885, acc: 0.5)
[2025-01-30 02:04:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2332/107898 [12:43<9:20:25,  3.14it/s][2025-01-30 02:04:53][root][INFO] - Training Epoch: 1/2, step 2331/107898 completed (loss: 1.8708548545837402, acc: 0.6666666865348816)
[2025-01-30 02:04:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2333/107898 [12:44<9:31:53,  3.08it/s][2025-01-30 02:04:53][root][INFO] - Training Epoch: 1/2, step 2332/107898 completed (loss: 0.8760320544242859, acc: 1.0)
[2025-01-30 02:04:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2334/107898 [12:44<9:37:23,  3.05it/s][2025-01-30 02:04:54][root][INFO] - Training Epoch: 1/2, step 2333/107898 completed (loss: 2.3855528831481934, acc: 0.4615384638309479)
[2025-01-30 02:04:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2335/107898 [12:44<9:43:43,  3.01it/s][2025-01-30 02:04:54][root][INFO] - Training Epoch: 1/2, step 2334/107898 completed (loss: 1.4022058248519897, acc: 0.875)
[2025-01-30 02:04:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2336/107898 [12:45<9:43:43,  3.01it/s][2025-01-30 02:04:54][root][INFO] - Training Epoch: 1/2, step 2335/107898 completed (loss: 0.30288395285606384, acc: 0.9142857193946838)
[2025-01-30 02:04:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2337/107898 [12:45<9:19:14,  3.15it/s][2025-01-30 02:04:55][root][INFO] - Training Epoch: 1/2, step 2336/107898 completed (loss: 1.1490164995193481, acc: 1.0)
[2025-01-30 02:04:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2338/107898 [12:45<9:03:38,  3.24it/s][2025-01-30 02:04:55][root][INFO] - Training Epoch: 1/2, step 2337/107898 completed (loss: 1.136163353919983, acc: 0.6666666865348816)
[2025-01-30 02:04:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2339/107898 [12:46<8:59:15,  3.26it/s][2025-01-30 02:04:55][root][INFO] - Training Epoch: 1/2, step 2338/107898 completed (loss: 1.7464238405227661, acc: 0.5833333134651184)
[2025-01-30 02:04:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2340/107898 [12:46<8:59:18,  3.26it/s][2025-01-30 02:04:56][root][INFO] - Training Epoch: 1/2, step 2339/107898 completed (loss: 0.03063865192234516, acc: 1.0)
[2025-01-30 02:04:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2341/107898 [12:46<8:57:05,  3.28it/s][2025-01-30 02:04:56][root][INFO] - Training Epoch: 1/2, step 2340/107898 completed (loss: 0.3656807243824005, acc: 0.8461538553237915)
[2025-01-30 02:04:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2342/107898 [12:46<9:04:31,  3.23it/s][2025-01-30 02:04:56][root][INFO] - Training Epoch: 1/2, step 2341/107898 completed (loss: 1.2730094194412231, acc: 0.6666666865348816)
[2025-01-30 02:04:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2343/107898 [12:47<9:12:17,  3.19it/s][2025-01-30 02:04:57][root][INFO] - Training Epoch: 1/2, step 2342/107898 completed (loss: 0.48587942123413086, acc: 0.7692307829856873)
[2025-01-30 02:04:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2344/107898 [12:47<9:13:49,  3.18it/s][2025-01-30 02:04:57][root][INFO] - Training Epoch: 1/2, step 2343/107898 completed (loss: 0.4187011420726776, acc: 0.8125)
[2025-01-30 02:04:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2345/107898 [12:47<9:12:12,  3.19it/s][2025-01-30 02:04:57][root][INFO] - Training Epoch: 1/2, step 2344/107898 completed (loss: 0.3753662407398224, acc: 1.0)
[2025-01-30 02:04:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2346/107898 [12:48<9:43:51,  3.01it/s][2025-01-30 02:04:58][root][INFO] - Training Epoch: 1/2, step 2345/107898 completed (loss: 2.8611419200897217, acc: 0.4000000059604645)
[2025-01-30 02:04:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2347/107898 [12:48<9:31:26,  3.08it/s][2025-01-30 02:04:58][root][INFO] - Training Epoch: 1/2, step 2346/107898 completed (loss: 0.30715587735176086, acc: 1.0)
[2025-01-30 02:04:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2348/107898 [12:48<9:20:38,  3.14it/s][2025-01-30 02:04:58][root][INFO] - Training Epoch: 1/2, step 2347/107898 completed (loss: 2.1712076663970947, acc: 0.6538461446762085)
[2025-01-30 02:04:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2349/107898 [12:49<9:15:53,  3.16it/s][2025-01-30 02:04:59][root][INFO] - Training Epoch: 1/2, step 2348/107898 completed (loss: 5.689660549163818, acc: 0.4285714328289032)
[2025-01-30 02:04:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2350/107898 [12:49<9:03:33,  3.24it/s][2025-01-30 02:04:59][root][INFO] - Training Epoch: 1/2, step 2349/107898 completed (loss: 1.4270551204681396, acc: 0.699999988079071)
[2025-01-30 02:04:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2351/107898 [12:49<9:03:53,  3.23it/s][2025-01-30 02:04:59][root][INFO] - Training Epoch: 1/2, step 2350/107898 completed (loss: 0.30083656311035156, acc: 0.9090909361839294)
[2025-01-30 02:04:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2352/107898 [12:50<8:58:03,  3.27it/s][2025-01-30 02:04:59][root][INFO] - Training Epoch: 1/2, step 2351/107898 completed (loss: 0.18861836194992065, acc: 1.0)
[2025-01-30 02:04:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2353/107898 [12:50<8:53:40,  3.30it/s][2025-01-30 02:05:00][root][INFO] - Training Epoch: 1/2, step 2352/107898 completed (loss: 0.5613102912902832, acc: 0.8399999737739563)
[2025-01-30 02:05:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2354/107898 [12:50<9:08:40,  3.21it/s][2025-01-30 02:05:00][root][INFO] - Training Epoch: 1/2, step 2353/107898 completed (loss: 0.57474684715271, acc: 0.8799999952316284)
[2025-01-30 02:05:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2355/107898 [12:51<9:29:19,  3.09it/s][2025-01-30 02:05:00][root][INFO] - Training Epoch: 1/2, step 2354/107898 completed (loss: 0.2163010984659195, acc: 1.0)
[2025-01-30 02:05:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2356/107898 [12:51<9:41:51,  3.02it/s][2025-01-30 02:05:01][root][INFO] - Training Epoch: 1/2, step 2355/107898 completed (loss: 1.7876217365264893, acc: 0.692307710647583)
[2025-01-30 02:05:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2357/107898 [12:51<9:37:23,  3.05it/s][2025-01-30 02:05:01][root][INFO] - Training Epoch: 1/2, step 2356/107898 completed (loss: 1.2357749938964844, acc: 0.5)
[2025-01-30 02:05:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2358/107898 [12:52<9:44:35,  3.01it/s][2025-01-30 02:05:01][root][INFO] - Training Epoch: 1/2, step 2357/107898 completed (loss: 0.5405622124671936, acc: 0.8333333134651184)
[2025-01-30 02:05:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2359/107898 [12:52<9:26:17,  3.11it/s][2025-01-30 02:05:02][root][INFO] - Training Epoch: 1/2, step 2358/107898 completed (loss: 0.13291940093040466, acc: 1.0)
[2025-01-30 02:05:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2360/107898 [12:52<9:48:49,  2.99it/s][2025-01-30 02:05:02][root][INFO] - Training Epoch: 1/2, step 2359/107898 completed (loss: 0.9781248569488525, acc: 0.807692289352417)
[2025-01-30 02:05:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2361/107898 [12:53<9:45:13,  3.01it/s][2025-01-30 02:05:02][root][INFO] - Training Epoch: 1/2, step 2360/107898 completed (loss: 0.039728790521621704, acc: 1.0)
[2025-01-30 02:05:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2362/107898 [12:53<9:34:44,  3.06it/s][2025-01-30 02:05:03][root][INFO] - Training Epoch: 1/2, step 2361/107898 completed (loss: 1.4832911491394043, acc: 0.7647058963775635)
[2025-01-30 02:05:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2363/107898 [12:53<9:58:08,  2.94it/s][2025-01-30 02:05:03][root][INFO] - Training Epoch: 1/2, step 2362/107898 completed (loss: 0.33678433299064636, acc: 0.9200000166893005)
[2025-01-30 02:05:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2364/107898 [12:54<9:56:22,  2.95it/s][2025-01-30 02:05:03][root][INFO] - Training Epoch: 1/2, step 2363/107898 completed (loss: 0.22985582053661346, acc: 0.9090909361839294)
[2025-01-30 02:05:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2365/107898 [12:54<9:41:12,  3.03it/s][2025-01-30 02:05:04][root][INFO] - Training Epoch: 1/2, step 2364/107898 completed (loss: 0.005649819038808346, acc: 1.0)
[2025-01-30 02:05:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2366/107898 [12:54<9:22:29,  3.13it/s][2025-01-30 02:05:04][root][INFO] - Training Epoch: 1/2, step 2365/107898 completed (loss: 0.06798458844423294, acc: 1.0)
[2025-01-30 02:05:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2367/107898 [12:55<9:37:45,  3.04it/s][2025-01-30 02:05:04][root][INFO] - Training Epoch: 1/2, step 2366/107898 completed (loss: 0.9036096334457397, acc: 0.5)
[2025-01-30 02:05:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2368/107898 [12:55<9:37:09,  3.05it/s][2025-01-30 02:05:05][root][INFO] - Training Epoch: 1/2, step 2367/107898 completed (loss: 0.12247733026742935, acc: 1.0)
[2025-01-30 02:05:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2369/107898 [12:55<9:45:06,  3.01it/s][2025-01-30 02:05:05][root][INFO] - Training Epoch: 1/2, step 2368/107898 completed (loss: 0.7077312469482422, acc: 0.8095238208770752)
[2025-01-30 02:05:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2370/107898 [12:56<9:24:49,  3.11it/s][2025-01-30 02:05:05][root][INFO] - Training Epoch: 1/2, step 2369/107898 completed (loss: 5.6734395027160645, acc: 0.3333333432674408)
[2025-01-30 02:05:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2371/107898 [12:56<9:06:36,  3.22it/s][2025-01-30 02:05:06][root][INFO] - Training Epoch: 1/2, step 2370/107898 completed (loss: 0.08819527179002762, acc: 1.0)
[2025-01-30 02:05:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2372/107898 [12:56<9:02:51,  3.24it/s][2025-01-30 02:05:06][root][INFO] - Training Epoch: 1/2, step 2371/107898 completed (loss: 1.2528398036956787, acc: 0.0)
[2025-01-30 02:05:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2373/107898 [12:56<9:02:21,  3.24it/s][2025-01-30 02:05:06][root][INFO] - Training Epoch: 1/2, step 2372/107898 completed (loss: 1.063838005065918, acc: 0.75)
[2025-01-30 02:05:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2374/107898 [12:57<8:46:49,  3.34it/s][2025-01-30 02:05:07][root][INFO] - Training Epoch: 1/2, step 2373/107898 completed (loss: 0.09315141290426254, acc: 0.95652174949646)
[2025-01-30 02:05:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2375/107898 [12:57<8:52:27,  3.30it/s][2025-01-30 02:05:07][root][INFO] - Training Epoch: 1/2, step 2374/107898 completed (loss: 1.185018539428711, acc: 0.7142857313156128)
[2025-01-30 02:05:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2376/107898 [12:57<9:19:17,  3.14it/s][2025-01-30 02:05:07][root][INFO] - Training Epoch: 1/2, step 2375/107898 completed (loss: 6.200417995452881, acc: 0.20000000298023224)
[2025-01-30 02:05:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2377/107898 [12:58<9:26:18,  3.11it/s][2025-01-30 02:05:08][root][INFO] - Training Epoch: 1/2, step 2376/107898 completed (loss: 3.117419719696045, acc: 0.0)
[2025-01-30 02:05:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2378/107898 [12:58<9:44:27,  3.01it/s][2025-01-30 02:05:08][root][INFO] - Training Epoch: 1/2, step 2377/107898 completed (loss: 0.14807340502738953, acc: 0.9375)
[2025-01-30 02:05:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2379/107898 [12:58<9:40:12,  3.03it/s][2025-01-30 02:05:08][root][INFO] - Training Epoch: 1/2, step 2378/107898 completed (loss: 0.7569379806518555, acc: 0.800000011920929)
[2025-01-30 02:05:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2380/107898 [12:59<9:52:41,  2.97it/s][2025-01-30 02:05:09][root][INFO] - Training Epoch: 1/2, step 2379/107898 completed (loss: 0.008708171546459198, acc: 1.0)
[2025-01-30 02:05:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2381/107898 [12:59<9:52:25,  2.97it/s][2025-01-30 02:05:09][root][INFO] - Training Epoch: 1/2, step 2380/107898 completed (loss: 0.7810341119766235, acc: 0.8235294222831726)
[2025-01-30 02:05:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2382/107898 [12:59<9:41:25,  3.02it/s][2025-01-30 02:05:09][root][INFO] - Training Epoch: 1/2, step 2381/107898 completed (loss: 4.373773097991943, acc: 0.3333333432674408)
[2025-01-30 02:05:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2383/107898 [13:00<9:28:12,  3.09it/s][2025-01-30 02:05:10][root][INFO] - Training Epoch: 1/2, step 2382/107898 completed (loss: 1.0388436317443848, acc: 0.807692289352417)
[2025-01-30 02:05:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2384/107898 [13:00<9:18:54,  3.15it/s][2025-01-30 02:05:10][root][INFO] - Training Epoch: 1/2, step 2383/107898 completed (loss: 0.35731714963912964, acc: 0.8888888955116272)
[2025-01-30 02:05:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2385/107898 [13:00<9:38:49,  3.04it/s][2025-01-30 02:05:10][root][INFO] - Training Epoch: 1/2, step 2384/107898 completed (loss: 0.058392442762851715, acc: 1.0)
[2025-01-30 02:05:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2386/107898 [13:01<9:40:54,  3.03it/s][2025-01-30 02:05:10][root][INFO] - Training Epoch: 1/2, step 2385/107898 completed (loss: 2.3699002265930176, acc: 0.5625)
[2025-01-30 02:05:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2387/107898 [13:01<9:37:41,  3.04it/s][2025-01-30 02:05:11][root][INFO] - Training Epoch: 1/2, step 2386/107898 completed (loss: 0.23792508244514465, acc: 1.0)
[2025-01-30 02:05:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2388/107898 [13:01<9:36:29,  3.05it/s][2025-01-30 02:05:11][root][INFO] - Training Epoch: 1/2, step 2387/107898 completed (loss: 1.9229928255081177, acc: 0.75)
[2025-01-30 02:05:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2389/107898 [13:02<9:22:14,  3.13it/s][2025-01-30 02:05:11][root][INFO] - Training Epoch: 1/2, step 2388/107898 completed (loss: 4.690526485443115, acc: 0.6666666865348816)
[2025-01-30 02:05:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2390/107898 [13:02<9:15:31,  3.17it/s][2025-01-30 02:05:12][root][INFO] - Training Epoch: 1/2, step 2389/107898 completed (loss: 1.776645541191101, acc: 0.7647058963775635)
[2025-01-30 02:05:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2391/107898 [13:02<9:13:09,  3.18it/s][2025-01-30 02:05:12][root][INFO] - Training Epoch: 1/2, step 2390/107898 completed (loss: 0.9641433358192444, acc: 0.6666666865348816)
[2025-01-30 02:05:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2392/107898 [13:03<9:36:11,  3.05it/s][2025-01-30 02:05:12][root][INFO] - Training Epoch: 1/2, step 2391/107898 completed (loss: 1.1258623600006104, acc: 0.8333333134651184)
[2025-01-30 02:05:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2393/107898 [13:03<9:42:12,  3.02it/s][2025-01-30 02:05:13][root][INFO] - Training Epoch: 1/2, step 2392/107898 completed (loss: 1.756277084350586, acc: 0.6153846383094788)
[2025-01-30 02:05:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2394/107898 [13:03<9:57:56,  2.94it/s][2025-01-30 02:05:13][root][INFO] - Training Epoch: 1/2, step 2393/107898 completed (loss: 0.40610286593437195, acc: 1.0)
[2025-01-30 02:05:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2395/107898 [13:04<9:55:13,  2.95it/s][2025-01-30 02:05:13][root][INFO] - Training Epoch: 1/2, step 2394/107898 completed (loss: 1.0531339645385742, acc: 0.7647058963775635)
[2025-01-30 02:05:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2396/107898 [13:04<9:42:11,  3.02it/s][2025-01-30 02:05:14][root][INFO] - Training Epoch: 1/2, step 2395/107898 completed (loss: 2.7194857597351074, acc: 0.2666666805744171)
[2025-01-30 02:05:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2397/107898 [13:04<9:28:57,  3.09it/s][2025-01-30 02:05:14][root][INFO] - Training Epoch: 1/2, step 2396/107898 completed (loss: 1.0293503999710083, acc: 0.8181818127632141)
[2025-01-30 02:05:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2398/107898 [13:05<9:39:48,  3.03it/s][2025-01-30 02:05:14][root][INFO] - Training Epoch: 1/2, step 2397/107898 completed (loss: 1.608609914779663, acc: 0.529411792755127)
[2025-01-30 02:05:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2399/107898 [13:05<9:35:41,  3.05it/s][2025-01-30 02:05:15][root][INFO] - Training Epoch: 1/2, step 2398/107898 completed (loss: 0.6970435976982117, acc: 1.0)
[2025-01-30 02:05:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2400/107898 [13:05<9:47:11,  2.99it/s][2025-01-30 02:05:15][root][INFO] - Training Epoch: 1/2, step 2399/107898 completed (loss: 1.274478793144226, acc: 0.7058823704719543)
[2025-01-30 02:05:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2401/107898 [13:06<9:43:52,  3.01it/s][2025-01-30 02:05:15][root][INFO] - Training Epoch: 1/2, step 2400/107898 completed (loss: 1.9163134098052979, acc: 0.8571428656578064)
[2025-01-30 02:05:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2402/107898 [13:06<9:39:42,  3.03it/s][2025-01-30 02:05:16][root][INFO] - Training Epoch: 1/2, step 2401/107898 completed (loss: 0.6179431676864624, acc: 0.8999999761581421)
[2025-01-30 02:05:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2403/107898 [13:06<9:31:28,  3.08it/s][2025-01-30 02:05:16][root][INFO] - Training Epoch: 1/2, step 2402/107898 completed (loss: 0.7418025135993958, acc: 0.8947368264198303)
[2025-01-30 02:05:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2404/107898 [13:07<9:55:35,  2.95it/s][2025-01-30 02:05:16][root][INFO] - Training Epoch: 1/2, step 2403/107898 completed (loss: 0.2962476909160614, acc: 0.8947368264198303)
[2025-01-30 02:05:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2405/107898 [13:07<9:54:28,  2.96it/s][2025-01-30 02:05:17][root][INFO] - Training Epoch: 1/2, step 2404/107898 completed (loss: 1.9073224067687988, acc: 0.75)
[2025-01-30 02:05:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2406/107898 [13:07<10:02:54,  2.92it/s][2025-01-30 02:05:17][root][INFO] - Training Epoch: 1/2, step 2405/107898 completed (loss: 0.691017746925354, acc: 0.7777777910232544)
[2025-01-30 02:05:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2407/107898 [13:08<9:58:31,  2.94it/s] [2025-01-30 02:05:17][root][INFO] - Training Epoch: 1/2, step 2406/107898 completed (loss: 2.8170995712280273, acc: 0.25)
[2025-01-30 02:05:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2408/107898 [13:08<9:46:10,  3.00it/s][2025-01-30 02:05:18][root][INFO] - Training Epoch: 1/2, step 2407/107898 completed (loss: 1.5833945274353027, acc: 0.8235294222831726)
[2025-01-30 02:05:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2409/107898 [13:08<9:30:50,  3.08it/s][2025-01-30 02:05:18][root][INFO] - Training Epoch: 1/2, step 2408/107898 completed (loss: 0.8802735209465027, acc: 0.699999988079071)
[2025-01-30 02:05:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2410/107898 [13:09<9:59:30,  2.93it/s][2025-01-30 02:05:18][root][INFO] - Training Epoch: 1/2, step 2409/107898 completed (loss: 0.8015546798706055, acc: 0.8571428656578064)
[2025-01-30 02:05:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2411/107898 [13:09<9:56:19,  2.95it/s][2025-01-30 02:05:19][root][INFO] - Training Epoch: 1/2, step 2410/107898 completed (loss: 0.7534955143928528, acc: 0.6000000238418579)
[2025-01-30 02:05:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2412/107898 [13:09<9:39:51,  3.03it/s][2025-01-30 02:05:19][root][INFO] - Training Epoch: 1/2, step 2411/107898 completed (loss: 1.4667221307754517, acc: 0.5)
[2025-01-30 02:05:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2413/107898 [13:10<9:16:08,  3.16it/s][2025-01-30 02:05:19][root][INFO] - Training Epoch: 1/2, step 2412/107898 completed (loss: 1.5821772813796997, acc: 0.6666666865348816)
[2025-01-30 02:05:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2414/107898 [13:10<9:07:46,  3.21it/s][2025-01-30 02:05:20][root][INFO] - Training Epoch: 1/2, step 2413/107898 completed (loss: 0.8148823380470276, acc: 0.8461538553237915)
[2025-01-30 02:05:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2415/107898 [13:10<8:59:45,  3.26it/s][2025-01-30 02:05:20][root][INFO] - Training Epoch: 1/2, step 2414/107898 completed (loss: 0.9110631346702576, acc: 1.0)
[2025-01-30 02:05:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2416/107898 [13:10<8:52:18,  3.30it/s][2025-01-30 02:05:20][root][INFO] - Training Epoch: 1/2, step 2415/107898 completed (loss: 2.994678258895874, acc: 0.5)
[2025-01-30 02:05:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2417/107898 [13:11<8:57:57,  3.27it/s][2025-01-30 02:05:21][root][INFO] - Training Epoch: 1/2, step 2416/107898 completed (loss: 1.6032459735870361, acc: 0.8181818127632141)
[2025-01-30 02:05:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2418/107898 [13:11<9:30:55,  3.08it/s][2025-01-30 02:05:21][root][INFO] - Training Epoch: 1/2, step 2417/107898 completed (loss: 0.7175241708755493, acc: 0.5)
[2025-01-30 02:05:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2419/107898 [13:12<9:39:42,  3.03it/s][2025-01-30 02:05:21][root][INFO] - Training Epoch: 1/2, step 2418/107898 completed (loss: 0.9882978796958923, acc: 0.7058823704719543)
[2025-01-30 02:05:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2420/107898 [13:12<9:24:49,  3.11it/s][2025-01-30 02:05:22][root][INFO] - Training Epoch: 1/2, step 2419/107898 completed (loss: 3.2970330715179443, acc: 0.1666666716337204)
[2025-01-30 02:05:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2421/107898 [13:12<9:28:44,  3.09it/s][2025-01-30 02:05:22][root][INFO] - Training Epoch: 1/2, step 2420/107898 completed (loss: 0.35919189453125, acc: 1.0)
[2025-01-30 02:05:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2422/107898 [13:12<9:18:33,  3.15it/s][2025-01-30 02:05:22][root][INFO] - Training Epoch: 1/2, step 2421/107898 completed (loss: 0.9889757633209229, acc: 0.8181818127632141)
[2025-01-30 02:05:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2423/107898 [13:13<9:04:54,  3.23it/s][2025-01-30 02:05:23][root][INFO] - Training Epoch: 1/2, step 2422/107898 completed (loss: 0.7084810137748718, acc: 1.0)
[2025-01-30 02:05:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2424/107898 [13:13<9:06:16,  3.22it/s][2025-01-30 02:05:23][root][INFO] - Training Epoch: 1/2, step 2423/107898 completed (loss: 0.028000548481941223, acc: 1.0)
[2025-01-30 02:05:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2425/107898 [13:13<8:41:55,  3.37it/s][2025-01-30 02:05:23][root][INFO] - Training Epoch: 1/2, step 2424/107898 completed (loss: 2.4210031032562256, acc: 0.3333333432674408)
[2025-01-30 02:05:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2426/107898 [13:14<8:43:26,  3.36it/s][2025-01-30 02:05:23][root][INFO] - Training Epoch: 1/2, step 2425/107898 completed (loss: 0.046289533376693726, acc: 1.0)
[2025-01-30 02:05:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2427/107898 [13:14<8:56:33,  3.28it/s][2025-01-30 02:05:24][root][INFO] - Training Epoch: 1/2, step 2426/107898 completed (loss: 0.4816396236419678, acc: 0.8571428656578064)
[2025-01-30 02:05:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2428/107898 [13:14<8:57:03,  3.27it/s][2025-01-30 02:05:24][root][INFO] - Training Epoch: 1/2, step 2427/107898 completed (loss: 0.07624322921037674, acc: 1.0)
[2025-01-30 02:05:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2429/107898 [13:15<9:03:50,  3.23it/s][2025-01-30 02:05:24][root][INFO] - Training Epoch: 1/2, step 2428/107898 completed (loss: 0.009618776850402355, acc: 1.0)
[2025-01-30 02:05:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2430/107898 [13:15<8:56:35,  3.28it/s][2025-01-30 02:05:25][root][INFO] - Training Epoch: 1/2, step 2429/107898 completed (loss: 0.3504318296909332, acc: 0.8666666746139526)
[2025-01-30 02:05:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2431/107898 [13:15<9:00:40,  3.25it/s][2025-01-30 02:05:25][root][INFO] - Training Epoch: 1/2, step 2430/107898 completed (loss: 1.046290397644043, acc: 0.625)
[2025-01-30 02:05:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2432/107898 [13:15<8:56:36,  3.28it/s][2025-01-30 02:05:25][root][INFO] - Training Epoch: 1/2, step 2431/107898 completed (loss: 1.4884991645812988, acc: 0.8181818127632141)
[2025-01-30 02:05:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2433/107898 [13:16<8:57:20,  3.27it/s][2025-01-30 02:05:26][root][INFO] - Training Epoch: 1/2, step 2432/107898 completed (loss: 3.9386110305786133, acc: 0.3333333432674408)
[2025-01-30 02:05:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2434/107898 [13:16<9:10:43,  3.19it/s][2025-01-30 02:05:26][root][INFO] - Training Epoch: 1/2, step 2433/107898 completed (loss: 1.29454505443573, acc: 0.5454545617103577)
[2025-01-30 02:05:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2435/107898 [13:16<9:05:24,  3.22it/s][2025-01-30 02:05:26][root][INFO] - Training Epoch: 1/2, step 2434/107898 completed (loss: 1.5915714502334595, acc: 0.7058823704719543)
[2025-01-30 02:05:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2436/107898 [13:17<9:24:15,  3.12it/s][2025-01-30 02:05:27][root][INFO] - Training Epoch: 1/2, step 2435/107898 completed (loss: 1.8580950498580933, acc: 0.7142857313156128)
[2025-01-30 02:05:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2437/107898 [13:17<9:34:55,  3.06it/s][2025-01-30 02:05:27][root][INFO] - Training Epoch: 1/2, step 2436/107898 completed (loss: 1.1707581281661987, acc: 0.6666666865348816)
[2025-01-30 02:05:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2438/107898 [13:17<9:30:31,  3.08it/s][2025-01-30 02:05:27][root][INFO] - Training Epoch: 1/2, step 2437/107898 completed (loss: 1.9293586015701294, acc: 0.5)
[2025-01-30 02:05:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2439/107898 [13:18<9:21:34,  3.13it/s][2025-01-30 02:05:28][root][INFO] - Training Epoch: 1/2, step 2438/107898 completed (loss: 1.87325119972229, acc: 0.6000000238418579)
[2025-01-30 02:05:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2440/107898 [13:18<9:34:51,  3.06it/s][2025-01-30 02:05:28][root][INFO] - Training Epoch: 1/2, step 2439/107898 completed (loss: 1.3819371461868286, acc: 0.692307710647583)
[2025-01-30 02:05:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2441/107898 [13:18<9:57:44,  2.94it/s][2025-01-30 02:05:28][root][INFO] - Training Epoch: 1/2, step 2440/107898 completed (loss: 0.35915639996528625, acc: 0.9333333373069763)
[2025-01-30 02:05:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2442/107898 [13:19<10:00:16,  2.93it/s][2025-01-30 02:05:29][root][INFO] - Training Epoch: 1/2, step 2441/107898 completed (loss: 0.6752868294715881, acc: 0.8999999761581421)
[2025-01-30 02:05:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2443/107898 [13:19<9:56:26,  2.95it/s] [2025-01-30 02:05:29][root][INFO] - Training Epoch: 1/2, step 2442/107898 completed (loss: 0.4944949746131897, acc: 0.800000011920929)
[2025-01-30 02:05:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2444/107898 [13:19<9:41:37,  3.02it/s][2025-01-30 02:05:29][root][INFO] - Training Epoch: 1/2, step 2443/107898 completed (loss: 0.4750567078590393, acc: 0.8888888955116272)
[2025-01-30 02:05:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2445/107898 [13:20<9:34:46,  3.06it/s][2025-01-30 02:05:30][root][INFO] - Training Epoch: 1/2, step 2444/107898 completed (loss: 2.094754695892334, acc: 0.6000000238418579)
[2025-01-30 02:05:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2446/107898 [13:20<9:28:27,  3.09it/s][2025-01-30 02:05:30][root][INFO] - Training Epoch: 1/2, step 2445/107898 completed (loss: 0.4375806152820587, acc: 0.9090909361839294)
[2025-01-30 02:05:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2447/107898 [13:20<9:30:22,  3.08it/s][2025-01-30 02:05:30][root][INFO] - Training Epoch: 1/2, step 2446/107898 completed (loss: 0.904083251953125, acc: 0.84375)
[2025-01-30 02:05:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2448/107898 [13:21<9:37:23,  3.04it/s][2025-01-30 02:05:31][root][INFO] - Training Epoch: 1/2, step 2447/107898 completed (loss: 0.005782832391560078, acc: 1.0)
[2025-01-30 02:05:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2449/107898 [13:21<9:25:30,  3.11it/s][2025-01-30 02:05:31][root][INFO] - Training Epoch: 1/2, step 2448/107898 completed (loss: 0.5417496562004089, acc: 0.8666666746139526)
[2025-01-30 02:05:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2450/107898 [13:21<9:32:23,  3.07it/s][2025-01-30 02:05:31][root][INFO] - Training Epoch: 1/2, step 2449/107898 completed (loss: 0.15776319801807404, acc: 0.9545454382896423)
[2025-01-30 02:05:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2451/107898 [13:22<9:23:31,  3.12it/s][2025-01-30 02:05:31][root][INFO] - Training Epoch: 1/2, step 2450/107898 completed (loss: 0.41495829820632935, acc: 1.0)
[2025-01-30 02:05:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2452/107898 [13:22<9:14:32,  3.17it/s][2025-01-30 02:05:32][root][INFO] - Training Epoch: 1/2, step 2451/107898 completed (loss: 0.009637800976634026, acc: 1.0)
[2025-01-30 02:05:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2453/107898 [13:22<9:12:32,  3.18it/s][2025-01-30 02:05:32][root][INFO] - Training Epoch: 1/2, step 2452/107898 completed (loss: 0.7965006232261658, acc: 0.8571428656578064)
[2025-01-30 02:05:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2454/107898 [13:23<9:14:41,  3.17it/s][2025-01-30 02:05:32][root][INFO] - Training Epoch: 1/2, step 2453/107898 completed (loss: 1.889983057975769, acc: 0.6666666865348816)
[2025-01-30 02:05:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2455/107898 [13:23<9:10:41,  3.19it/s][2025-01-30 02:05:33][root][INFO] - Training Epoch: 1/2, step 2454/107898 completed (loss: 0.8317427039146423, acc: 0.8235294222831726)
[2025-01-30 02:05:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2456/107898 [13:23<9:13:11,  3.18it/s][2025-01-30 02:05:33][root][INFO] - Training Epoch: 1/2, step 2455/107898 completed (loss: 1.028803825378418, acc: 0.8888888955116272)
[2025-01-30 02:05:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2457/107898 [13:24<9:05:42,  3.22it/s][2025-01-30 02:05:33][root][INFO] - Training Epoch: 1/2, step 2456/107898 completed (loss: 1.1969850063323975, acc: 0.7777777910232544)
[2025-01-30 02:05:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2458/107898 [13:24<8:56:48,  3.27it/s][2025-01-30 02:05:34][root][INFO] - Training Epoch: 1/2, step 2457/107898 completed (loss: 0.4722047448158264, acc: 1.0)
[2025-01-30 02:05:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2459/107898 [13:24<9:10:21,  3.19it/s][2025-01-30 02:05:34][root][INFO] - Training Epoch: 1/2, step 2458/107898 completed (loss: 0.40707114338874817, acc: 0.9354838728904724)
[2025-01-30 02:05:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2460/107898 [13:24<9:06:53,  3.21it/s][2025-01-30 02:05:34][root][INFO] - Training Epoch: 1/2, step 2459/107898 completed (loss: 1.933813452720642, acc: 0.6499999761581421)
[2025-01-30 02:05:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2461/107898 [13:25<9:10:53,  3.19it/s][2025-01-30 02:05:35][root][INFO] - Training Epoch: 1/2, step 2460/107898 completed (loss: 2.5575766563415527, acc: 0.625)
[2025-01-30 02:05:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2462/107898 [13:25<8:59:02,  3.26it/s][2025-01-30 02:05:35][root][INFO] - Training Epoch: 1/2, step 2461/107898 completed (loss: 1.9255973100662231, acc: 0.5555555820465088)
[2025-01-30 02:05:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2463/107898 [13:25<8:53:00,  3.30it/s][2025-01-30 02:05:35][root][INFO] - Training Epoch: 1/2, step 2462/107898 completed (loss: 2.9627628326416016, acc: 0.4000000059604645)
[2025-01-30 02:05:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2464/107898 [13:26<9:04:06,  3.23it/s][2025-01-30 02:05:35][root][INFO] - Training Epoch: 1/2, step 2463/107898 completed (loss: 2.2020483016967773, acc: 0.6206896305084229)
[2025-01-30 02:05:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2465/107898 [13:26<9:27:00,  3.10it/s][2025-01-30 02:05:36][root][INFO] - Training Epoch: 1/2, step 2464/107898 completed (loss: 0.008737949654459953, acc: 1.0)
[2025-01-30 02:05:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2466/107898 [13:26<9:35:12,  3.05it/s][2025-01-30 02:05:36][root][INFO] - Training Epoch: 1/2, step 2465/107898 completed (loss: 0.34691762924194336, acc: 0.8333333134651184)
[2025-01-30 02:05:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2467/107898 [13:27<9:31:36,  3.07it/s][2025-01-30 02:05:37][root][INFO] - Training Epoch: 1/2, step 2466/107898 completed (loss: 1.825642704963684, acc: 0.5)
[2025-01-30 02:05:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2468/107898 [13:27<9:14:54,  3.17it/s][2025-01-30 02:05:37][root][INFO] - Training Epoch: 1/2, step 2467/107898 completed (loss: 0.3871931731700897, acc: 1.0)
[2025-01-30 02:05:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2469/107898 [13:27<9:01:01,  3.25it/s][2025-01-30 02:05:37][root][INFO] - Training Epoch: 1/2, step 2468/107898 completed (loss: 2.6146373748779297, acc: 0.5)
[2025-01-30 02:05:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2470/107898 [13:28<9:18:47,  3.14it/s][2025-01-30 02:05:37][root][INFO] - Training Epoch: 1/2, step 2469/107898 completed (loss: 0.5884969830513, acc: 0.8333333134651184)
[2025-01-30 02:05:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2471/107898 [13:28<9:23:54,  3.12it/s][2025-01-30 02:05:38][root][INFO] - Training Epoch: 1/2, step 2470/107898 completed (loss: 0.505744993686676, acc: 0.9285714030265808)
[2025-01-30 02:05:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2472/107898 [13:28<9:11:42,  3.18it/s][2025-01-30 02:05:38][root][INFO] - Training Epoch: 1/2, step 2471/107898 completed (loss: 0.7265245914459229, acc: 0.75)
[2025-01-30 02:05:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2473/107898 [13:29<9:05:52,  3.22it/s][2025-01-30 02:05:38][root][INFO] - Training Epoch: 1/2, step 2472/107898 completed (loss: 4.141189098358154, acc: 0.5)
[2025-01-30 02:05:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2474/107898 [13:29<9:33:59,  3.06it/s][2025-01-30 02:05:39][root][INFO] - Training Epoch: 1/2, step 2473/107898 completed (loss: 0.1615639328956604, acc: 1.0)
[2025-01-30 02:05:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2475/107898 [13:29<9:47:17,  2.99it/s][2025-01-30 02:05:39][root][INFO] - Training Epoch: 1/2, step 2474/107898 completed (loss: 2.9299869537353516, acc: 0.3333333432674408)
[2025-01-30 02:05:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2476/107898 [13:30<9:53:07,  2.96it/s][2025-01-30 02:05:39][root][INFO] - Training Epoch: 1/2, step 2475/107898 completed (loss: 0.22202415764331818, acc: 1.0)
[2025-01-30 02:05:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2477/107898 [13:30<10:10:16,  2.88it/s][2025-01-30 02:05:40][root][INFO] - Training Epoch: 1/2, step 2476/107898 completed (loss: 0.24538812041282654, acc: 0.9523809552192688)
[2025-01-30 02:05:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2478/107898 [13:30<10:05:43,  2.90it/s][2025-01-30 02:05:40][root][INFO] - Training Epoch: 1/2, step 2477/107898 completed (loss: 0.6739923357963562, acc: 0.75)
[2025-01-30 02:05:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2479/107898 [13:31<9:40:59,  3.02it/s] [2025-01-30 02:05:40][root][INFO] - Training Epoch: 1/2, step 2478/107898 completed (loss: 0.7940354347229004, acc: 0.8571428656578064)
[2025-01-30 02:05:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2480/107898 [13:31<9:31:23,  3.07it/s][2025-01-30 02:05:41][root][INFO] - Training Epoch: 1/2, step 2479/107898 completed (loss: 0.6145384907722473, acc: 0.8571428656578064)
[2025-01-30 02:05:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2481/107898 [13:31<9:18:26,  3.15it/s][2025-01-30 02:05:41][root][INFO] - Training Epoch: 1/2, step 2480/107898 completed (loss: 0.31117603182792664, acc: 0.8947368264198303)
[2025-01-30 02:05:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2482/107898 [13:32<9:16:55,  3.15it/s][2025-01-30 02:05:41][root][INFO] - Training Epoch: 1/2, step 2481/107898 completed (loss: 1.7861422300338745, acc: 0.5333333611488342)
[2025-01-30 02:05:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2483/107898 [13:32<9:40:47,  3.03it/s][2025-01-30 02:05:42][root][INFO] - Training Epoch: 1/2, step 2482/107898 completed (loss: 0.30200257897377014, acc: 0.9375)
[2025-01-30 02:05:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2484/107898 [13:32<9:53:18,  2.96it/s][2025-01-30 02:05:42][root][INFO] - Training Epoch: 1/2, step 2483/107898 completed (loss: 0.2625523805618286, acc: 0.9473684430122375)
[2025-01-30 02:05:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2485/107898 [13:33<9:45:49,  3.00it/s][2025-01-30 02:05:42][root][INFO] - Training Epoch: 1/2, step 2484/107898 completed (loss: 4.331538200378418, acc: 0.4000000059604645)
[2025-01-30 02:05:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2486/107898 [13:33<9:35:53,  3.05it/s][2025-01-30 02:05:43][root][INFO] - Training Epoch: 1/2, step 2485/107898 completed (loss: 0.16974608600139618, acc: 1.0)
[2025-01-30 02:05:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2487/107898 [13:33<9:32:50,  3.07it/s][2025-01-30 02:05:43][root][INFO] - Training Epoch: 1/2, step 2486/107898 completed (loss: 0.8356406688690186, acc: 0.8333333134651184)
[2025-01-30 02:05:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2488/107898 [13:34<9:36:59,  3.04it/s][2025-01-30 02:05:43][root][INFO] - Training Epoch: 1/2, step 2487/107898 completed (loss: 1.1617299318313599, acc: 0.6666666865348816)
[2025-01-30 02:05:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2489/107898 [13:34<9:22:18,  3.12it/s][2025-01-30 02:05:44][root][INFO] - Training Epoch: 1/2, step 2488/107898 completed (loss: 0.10082654654979706, acc: 1.0)
[2025-01-30 02:05:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2490/107898 [13:34<9:08:39,  3.20it/s][2025-01-30 02:05:44][root][INFO] - Training Epoch: 1/2, step 2489/107898 completed (loss: 0.1112251952290535, acc: 1.0)
[2025-01-30 02:05:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2491/107898 [13:34<9:10:47,  3.19it/s][2025-01-30 02:05:44][root][INFO] - Training Epoch: 1/2, step 2490/107898 completed (loss: 0.6226342916488647, acc: 1.0)
[2025-01-30 02:05:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2492/107898 [13:35<9:29:35,  3.08it/s][2025-01-30 02:05:45][root][INFO] - Training Epoch: 1/2, step 2491/107898 completed (loss: 0.752349853515625, acc: 0.875)
[2025-01-30 02:05:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2493/107898 [13:35<9:34:23,  3.06it/s][2025-01-30 02:05:45][root][INFO] - Training Epoch: 1/2, step 2492/107898 completed (loss: 2.588228940963745, acc: 0.3333333432674408)
[2025-01-30 02:05:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2494/107898 [13:35<9:29:30,  3.08it/s][2025-01-30 02:05:45][root][INFO] - Training Epoch: 1/2, step 2493/107898 completed (loss: 0.521238386631012, acc: 0.7727272510528564)
[2025-01-30 02:05:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2495/107898 [13:36<9:28:46,  3.09it/s][2025-01-30 02:05:46][root][INFO] - Training Epoch: 1/2, step 2494/107898 completed (loss: 2.18829607963562, acc: 0.4285714328289032)
[2025-01-30 02:05:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2496/107898 [13:36<9:45:52,  3.00it/s][2025-01-30 02:05:46][root][INFO] - Training Epoch: 1/2, step 2495/107898 completed (loss: 0.21489360928535461, acc: 0.9677419066429138)
[2025-01-30 02:05:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2497/107898 [13:36<9:39:27,  3.03it/s][2025-01-30 02:05:46][root][INFO] - Training Epoch: 1/2, step 2496/107898 completed (loss: 0.6966454386711121, acc: 0.8387096524238586)
[2025-01-30 02:05:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2498/107898 [13:37<9:51:27,  2.97it/s][2025-01-30 02:05:47][root][INFO] - Training Epoch: 1/2, step 2497/107898 completed (loss: 0.2900785505771637, acc: 0.8823529481887817)
[2025-01-30 02:05:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2499/107898 [13:37<9:49:27,  2.98it/s][2025-01-30 02:05:47][root][INFO] - Training Epoch: 1/2, step 2498/107898 completed (loss: 1.436509609222412, acc: 0.6666666865348816)
[2025-01-30 02:05:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2500/107898 [13:37<9:37:10,  3.04it/s][2025-01-30 02:05:47][root][INFO] - Training Epoch: 1/2, step 2499/107898 completed (loss: 0.779143214225769, acc: 0.800000011920929)
[2025-01-30 02:05:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2501/107898 [13:38<9:26:57,  3.10it/s][2025-01-30 02:05:48][root][INFO] - Training Epoch: 1/2, step 2500/107898 completed (loss: 2.6331288814544678, acc: 0.375)
[2025-01-30 02:05:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2502/107898 [13:38<9:27:24,  3.10it/s][2025-01-30 02:05:48][root][INFO] - Training Epoch: 1/2, step 2501/107898 completed (loss: 1.2765215635299683, acc: 0.8333333134651184)
[2025-01-30 02:05:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2503/107898 [13:38<9:21:10,  3.13it/s][2025-01-30 02:05:48][root][INFO] - Training Epoch: 1/2, step 2502/107898 completed (loss: 0.42039117217063904, acc: 0.800000011920929)
[2025-01-30 02:05:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2504/107898 [13:39<9:34:12,  3.06it/s][2025-01-30 02:05:49][root][INFO] - Training Epoch: 1/2, step 2503/107898 completed (loss: 0.4148697555065155, acc: 1.0)
[2025-01-30 02:05:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2505/107898 [13:39<9:35:44,  3.05it/s][2025-01-30 02:05:49][root][INFO] - Training Epoch: 1/2, step 2504/107898 completed (loss: 1.3425018787384033, acc: 0.7200000286102295)
[2025-01-30 02:05:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2506/107898 [13:39<9:55:15,  2.95it/s][2025-01-30 02:05:49][root][INFO] - Training Epoch: 1/2, step 2505/107898 completed (loss: 0.08805382251739502, acc: 1.0)
[2025-01-30 02:05:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2507/107898 [13:40<9:50:18,  2.98it/s][2025-01-30 02:05:50][root][INFO] - Training Epoch: 1/2, step 2506/107898 completed (loss: 0.06983066350221634, acc: 1.0)
[2025-01-30 02:05:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2508/107898 [13:40<9:43:56,  3.01it/s][2025-01-30 02:05:50][root][INFO] - Training Epoch: 1/2, step 2507/107898 completed (loss: 1.9422727823257446, acc: 0.625)
[2025-01-30 02:05:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2509/107898 [13:40<9:39:50,  3.03it/s][2025-01-30 02:05:50][root][INFO] - Training Epoch: 1/2, step 2508/107898 completed (loss: 0.06467784941196442, acc: 1.0)
[2025-01-30 02:05:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2510/107898 [13:41<9:45:42,  3.00it/s][2025-01-30 02:05:51][root][INFO] - Training Epoch: 1/2, step 2509/107898 completed (loss: 0.5569931268692017, acc: 0.9285714030265808)
[2025-01-30 02:05:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2511/107898 [13:41<9:49:11,  2.98it/s][2025-01-30 02:05:51][root][INFO] - Training Epoch: 1/2, step 2510/107898 completed (loss: 0.269490510225296, acc: 1.0)
[2025-01-30 02:05:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2512/107898 [13:41<9:12:39,  3.18it/s][2025-01-30 02:05:51][root][INFO] - Training Epoch: 1/2, step 2511/107898 completed (loss: 0.5526759624481201, acc: 0.800000011920929)
[2025-01-30 02:05:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2513/107898 [13:42<9:01:06,  3.25it/s][2025-01-30 02:05:51][root][INFO] - Training Epoch: 1/2, step 2512/107898 completed (loss: 1.015068531036377, acc: 0.6666666865348816)
[2025-01-30 02:05:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2514/107898 [13:42<9:01:57,  3.24it/s][2025-01-30 02:05:52][root][INFO] - Training Epoch: 1/2, step 2513/107898 completed (loss: 0.8042898774147034, acc: 0.6666666865348816)
[2025-01-30 02:05:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2515/107898 [13:42<8:54:16,  3.29it/s][2025-01-30 02:05:52][root][INFO] - Training Epoch: 1/2, step 2514/107898 completed (loss: 1.2782620191574097, acc: 0.5)
[2025-01-30 02:05:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2516/107898 [13:43<8:57:33,  3.27it/s][2025-01-30 02:05:52][root][INFO] - Training Epoch: 1/2, step 2515/107898 completed (loss: 2.9677000045776367, acc: 0.25)
[2025-01-30 02:05:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2517/107898 [13:43<8:54:31,  3.29it/s][2025-01-30 02:05:53][root][INFO] - Training Epoch: 1/2, step 2516/107898 completed (loss: 0.30953431129455566, acc: 0.8571428656578064)
[2025-01-30 02:05:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2518/107898 [13:43<9:13:53,  3.17it/s][2025-01-30 02:05:53][root][INFO] - Training Epoch: 1/2, step 2517/107898 completed (loss: 0.9742392897605896, acc: 0.875)
[2025-01-30 02:05:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2519/107898 [13:44<9:27:28,  3.09it/s][2025-01-30 02:05:53][root][INFO] - Training Epoch: 1/2, step 2518/107898 completed (loss: 1.2395559549331665, acc: 0.75)
[2025-01-30 02:05:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2520/107898 [13:44<9:21:16,  3.13it/s][2025-01-30 02:05:54][root][INFO] - Training Epoch: 1/2, step 2519/107898 completed (loss: 0.1275092363357544, acc: 1.0)
[2025-01-30 02:05:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2521/107898 [13:44<9:14:59,  3.16it/s][2025-01-30 02:05:54][root][INFO] - Training Epoch: 1/2, step 2520/107898 completed (loss: 4.110880374908447, acc: 0.20000000298023224)
[2025-01-30 02:05:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2522/107898 [13:45<9:31:15,  3.07it/s][2025-01-30 02:05:54][root][INFO] - Training Epoch: 1/2, step 2521/107898 completed (loss: 0.0937410220503807, acc: 1.0)
[2025-01-30 02:05:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2523/107898 [13:45<9:35:34,  3.05it/s][2025-01-30 02:05:55][root][INFO] - Training Epoch: 1/2, step 2522/107898 completed (loss: 0.023242682218551636, acc: 1.0)
[2025-01-30 02:05:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2524/107898 [13:45<9:55:20,  2.95it/s][2025-01-30 02:05:55][root][INFO] - Training Epoch: 1/2, step 2523/107898 completed (loss: 0.08089803159236908, acc: 1.0)
[2025-01-30 02:05:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2525/107898 [13:46<9:55:07,  2.95it/s][2025-01-30 02:05:55][root][INFO] - Training Epoch: 1/2, step 2524/107898 completed (loss: 0.9278599619865417, acc: 0.75)
[2025-01-30 02:05:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2526/107898 [13:46<9:41:14,  3.02it/s][2025-01-30 02:05:56][root][INFO] - Training Epoch: 1/2, step 2525/107898 completed (loss: 0.8704991340637207, acc: 0.8260869383811951)
[2025-01-30 02:05:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2527/107898 [13:46<9:29:47,  3.08it/s][2025-01-30 02:05:56][root][INFO] - Training Epoch: 1/2, step 2526/107898 completed (loss: 0.02853100188076496, acc: 1.0)
[2025-01-30 02:05:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2528/107898 [13:47<9:29:14,  3.09it/s][2025-01-30 02:05:56][root][INFO] - Training Epoch: 1/2, step 2527/107898 completed (loss: 0.30796703696250916, acc: 0.9166666865348816)
[2025-01-30 02:05:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2529/107898 [13:47<9:15:29,  3.16it/s][2025-01-30 02:05:57][root][INFO] - Training Epoch: 1/2, step 2528/107898 completed (loss: 0.19329096376895905, acc: 0.9090909361839294)
[2025-01-30 02:05:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2530/107898 [13:47<9:27:32,  3.09it/s][2025-01-30 02:05:57][root][INFO] - Training Epoch: 1/2, step 2529/107898 completed (loss: 0.08135464787483215, acc: 1.0)
[2025-01-30 02:05:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2531/107898 [13:47<9:27:01,  3.10it/s][2025-01-30 02:05:57][root][INFO] - Training Epoch: 1/2, step 2530/107898 completed (loss: 0.37553563714027405, acc: 1.0)
[2025-01-30 02:05:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2532/107898 [13:48<9:14:50,  3.17it/s][2025-01-30 02:05:58][root][INFO] - Training Epoch: 1/2, step 2531/107898 completed (loss: 0.38864389061927795, acc: 0.6666666865348816)
[2025-01-30 02:05:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2533/107898 [13:48<10:05:31,  2.90it/s][2025-01-30 02:05:58][root][INFO] - Training Epoch: 1/2, step 2532/107898 completed (loss: 0.735438346862793, acc: 0.8333333134651184)
[2025-01-30 02:05:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2534/107898 [13:49<9:56:33,  2.94it/s] [2025-01-30 02:05:58][root][INFO] - Training Epoch: 1/2, step 2533/107898 completed (loss: 0.4422098994255066, acc: 1.0)
[2025-01-30 02:05:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2535/107898 [13:49<9:52:00,  2.97it/s][2025-01-30 02:05:59][root][INFO] - Training Epoch: 1/2, step 2534/107898 completed (loss: 1.110351324081421, acc: 0.7142857313156128)
[2025-01-30 02:05:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2536/107898 [13:49<9:50:17,  2.97it/s][2025-01-30 02:05:59][root][INFO] - Training Epoch: 1/2, step 2535/107898 completed (loss: 2.270747423171997, acc: 0.5652173757553101)
[2025-01-30 02:05:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2537/107898 [13:50<9:55:29,  2.95it/s][2025-01-30 02:05:59][root][INFO] - Training Epoch: 1/2, step 2536/107898 completed (loss: 0.00791969709098339, acc: 1.0)
[2025-01-30 02:05:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2538/107898 [13:50<9:51:17,  2.97it/s][2025-01-30 02:06:00][root][INFO] - Training Epoch: 1/2, step 2537/107898 completed (loss: 0.9505785703659058, acc: 0.7647058963775635)
[2025-01-30 02:06:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2539/107898 [13:50<9:48:59,  2.98it/s][2025-01-30 02:06:00][root][INFO] - Training Epoch: 1/2, step 2538/107898 completed (loss: 0.09512051194906235, acc: 1.0)
[2025-01-30 02:06:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2540/107898 [13:50<9:25:35,  3.10it/s][2025-01-30 02:06:00][root][INFO] - Training Epoch: 1/2, step 2539/107898 completed (loss: 0.48086273670196533, acc: 1.0)
[2025-01-30 02:06:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2541/107898 [13:51<9:28:08,  3.09it/s][2025-01-30 02:06:01][root][INFO] - Training Epoch: 1/2, step 2540/107898 completed (loss: 0.4039185345172882, acc: 0.8461538553237915)
[2025-01-30 02:06:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2542/107898 [13:51<9:05:36,  3.22it/s][2025-01-30 02:06:01][root][INFO] - Training Epoch: 1/2, step 2541/107898 completed (loss: 0.6695992350578308, acc: 0.8571428656578064)
[2025-01-30 02:06:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2543/107898 [13:51<9:09:24,  3.20it/s][2025-01-30 02:06:01][root][INFO] - Training Epoch: 1/2, step 2542/107898 completed (loss: 2.832948684692383, acc: 0.5151515007019043)
[2025-01-30 02:06:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2544/107898 [13:52<9:02:34,  3.24it/s][2025-01-30 02:06:02][root][INFO] - Training Epoch: 1/2, step 2543/107898 completed (loss: 0.23645775020122528, acc: 0.9444444179534912)
[2025-01-30 02:06:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2545/107898 [13:52<9:12:00,  3.18it/s][2025-01-30 02:06:02][root][INFO] - Training Epoch: 1/2, step 2544/107898 completed (loss: 0.14079876244068146, acc: 0.9375)
[2025-01-30 02:06:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2546/107898 [13:52<9:20:28,  3.13it/s][2025-01-30 02:06:02][root][INFO] - Training Epoch: 1/2, step 2545/107898 completed (loss: 1.5116941928863525, acc: 0.5)
[2025-01-30 02:06:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2547/107898 [13:53<9:13:41,  3.17it/s][2025-01-30 02:06:02][root][INFO] - Training Epoch: 1/2, step 2546/107898 completed (loss: 1.5453442335128784, acc: 0.5333333611488342)
[2025-01-30 02:06:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2548/107898 [13:53<9:18:35,  3.14it/s][2025-01-30 02:06:03][root][INFO] - Training Epoch: 1/2, step 2547/107898 completed (loss: 1.200311303138733, acc: 0.7931034564971924)
[2025-01-30 02:06:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2549/107898 [13:53<9:29:14,  3.08it/s][2025-01-30 02:06:03][root][INFO] - Training Epoch: 1/2, step 2548/107898 completed (loss: 0.6417067050933838, acc: 0.8999999761581421)
[2025-01-30 02:06:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2550/107898 [13:54<9:50:04,  2.98it/s][2025-01-30 02:06:03][root][INFO] - Training Epoch: 1/2, step 2549/107898 completed (loss: 0.02295392006635666, acc: 1.0)
[2025-01-30 02:06:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2551/107898 [13:54<9:36:49,  3.04it/s][2025-01-30 02:06:04][root][INFO] - Training Epoch: 1/2, step 2550/107898 completed (loss: 1.6240490674972534, acc: 0.0)
[2025-01-30 02:06:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2552/107898 [13:54<9:25:37,  3.10it/s][2025-01-30 02:06:04][root][INFO] - Training Epoch: 1/2, step 2551/107898 completed (loss: 4.939314365386963, acc: 0.3333333432674408)
[2025-01-30 02:06:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2553/107898 [13:55<9:28:29,  3.09it/s][2025-01-30 02:06:04][root][INFO] - Training Epoch: 1/2, step 2552/107898 completed (loss: 0.8727549910545349, acc: 0.9285714030265808)
[2025-01-30 02:06:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2554/107898 [13:55<9:43:00,  3.01it/s][2025-01-30 02:06:05][root][INFO] - Training Epoch: 1/2, step 2553/107898 completed (loss: 0.5332733392715454, acc: 0.8648648858070374)
[2025-01-30 02:06:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2555/107898 [13:55<9:24:38,  3.11it/s][2025-01-30 02:06:05][root][INFO] - Training Epoch: 1/2, step 2554/107898 completed (loss: 1.3107696771621704, acc: 0.7857142686843872)
[2025-01-30 02:06:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2556/107898 [13:56<9:29:19,  3.08it/s][2025-01-30 02:06:05][root][INFO] - Training Epoch: 1/2, step 2555/107898 completed (loss: 1.6843585968017578, acc: 0.6875)
[2025-01-30 02:06:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2557/107898 [13:56<9:18:06,  3.15it/s][2025-01-30 02:06:06][root][INFO] - Training Epoch: 1/2, step 2556/107898 completed (loss: 0.8362593650817871, acc: 0.6666666865348816)
[2025-01-30 02:06:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2558/107898 [13:56<9:15:57,  3.16it/s][2025-01-30 02:06:06][root][INFO] - Training Epoch: 1/2, step 2557/107898 completed (loss: 1.0186681747436523, acc: 0.8888888955116272)
[2025-01-30 02:06:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2559/107898 [13:57<9:30:30,  3.08it/s][2025-01-30 02:06:06][root][INFO] - Training Epoch: 1/2, step 2558/107898 completed (loss: 1.3427608013153076, acc: 0.8695651888847351)
[2025-01-30 02:06:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2560/107898 [13:57<9:56:03,  2.95it/s][2025-01-30 02:06:07][root][INFO] - Training Epoch: 1/2, step 2559/107898 completed (loss: 1.3403167724609375, acc: 0.7857142686843872)
[2025-01-30 02:06:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2561/107898 [13:57<9:43:13,  3.01it/s][2025-01-30 02:06:07][root][INFO] - Training Epoch: 1/2, step 2560/107898 completed (loss: 0.9688159823417664, acc: 0.5)
[2025-01-30 02:06:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2562/107898 [13:58<9:44:50,  3.00it/s][2025-01-30 02:06:07][root][INFO] - Training Epoch: 1/2, step 2561/107898 completed (loss: 0.01380363292992115, acc: 1.0)
[2025-01-30 02:06:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2563/107898 [13:58<9:47:09,  2.99it/s][2025-01-30 02:06:08][root][INFO] - Training Epoch: 1/2, step 2562/107898 completed (loss: 0.14392998814582825, acc: 1.0)
[2025-01-30 02:06:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2564/107898 [13:58<9:32:05,  3.07it/s][2025-01-30 02:06:08][root][INFO] - Training Epoch: 1/2, step 2563/107898 completed (loss: 0.008361401036381721, acc: 1.0)
[2025-01-30 02:06:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2565/107898 [13:59<9:45:31,  3.00it/s][2025-01-30 02:06:08][root][INFO] - Training Epoch: 1/2, step 2564/107898 completed (loss: 1.4652996063232422, acc: 0.6818181872367859)
[2025-01-30 02:06:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2566/107898 [13:59<9:40:11,  3.03it/s][2025-01-30 02:06:09][root][INFO] - Training Epoch: 1/2, step 2565/107898 completed (loss: 0.01800469309091568, acc: 1.0)
[2025-01-30 02:06:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2567/107898 [13:59<9:46:03,  3.00it/s][2025-01-30 02:06:09][root][INFO] - Training Epoch: 1/2, step 2566/107898 completed (loss: 1.708966612815857, acc: 0.6538461446762085)
[2025-01-30 02:06:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2568/107898 [14:00<9:45:39,  3.00it/s][2025-01-30 02:06:09][root][INFO] - Training Epoch: 1/2, step 2567/107898 completed (loss: 0.14318174123764038, acc: 1.0)
[2025-01-30 02:06:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2569/107898 [14:00<9:53:41,  2.96it/s][2025-01-30 02:06:10][root][INFO] - Training Epoch: 1/2, step 2568/107898 completed (loss: 0.6280579566955566, acc: 0.5)
[2025-01-30 02:06:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2570/107898 [14:00<10:14:04,  2.86it/s][2025-01-30 02:06:10][root][INFO] - Training Epoch: 1/2, step 2569/107898 completed (loss: 0.5457215905189514, acc: 0.90625)
[2025-01-30 02:06:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2571/107898 [14:01<10:05:14,  2.90it/s][2025-01-30 02:06:10][root][INFO] - Training Epoch: 1/2, step 2570/107898 completed (loss: 0.8693650364875793, acc: 1.0)
[2025-01-30 02:06:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2572/107898 [14:01<10:01:38,  2.92it/s][2025-01-30 02:06:11][root][INFO] - Training Epoch: 1/2, step 2571/107898 completed (loss: 0.6783837676048279, acc: 0.7599999904632568)
[2025-01-30 02:06:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2573/107898 [14:01<9:34:43,  3.05it/s] [2025-01-30 02:06:11][root][INFO] - Training Epoch: 1/2, step 2572/107898 completed (loss: 0.9912205934524536, acc: 0.7777777910232544)
[2025-01-30 02:06:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2574/107898 [14:02<9:26:43,  3.10it/s][2025-01-30 02:06:11][root][INFO] - Training Epoch: 1/2, step 2573/107898 completed (loss: 2.2889363765716553, acc: 0.4285714328289032)
[2025-01-30 02:06:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2575/107898 [14:02<9:21:21,  3.13it/s][2025-01-30 02:06:12][root][INFO] - Training Epoch: 1/2, step 2574/107898 completed (loss: 0.09032481908798218, acc: 1.0)
[2025-01-30 02:06:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2576/107898 [14:02<9:34:07,  3.06it/s][2025-01-30 02:06:12][root][INFO] - Training Epoch: 1/2, step 2575/107898 completed (loss: 1.5270657539367676, acc: 0.692307710647583)
[2025-01-30 02:06:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2577/107898 [14:03<9:22:24,  3.12it/s][2025-01-30 02:06:12][root][INFO] - Training Epoch: 1/2, step 2576/107898 completed (loss: 1.1970776319503784, acc: 0.8181818127632141)
[2025-01-30 02:06:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2578/107898 [14:03<9:05:25,  3.22it/s][2025-01-30 02:06:13][root][INFO] - Training Epoch: 1/2, step 2577/107898 completed (loss: 0.25427260994911194, acc: 1.0)
[2025-01-30 02:06:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2579/107898 [14:03<9:07:56,  3.20it/s][2025-01-30 02:06:13][root][INFO] - Training Epoch: 1/2, step 2578/107898 completed (loss: 0.08123835176229477, acc: 1.0)
[2025-01-30 02:06:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2580/107898 [14:03<9:06:30,  3.21it/s][2025-01-30 02:06:13][root][INFO] - Training Epoch: 1/2, step 2579/107898 completed (loss: 1.3677133321762085, acc: 0.7692307829856873)
[2025-01-30 02:06:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2581/107898 [14:04<9:15:00,  3.16it/s][2025-01-30 02:06:14][root][INFO] - Training Epoch: 1/2, step 2580/107898 completed (loss: 1.0581578016281128, acc: 0.8387096524238586)
[2025-01-30 02:06:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2582/107898 [14:04<9:04:05,  3.23it/s][2025-01-30 02:06:14][root][INFO] - Training Epoch: 1/2, step 2581/107898 completed (loss: 0.4333832859992981, acc: 0.9285714030265808)
[2025-01-30 02:06:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2583/107898 [14:04<9:13:51,  3.17it/s][2025-01-30 02:06:14][root][INFO] - Training Epoch: 1/2, step 2582/107898 completed (loss: 0.9413115382194519, acc: 0.8571428656578064)
[2025-01-30 02:06:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2584/107898 [14:05<9:05:00,  3.22it/s][2025-01-30 02:06:15][root][INFO] - Training Epoch: 1/2, step 2583/107898 completed (loss: 0.8907872438430786, acc: 0.8333333134651184)
[2025-01-30 02:06:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2585/107898 [14:05<9:12:51,  3.17it/s][2025-01-30 02:06:15][root][INFO] - Training Epoch: 1/2, step 2584/107898 completed (loss: 3.1298787593841553, acc: 0.6000000238418579)
[2025-01-30 02:06:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2586/107898 [14:05<9:06:14,  3.21it/s][2025-01-30 02:06:15][root][INFO] - Training Epoch: 1/2, step 2585/107898 completed (loss: 1.3813636302947998, acc: 0.6499999761581421)
[2025-01-30 02:06:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2587/107898 [14:06<9:08:09,  3.20it/s][2025-01-30 02:06:15][root][INFO] - Training Epoch: 1/2, step 2586/107898 completed (loss: 0.6593456864356995, acc: 0.7894737124443054)
[2025-01-30 02:06:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2588/107898 [14:06<9:35:14,  3.05it/s][2025-01-30 02:06:16][root][INFO] - Training Epoch: 1/2, step 2587/107898 completed (loss: 0.9508382081985474, acc: 0.8095238208770752)
[2025-01-30 02:06:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2589/107898 [14:06<9:38:18,  3.03it/s][2025-01-30 02:06:16][root][INFO] - Training Epoch: 1/2, step 2588/107898 completed (loss: 1.3997820615768433, acc: 0.4615384638309479)
[2025-01-30 02:06:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2590/107898 [14:07<9:29:01,  3.08it/s][2025-01-30 02:06:16][root][INFO] - Training Epoch: 1/2, step 2589/107898 completed (loss: 3.7844419479370117, acc: 0.3181818127632141)
[2025-01-30 02:06:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2591/107898 [14:07<9:19:03,  3.14it/s][2025-01-30 02:06:17][root][INFO] - Training Epoch: 1/2, step 2590/107898 completed (loss: 1.2226189374923706, acc: 0.7692307829856873)
[2025-01-30 02:06:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2592/107898 [14:07<9:38:55,  3.03it/s][2025-01-30 02:06:17][root][INFO] - Training Epoch: 1/2, step 2591/107898 completed (loss: 0.8951488733291626, acc: 0.90625)
[2025-01-30 02:06:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2593/107898 [14:08<9:27:19,  3.09it/s][2025-01-30 02:06:17][root][INFO] - Training Epoch: 1/2, step 2592/107898 completed (loss: 0.06278420984745026, acc: 1.0)
[2025-01-30 02:06:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2594/107898 [14:08<9:21:47,  3.12it/s][2025-01-30 02:06:18][root][INFO] - Training Epoch: 1/2, step 2593/107898 completed (loss: 2.2915542125701904, acc: 0.6428571343421936)
[2025-01-30 02:06:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2595/107898 [14:08<9:37:03,  3.04it/s][2025-01-30 02:06:18][root][INFO] - Training Epoch: 1/2, step 2594/107898 completed (loss: 0.21007996797561646, acc: 0.9375)
[2025-01-30 02:06:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2596/107898 [14:09<9:50:47,  2.97it/s][2025-01-30 02:06:18][root][INFO] - Training Epoch: 1/2, step 2595/107898 completed (loss: 3.322392463684082, acc: 0.5)
[2025-01-30 02:06:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2597/107898 [14:09<10:05:49,  2.90it/s][2025-01-30 02:06:19][root][INFO] - Training Epoch: 1/2, step 2596/107898 completed (loss: 0.26741155982017517, acc: 0.9166666865348816)
[2025-01-30 02:06:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2598/107898 [14:09<10:04:17,  2.90it/s][2025-01-30 02:06:19][root][INFO] - Training Epoch: 1/2, step 2597/107898 completed (loss: 2.86260986328125, acc: 0.4615384638309479)
[2025-01-30 02:06:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2599/107898 [14:10<9:45:20,  3.00it/s] [2025-01-30 02:06:19][root][INFO] - Training Epoch: 1/2, step 2598/107898 completed (loss: 1.1751196384429932, acc: 0.7142857313156128)
[2025-01-30 02:06:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2600/107898 [14:10<9:34:51,  3.05it/s][2025-01-30 02:06:20][root][INFO] - Training Epoch: 1/2, step 2599/107898 completed (loss: 0.16769440472126007, acc: 1.0)
[2025-01-30 02:06:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2601/107898 [14:10<9:43:29,  3.01it/s][2025-01-30 02:06:20][root][INFO] - Training Epoch: 1/2, step 2600/107898 completed (loss: 1.2629773616790771, acc: 0.8571428656578064)
[2025-01-30 02:06:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2602/107898 [14:11<10:07:56,  2.89it/s][2025-01-30 02:06:21][root][INFO] - Training Epoch: 1/2, step 2601/107898 completed (loss: 0.03326476365327835, acc: 1.0)
[2025-01-30 02:06:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2603/107898 [14:11<9:49:55,  2.97it/s] [2025-01-30 02:06:21][root][INFO] - Training Epoch: 1/2, step 2602/107898 completed (loss: 0.25351396203041077, acc: 1.0)
[2025-01-30 02:06:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2604/107898 [14:11<10:06:06,  2.90it/s][2025-01-30 02:06:21][root][INFO] - Training Epoch: 1/2, step 2603/107898 completed (loss: 1.236232042312622, acc: 0.7142857313156128)
[2025-01-30 02:06:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2605/107898 [14:12<10:02:19,  2.91it/s][2025-01-30 02:06:22][root][INFO] - Training Epoch: 1/2, step 2604/107898 completed (loss: 0.29169604182243347, acc: 1.0)
[2025-01-30 02:06:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2606/107898 [14:12<9:56:58,  2.94it/s] [2025-01-30 02:06:22][root][INFO] - Training Epoch: 1/2, step 2605/107898 completed (loss: 2.2621002197265625, acc: 0.4000000059604645)
[2025-01-30 02:06:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2607/107898 [14:12<9:49:02,  2.98it/s][2025-01-30 02:06:22][root][INFO] - Training Epoch: 1/2, step 2606/107898 completed (loss: 3.613471031188965, acc: 0.1818181872367859)
[2025-01-30 02:06:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2608/107898 [14:13<9:50:34,  2.97it/s][2025-01-30 02:06:23][root][INFO] - Training Epoch: 1/2, step 2607/107898 completed (loss: 0.011317839846014977, acc: 1.0)
[2025-01-30 02:06:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2609/107898 [14:13<10:04:12,  2.90it/s][2025-01-30 02:06:23][root][INFO] - Training Epoch: 1/2, step 2608/107898 completed (loss: 0.9045858979225159, acc: 0.75)
[2025-01-30 02:06:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2610/107898 [14:13<10:03:32,  2.91it/s][2025-01-30 02:06:23][root][INFO] - Training Epoch: 1/2, step 2609/107898 completed (loss: 1.3483906984329224, acc: 0.7142857313156128)
[2025-01-30 02:06:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2611/107898 [14:14<10:05:22,  2.90it/s][2025-01-30 02:06:24][root][INFO] - Training Epoch: 1/2, step 2610/107898 completed (loss: 0.38984477519989014, acc: 0.9090909361839294)
[2025-01-30 02:06:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2612/107898 [14:14<9:45:45,  3.00it/s] [2025-01-30 02:06:24][root][INFO] - Training Epoch: 1/2, step 2611/107898 completed (loss: 1.7601984739303589, acc: 0.6363636255264282)
[2025-01-30 02:06:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2613/107898 [14:14<9:25:09,  3.10it/s][2025-01-30 02:06:24][root][INFO] - Training Epoch: 1/2, step 2612/107898 completed (loss: 2.134213924407959, acc: 0.25)
[2025-01-30 02:06:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2614/107898 [14:15<9:10:58,  3.18it/s][2025-01-30 02:06:24][root][INFO] - Training Epoch: 1/2, step 2613/107898 completed (loss: 0.1598876565694809, acc: 1.0)
[2025-01-30 02:06:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2615/107898 [14:15<9:08:17,  3.20it/s][2025-01-30 02:06:25][root][INFO] - Training Epoch: 1/2, step 2614/107898 completed (loss: 1.9002008438110352, acc: 0.699999988079071)
[2025-01-30 02:06:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2616/107898 [14:15<9:07:05,  3.21it/s][2025-01-30 02:06:25][root][INFO] - Training Epoch: 1/2, step 2615/107898 completed (loss: 0.03388184681534767, acc: 1.0)
[2025-01-30 02:06:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2617/107898 [14:16<9:26:36,  3.10it/s][2025-01-30 02:06:25][root][INFO] - Training Epoch: 1/2, step 2616/107898 completed (loss: 3.083371639251709, acc: 0.2857142984867096)
[2025-01-30 02:06:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2618/107898 [14:16<9:41:30,  3.02it/s][2025-01-30 02:06:26][root][INFO] - Training Epoch: 1/2, step 2617/107898 completed (loss: 0.10041949152946472, acc: 1.0)
[2025-01-30 02:06:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2619/107898 [14:16<9:54:31,  2.95it/s][2025-01-30 02:06:26][root][INFO] - Training Epoch: 1/2, step 2618/107898 completed (loss: 0.6745385527610779, acc: 0.6666666865348816)
[2025-01-30 02:06:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2620/107898 [14:17<9:52:50,  2.96it/s][2025-01-30 02:06:26][root][INFO] - Training Epoch: 1/2, step 2619/107898 completed (loss: 1.0541808605194092, acc: 0.875)
[2025-01-30 02:06:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2621/107898 [14:17<9:50:31,  2.97it/s][2025-01-30 02:06:27][root][INFO] - Training Epoch: 1/2, step 2620/107898 completed (loss: 0.01727633737027645, acc: 1.0)
[2025-01-30 02:06:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2622/107898 [14:17<9:36:15,  3.04it/s][2025-01-30 02:06:27][root][INFO] - Training Epoch: 1/2, step 2621/107898 completed (loss: 0.12232957035303116, acc: 1.0)
[2025-01-30 02:06:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2623/107898 [14:18<9:40:59,  3.02it/s][2025-01-30 02:06:27][root][INFO] - Training Epoch: 1/2, step 2622/107898 completed (loss: 0.42406824231147766, acc: 0.8571428656578064)
[2025-01-30 02:06:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2624/107898 [14:18<9:31:23,  3.07it/s][2025-01-30 02:06:28][root][INFO] - Training Epoch: 1/2, step 2623/107898 completed (loss: 1.892910361289978, acc: 0.6666666865348816)
[2025-01-30 02:06:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2625/107898 [14:18<9:20:05,  3.13it/s][2025-01-30 02:06:28][root][INFO] - Training Epoch: 1/2, step 2624/107898 completed (loss: 0.036059845238924026, acc: 1.0)
[2025-01-30 02:06:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2626/107898 [14:19<9:14:27,  3.16it/s][2025-01-30 02:06:28][root][INFO] - Training Epoch: 1/2, step 2625/107898 completed (loss: 4.09983491897583, acc: 0.4000000059604645)
[2025-01-30 02:06:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2627/107898 [14:19<9:28:27,  3.09it/s][2025-01-30 02:06:29][root][INFO] - Training Epoch: 1/2, step 2626/107898 completed (loss: 3.7571232318878174, acc: 0.20000000298023224)
[2025-01-30 02:06:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2628/107898 [14:19<10:01:44,  2.92it/s][2025-01-30 02:06:29][root][INFO] - Training Epoch: 1/2, step 2627/107898 completed (loss: 1.0132733583450317, acc: 0.800000011920929)
[2025-01-30 02:06:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2629/107898 [14:20<9:57:17,  2.94it/s] [2025-01-30 02:06:29][root][INFO] - Training Epoch: 1/2, step 2628/107898 completed (loss: 0.14193180203437805, acc: 1.0)
[2025-01-30 02:06:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2630/107898 [14:20<9:49:32,  2.98it/s][2025-01-30 02:06:30][root][INFO] - Training Epoch: 1/2, step 2629/107898 completed (loss: 4.944568157196045, acc: 0.1666666716337204)
[2025-01-30 02:06:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2631/107898 [14:20<9:57:38,  2.94it/s][2025-01-30 02:06:30][root][INFO] - Training Epoch: 1/2, step 2630/107898 completed (loss: 0.5695837736129761, acc: 0.699999988079071)
[2025-01-30 02:06:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2632/107898 [14:21<10:09:16,  2.88it/s][2025-01-30 02:06:31][root][INFO] - Training Epoch: 1/2, step 2631/107898 completed (loss: 0.32052651047706604, acc: 1.0)
[2025-01-30 02:06:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2633/107898 [14:21<10:02:36,  2.91it/s][2025-01-30 02:06:31][root][INFO] - Training Epoch: 1/2, step 2632/107898 completed (loss: 0.09734349697828293, acc: 1.0)
[2025-01-30 02:06:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2634/107898 [14:21<9:52:33,  2.96it/s] [2025-01-30 02:06:31][root][INFO] - Training Epoch: 1/2, step 2633/107898 completed (loss: 0.41630253195762634, acc: 0.9375)
[2025-01-30 02:06:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2635/107898 [14:22<10:03:37,  2.91it/s][2025-01-30 02:06:32][root][INFO] - Training Epoch: 1/2, step 2634/107898 completed (loss: 0.031211184337735176, acc: 1.0)
[2025-01-30 02:06:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2636/107898 [14:22<9:54:39,  2.95it/s] [2025-01-30 02:06:32][root][INFO] - Training Epoch: 1/2, step 2635/107898 completed (loss: 0.6220046877861023, acc: 1.0)
[2025-01-30 02:06:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2637/107898 [14:22<9:32:26,  3.06it/s][2025-01-30 02:06:32][root][INFO] - Training Epoch: 1/2, step 2636/107898 completed (loss: 0.5386978983879089, acc: 0.6666666865348816)
[2025-01-30 02:06:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2638/107898 [14:23<9:23:43,  3.11it/s][2025-01-30 02:06:32][root][INFO] - Training Epoch: 1/2, step 2637/107898 completed (loss: 0.09759978950023651, acc: 1.0)
[2025-01-30 02:06:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2639/107898 [14:23<9:13:55,  3.17it/s][2025-01-30 02:06:33][root][INFO] - Training Epoch: 1/2, step 2638/107898 completed (loss: 0.6769715547561646, acc: 0.807692289352417)
[2025-01-30 02:06:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2640/107898 [14:23<9:26:00,  3.10it/s][2025-01-30 02:06:33][root][INFO] - Training Epoch: 1/2, step 2639/107898 completed (loss: 2.861175775527954, acc: 0.4285714328289032)
[2025-01-30 02:06:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2641/107898 [14:24<9:31:03,  3.07it/s][2025-01-30 02:06:33][root][INFO] - Training Epoch: 1/2, step 2640/107898 completed (loss: 0.529904305934906, acc: 0.8333333134651184)
[2025-01-30 02:06:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2642/107898 [14:24<9:34:58,  3.05it/s][2025-01-30 02:06:34][root][INFO] - Training Epoch: 1/2, step 2641/107898 completed (loss: 0.24092631042003632, acc: 1.0)
[2025-01-30 02:06:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2643/107898 [14:24<9:33:06,  3.06it/s][2025-01-30 02:06:34][root][INFO] - Training Epoch: 1/2, step 2642/107898 completed (loss: 0.669240415096283, acc: 0.8333333134651184)
[2025-01-30 02:06:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2644/107898 [14:25<9:16:39,  3.15it/s][2025-01-30 02:06:34][root][INFO] - Training Epoch: 1/2, step 2643/107898 completed (loss: 0.6769157648086548, acc: 0.8888888955116272)
[2025-01-30 02:06:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2645/107898 [14:25<9:14:12,  3.17it/s][2025-01-30 02:06:35][root][INFO] - Training Epoch: 1/2, step 2644/107898 completed (loss: 0.11100517958402634, acc: 1.0)
[2025-01-30 02:06:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2646/107898 [14:25<9:20:34,  3.13it/s][2025-01-30 02:06:35][root][INFO] - Training Epoch: 1/2, step 2645/107898 completed (loss: 0.4025951325893402, acc: 0.6666666865348816)
[2025-01-30 02:06:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2647/107898 [14:26<9:28:55,  3.08it/s][2025-01-30 02:06:35][root][INFO] - Training Epoch: 1/2, step 2646/107898 completed (loss: 0.8214578032493591, acc: 0.800000011920929)
[2025-01-30 02:06:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2648/107898 [14:26<9:47:36,  2.99it/s][2025-01-30 02:06:36][root][INFO] - Training Epoch: 1/2, step 2647/107898 completed (loss: 0.5423799753189087, acc: 0.75)
[2025-01-30 02:06:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2649/107898 [14:26<9:42:00,  3.01it/s][2025-01-30 02:06:36][root][INFO] - Training Epoch: 1/2, step 2648/107898 completed (loss: 2.181267023086548, acc: 0.6000000238418579)
[2025-01-30 02:06:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2650/107898 [14:27<9:30:59,  3.07it/s][2025-01-30 02:06:36][root][INFO] - Training Epoch: 1/2, step 2649/107898 completed (loss: 0.007449753116816282, acc: 1.0)
[2025-01-30 02:06:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2651/107898 [14:27<9:20:39,  3.13it/s][2025-01-30 02:06:37][root][INFO] - Training Epoch: 1/2, step 2650/107898 completed (loss: 0.28122377395629883, acc: 1.0)
[2025-01-30 02:06:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2652/107898 [14:27<9:18:56,  3.14it/s][2025-01-30 02:06:37][root][INFO] - Training Epoch: 1/2, step 2651/107898 completed (loss: 2.118748664855957, acc: 0.6666666865348816)
[2025-01-30 02:06:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2653/107898 [14:27<9:08:11,  3.20it/s][2025-01-30 02:06:37][root][INFO] - Training Epoch: 1/2, step 2652/107898 completed (loss: 2.874882936477661, acc: 0.5384615659713745)
[2025-01-30 02:06:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2654/107898 [14:28<9:28:12,  3.09it/s][2025-01-30 02:06:38][root][INFO] - Training Epoch: 1/2, step 2653/107898 completed (loss: 4.947050094604492, acc: 0.5)
[2025-01-30 02:06:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2655/107898 [14:28<9:33:00,  3.06it/s][2025-01-30 02:06:38][root][INFO] - Training Epoch: 1/2, step 2654/107898 completed (loss: 2.8952198028564453, acc: 0.3333333432674408)
[2025-01-30 02:06:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2656/107898 [14:28<9:34:08,  3.06it/s][2025-01-30 02:06:38][root][INFO] - Training Epoch: 1/2, step 2655/107898 completed (loss: 0.2930576503276825, acc: 0.8571428656578064)
[2025-01-30 02:06:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2657/107898 [14:29<9:33:07,  3.06it/s][2025-01-30 02:06:39][root][INFO] - Training Epoch: 1/2, step 2656/107898 completed (loss: 1.6219446659088135, acc: 0.8095238208770752)
[2025-01-30 02:06:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2658/107898 [14:29<9:23:44,  3.11it/s][2025-01-30 02:06:39][root][INFO] - Training Epoch: 1/2, step 2657/107898 completed (loss: 2.236698865890503, acc: 0.5)
[2025-01-30 02:06:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2659/107898 [14:29<9:13:19,  3.17it/s][2025-01-30 02:06:39][root][INFO] - Training Epoch: 1/2, step 2658/107898 completed (loss: 1.292026400566101, acc: 0.5714285969734192)
[2025-01-30 02:06:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2660/107898 [14:30<9:20:41,  3.13it/s][2025-01-30 02:06:40][root][INFO] - Training Epoch: 1/2, step 2659/107898 completed (loss: 0.9197359681129456, acc: 0.8620689511299133)
[2025-01-30 02:06:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2661/107898 [14:30<9:29:18,  3.08it/s][2025-01-30 02:06:40][root][INFO] - Training Epoch: 1/2, step 2660/107898 completed (loss: 1.6205649375915527, acc: 0.6666666865348816)
[2025-01-30 02:06:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2662/107898 [14:30<9:32:46,  3.06it/s][2025-01-30 02:06:40][root][INFO] - Training Epoch: 1/2, step 2661/107898 completed (loss: 1.2446644306182861, acc: 0.5)
[2025-01-30 02:06:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2663/107898 [14:31<9:24:38,  3.11it/s][2025-01-30 02:06:41][root][INFO] - Training Epoch: 1/2, step 2662/107898 completed (loss: 0.03157564625144005, acc: 1.0)
[2025-01-30 02:06:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2664/107898 [14:31<9:12:38,  3.17it/s][2025-01-30 02:06:41][root][INFO] - Training Epoch: 1/2, step 2663/107898 completed (loss: 0.5248986482620239, acc: 1.0)
[2025-01-30 02:06:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2665/107898 [14:31<9:11:49,  3.18it/s][2025-01-30 02:06:41][root][INFO] - Training Epoch: 1/2, step 2664/107898 completed (loss: 0.3561634123325348, acc: 1.0)
[2025-01-30 02:06:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2666/107898 [14:32<8:59:24,  3.25it/s][2025-01-30 02:06:41][root][INFO] - Training Epoch: 1/2, step 2665/107898 completed (loss: 1.3670635223388672, acc: 0.0)
[2025-01-30 02:06:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2667/107898 [14:32<8:52:13,  3.30it/s][2025-01-30 02:06:42][root][INFO] - Training Epoch: 1/2, step 2666/107898 completed (loss: 2.4856715202331543, acc: 0.5333333611488342)
[2025-01-30 02:06:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2668/107898 [14:32<8:53:28,  3.29it/s][2025-01-30 02:06:42][root][INFO] - Training Epoch: 1/2, step 2667/107898 completed (loss: 0.3683188259601593, acc: 0.8999999761581421)
[2025-01-30 02:06:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2669/107898 [14:33<8:56:15,  3.27it/s][2025-01-30 02:06:42][root][INFO] - Training Epoch: 1/2, step 2668/107898 completed (loss: 1.8635164499282837, acc: 0.75)
[2025-01-30 02:06:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2670/107898 [14:33<9:30:26,  3.07it/s][2025-01-30 02:06:43][root][INFO] - Training Epoch: 1/2, step 2669/107898 completed (loss: 0.6824718713760376, acc: 0.8484848737716675)
[2025-01-30 02:06:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2671/107898 [14:33<9:33:13,  3.06it/s][2025-01-30 02:06:43][root][INFO] - Training Epoch: 1/2, step 2670/107898 completed (loss: 2.5246808528900146, acc: 0.6000000238418579)
[2025-01-30 02:06:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2672/107898 [14:34<9:32:47,  3.06it/s][2025-01-30 02:06:43][root][INFO] - Training Epoch: 1/2, step 2671/107898 completed (loss: 0.836997389793396, acc: 0.5)
[2025-01-30 02:06:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2673/107898 [14:34<9:37:39,  3.04it/s][2025-01-30 02:06:44][root][INFO] - Training Epoch: 1/2, step 2672/107898 completed (loss: 0.538802444934845, acc: 0.8947368264198303)
[2025-01-30 02:06:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2674/107898 [14:34<9:26:56,  3.09it/s][2025-01-30 02:06:44][root][INFO] - Training Epoch: 1/2, step 2673/107898 completed (loss: 0.5508812665939331, acc: 0.8695651888847351)
[2025-01-30 02:06:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2675/107898 [14:35<9:04:30,  3.22it/s][2025-01-30 02:06:44][root][INFO] - Training Epoch: 1/2, step 2674/107898 completed (loss: 2.5131759643554688, acc: 0.5)
[2025-01-30 02:06:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2676/107898 [14:35<8:54:03,  3.28it/s][2025-01-30 02:06:45][root][INFO] - Training Epoch: 1/2, step 2675/107898 completed (loss: 0.20995298027992249, acc: 1.0)
[2025-01-30 02:06:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2677/107898 [14:35<9:08:19,  3.20it/s][2025-01-30 02:06:45][root][INFO] - Training Epoch: 1/2, step 2676/107898 completed (loss: 1.1052957773208618, acc: 0.6666666865348816)
[2025-01-30 02:06:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2678/107898 [14:35<9:34:12,  3.05it/s][2025-01-30 02:06:45][root][INFO] - Training Epoch: 1/2, step 2677/107898 completed (loss: 1.5537840127944946, acc: 0.6666666865348816)
[2025-01-30 02:06:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2679/107898 [14:36<9:48:49,  2.98it/s][2025-01-30 02:06:46][root][INFO] - Training Epoch: 1/2, step 2678/107898 completed (loss: 2.5793044567108154, acc: 0.5600000023841858)
[2025-01-30 02:06:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2680/107898 [14:36<9:41:47,  3.01it/s][2025-01-30 02:06:46][root][INFO] - Training Epoch: 1/2, step 2679/107898 completed (loss: 0.4067252576351166, acc: 0.949999988079071)
[2025-01-30 02:06:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2681/107898 [14:37<9:52:01,  2.96it/s][2025-01-30 02:06:46][root][INFO] - Training Epoch: 1/2, step 2680/107898 completed (loss: 0.1929694414138794, acc: 1.0)
[2025-01-30 02:06:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2682/107898 [14:37<9:37:53,  3.03it/s][2025-01-30 02:06:47][root][INFO] - Training Epoch: 1/2, step 2681/107898 completed (loss: 3.988884210586548, acc: 0.3333333432674408)
[2025-01-30 02:06:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2683/107898 [14:37<9:26:03,  3.10it/s][2025-01-30 02:06:47][root][INFO] - Training Epoch: 1/2, step 2682/107898 completed (loss: 0.8573974967002869, acc: 1.0)
[2025-01-30 02:06:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2684/107898 [14:38<9:49:43,  2.97it/s][2025-01-30 02:06:47][root][INFO] - Training Epoch: 1/2, step 2683/107898 completed (loss: 0.012936970219016075, acc: 1.0)
[2025-01-30 02:06:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2685/107898 [14:38<9:45:25,  3.00it/s][2025-01-30 02:06:48][root][INFO] - Training Epoch: 1/2, step 2684/107898 completed (loss: 0.152683824300766, acc: 1.0)
[2025-01-30 02:06:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2686/107898 [14:38<9:35:00,  3.05it/s][2025-01-30 02:06:48][root][INFO] - Training Epoch: 1/2, step 2685/107898 completed (loss: 1.6896567344665527, acc: 0.5)
[2025-01-30 02:06:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2687/107898 [14:38<9:23:39,  3.11it/s][2025-01-30 02:06:48][root][INFO] - Training Epoch: 1/2, step 2686/107898 completed (loss: 0.2896794080734253, acc: 1.0)
[2025-01-30 02:06:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2688/107898 [14:39<9:44:38,  3.00it/s][2025-01-30 02:06:49][root][INFO] - Training Epoch: 1/2, step 2687/107898 completed (loss: 2.113978624343872, acc: 0.5714285969734192)
[2025-01-30 02:06:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2689/107898 [14:39<9:43:48,  3.00it/s][2025-01-30 02:06:49][root][INFO] - Training Epoch: 1/2, step 2688/107898 completed (loss: 2.844841480255127, acc: 0.625)
[2025-01-30 02:06:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2690/107898 [14:39<9:34:10,  3.05it/s][2025-01-30 02:06:49][root][INFO] - Training Epoch: 1/2, step 2689/107898 completed (loss: 0.046925321221351624, acc: 1.0)
[2025-01-30 02:06:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2691/107898 [14:40<9:09:56,  3.19it/s][2025-01-30 02:06:50][root][INFO] - Training Epoch: 1/2, step 2690/107898 completed (loss: 0.9497596025466919, acc: 0.4285714328289032)
[2025-01-30 02:06:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2692/107898 [14:40<9:10:48,  3.18it/s][2025-01-30 02:06:50][root][INFO] - Training Epoch: 1/2, step 2691/107898 completed (loss: 0.012534800916910172, acc: 1.0)
[2025-01-30 02:06:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2693/107898 [14:40<9:07:09,  3.20it/s][2025-01-30 02:06:50][root][INFO] - Training Epoch: 1/2, step 2692/107898 completed (loss: 1.5811980962753296, acc: 0.800000011920929)
[2025-01-30 02:06:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2694/107898 [14:41<9:20:51,  3.13it/s][2025-01-30 02:06:50][root][INFO] - Training Epoch: 1/2, step 2693/107898 completed (loss: 5.564630508422852, acc: 0.3333333432674408)
[2025-01-30 02:06:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2695/107898 [14:41<9:23:13,  3.11it/s][2025-01-30 02:06:51][root][INFO] - Training Epoch: 1/2, step 2694/107898 completed (loss: 2.5436930656433105, acc: 0.5)
[2025-01-30 02:06:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2696/107898 [14:41<9:11:09,  3.18it/s][2025-01-30 02:06:51][root][INFO] - Training Epoch: 1/2, step 2695/107898 completed (loss: 4.312069892883301, acc: 0.4000000059604645)
[2025-01-30 02:06:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   2%|[34mâ–         [0m| 2697/107898 [14:42<9:11:46,  3.18it/s][2025-01-30 02:06:51][root][INFO] - Training Epoch: 1/2, step 2696/107898 completed (loss: 1.2641406059265137, acc: 0.7692307829856873)
[2025-01-30 02:06:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2698/107898 [14:42<8:59:38,  3.25it/s][2025-01-30 02:06:52][root][INFO] - Training Epoch: 1/2, step 2697/107898 completed (loss: 0.1331661492586136, acc: 1.0)
[2025-01-30 02:06:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2699/107898 [14:42<9:22:40,  3.12it/s][2025-01-30 02:06:52][root][INFO] - Training Epoch: 1/2, step 2698/107898 completed (loss: 2.4970085620880127, acc: 0.30000001192092896)
[2025-01-30 02:06:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2700/107898 [14:43<9:26:31,  3.09it/s][2025-01-30 02:06:52][root][INFO] - Training Epoch: 1/2, step 2699/107898 completed (loss: 1.6491657495498657, acc: 0.6666666865348816)
[2025-01-30 02:06:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2701/107898 [14:43<9:43:34,  3.00it/s][2025-01-30 02:06:53][root][INFO] - Training Epoch: 1/2, step 2700/107898 completed (loss: 0.7399186491966248, acc: 0.6666666865348816)
[2025-01-30 02:06:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2702/107898 [14:43<9:40:14,  3.02it/s][2025-01-30 02:06:53][root][INFO] - Training Epoch: 1/2, step 2701/107898 completed (loss: 0.01906372234225273, acc: 1.0)
[2025-01-30 02:06:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2703/107898 [14:44<9:57:35,  2.93it/s][2025-01-30 02:06:53][root][INFO] - Training Epoch: 1/2, step 2702/107898 completed (loss: 0.24459461867809296, acc: 0.949999988079071)
[2025-01-30 02:06:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2704/107898 [14:44<9:31:20,  3.07it/s][2025-01-30 02:06:54][root][INFO] - Training Epoch: 1/2, step 2703/107898 completed (loss: 0.03284215182065964, acc: 1.0)
[2025-01-30 02:06:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2705/107898 [14:44<9:17:29,  3.14it/s][2025-01-30 02:06:54][root][INFO] - Training Epoch: 1/2, step 2704/107898 completed (loss: 0.02581683173775673, acc: 1.0)
[2025-01-30 02:06:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2706/107898 [14:45<9:31:47,  3.07it/s][2025-01-30 02:06:54][root][INFO] - Training Epoch: 1/2, step 2705/107898 completed (loss: 0.8775678873062134, acc: 0.800000011920929)
[2025-01-30 02:06:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2707/107898 [14:45<9:43:39,  3.00it/s][2025-01-30 02:06:55][root][INFO] - Training Epoch: 1/2, step 2706/107898 completed (loss: 0.3085894286632538, acc: 1.0)
[2025-01-30 02:06:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2708/107898 [14:45<9:54:29,  2.95it/s][2025-01-30 02:06:55][root][INFO] - Training Epoch: 1/2, step 2707/107898 completed (loss: 1.4885649681091309, acc: 0.75)
[2025-01-30 02:06:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2709/107898 [14:46<10:14:00,  2.86it/s][2025-01-30 02:06:55][root][INFO] - Training Epoch: 1/2, step 2708/107898 completed (loss: 1.1100695133209229, acc: 0.7857142686843872)
[2025-01-30 02:06:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2710/107898 [14:46<10:18:09,  2.84it/s][2025-01-30 02:06:56][root][INFO] - Training Epoch: 1/2, step 2709/107898 completed (loss: 1.4263811111450195, acc: 0.6666666865348816)
[2025-01-30 02:06:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2711/107898 [14:46<10:16:59,  2.84it/s][2025-01-30 02:06:56][root][INFO] - Training Epoch: 1/2, step 2710/107898 completed (loss: 2.6039276123046875, acc: 0.4285714328289032)
[2025-01-30 02:06:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2712/107898 [14:47<10:14:49,  2.85it/s][2025-01-30 02:06:57][root][INFO] - Training Epoch: 1/2, step 2711/107898 completed (loss: 1.5525983572006226, acc: 0.800000011920929)
[2025-01-30 02:06:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2713/107898 [14:47<9:59:32,  2.92it/s] [2025-01-30 02:06:57][root][INFO] - Training Epoch: 1/2, step 2712/107898 completed (loss: 1.1576255559921265, acc: 0.782608687877655)
[2025-01-30 02:06:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2714/107898 [14:47<9:45:59,  2.99it/s][2025-01-30 02:06:57][root][INFO] - Training Epoch: 1/2, step 2713/107898 completed (loss: 0.3584127724170685, acc: 0.8333333134651184)
[2025-01-30 02:06:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2715/107898 [14:48<9:53:33,  2.95it/s][2025-01-30 02:06:58][root][INFO] - Training Epoch: 1/2, step 2714/107898 completed (loss: 0.8317766785621643, acc: 0.8333333134651184)
[2025-01-30 02:06:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2716/107898 [14:48<9:51:51,  2.96it/s][2025-01-30 02:06:58][root][INFO] - Training Epoch: 1/2, step 2715/107898 completed (loss: 1.2185962200164795, acc: 0.7272727489471436)
[2025-01-30 02:06:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2717/107898 [14:48<9:44:31,  3.00it/s][2025-01-30 02:06:58][root][INFO] - Training Epoch: 1/2, step 2716/107898 completed (loss: 1.1133836507797241, acc: 0.8125)
[2025-01-30 02:06:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2718/107898 [14:49<9:29:13,  3.08it/s][2025-01-30 02:06:58][root][INFO] - Training Epoch: 1/2, step 2717/107898 completed (loss: 0.809908926486969, acc: 0.8695651888847351)
[2025-01-30 02:06:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2719/107898 [14:49<9:13:02,  3.17it/s][2025-01-30 02:06:59][root][INFO] - Training Epoch: 1/2, step 2718/107898 completed (loss: 0.5890007019042969, acc: 0.90625)
[2025-01-30 02:06:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2720/107898 [14:49<9:12:51,  3.17it/s][2025-01-30 02:06:59][root][INFO] - Training Epoch: 1/2, step 2719/107898 completed (loss: 0.7736390233039856, acc: 1.0)
[2025-01-30 02:06:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2721/107898 [14:50<9:30:28,  3.07it/s][2025-01-30 02:06:59][root][INFO] - Training Epoch: 1/2, step 2720/107898 completed (loss: 2.3400235176086426, acc: 0.5)
[2025-01-30 02:07:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2722/107898 [14:50<9:20:22,  3.13it/s][2025-01-30 02:07:00][root][INFO] - Training Epoch: 1/2, step 2721/107898 completed (loss: 0.35253942012786865, acc: 0.9230769276618958)
[2025-01-30 02:07:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2723/107898 [14:50<9:30:02,  3.08it/s][2025-01-30 02:07:00][root][INFO] - Training Epoch: 1/2, step 2722/107898 completed (loss: 1.1018375158309937, acc: 0.6666666865348816)
[2025-01-30 02:07:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2724/107898 [14:51<9:26:53,  3.09it/s][2025-01-30 02:07:00][root][INFO] - Training Epoch: 1/2, step 2723/107898 completed (loss: 0.18833650648593903, acc: 0.8888888955116272)
[2025-01-30 02:07:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2725/107898 [14:51<9:21:27,  3.12it/s][2025-01-30 02:07:01][root][INFO] - Training Epoch: 1/2, step 2724/107898 completed (loss: 0.14194367825984955, acc: 1.0)
[2025-01-30 02:07:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2726/107898 [14:51<9:19:38,  3.13it/s][2025-01-30 02:07:01][root][INFO] - Training Epoch: 1/2, step 2725/107898 completed (loss: 0.6008505821228027, acc: 0.8181818127632141)
[2025-01-30 02:07:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2727/107898 [14:52<9:07:36,  3.20it/s][2025-01-30 02:07:01][root][INFO] - Training Epoch: 1/2, step 2726/107898 completed (loss: 0.1390506625175476, acc: 0.9375)
[2025-01-30 02:07:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2728/107898 [14:52<9:05:35,  3.21it/s][2025-01-30 02:07:02][root][INFO] - Training Epoch: 1/2, step 2727/107898 completed (loss: 0.5955447554588318, acc: 0.8999999761581421)
[2025-01-30 02:07:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2729/107898 [14:52<9:05:01,  3.22it/s][2025-01-30 02:07:02][root][INFO] - Training Epoch: 1/2, step 2728/107898 completed (loss: 2.3478481769561768, acc: 0.529411792755127)
[2025-01-30 02:07:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2730/107898 [14:52<9:06:37,  3.21it/s][2025-01-30 02:07:02][root][INFO] - Training Epoch: 1/2, step 2729/107898 completed (loss: 4.222906112670898, acc: 0.27272728085517883)
[2025-01-30 02:07:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2731/107898 [14:53<9:20:40,  3.13it/s][2025-01-30 02:07:03][root][INFO] - Training Epoch: 1/2, step 2730/107898 completed (loss: 0.2540093660354614, acc: 1.0)
[2025-01-30 02:07:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2732/107898 [14:53<9:43:08,  3.01it/s][2025-01-30 02:07:03][root][INFO] - Training Epoch: 1/2, step 2731/107898 completed (loss: 0.03075351007282734, acc: 1.0)
[2025-01-30 02:07:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2733/107898 [14:53<9:43:04,  3.01it/s][2025-01-30 02:07:03][root][INFO] - Training Epoch: 1/2, step 2732/107898 completed (loss: 2.0950205326080322, acc: 0.7692307829856873)
[2025-01-30 02:07:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2734/107898 [14:54<9:56:50,  2.94it/s][2025-01-30 02:07:04][root][INFO] - Training Epoch: 1/2, step 2733/107898 completed (loss: 0.07842841744422913, acc: 1.0)
[2025-01-30 02:07:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2735/107898 [14:54<9:57:56,  2.93it/s][2025-01-30 02:07:04][root][INFO] - Training Epoch: 1/2, step 2734/107898 completed (loss: 0.45730531215667725, acc: 0.9375)
[2025-01-30 02:07:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2736/107898 [14:55<9:40:47,  3.02it/s][2025-01-30 02:07:04][root][INFO] - Training Epoch: 1/2, step 2735/107898 completed (loss: 0.11199276149272919, acc: 1.0)
[2025-01-30 02:07:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2737/107898 [14:55<9:27:21,  3.09it/s][2025-01-30 02:07:05][root][INFO] - Training Epoch: 1/2, step 2736/107898 completed (loss: 3.3439693450927734, acc: 0.2916666567325592)
[2025-01-30 02:07:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2738/107898 [14:55<9:34:26,  3.05it/s][2025-01-30 02:07:05][root][INFO] - Training Epoch: 1/2, step 2737/107898 completed (loss: 0.764868438243866, acc: 0.8461538553237915)
[2025-01-30 02:07:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2739/107898 [14:56<9:56:22,  2.94it/s][2025-01-30 02:07:05][root][INFO] - Training Epoch: 1/2, step 2738/107898 completed (loss: 1.4923464059829712, acc: 0.5384615659713745)
[2025-01-30 02:07:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2740/107898 [14:56<9:52:04,  2.96it/s][2025-01-30 02:07:06][root][INFO] - Training Epoch: 1/2, step 2739/107898 completed (loss: 3.3064873218536377, acc: 0.3333333432674408)
[2025-01-30 02:07:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2741/107898 [14:56<10:03:25,  2.90it/s][2025-01-30 02:07:06][root][INFO] - Training Epoch: 1/2, step 2740/107898 completed (loss: 1.6011021137237549, acc: 0.7142857313156128)
[2025-01-30 02:07:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2742/107898 [14:57<9:43:10,  3.01it/s] [2025-01-30 02:07:06][root][INFO] - Training Epoch: 1/2, step 2741/107898 completed (loss: 0.7870330214500427, acc: 0.800000011920929)
[2025-01-30 02:07:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2743/107898 [14:57<9:17:50,  3.14it/s][2025-01-30 02:07:07][root][INFO] - Training Epoch: 1/2, step 2742/107898 completed (loss: 1.8167539834976196, acc: 0.6666666865348816)
[2025-01-30 02:07:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2744/107898 [14:57<9:42:01,  3.01it/s][2025-01-30 02:07:07][root][INFO] - Training Epoch: 1/2, step 2743/107898 completed (loss: 0.08639126271009445, acc: 1.0)
[2025-01-30 02:07:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2745/107898 [14:57<9:40:47,  3.02it/s][2025-01-30 02:07:07][root][INFO] - Training Epoch: 1/2, step 2744/107898 completed (loss: 2.1602067947387695, acc: 0.7272727489471436)
[2025-01-30 02:07:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2746/107898 [14:58<9:31:23,  3.07it/s][2025-01-30 02:07:08][root][INFO] - Training Epoch: 1/2, step 2745/107898 completed (loss: 1.9416574239730835, acc: 0.75)
[2025-01-30 02:07:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2747/107898 [14:58<9:20:03,  3.13it/s][2025-01-30 02:07:08][root][INFO] - Training Epoch: 1/2, step 2746/107898 completed (loss: 1.4539304971694946, acc: 0.7857142686843872)
[2025-01-30 02:07:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2748/107898 [14:58<9:11:59,  3.17it/s][2025-01-30 02:07:08][root][INFO] - Training Epoch: 1/2, step 2747/107898 completed (loss: 0.37169697880744934, acc: 1.0)
[2025-01-30 02:07:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2749/107898 [14:59<9:27:05,  3.09it/s][2025-01-30 02:07:09][root][INFO] - Training Epoch: 1/2, step 2748/107898 completed (loss: 3.704383373260498, acc: 0.17241379618644714)
[2025-01-30 02:07:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2750/107898 [14:59<9:11:31,  3.18it/s][2025-01-30 02:07:09][root][INFO] - Training Epoch: 1/2, step 2749/107898 completed (loss: 1.68430757522583, acc: 0.5)
[2025-01-30 02:07:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2751/107898 [14:59<8:59:40,  3.25it/s][2025-01-30 02:07:09][root][INFO] - Training Epoch: 1/2, step 2750/107898 completed (loss: 1.0946165323257446, acc: 0.7647058963775635)
[2025-01-30 02:07:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2752/107898 [15:00<8:46:00,  3.33it/s][2025-01-30 02:07:09][root][INFO] - Training Epoch: 1/2, step 2751/107898 completed (loss: 3.533101797103882, acc: 0.3333333432674408)
[2025-01-30 02:07:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2753/107898 [15:00<8:49:19,  3.31it/s][2025-01-30 02:07:10][root][INFO] - Training Epoch: 1/2, step 2752/107898 completed (loss: 1.5880330801010132, acc: 0.7142857313156128)
[2025-01-30 02:07:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2754/107898 [15:00<9:14:04,  3.16it/s][2025-01-30 02:07:10][root][INFO] - Training Epoch: 1/2, step 2753/107898 completed (loss: 0.1692269742488861, acc: 1.0)
[2025-01-30 02:07:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2755/107898 [15:01<9:25:41,  3.10it/s][2025-01-30 02:07:10][root][INFO] - Training Epoch: 1/2, step 2754/107898 completed (loss: 2.16776180267334, acc: 0.6000000238418579)
[2025-01-30 02:07:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2756/107898 [15:01<9:24:14,  3.11it/s][2025-01-30 02:07:11][root][INFO] - Training Epoch: 1/2, step 2755/107898 completed (loss: 0.3546486794948578, acc: 1.0)
[2025-01-30 02:07:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2757/107898 [15:01<9:19:51,  3.13it/s][2025-01-30 02:07:11][root][INFO] - Training Epoch: 1/2, step 2756/107898 completed (loss: 0.7074314951896667, acc: 0.7777777910232544)
[2025-01-30 02:07:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2758/107898 [15:02<9:19:23,  3.13it/s][2025-01-30 02:07:11][root][INFO] - Training Epoch: 1/2, step 2757/107898 completed (loss: 0.4450080692768097, acc: 0.6666666865348816)
[2025-01-30 02:07:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2759/107898 [15:02<9:17:43,  3.14it/s][2025-01-30 02:07:12][root][INFO] - Training Epoch: 1/2, step 2758/107898 completed (loss: 1.8410536050796509, acc: 0.6666666865348816)
[2025-01-30 02:07:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2760/107898 [15:02<9:09:04,  3.19it/s][2025-01-30 02:07:12][root][INFO] - Training Epoch: 1/2, step 2759/107898 completed (loss: 0.018265675753355026, acc: 1.0)
[2025-01-30 02:07:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2761/107898 [15:02<8:59:48,  3.25it/s][2025-01-30 02:07:12][root][INFO] - Training Epoch: 1/2, step 2760/107898 completed (loss: 1.6519817113876343, acc: 0.6000000238418579)
[2025-01-30 02:07:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2762/107898 [15:03<9:11:57,  3.17it/s][2025-01-30 02:07:13][root][INFO] - Training Epoch: 1/2, step 2761/107898 completed (loss: 0.7491967082023621, acc: 0.8571428656578064)
[2025-01-30 02:07:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2763/107898 [15:03<9:24:08,  3.11it/s][2025-01-30 02:07:13][root][INFO] - Training Epoch: 1/2, step 2762/107898 completed (loss: 0.9443407654762268, acc: 0.8421052694320679)
[2025-01-30 02:07:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2764/107898 [15:03<9:17:04,  3.15it/s][2025-01-30 02:07:13][root][INFO] - Training Epoch: 1/2, step 2763/107898 completed (loss: 0.827949583530426, acc: 1.0)
[2025-01-30 02:07:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2765/107898 [15:04<9:20:14,  3.13it/s][2025-01-30 02:07:14][root][INFO] - Training Epoch: 1/2, step 2764/107898 completed (loss: 0.9675830602645874, acc: 1.0)
[2025-01-30 02:07:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2766/107898 [15:04<9:41:03,  3.02it/s][2025-01-30 02:07:14][root][INFO] - Training Epoch: 1/2, step 2765/107898 completed (loss: 1.0425233840942383, acc: 0.75)
[2025-01-30 02:07:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2767/107898 [15:04<9:08:16,  3.20it/s][2025-01-30 02:07:14][root][INFO] - Training Epoch: 1/2, step 2766/107898 completed (loss: 2.9452288150787354, acc: 0.5)
[2025-01-30 02:07:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2768/107898 [15:05<9:20:08,  3.13it/s][2025-01-30 02:07:15][root][INFO] - Training Epoch: 1/2, step 2767/107898 completed (loss: 0.1726517528295517, acc: 1.0)
[2025-01-30 02:07:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2769/107898 [15:05<9:29:13,  3.08it/s][2025-01-30 02:07:15][root][INFO] - Training Epoch: 1/2, step 2768/107898 completed (loss: 0.871482789516449, acc: 0.8333333134651184)
[2025-01-30 02:07:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2770/107898 [15:05<9:32:53,  3.06it/s][2025-01-30 02:07:15][root][INFO] - Training Epoch: 1/2, step 2769/107898 completed (loss: 2.137482166290283, acc: 0.692307710647583)
[2025-01-30 02:07:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2771/107898 [15:06<9:15:48,  3.15it/s][2025-01-30 02:07:16][root][INFO] - Training Epoch: 1/2, step 2770/107898 completed (loss: 0.05489534139633179, acc: 1.0)
[2025-01-30 02:07:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2772/107898 [15:06<9:09:11,  3.19it/s][2025-01-30 02:07:16][root][INFO] - Training Epoch: 1/2, step 2771/107898 completed (loss: 1.620856761932373, acc: 0.8181818127632141)
[2025-01-30 02:07:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2773/107898 [15:06<8:54:26,  3.28it/s][2025-01-30 02:07:16][root][INFO] - Training Epoch: 1/2, step 2772/107898 completed (loss: 1.0704333782196045, acc: 0.6000000238418579)
[2025-01-30 02:07:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2774/107898 [15:07<8:58:42,  3.25it/s][2025-01-30 02:07:16][root][INFO] - Training Epoch: 1/2, step 2773/107898 completed (loss: 1.0184574127197266, acc: 0.8235294222831726)
[2025-01-30 02:07:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2775/107898 [15:07<9:22:53,  3.11it/s][2025-01-30 02:07:17][root][INFO] - Training Epoch: 1/2, step 2774/107898 completed (loss: 0.18046054244041443, acc: 1.0)
[2025-01-30 02:07:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2776/107898 [15:07<9:25:14,  3.10it/s][2025-01-30 02:07:17][root][INFO] - Training Epoch: 1/2, step 2775/107898 completed (loss: 0.1454220861196518, acc: 1.0)
[2025-01-30 02:07:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2777/107898 [15:08<9:31:36,  3.07it/s][2025-01-30 02:07:17][root][INFO] - Training Epoch: 1/2, step 2776/107898 completed (loss: 0.03930261731147766, acc: 1.0)
[2025-01-30 02:07:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2778/107898 [15:08<9:28:17,  3.08it/s][2025-01-30 02:07:18][root][INFO] - Training Epoch: 1/2, step 2777/107898 completed (loss: 0.04125693440437317, acc: 1.0)
[2025-01-30 02:07:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2779/107898 [15:08<9:45:17,  2.99it/s][2025-01-30 02:07:18][root][INFO] - Training Epoch: 1/2, step 2778/107898 completed (loss: 0.6694310903549194, acc: 0.8947368264198303)
[2025-01-30 02:07:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2780/107898 [15:09<9:46:43,  2.99it/s][2025-01-30 02:07:18][root][INFO] - Training Epoch: 1/2, step 2779/107898 completed (loss: 0.027536265552043915, acc: 1.0)
[2025-01-30 02:07:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2781/107898 [15:09<9:42:29,  3.01it/s][2025-01-30 02:07:19][root][INFO] - Training Epoch: 1/2, step 2780/107898 completed (loss: 1.2648870944976807, acc: 0.4000000059604645)
[2025-01-30 02:07:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2782/107898 [15:09<9:39:46,  3.02it/s][2025-01-30 02:07:19][root][INFO] - Training Epoch: 1/2, step 2781/107898 completed (loss: 3.7252211570739746, acc: 0.20000000298023224)
[2025-01-30 02:07:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2783/107898 [15:10<9:29:23,  3.08it/s][2025-01-30 02:07:19][root][INFO] - Training Epoch: 1/2, step 2782/107898 completed (loss: 0.5782371759414673, acc: 0.8888888955116272)
[2025-01-30 02:07:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2784/107898 [15:10<9:27:33,  3.09it/s][2025-01-30 02:07:20][root][INFO] - Training Epoch: 1/2, step 2783/107898 completed (loss: 0.5541833639144897, acc: 0.8571428656578064)
[2025-01-30 02:07:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2785/107898 [15:10<9:22:30,  3.11it/s][2025-01-30 02:07:20][root][INFO] - Training Epoch: 1/2, step 2784/107898 completed (loss: 0.3844459652900696, acc: 0.9333333373069763)
[2025-01-30 02:07:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2786/107898 [15:11<9:09:24,  3.19it/s][2025-01-30 02:07:20][root][INFO] - Training Epoch: 1/2, step 2785/107898 completed (loss: 0.03216881677508354, acc: 1.0)
[2025-01-30 02:07:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2787/107898 [15:11<9:04:55,  3.21it/s][2025-01-30 02:07:21][root][INFO] - Training Epoch: 1/2, step 2786/107898 completed (loss: 0.4135828912258148, acc: 0.9473684430122375)
[2025-01-30 02:07:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2788/107898 [15:11<9:18:01,  3.14it/s][2025-01-30 02:07:21][root][INFO] - Training Epoch: 1/2, step 2787/107898 completed (loss: 1.7981252670288086, acc: 0.3333333432674408)
[2025-01-30 02:07:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2789/107898 [15:11<9:14:17,  3.16it/s][2025-01-30 02:07:21][root][INFO] - Training Epoch: 1/2, step 2788/107898 completed (loss: 0.047396764159202576, acc: 1.0)
[2025-01-30 02:07:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2790/107898 [15:12<9:10:59,  3.18it/s][2025-01-30 02:07:22][root][INFO] - Training Epoch: 1/2, step 2789/107898 completed (loss: 4.389747142791748, acc: 0.23529411852359772)
[2025-01-30 02:07:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2791/107898 [15:12<9:22:39,  3.11it/s][2025-01-30 02:07:22][root][INFO] - Training Epoch: 1/2, step 2790/107898 completed (loss: 0.07670654356479645, acc: 1.0)
[2025-01-30 02:07:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2792/107898 [15:12<9:18:36,  3.14it/s][2025-01-30 02:07:22][root][INFO] - Training Epoch: 1/2, step 2791/107898 completed (loss: 5.13519811630249, acc: 0.0)
[2025-01-30 02:07:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2793/107898 [15:13<9:06:50,  3.20it/s][2025-01-30 02:07:23][root][INFO] - Training Epoch: 1/2, step 2792/107898 completed (loss: 0.01991065964102745, acc: 1.0)
[2025-01-30 02:07:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2794/107898 [15:13<9:06:55,  3.20it/s][2025-01-30 02:07:23][root][INFO] - Training Epoch: 1/2, step 2793/107898 completed (loss: 0.6745500564575195, acc: 0.9090909361839294)
[2025-01-30 02:07:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2795/107898 [15:13<9:05:41,  3.21it/s][2025-01-30 02:07:23][root][INFO] - Training Epoch: 1/2, step 2794/107898 completed (loss: 0.8182008862495422, acc: 0.800000011920929)
[2025-01-30 02:07:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2796/107898 [15:14<9:27:55,  3.08it/s][2025-01-30 02:07:24][root][INFO] - Training Epoch: 1/2, step 2795/107898 completed (loss: 0.7039588689804077, acc: 0.8823529481887817)
[2025-01-30 02:07:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2797/107898 [15:14<9:35:07,  3.05it/s][2025-01-30 02:07:24][root][INFO] - Training Epoch: 1/2, step 2796/107898 completed (loss: 0.16985642910003662, acc: 0.9411764740943909)
[2025-01-30 02:07:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2798/107898 [15:14<9:27:40,  3.09it/s][2025-01-30 02:07:24][root][INFO] - Training Epoch: 1/2, step 2797/107898 completed (loss: 0.23293817043304443, acc: 1.0)
[2025-01-30 02:07:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2799/107898 [15:15<9:13:57,  3.16it/s][2025-01-30 02:07:24][root][INFO] - Training Epoch: 1/2, step 2798/107898 completed (loss: 3.1174328327178955, acc: 0.375)
[2025-01-30 02:07:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2800/107898 [15:15<9:17:53,  3.14it/s][2025-01-30 02:07:25][root][INFO] - Training Epoch: 1/2, step 2799/107898 completed (loss: 0.6978573799133301, acc: 0.8333333134651184)
[2025-01-30 02:07:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2801/107898 [15:15<9:14:27,  3.16it/s][2025-01-30 02:07:25][root][INFO] - Training Epoch: 1/2, step 2800/107898 completed (loss: 0.40580207109451294, acc: 0.8999999761581421)
[2025-01-30 02:07:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2802/107898 [15:16<9:36:50,  3.04it/s][2025-01-30 02:07:25][root][INFO] - Training Epoch: 1/2, step 2801/107898 completed (loss: 2.7007858753204346, acc: 0.5)
[2025-01-30 02:07:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2803/107898 [15:16<9:47:46,  2.98it/s][2025-01-30 02:07:26][root][INFO] - Training Epoch: 1/2, step 2802/107898 completed (loss: 0.12053179740905762, acc: 0.9583333134651184)
[2025-01-30 02:07:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2804/107898 [15:16<9:48:29,  2.98it/s][2025-01-30 02:07:26][root][INFO] - Training Epoch: 1/2, step 2803/107898 completed (loss: 0.1641223132610321, acc: 0.8571428656578064)
[2025-01-30 02:07:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2805/107898 [15:17<10:01:41,  2.91it/s][2025-01-30 02:07:27][root][INFO] - Training Epoch: 1/2, step 2804/107898 completed (loss: 3.7630369663238525, acc: 0.05882352963089943)
[2025-01-30 02:07:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2806/107898 [15:17<9:58:37,  2.93it/s] [2025-01-30 02:07:27][root][INFO] - Training Epoch: 1/2, step 2805/107898 completed (loss: 0.0467994287610054, acc: 1.0)
[2025-01-30 02:07:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2807/107898 [15:17<9:43:29,  3.00it/s][2025-01-30 02:07:27][root][INFO] - Training Epoch: 1/2, step 2806/107898 completed (loss: 1.5978606939315796, acc: 0.75)
[2025-01-30 02:07:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2808/107898 [15:18<9:48:27,  2.98it/s][2025-01-30 02:07:28][root][INFO] - Training Epoch: 1/2, step 2807/107898 completed (loss: 1.1568243503570557, acc: 0.7058823704719543)
[2025-01-30 02:07:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2809/107898 [15:18<9:50:27,  2.97it/s][2025-01-30 02:07:28][root][INFO] - Training Epoch: 1/2, step 2808/107898 completed (loss: 0.06573005020618439, acc: 1.0)
[2025-01-30 02:07:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2810/107898 [15:18<9:46:22,  2.99it/s][2025-01-30 02:07:28][root][INFO] - Training Epoch: 1/2, step 2809/107898 completed (loss: 0.6590139269828796, acc: 0.5)
[2025-01-30 02:07:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2811/107898 [15:19<9:05:26,  3.21it/s][2025-01-30 02:07:28][root][INFO] - Training Epoch: 1/2, step 2810/107898 completed (loss: 0.0842694416642189, acc: 1.0)
[2025-01-30 02:07:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2812/107898 [15:19<8:38:50,  3.38it/s][2025-01-30 02:07:29][root][INFO] - Training Epoch: 1/2, step 2811/107898 completed (loss: 1.4993383884429932, acc: 0.6190476417541504)
[2025-01-30 02:07:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2813/107898 [15:19<8:49:19,  3.31it/s][2025-01-30 02:07:29][root][INFO] - Training Epoch: 1/2, step 2812/107898 completed (loss: 0.1781441867351532, acc: 1.0)
[2025-01-30 02:07:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2814/107898 [15:20<8:44:30,  3.34it/s][2025-01-30 02:07:29][root][INFO] - Training Epoch: 1/2, step 2813/107898 completed (loss: 2.382762908935547, acc: 0.625)
[2025-01-30 02:07:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2815/107898 [15:20<8:46:17,  3.33it/s][2025-01-30 02:07:30][root][INFO] - Training Epoch: 1/2, step 2814/107898 completed (loss: 0.2614505887031555, acc: 0.9166666865348816)
[2025-01-30 02:07:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2816/107898 [15:20<8:50:15,  3.30it/s][2025-01-30 02:07:30][root][INFO] - Training Epoch: 1/2, step 2815/107898 completed (loss: 1.3703747987747192, acc: 0.8235294222831726)
[2025-01-30 02:07:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2817/107898 [15:20<8:50:24,  3.30it/s][2025-01-30 02:07:30][root][INFO] - Training Epoch: 1/2, step 2816/107898 completed (loss: 0.7407252192497253, acc: 0.800000011920929)
[2025-01-30 02:07:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2818/107898 [15:21<8:53:20,  3.28it/s][2025-01-30 02:07:31][root][INFO] - Training Epoch: 1/2, step 2817/107898 completed (loss: 3.7764596939086914, acc: 0.27586206793785095)
[2025-01-30 02:07:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2819/107898 [15:21<8:55:33,  3.27it/s][2025-01-30 02:07:31][root][INFO] - Training Epoch: 1/2, step 2818/107898 completed (loss: 0.7781500816345215, acc: 0.8999999761581421)
[2025-01-30 02:07:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2820/107898 [15:21<8:52:44,  3.29it/s][2025-01-30 02:07:31][root][INFO] - Training Epoch: 1/2, step 2819/107898 completed (loss: 2.0171730518341064, acc: 0.6190476417541504)
[2025-01-30 02:07:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2821/107898 [15:22<9:17:50,  3.14it/s][2025-01-30 02:07:31][root][INFO] - Training Epoch: 1/2, step 2820/107898 completed (loss: 1.4869203567504883, acc: 0.7272727489471436)
[2025-01-30 02:07:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2822/107898 [15:22<8:52:49,  3.29it/s][2025-01-30 02:07:32][root][INFO] - Training Epoch: 1/2, step 2821/107898 completed (loss: 1.0850683450698853, acc: 0.7777777910232544)
[2025-01-30 02:07:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2823/107898 [15:22<8:56:09,  3.27it/s][2025-01-30 02:07:32][root][INFO] - Training Epoch: 1/2, step 2822/107898 completed (loss: 0.5606398582458496, acc: 0.8500000238418579)
[2025-01-30 02:07:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2824/107898 [15:23<8:46:09,  3.33it/s][2025-01-30 02:07:32][root][INFO] - Training Epoch: 1/2, step 2823/107898 completed (loss: 0.20837898552417755, acc: 0.75)
[2025-01-30 02:07:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2825/107898 [15:23<8:44:16,  3.34it/s][2025-01-30 02:07:33][root][INFO] - Training Epoch: 1/2, step 2824/107898 completed (loss: 0.0379653126001358, acc: 1.0)
[2025-01-30 02:07:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2826/107898 [15:23<8:51:01,  3.30it/s][2025-01-30 02:07:33][root][INFO] - Training Epoch: 1/2, step 2825/107898 completed (loss: 0.4374328553676605, acc: 0.800000011920929)
[2025-01-30 02:07:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2827/107898 [15:23<8:28:11,  3.45it/s][2025-01-30 02:07:33][root][INFO] - Training Epoch: 1/2, step 2826/107898 completed (loss: 1.517013669013977, acc: 0.6666666865348816)
[2025-01-30 02:07:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2828/107898 [15:24<8:37:02,  3.39it/s][2025-01-30 02:07:34][root][INFO] - Training Epoch: 1/2, step 2827/107898 completed (loss: 1.641164779663086, acc: 0.800000011920929)
[2025-01-30 02:07:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2829/107898 [15:24<8:33:39,  3.41it/s][2025-01-30 02:07:34][root][INFO] - Training Epoch: 1/2, step 2828/107898 completed (loss: 1.2419694662094116, acc: 0.75)
[2025-01-30 02:07:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2830/107898 [15:24<8:39:31,  3.37it/s][2025-01-30 02:07:34][root][INFO] - Training Epoch: 1/2, step 2829/107898 completed (loss: 0.7029026746749878, acc: 0.8333333134651184)
[2025-01-30 02:07:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2831/107898 [15:25<9:28:38,  3.08it/s][2025-01-30 02:07:35][root][INFO] - Training Epoch: 1/2, step 2830/107898 completed (loss: 1.0962543487548828, acc: 0.8421052694320679)
[2025-01-30 02:07:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2832/107898 [15:25<9:46:58,  2.98it/s][2025-01-30 02:07:35][root][INFO] - Training Epoch: 1/2, step 2831/107898 completed (loss: 3.0681560039520264, acc: 0.3333333432674408)
[2025-01-30 02:07:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2833/107898 [15:25<9:41:53,  3.01it/s][2025-01-30 02:07:35][root][INFO] - Training Epoch: 1/2, step 2832/107898 completed (loss: 0.612015962600708, acc: 0.5)
[2025-01-30 02:07:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2834/107898 [15:26<9:35:36,  3.04it/s][2025-01-30 02:07:36][root][INFO] - Training Epoch: 1/2, step 2833/107898 completed (loss: 2.3392937183380127, acc: 0.6111111044883728)
[2025-01-30 02:07:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2835/107898 [15:26<9:29:42,  3.07it/s][2025-01-30 02:07:36][root][INFO] - Training Epoch: 1/2, step 2834/107898 completed (loss: 1.1955535411834717, acc: 0.7307692170143127)
[2025-01-30 02:07:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2836/107898 [15:26<9:00:40,  3.24it/s][2025-01-30 02:07:36][root][INFO] - Training Epoch: 1/2, step 2835/107898 completed (loss: 2.6427555084228516, acc: 0.25)
[2025-01-30 02:07:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2837/107898 [15:27<8:50:53,  3.30it/s][2025-01-30 02:07:36][root][INFO] - Training Epoch: 1/2, step 2836/107898 completed (loss: 0.10443756729364395, acc: 1.0)
[2025-01-30 02:07:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2838/107898 [15:27<8:52:31,  3.29it/s][2025-01-30 02:07:37][root][INFO] - Training Epoch: 1/2, step 2837/107898 completed (loss: 1.0229159593582153, acc: 0.75)
[2025-01-30 02:07:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2839/107898 [15:27<9:15:09,  3.15it/s][2025-01-30 02:07:37][root][INFO] - Training Epoch: 1/2, step 2838/107898 completed (loss: 4.142267227172852, acc: 0.4166666567325592)
[2025-01-30 02:07:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2840/107898 [15:28<9:23:52,  3.11it/s][2025-01-30 02:07:37][root][INFO] - Training Epoch: 1/2, step 2839/107898 completed (loss: 0.6116563081741333, acc: 0.7142857313156128)
[2025-01-30 02:07:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2841/107898 [15:28<9:39:28,  3.02it/s][2025-01-30 02:07:38][root][INFO] - Training Epoch: 1/2, step 2840/107898 completed (loss: 0.43875885009765625, acc: 0.8695651888847351)
[2025-01-30 02:07:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2842/107898 [15:28<9:24:30,  3.10it/s][2025-01-30 02:07:38][root][INFO] - Training Epoch: 1/2, step 2841/107898 completed (loss: 0.026769135147333145, acc: 1.0)
[2025-01-30 02:07:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2843/107898 [15:29<9:02:25,  3.23it/s][2025-01-30 02:07:38][root][INFO] - Training Epoch: 1/2, step 2842/107898 completed (loss: 0.5647568702697754, acc: 0.8500000238418579)
[2025-01-30 02:07:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2844/107898 [15:29<8:58:50,  3.25it/s][2025-01-30 02:07:39][root][INFO] - Training Epoch: 1/2, step 2843/107898 completed (loss: 0.29021748900413513, acc: 1.0)
[2025-01-30 02:07:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2845/107898 [15:29<8:56:00,  3.27it/s][2025-01-30 02:07:39][root][INFO] - Training Epoch: 1/2, step 2844/107898 completed (loss: 0.11035801470279694, acc: 1.0)
[2025-01-30 02:07:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2846/107898 [15:29<8:58:16,  3.25it/s][2025-01-30 02:07:39][root][INFO] - Training Epoch: 1/2, step 2845/107898 completed (loss: 0.046353645622730255, acc: 1.0)
[2025-01-30 02:07:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2847/107898 [15:30<9:03:04,  3.22it/s][2025-01-30 02:07:40][root][INFO] - Training Epoch: 1/2, step 2846/107898 completed (loss: 0.4879060983657837, acc: 1.0)
[2025-01-30 02:07:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2848/107898 [15:30<8:58:33,  3.25it/s][2025-01-30 02:07:40][root][INFO] - Training Epoch: 1/2, step 2847/107898 completed (loss: 0.4313357472419739, acc: 1.0)
[2025-01-30 02:07:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2849/107898 [15:30<9:06:54,  3.20it/s][2025-01-30 02:07:40][root][INFO] - Training Epoch: 1/2, step 2848/107898 completed (loss: 0.4504726231098175, acc: 0.9130434989929199)
[2025-01-30 02:07:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2850/107898 [15:31<8:59:49,  3.24it/s][2025-01-30 02:07:40][root][INFO] - Training Epoch: 1/2, step 2849/107898 completed (loss: 4.4589362144470215, acc: 0.375)
[2025-01-30 02:07:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2851/107898 [15:31<8:54:47,  3.27it/s][2025-01-30 02:07:41][root][INFO] - Training Epoch: 1/2, step 2850/107898 completed (loss: 2.0205910205841064, acc: 0.5)
[2025-01-30 02:07:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2852/107898 [15:31<8:47:15,  3.32it/s][2025-01-30 02:07:41][root][INFO] - Training Epoch: 1/2, step 2851/107898 completed (loss: 0.45625001192092896, acc: 0.800000011920929)
[2025-01-30 02:07:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2853/107898 [15:32<8:51:48,  3.29it/s][2025-01-30 02:07:41][root][INFO] - Training Epoch: 1/2, step 2852/107898 completed (loss: 2.9317450523376465, acc: 0.3636363744735718)
[2025-01-30 02:07:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2854/107898 [15:32<9:02:34,  3.23it/s][2025-01-30 02:07:42][root][INFO] - Training Epoch: 1/2, step 2853/107898 completed (loss: 3.24662446975708, acc: 0.5)
[2025-01-30 02:07:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2855/107898 [15:32<9:04:46,  3.21it/s][2025-01-30 02:07:42][root][INFO] - Training Epoch: 1/2, step 2854/107898 completed (loss: 2.3575291633605957, acc: 0.6000000238418579)
[2025-01-30 02:07:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2856/107898 [15:33<9:02:01,  3.23it/s][2025-01-30 02:07:42][root][INFO] - Training Epoch: 1/2, step 2855/107898 completed (loss: 2.282308340072632, acc: 0.5454545617103577)
[2025-01-30 02:07:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2857/107898 [15:33<8:58:00,  3.25it/s][2025-01-30 02:07:43][root][INFO] - Training Epoch: 1/2, step 2856/107898 completed (loss: 0.18937456607818604, acc: 1.0)
[2025-01-30 02:07:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2858/107898 [15:33<9:04:49,  3.21it/s][2025-01-30 02:07:43][root][INFO] - Training Epoch: 1/2, step 2857/107898 completed (loss: 0.004863492213189602, acc: 1.0)
[2025-01-30 02:07:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2859/107898 [15:33<9:08:03,  3.19it/s][2025-01-30 02:07:43][root][INFO] - Training Epoch: 1/2, step 2858/107898 completed (loss: 1.7130582332611084, acc: 0.7368420958518982)
[2025-01-30 02:07:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2860/107898 [15:34<9:09:25,  3.19it/s][2025-01-30 02:07:44][root][INFO] - Training Epoch: 1/2, step 2859/107898 completed (loss: 1.4266858100891113, acc: 0.7272727489471436)
[2025-01-30 02:07:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2861/107898 [15:34<9:21:20,  3.12it/s][2025-01-30 02:07:44][root][INFO] - Training Epoch: 1/2, step 2860/107898 completed (loss: 0.7737622857093811, acc: 0.75)
[2025-01-30 02:07:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2862/107898 [15:34<9:46:53,  2.98it/s][2025-01-30 02:07:44][root][INFO] - Training Epoch: 1/2, step 2861/107898 completed (loss: 0.4388943910598755, acc: 0.8636363744735718)
[2025-01-30 02:07:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2863/107898 [15:35<9:40:34,  3.02it/s][2025-01-30 02:07:45][root][INFO] - Training Epoch: 1/2, step 2862/107898 completed (loss: 0.7168666124343872, acc: 0.8500000238418579)
[2025-01-30 02:07:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2864/107898 [15:35<9:34:38,  3.05it/s][2025-01-30 02:07:45][root][INFO] - Training Epoch: 1/2, step 2863/107898 completed (loss: 1.1896114349365234, acc: 0.6764705777168274)
[2025-01-30 02:07:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2865/107898 [15:35<9:18:39,  3.13it/s][2025-01-30 02:07:45][root][INFO] - Training Epoch: 1/2, step 2864/107898 completed (loss: 0.043175894767045975, acc: 1.0)
[2025-01-30 02:07:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2866/107898 [15:36<9:09:47,  3.18it/s][2025-01-30 02:07:46][root][INFO] - Training Epoch: 1/2, step 2865/107898 completed (loss: 0.2986920475959778, acc: 1.0)
[2025-01-30 02:07:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2867/107898 [15:36<9:03:33,  3.22it/s][2025-01-30 02:07:46][root][INFO] - Training Epoch: 1/2, step 2866/107898 completed (loss: 0.0033400580286979675, acc: 1.0)
[2025-01-30 02:07:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2868/107898 [15:36<9:05:26,  3.21it/s][2025-01-30 02:07:46][root][INFO] - Training Epoch: 1/2, step 2867/107898 completed (loss: 0.06233023479580879, acc: 1.0)
[2025-01-30 02:07:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2869/107898 [15:37<9:29:21,  3.07it/s][2025-01-30 02:07:46][root][INFO] - Training Epoch: 1/2, step 2868/107898 completed (loss: 2.361377716064453, acc: 0.3333333432674408)
[2025-01-30 02:07:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2870/107898 [15:37<9:44:32,  2.99it/s][2025-01-30 02:07:47][root][INFO] - Training Epoch: 1/2, step 2869/107898 completed (loss: 2.5722498893737793, acc: 0.5)
[2025-01-30 02:07:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2871/107898 [15:37<9:42:27,  3.01it/s][2025-01-30 02:07:47][root][INFO] - Training Epoch: 1/2, step 2870/107898 completed (loss: 0.5909649729728699, acc: 0.6666666865348816)
[2025-01-30 02:07:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2872/107898 [15:38<9:28:39,  3.08it/s][2025-01-30 02:07:47][root][INFO] - Training Epoch: 1/2, step 2871/107898 completed (loss: 0.10447880625724792, acc: 1.0)
[2025-01-30 02:07:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2873/107898 [15:38<9:34:38,  3.05it/s][2025-01-30 02:07:48][root][INFO] - Training Epoch: 1/2, step 2872/107898 completed (loss: 0.10491146892309189, acc: 1.0)
[2025-01-30 02:07:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2874/107898 [15:38<9:23:12,  3.11it/s][2025-01-30 02:07:48][root][INFO] - Training Epoch: 1/2, step 2873/107898 completed (loss: 2.4516801834106445, acc: 0.6086956262588501)
[2025-01-30 02:07:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2875/107898 [15:39<9:10:08,  3.18it/s][2025-01-30 02:07:48][root][INFO] - Training Epoch: 1/2, step 2874/107898 completed (loss: 0.020244641229510307, acc: 1.0)
[2025-01-30 02:07:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2876/107898 [15:39<8:56:55,  3.26it/s][2025-01-30 02:07:49][root][INFO] - Training Epoch: 1/2, step 2875/107898 completed (loss: 0.36527639627456665, acc: 0.8999999761581421)
[2025-01-30 02:07:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2877/107898 [15:39<8:57:19,  3.26it/s][2025-01-30 02:07:49][root][INFO] - Training Epoch: 1/2, step 2876/107898 completed (loss: 0.1348179131746292, acc: 1.0)
[2025-01-30 02:07:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2878/107898 [15:40<8:52:10,  3.29it/s][2025-01-30 02:07:49][root][INFO] - Training Epoch: 1/2, step 2877/107898 completed (loss: 0.00440732529386878, acc: 1.0)
[2025-01-30 02:07:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2879/107898 [15:40<9:15:15,  3.15it/s][2025-01-30 02:07:50][root][INFO] - Training Epoch: 1/2, step 2878/107898 completed (loss: 1.5373557806015015, acc: 0.6666666865348816)
[2025-01-30 02:07:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2880/107898 [15:40<9:24:16,  3.10it/s][2025-01-30 02:07:50][root][INFO] - Training Epoch: 1/2, step 2879/107898 completed (loss: 0.11548022925853729, acc: 1.0)
[2025-01-30 02:07:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2881/107898 [15:41<9:39:15,  3.02it/s][2025-01-30 02:07:50][root][INFO] - Training Epoch: 1/2, step 2880/107898 completed (loss: 0.02280276268720627, acc: 1.0)
[2025-01-30 02:07:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2882/107898 [15:41<9:56:09,  2.94it/s][2025-01-30 02:07:51][root][INFO] - Training Epoch: 1/2, step 2881/107898 completed (loss: 0.21972715854644775, acc: 1.0)
[2025-01-30 02:07:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2883/107898 [15:41<10:11:43,  2.86it/s][2025-01-30 02:07:51][root][INFO] - Training Epoch: 1/2, step 2882/107898 completed (loss: 1.5167213678359985, acc: 0.6000000238418579)
[2025-01-30 02:07:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2884/107898 [15:42<10:16:06,  2.84it/s][2025-01-30 02:07:51][root][INFO] - Training Epoch: 1/2, step 2883/107898 completed (loss: 3.0703630447387695, acc: 0.4166666567325592)
[2025-01-30 02:07:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2885/107898 [15:42<9:44:38,  2.99it/s] [2025-01-30 02:07:52][root][INFO] - Training Epoch: 1/2, step 2884/107898 completed (loss: 0.0009938289877027273, acc: 1.0)
[2025-01-30 02:07:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2886/107898 [15:42<9:28:33,  3.08it/s][2025-01-30 02:07:52][root][INFO] - Training Epoch: 1/2, step 2885/107898 completed (loss: 0.1852412074804306, acc: 0.9285714030265808)
[2025-01-30 02:07:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2887/107898 [15:43<9:37:50,  3.03it/s][2025-01-30 02:07:52][root][INFO] - Training Epoch: 1/2, step 2886/107898 completed (loss: 1.7956854104995728, acc: 0.6000000238418579)
[2025-01-30 02:07:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2888/107898 [15:43<9:49:22,  2.97it/s][2025-01-30 02:07:53][root][INFO] - Training Epoch: 1/2, step 2887/107898 completed (loss: 0.5560793876647949, acc: 0.8399999737739563)
[2025-01-30 02:07:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2889/107898 [15:43<9:36:31,  3.04it/s][2025-01-30 02:07:53][root][INFO] - Training Epoch: 1/2, step 2888/107898 completed (loss: 0.837762713432312, acc: 0.7142857313156128)
[2025-01-30 02:07:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2890/107898 [15:44<9:54:29,  2.94it/s][2025-01-30 02:07:53][root][INFO] - Training Epoch: 1/2, step 2889/107898 completed (loss: 1.3012291193008423, acc: 0.7272727489471436)
[2025-01-30 02:07:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2891/107898 [15:44<9:46:42,  2.98it/s][2025-01-30 02:07:54][root][INFO] - Training Epoch: 1/2, step 2890/107898 completed (loss: 1.6833522319793701, acc: 0.6875)
[2025-01-30 02:07:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2892/107898 [15:44<9:52:08,  2.96it/s][2025-01-30 02:07:54][root][INFO] - Training Epoch: 1/2, step 2891/107898 completed (loss: 4.6305389404296875, acc: 0.5)
[2025-01-30 02:07:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2893/107898 [15:45<9:50:59,  2.96it/s][2025-01-30 02:07:54][root][INFO] - Training Epoch: 1/2, step 2892/107898 completed (loss: 1.8603025674819946, acc: 0.5)
[2025-01-30 02:07:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2894/107898 [15:45<9:42:52,  3.00it/s][2025-01-30 02:07:55][root][INFO] - Training Epoch: 1/2, step 2893/107898 completed (loss: 0.26360034942626953, acc: 0.8181818127632141)
[2025-01-30 02:07:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2895/107898 [15:45<9:59:33,  2.92it/s][2025-01-30 02:07:55][root][INFO] - Training Epoch: 1/2, step 2894/107898 completed (loss: 0.06394488364458084, acc: 1.0)
[2025-01-30 02:07:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2896/107898 [15:46<9:53:42,  2.95it/s][2025-01-30 02:07:55][root][INFO] - Training Epoch: 1/2, step 2895/107898 completed (loss: 0.28553807735443115, acc: 1.0)
[2025-01-30 02:07:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2897/107898 [15:46<9:36:21,  3.04it/s][2025-01-30 02:07:56][root][INFO] - Training Epoch: 1/2, step 2896/107898 completed (loss: 2.6037328243255615, acc: 0.6428571343421936)
[2025-01-30 02:07:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2898/107898 [15:46<9:21:25,  3.12it/s][2025-01-30 02:07:56][root][INFO] - Training Epoch: 1/2, step 2897/107898 completed (loss: 0.4999810755252838, acc: 0.800000011920929)
[2025-01-30 02:07:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2899/107898 [15:47<9:16:00,  3.15it/s][2025-01-30 02:07:56][root][INFO] - Training Epoch: 1/2, step 2898/107898 completed (loss: 0.2096518874168396, acc: 1.0)
[2025-01-30 02:07:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2900/107898 [15:47<8:49:20,  3.31it/s][2025-01-30 02:07:57][root][INFO] - Training Epoch: 1/2, step 2899/107898 completed (loss: 1.3568618297576904, acc: 0.800000011920929)
[2025-01-30 02:07:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2901/107898 [15:47<9:07:11,  3.20it/s][2025-01-30 02:07:57][root][INFO] - Training Epoch: 1/2, step 2900/107898 completed (loss: 0.00068906310480088, acc: 1.0)
[2025-01-30 02:07:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2902/107898 [15:48<9:32:56,  3.05it/s][2025-01-30 02:07:57][root][INFO] - Training Epoch: 1/2, step 2901/107898 completed (loss: 0.0017528242897242308, acc: 1.0)
[2025-01-30 02:07:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2903/107898 [15:48<9:33:37,  3.05it/s][2025-01-30 02:07:58][root][INFO] - Training Epoch: 1/2, step 2902/107898 completed (loss: 0.9258005619049072, acc: 0.7647058963775635)
[2025-01-30 02:07:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2904/107898 [15:48<9:48:35,  2.97it/s][2025-01-30 02:07:58][root][INFO] - Training Epoch: 1/2, step 2903/107898 completed (loss: 0.0007714621024206281, acc: 1.0)
[2025-01-30 02:07:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2905/107898 [15:49<9:43:52,  3.00it/s][2025-01-30 02:07:58][root][INFO] - Training Epoch: 1/2, step 2904/107898 completed (loss: 0.0518159419298172, acc: 1.0)
[2025-01-30 02:07:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2906/107898 [15:49<9:41:25,  3.01it/s][2025-01-30 02:07:59][root][INFO] - Training Epoch: 1/2, step 2905/107898 completed (loss: 4.066822052001953, acc: 0.2380952388048172)
[2025-01-30 02:07:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2907/107898 [15:49<9:44:07,  3.00it/s][2025-01-30 02:07:59][root][INFO] - Training Epoch: 1/2, step 2906/107898 completed (loss: 2.5934793949127197, acc: 0.6666666865348816)
[2025-01-30 02:07:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2908/107898 [15:50<9:28:53,  3.08it/s][2025-01-30 02:07:59][root][INFO] - Training Epoch: 1/2, step 2907/107898 completed (loss: 0.012178942561149597, acc: 1.0)
[2025-01-30 02:07:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2909/107898 [15:50<9:22:47,  3.11it/s][2025-01-30 02:08:00][root][INFO] - Training Epoch: 1/2, step 2908/107898 completed (loss: 0.0047210389748215675, acc: 1.0)
[2025-01-30 02:08:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2910/107898 [15:50<9:28:53,  3.08it/s][2025-01-30 02:08:00][root][INFO] - Training Epoch: 1/2, step 2909/107898 completed (loss: 0.0197612177580595, acc: 1.0)
[2025-01-30 02:08:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2911/107898 [15:51<9:44:15,  2.99it/s][2025-01-30 02:08:00][root][INFO] - Training Epoch: 1/2, step 2910/107898 completed (loss: 0.34123939275741577, acc: 1.0)
[2025-01-30 02:08:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2912/107898 [15:51<9:39:58,  3.02it/s][2025-01-30 02:08:01][root][INFO] - Training Epoch: 1/2, step 2911/107898 completed (loss: 0.191024050116539, acc: 1.0)
[2025-01-30 02:08:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2913/107898 [15:51<9:40:01,  3.02it/s][2025-01-30 02:08:01][root][INFO] - Training Epoch: 1/2, step 2912/107898 completed (loss: 1.4889953136444092, acc: 0.5)
[2025-01-30 02:08:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2914/107898 [15:51<9:31:17,  3.06it/s][2025-01-30 02:08:01][root][INFO] - Training Epoch: 1/2, step 2913/107898 completed (loss: 0.10850799083709717, acc: 1.0)
[2025-01-30 02:08:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2915/107898 [15:52<9:19:20,  3.13it/s][2025-01-30 02:08:02][root][INFO] - Training Epoch: 1/2, step 2914/107898 completed (loss: 0.5206611156463623, acc: 0.9090909361839294)
[2025-01-30 02:08:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2916/107898 [15:52<9:27:35,  3.08it/s][2025-01-30 02:08:02][root][INFO] - Training Epoch: 1/2, step 2915/107898 completed (loss: 0.1569693684577942, acc: 0.8333333134651184)
[2025-01-30 02:08:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2917/107898 [15:52<9:39:28,  3.02it/s][2025-01-30 02:08:02][root][INFO] - Training Epoch: 1/2, step 2916/107898 completed (loss: 1.0771855115890503, acc: 0.75)
[2025-01-30 02:08:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2918/107898 [15:53<9:24:23,  3.10it/s][2025-01-30 02:08:03][root][INFO] - Training Epoch: 1/2, step 2917/107898 completed (loss: 0.8673283457756042, acc: 0.7857142686843872)
[2025-01-30 02:08:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2919/107898 [15:53<9:14:30,  3.16it/s][2025-01-30 02:08:03][root][INFO] - Training Epoch: 1/2, step 2918/107898 completed (loss: 1.4945597648620605, acc: 0.5)
[2025-01-30 02:08:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2920/107898 [15:53<9:11:17,  3.17it/s][2025-01-30 02:08:03][root][INFO] - Training Epoch: 1/2, step 2919/107898 completed (loss: 2.237643003463745, acc: 0.4285714328289032)
[2025-01-30 02:08:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2921/107898 [15:54<9:10:24,  3.18it/s][2025-01-30 02:08:03][root][INFO] - Training Epoch: 1/2, step 2920/107898 completed (loss: 0.0527057871222496, acc: 1.0)
[2025-01-30 02:08:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2922/107898 [15:54<9:23:49,  3.10it/s][2025-01-30 02:08:04][root][INFO] - Training Epoch: 1/2, step 2921/107898 completed (loss: 2.931277275085449, acc: 0.27272728085517883)
[2025-01-30 02:08:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2923/107898 [15:54<9:45:45,  2.99it/s][2025-01-30 02:08:04][root][INFO] - Training Epoch: 1/2, step 2922/107898 completed (loss: 0.5720727443695068, acc: 0.75)
[2025-01-30 02:08:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2924/107898 [15:55<9:51:48,  2.96it/s][2025-01-30 02:08:05][root][INFO] - Training Epoch: 1/2, step 2923/107898 completed (loss: 3.528153419494629, acc: 0.4444444477558136)
[2025-01-30 02:08:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2925/107898 [15:55<10:01:47,  2.91it/s][2025-01-30 02:08:05][root][INFO] - Training Epoch: 1/2, step 2924/107898 completed (loss: 1.2150148153305054, acc: 0.5454545617103577)
[2025-01-30 02:08:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2926/107898 [15:55<9:50:07,  2.96it/s] [2025-01-30 02:08:05][root][INFO] - Training Epoch: 1/2, step 2925/107898 completed (loss: 2.5821685791015625, acc: 0.6000000238418579)
[2025-01-30 02:08:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2927/107898 [15:56<9:31:02,  3.06it/s][2025-01-30 02:08:06][root][INFO] - Training Epoch: 1/2, step 2926/107898 completed (loss: 4.1528849601745605, acc: 0.3333333432674408)
[2025-01-30 02:08:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2928/107898 [15:56<9:18:02,  3.14it/s][2025-01-30 02:08:06][root][INFO] - Training Epoch: 1/2, step 2927/107898 completed (loss: 2.1596269607543945, acc: 0.5)
[2025-01-30 02:08:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2929/107898 [15:56<9:14:11,  3.16it/s][2025-01-30 02:08:06][root][INFO] - Training Epoch: 1/2, step 2928/107898 completed (loss: 0.0318230539560318, acc: 1.0)
[2025-01-30 02:08:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2930/107898 [15:57<9:41:51,  3.01it/s][2025-01-30 02:08:07][root][INFO] - Training Epoch: 1/2, step 2929/107898 completed (loss: 0.30269309878349304, acc: 0.875)
[2025-01-30 02:08:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2931/107898 [15:57<9:39:31,  3.02it/s][2025-01-30 02:08:07][root][INFO] - Training Epoch: 1/2, step 2930/107898 completed (loss: 0.08024342358112335, acc: 1.0)
[2025-01-30 02:08:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2932/107898 [15:57<9:21:25,  3.12it/s][2025-01-30 02:08:07][root][INFO] - Training Epoch: 1/2, step 2931/107898 completed (loss: 1.968827724456787, acc: 0.5454545617103577)
[2025-01-30 02:08:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2933/107898 [15:58<9:15:32,  3.15it/s][2025-01-30 02:08:07][root][INFO] - Training Epoch: 1/2, step 2932/107898 completed (loss: 2.0072128772735596, acc: 0.7647058963775635)
[2025-01-30 02:08:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2934/107898 [15:58<9:32:31,  3.06it/s][2025-01-30 02:08:08][root][INFO] - Training Epoch: 1/2, step 2933/107898 completed (loss: 1.2731367349624634, acc: 0.625)
[2025-01-30 02:08:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2935/107898 [15:58<9:42:33,  3.00it/s][2025-01-30 02:08:08][root][INFO] - Training Epoch: 1/2, step 2934/107898 completed (loss: 0.8832147717475891, acc: 0.8399999737739563)
[2025-01-30 02:08:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2936/107898 [15:59<9:30:18,  3.07it/s][2025-01-30 02:08:08][root][INFO] - Training Epoch: 1/2, step 2935/107898 completed (loss: 0.7802168726921082, acc: 1.0)
[2025-01-30 02:08:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2937/107898 [15:59<9:56:18,  2.93it/s][2025-01-30 02:08:09][root][INFO] - Training Epoch: 1/2, step 2936/107898 completed (loss: 0.021073848009109497, acc: 1.0)
[2025-01-30 02:08:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2938/107898 [15:59<9:55:19,  2.94it/s][2025-01-30 02:08:09][root][INFO] - Training Epoch: 1/2, step 2937/107898 completed (loss: 0.8345601558685303, acc: 0.8181818127632141)
[2025-01-30 02:08:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2939/107898 [16:00<10:03:39,  2.90it/s][2025-01-30 02:08:10][root][INFO] - Training Epoch: 1/2, step 2938/107898 completed (loss: 0.9598836898803711, acc: 0.7954545617103577)
[2025-01-30 02:08:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2940/107898 [16:00<9:43:56,  3.00it/s] [2025-01-30 02:08:10][root][INFO] - Training Epoch: 1/2, step 2939/107898 completed (loss: 1.2784005403518677, acc: 0.6363636255264282)
[2025-01-30 02:08:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2941/107898 [16:00<9:27:09,  3.08it/s][2025-01-30 02:08:10][root][INFO] - Training Epoch: 1/2, step 2940/107898 completed (loss: 0.4878864288330078, acc: 0.9333333373069763)
[2025-01-30 02:08:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2942/107898 [16:01<9:40:07,  3.02it/s][2025-01-30 02:08:10][root][INFO] - Training Epoch: 1/2, step 2941/107898 completed (loss: 1.8335009813308716, acc: 0.5862069129943848)
[2025-01-30 02:08:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2943/107898 [16:01<9:29:01,  3.07it/s][2025-01-30 02:08:11][root][INFO] - Training Epoch: 1/2, step 2942/107898 completed (loss: 0.9469462633132935, acc: 0.8999999761581421)
[2025-01-30 02:08:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2944/107898 [16:01<9:14:58,  3.15it/s][2025-01-30 02:08:11][root][INFO] - Training Epoch: 1/2, step 2943/107898 completed (loss: 0.0458499900996685, acc: 1.0)
[2025-01-30 02:08:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2945/107898 [16:02<9:12:16,  3.17it/s][2025-01-30 02:08:11][root][INFO] - Training Epoch: 1/2, step 2944/107898 completed (loss: 3.590975522994995, acc: 0.1428571492433548)
[2025-01-30 02:08:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2946/107898 [16:02<9:07:54,  3.19it/s][2025-01-30 02:08:12][root][INFO] - Training Epoch: 1/2, step 2945/107898 completed (loss: 1.2721534967422485, acc: 0.6666666865348816)
[2025-01-30 02:08:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2947/107898 [16:02<8:59:42,  3.24it/s][2025-01-30 02:08:12][root][INFO] - Training Epoch: 1/2, step 2946/107898 completed (loss: 0.05320797860622406, acc: 1.0)
[2025-01-30 02:08:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2948/107898 [16:03<9:05:31,  3.21it/s][2025-01-30 02:08:12][root][INFO] - Training Epoch: 1/2, step 2947/107898 completed (loss: 0.36836275458335876, acc: 0.9411764740943909)
[2025-01-30 02:08:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2949/107898 [16:03<9:07:39,  3.19it/s][2025-01-30 02:08:13][root][INFO] - Training Epoch: 1/2, step 2948/107898 completed (loss: 1.7101401090621948, acc: 0.692307710647583)
[2025-01-30 02:08:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2950/107898 [16:03<9:29:49,  3.07it/s][2025-01-30 02:08:13][root][INFO] - Training Epoch: 1/2, step 2949/107898 completed (loss: 3.410813570022583, acc: 0.4615384638309479)
[2025-01-30 02:08:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2951/107898 [16:04<9:51:16,  2.96it/s][2025-01-30 02:08:13][root][INFO] - Training Epoch: 1/2, step 2950/107898 completed (loss: 3.8578221797943115, acc: 0.5)
[2025-01-30 02:08:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2952/107898 [16:04<9:46:40,  2.98it/s][2025-01-30 02:08:14][root][INFO] - Training Epoch: 1/2, step 2951/107898 completed (loss: 1.40709388256073, acc: 0.7272727489471436)
[2025-01-30 02:08:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2953/107898 [16:04<9:40:44,  3.01it/s][2025-01-30 02:08:14][root][INFO] - Training Epoch: 1/2, step 2952/107898 completed (loss: 0.2542760670185089, acc: 1.0)
[2025-01-30 02:08:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2954/107898 [16:05<9:30:07,  3.07it/s][2025-01-30 02:08:14][root][INFO] - Training Epoch: 1/2, step 2953/107898 completed (loss: 1.1691794395446777, acc: 0.5833333134651184)
[2025-01-30 02:08:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2955/107898 [16:05<9:22:27,  3.11it/s][2025-01-30 02:08:15][root][INFO] - Training Epoch: 1/2, step 2954/107898 completed (loss: 3.7430808544158936, acc: 0.25)
[2025-01-30 02:08:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2956/107898 [16:05<9:10:07,  3.18it/s][2025-01-30 02:08:15][root][INFO] - Training Epoch: 1/2, step 2955/107898 completed (loss: 1.9372855424880981, acc: 0.5)
[2025-01-30 02:08:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2957/107898 [16:05<8:57:49,  3.25it/s][2025-01-30 02:08:15][root][INFO] - Training Epoch: 1/2, step 2956/107898 completed (loss: 0.041182953864336014, acc: 1.0)
[2025-01-30 02:08:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2958/107898 [16:06<8:57:46,  3.25it/s][2025-01-30 02:08:16][root][INFO] - Training Epoch: 1/2, step 2957/107898 completed (loss: 0.4702287018299103, acc: 0.8666666746139526)
[2025-01-30 02:08:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2959/107898 [16:06<9:05:31,  3.21it/s][2025-01-30 02:08:16][root][INFO] - Training Epoch: 1/2, step 2958/107898 completed (loss: 0.18558061122894287, acc: 0.9375)
[2025-01-30 02:08:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2960/107898 [16:06<9:14:01,  3.16it/s][2025-01-30 02:08:16][root][INFO] - Training Epoch: 1/2, step 2959/107898 completed (loss: 1.045249581336975, acc: 0.9090909361839294)
[2025-01-30 02:08:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2961/107898 [16:07<9:13:28,  3.16it/s][2025-01-30 02:08:16][root][INFO] - Training Epoch: 1/2, step 2960/107898 completed (loss: 1.0636123418807983, acc: 0.6666666865348816)
[2025-01-30 02:08:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2962/107898 [16:07<9:24:28,  3.10it/s][2025-01-30 02:08:17][root][INFO] - Training Epoch: 1/2, step 2961/107898 completed (loss: 0.18762274086475372, acc: 1.0)
[2025-01-30 02:08:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2963/107898 [16:07<9:17:55,  3.13it/s][2025-01-30 02:08:17][root][INFO] - Training Epoch: 1/2, step 2962/107898 completed (loss: 0.01024556066840887, acc: 1.0)
[2025-01-30 02:08:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2964/107898 [16:08<9:40:55,  3.01it/s][2025-01-30 02:08:18][root][INFO] - Training Epoch: 1/2, step 2963/107898 completed (loss: 2.6960368156433105, acc: 0.4615384638309479)
[2025-01-30 02:08:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2965/107898 [16:08<9:41:41,  3.01it/s][2025-01-30 02:08:18][root][INFO] - Training Epoch: 1/2, step 2964/107898 completed (loss: 0.33914077281951904, acc: 1.0)
[2025-01-30 02:08:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2966/107898 [16:08<9:34:07,  3.05it/s][2025-01-30 02:08:18][root][INFO] - Training Epoch: 1/2, step 2965/107898 completed (loss: 0.6846783757209778, acc: 0.6666666865348816)
[2025-01-30 02:08:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2967/107898 [16:09<9:36:11,  3.04it/s][2025-01-30 02:08:18][root][INFO] - Training Epoch: 1/2, step 2966/107898 completed (loss: 0.003460200037807226, acc: 1.0)
[2025-01-30 02:08:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2968/107898 [16:09<9:41:05,  3.01it/s][2025-01-30 02:08:19][root][INFO] - Training Epoch: 1/2, step 2967/107898 completed (loss: 0.1666214019060135, acc: 0.95652174949646)
[2025-01-30 02:08:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2969/107898 [16:09<9:28:11,  3.08it/s][2025-01-30 02:08:19][root][INFO] - Training Epoch: 1/2, step 2968/107898 completed (loss: 0.018924150615930557, acc: 1.0)
[2025-01-30 02:08:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2970/107898 [16:10<9:44:23,  2.99it/s][2025-01-30 02:08:19][root][INFO] - Training Epoch: 1/2, step 2969/107898 completed (loss: 0.22444403171539307, acc: 1.0)
[2025-01-30 02:08:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2971/107898 [16:10<9:40:33,  3.01it/s][2025-01-30 02:08:20][root][INFO] - Training Epoch: 1/2, step 2970/107898 completed (loss: 0.44470909237861633, acc: 0.7142857313156128)
[2025-01-30 02:08:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2972/107898 [16:10<9:41:16,  3.01it/s][2025-01-30 02:08:20][root][INFO] - Training Epoch: 1/2, step 2971/107898 completed (loss: 0.2617977559566498, acc: 0.9545454382896423)
[2025-01-30 02:08:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2973/107898 [16:11<9:33:51,  3.05it/s][2025-01-30 02:08:20][root][INFO] - Training Epoch: 1/2, step 2972/107898 completed (loss: 2.473165273666382, acc: 0.4444444477558136)
[2025-01-30 02:08:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2974/107898 [16:11<9:21:39,  3.11it/s][2025-01-30 02:08:21][root][INFO] - Training Epoch: 1/2, step 2973/107898 completed (loss: 0.21304579079151154, acc: 1.0)
[2025-01-30 02:08:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2975/107898 [16:11<9:20:01,  3.12it/s][2025-01-30 02:08:21][root][INFO] - Training Epoch: 1/2, step 2974/107898 completed (loss: 1.3011759519577026, acc: 0.7727272510528564)
[2025-01-30 02:08:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2976/107898 [16:12<9:08:22,  3.19it/s][2025-01-30 02:08:21][root][INFO] - Training Epoch: 1/2, step 2975/107898 completed (loss: 0.04482781141996384, acc: 1.0)
[2025-01-30 02:08:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2977/107898 [16:12<9:29:10,  3.07it/s][2025-01-30 02:08:22][root][INFO] - Training Epoch: 1/2, step 2976/107898 completed (loss: 3.637699604034424, acc: 0.25)
[2025-01-30 02:08:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2978/107898 [16:12<9:31:57,  3.06it/s][2025-01-30 02:08:22][root][INFO] - Training Epoch: 1/2, step 2977/107898 completed (loss: 3.2402844429016113, acc: 0.5384615659713745)
[2025-01-30 02:08:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2979/107898 [16:13<9:19:07,  3.13it/s][2025-01-30 02:08:22][root][INFO] - Training Epoch: 1/2, step 2978/107898 completed (loss: 1.5865894556045532, acc: 0.8235294222831726)
[2025-01-30 02:08:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2980/107898 [16:13<9:16:56,  3.14it/s][2025-01-30 02:08:23][root][INFO] - Training Epoch: 1/2, step 2979/107898 completed (loss: 2.026064395904541, acc: 0.0)
[2025-01-30 02:08:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2981/107898 [16:13<9:07:04,  3.20it/s][2025-01-30 02:08:23][root][INFO] - Training Epoch: 1/2, step 2980/107898 completed (loss: 2.0915379524230957, acc: 0.6666666865348816)
[2025-01-30 02:08:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2982/107898 [16:14<9:32:23,  3.05it/s][2025-01-30 02:08:23][root][INFO] - Training Epoch: 1/2, step 2981/107898 completed (loss: 2.715667724609375, acc: 0.4545454680919647)
[2025-01-30 02:08:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2983/107898 [16:14<9:32:14,  3.06it/s][2025-01-30 02:08:24][root][INFO] - Training Epoch: 1/2, step 2982/107898 completed (loss: 3.9409303665161133, acc: 0.1666666716337204)
[2025-01-30 02:08:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2984/107898 [16:14<9:29:33,  3.07it/s][2025-01-30 02:08:24][root][INFO] - Training Epoch: 1/2, step 2983/107898 completed (loss: 4.156877040863037, acc: 0.3333333432674408)
[2025-01-30 02:08:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2985/107898 [16:15<9:38:44,  3.02it/s][2025-01-30 02:08:24][root][INFO] - Training Epoch: 1/2, step 2984/107898 completed (loss: 3.5863330364227295, acc: 0.3076923191547394)
[2025-01-30 02:08:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2986/107898 [16:15<9:09:36,  3.18it/s][2025-01-30 02:08:25][root][INFO] - Training Epoch: 1/2, step 2985/107898 completed (loss: 0.08323058485984802, acc: 1.0)
[2025-01-30 02:08:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2987/107898 [16:15<9:30:12,  3.07it/s][2025-01-30 02:08:25][root][INFO] - Training Epoch: 1/2, step 2986/107898 completed (loss: 2.1069540977478027, acc: 0.5)
[2025-01-30 02:08:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2988/107898 [16:16<9:29:24,  3.07it/s][2025-01-30 02:08:25][root][INFO] - Training Epoch: 1/2, step 2987/107898 completed (loss: 0.5960676670074463, acc: 1.0)
[2025-01-30 02:08:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2989/107898 [16:16<9:23:42,  3.10it/s][2025-01-30 02:08:26][root][INFO] - Training Epoch: 1/2, step 2988/107898 completed (loss: 0.46532946825027466, acc: 0.800000011920929)
[2025-01-30 02:08:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2990/107898 [16:16<9:18:13,  3.13it/s][2025-01-30 02:08:26][root][INFO] - Training Epoch: 1/2, step 2989/107898 completed (loss: 0.8538792133331299, acc: 0.5)
[2025-01-30 02:08:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2991/107898 [16:16<9:12:18,  3.17it/s][2025-01-30 02:08:26][root][INFO] - Training Epoch: 1/2, step 2990/107898 completed (loss: 0.4529818594455719, acc: 0.875)
[2025-01-30 02:08:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2992/107898 [16:17<9:02:04,  3.23it/s][2025-01-30 02:08:27][root][INFO] - Training Epoch: 1/2, step 2991/107898 completed (loss: 3.4933221340179443, acc: 0.3333333432674408)
[2025-01-30 02:08:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2993/107898 [16:17<8:53:58,  3.27it/s][2025-01-30 02:08:27][root][INFO] - Training Epoch: 1/2, step 2992/107898 completed (loss: 0.43187493085861206, acc: 1.0)
[2025-01-30 02:08:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2994/107898 [16:17<9:25:50,  3.09it/s][2025-01-30 02:08:27][root][INFO] - Training Epoch: 1/2, step 2993/107898 completed (loss: 0.5097528696060181, acc: 0.9130434989929199)
[2025-01-30 02:08:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2995/107898 [16:18<9:09:41,  3.18it/s][2025-01-30 02:08:27][root][INFO] - Training Epoch: 1/2, step 2994/107898 completed (loss: 1.436855435371399, acc: 0.699999988079071)
[2025-01-30 02:08:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2996/107898 [16:18<9:01:12,  3.23it/s][2025-01-30 02:08:28][root][INFO] - Training Epoch: 1/2, step 2995/107898 completed (loss: 0.985722541809082, acc: 0.6363636255264282)
[2025-01-30 02:08:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2997/107898 [16:18<8:58:21,  3.25it/s][2025-01-30 02:08:28][root][INFO] - Training Epoch: 1/2, step 2996/107898 completed (loss: 0.6182769536972046, acc: 0.875)
[2025-01-30 02:08:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2998/107898 [16:19<9:03:10,  3.22it/s][2025-01-30 02:08:28][root][INFO] - Training Epoch: 1/2, step 2997/107898 completed (loss: 2.9200222492218018, acc: 0.25)
[2025-01-30 02:08:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 2999/107898 [16:19<8:55:10,  3.27it/s][2025-01-30 02:08:29][root][INFO] - Training Epoch: 1/2, step 2998/107898 completed (loss: 0.9510520696640015, acc: 0.8148148059844971)
[2025-01-30 02:08:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3000/107898 [16:19<8:46:32,  3.32it/s][2025-01-30 02:08:29][root][INFO] - Training Epoch: 1/2, step 2999/107898 completed (loss: 2.573467254638672, acc: 0.6000000238418579)
[2025-01-30 02:08:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3001/107898 [16:20<8:51:20,  3.29it/s][2025-01-30 02:08:29][root][INFO] - Training Epoch: 1/2, step 3000/107898 completed (loss: 0.023000599816441536, acc: 1.0)
[2025-01-30 02:08:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3002/107898 [16:20<9:17:44,  3.13it/s][2025-01-30 02:08:30][root][INFO] - Training Epoch: 1/2, step 3001/107898 completed (loss: 0.027860580012202263, acc: 1.0)
[2025-01-30 02:08:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3003/107898 [16:20<9:24:09,  3.10it/s][2025-01-30 02:08:30][root][INFO] - Training Epoch: 1/2, step 3002/107898 completed (loss: 0.21155591309070587, acc: 1.0)
[2025-01-30 02:08:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3004/107898 [16:21<9:38:36,  3.02it/s][2025-01-30 02:08:30][root][INFO] - Training Epoch: 1/2, step 3003/107898 completed (loss: 0.01592782512307167, acc: 1.0)
[2025-01-30 02:08:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3005/107898 [16:21<9:19:22,  3.13it/s][2025-01-30 02:08:31][root][INFO] - Training Epoch: 1/2, step 3004/107898 completed (loss: 3.489306688308716, acc: 0.25)
[2025-01-30 02:08:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3006/107898 [16:21<9:13:37,  3.16it/s][2025-01-30 02:08:31][root][INFO] - Training Epoch: 1/2, step 3005/107898 completed (loss: 0.9740287065505981, acc: 0.8260869383811951)
[2025-01-30 02:08:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3007/107898 [16:21<9:10:13,  3.18it/s][2025-01-30 02:08:31][root][INFO] - Training Epoch: 1/2, step 3006/107898 completed (loss: 0.49096134305000305, acc: 0.9230769276618958)
[2025-01-30 02:08:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3008/107898 [16:22<8:59:37,  3.24it/s][2025-01-30 02:08:32][root][INFO] - Training Epoch: 1/2, step 3007/107898 completed (loss: 1.1120479106903076, acc: 0.75)
[2025-01-30 02:08:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3009/107898 [16:22<9:02:34,  3.22it/s][2025-01-30 02:08:32][root][INFO] - Training Epoch: 1/2, step 3008/107898 completed (loss: 0.25847408175468445, acc: 0.9375)
[2025-01-30 02:08:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3010/107898 [16:22<8:54:18,  3.27it/s][2025-01-30 02:08:32][root][INFO] - Training Epoch: 1/2, step 3009/107898 completed (loss: 1.579228162765503, acc: 0.692307710647583)
[2025-01-30 02:08:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3011/107898 [16:23<9:02:47,  3.22it/s][2025-01-30 02:08:32][root][INFO] - Training Epoch: 1/2, step 3010/107898 completed (loss: 1.510022759437561, acc: 0.6296296119689941)
[2025-01-30 02:08:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3012/107898 [16:23<9:04:12,  3.21it/s][2025-01-30 02:08:33][root][INFO] - Training Epoch: 1/2, step 3011/107898 completed (loss: 2.6225342750549316, acc: 0.4000000059604645)
[2025-01-30 02:08:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3013/107898 [16:23<9:26:48,  3.08it/s][2025-01-30 02:08:33][root][INFO] - Training Epoch: 1/2, step 3012/107898 completed (loss: 0.6752389073371887, acc: 0.8666666746139526)
[2025-01-30 02:08:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3014/107898 [16:24<9:19:58,  3.12it/s][2025-01-30 02:08:33][root][INFO] - Training Epoch: 1/2, step 3013/107898 completed (loss: 1.0223619937896729, acc: 0.5)
[2025-01-30 02:08:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3015/107898 [16:24<9:20:59,  3.12it/s][2025-01-30 02:08:34][root][INFO] - Training Epoch: 1/2, step 3014/107898 completed (loss: 1.046233892440796, acc: 0.5)
[2025-01-30 02:08:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3016/107898 [16:24<9:16:55,  3.14it/s][2025-01-30 02:08:34][root][INFO] - Training Epoch: 1/2, step 3015/107898 completed (loss: 0.8807697296142578, acc: 0.6666666865348816)
[2025-01-30 02:08:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3017/107898 [16:25<9:15:41,  3.15it/s][2025-01-30 02:08:34][root][INFO] - Training Epoch: 1/2, step 3016/107898 completed (loss: 1.9656802415847778, acc: 0.6153846383094788)
[2025-01-30 02:08:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3018/107898 [16:25<9:16:01,  3.14it/s][2025-01-30 02:08:35][root][INFO] - Training Epoch: 1/2, step 3017/107898 completed (loss: 0.7634239792823792, acc: 0.8666666746139526)
[2025-01-30 02:08:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3019/107898 [16:25<9:46:56,  2.98it/s][2025-01-30 02:08:35][root][INFO] - Training Epoch: 1/2, step 3018/107898 completed (loss: 1.3031283617019653, acc: 0.6363636255264282)
[2025-01-30 02:08:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3020/107898 [16:26<9:46:15,  2.98it/s][2025-01-30 02:08:35][root][INFO] - Training Epoch: 1/2, step 3019/107898 completed (loss: 0.21036888659000397, acc: 0.9166666865348816)
[2025-01-30 02:08:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3021/107898 [16:26<9:28:53,  3.07it/s][2025-01-30 02:08:36][root][INFO] - Training Epoch: 1/2, step 3020/107898 completed (loss: 0.42694684863090515, acc: 0.9411764740943909)
[2025-01-30 02:08:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3022/107898 [16:26<9:16:55,  3.14it/s][2025-01-30 02:08:36][root][INFO] - Training Epoch: 1/2, step 3021/107898 completed (loss: 0.028165223076939583, acc: 1.0)
[2025-01-30 02:08:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3023/107898 [16:27<9:32:06,  3.06it/s][2025-01-30 02:08:36][root][INFO] - Training Epoch: 1/2, step 3022/107898 completed (loss: 0.028355896472930908, acc: 1.0)
[2025-01-30 02:08:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3024/107898 [16:27<9:35:11,  3.04it/s][2025-01-30 02:08:37][root][INFO] - Training Epoch: 1/2, step 3023/107898 completed (loss: 1.108811378479004, acc: 0.75)
[2025-01-30 02:08:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3025/107898 [16:27<9:27:15,  3.08it/s][2025-01-30 02:08:37][root][INFO] - Training Epoch: 1/2, step 3024/107898 completed (loss: 0.15573272109031677, acc: 1.0)
[2025-01-30 02:08:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3026/107898 [16:28<9:34:10,  3.04it/s][2025-01-30 02:08:37][root][INFO] - Training Epoch: 1/2, step 3025/107898 completed (loss: 0.20955389738082886, acc: 1.0)
[2025-01-30 02:08:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3027/107898 [16:28<9:45:28,  2.99it/s][2025-01-30 02:08:38][root][INFO] - Training Epoch: 1/2, step 3026/107898 completed (loss: 0.8517634272575378, acc: 0.8500000238418579)
[2025-01-30 02:08:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3028/107898 [16:28<10:00:34,  2.91it/s][2025-01-30 02:08:38][root][INFO] - Training Epoch: 1/2, step 3027/107898 completed (loss: 1.2399513721466064, acc: 0.7727272510528564)
[2025-01-30 02:08:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3029/107898 [16:29<10:07:05,  2.88it/s][2025-01-30 02:08:38][root][INFO] - Training Epoch: 1/2, step 3028/107898 completed (loss: 2.6835668087005615, acc: 0.6000000238418579)
[2025-01-30 02:08:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3030/107898 [16:29<9:58:35,  2.92it/s] [2025-01-30 02:08:39][root][INFO] - Training Epoch: 1/2, step 3029/107898 completed (loss: 1.4122159481048584, acc: 0.699999988079071)
[2025-01-30 02:08:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3031/107898 [16:29<10:05:04,  2.89it/s][2025-01-30 02:08:39][root][INFO] - Training Epoch: 1/2, step 3030/107898 completed (loss: 1.5359171628952026, acc: 0.7142857313156128)
[2025-01-30 02:08:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3032/107898 [16:30<9:52:25,  2.95it/s] [2025-01-30 02:08:39][root][INFO] - Training Epoch: 1/2, step 3031/107898 completed (loss: 0.9173908829689026, acc: 0.7647058963775635)
[2025-01-30 02:08:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3033/107898 [16:30<9:42:02,  3.00it/s][2025-01-30 02:08:40][root][INFO] - Training Epoch: 1/2, step 3032/107898 completed (loss: 0.6117004156112671, acc: 0.800000011920929)
[2025-01-30 02:08:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3034/107898 [16:30<9:50:58,  2.96it/s][2025-01-30 02:08:40][root][INFO] - Training Epoch: 1/2, step 3033/107898 completed (loss: 0.003808678360655904, acc: 1.0)
[2025-01-30 02:08:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3035/107898 [16:31<9:45:26,  2.99it/s][2025-01-30 02:08:40][root][INFO] - Training Epoch: 1/2, step 3034/107898 completed (loss: 0.8298463225364685, acc: 0.7599999904632568)
[2025-01-30 02:08:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3036/107898 [16:31<9:38:28,  3.02it/s][2025-01-30 02:08:41][root][INFO] - Training Epoch: 1/2, step 3035/107898 completed (loss: 0.011852798983454704, acc: 1.0)
[2025-01-30 02:08:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3037/107898 [16:31<9:22:30,  3.11it/s][2025-01-30 02:08:41][root][INFO] - Training Epoch: 1/2, step 3036/107898 completed (loss: 0.08001526445150375, acc: 1.0)
[2025-01-30 02:08:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3038/107898 [16:32<9:05:47,  3.20it/s][2025-01-30 02:08:41][root][INFO] - Training Epoch: 1/2, step 3037/107898 completed (loss: 1.920331358909607, acc: 0.5)
[2025-01-30 02:08:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3039/107898 [16:32<9:05:51,  3.20it/s][2025-01-30 02:08:42][root][INFO] - Training Epoch: 1/2, step 3038/107898 completed (loss: 1.3222332000732422, acc: 0.6666666865348816)
[2025-01-30 02:08:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3040/107898 [16:32<9:25:07,  3.09it/s][2025-01-30 02:08:42][root][INFO] - Training Epoch: 1/2, step 3039/107898 completed (loss: 0.05742726847529411, acc: 1.0)
[2025-01-30 02:08:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3041/107898 [16:33<9:39:54,  3.01it/s][2025-01-30 02:08:42][root][INFO] - Training Epoch: 1/2, step 3040/107898 completed (loss: 3.690774440765381, acc: 0.18518517911434174)
[2025-01-30 02:08:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3042/107898 [16:33<9:45:49,  2.98it/s][2025-01-30 02:08:43][root][INFO] - Training Epoch: 1/2, step 3041/107898 completed (loss: 1.9720667600631714, acc: 0.7083333134651184)
[2025-01-30 02:08:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3043/107898 [16:33<9:53:22,  2.95it/s][2025-01-30 02:08:43][root][INFO] - Training Epoch: 1/2, step 3042/107898 completed (loss: 3.090362787246704, acc: 0.1111111119389534)
[2025-01-30 02:08:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3044/107898 [16:34<10:09:14,  2.87it/s][2025-01-30 02:08:43][root][INFO] - Training Epoch: 1/2, step 3043/107898 completed (loss: 1.3643499612808228, acc: 0.6000000238418579)
[2025-01-30 02:08:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3045/107898 [16:34<9:54:09,  2.94it/s] [2025-01-30 02:08:44][root][INFO] - Training Epoch: 1/2, step 3044/107898 completed (loss: 0.3730049431324005, acc: 1.0)
[2025-01-30 02:08:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3046/107898 [16:34<10:01:30,  2.91it/s][2025-01-30 02:08:44][root][INFO] - Training Epoch: 1/2, step 3045/107898 completed (loss: 1.6853934526443481, acc: 0.7333333492279053)
[2025-01-30 02:08:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3047/107898 [16:35<9:53:25,  2.94it/s] [2025-01-30 02:08:44][root][INFO] - Training Epoch: 1/2, step 3046/107898 completed (loss: 0.14128147065639496, acc: 1.0)
[2025-01-30 02:08:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3048/107898 [16:35<9:56:01,  2.93it/s][2025-01-30 02:08:45][root][INFO] - Training Epoch: 1/2, step 3047/107898 completed (loss: 3.453335762023926, acc: 0.25)
[2025-01-30 02:08:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3049/107898 [16:35<9:44:21,  2.99it/s][2025-01-30 02:08:45][root][INFO] - Training Epoch: 1/2, step 3048/107898 completed (loss: 0.44526782631874084, acc: 0.8571428656578064)
[2025-01-30 02:08:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3050/107898 [16:36<9:32:10,  3.05it/s][2025-01-30 02:08:45][root][INFO] - Training Epoch: 1/2, step 3049/107898 completed (loss: 0.0650467798113823, acc: 1.0)
[2025-01-30 02:08:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3051/107898 [16:36<9:53:06,  2.95it/s][2025-01-30 02:08:46][root][INFO] - Training Epoch: 1/2, step 3050/107898 completed (loss: 0.5635796189308167, acc: 0.9285714030265808)
[2025-01-30 02:08:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3052/107898 [16:36<10:05:33,  2.89it/s][2025-01-30 02:08:46][root][INFO] - Training Epoch: 1/2, step 3051/107898 completed (loss: 0.1762838363647461, acc: 1.0)
[2025-01-30 02:08:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3053/107898 [16:37<9:56:44,  2.93it/s] [2025-01-30 02:08:46][root][INFO] - Training Epoch: 1/2, step 3052/107898 completed (loss: 1.7375576496124268, acc: 0.6153846383094788)
[2025-01-30 02:08:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3054/107898 [16:37<9:44:02,  2.99it/s][2025-01-30 02:08:47][root][INFO] - Training Epoch: 1/2, step 3053/107898 completed (loss: 0.3151342272758484, acc: 1.0)
[2025-01-30 02:08:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3055/107898 [16:37<9:19:21,  3.12it/s][2025-01-30 02:08:47][root][INFO] - Training Epoch: 1/2, step 3054/107898 completed (loss: 2.5615532398223877, acc: 0.3333333432674408)
[2025-01-30 02:08:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3056/107898 [16:38<9:24:27,  3.10it/s][2025-01-30 02:08:47][root][INFO] - Training Epoch: 1/2, step 3055/107898 completed (loss: 4.9625372886657715, acc: 0.2222222238779068)
[2025-01-30 02:08:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3057/107898 [16:38<9:20:57,  3.11it/s][2025-01-30 02:08:48][root][INFO] - Training Epoch: 1/2, step 3056/107898 completed (loss: 0.519853949546814, acc: 0.75)
[2025-01-30 02:08:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3058/107898 [16:38<9:26:11,  3.09it/s][2025-01-30 02:08:48][root][INFO] - Training Epoch: 1/2, step 3057/107898 completed (loss: 0.06260259449481964, acc: 1.0)
[2025-01-30 02:08:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3059/107898 [16:39<9:08:14,  3.19it/s][2025-01-30 02:08:48][root][INFO] - Training Epoch: 1/2, step 3058/107898 completed (loss: 0.5250181555747986, acc: 0.8999999761581421)
[2025-01-30 02:08:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3060/107898 [16:39<9:19:37,  3.12it/s][2025-01-30 02:08:49][root][INFO] - Training Epoch: 1/2, step 3059/107898 completed (loss: 0.18938378989696503, acc: 1.0)
[2025-01-30 02:08:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3061/107898 [16:39<9:06:44,  3.20it/s][2025-01-30 02:08:49][root][INFO] - Training Epoch: 1/2, step 3060/107898 completed (loss: 0.853715181350708, acc: 0.6666666865348816)
[2025-01-30 02:08:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3062/107898 [16:40<9:21:39,  3.11it/s][2025-01-30 02:08:49][root][INFO] - Training Epoch: 1/2, step 3061/107898 completed (loss: 0.1710648387670517, acc: 1.0)
[2025-01-30 02:08:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3063/107898 [16:40<9:34:02,  3.04it/s][2025-01-30 02:08:50][root][INFO] - Training Epoch: 1/2, step 3062/107898 completed (loss: 1.893369197845459, acc: 0.692307710647583)
[2025-01-30 02:08:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3064/107898 [16:40<9:29:39,  3.07it/s][2025-01-30 02:08:50][root][INFO] - Training Epoch: 1/2, step 3063/107898 completed (loss: 0.05898844450712204, acc: 1.0)
[2025-01-30 02:08:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3065/107898 [16:40<9:04:01,  3.21it/s][2025-01-30 02:08:50][root][INFO] - Training Epoch: 1/2, step 3064/107898 completed (loss: 4.66977071762085, acc: 0.3333333432674408)
[2025-01-30 02:08:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3066/107898 [16:41<9:05:03,  3.21it/s][2025-01-30 02:08:51][root][INFO] - Training Epoch: 1/2, step 3065/107898 completed (loss: 0.012670520693063736, acc: 1.0)
[2025-01-30 02:08:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3067/107898 [16:41<9:27:20,  3.08it/s][2025-01-30 02:08:51][root][INFO] - Training Epoch: 1/2, step 3066/107898 completed (loss: 0.7372421622276306, acc: 0.7142857313156128)
[2025-01-30 02:08:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3068/107898 [16:41<9:16:46,  3.14it/s][2025-01-30 02:08:51][root][INFO] - Training Epoch: 1/2, step 3067/107898 completed (loss: 0.4781791567802429, acc: 1.0)
[2025-01-30 02:08:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3069/107898 [16:42<9:02:07,  3.22it/s][2025-01-30 02:08:52][root][INFO] - Training Epoch: 1/2, step 3068/107898 completed (loss: 1.2481956481933594, acc: 0.692307710647583)
[2025-01-30 02:08:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3070/107898 [16:42<9:26:35,  3.08it/s][2025-01-30 02:08:52][root][INFO] - Training Epoch: 1/2, step 3069/107898 completed (loss: 0.5192403197288513, acc: 0.9166666865348816)
[2025-01-30 02:08:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3071/107898 [16:42<9:23:00,  3.10it/s][2025-01-30 02:08:52][root][INFO] - Training Epoch: 1/2, step 3070/107898 completed (loss: 1.7693129777908325, acc: 0.5833333134651184)
[2025-01-30 02:08:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3072/107898 [16:43<9:09:48,  3.18it/s][2025-01-30 02:08:52][root][INFO] - Training Epoch: 1/2, step 3071/107898 completed (loss: 1.0891005992889404, acc: 0.8666666746139526)
[2025-01-30 02:08:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3073/107898 [16:43<9:30:51,  3.06it/s][2025-01-30 02:08:53][root][INFO] - Training Epoch: 1/2, step 3072/107898 completed (loss: 0.21708138287067413, acc: 1.0)
[2025-01-30 02:08:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3074/107898 [16:43<9:35:12,  3.04it/s][2025-01-30 02:08:53][root][INFO] - Training Epoch: 1/2, step 3073/107898 completed (loss: 0.05788249522447586, acc: 1.0)
[2025-01-30 02:08:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3075/107898 [16:44<9:32:19,  3.05it/s][2025-01-30 02:08:54][root][INFO] - Training Epoch: 1/2, step 3074/107898 completed (loss: 1.3656861782073975, acc: 0.6666666865348816)
[2025-01-30 02:08:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3076/107898 [16:44<9:53:55,  2.94it/s][2025-01-30 02:08:54][root][INFO] - Training Epoch: 1/2, step 3075/107898 completed (loss: 0.9996649026870728, acc: 0.8181818127632141)
[2025-01-30 02:08:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3077/107898 [16:44<9:46:47,  2.98it/s][2025-01-30 02:08:54][root][INFO] - Training Epoch: 1/2, step 3076/107898 completed (loss: 2.324075222015381, acc: 0.5)
[2025-01-30 02:08:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3078/107898 [16:45<9:28:12,  3.07it/s][2025-01-30 02:08:55][root][INFO] - Training Epoch: 1/2, step 3077/107898 completed (loss: 0.887665867805481, acc: 0.800000011920929)
[2025-01-30 02:08:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3079/107898 [16:45<9:11:36,  3.17it/s][2025-01-30 02:08:55][root][INFO] - Training Epoch: 1/2, step 3078/107898 completed (loss: 0.36061516404151917, acc: 1.0)
[2025-01-30 02:08:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3080/107898 [16:45<9:12:32,  3.16it/s][2025-01-30 02:08:55][root][INFO] - Training Epoch: 1/2, step 3079/107898 completed (loss: 0.8909776210784912, acc: 0.875)
[2025-01-30 02:08:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3081/107898 [16:46<9:29:36,  3.07it/s][2025-01-30 02:08:55][root][INFO] - Training Epoch: 1/2, step 3080/107898 completed (loss: 0.947559654712677, acc: 0.6666666865348816)
[2025-01-30 02:08:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3082/107898 [16:46<9:33:12,  3.05it/s][2025-01-30 02:08:56][root][INFO] - Training Epoch: 1/2, step 3081/107898 completed (loss: 0.012398768216371536, acc: 1.0)
[2025-01-30 02:08:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3083/107898 [16:46<9:52:23,  2.95it/s][2025-01-30 02:08:56][root][INFO] - Training Epoch: 1/2, step 3082/107898 completed (loss: 0.7812957763671875, acc: 0.8571428656578064)
[2025-01-30 02:08:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3084/107898 [16:47<9:47:43,  2.97it/s][2025-01-30 02:08:56][root][INFO] - Training Epoch: 1/2, step 3083/107898 completed (loss: 0.011945713311433792, acc: 1.0)
[2025-01-30 02:08:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3085/107898 [16:47<9:36:37,  3.03it/s][2025-01-30 02:08:57][root][INFO] - Training Epoch: 1/2, step 3084/107898 completed (loss: 2.14125657081604, acc: 0.5555555820465088)
[2025-01-30 02:08:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3086/107898 [16:47<9:21:47,  3.11it/s][2025-01-30 02:08:57][root][INFO] - Training Epoch: 1/2, step 3085/107898 completed (loss: 0.1435818076133728, acc: 1.0)
[2025-01-30 02:08:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3087/107898 [16:48<9:14:03,  3.15it/s][2025-01-30 02:08:57][root][INFO] - Training Epoch: 1/2, step 3086/107898 completed (loss: 1.3085381984710693, acc: 0.800000011920929)
[2025-01-30 02:08:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3088/107898 [16:48<9:16:43,  3.14it/s][2025-01-30 02:08:58][root][INFO] - Training Epoch: 1/2, step 3087/107898 completed (loss: 2.640501022338867, acc: 0.5600000023841858)
[2025-01-30 02:08:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3089/107898 [16:48<9:04:17,  3.21it/s][2025-01-30 02:08:58][root][INFO] - Training Epoch: 1/2, step 3088/107898 completed (loss: 0.866646945476532, acc: 1.0)
[2025-01-30 02:08:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3090/107898 [16:49<9:15:24,  3.15it/s][2025-01-30 02:08:58][root][INFO] - Training Epoch: 1/2, step 3089/107898 completed (loss: 0.4865339696407318, acc: 0.8333333134651184)
[2025-01-30 02:08:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3091/107898 [16:49<9:12:02,  3.16it/s][2025-01-30 02:08:59][root][INFO] - Training Epoch: 1/2, step 3090/107898 completed (loss: 2.212393283843994, acc: 0.3636363744735718)
[2025-01-30 02:08:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3092/107898 [16:49<9:13:38,  3.16it/s][2025-01-30 02:08:59][root][INFO] - Training Epoch: 1/2, step 3091/107898 completed (loss: 0.002485474804416299, acc: 1.0)
[2025-01-30 02:08:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3093/107898 [16:50<9:05:45,  3.20it/s][2025-01-30 02:08:59][root][INFO] - Training Epoch: 1/2, step 3092/107898 completed (loss: 0.9119312763214111, acc: 0.8666666746139526)
[2025-01-30 02:08:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3094/107898 [16:50<9:21:52,  3.11it/s][2025-01-30 02:09:00][root][INFO] - Training Epoch: 1/2, step 3093/107898 completed (loss: 0.7046051621437073, acc: 0.8571428656578064)
[2025-01-30 02:09:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3095/107898 [16:50<9:28:41,  3.07it/s][2025-01-30 02:09:00][root][INFO] - Training Epoch: 1/2, step 3094/107898 completed (loss: 0.33982813358306885, acc: 0.8888888955116272)
[2025-01-30 02:09:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3096/107898 [16:50<9:19:42,  3.12it/s][2025-01-30 02:09:00][root][INFO] - Training Epoch: 1/2, step 3095/107898 completed (loss: 0.6152196526527405, acc: 0.9090909361839294)
[2025-01-30 02:09:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3097/107898 [16:51<9:05:35,  3.20it/s][2025-01-30 02:09:01][root][INFO] - Training Epoch: 1/2, step 3096/107898 completed (loss: 0.7365264892578125, acc: 0.8333333134651184)
[2025-01-30 02:09:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3098/107898 [16:51<9:06:51,  3.19it/s][2025-01-30 02:09:01][root][INFO] - Training Epoch: 1/2, step 3097/107898 completed (loss: 1.0405040979385376, acc: 0.8888888955116272)
[2025-01-30 02:09:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3099/107898 [16:51<9:17:22,  3.13it/s][2025-01-30 02:09:01][root][INFO] - Training Epoch: 1/2, step 3098/107898 completed (loss: 0.4593602418899536, acc: 1.0)
[2025-01-30 02:09:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3100/107898 [16:52<9:40:23,  3.01it/s][2025-01-30 02:09:02][root][INFO] - Training Epoch: 1/2, step 3099/107898 completed (loss: 1.3489973545074463, acc: 0.5)
[2025-01-30 02:09:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3101/107898 [16:52<9:20:27,  3.12it/s][2025-01-30 02:09:02][root][INFO] - Training Epoch: 1/2, step 3100/107898 completed (loss: 0.13693654537200928, acc: 1.0)
[2025-01-30 02:09:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3102/107898 [16:52<9:16:13,  3.14it/s][2025-01-30 02:09:02][root][INFO] - Training Epoch: 1/2, step 3101/107898 completed (loss: 0.6821349859237671, acc: 0.8636363744735718)
[2025-01-30 02:09:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3103/107898 [16:53<9:08:49,  3.18it/s][2025-01-30 02:09:03][root][INFO] - Training Epoch: 1/2, step 3102/107898 completed (loss: 0.02177393063902855, acc: 1.0)
[2025-01-30 02:09:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3104/107898 [16:53<8:48:17,  3.31it/s][2025-01-30 02:09:03][root][INFO] - Training Epoch: 1/2, step 3103/107898 completed (loss: 1.175411343574524, acc: 0.625)
[2025-01-30 02:09:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3105/107898 [16:53<8:40:13,  3.36it/s][2025-01-30 02:09:03][root][INFO] - Training Epoch: 1/2, step 3104/107898 completed (loss: 0.01643369160592556, acc: 1.0)
[2025-01-30 02:09:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3106/107898 [16:54<8:52:53,  3.28it/s][2025-01-30 02:09:03][root][INFO] - Training Epoch: 1/2, step 3105/107898 completed (loss: 1.4007526636123657, acc: 0.699999988079071)
[2025-01-30 02:09:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3107/107898 [16:54<9:05:04,  3.20it/s][2025-01-30 02:09:04][root][INFO] - Training Epoch: 1/2, step 3106/107898 completed (loss: 1.0772438049316406, acc: 0.8260869383811951)
[2025-01-30 02:09:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3108/107898 [16:54<9:26:52,  3.08it/s][2025-01-30 02:09:04][root][INFO] - Training Epoch: 1/2, step 3107/107898 completed (loss: 1.600233554840088, acc: 0.4444444477558136)
[2025-01-30 02:09:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3109/107898 [16:55<9:28:29,  3.07it/s][2025-01-30 02:09:04][root][INFO] - Training Epoch: 1/2, step 3108/107898 completed (loss: 0.6812218427658081, acc: 0.807692289352417)
[2025-01-30 02:09:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3110/107898 [16:55<9:19:42,  3.12it/s][2025-01-30 02:09:05][root][INFO] - Training Epoch: 1/2, step 3109/107898 completed (loss: 1.1247318983078003, acc: 0.8125)
[2025-01-30 02:09:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3111/107898 [16:55<9:05:47,  3.20it/s][2025-01-30 02:09:05][root][INFO] - Training Epoch: 1/2, step 3110/107898 completed (loss: 0.0811193659901619, acc: 1.0)
[2025-01-30 02:09:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3112/107898 [16:56<8:56:34,  3.25it/s][2025-01-30 02:09:05][root][INFO] - Training Epoch: 1/2, step 3111/107898 completed (loss: 0.49616676568984985, acc: 0.9130434989929199)
[2025-01-30 02:09:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3113/107898 [16:56<8:59:34,  3.24it/s][2025-01-30 02:09:06][root][INFO] - Training Epoch: 1/2, step 3112/107898 completed (loss: 1.25288724899292, acc: 0.75)
[2025-01-30 02:09:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3114/107898 [16:56<8:42:57,  3.34it/s][2025-01-30 02:09:06][root][INFO] - Training Epoch: 1/2, step 3113/107898 completed (loss: 0.05328573286533356, acc: 1.0)
[2025-01-30 02:09:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3115/107898 [16:56<9:11:20,  3.17it/s][2025-01-30 02:09:06][root][INFO] - Training Epoch: 1/2, step 3114/107898 completed (loss: 0.004111021291464567, acc: 1.0)
[2025-01-30 02:09:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3116/107898 [16:57<9:13:19,  3.16it/s][2025-01-30 02:09:07][root][INFO] - Training Epoch: 1/2, step 3115/107898 completed (loss: 2.4610891342163086, acc: 0.30000001192092896)
[2025-01-30 02:09:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3117/107898 [16:57<9:43:30,  2.99it/s][2025-01-30 02:09:07][root][INFO] - Training Epoch: 1/2, step 3116/107898 completed (loss: 0.6899142265319824, acc: 0.8421052694320679)
[2025-01-30 02:09:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3118/107898 [16:57<9:32:59,  3.05it/s][2025-01-30 02:09:07][root][INFO] - Training Epoch: 1/2, step 3117/107898 completed (loss: 3.122422933578491, acc: 0.1428571492433548)
[2025-01-30 02:09:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3119/107898 [16:58<9:43:25,  2.99it/s][2025-01-30 02:09:08][root][INFO] - Training Epoch: 1/2, step 3118/107898 completed (loss: 0.7461438179016113, acc: 0.75)
[2025-01-30 02:09:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3120/107898 [16:58<9:44:00,  2.99it/s][2025-01-30 02:09:08][root][INFO] - Training Epoch: 1/2, step 3119/107898 completed (loss: 0.9117365479469299, acc: 0.7586206793785095)
[2025-01-30 02:09:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3121/107898 [16:58<9:41:42,  3.00it/s][2025-01-30 02:09:08][root][INFO] - Training Epoch: 1/2, step 3120/107898 completed (loss: 1.7791930437088013, acc: 0.5454545617103577)
[2025-01-30 02:09:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3122/107898 [16:59<9:26:01,  3.09it/s][2025-01-30 02:09:09][root][INFO] - Training Epoch: 1/2, step 3121/107898 completed (loss: 0.020365603268146515, acc: 1.0)
[2025-01-30 02:09:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3123/107898 [16:59<9:12:25,  3.16it/s][2025-01-30 02:09:09][root][INFO] - Training Epoch: 1/2, step 3122/107898 completed (loss: 5.342964172363281, acc: 0.3333333432674408)
[2025-01-30 02:09:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3124/107898 [16:59<9:04:48,  3.21it/s][2025-01-30 02:09:09][root][INFO] - Training Epoch: 1/2, step 3123/107898 completed (loss: 1.7160544395446777, acc: 0.75)
[2025-01-30 02:09:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3125/107898 [17:00<9:01:18,  3.23it/s][2025-01-30 02:09:09][root][INFO] - Training Epoch: 1/2, step 3124/107898 completed (loss: 3.7591745853424072, acc: 0.27272728085517883)
[2025-01-30 02:09:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3126/107898 [17:00<9:05:08,  3.20it/s][2025-01-30 02:09:10][root][INFO] - Training Epoch: 1/2, step 3125/107898 completed (loss: 4.469787120819092, acc: 0.1818181872367859)
[2025-01-30 02:09:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3127/107898 [17:00<8:53:46,  3.27it/s][2025-01-30 02:09:10][root][INFO] - Training Epoch: 1/2, step 3126/107898 completed (loss: 0.6626459360122681, acc: 0.800000011920929)
[2025-01-30 02:09:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3128/107898 [17:01<8:57:43,  3.25it/s][2025-01-30 02:09:10][root][INFO] - Training Epoch: 1/2, step 3127/107898 completed (loss: 1.2967889308929443, acc: 0.800000011920929)
[2025-01-30 02:09:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3129/107898 [17:01<9:23:59,  3.10it/s][2025-01-30 02:09:11][root][INFO] - Training Epoch: 1/2, step 3128/107898 completed (loss: 3.457487106323242, acc: 0.4117647111415863)
[2025-01-30 02:09:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3130/107898 [17:01<9:48:57,  2.96it/s][2025-01-30 02:09:11][root][INFO] - Training Epoch: 1/2, step 3129/107898 completed (loss: 1.2937229871749878, acc: 0.6666666865348816)
[2025-01-30 02:09:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3131/107898 [17:02<9:44:48,  2.99it/s][2025-01-30 02:09:11][root][INFO] - Training Epoch: 1/2, step 3130/107898 completed (loss: 1.6370420455932617, acc: 0.800000011920929)
[2025-01-30 02:09:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3132/107898 [17:02<9:57:00,  2.92it/s][2025-01-30 02:09:12][root][INFO] - Training Epoch: 1/2, step 3131/107898 completed (loss: 0.9047306180000305, acc: 0.8181818127632141)
[2025-01-30 02:09:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3133/107898 [17:02<10:09:27,  2.86it/s][2025-01-30 02:09:12][root][INFO] - Training Epoch: 1/2, step 3132/107898 completed (loss: 0.030571626499295235, acc: 1.0)
[2025-01-30 02:09:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3134/107898 [17:03<9:53:23,  2.94it/s] [2025-01-30 02:09:12][root][INFO] - Training Epoch: 1/2, step 3133/107898 completed (loss: 1.06889808177948, acc: 0.6666666865348816)
[2025-01-30 02:09:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3135/107898 [17:03<10:00:07,  2.91it/s][2025-01-30 02:09:13][root][INFO] - Training Epoch: 1/2, step 3134/107898 completed (loss: 1.9069275856018066, acc: 0.6666666865348816)
[2025-01-30 02:09:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3136/107898 [17:03<10:03:03,  2.90it/s][2025-01-30 02:09:13][root][INFO] - Training Epoch: 1/2, step 3135/107898 completed (loss: 0.1298488974571228, acc: 1.0)
[2025-01-30 02:09:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3137/107898 [17:04<9:50:35,  2.96it/s] [2025-01-30 02:09:14][root][INFO] - Training Epoch: 1/2, step 3136/107898 completed (loss: 1.2241435050964355, acc: 0.5)
[2025-01-30 02:09:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3138/107898 [17:04<9:35:44,  3.03it/s][2025-01-30 02:09:14][root][INFO] - Training Epoch: 1/2, step 3137/107898 completed (loss: 0.9804578423500061, acc: 0.761904776096344)
[2025-01-30 02:09:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3139/107898 [17:04<9:20:47,  3.11it/s][2025-01-30 02:09:14][root][INFO] - Training Epoch: 1/2, step 3138/107898 completed (loss: 0.5113109350204468, acc: 0.9166666865348816)
[2025-01-30 02:09:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3140/107898 [17:05<8:49:07,  3.30it/s][2025-01-30 02:09:14][root][INFO] - Training Epoch: 1/2, step 3139/107898 completed (loss: 0.4979664385318756, acc: 1.0)
[2025-01-30 02:09:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3141/107898 [17:05<9:00:53,  3.23it/s][2025-01-30 02:09:15][root][INFO] - Training Epoch: 1/2, step 3140/107898 completed (loss: 2.064436197280884, acc: 0.6153846383094788)
[2025-01-30 02:09:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3142/107898 [17:05<8:51:43,  3.28it/s][2025-01-30 02:09:15][root][INFO] - Training Epoch: 1/2, step 3141/107898 completed (loss: 3.6653835773468018, acc: 0.3333333432674408)
[2025-01-30 02:09:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3143/107898 [17:06<8:52:09,  3.28it/s][2025-01-30 02:09:15][root][INFO] - Training Epoch: 1/2, step 3142/107898 completed (loss: 1.9964090585708618, acc: 0.6666666865348816)
[2025-01-30 02:09:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3144/107898 [17:06<9:09:06,  3.18it/s][2025-01-30 02:09:16][root][INFO] - Training Epoch: 1/2, step 3143/107898 completed (loss: 1.8955543041229248, acc: 0.5882353186607361)
[2025-01-30 02:09:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3145/107898 [17:06<9:05:19,  3.20it/s][2025-01-30 02:09:16][root][INFO] - Training Epoch: 1/2, step 3144/107898 completed (loss: 0.09936065226793289, acc: 1.0)
[2025-01-30 02:09:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3146/107898 [17:06<9:05:01,  3.20it/s][2025-01-30 02:09:16][root][INFO] - Training Epoch: 1/2, step 3145/107898 completed (loss: 0.11373481899499893, acc: 1.0)
[2025-01-30 02:09:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3147/107898 [17:07<9:30:48,  3.06it/s][2025-01-30 02:09:17][root][INFO] - Training Epoch: 1/2, step 3146/107898 completed (loss: 1.04239821434021, acc: 0.75)
[2025-01-30 02:09:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3148/107898 [17:07<9:44:50,  2.99it/s][2025-01-30 02:09:17][root][INFO] - Training Epoch: 1/2, step 3147/107898 completed (loss: 0.014358166605234146, acc: 1.0)
[2025-01-30 02:09:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3149/107898 [17:08<9:47:59,  2.97it/s][2025-01-30 02:09:17][root][INFO] - Training Epoch: 1/2, step 3148/107898 completed (loss: 1.024017095565796, acc: 0.6000000238418579)
[2025-01-30 02:09:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3150/107898 [17:08<9:32:17,  3.05it/s][2025-01-30 02:09:18][root][INFO] - Training Epoch: 1/2, step 3149/107898 completed (loss: 0.31472718715667725, acc: 1.0)
[2025-01-30 02:09:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3151/107898 [17:08<9:35:02,  3.04it/s][2025-01-30 02:09:18][root][INFO] - Training Epoch: 1/2, step 3150/107898 completed (loss: 2.5340332984924316, acc: 0.6842105388641357)
[2025-01-30 02:09:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3152/107898 [17:08<9:20:45,  3.11it/s][2025-01-30 02:09:18][root][INFO] - Training Epoch: 1/2, step 3151/107898 completed (loss: 2.304077386856079, acc: 0.75)
[2025-01-30 02:09:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3153/107898 [17:09<9:15:59,  3.14it/s][2025-01-30 02:09:19][root][INFO] - Training Epoch: 1/2, step 3152/107898 completed (loss: 0.04589683562517166, acc: 1.0)
[2025-01-30 02:09:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3154/107898 [17:09<9:28:51,  3.07it/s][2025-01-30 02:09:19][root][INFO] - Training Epoch: 1/2, step 3153/107898 completed (loss: 1.4793384075164795, acc: 0.739130437374115)
[2025-01-30 02:09:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3155/107898 [17:09<9:16:15,  3.14it/s][2025-01-30 02:09:19][root][INFO] - Training Epoch: 1/2, step 3154/107898 completed (loss: 0.2755885422229767, acc: 1.0)
[2025-01-30 02:09:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3156/107898 [17:10<9:14:09,  3.15it/s][2025-01-30 02:09:20][root][INFO] - Training Epoch: 1/2, step 3155/107898 completed (loss: 0.07412341237068176, acc: 1.0)
[2025-01-30 02:09:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3157/107898 [17:10<9:10:52,  3.17it/s][2025-01-30 02:09:20][root][INFO] - Training Epoch: 1/2, step 3156/107898 completed (loss: 0.5530045628547668, acc: 0.9354838728904724)
[2025-01-30 02:09:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3158/107898 [17:10<9:08:36,  3.18it/s][2025-01-30 02:09:20][root][INFO] - Training Epoch: 1/2, step 3157/107898 completed (loss: 0.6087532639503479, acc: 0.9090909361839294)
[2025-01-30 02:09:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3159/107898 [17:11<9:33:01,  3.05it/s][2025-01-30 02:09:21][root][INFO] - Training Epoch: 1/2, step 3158/107898 completed (loss: 0.5268150568008423, acc: 0.9285714030265808)
[2025-01-30 02:09:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3160/107898 [17:11<9:35:42,  3.03it/s][2025-01-30 02:09:21][root][INFO] - Training Epoch: 1/2, step 3159/107898 completed (loss: 0.09449423849582672, acc: 1.0)
[2025-01-30 02:09:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3161/107898 [17:11<9:28:18,  3.07it/s][2025-01-30 02:09:21][root][INFO] - Training Epoch: 1/2, step 3160/107898 completed (loss: 1.1599208116531372, acc: 0.75)
[2025-01-30 02:09:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3162/107898 [17:12<9:20:31,  3.11it/s][2025-01-30 02:09:21][root][INFO] - Training Epoch: 1/2, step 3161/107898 completed (loss: 3.083834648132324, acc: 0.31578946113586426)
[2025-01-30 02:09:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3163/107898 [17:12<9:17:35,  3.13it/s][2025-01-30 02:09:22][root][INFO] - Training Epoch: 1/2, step 3162/107898 completed (loss: 0.560314953327179, acc: 0.9032257795333862)
[2025-01-30 02:09:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3164/107898 [17:12<9:03:45,  3.21it/s][2025-01-30 02:09:22][root][INFO] - Training Epoch: 1/2, step 3163/107898 completed (loss: 1.223054051399231, acc: 0.75)
[2025-01-30 02:09:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3165/107898 [17:13<8:57:32,  3.25it/s][2025-01-30 02:09:22][root][INFO] - Training Epoch: 1/2, step 3164/107898 completed (loss: 1.4046577215194702, acc: 0.739130437374115)
[2025-01-30 02:09:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3166/107898 [17:13<8:49:22,  3.30it/s][2025-01-30 02:09:23][root][INFO] - Training Epoch: 1/2, step 3165/107898 completed (loss: 1.3034946918487549, acc: 0.6666666865348816)
[2025-01-30 02:09:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3167/107898 [17:13<9:19:47,  3.12it/s][2025-01-30 02:09:23][root][INFO] - Training Epoch: 1/2, step 3166/107898 completed (loss: 2.0427534580230713, acc: 0.6666666865348816)
[2025-01-30 02:09:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3168/107898 [17:14<9:31:41,  3.05it/s][2025-01-30 02:09:23][root][INFO] - Training Epoch: 1/2, step 3167/107898 completed (loss: 1.4304567575454712, acc: 0.7692307829856873)
[2025-01-30 02:09:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3169/107898 [17:14<9:49:22,  2.96it/s][2025-01-30 02:09:24][root][INFO] - Training Epoch: 1/2, step 3168/107898 completed (loss: 0.26842784881591797, acc: 1.0)
[2025-01-30 02:09:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3170/107898 [17:14<9:42:10,  3.00it/s][2025-01-30 02:09:24][root][INFO] - Training Epoch: 1/2, step 3169/107898 completed (loss: 1.0325312614440918, acc: 0.7777777910232544)
[2025-01-30 02:09:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3171/107898 [17:15<9:26:23,  3.08it/s][2025-01-30 02:09:24][root][INFO] - Training Epoch: 1/2, step 3170/107898 completed (loss: 2.6747941970825195, acc: 0.5)
[2025-01-30 02:09:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3172/107898 [17:15<9:23:11,  3.10it/s][2025-01-30 02:09:25][root][INFO] - Training Epoch: 1/2, step 3171/107898 completed (loss: 1.0269510746002197, acc: 0.800000011920929)
[2025-01-30 02:09:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3173/107898 [17:15<9:46:12,  2.98it/s][2025-01-30 02:09:25][root][INFO] - Training Epoch: 1/2, step 3172/107898 completed (loss: 1.3007686138153076, acc: 0.625)
[2025-01-30 02:09:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3174/107898 [17:16<10:22:22,  2.80it/s][2025-01-30 02:09:25][root][INFO] - Training Epoch: 1/2, step 3173/107898 completed (loss: 1.7554140090942383, acc: 0.6666666865348816)
[2025-01-30 02:09:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3175/107898 [17:16<9:56:47,  2.92it/s] [2025-01-30 02:09:26][root][INFO] - Training Epoch: 1/2, step 3174/107898 completed (loss: 1.10121750831604, acc: 0.7857142686843872)
[2025-01-30 02:09:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3176/107898 [17:16<9:49:11,  2.96it/s][2025-01-30 02:09:26][root][INFO] - Training Epoch: 1/2, step 3175/107898 completed (loss: 0.3430543839931488, acc: 0.9032257795333862)
[2025-01-30 02:09:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3177/107898 [17:17<9:59:35,  2.91it/s][2025-01-30 02:09:26][root][INFO] - Training Epoch: 1/2, step 3176/107898 completed (loss: 1.15199875831604, acc: 0.7777777910232544)
[2025-01-30 02:09:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3178/107898 [17:17<9:53:06,  2.94it/s][2025-01-30 02:09:27][root][INFO] - Training Epoch: 1/2, step 3177/107898 completed (loss: 1.6445354223251343, acc: 0.75)
[2025-01-30 02:09:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3179/107898 [17:17<10:01:09,  2.90it/s][2025-01-30 02:09:27][root][INFO] - Training Epoch: 1/2, step 3178/107898 completed (loss: 0.5809500217437744, acc: 0.8999999761581421)
[2025-01-30 02:09:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3180/107898 [17:18<9:59:34,  2.91it/s] [2025-01-30 02:09:27][root][INFO] - Training Epoch: 1/2, step 3179/107898 completed (loss: 1.8278602361679077, acc: 0.5)
[2025-01-30 02:09:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3181/107898 [17:18<9:56:14,  2.93it/s][2025-01-30 02:09:28][root][INFO] - Training Epoch: 1/2, step 3180/107898 completed (loss: 2.972320079803467, acc: 0.5)
[2025-01-30 02:09:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3182/107898 [17:18<9:25:31,  3.09it/s][2025-01-30 02:09:28][root][INFO] - Training Epoch: 1/2, step 3181/107898 completed (loss: 0.027946507558226585, acc: 1.0)
[2025-01-30 02:09:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3183/107898 [17:19<9:04:45,  3.20it/s][2025-01-30 02:09:28][root][INFO] - Training Epoch: 1/2, step 3182/107898 completed (loss: 4.105781078338623, acc: 0.5)
[2025-01-30 02:09:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3184/107898 [17:19<9:05:55,  3.20it/s][2025-01-30 02:09:29][root][INFO] - Training Epoch: 1/2, step 3183/107898 completed (loss: 0.6773574352264404, acc: 0.8181818127632141)
[2025-01-30 02:09:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3185/107898 [17:19<9:04:08,  3.21it/s][2025-01-30 02:09:29][root][INFO] - Training Epoch: 1/2, step 3184/107898 completed (loss: 2.6609346866607666, acc: 0.3333333432674408)
[2025-01-30 02:09:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3186/107898 [17:20<8:56:07,  3.26it/s][2025-01-30 02:09:29][root][INFO] - Training Epoch: 1/2, step 3185/107898 completed (loss: 1.4539066553115845, acc: 0.800000011920929)
[2025-01-30 02:09:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3187/107898 [17:20<8:53:19,  3.27it/s][2025-01-30 02:09:30][root][INFO] - Training Epoch: 1/2, step 3186/107898 completed (loss: 0.023684993386268616, acc: 1.0)
[2025-01-30 02:09:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3188/107898 [17:20<9:06:59,  3.19it/s][2025-01-30 02:09:30][root][INFO] - Training Epoch: 1/2, step 3187/107898 completed (loss: 1.766513466835022, acc: 0.7777777910232544)
[2025-01-30 02:09:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3189/107898 [17:21<9:30:05,  3.06it/s][2025-01-30 02:09:30][root][INFO] - Training Epoch: 1/2, step 3188/107898 completed (loss: 3.167649507522583, acc: 0.3125)
[2025-01-30 02:09:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3190/107898 [17:21<9:45:51,  2.98it/s][2025-01-30 02:09:31][root][INFO] - Training Epoch: 1/2, step 3189/107898 completed (loss: 1.4496843814849854, acc: 0.8095238208770752)
[2025-01-30 02:09:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3191/107898 [17:21<9:35:03,  3.03it/s][2025-01-30 02:09:31][root][INFO] - Training Epoch: 1/2, step 3190/107898 completed (loss: 0.1883377730846405, acc: 1.0)
[2025-01-30 02:09:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3192/107898 [17:21<9:21:29,  3.11it/s][2025-01-30 02:09:31][root][INFO] - Training Epoch: 1/2, step 3191/107898 completed (loss: 0.7374283075332642, acc: 0.5)
[2025-01-30 02:09:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3193/107898 [17:22<9:12:44,  3.16it/s][2025-01-30 02:09:32][root][INFO] - Training Epoch: 1/2, step 3192/107898 completed (loss: 0.45089998841285706, acc: 0.8333333134651184)
[2025-01-30 02:09:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3194/107898 [17:22<9:25:08,  3.09it/s][2025-01-30 02:09:32][root][INFO] - Training Epoch: 1/2, step 3193/107898 completed (loss: 0.5097553730010986, acc: 0.875)
[2025-01-30 02:09:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3195/107898 [17:22<9:18:04,  3.13it/s][2025-01-30 02:09:32][root][INFO] - Training Epoch: 1/2, step 3194/107898 completed (loss: 0.45770832896232605, acc: 0.8333333134651184)
[2025-01-30 02:09:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3196/107898 [17:23<8:53:27,  3.27it/s][2025-01-30 02:09:33][root][INFO] - Training Epoch: 1/2, step 3195/107898 completed (loss: 1.0475784540176392, acc: 0.8571428656578064)
[2025-01-30 02:09:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3197/107898 [17:23<8:52:36,  3.28it/s][2025-01-30 02:09:33][root][INFO] - Training Epoch: 1/2, step 3196/107898 completed (loss: 0.011954506859183311, acc: 1.0)
[2025-01-30 02:09:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3198/107898 [17:23<8:51:54,  3.28it/s][2025-01-30 02:09:33][root][INFO] - Training Epoch: 1/2, step 3197/107898 completed (loss: 0.14244617521762848, acc: 1.0)
[2025-01-30 02:09:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3199/107898 [17:24<8:54:31,  3.26it/s][2025-01-30 02:09:33][root][INFO] - Training Epoch: 1/2, step 3198/107898 completed (loss: 2.4070000648498535, acc: 0.5454545617103577)
[2025-01-30 02:09:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3200/107898 [17:24<8:58:28,  3.24it/s][2025-01-30 02:09:34][root][INFO] - Training Epoch: 1/2, step 3199/107898 completed (loss: 0.009598109871149063, acc: 1.0)
[2025-01-30 02:09:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3201/107898 [17:24<8:58:30,  3.24it/s][2025-01-30 02:09:34][root][INFO] - Training Epoch: 1/2, step 3200/107898 completed (loss: 1.238882303237915, acc: 0.7777777910232544)
[2025-01-30 02:09:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3202/107898 [17:25<9:06:30,  3.19it/s][2025-01-30 02:09:34][root][INFO] - Training Epoch: 1/2, step 3201/107898 completed (loss: 1.215738296508789, acc: 0.7142857313156128)
[2025-01-30 02:09:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3203/107898 [17:25<9:41:46,  3.00it/s][2025-01-30 02:09:35][root][INFO] - Training Epoch: 1/2, step 3202/107898 completed (loss: 1.6977547407150269, acc: 0.6739130616188049)
[2025-01-30 02:09:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3204/107898 [17:25<9:52:45,  2.94it/s][2025-01-30 02:09:35][root][INFO] - Training Epoch: 1/2, step 3203/107898 completed (loss: 0.01651420071721077, acc: 1.0)
[2025-01-30 02:09:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3205/107898 [17:26<9:42:47,  2.99it/s][2025-01-30 02:09:35][root][INFO] - Training Epoch: 1/2, step 3204/107898 completed (loss: 0.04839755967259407, acc: 1.0)
[2025-01-30 02:09:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3206/107898 [17:26<9:33:01,  3.05it/s][2025-01-30 02:09:36][root][INFO] - Training Epoch: 1/2, step 3205/107898 completed (loss: 0.4622654914855957, acc: 1.0)
[2025-01-30 02:09:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3207/107898 [17:26<9:46:35,  2.97it/s][2025-01-30 02:09:36][root][INFO] - Training Epoch: 1/2, step 3206/107898 completed (loss: 2.3200018405914307, acc: 0.5)
[2025-01-30 02:09:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3208/107898 [17:27<9:24:26,  3.09it/s][2025-01-30 02:09:36][root][INFO] - Training Epoch: 1/2, step 3207/107898 completed (loss: 0.011234299279749393, acc: 1.0)
[2025-01-30 02:09:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3209/107898 [17:27<9:10:06,  3.17it/s][2025-01-30 02:09:37][root][INFO] - Training Epoch: 1/2, step 3208/107898 completed (loss: 1.464393138885498, acc: 0.6666666865348816)
[2025-01-30 02:09:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3210/107898 [17:27<9:17:43,  3.13it/s][2025-01-30 02:09:37][root][INFO] - Training Epoch: 1/2, step 3209/107898 completed (loss: 4.2981085777282715, acc: 0.3333333432674408)
[2025-01-30 02:09:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3211/107898 [17:28<9:24:11,  3.09it/s][2025-01-30 02:09:37][root][INFO] - Training Epoch: 1/2, step 3210/107898 completed (loss: 0.007098184898495674, acc: 1.0)
[2025-01-30 02:09:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3212/107898 [17:28<9:30:59,  3.06it/s][2025-01-30 02:09:38][root][INFO] - Training Epoch: 1/2, step 3211/107898 completed (loss: 0.40443065762519836, acc: 0.8571428656578064)
[2025-01-30 02:09:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3213/107898 [17:28<9:47:08,  2.97it/s][2025-01-30 02:09:38][root][INFO] - Training Epoch: 1/2, step 3212/107898 completed (loss: 0.9390265941619873, acc: 0.5)
[2025-01-30 02:09:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3214/107898 [17:29<9:53:39,  2.94it/s][2025-01-30 02:09:38][root][INFO] - Training Epoch: 1/2, step 3213/107898 completed (loss: 3.137683153152466, acc: 0.5)
[2025-01-30 02:09:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3215/107898 [17:29<9:52:58,  2.94it/s][2025-01-30 02:09:39][root][INFO] - Training Epoch: 1/2, step 3214/107898 completed (loss: 1.7145541906356812, acc: 0.800000011920929)
[2025-01-30 02:09:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3216/107898 [17:29<9:43:18,  2.99it/s][2025-01-30 02:09:39][root][INFO] - Training Epoch: 1/2, step 3215/107898 completed (loss: 1.01028311252594, acc: 0.800000011920929)
[2025-01-30 02:09:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3217/107898 [17:30<9:27:08,  3.08it/s][2025-01-30 02:09:39][root][INFO] - Training Epoch: 1/2, step 3216/107898 completed (loss: 1.3766165971755981, acc: 0.800000011920929)
[2025-01-30 02:09:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3218/107898 [17:30<9:12:47,  3.16it/s][2025-01-30 02:09:40][root][INFO] - Training Epoch: 1/2, step 3217/107898 completed (loss: 1.6462886333465576, acc: 0.5555555820465088)
[2025-01-30 02:09:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3219/107898 [17:30<9:04:03,  3.21it/s][2025-01-30 02:09:40][root][INFO] - Training Epoch: 1/2, step 3218/107898 completed (loss: 0.47016027569770813, acc: 0.9090909361839294)
[2025-01-30 02:09:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3220/107898 [17:31<9:22:55,  3.10it/s][2025-01-30 02:09:40][root][INFO] - Training Epoch: 1/2, step 3219/107898 completed (loss: 0.2979050278663635, acc: 1.0)
[2025-01-30 02:09:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3221/107898 [17:31<9:21:49,  3.11it/s][2025-01-30 02:09:41][root][INFO] - Training Epoch: 1/2, step 3220/107898 completed (loss: 0.06997529417276382, acc: 1.0)
[2025-01-30 02:09:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3222/107898 [17:31<9:38:09,  3.02it/s][2025-01-30 02:09:41][root][INFO] - Training Epoch: 1/2, step 3221/107898 completed (loss: 2.7813503742218018, acc: 0.3199999928474426)
[2025-01-30 02:09:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3223/107898 [17:32<9:51:45,  2.95it/s][2025-01-30 02:09:41][root][INFO] - Training Epoch: 1/2, step 3222/107898 completed (loss: 0.019459035247564316, acc: 1.0)
[2025-01-30 02:09:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3224/107898 [17:32<9:52:25,  2.94it/s][2025-01-30 02:09:42][root][INFO] - Training Epoch: 1/2, step 3223/107898 completed (loss: 3.5212936401367188, acc: 0.6000000238418579)
[2025-01-30 02:09:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3225/107898 [17:32<9:51:38,  2.95it/s][2025-01-30 02:09:42][root][INFO] - Training Epoch: 1/2, step 3224/107898 completed (loss: 3.4422640800476074, acc: 0.5)
[2025-01-30 02:09:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3226/107898 [17:33<9:49:47,  2.96it/s][2025-01-30 02:09:42][root][INFO] - Training Epoch: 1/2, step 3225/107898 completed (loss: 1.707614779472351, acc: 0.7692307829856873)
[2025-01-30 02:09:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3227/107898 [17:33<9:36:51,  3.02it/s][2025-01-30 02:09:43][root][INFO] - Training Epoch: 1/2, step 3226/107898 completed (loss: 1.3474427461624146, acc: 0.7777777910232544)
[2025-01-30 02:09:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3228/107898 [17:33<9:52:52,  2.94it/s][2025-01-30 02:09:43][root][INFO] - Training Epoch: 1/2, step 3227/107898 completed (loss: 0.9752988219261169, acc: 0.7272727489471436)
[2025-01-30 02:09:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3229/107898 [17:34<10:02:09,  2.90it/s][2025-01-30 02:09:43][root][INFO] - Training Epoch: 1/2, step 3228/107898 completed (loss: 0.7229158878326416, acc: 0.8275862336158752)
[2025-01-30 02:09:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3230/107898 [17:34<9:58:23,  2.92it/s] [2025-01-30 02:09:44][root][INFO] - Training Epoch: 1/2, step 3229/107898 completed (loss: 0.2072407752275467, acc: 1.0)
[2025-01-30 02:09:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3231/107898 [17:34<9:44:15,  2.99it/s][2025-01-30 02:09:44][root][INFO] - Training Epoch: 1/2, step 3230/107898 completed (loss: 0.9718510508537292, acc: 0.7692307829856873)
[2025-01-30 02:09:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3232/107898 [17:35<9:44:21,  2.99it/s][2025-01-30 02:09:44][root][INFO] - Training Epoch: 1/2, step 3231/107898 completed (loss: 2.3629143238067627, acc: 0.5)
[2025-01-30 02:09:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3233/107898 [17:35<9:35:31,  3.03it/s][2025-01-30 02:09:45][root][INFO] - Training Epoch: 1/2, step 3232/107898 completed (loss: 0.142828568816185, acc: 1.0)
[2025-01-30 02:09:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3234/107898 [17:35<9:46:27,  2.97it/s][2025-01-30 02:09:45][root][INFO] - Training Epoch: 1/2, step 3233/107898 completed (loss: 5.34309720993042, acc: 0.25)
[2025-01-30 02:09:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3235/107898 [17:36<9:46:45,  2.97it/s][2025-01-30 02:09:45][root][INFO] - Training Epoch: 1/2, step 3234/107898 completed (loss: 1.8689591884613037, acc: 0.6521739363670349)
[2025-01-30 02:09:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3236/107898 [17:36<9:40:08,  3.01it/s][2025-01-30 02:09:46][root][INFO] - Training Epoch: 1/2, step 3235/107898 completed (loss: 5.233734130859375, acc: 0.0)
[2025-01-30 02:09:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3237/107898 [17:36<9:42:42,  2.99it/s][2025-01-30 02:09:46][root][INFO] - Training Epoch: 1/2, step 3236/107898 completed (loss: 0.5071167349815369, acc: 1.0)
[2025-01-30 02:09:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3238/107898 [17:37<9:43:35,  2.99it/s][2025-01-30 02:09:46][root][INFO] - Training Epoch: 1/2, step 3237/107898 completed (loss: 1.342195749282837, acc: 0.75)
[2025-01-30 02:09:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3239/107898 [17:37<9:34:46,  3.03it/s][2025-01-30 02:09:47][root][INFO] - Training Epoch: 1/2, step 3238/107898 completed (loss: 1.5218247175216675, acc: 0.6666666865348816)
[2025-01-30 02:09:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3240/107898 [17:37<9:25:39,  3.08it/s][2025-01-30 02:09:47][root][INFO] - Training Epoch: 1/2, step 3239/107898 completed (loss: 1.1618850231170654, acc: 0.7307692170143127)
[2025-01-30 02:09:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3241/107898 [17:38<9:09:08,  3.18it/s][2025-01-30 02:09:47][root][INFO] - Training Epoch: 1/2, step 3240/107898 completed (loss: 0.014350605197250843, acc: 1.0)
[2025-01-30 02:09:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3242/107898 [17:38<9:06:27,  3.19it/s][2025-01-30 02:09:48][root][INFO] - Training Epoch: 1/2, step 3241/107898 completed (loss: 0.3647342920303345, acc: 1.0)
[2025-01-30 02:09:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3243/107898 [17:38<9:16:10,  3.14it/s][2025-01-30 02:09:48][root][INFO] - Training Epoch: 1/2, step 3242/107898 completed (loss: 1.3544981479644775, acc: 0.5)
[2025-01-30 02:09:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3244/107898 [17:38<9:13:21,  3.15it/s][2025-01-30 02:09:48][root][INFO] - Training Epoch: 1/2, step 3243/107898 completed (loss: 0.40078920125961304, acc: 0.9523809552192688)
[2025-01-30 02:09:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3245/107898 [17:39<9:06:41,  3.19it/s][2025-01-30 02:09:49][root][INFO] - Training Epoch: 1/2, step 3244/107898 completed (loss: 1.3539494276046753, acc: 0.7647058963775635)
[2025-01-30 02:09:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3246/107898 [17:39<9:04:13,  3.20it/s][2025-01-30 02:09:49][root][INFO] - Training Epoch: 1/2, step 3245/107898 completed (loss: 3.9530580043792725, acc: 0.2857142984867096)
[2025-01-30 02:09:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3247/107898 [17:39<9:22:58,  3.10it/s][2025-01-30 02:09:49][root][INFO] - Training Epoch: 1/2, step 3246/107898 completed (loss: 0.2701230049133301, acc: 1.0)
[2025-01-30 02:09:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3248/107898 [17:40<9:48:40,  2.96it/s][2025-01-30 02:09:50][root][INFO] - Training Epoch: 1/2, step 3247/107898 completed (loss: 1.3184629678726196, acc: 0.7727272510528564)
[2025-01-30 02:09:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3249/107898 [17:40<9:42:48,  2.99it/s][2025-01-30 02:09:50][root][INFO] - Training Epoch: 1/2, step 3248/107898 completed (loss: 0.5103307366371155, acc: 0.8823529481887817)
[2025-01-30 02:09:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3250/107898 [17:40<9:37:25,  3.02it/s][2025-01-30 02:09:50][root][INFO] - Training Epoch: 1/2, step 3249/107898 completed (loss: 0.9212525486946106, acc: 0.8333333134651184)
[2025-01-30 02:09:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3251/107898 [17:41<9:26:41,  3.08it/s][2025-01-30 02:09:51][root][INFO] - Training Epoch: 1/2, step 3250/107898 completed (loss: 0.06445682048797607, acc: 1.0)
[2025-01-30 02:09:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3252/107898 [17:41<8:57:11,  3.25it/s][2025-01-30 02:09:51][root][INFO] - Training Epoch: 1/2, step 3251/107898 completed (loss: 0.5393209457397461, acc: 0.75)
[2025-01-30 02:09:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3253/107898 [17:41<8:46:12,  3.31it/s][2025-01-30 02:09:51][root][INFO] - Training Epoch: 1/2, step 3252/107898 completed (loss: 2.019232988357544, acc: 0.625)
[2025-01-30 02:09:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3254/107898 [17:42<8:48:34,  3.30it/s][2025-01-30 02:09:51][root][INFO] - Training Epoch: 1/2, step 3253/107898 completed (loss: 1.6265474557876587, acc: 0.3333333432674408)
[2025-01-30 02:09:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3255/107898 [17:42<8:50:28,  3.29it/s][2025-01-30 02:09:52][root][INFO] - Training Epoch: 1/2, step 3254/107898 completed (loss: 0.005833061411976814, acc: 1.0)
[2025-01-30 02:09:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3256/107898 [17:42<9:12:05,  3.16it/s][2025-01-30 02:09:52][root][INFO] - Training Epoch: 1/2, step 3255/107898 completed (loss: 1.4726656675338745, acc: 0.7142857313156128)
[2025-01-30 02:09:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3257/107898 [17:43<9:24:32,  3.09it/s][2025-01-30 02:09:52][root][INFO] - Training Epoch: 1/2, step 3256/107898 completed (loss: 1.1956027746200562, acc: 0.8181818127632141)
[2025-01-30 02:09:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3258/107898 [17:43<9:37:28,  3.02it/s][2025-01-30 02:09:53][root][INFO] - Training Epoch: 1/2, step 3257/107898 completed (loss: 3.2464160919189453, acc: 0.30000001192092896)
[2025-01-30 02:09:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3259/107898 [17:43<9:37:58,  3.02it/s][2025-01-30 02:09:53][root][INFO] - Training Epoch: 1/2, step 3258/107898 completed (loss: 0.748230516910553, acc: 0.8571428656578064)
[2025-01-30 02:09:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3260/107898 [17:44<9:20:03,  3.11it/s][2025-01-30 02:09:53][root][INFO] - Training Epoch: 1/2, step 3259/107898 completed (loss: 1.4205870628356934, acc: 0.75)
[2025-01-30 02:09:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3261/107898 [17:44<9:21:39,  3.11it/s][2025-01-30 02:09:54][root][INFO] - Training Epoch: 1/2, step 3260/107898 completed (loss: 2.4403798580169678, acc: 0.5384615659713745)
[2025-01-30 02:09:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3262/107898 [17:44<9:05:52,  3.19it/s][2025-01-30 02:09:54][root][INFO] - Training Epoch: 1/2, step 3261/107898 completed (loss: 1.0824288129806519, acc: 0.5714285969734192)
[2025-01-30 02:09:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3263/107898 [17:45<9:14:58,  3.14it/s][2025-01-30 02:09:54][root][INFO] - Training Epoch: 1/2, step 3262/107898 completed (loss: 1.0850672721862793, acc: 0.7692307829856873)
[2025-01-30 02:09:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3264/107898 [17:45<9:10:30,  3.17it/s][2025-01-30 02:09:55][root][INFO] - Training Epoch: 1/2, step 3263/107898 completed (loss: 0.9043607115745544, acc: 0.8333333134651184)
[2025-01-30 02:09:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3265/107898 [17:45<9:17:51,  3.13it/s][2025-01-30 02:09:55][root][INFO] - Training Epoch: 1/2, step 3264/107898 completed (loss: 3.8851840496063232, acc: 0.3333333432674408)
[2025-01-30 02:09:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3266/107898 [17:46<9:36:22,  3.03it/s][2025-01-30 02:09:55][root][INFO] - Training Epoch: 1/2, step 3265/107898 completed (loss: 5.395557880401611, acc: 0.1666666716337204)
[2025-01-30 02:09:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3267/107898 [17:46<9:37:22,  3.02it/s][2025-01-30 02:09:56][root][INFO] - Training Epoch: 1/2, step 3266/107898 completed (loss: 2.6524429321289062, acc: 0.25)
[2025-01-30 02:09:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3268/107898 [17:46<9:26:45,  3.08it/s][2025-01-30 02:09:56][root][INFO] - Training Epoch: 1/2, step 3267/107898 completed (loss: 0.25801485776901245, acc: 1.0)
[2025-01-30 02:09:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3269/107898 [17:46<9:28:23,  3.07it/s][2025-01-30 02:09:56][root][INFO] - Training Epoch: 1/2, step 3268/107898 completed (loss: 0.6959468722343445, acc: 0.8888888955116272)
[2025-01-30 02:09:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3270/107898 [17:47<9:22:41,  3.10it/s][2025-01-30 02:09:57][root][INFO] - Training Epoch: 1/2, step 3269/107898 completed (loss: 0.11917203664779663, acc: 1.0)
[2025-01-30 02:09:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3271/107898 [17:47<9:29:28,  3.06it/s][2025-01-30 02:09:57][root][INFO] - Training Epoch: 1/2, step 3270/107898 completed (loss: 0.005846225656569004, acc: 1.0)
[2025-01-30 02:09:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3272/107898 [17:47<9:21:57,  3.10it/s][2025-01-30 02:09:57][root][INFO] - Training Epoch: 1/2, step 3271/107898 completed (loss: 1.4149020910263062, acc: 0.0)
[2025-01-30 02:09:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3273/107898 [17:48<9:24:12,  3.09it/s][2025-01-30 02:09:58][root][INFO] - Training Epoch: 1/2, step 3272/107898 completed (loss: 0.5760692954063416, acc: 0.8709677457809448)
[2025-01-30 02:09:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3274/107898 [17:48<9:24:18,  3.09it/s][2025-01-30 02:09:58][root][INFO] - Training Epoch: 1/2, step 3273/107898 completed (loss: 0.6919203400611877, acc: 0.8571428656578064)
[2025-01-30 02:09:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3275/107898 [17:48<9:13:21,  3.15it/s][2025-01-30 02:09:58][root][INFO] - Training Epoch: 1/2, step 3274/107898 completed (loss: 0.018907679244875908, acc: 1.0)
[2025-01-30 02:09:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3276/107898 [17:49<9:13:00,  3.15it/s][2025-01-30 02:09:59][root][INFO] - Training Epoch: 1/2, step 3275/107898 completed (loss: 2.6817119121551514, acc: 0.47058823704719543)
[2025-01-30 02:09:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3277/107898 [17:49<9:12:26,  3.16it/s][2025-01-30 02:09:59][root][INFO] - Training Epoch: 1/2, step 3276/107898 completed (loss: 0.3423331677913666, acc: 0.875)
[2025-01-30 02:09:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3278/107898 [17:49<9:09:33,  3.17it/s][2025-01-30 02:09:59][root][INFO] - Training Epoch: 1/2, step 3277/107898 completed (loss: 0.5957251787185669, acc: 0.8571428656578064)
[2025-01-30 02:09:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3279/107898 [17:50<9:04:41,  3.20it/s][2025-01-30 02:09:59][root][INFO] - Training Epoch: 1/2, step 3278/107898 completed (loss: 2.722161293029785, acc: 0.375)
[2025-01-30 02:10:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3280/107898 [17:50<9:26:30,  3.08it/s][2025-01-30 02:10:00][root][INFO] - Training Epoch: 1/2, step 3279/107898 completed (loss: 0.01617036573588848, acc: 1.0)
[2025-01-30 02:10:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3281/107898 [17:50<9:23:55,  3.09it/s][2025-01-30 02:10:00][root][INFO] - Training Epoch: 1/2, step 3280/107898 completed (loss: 0.0685698464512825, acc: 1.0)
[2025-01-30 02:10:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3282/107898 [17:51<9:23:45,  3.09it/s][2025-01-30 02:10:00][root][INFO] - Training Epoch: 1/2, step 3281/107898 completed (loss: 0.12060901522636414, acc: 1.0)
[2025-01-30 02:10:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3283/107898 [17:51<9:09:59,  3.17it/s][2025-01-30 02:10:01][root][INFO] - Training Epoch: 1/2, step 3282/107898 completed (loss: 0.8190582394599915, acc: 0.8636363744735718)
[2025-01-30 02:10:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3284/107898 [17:51<9:09:23,  3.17it/s][2025-01-30 02:10:01][root][INFO] - Training Epoch: 1/2, step 3283/107898 completed (loss: 1.1602379083633423, acc: 0.7857142686843872)
[2025-01-30 02:10:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3285/107898 [17:52<8:43:43,  3.33it/s][2025-01-30 02:10:01][root][INFO] - Training Epoch: 1/2, step 3284/107898 completed (loss: 1.1054394245147705, acc: 0.7647058963775635)
[2025-01-30 02:10:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3286/107898 [17:52<9:08:05,  3.18it/s][2025-01-30 02:10:02][root][INFO] - Training Epoch: 1/2, step 3285/107898 completed (loss: 1.6421843767166138, acc: 0.8333333134651184)
[2025-01-30 02:10:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3287/107898 [17:52<9:34:13,  3.04it/s][2025-01-30 02:10:02][root][INFO] - Training Epoch: 1/2, step 3286/107898 completed (loss: 0.4243801236152649, acc: 0.8571428656578064)
[2025-01-30 02:10:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3288/107898 [17:53<9:26:24,  3.08it/s][2025-01-30 02:10:02][root][INFO] - Training Epoch: 1/2, step 3287/107898 completed (loss: 0.5873443484306335, acc: 0.8571428656578064)
[2025-01-30 02:10:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3289/107898 [17:53<9:28:10,  3.07it/s][2025-01-30 02:10:03][root][INFO] - Training Epoch: 1/2, step 3288/107898 completed (loss: 0.03720622882246971, acc: 1.0)
[2025-01-30 02:10:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3290/107898 [17:53<9:37:52,  3.02it/s][2025-01-30 02:10:03][root][INFO] - Training Epoch: 1/2, step 3289/107898 completed (loss: 1.6306779384613037, acc: 0.625)
[2025-01-30 02:10:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3291/107898 [17:54<9:37:58,  3.02it/s][2025-01-30 02:10:03][root][INFO] - Training Epoch: 1/2, step 3290/107898 completed (loss: 0.03322626277804375, acc: 1.0)
[2025-01-30 02:10:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3292/107898 [17:54<9:51:09,  2.95it/s][2025-01-30 02:10:04][root][INFO] - Training Epoch: 1/2, step 3291/107898 completed (loss: 1.0441049337387085, acc: 0.804347813129425)
[2025-01-30 02:10:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3293/107898 [17:54<9:41:44,  3.00it/s][2025-01-30 02:10:04][root][INFO] - Training Epoch: 1/2, step 3292/107898 completed (loss: 1.9500480890274048, acc: 0.6470588445663452)
[2025-01-30 02:10:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3294/107898 [17:55<9:42:38,  2.99it/s][2025-01-30 02:10:04][root][INFO] - Training Epoch: 1/2, step 3293/107898 completed (loss: 1.6292434930801392, acc: 0.7586206793785095)
[2025-01-30 02:10:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3295/107898 [17:55<9:20:33,  3.11it/s][2025-01-30 02:10:05][root][INFO] - Training Epoch: 1/2, step 3294/107898 completed (loss: 0.3670009672641754, acc: 0.8571428656578064)
[2025-01-30 02:10:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3296/107898 [17:55<9:36:03,  3.03it/s][2025-01-30 02:10:05][root][INFO] - Training Epoch: 1/2, step 3295/107898 completed (loss: 0.33266785740852356, acc: 0.8571428656578064)
[2025-01-30 02:10:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3297/107898 [17:56<9:55:53,  2.93it/s][2025-01-30 02:10:05][root][INFO] - Training Epoch: 1/2, step 3296/107898 completed (loss: 3.970369577407837, acc: 0.3636363744735718)
[2025-01-30 02:10:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3298/107898 [17:56<9:46:54,  2.97it/s][2025-01-30 02:10:06][root][INFO] - Training Epoch: 1/2, step 3297/107898 completed (loss: 2.4343841075897217, acc: 0.5555555820465088)
[2025-01-30 02:10:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3299/107898 [17:56<9:34:51,  3.03it/s][2025-01-30 02:10:06][root][INFO] - Training Epoch: 1/2, step 3298/107898 completed (loss: 2.0912060737609863, acc: 0.800000011920929)
[2025-01-30 02:10:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3300/107898 [17:57<9:42:59,  2.99it/s][2025-01-30 02:10:06][root][INFO] - Training Epoch: 1/2, step 3299/107898 completed (loss: 1.1496739387512207, acc: 0.761904776096344)
[2025-01-30 02:10:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3301/107898 [17:57<9:30:30,  3.06it/s][2025-01-30 02:10:07][root][INFO] - Training Epoch: 1/2, step 3300/107898 completed (loss: 0.003240009769797325, acc: 1.0)
[2025-01-30 02:10:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3302/107898 [17:57<9:22:44,  3.10it/s][2025-01-30 02:10:07][root][INFO] - Training Epoch: 1/2, step 3301/107898 completed (loss: 0.16308069229125977, acc: 1.0)
[2025-01-30 02:10:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3303/107898 [17:58<9:17:53,  3.12it/s][2025-01-30 02:10:07][root][INFO] - Training Epoch: 1/2, step 3302/107898 completed (loss: 3.6992733478546143, acc: 0.375)
[2025-01-30 02:10:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3304/107898 [17:58<9:22:46,  3.10it/s][2025-01-30 02:10:08][root][INFO] - Training Epoch: 1/2, step 3303/107898 completed (loss: 1.7022136449813843, acc: 0.6315789222717285)
[2025-01-30 02:10:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3305/107898 [17:58<9:28:56,  3.06it/s][2025-01-30 02:10:08][root][INFO] - Training Epoch: 1/2, step 3304/107898 completed (loss: 6.1697587966918945, acc: 0.20000000298023224)
[2025-01-30 02:10:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3306/107898 [17:59<9:41:37,  3.00it/s][2025-01-30 02:10:08][root][INFO] - Training Epoch: 1/2, step 3305/107898 completed (loss: 0.013795224018394947, acc: 1.0)
[2025-01-30 02:10:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3307/107898 [17:59<9:34:21,  3.04it/s][2025-01-30 02:10:09][root][INFO] - Training Epoch: 1/2, step 3306/107898 completed (loss: 2.6090664863586426, acc: 0.6666666865348816)
[2025-01-30 02:10:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3308/107898 [17:59<9:38:56,  3.01it/s][2025-01-30 02:10:09][root][INFO] - Training Epoch: 1/2, step 3307/107898 completed (loss: 3.281010389328003, acc: 0.5555555820465088)
[2025-01-30 02:10:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3309/107898 [17:59<9:08:25,  3.18it/s][2025-01-30 02:10:09][root][INFO] - Training Epoch: 1/2, step 3308/107898 completed (loss: 1.8313884735107422, acc: 0.6111111044883728)
[2025-01-30 02:10:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3310/107898 [18:00<9:06:23,  3.19it/s][2025-01-30 02:10:10][root][INFO] - Training Epoch: 1/2, step 3309/107898 completed (loss: 1.7956510782241821, acc: 0.5789473652839661)
[2025-01-30 02:10:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3311/107898 [18:00<8:55:41,  3.25it/s][2025-01-30 02:10:10][root][INFO] - Training Epoch: 1/2, step 3310/107898 completed (loss: 2.2860066890716553, acc: 0.5)
[2025-01-30 02:10:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3312/107898 [18:00<8:52:15,  3.27it/s][2025-01-30 02:10:10][root][INFO] - Training Epoch: 1/2, step 3311/107898 completed (loss: 0.6477329134941101, acc: 0.8695651888847351)
[2025-01-30 02:10:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3313/107898 [18:01<9:04:36,  3.20it/s][2025-01-30 02:10:10][root][INFO] - Training Epoch: 1/2, step 3312/107898 completed (loss: 3.4154462814331055, acc: 0.5)
[2025-01-30 02:10:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3314/107898 [18:01<9:11:38,  3.16it/s][2025-01-30 02:10:11][root][INFO] - Training Epoch: 1/2, step 3313/107898 completed (loss: 0.6485698819160461, acc: 0.8620689511299133)
[2025-01-30 02:10:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3315/107898 [18:01<9:29:11,  3.06it/s][2025-01-30 02:10:11][root][INFO] - Training Epoch: 1/2, step 3314/107898 completed (loss: 0.018095407634973526, acc: 1.0)
[2025-01-30 02:10:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3316/107898 [18:02<9:43:14,  2.99it/s][2025-01-30 02:10:12][root][INFO] - Training Epoch: 1/2, step 3315/107898 completed (loss: 0.22373338043689728, acc: 1.0)
[2025-01-30 02:10:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3317/107898 [18:02<9:43:26,  2.99it/s][2025-01-30 02:10:12][root][INFO] - Training Epoch: 1/2, step 3316/107898 completed (loss: 3.9316506385803223, acc: 0.19230769574642181)
[2025-01-30 02:10:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3318/107898 [18:02<9:35:03,  3.03it/s][2025-01-30 02:10:12][root][INFO] - Training Epoch: 1/2, step 3317/107898 completed (loss: 0.3837968707084656, acc: 0.95652174949646)
[2025-01-30 02:10:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3319/107898 [18:03<9:15:19,  3.14it/s][2025-01-30 02:10:12][root][INFO] - Training Epoch: 1/2, step 3318/107898 completed (loss: 0.4836733341217041, acc: 1.0)
[2025-01-30 02:10:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3320/107898 [18:03<9:35:05,  3.03it/s][2025-01-30 02:10:13][root][INFO] - Training Epoch: 1/2, step 3319/107898 completed (loss: 1.1659029722213745, acc: 0.6666666865348816)
[2025-01-30 02:10:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3321/107898 [18:03<9:38:52,  3.01it/s][2025-01-30 02:10:13][root][INFO] - Training Epoch: 1/2, step 3320/107898 completed (loss: 0.8363096117973328, acc: 0.8181818127632141)
[2025-01-30 02:10:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3322/107898 [18:04<9:09:11,  3.17it/s][2025-01-30 02:10:13][root][INFO] - Training Epoch: 1/2, step 3321/107898 completed (loss: 1.3211758136749268, acc: 0.5)
[2025-01-30 02:10:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3323/107898 [18:04<9:03:59,  3.20it/s][2025-01-30 02:10:14][root][INFO] - Training Epoch: 1/2, step 3322/107898 completed (loss: 3.5427818298339844, acc: 0.3529411852359772)
[2025-01-30 02:10:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3324/107898 [18:04<9:01:50,  3.22it/s][2025-01-30 02:10:14][root][INFO] - Training Epoch: 1/2, step 3323/107898 completed (loss: 3.8979971408843994, acc: 0.5)
[2025-01-30 02:10:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3325/107898 [18:05<8:48:50,  3.30it/s][2025-01-30 02:10:14][root][INFO] - Training Epoch: 1/2, step 3324/107898 completed (loss: 0.562685489654541, acc: 0.9285714030265808)
[2025-01-30 02:10:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3326/107898 [18:05<8:50:33,  3.28it/s][2025-01-30 02:10:15][root][INFO] - Training Epoch: 1/2, step 3325/107898 completed (loss: 1.1141637563705444, acc: 0.625)
[2025-01-30 02:10:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3327/107898 [18:05<8:58:26,  3.24it/s][2025-01-30 02:10:15][root][INFO] - Training Epoch: 1/2, step 3326/107898 completed (loss: 1.1359949111938477, acc: 0.7777777910232544)
[2025-01-30 02:10:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3328/107898 [18:06<9:26:09,  3.08it/s][2025-01-30 02:10:15][root][INFO] - Training Epoch: 1/2, step 3327/107898 completed (loss: 1.2843947410583496, acc: 0.7647058963775635)
[2025-01-30 02:10:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3329/107898 [18:06<9:47:11,  2.97it/s][2025-01-30 02:10:16][root][INFO] - Training Epoch: 1/2, step 3328/107898 completed (loss: 3.3519716262817383, acc: 0.4000000059604645)
[2025-01-30 02:10:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3330/107898 [18:06<9:42:43,  2.99it/s][2025-01-30 02:10:16][root][INFO] - Training Epoch: 1/2, step 3329/107898 completed (loss: 0.3802209496498108, acc: 1.0)
[2025-01-30 02:10:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3331/107898 [18:07<9:55:11,  2.93it/s][2025-01-30 02:10:16][root][INFO] - Training Epoch: 1/2, step 3330/107898 completed (loss: 0.003098092507570982, acc: 1.0)
[2025-01-30 02:10:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3332/107898 [18:07<9:47:56,  2.96it/s][2025-01-30 02:10:17][root][INFO] - Training Epoch: 1/2, step 3331/107898 completed (loss: 0.1273106038570404, acc: 1.0)
[2025-01-30 02:10:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3333/107898 [18:07<9:43:04,  2.99it/s][2025-01-30 02:10:17][root][INFO] - Training Epoch: 1/2, step 3332/107898 completed (loss: 0.15878336131572723, acc: 0.9666666388511658)
[2025-01-30 02:10:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3334/107898 [18:08<9:44:13,  2.98it/s][2025-01-30 02:10:17][root][INFO] - Training Epoch: 1/2, step 3333/107898 completed (loss: 0.4174463152885437, acc: 0.8695651888847351)
[2025-01-30 02:10:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3335/107898 [18:08<9:55:47,  2.93it/s][2025-01-30 02:10:18][root][INFO] - Training Epoch: 1/2, step 3334/107898 completed (loss: 0.9252033233642578, acc: 0.7692307829856873)
[2025-01-30 02:10:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3336/107898 [18:08<10:04:08,  2.88it/s][2025-01-30 02:10:18][root][INFO] - Training Epoch: 1/2, step 3335/107898 completed (loss: 0.004612976685166359, acc: 1.0)
[2025-01-30 02:10:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3337/107898 [18:09<10:05:36,  2.88it/s][2025-01-30 02:10:18][root][INFO] - Training Epoch: 1/2, step 3336/107898 completed (loss: 1.1871283054351807, acc: 0.7692307829856873)
[2025-01-30 02:10:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3338/107898 [18:09<9:46:30,  2.97it/s] [2025-01-30 02:10:19][root][INFO] - Training Epoch: 1/2, step 3337/107898 completed (loss: 1.7910289764404297, acc: 0.6666666865348816)
[2025-01-30 02:10:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3339/107898 [18:09<9:31:28,  3.05it/s][2025-01-30 02:10:19][root][INFO] - Training Epoch: 1/2, step 3338/107898 completed (loss: 0.015711097046732903, acc: 1.0)
[2025-01-30 02:10:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3340/107898 [18:10<9:35:13,  3.03it/s][2025-01-30 02:10:19][root][INFO] - Training Epoch: 1/2, step 3339/107898 completed (loss: 0.01726772077381611, acc: 1.0)
[2025-01-30 02:10:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3341/107898 [18:10<9:27:52,  3.07it/s][2025-01-30 02:10:20][root][INFO] - Training Epoch: 1/2, step 3340/107898 completed (loss: 0.15418140590190887, acc: 1.0)
[2025-01-30 02:10:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3342/107898 [18:10<9:36:25,  3.02it/s][2025-01-30 02:10:20][root][INFO] - Training Epoch: 1/2, step 3341/107898 completed (loss: 0.1394510716199875, acc: 1.0)
[2025-01-30 02:10:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3343/107898 [18:11<9:35:41,  3.03it/s][2025-01-30 02:10:20][root][INFO] - Training Epoch: 1/2, step 3342/107898 completed (loss: 0.4255991280078888, acc: 0.75)
[2025-01-30 02:10:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3344/107898 [18:11<9:32:39,  3.04it/s][2025-01-30 02:10:21][root][INFO] - Training Epoch: 1/2, step 3343/107898 completed (loss: 2.419759511947632, acc: 0.5714285969734192)
[2025-01-30 02:10:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3345/107898 [18:11<9:16:26,  3.13it/s][2025-01-30 02:10:21][root][INFO] - Training Epoch: 1/2, step 3344/107898 completed (loss: 1.3033039569854736, acc: 0.692307710647583)
[2025-01-30 02:10:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3346/107898 [18:11<8:57:13,  3.24it/s][2025-01-30 02:10:21][root][INFO] - Training Epoch: 1/2, step 3345/107898 completed (loss: 4.630895614624023, acc: 0.06666667014360428)
[2025-01-30 02:10:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3347/107898 [18:12<8:50:28,  3.28it/s][2025-01-30 02:10:22][root][INFO] - Training Epoch: 1/2, step 3346/107898 completed (loss: 0.569444477558136, acc: 0.8333333134651184)
[2025-01-30 02:10:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3348/107898 [18:12<9:17:06,  3.13it/s][2025-01-30 02:10:22][root][INFO] - Training Epoch: 1/2, step 3347/107898 completed (loss: 1.0333236455917358, acc: 0.800000011920929)
[2025-01-30 02:10:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3349/107898 [18:12<9:16:57,  3.13it/s][2025-01-30 02:10:22][root][INFO] - Training Epoch: 1/2, step 3348/107898 completed (loss: 0.984716534614563, acc: 0.8421052694320679)
[2025-01-30 02:10:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3350/107898 [18:13<9:34:58,  3.03it/s][2025-01-30 02:10:23][root][INFO] - Training Epoch: 1/2, step 3349/107898 completed (loss: 0.005939858499914408, acc: 1.0)
[2025-01-30 02:10:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3351/107898 [18:13<9:34:16,  3.03it/s][2025-01-30 02:10:23][root][INFO] - Training Epoch: 1/2, step 3350/107898 completed (loss: 0.00712886406108737, acc: 1.0)
[2025-01-30 02:10:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3352/107898 [18:13<9:32:48,  3.04it/s][2025-01-30 02:10:23][root][INFO] - Training Epoch: 1/2, step 3351/107898 completed (loss: 2.8356058597564697, acc: 0.6363636255264282)
[2025-01-30 02:10:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3353/107898 [18:14<9:12:01,  3.16it/s][2025-01-30 02:10:24][root][INFO] - Training Epoch: 1/2, step 3352/107898 completed (loss: 3.7193257808685303, acc: 0.3125)
[2025-01-30 02:10:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3354/107898 [18:14<9:11:34,  3.16it/s][2025-01-30 02:10:24][root][INFO] - Training Epoch: 1/2, step 3353/107898 completed (loss: 0.6991723775863647, acc: 0.8125)
[2025-01-30 02:10:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3355/107898 [18:14<9:33:06,  3.04it/s][2025-01-30 02:10:24][root][INFO] - Training Epoch: 1/2, step 3354/107898 completed (loss: 0.02550910972058773, acc: 1.0)
[2025-01-30 02:10:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3356/107898 [18:15<9:29:10,  3.06it/s][2025-01-30 02:10:25][root][INFO] - Training Epoch: 1/2, step 3355/107898 completed (loss: 2.4278922080993652, acc: 0.4000000059604645)
[2025-01-30 02:10:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3357/107898 [18:15<9:27:38,  3.07it/s][2025-01-30 02:10:25][root][INFO] - Training Epoch: 1/2, step 3356/107898 completed (loss: 0.5974406003952026, acc: 0.5)
[2025-01-30 02:10:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3358/107898 [18:15<9:19:36,  3.11it/s][2025-01-30 02:10:25][root][INFO] - Training Epoch: 1/2, step 3357/107898 completed (loss: 5.080331325531006, acc: 0.3333333432674408)
[2025-01-30 02:10:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3359/107898 [18:16<9:12:07,  3.16it/s][2025-01-30 02:10:25][root][INFO] - Training Epoch: 1/2, step 3358/107898 completed (loss: 0.42692774534225464, acc: 0.8181818127632141)
[2025-01-30 02:10:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3360/107898 [18:16<9:04:58,  3.20it/s][2025-01-30 02:10:26][root][INFO] - Training Epoch: 1/2, step 3359/107898 completed (loss: 3.1273844242095947, acc: 0.4615384638309479)
[2025-01-30 02:10:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3361/107898 [18:16<8:58:50,  3.23it/s][2025-01-30 02:10:26][root][INFO] - Training Epoch: 1/2, step 3360/107898 completed (loss: 2.059229612350464, acc: 0.5625)
[2025-01-30 02:10:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3362/107898 [18:17<9:28:57,  3.06it/s][2025-01-30 02:10:26][root][INFO] - Training Epoch: 1/2, step 3361/107898 completed (loss: 4.41013765335083, acc: 0.22727273404598236)
[2025-01-30 02:10:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3363/107898 [18:17<9:17:49,  3.12it/s][2025-01-30 02:10:27][root][INFO] - Training Epoch: 1/2, step 3362/107898 completed (loss: 1.0326861143112183, acc: 0.75)
[2025-01-30 02:10:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3364/107898 [18:17<9:32:48,  3.04it/s][2025-01-30 02:10:27][root][INFO] - Training Epoch: 1/2, step 3363/107898 completed (loss: 0.9232872724533081, acc: 0.7777777910232544)
[2025-01-30 02:10:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3365/107898 [18:18<9:28:25,  3.07it/s][2025-01-30 02:10:27][root][INFO] - Training Epoch: 1/2, step 3364/107898 completed (loss: 0.8675658702850342, acc: 0.8947368264198303)
[2025-01-30 02:10:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3366/107898 [18:18<9:17:52,  3.12it/s][2025-01-30 02:10:28][root][INFO] - Training Epoch: 1/2, step 3365/107898 completed (loss: 0.8475919961929321, acc: 0.7142857313156128)
[2025-01-30 02:10:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3367/107898 [18:18<9:06:58,  3.19it/s][2025-01-30 02:10:28][root][INFO] - Training Epoch: 1/2, step 3366/107898 completed (loss: 0.4159586727619171, acc: 0.8888888955116272)
[2025-01-30 02:10:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3368/107898 [18:19<9:26:00,  3.08it/s][2025-01-30 02:10:28][root][INFO] - Training Epoch: 1/2, step 3367/107898 completed (loss: 0.020076507702469826, acc: 1.0)
[2025-01-30 02:10:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3369/107898 [18:19<9:31:56,  3.05it/s][2025-01-30 02:10:29][root][INFO] - Training Epoch: 1/2, step 3368/107898 completed (loss: 1.195499062538147, acc: 0.8999999761581421)
[2025-01-30 02:10:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3370/107898 [18:19<9:24:04,  3.09it/s][2025-01-30 02:10:29][root][INFO] - Training Epoch: 1/2, step 3369/107898 completed (loss: 0.12286484986543655, acc: 1.0)
[2025-01-30 02:10:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3371/107898 [18:20<9:41:52,  2.99it/s][2025-01-30 02:10:29][root][INFO] - Training Epoch: 1/2, step 3370/107898 completed (loss: 0.3621813952922821, acc: 0.9375)
[2025-01-30 02:10:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3372/107898 [18:20<9:43:50,  2.98it/s][2025-01-30 02:10:30][root][INFO] - Training Epoch: 1/2, step 3371/107898 completed (loss: 2.445729970932007, acc: 0.5454545617103577)
[2025-01-30 02:10:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3373/107898 [18:20<9:44:35,  2.98it/s][2025-01-30 02:10:30][root][INFO] - Training Epoch: 1/2, step 3372/107898 completed (loss: 2.2202632427215576, acc: 0.3333333432674408)
[2025-01-30 02:10:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3374/107898 [18:21<9:50:54,  2.95it/s][2025-01-30 02:10:30][root][INFO] - Training Epoch: 1/2, step 3373/107898 completed (loss: 3.466947555541992, acc: 0.29411765933036804)
[2025-01-30 02:10:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3375/107898 [18:21<9:50:17,  2.95it/s][2025-01-30 02:10:31][root][INFO] - Training Epoch: 1/2, step 3374/107898 completed (loss: 1.374053716659546, acc: 0.7307692170143127)
[2025-01-30 02:10:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3376/107898 [18:21<9:34:55,  3.03it/s][2025-01-30 02:10:31][root][INFO] - Training Epoch: 1/2, step 3375/107898 completed (loss: 1.8266122341156006, acc: 0.6000000238418579)
[2025-01-30 02:10:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3377/107898 [18:22<9:50:25,  2.95it/s][2025-01-30 02:10:31][root][INFO] - Training Epoch: 1/2, step 3376/107898 completed (loss: 0.02131705917418003, acc: 1.0)
[2025-01-30 02:10:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3378/107898 [18:22<9:25:04,  3.08it/s][2025-01-30 02:10:32][root][INFO] - Training Epoch: 1/2, step 3377/107898 completed (loss: 3.103517770767212, acc: 0.3333333432674408)
[2025-01-30 02:10:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3379/107898 [18:22<9:33:50,  3.04it/s][2025-01-30 02:10:32][root][INFO] - Training Epoch: 1/2, step 3378/107898 completed (loss: 0.2272731214761734, acc: 1.0)
[2025-01-30 02:10:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3380/107898 [18:23<9:35:52,  3.02it/s][2025-01-30 02:10:32][root][INFO] - Training Epoch: 1/2, step 3379/107898 completed (loss: 0.2595604360103607, acc: 0.875)
[2025-01-30 02:10:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3381/107898 [18:23<9:35:01,  3.03it/s][2025-01-30 02:10:33][root][INFO] - Training Epoch: 1/2, step 3380/107898 completed (loss: 0.298290491104126, acc: 0.9375)
[2025-01-30 02:10:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3382/107898 [18:23<9:22:59,  3.09it/s][2025-01-30 02:10:33][root][INFO] - Training Epoch: 1/2, step 3381/107898 completed (loss: 0.7397997975349426, acc: 0.8571428656578064)
[2025-01-30 02:10:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3383/107898 [18:24<9:13:24,  3.15it/s][2025-01-30 02:10:33][root][INFO] - Training Epoch: 1/2, step 3382/107898 completed (loss: 0.6782417297363281, acc: 0.8461538553237915)
[2025-01-30 02:10:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3384/107898 [18:24<9:04:21,  3.20it/s][2025-01-30 02:10:34][root][INFO] - Training Epoch: 1/2, step 3383/107898 completed (loss: 1.635977029800415, acc: 0.5)
[2025-01-30 02:10:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3385/107898 [18:24<9:18:12,  3.12it/s][2025-01-30 02:10:34][root][INFO] - Training Epoch: 1/2, step 3384/107898 completed (loss: 1.4622831344604492, acc: 0.75)
[2025-01-30 02:10:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3386/107898 [18:24<9:07:03,  3.18it/s][2025-01-30 02:10:34][root][INFO] - Training Epoch: 1/2, step 3385/107898 completed (loss: 2.1196367740631104, acc: 0.3333333432674408)
[2025-01-30 02:10:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3387/107898 [18:25<8:59:49,  3.23it/s][2025-01-30 02:10:35][root][INFO] - Training Epoch: 1/2, step 3386/107898 completed (loss: 0.011428925208747387, acc: 1.0)
[2025-01-30 02:10:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3388/107898 [18:25<9:19:50,  3.11it/s][2025-01-30 02:10:35][root][INFO] - Training Epoch: 1/2, step 3387/107898 completed (loss: 3.4507501125335693, acc: 0.42424243688583374)
[2025-01-30 02:10:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3389/107898 [18:25<9:11:35,  3.16it/s][2025-01-30 02:10:35][root][INFO] - Training Epoch: 1/2, step 3388/107898 completed (loss: 1.81853449344635, acc: 0.6666666865348816)
[2025-01-30 02:10:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3390/107898 [18:26<9:01:22,  3.22it/s][2025-01-30 02:10:36][root][INFO] - Training Epoch: 1/2, step 3389/107898 completed (loss: 3.9911913871765137, acc: 0.20000000298023224)
[2025-01-30 02:10:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3391/107898 [18:26<8:59:31,  3.23it/s][2025-01-30 02:10:36][root][INFO] - Training Epoch: 1/2, step 3390/107898 completed (loss: 4.045284748077393, acc: 0.0)
[2025-01-30 02:10:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3392/107898 [18:26<9:20:38,  3.11it/s][2025-01-30 02:10:36][root][INFO] - Training Epoch: 1/2, step 3391/107898 completed (loss: 1.2203633785247803, acc: 0.7333333492279053)
[2025-01-30 02:10:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3393/107898 [18:27<9:21:34,  3.10it/s][2025-01-30 02:10:36][root][INFO] - Training Epoch: 1/2, step 3392/107898 completed (loss: 1.1992257833480835, acc: 0.75)
[2025-01-30 02:10:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3394/107898 [18:27<9:33:36,  3.04it/s][2025-01-30 02:10:37][root][INFO] - Training Epoch: 1/2, step 3393/107898 completed (loss: 2.4937164783477783, acc: 0.6666666865348816)
[2025-01-30 02:10:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3395/107898 [18:27<9:33:24,  3.04it/s][2025-01-30 02:10:37][root][INFO] - Training Epoch: 1/2, step 3394/107898 completed (loss: 0.12035716325044632, acc: 1.0)
[2025-01-30 02:10:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3396/107898 [18:28<9:25:03,  3.08it/s][2025-01-30 02:10:37][root][INFO] - Training Epoch: 1/2, step 3395/107898 completed (loss: 0.012694504112005234, acc: 1.0)
[2025-01-30 02:10:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3397/107898 [18:28<9:29:58,  3.06it/s][2025-01-30 02:10:38][root][INFO] - Training Epoch: 1/2, step 3396/107898 completed (loss: 3.874492883682251, acc: 0.375)
[2025-01-30 02:10:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3398/107898 [18:28<9:18:00,  3.12it/s][2025-01-30 02:10:38][root][INFO] - Training Epoch: 1/2, step 3397/107898 completed (loss: 1.3444746732711792, acc: 0.6666666865348816)
[2025-01-30 02:10:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3399/107898 [18:29<9:10:46,  3.16it/s][2025-01-30 02:10:38][root][INFO] - Training Epoch: 1/2, step 3398/107898 completed (loss: 0.440952867269516, acc: 0.9333333373069763)
[2025-01-30 02:10:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3400/107898 [18:29<9:39:40,  3.00it/s][2025-01-30 02:10:39][root][INFO] - Training Epoch: 1/2, step 3399/107898 completed (loss: 4.041498184204102, acc: 0.20000000298023224)
[2025-01-30 02:10:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3401/107898 [18:29<9:42:08,  2.99it/s][2025-01-30 02:10:39][root][INFO] - Training Epoch: 1/2, step 3400/107898 completed (loss: 2.1332061290740967, acc: 0.4285714328289032)
[2025-01-30 02:10:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3402/107898 [18:30<9:33:04,  3.04it/s][2025-01-30 02:10:39][root][INFO] - Training Epoch: 1/2, step 3401/107898 completed (loss: 1.0835726261138916, acc: 0.7857142686843872)
[2025-01-30 02:10:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3403/107898 [18:30<9:32:03,  3.04it/s][2025-01-30 02:10:40][root][INFO] - Training Epoch: 1/2, step 3402/107898 completed (loss: 4.3602519035339355, acc: 0.6666666865348816)
[2025-01-30 02:10:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3404/107898 [18:30<9:25:31,  3.08it/s][2025-01-30 02:10:40][root][INFO] - Training Epoch: 1/2, step 3403/107898 completed (loss: 3.761512041091919, acc: 0.20000000298023224)
[2025-01-30 02:10:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3405/107898 [18:31<8:54:59,  3.26it/s][2025-01-30 02:10:40][root][INFO] - Training Epoch: 1/2, step 3404/107898 completed (loss: 0.9847017526626587, acc: 0.800000011920929)
[2025-01-30 02:10:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3406/107898 [18:31<8:55:20,  3.25it/s][2025-01-30 02:10:41][root][INFO] - Training Epoch: 1/2, step 3405/107898 completed (loss: 2.2977254390716553, acc: 0.5454545617103577)
[2025-01-30 02:10:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3407/107898 [18:31<9:26:01,  3.08it/s][2025-01-30 02:10:41][root][INFO] - Training Epoch: 1/2, step 3406/107898 completed (loss: 1.0616343021392822, acc: 0.800000011920929)
[2025-01-30 02:10:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3408/107898 [18:32<9:12:20,  3.15it/s][2025-01-30 02:10:41][root][INFO] - Training Epoch: 1/2, step 3407/107898 completed (loss: 6.776668071746826, acc: 0.5)
[2025-01-30 02:10:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3409/107898 [18:32<9:06:54,  3.18it/s][2025-01-30 02:10:42][root][INFO] - Training Epoch: 1/2, step 3408/107898 completed (loss: 5.255894660949707, acc: 0.0)
[2025-01-30 02:10:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3410/107898 [18:32<8:56:44,  3.24it/s][2025-01-30 02:10:42][root][INFO] - Training Epoch: 1/2, step 3409/107898 completed (loss: 1.7056429386138916, acc: 0.5555555820465088)
[2025-01-30 02:10:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3411/107898 [18:32<9:01:32,  3.22it/s][2025-01-30 02:10:42][root][INFO] - Training Epoch: 1/2, step 3410/107898 completed (loss: 4.269413471221924, acc: 0.2857142984867096)
[2025-01-30 02:10:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3412/107898 [18:33<8:55:46,  3.25it/s][2025-01-30 02:10:43][root][INFO] - Training Epoch: 1/2, step 3411/107898 completed (loss: 1.2224218845367432, acc: 0.800000011920929)
[2025-01-30 02:10:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3413/107898 [18:33<8:56:59,  3.24it/s][2025-01-30 02:10:43][root][INFO] - Training Epoch: 1/2, step 3412/107898 completed (loss: 3.559864044189453, acc: 0.375)
[2025-01-30 02:10:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3414/107898 [18:33<9:04:50,  3.20it/s][2025-01-30 02:10:43][root][INFO] - Training Epoch: 1/2, step 3413/107898 completed (loss: 4.640797138214111, acc: 0.20000000298023224)
[2025-01-30 02:10:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3415/107898 [18:34<9:02:45,  3.21it/s][2025-01-30 02:10:43][root][INFO] - Training Epoch: 1/2, step 3414/107898 completed (loss: 1.1383657455444336, acc: 0.8181818127632141)
[2025-01-30 02:10:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3416/107898 [18:34<9:04:14,  3.20it/s][2025-01-30 02:10:44][root][INFO] - Training Epoch: 1/2, step 3415/107898 completed (loss: 4.6650776863098145, acc: 0.0)
[2025-01-30 02:10:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3417/107898 [18:34<8:53:41,  3.26it/s][2025-01-30 02:10:44][root][INFO] - Training Epoch: 1/2, step 3416/107898 completed (loss: 1.8693500757217407, acc: 0.5)
[2025-01-30 02:10:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3418/107898 [18:35<8:56:33,  3.25it/s][2025-01-30 02:10:44][root][INFO] - Training Epoch: 1/2, step 3417/107898 completed (loss: 0.7208912968635559, acc: 0.8095238208770752)
[2025-01-30 02:10:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3419/107898 [18:35<8:50:27,  3.28it/s][2025-01-30 02:10:45][root][INFO] - Training Epoch: 1/2, step 3418/107898 completed (loss: 0.2395714819431305, acc: 1.0)
[2025-01-30 02:10:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3420/107898 [18:35<9:19:29,  3.11it/s][2025-01-30 02:10:45][root][INFO] - Training Epoch: 1/2, step 3419/107898 completed (loss: 3.328695297241211, acc: 0.3333333432674408)
[2025-01-30 02:10:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3421/107898 [18:36<9:32:04,  3.04it/s][2025-01-30 02:10:45][root][INFO] - Training Epoch: 1/2, step 3420/107898 completed (loss: 1.1334280967712402, acc: 0.8125)
[2025-01-30 02:10:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3422/107898 [18:36<9:54:21,  2.93it/s][2025-01-30 02:10:46][root][INFO] - Training Epoch: 1/2, step 3421/107898 completed (loss: 2.5165326595306396, acc: 0.6538461446762085)
[2025-01-30 02:10:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3423/107898 [18:36<9:12:26,  3.15it/s][2025-01-30 02:10:46][root][INFO] - Training Epoch: 1/2, step 3422/107898 completed (loss: 0.7288660407066345, acc: 0.875)
[2025-01-30 02:10:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3424/107898 [18:37<9:11:16,  3.16it/s][2025-01-30 02:10:46][root][INFO] - Training Epoch: 1/2, step 3423/107898 completed (loss: 0.3229948878288269, acc: 1.0)
[2025-01-30 02:10:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3425/107898 [18:37<9:00:21,  3.22it/s][2025-01-30 02:10:47][root][INFO] - Training Epoch: 1/2, step 3424/107898 completed (loss: 2.4445035457611084, acc: 0.4000000059604645)
[2025-01-30 02:10:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3426/107898 [18:37<9:40:20,  3.00it/s][2025-01-30 02:10:47][root][INFO] - Training Epoch: 1/2, step 3425/107898 completed (loss: 0.0032004795502871275, acc: 1.0)
[2025-01-30 02:10:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3427/107898 [18:38<9:51:04,  2.95it/s][2025-01-30 02:10:47][root][INFO] - Training Epoch: 1/2, step 3426/107898 completed (loss: 1.7310764789581299, acc: 0.625)
[2025-01-30 02:10:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3428/107898 [18:38<9:51:49,  2.94it/s][2025-01-30 02:10:48][root][INFO] - Training Epoch: 1/2, step 3427/107898 completed (loss: 0.5994653105735779, acc: 0.9090909361839294)
[2025-01-30 02:10:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3429/107898 [18:38<9:57:40,  2.91it/s][2025-01-30 02:10:48][root][INFO] - Training Epoch: 1/2, step 3428/107898 completed (loss: 0.9880083203315735, acc: 0.6000000238418579)
[2025-01-30 02:10:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3430/107898 [18:39<9:50:31,  2.95it/s][2025-01-30 02:10:48][root][INFO] - Training Epoch: 1/2, step 3429/107898 completed (loss: 2.140092134475708, acc: 0.3333333432674408)
[2025-01-30 02:10:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3431/107898 [18:39<9:32:13,  3.04it/s][2025-01-30 02:10:49][root][INFO] - Training Epoch: 1/2, step 3430/107898 completed (loss: 0.36294224858283997, acc: 0.8333333134651184)
[2025-01-30 02:10:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3432/107898 [18:39<9:12:48,  3.15it/s][2025-01-30 02:10:49][root][INFO] - Training Epoch: 1/2, step 3431/107898 completed (loss: 2.2761616706848145, acc: 0.75)
[2025-01-30 02:10:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3433/107898 [18:40<9:04:53,  3.20it/s][2025-01-30 02:10:49][root][INFO] - Training Epoch: 1/2, step 3432/107898 completed (loss: 1.9564985036849976, acc: 0.6666666865348816)
[2025-01-30 02:10:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3434/107898 [18:40<9:21:05,  3.10it/s][2025-01-30 02:10:50][root][INFO] - Training Epoch: 1/2, step 3433/107898 completed (loss: 0.32005971670150757, acc: 1.0)
[2025-01-30 02:10:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3435/107898 [18:40<9:46:53,  2.97it/s][2025-01-30 02:10:50][root][INFO] - Training Epoch: 1/2, step 3434/107898 completed (loss: 1.588057041168213, acc: 0.7777777910232544)
[2025-01-30 02:10:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3436/107898 [18:41<10:02:39,  2.89it/s][2025-01-30 02:10:50][root][INFO] - Training Epoch: 1/2, step 3435/107898 completed (loss: 5.21246862411499, acc: 0.25)
[2025-01-30 02:10:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3437/107898 [18:41<10:06:50,  2.87it/s][2025-01-30 02:10:51][root][INFO] - Training Epoch: 1/2, step 3436/107898 completed (loss: 0.3196013569831848, acc: 0.95652174949646)
[2025-01-30 02:10:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3438/107898 [18:41<9:42:15,  2.99it/s] [2025-01-30 02:10:51][root][INFO] - Training Epoch: 1/2, step 3437/107898 completed (loss: 4.887505531311035, acc: 0.20000000298023224)
[2025-01-30 02:10:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3439/107898 [18:42<9:24:46,  3.08it/s][2025-01-30 02:10:51][root][INFO] - Training Epoch: 1/2, step 3438/107898 completed (loss: 1.9485509395599365, acc: 0.5)
[2025-01-30 02:10:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3440/107898 [18:42<9:41:35,  2.99it/s][2025-01-30 02:10:52][root][INFO] - Training Epoch: 1/2, step 3439/107898 completed (loss: 2.598930597305298, acc: 0.2222222238779068)
[2025-01-30 02:10:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3441/107898 [18:42<9:45:35,  2.97it/s][2025-01-30 02:10:52][root][INFO] - Training Epoch: 1/2, step 3440/107898 completed (loss: 0.011050526052713394, acc: 1.0)
[2025-01-30 02:10:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3442/107898 [18:43<9:44:15,  2.98it/s][2025-01-30 02:10:52][root][INFO] - Training Epoch: 1/2, step 3441/107898 completed (loss: 2.160283327102661, acc: 0.7777777910232544)
[2025-01-30 02:10:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3443/107898 [18:43<9:39:21,  3.00it/s][2025-01-30 02:10:53][root][INFO] - Training Epoch: 1/2, step 3442/107898 completed (loss: 1.8113309144973755, acc: 0.6470588445663452)
[2025-01-30 02:10:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3444/107898 [18:43<9:29:24,  3.06it/s][2025-01-30 02:10:53][root][INFO] - Training Epoch: 1/2, step 3443/107898 completed (loss: 0.514410138130188, acc: 0.8571428656578064)
[2025-01-30 02:10:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3445/107898 [18:44<9:37:22,  3.02it/s][2025-01-30 02:10:53][root][INFO] - Training Epoch: 1/2, step 3444/107898 completed (loss: 1.7516324520111084, acc: 0.5384615659713745)
[2025-01-30 02:10:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3446/107898 [18:44<9:42:20,  2.99it/s][2025-01-30 02:10:54][root][INFO] - Training Epoch: 1/2, step 3445/107898 completed (loss: 0.6867986917495728, acc: 0.8857142925262451)
[2025-01-30 02:10:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3447/107898 [18:44<9:18:10,  3.12it/s][2025-01-30 02:10:54][root][INFO] - Training Epoch: 1/2, step 3446/107898 completed (loss: 0.19985418021678925, acc: 1.0)
[2025-01-30 02:10:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3448/107898 [18:45<9:41:10,  3.00it/s][2025-01-30 02:10:54][root][INFO] - Training Epoch: 1/2, step 3447/107898 completed (loss: 0.769201397895813, acc: 0.5)
[2025-01-30 02:10:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3449/107898 [18:45<9:18:40,  3.12it/s][2025-01-30 02:10:55][root][INFO] - Training Epoch: 1/2, step 3448/107898 completed (loss: 2.1390819549560547, acc: 0.5)
[2025-01-30 02:10:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3450/107898 [18:45<9:04:36,  3.20it/s][2025-01-30 02:10:55][root][INFO] - Training Epoch: 1/2, step 3449/107898 completed (loss: 0.5255141258239746, acc: 0.9333333373069763)
[2025-01-30 02:10:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3451/107898 [18:45<9:03:49,  3.20it/s][2025-01-30 02:10:55][root][INFO] - Training Epoch: 1/2, step 3450/107898 completed (loss: 0.25419703125953674, acc: 1.0)
[2025-01-30 02:10:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3452/107898 [18:46<8:58:05,  3.24it/s][2025-01-30 02:10:56][root][INFO] - Training Epoch: 1/2, step 3451/107898 completed (loss: 2.8118293285369873, acc: 0.5555555820465088)
[2025-01-30 02:10:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3453/107898 [18:46<9:11:22,  3.16it/s][2025-01-30 02:10:56][root][INFO] - Training Epoch: 1/2, step 3452/107898 completed (loss: 0.4506351053714752, acc: 0.9200000166893005)
[2025-01-30 02:10:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3454/107898 [18:46<9:06:21,  3.19it/s][2025-01-30 02:10:56][root][INFO] - Training Epoch: 1/2, step 3453/107898 completed (loss: 0.5633254051208496, acc: 0.7777777910232544)
[2025-01-30 02:10:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3455/107898 [18:47<9:30:39,  3.05it/s][2025-01-30 02:10:57][root][INFO] - Training Epoch: 1/2, step 3454/107898 completed (loss: 0.07185827940702438, acc: 1.0)
[2025-01-30 02:10:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3456/107898 [18:47<9:12:04,  3.15it/s][2025-01-30 02:10:57][root][INFO] - Training Epoch: 1/2, step 3455/107898 completed (loss: 0.7472386360168457, acc: 0.75)
[2025-01-30 02:10:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3457/107898 [18:47<8:54:31,  3.26it/s][2025-01-30 02:10:57][root][INFO] - Training Epoch: 1/2, step 3456/107898 completed (loss: 0.028135700151324272, acc: 1.0)
[2025-01-30 02:10:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3458/107898 [18:48<8:43:01,  3.33it/s][2025-01-30 02:10:57][root][INFO] - Training Epoch: 1/2, step 3457/107898 completed (loss: 0.03093501180410385, acc: 1.0)
[2025-01-30 02:10:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3459/107898 [18:48<8:54:16,  3.26it/s][2025-01-30 02:10:58][root][INFO] - Training Epoch: 1/2, step 3458/107898 completed (loss: 0.8771595358848572, acc: 0.8461538553237915)
[2025-01-30 02:10:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3460/107898 [18:48<8:42:29,  3.33it/s][2025-01-30 02:10:58][root][INFO] - Training Epoch: 1/2, step 3459/107898 completed (loss: 1.7071651220321655, acc: 0.6818181872367859)
[2025-01-30 02:10:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3461/107898 [18:49<9:00:48,  3.22it/s][2025-01-30 02:10:58][root][INFO] - Training Epoch: 1/2, step 3460/107898 completed (loss: 1.4419840574264526, acc: 0.8333333134651184)
[2025-01-30 02:10:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3462/107898 [18:49<9:03:46,  3.20it/s][2025-01-30 02:10:59][root][INFO] - Training Epoch: 1/2, step 3461/107898 completed (loss: 0.0638185515999794, acc: 1.0)
[2025-01-30 02:10:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3463/107898 [18:49<9:03:20,  3.20it/s][2025-01-30 02:10:59][root][INFO] - Training Epoch: 1/2, step 3462/107898 completed (loss: 3.6741068363189697, acc: 0.3571428656578064)
[2025-01-30 02:10:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3464/107898 [18:49<8:55:44,  3.25it/s][2025-01-30 02:10:59][root][INFO] - Training Epoch: 1/2, step 3463/107898 completed (loss: 0.003402142086997628, acc: 1.0)
[2025-01-30 02:10:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3465/107898 [18:50<8:53:42,  3.26it/s][2025-01-30 02:11:00][root][INFO] - Training Epoch: 1/2, step 3464/107898 completed (loss: 0.13030512630939484, acc: 1.0)
[2025-01-30 02:11:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3466/107898 [18:50<9:06:53,  3.18it/s][2025-01-30 02:11:00][root][INFO] - Training Epoch: 1/2, step 3465/107898 completed (loss: 4.016984462738037, acc: 0.31578946113586426)
[2025-01-30 02:11:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3467/107898 [18:50<9:09:01,  3.17it/s][2025-01-30 02:11:00][root][INFO] - Training Epoch: 1/2, step 3466/107898 completed (loss: 0.045608825981616974, acc: 1.0)
[2025-01-30 02:11:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3468/107898 [18:51<9:19:23,  3.11it/s][2025-01-30 02:11:01][root][INFO] - Training Epoch: 1/2, step 3467/107898 completed (loss: 0.0860481932759285, acc: 1.0)
[2025-01-30 02:11:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3469/107898 [18:51<9:28:10,  3.06it/s][2025-01-30 02:11:01][root][INFO] - Training Epoch: 1/2, step 3468/107898 completed (loss: 0.2650483250617981, acc: 0.8999999761581421)
[2025-01-30 02:11:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3470/107898 [18:51<9:28:33,  3.06it/s][2025-01-30 02:11:01][root][INFO] - Training Epoch: 1/2, step 3469/107898 completed (loss: 0.37242528796195984, acc: 0.8461538553237915)
[2025-01-30 02:11:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3471/107898 [18:52<9:15:54,  3.13it/s][2025-01-30 02:11:02][root][INFO] - Training Epoch: 1/2, step 3470/107898 completed (loss: 1.4989949464797974, acc: 0.6666666865348816)
[2025-01-30 02:11:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3472/107898 [18:52<9:23:27,  3.09it/s][2025-01-30 02:11:02][root][INFO] - Training Epoch: 1/2, step 3471/107898 completed (loss: 0.3519861102104187, acc: 0.8888888955116272)
[2025-01-30 02:11:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3473/107898 [18:52<9:42:23,  2.99it/s][2025-01-30 02:11:02][root][INFO] - Training Epoch: 1/2, step 3472/107898 completed (loss: 2.1704673767089844, acc: 0.6666666865348816)
[2025-01-30 02:11:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3474/107898 [18:53<9:38:39,  3.01it/s][2025-01-30 02:11:03][root][INFO] - Training Epoch: 1/2, step 3473/107898 completed (loss: 0.019419312477111816, acc: 1.0)
[2025-01-30 02:11:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3475/107898 [18:53<9:48:07,  2.96it/s][2025-01-30 02:11:03][root][INFO] - Training Epoch: 1/2, step 3474/107898 completed (loss: 1.1271790266036987, acc: 0.7272727489471436)
[2025-01-30 02:11:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3476/107898 [18:53<9:55:44,  2.92it/s][2025-01-30 02:11:03][root][INFO] - Training Epoch: 1/2, step 3475/107898 completed (loss: 0.7262244820594788, acc: 0.6666666865348816)
[2025-01-30 02:11:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3477/107898 [18:54<9:48:26,  2.96it/s][2025-01-30 02:11:04][root][INFO] - Training Epoch: 1/2, step 3476/107898 completed (loss: 3.371706962585449, acc: 0.1818181872367859)
[2025-01-30 02:11:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3478/107898 [18:54<9:27:31,  3.07it/s][2025-01-30 02:11:04][root][INFO] - Training Epoch: 1/2, step 3477/107898 completed (loss: 0.03292568027973175, acc: 1.0)
[2025-01-30 02:11:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3479/107898 [18:54<9:13:32,  3.14it/s][2025-01-30 02:11:04][root][INFO] - Training Epoch: 1/2, step 3478/107898 completed (loss: 0.1588529497385025, acc: 0.9230769276618958)
[2025-01-30 02:11:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3480/107898 [18:55<9:07:28,  3.18it/s][2025-01-30 02:11:05][root][INFO] - Training Epoch: 1/2, step 3479/107898 completed (loss: 0.017474884167313576, acc: 1.0)
[2025-01-30 02:11:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3481/107898 [18:55<9:08:14,  3.17it/s][2025-01-30 02:11:05][root][INFO] - Training Epoch: 1/2, step 3480/107898 completed (loss: 0.09383691102266312, acc: 0.9333333373069763)
[2025-01-30 02:11:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3482/107898 [18:55<9:05:03,  3.19it/s][2025-01-30 02:11:05][root][INFO] - Training Epoch: 1/2, step 3481/107898 completed (loss: 1.7315505743026733, acc: 0.6666666865348816)
[2025-01-30 02:11:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3483/107898 [18:56<9:21:22,  3.10it/s][2025-01-30 02:11:05][root][INFO] - Training Epoch: 1/2, step 3482/107898 completed (loss: 2.169114589691162, acc: 0.75)
[2025-01-30 02:11:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3484/107898 [18:56<9:41:49,  2.99it/s][2025-01-30 02:11:06][root][INFO] - Training Epoch: 1/2, step 3483/107898 completed (loss: 0.0022006784565746784, acc: 1.0)
[2025-01-30 02:11:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3485/107898 [18:56<9:43:57,  2.98it/s][2025-01-30 02:11:06][root][INFO] - Training Epoch: 1/2, step 3484/107898 completed (loss: 0.0414128415286541, acc: 1.0)
[2025-01-30 02:11:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3486/107898 [18:57<10:06:52,  2.87it/s][2025-01-30 02:11:07][root][INFO] - Training Epoch: 1/2, step 3485/107898 completed (loss: 2.659940481185913, acc: 0.6086956262588501)
[2025-01-30 02:11:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3487/107898 [18:57<10:07:23,  2.86it/s][2025-01-30 02:11:07][root][INFO] - Training Epoch: 1/2, step 3486/107898 completed (loss: 0.611397922039032, acc: 0.8181818127632141)
[2025-01-30 02:11:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3488/107898 [18:57<10:13:03,  2.84it/s][2025-01-30 02:11:07][root][INFO] - Training Epoch: 1/2, step 3487/107898 completed (loss: 0.5299735069274902, acc: 0.8148148059844971)
[2025-01-30 02:11:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3489/107898 [18:58<9:40:39,  3.00it/s] [2025-01-30 02:11:08][root][INFO] - Training Epoch: 1/2, step 3488/107898 completed (loss: 0.14323000609874725, acc: 1.0)
[2025-01-30 02:11:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3490/107898 [18:58<10:02:06,  2.89it/s][2025-01-30 02:11:08][root][INFO] - Training Epoch: 1/2, step 3489/107898 completed (loss: 1.0303826332092285, acc: 0.8666666746139526)
[2025-01-30 02:11:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3491/107898 [18:58<9:58:10,  2.91it/s] [2025-01-30 02:11:08][root][INFO] - Training Epoch: 1/2, step 3490/107898 completed (loss: 2.5728631019592285, acc: 0.4000000059604645)
[2025-01-30 02:11:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3492/107898 [18:59<10:08:14,  2.86it/s][2025-01-30 02:11:09][root][INFO] - Training Epoch: 1/2, step 3491/107898 completed (loss: 0.4707043170928955, acc: 0.9285714030265808)
[2025-01-30 02:11:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3493/107898 [18:59<9:46:31,  2.97it/s] [2025-01-30 02:11:09][root][INFO] - Training Epoch: 1/2, step 3492/107898 completed (loss: 2.3229358196258545, acc: 0.5714285969734192)
[2025-01-30 02:11:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3494/107898 [18:59<9:48:49,  2.96it/s][2025-01-30 02:11:09][root][INFO] - Training Epoch: 1/2, step 3493/107898 completed (loss: 1.1847026348114014, acc: 0.5)
[2025-01-30 02:11:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3495/107898 [19:00<9:27:21,  3.07it/s][2025-01-30 02:11:10][root][INFO] - Training Epoch: 1/2, step 3494/107898 completed (loss: 1.41864812374115, acc: 0.6399999856948853)
[2025-01-30 02:11:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3496/107898 [19:00<9:40:48,  3.00it/s][2025-01-30 02:11:10][root][INFO] - Training Epoch: 1/2, step 3495/107898 completed (loss: 3.5255794525146484, acc: 0.3571428656578064)
[2025-01-30 02:11:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3497/107898 [19:01<10:14:17,  2.83it/s][2025-01-30 02:11:10][root][INFO] - Training Epoch: 1/2, step 3496/107898 completed (loss: 0.8362753987312317, acc: 0.75)
[2025-01-30 02:11:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3498/107898 [19:01<10:16:32,  2.82it/s][2025-01-30 02:11:11][root][INFO] - Training Epoch: 1/2, step 3497/107898 completed (loss: 0.3348374366760254, acc: 1.0)
[2025-01-30 02:11:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3499/107898 [19:01<10:12:59,  2.84it/s][2025-01-30 02:11:11][root][INFO] - Training Epoch: 1/2, step 3498/107898 completed (loss: 0.8335496783256531, acc: 0.8666666746139526)
[2025-01-30 02:11:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3500/107898 [19:02<10:01:03,  2.89it/s][2025-01-30 02:11:11][root][INFO] - Training Epoch: 1/2, step 3499/107898 completed (loss: 0.6303122043609619, acc: 0.8636363744735718)
[2025-01-30 02:11:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3501/107898 [19:02<9:51:15,  2.94it/s] [2025-01-30 02:11:12][root][INFO] - Training Epoch: 1/2, step 3500/107898 completed (loss: 0.037227045744657516, acc: 1.0)
[2025-01-30 02:11:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3502/107898 [19:02<9:44:59,  2.97it/s][2025-01-30 02:11:12][root][INFO] - Training Epoch: 1/2, step 3501/107898 completed (loss: 2.1978728771209717, acc: 0.3333333432674408)
[2025-01-30 02:11:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3503/107898 [19:03<12:32:46,  2.31it/s][2025-01-30 02:11:13][root][INFO] - Training Epoch: 1/2, step 3502/107898 completed (loss: 4.580811977386475, acc: 0.30000001192092896)
[2025-01-30 02:11:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3504/107898 [19:03<11:12:47,  2.59it/s][2025-01-30 02:11:13][root][INFO] - Training Epoch: 1/2, step 3503/107898 completed (loss: 1.7605663537979126, acc: 0.6000000238418579)
[2025-01-30 02:11:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3505/107898 [19:03<10:31:19,  2.76it/s][2025-01-30 02:11:13][root][INFO] - Training Epoch: 1/2, step 3504/107898 completed (loss: 1.1520510911941528, acc: 0.807692289352417)
[2025-01-30 02:11:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3506/107898 [19:04<9:55:34,  2.92it/s] [2025-01-30 02:11:14][root][INFO] - Training Epoch: 1/2, step 3505/107898 completed (loss: 5.925858974456787, acc: 0.5)
[2025-01-30 02:11:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3507/107898 [19:04<9:29:02,  3.06it/s][2025-01-30 02:11:14][root][INFO] - Training Epoch: 1/2, step 3506/107898 completed (loss: 0.6005058288574219, acc: 0.6666666865348816)
[2025-01-30 02:11:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3508/107898 [19:04<9:16:48,  3.12it/s][2025-01-30 02:11:14][root][INFO] - Training Epoch: 1/2, step 3507/107898 completed (loss: 0.8193507790565491, acc: 0.8125)
[2025-01-30 02:11:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3509/107898 [19:05<9:42:23,  2.99it/s][2025-01-30 02:11:15][root][INFO] - Training Epoch: 1/2, step 3508/107898 completed (loss: 0.3100331127643585, acc: 0.8823529481887817)
[2025-01-30 02:11:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3510/107898 [19:05<9:33:44,  3.03it/s][2025-01-30 02:11:15][root][INFO] - Training Epoch: 1/2, step 3509/107898 completed (loss: 2.116490602493286, acc: 0.625)
[2025-01-30 02:11:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3511/107898 [19:05<9:50:56,  2.94it/s][2025-01-30 02:11:15][root][INFO] - Training Epoch: 1/2, step 3510/107898 completed (loss: 0.4597199857234955, acc: 1.0)
[2025-01-30 02:11:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3512/107898 [19:06<10:01:09,  2.89it/s][2025-01-30 02:11:16][root][INFO] - Training Epoch: 1/2, step 3511/107898 completed (loss: 2.599489212036133, acc: 0.6315789222717285)
[2025-01-30 02:11:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3513/107898 [19:06<10:03:11,  2.88it/s][2025-01-30 02:11:16][root][INFO] - Training Epoch: 1/2, step 3512/107898 completed (loss: 1.5044164657592773, acc: 0.6666666865348816)
[2025-01-30 02:11:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3514/107898 [19:06<10:05:05,  2.88it/s][2025-01-30 02:11:16][root][INFO] - Training Epoch: 1/2, step 3513/107898 completed (loss: 2.9263510704040527, acc: 0.4482758641242981)
[2025-01-30 02:11:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3515/107898 [19:07<10:14:54,  2.83it/s][2025-01-30 02:11:17][root][INFO] - Training Epoch: 1/2, step 3514/107898 completed (loss: 1.2710235118865967, acc: 0.8125)
[2025-01-30 02:11:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3516/107898 [19:07<9:57:19,  2.91it/s] [2025-01-30 02:11:17][root][INFO] - Training Epoch: 1/2, step 3515/107898 completed (loss: 3.2668235301971436, acc: 0.6000000238418579)
[2025-01-30 02:11:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3517/107898 [19:08<10:02:15,  2.89it/s][2025-01-30 02:11:17][root][INFO] - Training Epoch: 1/2, step 3516/107898 completed (loss: 2.2827794551849365, acc: 0.5)
[2025-01-30 02:11:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3518/107898 [19:08<9:49:38,  2.95it/s] [2025-01-30 02:11:18][root][INFO] - Training Epoch: 1/2, step 3517/107898 completed (loss: 0.0062395790591835976, acc: 1.0)
[2025-01-30 02:11:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3519/107898 [19:08<9:59:47,  2.90it/s][2025-01-30 02:11:18][root][INFO] - Training Epoch: 1/2, step 3518/107898 completed (loss: 0.6685194969177246, acc: 0.75)
[2025-01-30 02:11:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3520/107898 [19:09<9:46:46,  2.96it/s][2025-01-30 02:11:18][root][INFO] - Training Epoch: 1/2, step 3519/107898 completed (loss: 0.003114613937214017, acc: 1.0)
[2025-01-30 02:11:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3521/107898 [19:09<9:38:00,  3.01it/s][2025-01-30 02:11:19][root][INFO] - Training Epoch: 1/2, step 3520/107898 completed (loss: 0.2724703848361969, acc: 0.9090909361839294)
[2025-01-30 02:11:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3522/107898 [19:09<9:29:53,  3.05it/s][2025-01-30 02:11:19][root][INFO] - Training Epoch: 1/2, step 3521/107898 completed (loss: 1.2327805757522583, acc: 0.7083333134651184)
[2025-01-30 02:11:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3523/107898 [19:09<9:38:38,  3.01it/s][2025-01-30 02:11:19][root][INFO] - Training Epoch: 1/2, step 3522/107898 completed (loss: 0.06068085879087448, acc: 1.0)
[2025-01-30 02:11:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3524/107898 [19:10<9:36:45,  3.02it/s][2025-01-30 02:11:20][root][INFO] - Training Epoch: 1/2, step 3523/107898 completed (loss: 1.513872504234314, acc: 0.7142857313156128)
[2025-01-30 02:11:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3525/107898 [19:10<9:31:17,  3.04it/s][2025-01-30 02:11:20][root][INFO] - Training Epoch: 1/2, step 3524/107898 completed (loss: 3.957512617111206, acc: 0.4166666567325592)
[2025-01-30 02:11:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3526/107898 [19:10<9:16:46,  3.12it/s][2025-01-30 02:11:20][root][INFO] - Training Epoch: 1/2, step 3525/107898 completed (loss: 1.3534724712371826, acc: 0.800000011920929)
[2025-01-30 02:11:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3527/107898 [19:11<9:06:19,  3.18it/s][2025-01-30 02:11:21][root][INFO] - Training Epoch: 1/2, step 3526/107898 completed (loss: 0.7780138850212097, acc: 0.8571428656578064)
[2025-01-30 02:11:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3528/107898 [19:11<9:17:51,  3.12it/s][2025-01-30 02:11:21][root][INFO] - Training Epoch: 1/2, step 3527/107898 completed (loss: 0.6360561847686768, acc: 0.6666666865348816)
[2025-01-30 02:11:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3529/107898 [19:11<9:37:51,  3.01it/s][2025-01-30 02:11:21][root][INFO] - Training Epoch: 1/2, step 3528/107898 completed (loss: 0.033794041723012924, acc: 1.0)
[2025-01-30 02:11:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3530/107898 [19:12<9:24:39,  3.08it/s][2025-01-30 02:11:22][root][INFO] - Training Epoch: 1/2, step 3529/107898 completed (loss: 0.2746230661869049, acc: 1.0)
[2025-01-30 02:11:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3531/107898 [19:12<9:22:08,  3.09it/s][2025-01-30 02:11:22][root][INFO] - Training Epoch: 1/2, step 3530/107898 completed (loss: 0.24826286733150482, acc: 0.9166666865348816)
[2025-01-30 02:11:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3532/107898 [19:12<9:25:36,  3.08it/s][2025-01-30 02:11:22][root][INFO] - Training Epoch: 1/2, step 3531/107898 completed (loss: 3.187770366668701, acc: 0.43478259444236755)
[2025-01-30 02:11:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3533/107898 [19:13<9:31:59,  3.04it/s][2025-01-30 02:11:23][root][INFO] - Training Epoch: 1/2, step 3532/107898 completed (loss: 1.962408185005188, acc: 0.7142857313156128)
[2025-01-30 02:11:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3534/107898 [19:13<9:24:13,  3.08it/s][2025-01-30 02:11:23][root][INFO] - Training Epoch: 1/2, step 3533/107898 completed (loss: 0.030460219830274582, acc: 1.0)
[2025-01-30 02:11:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3535/107898 [19:13<9:18:02,  3.12it/s][2025-01-30 02:11:23][root][INFO] - Training Epoch: 1/2, step 3534/107898 completed (loss: 0.0550190731883049, acc: 1.0)
[2025-01-30 02:11:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3536/107898 [19:14<9:05:55,  3.19it/s][2025-01-30 02:11:23][root][INFO] - Training Epoch: 1/2, step 3535/107898 completed (loss: 0.12857544422149658, acc: 0.875)
[2025-01-30 02:11:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3537/107898 [19:14<8:58:26,  3.23it/s][2025-01-30 02:11:24][root][INFO] - Training Epoch: 1/2, step 3536/107898 completed (loss: 1.2620539665222168, acc: 0.800000011920929)
[2025-01-30 02:11:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3538/107898 [19:14<9:02:33,  3.21it/s][2025-01-30 02:11:24][root][INFO] - Training Epoch: 1/2, step 3537/107898 completed (loss: 1.208478569984436, acc: 0.7692307829856873)
[2025-01-30 02:11:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3539/107898 [19:15<8:34:00,  3.38it/s][2025-01-30 02:11:24][root][INFO] - Training Epoch: 1/2, step 3538/107898 completed (loss: 0.3799234628677368, acc: 0.8461538553237915)
[2025-01-30 02:11:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3540/107898 [19:15<8:57:54,  3.23it/s][2025-01-30 02:11:25][root][INFO] - Training Epoch: 1/2, step 3539/107898 completed (loss: 1.303773283958435, acc: 0.6666666865348816)
[2025-01-30 02:11:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3541/107898 [19:15<9:27:18,  3.07it/s][2025-01-30 02:11:25][root][INFO] - Training Epoch: 1/2, step 3540/107898 completed (loss: 0.3773611783981323, acc: 0.800000011920929)
[2025-01-30 02:11:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3542/107898 [19:16<9:23:03,  3.09it/s][2025-01-30 02:11:25][root][INFO] - Training Epoch: 1/2, step 3541/107898 completed (loss: 1.0941120386123657, acc: 0.761904776096344)
[2025-01-30 02:11:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3543/107898 [19:16<9:17:09,  3.12it/s][2025-01-30 02:11:26][root][INFO] - Training Epoch: 1/2, step 3542/107898 completed (loss: 2.218438148498535, acc: 0.46666666865348816)
[2025-01-30 02:11:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3544/107898 [19:16<9:03:03,  3.20it/s][2025-01-30 02:11:26][root][INFO] - Training Epoch: 1/2, step 3543/107898 completed (loss: 5.591566562652588, acc: 0.20000000298023224)
[2025-01-30 02:11:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3545/107898 [19:16<8:55:13,  3.25it/s][2025-01-30 02:11:26][root][INFO] - Training Epoch: 1/2, step 3544/107898 completed (loss: 3.688807725906372, acc: 0.3333333432674408)
[2025-01-30 02:11:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3546/107898 [19:17<8:49:02,  3.29it/s][2025-01-30 02:11:27][root][INFO] - Training Epoch: 1/2, step 3545/107898 completed (loss: 0.7054757475852966, acc: 0.6666666865348816)
[2025-01-30 02:11:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3547/107898 [19:17<8:44:14,  3.32it/s][2025-01-30 02:11:27][root][INFO] - Training Epoch: 1/2, step 3546/107898 completed (loss: 2.35076904296875, acc: 0.5454545617103577)
[2025-01-30 02:11:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3548/107898 [19:17<8:39:41,  3.35it/s][2025-01-30 02:11:27][root][INFO] - Training Epoch: 1/2, step 3547/107898 completed (loss: 1.1657534837722778, acc: 0.7647058963775635)
[2025-01-30 02:11:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3549/107898 [19:18<8:39:42,  3.35it/s][2025-01-30 02:11:27][root][INFO] - Training Epoch: 1/2, step 3548/107898 completed (loss: 1.430780053138733, acc: 0.6666666865348816)
[2025-01-30 02:11:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3550/107898 [19:18<8:42:55,  3.33it/s][2025-01-30 02:11:28][root][INFO] - Training Epoch: 1/2, step 3549/107898 completed (loss: 0.7075180411338806, acc: 0.8461538553237915)
[2025-01-30 02:11:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3551/107898 [19:18<9:15:01,  3.13it/s][2025-01-30 02:11:28][root][INFO] - Training Epoch: 1/2, step 3550/107898 completed (loss: 1.7791022062301636, acc: 0.5625)
[2025-01-30 02:11:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3552/107898 [19:19<9:20:32,  3.10it/s][2025-01-30 02:11:28][root][INFO] - Training Epoch: 1/2, step 3551/107898 completed (loss: 0.0023162930738180876, acc: 1.0)
[2025-01-30 02:11:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3553/107898 [19:19<9:37:37,  3.01it/s][2025-01-30 02:11:29][root][INFO] - Training Epoch: 1/2, step 3552/107898 completed (loss: 0.8173992037773132, acc: 0.7142857313156128)
[2025-01-30 02:11:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3554/107898 [19:19<9:38:21,  3.01it/s][2025-01-30 02:11:29][root][INFO] - Training Epoch: 1/2, step 3553/107898 completed (loss: 0.5205991864204407, acc: 0.8571428656578064)
[2025-01-30 02:11:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3555/107898 [19:20<9:14:45,  3.13it/s][2025-01-30 02:11:29][root][INFO] - Training Epoch: 1/2, step 3554/107898 completed (loss: 2.0222725868225098, acc: 0.4444444477558136)
[2025-01-30 02:11:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3556/107898 [19:20<9:07:42,  3.18it/s][2025-01-30 02:11:30][root][INFO] - Training Epoch: 1/2, step 3555/107898 completed (loss: 1.3125511407852173, acc: 0.75)
[2025-01-30 02:11:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3557/107898 [19:20<8:57:33,  3.24it/s][2025-01-30 02:11:30][root][INFO] - Training Epoch: 1/2, step 3556/107898 completed (loss: 0.9224234819412231, acc: 0.7692307829856873)
[2025-01-30 02:11:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3558/107898 [19:21<9:15:12,  3.13it/s][2025-01-30 02:11:30][root][INFO] - Training Epoch: 1/2, step 3557/107898 completed (loss: 0.8958549499511719, acc: 0.807692289352417)
[2025-01-30 02:11:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3559/107898 [19:21<9:08:18,  3.17it/s][2025-01-30 02:11:31][root][INFO] - Training Epoch: 1/2, step 3558/107898 completed (loss: 0.2154785543680191, acc: 1.0)
[2025-01-30 02:11:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3560/107898 [19:21<8:57:31,  3.24it/s][2025-01-30 02:11:31][root][INFO] - Training Epoch: 1/2, step 3559/107898 completed (loss: 0.006368137896060944, acc: 1.0)
[2025-01-30 02:11:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3561/107898 [19:21<8:53:21,  3.26it/s][2025-01-30 02:11:31][root][INFO] - Training Epoch: 1/2, step 3560/107898 completed (loss: 0.4813211262226105, acc: 0.9375)
[2025-01-30 02:11:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3562/107898 [19:22<8:54:58,  3.25it/s][2025-01-30 02:11:32][root][INFO] - Training Epoch: 1/2, step 3561/107898 completed (loss: 0.03126423805952072, acc: 1.0)
[2025-01-30 02:11:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3563/107898 [19:22<8:56:07,  3.24it/s][2025-01-30 02:11:32][root][INFO] - Training Epoch: 1/2, step 3562/107898 completed (loss: 1.5515226125717163, acc: 0.5)
[2025-01-30 02:11:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3564/107898 [19:22<8:57:48,  3.23it/s][2025-01-30 02:11:32][root][INFO] - Training Epoch: 1/2, step 3563/107898 completed (loss: 0.5846551656723022, acc: 0.9375)
[2025-01-30 02:11:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3565/107898 [19:23<9:21:28,  3.10it/s][2025-01-30 02:11:33][root][INFO] - Training Epoch: 1/2, step 3564/107898 completed (loss: 0.41339555382728577, acc: 0.8888888955116272)
[2025-01-30 02:11:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3566/107898 [19:23<9:27:03,  3.07it/s][2025-01-30 02:11:33][root][INFO] - Training Epoch: 1/2, step 3565/107898 completed (loss: 1.7581533193588257, acc: 0.5)
[2025-01-30 02:11:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3567/107898 [19:23<9:22:41,  3.09it/s][2025-01-30 02:11:33][root][INFO] - Training Epoch: 1/2, step 3566/107898 completed (loss: 0.16842572391033173, acc: 1.0)
[2025-01-30 02:11:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3568/107898 [19:24<9:40:39,  2.99it/s][2025-01-30 02:11:34][root][INFO] - Training Epoch: 1/2, step 3567/107898 completed (loss: 1.7843468189239502, acc: 0.7692307829856873)
[2025-01-30 02:11:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3569/107898 [19:24<9:53:28,  2.93it/s][2025-01-30 02:11:34][root][INFO] - Training Epoch: 1/2, step 3568/107898 completed (loss: 4.706801414489746, acc: 0.2222222238779068)
[2025-01-30 02:11:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3570/107898 [19:24<9:52:49,  2.93it/s][2025-01-30 02:11:34][root][INFO] - Training Epoch: 1/2, step 3569/107898 completed (loss: 0.6970090270042419, acc: 0.9090909361839294)
[2025-01-30 02:11:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3571/107898 [19:25<9:47:51,  2.96it/s][2025-01-30 02:11:35][root][INFO] - Training Epoch: 1/2, step 3570/107898 completed (loss: 0.041044339537620544, acc: 1.0)
[2025-01-30 02:11:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3572/107898 [19:25<9:49:21,  2.95it/s][2025-01-30 02:11:35][root][INFO] - Training Epoch: 1/2, step 3571/107898 completed (loss: 0.24730119109153748, acc: 1.0)
[2025-01-30 02:11:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3573/107898 [19:25<9:46:02,  2.97it/s][2025-01-30 02:11:35][root][INFO] - Training Epoch: 1/2, step 3572/107898 completed (loss: 0.4728837311267853, acc: 1.0)
[2025-01-30 02:11:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3574/107898 [19:26<9:34:15,  3.03it/s][2025-01-30 02:11:36][root][INFO] - Training Epoch: 1/2, step 3573/107898 completed (loss: 0.3882943093776703, acc: 0.8333333134651184)
[2025-01-30 02:11:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3575/107898 [19:26<9:48:50,  2.95it/s][2025-01-30 02:11:36][root][INFO] - Training Epoch: 1/2, step 3574/107898 completed (loss: 0.012330511584877968, acc: 1.0)
[2025-01-30 02:11:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3576/107898 [19:26<9:35:25,  3.02it/s][2025-01-30 02:11:36][root][INFO] - Training Epoch: 1/2, step 3575/107898 completed (loss: 0.028543278574943542, acc: 1.0)
[2025-01-30 02:11:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3577/107898 [19:27<9:44:44,  2.97it/s][2025-01-30 02:11:37][root][INFO] - Training Epoch: 1/2, step 3576/107898 completed (loss: 0.014657814055681229, acc: 1.0)
[2025-01-30 02:11:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3578/107898 [19:27<9:37:48,  3.01it/s][2025-01-30 02:11:37][root][INFO] - Training Epoch: 1/2, step 3577/107898 completed (loss: 0.5996072888374329, acc: 0.6666666865348816)
[2025-01-30 02:11:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3579/107898 [19:27<9:28:23,  3.06it/s][2025-01-30 02:11:37][root][INFO] - Training Epoch: 1/2, step 3578/107898 completed (loss: 1.5261634588241577, acc: 0.75)
[2025-01-30 02:11:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3580/107898 [19:28<9:25:19,  3.08it/s][2025-01-30 02:11:38][root][INFO] - Training Epoch: 1/2, step 3579/107898 completed (loss: 0.7290589809417725, acc: 0.800000011920929)
[2025-01-30 02:11:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3581/107898 [19:28<9:14:31,  3.14it/s][2025-01-30 02:11:38][root][INFO] - Training Epoch: 1/2, step 3580/107898 completed (loss: 0.3048350214958191, acc: 1.0)
[2025-01-30 02:11:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3582/107898 [19:28<9:07:07,  3.18it/s][2025-01-30 02:11:38][root][INFO] - Training Epoch: 1/2, step 3581/107898 completed (loss: 0.6790943145751953, acc: 0.8888888955116272)
[2025-01-30 02:11:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3583/107898 [19:29<9:16:49,  3.12it/s][2025-01-30 02:11:38][root][INFO] - Training Epoch: 1/2, step 3582/107898 completed (loss: 1.366176962852478, acc: 0.75)
[2025-01-30 02:11:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3584/107898 [19:29<9:36:41,  3.01it/s][2025-01-30 02:11:39][root][INFO] - Training Epoch: 1/2, step 3583/107898 completed (loss: 3.957710027694702, acc: 0.0)
[2025-01-30 02:11:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3585/107898 [19:29<9:38:42,  3.00it/s][2025-01-30 02:11:39][root][INFO] - Training Epoch: 1/2, step 3584/107898 completed (loss: 0.911274254322052, acc: 0.6666666865348816)
[2025-01-30 02:11:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3586/107898 [19:30<10:05:57,  2.87it/s][2025-01-30 02:11:40][root][INFO] - Training Epoch: 1/2, step 3585/107898 completed (loss: 4.448108196258545, acc: 0.25806450843811035)
[2025-01-30 02:11:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3587/107898 [19:30<9:58:45,  2.90it/s] [2025-01-30 02:11:40][root][INFO] - Training Epoch: 1/2, step 3586/107898 completed (loss: 0.0015250082360580564, acc: 1.0)
[2025-01-30 02:11:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3588/107898 [19:30<10:02:32,  2.89it/s][2025-01-30 02:11:40][root][INFO] - Training Epoch: 1/2, step 3587/107898 completed (loss: 0.9091349840164185, acc: 0.8888888955116272)
[2025-01-30 02:11:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3589/107898 [19:31<9:57:53,  2.91it/s] [2025-01-30 02:11:41][root][INFO] - Training Epoch: 1/2, step 3588/107898 completed (loss: 0.2006397843360901, acc: 0.9411764740943909)
[2025-01-30 02:11:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3590/107898 [19:31<10:11:20,  2.84it/s][2025-01-30 02:11:41][root][INFO] - Training Epoch: 1/2, step 3589/107898 completed (loss: 2.0305721759796143, acc: 0.5)
[2025-01-30 02:11:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3591/107898 [19:32<10:10:25,  2.85it/s][2025-01-30 02:11:41][root][INFO] - Training Epoch: 1/2, step 3590/107898 completed (loss: 2.9478964805603027, acc: 0.3333333432674408)
[2025-01-30 02:11:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3592/107898 [19:32<10:05:05,  2.87it/s][2025-01-30 02:11:42][root][INFO] - Training Epoch: 1/2, step 3591/107898 completed (loss: 0.1117052361369133, acc: 1.0)
[2025-01-30 02:11:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3593/107898 [19:32<9:50:42,  2.94it/s] [2025-01-30 02:11:42][root][INFO] - Training Epoch: 1/2, step 3592/107898 completed (loss: 1.713591456413269, acc: 0.7333333492279053)
[2025-01-30 02:11:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3594/107898 [19:32<9:33:25,  3.03it/s][2025-01-30 02:11:42][root][INFO] - Training Epoch: 1/2, step 3593/107898 completed (loss: 0.005837146192789078, acc: 1.0)
[2025-01-30 02:11:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3595/107898 [19:33<9:15:34,  3.13it/s][2025-01-30 02:11:43][root][INFO] - Training Epoch: 1/2, step 3594/107898 completed (loss: 0.0023027367424219847, acc: 1.0)
[2025-01-30 02:11:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3596/107898 [19:33<9:22:49,  3.09it/s][2025-01-30 02:11:43][root][INFO] - Training Epoch: 1/2, step 3595/107898 completed (loss: 0.9009546041488647, acc: 0.75)
[2025-01-30 02:11:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3597/107898 [19:33<9:30:23,  3.05it/s][2025-01-30 02:11:43][root][INFO] - Training Epoch: 1/2, step 3596/107898 completed (loss: 0.09591380506753922, acc: 1.0)
[2025-01-30 02:11:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3598/107898 [19:34<9:24:57,  3.08it/s][2025-01-30 02:11:44][root][INFO] - Training Epoch: 1/2, step 3597/107898 completed (loss: 1.0319316387176514, acc: 0.800000011920929)
[2025-01-30 02:11:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3599/107898 [19:34<9:07:35,  3.17it/s][2025-01-30 02:11:44][root][INFO] - Training Epoch: 1/2, step 3598/107898 completed (loss: 0.05360082909464836, acc: 1.0)
[2025-01-30 02:11:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3600/107898 [19:34<9:06:43,  3.18it/s][2025-01-30 02:11:44][root][INFO] - Training Epoch: 1/2, step 3599/107898 completed (loss: 1.224111557006836, acc: 0.800000011920929)
[2025-01-30 02:11:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3601/107898 [19:35<8:59:15,  3.22it/s][2025-01-30 02:11:44][root][INFO] - Training Epoch: 1/2, step 3600/107898 completed (loss: 0.5405829548835754, acc: 0.8333333134651184)
[2025-01-30 02:11:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3602/107898 [19:35<8:52:34,  3.26it/s][2025-01-30 02:11:45][root][INFO] - Training Epoch: 1/2, step 3601/107898 completed (loss: 0.04506656154990196, acc: 1.0)
[2025-01-30 02:11:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3603/107898 [19:35<8:57:52,  3.23it/s][2025-01-30 02:11:45][root][INFO] - Training Epoch: 1/2, step 3602/107898 completed (loss: 2.8780007362365723, acc: 0.5714285969734192)
[2025-01-30 02:11:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3604/107898 [19:36<8:46:40,  3.30it/s][2025-01-30 02:11:45][root][INFO] - Training Epoch: 1/2, step 3603/107898 completed (loss: 2.8569228649139404, acc: 0.6000000238418579)
[2025-01-30 02:11:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3605/107898 [19:36<9:08:42,  3.17it/s][2025-01-30 02:11:46][root][INFO] - Training Epoch: 1/2, step 3604/107898 completed (loss: 1.5477427244186401, acc: 0.529411792755127)
[2025-01-30 02:11:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3606/107898 [19:36<9:19:10,  3.11it/s][2025-01-30 02:11:46][root][INFO] - Training Epoch: 1/2, step 3605/107898 completed (loss: 2.510507583618164, acc: 0.375)
[2025-01-30 02:11:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3607/107898 [19:37<9:43:43,  2.98it/s][2025-01-30 02:11:46][root][INFO] - Training Epoch: 1/2, step 3606/107898 completed (loss: 0.7155943512916565, acc: 0.8571428656578064)
[2025-01-30 02:11:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3608/107898 [19:37<10:01:07,  2.89it/s][2025-01-30 02:11:47][root][INFO] - Training Epoch: 1/2, step 3607/107898 completed (loss: 1.1423701047897339, acc: 0.6363636255264282)
[2025-01-30 02:11:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3609/107898 [19:37<9:46:38,  2.96it/s] [2025-01-30 02:11:47][root][INFO] - Training Epoch: 1/2, step 3608/107898 completed (loss: 1.9856361150741577, acc: 0.800000011920929)
[2025-01-30 02:11:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3610/107898 [19:38<9:28:36,  3.06it/s][2025-01-30 02:11:47][root][INFO] - Training Epoch: 1/2, step 3609/107898 completed (loss: 1.4014545679092407, acc: 0.5)
[2025-01-30 02:11:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3611/107898 [19:38<9:44:11,  2.98it/s][2025-01-30 02:11:48][root][INFO] - Training Epoch: 1/2, step 3610/107898 completed (loss: 0.06781331449747086, acc: 1.0)
[2025-01-30 02:11:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3612/107898 [19:38<9:57:17,  2.91it/s][2025-01-30 02:11:48][root][INFO] - Training Epoch: 1/2, step 3611/107898 completed (loss: 0.14698781073093414, acc: 1.0)
[2025-01-30 02:11:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3613/107898 [19:39<9:52:31,  2.93it/s][2025-01-30 02:11:48][root][INFO] - Training Epoch: 1/2, step 3612/107898 completed (loss: 0.1548413187265396, acc: 1.0)
[2025-01-30 02:11:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3614/107898 [19:39<9:44:10,  2.98it/s][2025-01-30 02:11:49][root][INFO] - Training Epoch: 1/2, step 3613/107898 completed (loss: 0.0017077081138268113, acc: 1.0)
[2025-01-30 02:11:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3615/107898 [19:39<9:24:23,  3.08it/s][2025-01-30 02:11:49][root][INFO] - Training Epoch: 1/2, step 3614/107898 completed (loss: 3.7849912643432617, acc: 0.4545454680919647)
[2025-01-30 02:11:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3616/107898 [19:40<9:35:55,  3.02it/s][2025-01-30 02:11:49][root][INFO] - Training Epoch: 1/2, step 3615/107898 completed (loss: 0.2684139907360077, acc: 1.0)
[2025-01-30 02:11:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3617/107898 [19:40<9:33:48,  3.03it/s][2025-01-30 02:11:50][root][INFO] - Training Epoch: 1/2, step 3616/107898 completed (loss: 3.7419230937957764, acc: 0.3333333432674408)
[2025-01-30 02:11:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3618/107898 [19:40<9:17:06,  3.12it/s][2025-01-30 02:11:50][root][INFO] - Training Epoch: 1/2, step 3617/107898 completed (loss: 0.36100566387176514, acc: 0.9230769276618958)
[2025-01-30 02:11:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3619/107898 [19:41<9:09:55,  3.16it/s][2025-01-30 02:11:50][root][INFO] - Training Epoch: 1/2, step 3618/107898 completed (loss: 0.060250770300626755, acc: 1.0)
[2025-01-30 02:11:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3620/107898 [19:41<9:04:01,  3.19it/s][2025-01-30 02:11:51][root][INFO] - Training Epoch: 1/2, step 3619/107898 completed (loss: 2.394996166229248, acc: 0.6896551847457886)
[2025-01-30 02:11:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3621/107898 [19:41<8:52:04,  3.27it/s][2025-01-30 02:11:51][root][INFO] - Training Epoch: 1/2, step 3620/107898 completed (loss: 0.004110053181648254, acc: 1.0)
[2025-01-30 02:11:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3622/107898 [19:41<8:58:34,  3.23it/s][2025-01-30 02:11:51][root][INFO] - Training Epoch: 1/2, step 3621/107898 completed (loss: 0.31615281105041504, acc: 1.0)
[2025-01-30 02:11:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3623/107898 [19:42<9:15:01,  3.13it/s][2025-01-30 02:11:52][root][INFO] - Training Epoch: 1/2, step 3622/107898 completed (loss: 0.004067522939294577, acc: 1.0)
[2025-01-30 02:11:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3624/107898 [19:42<9:10:39,  3.16it/s][2025-01-30 02:11:52][root][INFO] - Training Epoch: 1/2, step 3623/107898 completed (loss: 2.031816005706787, acc: 0.5)
[2025-01-30 02:11:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3625/107898 [19:42<9:28:32,  3.06it/s][2025-01-30 02:11:52][root][INFO] - Training Epoch: 1/2, step 3624/107898 completed (loss: 0.2091708779335022, acc: 1.0)
[2025-01-30 02:11:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3626/107898 [19:43<9:40:29,  2.99it/s][2025-01-30 02:11:53][root][INFO] - Training Epoch: 1/2, step 3625/107898 completed (loss: 0.31561532616615295, acc: 0.9333333373069763)
[2025-01-30 02:11:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3627/107898 [19:43<9:50:58,  2.94it/s][2025-01-30 02:11:53][root][INFO] - Training Epoch: 1/2, step 3626/107898 completed (loss: 1.2969067096710205, acc: 0.800000011920929)
[2025-01-30 02:11:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3628/107898 [19:44<9:54:55,  2.92it/s][2025-01-30 02:11:53][root][INFO] - Training Epoch: 1/2, step 3627/107898 completed (loss: 0.008581466041505337, acc: 1.0)
[2025-01-30 02:11:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3629/107898 [19:44<9:50:11,  2.94it/s][2025-01-30 02:11:54][root][INFO] - Training Epoch: 1/2, step 3628/107898 completed (loss: 0.7824137806892395, acc: 0.8888888955116272)
[2025-01-30 02:11:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3630/107898 [19:44<9:50:33,  2.94it/s][2025-01-30 02:11:54][root][INFO] - Training Epoch: 1/2, step 3629/107898 completed (loss: 1.6197103261947632, acc: 0.6428571343421936)
[2025-01-30 02:11:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3631/107898 [19:45<10:05:53,  2.87it/s][2025-01-30 02:11:54][root][INFO] - Training Epoch: 1/2, step 3630/107898 completed (loss: 1.1879504919052124, acc: 0.7599999904632568)
[2025-01-30 02:11:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3632/107898 [19:45<9:52:17,  2.93it/s] [2025-01-30 02:11:55][root][INFO] - Training Epoch: 1/2, step 3631/107898 completed (loss: 0.7655726671218872, acc: 0.8571428656578064)
[2025-01-30 02:11:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3633/107898 [19:45<9:46:44,  2.96it/s][2025-01-30 02:11:55][root][INFO] - Training Epoch: 1/2, step 3632/107898 completed (loss: 1.133307695388794, acc: 0.7894737124443054)
[2025-01-30 02:11:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3634/107898 [19:46<9:34:40,  3.02it/s][2025-01-30 02:11:55][root][INFO] - Training Epoch: 1/2, step 3633/107898 completed (loss: 0.22176876664161682, acc: 1.0)
[2025-01-30 02:11:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3635/107898 [19:46<9:22:54,  3.09it/s][2025-01-30 02:11:56][root][INFO] - Training Epoch: 1/2, step 3634/107898 completed (loss: 0.6950376033782959, acc: 0.5)
[2025-01-30 02:11:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3636/107898 [19:46<9:10:41,  3.16it/s][2025-01-30 02:11:56][root][INFO] - Training Epoch: 1/2, step 3635/107898 completed (loss: 0.54334557056427, acc: 0.8461538553237915)
[2025-01-30 02:11:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3637/107898 [19:46<9:06:49,  3.18it/s][2025-01-30 02:11:56][root][INFO] - Training Epoch: 1/2, step 3636/107898 completed (loss: 5.17519998550415, acc: 0.20000000298023224)
[2025-01-30 02:11:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3638/107898 [19:47<8:54:05,  3.25it/s][2025-01-30 02:11:57][root][INFO] - Training Epoch: 1/2, step 3637/107898 completed (loss: 1.2549031972885132, acc: 0.75)
[2025-01-30 02:11:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3639/107898 [19:47<8:46:09,  3.30it/s][2025-01-30 02:11:57][root][INFO] - Training Epoch: 1/2, step 3638/107898 completed (loss: 0.015460082329809666, acc: 1.0)
[2025-01-30 02:11:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3640/107898 [19:47<9:14:18,  3.13it/s][2025-01-30 02:11:57][root][INFO] - Training Epoch: 1/2, step 3639/107898 completed (loss: 3.293562412261963, acc: 0.4000000059604645)
[2025-01-30 02:11:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3641/107898 [19:48<9:30:36,  3.05it/s][2025-01-30 02:11:58][root][INFO] - Training Epoch: 1/2, step 3640/107898 completed (loss: 0.35171207785606384, acc: 0.939393937587738)
[2025-01-30 02:11:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3642/107898 [19:48<9:27:35,  3.06it/s][2025-01-30 02:11:58][root][INFO] - Training Epoch: 1/2, step 3641/107898 completed (loss: 1.73081374168396, acc: 0.739130437374115)
[2025-01-30 02:11:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3643/107898 [19:48<9:24:33,  3.08it/s][2025-01-30 02:11:58][root][INFO] - Training Epoch: 1/2, step 3642/107898 completed (loss: 0.009729237295687199, acc: 1.0)
[2025-01-30 02:11:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3644/107898 [19:49<9:27:26,  3.06it/s][2025-01-30 02:11:59][root][INFO] - Training Epoch: 1/2, step 3643/107898 completed (loss: 4.28223991394043, acc: 0.3333333432674408)
[2025-01-30 02:11:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3645/107898 [19:49<9:14:42,  3.13it/s][2025-01-30 02:11:59][root][INFO] - Training Epoch: 1/2, step 3644/107898 completed (loss: 0.5798109769821167, acc: 0.875)
[2025-01-30 02:11:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3646/107898 [19:49<9:31:15,  3.04it/s][2025-01-30 02:11:59][root][INFO] - Training Epoch: 1/2, step 3645/107898 completed (loss: 0.1392521858215332, acc: 1.0)
[2025-01-30 02:11:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3647/107898 [19:50<9:35:23,  3.02it/s][2025-01-30 02:12:00][root][INFO] - Training Epoch: 1/2, step 3646/107898 completed (loss: 1.2236523628234863, acc: 0.8461538553237915)
[2025-01-30 02:12:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3648/107898 [19:50<9:33:51,  3.03it/s][2025-01-30 02:12:00][root][INFO] - Training Epoch: 1/2, step 3647/107898 completed (loss: 0.8811582326889038, acc: 0.8235294222831726)
[2025-01-30 02:12:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3649/107898 [19:50<9:10:22,  3.16it/s][2025-01-30 02:12:00][root][INFO] - Training Epoch: 1/2, step 3648/107898 completed (loss: 2.4910190105438232, acc: 0.6363636255264282)
[2025-01-30 02:12:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3650/107898 [19:51<9:04:45,  3.19it/s][2025-01-30 02:12:00][root][INFO] - Training Epoch: 1/2, step 3649/107898 completed (loss: 1.2476977109909058, acc: 0.8333333134651184)
[2025-01-30 02:12:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3651/107898 [19:51<9:20:49,  3.10it/s][2025-01-30 02:12:01][root][INFO] - Training Epoch: 1/2, step 3650/107898 completed (loss: 0.39320752024650574, acc: 1.0)
[2025-01-30 02:12:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3652/107898 [19:51<9:24:21,  3.08it/s][2025-01-30 02:12:01][root][INFO] - Training Epoch: 1/2, step 3651/107898 completed (loss: 0.010646672919392586, acc: 1.0)
[2025-01-30 02:12:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3653/107898 [19:52<9:25:50,  3.07it/s][2025-01-30 02:12:01][root][INFO] - Training Epoch: 1/2, step 3652/107898 completed (loss: 0.03572472557425499, acc: 1.0)
[2025-01-30 02:12:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3654/107898 [19:52<9:46:03,  2.96it/s][2025-01-30 02:12:02][root][INFO] - Training Epoch: 1/2, step 3653/107898 completed (loss: 1.307775855064392, acc: 0.7083333134651184)
[2025-01-30 02:12:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3655/107898 [19:52<9:32:13,  3.04it/s][2025-01-30 02:12:02][root][INFO] - Training Epoch: 1/2, step 3654/107898 completed (loss: 1.6071332693099976, acc: 0.7058823704719543)
[2025-01-30 02:12:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3656/107898 [19:53<9:18:26,  3.11it/s][2025-01-30 02:12:02][root][INFO] - Training Epoch: 1/2, step 3655/107898 completed (loss: 0.3790237009525299, acc: 0.9047619104385376)
[2025-01-30 02:12:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3657/107898 [19:53<9:09:33,  3.16it/s][2025-01-30 02:12:03][root][INFO] - Training Epoch: 1/2, step 3656/107898 completed (loss: 1.220132827758789, acc: 0.8571428656578064)
[2025-01-30 02:12:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3658/107898 [19:53<8:58:54,  3.22it/s][2025-01-30 02:12:03][root][INFO] - Training Epoch: 1/2, step 3657/107898 completed (loss: 3.287980794906616, acc: 0.3571428656578064)
[2025-01-30 02:12:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3659/107898 [19:54<8:50:25,  3.28it/s][2025-01-30 02:12:03][root][INFO] - Training Epoch: 1/2, step 3658/107898 completed (loss: 2.6827244758605957, acc: 0.2857142984867096)
[2025-01-30 02:12:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3660/107898 [19:54<9:15:32,  3.13it/s][2025-01-30 02:12:04][root][INFO] - Training Epoch: 1/2, step 3659/107898 completed (loss: 0.38189250230789185, acc: 0.8823529481887817)
[2025-01-30 02:12:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3661/107898 [19:54<9:18:19,  3.11it/s][2025-01-30 02:12:04][root][INFO] - Training Epoch: 1/2, step 3660/107898 completed (loss: 0.08289019018411636, acc: 1.0)
[2025-01-30 02:12:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3662/107898 [19:54<9:04:04,  3.19it/s][2025-01-30 02:12:04][root][INFO] - Training Epoch: 1/2, step 3661/107898 completed (loss: 0.741244375705719, acc: 0.9090909361839294)
[2025-01-30 02:12:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3663/107898 [19:55<8:56:23,  3.24it/s][2025-01-30 02:12:05][root][INFO] - Training Epoch: 1/2, step 3662/107898 completed (loss: 2.2668752670288086, acc: 0.0)
[2025-01-30 02:12:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3664/107898 [19:55<8:59:13,  3.22it/s][2025-01-30 02:12:05][root][INFO] - Training Epoch: 1/2, step 3663/107898 completed (loss: 1.1939901113510132, acc: 0.75)
[2025-01-30 02:12:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3665/107898 [19:55<9:02:00,  3.21it/s][2025-01-30 02:12:05][root][INFO] - Training Epoch: 1/2, step 3664/107898 completed (loss: 1.7170354127883911, acc: 0.692307710647583)
[2025-01-30 02:12:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3666/107898 [19:56<9:01:27,  3.21it/s][2025-01-30 02:12:06][root][INFO] - Training Epoch: 1/2, step 3665/107898 completed (loss: 0.7530955672264099, acc: 0.8571428656578064)
[2025-01-30 02:12:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3667/107898 [19:56<9:11:08,  3.15it/s][2025-01-30 02:12:06][root][INFO] - Training Epoch: 1/2, step 3666/107898 completed (loss: 3.202789306640625, acc: 0.25)
[2025-01-30 02:12:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3668/107898 [19:56<9:01:42,  3.21it/s][2025-01-30 02:12:06][root][INFO] - Training Epoch: 1/2, step 3667/107898 completed (loss: 0.7845892310142517, acc: 0.0)
[2025-01-30 02:12:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3669/107898 [19:57<9:11:05,  3.15it/s][2025-01-30 02:12:06][root][INFO] - Training Epoch: 1/2, step 3668/107898 completed (loss: 1.0224980115890503, acc: 0.7692307829856873)
[2025-01-30 02:12:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3670/107898 [19:57<9:13:21,  3.14it/s][2025-01-30 02:12:07][root][INFO] - Training Epoch: 1/2, step 3669/107898 completed (loss: 0.06664791703224182, acc: 1.0)
[2025-01-30 02:12:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3671/107898 [19:57<9:29:50,  3.05it/s][2025-01-30 02:12:07][root][INFO] - Training Epoch: 1/2, step 3670/107898 completed (loss: 3.6956818103790283, acc: 0.3333333432674408)
[2025-01-30 02:12:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3672/107898 [19:58<9:21:02,  3.10it/s][2025-01-30 02:12:07][root][INFO] - Training Epoch: 1/2, step 3671/107898 completed (loss: 0.12230376899242401, acc: 1.0)
[2025-01-30 02:12:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3673/107898 [19:58<9:15:20,  3.13it/s][2025-01-30 02:12:08][root][INFO] - Training Epoch: 1/2, step 3672/107898 completed (loss: 1.6119171380996704, acc: 0.4285714328289032)
[2025-01-30 02:12:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3674/107898 [19:58<9:08:48,  3.17it/s][2025-01-30 02:12:08][root][INFO] - Training Epoch: 1/2, step 3673/107898 completed (loss: 4.277328014373779, acc: 0.2857142984867096)
[2025-01-30 02:12:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3675/107898 [19:59<9:03:19,  3.20it/s][2025-01-30 02:12:08][root][INFO] - Training Epoch: 1/2, step 3674/107898 completed (loss: 1.5473811626434326, acc: 0.6499999761581421)
[2025-01-30 02:12:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3676/107898 [19:59<8:52:47,  3.26it/s][2025-01-30 02:12:09][root][INFO] - Training Epoch: 1/2, step 3675/107898 completed (loss: 2.5351481437683105, acc: 0.3333333432674408)
[2025-01-30 02:12:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3677/107898 [19:59<8:46:38,  3.30it/s][2025-01-30 02:12:09][root][INFO] - Training Epoch: 1/2, step 3676/107898 completed (loss: 2.1880781650543213, acc: 0.7307692170143127)
[2025-01-30 02:12:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3678/107898 [19:59<8:39:44,  3.34it/s][2025-01-30 02:12:09][root][INFO] - Training Epoch: 1/2, step 3677/107898 completed (loss: 0.0037983092479407787, acc: 1.0)
[2025-01-30 02:12:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3679/107898 [20:00<8:46:50,  3.30it/s][2025-01-30 02:12:10][root][INFO] - Training Epoch: 1/2, step 3678/107898 completed (loss: 0.6870678663253784, acc: 1.0)
[2025-01-30 02:12:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3680/107898 [20:00<8:53:04,  3.26it/s][2025-01-30 02:12:10][root][INFO] - Training Epoch: 1/2, step 3679/107898 completed (loss: 1.3446646928787231, acc: 0.9166666865348816)
[2025-01-30 02:12:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3681/107898 [20:00<8:44:38,  3.31it/s][2025-01-30 02:12:10][root][INFO] - Training Epoch: 1/2, step 3680/107898 completed (loss: 0.5290296077728271, acc: 0.875)
[2025-01-30 02:12:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3682/107898 [20:01<8:45:15,  3.31it/s][2025-01-30 02:12:10][root][INFO] - Training Epoch: 1/2, step 3681/107898 completed (loss: 1.0974763631820679, acc: 0.6666666865348816)
[2025-01-30 02:12:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3683/107898 [20:01<8:40:30,  3.34it/s][2025-01-30 02:12:11][root][INFO] - Training Epoch: 1/2, step 3682/107898 completed (loss: 2.4355616569519043, acc: 0.625)
[2025-01-30 02:12:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3684/107898 [20:01<8:46:15,  3.30it/s][2025-01-30 02:12:11][root][INFO] - Training Epoch: 1/2, step 3683/107898 completed (loss: 1.3271297216415405, acc: 0.6666666865348816)
[2025-01-30 02:12:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3685/107898 [20:02<9:09:07,  3.16it/s][2025-01-30 02:12:11][root][INFO] - Training Epoch: 1/2, step 3684/107898 completed (loss: 1.1791777610778809, acc: 0.8333333134651184)
[2025-01-30 02:12:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3686/107898 [20:02<9:09:28,  3.16it/s][2025-01-30 02:12:12][root][INFO] - Training Epoch: 1/2, step 3685/107898 completed (loss: 4.337613105773926, acc: 0.3333333432674408)
[2025-01-30 02:12:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3687/107898 [20:02<9:23:53,  3.08it/s][2025-01-30 02:12:12][root][INFO] - Training Epoch: 1/2, step 3686/107898 completed (loss: 0.14561787247657776, acc: 1.0)
[2025-01-30 02:12:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3688/107898 [20:03<9:23:45,  3.08it/s][2025-01-30 02:12:12][root][INFO] - Training Epoch: 1/2, step 3687/107898 completed (loss: 1.3868446350097656, acc: 0.6666666865348816)
[2025-01-30 02:12:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3689/107898 [20:03<9:42:57,  2.98it/s][2025-01-30 02:12:13][root][INFO] - Training Epoch: 1/2, step 3688/107898 completed (loss: 0.031856339424848557, acc: 1.0)
[2025-01-30 02:12:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3690/107898 [20:03<9:34:22,  3.02it/s][2025-01-30 02:12:13][root][INFO] - Training Epoch: 1/2, step 3689/107898 completed (loss: 1.530908465385437, acc: 0.8125)
[2025-01-30 02:12:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3691/107898 [20:04<9:49:28,  2.95it/s][2025-01-30 02:12:13][root][INFO] - Training Epoch: 1/2, step 3690/107898 completed (loss: 0.6269311904907227, acc: 0.8947368264198303)
[2025-01-30 02:12:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3692/107898 [20:04<9:43:52,  2.97it/s][2025-01-30 02:12:14][root][INFO] - Training Epoch: 1/2, step 3691/107898 completed (loss: 0.0029536047950387, acc: 1.0)
[2025-01-30 02:12:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3693/107898 [20:04<9:32:48,  3.03it/s][2025-01-30 02:12:14][root][INFO] - Training Epoch: 1/2, step 3692/107898 completed (loss: 0.5887321829795837, acc: 0.800000011920929)
[2025-01-30 02:12:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3694/107898 [20:05<9:33:00,  3.03it/s][2025-01-30 02:12:14][root][INFO] - Training Epoch: 1/2, step 3693/107898 completed (loss: 1.7583221197128296, acc: 0.6000000238418579)
[2025-01-30 02:12:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3695/107898 [20:05<9:29:56,  3.05it/s][2025-01-30 02:12:15][root][INFO] - Training Epoch: 1/2, step 3694/107898 completed (loss: 1.284210443496704, acc: 0.6000000238418579)
[2025-01-30 02:12:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3696/107898 [20:05<9:37:26,  3.01it/s][2025-01-30 02:12:15][root][INFO] - Training Epoch: 1/2, step 3695/107898 completed (loss: 0.026141222566366196, acc: 1.0)
[2025-01-30 02:12:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3697/107898 [20:06<9:37:21,  3.01it/s][2025-01-30 02:12:15][root][INFO] - Training Epoch: 1/2, step 3696/107898 completed (loss: 3.6473796367645264, acc: 0.25)
[2025-01-30 02:12:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3698/107898 [20:06<9:34:10,  3.02it/s][2025-01-30 02:12:16][root][INFO] - Training Epoch: 1/2, step 3697/107898 completed (loss: 0.05695421248674393, acc: 1.0)
[2025-01-30 02:12:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3699/107898 [20:06<9:50:15,  2.94it/s][2025-01-30 02:12:16][root][INFO] - Training Epoch: 1/2, step 3698/107898 completed (loss: 0.6998966932296753, acc: 0.5)
[2025-01-30 02:12:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3700/107898 [20:07<9:47:42,  2.95it/s][2025-01-30 02:12:16][root][INFO] - Training Epoch: 1/2, step 3699/107898 completed (loss: 0.29969531297683716, acc: 0.8999999761581421)
[2025-01-30 02:12:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3701/107898 [20:07<9:43:24,  2.98it/s][2025-01-30 02:12:17][root][INFO] - Training Epoch: 1/2, step 3700/107898 completed (loss: 1.2963632345199585, acc: 0.7142857313156128)
[2025-01-30 02:12:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3702/107898 [20:07<9:50:02,  2.94it/s][2025-01-30 02:12:17][root][INFO] - Training Epoch: 1/2, step 3701/107898 completed (loss: 0.02775546908378601, acc: 1.0)
[2025-01-30 02:12:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3703/107898 [20:08<10:00:15,  2.89it/s][2025-01-30 02:12:17][root][INFO] - Training Epoch: 1/2, step 3702/107898 completed (loss: 3.5991342067718506, acc: 0.4285714328289032)
[2025-01-30 02:12:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3704/107898 [20:08<9:50:13,  2.94it/s] [2025-01-30 02:12:18][root][INFO] - Training Epoch: 1/2, step 3703/107898 completed (loss: 0.46109068393707275, acc: 0.8333333134651184)
[2025-01-30 02:12:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3705/107898 [20:08<9:38:53,  3.00it/s][2025-01-30 02:12:18][root][INFO] - Training Epoch: 1/2, step 3704/107898 completed (loss: 1.0776337385177612, acc: 0.6666666865348816)
[2025-01-30 02:12:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3706/107898 [20:09<9:36:11,  3.01it/s][2025-01-30 02:12:18][root][INFO] - Training Epoch: 1/2, step 3705/107898 completed (loss: 0.3763507306575775, acc: 1.0)
[2025-01-30 02:12:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3707/107898 [20:09<9:32:46,  3.03it/s][2025-01-30 02:12:19][root][INFO] - Training Epoch: 1/2, step 3706/107898 completed (loss: 0.0566629059612751, acc: 1.0)
[2025-01-30 02:12:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3708/107898 [20:09<9:25:41,  3.07it/s][2025-01-30 02:12:19][root][INFO] - Training Epoch: 1/2, step 3707/107898 completed (loss: 0.3115125298500061, acc: 0.9200000166893005)
[2025-01-30 02:12:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3709/107898 [20:10<9:11:26,  3.15it/s][2025-01-30 02:12:19][root][INFO] - Training Epoch: 1/2, step 3708/107898 completed (loss: 0.7602198719978333, acc: 0.75)
[2025-01-30 02:12:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3710/107898 [20:10<9:22:27,  3.09it/s][2025-01-30 02:12:20][root][INFO] - Training Epoch: 1/2, step 3709/107898 completed (loss: 0.0021855635568499565, acc: 1.0)
[2025-01-30 02:12:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3711/107898 [20:10<9:34:00,  3.03it/s][2025-01-30 02:12:20][root][INFO] - Training Epoch: 1/2, step 3710/107898 completed (loss: 1.0434883832931519, acc: 0.8461538553237915)
[2025-01-30 02:12:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3712/107898 [20:11<9:43:39,  2.98it/s][2025-01-30 02:12:20][root][INFO] - Training Epoch: 1/2, step 3711/107898 completed (loss: 0.1922689825296402, acc: 1.0)
[2025-01-30 02:12:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3713/107898 [20:11<9:35:24,  3.02it/s][2025-01-30 02:12:21][root][INFO] - Training Epoch: 1/2, step 3712/107898 completed (loss: 0.00580105185508728, acc: 1.0)
[2025-01-30 02:12:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3714/107898 [20:11<9:36:30,  3.01it/s][2025-01-30 02:12:21][root][INFO] - Training Epoch: 1/2, step 3713/107898 completed (loss: 1.4605697393417358, acc: 0.5)
[2025-01-30 02:12:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3715/107898 [20:12<9:55:03,  2.92it/s][2025-01-30 02:12:21][root][INFO] - Training Epoch: 1/2, step 3714/107898 completed (loss: 0.7872731685638428, acc: 0.7407407164573669)
[2025-01-30 02:12:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3716/107898 [20:12<9:58:59,  2.90it/s][2025-01-30 02:12:22][root][INFO] - Training Epoch: 1/2, step 3715/107898 completed (loss: 0.9398764967918396, acc: 0.8461538553237915)
[2025-01-30 02:12:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3717/107898 [20:12<9:37:35,  3.01it/s][2025-01-30 02:12:22][root][INFO] - Training Epoch: 1/2, step 3716/107898 completed (loss: 0.8799421191215515, acc: 0.5)
[2025-01-30 02:12:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3718/107898 [20:13<9:41:10,  2.99it/s][2025-01-30 02:12:22][root][INFO] - Training Epoch: 1/2, step 3717/107898 completed (loss: 1.2654207944869995, acc: 0.7272727489471436)
[2025-01-30 02:12:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3719/107898 [20:13<9:46:16,  2.96it/s][2025-01-30 02:12:23][root][INFO] - Training Epoch: 1/2, step 3718/107898 completed (loss: 0.10241981595754623, acc: 1.0)
[2025-01-30 02:12:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3720/107898 [20:13<9:56:50,  2.91it/s][2025-01-30 02:12:23][root][INFO] - Training Epoch: 1/2, step 3719/107898 completed (loss: 4.5420331954956055, acc: 0.20000000298023224)
[2025-01-30 02:12:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3721/107898 [20:14<9:48:20,  2.95it/s][2025-01-30 02:12:23][root][INFO] - Training Epoch: 1/2, step 3720/107898 completed (loss: 0.38972437381744385, acc: 0.800000011920929)
[2025-01-30 02:12:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3722/107898 [20:14<9:56:20,  2.91it/s][2025-01-30 02:12:24][root][INFO] - Training Epoch: 1/2, step 3721/107898 completed (loss: 0.5232480764389038, acc: 0.8846153616905212)
[2025-01-30 02:12:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3723/107898 [20:14<9:15:45,  3.12it/s][2025-01-30 02:12:24][root][INFO] - Training Epoch: 1/2, step 3722/107898 completed (loss: 0.1430211067199707, acc: 1.0)
[2025-01-30 02:12:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3724/107898 [20:15<9:19:13,  3.10it/s][2025-01-30 02:12:24][root][INFO] - Training Epoch: 1/2, step 3723/107898 completed (loss: 0.005547716747969389, acc: 1.0)
[2025-01-30 02:12:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3725/107898 [20:15<9:43:28,  2.98it/s][2025-01-30 02:12:25][root][INFO] - Training Epoch: 1/2, step 3724/107898 completed (loss: 0.451265424489975, acc: 1.0)
[2025-01-30 02:12:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3726/107898 [20:15<9:37:25,  3.01it/s][2025-01-30 02:12:25][root][INFO] - Training Epoch: 1/2, step 3725/107898 completed (loss: 0.9306082725524902, acc: 0.75)
[2025-01-30 02:12:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3727/107898 [20:16<9:34:41,  3.02it/s][2025-01-30 02:12:25][root][INFO] - Training Epoch: 1/2, step 3726/107898 completed (loss: 0.7353441715240479, acc: 0.8275862336158752)
[2025-01-30 02:12:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3728/107898 [20:16<9:23:48,  3.08it/s][2025-01-30 02:12:26][root][INFO] - Training Epoch: 1/2, step 3727/107898 completed (loss: 2.2984719276428223, acc: 0.5714285969734192)
[2025-01-30 02:12:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3729/107898 [20:16<9:14:18,  3.13it/s][2025-01-30 02:12:26][root][INFO] - Training Epoch: 1/2, step 3728/107898 completed (loss: 1.2408844232559204, acc: 0.5)
[2025-01-30 02:12:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3730/107898 [20:17<9:31:49,  3.04it/s][2025-01-30 02:12:26][root][INFO] - Training Epoch: 1/2, step 3729/107898 completed (loss: 0.0077273109927773476, acc: 1.0)
[2025-01-30 02:12:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3731/107898 [20:17<9:33:14,  3.03it/s][2025-01-30 02:12:27][root][INFO] - Training Epoch: 1/2, step 3730/107898 completed (loss: 2.639543056488037, acc: 0.5)
[2025-01-30 02:12:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3732/107898 [20:17<9:16:56,  3.12it/s][2025-01-30 02:12:27][root][INFO] - Training Epoch: 1/2, step 3731/107898 completed (loss: 0.995521605014801, acc: 0.8181818127632141)
[2025-01-30 02:12:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3733/107898 [20:18<9:40:49,  2.99it/s][2025-01-30 02:12:27][root][INFO] - Training Epoch: 1/2, step 3732/107898 completed (loss: 4.135350704193115, acc: 0.3333333432674408)
[2025-01-30 02:12:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3734/107898 [20:18<9:44:04,  2.97it/s][2025-01-30 02:12:28][root][INFO] - Training Epoch: 1/2, step 3733/107898 completed (loss: 1.0441838502883911, acc: 0.7272727489471436)
[2025-01-30 02:12:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3735/107898 [20:18<9:30:07,  3.05it/s][2025-01-30 02:12:28][root][INFO] - Training Epoch: 1/2, step 3734/107898 completed (loss: 0.10112476348876953, acc: 1.0)
[2025-01-30 02:12:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3736/107898 [20:19<9:37:50,  3.00it/s][2025-01-30 02:12:28][root][INFO] - Training Epoch: 1/2, step 3735/107898 completed (loss: 3.6790037155151367, acc: 0.20000000298023224)
[2025-01-30 02:12:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3737/107898 [20:19<9:28:02,  3.06it/s][2025-01-30 02:12:29][root][INFO] - Training Epoch: 1/2, step 3736/107898 completed (loss: 0.47643113136291504, acc: 0.8999999761581421)
[2025-01-30 02:12:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3738/107898 [20:19<9:25:04,  3.07it/s][2025-01-30 02:12:29][root][INFO] - Training Epoch: 1/2, step 3737/107898 completed (loss: 0.37493184208869934, acc: 0.7777777910232544)
[2025-01-30 02:12:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3739/107898 [20:20<9:38:06,  3.00it/s][2025-01-30 02:12:29][root][INFO] - Training Epoch: 1/2, step 3738/107898 completed (loss: 1.635903000831604, acc: 0.5925925970077515)
[2025-01-30 02:12:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3740/107898 [20:20<9:51:26,  2.94it/s][2025-01-30 02:12:30][root][INFO] - Training Epoch: 1/2, step 3739/107898 completed (loss: 0.9867542386054993, acc: 0.75)
[2025-01-30 02:12:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3741/107898 [20:20<10:00:58,  2.89it/s][2025-01-30 02:12:30][root][INFO] - Training Epoch: 1/2, step 3740/107898 completed (loss: 0.016824884340167046, acc: 1.0)
[2025-01-30 02:12:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3742/107898 [20:21<9:58:23,  2.90it/s] [2025-01-30 02:12:30][root][INFO] - Training Epoch: 1/2, step 3741/107898 completed (loss: 0.03853413462638855, acc: 1.0)
[2025-01-30 02:12:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3743/107898 [20:21<9:38:41,  3.00it/s][2025-01-30 02:12:31][root][INFO] - Training Epoch: 1/2, step 3742/107898 completed (loss: 1.5100057125091553, acc: 0.692307710647583)
[2025-01-30 02:12:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3744/107898 [20:21<9:30:42,  3.04it/s][2025-01-30 02:12:31][root][INFO] - Training Epoch: 1/2, step 3743/107898 completed (loss: 0.1351146697998047, acc: 1.0)
[2025-01-30 02:12:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3745/107898 [20:22<9:26:56,  3.06it/s][2025-01-30 02:12:31][root][INFO] - Training Epoch: 1/2, step 3744/107898 completed (loss: 1.1014466285705566, acc: 0.8999999761581421)
[2025-01-30 02:12:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3746/107898 [20:22<9:34:21,  3.02it/s][2025-01-30 02:12:32][root][INFO] - Training Epoch: 1/2, step 3745/107898 completed (loss: 0.7719904184341431, acc: 0.8571428656578064)
[2025-01-30 02:12:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3747/107898 [20:22<9:38:16,  3.00it/s][2025-01-30 02:12:32][root][INFO] - Training Epoch: 1/2, step 3746/107898 completed (loss: 0.5825585722923279, acc: 1.0)
[2025-01-30 02:12:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3748/107898 [20:23<9:37:26,  3.01it/s][2025-01-30 02:12:32][root][INFO] - Training Epoch: 1/2, step 3747/107898 completed (loss: 0.29313546419143677, acc: 0.8333333134651184)
[2025-01-30 02:12:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3749/107898 [20:23<9:28:10,  3.06it/s][2025-01-30 02:12:33][root][INFO] - Training Epoch: 1/2, step 3748/107898 completed (loss: 0.9210590720176697, acc: 0.75)
[2025-01-30 02:12:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3750/107898 [20:23<9:33:30,  3.03it/s][2025-01-30 02:12:33][root][INFO] - Training Epoch: 1/2, step 3749/107898 completed (loss: 2.62809419631958, acc: 0.5454545617103577)
[2025-01-30 02:12:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3751/107898 [20:24<9:51:03,  2.94it/s][2025-01-30 02:12:33][root][INFO] - Training Epoch: 1/2, step 3750/107898 completed (loss: 0.8160388469696045, acc: 0.8518518805503845)
[2025-01-30 02:12:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3752/107898 [20:24<9:31:15,  3.04it/s][2025-01-30 02:12:34][root][INFO] - Training Epoch: 1/2, step 3751/107898 completed (loss: 2.4655497074127197, acc: 0.25)
[2025-01-30 02:12:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3753/107898 [20:24<9:35:19,  3.02it/s][2025-01-30 02:12:34][root][INFO] - Training Epoch: 1/2, step 3752/107898 completed (loss: 1.1464613676071167, acc: 0.75)
[2025-01-30 02:12:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3754/107898 [20:25<9:39:28,  3.00it/s][2025-01-30 02:12:34][root][INFO] - Training Epoch: 1/2, step 3753/107898 completed (loss: 0.25985220074653625, acc: 0.9090909361839294)
[2025-01-30 02:12:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3755/107898 [20:25<9:36:14,  3.01it/s][2025-01-30 02:12:35][root][INFO] - Training Epoch: 1/2, step 3754/107898 completed (loss: 0.7892879247665405, acc: 0.807692289352417)
[2025-01-30 02:12:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3756/107898 [20:25<9:44:37,  2.97it/s][2025-01-30 02:12:35][root][INFO] - Training Epoch: 1/2, step 3755/107898 completed (loss: 0.02754778414964676, acc: 1.0)
[2025-01-30 02:12:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3757/107898 [20:26<9:44:34,  2.97it/s][2025-01-30 02:12:35][root][INFO] - Training Epoch: 1/2, step 3756/107898 completed (loss: 1.3668713569641113, acc: 0.8181818127632141)
[2025-01-30 02:12:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3758/107898 [20:26<9:41:59,  2.98it/s][2025-01-30 02:12:36][root][INFO] - Training Epoch: 1/2, step 3757/107898 completed (loss: 1.2425955533981323, acc: 0.7058823704719543)
[2025-01-30 02:12:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3759/107898 [20:26<9:25:22,  3.07it/s][2025-01-30 02:12:36][root][INFO] - Training Epoch: 1/2, step 3758/107898 completed (loss: 1.3992981910705566, acc: 0.6470588445663452)
[2025-01-30 02:12:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3760/107898 [20:27<9:41:41,  2.98it/s][2025-01-30 02:12:36][root][INFO] - Training Epoch: 1/2, step 3759/107898 completed (loss: 2.343587636947632, acc: 0.4444444477558136)
[2025-01-30 02:12:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3761/107898 [20:27<9:34:09,  3.02it/s][2025-01-30 02:12:37][root][INFO] - Training Epoch: 1/2, step 3760/107898 completed (loss: 0.2836301028728485, acc: 1.0)
[2025-01-30 02:12:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3762/107898 [20:27<9:21:58,  3.09it/s][2025-01-30 02:12:37][root][INFO] - Training Epoch: 1/2, step 3761/107898 completed (loss: 1.607818603515625, acc: 0.7272727489471436)
[2025-01-30 02:12:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3763/107898 [20:28<9:08:49,  3.16it/s][2025-01-30 02:12:37][root][INFO] - Training Epoch: 1/2, step 3762/107898 completed (loss: 1.418036937713623, acc: 0.7333333492279053)
[2025-01-30 02:12:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3764/107898 [20:28<9:00:30,  3.21it/s][2025-01-30 02:12:38][root][INFO] - Training Epoch: 1/2, step 3763/107898 completed (loss: 0.9351255297660828, acc: 0.5)
[2025-01-30 02:12:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3765/107898 [20:28<9:01:58,  3.20it/s][2025-01-30 02:12:38][root][INFO] - Training Epoch: 1/2, step 3764/107898 completed (loss: 1.2984226942062378, acc: 0.75)
[2025-01-30 02:12:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3766/107898 [20:28<9:07:49,  3.17it/s][2025-01-30 02:12:38][root][INFO] - Training Epoch: 1/2, step 3765/107898 completed (loss: 0.7146375179290771, acc: 0.8484848737716675)
[2025-01-30 02:12:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3767/107898 [20:29<8:58:09,  3.22it/s][2025-01-30 02:12:39][root][INFO] - Training Epoch: 1/2, step 3766/107898 completed (loss: 4.199778079986572, acc: 0.21052631735801697)
[2025-01-30 02:12:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3768/107898 [20:29<9:16:08,  3.12it/s][2025-01-30 02:12:39][root][INFO] - Training Epoch: 1/2, step 3767/107898 completed (loss: 0.0006494108238257468, acc: 1.0)
[2025-01-30 02:12:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3769/107898 [20:29<9:13:54,  3.13it/s][2025-01-30 02:12:39][root][INFO] - Training Epoch: 1/2, step 3768/107898 completed (loss: 0.276260107755661, acc: 1.0)
[2025-01-30 02:12:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3770/107898 [20:30<9:06:56,  3.17it/s][2025-01-30 02:12:40][root][INFO] - Training Epoch: 1/2, step 3769/107898 completed (loss: 0.0012240427313372493, acc: 1.0)
[2025-01-30 02:12:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3771/107898 [20:30<9:22:12,  3.09it/s][2025-01-30 02:12:40][root][INFO] - Training Epoch: 1/2, step 3770/107898 completed (loss: 3.773698091506958, acc: 0.4000000059604645)
[2025-01-30 02:12:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3772/107898 [20:30<9:45:26,  2.96it/s][2025-01-30 02:12:40][root][INFO] - Training Epoch: 1/2, step 3771/107898 completed (loss: 1.2310978174209595, acc: 0.739130437374115)
[2025-01-30 02:12:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3773/107898 [20:31<9:46:20,  2.96it/s][2025-01-30 02:12:41][root][INFO] - Training Epoch: 1/2, step 3772/107898 completed (loss: 0.7077369093894958, acc: 0.8181818127632141)
[2025-01-30 02:12:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3774/107898 [20:31<9:39:33,  2.99it/s][2025-01-30 02:12:41][root][INFO] - Training Epoch: 1/2, step 3773/107898 completed (loss: 0.66532963514328, acc: 0.9090909361839294)
[2025-01-30 02:12:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3775/107898 [20:31<9:52:23,  2.93it/s][2025-01-30 02:12:41][root][INFO] - Training Epoch: 1/2, step 3774/107898 completed (loss: 0.4950355589389801, acc: 0.9545454382896423)
[2025-01-30 02:12:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   3%|[34mâ–Ž         [0m| 3776/107898 [20:32<9:52:45,  2.93it/s][2025-01-30 02:12:42][root][INFO] - Training Epoch: 1/2, step 3775/107898 completed (loss: 1.2300281524658203, acc: 0.6538461446762085)
[2025-01-30 02:12:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3777/107898 [20:32<9:45:59,  2.96it/s][2025-01-30 02:12:42][root][INFO] - Training Epoch: 1/2, step 3776/107898 completed (loss: 3.6557371616363525, acc: 0.4545454680919647)
[2025-01-30 02:12:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3778/107898 [20:32<9:24:27,  3.07it/s][2025-01-30 02:12:42][root][INFO] - Training Epoch: 1/2, step 3777/107898 completed (loss: 0.006602870766073465, acc: 1.0)
[2025-01-30 02:12:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3779/107898 [20:33<9:09:52,  3.16it/s][2025-01-30 02:12:43][root][INFO] - Training Epoch: 1/2, step 3778/107898 completed (loss: 4.791871547698975, acc: 0.5)
[2025-01-30 02:12:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3780/107898 [20:33<9:15:47,  3.12it/s][2025-01-30 02:12:43][root][INFO] - Training Epoch: 1/2, step 3779/107898 completed (loss: 0.19021931290626526, acc: 1.0)
[2025-01-30 02:12:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3781/107898 [20:33<9:11:18,  3.15it/s][2025-01-30 02:12:43][root][INFO] - Training Epoch: 1/2, step 3780/107898 completed (loss: 0.0009378152899444103, acc: 1.0)
[2025-01-30 02:12:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3782/107898 [20:34<9:03:40,  3.19it/s][2025-01-30 02:12:43][root][INFO] - Training Epoch: 1/2, step 3781/107898 completed (loss: 0.8770532011985779, acc: 0.7857142686843872)
[2025-01-30 02:12:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3783/107898 [20:34<9:05:30,  3.18it/s][2025-01-30 02:12:44][root][INFO] - Training Epoch: 1/2, step 3782/107898 completed (loss: 0.3163757920265198, acc: 1.0)
[2025-01-30 02:12:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3784/107898 [20:34<9:19:09,  3.10it/s][2025-01-30 02:12:44][root][INFO] - Training Epoch: 1/2, step 3783/107898 completed (loss: 0.00442509213462472, acc: 1.0)
[2025-01-30 02:12:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3785/107898 [20:35<9:46:10,  2.96it/s][2025-01-30 02:12:45][root][INFO] - Training Epoch: 1/2, step 3784/107898 completed (loss: 0.7550955414772034, acc: 0.84375)
[2025-01-30 02:12:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3786/107898 [20:35<9:59:07,  2.90it/s][2025-01-30 02:12:45][root][INFO] - Training Epoch: 1/2, step 3785/107898 completed (loss: 0.003046690486371517, acc: 1.0)
[2025-01-30 02:12:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3787/107898 [20:35<10:03:33,  2.87it/s][2025-01-30 02:12:45][root][INFO] - Training Epoch: 1/2, step 3786/107898 completed (loss: 0.013276388868689537, acc: 1.0)
[2025-01-30 02:12:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3788/107898 [20:36<9:41:25,  2.98it/s] [2025-01-30 02:12:46][root][INFO] - Training Epoch: 1/2, step 3787/107898 completed (loss: 1.1809269189834595, acc: 0.875)
[2025-01-30 02:12:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3789/107898 [20:36<9:22:02,  3.09it/s][2025-01-30 02:12:46][root][INFO] - Training Epoch: 1/2, step 3788/107898 completed (loss: 2.033633232116699, acc: 0.5714285969734192)
[2025-01-30 02:12:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3790/107898 [20:36<9:09:05,  3.16it/s][2025-01-30 02:12:46][root][INFO] - Training Epoch: 1/2, step 3789/107898 completed (loss: 0.49452710151672363, acc: 1.0)
[2025-01-30 02:12:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3791/107898 [20:37<9:05:32,  3.18it/s][2025-01-30 02:12:46][root][INFO] - Training Epoch: 1/2, step 3790/107898 completed (loss: 1.332666039466858, acc: 0.6666666865348816)
[2025-01-30 02:12:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3792/107898 [20:37<9:07:27,  3.17it/s][2025-01-30 02:12:47][root][INFO] - Training Epoch: 1/2, step 3791/107898 completed (loss: 0.08806075155735016, acc: 1.0)
[2025-01-30 02:12:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3793/107898 [20:37<8:56:11,  3.24it/s][2025-01-30 02:12:47][root][INFO] - Training Epoch: 1/2, step 3792/107898 completed (loss: 3.353452444076538, acc: 0.3333333432674408)
[2025-01-30 02:12:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3794/107898 [20:38<8:59:08,  3.22it/s][2025-01-30 02:12:47][root][INFO] - Training Epoch: 1/2, step 3793/107898 completed (loss: 0.892309308052063, acc: 0.800000011920929)
[2025-01-30 02:12:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3795/107898 [20:38<8:56:52,  3.23it/s][2025-01-30 02:12:48][root][INFO] - Training Epoch: 1/2, step 3794/107898 completed (loss: 0.3528423607349396, acc: 1.0)
[2025-01-30 02:12:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3796/107898 [20:38<8:57:22,  3.23it/s][2025-01-30 02:12:48][root][INFO] - Training Epoch: 1/2, step 3795/107898 completed (loss: 0.32836100459098816, acc: 0.8823529481887817)
[2025-01-30 02:12:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3797/107898 [20:39<8:57:28,  3.23it/s][2025-01-30 02:12:48][root][INFO] - Training Epoch: 1/2, step 3796/107898 completed (loss: 3.101348876953125, acc: 0.38461539149284363)
[2025-01-30 02:12:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3798/107898 [20:39<8:52:09,  3.26it/s][2025-01-30 02:12:49][root][INFO] - Training Epoch: 1/2, step 3797/107898 completed (loss: 1.4897305965423584, acc: 0.6666666865348816)
[2025-01-30 02:12:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3799/107898 [20:39<9:15:39,  3.12it/s][2025-01-30 02:12:49][root][INFO] - Training Epoch: 1/2, step 3798/107898 completed (loss: 1.6815065145492554, acc: 0.6666666865348816)
[2025-01-30 02:12:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3800/107898 [20:39<9:23:04,  3.08it/s][2025-01-30 02:12:49][root][INFO] - Training Epoch: 1/2, step 3799/107898 completed (loss: 0.39500975608825684, acc: 0.6666666865348816)
[2025-01-30 02:12:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3801/107898 [20:40<9:17:49,  3.11it/s][2025-01-30 02:12:50][root][INFO] - Training Epoch: 1/2, step 3800/107898 completed (loss: 1.5771713256835938, acc: 0.6764705777168274)
[2025-01-30 02:12:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3802/107898 [20:40<8:54:37,  3.25it/s][2025-01-30 02:12:50][root][INFO] - Training Epoch: 1/2, step 3801/107898 completed (loss: 5.195380210876465, acc: 0.20000000298023224)
[2025-01-30 02:12:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3803/107898 [20:40<9:21:14,  3.09it/s][2025-01-30 02:12:50][root][INFO] - Training Epoch: 1/2, step 3802/107898 completed (loss: 0.003245109925046563, acc: 1.0)
[2025-01-30 02:12:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3804/107898 [20:41<9:15:33,  3.12it/s][2025-01-30 02:12:51][root][INFO] - Training Epoch: 1/2, step 3803/107898 completed (loss: 1.659492015838623, acc: 0.6666666865348816)
[2025-01-30 02:12:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3805/107898 [20:41<9:25:36,  3.07it/s][2025-01-30 02:12:51][root][INFO] - Training Epoch: 1/2, step 3804/107898 completed (loss: 2.9784586429595947, acc: 0.5)
[2025-01-30 02:12:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3806/107898 [20:41<9:17:08,  3.11it/s][2025-01-30 02:12:51][root][INFO] - Training Epoch: 1/2, step 3805/107898 completed (loss: 0.6525489091873169, acc: 0.8095238208770752)
[2025-01-30 02:12:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3807/107898 [20:42<9:31:34,  3.04it/s][2025-01-30 02:12:52][root][INFO] - Training Epoch: 1/2, step 3806/107898 completed (loss: 1.5753273963928223, acc: 0.71875)
[2025-01-30 02:12:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3808/107898 [20:42<9:33:16,  3.03it/s][2025-01-30 02:12:52][root][INFO] - Training Epoch: 1/2, step 3807/107898 completed (loss: 2.529635190963745, acc: 0.6666666865348816)
[2025-01-30 02:12:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3809/107898 [20:42<9:31:24,  3.04it/s][2025-01-30 02:12:52][root][INFO] - Training Epoch: 1/2, step 3808/107898 completed (loss: 0.9454659223556519, acc: 0.7777777910232544)
[2025-01-30 02:12:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3810/107898 [20:43<9:46:03,  2.96it/s][2025-01-30 02:12:53][root][INFO] - Training Epoch: 1/2, step 3809/107898 completed (loss: 2.6546742916107178, acc: 0.6666666865348816)
[2025-01-30 02:12:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3811/107898 [20:43<10:04:54,  2.87it/s][2025-01-30 02:12:53][root][INFO] - Training Epoch: 1/2, step 3810/107898 completed (loss: 4.374082088470459, acc: 0.20000000298023224)
[2025-01-30 02:12:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3812/107898 [20:44<10:23:03,  2.78it/s][2025-01-30 02:12:53][root][INFO] - Training Epoch: 1/2, step 3811/107898 completed (loss: 0.7319002151489258, acc: 0.8536585569381714)
[2025-01-30 02:12:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3813/107898 [20:44<10:02:07,  2.88it/s][2025-01-30 02:12:54][root][INFO] - Training Epoch: 1/2, step 3812/107898 completed (loss: 0.5981391072273254, acc: 0.8333333134651184)
[2025-01-30 02:12:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3814/107898 [20:44<9:58:23,  2.90it/s] [2025-01-30 02:12:54][root][INFO] - Training Epoch: 1/2, step 3813/107898 completed (loss: 0.32535266876220703, acc: 0.8125)
[2025-01-30 02:12:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3815/107898 [20:45<9:45:07,  2.96it/s][2025-01-30 02:12:54][root][INFO] - Training Epoch: 1/2, step 3814/107898 completed (loss: 1.200201392173767, acc: 0.739130437374115)
[2025-01-30 02:12:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3816/107898 [20:45<9:33:26,  3.03it/s][2025-01-30 02:12:55][root][INFO] - Training Epoch: 1/2, step 3815/107898 completed (loss: 1.71186363697052, acc: 0.3333333432674408)
[2025-01-30 02:12:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3817/107898 [20:45<9:56:19,  2.91it/s][2025-01-30 02:12:55][root][INFO] - Training Epoch: 1/2, step 3816/107898 completed (loss: 1.335890293121338, acc: 0.692307710647583)
[2025-01-30 02:12:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3818/107898 [20:46<9:39:31,  2.99it/s][2025-01-30 02:12:55][root][INFO] - Training Epoch: 1/2, step 3817/107898 completed (loss: 0.3166186213493347, acc: 0.800000011920929)
[2025-01-30 02:12:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3819/107898 [20:46<9:23:01,  3.08it/s][2025-01-30 02:12:56][root][INFO] - Training Epoch: 1/2, step 3818/107898 completed (loss: 0.09746017307043076, acc: 0.9473684430122375)
[2025-01-30 02:12:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3820/107898 [20:46<9:44:12,  2.97it/s][2025-01-30 02:12:56][root][INFO] - Training Epoch: 1/2, step 3819/107898 completed (loss: 3.813885450363159, acc: 0.5)
[2025-01-30 02:12:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3821/107898 [20:47<9:41:22,  2.98it/s][2025-01-30 02:12:56][root][INFO] - Training Epoch: 1/2, step 3820/107898 completed (loss: 1.8688253164291382, acc: 0.6153846383094788)
[2025-01-30 02:12:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3822/107898 [20:47<9:33:37,  3.02it/s][2025-01-30 02:12:57][root][INFO] - Training Epoch: 1/2, step 3821/107898 completed (loss: 4.021366596221924, acc: 0.3125)
[2025-01-30 02:12:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3823/107898 [20:47<9:12:43,  3.14it/s][2025-01-30 02:12:57][root][INFO] - Training Epoch: 1/2, step 3822/107898 completed (loss: 0.07185622304677963, acc: 1.0)
[2025-01-30 02:12:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3824/107898 [20:47<9:09:29,  3.16it/s][2025-01-30 02:12:57][root][INFO] - Training Epoch: 1/2, step 3823/107898 completed (loss: 0.7444688677787781, acc: 0.5)
[2025-01-30 02:12:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3825/107898 [20:48<8:56:43,  3.23it/s][2025-01-30 02:12:58][root][INFO] - Training Epoch: 1/2, step 3824/107898 completed (loss: 0.1015961542725563, acc: 1.0)
[2025-01-30 02:12:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3826/107898 [20:48<8:59:21,  3.22it/s][2025-01-30 02:12:58][root][INFO] - Training Epoch: 1/2, step 3825/107898 completed (loss: 0.25218120217323303, acc: 0.9354838728904724)
[2025-01-30 02:12:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3827/107898 [20:48<9:00:53,  3.21it/s][2025-01-30 02:12:58][root][INFO] - Training Epoch: 1/2, step 3826/107898 completed (loss: 0.6855756044387817, acc: 1.0)
[2025-01-30 02:12:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3828/107898 [20:49<9:05:37,  3.18it/s][2025-01-30 02:12:58][root][INFO] - Training Epoch: 1/2, step 3827/107898 completed (loss: 0.9718431830406189, acc: 0.0)
[2025-01-30 02:12:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3829/107898 [20:49<8:57:50,  3.22it/s][2025-01-30 02:12:59][root][INFO] - Training Epoch: 1/2, step 3828/107898 completed (loss: 0.9547869563102722, acc: 0.8235294222831726)
[2025-01-30 02:12:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3830/107898 [20:49<8:59:40,  3.21it/s][2025-01-30 02:12:59][root][INFO] - Training Epoch: 1/2, step 3829/107898 completed (loss: 0.5459346175193787, acc: 0.8999999761581421)
[2025-01-30 02:12:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3831/107898 [20:50<8:51:38,  3.26it/s][2025-01-30 02:12:59][root][INFO] - Training Epoch: 1/2, step 3830/107898 completed (loss: 0.14632092416286469, acc: 1.0)
[2025-01-30 02:12:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3832/107898 [20:50<8:47:58,  3.29it/s][2025-01-30 02:13:00][root][INFO] - Training Epoch: 1/2, step 3831/107898 completed (loss: 1.247888445854187, acc: 0.7222222089767456)
[2025-01-30 02:13:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3833/107898 [20:50<9:08:06,  3.16it/s][2025-01-30 02:13:00][root][INFO] - Training Epoch: 1/2, step 3832/107898 completed (loss: 3.045668125152588, acc: 0.4285714328289032)
[2025-01-30 02:13:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3834/107898 [20:51<9:05:18,  3.18it/s][2025-01-30 02:13:00][root][INFO] - Training Epoch: 1/2, step 3833/107898 completed (loss: 1.9456368684768677, acc: 0.6071428656578064)
[2025-01-30 02:13:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3835/107898 [20:51<8:59:14,  3.22it/s][2025-01-30 02:13:01][root][INFO] - Training Epoch: 1/2, step 3834/107898 completed (loss: 3.5557162761688232, acc: 0.3333333432674408)
[2025-01-30 02:13:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3836/107898 [20:51<9:16:43,  3.12it/s][2025-01-30 02:13:01][root][INFO] - Training Epoch: 1/2, step 3835/107898 completed (loss: 0.0011746302479878068, acc: 1.0)
[2025-01-30 02:13:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3837/107898 [20:52<9:26:01,  3.06it/s][2025-01-30 02:13:01][root][INFO] - Training Epoch: 1/2, step 3836/107898 completed (loss: 1.1510059833526611, acc: 0.699999988079071)
[2025-01-30 02:13:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3838/107898 [20:52<9:22:54,  3.08it/s][2025-01-30 02:13:02][root][INFO] - Training Epoch: 1/2, step 3837/107898 completed (loss: 0.13727355003356934, acc: 1.0)
[2025-01-30 02:13:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3839/107898 [20:52<9:26:01,  3.06it/s][2025-01-30 02:13:02][root][INFO] - Training Epoch: 1/2, step 3838/107898 completed (loss: 0.1954932063817978, acc: 1.0)
[2025-01-30 02:13:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3840/107898 [20:52<9:17:47,  3.11it/s][2025-01-30 02:13:02][root][INFO] - Training Epoch: 1/2, step 3839/107898 completed (loss: 1.0875940322875977, acc: 0.5)
[2025-01-30 02:13:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3841/107898 [20:53<9:04:57,  3.18it/s][2025-01-30 02:13:03][root][INFO] - Training Epoch: 1/2, step 3840/107898 completed (loss: 1.3135377168655396, acc: 0.6666666865348816)
[2025-01-30 02:13:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3842/107898 [20:53<8:48:53,  3.28it/s][2025-01-30 02:13:03][root][INFO] - Training Epoch: 1/2, step 3841/107898 completed (loss: 0.0982920303940773, acc: 1.0)
[2025-01-30 02:13:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3843/107898 [20:53<8:43:55,  3.31it/s][2025-01-30 02:13:03][root][INFO] - Training Epoch: 1/2, step 3842/107898 completed (loss: 0.20601464807987213, acc: 1.0)
[2025-01-30 02:13:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3844/107898 [20:54<8:43:21,  3.31it/s][2025-01-30 02:13:03][root][INFO] - Training Epoch: 1/2, step 3843/107898 completed (loss: 2.3404033184051514, acc: 0.6666666865348816)
[2025-01-30 02:13:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3845/107898 [20:54<8:48:45,  3.28it/s][2025-01-30 02:13:04][root][INFO] - Training Epoch: 1/2, step 3844/107898 completed (loss: 0.04850847274065018, acc: 1.0)
[2025-01-30 02:13:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3846/107898 [20:54<8:49:06,  3.28it/s][2025-01-30 02:13:04][root][INFO] - Training Epoch: 1/2, step 3845/107898 completed (loss: 1.1226369142532349, acc: 0.739130437374115)
[2025-01-30 02:13:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3847/107898 [20:55<8:47:19,  3.29it/s][2025-01-30 02:13:04][root][INFO] - Training Epoch: 1/2, step 3846/107898 completed (loss: 3.4996337890625, acc: 0.2142857164144516)
[2025-01-30 02:13:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3848/107898 [20:55<9:21:24,  3.09it/s][2025-01-30 02:13:05][root][INFO] - Training Epoch: 1/2, step 3847/107898 completed (loss: 0.6704444885253906, acc: 0.761904776096344)
[2025-01-30 02:13:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3849/107898 [20:55<9:15:35,  3.12it/s][2025-01-30 02:13:05][root][INFO] - Training Epoch: 1/2, step 3848/107898 completed (loss: 1.7560557126998901, acc: 0.8333333134651184)
[2025-01-30 02:13:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3850/107898 [20:56<9:12:12,  3.14it/s][2025-01-30 02:13:05][root][INFO] - Training Epoch: 1/2, step 3849/107898 completed (loss: 1.169319987297058, acc: 0.7647058963775635)
[2025-01-30 02:13:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3851/107898 [20:56<9:04:40,  3.18it/s][2025-01-30 02:13:06][root][INFO] - Training Epoch: 1/2, step 3850/107898 completed (loss: 1.7652721405029297, acc: 0.75)
[2025-01-30 02:13:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3852/107898 [20:56<9:03:34,  3.19it/s][2025-01-30 02:13:06][root][INFO] - Training Epoch: 1/2, step 3851/107898 completed (loss: 1.2237420082092285, acc: 0.75)
[2025-01-30 02:13:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3853/107898 [20:57<9:01:47,  3.20it/s][2025-01-30 02:13:06][root][INFO] - Training Epoch: 1/2, step 3852/107898 completed (loss: 0.0197003111243248, acc: 1.0)
[2025-01-30 02:13:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3854/107898 [20:57<9:03:59,  3.19it/s][2025-01-30 02:13:07][root][INFO] - Training Epoch: 1/2, step 3853/107898 completed (loss: 0.2495620846748352, acc: 1.0)
[2025-01-30 02:13:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3855/107898 [20:57<9:32:10,  3.03it/s][2025-01-30 02:13:07][root][INFO] - Training Epoch: 1/2, step 3854/107898 completed (loss: 0.03863533213734627, acc: 1.0)
[2025-01-30 02:13:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3856/107898 [20:57<9:23:18,  3.08it/s][2025-01-30 02:13:07][root][INFO] - Training Epoch: 1/2, step 3855/107898 completed (loss: 1.8779007196426392, acc: 0.5714285969734192)
[2025-01-30 02:13:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3857/107898 [20:58<9:11:37,  3.14it/s][2025-01-30 02:13:08][root][INFO] - Training Epoch: 1/2, step 3856/107898 completed (loss: 0.8651606440544128, acc: 0.8333333134651184)
[2025-01-30 02:13:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3858/107898 [20:58<9:22:50,  3.08it/s][2025-01-30 02:13:08][root][INFO] - Training Epoch: 1/2, step 3857/107898 completed (loss: 0.48342323303222656, acc: 0.8333333134651184)
[2025-01-30 02:13:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3859/107898 [20:58<9:17:18,  3.11it/s][2025-01-30 02:13:08][root][INFO] - Training Epoch: 1/2, step 3858/107898 completed (loss: 3.2368392944335938, acc: 0.3888888955116272)
[2025-01-30 02:13:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3860/107898 [20:59<9:14:49,  3.13it/s][2025-01-30 02:13:09][root][INFO] - Training Epoch: 1/2, step 3859/107898 completed (loss: 0.09337683767080307, acc: 1.0)
[2025-01-30 02:13:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3861/107898 [20:59<9:05:30,  3.18it/s][2025-01-30 02:13:09][root][INFO] - Training Epoch: 1/2, step 3860/107898 completed (loss: 1.1603820323944092, acc: 0.761904776096344)
[2025-01-30 02:13:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3862/107898 [20:59<9:02:48,  3.19it/s][2025-01-30 02:13:09][root][INFO] - Training Epoch: 1/2, step 3861/107898 completed (loss: 1.8282972574234009, acc: 0.75)
[2025-01-30 02:13:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3863/107898 [21:00<9:24:29,  3.07it/s][2025-01-30 02:13:10][root][INFO] - Training Epoch: 1/2, step 3862/107898 completed (loss: 0.1800498068332672, acc: 0.9375)
[2025-01-30 02:13:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3864/107898 [21:00<9:24:43,  3.07it/s][2025-01-30 02:13:10][root][INFO] - Training Epoch: 1/2, step 3863/107898 completed (loss: 0.010249730199575424, acc: 1.0)
[2025-01-30 02:13:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3865/107898 [21:00<9:18:24,  3.11it/s][2025-01-30 02:13:10][root][INFO] - Training Epoch: 1/2, step 3864/107898 completed (loss: 0.8449615836143494, acc: 0.6666666865348816)
[2025-01-30 02:13:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3866/107898 [21:01<9:14:52,  3.12it/s][2025-01-30 02:13:10][root][INFO] - Training Epoch: 1/2, step 3865/107898 completed (loss: 0.5436553359031677, acc: 0.9090909361839294)
[2025-01-30 02:13:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3867/107898 [21:01<9:24:47,  3.07it/s][2025-01-30 02:13:11][root][INFO] - Training Epoch: 1/2, step 3866/107898 completed (loss: 0.5166277885437012, acc: 0.8947368264198303)
[2025-01-30 02:13:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3868/107898 [21:01<9:33:37,  3.02it/s][2025-01-30 02:13:11][root][INFO] - Training Epoch: 1/2, step 3867/107898 completed (loss: 0.7328416705131531, acc: 0.7916666865348816)
[2025-01-30 02:13:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3869/107898 [21:02<9:30:46,  3.04it/s][2025-01-30 02:13:11][root][INFO] - Training Epoch: 1/2, step 3868/107898 completed (loss: 1.7725356817245483, acc: 0.7333333492279053)
[2025-01-30 02:13:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3870/107898 [21:02<9:33:36,  3.02it/s][2025-01-30 02:13:12][root][INFO] - Training Epoch: 1/2, step 3869/107898 completed (loss: 1.3395419120788574, acc: 0.699999988079071)
[2025-01-30 02:13:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3871/107898 [21:02<9:28:20,  3.05it/s][2025-01-30 02:13:12][root][INFO] - Training Epoch: 1/2, step 3870/107898 completed (loss: 3.402235746383667, acc: 0.4000000059604645)
[2025-01-30 02:13:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3872/107898 [21:03<9:24:33,  3.07it/s][2025-01-30 02:13:12][root][INFO] - Training Epoch: 1/2, step 3871/107898 completed (loss: 0.5715588331222534, acc: 0.9047619104385376)
[2025-01-30 02:13:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3873/107898 [21:03<9:41:17,  2.98it/s][2025-01-30 02:13:13][root][INFO] - Training Epoch: 1/2, step 3872/107898 completed (loss: 0.49687257409095764, acc: 0.8999999761581421)
[2025-01-30 02:13:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3874/107898 [21:03<10:04:16,  2.87it/s][2025-01-30 02:13:13][root][INFO] - Training Epoch: 1/2, step 3873/107898 completed (loss: 1.1573678255081177, acc: 0.6666666865348816)
[2025-01-30 02:13:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3875/107898 [21:04<10:06:33,  2.86it/s][2025-01-30 02:13:14][root][INFO] - Training Epoch: 1/2, step 3874/107898 completed (loss: 0.19817878305912018, acc: 1.0)
[2025-01-30 02:13:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3876/107898 [21:04<10:10:12,  2.84it/s][2025-01-30 02:13:14][root][INFO] - Training Epoch: 1/2, step 3875/107898 completed (loss: 0.4746212363243103, acc: 0.800000011920929)
[2025-01-30 02:13:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3877/107898 [21:04<10:09:48,  2.84it/s][2025-01-30 02:13:14][root][INFO] - Training Epoch: 1/2, step 3876/107898 completed (loss: 0.7386771440505981, acc: 0.8275862336158752)
[2025-01-30 02:13:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3878/107898 [21:05<9:51:40,  2.93it/s] [2025-01-30 02:13:15][root][INFO] - Training Epoch: 1/2, step 3877/107898 completed (loss: 2.3510899543762207, acc: 0.6000000238418579)
[2025-01-30 02:13:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3879/107898 [21:05<9:29:46,  3.04it/s][2025-01-30 02:13:15][root][INFO] - Training Epoch: 1/2, step 3878/107898 completed (loss: 1.8182471990585327, acc: 0.7857142686843872)
[2025-01-30 02:13:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3880/107898 [21:05<9:16:08,  3.12it/s][2025-01-30 02:13:15][root][INFO] - Training Epoch: 1/2, step 3879/107898 completed (loss: 1.1190853118896484, acc: 0.692307710647583)
[2025-01-30 02:13:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3881/107898 [21:06<9:04:45,  3.18it/s][2025-01-30 02:13:15][root][INFO] - Training Epoch: 1/2, step 3880/107898 completed (loss: 0.12404525279998779, acc: 1.0)
[2025-01-30 02:13:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3882/107898 [21:06<9:32:34,  3.03it/s][2025-01-30 02:13:16][root][INFO] - Training Epoch: 1/2, step 3881/107898 completed (loss: 0.014856631867587566, acc: 1.0)
[2025-01-30 02:13:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3883/107898 [21:06<9:24:49,  3.07it/s][2025-01-30 02:13:16][root][INFO] - Training Epoch: 1/2, step 3882/107898 completed (loss: 2.9134223461151123, acc: 0.5)
[2025-01-30 02:13:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3884/107898 [21:07<9:23:39,  3.08it/s][2025-01-30 02:13:16][root][INFO] - Training Epoch: 1/2, step 3883/107898 completed (loss: 0.6641161441802979, acc: 0.8695651888847351)
[2025-01-30 02:13:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3885/107898 [21:07<9:09:43,  3.15it/s][2025-01-30 02:13:17][root][INFO] - Training Epoch: 1/2, step 3884/107898 completed (loss: 2.6127545833587646, acc: 0.3333333432674408)
[2025-01-30 02:13:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3886/107898 [21:07<9:00:02,  3.21it/s][2025-01-30 02:13:17][root][INFO] - Training Epoch: 1/2, step 3885/107898 completed (loss: 0.27996185421943665, acc: 1.0)
[2025-01-30 02:13:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3887/107898 [21:08<8:58:56,  3.22it/s][2025-01-30 02:13:17][root][INFO] - Training Epoch: 1/2, step 3886/107898 completed (loss: 3.09037709236145, acc: 0.3333333432674408)
[2025-01-30 02:13:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3888/107898 [21:08<8:46:55,  3.29it/s][2025-01-30 02:13:18][root][INFO] - Training Epoch: 1/2, step 3887/107898 completed (loss: 0.07911298424005508, acc: 1.0)
[2025-01-30 02:13:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3889/107898 [21:08<9:00:19,  3.21it/s][2025-01-30 02:13:18][root][INFO] - Training Epoch: 1/2, step 3888/107898 completed (loss: 3.144082546234131, acc: 0.3181818127632141)
[2025-01-30 02:13:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3890/107898 [21:09<9:02:26,  3.20it/s][2025-01-30 02:13:18][root][INFO] - Training Epoch: 1/2, step 3889/107898 completed (loss: 1.2335255146026611, acc: 0.7894737124443054)
[2025-01-30 02:13:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3891/107898 [21:09<9:02:31,  3.20it/s][2025-01-30 02:13:19][root][INFO] - Training Epoch: 1/2, step 3890/107898 completed (loss: 0.9603450298309326, acc: 0.7692307829856873)
[2025-01-30 02:13:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3892/107898 [21:09<8:57:01,  3.23it/s][2025-01-30 02:13:19][root][INFO] - Training Epoch: 1/2, step 3891/107898 completed (loss: 0.8363000154495239, acc: 0.8888888955116272)
[2025-01-30 02:13:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3893/107898 [21:09<9:09:42,  3.15it/s][2025-01-30 02:13:19][root][INFO] - Training Epoch: 1/2, step 3892/107898 completed (loss: 1.8725544214248657, acc: 0.625)
[2025-01-30 02:13:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3894/107898 [21:10<9:20:58,  3.09it/s][2025-01-30 02:13:20][root][INFO] - Training Epoch: 1/2, step 3893/107898 completed (loss: 0.162563756108284, acc: 1.0)
[2025-01-30 02:13:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3895/107898 [21:10<9:31:59,  3.03it/s][2025-01-30 02:13:20][root][INFO] - Training Epoch: 1/2, step 3894/107898 completed (loss: 2.134781837463379, acc: 0.5)
[2025-01-30 02:13:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3896/107898 [21:10<9:18:49,  3.10it/s][2025-01-30 02:13:20][root][INFO] - Training Epoch: 1/2, step 3895/107898 completed (loss: 0.006387236062437296, acc: 1.0)
[2025-01-30 02:13:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3897/107898 [21:11<9:11:47,  3.14it/s][2025-01-30 02:13:21][root][INFO] - Training Epoch: 1/2, step 3896/107898 completed (loss: 0.4210784137248993, acc: 0.6666666865348816)
[2025-01-30 02:13:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3898/107898 [21:11<9:22:06,  3.08it/s][2025-01-30 02:13:21][root][INFO] - Training Epoch: 1/2, step 3897/107898 completed (loss: 0.0025834091939032078, acc: 1.0)
[2025-01-30 02:13:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3899/107898 [21:11<9:46:32,  2.96it/s][2025-01-30 02:13:21][root][INFO] - Training Epoch: 1/2, step 3898/107898 completed (loss: 0.05455585941672325, acc: 1.0)
[2025-01-30 02:13:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3900/107898 [21:12<9:39:24,  2.99it/s][2025-01-30 02:13:22][root][INFO] - Training Epoch: 1/2, step 3899/107898 completed (loss: 0.34645846486091614, acc: 1.0)
[2025-01-30 02:13:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3901/107898 [21:12<9:16:45,  3.11it/s][2025-01-30 02:13:22][root][INFO] - Training Epoch: 1/2, step 3900/107898 completed (loss: 0.9959461092948914, acc: 0.75)
[2025-01-30 02:13:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3902/107898 [21:12<9:01:31,  3.20it/s][2025-01-30 02:13:22][root][INFO] - Training Epoch: 1/2, step 3901/107898 completed (loss: 0.7389929890632629, acc: 0.8235294222831726)
[2025-01-30 02:13:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3903/107898 [21:13<8:55:03,  3.24it/s][2025-01-30 02:13:22][root][INFO] - Training Epoch: 1/2, step 3902/107898 completed (loss: 0.09329989552497864, acc: 1.0)
[2025-01-30 02:13:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3904/107898 [21:13<9:18:12,  3.10it/s][2025-01-30 02:13:23][root][INFO] - Training Epoch: 1/2, step 3903/107898 completed (loss: 0.14466328918933868, acc: 1.0)
[2025-01-30 02:13:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3905/107898 [21:13<9:20:38,  3.09it/s][2025-01-30 02:13:23][root][INFO] - Training Epoch: 1/2, step 3904/107898 completed (loss: 0.03322779759764671, acc: 1.0)
[2025-01-30 02:13:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3906/107898 [21:14<9:10:06,  3.15it/s][2025-01-30 02:13:23][root][INFO] - Training Epoch: 1/2, step 3905/107898 completed (loss: 4.302520275115967, acc: 0.3333333432674408)
[2025-01-30 02:13:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3907/107898 [21:14<9:07:24,  3.17it/s][2025-01-30 02:13:24][root][INFO] - Training Epoch: 1/2, step 3906/107898 completed (loss: 1.0787625312805176, acc: 0.8181818127632141)
[2025-01-30 02:13:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3908/107898 [21:14<9:19:49,  3.10it/s][2025-01-30 02:13:24][root][INFO] - Training Epoch: 1/2, step 3907/107898 completed (loss: 3.185723066329956, acc: 0.25)
[2025-01-30 02:13:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3909/107898 [21:15<9:20:28,  3.09it/s][2025-01-30 02:13:24][root][INFO] - Training Epoch: 1/2, step 3908/107898 completed (loss: 1.9812817573547363, acc: 0.6666666865348816)
[2025-01-30 02:13:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3910/107898 [21:15<8:56:37,  3.23it/s][2025-01-30 02:13:25][root][INFO] - Training Epoch: 1/2, step 3909/107898 completed (loss: 0.8752689361572266, acc: 0.8333333134651184)
[2025-01-30 02:13:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3911/107898 [21:15<9:19:42,  3.10it/s][2025-01-30 02:13:25][root][INFO] - Training Epoch: 1/2, step 3910/107898 completed (loss: 0.7064166069030762, acc: 0.9090909361839294)
[2025-01-30 02:13:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3912/107898 [21:16<10:13:28,  2.83it/s][2025-01-30 02:13:26][root][INFO] - Training Epoch: 1/2, step 3911/107898 completed (loss: 1.1905587911605835, acc: 0.5)
[2025-01-30 02:13:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3913/107898 [21:16<10:08:20,  2.85it/s][2025-01-30 02:13:26][root][INFO] - Training Epoch: 1/2, step 3912/107898 completed (loss: 1.6715909242630005, acc: 0.5)
[2025-01-30 02:13:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3914/107898 [21:16<10:13:06,  2.83it/s][2025-01-30 02:13:26][root][INFO] - Training Epoch: 1/2, step 3913/107898 completed (loss: 2.239905595779419, acc: 0.5897436141967773)
[2025-01-30 02:13:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3915/107898 [21:17<10:02:38,  2.88it/s][2025-01-30 02:13:27][root][INFO] - Training Epoch: 1/2, step 3914/107898 completed (loss: 0.4087313711643219, acc: 1.0)
[2025-01-30 02:13:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3916/107898 [21:17<9:25:49,  3.06it/s] [2025-01-30 02:13:27][root][INFO] - Training Epoch: 1/2, step 3915/107898 completed (loss: 2.8987996578216553, acc: 0.4285714328289032)
[2025-01-30 02:13:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3917/107898 [21:17<9:24:55,  3.07it/s][2025-01-30 02:13:27][root][INFO] - Training Epoch: 1/2, step 3916/107898 completed (loss: 0.0872429832816124, acc: 1.0)
[2025-01-30 02:13:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3918/107898 [21:18<9:11:28,  3.14it/s][2025-01-30 02:13:27][root][INFO] - Training Epoch: 1/2, step 3917/107898 completed (loss: 1.5547525882720947, acc: 0.6875)
[2025-01-30 02:13:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3919/107898 [21:18<9:00:15,  3.21it/s][2025-01-30 02:13:28][root][INFO] - Training Epoch: 1/2, step 3918/107898 completed (loss: 0.06350232660770416, acc: 1.0)
[2025-01-30 02:13:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3920/107898 [21:18<8:52:11,  3.26it/s][2025-01-30 02:13:28][root][INFO] - Training Epoch: 1/2, step 3919/107898 completed (loss: 0.024002330377697945, acc: 1.0)
[2025-01-30 02:13:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3921/107898 [21:19<8:59:15,  3.21it/s][2025-01-30 02:13:28][root][INFO] - Training Epoch: 1/2, step 3920/107898 completed (loss: 1.108691930770874, acc: 0.6666666865348816)
[2025-01-30 02:13:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3922/107898 [21:19<8:41:33,  3.32it/s][2025-01-30 02:13:29][root][INFO] - Training Epoch: 1/2, step 3921/107898 completed (loss: 0.06111875921487808, acc: 1.0)
[2025-01-30 02:13:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3923/107898 [21:19<8:43:05,  3.31it/s][2025-01-30 02:13:29][root][INFO] - Training Epoch: 1/2, step 3922/107898 completed (loss: 0.5525614023208618, acc: 0.800000011920929)
[2025-01-30 02:13:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3924/107898 [21:19<8:45:53,  3.30it/s][2025-01-30 02:13:29][root][INFO] - Training Epoch: 1/2, step 3923/107898 completed (loss: 2.794339656829834, acc: 0.2857142984867096)
[2025-01-30 02:13:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3925/107898 [21:20<9:20:55,  3.09it/s][2025-01-30 02:13:30][root][INFO] - Training Epoch: 1/2, step 3924/107898 completed (loss: 0.7163756489753723, acc: 0.8799999952316284)
[2025-01-30 02:13:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3926/107898 [21:20<9:40:54,  2.98it/s][2025-01-30 02:13:30][root][INFO] - Training Epoch: 1/2, step 3925/107898 completed (loss: 3.399031162261963, acc: 0.32258063554763794)
[2025-01-30 02:13:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3927/107898 [21:21<9:30:30,  3.04it/s][2025-01-30 02:13:30][root][INFO] - Training Epoch: 1/2, step 3926/107898 completed (loss: 0.3586987257003784, acc: 0.9523809552192688)
[2025-01-30 02:13:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3928/107898 [21:21<9:11:28,  3.14it/s][2025-01-30 02:13:31][root][INFO] - Training Epoch: 1/2, step 3927/107898 completed (loss: 0.002530040219426155, acc: 1.0)
[2025-01-30 02:13:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3929/107898 [21:21<9:31:42,  3.03it/s][2025-01-30 02:13:31][root][INFO] - Training Epoch: 1/2, step 3928/107898 completed (loss: 5.209255218505859, acc: 0.3333333432674408)
[2025-01-30 02:13:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3930/107898 [21:21<9:35:49,  3.01it/s][2025-01-30 02:13:31][root][INFO] - Training Epoch: 1/2, step 3929/107898 completed (loss: 0.014894627965986729, acc: 1.0)
[2025-01-30 02:13:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3931/107898 [21:22<9:44:12,  2.97it/s][2025-01-30 02:13:32][root][INFO] - Training Epoch: 1/2, step 3930/107898 completed (loss: 1.5440982580184937, acc: 0.7857142686843872)
[2025-01-30 02:13:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3932/107898 [21:22<9:49:13,  2.94it/s][2025-01-30 02:13:32][root][INFO] - Training Epoch: 1/2, step 3931/107898 completed (loss: 1.6609585285186768, acc: 0.5)
[2025-01-30 02:13:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3933/107898 [21:23<9:58:28,  2.90it/s][2025-01-30 02:13:32][root][INFO] - Training Epoch: 1/2, step 3932/107898 completed (loss: 0.9365943670272827, acc: 0.7142857313156128)
[2025-01-30 02:13:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3934/107898 [21:23<9:39:32,  2.99it/s][2025-01-30 02:13:33][root][INFO] - Training Epoch: 1/2, step 3933/107898 completed (loss: 3.0631253719329834, acc: 0.3333333432674408)
[2025-01-30 02:13:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3935/107898 [21:23<9:21:34,  3.09it/s][2025-01-30 02:13:33][root][INFO] - Training Epoch: 1/2, step 3934/107898 completed (loss: 0.06862124055624008, acc: 1.0)
[2025-01-30 02:13:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3936/107898 [21:24<9:33:11,  3.02it/s][2025-01-30 02:13:33][root][INFO] - Training Epoch: 1/2, step 3935/107898 completed (loss: 1.8501238822937012, acc: 0.5)
[2025-01-30 02:13:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3937/107898 [21:24<9:40:42,  2.98it/s][2025-01-30 02:13:34][root][INFO] - Training Epoch: 1/2, step 3936/107898 completed (loss: 0.27242547273635864, acc: 0.949999988079071)
[2025-01-30 02:13:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3938/107898 [21:24<9:39:57,  2.99it/s][2025-01-30 02:13:34][root][INFO] - Training Epoch: 1/2, step 3937/107898 completed (loss: 1.2568881511688232, acc: 0.6428571343421936)
[2025-01-30 02:13:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3939/107898 [21:25<9:30:53,  3.04it/s][2025-01-30 02:13:34][root][INFO] - Training Epoch: 1/2, step 3938/107898 completed (loss: 0.18453089892864227, acc: 1.0)
[2025-01-30 02:13:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3940/107898 [21:25<9:09:19,  3.15it/s][2025-01-30 02:13:35][root][INFO] - Training Epoch: 1/2, step 3939/107898 completed (loss: 0.35316136479377747, acc: 0.8571428656578064)
[2025-01-30 02:13:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3941/107898 [21:25<8:55:49,  3.23it/s][2025-01-30 02:13:35][root][INFO] - Training Epoch: 1/2, step 3940/107898 completed (loss: 2.5524120330810547, acc: 0.5555555820465088)
[2025-01-30 02:13:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3942/107898 [21:25<9:18:34,  3.10it/s][2025-01-30 02:13:35][root][INFO] - Training Epoch: 1/2, step 3941/107898 completed (loss: 0.45116710662841797, acc: 1.0)
[2025-01-30 02:13:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3943/107898 [21:26<9:16:46,  3.11it/s][2025-01-30 02:13:36][root][INFO] - Training Epoch: 1/2, step 3942/107898 completed (loss: 0.6026338934898376, acc: 0.7692307829856873)
[2025-01-30 02:13:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3944/107898 [21:26<9:17:59,  3.11it/s][2025-01-30 02:13:36][root][INFO] - Training Epoch: 1/2, step 3943/107898 completed (loss: 0.020563462749123573, acc: 1.0)
[2025-01-30 02:13:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3945/107898 [21:26<9:11:25,  3.14it/s][2025-01-30 02:13:36][root][INFO] - Training Epoch: 1/2, step 3944/107898 completed (loss: 0.2663462162017822, acc: 0.9090909361839294)
[2025-01-30 02:13:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3946/107898 [21:27<8:59:46,  3.21it/s][2025-01-30 02:13:36][root][INFO] - Training Epoch: 1/2, step 3945/107898 completed (loss: 0.003181986976414919, acc: 1.0)
[2025-01-30 02:13:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3947/107898 [21:27<8:58:16,  3.22it/s][2025-01-30 02:13:37][root][INFO] - Training Epoch: 1/2, step 3946/107898 completed (loss: 0.6523187160491943, acc: 0.9230769276618958)
[2025-01-30 02:13:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3948/107898 [21:27<9:20:13,  3.09it/s][2025-01-30 02:13:37][root][INFO] - Training Epoch: 1/2, step 3947/107898 completed (loss: 0.9280930161476135, acc: 0.75)
[2025-01-30 02:13:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3949/107898 [21:28<9:33:38,  3.02it/s][2025-01-30 02:13:37][root][INFO] - Training Epoch: 1/2, step 3948/107898 completed (loss: 1.528568983078003, acc: 0.7241379022598267)
[2025-01-30 02:13:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3950/107898 [21:28<9:22:08,  3.08it/s][2025-01-30 02:13:38][root][INFO] - Training Epoch: 1/2, step 3949/107898 completed (loss: 0.6821871399879456, acc: 0.8846153616905212)
[2025-01-30 02:13:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3951/107898 [21:28<9:30:58,  3.03it/s][2025-01-30 02:13:38][root][INFO] - Training Epoch: 1/2, step 3950/107898 completed (loss: 0.7024619579315186, acc: 0.8888888955116272)
[2025-01-30 02:13:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3952/107898 [21:29<9:33:48,  3.02it/s][2025-01-30 02:13:38][root][INFO] - Training Epoch: 1/2, step 3951/107898 completed (loss: 0.05962857976555824, acc: 1.0)
[2025-01-30 02:13:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3953/107898 [21:29<9:23:01,  3.08it/s][2025-01-30 02:13:39][root][INFO] - Training Epoch: 1/2, step 3952/107898 completed (loss: 3.8161604404449463, acc: 0.27272728085517883)
[2025-01-30 02:13:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3954/107898 [21:29<9:34:40,  3.01it/s][2025-01-30 02:13:39][root][INFO] - Training Epoch: 1/2, step 3953/107898 completed (loss: 0.4528587758541107, acc: 0.8611111044883728)
[2025-01-30 02:13:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3955/107898 [21:30<9:24:24,  3.07it/s][2025-01-30 02:13:39][root][INFO] - Training Epoch: 1/2, step 3954/107898 completed (loss: 1.4290904998779297, acc: 0.75)
[2025-01-30 02:13:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3956/107898 [21:30<9:37:38,  3.00it/s][2025-01-30 02:13:40][root][INFO] - Training Epoch: 1/2, step 3955/107898 completed (loss: 2.4321858882904053, acc: 0.4285714328289032)
[2025-01-30 02:13:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3957/107898 [21:30<9:46:08,  2.96it/s][2025-01-30 02:13:40][root][INFO] - Training Epoch: 1/2, step 3956/107898 completed (loss: 0.6427409052848816, acc: 0.8333333134651184)
[2025-01-30 02:13:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3958/107898 [21:31<9:37:11,  3.00it/s][2025-01-30 02:13:40][root][INFO] - Training Epoch: 1/2, step 3957/107898 completed (loss: 2.162771701812744, acc: 0.6000000238418579)
[2025-01-30 02:13:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3959/107898 [21:31<9:43:56,  2.97it/s][2025-01-30 02:13:41][root][INFO] - Training Epoch: 1/2, step 3958/107898 completed (loss: 2.19683837890625, acc: 0.6000000238418579)
[2025-01-30 02:13:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3960/107898 [21:31<9:52:13,  2.93it/s][2025-01-30 02:13:41][root][INFO] - Training Epoch: 1/2, step 3959/107898 completed (loss: 0.3614867329597473, acc: 1.0)
[2025-01-30 02:13:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3961/107898 [21:32<9:52:33,  2.92it/s][2025-01-30 02:13:42][root][INFO] - Training Epoch: 1/2, step 3960/107898 completed (loss: 0.3217135965824127, acc: 1.0)
[2025-01-30 02:13:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3962/107898 [21:32<10:01:18,  2.88it/s][2025-01-30 02:13:42][root][INFO] - Training Epoch: 1/2, step 3961/107898 completed (loss: 0.8062431216239929, acc: 0.8181818127632141)
[2025-01-30 02:13:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3963/107898 [21:32<9:43:24,  2.97it/s] [2025-01-30 02:13:42][root][INFO] - Training Epoch: 1/2, step 3962/107898 completed (loss: 1.110163927078247, acc: 0.699999988079071)
[2025-01-30 02:13:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3964/107898 [21:33<9:42:23,  2.97it/s][2025-01-30 02:13:43][root][INFO] - Training Epoch: 1/2, step 3963/107898 completed (loss: 0.03645486757159233, acc: 1.0)
[2025-01-30 02:13:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3965/107898 [21:33<9:40:33,  2.98it/s][2025-01-30 02:13:43][root][INFO] - Training Epoch: 1/2, step 3964/107898 completed (loss: 0.5062293410301208, acc: 1.0)
[2025-01-30 02:13:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3966/107898 [21:33<9:55:55,  2.91it/s][2025-01-30 02:13:43][root][INFO] - Training Epoch: 1/2, step 3965/107898 completed (loss: 1.6485493183135986, acc: 0.7142857313156128)
[2025-01-30 02:13:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3967/107898 [21:34<9:26:44,  3.06it/s][2025-01-30 02:13:43][root][INFO] - Training Epoch: 1/2, step 3966/107898 completed (loss: 0.061794597655534744, acc: 1.0)
[2025-01-30 02:13:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3968/107898 [21:34<9:40:35,  2.98it/s][2025-01-30 02:13:44][root][INFO] - Training Epoch: 1/2, step 3967/107898 completed (loss: 1.5560554265975952, acc: 0.5)
[2025-01-30 02:13:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3969/107898 [21:34<9:50:33,  2.93it/s][2025-01-30 02:13:44][root][INFO] - Training Epoch: 1/2, step 3968/107898 completed (loss: 0.00990641675889492, acc: 1.0)
[2025-01-30 02:13:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3970/107898 [21:35<9:26:51,  3.06it/s][2025-01-30 02:13:44][root][INFO] - Training Epoch: 1/2, step 3969/107898 completed (loss: 0.88034588098526, acc: 0.7666666507720947)
[2025-01-30 02:13:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3971/107898 [21:35<9:33:12,  3.02it/s][2025-01-30 02:13:45][root][INFO] - Training Epoch: 1/2, step 3970/107898 completed (loss: 1.6086094379425049, acc: 0.692307710647583)
[2025-01-30 02:13:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3972/107898 [21:35<9:51:24,  2.93it/s][2025-01-30 02:13:45][root][INFO] - Training Epoch: 1/2, step 3971/107898 completed (loss: 1.8761485815048218, acc: 0.75)
[2025-01-30 02:13:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3973/107898 [21:36<9:49:23,  2.94it/s][2025-01-30 02:13:46][root][INFO] - Training Epoch: 1/2, step 3972/107898 completed (loss: 0.43776822090148926, acc: 0.6666666865348816)
[2025-01-30 02:13:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3974/107898 [21:36<9:56:01,  2.91it/s][2025-01-30 02:13:46][root][INFO] - Training Epoch: 1/2, step 3973/107898 completed (loss: 1.3786418437957764, acc: 0.5)
[2025-01-30 02:13:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3975/107898 [21:36<10:08:16,  2.85it/s][2025-01-30 02:13:46][root][INFO] - Training Epoch: 1/2, step 3974/107898 completed (loss: 0.6337639093399048, acc: 0.8333333134651184)
[2025-01-30 02:13:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3976/107898 [21:37<10:19:19,  2.80it/s][2025-01-30 02:13:47][root][INFO] - Training Epoch: 1/2, step 3975/107898 completed (loss: 0.15691816806793213, acc: 1.0)
[2025-01-30 02:13:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3977/107898 [21:37<10:03:09,  2.87it/s][2025-01-30 02:13:47][root][INFO] - Training Epoch: 1/2, step 3976/107898 completed (loss: 2.857156991958618, acc: 0.5454545617103577)
[2025-01-30 02:13:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3978/107898 [21:37<9:37:37,  3.00it/s] [2025-01-30 02:13:47][root][INFO] - Training Epoch: 1/2, step 3977/107898 completed (loss: 0.37121906876564026, acc: 1.0)
[2025-01-30 02:13:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3979/107898 [21:38<9:10:19,  3.15it/s][2025-01-30 02:13:48][root][INFO] - Training Epoch: 1/2, step 3978/107898 completed (loss: 0.021478570997714996, acc: 1.0)
[2025-01-30 02:13:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3980/107898 [21:38<9:25:53,  3.06it/s][2025-01-30 02:13:48][root][INFO] - Training Epoch: 1/2, step 3979/107898 completed (loss: 0.6467561721801758, acc: 0.75)
[2025-01-30 02:13:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3981/107898 [21:38<9:27:19,  3.05it/s][2025-01-30 02:13:48][root][INFO] - Training Epoch: 1/2, step 3980/107898 completed (loss: 0.39372003078460693, acc: 0.800000011920929)
[2025-01-30 02:13:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3982/107898 [21:39<9:18:08,  3.10it/s][2025-01-30 02:13:49][root][INFO] - Training Epoch: 1/2, step 3981/107898 completed (loss: 0.08559851348400116, acc: 1.0)
[2025-01-30 02:13:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3983/107898 [21:39<9:17:38,  3.11it/s][2025-01-30 02:13:49][root][INFO] - Training Epoch: 1/2, step 3982/107898 completed (loss: 2.4907827377319336, acc: 0.2631579041481018)
[2025-01-30 02:13:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3984/107898 [21:39<9:21:20,  3.09it/s][2025-01-30 02:13:49][root][INFO] - Training Epoch: 1/2, step 3983/107898 completed (loss: 0.0017481985269114375, acc: 1.0)
[2025-01-30 02:13:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3985/107898 [21:40<9:04:55,  3.18it/s][2025-01-30 02:13:49][root][INFO] - Training Epoch: 1/2, step 3984/107898 completed (loss: 4.326777458190918, acc: 0.5)
[2025-01-30 02:13:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3986/107898 [21:40<9:03:35,  3.19it/s][2025-01-30 02:13:50][root][INFO] - Training Epoch: 1/2, step 3985/107898 completed (loss: 1.1927586793899536, acc: 0.875)
[2025-01-30 02:13:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3987/107898 [21:40<9:15:39,  3.12it/s][2025-01-30 02:13:50][root][INFO] - Training Epoch: 1/2, step 3986/107898 completed (loss: 0.31400173902511597, acc: 0.9047619104385376)
[2025-01-30 02:13:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3988/107898 [21:41<9:33:45,  3.02it/s][2025-01-30 02:13:50][root][INFO] - Training Epoch: 1/2, step 3987/107898 completed (loss: 4.25209903717041, acc: 0.4000000059604645)
[2025-01-30 02:13:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3989/107898 [21:41<9:26:25,  3.06it/s][2025-01-30 02:13:51][root][INFO] - Training Epoch: 1/2, step 3988/107898 completed (loss: 1.4262653589248657, acc: 0.625)
[2025-01-30 02:13:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3990/107898 [21:41<9:19:29,  3.10it/s][2025-01-30 02:13:51][root][INFO] - Training Epoch: 1/2, step 3989/107898 completed (loss: 3.5207531452178955, acc: 0.3888888955116272)
[2025-01-30 02:13:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3991/107898 [21:42<9:21:18,  3.09it/s][2025-01-30 02:13:51][root][INFO] - Training Epoch: 1/2, step 3990/107898 completed (loss: 1.8822022676467896, acc: 0.6428571343421936)
[2025-01-30 02:13:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3992/107898 [21:42<9:11:18,  3.14it/s][2025-01-30 02:13:52][root][INFO] - Training Epoch: 1/2, step 3991/107898 completed (loss: 0.3165759742259979, acc: 1.0)
[2025-01-30 02:13:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3993/107898 [21:42<9:29:21,  3.04it/s][2025-01-30 02:13:52][root][INFO] - Training Epoch: 1/2, step 3992/107898 completed (loss: 1.8509690761566162, acc: 0.5714285969734192)
[2025-01-30 02:13:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3994/107898 [21:43<9:12:13,  3.14it/s][2025-01-30 02:13:52][root][INFO] - Training Epoch: 1/2, step 3993/107898 completed (loss: 0.6186703443527222, acc: 0.8125)
[2025-01-30 02:13:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3995/107898 [21:43<8:56:17,  3.23it/s][2025-01-30 02:13:53][root][INFO] - Training Epoch: 1/2, step 3994/107898 completed (loss: 0.001294230460189283, acc: 1.0)
[2025-01-30 02:13:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3996/107898 [21:43<9:00:10,  3.21it/s][2025-01-30 02:13:53][root][INFO] - Training Epoch: 1/2, step 3995/107898 completed (loss: 0.007284743711352348, acc: 1.0)
[2025-01-30 02:13:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3997/107898 [21:44<9:00:38,  3.20it/s][2025-01-30 02:13:53][root][INFO] - Training Epoch: 1/2, step 3996/107898 completed (loss: 0.27914705872535706, acc: 0.9444444179534912)
[2025-01-30 02:13:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3998/107898 [21:44<9:03:03,  3.19it/s][2025-01-30 02:13:54][root][INFO] - Training Epoch: 1/2, step 3997/107898 completed (loss: 0.34895092248916626, acc: 0.9024389982223511)
[2025-01-30 02:13:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 3999/107898 [21:44<9:27:35,  3.05it/s][2025-01-30 02:13:54][root][INFO] - Training Epoch: 1/2, step 3998/107898 completed (loss: 0.7133408784866333, acc: 0.75)
[2025-01-30 02:13:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4000/107898 [21:45<9:18:20,  3.10it/s][2025-01-30 02:13:54][root][INFO] - Training Epoch: 1/2, step 3999/107898 completed (loss: 0.25052130222320557, acc: 0.9545454382896423)
[2025-01-30 02:13:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4001/107898 [21:45<9:02:04,  3.19it/s][2025-01-30 02:13:55][root][INFO] - Training Epoch: 1/2, step 4000/107898 completed (loss: 1.562296748161316, acc: 0.6666666865348816)
[2025-01-30 02:13:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4002/107898 [21:45<8:57:30,  3.22it/s][2025-01-30 02:13:55][root][INFO] - Training Epoch: 1/2, step 4001/107898 completed (loss: 1.0473291873931885, acc: 0.9333333373069763)
[2025-01-30 02:13:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4003/107898 [21:45<8:52:06,  3.25it/s][2025-01-30 02:13:55][root][INFO] - Training Epoch: 1/2, step 4002/107898 completed (loss: 0.12396875768899918, acc: 1.0)
[2025-01-30 02:13:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4004/107898 [21:46<9:09:12,  3.15it/s][2025-01-30 02:13:56][root][INFO] - Training Epoch: 1/2, step 4003/107898 completed (loss: 1.7416144609451294, acc: 0.8461538553237915)
[2025-01-30 02:13:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4005/107898 [21:46<9:03:48,  3.18it/s][2025-01-30 02:13:56][root][INFO] - Training Epoch: 1/2, step 4004/107898 completed (loss: 0.7799620032310486, acc: 0.7272727489471436)
[2025-01-30 02:13:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4006/107898 [21:46<9:31:03,  3.03it/s][2025-01-30 02:13:56][root][INFO] - Training Epoch: 1/2, step 4005/107898 completed (loss: 4.39985466003418, acc: 0.3611111044883728)
[2025-01-30 02:13:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4007/107898 [21:47<9:47:44,  2.95it/s][2025-01-30 02:13:57][root][INFO] - Training Epoch: 1/2, step 4006/107898 completed (loss: 0.8225402235984802, acc: 0.6666666865348816)
[2025-01-30 02:13:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4008/107898 [21:47<9:22:02,  3.08it/s][2025-01-30 02:13:57][root][INFO] - Training Epoch: 1/2, step 4007/107898 completed (loss: 0.7439402937889099, acc: 0.75)
[2025-01-30 02:13:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4009/107898 [21:47<9:09:15,  3.15it/s][2025-01-30 02:13:57][root][INFO] - Training Epoch: 1/2, step 4008/107898 completed (loss: 1.4968181848526, acc: 0.7857142686843872)
[2025-01-30 02:13:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4010/107898 [21:48<9:18:05,  3.10it/s][2025-01-30 02:13:57][root][INFO] - Training Epoch: 1/2, step 4009/107898 completed (loss: 0.037309929728507996, acc: 1.0)
[2025-01-30 02:13:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4011/107898 [21:48<9:27:29,  3.05it/s][2025-01-30 02:13:58][root][INFO] - Training Epoch: 1/2, step 4010/107898 completed (loss: 0.6602491736412048, acc: 0.8260869383811951)
[2025-01-30 02:13:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4012/107898 [21:48<9:24:56,  3.06it/s][2025-01-30 02:13:58][root][INFO] - Training Epoch: 1/2, step 4011/107898 completed (loss: 0.04272739961743355, acc: 1.0)
[2025-01-30 02:13:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4013/107898 [21:49<9:47:40,  2.95it/s][2025-01-30 02:13:59][root][INFO] - Training Epoch: 1/2, step 4012/107898 completed (loss: 1.1723449230194092, acc: 0.8205128312110901)
[2025-01-30 02:13:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4014/107898 [21:49<9:33:11,  3.02it/s][2025-01-30 02:13:59][root][INFO] - Training Epoch: 1/2, step 4013/107898 completed (loss: 1.5540326833724976, acc: 0.5384615659713745)
[2025-01-30 02:13:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4015/107898 [21:49<9:15:16,  3.12it/s][2025-01-30 02:13:59][root][INFO] - Training Epoch: 1/2, step 4014/107898 completed (loss: 0.7456827759742737, acc: 0.5)
[2025-01-30 02:13:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4016/107898 [21:50<9:17:17,  3.11it/s][2025-01-30 02:13:59][root][INFO] - Training Epoch: 1/2, step 4015/107898 completed (loss: 0.11440771818161011, acc: 1.0)
[2025-01-30 02:14:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4017/107898 [21:50<9:01:09,  3.20it/s][2025-01-30 02:14:00][root][INFO] - Training Epoch: 1/2, step 4016/107898 completed (loss: 1.5196763277053833, acc: 0.6666666865348816)
[2025-01-30 02:14:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4018/107898 [21:50<8:53:18,  3.25it/s][2025-01-30 02:14:00][root][INFO] - Training Epoch: 1/2, step 4017/107898 completed (loss: 0.9725990295410156, acc: 0.8333333134651184)
[2025-01-30 02:14:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4019/107898 [21:51<8:55:17,  3.23it/s][2025-01-30 02:14:00][root][INFO] - Training Epoch: 1/2, step 4018/107898 completed (loss: 0.05631297826766968, acc: 1.0)
[2025-01-30 02:14:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4020/107898 [21:51<9:22:03,  3.08it/s][2025-01-30 02:14:01][root][INFO] - Training Epoch: 1/2, step 4019/107898 completed (loss: 1.1037039756774902, acc: 0.7272727489471436)
[2025-01-30 02:14:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4021/107898 [21:51<9:18:24,  3.10it/s][2025-01-30 02:14:01][root][INFO] - Training Epoch: 1/2, step 4020/107898 completed (loss: 1.1288902759552002, acc: 0.7142857313156128)
[2025-01-30 02:14:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4022/107898 [21:52<9:16:13,  3.11it/s][2025-01-30 02:14:01][root][INFO] - Training Epoch: 1/2, step 4021/107898 completed (loss: 0.07911618053913116, acc: 1.0)
[2025-01-30 02:14:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4023/107898 [21:52<9:33:38,  3.02it/s][2025-01-30 02:14:02][root][INFO] - Training Epoch: 1/2, step 4022/107898 completed (loss: 0.36540257930755615, acc: 1.0)
[2025-01-30 02:14:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4024/107898 [21:52<9:53:01,  2.92it/s][2025-01-30 02:14:02][root][INFO] - Training Epoch: 1/2, step 4023/107898 completed (loss: 1.0581128597259521, acc: 0.6785714030265808)
[2025-01-30 02:14:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4025/107898 [21:53<9:51:00,  2.93it/s][2025-01-30 02:14:02][root][INFO] - Training Epoch: 1/2, step 4024/107898 completed (loss: 2.6655266284942627, acc: 0.4117647111415863)
[2025-01-30 02:14:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4026/107898 [21:53<9:37:20,  3.00it/s][2025-01-30 02:14:03][root][INFO] - Training Epoch: 1/2, step 4025/107898 completed (loss: 0.19455653429031372, acc: 1.0)
[2025-01-30 02:14:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4027/107898 [21:53<9:37:58,  3.00it/s][2025-01-30 02:14:03][root][INFO] - Training Epoch: 1/2, step 4026/107898 completed (loss: 3.120410442352295, acc: 0.5)
[2025-01-30 02:14:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4028/107898 [21:54<9:13:55,  3.13it/s][2025-01-30 02:14:03][root][INFO] - Training Epoch: 1/2, step 4027/107898 completed (loss: 0.40634676814079285, acc: 1.0)
[2025-01-30 02:14:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4029/107898 [21:54<9:30:57,  3.03it/s][2025-01-30 02:14:04][root][INFO] - Training Epoch: 1/2, step 4028/107898 completed (loss: 0.3562207520008087, acc: 0.8846153616905212)
[2025-01-30 02:14:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4030/107898 [21:54<9:20:51,  3.09it/s][2025-01-30 02:14:04][root][INFO] - Training Epoch: 1/2, step 4029/107898 completed (loss: 0.41920626163482666, acc: 1.0)
[2025-01-30 02:14:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4031/107898 [21:55<9:05:07,  3.18it/s][2025-01-30 02:14:04][root][INFO] - Training Epoch: 1/2, step 4030/107898 completed (loss: 0.00263759377412498, acc: 1.0)
[2025-01-30 02:14:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4032/107898 [21:55<9:06:50,  3.17it/s][2025-01-30 02:14:05][root][INFO] - Training Epoch: 1/2, step 4031/107898 completed (loss: 1.5826934576034546, acc: 0.6666666865348816)
[2025-01-30 02:14:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4033/107898 [21:55<8:59:03,  3.21it/s][2025-01-30 02:14:05][root][INFO] - Training Epoch: 1/2, step 4032/107898 completed (loss: 1.7635689973831177, acc: 0.7222222089767456)
[2025-01-30 02:14:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4034/107898 [21:55<9:18:03,  3.10it/s][2025-01-30 02:14:05][root][INFO] - Training Epoch: 1/2, step 4033/107898 completed (loss: 0.15337446331977844, acc: 1.0)
[2025-01-30 02:14:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4035/107898 [21:56<9:27:52,  3.05it/s][2025-01-30 02:14:06][root][INFO] - Training Epoch: 1/2, step 4034/107898 completed (loss: 0.6085126399993896, acc: 0.8620689511299133)
[2025-01-30 02:14:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4036/107898 [21:56<9:45:57,  2.95it/s][2025-01-30 02:14:06][root][INFO] - Training Epoch: 1/2, step 4035/107898 completed (loss: 0.21346335113048553, acc: 0.9090909361839294)
[2025-01-30 02:14:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4037/107898 [21:57<9:56:26,  2.90it/s][2025-01-30 02:14:06][root][INFO] - Training Epoch: 1/2, step 4036/107898 completed (loss: 0.004534355364739895, acc: 1.0)
[2025-01-30 02:14:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4038/107898 [21:57<9:48:17,  2.94it/s][2025-01-30 02:14:07][root][INFO] - Training Epoch: 1/2, step 4037/107898 completed (loss: 0.6984199285507202, acc: 0.875)
[2025-01-30 02:14:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4039/107898 [21:57<9:26:49,  3.05it/s][2025-01-30 02:14:07][root][INFO] - Training Epoch: 1/2, step 4038/107898 completed (loss: 0.02667139656841755, acc: 1.0)
[2025-01-30 02:14:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4040/107898 [21:58<9:38:08,  2.99it/s][2025-01-30 02:14:07][root][INFO] - Training Epoch: 1/2, step 4039/107898 completed (loss: 0.8967594504356384, acc: 0.8333333134651184)
[2025-01-30 02:14:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4041/107898 [21:58<9:53:49,  2.91it/s][2025-01-30 02:14:08][root][INFO] - Training Epoch: 1/2, step 4040/107898 completed (loss: 1.3430043458938599, acc: 0.7647058963775635)
[2025-01-30 02:14:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4042/107898 [21:58<9:48:37,  2.94it/s][2025-01-30 02:14:08][root][INFO] - Training Epoch: 1/2, step 4041/107898 completed (loss: 2.9147889614105225, acc: 0.5)
[2025-01-30 02:14:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4043/107898 [21:59<9:45:03,  2.96it/s][2025-01-30 02:14:08][root][INFO] - Training Epoch: 1/2, step 4042/107898 completed (loss: 3.1885972023010254, acc: 0.4000000059604645)
[2025-01-30 02:14:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4044/107898 [21:59<9:30:16,  3.04it/s][2025-01-30 02:14:09][root][INFO] - Training Epoch: 1/2, step 4043/107898 completed (loss: 1.6470906734466553, acc: 0.75)
[2025-01-30 02:14:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4045/107898 [21:59<9:36:55,  3.00it/s][2025-01-30 02:14:09][root][INFO] - Training Epoch: 1/2, step 4044/107898 completed (loss: 0.760811448097229, acc: 0.8620689511299133)
[2025-01-30 02:14:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–Ž         [0m| 4046/107898 [22:00<9:20:44,  3.09it/s][2025-01-30 02:14:09][root][INFO] - Training Epoch: 1/2, step 4045/107898 completed (loss: 0.2311926782131195, acc: 0.9411764740943909)
[2025-01-30 02:14:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4047/107898 [22:00<9:27:15,  3.05it/s][2025-01-30 02:14:10][root][INFO] - Training Epoch: 1/2, step 4046/107898 completed (loss: 1.6232683658599854, acc: 0.75)
[2025-01-30 02:14:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4048/107898 [22:00<9:25:13,  3.06it/s][2025-01-30 02:14:10][root][INFO] - Training Epoch: 1/2, step 4047/107898 completed (loss: 3.6492936611175537, acc: 0.25)
[2025-01-30 02:14:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4049/107898 [22:01<9:38:02,  2.99it/s][2025-01-30 02:14:10][root][INFO] - Training Epoch: 1/2, step 4048/107898 completed (loss: 0.6751502156257629, acc: 0.8095238208770752)
[2025-01-30 02:14:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4050/107898 [22:01<9:50:42,  2.93it/s][2025-01-30 02:14:11][root][INFO] - Training Epoch: 1/2, step 4049/107898 completed (loss: 1.3652130365371704, acc: 0.8571428656578064)
[2025-01-30 02:14:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4051/107898 [22:01<9:27:30,  3.05it/s][2025-01-30 02:14:11][root][INFO] - Training Epoch: 1/2, step 4050/107898 completed (loss: 3.00954008102417, acc: 0.3333333432674408)
[2025-01-30 02:14:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4052/107898 [22:02<9:47:14,  2.95it/s][2025-01-30 02:14:11][root][INFO] - Training Epoch: 1/2, step 4051/107898 completed (loss: 4.0368266105651855, acc: 0.25)
[2025-01-30 02:14:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4053/107898 [22:02<9:45:40,  2.96it/s][2025-01-30 02:14:12][root][INFO] - Training Epoch: 1/2, step 4052/107898 completed (loss: 1.1981899738311768, acc: 0.875)
[2025-01-30 02:14:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4054/107898 [22:02<9:39:10,  2.99it/s][2025-01-30 02:14:12][root][INFO] - Training Epoch: 1/2, step 4053/107898 completed (loss: 0.8825820684432983, acc: 0.8387096524238586)
[2025-01-30 02:14:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4055/107898 [22:02<9:17:25,  3.10it/s][2025-01-30 02:14:12][root][INFO] - Training Epoch: 1/2, step 4054/107898 completed (loss: 0.00047026650281623006, acc: 1.0)
[2025-01-30 02:14:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4056/107898 [22:03<9:06:57,  3.16it/s][2025-01-30 02:14:13][root][INFO] - Training Epoch: 1/2, step 4055/107898 completed (loss: 0.5214385986328125, acc: 0.8095238208770752)
[2025-01-30 02:14:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4057/107898 [22:03<9:39:42,  2.99it/s][2025-01-30 02:14:13][root][INFO] - Training Epoch: 1/2, step 4056/107898 completed (loss: 0.45644593238830566, acc: 0.9259259104728699)
[2025-01-30 02:14:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4058/107898 [22:04<9:35:36,  3.01it/s][2025-01-30 02:14:13][root][INFO] - Training Epoch: 1/2, step 4057/107898 completed (loss: 0.27158334851264954, acc: 0.9375)
[2025-01-30 02:14:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4059/107898 [22:04<9:58:42,  2.89it/s][2025-01-30 02:14:14][root][INFO] - Training Epoch: 1/2, step 4058/107898 completed (loss: 0.40933865308761597, acc: 0.8571428656578064)
[2025-01-30 02:14:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4060/107898 [22:04<9:21:21,  3.08it/s][2025-01-30 02:14:14][root][INFO] - Training Epoch: 1/2, step 4059/107898 completed (loss: 0.007174360565841198, acc: 1.0)
[2025-01-30 02:14:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4061/107898 [22:05<9:42:13,  2.97it/s][2025-01-30 02:14:14][root][INFO] - Training Epoch: 1/2, step 4060/107898 completed (loss: 1.377603530883789, acc: 0.8214285969734192)
[2025-01-30 02:14:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4062/107898 [22:05<9:36:46,  3.00it/s][2025-01-30 02:14:15][root][INFO] - Training Epoch: 1/2, step 4061/107898 completed (loss: 0.11100276559591293, acc: 1.0)
[2025-01-30 02:14:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4063/107898 [22:05<9:22:08,  3.08it/s][2025-01-30 02:14:15][root][INFO] - Training Epoch: 1/2, step 4062/107898 completed (loss: 0.7463862895965576, acc: 0.8571428656578064)
[2025-01-30 02:14:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4064/107898 [22:05<9:31:00,  3.03it/s][2025-01-30 02:14:15][root][INFO] - Training Epoch: 1/2, step 4063/107898 completed (loss: 0.8994886875152588, acc: 0.5)
[2025-01-30 02:14:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4065/107898 [22:06<9:32:48,  3.02it/s][2025-01-30 02:14:16][root][INFO] - Training Epoch: 1/2, step 4064/107898 completed (loss: 4.183929920196533, acc: 0.3076923191547394)
[2025-01-30 02:14:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4066/107898 [22:06<9:41:44,  2.97it/s][2025-01-30 02:14:16][root][INFO] - Training Epoch: 1/2, step 4065/107898 completed (loss: 0.6250613331794739, acc: 0.875)
[2025-01-30 02:14:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4067/107898 [22:06<9:31:23,  3.03it/s][2025-01-30 02:14:16][root][INFO] - Training Epoch: 1/2, step 4066/107898 completed (loss: 3.4071669578552246, acc: 0.5)
[2025-01-30 02:14:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4068/107898 [22:07<9:07:45,  3.16it/s][2025-01-30 02:14:17][root][INFO] - Training Epoch: 1/2, step 4067/107898 completed (loss: 0.5908067226409912, acc: 0.8888888955116272)
[2025-01-30 02:14:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4069/107898 [22:07<8:59:34,  3.21it/s][2025-01-30 02:14:17][root][INFO] - Training Epoch: 1/2, step 4068/107898 completed (loss: 1.869044303894043, acc: 0.6666666865348816)
[2025-01-30 02:14:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4070/107898 [22:07<8:51:50,  3.25it/s][2025-01-30 02:14:17][root][INFO] - Training Epoch: 1/2, step 4069/107898 completed (loss: 0.3560447692871094, acc: 0.8333333134651184)
[2025-01-30 02:14:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4071/107898 [22:08<8:50:42,  3.26it/s][2025-01-30 02:14:17][root][INFO] - Training Epoch: 1/2, step 4070/107898 completed (loss: 2.3005757331848145, acc: 0.517241358757019)
[2025-01-30 02:14:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4072/107898 [22:08<8:51:49,  3.25it/s][2025-01-30 02:14:18][root][INFO] - Training Epoch: 1/2, step 4071/107898 completed (loss: 0.6051519513130188, acc: 0.8235294222831726)
[2025-01-30 02:14:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4073/107898 [22:08<9:06:40,  3.17it/s][2025-01-30 02:14:18][root][INFO] - Training Epoch: 1/2, step 4072/107898 completed (loss: 1.584631085395813, acc: 0.6363636255264282)
[2025-01-30 02:14:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4074/107898 [22:09<9:19:02,  3.10it/s][2025-01-30 02:14:18][root][INFO] - Training Epoch: 1/2, step 4073/107898 completed (loss: 0.5824463963508606, acc: 0.8571428656578064)
[2025-01-30 02:14:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4075/107898 [22:09<9:12:37,  3.13it/s][2025-01-30 02:14:19][root][INFO] - Training Epoch: 1/2, step 4074/107898 completed (loss: 0.3809407949447632, acc: 0.6666666865348816)
[2025-01-30 02:14:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4076/107898 [22:09<9:22:30,  3.08it/s][2025-01-30 02:14:19][root][INFO] - Training Epoch: 1/2, step 4075/107898 completed (loss: 0.5000275373458862, acc: 0.7142857313156128)
[2025-01-30 02:14:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4077/107898 [22:10<9:24:05,  3.07it/s][2025-01-30 02:14:19][root][INFO] - Training Epoch: 1/2, step 4076/107898 completed (loss: 0.400285005569458, acc: 1.0)
[2025-01-30 02:14:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4078/107898 [22:10<9:19:26,  3.09it/s][2025-01-30 02:14:20][root][INFO] - Training Epoch: 1/2, step 4077/107898 completed (loss: 0.15697813034057617, acc: 0.8571428656578064)
[2025-01-30 02:14:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4079/107898 [22:10<9:28:16,  3.04it/s][2025-01-30 02:14:20][root][INFO] - Training Epoch: 1/2, step 4078/107898 completed (loss: 0.005953445564955473, acc: 1.0)
[2025-01-30 02:14:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4080/107898 [22:11<9:26:20,  3.06it/s][2025-01-30 02:14:20][root][INFO] - Training Epoch: 1/2, step 4079/107898 completed (loss: 0.10197277367115021, acc: 1.0)
[2025-01-30 02:14:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4081/107898 [22:11<9:12:01,  3.13it/s][2025-01-30 02:14:21][root][INFO] - Training Epoch: 1/2, step 4080/107898 completed (loss: 0.3295489549636841, acc: 0.8333333134651184)
[2025-01-30 02:14:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4082/107898 [22:11<8:58:47,  3.21it/s][2025-01-30 02:14:21][root][INFO] - Training Epoch: 1/2, step 4081/107898 completed (loss: 0.7093560099601746, acc: 0.7142857313156128)
[2025-01-30 02:14:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4083/107898 [22:12<8:51:01,  3.26it/s][2025-01-30 02:14:21][root][INFO] - Training Epoch: 1/2, step 4082/107898 completed (loss: 0.5939594507217407, acc: 0.5)
[2025-01-30 02:14:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4084/107898 [22:12<8:50:03,  3.26it/s][2025-01-30 02:14:22][root][INFO] - Training Epoch: 1/2, step 4083/107898 completed (loss: 1.766295313835144, acc: 0.7272727489471436)
[2025-01-30 02:14:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4085/107898 [22:12<8:44:13,  3.30it/s][2025-01-30 02:14:22][root][INFO] - Training Epoch: 1/2, step 4084/107898 completed (loss: 0.4418591260910034, acc: 1.0)
[2025-01-30 02:14:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4086/107898 [22:12<8:45:05,  3.30it/s][2025-01-30 02:14:22][root][INFO] - Training Epoch: 1/2, step 4085/107898 completed (loss: 0.36171093583106995, acc: 0.8999999761581421)
[2025-01-30 02:14:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4087/107898 [22:13<9:00:50,  3.20it/s][2025-01-30 02:14:23][root][INFO] - Training Epoch: 1/2, step 4086/107898 completed (loss: 1.5078164339065552, acc: 0.75)
[2025-01-30 02:14:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4088/107898 [22:13<8:59:40,  3.21it/s][2025-01-30 02:14:23][root][INFO] - Training Epoch: 1/2, step 4087/107898 completed (loss: 2.7677109241485596, acc: 0.5)
[2025-01-30 02:14:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4089/107898 [22:13<8:56:59,  3.22it/s][2025-01-30 02:14:23][root][INFO] - Training Epoch: 1/2, step 4088/107898 completed (loss: 2.7030112743377686, acc: 0.4545454680919647)
[2025-01-30 02:14:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4090/107898 [22:14<9:06:51,  3.16it/s][2025-01-30 02:14:23][root][INFO] - Training Epoch: 1/2, step 4089/107898 completed (loss: 0.18949903547763824, acc: 0.9259259104728699)
[2025-01-30 02:14:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4091/107898 [22:14<9:04:02,  3.18it/s][2025-01-30 02:14:24][root][INFO] - Training Epoch: 1/2, step 4090/107898 completed (loss: 2.017585039138794, acc: 0.4545454680919647)
[2025-01-30 02:14:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4092/107898 [22:14<8:59:44,  3.21it/s][2025-01-30 02:14:24][root][INFO] - Training Epoch: 1/2, step 4091/107898 completed (loss: 0.05831948295235634, acc: 1.0)
[2025-01-30 02:14:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4093/107898 [22:15<9:25:46,  3.06it/s][2025-01-30 02:14:24][root][INFO] - Training Epoch: 1/2, step 4092/107898 completed (loss: 1.0970591306686401, acc: 0.692307710647583)
[2025-01-30 02:14:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4094/107898 [22:15<9:22:12,  3.08it/s][2025-01-30 02:14:25][root][INFO] - Training Epoch: 1/2, step 4093/107898 completed (loss: 2.4611616134643555, acc: 0.4615384638309479)
[2025-01-30 02:14:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4095/107898 [22:15<9:17:38,  3.10it/s][2025-01-30 02:14:25][root][INFO] - Training Epoch: 1/2, step 4094/107898 completed (loss: 0.050580739974975586, acc: 1.0)
[2025-01-30 02:14:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4096/107898 [22:16<9:05:22,  3.17it/s][2025-01-30 02:14:25][root][INFO] - Training Epoch: 1/2, step 4095/107898 completed (loss: 0.06730706989765167, acc: 1.0)
[2025-01-30 02:14:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4097/107898 [22:16<9:23:37,  3.07it/s][2025-01-30 02:14:26][root][INFO] - Training Epoch: 1/2, step 4096/107898 completed (loss: 0.005835448391735554, acc: 1.0)
[2025-01-30 02:14:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4098/107898 [22:16<9:28:40,  3.04it/s][2025-01-30 02:14:26][root][INFO] - Training Epoch: 1/2, step 4097/107898 completed (loss: 1.411214828491211, acc: 0.7142857313156128)
[2025-01-30 02:14:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4099/107898 [22:17<9:51:55,  2.92it/s][2025-01-30 02:14:26][root][INFO] - Training Epoch: 1/2, step 4098/107898 completed (loss: 1.8608101606369019, acc: 0.692307710647583)
[2025-01-30 02:14:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4100/107898 [22:17<9:41:10,  2.98it/s][2025-01-30 02:14:27][root][INFO] - Training Epoch: 1/2, step 4099/107898 completed (loss: 0.21928417682647705, acc: 0.9583333134651184)
[2025-01-30 02:14:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4101/107898 [22:17<9:28:09,  3.04it/s][2025-01-30 02:14:27][root][INFO] - Training Epoch: 1/2, step 4100/107898 completed (loss: 0.0854010134935379, acc: 1.0)
[2025-01-30 02:14:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4102/107898 [22:18<9:12:13,  3.13it/s][2025-01-30 02:14:27][root][INFO] - Training Epoch: 1/2, step 4101/107898 completed (loss: 0.9073063731193542, acc: 0.8947368264198303)
[2025-01-30 02:14:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4103/107898 [22:18<9:29:59,  3.03it/s][2025-01-30 02:14:28][root][INFO] - Training Epoch: 1/2, step 4102/107898 completed (loss: 0.7068740129470825, acc: 0.8999999761581421)
[2025-01-30 02:14:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4104/107898 [22:18<9:24:00,  3.07it/s][2025-01-30 02:14:28][root][INFO] - Training Epoch: 1/2, step 4103/107898 completed (loss: 1.3791941404342651, acc: 0.8181818127632141)
[2025-01-30 02:14:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4105/107898 [22:19<9:18:18,  3.10it/s][2025-01-30 02:14:28][root][INFO] - Training Epoch: 1/2, step 4104/107898 completed (loss: 1.05022132396698, acc: 0.8275862336158752)
[2025-01-30 02:14:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4106/107898 [22:19<9:40:22,  2.98it/s][2025-01-30 02:14:29][root][INFO] - Training Epoch: 1/2, step 4105/107898 completed (loss: 1.305733323097229, acc: 0.8095238208770752)
[2025-01-30 02:14:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4107/107898 [22:19<9:34:33,  3.01it/s][2025-01-30 02:14:29][root][INFO] - Training Epoch: 1/2, step 4106/107898 completed (loss: 0.004903462249785662, acc: 1.0)
[2025-01-30 02:14:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4108/107898 [22:20<9:45:57,  2.95it/s][2025-01-30 02:14:29][root][INFO] - Training Epoch: 1/2, step 4107/107898 completed (loss: 4.099076271057129, acc: 0.11538461595773697)
[2025-01-30 02:14:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4109/107898 [22:20<9:27:43,  3.05it/s][2025-01-30 02:14:30][root][INFO] - Training Epoch: 1/2, step 4108/107898 completed (loss: 1.962286114692688, acc: 0.7058823704719543)
[2025-01-30 02:14:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4110/107898 [22:20<9:30:48,  3.03it/s][2025-01-30 02:14:30][root][INFO] - Training Epoch: 1/2, step 4109/107898 completed (loss: 0.9883437156677246, acc: 0.5)
[2025-01-30 02:14:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4111/107898 [22:21<9:27:46,  3.05it/s][2025-01-30 02:14:30][root][INFO] - Training Epoch: 1/2, step 4110/107898 completed (loss: 0.354521781206131, acc: 0.9230769276618958)
[2025-01-30 02:14:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4112/107898 [22:21<9:18:50,  3.10it/s][2025-01-30 02:14:31][root][INFO] - Training Epoch: 1/2, step 4111/107898 completed (loss: 0.0044243838638067245, acc: 1.0)
[2025-01-30 02:14:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4113/107898 [22:21<9:30:08,  3.03it/s][2025-01-30 02:14:31][root][INFO] - Training Epoch: 1/2, step 4112/107898 completed (loss: 1.6097679138183594, acc: 0.5333333611488342)
[2025-01-30 02:14:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4114/107898 [22:22<9:41:38,  2.97it/s][2025-01-30 02:14:31][root][INFO] - Training Epoch: 1/2, step 4113/107898 completed (loss: 1.3808059692382812, acc: 0.7307692170143127)
[2025-01-30 02:14:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4115/107898 [22:22<9:45:50,  2.95it/s][2025-01-30 02:14:32][root][INFO] - Training Epoch: 1/2, step 4114/107898 completed (loss: 0.014053871855139732, acc: 1.0)
[2025-01-30 02:14:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4116/107898 [22:22<9:38:27,  2.99it/s][2025-01-30 02:14:32][root][INFO] - Training Epoch: 1/2, step 4115/107898 completed (loss: 0.3107936978340149, acc: 0.9473684430122375)
[2025-01-30 02:14:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4117/107898 [22:23<9:33:59,  3.01it/s][2025-01-30 02:14:32][root][INFO] - Training Epoch: 1/2, step 4116/107898 completed (loss: 1.627810001373291, acc: 0.6666666865348816)
[2025-01-30 02:14:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4118/107898 [22:23<8:58:43,  3.21it/s][2025-01-30 02:14:33][root][INFO] - Training Epoch: 1/2, step 4117/107898 completed (loss: 0.5548171401023865, acc: 0.8823529481887817)
[2025-01-30 02:14:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4119/107898 [22:23<9:20:55,  3.08it/s][2025-01-30 02:14:33][root][INFO] - Training Epoch: 1/2, step 4118/107898 completed (loss: 5.070703983306885, acc: 0.1666666716337204)
[2025-01-30 02:14:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4120/107898 [22:24<9:28:34,  3.04it/s][2025-01-30 02:14:33][root][INFO] - Training Epoch: 1/2, step 4119/107898 completed (loss: 0.2282489836215973, acc: 1.0)
[2025-01-30 02:14:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4121/107898 [22:24<9:19:31,  3.09it/s][2025-01-30 02:14:34][root][INFO] - Training Epoch: 1/2, step 4120/107898 completed (loss: 0.8651005029678345, acc: 0.8461538553237915)
[2025-01-30 02:14:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4122/107898 [22:24<9:07:52,  3.16it/s][2025-01-30 02:14:34][root][INFO] - Training Epoch: 1/2, step 4121/107898 completed (loss: 0.22526618838310242, acc: 1.0)
[2025-01-30 02:14:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4123/107898 [22:24<9:03:28,  3.18it/s][2025-01-30 02:14:34][root][INFO] - Training Epoch: 1/2, step 4122/107898 completed (loss: 2.52174711227417, acc: 0.5)
[2025-01-30 02:14:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4124/107898 [22:25<8:52:06,  3.25it/s][2025-01-30 02:14:35][root][INFO] - Training Epoch: 1/2, step 4123/107898 completed (loss: 0.6087965965270996, acc: 0.8999999761581421)
[2025-01-30 02:14:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4125/107898 [22:25<8:54:32,  3.24it/s][2025-01-30 02:14:35][root][INFO] - Training Epoch: 1/2, step 4124/107898 completed (loss: 1.1883392333984375, acc: 0.7777777910232544)
[2025-01-30 02:14:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4126/107898 [22:25<9:16:37,  3.11it/s][2025-01-30 02:14:35][root][INFO] - Training Epoch: 1/2, step 4125/107898 completed (loss: 0.0005479360115714371, acc: 1.0)
[2025-01-30 02:14:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4127/107898 [22:26<9:24:19,  3.06it/s][2025-01-30 02:14:36][root][INFO] - Training Epoch: 1/2, step 4126/107898 completed (loss: 1.5369040966033936, acc: 0.6521739363670349)
[2025-01-30 02:14:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4128/107898 [22:26<9:20:11,  3.09it/s][2025-01-30 02:14:36][root][INFO] - Training Epoch: 1/2, step 4127/107898 completed (loss: 2.6004884243011475, acc: 0.4545454680919647)
[2025-01-30 02:14:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4129/107898 [22:26<9:10:33,  3.14it/s][2025-01-30 02:14:36][root][INFO] - Training Epoch: 1/2, step 4128/107898 completed (loss: 0.298044890165329, acc: 1.0)
[2025-01-30 02:14:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4130/107898 [22:27<8:48:24,  3.27it/s][2025-01-30 02:14:36][root][INFO] - Training Epoch: 1/2, step 4129/107898 completed (loss: 1.133065104484558, acc: 0.6666666865348816)
[2025-01-30 02:14:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4131/107898 [22:27<8:41:57,  3.31it/s][2025-01-30 02:14:37][root][INFO] - Training Epoch: 1/2, step 4130/107898 completed (loss: 2.396918296813965, acc: 0.6666666865348816)
[2025-01-30 02:14:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4132/107898 [22:27<8:38:13,  3.34it/s][2025-01-30 02:14:37][root][INFO] - Training Epoch: 1/2, step 4131/107898 completed (loss: 0.5377138257026672, acc: 0.6666666865348816)
[2025-01-30 02:14:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4133/107898 [22:28<8:44:12,  3.30it/s][2025-01-30 02:14:37][root][INFO] - Training Epoch: 1/2, step 4132/107898 completed (loss: 0.7735158801078796, acc: 0.7692307829856873)
[2025-01-30 02:14:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4134/107898 [22:28<9:08:03,  3.16it/s][2025-01-30 02:14:38][root][INFO] - Training Epoch: 1/2, step 4133/107898 completed (loss: 0.7542499303817749, acc: 0.75)
[2025-01-30 02:14:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4135/107898 [22:28<9:29:28,  3.04it/s][2025-01-30 02:14:38][root][INFO] - Training Epoch: 1/2, step 4134/107898 completed (loss: 0.005245730746537447, acc: 1.0)
[2025-01-30 02:14:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4136/107898 [22:29<9:46:01,  2.95it/s][2025-01-30 02:14:38][root][INFO] - Training Epoch: 1/2, step 4135/107898 completed (loss: 4.972871780395508, acc: 0.5)
[2025-01-30 02:14:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4137/107898 [22:29<9:44:56,  2.96it/s][2025-01-30 02:14:39][root][INFO] - Training Epoch: 1/2, step 4136/107898 completed (loss: 0.013788318261504173, acc: 1.0)
[2025-01-30 02:14:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4138/107898 [22:29<9:34:17,  3.01it/s][2025-01-30 02:14:39][root][INFO] - Training Epoch: 1/2, step 4137/107898 completed (loss: 0.005582151468843222, acc: 1.0)
[2025-01-30 02:14:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4139/107898 [22:30<9:24:06,  3.07it/s][2025-01-30 02:14:39][root][INFO] - Training Epoch: 1/2, step 4138/107898 completed (loss: 0.7929713129997253, acc: 0.75)
[2025-01-30 02:14:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4140/107898 [22:30<9:16:35,  3.11it/s][2025-01-30 02:14:40][root][INFO] - Training Epoch: 1/2, step 4139/107898 completed (loss: 0.18119573593139648, acc: 1.0)
[2025-01-30 02:14:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4141/107898 [22:30<8:47:07,  3.28it/s][2025-01-30 02:14:40][root][INFO] - Training Epoch: 1/2, step 4140/107898 completed (loss: 0.47478899359703064, acc: 0.8823529481887817)
[2025-01-30 02:14:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4142/107898 [22:31<8:59:58,  3.20it/s][2025-01-30 02:14:40][root][INFO] - Training Epoch: 1/2, step 4141/107898 completed (loss: 0.4975031018257141, acc: 0.9090909361839294)
[2025-01-30 02:14:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4143/107898 [22:31<8:59:50,  3.20it/s][2025-01-30 02:14:41][root][INFO] - Training Epoch: 1/2, step 4142/107898 completed (loss: 0.29620495438575745, acc: 1.0)
[2025-01-30 02:14:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4144/107898 [22:31<9:13:56,  3.12it/s][2025-01-30 02:14:41][root][INFO] - Training Epoch: 1/2, step 4143/107898 completed (loss: 0.8689597845077515, acc: 1.0)
[2025-01-30 02:14:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4145/107898 [22:31<9:13:29,  3.12it/s][2025-01-30 02:14:41][root][INFO] - Training Epoch: 1/2, step 4144/107898 completed (loss: 1.195547103881836, acc: 0.5)
[2025-01-30 02:14:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4146/107898 [22:32<9:10:29,  3.14it/s][2025-01-30 02:14:42][root][INFO] - Training Epoch: 1/2, step 4145/107898 completed (loss: 0.3237285017967224, acc: 0.9285714030265808)
[2025-01-30 02:14:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4147/107898 [22:32<9:06:49,  3.16it/s][2025-01-30 02:14:42][root][INFO] - Training Epoch: 1/2, step 4146/107898 completed (loss: 0.5285421013832092, acc: 0.8888888955116272)
[2025-01-30 02:14:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4148/107898 [22:32<8:54:55,  3.23it/s][2025-01-30 02:14:42][root][INFO] - Training Epoch: 1/2, step 4147/107898 completed (loss: 1.1640081405639648, acc: 0.699999988079071)
[2025-01-30 02:14:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4149/107898 [22:33<8:52:10,  3.25it/s][2025-01-30 02:14:42][root][INFO] - Training Epoch: 1/2, step 4148/107898 completed (loss: 4.778462886810303, acc: 0.25)
[2025-01-30 02:14:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4150/107898 [22:33<8:53:52,  3.24it/s][2025-01-30 02:14:43][root][INFO] - Training Epoch: 1/2, step 4149/107898 completed (loss: 0.37649524211883545, acc: 0.8421052694320679)
[2025-01-30 02:14:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4151/107898 [22:33<8:52:06,  3.25it/s][2025-01-30 02:14:43][root][INFO] - Training Epoch: 1/2, step 4150/107898 completed (loss: 0.49965524673461914, acc: 1.0)
[2025-01-30 02:14:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4152/107898 [22:34<8:45:45,  3.29it/s][2025-01-30 02:14:43][root][INFO] - Training Epoch: 1/2, step 4151/107898 completed (loss: 0.5791613459587097, acc: 0.9090909361839294)
[2025-01-30 02:14:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4153/107898 [22:34<8:45:54,  3.29it/s][2025-01-30 02:14:44][root][INFO] - Training Epoch: 1/2, step 4152/107898 completed (loss: 0.29699161648750305, acc: 0.8888888955116272)
[2025-01-30 02:14:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4154/107898 [22:34<9:17:50,  3.10it/s][2025-01-30 02:14:44][root][INFO] - Training Epoch: 1/2, step 4153/107898 completed (loss: 0.2715068757534027, acc: 0.9473684430122375)
[2025-01-30 02:14:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4155/107898 [22:35<9:28:58,  3.04it/s][2025-01-30 02:14:44][root][INFO] - Training Epoch: 1/2, step 4154/107898 completed (loss: 3.1666712760925293, acc: 0.2777777910232544)
[2025-01-30 02:14:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4156/107898 [22:35<9:26:58,  3.05it/s][2025-01-30 02:14:45][root][INFO] - Training Epoch: 1/2, step 4155/107898 completed (loss: 1.3313549757003784, acc: 0.7142857313156128)
[2025-01-30 02:14:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4157/107898 [22:35<9:17:22,  3.10it/s][2025-01-30 02:14:45][root][INFO] - Training Epoch: 1/2, step 4156/107898 completed (loss: 1.1909722089767456, acc: 0.8260869383811951)
[2025-01-30 02:14:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4158/107898 [22:36<9:35:35,  3.00it/s][2025-01-30 02:14:45][root][INFO] - Training Epoch: 1/2, step 4157/107898 completed (loss: 1.0635865926742554, acc: 0.7142857313156128)
[2025-01-30 02:14:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4159/107898 [22:36<9:15:58,  3.11it/s][2025-01-30 02:14:46][root][INFO] - Training Epoch: 1/2, step 4158/107898 completed (loss: 0.0734308511018753, acc: 1.0)
[2025-01-30 02:14:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4160/107898 [22:36<9:04:10,  3.18it/s][2025-01-30 02:14:46][root][INFO] - Training Epoch: 1/2, step 4159/107898 completed (loss: 0.2342640608549118, acc: 0.8999999761581421)
[2025-01-30 02:14:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4161/107898 [22:37<9:22:47,  3.07it/s][2025-01-30 02:14:46][root][INFO] - Training Epoch: 1/2, step 4160/107898 completed (loss: 0.7191987037658691, acc: 0.8823529481887817)
[2025-01-30 02:14:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4162/107898 [22:37<9:30:08,  3.03it/s][2025-01-30 02:14:47][root][INFO] - Training Epoch: 1/2, step 4161/107898 completed (loss: 0.7720741033554077, acc: 0.800000011920929)
[2025-01-30 02:14:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4163/107898 [22:37<9:29:02,  3.04it/s][2025-01-30 02:14:47][root][INFO] - Training Epoch: 1/2, step 4162/107898 completed (loss: 1.1259547472000122, acc: 0.9166666865348816)
[2025-01-30 02:14:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4164/107898 [22:38<9:20:00,  3.09it/s][2025-01-30 02:14:47][root][INFO] - Training Epoch: 1/2, step 4163/107898 completed (loss: 0.05544009432196617, acc: 1.0)
[2025-01-30 02:14:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4165/107898 [22:38<9:14:45,  3.12it/s][2025-01-30 02:14:48][root][INFO] - Training Epoch: 1/2, step 4164/107898 completed (loss: 0.37333759665489197, acc: 0.8846153616905212)
[2025-01-30 02:14:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4166/107898 [22:38<9:24:10,  3.06it/s][2025-01-30 02:14:48][root][INFO] - Training Epoch: 1/2, step 4165/107898 completed (loss: 1.4326212406158447, acc: 0.5882353186607361)
[2025-01-30 02:14:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4167/107898 [22:39<9:26:36,  3.05it/s][2025-01-30 02:14:48][root][INFO] - Training Epoch: 1/2, step 4166/107898 completed (loss: 2.1372551918029785, acc: 0.5)
[2025-01-30 02:14:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4168/107898 [22:39<9:24:36,  3.06it/s][2025-01-30 02:14:49][root][INFO] - Training Epoch: 1/2, step 4167/107898 completed (loss: 0.723411500453949, acc: 0.800000011920929)
[2025-01-30 02:14:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4169/107898 [22:39<9:40:27,  2.98it/s][2025-01-30 02:14:49][root][INFO] - Training Epoch: 1/2, step 4168/107898 completed (loss: 1.0441538095474243, acc: 0.7419354915618896)
[2025-01-30 02:14:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4170/107898 [22:40<9:32:33,  3.02it/s][2025-01-30 02:14:49][root][INFO] - Training Epoch: 1/2, step 4169/107898 completed (loss: 0.0004186943988315761, acc: 1.0)
[2025-01-30 02:14:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4171/107898 [22:40<9:10:58,  3.14it/s][2025-01-30 02:14:50][root][INFO] - Training Epoch: 1/2, step 4170/107898 completed (loss: 1.7566254138946533, acc: 0.7857142686843872)
[2025-01-30 02:14:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4172/107898 [22:40<9:01:05,  3.19it/s][2025-01-30 02:14:50][root][INFO] - Training Epoch: 1/2, step 4171/107898 completed (loss: 0.9558575749397278, acc: 0.875)
[2025-01-30 02:14:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4173/107898 [22:40<9:28:47,  3.04it/s][2025-01-30 02:14:50][root][INFO] - Training Epoch: 1/2, step 4172/107898 completed (loss: 1.0942729711532593, acc: 0.5)
[2025-01-30 02:14:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4174/107898 [22:41<9:23:48,  3.07it/s][2025-01-30 02:14:51][root][INFO] - Training Epoch: 1/2, step 4173/107898 completed (loss: 4.149113178253174, acc: 0.1538461595773697)
[2025-01-30 02:14:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4175/107898 [22:41<9:31:57,  3.02it/s][2025-01-30 02:14:51][root][INFO] - Training Epoch: 1/2, step 4174/107898 completed (loss: 1.7888658046722412, acc: 0.75)
[2025-01-30 02:14:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4176/107898 [22:41<9:24:33,  3.06it/s][2025-01-30 02:14:51][root][INFO] - Training Epoch: 1/2, step 4175/107898 completed (loss: 4.860733509063721, acc: 0.3333333432674408)
[2025-01-30 02:14:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4177/107898 [22:42<9:18:46,  3.09it/s][2025-01-30 02:14:52][root][INFO] - Training Epoch: 1/2, step 4176/107898 completed (loss: 0.026231471449136734, acc: 1.0)
[2025-01-30 02:14:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4178/107898 [22:42<9:45:43,  2.95it/s][2025-01-30 02:14:52][root][INFO] - Training Epoch: 1/2, step 4177/107898 completed (loss: 0.5754202008247375, acc: 0.8666666746139526)
[2025-01-30 02:14:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4179/107898 [22:42<9:39:30,  2.98it/s][2025-01-30 02:14:52][root][INFO] - Training Epoch: 1/2, step 4178/107898 completed (loss: 0.13226281106472015, acc: 1.0)
[2025-01-30 02:14:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4180/107898 [22:43<9:34:19,  3.01it/s][2025-01-30 02:14:53][root][INFO] - Training Epoch: 1/2, step 4179/107898 completed (loss: 0.2989898920059204, acc: 0.8888888955116272)
[2025-01-30 02:14:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4181/107898 [22:43<9:42:04,  2.97it/s][2025-01-30 02:14:53][root][INFO] - Training Epoch: 1/2, step 4180/107898 completed (loss: 0.0015528203221037984, acc: 1.0)
[2025-01-30 02:14:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4182/107898 [22:43<9:26:30,  3.05it/s][2025-01-30 02:14:53][root][INFO] - Training Epoch: 1/2, step 4181/107898 completed (loss: 1.5081225633621216, acc: 0.6666666865348816)
[2025-01-30 02:14:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4183/107898 [22:44<9:10:42,  3.14it/s][2025-01-30 02:14:54][root][INFO] - Training Epoch: 1/2, step 4182/107898 completed (loss: 1.142015814781189, acc: 0.800000011920929)
[2025-01-30 02:14:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4184/107898 [22:44<9:09:40,  3.14it/s][2025-01-30 02:14:54][root][INFO] - Training Epoch: 1/2, step 4183/107898 completed (loss: 3.8669626712799072, acc: 0.37931033968925476)
[2025-01-30 02:14:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4185/107898 [22:44<9:01:56,  3.19it/s][2025-01-30 02:14:54][root][INFO] - Training Epoch: 1/2, step 4184/107898 completed (loss: 0.24027042090892792, acc: 0.9090909361839294)
[2025-01-30 02:14:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4186/107898 [22:45<9:20:40,  3.08it/s][2025-01-30 02:14:55][root][INFO] - Training Epoch: 1/2, step 4185/107898 completed (loss: 0.8005717992782593, acc: 0.7857142686843872)
[2025-01-30 02:14:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4187/107898 [22:45<9:14:58,  3.11it/s][2025-01-30 02:14:55][root][INFO] - Training Epoch: 1/2, step 4186/107898 completed (loss: 2.1069374084472656, acc: 0.6000000238418579)
[2025-01-30 02:14:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4188/107898 [22:45<9:34:35,  3.01it/s][2025-01-30 02:14:55][root][INFO] - Training Epoch: 1/2, step 4187/107898 completed (loss: 0.012321004644036293, acc: 1.0)
[2025-01-30 02:14:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4189/107898 [22:46<9:46:42,  2.95it/s][2025-01-30 02:14:56][root][INFO] - Training Epoch: 1/2, step 4188/107898 completed (loss: 0.6861975193023682, acc: 0.8636363744735718)
[2025-01-30 02:14:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4190/107898 [22:46<9:25:01,  3.06it/s][2025-01-30 02:14:56][root][INFO] - Training Epoch: 1/2, step 4189/107898 completed (loss: 0.11354883015155792, acc: 1.0)
[2025-01-30 02:14:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4191/107898 [22:46<9:08:56,  3.15it/s][2025-01-30 02:14:56][root][INFO] - Training Epoch: 1/2, step 4190/107898 completed (loss: 0.2974669635295868, acc: 0.75)
[2025-01-30 02:14:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4192/107898 [22:47<9:39:06,  2.98it/s][2025-01-30 02:14:57][root][INFO] - Training Epoch: 1/2, step 4191/107898 completed (loss: 0.6934537887573242, acc: 0.875)
[2025-01-30 02:14:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4193/107898 [22:47<9:36:53,  3.00it/s][2025-01-30 02:14:57][root][INFO] - Training Epoch: 1/2, step 4192/107898 completed (loss: 3.230947732925415, acc: 0.1428571492433548)
[2025-01-30 02:14:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4194/107898 [22:47<9:28:59,  3.04it/s][2025-01-30 02:14:57][root][INFO] - Training Epoch: 1/2, step 4193/107898 completed (loss: 1.771765112876892, acc: 0.7857142686843872)
[2025-01-30 02:14:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4195/107898 [22:48<9:22:15,  3.07it/s][2025-01-30 02:14:57][root][INFO] - Training Epoch: 1/2, step 4194/107898 completed (loss: 1.8133615255355835, acc: 0.5384615659713745)
[2025-01-30 02:14:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4196/107898 [22:48<9:33:38,  3.01it/s][2025-01-30 02:14:58][root][INFO] - Training Epoch: 1/2, step 4195/107898 completed (loss: 1.5256158113479614, acc: 0.7272727489471436)
[2025-01-30 02:14:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4197/107898 [22:48<9:42:50,  2.97it/s][2025-01-30 02:14:58][root][INFO] - Training Epoch: 1/2, step 4196/107898 completed (loss: 0.08274178206920624, acc: 1.0)
[2025-01-30 02:14:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4198/107898 [22:49<9:43:31,  2.96it/s][2025-01-30 02:14:59][root][INFO] - Training Epoch: 1/2, step 4197/107898 completed (loss: 0.7267561554908752, acc: 1.0)
[2025-01-30 02:14:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4199/107898 [22:49<9:32:25,  3.02it/s][2025-01-30 02:14:59][root][INFO] - Training Epoch: 1/2, step 4198/107898 completed (loss: 1.276301383972168, acc: 0.75)
[2025-01-30 02:14:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4200/107898 [22:49<9:41:29,  2.97it/s][2025-01-30 02:14:59][root][INFO] - Training Epoch: 1/2, step 4199/107898 completed (loss: 0.3186776638031006, acc: 0.9655172228813171)
[2025-01-30 02:14:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4201/107898 [22:50<9:25:52,  3.05it/s][2025-01-30 02:14:59][root][INFO] - Training Epoch: 1/2, step 4200/107898 completed (loss: 2.2440438270568848, acc: 0.5)
[2025-01-30 02:15:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4202/107898 [22:50<9:11:48,  3.13it/s][2025-01-30 02:15:00][root][INFO] - Training Epoch: 1/2, step 4201/107898 completed (loss: 0.45399874448776245, acc: 0.875)
[2025-01-30 02:15:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4203/107898 [22:50<9:26:08,  3.05it/s][2025-01-30 02:15:00][root][INFO] - Training Epoch: 1/2, step 4202/107898 completed (loss: 0.4927869439125061, acc: 0.9375)
[2025-01-30 02:15:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4204/107898 [22:51<9:14:12,  3.12it/s][2025-01-30 02:15:00][root][INFO] - Training Epoch: 1/2, step 4203/107898 completed (loss: 0.38079583644866943, acc: 0.8888888955116272)
[2025-01-30 02:15:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4205/107898 [22:51<9:35:17,  3.00it/s][2025-01-30 02:15:01][root][INFO] - Training Epoch: 1/2, step 4204/107898 completed (loss: 0.7838353514671326, acc: 0.8461538553237915)
[2025-01-30 02:15:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4206/107898 [22:51<9:31:40,  3.02it/s][2025-01-30 02:15:01][root][INFO] - Training Epoch: 1/2, step 4205/107898 completed (loss: 2.4511783123016357, acc: 0.5384615659713745)
[2025-01-30 02:15:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4207/107898 [22:52<9:31:08,  3.03it/s][2025-01-30 02:15:01][root][INFO] - Training Epoch: 1/2, step 4206/107898 completed (loss: 2.1429998874664307, acc: 0.6666666865348816)
[2025-01-30 02:15:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4208/107898 [22:52<9:20:38,  3.08it/s][2025-01-30 02:15:02][root][INFO] - Training Epoch: 1/2, step 4207/107898 completed (loss: 0.024564772844314575, acc: 1.0)
[2025-01-30 02:15:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4209/107898 [22:52<9:18:48,  3.09it/s][2025-01-30 02:15:02][root][INFO] - Training Epoch: 1/2, step 4208/107898 completed (loss: 0.7047261595726013, acc: 0.800000011920929)
[2025-01-30 02:15:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4210/107898 [22:53<9:02:41,  3.18it/s][2025-01-30 02:15:02][root][INFO] - Training Epoch: 1/2, step 4209/107898 completed (loss: 3.342911720275879, acc: 0.3333333432674408)
[2025-01-30 02:15:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4211/107898 [22:53<8:57:18,  3.22it/s][2025-01-30 02:15:03][root][INFO] - Training Epoch: 1/2, step 4210/107898 completed (loss: 0.2884802222251892, acc: 0.949999988079071)
[2025-01-30 02:15:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4212/107898 [22:53<9:14:56,  3.11it/s][2025-01-30 02:15:03][root][INFO] - Training Epoch: 1/2, step 4211/107898 completed (loss: 0.14879736304283142, acc: 1.0)
[2025-01-30 02:15:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4213/107898 [22:54<9:15:53,  3.11it/s][2025-01-30 02:15:03][root][INFO] - Training Epoch: 1/2, step 4212/107898 completed (loss: 4.126312732696533, acc: 0.3888888955116272)
[2025-01-30 02:15:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4214/107898 [22:54<9:15:20,  3.11it/s][2025-01-30 02:15:04][root][INFO] - Training Epoch: 1/2, step 4213/107898 completed (loss: 0.010504313744604588, acc: 1.0)
[2025-01-30 02:15:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4215/107898 [22:54<9:12:09,  3.13it/s][2025-01-30 02:15:04][root][INFO] - Training Epoch: 1/2, step 4214/107898 completed (loss: 0.8365124464035034, acc: 0.8888888955116272)
[2025-01-30 02:15:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4216/107898 [22:54<9:02:42,  3.18it/s][2025-01-30 02:15:04][root][INFO] - Training Epoch: 1/2, step 4215/107898 completed (loss: 0.01898227073252201, acc: 1.0)
[2025-01-30 02:15:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4217/107898 [22:55<9:01:01,  3.19it/s][2025-01-30 02:15:05][root][INFO] - Training Epoch: 1/2, step 4216/107898 completed (loss: 0.6591295599937439, acc: 0.875)
[2025-01-30 02:15:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4218/107898 [22:55<9:03:36,  3.18it/s][2025-01-30 02:15:05][root][INFO] - Training Epoch: 1/2, step 4217/107898 completed (loss: 2.1065032482147217, acc: 0.5)
[2025-01-30 02:15:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4219/107898 [22:55<9:02:10,  3.19it/s][2025-01-30 02:15:05][root][INFO] - Training Epoch: 1/2, step 4218/107898 completed (loss: 0.30758607387542725, acc: 1.0)
[2025-01-30 02:15:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4220/107898 [22:56<8:54:07,  3.24it/s][2025-01-30 02:15:06][root][INFO] - Training Epoch: 1/2, step 4219/107898 completed (loss: 0.9179414510726929, acc: 0.7692307829856873)
[2025-01-30 02:15:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4221/107898 [22:56<8:50:27,  3.26it/s][2025-01-30 02:15:06][root][INFO] - Training Epoch: 1/2, step 4220/107898 completed (loss: 0.7441117167472839, acc: 0.8500000238418579)
[2025-01-30 02:15:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4222/107898 [22:56<8:44:02,  3.30it/s][2025-01-30 02:15:06][root][INFO] - Training Epoch: 1/2, step 4221/107898 completed (loss: 0.17973190546035767, acc: 1.0)
[2025-01-30 02:15:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4223/107898 [22:57<8:52:14,  3.25it/s][2025-01-30 02:15:06][root][INFO] - Training Epoch: 1/2, step 4222/107898 completed (loss: 0.22869887948036194, acc: 1.0)
[2025-01-30 02:15:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4224/107898 [22:57<8:40:43,  3.32it/s][2025-01-30 02:15:07][root][INFO] - Training Epoch: 1/2, step 4223/107898 completed (loss: 2.229231357574463, acc: 0.6000000238418579)
[2025-01-30 02:15:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4225/107898 [22:57<8:43:40,  3.30it/s][2025-01-30 02:15:07][root][INFO] - Training Epoch: 1/2, step 4224/107898 completed (loss: 1.9032213687896729, acc: 0.6153846383094788)
[2025-01-30 02:15:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4226/107898 [22:58<8:58:43,  3.21it/s][2025-01-30 02:15:07][root][INFO] - Training Epoch: 1/2, step 4225/107898 completed (loss: 0.07740268111228943, acc: 1.0)
[2025-01-30 02:15:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4227/107898 [22:58<9:23:39,  3.07it/s][2025-01-30 02:15:08][root][INFO] - Training Epoch: 1/2, step 4226/107898 completed (loss: 0.016225524246692657, acc: 1.0)
[2025-01-30 02:15:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4228/107898 [22:58<9:12:58,  3.12it/s][2025-01-30 02:15:08][root][INFO] - Training Epoch: 1/2, step 4227/107898 completed (loss: 0.7786874771118164, acc: 0.807692289352417)
[2025-01-30 02:15:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4229/107898 [22:59<9:04:17,  3.17it/s][2025-01-30 02:15:08][root][INFO] - Training Epoch: 1/2, step 4228/107898 completed (loss: 0.4897328317165375, acc: 1.0)
[2025-01-30 02:15:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4230/107898 [22:59<9:03:27,  3.18it/s][2025-01-30 02:15:09][root][INFO] - Training Epoch: 1/2, step 4229/107898 completed (loss: 0.5040059089660645, acc: 0.8799999952316284)
[2025-01-30 02:15:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4231/107898 [22:59<8:47:52,  3.27it/s][2025-01-30 02:15:09][root][INFO] - Training Epoch: 1/2, step 4230/107898 completed (loss: 0.4220540523529053, acc: 0.875)
[2025-01-30 02:15:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4232/107898 [22:59<9:14:38,  3.12it/s][2025-01-30 02:15:09][root][INFO] - Training Epoch: 1/2, step 4231/107898 completed (loss: 0.4448956251144409, acc: 0.9166666865348816)
[2025-01-30 02:15:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4233/107898 [23:00<9:14:49,  3.11it/s][2025-01-30 02:15:10][root][INFO] - Training Epoch: 1/2, step 4232/107898 completed (loss: 0.002289712429046631, acc: 1.0)
[2025-01-30 02:15:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4234/107898 [23:00<9:27:36,  3.04it/s][2025-01-30 02:15:10][root][INFO] - Training Epoch: 1/2, step 4233/107898 completed (loss: 4.567835330963135, acc: 0.20000000298023224)
[2025-01-30 02:15:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4235/107898 [23:01<9:43:40,  2.96it/s][2025-01-30 02:15:10][root][INFO] - Training Epoch: 1/2, step 4234/107898 completed (loss: 4.976534366607666, acc: 0.0)
[2025-01-30 02:15:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4236/107898 [23:01<9:40:45,  2.97it/s][2025-01-30 02:15:11][root][INFO] - Training Epoch: 1/2, step 4235/107898 completed (loss: 0.3043789565563202, acc: 0.6666666865348816)
[2025-01-30 02:15:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4237/107898 [23:01<9:27:51,  3.04it/s][2025-01-30 02:15:11][root][INFO] - Training Epoch: 1/2, step 4236/107898 completed (loss: 1.5676175355911255, acc: 0.5789473652839661)
[2025-01-30 02:15:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4238/107898 [23:01<9:21:49,  3.08it/s][2025-01-30 02:15:11][root][INFO] - Training Epoch: 1/2, step 4237/107898 completed (loss: 0.6742775440216064, acc: 0.8421052694320679)
[2025-01-30 02:15:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4239/107898 [23:02<9:13:25,  3.12it/s][2025-01-30 02:15:12][root][INFO] - Training Epoch: 1/2, step 4238/107898 completed (loss: 0.9466311931610107, acc: 0.7894737124443054)
[2025-01-30 02:15:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4240/107898 [23:02<9:28:25,  3.04it/s][2025-01-30 02:15:12][root][INFO] - Training Epoch: 1/2, step 4239/107898 completed (loss: 1.5755081176757812, acc: 0.6666666865348816)
[2025-01-30 02:15:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4241/107898 [23:02<9:24:59,  3.06it/s][2025-01-30 02:15:12][root][INFO] - Training Epoch: 1/2, step 4240/107898 completed (loss: 2.3929858207702637, acc: 0.625)
[2025-01-30 02:15:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4242/107898 [23:03<9:34:25,  3.01it/s][2025-01-30 02:15:13][root][INFO] - Training Epoch: 1/2, step 4241/107898 completed (loss: 0.18995147943496704, acc: 1.0)
[2025-01-30 02:15:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4243/107898 [23:03<9:33:42,  3.01it/s][2025-01-30 02:15:13][root][INFO] - Training Epoch: 1/2, step 4242/107898 completed (loss: 0.015087691135704517, acc: 1.0)
[2025-01-30 02:15:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4244/107898 [23:03<9:23:24,  3.07it/s][2025-01-30 02:15:13][root][INFO] - Training Epoch: 1/2, step 4243/107898 completed (loss: 0.001092975726351142, acc: 1.0)
[2025-01-30 02:15:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4245/107898 [23:04<9:12:40,  3.13it/s][2025-01-30 02:15:14][root][INFO] - Training Epoch: 1/2, step 4244/107898 completed (loss: 0.0026705553755164146, acc: 1.0)
[2025-01-30 02:15:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4246/107898 [23:04<9:03:51,  3.18it/s][2025-01-30 02:15:14][root][INFO] - Training Epoch: 1/2, step 4245/107898 completed (loss: 2.0460803508758545, acc: 0.5483871102333069)
[2025-01-30 02:15:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4247/107898 [23:04<9:01:50,  3.19it/s][2025-01-30 02:15:14][root][INFO] - Training Epoch: 1/2, step 4246/107898 completed (loss: 0.5599076151847839, acc: 0.6666666865348816)
[2025-01-30 02:15:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4248/107898 [23:05<9:14:17,  3.12it/s][2025-01-30 02:15:15][root][INFO] - Training Epoch: 1/2, step 4247/107898 completed (loss: 1.6483392715454102, acc: 0.8125)
[2025-01-30 02:15:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4249/107898 [23:05<9:10:04,  3.14it/s][2025-01-30 02:15:15][root][INFO] - Training Epoch: 1/2, step 4248/107898 completed (loss: 4.627139091491699, acc: 0.4000000059604645)
[2025-01-30 02:15:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4250/107898 [23:05<8:55:57,  3.22it/s][2025-01-30 02:15:15][root][INFO] - Training Epoch: 1/2, step 4249/107898 completed (loss: 2.8804214000701904, acc: 0.3333333432674408)
[2025-01-30 02:15:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4251/107898 [23:06<8:55:15,  3.23it/s][2025-01-30 02:15:15][root][INFO] - Training Epoch: 1/2, step 4250/107898 completed (loss: 0.10041942447423935, acc: 1.0)
[2025-01-30 02:15:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4252/107898 [23:06<9:09:39,  3.14it/s][2025-01-30 02:15:16][root][INFO] - Training Epoch: 1/2, step 4251/107898 completed (loss: 1.3172155618667603, acc: 0.7083333134651184)
[2025-01-30 02:15:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4253/107898 [23:06<9:24:32,  3.06it/s][2025-01-30 02:15:16][root][INFO] - Training Epoch: 1/2, step 4252/107898 completed (loss: 2.75948429107666, acc: 0.3333333432674408)
[2025-01-30 02:15:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4254/107898 [23:07<9:23:45,  3.06it/s][2025-01-30 02:15:16][root][INFO] - Training Epoch: 1/2, step 4253/107898 completed (loss: 3.9985435009002686, acc: 0.25)
[2025-01-30 02:15:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4255/107898 [23:07<9:21:58,  3.07it/s][2025-01-30 02:15:17][root][INFO] - Training Epoch: 1/2, step 4254/107898 completed (loss: 1.1107600927352905, acc: 0.6000000238418579)
[2025-01-30 02:15:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4256/107898 [23:07<9:31:02,  3.02it/s][2025-01-30 02:15:17][root][INFO] - Training Epoch: 1/2, step 4255/107898 completed (loss: 1.8982375860214233, acc: 0.739130437374115)
[2025-01-30 02:15:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4257/107898 [23:08<9:33:50,  3.01it/s][2025-01-30 02:15:17][root][INFO] - Training Epoch: 1/2, step 4256/107898 completed (loss: 0.461721807718277, acc: 0.875)
[2025-01-30 02:15:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4258/107898 [23:08<9:29:42,  3.03it/s][2025-01-30 02:15:18][root][INFO] - Training Epoch: 1/2, step 4257/107898 completed (loss: 0.8773528933525085, acc: 0.7777777910232544)
[2025-01-30 02:15:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4259/107898 [23:08<9:24:25,  3.06it/s][2025-01-30 02:15:18][root][INFO] - Training Epoch: 1/2, step 4258/107898 completed (loss: 0.1878911405801773, acc: 1.0)
[2025-01-30 02:15:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4260/107898 [23:09<9:34:40,  3.01it/s][2025-01-30 02:15:18][root][INFO] - Training Epoch: 1/2, step 4259/107898 completed (loss: 3.3234355449676514, acc: 0.3333333432674408)
[2025-01-30 02:15:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4261/107898 [23:09<9:46:21,  2.95it/s][2025-01-30 02:15:19][root][INFO] - Training Epoch: 1/2, step 4260/107898 completed (loss: 0.5719555020332336, acc: 0.9375)
[2025-01-30 02:15:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4262/107898 [23:09<9:32:07,  3.02it/s][2025-01-30 02:15:19][root][INFO] - Training Epoch: 1/2, step 4261/107898 completed (loss: 0.17563055455684662, acc: 1.0)
[2025-01-30 02:15:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4263/107898 [23:10<9:14:03,  3.12it/s][2025-01-30 02:15:19][root][INFO] - Training Epoch: 1/2, step 4262/107898 completed (loss: 1.4347071647644043, acc: 0.5)
[2025-01-30 02:15:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4264/107898 [23:10<9:03:39,  3.18it/s][2025-01-30 02:15:20][root][INFO] - Training Epoch: 1/2, step 4263/107898 completed (loss: 4.7795281410217285, acc: 0.1875)
[2025-01-30 02:15:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4265/107898 [23:10<9:25:44,  3.05it/s][2025-01-30 02:15:20][root][INFO] - Training Epoch: 1/2, step 4264/107898 completed (loss: 0.6623455286026001, acc: 0.949999988079071)
[2025-01-30 02:15:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4266/107898 [23:11<9:33:25,  3.01it/s][2025-01-30 02:15:20][root][INFO] - Training Epoch: 1/2, step 4265/107898 completed (loss: 0.07338923960924149, acc: 1.0)
[2025-01-30 02:15:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4267/107898 [23:11<9:18:08,  3.09it/s][2025-01-30 02:15:21][root][INFO] - Training Epoch: 1/2, step 4266/107898 completed (loss: 1.517040729522705, acc: 0.6666666865348816)
[2025-01-30 02:15:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4268/107898 [23:11<9:13:10,  3.12it/s][2025-01-30 02:15:21][root][INFO] - Training Epoch: 1/2, step 4267/107898 completed (loss: 0.03011193312704563, acc: 1.0)
[2025-01-30 02:15:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4269/107898 [23:12<9:17:49,  3.10it/s][2025-01-30 02:15:21][root][INFO] - Training Epoch: 1/2, step 4268/107898 completed (loss: 0.7692429423332214, acc: 0.8666666746139526)
[2025-01-30 02:15:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4270/107898 [23:12<9:04:06,  3.17it/s][2025-01-30 02:15:22][root][INFO] - Training Epoch: 1/2, step 4269/107898 completed (loss: 0.08025570213794708, acc: 1.0)
[2025-01-30 02:15:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4271/107898 [23:12<8:57:15,  3.21it/s][2025-01-30 02:15:22][root][INFO] - Training Epoch: 1/2, step 4270/107898 completed (loss: 0.0373074971139431, acc: 1.0)
[2025-01-30 02:15:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4272/107898 [23:12<9:18:50,  3.09it/s][2025-01-30 02:15:22][root][INFO] - Training Epoch: 1/2, step 4271/107898 completed (loss: 0.39710092544555664, acc: 1.0)
[2025-01-30 02:15:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4273/107898 [23:13<9:23:13,  3.07it/s][2025-01-30 02:15:23][root][INFO] - Training Epoch: 1/2, step 4272/107898 completed (loss: 1.1732736825942993, acc: 0.5)
[2025-01-30 02:15:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4274/107898 [23:13<9:35:11,  3.00it/s][2025-01-30 02:15:23][root][INFO] - Training Epoch: 1/2, step 4273/107898 completed (loss: 0.3340390920639038, acc: 0.875)
[2025-01-30 02:15:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4275/107898 [23:14<9:38:22,  2.99it/s][2025-01-30 02:15:23][root][INFO] - Training Epoch: 1/2, step 4274/107898 completed (loss: 1.2819700241088867, acc: 0.7241379022598267)
[2025-01-30 02:15:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4276/107898 [23:14<9:26:02,  3.05it/s][2025-01-30 02:15:24][root][INFO] - Training Epoch: 1/2, step 4275/107898 completed (loss: 0.07998970150947571, acc: 1.0)
[2025-01-30 02:15:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4277/107898 [23:14<9:33:11,  3.01it/s][2025-01-30 02:15:24][root][INFO] - Training Epoch: 1/2, step 4276/107898 completed (loss: 4.835659503936768, acc: 0.17241379618644714)
[2025-01-30 02:15:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4278/107898 [23:15<9:46:07,  2.95it/s][2025-01-30 02:15:24][root][INFO] - Training Epoch: 1/2, step 4277/107898 completed (loss: 0.1380271166563034, acc: 1.0)
[2025-01-30 02:15:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4279/107898 [23:15<9:45:37,  2.95it/s][2025-01-30 02:15:25][root][INFO] - Training Epoch: 1/2, step 4278/107898 completed (loss: 0.9697017669677734, acc: 0.800000011920929)
[2025-01-30 02:15:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4280/107898 [23:15<9:58:34,  2.89it/s][2025-01-30 02:15:25][root][INFO] - Training Epoch: 1/2, step 4279/107898 completed (loss: 1.3335314989089966, acc: 0.75)
[2025-01-30 02:15:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4281/107898 [23:16<10:05:10,  2.85it/s][2025-01-30 02:15:25][root][INFO] - Training Epoch: 1/2, step 4280/107898 completed (loss: 1.0127568244934082, acc: 0.5)
[2025-01-30 02:15:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4282/107898 [23:16<9:58:59,  2.88it/s] [2025-01-30 02:15:26][root][INFO] - Training Epoch: 1/2, step 4281/107898 completed (loss: 0.39167192578315735, acc: 0.9166666865348816)
[2025-01-30 02:15:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4283/107898 [23:16<10:10:44,  2.83it/s][2025-01-30 02:15:26][root][INFO] - Training Epoch: 1/2, step 4282/107898 completed (loss: 1.42268967628479, acc: 0.6000000238418579)
[2025-01-30 02:15:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4284/107898 [23:17<9:33:31,  3.01it/s] [2025-01-30 02:15:26][root][INFO] - Training Epoch: 1/2, step 4283/107898 completed (loss: 0.00485578365623951, acc: 1.0)
[2025-01-30 02:15:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4285/107898 [23:17<9:24:53,  3.06it/s][2025-01-30 02:15:27][root][INFO] - Training Epoch: 1/2, step 4284/107898 completed (loss: 1.0388737916946411, acc: 0.8333333134651184)
[2025-01-30 02:15:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4286/107898 [23:17<9:09:38,  3.14it/s][2025-01-30 02:15:27][root][INFO] - Training Epoch: 1/2, step 4285/107898 completed (loss: 0.03840569779276848, acc: 1.0)
[2025-01-30 02:15:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4287/107898 [23:17<8:56:34,  3.22it/s][2025-01-30 02:15:27][root][INFO] - Training Epoch: 1/2, step 4286/107898 completed (loss: 0.0022501663770526648, acc: 1.0)
[2025-01-30 02:15:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4288/107898 [23:18<8:59:51,  3.20it/s][2025-01-30 02:15:28][root][INFO] - Training Epoch: 1/2, step 4287/107898 completed (loss: 0.20861658453941345, acc: 0.95652174949646)
[2025-01-30 02:15:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4289/107898 [23:18<9:12:48,  3.12it/s][2025-01-30 02:15:28][root][INFO] - Training Epoch: 1/2, step 4288/107898 completed (loss: 0.17362983524799347, acc: 1.0)
[2025-01-30 02:15:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4290/107898 [23:18<9:26:46,  3.05it/s][2025-01-30 02:15:28][root][INFO] - Training Epoch: 1/2, step 4289/107898 completed (loss: 3.986569404602051, acc: 0.20000000298023224)
[2025-01-30 02:15:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4291/107898 [23:19<9:08:01,  3.15it/s][2025-01-30 02:15:29][root][INFO] - Training Epoch: 1/2, step 4290/107898 completed (loss: 0.7000942826271057, acc: 0.8571428656578064)
[2025-01-30 02:15:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4292/107898 [23:19<9:22:46,  3.07it/s][2025-01-30 02:15:29][root][INFO] - Training Epoch: 1/2, step 4291/107898 completed (loss: 0.002295105252414942, acc: 1.0)
[2025-01-30 02:15:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4293/107898 [23:19<9:32:07,  3.02it/s][2025-01-30 02:15:29][root][INFO] - Training Epoch: 1/2, step 4292/107898 completed (loss: 1.6131515502929688, acc: 0.5)
[2025-01-30 02:15:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4294/107898 [23:20<9:33:41,  3.01it/s][2025-01-30 02:15:30][root][INFO] - Training Epoch: 1/2, step 4293/107898 completed (loss: 1.496619701385498, acc: 0.5882353186607361)
[2025-01-30 02:15:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4295/107898 [23:20<9:46:02,  2.95it/s][2025-01-30 02:15:30][root][INFO] - Training Epoch: 1/2, step 4294/107898 completed (loss: 0.3582548201084137, acc: 0.9285714030265808)
[2025-01-30 02:15:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4296/107898 [23:20<9:40:13,  2.98it/s][2025-01-30 02:15:30][root][INFO] - Training Epoch: 1/2, step 4295/107898 completed (loss: 0.009196105413138866, acc: 1.0)
[2025-01-30 02:15:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4297/107898 [23:21<9:23:51,  3.06it/s][2025-01-30 02:15:31][root][INFO] - Training Epoch: 1/2, step 4296/107898 completed (loss: 3.3402440547943115, acc: 0.5)
[2025-01-30 02:15:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4298/107898 [23:21<9:29:54,  3.03it/s][2025-01-30 02:15:31][root][INFO] - Training Epoch: 1/2, step 4297/107898 completed (loss: 1.0730276107788086, acc: 0.761904776096344)
[2025-01-30 02:15:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4299/107898 [23:21<9:26:50,  3.05it/s][2025-01-30 02:15:31][root][INFO] - Training Epoch: 1/2, step 4298/107898 completed (loss: 1.4535459280014038, acc: 0.7333333492279053)
[2025-01-30 02:15:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4300/107898 [23:22<9:38:07,  2.99it/s][2025-01-30 02:15:32][root][INFO] - Training Epoch: 1/2, step 4299/107898 completed (loss: 1.599802851676941, acc: 0.7272727489471436)
[2025-01-30 02:15:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4301/107898 [23:22<9:20:11,  3.08it/s][2025-01-30 02:15:32][root][INFO] - Training Epoch: 1/2, step 4300/107898 completed (loss: 1.2306294441223145, acc: 0.8333333134651184)
[2025-01-30 02:15:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4302/107898 [23:22<9:43:52,  2.96it/s][2025-01-30 02:15:32][root][INFO] - Training Epoch: 1/2, step 4301/107898 completed (loss: 0.02365509793162346, acc: 1.0)
[2025-01-30 02:15:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4303/107898 [23:23<9:46:08,  2.95it/s][2025-01-30 02:15:33][root][INFO] - Training Epoch: 1/2, step 4302/107898 completed (loss: 3.346543550491333, acc: 0.3333333432674408)
[2025-01-30 02:15:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4304/107898 [23:23<9:51:45,  2.92it/s][2025-01-30 02:15:33][root][INFO] - Training Epoch: 1/2, step 4303/107898 completed (loss: 0.7274243831634521, acc: 0.8333333134651184)
[2025-01-30 02:15:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4305/107898 [23:23<9:46:31,  2.94it/s][2025-01-30 02:15:33][root][INFO] - Training Epoch: 1/2, step 4304/107898 completed (loss: 0.8848397135734558, acc: 0.9285714030265808)
[2025-01-30 02:15:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4306/107898 [23:24<9:53:04,  2.91it/s][2025-01-30 02:15:34][root][INFO] - Training Epoch: 1/2, step 4305/107898 completed (loss: 1.5232287645339966, acc: 0.7142857313156128)
[2025-01-30 02:15:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4307/107898 [23:24<9:57:21,  2.89it/s][2025-01-30 02:15:34][root][INFO] - Training Epoch: 1/2, step 4306/107898 completed (loss: 2.0926575660705566, acc: 0.6000000238418579)
[2025-01-30 02:15:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4308/107898 [23:25<9:49:27,  2.93it/s][2025-01-30 02:15:34][root][INFO] - Training Epoch: 1/2, step 4307/107898 completed (loss: 0.8388575315475464, acc: 0.761904776096344)
[2025-01-30 02:15:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4309/107898 [23:25<9:40:53,  2.97it/s][2025-01-30 02:15:35][root][INFO] - Training Epoch: 1/2, step 4308/107898 completed (loss: 0.4944615662097931, acc: 0.7894737124443054)
[2025-01-30 02:15:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4310/107898 [23:25<9:34:08,  3.01it/s][2025-01-30 02:15:35][root][INFO] - Training Epoch: 1/2, step 4309/107898 completed (loss: 3.2760019302368164, acc: 0.6666666865348816)
[2025-01-30 02:15:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4311/107898 [23:26<9:32:32,  3.02it/s][2025-01-30 02:15:35][root][INFO] - Training Epoch: 1/2, step 4310/107898 completed (loss: 2.6163294315338135, acc: 0.5)
[2025-01-30 02:15:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4312/107898 [23:26<9:23:56,  3.06it/s][2025-01-30 02:15:36][root][INFO] - Training Epoch: 1/2, step 4311/107898 completed (loss: 0.05379676818847656, acc: 1.0)
[2025-01-30 02:15:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4313/107898 [23:26<9:28:31,  3.04it/s][2025-01-30 02:15:36][root][INFO] - Training Epoch: 1/2, step 4312/107898 completed (loss: 0.761099636554718, acc: 0.75)
[2025-01-30 02:15:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4314/107898 [23:26<9:28:57,  3.03it/s][2025-01-30 02:15:36][root][INFO] - Training Epoch: 1/2, step 4313/107898 completed (loss: 1.2910804748535156, acc: 0.75)
[2025-01-30 02:15:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4315/107898 [23:27<9:18:09,  3.09it/s][2025-01-30 02:15:37][root][INFO] - Training Epoch: 1/2, step 4314/107898 completed (loss: 0.23720026016235352, acc: 0.9333333373069763)
[2025-01-30 02:15:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4316/107898 [23:27<9:38:17,  2.99it/s][2025-01-30 02:15:37][root][INFO] - Training Epoch: 1/2, step 4315/107898 completed (loss: 0.1524788737297058, acc: 0.9677419066429138)
[2025-01-30 02:15:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4317/107898 [23:27<9:35:09,  3.00it/s][2025-01-30 02:15:37][root][INFO] - Training Epoch: 1/2, step 4316/107898 completed (loss: 0.3141549229621887, acc: 0.8888888955116272)
[2025-01-30 02:15:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4318/107898 [23:28<9:26:05,  3.05it/s][2025-01-30 02:15:38][root][INFO] - Training Epoch: 1/2, step 4317/107898 completed (loss: 2.284018039703369, acc: 0.6470588445663452)
[2025-01-30 02:15:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4319/107898 [23:28<9:40:33,  2.97it/s][2025-01-30 02:15:38][root][INFO] - Training Epoch: 1/2, step 4318/107898 completed (loss: 0.2128264158964157, acc: 1.0)
[2025-01-30 02:15:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4320/107898 [23:29<9:45:55,  2.95it/s][2025-01-30 02:15:38][root][INFO] - Training Epoch: 1/2, step 4319/107898 completed (loss: 0.14636169373989105, acc: 1.0)
[2025-01-30 02:15:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4321/107898 [23:29<9:39:03,  2.98it/s][2025-01-30 02:15:39][root][INFO] - Training Epoch: 1/2, step 4320/107898 completed (loss: 0.5619472861289978, acc: 0.9117646813392639)
[2025-01-30 02:15:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4322/107898 [23:29<9:26:28,  3.05it/s][2025-01-30 02:15:39][root][INFO] - Training Epoch: 1/2, step 4321/107898 completed (loss: 3.669645071029663, acc: 0.5)
[2025-01-30 02:15:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4323/107898 [23:29<9:23:11,  3.07it/s][2025-01-30 02:15:39][root][INFO] - Training Epoch: 1/2, step 4322/107898 completed (loss: 1.1514966487884521, acc: 0.6666666865348816)
[2025-01-30 02:15:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4324/107898 [23:30<9:18:07,  3.09it/s][2025-01-30 02:15:40][root][INFO] - Training Epoch: 1/2, step 4323/107898 completed (loss: 2.7684426307678223, acc: 0.5)
[2025-01-30 02:15:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4325/107898 [23:30<9:14:42,  3.11it/s][2025-01-30 02:15:40][root][INFO] - Training Epoch: 1/2, step 4324/107898 completed (loss: 1.9030460119247437, acc: 0.6666666865348816)
[2025-01-30 02:15:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4326/107898 [23:30<8:56:03,  3.22it/s][2025-01-30 02:15:40][root][INFO] - Training Epoch: 1/2, step 4325/107898 completed (loss: 0.28885123133659363, acc: 1.0)
[2025-01-30 02:15:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4327/107898 [23:31<8:50:21,  3.25it/s][2025-01-30 02:15:40][root][INFO] - Training Epoch: 1/2, step 4326/107898 completed (loss: 4.646867275238037, acc: 0.5)
[2025-01-30 02:15:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4328/107898 [23:31<8:54:46,  3.23it/s][2025-01-30 02:15:41][root][INFO] - Training Epoch: 1/2, step 4327/107898 completed (loss: 0.7884545922279358, acc: 0.800000011920929)
[2025-01-30 02:15:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4329/107898 [23:31<8:43:17,  3.30it/s][2025-01-30 02:15:41][root][INFO] - Training Epoch: 1/2, step 4328/107898 completed (loss: 0.19378061592578888, acc: 1.0)
[2025-01-30 02:15:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4330/107898 [23:32<8:50:04,  3.26it/s][2025-01-30 02:15:41][root][INFO] - Training Epoch: 1/2, step 4329/107898 completed (loss: 1.1996999979019165, acc: 0.7058823704719543)
[2025-01-30 02:15:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4331/107898 [23:32<8:51:42,  3.25it/s][2025-01-30 02:15:42][root][INFO] - Training Epoch: 1/2, step 4330/107898 completed (loss: 2.686060905456543, acc: 0.6000000238418579)
[2025-01-30 02:15:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4332/107898 [23:32<8:54:04,  3.23it/s][2025-01-30 02:15:42][root][INFO] - Training Epoch: 1/2, step 4331/107898 completed (loss: 0.8642356991767883, acc: 0.8571428656578064)
[2025-01-30 02:15:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4333/107898 [23:33<9:20:08,  3.08it/s][2025-01-30 02:15:42][root][INFO] - Training Epoch: 1/2, step 4332/107898 completed (loss: 1.570102572441101, acc: 0.5)
[2025-01-30 02:15:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4334/107898 [23:33<9:32:55,  3.01it/s][2025-01-30 02:15:43][root][INFO] - Training Epoch: 1/2, step 4333/107898 completed (loss: 3.2168242931365967, acc: 0.4000000059604645)
[2025-01-30 02:15:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4335/107898 [23:33<9:10:31,  3.14it/s][2025-01-30 02:15:43][root][INFO] - Training Epoch: 1/2, step 4334/107898 completed (loss: 0.10213253647089005, acc: 1.0)
[2025-01-30 02:15:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4336/107898 [23:34<9:27:53,  3.04it/s][2025-01-30 02:15:43][root][INFO] - Training Epoch: 1/2, step 4335/107898 completed (loss: 0.7486119270324707, acc: 0.7894737124443054)
[2025-01-30 02:15:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4337/107898 [23:34<9:26:40,  3.05it/s][2025-01-30 02:15:44][root][INFO] - Training Epoch: 1/2, step 4336/107898 completed (loss: 0.10994082689285278, acc: 1.0)
[2025-01-30 02:15:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4338/107898 [23:34<9:08:49,  3.14it/s][2025-01-30 02:15:44][root][INFO] - Training Epoch: 1/2, step 4337/107898 completed (loss: 3.977937698364258, acc: 0.4000000059604645)
[2025-01-30 02:15:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4339/107898 [23:34<8:53:44,  3.23it/s][2025-01-30 02:15:44][root][INFO] - Training Epoch: 1/2, step 4338/107898 completed (loss: 0.014706091955304146, acc: 1.0)
[2025-01-30 02:15:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4340/107898 [23:35<9:07:56,  3.15it/s][2025-01-30 02:15:45][root][INFO] - Training Epoch: 1/2, step 4339/107898 completed (loss: 0.8991956114768982, acc: 0.8695651888847351)
[2025-01-30 02:15:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4341/107898 [23:35<9:17:46,  3.09it/s][2025-01-30 02:15:45][root][INFO] - Training Epoch: 1/2, step 4340/107898 completed (loss: 0.5789344906806946, acc: 1.0)
[2025-01-30 02:15:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4342/107898 [23:35<9:23:36,  3.06it/s][2025-01-30 02:15:45][root][INFO] - Training Epoch: 1/2, step 4341/107898 completed (loss: 1.1877801418304443, acc: 0.75)
[2025-01-30 02:15:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4343/107898 [23:36<9:25:46,  3.05it/s][2025-01-30 02:15:46][root][INFO] - Training Epoch: 1/2, step 4342/107898 completed (loss: 3.7748982906341553, acc: 0.0)
[2025-01-30 02:15:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4344/107898 [23:36<9:35:10,  3.00it/s][2025-01-30 02:15:46][root][INFO] - Training Epoch: 1/2, step 4343/107898 completed (loss: 0.3459247946739197, acc: 0.9375)
[2025-01-30 02:15:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4345/107898 [23:37<9:49:41,  2.93it/s][2025-01-30 02:15:46][root][INFO] - Training Epoch: 1/2, step 4344/107898 completed (loss: 0.038111474364995956, acc: 1.0)
[2025-01-30 02:15:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4346/107898 [23:37<9:36:50,  2.99it/s][2025-01-30 02:15:47][root][INFO] - Training Epoch: 1/2, step 4345/107898 completed (loss: 0.7541989088058472, acc: 0.5)
[2025-01-30 02:15:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4347/107898 [23:37<9:17:35,  3.10it/s][2025-01-30 02:15:47][root][INFO] - Training Epoch: 1/2, step 4346/107898 completed (loss: 3.0090458393096924, acc: 0.4000000059604645)
[2025-01-30 02:15:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4348/107898 [23:37<9:34:56,  3.00it/s][2025-01-30 02:15:47][root][INFO] - Training Epoch: 1/2, step 4347/107898 completed (loss: 1.8398691415786743, acc: 0.7058823704719543)
[2025-01-30 02:15:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4349/107898 [23:38<9:44:39,  2.95it/s][2025-01-30 02:15:48][root][INFO] - Training Epoch: 1/2, step 4348/107898 completed (loss: 0.07848239690065384, acc: 1.0)
[2025-01-30 02:15:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4350/107898 [23:38<9:36:40,  2.99it/s][2025-01-30 02:15:48][root][INFO] - Training Epoch: 1/2, step 4349/107898 completed (loss: 2.412348985671997, acc: 0.4000000059604645)
[2025-01-30 02:15:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4351/107898 [23:38<9:13:56,  3.12it/s][2025-01-30 02:15:48][root][INFO] - Training Epoch: 1/2, step 4350/107898 completed (loss: 0.04179342836141586, acc: 1.0)
[2025-01-30 02:15:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4352/107898 [23:39<9:18:07,  3.09it/s][2025-01-30 02:15:49][root][INFO] - Training Epoch: 1/2, step 4351/107898 completed (loss: 0.1069740429520607, acc: 1.0)
[2025-01-30 02:15:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4353/107898 [23:39<9:23:22,  3.06it/s][2025-01-30 02:15:49][root][INFO] - Training Epoch: 1/2, step 4352/107898 completed (loss: 0.0023474805057048798, acc: 1.0)
[2025-01-30 02:15:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4354/107898 [23:39<9:22:54,  3.07it/s][2025-01-30 02:15:49][root][INFO] - Training Epoch: 1/2, step 4353/107898 completed (loss: 2.207845449447632, acc: 0.6666666865348816)
[2025-01-30 02:15:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4355/107898 [23:40<9:10:00,  3.14it/s][2025-01-30 02:15:50][root][INFO] - Training Epoch: 1/2, step 4354/107898 completed (loss: 0.38455790281295776, acc: 0.5)
[2025-01-30 02:15:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4356/107898 [23:40<9:21:38,  3.07it/s][2025-01-30 02:15:50][root][INFO] - Training Epoch: 1/2, step 4355/107898 completed (loss: 1.2314168214797974, acc: 0.6666666865348816)
[2025-01-30 02:15:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4357/107898 [23:40<9:19:50,  3.08it/s][2025-01-30 02:15:50][root][INFO] - Training Epoch: 1/2, step 4356/107898 completed (loss: 1.4596444368362427, acc: 0.6666666865348816)
[2025-01-30 02:15:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4358/107898 [23:41<9:20:39,  3.08it/s][2025-01-30 02:15:51][root][INFO] - Training Epoch: 1/2, step 4357/107898 completed (loss: 2.539374351501465, acc: 0.5454545617103577)
[2025-01-30 02:15:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4359/107898 [23:41<9:43:10,  2.96it/s][2025-01-30 02:15:51][root][INFO] - Training Epoch: 1/2, step 4358/107898 completed (loss: 0.8807918429374695, acc: 0.800000011920929)
[2025-01-30 02:15:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4360/107898 [23:41<9:46:31,  2.94it/s][2025-01-30 02:15:51][root][INFO] - Training Epoch: 1/2, step 4359/107898 completed (loss: 0.024978473782539368, acc: 1.0)
[2025-01-30 02:15:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4361/107898 [23:42<9:29:26,  3.03it/s][2025-01-30 02:15:52][root][INFO] - Training Epoch: 1/2, step 4360/107898 completed (loss: 1.5147203207015991, acc: 0.75)
[2025-01-30 02:15:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4362/107898 [23:42<9:35:37,  3.00it/s][2025-01-30 02:15:52][root][INFO] - Training Epoch: 1/2, step 4361/107898 completed (loss: 1.8362818956375122, acc: 0.75)
[2025-01-30 02:15:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4363/107898 [23:42<9:26:32,  3.05it/s][2025-01-30 02:15:52][root][INFO] - Training Epoch: 1/2, step 4362/107898 completed (loss: 0.9785119295120239, acc: 0.8999999761581421)
[2025-01-30 02:15:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4364/107898 [23:43<9:30:53,  3.02it/s][2025-01-30 02:15:53][root][INFO] - Training Epoch: 1/2, step 4363/107898 completed (loss: 0.6757996678352356, acc: 0.8333333134651184)
[2025-01-30 02:15:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4365/107898 [23:43<9:17:48,  3.09it/s][2025-01-30 02:15:53][root][INFO] - Training Epoch: 1/2, step 4364/107898 completed (loss: 0.1875907927751541, acc: 0.9166666865348816)
[2025-01-30 02:15:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4366/107898 [23:43<9:24:54,  3.05it/s][2025-01-30 02:15:53][root][INFO] - Training Epoch: 1/2, step 4365/107898 completed (loss: 0.32594767212867737, acc: 0.9090909361839294)
[2025-01-30 02:15:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4367/107898 [23:44<9:21:53,  3.07it/s][2025-01-30 02:15:54][root][INFO] - Training Epoch: 1/2, step 4366/107898 completed (loss: 0.46531957387924194, acc: 0.931034505367279)
[2025-01-30 02:15:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4368/107898 [23:44<9:12:28,  3.12it/s][2025-01-30 02:15:54][root][INFO] - Training Epoch: 1/2, step 4367/107898 completed (loss: 0.10957283526659012, acc: 1.0)
[2025-01-30 02:15:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4369/107898 [23:44<9:00:00,  3.20it/s][2025-01-30 02:15:54][root][INFO] - Training Epoch: 1/2, step 4368/107898 completed (loss: 1.9561433792114258, acc: 0.6666666865348816)
[2025-01-30 02:15:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4370/107898 [23:45<9:13:15,  3.12it/s][2025-01-30 02:15:54][root][INFO] - Training Epoch: 1/2, step 4369/107898 completed (loss: 0.023169225081801414, acc: 1.0)
[2025-01-30 02:15:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4371/107898 [23:45<9:09:13,  3.14it/s][2025-01-30 02:15:55][root][INFO] - Training Epoch: 1/2, step 4370/107898 completed (loss: 3.931396245956421, acc: 0.375)
[2025-01-30 02:15:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4372/107898 [23:45<9:16:30,  3.10it/s][2025-01-30 02:15:55][root][INFO] - Training Epoch: 1/2, step 4371/107898 completed (loss: 0.6956436038017273, acc: 0.75)
[2025-01-30 02:15:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4373/107898 [23:46<9:22:22,  3.07it/s][2025-01-30 02:15:55][root][INFO] - Training Epoch: 1/2, step 4372/107898 completed (loss: 3.5601823329925537, acc: 0.22727273404598236)
[2025-01-30 02:15:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4374/107898 [23:46<9:06:52,  3.16it/s][2025-01-30 02:15:56][root][INFO] - Training Epoch: 1/2, step 4373/107898 completed (loss: 0.09456651657819748, acc: 1.0)
[2025-01-30 02:15:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4375/107898 [23:46<8:53:20,  3.24it/s][2025-01-30 02:15:56][root][INFO] - Training Epoch: 1/2, step 4374/107898 completed (loss: 0.6717696785926819, acc: 0.8571428656578064)
[2025-01-30 02:15:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4376/107898 [23:47<8:45:05,  3.29it/s][2025-01-30 02:15:56][root][INFO] - Training Epoch: 1/2, step 4375/107898 completed (loss: 0.4825004041194916, acc: 0.9166666865348816)
[2025-01-30 02:15:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4377/107898 [23:47<8:39:06,  3.32it/s][2025-01-30 02:15:57][root][INFO] - Training Epoch: 1/2, step 4376/107898 completed (loss: 1.748909831047058, acc: 0.5)
[2025-01-30 02:15:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4378/107898 [23:47<9:06:09,  3.16it/s][2025-01-30 02:15:57][root][INFO] - Training Epoch: 1/2, step 4377/107898 completed (loss: 2.331679582595825, acc: 0.5)
[2025-01-30 02:15:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4379/107898 [23:48<9:16:47,  3.10it/s][2025-01-30 02:15:57][root][INFO] - Training Epoch: 1/2, step 4378/107898 completed (loss: 0.1132134422659874, acc: 1.0)
[2025-01-30 02:15:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4380/107898 [23:48<9:14:56,  3.11it/s][2025-01-30 02:15:58][root][INFO] - Training Epoch: 1/2, step 4379/107898 completed (loss: 4.074404716491699, acc: 0.5)
[2025-01-30 02:15:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4381/107898 [23:48<9:17:55,  3.09it/s][2025-01-30 02:15:58][root][INFO] - Training Epoch: 1/2, step 4380/107898 completed (loss: 1.3398724794387817, acc: 0.5)
[2025-01-30 02:15:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4382/107898 [23:48<9:14:10,  3.11it/s][2025-01-30 02:15:58][root][INFO] - Training Epoch: 1/2, step 4381/107898 completed (loss: 0.2646777629852295, acc: 1.0)
[2025-01-30 02:15:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4383/107898 [23:49<9:03:13,  3.18it/s][2025-01-30 02:15:59][root][INFO] - Training Epoch: 1/2, step 4382/107898 completed (loss: 1.2783453464508057, acc: 0.5)
[2025-01-30 02:15:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4384/107898 [23:49<8:56:00,  3.22it/s][2025-01-30 02:15:59][root][INFO] - Training Epoch: 1/2, step 4383/107898 completed (loss: 2.576974868774414, acc: 0.6000000238418579)
[2025-01-30 02:15:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4385/107898 [23:49<8:55:30,  3.22it/s][2025-01-30 02:15:59][root][INFO] - Training Epoch: 1/2, step 4384/107898 completed (loss: 1.505208134651184, acc: 0.3333333432674408)
[2025-01-30 02:15:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4386/107898 [23:50<8:57:51,  3.21it/s][2025-01-30 02:15:59][root][INFO] - Training Epoch: 1/2, step 4385/107898 completed (loss: 1.2116034030914307, acc: 0.75)
[2025-01-30 02:16:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4387/107898 [23:50<9:19:22,  3.08it/s][2025-01-30 02:16:00][root][INFO] - Training Epoch: 1/2, step 4386/107898 completed (loss: 3.1060218811035156, acc: 0.20000000298023224)
[2025-01-30 02:16:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4388/107898 [23:50<9:26:14,  3.05it/s][2025-01-30 02:16:00][root][INFO] - Training Epoch: 1/2, step 4387/107898 completed (loss: 0.22873537242412567, acc: 0.9166666865348816)
[2025-01-30 02:16:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4389/107898 [23:51<9:27:51,  3.04it/s][2025-01-30 02:16:01][root][INFO] - Training Epoch: 1/2, step 4388/107898 completed (loss: 0.3603522479534149, acc: 0.9166666865348816)
[2025-01-30 02:16:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4390/107898 [23:51<9:20:01,  3.08it/s][2025-01-30 02:16:01][root][INFO] - Training Epoch: 1/2, step 4389/107898 completed (loss: 0.479972779750824, acc: 0.8666666746139526)
[2025-01-30 02:16:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4391/107898 [23:51<9:08:29,  3.15it/s][2025-01-30 02:16:01][root][INFO] - Training Epoch: 1/2, step 4390/107898 completed (loss: 0.01247181836515665, acc: 1.0)
[2025-01-30 02:16:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4392/107898 [23:52<9:17:19,  3.10it/s][2025-01-30 02:16:01][root][INFO] - Training Epoch: 1/2, step 4391/107898 completed (loss: 0.5884897708892822, acc: 0.8888888955116272)
[2025-01-30 02:16:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4393/107898 [23:52<9:12:34,  3.12it/s][2025-01-30 02:16:02][root][INFO] - Training Epoch: 1/2, step 4392/107898 completed (loss: 0.0775177851319313, acc: 1.0)
[2025-01-30 02:16:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4394/107898 [23:52<9:19:26,  3.08it/s][2025-01-30 02:16:02][root][INFO] - Training Epoch: 1/2, step 4393/107898 completed (loss: 2.1851658821105957, acc: 0.6785714030265808)
[2025-01-30 02:16:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4395/107898 [23:53<9:04:52,  3.17it/s][2025-01-30 02:16:02][root][INFO] - Training Epoch: 1/2, step 4394/107898 completed (loss: 0.15401118993759155, acc: 1.0)
[2025-01-30 02:16:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4396/107898 [23:53<9:37:07,  2.99it/s][2025-01-30 02:16:03][root][INFO] - Training Epoch: 1/2, step 4395/107898 completed (loss: 0.34408634901046753, acc: 0.9200000166893005)
[2025-01-30 02:16:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4397/107898 [23:53<9:50:56,  2.92it/s][2025-01-30 02:16:03][root][INFO] - Training Epoch: 1/2, step 4396/107898 completed (loss: 2.2766363620758057, acc: 0.4000000059604645)
[2025-01-30 02:16:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4398/107898 [23:54<9:48:46,  2.93it/s][2025-01-30 02:16:03][root][INFO] - Training Epoch: 1/2, step 4397/107898 completed (loss: 1.8296124935150146, acc: 0.5789473652839661)
[2025-01-30 02:16:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4399/107898 [23:54<9:33:06,  3.01it/s][2025-01-30 02:16:04][root][INFO] - Training Epoch: 1/2, step 4398/107898 completed (loss: 3.495572566986084, acc: 0.0)
[2025-01-30 02:16:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4400/107898 [23:54<9:20:04,  3.08it/s][2025-01-30 02:16:04][root][INFO] - Training Epoch: 1/2, step 4399/107898 completed (loss: 3.713639736175537, acc: 0.25)
[2025-01-30 02:16:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4401/107898 [23:55<9:30:44,  3.02it/s][2025-01-30 02:16:04][root][INFO] - Training Epoch: 1/2, step 4400/107898 completed (loss: 0.3550039529800415, acc: 0.8636363744735718)
[2025-01-30 02:16:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4402/107898 [23:55<9:31:45,  3.02it/s][2025-01-30 02:16:05][root][INFO] - Training Epoch: 1/2, step 4401/107898 completed (loss: 0.19835175573825836, acc: 0.8888888955116272)
[2025-01-30 02:16:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4403/107898 [23:55<9:41:28,  2.97it/s][2025-01-30 02:16:05][root][INFO] - Training Epoch: 1/2, step 4402/107898 completed (loss: 2.06060528755188, acc: 0.5)
[2025-01-30 02:16:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4404/107898 [23:56<9:56:18,  2.89it/s][2025-01-30 02:16:05][root][INFO] - Training Epoch: 1/2, step 4403/107898 completed (loss: 2.927274465560913, acc: 0.5)
[2025-01-30 02:16:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4405/107898 [23:56<9:44:55,  2.95it/s][2025-01-30 02:16:06][root][INFO] - Training Epoch: 1/2, step 4404/107898 completed (loss: 2.8748137950897217, acc: 0.25)
[2025-01-30 02:16:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4406/107898 [23:56<9:47:46,  2.93it/s][2025-01-30 02:16:06][root][INFO] - Training Epoch: 1/2, step 4405/107898 completed (loss: 4.01694917678833, acc: 0.5)
[2025-01-30 02:16:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4407/107898 [23:57<9:32:54,  3.01it/s][2025-01-30 02:16:06][root][INFO] - Training Epoch: 1/2, step 4406/107898 completed (loss: 2.2492246627807617, acc: 0.6666666865348816)
[2025-01-30 02:16:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4408/107898 [23:57<9:26:42,  3.04it/s][2025-01-30 02:16:07][root][INFO] - Training Epoch: 1/2, step 4407/107898 completed (loss: 1.6863023042678833, acc: 0.75)
[2025-01-30 02:16:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4409/107898 [23:57<9:36:50,  2.99it/s][2025-01-30 02:16:07][root][INFO] - Training Epoch: 1/2, step 4408/107898 completed (loss: 3.3311657905578613, acc: 0.5)
[2025-01-30 02:16:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4410/107898 [23:58<9:33:32,  3.01it/s][2025-01-30 02:16:07][root][INFO] - Training Epoch: 1/2, step 4409/107898 completed (loss: 0.24499061703681946, acc: 1.0)
[2025-01-30 02:16:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4411/107898 [23:58<9:32:52,  3.01it/s][2025-01-30 02:16:08][root][INFO] - Training Epoch: 1/2, step 4410/107898 completed (loss: 0.4688619077205658, acc: 1.0)
[2025-01-30 02:16:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4412/107898 [23:58<9:27:29,  3.04it/s][2025-01-30 02:16:08][root][INFO] - Training Epoch: 1/2, step 4411/107898 completed (loss: 1.307238221168518, acc: 0.692307710647583)
[2025-01-30 02:16:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4413/107898 [23:59<9:28:18,  3.03it/s][2025-01-30 02:16:08][root][INFO] - Training Epoch: 1/2, step 4412/107898 completed (loss: 0.544888973236084, acc: 0.6666666865348816)
[2025-01-30 02:16:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4414/107898 [23:59<9:27:04,  3.04it/s][2025-01-30 02:16:09][root][INFO] - Training Epoch: 1/2, step 4413/107898 completed (loss: 0.6393941640853882, acc: 0.800000011920929)
[2025-01-30 02:16:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4415/107898 [23:59<9:29:43,  3.03it/s][2025-01-30 02:16:09][root][INFO] - Training Epoch: 1/2, step 4414/107898 completed (loss: 3.4219679832458496, acc: 0.2666666805744171)
[2025-01-30 02:16:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4416/107898 [24:00<9:31:37,  3.02it/s][2025-01-30 02:16:09][root][INFO] - Training Epoch: 1/2, step 4415/107898 completed (loss: 1.311553716659546, acc: 0.6153846383094788)
[2025-01-30 02:16:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4417/107898 [24:00<9:27:39,  3.04it/s][2025-01-30 02:16:10][root][INFO] - Training Epoch: 1/2, step 4416/107898 completed (loss: 0.8279067277908325, acc: 0.8333333134651184)
[2025-01-30 02:16:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4418/107898 [24:00<9:35:12,  3.00it/s][2025-01-30 02:16:10][root][INFO] - Training Epoch: 1/2, step 4417/107898 completed (loss: 1.4617700576782227, acc: 0.6315789222717285)
[2025-01-30 02:16:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4419/107898 [24:01<9:28:50,  3.03it/s][2025-01-30 02:16:10][root][INFO] - Training Epoch: 1/2, step 4418/107898 completed (loss: 0.9976624250411987, acc: 0.5)
[2025-01-30 02:16:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4420/107898 [24:01<9:33:41,  3.01it/s][2025-01-30 02:16:11][root][INFO] - Training Epoch: 1/2, step 4419/107898 completed (loss: 0.2887074947357178, acc: 0.9487179517745972)
[2025-01-30 02:16:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4421/107898 [24:01<9:43:51,  2.95it/s][2025-01-30 02:16:11][root][INFO] - Training Epoch: 1/2, step 4420/107898 completed (loss: 3.4016337394714355, acc: 0.4285714328289032)
[2025-01-30 02:16:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4422/107898 [24:02<9:42:11,  2.96it/s][2025-01-30 02:16:11][root][INFO] - Training Epoch: 1/2, step 4421/107898 completed (loss: 0.8606310486793518, acc: 0.5)
[2025-01-30 02:16:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4423/107898 [24:02<9:40:57,  2.97it/s][2025-01-30 02:16:12][root][INFO] - Training Epoch: 1/2, step 4422/107898 completed (loss: 0.7282546758651733, acc: 0.90625)
[2025-01-30 02:16:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4424/107898 [24:02<9:54:39,  2.90it/s][2025-01-30 02:16:12][root][INFO] - Training Epoch: 1/2, step 4423/107898 completed (loss: 1.4673093557357788, acc: 0.4285714328289032)
[2025-01-30 02:16:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4425/107898 [24:03<10:00:19,  2.87it/s][2025-01-30 02:16:13][root][INFO] - Training Epoch: 1/2, step 4424/107898 completed (loss: 0.048187095671892166, acc: 1.0)
[2025-01-30 02:16:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4426/107898 [24:03<10:04:18,  2.85it/s][2025-01-30 02:16:13][root][INFO] - Training Epoch: 1/2, step 4425/107898 completed (loss: 0.5787182450294495, acc: 1.0)
[2025-01-30 02:16:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4427/107898 [24:03<9:56:14,  2.89it/s] [2025-01-30 02:16:13][root][INFO] - Training Epoch: 1/2, step 4426/107898 completed (loss: 0.8899916410446167, acc: 0.7142857313156128)
[2025-01-30 02:16:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4428/107898 [24:04<9:38:24,  2.98it/s][2025-01-30 02:16:14][root][INFO] - Training Epoch: 1/2, step 4427/107898 completed (loss: 2.9402666091918945, acc: 0.3333333432674408)
[2025-01-30 02:16:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4429/107898 [24:04<9:45:14,  2.95it/s][2025-01-30 02:16:14][root][INFO] - Training Epoch: 1/2, step 4428/107898 completed (loss: 0.6701300144195557, acc: 0.7368420958518982)
[2025-01-30 02:16:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4430/107898 [24:04<9:45:03,  2.95it/s][2025-01-30 02:16:14][root][INFO] - Training Epoch: 1/2, step 4429/107898 completed (loss: 0.11535532772541046, acc: 1.0)
[2025-01-30 02:16:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4431/107898 [24:05<9:33:25,  3.01it/s][2025-01-30 02:16:15][root][INFO] - Training Epoch: 1/2, step 4430/107898 completed (loss: 0.26616695523262024, acc: 1.0)
[2025-01-30 02:16:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4432/107898 [24:05<9:18:06,  3.09it/s][2025-01-30 02:16:15][root][INFO] - Training Epoch: 1/2, step 4431/107898 completed (loss: 0.11836510896682739, acc: 1.0)
[2025-01-30 02:16:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4433/107898 [24:05<9:09:16,  3.14it/s][2025-01-30 02:16:15][root][INFO] - Training Epoch: 1/2, step 4432/107898 completed (loss: 0.027190759778022766, acc: 1.0)
[2025-01-30 02:16:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4434/107898 [24:06<8:54:44,  3.22it/s][2025-01-30 02:16:15][root][INFO] - Training Epoch: 1/2, step 4433/107898 completed (loss: 0.7142223715782166, acc: 1.0)
[2025-01-30 02:16:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4435/107898 [24:06<9:11:30,  3.13it/s][2025-01-30 02:16:16][root][INFO] - Training Epoch: 1/2, step 4434/107898 completed (loss: 0.04339471086859703, acc: 1.0)
[2025-01-30 02:16:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4436/107898 [24:06<9:23:07,  3.06it/s][2025-01-30 02:16:16][root][INFO] - Training Epoch: 1/2, step 4435/107898 completed (loss: 1.4995938539505005, acc: 0.6666666865348816)
[2025-01-30 02:16:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4437/107898 [24:07<9:02:25,  3.18it/s][2025-01-30 02:16:16][root][INFO] - Training Epoch: 1/2, step 4436/107898 completed (loss: 1.7112011909484863, acc: 0.5833333134651184)
[2025-01-30 02:16:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4438/107898 [24:07<8:52:59,  3.24it/s][2025-01-30 02:16:17][root][INFO] - Training Epoch: 1/2, step 4437/107898 completed (loss: 0.6699120402336121, acc: 0.75)
[2025-01-30 02:16:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4439/107898 [24:07<8:46:59,  3.27it/s][2025-01-30 02:16:17][root][INFO] - Training Epoch: 1/2, step 4438/107898 completed (loss: 1.9818148612976074, acc: 0.6666666865348816)
[2025-01-30 02:16:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4440/107898 [24:07<8:43:53,  3.29it/s][2025-01-30 02:16:17][root][INFO] - Training Epoch: 1/2, step 4439/107898 completed (loss: 0.0019000142347067595, acc: 1.0)
[2025-01-30 02:16:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4441/107898 [24:08<8:53:05,  3.23it/s][2025-01-30 02:16:18][root][INFO] - Training Epoch: 1/2, step 4440/107898 completed (loss: 0.059796303510665894, acc: 1.0)
[2025-01-30 02:16:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4442/107898 [24:08<9:06:55,  3.15it/s][2025-01-30 02:16:18][root][INFO] - Training Epoch: 1/2, step 4441/107898 completed (loss: 2.0363075733184814, acc: 0.375)
[2025-01-30 02:16:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4443/107898 [24:08<9:07:14,  3.15it/s][2025-01-30 02:16:18][root][INFO] - Training Epoch: 1/2, step 4442/107898 completed (loss: 2.181274652481079, acc: 0.6428571343421936)
[2025-01-30 02:16:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4444/107898 [24:09<9:07:08,  3.15it/s][2025-01-30 02:16:19][root][INFO] - Training Epoch: 1/2, step 4443/107898 completed (loss: 0.6464317440986633, acc: 0.8260869383811951)
[2025-01-30 02:16:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4445/107898 [24:09<8:55:15,  3.22it/s][2025-01-30 02:16:19][root][INFO] - Training Epoch: 1/2, step 4444/107898 completed (loss: 0.024084942415356636, acc: 1.0)
[2025-01-30 02:16:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4446/107898 [24:09<8:48:06,  3.26it/s][2025-01-30 02:16:19][root][INFO] - Training Epoch: 1/2, step 4445/107898 completed (loss: 0.19859014451503754, acc: 0.9166666865348816)
[2025-01-30 02:16:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4447/107898 [24:10<9:02:50,  3.18it/s][2025-01-30 02:16:20][root][INFO] - Training Epoch: 1/2, step 4446/107898 completed (loss: 1.713493824005127, acc: 0.71875)
[2025-01-30 02:16:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4448/107898 [24:10<8:58:04,  3.20it/s][2025-01-30 02:16:20][root][INFO] - Training Epoch: 1/2, step 4447/107898 completed (loss: 0.18146394193172455, acc: 0.9285714030265808)
[2025-01-30 02:16:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4449/107898 [24:10<8:59:37,  3.20it/s][2025-01-30 02:16:20][root][INFO] - Training Epoch: 1/2, step 4448/107898 completed (loss: 3.9148919582366943, acc: 0.1666666716337204)
[2025-01-30 02:16:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4450/107898 [24:11<9:10:10,  3.13it/s][2025-01-30 02:16:20][root][INFO] - Training Epoch: 1/2, step 4449/107898 completed (loss: 0.010475360788404942, acc: 1.0)
[2025-01-30 02:16:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4451/107898 [24:11<9:16:02,  3.10it/s][2025-01-30 02:16:21][root][INFO] - Training Epoch: 1/2, step 4450/107898 completed (loss: 0.9548962712287903, acc: 0.7692307829856873)
[2025-01-30 02:16:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4452/107898 [24:11<9:08:20,  3.14it/s][2025-01-30 02:16:21][root][INFO] - Training Epoch: 1/2, step 4451/107898 completed (loss: 2.669952392578125, acc: 0.46666666865348816)
[2025-01-30 02:16:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4453/107898 [24:12<8:55:04,  3.22it/s][2025-01-30 02:16:21][root][INFO] - Training Epoch: 1/2, step 4452/107898 completed (loss: 0.017268041148781776, acc: 1.0)
[2025-01-30 02:16:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4454/107898 [24:12<8:51:46,  3.24it/s][2025-01-30 02:16:22][root][INFO] - Training Epoch: 1/2, step 4453/107898 completed (loss: 0.04977822303771973, acc: 1.0)
[2025-01-30 02:16:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4455/107898 [24:12<9:02:24,  3.18it/s][2025-01-30 02:16:22][root][INFO] - Training Epoch: 1/2, step 4454/107898 completed (loss: 3.4898109436035156, acc: 0.15000000596046448)
[2025-01-30 02:16:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4456/107898 [24:13<9:03:51,  3.17it/s][2025-01-30 02:16:22][root][INFO] - Training Epoch: 1/2, step 4455/107898 completed (loss: 0.021223284304142, acc: 1.0)
[2025-01-30 02:16:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4457/107898 [24:13<9:25:25,  3.05it/s][2025-01-30 02:16:23][root][INFO] - Training Epoch: 1/2, step 4456/107898 completed (loss: 0.6629694104194641, acc: 0.6666666865348816)
[2025-01-30 02:16:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4458/107898 [24:13<9:35:39,  2.99it/s][2025-01-30 02:16:23][root][INFO] - Training Epoch: 1/2, step 4457/107898 completed (loss: 0.08635257929563522, acc: 1.0)
[2025-01-30 02:16:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4459/107898 [24:14<9:41:36,  2.96it/s][2025-01-30 02:16:23][root][INFO] - Training Epoch: 1/2, step 4458/107898 completed (loss: 2.024282455444336, acc: 0.6428571343421936)
[2025-01-30 02:16:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4460/107898 [24:14<9:35:38,  2.99it/s][2025-01-30 02:16:24][root][INFO] - Training Epoch: 1/2, step 4459/107898 completed (loss: 0.46242889761924744, acc: 0.8333333134651184)
[2025-01-30 02:16:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4461/107898 [24:14<9:23:23,  3.06it/s][2025-01-30 02:16:24][root][INFO] - Training Epoch: 1/2, step 4460/107898 completed (loss: 2.701960325241089, acc: 0.4000000059604645)
[2025-01-30 02:16:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4462/107898 [24:15<9:13:22,  3.12it/s][2025-01-30 02:16:24][root][INFO] - Training Epoch: 1/2, step 4461/107898 completed (loss: 0.014765022322535515, acc: 1.0)
[2025-01-30 02:16:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4463/107898 [24:15<9:35:22,  3.00it/s][2025-01-30 02:16:25][root][INFO] - Training Epoch: 1/2, step 4462/107898 completed (loss: 3.5407395362854004, acc: 0.29032257199287415)
[2025-01-30 02:16:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4464/107898 [24:15<9:55:07,  2.90it/s][2025-01-30 02:16:25][root][INFO] - Training Epoch: 1/2, step 4463/107898 completed (loss: 0.608301043510437, acc: 0.5)
[2025-01-30 02:16:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4465/107898 [24:16<9:58:27,  2.88it/s][2025-01-30 02:16:25][root][INFO] - Training Epoch: 1/2, step 4464/107898 completed (loss: 0.4000939726829529, acc: 1.0)
[2025-01-30 02:16:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4466/107898 [24:16<10:04:52,  2.85it/s][2025-01-30 02:16:26][root][INFO] - Training Epoch: 1/2, step 4465/107898 completed (loss: 1.0067564249038696, acc: 0.807692289352417)
[2025-01-30 02:16:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4467/107898 [24:16<9:37:04,  2.99it/s] [2025-01-30 02:16:26][root][INFO] - Training Epoch: 1/2, step 4466/107898 completed (loss: 0.038130320608615875, acc: 1.0)
[2025-01-30 02:16:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4468/107898 [24:17<9:15:14,  3.10it/s][2025-01-30 02:16:26][root][INFO] - Training Epoch: 1/2, step 4467/107898 completed (loss: 0.02532476745545864, acc: 1.0)
[2025-01-30 02:16:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4469/107898 [24:17<9:04:06,  3.17it/s][2025-01-30 02:16:27][root][INFO] - Training Epoch: 1/2, step 4468/107898 completed (loss: 1.655857801437378, acc: 0.5555555820465088)
[2025-01-30 02:16:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4470/107898 [24:17<8:54:47,  3.22it/s][2025-01-30 02:16:27][root][INFO] - Training Epoch: 1/2, step 4469/107898 completed (loss: 0.014062625356018543, acc: 1.0)
[2025-01-30 02:16:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4471/107898 [24:17<8:55:26,  3.22it/s][2025-01-30 02:16:27][root][INFO] - Training Epoch: 1/2, step 4470/107898 completed (loss: 0.028203662484884262, acc: 1.0)
[2025-01-30 02:16:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4472/107898 [24:18<9:00:41,  3.19it/s][2025-01-30 02:16:28][root][INFO] - Training Epoch: 1/2, step 4471/107898 completed (loss: 1.2648807764053345, acc: 0.7894737124443054)
[2025-01-30 02:16:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4473/107898 [24:18<9:11:53,  3.12it/s][2025-01-30 02:16:28][root][INFO] - Training Epoch: 1/2, step 4472/107898 completed (loss: 1.7091408967971802, acc: 0.5)
[2025-01-30 02:16:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4474/107898 [24:18<9:04:05,  3.17it/s][2025-01-30 02:16:28][root][INFO] - Training Epoch: 1/2, step 4473/107898 completed (loss: 0.02117455005645752, acc: 1.0)
[2025-01-30 02:16:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4475/107898 [24:19<9:06:35,  3.15it/s][2025-01-30 02:16:29][root][INFO] - Training Epoch: 1/2, step 4474/107898 completed (loss: 4.411497592926025, acc: 0.3333333432674408)
[2025-01-30 02:16:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4476/107898 [24:19<8:38:22,  3.33it/s][2025-01-30 02:16:29][root][INFO] - Training Epoch: 1/2, step 4475/107898 completed (loss: 3.2631704807281494, acc: 0.5714285969734192)
[2025-01-30 02:16:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4477/107898 [24:19<9:02:13,  3.18it/s][2025-01-30 02:16:29][root][INFO] - Training Epoch: 1/2, step 4476/107898 completed (loss: 0.10748287290334702, acc: 1.0)
[2025-01-30 02:16:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4478/107898 [24:20<9:24:46,  3.05it/s][2025-01-30 02:16:30][root][INFO] - Training Epoch: 1/2, step 4477/107898 completed (loss: 0.008615122176706791, acc: 1.0)
[2025-01-30 02:16:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4479/107898 [24:20<9:24:55,  3.05it/s][2025-01-30 02:16:30][root][INFO] - Training Epoch: 1/2, step 4478/107898 completed (loss: 1.0382753610610962, acc: 0.7333333492279053)
[2025-01-30 02:16:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4480/107898 [24:20<9:14:53,  3.11it/s][2025-01-30 02:16:30][root][INFO] - Training Epoch: 1/2, step 4479/107898 completed (loss: 2.4622418880462646, acc: 0.7777777910232544)
[2025-01-30 02:16:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4481/107898 [24:21<9:29:10,  3.03it/s][2025-01-30 02:16:31][root][INFO] - Training Epoch: 1/2, step 4480/107898 completed (loss: 0.024858323857188225, acc: 1.0)
[2025-01-30 02:16:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4482/107898 [24:21<9:28:14,  3.03it/s][2025-01-30 02:16:31][root][INFO] - Training Epoch: 1/2, step 4481/107898 completed (loss: 0.5060126781463623, acc: 0.8571428656578064)
[2025-01-30 02:16:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4483/107898 [24:21<9:22:41,  3.06it/s][2025-01-30 02:16:31][root][INFO] - Training Epoch: 1/2, step 4482/107898 completed (loss: 0.8402307033538818, acc: 0.8148148059844971)
[2025-01-30 02:16:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4484/107898 [24:22<9:09:19,  3.14it/s][2025-01-30 02:16:31][root][INFO] - Training Epoch: 1/2, step 4483/107898 completed (loss: 1.3536690473556519, acc: 0.6000000238418579)
[2025-01-30 02:16:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4485/107898 [24:22<9:30:23,  3.02it/s][2025-01-30 02:16:32][root][INFO] - Training Epoch: 1/2, step 4484/107898 completed (loss: 0.04806198552250862, acc: 1.0)
[2025-01-30 02:16:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4486/107898 [24:22<9:37:17,  2.99it/s][2025-01-30 02:16:32][root][INFO] - Training Epoch: 1/2, step 4485/107898 completed (loss: 0.31494322419166565, acc: 0.875)
[2025-01-30 02:16:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4487/107898 [24:23<9:41:00,  2.97it/s][2025-01-30 02:16:33][root][INFO] - Training Epoch: 1/2, step 4486/107898 completed (loss: 0.5317903161048889, acc: 0.9166666865348816)
[2025-01-30 02:16:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4488/107898 [24:23<9:31:22,  3.02it/s][2025-01-30 02:16:33][root][INFO] - Training Epoch: 1/2, step 4487/107898 completed (loss: 0.8484698534011841, acc: 0.7931034564971924)
[2025-01-30 02:16:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4489/107898 [24:23<9:42:47,  2.96it/s][2025-01-30 02:16:33][root][INFO] - Training Epoch: 1/2, step 4488/107898 completed (loss: 1.0708290338516235, acc: 0.7857142686843872)
[2025-01-30 02:16:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4490/107898 [24:24<10:03:14,  2.86it/s][2025-01-30 02:16:34][root][INFO] - Training Epoch: 1/2, step 4489/107898 completed (loss: 0.9732611775398254, acc: 0.7857142686843872)
[2025-01-30 02:16:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4491/107898 [24:24<9:51:06,  2.92it/s] [2025-01-30 02:16:34][root][INFO] - Training Epoch: 1/2, step 4490/107898 completed (loss: 0.7378004789352417, acc: 0.9047619104385376)
[2025-01-30 02:16:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4492/107898 [24:24<9:30:35,  3.02it/s][2025-01-30 02:16:34][root][INFO] - Training Epoch: 1/2, step 4491/107898 completed (loss: 0.007439515087753534, acc: 1.0)
[2025-01-30 02:16:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4493/107898 [24:25<9:18:00,  3.09it/s][2025-01-30 02:16:34][root][INFO] - Training Epoch: 1/2, step 4492/107898 completed (loss: 4.410244464874268, acc: 0.4000000059604645)
[2025-01-30 02:16:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4494/107898 [24:25<8:42:02,  3.30it/s][2025-01-30 02:16:35][root][INFO] - Training Epoch: 1/2, step 4493/107898 completed (loss: 0.2413814663887024, acc: 0.9629629850387573)
[2025-01-30 02:16:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4495/107898 [24:25<8:38:12,  3.33it/s][2025-01-30 02:16:35][root][INFO] - Training Epoch: 1/2, step 4494/107898 completed (loss: 0.06692105531692505, acc: 1.0)
[2025-01-30 02:16:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4496/107898 [24:26<9:02:35,  3.18it/s][2025-01-30 02:16:35][root][INFO] - Training Epoch: 1/2, step 4495/107898 completed (loss: 0.010251086205244064, acc: 1.0)
[2025-01-30 02:16:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4497/107898 [24:26<9:17:14,  3.09it/s][2025-01-30 02:16:36][root][INFO] - Training Epoch: 1/2, step 4496/107898 completed (loss: 0.26319852471351624, acc: 0.9615384340286255)
[2025-01-30 02:16:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4498/107898 [24:26<9:10:34,  3.13it/s][2025-01-30 02:16:36][root][INFO] - Training Epoch: 1/2, step 4497/107898 completed (loss: 5.05230712890625, acc: 0.1428571492433548)
[2025-01-30 02:16:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4499/107898 [24:27<9:23:25,  3.06it/s][2025-01-30 02:16:36][root][INFO] - Training Epoch: 1/2, step 4498/107898 completed (loss: 0.6619114279747009, acc: 0.75)
[2025-01-30 02:16:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4500/107898 [24:27<9:26:50,  3.04it/s][2025-01-30 02:16:37][root][INFO] - Training Epoch: 1/2, step 4499/107898 completed (loss: 1.287652850151062, acc: 0.7142857313156128)
[2025-01-30 02:16:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4501/107898 [24:27<9:37:51,  2.98it/s][2025-01-30 02:16:37][root][INFO] - Training Epoch: 1/2, step 4500/107898 completed (loss: 0.027670737355947495, acc: 1.0)
[2025-01-30 02:16:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4502/107898 [24:28<9:05:07,  3.16it/s][2025-01-30 02:16:37][root][INFO] - Training Epoch: 1/2, step 4501/107898 completed (loss: 0.3631579577922821, acc: 1.0)
[2025-01-30 02:16:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4503/107898 [24:28<9:03:33,  3.17it/s][2025-01-30 02:16:38][root][INFO] - Training Epoch: 1/2, step 4502/107898 completed (loss: 1.0317461490631104, acc: 0.699999988079071)
[2025-01-30 02:16:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4504/107898 [24:28<9:01:41,  3.18it/s][2025-01-30 02:16:38][root][INFO] - Training Epoch: 1/2, step 4503/107898 completed (loss: 1.3804908990859985, acc: 0.875)
[2025-01-30 02:16:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4505/107898 [24:29<9:15:47,  3.10it/s][2025-01-30 02:16:38][root][INFO] - Training Epoch: 1/2, step 4504/107898 completed (loss: 1.348319411277771, acc: 0.7857142686843872)
[2025-01-30 02:16:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4506/107898 [24:29<9:14:43,  3.11it/s][2025-01-30 02:16:39][root][INFO] - Training Epoch: 1/2, step 4505/107898 completed (loss: 1.8640272617340088, acc: 0.5)
[2025-01-30 02:16:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4507/107898 [24:29<9:15:13,  3.10it/s][2025-01-30 02:16:39][root][INFO] - Training Epoch: 1/2, step 4506/107898 completed (loss: 0.88653564453125, acc: 0.8571428656578064)
[2025-01-30 02:16:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4508/107898 [24:30<9:37:00,  2.99it/s][2025-01-30 02:16:39][root][INFO] - Training Epoch: 1/2, step 4507/107898 completed (loss: 2.4516236782073975, acc: 0.4545454680919647)
[2025-01-30 02:16:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4509/107898 [24:30<9:38:35,  2.98it/s][2025-01-30 02:16:40][root][INFO] - Training Epoch: 1/2, step 4508/107898 completed (loss: 0.8349810242652893, acc: 0.7058823704719543)
[2025-01-30 02:16:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4510/107898 [24:30<9:27:46,  3.03it/s][2025-01-30 02:16:40][root][INFO] - Training Epoch: 1/2, step 4509/107898 completed (loss: 1.9022778272628784, acc: 0.5757575631141663)
[2025-01-30 02:16:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4511/107898 [24:31<9:25:14,  3.05it/s][2025-01-30 02:16:40][root][INFO] - Training Epoch: 1/2, step 4510/107898 completed (loss: 0.18453922867774963, acc: 1.0)
[2025-01-30 02:16:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4512/107898 [24:31<9:12:42,  3.12it/s][2025-01-30 02:16:41][root][INFO] - Training Epoch: 1/2, step 4511/107898 completed (loss: 2.8046722412109375, acc: 0.5)
[2025-01-30 02:16:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4513/107898 [24:31<8:59:20,  3.19it/s][2025-01-30 02:16:41][root][INFO] - Training Epoch: 1/2, step 4512/107898 completed (loss: 0.30713167786598206, acc: 1.0)
[2025-01-30 02:16:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4514/107898 [24:31<8:55:50,  3.22it/s][2025-01-30 02:16:41][root][INFO] - Training Epoch: 1/2, step 4513/107898 completed (loss: 1.3683422803878784, acc: 0.875)
[2025-01-30 02:16:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4515/107898 [24:32<8:45:46,  3.28it/s][2025-01-30 02:16:41][root][INFO] - Training Epoch: 1/2, step 4514/107898 completed (loss: 0.08874431252479553, acc: 1.0)
[2025-01-30 02:16:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4516/107898 [24:32<8:48:01,  3.26it/s][2025-01-30 02:16:42][root][INFO] - Training Epoch: 1/2, step 4515/107898 completed (loss: 0.21564558148384094, acc: 1.0)
[2025-01-30 02:16:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4517/107898 [24:32<8:54:14,  3.23it/s][2025-01-30 02:16:42][root][INFO] - Training Epoch: 1/2, step 4516/107898 completed (loss: 0.1588749885559082, acc: 0.9444444179534912)
[2025-01-30 02:16:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4518/107898 [24:33<9:05:12,  3.16it/s][2025-01-30 02:16:42][root][INFO] - Training Epoch: 1/2, step 4517/107898 completed (loss: 1.0740699768066406, acc: 0.8571428656578064)
[2025-01-30 02:16:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4519/107898 [24:33<8:59:30,  3.19it/s][2025-01-30 02:16:43][root][INFO] - Training Epoch: 1/2, step 4518/107898 completed (loss: 4.537785053253174, acc: 0.3333333432674408)
[2025-01-30 02:16:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4520/107898 [24:33<9:14:19,  3.11it/s][2025-01-30 02:16:43][root][INFO] - Training Epoch: 1/2, step 4519/107898 completed (loss: 0.5419644117355347, acc: 0.9047619104385376)
[2025-01-30 02:16:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4521/107898 [24:34<9:16:09,  3.10it/s][2025-01-30 02:16:43][root][INFO] - Training Epoch: 1/2, step 4520/107898 completed (loss: 0.48623892664909363, acc: 0.9285714030265808)
[2025-01-30 02:16:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4522/107898 [24:34<9:34:37,  3.00it/s][2025-01-30 02:16:44][root][INFO] - Training Epoch: 1/2, step 4521/107898 completed (loss: 1.9126447439193726, acc: 0.6666666865348816)
[2025-01-30 02:16:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4523/107898 [24:34<9:33:54,  3.00it/s][2025-01-30 02:16:44][root][INFO] - Training Epoch: 1/2, step 4522/107898 completed (loss: 2.2282819747924805, acc: 0.6111111044883728)
[2025-01-30 02:16:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4524/107898 [24:35<9:17:16,  3.09it/s][2025-01-30 02:16:44][root][INFO] - Training Epoch: 1/2, step 4523/107898 completed (loss: 3.625779867172241, acc: 0.2857142984867096)
[2025-01-30 02:16:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4525/107898 [24:35<9:38:42,  2.98it/s][2025-01-30 02:16:45][root][INFO] - Training Epoch: 1/2, step 4524/107898 completed (loss: 2.751106023788452, acc: 0.4399999976158142)
[2025-01-30 02:16:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4526/107898 [24:35<9:39:35,  2.97it/s][2025-01-30 02:16:45][root][INFO] - Training Epoch: 1/2, step 4525/107898 completed (loss: 0.26869696378707886, acc: 0.8888888955116272)
[2025-01-30 02:16:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4527/107898 [24:36<9:30:46,  3.02it/s][2025-01-30 02:16:45][root][INFO] - Training Epoch: 1/2, step 4526/107898 completed (loss: 2.007075309753418, acc: 0.6000000238418579)
[2025-01-30 02:16:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4528/107898 [24:36<9:19:24,  3.08it/s][2025-01-30 02:16:46][root][INFO] - Training Epoch: 1/2, step 4527/107898 completed (loss: 1.4516167640686035, acc: 0.6666666865348816)
[2025-01-30 02:16:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4529/107898 [24:36<9:02:46,  3.17it/s][2025-01-30 02:16:46][root][INFO] - Training Epoch: 1/2, step 4528/107898 completed (loss: 1.016208291053772, acc: 0.8571428656578064)
[2025-01-30 02:16:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4530/107898 [24:37<9:02:17,  3.18it/s][2025-01-30 02:16:46][root][INFO] - Training Epoch: 1/2, step 4529/107898 completed (loss: 0.4725600481033325, acc: 0.8260869383811951)
[2025-01-30 02:16:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4531/107898 [24:37<8:57:56,  3.20it/s][2025-01-30 02:16:47][root][INFO] - Training Epoch: 1/2, step 4530/107898 completed (loss: 0.9529822468757629, acc: 0.807692289352417)
[2025-01-30 02:16:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4532/107898 [24:37<8:47:25,  3.27it/s][2025-01-30 02:16:47][root][INFO] - Training Epoch: 1/2, step 4531/107898 completed (loss: 4.690091609954834, acc: 0.09090909361839294)
[2025-01-30 02:16:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4533/107898 [24:37<8:42:38,  3.30it/s][2025-01-30 02:16:47][root][INFO] - Training Epoch: 1/2, step 4532/107898 completed (loss: 0.000890926574356854, acc: 1.0)
[2025-01-30 02:16:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4534/107898 [24:38<8:51:15,  3.24it/s][2025-01-30 02:16:48][root][INFO] - Training Epoch: 1/2, step 4533/107898 completed (loss: 0.9875929951667786, acc: 0.8999999761581421)
[2025-01-30 02:16:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4535/107898 [24:38<9:03:49,  3.17it/s][2025-01-30 02:16:48][root][INFO] - Training Epoch: 1/2, step 4534/107898 completed (loss: 3.9969065189361572, acc: 0.3181818127632141)
[2025-01-30 02:16:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4536/107898 [24:38<8:59:55,  3.19it/s][2025-01-30 02:16:48][root][INFO] - Training Epoch: 1/2, step 4535/107898 completed (loss: 0.3217225968837738, acc: 1.0)
[2025-01-30 02:16:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4537/107898 [24:39<9:22:29,  3.06it/s][2025-01-30 02:16:49][root][INFO] - Training Epoch: 1/2, step 4536/107898 completed (loss: 3.570091485977173, acc: 0.30434781312942505)
[2025-01-30 02:16:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4538/107898 [24:39<9:25:27,  3.05it/s][2025-01-30 02:16:49][root][INFO] - Training Epoch: 1/2, step 4537/107898 completed (loss: 2.3439619541168213, acc: 0.6666666865348816)
[2025-01-30 02:16:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4539/107898 [24:39<9:15:02,  3.10it/s][2025-01-30 02:16:49][root][INFO] - Training Epoch: 1/2, step 4538/107898 completed (loss: 0.4833199977874756, acc: 0.6666666865348816)
[2025-01-30 02:16:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4540/107898 [24:40<9:26:18,  3.04it/s][2025-01-30 02:16:50][root][INFO] - Training Epoch: 1/2, step 4539/107898 completed (loss: 0.026856273412704468, acc: 1.0)
[2025-01-30 02:16:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4541/107898 [24:40<9:27:28,  3.04it/s][2025-01-30 02:16:50][root][INFO] - Training Epoch: 1/2, step 4540/107898 completed (loss: 0.004887461196631193, acc: 1.0)
[2025-01-30 02:16:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4542/107898 [24:40<9:21:53,  3.07it/s][2025-01-30 02:16:50][root][INFO] - Training Epoch: 1/2, step 4541/107898 completed (loss: 0.5669207572937012, acc: 0.8823529481887817)
[2025-01-30 02:16:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4543/107898 [24:41<9:16:04,  3.10it/s][2025-01-30 02:16:51][root][INFO] - Training Epoch: 1/2, step 4542/107898 completed (loss: 0.0027532114181667566, acc: 1.0)
[2025-01-30 02:16:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4544/107898 [24:41<9:12:54,  3.12it/s][2025-01-30 02:16:51][root][INFO] - Training Epoch: 1/2, step 4543/107898 completed (loss: 0.5724783539772034, acc: 0.7857142686843872)
[2025-01-30 02:16:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4545/107898 [24:41<8:57:57,  3.20it/s][2025-01-30 02:16:51][root][INFO] - Training Epoch: 1/2, step 4544/107898 completed (loss: 0.6766095161437988, acc: 0.875)
[2025-01-30 02:16:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4546/107898 [24:42<8:48:15,  3.26it/s][2025-01-30 02:16:51][root][INFO] - Training Epoch: 1/2, step 4545/107898 completed (loss: 1.3472272157669067, acc: 0.692307710647583)
[2025-01-30 02:16:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4547/107898 [24:42<9:06:01,  3.15it/s][2025-01-30 02:16:52][root][INFO] - Training Epoch: 1/2, step 4546/107898 completed (loss: 3.025562047958374, acc: 0.6666666865348816)
[2025-01-30 02:16:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4548/107898 [24:42<9:06:50,  3.15it/s][2025-01-30 02:16:52][root][INFO] - Training Epoch: 1/2, step 4547/107898 completed (loss: 0.019226478412747383, acc: 1.0)
[2025-01-30 02:16:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4549/107898 [24:43<8:51:01,  3.24it/s][2025-01-30 02:16:52][root][INFO] - Training Epoch: 1/2, step 4548/107898 completed (loss: 2.6303296089172363, acc: 0.20000000298023224)
[2025-01-30 02:16:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4550/107898 [24:43<8:52:04,  3.24it/s][2025-01-30 02:16:53][root][INFO] - Training Epoch: 1/2, step 4549/107898 completed (loss: 1.2137776613235474, acc: 0.75)
[2025-01-30 02:16:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4551/107898 [24:43<9:04:47,  3.16it/s][2025-01-30 02:16:53][root][INFO] - Training Epoch: 1/2, step 4550/107898 completed (loss: 3.4805550575256348, acc: 0.25)
[2025-01-30 02:16:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4552/107898 [24:44<9:15:16,  3.10it/s][2025-01-30 02:16:53][root][INFO] - Training Epoch: 1/2, step 4551/107898 completed (loss: 0.26133954524993896, acc: 1.0)
[2025-01-30 02:16:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4553/107898 [24:44<10:20:44,  2.77it/s][2025-01-30 02:16:54][root][INFO] - Training Epoch: 1/2, step 4552/107898 completed (loss: 0.8369048237800598, acc: 0.8518518805503845)
[2025-01-30 02:16:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4554/107898 [24:44<9:49:42,  2.92it/s] [2025-01-30 02:16:54][root][INFO] - Training Epoch: 1/2, step 4553/107898 completed (loss: 0.4089354872703552, acc: 1.0)
[2025-01-30 02:16:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4555/107898 [24:45<9:29:57,  3.02it/s][2025-01-30 02:16:54][root][INFO] - Training Epoch: 1/2, step 4554/107898 completed (loss: 0.14953230321407318, acc: 1.0)
[2025-01-30 02:16:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4556/107898 [24:45<9:15:03,  3.10it/s][2025-01-30 02:16:55][root][INFO] - Training Epoch: 1/2, step 4555/107898 completed (loss: 0.010873171500861645, acc: 1.0)
[2025-01-30 02:16:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4557/107898 [24:45<9:33:12,  3.00it/s][2025-01-30 02:16:55][root][INFO] - Training Epoch: 1/2, step 4556/107898 completed (loss: 0.009025846607983112, acc: 1.0)
[2025-01-30 02:16:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4558/107898 [24:46<9:29:39,  3.02it/s][2025-01-30 02:16:55][root][INFO] - Training Epoch: 1/2, step 4557/107898 completed (loss: 0.47762438654899597, acc: 0.8965517282485962)
[2025-01-30 02:16:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4559/107898 [24:46<9:27:28,  3.04it/s][2025-01-30 02:16:56][root][INFO] - Training Epoch: 1/2, step 4558/107898 completed (loss: 1.7042330503463745, acc: 0.6666666865348816)
[2025-01-30 02:16:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4560/107898 [24:46<9:05:23,  3.16it/s][2025-01-30 02:16:56][root][INFO] - Training Epoch: 1/2, step 4559/107898 completed (loss: 0.7506778240203857, acc: 0.7692307829856873)
[2025-01-30 02:16:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4561/107898 [24:47<9:03:16,  3.17it/s][2025-01-30 02:16:56][root][INFO] - Training Epoch: 1/2, step 4560/107898 completed (loss: 0.06898438930511475, acc: 1.0)
[2025-01-30 02:16:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4562/107898 [24:47<9:25:43,  3.04it/s][2025-01-30 02:16:57][root][INFO] - Training Epoch: 1/2, step 4561/107898 completed (loss: 2.1934776306152344, acc: 0.5)
[2025-01-30 02:16:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4563/107898 [24:47<9:44:47,  2.95it/s][2025-01-30 02:16:57][root][INFO] - Training Epoch: 1/2, step 4562/107898 completed (loss: 1.7108899354934692, acc: 0.5)
[2025-01-30 02:16:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4564/107898 [24:48<9:51:41,  2.91it/s][2025-01-30 02:16:57][root][INFO] - Training Epoch: 1/2, step 4563/107898 completed (loss: 0.15082237124443054, acc: 1.0)
[2025-01-30 02:16:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4565/107898 [24:48<9:49:10,  2.92it/s][2025-01-30 02:16:58][root][INFO] - Training Epoch: 1/2, step 4564/107898 completed (loss: 0.4892216622829437, acc: 0.9333333373069763)
[2025-01-30 02:16:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4566/107898 [24:48<9:34:31,  3.00it/s][2025-01-30 02:16:58][root][INFO] - Training Epoch: 1/2, step 4565/107898 completed (loss: 0.06713107973337173, acc: 1.0)
[2025-01-30 02:16:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4567/107898 [24:49<9:40:19,  2.97it/s][2025-01-30 02:16:58][root][INFO] - Training Epoch: 1/2, step 4566/107898 completed (loss: 0.2261495143175125, acc: 0.8999999761581421)
[2025-01-30 02:16:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4568/107898 [24:49<9:25:41,  3.04it/s][2025-01-30 02:16:59][root][INFO] - Training Epoch: 1/2, step 4567/107898 completed (loss: 0.005678113549947739, acc: 1.0)
[2025-01-30 02:16:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4569/107898 [24:49<9:15:48,  3.10it/s][2025-01-30 02:16:59][root][INFO] - Training Epoch: 1/2, step 4568/107898 completed (loss: 0.572537899017334, acc: 0.7857142686843872)
[2025-01-30 02:16:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4570/107898 [24:50<9:26:26,  3.04it/s][2025-01-30 02:16:59][root][INFO] - Training Epoch: 1/2, step 4569/107898 completed (loss: 2.565582752227783, acc: 0.3499999940395355)
[2025-01-30 02:16:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4571/107898 [24:50<9:26:05,  3.04it/s][2025-01-30 02:17:00][root][INFO] - Training Epoch: 1/2, step 4570/107898 completed (loss: 0.4971601366996765, acc: 0.800000011920929)
[2025-01-30 02:17:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4572/107898 [24:50<9:16:13,  3.10it/s][2025-01-30 02:17:00][root][INFO] - Training Epoch: 1/2, step 4571/107898 completed (loss: 0.5635778307914734, acc: 0.9285714030265808)
[2025-01-30 02:17:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4573/107898 [24:51<9:21:28,  3.07it/s][2025-01-30 02:17:00][root][INFO] - Training Epoch: 1/2, step 4572/107898 completed (loss: 0.8184888362884521, acc: 0.75)
[2025-01-30 02:17:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4574/107898 [24:51<9:47:07,  2.93it/s][2025-01-30 02:17:01][root][INFO] - Training Epoch: 1/2, step 4573/107898 completed (loss: 0.4941806495189667, acc: 0.9285714030265808)
[2025-01-30 02:17:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4575/107898 [24:51<9:52:27,  2.91it/s][2025-01-30 02:17:01][root][INFO] - Training Epoch: 1/2, step 4574/107898 completed (loss: 0.342254638671875, acc: 0.8333333134651184)
[2025-01-30 02:17:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4576/107898 [24:52<9:49:05,  2.92it/s][2025-01-30 02:17:01][root][INFO] - Training Epoch: 1/2, step 4575/107898 completed (loss: 0.0036014625802636147, acc: 1.0)
[2025-01-30 02:17:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4577/107898 [24:52<9:43:59,  2.95it/s][2025-01-30 02:17:02][root][INFO] - Training Epoch: 1/2, step 4576/107898 completed (loss: 0.6157470345497131, acc: 0.800000011920929)
[2025-01-30 02:17:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4578/107898 [24:52<9:20:46,  3.07it/s][2025-01-30 02:17:02][root][INFO] - Training Epoch: 1/2, step 4577/107898 completed (loss: 4.565666198730469, acc: 0.3333333432674408)
[2025-01-30 02:17:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4579/107898 [24:53<9:26:00,  3.04it/s][2025-01-30 02:17:02][root][INFO] - Training Epoch: 1/2, step 4578/107898 completed (loss: 0.5582433938980103, acc: 0.9411764740943909)
[2025-01-30 02:17:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4580/107898 [24:53<9:32:23,  3.01it/s][2025-01-30 02:17:03][root][INFO] - Training Epoch: 1/2, step 4579/107898 completed (loss: 0.37881729006767273, acc: 0.9032257795333862)
[2025-01-30 02:17:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4581/107898 [24:53<9:15:22,  3.10it/s][2025-01-30 02:17:03][root][INFO] - Training Epoch: 1/2, step 4580/107898 completed (loss: 0.0008486873703077435, acc: 1.0)
[2025-01-30 02:17:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4582/107898 [24:54<9:49:38,  2.92it/s][2025-01-30 02:17:03][root][INFO] - Training Epoch: 1/2, step 4581/107898 completed (loss: 3.600365400314331, acc: 0.5)
[2025-01-30 02:17:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4583/107898 [24:54<9:42:28,  2.96it/s][2025-01-30 02:17:04][root][INFO] - Training Epoch: 1/2, step 4582/107898 completed (loss: 0.04665224626660347, acc: 1.0)
[2025-01-30 02:17:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4584/107898 [24:54<9:53:21,  2.90it/s][2025-01-30 02:17:04][root][INFO] - Training Epoch: 1/2, step 4583/107898 completed (loss: 0.0007142812246456742, acc: 1.0)
[2025-01-30 02:17:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4585/107898 [24:55<9:37:16,  2.98it/s][2025-01-30 02:17:04][root][INFO] - Training Epoch: 1/2, step 4584/107898 completed (loss: 4.336890697479248, acc: 0.25)
[2025-01-30 02:17:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4586/107898 [24:55<9:35:09,  2.99it/s][2025-01-30 02:17:05][root][INFO] - Training Epoch: 1/2, step 4585/107898 completed (loss: 0.7163038849830627, acc: 0.8421052694320679)
[2025-01-30 02:17:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4587/107898 [24:55<9:13:59,  3.11it/s][2025-01-30 02:17:05][root][INFO] - Training Epoch: 1/2, step 4586/107898 completed (loss: 0.011841481551527977, acc: 1.0)
[2025-01-30 02:17:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4588/107898 [24:56<9:19:48,  3.08it/s][2025-01-30 02:17:05][root][INFO] - Training Epoch: 1/2, step 4587/107898 completed (loss: 4.752457618713379, acc: 0.1111111119389534)
[2025-01-30 02:17:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4589/107898 [24:56<9:10:45,  3.13it/s][2025-01-30 02:17:06][root][INFO] - Training Epoch: 1/2, step 4588/107898 completed (loss: 1.4643911123275757, acc: 0.7857142686843872)
[2025-01-30 02:17:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4590/107898 [24:56<8:58:53,  3.20it/s][2025-01-30 02:17:06][root][INFO] - Training Epoch: 1/2, step 4589/107898 completed (loss: 2.3832895755767822, acc: 0.5454545617103577)
[2025-01-30 02:17:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4591/107898 [24:56<9:08:31,  3.14it/s][2025-01-30 02:17:06][root][INFO] - Training Epoch: 1/2, step 4590/107898 completed (loss: 0.03388608619570732, acc: 1.0)
[2025-01-30 02:17:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4592/107898 [24:57<9:25:08,  3.05it/s][2025-01-30 02:17:07][root][INFO] - Training Epoch: 1/2, step 4591/107898 completed (loss: 3.526803731918335, acc: 0.375)
[2025-01-30 02:17:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4593/107898 [24:57<9:41:35,  2.96it/s][2025-01-30 02:17:07][root][INFO] - Training Epoch: 1/2, step 4592/107898 completed (loss: 0.2446911484003067, acc: 0.9047619104385376)
[2025-01-30 02:17:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4594/107898 [24:58<9:37:47,  2.98it/s][2025-01-30 02:17:07][root][INFO] - Training Epoch: 1/2, step 4593/107898 completed (loss: 2.3335840702056885, acc: 0.5)
[2025-01-30 02:17:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4595/107898 [24:58<9:30:20,  3.02it/s][2025-01-30 02:17:08][root][INFO] - Training Epoch: 1/2, step 4594/107898 completed (loss: 0.5474512577056885, acc: 0.9411764740943909)
[2025-01-30 02:17:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4596/107898 [24:58<9:18:48,  3.08it/s][2025-01-30 02:17:08][root][INFO] - Training Epoch: 1/2, step 4595/107898 completed (loss: 3.43115234375, acc: 0.5)
[2025-01-30 02:17:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4597/107898 [24:58<9:25:49,  3.04it/s][2025-01-30 02:17:08][root][INFO] - Training Epoch: 1/2, step 4596/107898 completed (loss: 4.40766716003418, acc: 0.3333333432674408)
[2025-01-30 02:17:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4598/107898 [24:59<9:34:35,  3.00it/s][2025-01-30 02:17:09][root][INFO] - Training Epoch: 1/2, step 4597/107898 completed (loss: 1.5504807233810425, acc: 0.6774193644523621)
[2025-01-30 02:17:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4599/107898 [24:59<9:38:09,  2.98it/s][2025-01-30 02:17:09][root][INFO] - Training Epoch: 1/2, step 4598/107898 completed (loss: 1.3077000379562378, acc: 0.6499999761581421)
[2025-01-30 02:17:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4600/107898 [25:00<9:39:10,  2.97it/s][2025-01-30 02:17:09][root][INFO] - Training Epoch: 1/2, step 4599/107898 completed (loss: 3.7415771484375, acc: 0.5)
[2025-01-30 02:17:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4601/107898 [25:00<9:34:27,  3.00it/s][2025-01-30 02:17:10][root][INFO] - Training Epoch: 1/2, step 4600/107898 completed (loss: 0.7465150356292725, acc: 0.8333333134651184)
[2025-01-30 02:17:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4602/107898 [25:00<9:39:15,  2.97it/s][2025-01-30 02:17:10][root][INFO] - Training Epoch: 1/2, step 4601/107898 completed (loss: 1.2854528427124023, acc: 0.875)
[2025-01-30 02:17:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4603/107898 [25:01<9:40:45,  2.96it/s][2025-01-30 02:17:10][root][INFO] - Training Epoch: 1/2, step 4602/107898 completed (loss: 1.4930126667022705, acc: 0.6000000238418579)
[2025-01-30 02:17:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4604/107898 [25:01<9:31:41,  3.01it/s][2025-01-30 02:17:11][root][INFO] - Training Epoch: 1/2, step 4603/107898 completed (loss: 0.19707417488098145, acc: 1.0)
[2025-01-30 02:17:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4605/107898 [25:01<9:49:40,  2.92it/s][2025-01-30 02:17:11][root][INFO] - Training Epoch: 1/2, step 4604/107898 completed (loss: 2.513854503631592, acc: 0.4000000059604645)
[2025-01-30 02:17:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4606/107898 [25:02<9:51:01,  2.91it/s][2025-01-30 02:17:11][root][INFO] - Training Epoch: 1/2, step 4605/107898 completed (loss: 0.6455081701278687, acc: 0.875)
[2025-01-30 02:17:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4607/107898 [25:02<9:45:12,  2.94it/s][2025-01-30 02:17:12][root][INFO] - Training Epoch: 1/2, step 4606/107898 completed (loss: 4.478410720825195, acc: 0.2222222238779068)
[2025-01-30 02:17:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4608/107898 [25:02<9:30:01,  3.02it/s][2025-01-30 02:17:12][root][INFO] - Training Epoch: 1/2, step 4607/107898 completed (loss: 0.014737052842974663, acc: 1.0)
[2025-01-30 02:17:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4609/107898 [25:02<9:12:54,  3.11it/s][2025-01-30 02:17:12][root][INFO] - Training Epoch: 1/2, step 4608/107898 completed (loss: 0.42944252490997314, acc: 0.8888888955116272)
[2025-01-30 02:17:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4610/107898 [25:03<9:00:27,  3.19it/s][2025-01-30 02:17:13][root][INFO] - Training Epoch: 1/2, step 4609/107898 completed (loss: 1.0572088956832886, acc: 0.5)
[2025-01-30 02:17:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4611/107898 [25:03<9:22:00,  3.06it/s][2025-01-30 02:17:13][root][INFO] - Training Epoch: 1/2, step 4610/107898 completed (loss: 3.672494411468506, acc: 0.29411765933036804)
[2025-01-30 02:17:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4612/107898 [25:04<9:39:19,  2.97it/s][2025-01-30 02:17:13][root][INFO] - Training Epoch: 1/2, step 4611/107898 completed (loss: 0.2705988883972168, acc: 1.0)
[2025-01-30 02:17:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4613/107898 [25:04<9:57:09,  2.88it/s][2025-01-30 02:17:14][root][INFO] - Training Epoch: 1/2, step 4612/107898 completed (loss: 0.5017570853233337, acc: 0.949999988079071)
[2025-01-30 02:17:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4614/107898 [25:04<10:01:53,  2.86it/s][2025-01-30 02:17:14][root][INFO] - Training Epoch: 1/2, step 4613/107898 completed (loss: 2.17360520362854, acc: 0.5)
[2025-01-30 02:17:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4615/107898 [25:05<9:59:26,  2.87it/s] [2025-01-30 02:17:14][root][INFO] - Training Epoch: 1/2, step 4614/107898 completed (loss: 0.20712026953697205, acc: 1.0)
[2025-01-30 02:17:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4616/107898 [25:05<9:48:25,  2.93it/s][2025-01-30 02:17:15][root][INFO] - Training Epoch: 1/2, step 4615/107898 completed (loss: 0.8460060358047485, acc: 0.7692307829856873)
[2025-01-30 02:17:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4617/107898 [25:05<9:42:39,  2.95it/s][2025-01-30 02:17:15][root][INFO] - Training Epoch: 1/2, step 4616/107898 completed (loss: 0.09312255680561066, acc: 1.0)
[2025-01-30 02:17:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4618/107898 [25:06<9:28:26,  3.03it/s][2025-01-30 02:17:15][root][INFO] - Training Epoch: 1/2, step 4617/107898 completed (loss: 1.7767083644866943, acc: 0.6000000238418579)
[2025-01-30 02:17:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4619/107898 [25:06<9:36:18,  2.99it/s][2025-01-30 02:17:16][root][INFO] - Training Epoch: 1/2, step 4618/107898 completed (loss: 0.9356926679611206, acc: 0.761904776096344)
[2025-01-30 02:17:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4620/107898 [25:06<9:45:16,  2.94it/s][2025-01-30 02:17:16][root][INFO] - Training Epoch: 1/2, step 4619/107898 completed (loss: 0.9621484279632568, acc: 0.782608687877655)
[2025-01-30 02:17:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4621/107898 [25:07<9:27:55,  3.03it/s][2025-01-30 02:17:16][root][INFO] - Training Epoch: 1/2, step 4620/107898 completed (loss: 4.728670597076416, acc: 0.5)
[2025-01-30 02:17:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4622/107898 [25:07<9:33:03,  3.00it/s][2025-01-30 02:17:17][root][INFO] - Training Epoch: 1/2, step 4621/107898 completed (loss: 1.3905715942382812, acc: 0.7777777910232544)
[2025-01-30 02:17:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4623/107898 [25:07<9:24:11,  3.05it/s][2025-01-30 02:17:17][root][INFO] - Training Epoch: 1/2, step 4622/107898 completed (loss: 0.3465801775455475, acc: 0.8999999761581421)
[2025-01-30 02:17:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4624/107898 [25:08<9:06:55,  3.15it/s][2025-01-30 02:17:17][root][INFO] - Training Epoch: 1/2, step 4623/107898 completed (loss: 0.051102377474308014, acc: 1.0)
[2025-01-30 02:17:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4625/107898 [25:08<9:28:02,  3.03it/s][2025-01-30 02:17:18][root][INFO] - Training Epoch: 1/2, step 4624/107898 completed (loss: 0.8138347268104553, acc: 0.8235294222831726)
[2025-01-30 02:17:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4626/107898 [25:08<9:34:14,  3.00it/s][2025-01-30 02:17:18][root][INFO] - Training Epoch: 1/2, step 4625/107898 completed (loss: 0.21890632808208466, acc: 1.0)
[2025-01-30 02:17:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4627/107898 [25:09<9:33:54,  3.00it/s][2025-01-30 02:17:18][root][INFO] - Training Epoch: 1/2, step 4626/107898 completed (loss: 2.422748327255249, acc: 0.5)
[2025-01-30 02:17:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4628/107898 [25:09<9:15:42,  3.10it/s][2025-01-30 02:17:19][root][INFO] - Training Epoch: 1/2, step 4627/107898 completed (loss: 2.0978591442108154, acc: 0.5714285969734192)
[2025-01-30 02:17:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4629/107898 [25:09<8:56:56,  3.21it/s][2025-01-30 02:17:19][root][INFO] - Training Epoch: 1/2, step 4628/107898 completed (loss: 0.1112290546298027, acc: 0.9411764740943909)
[2025-01-30 02:17:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4630/107898 [25:09<9:15:52,  3.10it/s][2025-01-30 02:17:19][root][INFO] - Training Epoch: 1/2, step 4629/107898 completed (loss: 0.7936367988586426, acc: 1.0)
[2025-01-30 02:17:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4631/107898 [25:10<9:24:28,  3.05it/s][2025-01-30 02:17:20][root][INFO] - Training Epoch: 1/2, step 4630/107898 completed (loss: 0.0052694822661578655, acc: 1.0)
[2025-01-30 02:17:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4632/107898 [25:10<9:30:29,  3.02it/s][2025-01-30 02:17:20][root][INFO] - Training Epoch: 1/2, step 4631/107898 completed (loss: 0.8325710296630859, acc: 0.8571428656578064)
[2025-01-30 02:17:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4633/107898 [25:10<9:16:40,  3.09it/s][2025-01-30 02:17:20][root][INFO] - Training Epoch: 1/2, step 4632/107898 completed (loss: 1.3761035203933716, acc: 0.6764705777168274)
[2025-01-30 02:17:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4634/107898 [25:11<9:07:11,  3.15it/s][2025-01-30 02:17:21][root][INFO] - Training Epoch: 1/2, step 4633/107898 completed (loss: 1.287407636642456, acc: 0.6000000238418579)
[2025-01-30 02:17:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4635/107898 [25:11<8:59:50,  3.19it/s][2025-01-30 02:17:21][root][INFO] - Training Epoch: 1/2, step 4634/107898 completed (loss: 1.9856672286987305, acc: 0.5)
[2025-01-30 02:17:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4636/107898 [25:11<9:00:07,  3.19it/s][2025-01-30 02:17:21][root][INFO] - Training Epoch: 1/2, step 4635/107898 completed (loss: 0.2504226863384247, acc: 0.9090909361839294)
[2025-01-30 02:17:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4637/107898 [25:12<8:45:56,  3.27it/s][2025-01-30 02:17:21][root][INFO] - Training Epoch: 1/2, step 4636/107898 completed (loss: 0.0046974532306194305, acc: 1.0)
[2025-01-30 02:17:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4638/107898 [25:12<9:09:22,  3.13it/s][2025-01-30 02:17:22][root][INFO] - Training Epoch: 1/2, step 4637/107898 completed (loss: 1.712554693222046, acc: 0.6666666865348816)
[2025-01-30 02:17:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4639/107898 [25:12<9:12:16,  3.12it/s][2025-01-30 02:17:22][root][INFO] - Training Epoch: 1/2, step 4638/107898 completed (loss: 1.495661973953247, acc: 0.7142857313156128)
[2025-01-30 02:17:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4640/107898 [25:13<9:22:38,  3.06it/s][2025-01-30 02:17:22][root][INFO] - Training Epoch: 1/2, step 4639/107898 completed (loss: 0.07710544019937515, acc: 1.0)
[2025-01-30 02:17:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4641/107898 [25:13<9:23:24,  3.05it/s][2025-01-30 02:17:23][root][INFO] - Training Epoch: 1/2, step 4640/107898 completed (loss: 0.49899694323539734, acc: 0.8571428656578064)
[2025-01-30 02:17:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4642/107898 [25:13<9:15:05,  3.10it/s][2025-01-30 02:17:23][root][INFO] - Training Epoch: 1/2, step 4641/107898 completed (loss: 3.8896992206573486, acc: 0.14814814925193787)
[2025-01-30 02:17:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4643/107898 [25:14<9:07:05,  3.15it/s][2025-01-30 02:17:23][root][INFO] - Training Epoch: 1/2, step 4642/107898 completed (loss: 2.0911824703216553, acc: 0.75)
[2025-01-30 02:17:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4644/107898 [25:14<8:55:27,  3.21it/s][2025-01-30 02:17:24][root][INFO] - Training Epoch: 1/2, step 4643/107898 completed (loss: 2.126864194869995, acc: 0.5)
[2025-01-30 02:17:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4645/107898 [25:14<9:17:43,  3.09it/s][2025-01-30 02:17:24][root][INFO] - Training Epoch: 1/2, step 4644/107898 completed (loss: 0.7336134314537048, acc: 0.7777777910232544)
[2025-01-30 02:17:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4646/107898 [25:15<9:27:14,  3.03it/s][2025-01-30 02:17:24][root][INFO] - Training Epoch: 1/2, step 4645/107898 completed (loss: 0.5707530379295349, acc: 0.8666666746139526)
[2025-01-30 02:17:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4647/107898 [25:15<9:21:14,  3.07it/s][2025-01-30 02:17:25][root][INFO] - Training Epoch: 1/2, step 4646/107898 completed (loss: 2.64020037651062, acc: 0.800000011920929)
[2025-01-30 02:17:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4648/107898 [25:15<9:16:16,  3.09it/s][2025-01-30 02:17:25][root][INFO] - Training Epoch: 1/2, step 4647/107898 completed (loss: 1.8922104835510254, acc: 0.5)
[2025-01-30 02:17:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4649/107898 [25:16<9:27:29,  3.03it/s][2025-01-30 02:17:25][root][INFO] - Training Epoch: 1/2, step 4648/107898 completed (loss: 0.6256193518638611, acc: 0.8235294222831726)
[2025-01-30 02:17:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4650/107898 [25:16<9:36:12,  2.99it/s][2025-01-30 02:17:26][root][INFO] - Training Epoch: 1/2, step 4649/107898 completed (loss: 0.35761553049087524, acc: 1.0)
[2025-01-30 02:17:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4651/107898 [25:16<9:31:49,  3.01it/s][2025-01-30 02:17:26][root][INFO] - Training Epoch: 1/2, step 4650/107898 completed (loss: 0.6150162220001221, acc: 0.8636363744735718)
[2025-01-30 02:17:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4652/107898 [25:17<9:09:25,  3.13it/s][2025-01-30 02:17:26][root][INFO] - Training Epoch: 1/2, step 4651/107898 completed (loss: 0.5984709858894348, acc: 0.6666666865348816)
[2025-01-30 02:17:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4653/107898 [25:17<8:57:48,  3.20it/s][2025-01-30 02:17:27][root][INFO] - Training Epoch: 1/2, step 4652/107898 completed (loss: 2.7590949535369873, acc: 0.3571428656578064)
[2025-01-30 02:17:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4654/107898 [25:17<9:18:30,  3.08it/s][2025-01-30 02:17:27][root][INFO] - Training Epoch: 1/2, step 4653/107898 completed (loss: 1.0223098993301392, acc: 0.7333333492279053)
[2025-01-30 02:17:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4655/107898 [25:18<9:45:58,  2.94it/s][2025-01-30 02:17:27][root][INFO] - Training Epoch: 1/2, step 4654/107898 completed (loss: 0.20566678047180176, acc: 1.0)
[2025-01-30 02:17:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4656/107898 [25:18<9:38:46,  2.97it/s][2025-01-30 02:17:28][root][INFO] - Training Epoch: 1/2, step 4655/107898 completed (loss: 0.7778469920158386, acc: 0.8235294222831726)
[2025-01-30 02:17:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4657/107898 [25:18<9:20:50,  3.07it/s][2025-01-30 02:17:28][root][INFO] - Training Epoch: 1/2, step 4656/107898 completed (loss: 0.03886372596025467, acc: 1.0)
[2025-01-30 02:17:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4658/107898 [25:19<9:27:17,  3.03it/s][2025-01-30 02:17:28][root][INFO] - Training Epoch: 1/2, step 4657/107898 completed (loss: 0.17040705680847168, acc: 1.0)
[2025-01-30 02:17:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4659/107898 [25:19<9:29:55,  3.02it/s][2025-01-30 02:17:29][root][INFO] - Training Epoch: 1/2, step 4658/107898 completed (loss: 0.08401649445295334, acc: 1.0)
[2025-01-30 02:17:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4660/107898 [25:19<9:19:33,  3.07it/s][2025-01-30 02:17:29][root][INFO] - Training Epoch: 1/2, step 4659/107898 completed (loss: 1.8932663202285767, acc: 0.625)
[2025-01-30 02:17:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4661/107898 [25:19<8:47:20,  3.26it/s][2025-01-30 02:17:29][root][INFO] - Training Epoch: 1/2, step 4660/107898 completed (loss: 0.8027361035346985, acc: 0.8666666746139526)
[2025-01-30 02:17:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4662/107898 [25:20<8:44:21,  3.28it/s][2025-01-30 02:17:30][root][INFO] - Training Epoch: 1/2, step 4661/107898 completed (loss: 1.4572973251342773, acc: 0.6842105388641357)
[2025-01-30 02:17:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4663/107898 [25:20<8:32:54,  3.35it/s][2025-01-30 02:17:30][root][INFO] - Training Epoch: 1/2, step 4662/107898 completed (loss: 0.17425625026226044, acc: 1.0)
[2025-01-30 02:17:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4664/107898 [25:20<8:41:01,  3.30it/s][2025-01-30 02:17:30][root][INFO] - Training Epoch: 1/2, step 4663/107898 completed (loss: 2.1575441360473633, acc: 0.6666666865348816)
[2025-01-30 02:17:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4665/107898 [25:21<8:38:15,  3.32it/s][2025-01-30 02:17:30][root][INFO] - Training Epoch: 1/2, step 4664/107898 completed (loss: 1.3661425113677979, acc: 0.7142857313156128)
[2025-01-30 02:17:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4666/107898 [25:21<8:38:07,  3.32it/s][2025-01-30 02:17:31][root][INFO] - Training Epoch: 1/2, step 4665/107898 completed (loss: 2.688131093978882, acc: 0.6000000238418579)
[2025-01-30 02:17:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4667/107898 [25:21<8:33:49,  3.35it/s][2025-01-30 02:17:31][root][INFO] - Training Epoch: 1/2, step 4666/107898 completed (loss: 0.33581486344337463, acc: 1.0)
[2025-01-30 02:17:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4668/107898 [25:22<8:43:57,  3.28it/s][2025-01-30 02:17:31][root][INFO] - Training Epoch: 1/2, step 4667/107898 completed (loss: 0.0018683825619518757, acc: 1.0)
[2025-01-30 02:17:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4669/107898 [25:22<9:05:23,  3.15it/s][2025-01-30 02:17:32][root][INFO] - Training Epoch: 1/2, step 4668/107898 completed (loss: 0.015221236273646355, acc: 1.0)
[2025-01-30 02:17:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4670/107898 [25:22<9:32:42,  3.00it/s][2025-01-30 02:17:32][root][INFO] - Training Epoch: 1/2, step 4669/107898 completed (loss: 0.22365525364875793, acc: 1.0)
[2025-01-30 02:17:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4671/107898 [25:23<9:25:44,  3.04it/s][2025-01-30 02:17:32][root][INFO] - Training Epoch: 1/2, step 4670/107898 completed (loss: 0.4759618043899536, acc: 0.9090909361839294)
[2025-01-30 02:17:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4672/107898 [25:23<9:35:11,  2.99it/s][2025-01-30 02:17:33][root][INFO] - Training Epoch: 1/2, step 4671/107898 completed (loss: 0.8970590233802795, acc: 0.6666666865348816)
[2025-01-30 02:17:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4673/107898 [25:23<9:34:04,  3.00it/s][2025-01-30 02:17:33][root][INFO] - Training Epoch: 1/2, step 4672/107898 completed (loss: 0.012711100280284882, acc: 1.0)
[2025-01-30 02:17:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4674/107898 [25:24<9:19:59,  3.07it/s][2025-01-30 02:17:33][root][INFO] - Training Epoch: 1/2, step 4673/107898 completed (loss: 0.023804910480976105, acc: 1.0)
[2025-01-30 02:17:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4675/107898 [25:24<9:14:39,  3.10it/s][2025-01-30 02:17:34][root][INFO] - Training Epoch: 1/2, step 4674/107898 completed (loss: 0.014147751033306122, acc: 1.0)
[2025-01-30 02:17:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4676/107898 [25:24<9:06:55,  3.15it/s][2025-01-30 02:17:34][root][INFO] - Training Epoch: 1/2, step 4675/107898 completed (loss: 0.689723014831543, acc: 0.8823529481887817)
[2025-01-30 02:17:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4677/107898 [25:24<8:42:36,  3.29it/s][2025-01-30 02:17:34][root][INFO] - Training Epoch: 1/2, step 4676/107898 completed (loss: 1.6270012855529785, acc: 0.8181818127632141)
[2025-01-30 02:17:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4678/107898 [25:25<8:57:47,  3.20it/s][2025-01-30 02:17:35][root][INFO] - Training Epoch: 1/2, step 4677/107898 completed (loss: 1.0022600889205933, acc: 0.6000000238418579)
[2025-01-30 02:17:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4679/107898 [25:25<9:03:44,  3.16it/s][2025-01-30 02:17:35][root][INFO] - Training Epoch: 1/2, step 4678/107898 completed (loss: 2.1895971298217773, acc: 0.625)
[2025-01-30 02:17:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4680/107898 [25:25<9:07:21,  3.14it/s][2025-01-30 02:17:35][root][INFO] - Training Epoch: 1/2, step 4679/107898 completed (loss: 2.44826340675354, acc: 0.6666666865348816)
[2025-01-30 02:17:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4681/107898 [25:26<9:11:53,  3.12it/s][2025-01-30 02:17:36][root][INFO] - Training Epoch: 1/2, step 4680/107898 completed (loss: 0.7452877759933472, acc: 0.8333333134651184)
[2025-01-30 02:17:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4682/107898 [25:26<8:29:37,  3.38it/s][2025-01-30 02:17:36][root][INFO] - Training Epoch: 1/2, step 4681/107898 completed (loss: 3.0568699836730957, acc: 0.5)
[2025-01-30 02:17:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4683/107898 [25:26<8:48:58,  3.25it/s][2025-01-30 02:17:36][root][INFO] - Training Epoch: 1/2, step 4682/107898 completed (loss: 1.0473161935806274, acc: 0.875)
[2025-01-30 02:17:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4684/107898 [25:27<8:49:55,  3.25it/s][2025-01-30 02:17:36][root][INFO] - Training Epoch: 1/2, step 4683/107898 completed (loss: 1.0419546365737915, acc: 0.8333333134651184)
[2025-01-30 02:17:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4685/107898 [25:27<8:48:12,  3.26it/s][2025-01-30 02:17:37][root][INFO] - Training Epoch: 1/2, step 4684/107898 completed (loss: 0.8361449837684631, acc: 0.7727272510528564)
[2025-01-30 02:17:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4686/107898 [25:27<9:00:01,  3.19it/s][2025-01-30 02:17:37][root][INFO] - Training Epoch: 1/2, step 4685/107898 completed (loss: 0.7355884313583374, acc: 0.8999999761581421)
[2025-01-30 02:17:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4687/107898 [25:28<9:27:17,  3.03it/s][2025-01-30 02:17:37][root][INFO] - Training Epoch: 1/2, step 4686/107898 completed (loss: 0.4842384457588196, acc: 0.9117646813392639)
[2025-01-30 02:17:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4688/107898 [25:28<9:17:18,  3.09it/s][2025-01-30 02:17:38][root][INFO] - Training Epoch: 1/2, step 4687/107898 completed (loss: 0.6471196413040161, acc: 0.8846153616905212)
[2025-01-30 02:17:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4689/107898 [25:28<9:36:22,  2.98it/s][2025-01-30 02:17:38][root][INFO] - Training Epoch: 1/2, step 4688/107898 completed (loss: 0.5937064290046692, acc: 1.0)
[2025-01-30 02:17:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4690/107898 [25:29<9:39:49,  2.97it/s][2025-01-30 02:17:38][root][INFO] - Training Epoch: 1/2, step 4689/107898 completed (loss: 1.731013536453247, acc: 0.6499999761581421)
[2025-01-30 02:17:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4691/107898 [25:29<9:25:23,  3.04it/s][2025-01-30 02:17:39][root][INFO] - Training Epoch: 1/2, step 4690/107898 completed (loss: 0.11405326426029205, acc: 1.0)
[2025-01-30 02:17:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4692/107898 [25:29<9:18:07,  3.08it/s][2025-01-30 02:17:39][root][INFO] - Training Epoch: 1/2, step 4691/107898 completed (loss: 2.7940073013305664, acc: 0.2222222238779068)
[2025-01-30 02:17:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4693/107898 [25:30<9:38:00,  2.98it/s][2025-01-30 02:17:39][root][INFO] - Training Epoch: 1/2, step 4692/107898 completed (loss: 0.8303773999214172, acc: 0.8500000238418579)
[2025-01-30 02:17:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4694/107898 [25:30<9:50:48,  2.91it/s][2025-01-30 02:17:40][root][INFO] - Training Epoch: 1/2, step 4693/107898 completed (loss: 1.1482069492340088, acc: 0.75)
[2025-01-30 02:17:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4695/107898 [25:30<9:47:31,  2.93it/s][2025-01-30 02:17:40][root][INFO] - Training Epoch: 1/2, step 4694/107898 completed (loss: 0.745172381401062, acc: 0.8928571343421936)
[2025-01-30 02:17:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4696/107898 [25:31<9:54:50,  2.89it/s][2025-01-30 02:17:41][root][INFO] - Training Epoch: 1/2, step 4695/107898 completed (loss: 1.6593900918960571, acc: 0.7272727489471436)
[2025-01-30 02:17:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4697/107898 [25:31<9:30:48,  3.01it/s][2025-01-30 02:17:41][root][INFO] - Training Epoch: 1/2, step 4696/107898 completed (loss: 0.09571369737386703, acc: 1.0)
[2025-01-30 02:17:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4698/107898 [25:31<8:58:28,  3.19it/s][2025-01-30 02:17:41][root][INFO] - Training Epoch: 1/2, step 4697/107898 completed (loss: 0.7081477642059326, acc: 0.875)
[2025-01-30 02:17:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4699/107898 [25:32<8:54:54,  3.22it/s][2025-01-30 02:17:41][root][INFO] - Training Epoch: 1/2, step 4698/107898 completed (loss: 1.0903160572052002, acc: 0.7692307829856873)
[2025-01-30 02:17:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4700/107898 [25:32<8:54:55,  3.22it/s][2025-01-30 02:17:42][root][INFO] - Training Epoch: 1/2, step 4699/107898 completed (loss: 3.692070960998535, acc: 0.3333333432674408)
[2025-01-30 02:17:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4701/107898 [25:32<9:09:16,  3.13it/s][2025-01-30 02:17:42][root][INFO] - Training Epoch: 1/2, step 4700/107898 completed (loss: 4.143791675567627, acc: 0.4444444477558136)
[2025-01-30 02:17:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4702/107898 [25:33<8:44:31,  3.28it/s][2025-01-30 02:17:42][root][INFO] - Training Epoch: 1/2, step 4701/107898 completed (loss: 1.3178094625473022, acc: 0.6000000238418579)
[2025-01-30 02:17:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4703/107898 [25:33<9:11:09,  3.12it/s][2025-01-30 02:17:43][root][INFO] - Training Epoch: 1/2, step 4702/107898 completed (loss: 0.2581629455089569, acc: 1.0)
[2025-01-30 02:17:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4704/107898 [25:33<9:17:16,  3.09it/s][2025-01-30 02:17:43][root][INFO] - Training Epoch: 1/2, step 4703/107898 completed (loss: 0.8628089427947998, acc: 0.8888888955116272)
[2025-01-30 02:17:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4705/107898 [25:34<9:25:17,  3.04it/s][2025-01-30 02:17:43][root][INFO] - Training Epoch: 1/2, step 4704/107898 completed (loss: 0.11364785581827164, acc: 1.0)
[2025-01-30 02:17:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4706/107898 [25:34<9:44:33,  2.94it/s][2025-01-30 02:17:44][root][INFO] - Training Epoch: 1/2, step 4705/107898 completed (loss: 0.7711791396141052, acc: 0.8823529481887817)
[2025-01-30 02:17:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4707/107898 [25:34<9:39:53,  2.97it/s][2025-01-30 02:17:44][root][INFO] - Training Epoch: 1/2, step 4706/107898 completed (loss: 2.027299165725708, acc: 0.4285714328289032)
[2025-01-30 02:17:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4708/107898 [25:35<9:30:18,  3.02it/s][2025-01-30 02:17:44][root][INFO] - Training Epoch: 1/2, step 4707/107898 completed (loss: 0.08009140193462372, acc: 1.0)
[2025-01-30 02:17:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4709/107898 [25:35<9:14:49,  3.10it/s][2025-01-30 02:17:45][root][INFO] - Training Epoch: 1/2, step 4708/107898 completed (loss: 1.1641684770584106, acc: 0.8181818127632141)
[2025-01-30 02:17:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4710/107898 [25:35<9:23:37,  3.05it/s][2025-01-30 02:17:45][root][INFO] - Training Epoch: 1/2, step 4709/107898 completed (loss: 0.006961799692362547, acc: 1.0)
[2025-01-30 02:17:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4711/107898 [25:36<9:11:53,  3.12it/s][2025-01-30 02:17:45][root][INFO] - Training Epoch: 1/2, step 4710/107898 completed (loss: 1.6426143646240234, acc: 0.5)
[2025-01-30 02:17:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4712/107898 [25:36<9:05:28,  3.15it/s][2025-01-30 02:17:46][root][INFO] - Training Epoch: 1/2, step 4711/107898 completed (loss: 0.26918211579322815, acc: 0.9166666865348816)
[2025-01-30 02:17:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4713/107898 [25:36<9:25:22,  3.04it/s][2025-01-30 02:17:46][root][INFO] - Training Epoch: 1/2, step 4712/107898 completed (loss: 1.7392301559448242, acc: 0.6315789222717285)
[2025-01-30 02:17:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4714/107898 [25:36<9:17:26,  3.09it/s][2025-01-30 02:17:46][root][INFO] - Training Epoch: 1/2, step 4713/107898 completed (loss: 0.5284664630889893, acc: 0.875)
[2025-01-30 02:17:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4715/107898 [25:37<9:13:35,  3.11it/s][2025-01-30 02:17:47][root][INFO] - Training Epoch: 1/2, step 4714/107898 completed (loss: 0.3117903470993042, acc: 1.0)
[2025-01-30 02:17:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4716/107898 [25:37<9:32:41,  3.00it/s][2025-01-30 02:17:47][root][INFO] - Training Epoch: 1/2, step 4715/107898 completed (loss: 0.3013172447681427, acc: 0.9375)
[2025-01-30 02:17:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4717/107898 [25:37<9:20:32,  3.07it/s][2025-01-30 02:17:47][root][INFO] - Training Epoch: 1/2, step 4716/107898 completed (loss: 1.5068349838256836, acc: 0.7419354915618896)
[2025-01-30 02:17:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4718/107898 [25:38<9:38:23,  2.97it/s][2025-01-30 02:17:48][root][INFO] - Training Epoch: 1/2, step 4717/107898 completed (loss: 3.3425827026367188, acc: 0.42307692766189575)
[2025-01-30 02:17:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4719/107898 [25:38<9:40:22,  2.96it/s][2025-01-30 02:17:48][root][INFO] - Training Epoch: 1/2, step 4718/107898 completed (loss: 0.634056806564331, acc: 0.7916666865348816)
[2025-01-30 02:17:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4720/107898 [25:39<10:00:48,  2.86it/s][2025-01-30 02:17:48][root][INFO] - Training Epoch: 1/2, step 4719/107898 completed (loss: 1.2819446325302124, acc: 0.6764705777168274)
[2025-01-30 02:17:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4721/107898 [25:39<9:47:47,  2.93it/s] [2025-01-30 02:17:49][root][INFO] - Training Epoch: 1/2, step 4720/107898 completed (loss: 2.8485302925109863, acc: 0.46666666865348816)
[2025-01-30 02:17:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4722/107898 [25:39<9:25:05,  3.04it/s][2025-01-30 02:17:49][root][INFO] - Training Epoch: 1/2, step 4721/107898 completed (loss: 0.003517571371048689, acc: 1.0)
[2025-01-30 02:17:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4723/107898 [25:39<9:11:55,  3.12it/s][2025-01-30 02:17:49][root][INFO] - Training Epoch: 1/2, step 4722/107898 completed (loss: 0.35516658425331116, acc: 1.0)
[2025-01-30 02:17:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4724/107898 [25:40<9:26:41,  3.03it/s][2025-01-30 02:17:50][root][INFO] - Training Epoch: 1/2, step 4723/107898 completed (loss: 0.6942829489707947, acc: 0.8125)
[2025-01-30 02:17:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4725/107898 [25:40<9:32:01,  3.01it/s][2025-01-30 02:17:50][root][INFO] - Training Epoch: 1/2, step 4724/107898 completed (loss: 0.3522469103336334, acc: 1.0)
[2025-01-30 02:17:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4726/107898 [25:41<9:39:22,  2.97it/s][2025-01-30 02:17:50][root][INFO] - Training Epoch: 1/2, step 4725/107898 completed (loss: 1.0080732107162476, acc: 0.800000011920929)
[2025-01-30 02:17:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4727/107898 [25:41<9:34:20,  2.99it/s][2025-01-30 02:17:51][root][INFO] - Training Epoch: 1/2, step 4726/107898 completed (loss: 1.8321926593780518, acc: 0.800000011920929)
[2025-01-30 02:17:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4728/107898 [25:41<9:19:59,  3.07it/s][2025-01-30 02:17:51][root][INFO] - Training Epoch: 1/2, step 4727/107898 completed (loss: 1.7366712093353271, acc: 0.5555555820465088)
[2025-01-30 02:17:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4729/107898 [25:41<9:24:32,  3.05it/s][2025-01-30 02:17:51][root][INFO] - Training Epoch: 1/2, step 4728/107898 completed (loss: 0.03716369718313217, acc: 1.0)
[2025-01-30 02:17:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4730/107898 [25:42<9:07:36,  3.14it/s][2025-01-30 02:17:52][root][INFO] - Training Epoch: 1/2, step 4729/107898 completed (loss: 0.07109054177999496, acc: 1.0)
[2025-01-30 02:17:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4731/107898 [25:42<9:13:29,  3.11it/s][2025-01-30 02:17:52][root][INFO] - Training Epoch: 1/2, step 4730/107898 completed (loss: 0.2617233991622925, acc: 0.8888888955116272)
[2025-01-30 02:17:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4732/107898 [25:42<8:57:39,  3.20it/s][2025-01-30 02:17:52][root][INFO] - Training Epoch: 1/2, step 4731/107898 completed (loss: 1.5181705951690674, acc: 0.7857142686843872)
[2025-01-30 02:17:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4733/107898 [25:43<9:06:16,  3.15it/s][2025-01-30 02:17:53][root][INFO] - Training Epoch: 1/2, step 4732/107898 completed (loss: 0.8031221628189087, acc: 0.807692289352417)
[2025-01-30 02:17:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4734/107898 [25:43<9:24:31,  3.05it/s][2025-01-30 02:17:53][root][INFO] - Training Epoch: 1/2, step 4733/107898 completed (loss: 1.3464429378509521, acc: 0.6785714030265808)
[2025-01-30 02:17:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4735/107898 [25:43<9:39:41,  2.97it/s][2025-01-30 02:17:53][root][INFO] - Training Epoch: 1/2, step 4734/107898 completed (loss: 4.519158363342285, acc: 0.4285714328289032)
[2025-01-30 02:17:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4736/107898 [25:44<9:37:43,  2.98it/s][2025-01-30 02:17:54][root][INFO] - Training Epoch: 1/2, step 4735/107898 completed (loss: 1.277825117111206, acc: 0.6666666865348816)
[2025-01-30 02:17:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4737/107898 [25:44<9:42:40,  2.95it/s][2025-01-30 02:17:54][root][INFO] - Training Epoch: 1/2, step 4736/107898 completed (loss: 2.698845386505127, acc: 0.5384615659713745)
[2025-01-30 02:17:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4738/107898 [25:44<9:26:53,  3.03it/s][2025-01-30 02:17:54][root][INFO] - Training Epoch: 1/2, step 4737/107898 completed (loss: 1.7540839910507202, acc: 0.7272727489471436)
[2025-01-30 02:17:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4739/107898 [25:45<9:16:45,  3.09it/s][2025-01-30 02:17:55][root][INFO] - Training Epoch: 1/2, step 4738/107898 completed (loss: 0.8427821397781372, acc: 0.800000011920929)
[2025-01-30 02:17:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4740/107898 [25:45<9:23:28,  3.05it/s][2025-01-30 02:17:55][root][INFO] - Training Epoch: 1/2, step 4739/107898 completed (loss: 4.275620937347412, acc: 0.23529411852359772)
[2025-01-30 02:17:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4741/107898 [25:45<9:07:00,  3.14it/s][2025-01-30 02:17:55][root][INFO] - Training Epoch: 1/2, step 4740/107898 completed (loss: 0.9163015484809875, acc: 0.6000000238418579)
[2025-01-30 02:17:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4742/107898 [25:46<8:59:41,  3.19it/s][2025-01-30 02:17:55][root][INFO] - Training Epoch: 1/2, step 4741/107898 completed (loss: 0.15079565346240997, acc: 1.0)
[2025-01-30 02:17:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4743/107898 [25:46<9:38:21,  2.97it/s][2025-01-30 02:17:56][root][INFO] - Training Epoch: 1/2, step 4742/107898 completed (loss: 0.003208031179383397, acc: 1.0)
[2025-01-30 02:17:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4744/107898 [25:46<9:36:20,  2.98it/s][2025-01-30 02:17:56][root][INFO] - Training Epoch: 1/2, step 4743/107898 completed (loss: 0.19072158634662628, acc: 1.0)
[2025-01-30 02:17:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4745/107898 [25:47<9:40:10,  2.96it/s][2025-01-30 02:17:57][root][INFO] - Training Epoch: 1/2, step 4744/107898 completed (loss: 0.6062921285629272, acc: 0.875)
[2025-01-30 02:17:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4746/107898 [25:47<9:38:04,  2.97it/s][2025-01-30 02:17:57][root][INFO] - Training Epoch: 1/2, step 4745/107898 completed (loss: 1.3491671085357666, acc: 0.8461538553237915)
[2025-01-30 02:17:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4747/107898 [25:47<9:26:38,  3.03it/s][2025-01-30 02:17:57][root][INFO] - Training Epoch: 1/2, step 4746/107898 completed (loss: 1.0540069341659546, acc: 0.7142857313156128)
[2025-01-30 02:17:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4748/107898 [25:48<9:34:57,  2.99it/s][2025-01-30 02:17:58][root][INFO] - Training Epoch: 1/2, step 4747/107898 completed (loss: 1.2594579458236694, acc: 0.625)
[2025-01-30 02:17:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4749/107898 [25:48<9:41:46,  2.96it/s][2025-01-30 02:17:58][root][INFO] - Training Epoch: 1/2, step 4748/107898 completed (loss: 0.5606819987297058, acc: 0.75)
[2025-01-30 02:17:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4750/107898 [25:48<9:37:52,  2.97it/s][2025-01-30 02:17:58][root][INFO] - Training Epoch: 1/2, step 4749/107898 completed (loss: 3.7234864234924316, acc: 0.3181818127632141)
[2025-01-30 02:17:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4751/107898 [25:49<9:55:57,  2.88it/s][2025-01-30 02:17:59][root][INFO] - Training Epoch: 1/2, step 4750/107898 completed (loss: 1.1307584047317505, acc: 0.875)
[2025-01-30 02:17:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4752/107898 [25:49<9:30:16,  3.01it/s][2025-01-30 02:17:59][root][INFO] - Training Epoch: 1/2, step 4751/107898 completed (loss: 2.349283218383789, acc: 0.7142857313156128)
[2025-01-30 02:17:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4753/107898 [25:49<9:20:46,  3.07it/s][2025-01-30 02:17:59][root][INFO] - Training Epoch: 1/2, step 4752/107898 completed (loss: 1.3627469539642334, acc: 0.7142857313156128)
[2025-01-30 02:17:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4754/107898 [25:50<9:09:38,  3.13it/s][2025-01-30 02:17:59][root][INFO] - Training Epoch: 1/2, step 4753/107898 completed (loss: 2.0438525676727295, acc: 0.6000000238418579)
[2025-01-30 02:18:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4755/107898 [25:50<8:54:49,  3.21it/s][2025-01-30 02:18:00][root][INFO] - Training Epoch: 1/2, step 4754/107898 completed (loss: 0.0017568024341017008, acc: 1.0)
[2025-01-30 02:18:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4756/107898 [25:50<8:53:35,  3.22it/s][2025-01-30 02:18:00][root][INFO] - Training Epoch: 1/2, step 4755/107898 completed (loss: 1.406678318977356, acc: 0.6363636255264282)
[2025-01-30 02:18:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4757/107898 [25:51<9:15:56,  3.09it/s][2025-01-30 02:18:00][root][INFO] - Training Epoch: 1/2, step 4756/107898 completed (loss: 0.4116896986961365, acc: 0.8571428656578064)
[2025-01-30 02:18:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4758/107898 [25:51<9:39:06,  2.97it/s][2025-01-30 02:18:01][root][INFO] - Training Epoch: 1/2, step 4757/107898 completed (loss: 1.5267395973205566, acc: 0.3333333432674408)
[2025-01-30 02:18:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4759/107898 [25:51<9:33:15,  3.00it/s][2025-01-30 02:18:01][root][INFO] - Training Epoch: 1/2, step 4758/107898 completed (loss: 0.004500142298638821, acc: 1.0)
[2025-01-30 02:18:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4760/107898 [25:52<9:44:15,  2.94it/s][2025-01-30 02:18:01][root][INFO] - Training Epoch: 1/2, step 4759/107898 completed (loss: 0.7911872267723083, acc: 0.8333333134651184)
[2025-01-30 02:18:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4761/107898 [25:52<9:08:41,  3.13it/s][2025-01-30 02:18:02][root][INFO] - Training Epoch: 1/2, step 4760/107898 completed (loss: 0.2644592225551605, acc: 1.0)
[2025-01-30 02:18:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4762/107898 [25:52<9:04:07,  3.16it/s][2025-01-30 02:18:02][root][INFO] - Training Epoch: 1/2, step 4761/107898 completed (loss: 0.30022355914115906, acc: 1.0)
[2025-01-30 02:18:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4763/107898 [25:53<9:03:04,  3.17it/s][2025-01-30 02:18:02][root][INFO] - Training Epoch: 1/2, step 4762/107898 completed (loss: 0.12055698037147522, acc: 0.9655172228813171)
[2025-01-30 02:18:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4764/107898 [25:53<8:59:08,  3.19it/s][2025-01-30 02:18:03][root][INFO] - Training Epoch: 1/2, step 4763/107898 completed (loss: 0.44083237648010254, acc: 0.8684210777282715)
[2025-01-30 02:18:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4765/107898 [25:53<9:19:35,  3.07it/s][2025-01-30 02:18:03][root][INFO] - Training Epoch: 1/2, step 4764/107898 completed (loss: 2.1295089721679688, acc: 0.5714285969734192)
[2025-01-30 02:18:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4766/107898 [25:54<9:22:59,  3.05it/s][2025-01-30 02:18:03][root][INFO] - Training Epoch: 1/2, step 4765/107898 completed (loss: 0.14738692343235016, acc: 1.0)
[2025-01-30 02:18:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4767/107898 [25:54<9:32:35,  3.00it/s][2025-01-30 02:18:04][root][INFO] - Training Epoch: 1/2, step 4766/107898 completed (loss: 2.7523586750030518, acc: 0.5833333134651184)
[2025-01-30 02:18:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4768/107898 [25:54<9:41:24,  2.96it/s][2025-01-30 02:18:04][root][INFO] - Training Epoch: 1/2, step 4767/107898 completed (loss: 3.287562131881714, acc: 0.5555555820465088)
[2025-01-30 02:18:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4769/107898 [25:55<9:29:20,  3.02it/s][2025-01-30 02:18:04][root][INFO] - Training Epoch: 1/2, step 4768/107898 completed (loss: 0.11272810399532318, acc: 1.0)
[2025-01-30 02:18:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4770/107898 [25:55<9:45:16,  2.94it/s][2025-01-30 02:18:05][root][INFO] - Training Epoch: 1/2, step 4769/107898 completed (loss: 1.6093311309814453, acc: 0.8235294222831726)
[2025-01-30 02:18:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4771/107898 [25:55<9:21:51,  3.06it/s][2025-01-30 02:18:05][root][INFO] - Training Epoch: 1/2, step 4770/107898 completed (loss: 0.0032599165569990873, acc: 1.0)
[2025-01-30 02:18:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4772/107898 [25:56<9:02:19,  3.17it/s][2025-01-30 02:18:05][root][INFO] - Training Epoch: 1/2, step 4771/107898 completed (loss: 0.913167417049408, acc: 0.8636363744735718)
[2025-01-30 02:18:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4773/107898 [25:56<8:47:51,  3.26it/s][2025-01-30 02:18:06][root][INFO] - Training Epoch: 1/2, step 4772/107898 completed (loss: 1.6733654737472534, acc: 0.7272727489471436)
[2025-01-30 02:18:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4774/107898 [25:56<8:52:50,  3.23it/s][2025-01-30 02:18:06][root][INFO] - Training Epoch: 1/2, step 4773/107898 completed (loss: 0.4283987879753113, acc: 0.8947368264198303)
[2025-01-30 02:18:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4775/107898 [25:56<8:50:18,  3.24it/s][2025-01-30 02:18:06][root][INFO] - Training Epoch: 1/2, step 4774/107898 completed (loss: 0.0009066717466339469, acc: 1.0)
[2025-01-30 02:18:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4776/107898 [25:57<9:09:06,  3.13it/s][2025-01-30 02:18:07][root][INFO] - Training Epoch: 1/2, step 4775/107898 completed (loss: 1.0047664642333984, acc: 0.6666666865348816)
[2025-01-30 02:18:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4777/107898 [25:57<9:03:16,  3.16it/s][2025-01-30 02:18:07][root][INFO] - Training Epoch: 1/2, step 4776/107898 completed (loss: 0.2448359578847885, acc: 1.0)
[2025-01-30 02:18:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4778/107898 [25:57<8:53:09,  3.22it/s][2025-01-30 02:18:07][root][INFO] - Training Epoch: 1/2, step 4777/107898 completed (loss: 0.2128467559814453, acc: 0.875)
[2025-01-30 02:18:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4779/107898 [25:58<9:13:53,  3.10it/s][2025-01-30 02:18:08][root][INFO] - Training Epoch: 1/2, step 4778/107898 completed (loss: 3.9424569606781006, acc: 0.3181818127632141)
[2025-01-30 02:18:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4780/107898 [25:58<9:11:05,  3.12it/s][2025-01-30 02:18:08][root][INFO] - Training Epoch: 1/2, step 4779/107898 completed (loss: 0.5605729818344116, acc: 0.875)
[2025-01-30 02:18:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4781/107898 [25:58<8:42:18,  3.29it/s][2025-01-30 02:18:08][root][INFO] - Training Epoch: 1/2, step 4780/107898 completed (loss: 0.052607178688049316, acc: 1.0)
[2025-01-30 02:18:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4782/107898 [25:59<8:58:39,  3.19it/s][2025-01-30 02:18:08][root][INFO] - Training Epoch: 1/2, step 4781/107898 completed (loss: 0.0009506554924882948, acc: 1.0)
[2025-01-30 02:18:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4783/107898 [25:59<9:02:31,  3.17it/s][2025-01-30 02:18:09][root][INFO] - Training Epoch: 1/2, step 4782/107898 completed (loss: 1.0074849128723145, acc: 0.75)
[2025-01-30 02:18:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4784/107898 [25:59<9:10:28,  3.12it/s][2025-01-30 02:18:09][root][INFO] - Training Epoch: 1/2, step 4783/107898 completed (loss: 1.54879891872406, acc: 0.6842105388641357)
[2025-01-30 02:18:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4785/107898 [26:00<9:12:55,  3.11it/s][2025-01-30 02:18:09][root][INFO] - Training Epoch: 1/2, step 4784/107898 completed (loss: 0.7533171772956848, acc: 0.875)
[2025-01-30 02:18:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4786/107898 [26:00<9:02:51,  3.17it/s][2025-01-30 02:18:10][root][INFO] - Training Epoch: 1/2, step 4785/107898 completed (loss: 1.0105751752853394, acc: 0.7857142686843872)
[2025-01-30 02:18:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4787/107898 [26:00<9:19:50,  3.07it/s][2025-01-30 02:18:10][root][INFO] - Training Epoch: 1/2, step 4786/107898 completed (loss: 0.003615104127675295, acc: 1.0)
[2025-01-30 02:18:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4788/107898 [26:01<9:24:50,  3.04it/s][2025-01-30 02:18:10][root][INFO] - Training Epoch: 1/2, step 4787/107898 completed (loss: 0.037296805530786514, acc: 1.0)
[2025-01-30 02:18:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4789/107898 [26:01<9:21:52,  3.06it/s][2025-01-30 02:18:11][root][INFO] - Training Epoch: 1/2, step 4788/107898 completed (loss: 1.6609455347061157, acc: 0.7368420958518982)
[2025-01-30 02:18:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4790/107898 [26:01<9:16:04,  3.09it/s][2025-01-30 02:18:11][root][INFO] - Training Epoch: 1/2, step 4789/107898 completed (loss: 0.9979557991027832, acc: 0.8225806355476379)
[2025-01-30 02:18:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4791/107898 [26:02<9:31:20,  3.01it/s][2025-01-30 02:18:11][root][INFO] - Training Epoch: 1/2, step 4790/107898 completed (loss: 0.45999792218208313, acc: 0.8888888955116272)
[2025-01-30 02:18:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4792/107898 [26:02<9:18:22,  3.08it/s][2025-01-30 02:18:12][root][INFO] - Training Epoch: 1/2, step 4791/107898 completed (loss: 0.9976376891136169, acc: 0.8333333134651184)
[2025-01-30 02:18:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4793/107898 [26:02<9:43:03,  2.95it/s][2025-01-30 02:18:12][root][INFO] - Training Epoch: 1/2, step 4792/107898 completed (loss: 0.00156054284889251, acc: 1.0)
[2025-01-30 02:18:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4794/107898 [26:03<9:48:34,  2.92it/s][2025-01-30 02:18:12][root][INFO] - Training Epoch: 1/2, step 4793/107898 completed (loss: 1.111344575881958, acc: 0.7916666865348816)
[2025-01-30 02:18:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4795/107898 [26:03<9:35:21,  2.99it/s][2025-01-30 02:18:13][root][INFO] - Training Epoch: 1/2, step 4794/107898 completed (loss: 0.08594746887683868, acc: 1.0)
[2025-01-30 02:18:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4796/107898 [26:03<9:44:04,  2.94it/s][2025-01-30 02:18:13][root][INFO] - Training Epoch: 1/2, step 4795/107898 completed (loss: 1.0667378902435303, acc: 0.7142857313156128)
[2025-01-30 02:18:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4797/107898 [26:04<9:20:41,  3.06it/s][2025-01-30 02:18:13][root][INFO] - Training Epoch: 1/2, step 4796/107898 completed (loss: 4.193434715270996, acc: 0.20000000298023224)
[2025-01-30 02:18:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4798/107898 [26:04<9:01:10,  3.18it/s][2025-01-30 02:18:14][root][INFO] - Training Epoch: 1/2, step 4797/107898 completed (loss: 0.8167406320571899, acc: 0.8571428656578064)
[2025-01-30 02:18:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4799/107898 [26:04<8:50:28,  3.24it/s][2025-01-30 02:18:14][root][INFO] - Training Epoch: 1/2, step 4798/107898 completed (loss: 3.064720392227173, acc: 0.5)
[2025-01-30 02:18:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4800/107898 [26:05<9:31:19,  3.01it/s][2025-01-30 02:18:14][root][INFO] - Training Epoch: 1/2, step 4799/107898 completed (loss: 1.635481834411621, acc: 0.5833333134651184)
[2025-01-30 02:18:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4801/107898 [26:05<9:33:46,  2.99it/s][2025-01-30 02:18:15][root][INFO] - Training Epoch: 1/2, step 4800/107898 completed (loss: 1.1165502071380615, acc: 0.8999999761581421)
[2025-01-30 02:18:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4802/107898 [26:05<9:25:01,  3.04it/s][2025-01-30 02:18:15][root][INFO] - Training Epoch: 1/2, step 4801/107898 completed (loss: 0.08100209385156631, acc: 1.0)
[2025-01-30 02:18:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4803/107898 [26:06<8:57:20,  3.20it/s][2025-01-30 02:18:15][root][INFO] - Training Epoch: 1/2, step 4802/107898 completed (loss: 0.38286957144737244, acc: 1.0)
[2025-01-30 02:18:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4804/107898 [26:06<8:54:52,  3.21it/s][2025-01-30 02:18:16][root][INFO] - Training Epoch: 1/2, step 4803/107898 completed (loss: 0.5903881788253784, acc: 0.8947368264198303)
[2025-01-30 02:18:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4805/107898 [26:06<9:10:52,  3.12it/s][2025-01-30 02:18:16][root][INFO] - Training Epoch: 1/2, step 4804/107898 completed (loss: 1.843415379524231, acc: 0.7142857313156128)
[2025-01-30 02:18:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4806/107898 [26:06<9:06:24,  3.14it/s][2025-01-30 02:18:16][root][INFO] - Training Epoch: 1/2, step 4805/107898 completed (loss: 0.34345191717147827, acc: 0.8823529481887817)
[2025-01-30 02:18:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4807/107898 [26:07<9:07:07,  3.14it/s][2025-01-30 02:18:17][root][INFO] - Training Epoch: 1/2, step 4806/107898 completed (loss: 0.1265743523836136, acc: 0.9523809552192688)
[2025-01-30 02:18:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4808/107898 [26:07<9:03:04,  3.16it/s][2025-01-30 02:18:17][root][INFO] - Training Epoch: 1/2, step 4807/107898 completed (loss: 0.4067159593105316, acc: 0.9090909361839294)
[2025-01-30 02:18:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4809/107898 [26:07<8:52:17,  3.23it/s][2025-01-30 02:18:17][root][INFO] - Training Epoch: 1/2, step 4808/107898 completed (loss: 0.23045647144317627, acc: 0.9473684430122375)
[2025-01-30 02:18:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4810/107898 [26:08<8:53:31,  3.22it/s][2025-01-30 02:18:18][root][INFO] - Training Epoch: 1/2, step 4809/107898 completed (loss: 0.835727870464325, acc: 0.8275862336158752)
[2025-01-30 02:18:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4811/107898 [26:08<9:02:08,  3.17it/s][2025-01-30 02:18:18][root][INFO] - Training Epoch: 1/2, step 4810/107898 completed (loss: 0.2939322888851166, acc: 0.9473684430122375)
[2025-01-30 02:18:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4812/107898 [26:08<8:39:14,  3.31it/s][2025-01-30 02:18:18][root][INFO] - Training Epoch: 1/2, step 4811/107898 completed (loss: 2.8285415172576904, acc: 0.3333333432674408)
[2025-01-30 02:18:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4813/107898 [26:09<8:35:59,  3.33it/s][2025-01-30 02:18:18][root][INFO] - Training Epoch: 1/2, step 4812/107898 completed (loss: 0.0016823887126520276, acc: 1.0)
[2025-01-30 02:18:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4814/107898 [26:09<8:35:15,  3.33it/s][2025-01-30 02:18:19][root][INFO] - Training Epoch: 1/2, step 4813/107898 completed (loss: 0.6330474615097046, acc: 0.7777777910232544)
[2025-01-30 02:18:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4815/107898 [26:09<8:55:17,  3.21it/s][2025-01-30 02:18:19][root][INFO] - Training Epoch: 1/2, step 4814/107898 completed (loss: 0.8367053270339966, acc: 0.761904776096344)
[2025-01-30 02:18:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4816/107898 [26:10<8:45:50,  3.27it/s][2025-01-30 02:18:19][root][INFO] - Training Epoch: 1/2, step 4815/107898 completed (loss: 0.04281124845147133, acc: 1.0)
[2025-01-30 02:18:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4817/107898 [26:10<9:04:25,  3.16it/s][2025-01-30 02:18:20][root][INFO] - Training Epoch: 1/2, step 4816/107898 completed (loss: 4.328137397766113, acc: 0.0)
[2025-01-30 02:18:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4818/107898 [26:10<8:56:59,  3.20it/s][2025-01-30 02:18:20][root][INFO] - Training Epoch: 1/2, step 4817/107898 completed (loss: 2.003436803817749, acc: 0.625)
[2025-01-30 02:18:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4819/107898 [26:10<8:51:26,  3.23it/s][2025-01-30 02:18:20][root][INFO] - Training Epoch: 1/2, step 4818/107898 completed (loss: 2.3508505821228027, acc: 0.4615384638309479)
[2025-01-30 02:18:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4820/107898 [26:11<9:08:05,  3.13it/s][2025-01-30 02:18:21][root][INFO] - Training Epoch: 1/2, step 4819/107898 completed (loss: 0.9283626675605774, acc: 0.7666666507720947)
[2025-01-30 02:18:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4821/107898 [26:11<9:05:29,  3.15it/s][2025-01-30 02:18:21][root][INFO] - Training Epoch: 1/2, step 4820/107898 completed (loss: 0.2364664226770401, acc: 1.0)
[2025-01-30 02:18:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4822/107898 [26:12<9:28:03,  3.02it/s][2025-01-30 02:18:21][root][INFO] - Training Epoch: 1/2, step 4821/107898 completed (loss: 1.6703041791915894, acc: 0.6153846383094788)
[2025-01-30 02:18:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4823/107898 [26:12<9:08:18,  3.13it/s][2025-01-30 02:18:22][root][INFO] - Training Epoch: 1/2, step 4822/107898 completed (loss: 0.3268047571182251, acc: 0.8571428656578064)
[2025-01-30 02:18:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4824/107898 [26:12<8:53:58,  3.22it/s][2025-01-30 02:18:22][root][INFO] - Training Epoch: 1/2, step 4823/107898 completed (loss: 0.7233132719993591, acc: 0.6666666865348816)
[2025-01-30 02:18:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4825/107898 [26:12<8:49:38,  3.24it/s][2025-01-30 02:18:22][root][INFO] - Training Epoch: 1/2, step 4824/107898 completed (loss: 0.005458206869661808, acc: 1.0)
[2025-01-30 02:18:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4826/107898 [26:13<9:03:10,  3.16it/s][2025-01-30 02:18:23][root][INFO] - Training Epoch: 1/2, step 4825/107898 completed (loss: 1.5712367296218872, acc: 0.75)
[2025-01-30 02:18:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4827/107898 [26:13<9:04:57,  3.15it/s][2025-01-30 02:18:23][root][INFO] - Training Epoch: 1/2, step 4826/107898 completed (loss: 1.0207120180130005, acc: 0.8235294222831726)
[2025-01-30 02:18:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4828/107898 [26:13<8:59:18,  3.19it/s][2025-01-30 02:18:23][root][INFO] - Training Epoch: 1/2, step 4827/107898 completed (loss: 0.12319345772266388, acc: 1.0)
[2025-01-30 02:18:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4829/107898 [26:14<9:13:47,  3.10it/s][2025-01-30 02:18:23][root][INFO] - Training Epoch: 1/2, step 4828/107898 completed (loss: 0.0023677507415413857, acc: 1.0)
[2025-01-30 02:18:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4830/107898 [26:14<9:21:25,  3.06it/s][2025-01-30 02:18:24][root][INFO] - Training Epoch: 1/2, step 4829/107898 completed (loss: 3.147230863571167, acc: 0.4444444477558136)
[2025-01-30 02:18:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4831/107898 [26:14<9:21:49,  3.06it/s][2025-01-30 02:18:24][root][INFO] - Training Epoch: 1/2, step 4830/107898 completed (loss: 0.0010160397505387664, acc: 1.0)
[2025-01-30 02:18:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4832/107898 [26:15<9:30:30,  3.01it/s][2025-01-30 02:18:25][root][INFO] - Training Epoch: 1/2, step 4831/107898 completed (loss: 0.07997813075780869, acc: 1.0)
[2025-01-30 02:18:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4833/107898 [26:15<9:38:06,  2.97it/s][2025-01-30 02:18:25][root][INFO] - Training Epoch: 1/2, step 4832/107898 completed (loss: 1.0675441026687622, acc: 0.5882353186607361)
[2025-01-30 02:18:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4834/107898 [26:15<9:24:05,  3.05it/s][2025-01-30 02:18:25][root][INFO] - Training Epoch: 1/2, step 4833/107898 completed (loss: 0.10562042891979218, acc: 1.0)
[2025-01-30 02:18:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4835/107898 [26:16<9:03:28,  3.16it/s][2025-01-30 02:18:25][root][INFO] - Training Epoch: 1/2, step 4834/107898 completed (loss: 2.1793086528778076, acc: 0.75)
[2025-01-30 02:18:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4836/107898 [26:16<8:53:09,  3.22it/s][2025-01-30 02:18:26][root][INFO] - Training Epoch: 1/2, step 4835/107898 completed (loss: 0.6486172080039978, acc: 0.7777777910232544)
[2025-01-30 02:18:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4837/107898 [26:16<8:49:04,  3.25it/s][2025-01-30 02:18:26][root][INFO] - Training Epoch: 1/2, step 4836/107898 completed (loss: 0.13745227456092834, acc: 1.0)
[2025-01-30 02:18:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4838/107898 [26:17<8:43:59,  3.28it/s][2025-01-30 02:18:26][root][INFO] - Training Epoch: 1/2, step 4837/107898 completed (loss: 0.2344178408384323, acc: 1.0)
[2025-01-30 02:18:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4839/107898 [26:17<9:08:22,  3.13it/s][2025-01-30 02:18:27][root][INFO] - Training Epoch: 1/2, step 4838/107898 completed (loss: 0.001899468945339322, acc: 1.0)
[2025-01-30 02:18:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4840/107898 [26:17<8:50:43,  3.24it/s][2025-01-30 02:18:27][root][INFO] - Training Epoch: 1/2, step 4839/107898 completed (loss: 0.0013616387732326984, acc: 1.0)
[2025-01-30 02:18:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4841/107898 [26:17<8:45:43,  3.27it/s][2025-01-30 02:18:27][root][INFO] - Training Epoch: 1/2, step 4840/107898 completed (loss: 0.40978917479515076, acc: 0.8571428656578064)
[2025-01-30 02:18:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4842/107898 [26:18<8:48:54,  3.25it/s][2025-01-30 02:18:28][root][INFO] - Training Epoch: 1/2, step 4841/107898 completed (loss: 3.3472280502319336, acc: 0.25)
[2025-01-30 02:18:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4843/107898 [26:18<8:58:45,  3.19it/s][2025-01-30 02:18:28][root][INFO] - Training Epoch: 1/2, step 4842/107898 completed (loss: 0.7237133383750916, acc: 0.9090909361839294)
[2025-01-30 02:18:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4844/107898 [26:18<9:03:51,  3.16it/s][2025-01-30 02:18:28][root][INFO] - Training Epoch: 1/2, step 4843/107898 completed (loss: 1.2292710542678833, acc: 0.761904776096344)
[2025-01-30 02:18:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4845/107898 [26:19<8:58:45,  3.19it/s][2025-01-30 02:18:29][root][INFO] - Training Epoch: 1/2, step 4844/107898 completed (loss: 0.6466185450553894, acc: 0.75)
[2025-01-30 02:18:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4846/107898 [26:19<9:00:54,  3.18it/s][2025-01-30 02:18:29][root][INFO] - Training Epoch: 1/2, step 4845/107898 completed (loss: 0.3730577230453491, acc: 0.9722222089767456)
[2025-01-30 02:18:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4847/107898 [26:19<8:51:28,  3.23it/s][2025-01-30 02:18:29][root][INFO] - Training Epoch: 1/2, step 4846/107898 completed (loss: 0.06203927472233772, acc: 1.0)
[2025-01-30 02:18:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4848/107898 [26:20<8:41:38,  3.29it/s][2025-01-30 02:18:29][root][INFO] - Training Epoch: 1/2, step 4847/107898 completed (loss: 0.6976379156112671, acc: 0.6666666865348816)
[2025-01-30 02:18:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4849/107898 [26:20<8:39:04,  3.31it/s][2025-01-30 02:18:30][root][INFO] - Training Epoch: 1/2, step 4848/107898 completed (loss: 1.7634515762329102, acc: 0.375)
[2025-01-30 02:18:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4850/107898 [26:20<8:34:27,  3.34it/s][2025-01-30 02:18:30][root][INFO] - Training Epoch: 1/2, step 4849/107898 completed (loss: 0.36675453186035156, acc: 0.8823529481887817)
[2025-01-30 02:18:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4851/107898 [26:21<8:35:31,  3.33it/s][2025-01-30 02:18:30][root][INFO] - Training Epoch: 1/2, step 4850/107898 completed (loss: 1.6365538835525513, acc: 0.7777777910232544)
[2025-01-30 02:18:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4852/107898 [26:21<8:32:55,  3.35it/s][2025-01-30 02:18:31][root][INFO] - Training Epoch: 1/2, step 4851/107898 completed (loss: 0.12147306650876999, acc: 1.0)
[2025-01-30 02:18:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4853/107898 [26:21<8:29:44,  3.37it/s][2025-01-30 02:18:31][root][INFO] - Training Epoch: 1/2, step 4852/107898 completed (loss: 0.14832422137260437, acc: 1.0)
[2025-01-30 02:18:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4854/107898 [26:21<8:38:44,  3.31it/s][2025-01-30 02:18:31][root][INFO] - Training Epoch: 1/2, step 4853/107898 completed (loss: 0.3949918746948242, acc: 0.8846153616905212)
[2025-01-30 02:18:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   4%|[34mâ–         [0m| 4855/107898 [26:22<8:42:28,  3.29it/s][2025-01-30 02:18:32][root][INFO] - Training Epoch: 1/2, step 4854/107898 completed (loss: 0.3376789093017578, acc: 1.0)
[2025-01-30 02:18:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4856/107898 [26:22<9:03:20,  3.16it/s][2025-01-30 02:18:32][root][INFO] - Training Epoch: 1/2, step 4855/107898 completed (loss: 0.125999316573143, acc: 1.0)
[2025-01-30 02:18:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4857/107898 [26:22<9:15:19,  3.09it/s][2025-01-30 02:18:32][root][INFO] - Training Epoch: 1/2, step 4856/107898 completed (loss: 0.3807908892631531, acc: 0.8888888955116272)
[2025-01-30 02:18:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4858/107898 [26:23<9:23:40,  3.05it/s][2025-01-30 02:18:33][root][INFO] - Training Epoch: 1/2, step 4857/107898 completed (loss: 0.38840535283088684, acc: 0.800000011920929)
[2025-01-30 02:18:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4859/107898 [26:23<9:27:27,  3.03it/s][2025-01-30 02:18:33][root][INFO] - Training Epoch: 1/2, step 4858/107898 completed (loss: 2.784044027328491, acc: 0.3636363744735718)
[2025-01-30 02:18:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4860/107898 [26:23<9:44:42,  2.94it/s][2025-01-30 02:18:33][root][INFO] - Training Epoch: 1/2, step 4859/107898 completed (loss: 1.6610054969787598, acc: 0.5)
[2025-01-30 02:18:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4861/107898 [26:24<9:43:13,  2.94it/s][2025-01-30 02:18:34][root][INFO] - Training Epoch: 1/2, step 4860/107898 completed (loss: 2.0077931880950928, acc: 0.38461539149284363)
[2025-01-30 02:18:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4862/107898 [26:24<9:30:39,  3.01it/s][2025-01-30 02:18:34][root][INFO] - Training Epoch: 1/2, step 4861/107898 completed (loss: 2.049683094024658, acc: 0.7272727489471436)
[2025-01-30 02:18:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4863/107898 [26:25<9:42:07,  2.95it/s][2025-01-30 02:18:34][root][INFO] - Training Epoch: 1/2, step 4862/107898 completed (loss: 0.029104257002472878, acc: 1.0)
[2025-01-30 02:18:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4864/107898 [26:25<9:39:15,  2.96it/s][2025-01-30 02:18:35][root][INFO] - Training Epoch: 1/2, step 4863/107898 completed (loss: 0.502599835395813, acc: 0.800000011920929)
[2025-01-30 02:18:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4865/107898 [26:25<9:33:24,  2.99it/s][2025-01-30 02:18:35][root][INFO] - Training Epoch: 1/2, step 4864/107898 completed (loss: 0.30955299735069275, acc: 0.9230769276618958)
[2025-01-30 02:18:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4866/107898 [26:25<9:12:15,  3.11it/s][2025-01-30 02:18:35][root][INFO] - Training Epoch: 1/2, step 4865/107898 completed (loss: 1.43269944190979, acc: 0.800000011920929)
[2025-01-30 02:18:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4867/107898 [26:26<9:31:05,  3.01it/s][2025-01-30 02:18:36][root][INFO] - Training Epoch: 1/2, step 4866/107898 completed (loss: 0.3738345801830292, acc: 0.8936170339584351)
[2025-01-30 02:18:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4868/107898 [26:26<9:11:33,  3.11it/s][2025-01-30 02:18:36][root][INFO] - Training Epoch: 1/2, step 4867/107898 completed (loss: 0.009570702910423279, acc: 1.0)
[2025-01-30 02:18:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4869/107898 [26:26<8:41:43,  3.29it/s][2025-01-30 02:18:36][root][INFO] - Training Epoch: 1/2, step 4868/107898 completed (loss: 1.5146005153656006, acc: 0.7142857313156128)
[2025-01-30 02:18:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4870/107898 [26:27<8:39:46,  3.30it/s][2025-01-30 02:18:36][root][INFO] - Training Epoch: 1/2, step 4869/107898 completed (loss: 1.4789066314697266, acc: 0.6666666865348816)
[2025-01-30 02:18:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4871/107898 [26:27<8:38:17,  3.31it/s][2025-01-30 02:18:37][root][INFO] - Training Epoch: 1/2, step 4870/107898 completed (loss: 0.17591477930545807, acc: 1.0)
[2025-01-30 02:18:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4872/107898 [26:27<8:35:40,  3.33it/s][2025-01-30 02:18:37][root][INFO] - Training Epoch: 1/2, step 4871/107898 completed (loss: 3.8738417625427246, acc: 0.75)
[2025-01-30 02:18:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4873/107898 [26:28<8:40:59,  3.30it/s][2025-01-30 02:18:37][root][INFO] - Training Epoch: 1/2, step 4872/107898 completed (loss: 2.3627254962921143, acc: 0.7058823704719543)
[2025-01-30 02:18:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4874/107898 [26:28<8:44:42,  3.27it/s][2025-01-30 02:18:38][root][INFO] - Training Epoch: 1/2, step 4873/107898 completed (loss: 1.800417423248291, acc: 0.25)
[2025-01-30 02:18:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4875/107898 [26:28<8:47:12,  3.26it/s][2025-01-30 02:18:38][root][INFO] - Training Epoch: 1/2, step 4874/107898 completed (loss: 0.015516155399382114, acc: 1.0)
[2025-01-30 02:18:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4876/107898 [26:29<9:13:33,  3.10it/s][2025-01-30 02:18:38][root][INFO] - Training Epoch: 1/2, step 4875/107898 completed (loss: 0.25574082136154175, acc: 1.0)
[2025-01-30 02:18:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4877/107898 [26:29<9:24:02,  3.04it/s][2025-01-30 02:18:39][root][INFO] - Training Epoch: 1/2, step 4876/107898 completed (loss: 4.715274333953857, acc: 0.3181818127632141)
[2025-01-30 02:18:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4878/107898 [26:29<9:18:11,  3.08it/s][2025-01-30 02:18:39][root][INFO] - Training Epoch: 1/2, step 4877/107898 completed (loss: 0.015375625342130661, acc: 1.0)
[2025-01-30 02:18:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4879/107898 [26:30<8:57:44,  3.19it/s][2025-01-30 02:18:39][root][INFO] - Training Epoch: 1/2, step 4878/107898 completed (loss: 1.575616478919983, acc: 0.75)
[2025-01-30 02:18:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4880/107898 [26:30<9:00:21,  3.18it/s][2025-01-30 02:18:40][root][INFO] - Training Epoch: 1/2, step 4879/107898 completed (loss: 0.8827294111251831, acc: 0.800000011920929)
[2025-01-30 02:18:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4881/107898 [26:30<9:26:14,  3.03it/s][2025-01-30 02:18:40][root][INFO] - Training Epoch: 1/2, step 4880/107898 completed (loss: 0.00782524049282074, acc: 1.0)
[2025-01-30 02:18:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4882/107898 [26:31<9:44:48,  2.94it/s][2025-01-30 02:18:40][root][INFO] - Training Epoch: 1/2, step 4881/107898 completed (loss: 0.7013468742370605, acc: 0.782608687877655)
[2025-01-30 02:18:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4883/107898 [26:31<9:29:18,  3.02it/s][2025-01-30 02:18:41][root][INFO] - Training Epoch: 1/2, step 4882/107898 completed (loss: 0.3309425115585327, acc: 1.0)
[2025-01-30 02:18:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4884/107898 [26:31<9:14:58,  3.09it/s][2025-01-30 02:18:41][root][INFO] - Training Epoch: 1/2, step 4883/107898 completed (loss: 0.0015819452237337828, acc: 1.0)
[2025-01-30 02:18:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4885/107898 [26:32<9:28:35,  3.02it/s][2025-01-30 02:18:41][root][INFO] - Training Epoch: 1/2, step 4884/107898 completed (loss: 0.5908425450325012, acc: 0.8636363744735718)
[2025-01-30 02:18:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4886/107898 [26:32<9:28:28,  3.02it/s][2025-01-30 02:18:42][root][INFO] - Training Epoch: 1/2, step 4885/107898 completed (loss: 1.6965241432189941, acc: 0.7599999904632568)
[2025-01-30 02:18:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4887/107898 [26:32<9:18:25,  3.07it/s][2025-01-30 02:18:42][root][INFO] - Training Epoch: 1/2, step 4886/107898 completed (loss: 0.8825293183326721, acc: 0.6666666865348816)
[2025-01-30 02:18:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4888/107898 [26:32<9:03:19,  3.16it/s][2025-01-30 02:18:42][root][INFO] - Training Epoch: 1/2, step 4887/107898 completed (loss: 0.002840969245880842, acc: 1.0)
[2025-01-30 02:18:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4889/107898 [26:33<9:06:01,  3.14it/s][2025-01-30 02:18:43][root][INFO] - Training Epoch: 1/2, step 4888/107898 completed (loss: 1.0073180198669434, acc: 0.8181818127632141)
[2025-01-30 02:18:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4890/107898 [26:33<9:22:00,  3.05it/s][2025-01-30 02:18:43][root][INFO] - Training Epoch: 1/2, step 4889/107898 completed (loss: 0.17382632195949554, acc: 0.949999988079071)
[2025-01-30 02:18:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4891/107898 [26:34<9:48:14,  2.92it/s][2025-01-30 02:18:43][root][INFO] - Training Epoch: 1/2, step 4890/107898 completed (loss: 1.2557785511016846, acc: 0.6666666865348816)
[2025-01-30 02:18:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4892/107898 [26:34<9:42:56,  2.95it/s][2025-01-30 02:18:44][root][INFO] - Training Epoch: 1/2, step 4891/107898 completed (loss: 0.964371383190155, acc: 0.875)
[2025-01-30 02:18:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4893/107898 [26:34<9:19:18,  3.07it/s][2025-01-30 02:18:44][root][INFO] - Training Epoch: 1/2, step 4892/107898 completed (loss: 0.21012841165065765, acc: 1.0)
[2025-01-30 02:18:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4894/107898 [26:34<9:09:54,  3.12it/s][2025-01-30 02:18:44][root][INFO] - Training Epoch: 1/2, step 4893/107898 completed (loss: 0.1250419020652771, acc: 1.0)
[2025-01-30 02:18:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4895/107898 [26:35<8:58:03,  3.19it/s][2025-01-30 02:18:45][root][INFO] - Training Epoch: 1/2, step 4894/107898 completed (loss: 1.2012063264846802, acc: 0.5)
[2025-01-30 02:18:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4896/107898 [26:35<8:49:59,  3.24it/s][2025-01-30 02:18:45][root][INFO] - Training Epoch: 1/2, step 4895/107898 completed (loss: 1.7271723747253418, acc: 0.7272727489471436)
[2025-01-30 02:18:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4897/107898 [26:35<8:34:15,  3.34it/s][2025-01-30 02:18:45][root][INFO] - Training Epoch: 1/2, step 4896/107898 completed (loss: 0.607053816318512, acc: 0.8999999761581421)
[2025-01-30 02:18:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4898/107898 [26:36<8:27:58,  3.38it/s][2025-01-30 02:18:45][root][INFO] - Training Epoch: 1/2, step 4897/107898 completed (loss: 1.1850372552871704, acc: 0.75)
[2025-01-30 02:18:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4899/107898 [26:36<8:53:05,  3.22it/s][2025-01-30 02:18:46][root][INFO] - Training Epoch: 1/2, step 4898/107898 completed (loss: 0.3105606734752655, acc: 0.9285714030265808)
[2025-01-30 02:18:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4900/107898 [26:36<8:56:24,  3.20it/s][2025-01-30 02:18:46][root][INFO] - Training Epoch: 1/2, step 4899/107898 completed (loss: 4.5802178382873535, acc: 0.3333333432674408)
[2025-01-30 02:18:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4901/107898 [26:37<9:00:13,  3.18it/s][2025-01-30 02:18:46][root][INFO] - Training Epoch: 1/2, step 4900/107898 completed (loss: 0.057364314794540405, acc: 1.0)
[2025-01-30 02:18:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4902/107898 [26:37<9:13:38,  3.10it/s][2025-01-30 02:18:47][root][INFO] - Training Epoch: 1/2, step 4901/107898 completed (loss: 0.7296708226203918, acc: 0.8666666746139526)
[2025-01-30 02:18:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4903/107898 [26:37<9:04:19,  3.15it/s][2025-01-30 02:18:47][root][INFO] - Training Epoch: 1/2, step 4902/107898 completed (loss: 1.4989980459213257, acc: 0.6666666865348816)
[2025-01-30 02:18:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4904/107898 [26:38<9:03:40,  3.16it/s][2025-01-30 02:18:47][root][INFO] - Training Epoch: 1/2, step 4903/107898 completed (loss: 0.014891781844198704, acc: 1.0)
[2025-01-30 02:18:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4905/107898 [26:38<8:53:40,  3.22it/s][2025-01-30 02:18:48][root][INFO] - Training Epoch: 1/2, step 4904/107898 completed (loss: 2.1967287063598633, acc: 0.4444444477558136)
[2025-01-30 02:18:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4906/107898 [26:38<8:47:35,  3.25it/s][2025-01-30 02:18:48][root][INFO] - Training Epoch: 1/2, step 4905/107898 completed (loss: 0.14780454337596893, acc: 1.0)
[2025-01-30 02:18:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4907/107898 [26:38<8:43:27,  3.28it/s][2025-01-30 02:18:48][root][INFO] - Training Epoch: 1/2, step 4906/107898 completed (loss: 0.04387770965695381, acc: 1.0)
[2025-01-30 02:18:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4908/107898 [26:39<8:52:51,  3.22it/s][2025-01-30 02:18:49][root][INFO] - Training Epoch: 1/2, step 4907/107898 completed (loss: 0.497672975063324, acc: 0.9375)
[2025-01-30 02:18:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4909/107898 [26:39<8:47:22,  3.25it/s][2025-01-30 02:18:49][root][INFO] - Training Epoch: 1/2, step 4908/107898 completed (loss: 0.7514232993125916, acc: 0.75)
[2025-01-30 02:18:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4910/107898 [26:39<8:46:30,  3.26it/s][2025-01-30 02:18:49][root][INFO] - Training Epoch: 1/2, step 4909/107898 completed (loss: 1.8968467712402344, acc: 0.800000011920929)
[2025-01-30 02:18:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4911/107898 [26:40<8:39:06,  3.31it/s][2025-01-30 02:18:49][root][INFO] - Training Epoch: 1/2, step 4910/107898 completed (loss: 1.6729801893234253, acc: 0.5)
[2025-01-30 02:18:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4912/107898 [26:40<8:36:00,  3.33it/s][2025-01-30 02:18:50][root][INFO] - Training Epoch: 1/2, step 4911/107898 completed (loss: 0.2664368450641632, acc: 1.0)
[2025-01-30 02:18:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4913/107898 [26:40<8:47:33,  3.25it/s][2025-01-30 02:18:50][root][INFO] - Training Epoch: 1/2, step 4912/107898 completed (loss: 4.5726728439331055, acc: 0.5)
[2025-01-30 02:18:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4914/107898 [26:41<9:05:47,  3.14it/s][2025-01-30 02:18:50][root][INFO] - Training Epoch: 1/2, step 4913/107898 completed (loss: 0.24286219477653503, acc: 0.9375)
[2025-01-30 02:18:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4915/107898 [26:41<8:46:34,  3.26it/s][2025-01-30 02:18:51][root][INFO] - Training Epoch: 1/2, step 4914/107898 completed (loss: 1.0907130241394043, acc: 0.75)
[2025-01-30 02:18:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4916/107898 [26:41<8:40:46,  3.30it/s][2025-01-30 02:18:51][root][INFO] - Training Epoch: 1/2, step 4915/107898 completed (loss: 0.36344632506370544, acc: 0.8999999761581421)
[2025-01-30 02:18:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4917/107898 [26:41<8:39:26,  3.30it/s][2025-01-30 02:18:51][root][INFO] - Training Epoch: 1/2, step 4916/107898 completed (loss: 0.33310896158218384, acc: 1.0)
[2025-01-30 02:18:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4918/107898 [26:42<8:42:39,  3.28it/s][2025-01-30 02:18:52][root][INFO] - Training Epoch: 1/2, step 4917/107898 completed (loss: 1.883762240409851, acc: 0.3333333432674408)
[2025-01-30 02:18:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4919/107898 [26:42<9:00:34,  3.17it/s][2025-01-30 02:18:52][root][INFO] - Training Epoch: 1/2, step 4918/107898 completed (loss: 2.3688056468963623, acc: 0.6666666865348816)
[2025-01-30 02:18:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4920/107898 [26:42<9:11:41,  3.11it/s][2025-01-30 02:18:52][root][INFO] - Training Epoch: 1/2, step 4919/107898 completed (loss: 0.36257028579711914, acc: 0.8999999761581421)
[2025-01-30 02:18:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4921/107898 [26:43<9:30:17,  3.01it/s][2025-01-30 02:18:53][root][INFO] - Training Epoch: 1/2, step 4920/107898 completed (loss: 0.04197895526885986, acc: 1.0)
[2025-01-30 02:18:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4922/107898 [26:43<9:48:16,  2.92it/s][2025-01-30 02:18:53][root][INFO] - Training Epoch: 1/2, step 4921/107898 completed (loss: 0.2005825638771057, acc: 1.0)
[2025-01-30 02:18:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4923/107898 [26:44<10:01:04,  2.86it/s][2025-01-30 02:18:53][root][INFO] - Training Epoch: 1/2, step 4922/107898 completed (loss: 0.07907764613628387, acc: 1.0)
[2025-01-30 02:18:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4924/107898 [26:44<9:53:53,  2.89it/s] [2025-01-30 02:18:54][root][INFO] - Training Epoch: 1/2, step 4923/107898 completed (loss: 0.48531731963157654, acc: 0.8571428656578064)
[2025-01-30 02:18:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4925/107898 [26:44<9:37:26,  2.97it/s][2025-01-30 02:18:54][root][INFO] - Training Epoch: 1/2, step 4924/107898 completed (loss: 0.9307289719581604, acc: 0.7142857313156128)
[2025-01-30 02:18:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4926/107898 [26:45<9:23:00,  3.05it/s][2025-01-30 02:18:54][root][INFO] - Training Epoch: 1/2, step 4925/107898 completed (loss: 1.6647146940231323, acc: 0.5)
[2025-01-30 02:18:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4927/107898 [26:45<9:08:02,  3.13it/s][2025-01-30 02:18:55][root][INFO] - Training Epoch: 1/2, step 4926/107898 completed (loss: 2.0540482997894287, acc: 0.0)
[2025-01-30 02:18:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4928/107898 [26:45<9:20:52,  3.06it/s][2025-01-30 02:18:55][root][INFO] - Training Epoch: 1/2, step 4927/107898 completed (loss: 0.04977793991565704, acc: 1.0)
[2025-01-30 02:18:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4929/107898 [26:45<9:09:26,  3.12it/s][2025-01-30 02:18:55][root][INFO] - Training Epoch: 1/2, step 4928/107898 completed (loss: 0.46637651324272156, acc: 0.7777777910232544)
[2025-01-30 02:18:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4930/107898 [26:46<9:02:35,  3.16it/s][2025-01-30 02:18:56][root][INFO] - Training Epoch: 1/2, step 4929/107898 completed (loss: 0.6202155351638794, acc: 0.8888888955116272)
[2025-01-30 02:18:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4931/107898 [26:46<9:16:12,  3.09it/s][2025-01-30 02:18:56][root][INFO] - Training Epoch: 1/2, step 4930/107898 completed (loss: 1.0127251148223877, acc: 0.8333333134651184)
[2025-01-30 02:18:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4932/107898 [26:46<9:28:30,  3.02it/s][2025-01-30 02:18:56][root][INFO] - Training Epoch: 1/2, step 4931/107898 completed (loss: 1.630514144897461, acc: 0.5)
[2025-01-30 02:18:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4933/107898 [26:47<9:36:43,  2.98it/s][2025-01-30 02:18:57][root][INFO] - Training Epoch: 1/2, step 4932/107898 completed (loss: 0.33533942699432373, acc: 0.8888888955116272)
[2025-01-30 02:18:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4934/107898 [26:47<9:32:18,  3.00it/s][2025-01-30 02:18:57][root][INFO] - Training Epoch: 1/2, step 4933/107898 completed (loss: 0.8067598938941956, acc: 0.7142857313156128)
[2025-01-30 02:18:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4935/107898 [26:47<9:40:03,  2.96it/s][2025-01-30 02:18:57][root][INFO] - Training Epoch: 1/2, step 4934/107898 completed (loss: 0.16149812936782837, acc: 0.9655172228813171)
[2025-01-30 02:18:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4936/107898 [26:48<9:31:29,  3.00it/s][2025-01-30 02:18:58][root][INFO] - Training Epoch: 1/2, step 4935/107898 completed (loss: 1.2268134355545044, acc: 0.8125)
[2025-01-30 02:18:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4937/107898 [26:48<9:34:00,  2.99it/s][2025-01-30 02:18:58][root][INFO] - Training Epoch: 1/2, step 4936/107898 completed (loss: 3.366673231124878, acc: 0.42105263471603394)
[2025-01-30 02:18:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4938/107898 [26:49<9:46:28,  2.93it/s][2025-01-30 02:18:58][root][INFO] - Training Epoch: 1/2, step 4937/107898 completed (loss: 0.20938660204410553, acc: 1.0)
[2025-01-30 02:18:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4939/107898 [26:49<9:56:03,  2.88it/s][2025-01-30 02:18:59][root][INFO] - Training Epoch: 1/2, step 4938/107898 completed (loss: 0.8813915252685547, acc: 0.800000011920929)
[2025-01-30 02:18:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4940/107898 [26:49<9:44:14,  2.94it/s][2025-01-30 02:18:59][root][INFO] - Training Epoch: 1/2, step 4939/107898 completed (loss: 0.22071462869644165, acc: 1.0)
[2025-01-30 02:18:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4941/107898 [26:50<9:29:18,  3.01it/s][2025-01-30 02:18:59][root][INFO] - Training Epoch: 1/2, step 4940/107898 completed (loss: 0.2394479215145111, acc: 1.0)
[2025-01-30 02:18:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4942/107898 [26:50<9:15:34,  3.09it/s][2025-01-30 02:19:00][root][INFO] - Training Epoch: 1/2, step 4941/107898 completed (loss: 2.2463927268981934, acc: 0.6000000238418579)
[2025-01-30 02:19:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4943/107898 [26:50<9:10:28,  3.12it/s][2025-01-30 02:19:00][root][INFO] - Training Epoch: 1/2, step 4942/107898 completed (loss: 0.05458632856607437, acc: 1.0)
[2025-01-30 02:19:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4944/107898 [26:50<8:55:14,  3.21it/s][2025-01-30 02:19:00][root][INFO] - Training Epoch: 1/2, step 4943/107898 completed (loss: 0.9505281448364258, acc: 0.800000011920929)
[2025-01-30 02:19:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4945/107898 [26:51<9:10:48,  3.12it/s][2025-01-30 02:19:01][root][INFO] - Training Epoch: 1/2, step 4944/107898 completed (loss: 0.6760523915290833, acc: 0.875)
[2025-01-30 02:19:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4946/107898 [26:51<9:11:35,  3.11it/s][2025-01-30 02:19:01][root][INFO] - Training Epoch: 1/2, step 4945/107898 completed (loss: 0.3071257472038269, acc: 0.8666666746139526)
[2025-01-30 02:19:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4947/107898 [26:51<9:23:30,  3.04it/s][2025-01-30 02:19:01][root][INFO] - Training Epoch: 1/2, step 4946/107898 completed (loss: 0.3370485007762909, acc: 0.9117646813392639)
[2025-01-30 02:19:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4948/107898 [26:52<9:21:29,  3.06it/s][2025-01-30 02:19:02][root][INFO] - Training Epoch: 1/2, step 4947/107898 completed (loss: 0.059877969324588776, acc: 1.0)
[2025-01-30 02:19:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4949/107898 [26:52<9:24:21,  3.04it/s][2025-01-30 02:19:02][root][INFO] - Training Epoch: 1/2, step 4948/107898 completed (loss: 2.970048189163208, acc: 0.4000000059604645)
[2025-01-30 02:19:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4950/107898 [26:52<9:23:14,  3.05it/s][2025-01-30 02:19:02][root][INFO] - Training Epoch: 1/2, step 4949/107898 completed (loss: 0.31458449363708496, acc: 1.0)
[2025-01-30 02:19:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4951/107898 [26:53<9:38:27,  2.97it/s][2025-01-30 02:19:03][root][INFO] - Training Epoch: 1/2, step 4950/107898 completed (loss: 2.3462419509887695, acc: 0.40740740299224854)
[2025-01-30 02:19:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4952/107898 [26:53<9:40:53,  2.95it/s][2025-01-30 02:19:03][root][INFO] - Training Epoch: 1/2, step 4951/107898 completed (loss: 0.5765125751495361, acc: 1.0)
[2025-01-30 02:19:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4953/107898 [26:53<9:36:05,  2.98it/s][2025-01-30 02:19:03][root][INFO] - Training Epoch: 1/2, step 4952/107898 completed (loss: 2.3145554065704346, acc: 0.1666666716337204)
[2025-01-30 02:19:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4954/107898 [26:54<9:24:33,  3.04it/s][2025-01-30 02:19:04][root][INFO] - Training Epoch: 1/2, step 4953/107898 completed (loss: 0.07530848681926727, acc: 1.0)
[2025-01-30 02:19:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4955/107898 [26:54<9:15:20,  3.09it/s][2025-01-30 02:19:04][root][INFO] - Training Epoch: 1/2, step 4954/107898 completed (loss: 0.35216864943504333, acc: 0.6666666865348816)
[2025-01-30 02:19:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4956/107898 [26:54<9:13:19,  3.10it/s][2025-01-30 02:19:04][root][INFO] - Training Epoch: 1/2, step 4955/107898 completed (loss: 2.0987589359283447, acc: 0.6153846383094788)
[2025-01-30 02:19:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4957/107898 [26:55<9:29:21,  3.01it/s][2025-01-30 02:19:05][root][INFO] - Training Epoch: 1/2, step 4956/107898 completed (loss: 0.703283965587616, acc: 0.8333333134651184)
[2025-01-30 02:19:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4958/107898 [26:55<9:49:21,  2.91it/s][2025-01-30 02:19:05][root][INFO] - Training Epoch: 1/2, step 4957/107898 completed (loss: 0.5993413329124451, acc: 0.9285714030265808)
[2025-01-30 02:19:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4959/107898 [26:55<9:46:44,  2.92it/s][2025-01-30 02:19:05][root][INFO] - Training Epoch: 1/2, step 4958/107898 completed (loss: 1.2987473011016846, acc: 0.7941176295280457)
[2025-01-30 02:19:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4960/107898 [26:56<9:25:51,  3.03it/s][2025-01-30 02:19:06][root][INFO] - Training Epoch: 1/2, step 4959/107898 completed (loss: 0.04058427736163139, acc: 1.0)
[2025-01-30 02:19:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4961/107898 [26:56<9:08:16,  3.13it/s][2025-01-30 02:19:06][root][INFO] - Training Epoch: 1/2, step 4960/107898 completed (loss: 2.0509655475616455, acc: 0.800000011920929)
[2025-01-30 02:19:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4962/107898 [26:56<9:03:55,  3.15it/s][2025-01-30 02:19:06][root][INFO] - Training Epoch: 1/2, step 4961/107898 completed (loss: 2.234498977661133, acc: 0.6666666865348816)
[2025-01-30 02:19:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4963/107898 [26:57<9:12:27,  3.11it/s][2025-01-30 02:19:06][root][INFO] - Training Epoch: 1/2, step 4962/107898 completed (loss: 0.6883057355880737, acc: 0.7407407164573669)
[2025-01-30 02:19:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4964/107898 [26:57<9:25:00,  3.04it/s][2025-01-30 02:19:07][root][INFO] - Training Epoch: 1/2, step 4963/107898 completed (loss: 0.27919653058052063, acc: 0.9090909361839294)
[2025-01-30 02:19:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4965/107898 [26:57<9:41:34,  2.95it/s][2025-01-30 02:19:07][root][INFO] - Training Epoch: 1/2, step 4964/107898 completed (loss: 1.0451527833938599, acc: 0.6666666865348816)
[2025-01-30 02:19:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4966/107898 [26:58<9:48:49,  2.91it/s][2025-01-30 02:19:08][root][INFO] - Training Epoch: 1/2, step 4965/107898 completed (loss: 3.1525001525878906, acc: 0.3461538553237915)
[2025-01-30 02:19:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4967/107898 [26:58<9:53:04,  2.89it/s][2025-01-30 02:19:08][root][INFO] - Training Epoch: 1/2, step 4966/107898 completed (loss: 2.109708070755005, acc: 0.6666666865348816)
[2025-01-30 02:19:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4968/107898 [26:58<9:41:13,  2.95it/s][2025-01-30 02:19:08][root][INFO] - Training Epoch: 1/2, step 4967/107898 completed (loss: 0.45666074752807617, acc: 1.0)
[2025-01-30 02:19:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4969/107898 [26:59<9:20:41,  3.06it/s][2025-01-30 02:19:09][root][INFO] - Training Epoch: 1/2, step 4968/107898 completed (loss: 0.24465370178222656, acc: 0.8333333134651184)
[2025-01-30 02:19:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4970/107898 [26:59<9:06:38,  3.14it/s][2025-01-30 02:19:09][root][INFO] - Training Epoch: 1/2, step 4969/107898 completed (loss: 0.8020782470703125, acc: 0.8823529481887817)
[2025-01-30 02:19:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4971/107898 [26:59<9:34:58,  2.98it/s][2025-01-30 02:19:09][root][INFO] - Training Epoch: 1/2, step 4970/107898 completed (loss: 1.325095772743225, acc: 0.7837837934494019)
[2025-01-30 02:19:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4972/107898 [27:00<9:33:29,  2.99it/s][2025-01-30 02:19:10][root][INFO] - Training Epoch: 1/2, step 4971/107898 completed (loss: 0.1539973020553589, acc: 1.0)
[2025-01-30 02:19:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4973/107898 [27:00<9:56:45,  2.87it/s][2025-01-30 02:19:10][root][INFO] - Training Epoch: 1/2, step 4972/107898 completed (loss: 1.2738988399505615, acc: 0.5)
[2025-01-30 02:19:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4974/107898 [27:00<9:45:28,  2.93it/s][2025-01-30 02:19:10][root][INFO] - Training Epoch: 1/2, step 4973/107898 completed (loss: 0.02296181209385395, acc: 1.0)
[2025-01-30 02:19:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4975/107898 [27:01<9:42:06,  2.95it/s][2025-01-30 02:19:11][root][INFO] - Training Epoch: 1/2, step 4974/107898 completed (loss: 1.825880527496338, acc: 0.75)
[2025-01-30 02:19:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4976/107898 [27:01<9:42:26,  2.95it/s][2025-01-30 02:19:11][root][INFO] - Training Epoch: 1/2, step 4975/107898 completed (loss: 0.03804335370659828, acc: 1.0)
[2025-01-30 02:19:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4977/107898 [27:01<9:28:34,  3.02it/s][2025-01-30 02:19:11][root][INFO] - Training Epoch: 1/2, step 4976/107898 completed (loss: 0.7190722823143005, acc: 0.8181818127632141)
[2025-01-30 02:19:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4978/107898 [27:02<9:03:13,  3.16it/s][2025-01-30 02:19:11][root][INFO] - Training Epoch: 1/2, step 4977/107898 completed (loss: 0.1622583568096161, acc: 1.0)
[2025-01-30 02:19:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4979/107898 [27:02<9:10:10,  3.12it/s][2025-01-30 02:19:12][root][INFO] - Training Epoch: 1/2, step 4978/107898 completed (loss: 0.6195812821388245, acc: 0.875)
[2025-01-30 02:19:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4980/107898 [27:02<9:16:07,  3.08it/s][2025-01-30 02:19:12][root][INFO] - Training Epoch: 1/2, step 4979/107898 completed (loss: 0.17195767164230347, acc: 1.0)
[2025-01-30 02:19:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4981/107898 [27:03<9:47:53,  2.92it/s][2025-01-30 02:19:13][root][INFO] - Training Epoch: 1/2, step 4980/107898 completed (loss: 4.301061630249023, acc: 0.1666666716337204)
[2025-01-30 02:19:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4982/107898 [27:03<9:47:15,  2.92it/s][2025-01-30 02:19:13][root][INFO] - Training Epoch: 1/2, step 4981/107898 completed (loss: 2.051769256591797, acc: 0.5714285969734192)
[2025-01-30 02:19:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4983/107898 [27:03<9:41:51,  2.95it/s][2025-01-30 02:19:13][root][INFO] - Training Epoch: 1/2, step 4982/107898 completed (loss: 1.1144393682479858, acc: 0.8333333134651184)
[2025-01-30 02:19:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4984/107898 [27:04<9:42:49,  2.94it/s][2025-01-30 02:19:14][root][INFO] - Training Epoch: 1/2, step 4983/107898 completed (loss: 2.1243956089019775, acc: 0.5714285969734192)
[2025-01-30 02:19:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4985/107898 [27:04<9:30:25,  3.01it/s][2025-01-30 02:19:14][root][INFO] - Training Epoch: 1/2, step 4984/107898 completed (loss: 0.44042912125587463, acc: 0.875)
[2025-01-30 02:19:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4986/107898 [27:04<9:20:39,  3.06it/s][2025-01-30 02:19:14][root][INFO] - Training Epoch: 1/2, step 4985/107898 completed (loss: 0.027574053034186363, acc: 1.0)
[2025-01-30 02:19:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4987/107898 [27:05<9:28:41,  3.02it/s][2025-01-30 02:19:15][root][INFO] - Training Epoch: 1/2, step 4986/107898 completed (loss: 1.4886219501495361, acc: 0.7142857313156128)
[2025-01-30 02:19:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4988/107898 [27:05<9:28:12,  3.02it/s][2025-01-30 02:19:15][root][INFO] - Training Epoch: 1/2, step 4987/107898 completed (loss: 0.016448404639959335, acc: 1.0)
[2025-01-30 02:19:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4989/107898 [27:05<9:34:51,  2.98it/s][2025-01-30 02:19:15][root][INFO] - Training Epoch: 1/2, step 4988/107898 completed (loss: 0.40409618616104126, acc: 0.9111111164093018)
[2025-01-30 02:19:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4990/107898 [27:06<9:26:47,  3.03it/s][2025-01-30 02:19:16][root][INFO] - Training Epoch: 1/2, step 4989/107898 completed (loss: 0.7632944583892822, acc: 0.9166666865348816)
[2025-01-30 02:19:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4991/107898 [27:06<9:15:13,  3.09it/s][2025-01-30 02:19:16][root][INFO] - Training Epoch: 1/2, step 4990/107898 completed (loss: 1.5346490144729614, acc: 0.7857142686843872)
[2025-01-30 02:19:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4992/107898 [27:06<9:00:06,  3.18it/s][2025-01-30 02:19:16][root][INFO] - Training Epoch: 1/2, step 4991/107898 completed (loss: 0.5939357876777649, acc: 1.0)
[2025-01-30 02:19:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4993/107898 [27:07<8:53:21,  3.22it/s][2025-01-30 02:19:16][root][INFO] - Training Epoch: 1/2, step 4992/107898 completed (loss: 2.078291177749634, acc: 0.4285714328289032)
[2025-01-30 02:19:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4994/107898 [27:07<8:44:27,  3.27it/s][2025-01-30 02:19:17][root][INFO] - Training Epoch: 1/2, step 4993/107898 completed (loss: 1.0603299140930176, acc: 0.75)
[2025-01-30 02:19:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4995/107898 [27:07<8:48:34,  3.24it/s][2025-01-30 02:19:17][root][INFO] - Training Epoch: 1/2, step 4994/107898 completed (loss: 2.022970676422119, acc: 0.6666666865348816)
[2025-01-30 02:19:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4996/107898 [27:08<9:13:40,  3.10it/s][2025-01-30 02:19:17][root][INFO] - Training Epoch: 1/2, step 4995/107898 completed (loss: 4.643418788909912, acc: 0.31578946113586426)
[2025-01-30 02:19:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4997/107898 [27:08<9:09:36,  3.12it/s][2025-01-30 02:19:18][root][INFO] - Training Epoch: 1/2, step 4996/107898 completed (loss: 0.010497353971004486, acc: 1.0)
[2025-01-30 02:19:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4998/107898 [27:08<9:06:24,  3.14it/s][2025-01-30 02:19:18][root][INFO] - Training Epoch: 1/2, step 4997/107898 completed (loss: 0.14079438149929047, acc: 0.9166666865348816)
[2025-01-30 02:19:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 4999/107898 [27:09<9:11:43,  3.11it/s][2025-01-30 02:19:18][root][INFO] - Training Epoch: 1/2, step 4998/107898 completed (loss: 0.7531034350395203, acc: 0.8387096524238586)
[2025-01-30 02:19:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5000/107898 [27:09<8:54:19,  3.21it/s][2025-01-30 02:19:19][root][INFO] - Training Epoch: 1/2, step 4999/107898 completed (loss: 0.011262306943535805, acc: 1.0)
[2025-01-30 02:19:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5001/107898 [27:09<8:58:15,  3.19it/s][2025-01-30 02:19:19][root][INFO] - Training Epoch: 1/2, step 5000/107898 completed (loss: 1.8317821025848389, acc: 0.6428571343421936)
[2025-01-30 02:19:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5002/107898 [27:09<8:53:14,  3.22it/s][2025-01-30 02:19:19][root][INFO] - Training Epoch: 1/2, step 5001/107898 completed (loss: 0.4875819981098175, acc: 0.7777777910232544)
[2025-01-30 02:19:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5003/107898 [27:10<9:25:19,  3.03it/s][2025-01-30 02:19:20][root][INFO] - Training Epoch: 1/2, step 5002/107898 completed (loss: 1.487588882446289, acc: 0.6666666865348816)
[2025-01-30 02:19:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5004/107898 [27:10<9:23:51,  3.04it/s][2025-01-30 02:19:20][root][INFO] - Training Epoch: 1/2, step 5003/107898 completed (loss: 4.056705951690674, acc: 0.3636363744735718)
[2025-01-30 02:19:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5005/107898 [27:10<9:10:59,  3.11it/s][2025-01-30 02:19:20][root][INFO] - Training Epoch: 1/2, step 5004/107898 completed (loss: 0.0048687756061553955, acc: 1.0)
[2025-01-30 02:19:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5006/107898 [27:11<9:12:52,  3.10it/s][2025-01-30 02:19:21][root][INFO] - Training Epoch: 1/2, step 5005/107898 completed (loss: 0.2107435017824173, acc: 1.0)
[2025-01-30 02:19:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5007/107898 [27:11<9:18:16,  3.07it/s][2025-01-30 02:19:21][root][INFO] - Training Epoch: 1/2, step 5006/107898 completed (loss: 1.78053879737854, acc: 0.6666666865348816)
[2025-01-30 02:19:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5008/107898 [27:11<9:27:20,  3.02it/s][2025-01-30 02:19:21][root][INFO] - Training Epoch: 1/2, step 5007/107898 completed (loss: 1.2887543439865112, acc: 0.8095238208770752)
[2025-01-30 02:19:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5009/107898 [27:12<9:36:41,  2.97it/s][2025-01-30 02:19:22][root][INFO] - Training Epoch: 1/2, step 5008/107898 completed (loss: 1.108502984046936, acc: 0.7407407164573669)
[2025-01-30 02:19:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5010/107898 [27:12<9:43:12,  2.94it/s][2025-01-30 02:19:22][root][INFO] - Training Epoch: 1/2, step 5009/107898 completed (loss: 1.0426162481307983, acc: 0.8125)
[2025-01-30 02:19:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5011/107898 [27:13<9:33:01,  2.99it/s][2025-01-30 02:19:22][root][INFO] - Training Epoch: 1/2, step 5010/107898 completed (loss: 1.076436161994934, acc: 0.6000000238418579)
[2025-01-30 02:19:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5012/107898 [27:13<9:17:39,  3.07it/s][2025-01-30 02:19:23][root][INFO] - Training Epoch: 1/2, step 5011/107898 completed (loss: 0.4735017418861389, acc: 0.8888888955116272)
[2025-01-30 02:19:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5013/107898 [27:13<9:30:14,  3.01it/s][2025-01-30 02:19:23][root][INFO] - Training Epoch: 1/2, step 5012/107898 completed (loss: 0.04408649727702141, acc: 1.0)
[2025-01-30 02:19:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5014/107898 [27:14<9:52:19,  2.89it/s][2025-01-30 02:19:23][root][INFO] - Training Epoch: 1/2, step 5013/107898 completed (loss: 1.020292043685913, acc: 0.6666666865348816)
[2025-01-30 02:19:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5015/107898 [27:14<9:50:31,  2.90it/s][2025-01-30 02:19:24][root][INFO] - Training Epoch: 1/2, step 5014/107898 completed (loss: 1.5861907005310059, acc: 0.8333333134651184)
[2025-01-30 02:19:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5016/107898 [27:14<9:44:59,  2.93it/s][2025-01-30 02:19:24][root][INFO] - Training Epoch: 1/2, step 5015/107898 completed (loss: 1.246596097946167, acc: 0.7777777910232544)
[2025-01-30 02:19:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5017/107898 [27:15<9:54:44,  2.88it/s][2025-01-30 02:19:24][root][INFO] - Training Epoch: 1/2, step 5016/107898 completed (loss: 0.14806661009788513, acc: 1.0)
[2025-01-30 02:19:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5018/107898 [27:15<9:49:55,  2.91it/s][2025-01-30 02:19:25][root][INFO] - Training Epoch: 1/2, step 5017/107898 completed (loss: 0.6342632174491882, acc: 1.0)
[2025-01-30 02:19:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5019/107898 [27:15<9:31:16,  3.00it/s][2025-01-30 02:19:25][root][INFO] - Training Epoch: 1/2, step 5018/107898 completed (loss: 0.015775049105286598, acc: 1.0)
[2025-01-30 02:19:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5020/107898 [27:16<9:16:48,  3.08it/s][2025-01-30 02:19:25][root][INFO] - Training Epoch: 1/2, step 5019/107898 completed (loss: 0.07971832156181335, acc: 1.0)
[2025-01-30 02:19:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5021/107898 [27:16<9:12:35,  3.10it/s][2025-01-30 02:19:26][root][INFO] - Training Epoch: 1/2, step 5020/107898 completed (loss: 0.004504494369029999, acc: 1.0)
[2025-01-30 02:19:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5022/107898 [27:16<9:18:39,  3.07it/s][2025-01-30 02:19:26][root][INFO] - Training Epoch: 1/2, step 5021/107898 completed (loss: 0.9189247488975525, acc: 0.6666666865348816)
[2025-01-30 02:19:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5023/107898 [27:16<9:13:39,  3.10it/s][2025-01-30 02:19:26][root][INFO] - Training Epoch: 1/2, step 5022/107898 completed (loss: 0.6719696521759033, acc: 0.7272727489471436)
[2025-01-30 02:19:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5024/107898 [27:17<8:46:12,  3.26it/s][2025-01-30 02:19:27][root][INFO] - Training Epoch: 1/2, step 5023/107898 completed (loss: 3.4729511737823486, acc: 0.30000001192092896)
[2025-01-30 02:19:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5025/107898 [27:17<8:49:37,  3.24it/s][2025-01-30 02:19:27][root][INFO] - Training Epoch: 1/2, step 5024/107898 completed (loss: 2.1763644218444824, acc: 0.6086956262588501)
[2025-01-30 02:19:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5026/107898 [27:17<8:52:49,  3.22it/s][2025-01-30 02:19:27][root][INFO] - Training Epoch: 1/2, step 5025/107898 completed (loss: 1.5025222301483154, acc: 0.625)
[2025-01-30 02:19:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5027/107898 [27:18<9:10:56,  3.11it/s][2025-01-30 02:19:28][root][INFO] - Training Epoch: 1/2, step 5026/107898 completed (loss: 0.00331227108836174, acc: 1.0)
[2025-01-30 02:19:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5028/107898 [27:18<9:06:28,  3.14it/s][2025-01-30 02:19:28][root][INFO] - Training Epoch: 1/2, step 5027/107898 completed (loss: 1.073279857635498, acc: 0.9230769276618958)
[2025-01-30 02:19:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5029/107898 [27:18<8:59:03,  3.18it/s][2025-01-30 02:19:28][root][INFO] - Training Epoch: 1/2, step 5028/107898 completed (loss: 0.6955935955047607, acc: 0.8421052694320679)
[2025-01-30 02:19:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5030/107898 [27:19<8:53:57,  3.21it/s][2025-01-30 02:19:28][root][INFO] - Training Epoch: 1/2, step 5029/107898 completed (loss: 0.27127689123153687, acc: 1.0)
[2025-01-30 02:19:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5031/107898 [27:19<8:53:39,  3.21it/s][2025-01-30 02:19:29][root][INFO] - Training Epoch: 1/2, step 5030/107898 completed (loss: 2.1998260021209717, acc: 0.7142857313156128)
[2025-01-30 02:19:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5032/107898 [27:19<8:33:13,  3.34it/s][2025-01-30 02:19:29][root][INFO] - Training Epoch: 1/2, step 5031/107898 completed (loss: 0.0023691647220402956, acc: 1.0)
[2025-01-30 02:19:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5033/107898 [27:20<8:41:40,  3.29it/s][2025-01-30 02:19:29][root][INFO] - Training Epoch: 1/2, step 5032/107898 completed (loss: 1.7701958417892456, acc: 0.6363636255264282)
[2025-01-30 02:19:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5034/107898 [27:20<8:39:58,  3.30it/s][2025-01-30 02:19:30][root][INFO] - Training Epoch: 1/2, step 5033/107898 completed (loss: 0.7781828045845032, acc: 0.7272727489471436)
[2025-01-30 02:19:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5035/107898 [27:20<8:53:49,  3.21it/s][2025-01-30 02:19:30][root][INFO] - Training Epoch: 1/2, step 5034/107898 completed (loss: 1.0172368288040161, acc: 0.7692307829856873)
[2025-01-30 02:19:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5036/107898 [27:21<9:30:15,  3.01it/s][2025-01-30 02:19:30][root][INFO] - Training Epoch: 1/2, step 5035/107898 completed (loss: 0.9571966528892517, acc: 0.6666666865348816)
[2025-01-30 02:19:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5037/107898 [27:21<9:10:26,  3.11it/s][2025-01-30 02:19:31][root][INFO] - Training Epoch: 1/2, step 5036/107898 completed (loss: 0.11348161101341248, acc: 1.0)
[2025-01-30 02:19:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5038/107898 [27:21<9:36:08,  2.98it/s][2025-01-30 02:19:31][root][INFO] - Training Epoch: 1/2, step 5037/107898 completed (loss: 0.3868147134780884, acc: 0.9024389982223511)
[2025-01-30 02:19:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5039/107898 [27:22<9:25:09,  3.03it/s][2025-01-30 02:19:31][root][INFO] - Training Epoch: 1/2, step 5038/107898 completed (loss: 0.7979924082756042, acc: 0.7333333492279053)
[2025-01-30 02:19:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5040/107898 [27:22<9:30:50,  3.00it/s][2025-01-30 02:19:32][root][INFO] - Training Epoch: 1/2, step 5039/107898 completed (loss: 0.44759735465049744, acc: 0.6666666865348816)
[2025-01-30 02:19:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5041/107898 [27:22<9:45:28,  2.93it/s][2025-01-30 02:19:32][root][INFO] - Training Epoch: 1/2, step 5040/107898 completed (loss: 0.004757670219987631, acc: 1.0)
[2025-01-30 02:19:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5042/107898 [27:23<10:05:47,  2.83it/s][2025-01-30 02:19:32][root][INFO] - Training Epoch: 1/2, step 5041/107898 completed (loss: 2.803117275238037, acc: 0.3571428656578064)
[2025-01-30 02:19:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5043/107898 [27:23<9:51:51,  2.90it/s] [2025-01-30 02:19:33][root][INFO] - Training Epoch: 1/2, step 5042/107898 completed (loss: 0.01311212033033371, acc: 1.0)
[2025-01-30 02:19:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5044/107898 [27:23<9:43:02,  2.94it/s][2025-01-30 02:19:33][root][INFO] - Training Epoch: 1/2, step 5043/107898 completed (loss: 0.9030675888061523, acc: 0.7777777910232544)
[2025-01-30 02:19:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5045/107898 [27:24<9:28:41,  3.01it/s][2025-01-30 02:19:33][root][INFO] - Training Epoch: 1/2, step 5044/107898 completed (loss: 0.8059291839599609, acc: 0.7777777910232544)
[2025-01-30 02:19:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5046/107898 [27:24<9:20:30,  3.06it/s][2025-01-30 02:19:34][root][INFO] - Training Epoch: 1/2, step 5045/107898 completed (loss: 0.06966770440340042, acc: 1.0)
[2025-01-30 02:19:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5047/107898 [27:24<9:12:19,  3.10it/s][2025-01-30 02:19:34][root][INFO] - Training Epoch: 1/2, step 5046/107898 completed (loss: 2.6356239318847656, acc: 0.5)
[2025-01-30 02:19:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5048/107898 [27:25<9:01:56,  3.16it/s][2025-01-30 02:19:34][root][INFO] - Training Epoch: 1/2, step 5047/107898 completed (loss: 0.005896699149161577, acc: 1.0)
[2025-01-30 02:19:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5049/107898 [27:25<8:53:34,  3.21it/s][2025-01-30 02:19:35][root][INFO] - Training Epoch: 1/2, step 5048/107898 completed (loss: 1.9977346658706665, acc: 0.7037037014961243)
[2025-01-30 02:19:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5050/107898 [27:25<9:07:19,  3.13it/s][2025-01-30 02:19:35][root][INFO] - Training Epoch: 1/2, step 5049/107898 completed (loss: 0.9571760296821594, acc: 0.6875)
[2025-01-30 02:19:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5051/107898 [27:25<9:14:29,  3.09it/s][2025-01-30 02:19:35][root][INFO] - Training Epoch: 1/2, step 5050/107898 completed (loss: 0.05991809070110321, acc: 1.0)
[2025-01-30 02:19:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5052/107898 [27:26<9:23:09,  3.04it/s][2025-01-30 02:19:36][root][INFO] - Training Epoch: 1/2, step 5051/107898 completed (loss: 0.7160670757293701, acc: 0.8636363744735718)
[2025-01-30 02:19:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5053/107898 [27:26<9:11:03,  3.11it/s][2025-01-30 02:19:36][root][INFO] - Training Epoch: 1/2, step 5052/107898 completed (loss: 3.6048460006713867, acc: 0.2380952388048172)
[2025-01-30 02:19:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5054/107898 [27:26<9:26:02,  3.03it/s][2025-01-30 02:19:36][root][INFO] - Training Epoch: 1/2, step 5053/107898 completed (loss: 0.12300507724285126, acc: 1.0)
[2025-01-30 02:19:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5055/107898 [27:27<9:32:48,  2.99it/s][2025-01-30 02:19:37][root][INFO] - Training Epoch: 1/2, step 5054/107898 completed (loss: 1.854589819908142, acc: 0.6000000238418579)
[2025-01-30 02:19:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5056/107898 [27:27<9:32:08,  3.00it/s][2025-01-30 02:19:37][root][INFO] - Training Epoch: 1/2, step 5055/107898 completed (loss: 0.002924978267401457, acc: 1.0)
[2025-01-30 02:19:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5057/107898 [27:27<9:20:27,  3.06it/s][2025-01-30 02:19:37][root][INFO] - Training Epoch: 1/2, step 5056/107898 completed (loss: 2.966294527053833, acc: 0.4375)
[2025-01-30 02:19:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5058/107898 [27:28<9:26:06,  3.03it/s][2025-01-30 02:19:38][root][INFO] - Training Epoch: 1/2, step 5057/107898 completed (loss: 0.3998397886753082, acc: 0.8333333134651184)
[2025-01-30 02:19:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5059/107898 [27:28<9:39:12,  2.96it/s][2025-01-30 02:19:38][root][INFO] - Training Epoch: 1/2, step 5058/107898 completed (loss: 1.088830828666687, acc: 0.8125)
[2025-01-30 02:19:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5060/107898 [27:29<9:39:08,  2.96it/s][2025-01-30 02:19:38][root][INFO] - Training Epoch: 1/2, step 5059/107898 completed (loss: 0.7723140716552734, acc: 0.7142857313156128)
[2025-01-30 02:19:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5061/107898 [27:29<9:34:39,  2.98it/s][2025-01-30 02:19:39][root][INFO] - Training Epoch: 1/2, step 5060/107898 completed (loss: 0.40822920203208923, acc: 0.875)
[2025-01-30 02:19:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5062/107898 [27:29<9:23:07,  3.04it/s][2025-01-30 02:19:39][root][INFO] - Training Epoch: 1/2, step 5061/107898 completed (loss: 0.6092773079872131, acc: 0.7142857313156128)
[2025-01-30 02:19:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5063/107898 [27:29<9:28:41,  3.01it/s][2025-01-30 02:19:39][root][INFO] - Training Epoch: 1/2, step 5062/107898 completed (loss: 0.6132325530052185, acc: 0.8333333134651184)
[2025-01-30 02:19:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5064/107898 [27:30<9:34:28,  2.98it/s][2025-01-30 02:19:40][root][INFO] - Training Epoch: 1/2, step 5063/107898 completed (loss: 0.09072095155715942, acc: 1.0)
[2025-01-30 02:19:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5065/107898 [27:30<9:23:05,  3.04it/s][2025-01-30 02:19:40][root][INFO] - Training Epoch: 1/2, step 5064/107898 completed (loss: 0.0428776741027832, acc: 1.0)
[2025-01-30 02:19:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5066/107898 [27:30<9:06:56,  3.13it/s][2025-01-30 02:19:40][root][INFO] - Training Epoch: 1/2, step 5065/107898 completed (loss: 1.0909823179244995, acc: 0.699999988079071)
[2025-01-30 02:19:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5067/107898 [27:31<9:00:48,  3.17it/s][2025-01-30 02:19:41][root][INFO] - Training Epoch: 1/2, step 5066/107898 completed (loss: 0.9040231704711914, acc: 0.7142857313156128)
[2025-01-30 02:19:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5068/107898 [27:31<8:57:04,  3.19it/s][2025-01-30 02:19:41][root][INFO] - Training Epoch: 1/2, step 5067/107898 completed (loss: 0.1290213167667389, acc: 1.0)
[2025-01-30 02:19:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5069/107898 [27:31<8:51:34,  3.22it/s][2025-01-30 02:19:41][root][INFO] - Training Epoch: 1/2, step 5068/107898 completed (loss: 0.14761243760585785, acc: 0.9285714030265808)
[2025-01-30 02:19:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5070/107898 [27:32<8:43:09,  3.28it/s][2025-01-30 02:19:41][root][INFO] - Training Epoch: 1/2, step 5069/107898 completed (loss: 2.530261516571045, acc: 0.0)
[2025-01-30 02:19:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5071/107898 [27:32<8:43:05,  3.28it/s][2025-01-30 02:19:42][root][INFO] - Training Epoch: 1/2, step 5070/107898 completed (loss: 0.0018123517511412501, acc: 1.0)
[2025-01-30 02:19:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5072/107898 [27:32<8:46:34,  3.25it/s][2025-01-30 02:19:42][root][INFO] - Training Epoch: 1/2, step 5071/107898 completed (loss: 0.5255239605903625, acc: 0.8571428656578064)
[2025-01-30 02:19:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5073/107898 [27:33<8:36:58,  3.31it/s][2025-01-30 02:19:42][root][INFO] - Training Epoch: 1/2, step 5072/107898 completed (loss: 0.18550705909729004, acc: 0.8823529481887817)
[2025-01-30 02:19:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5074/107898 [27:33<8:57:25,  3.19it/s][2025-01-30 02:19:43][root][INFO] - Training Epoch: 1/2, step 5073/107898 completed (loss: 0.17440985143184662, acc: 1.0)
[2025-01-30 02:19:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5075/107898 [27:33<9:21:07,  3.05it/s][2025-01-30 02:19:43][root][INFO] - Training Epoch: 1/2, step 5074/107898 completed (loss: 0.1149660125374794, acc: 1.0)
[2025-01-30 02:19:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5076/107898 [27:34<9:47:16,  2.92it/s][2025-01-30 02:19:43][root][INFO] - Training Epoch: 1/2, step 5075/107898 completed (loss: 1.952747106552124, acc: 0.3333333432674408)
[2025-01-30 02:19:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5077/107898 [27:34<9:51:05,  2.90it/s][2025-01-30 02:19:44][root][INFO] - Training Epoch: 1/2, step 5076/107898 completed (loss: 0.8543310165405273, acc: 0.6666666865348816)
[2025-01-30 02:19:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5078/107898 [27:34<9:52:02,  2.89it/s][2025-01-30 02:19:44][root][INFO] - Training Epoch: 1/2, step 5077/107898 completed (loss: 0.6392882466316223, acc: 0.875)
[2025-01-30 02:19:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5079/107898 [27:35<9:30:08,  3.01it/s][2025-01-30 02:19:44][root][INFO] - Training Epoch: 1/2, step 5078/107898 completed (loss: 0.25878939032554626, acc: 1.0)
[2025-01-30 02:19:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5080/107898 [27:35<9:44:21,  2.93it/s][2025-01-30 02:19:45][root][INFO] - Training Epoch: 1/2, step 5079/107898 completed (loss: 1.5124315023422241, acc: 0.8571428656578064)
[2025-01-30 02:19:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5081/107898 [27:35<9:43:59,  2.93it/s][2025-01-30 02:19:45][root][INFO] - Training Epoch: 1/2, step 5080/107898 completed (loss: 0.22397272288799286, acc: 1.0)
[2025-01-30 02:19:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5082/107898 [27:36<10:02:07,  2.85it/s][2025-01-30 02:19:46][root][INFO] - Training Epoch: 1/2, step 5081/107898 completed (loss: 3.3780734539031982, acc: 0.23999999463558197)
[2025-01-30 02:19:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5083/107898 [27:36<9:45:15,  2.93it/s] [2025-01-30 02:19:46][root][INFO] - Training Epoch: 1/2, step 5082/107898 completed (loss: 0.00956287607550621, acc: 1.0)
[2025-01-30 02:19:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5084/107898 [27:36<9:22:07,  3.05it/s][2025-01-30 02:19:46][root][INFO] - Training Epoch: 1/2, step 5083/107898 completed (loss: 0.04706953465938568, acc: 1.0)
[2025-01-30 02:19:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5085/107898 [27:37<9:45:45,  2.93it/s][2025-01-30 02:19:46][root][INFO] - Training Epoch: 1/2, step 5084/107898 completed (loss: 1.237610936164856, acc: 0.625)
[2025-01-30 02:19:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5086/107898 [27:37<9:42:32,  2.94it/s][2025-01-30 02:19:47][root][INFO] - Training Epoch: 1/2, step 5085/107898 completed (loss: 0.10507985949516296, acc: 1.0)
[2025-01-30 02:19:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5087/107898 [27:37<9:33:50,  2.99it/s][2025-01-30 02:19:47][root][INFO] - Training Epoch: 1/2, step 5086/107898 completed (loss: 0.551633358001709, acc: 0.8999999761581421)
[2025-01-30 02:19:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5088/107898 [27:38<9:14:55,  3.09it/s][2025-01-30 02:19:47][root][INFO] - Training Epoch: 1/2, step 5087/107898 completed (loss: 0.5435076951980591, acc: 0.8823529481887817)
[2025-01-30 02:19:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5089/107898 [27:38<8:59:38,  3.18it/s][2025-01-30 02:19:48][root][INFO] - Training Epoch: 1/2, step 5088/107898 completed (loss: 0.0051208436489105225, acc: 1.0)
[2025-01-30 02:19:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5090/107898 [27:38<8:50:08,  3.23it/s][2025-01-30 02:19:48][root][INFO] - Training Epoch: 1/2, step 5089/107898 completed (loss: 1.3736218214035034, acc: 0.6666666865348816)
[2025-01-30 02:19:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5091/107898 [27:39<8:52:09,  3.22it/s][2025-01-30 02:19:48][root][INFO] - Training Epoch: 1/2, step 5090/107898 completed (loss: 0.009153190068900585, acc: 1.0)
[2025-01-30 02:19:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5092/107898 [27:39<9:09:18,  3.12it/s][2025-01-30 02:19:49][root][INFO] - Training Epoch: 1/2, step 5091/107898 completed (loss: 0.5772222876548767, acc: 0.8399999737739563)
[2025-01-30 02:19:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5093/107898 [27:39<9:25:34,  3.03it/s][2025-01-30 02:19:49][root][INFO] - Training Epoch: 1/2, step 5092/107898 completed (loss: 0.10757765918970108, acc: 1.0)
[2025-01-30 02:19:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5094/107898 [27:40<9:22:27,  3.05it/s][2025-01-30 02:19:49][root][INFO] - Training Epoch: 1/2, step 5093/107898 completed (loss: 1.2153956890106201, acc: 0.8235294222831726)
[2025-01-30 02:19:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5095/107898 [27:40<9:15:25,  3.08it/s][2025-01-30 02:19:50][root][INFO] - Training Epoch: 1/2, step 5094/107898 completed (loss: 0.15071941912174225, acc: 0.949999988079071)
[2025-01-30 02:19:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5096/107898 [27:40<9:20:51,  3.05it/s][2025-01-30 02:19:50][root][INFO] - Training Epoch: 1/2, step 5095/107898 completed (loss: 0.10832154750823975, acc: 1.0)
[2025-01-30 02:19:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5097/107898 [27:41<9:18:30,  3.07it/s][2025-01-30 02:19:50][root][INFO] - Training Epoch: 1/2, step 5096/107898 completed (loss: 4.485846519470215, acc: 0.25)
[2025-01-30 02:19:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5098/107898 [27:41<9:12:24,  3.10it/s][2025-01-30 02:19:51][root][INFO] - Training Epoch: 1/2, step 5097/107898 completed (loss: 4.036314964294434, acc: 0.6000000238418579)
[2025-01-30 02:19:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5099/107898 [27:41<9:01:00,  3.17it/s][2025-01-30 02:19:51][root][INFO] - Training Epoch: 1/2, step 5098/107898 completed (loss: 0.9493032097816467, acc: 0.6666666865348816)
[2025-01-30 02:19:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5100/107898 [27:41<8:56:30,  3.19it/s][2025-01-30 02:19:51][root][INFO] - Training Epoch: 1/2, step 5099/107898 completed (loss: 1.5978807210922241, acc: 0.7777777910232544)
[2025-01-30 02:19:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5101/107898 [27:42<9:17:10,  3.07it/s][2025-01-30 02:19:52][root][INFO] - Training Epoch: 1/2, step 5100/107898 completed (loss: 0.7425696849822998, acc: 0.9090909361839294)
[2025-01-30 02:19:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5102/107898 [27:42<9:26:46,  3.02it/s][2025-01-30 02:19:52][root][INFO] - Training Epoch: 1/2, step 5101/107898 completed (loss: 0.2517523169517517, acc: 0.9090909361839294)
[2025-01-30 02:19:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5103/107898 [27:42<9:21:17,  3.05it/s][2025-01-30 02:19:52][root][INFO] - Training Epoch: 1/2, step 5102/107898 completed (loss: 0.16192159056663513, acc: 0.96875)
[2025-01-30 02:19:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5104/107898 [27:43<9:14:11,  3.09it/s][2025-01-30 02:19:53][root][INFO] - Training Epoch: 1/2, step 5103/107898 completed (loss: 0.014765325002372265, acc: 1.0)
[2025-01-30 02:19:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5105/107898 [27:43<8:59:26,  3.18it/s][2025-01-30 02:19:53][root][INFO] - Training Epoch: 1/2, step 5104/107898 completed (loss: 0.007035786285996437, acc: 1.0)
[2025-01-30 02:19:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5106/107898 [27:43<8:53:07,  3.21it/s][2025-01-30 02:19:53][root][INFO] - Training Epoch: 1/2, step 5105/107898 completed (loss: 1.3839237689971924, acc: 0.7272727489471436)
[2025-01-30 02:19:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5107/107898 [27:44<8:47:38,  3.25it/s][2025-01-30 02:19:53][root][INFO] - Training Epoch: 1/2, step 5106/107898 completed (loss: 0.4188711643218994, acc: 0.6666666865348816)
[2025-01-30 02:19:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5108/107898 [27:44<8:56:47,  3.19it/s][2025-01-30 02:19:54][root][INFO] - Training Epoch: 1/2, step 5107/107898 completed (loss: 0.3566669523715973, acc: 0.9523809552192688)
[2025-01-30 02:19:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5109/107898 [27:44<9:03:02,  3.15it/s][2025-01-30 02:19:54][root][INFO] - Training Epoch: 1/2, step 5108/107898 completed (loss: 0.359255850315094, acc: 0.9411764740943909)
[2025-01-30 02:19:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5110/107898 [27:45<9:11:11,  3.11it/s][2025-01-30 02:19:54][root][INFO] - Training Epoch: 1/2, step 5109/107898 completed (loss: 4.833166122436523, acc: 0.3333333432674408)
[2025-01-30 02:19:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5111/107898 [27:45<9:16:55,  3.08it/s][2025-01-30 02:19:55][root][INFO] - Training Epoch: 1/2, step 5110/107898 completed (loss: 3.9029412269592285, acc: 0.26923078298568726)
[2025-01-30 02:19:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5112/107898 [27:45<9:43:47,  2.93it/s][2025-01-30 02:19:55][root][INFO] - Training Epoch: 1/2, step 5111/107898 completed (loss: 0.0009992012055590749, acc: 1.0)
[2025-01-30 02:19:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5113/107898 [27:46<9:35:08,  2.98it/s][2025-01-30 02:19:56][root][INFO] - Training Epoch: 1/2, step 5112/107898 completed (loss: 1.1388118267059326, acc: 0.6666666865348816)
[2025-01-30 02:19:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5114/107898 [27:46<9:26:53,  3.02it/s][2025-01-30 02:19:56][root][INFO] - Training Epoch: 1/2, step 5113/107898 completed (loss: 0.6968029141426086, acc: 0.7857142686843872)
[2025-01-30 02:19:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5115/107898 [27:46<9:14:51,  3.09it/s][2025-01-30 02:19:56][root][INFO] - Training Epoch: 1/2, step 5114/107898 completed (loss: 0.40741580724716187, acc: 0.8999999761581421)
[2025-01-30 02:19:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5116/107898 [27:47<9:10:33,  3.11it/s][2025-01-30 02:19:56][root][INFO] - Training Epoch: 1/2, step 5115/107898 completed (loss: 1.0984846353530884, acc: 0.7916666865348816)
[2025-01-30 02:19:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5117/107898 [27:47<9:20:17,  3.06it/s][2025-01-30 02:19:57][root][INFO] - Training Epoch: 1/2, step 5116/107898 completed (loss: 0.9031679034233093, acc: 0.0)
[2025-01-30 02:19:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5118/107898 [27:47<9:05:36,  3.14it/s][2025-01-30 02:19:57][root][INFO] - Training Epoch: 1/2, step 5117/107898 completed (loss: 2.4347658157348633, acc: 0.5)
[2025-01-30 02:19:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5119/107898 [27:48<8:57:40,  3.19it/s][2025-01-30 02:19:57][root][INFO] - Training Epoch: 1/2, step 5118/107898 completed (loss: 0.35137277841567993, acc: 1.0)
[2025-01-30 02:19:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5120/107898 [27:48<9:09:49,  3.12it/s][2025-01-30 02:19:58][root][INFO] - Training Epoch: 1/2, step 5119/107898 completed (loss: 0.36691978573799133, acc: 0.8571428656578064)
[2025-01-30 02:19:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5121/107898 [27:48<9:19:21,  3.06it/s][2025-01-30 02:19:58][root][INFO] - Training Epoch: 1/2, step 5120/107898 completed (loss: 3.2326223850250244, acc: 0.4285714328289032)
[2025-01-30 02:19:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5122/107898 [27:49<9:06:10,  3.14it/s][2025-01-30 02:19:58][root][INFO] - Training Epoch: 1/2, step 5121/107898 completed (loss: 4.485489845275879, acc: 0.1111111119389534)
[2025-01-30 02:19:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5123/107898 [27:49<9:19:11,  3.06it/s][2025-01-30 02:19:59][root][INFO] - Training Epoch: 1/2, step 5122/107898 completed (loss: 0.9260726571083069, acc: 0.6666666865348816)
[2025-01-30 02:19:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5124/107898 [27:49<9:21:29,  3.05it/s][2025-01-30 02:19:59][root][INFO] - Training Epoch: 1/2, step 5123/107898 completed (loss: 1.9392105340957642, acc: 0.6666666865348816)
[2025-01-30 02:19:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5125/107898 [27:50<9:34:22,  2.98it/s][2025-01-30 02:19:59][root][INFO] - Training Epoch: 1/2, step 5124/107898 completed (loss: 0.0035359933972358704, acc: 1.0)
[2025-01-30 02:20:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5126/107898 [27:50<9:57:45,  2.87it/s][2025-01-30 02:20:00][root][INFO] - Training Epoch: 1/2, step 5125/107898 completed (loss: 4.05603551864624, acc: 0.09090909361839294)
[2025-01-30 02:20:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5127/107898 [27:50<9:43:35,  2.94it/s][2025-01-30 02:20:00][root][INFO] - Training Epoch: 1/2, step 5126/107898 completed (loss: 0.9288559556007385, acc: 0.6666666865348816)
[2025-01-30 02:20:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5128/107898 [27:51<9:34:34,  2.98it/s][2025-01-30 02:20:00][root][INFO] - Training Epoch: 1/2, step 5127/107898 completed (loss: 1.1852408647537231, acc: 0.5)
[2025-01-30 02:20:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5129/107898 [27:51<9:23:14,  3.04it/s][2025-01-30 02:20:01][root][INFO] - Training Epoch: 1/2, step 5128/107898 completed (loss: 0.3161914050579071, acc: 0.875)
[2025-01-30 02:20:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5130/107898 [27:51<9:13:05,  3.10it/s][2025-01-30 02:20:01][root][INFO] - Training Epoch: 1/2, step 5129/107898 completed (loss: 1.7183454036712646, acc: 0.7142857313156128)
[2025-01-30 02:20:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5131/107898 [27:52<9:07:31,  3.13it/s][2025-01-30 02:20:01][root][INFO] - Training Epoch: 1/2, step 5130/107898 completed (loss: 0.9841904640197754, acc: 0.6666666865348816)
[2025-01-30 02:20:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5132/107898 [27:52<8:59:31,  3.17it/s][2025-01-30 02:20:02][root][INFO] - Training Epoch: 1/2, step 5131/107898 completed (loss: 0.31281915307044983, acc: 0.9285714030265808)
[2025-01-30 02:20:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5133/107898 [27:52<8:54:16,  3.21it/s][2025-01-30 02:20:02][root][INFO] - Training Epoch: 1/2, step 5132/107898 completed (loss: 0.2914918065071106, acc: 1.0)
[2025-01-30 02:20:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5134/107898 [27:53<9:18:07,  3.07it/s][2025-01-30 02:20:02][root][INFO] - Training Epoch: 1/2, step 5133/107898 completed (loss: 2.25871205329895, acc: 0.7142857313156128)
[2025-01-30 02:20:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5135/107898 [27:53<9:23:07,  3.04it/s][2025-01-30 02:20:03][root][INFO] - Training Epoch: 1/2, step 5134/107898 completed (loss: 1.9842424392700195, acc: 0.4000000059604645)
[2025-01-30 02:20:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5136/107898 [27:53<9:44:42,  2.93it/s][2025-01-30 02:20:03][root][INFO] - Training Epoch: 1/2, step 5135/107898 completed (loss: 1.293379306793213, acc: 0.7200000286102295)
[2025-01-30 02:20:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5137/107898 [27:54<9:51:15,  2.90it/s][2025-01-30 02:20:03][root][INFO] - Training Epoch: 1/2, step 5136/107898 completed (loss: 3.341930389404297, acc: 0.4285714328289032)
[2025-01-30 02:20:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5138/107898 [27:54<9:39:27,  2.96it/s][2025-01-30 02:20:04][root][INFO] - Training Epoch: 1/2, step 5137/107898 completed (loss: 0.8666512966156006, acc: 0.6666666865348816)
[2025-01-30 02:20:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5139/107898 [27:54<9:42:22,  2.94it/s][2025-01-30 02:20:04][root][INFO] - Training Epoch: 1/2, step 5138/107898 completed (loss: 0.3461437225341797, acc: 0.9166666865348816)
[2025-01-30 02:20:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5140/107898 [27:55<9:26:34,  3.02it/s][2025-01-30 02:20:04][root][INFO] - Training Epoch: 1/2, step 5139/107898 completed (loss: 1.7183208465576172, acc: 0.75)
[2025-01-30 02:20:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5141/107898 [27:55<9:14:33,  3.09it/s][2025-01-30 02:20:05][root][INFO] - Training Epoch: 1/2, step 5140/107898 completed (loss: 0.025298716500401497, acc: 1.0)
[2025-01-30 02:20:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5142/107898 [27:55<9:00:55,  3.17it/s][2025-01-30 02:20:05][root][INFO] - Training Epoch: 1/2, step 5141/107898 completed (loss: 0.04754255339503288, acc: 1.0)
[2025-01-30 02:20:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5143/107898 [27:55<8:55:55,  3.20it/s][2025-01-30 02:20:05][root][INFO] - Training Epoch: 1/2, step 5142/107898 completed (loss: 0.760749876499176, acc: 0.8461538553237915)
[2025-01-30 02:20:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5144/107898 [27:56<8:46:43,  3.25it/s][2025-01-30 02:20:06][root][INFO] - Training Epoch: 1/2, step 5143/107898 completed (loss: 0.16429467499256134, acc: 1.0)
[2025-01-30 02:20:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5145/107898 [27:56<8:41:52,  3.28it/s][2025-01-30 02:20:06][root][INFO] - Training Epoch: 1/2, step 5144/107898 completed (loss: 3.398344039916992, acc: 0.25)
[2025-01-30 02:20:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5146/107898 [27:56<8:48:26,  3.24it/s][2025-01-30 02:20:06][root][INFO] - Training Epoch: 1/2, step 5145/107898 completed (loss: 3.710829496383667, acc: 0.25)
[2025-01-30 02:20:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5147/107898 [27:57<8:47:32,  3.25it/s][2025-01-30 02:20:06][root][INFO] - Training Epoch: 1/2, step 5146/107898 completed (loss: 0.301540344953537, acc: 0.6666666865348816)
[2025-01-30 02:20:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5148/107898 [27:57<8:44:59,  3.26it/s][2025-01-30 02:20:07][root][INFO] - Training Epoch: 1/2, step 5147/107898 completed (loss: 1.324364423751831, acc: 0.5)
[2025-01-30 02:20:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5149/107898 [27:57<8:47:39,  3.25it/s][2025-01-30 02:20:07][root][INFO] - Training Epoch: 1/2, step 5148/107898 completed (loss: 0.5403987765312195, acc: 1.0)
[2025-01-30 02:20:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5150/107898 [27:58<9:08:19,  3.12it/s][2025-01-30 02:20:07][root][INFO] - Training Epoch: 1/2, step 5149/107898 completed (loss: 0.040158964693546295, acc: 1.0)
[2025-01-30 02:20:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5151/107898 [27:58<9:15:44,  3.08it/s][2025-01-30 02:20:08][root][INFO] - Training Epoch: 1/2, step 5150/107898 completed (loss: 0.4401296377182007, acc: 0.9473684430122375)
[2025-01-30 02:20:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5152/107898 [27:58<9:27:26,  3.02it/s][2025-01-30 02:20:08][root][INFO] - Training Epoch: 1/2, step 5151/107898 completed (loss: 0.7034538984298706, acc: 0.800000011920929)
[2025-01-30 02:20:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5153/107898 [27:59<9:19:03,  3.06it/s][2025-01-30 02:20:08][root][INFO] - Training Epoch: 1/2, step 5152/107898 completed (loss: 1.2967392206192017, acc: 0.699999988079071)
[2025-01-30 02:20:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5154/107898 [27:59<9:12:11,  3.10it/s][2025-01-30 02:20:09][root][INFO] - Training Epoch: 1/2, step 5153/107898 completed (loss: 1.8878754377365112, acc: 0.6875)
[2025-01-30 02:20:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5155/107898 [27:59<9:26:14,  3.02it/s][2025-01-30 02:20:09][root][INFO] - Training Epoch: 1/2, step 5154/107898 completed (loss: 0.03326638787984848, acc: 1.0)
[2025-01-30 02:20:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5156/107898 [28:00<9:30:44,  3.00it/s][2025-01-30 02:20:09][root][INFO] - Training Epoch: 1/2, step 5155/107898 completed (loss: 0.45721694827079773, acc: 0.9333333373069763)
[2025-01-30 02:20:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5157/107898 [28:00<9:17:53,  3.07it/s][2025-01-30 02:20:10][root][INFO] - Training Epoch: 1/2, step 5156/107898 completed (loss: 1.5652869939804077, acc: 0.6363636255264282)
[2025-01-30 02:20:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5158/107898 [28:00<9:35:18,  2.98it/s][2025-01-30 02:20:10][root][INFO] - Training Epoch: 1/2, step 5157/107898 completed (loss: 1.4686485528945923, acc: 0.699999988079071)
[2025-01-30 02:20:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5159/107898 [28:01<9:34:11,  2.98it/s][2025-01-30 02:20:10][root][INFO] - Training Epoch: 1/2, step 5158/107898 completed (loss: 0.07655607163906097, acc: 1.0)
[2025-01-30 02:20:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5160/107898 [28:01<9:35:00,  2.98it/s][2025-01-30 02:20:11][root][INFO] - Training Epoch: 1/2, step 5159/107898 completed (loss: 0.2525070607662201, acc: 0.96875)
[2025-01-30 02:20:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5161/107898 [28:01<9:21:35,  3.05it/s][2025-01-30 02:20:11][root][INFO] - Training Epoch: 1/2, step 5160/107898 completed (loss: 1.0544662475585938, acc: 0.7777777910232544)
[2025-01-30 02:20:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5162/107898 [28:02<9:01:00,  3.16it/s][2025-01-30 02:20:11][root][INFO] - Training Epoch: 1/2, step 5161/107898 completed (loss: 0.15547610819339752, acc: 1.0)
[2025-01-30 02:20:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5163/107898 [28:02<8:54:47,  3.20it/s][2025-01-30 02:20:12][root][INFO] - Training Epoch: 1/2, step 5162/107898 completed (loss: 0.3823680579662323, acc: 0.8888888955116272)
[2025-01-30 02:20:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5164/107898 [28:02<8:49:55,  3.23it/s][2025-01-30 02:20:12][root][INFO] - Training Epoch: 1/2, step 5163/107898 completed (loss: 0.12087823450565338, acc: 1.0)
[2025-01-30 02:20:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5165/107898 [28:03<8:57:34,  3.19it/s][2025-01-30 02:20:12][root][INFO] - Training Epoch: 1/2, step 5164/107898 completed (loss: 1.6918469667434692, acc: 0.7200000286102295)
[2025-01-30 02:20:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5166/107898 [28:03<8:49:26,  3.23it/s][2025-01-30 02:20:13][root][INFO] - Training Epoch: 1/2, step 5165/107898 completed (loss: 0.0026698317378759384, acc: 1.0)
[2025-01-30 02:20:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5167/107898 [28:03<8:44:01,  3.27it/s][2025-01-30 02:20:13][root][INFO] - Training Epoch: 1/2, step 5166/107898 completed (loss: 0.3136700987815857, acc: 1.0)
[2025-01-30 02:20:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5168/107898 [28:03<8:58:16,  3.18it/s][2025-01-30 02:20:13][root][INFO] - Training Epoch: 1/2, step 5167/107898 completed (loss: 0.7485073208808899, acc: 0.875)
[2025-01-30 02:20:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5169/107898 [28:04<8:56:17,  3.19it/s][2025-01-30 02:20:14][root][INFO] - Training Epoch: 1/2, step 5168/107898 completed (loss: 0.011480108834803104, acc: 1.0)
[2025-01-30 02:20:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5170/107898 [28:04<8:58:17,  3.18it/s][2025-01-30 02:20:14][root][INFO] - Training Epoch: 1/2, step 5169/107898 completed (loss: 0.003970737103372812, acc: 1.0)
[2025-01-30 02:20:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5171/107898 [28:04<9:09:37,  3.12it/s][2025-01-30 02:20:14][root][INFO] - Training Epoch: 1/2, step 5170/107898 completed (loss: 0.10453204810619354, acc: 1.0)
[2025-01-30 02:20:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5172/107898 [28:05<9:05:54,  3.14it/s][2025-01-30 02:20:15][root][INFO] - Training Epoch: 1/2, step 5171/107898 completed (loss: 0.12536020576953888, acc: 1.0)
[2025-01-30 02:20:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5173/107898 [28:05<8:50:49,  3.23it/s][2025-01-30 02:20:15][root][INFO] - Training Epoch: 1/2, step 5172/107898 completed (loss: 0.17327697575092316, acc: 1.0)
[2025-01-30 02:20:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5174/107898 [28:05<9:10:10,  3.11it/s][2025-01-30 02:20:15][root][INFO] - Training Epoch: 1/2, step 5173/107898 completed (loss: 0.06654053181409836, acc: 1.0)
[2025-01-30 02:20:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5175/107898 [28:06<9:10:56,  3.11it/s][2025-01-30 02:20:15][root][INFO] - Training Epoch: 1/2, step 5174/107898 completed (loss: 0.010332007892429829, acc: 1.0)
[2025-01-30 02:20:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5176/107898 [28:06<9:16:27,  3.08it/s][2025-01-30 02:20:16][root][INFO] - Training Epoch: 1/2, step 5175/107898 completed (loss: 3.5492844581604004, acc: 0.30000001192092896)
[2025-01-30 02:20:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5177/107898 [28:06<9:15:53,  3.08it/s][2025-01-30 02:20:16][root][INFO] - Training Epoch: 1/2, step 5176/107898 completed (loss: 0.013379139825701714, acc: 1.0)
[2025-01-30 02:20:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5178/107898 [28:07<9:10:41,  3.11it/s][2025-01-30 02:20:16][root][INFO] - Training Epoch: 1/2, step 5177/107898 completed (loss: 0.1260945200920105, acc: 0.9285714030265808)
[2025-01-30 02:20:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5179/107898 [28:07<9:03:58,  3.15it/s][2025-01-30 02:20:17][root][INFO] - Training Epoch: 1/2, step 5178/107898 completed (loss: 1.0031365156173706, acc: 0.75)
[2025-01-30 02:20:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5180/107898 [28:07<9:20:23,  3.05it/s][2025-01-30 02:20:17][root][INFO] - Training Epoch: 1/2, step 5179/107898 completed (loss: 4.378007888793945, acc: 0.3125)
[2025-01-30 02:20:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5181/107898 [28:08<9:25:14,  3.03it/s][2025-01-30 02:20:17][root][INFO] - Training Epoch: 1/2, step 5180/107898 completed (loss: 1.8934450149536133, acc: 0.699999988079071)
[2025-01-30 02:20:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5182/107898 [28:08<9:08:07,  3.12it/s][2025-01-30 02:20:18][root][INFO] - Training Epoch: 1/2, step 5181/107898 completed (loss: 0.09150592237710953, acc: 1.0)
[2025-01-30 02:20:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5183/107898 [28:08<8:58:28,  3.18it/s][2025-01-30 02:20:18][root][INFO] - Training Epoch: 1/2, step 5182/107898 completed (loss: 0.1239270493388176, acc: 1.0)
[2025-01-30 02:20:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5184/107898 [28:09<8:55:16,  3.20it/s][2025-01-30 02:20:18][root][INFO] - Training Epoch: 1/2, step 5183/107898 completed (loss: 1.713786005973816, acc: 0.0)
[2025-01-30 02:20:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5185/107898 [28:09<8:46:45,  3.25it/s][2025-01-30 02:20:19][root][INFO] - Training Epoch: 1/2, step 5184/107898 completed (loss: 0.03485652059316635, acc: 1.0)
[2025-01-30 02:20:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5186/107898 [28:09<8:50:13,  3.23it/s][2025-01-30 02:20:19][root][INFO] - Training Epoch: 1/2, step 5185/107898 completed (loss: 0.08231428265571594, acc: 1.0)
[2025-01-30 02:20:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5187/107898 [28:09<8:41:20,  3.28it/s][2025-01-30 02:20:19][root][INFO] - Training Epoch: 1/2, step 5186/107898 completed (loss: 0.30327120423316956, acc: 0.6666666865348816)
[2025-01-30 02:20:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5188/107898 [28:10<8:34:01,  3.33it/s][2025-01-30 02:20:20][root][INFO] - Training Epoch: 1/2, step 5187/107898 completed (loss: 0.9199144244194031, acc: 0.5)
[2025-01-30 02:20:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5189/107898 [28:10<9:20:27,  3.05it/s][2025-01-30 02:20:20][root][INFO] - Training Epoch: 1/2, step 5188/107898 completed (loss: 3.210646390914917, acc: 0.20512820780277252)
[2025-01-30 02:20:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5190/107898 [28:10<9:08:40,  3.12it/s][2025-01-30 02:20:20][root][INFO] - Training Epoch: 1/2, step 5189/107898 completed (loss: 0.7578845620155334, acc: 0.5)
[2025-01-30 02:20:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5191/107898 [28:11<9:03:23,  3.15it/s][2025-01-30 02:20:21][root][INFO] - Training Epoch: 1/2, step 5190/107898 completed (loss: 1.1508198976516724, acc: 0.7142857313156128)
[2025-01-30 02:20:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5192/107898 [28:11<9:14:33,  3.09it/s][2025-01-30 02:20:21][root][INFO] - Training Epoch: 1/2, step 5191/107898 completed (loss: 0.263933002948761, acc: 0.875)
[2025-01-30 02:20:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5193/107898 [28:11<9:21:53,  3.05it/s][2025-01-30 02:20:21][root][INFO] - Training Epoch: 1/2, step 5192/107898 completed (loss: 0.7018199563026428, acc: 0.9090909361839294)
[2025-01-30 02:20:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5194/107898 [28:12<9:24:37,  3.03it/s][2025-01-30 02:20:22][root][INFO] - Training Epoch: 1/2, step 5193/107898 completed (loss: 0.027498040348291397, acc: 1.0)
[2025-01-30 02:20:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5195/107898 [28:12<9:42:18,  2.94it/s][2025-01-30 02:20:22][root][INFO] - Training Epoch: 1/2, step 5194/107898 completed (loss: 1.6337584257125854, acc: 0.5)
[2025-01-30 02:20:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5196/107898 [28:12<9:35:44,  2.97it/s][2025-01-30 02:20:22][root][INFO] - Training Epoch: 1/2, step 5195/107898 completed (loss: 0.271456778049469, acc: 0.6666666865348816)
[2025-01-30 02:20:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5197/107898 [28:13<9:23:16,  3.04it/s][2025-01-30 02:20:23][root][INFO] - Training Epoch: 1/2, step 5196/107898 completed (loss: 0.434444785118103, acc: 0.6666666865348816)
[2025-01-30 02:20:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5198/107898 [28:13<9:29:18,  3.01it/s][2025-01-30 02:20:23][root][INFO] - Training Epoch: 1/2, step 5197/107898 completed (loss: 0.6229696273803711, acc: 0.8695651888847351)
[2025-01-30 02:20:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5199/107898 [28:13<9:40:04,  2.95it/s][2025-01-30 02:20:23][root][INFO] - Training Epoch: 1/2, step 5198/107898 completed (loss: 2.8461759090423584, acc: 0.25)
[2025-01-30 02:20:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5200/107898 [28:14<9:35:26,  2.97it/s][2025-01-30 02:20:24][root][INFO] - Training Epoch: 1/2, step 5199/107898 completed (loss: 0.7369097471237183, acc: 0.84375)
[2025-01-30 02:20:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5201/107898 [28:14<9:35:35,  2.97it/s][2025-01-30 02:20:24][root][INFO] - Training Epoch: 1/2, step 5200/107898 completed (loss: 0.2737809717655182, acc: 0.9285714030265808)
[2025-01-30 02:20:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5202/107898 [28:14<9:32:08,  2.99it/s][2025-01-30 02:20:24][root][INFO] - Training Epoch: 1/2, step 5201/107898 completed (loss: 0.6212127208709717, acc: 0.9333333373069763)
[2025-01-30 02:20:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5203/107898 [28:15<9:18:10,  3.07it/s][2025-01-30 02:20:25][root][INFO] - Training Epoch: 1/2, step 5202/107898 completed (loss: 1.8850468397140503, acc: 0.2857142984867096)
[2025-01-30 02:20:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5204/107898 [28:15<9:27:02,  3.02it/s][2025-01-30 02:20:25][root][INFO] - Training Epoch: 1/2, step 5203/107898 completed (loss: 0.6298617124557495, acc: 0.6666666865348816)
[2025-01-30 02:20:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5205/107898 [28:15<9:34:44,  2.98it/s][2025-01-30 02:20:25][root][INFO] - Training Epoch: 1/2, step 5204/107898 completed (loss: 0.673400342464447, acc: 0.6666666865348816)
[2025-01-30 02:20:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5206/107898 [28:16<9:26:40,  3.02it/s][2025-01-30 02:20:26][root][INFO] - Training Epoch: 1/2, step 5205/107898 completed (loss: 1.3824822902679443, acc: 0.6000000238418579)
[2025-01-30 02:20:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5207/107898 [28:16<9:08:49,  3.12it/s][2025-01-30 02:20:26][root][INFO] - Training Epoch: 1/2, step 5206/107898 completed (loss: 0.5655775666236877, acc: 0.6666666865348816)
[2025-01-30 02:20:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5208/107898 [28:16<8:59:57,  3.17it/s][2025-01-30 02:20:26][root][INFO] - Training Epoch: 1/2, step 5207/107898 completed (loss: 0.044259339570999146, acc: 1.0)
[2025-01-30 02:20:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5209/107898 [28:17<8:56:27,  3.19it/s][2025-01-30 02:20:26][root][INFO] - Training Epoch: 1/2, step 5208/107898 completed (loss: 0.900448739528656, acc: 0.9130434989929199)
[2025-01-30 02:20:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5210/107898 [28:17<8:58:20,  3.18it/s][2025-01-30 02:20:27][root][INFO] - Training Epoch: 1/2, step 5209/107898 completed (loss: 0.10905809700489044, acc: 1.0)
[2025-01-30 02:20:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5211/107898 [28:17<8:57:14,  3.19it/s][2025-01-30 02:20:27][root][INFO] - Training Epoch: 1/2, step 5210/107898 completed (loss: 3.436760902404785, acc: 0.5)
[2025-01-30 02:20:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5212/107898 [28:18<8:49:40,  3.23it/s][2025-01-30 02:20:27][root][INFO] - Training Epoch: 1/2, step 5211/107898 completed (loss: 0.13034728169441223, acc: 1.0)
[2025-01-30 02:20:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5213/107898 [28:18<9:15:00,  3.08it/s][2025-01-30 02:20:28][root][INFO] - Training Epoch: 1/2, step 5212/107898 completed (loss: 0.1808021515607834, acc: 0.9090909361839294)
[2025-01-30 02:20:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5214/107898 [28:18<9:20:50,  3.05it/s][2025-01-30 02:20:28][root][INFO] - Training Epoch: 1/2, step 5213/107898 completed (loss: 0.14219073951244354, acc: 1.0)
[2025-01-30 02:20:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5215/107898 [28:19<9:18:33,  3.06it/s][2025-01-30 02:20:28][root][INFO] - Training Epoch: 1/2, step 5214/107898 completed (loss: 0.9857077598571777, acc: 0.8823529481887817)
[2025-01-30 02:20:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5216/107898 [28:19<10:02:46,  2.84it/s][2025-01-30 02:20:29][root][INFO] - Training Epoch: 1/2, step 5215/107898 completed (loss: 0.879170298576355, acc: 0.8399999737739563)
[2025-01-30 02:20:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5217/107898 [28:19<9:27:01,  3.02it/s] [2025-01-30 02:20:29][root][INFO] - Training Epoch: 1/2, step 5216/107898 completed (loss: 0.11779468506574631, acc: 1.0)
[2025-01-30 02:20:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5218/107898 [28:20<9:10:15,  3.11it/s][2025-01-30 02:20:29][root][INFO] - Training Epoch: 1/2, step 5217/107898 completed (loss: 0.013808525167405605, acc: 1.0)
[2025-01-30 02:20:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5219/107898 [28:20<9:05:34,  3.14it/s][2025-01-30 02:20:30][root][INFO] - Training Epoch: 1/2, step 5218/107898 completed (loss: 1.6896311044692993, acc: 0.6666666865348816)
[2025-01-30 02:20:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5220/107898 [28:20<9:15:48,  3.08it/s][2025-01-30 02:20:30][root][INFO] - Training Epoch: 1/2, step 5219/107898 completed (loss: 0.3847496807575226, acc: 0.7857142686843872)
[2025-01-30 02:20:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5221/107898 [28:21<9:26:19,  3.02it/s][2025-01-30 02:20:30][root][INFO] - Training Epoch: 1/2, step 5220/107898 completed (loss: 1.7323352098464966, acc: 0.529411792755127)
[2025-01-30 02:20:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5222/107898 [28:21<9:10:58,  3.11it/s][2025-01-30 02:20:31][root][INFO] - Training Epoch: 1/2, step 5221/107898 completed (loss: 2.9986517429351807, acc: 0.3333333432674408)
[2025-01-30 02:20:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5223/107898 [28:21<9:00:30,  3.17it/s][2025-01-30 02:20:31][root][INFO] - Training Epoch: 1/2, step 5222/107898 completed (loss: 3.0369129180908203, acc: 0.0)
[2025-01-30 02:20:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5224/107898 [28:22<8:58:33,  3.18it/s][2025-01-30 02:20:31][root][INFO] - Training Epoch: 1/2, step 5223/107898 completed (loss: 0.07337525486946106, acc: 1.0)
[2025-01-30 02:20:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5225/107898 [28:22<9:21:56,  3.05it/s][2025-01-30 02:20:32][root][INFO] - Training Epoch: 1/2, step 5224/107898 completed (loss: 0.7054467797279358, acc: 0.8421052694320679)
[2025-01-30 02:20:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5226/107898 [28:22<9:30:27,  3.00it/s][2025-01-30 02:20:32][root][INFO] - Training Epoch: 1/2, step 5225/107898 completed (loss: 0.9987727999687195, acc: 0.800000011920929)
[2025-01-30 02:20:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5227/107898 [28:23<9:40:49,  2.95it/s][2025-01-30 02:20:32][root][INFO] - Training Epoch: 1/2, step 5226/107898 completed (loss: 0.0029638272244483232, acc: 1.0)
[2025-01-30 02:20:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5228/107898 [28:23<9:42:25,  2.94it/s][2025-01-30 02:20:33][root][INFO] - Training Epoch: 1/2, step 5227/107898 completed (loss: 0.636733889579773, acc: 0.800000011920929)
[2025-01-30 02:20:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5229/107898 [28:23<9:42:14,  2.94it/s][2025-01-30 02:20:33][root][INFO] - Training Epoch: 1/2, step 5228/107898 completed (loss: 0.5937967300415039, acc: 0.6666666865348816)
[2025-01-30 02:20:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5230/107898 [28:24<9:51:56,  2.89it/s][2025-01-30 02:20:33][root][INFO] - Training Epoch: 1/2, step 5229/107898 completed (loss: 0.0017087418818846345, acc: 1.0)
[2025-01-30 02:20:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5231/107898 [28:24<9:45:00,  2.92it/s][2025-01-30 02:20:34][root][INFO] - Training Epoch: 1/2, step 5230/107898 completed (loss: 0.36316365003585815, acc: 0.8999999761581421)
[2025-01-30 02:20:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5232/107898 [28:24<9:55:32,  2.87it/s][2025-01-30 02:20:34][root][INFO] - Training Epoch: 1/2, step 5231/107898 completed (loss: 2.064882755279541, acc: 0.4285714328289032)
[2025-01-30 02:20:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5233/107898 [28:25<9:52:16,  2.89it/s][2025-01-30 02:20:34][root][INFO] - Training Epoch: 1/2, step 5232/107898 completed (loss: 0.029644565656781197, acc: 1.0)
[2025-01-30 02:20:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5234/107898 [28:25<10:02:31,  2.84it/s][2025-01-30 02:20:35][root][INFO] - Training Epoch: 1/2, step 5233/107898 completed (loss: 0.720594048500061, acc: 0.8799999952316284)
[2025-01-30 02:20:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5235/107898 [28:25<10:09:31,  2.81it/s][2025-01-30 02:20:35][root][INFO] - Training Epoch: 1/2, step 5234/107898 completed (loss: 0.010504163801670074, acc: 1.0)
[2025-01-30 02:20:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5236/107898 [28:26<10:09:36,  2.81it/s][2025-01-30 02:20:36][root][INFO] - Training Epoch: 1/2, step 5235/107898 completed (loss: 0.07262829691171646, acc: 1.0)
[2025-01-30 02:20:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5237/107898 [28:26<9:43:47,  2.93it/s] [2025-01-30 02:20:36][root][INFO] - Training Epoch: 1/2, step 5236/107898 completed (loss: 0.8771283030509949, acc: 0.875)
[2025-01-30 02:20:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5238/107898 [28:26<9:49:48,  2.90it/s][2025-01-30 02:20:36][root][INFO] - Training Epoch: 1/2, step 5237/107898 completed (loss: 0.25700631737709045, acc: 1.0)
[2025-01-30 02:20:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5239/107898 [28:27<9:49:23,  2.90it/s][2025-01-30 02:20:37][root][INFO] - Training Epoch: 1/2, step 5238/107898 completed (loss: 3.6869168281555176, acc: 0.6000000238418579)
[2025-01-30 02:20:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5240/107898 [28:27<9:53:01,  2.89it/s][2025-01-30 02:20:37][root][INFO] - Training Epoch: 1/2, step 5239/107898 completed (loss: 1.9411875009536743, acc: 0.7857142686843872)
[2025-01-30 02:20:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5241/107898 [28:27<9:45:41,  2.92it/s][2025-01-30 02:20:37][root][INFO] - Training Epoch: 1/2, step 5240/107898 completed (loss: 0.5745252966880798, acc: 0.9047619104385376)
[2025-01-30 02:20:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5242/107898 [28:28<9:34:08,  2.98it/s][2025-01-30 02:20:38][root][INFO] - Training Epoch: 1/2, step 5241/107898 completed (loss: 2.418978691101074, acc: 0.6000000238418579)
[2025-01-30 02:20:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5243/107898 [28:28<9:03:25,  3.15it/s][2025-01-30 02:20:38][root][INFO] - Training Epoch: 1/2, step 5242/107898 completed (loss: 0.5452716946601868, acc: 0.6666666865348816)
[2025-01-30 02:20:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5244/107898 [28:28<9:19:57,  3.06it/s][2025-01-30 02:20:38][root][INFO] - Training Epoch: 1/2, step 5243/107898 completed (loss: 0.303301066160202, acc: 1.0)
[2025-01-30 02:20:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5245/107898 [28:29<9:26:00,  3.02it/s][2025-01-30 02:20:39][root][INFO] - Training Epoch: 1/2, step 5244/107898 completed (loss: 1.8300583362579346, acc: 0.6000000238418579)
[2025-01-30 02:20:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5246/107898 [28:29<9:20:40,  3.05it/s][2025-01-30 02:20:39][root][INFO] - Training Epoch: 1/2, step 5245/107898 completed (loss: 0.7754293084144592, acc: 0.8571428656578064)
[2025-01-30 02:20:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5247/107898 [28:29<9:32:11,  2.99it/s][2025-01-30 02:20:39][root][INFO] - Training Epoch: 1/2, step 5246/107898 completed (loss: 1.4882006645202637, acc: 0.6363636255264282)
[2025-01-30 02:20:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5248/107898 [28:30<9:30:46,  3.00it/s][2025-01-30 02:20:40][root][INFO] - Training Epoch: 1/2, step 5247/107898 completed (loss: 0.010467637330293655, acc: 1.0)
[2025-01-30 02:20:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5249/107898 [28:30<9:26:29,  3.02it/s][2025-01-30 02:20:40][root][INFO] - Training Epoch: 1/2, step 5248/107898 completed (loss: 1.6862363815307617, acc: 0.4000000059604645)
[2025-01-30 02:20:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5250/107898 [28:30<9:17:39,  3.07it/s][2025-01-30 02:20:40][root][INFO] - Training Epoch: 1/2, step 5249/107898 completed (loss: 0.30227839946746826, acc: 1.0)
[2025-01-30 02:20:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5251/107898 [28:31<9:03:47,  3.15it/s][2025-01-30 02:20:40][root][INFO] - Training Epoch: 1/2, step 5250/107898 completed (loss: 0.9766929745674133, acc: 0.800000011920929)
[2025-01-30 02:20:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5252/107898 [28:31<9:04:56,  3.14it/s][2025-01-30 02:20:41][root][INFO] - Training Epoch: 1/2, step 5251/107898 completed (loss: 0.6980950236320496, acc: 0.8666666746139526)
[2025-01-30 02:20:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5253/107898 [28:31<9:07:38,  3.12it/s][2025-01-30 02:20:41][root][INFO] - Training Epoch: 1/2, step 5252/107898 completed (loss: 3.2320640087127686, acc: 0.0)
[2025-01-30 02:20:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5254/107898 [28:32<9:11:56,  3.10it/s][2025-01-30 02:20:41][root][INFO] - Training Epoch: 1/2, step 5253/107898 completed (loss: 0.15118110179901123, acc: 1.0)
[2025-01-30 02:20:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5255/107898 [28:32<8:58:19,  3.18it/s][2025-01-30 02:20:42][root][INFO] - Training Epoch: 1/2, step 5254/107898 completed (loss: 2.8310461044311523, acc: 0.42105263471603394)
[2025-01-30 02:20:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5256/107898 [28:32<8:50:55,  3.22it/s][2025-01-30 02:20:42][root][INFO] - Training Epoch: 1/2, step 5255/107898 completed (loss: 0.8939084410667419, acc: 0.800000011920929)
[2025-01-30 02:20:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5257/107898 [28:33<9:26:44,  3.02it/s][2025-01-30 02:20:42][root][INFO] - Training Epoch: 1/2, step 5256/107898 completed (loss: 5.17645788192749, acc: 0.5)
[2025-01-30 02:20:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5258/107898 [28:33<8:59:27,  3.17it/s][2025-01-30 02:20:43][root][INFO] - Training Epoch: 1/2, step 5257/107898 completed (loss: 0.5751287341117859, acc: 0.8888888955116272)
[2025-01-30 02:20:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5259/107898 [28:33<8:53:27,  3.21it/s][2025-01-30 02:20:43][root][INFO] - Training Epoch: 1/2, step 5258/107898 completed (loss: 0.005580281838774681, acc: 1.0)
[2025-01-30 02:20:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5260/107898 [28:34<8:48:58,  3.23it/s][2025-01-30 02:20:43][root][INFO] - Training Epoch: 1/2, step 5259/107898 completed (loss: 0.3631305694580078, acc: 1.0)
[2025-01-30 02:20:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5261/107898 [28:34<8:52:47,  3.21it/s][2025-01-30 02:20:44][root][INFO] - Training Epoch: 1/2, step 5260/107898 completed (loss: 0.5273908972740173, acc: 0.8823529481887817)
[2025-01-30 02:20:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5262/107898 [28:34<8:54:36,  3.20it/s][2025-01-30 02:20:44][root][INFO] - Training Epoch: 1/2, step 5261/107898 completed (loss: 3.774524688720703, acc: 0.2142857164144516)
[2025-01-30 02:20:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5263/107898 [28:34<8:30:24,  3.35it/s][2025-01-30 02:20:44][root][INFO] - Training Epoch: 1/2, step 5262/107898 completed (loss: 0.3986981511116028, acc: 0.875)
[2025-01-30 02:20:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5264/107898 [28:35<8:29:09,  3.36it/s][2025-01-30 02:20:45][root][INFO] - Training Epoch: 1/2, step 5263/107898 completed (loss: 0.08281105011701584, acc: 1.0)
[2025-01-30 02:20:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5265/107898 [28:35<8:29:12,  3.36it/s][2025-01-30 02:20:45][root][INFO] - Training Epoch: 1/2, step 5264/107898 completed (loss: 0.13269130885601044, acc: 1.0)
[2025-01-30 02:20:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5266/107898 [28:35<8:32:03,  3.34it/s][2025-01-30 02:20:45][root][INFO] - Training Epoch: 1/2, step 5265/107898 completed (loss: 0.49737969040870667, acc: 0.949999988079071)
[2025-01-30 02:20:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5267/107898 [28:36<8:40:00,  3.29it/s][2025-01-30 02:20:45][root][INFO] - Training Epoch: 1/2, step 5266/107898 completed (loss: 1.9123151302337646, acc: 0.6666666865348816)
[2025-01-30 02:20:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5268/107898 [28:36<8:57:59,  3.18it/s][2025-01-30 02:20:46][root][INFO] - Training Epoch: 1/2, step 5267/107898 completed (loss: 1.1563522815704346, acc: 0.800000011920929)
[2025-01-30 02:20:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5269/107898 [28:36<8:50:10,  3.23it/s][2025-01-30 02:20:46][root][INFO] - Training Epoch: 1/2, step 5268/107898 completed (loss: 0.5842776298522949, acc: 0.8888888955116272)
[2025-01-30 02:20:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5270/107898 [28:37<8:49:29,  3.23it/s][2025-01-30 02:20:46][root][INFO] - Training Epoch: 1/2, step 5269/107898 completed (loss: 0.2314973771572113, acc: 0.9375)
[2025-01-30 02:20:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5271/107898 [28:37<8:45:15,  3.26it/s][2025-01-30 02:20:47][root][INFO] - Training Epoch: 1/2, step 5270/107898 completed (loss: 0.009351562708616257, acc: 1.0)
[2025-01-30 02:20:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5272/107898 [28:37<9:03:36,  3.15it/s][2025-01-30 02:20:47][root][INFO] - Training Epoch: 1/2, step 5271/107898 completed (loss: 0.26194092631340027, acc: 0.875)
[2025-01-30 02:20:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5273/107898 [28:38<9:12:10,  3.10it/s][2025-01-30 02:20:47][root][INFO] - Training Epoch: 1/2, step 5272/107898 completed (loss: 0.5350584983825684, acc: 0.8333333134651184)
[2025-01-30 02:20:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5274/107898 [28:38<9:05:40,  3.13it/s][2025-01-30 02:20:48][root][INFO] - Training Epoch: 1/2, step 5273/107898 completed (loss: 0.036023955792188644, acc: 1.0)
[2025-01-30 02:20:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5275/107898 [28:38<8:44:00,  3.26it/s][2025-01-30 02:20:48][root][INFO] - Training Epoch: 1/2, step 5274/107898 completed (loss: 0.9006765484809875, acc: 1.0)
[2025-01-30 02:20:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5276/107898 [28:38<8:46:59,  3.25it/s][2025-01-30 02:20:48][root][INFO] - Training Epoch: 1/2, step 5275/107898 completed (loss: 0.7805982232093811, acc: 0.8636363744735718)
[2025-01-30 02:20:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5277/107898 [28:39<8:45:19,  3.26it/s][2025-01-30 02:20:49][root][INFO] - Training Epoch: 1/2, step 5276/107898 completed (loss: 1.4956669807434082, acc: 0.5882353186607361)
[2025-01-30 02:20:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5278/107898 [28:39<9:16:35,  3.07it/s][2025-01-30 02:20:49][root][INFO] - Training Epoch: 1/2, step 5277/107898 completed (loss: 0.008445960469543934, acc: 1.0)
[2025-01-30 02:20:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5279/107898 [28:39<9:26:28,  3.02it/s][2025-01-30 02:20:49][root][INFO] - Training Epoch: 1/2, step 5278/107898 completed (loss: 3.120681047439575, acc: 0.30000001192092896)
[2025-01-30 02:20:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5280/107898 [28:40<9:12:59,  3.09it/s][2025-01-30 02:20:50][root][INFO] - Training Epoch: 1/2, step 5279/107898 completed (loss: 4.6231255531311035, acc: 0.5)
[2025-01-30 02:20:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5281/107898 [28:40<9:17:36,  3.07it/s][2025-01-30 02:20:50][root][INFO] - Training Epoch: 1/2, step 5280/107898 completed (loss: 0.0034058575984090567, acc: 1.0)
[2025-01-30 02:20:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5282/107898 [28:40<9:10:54,  3.10it/s][2025-01-30 02:20:50][root][INFO] - Training Epoch: 1/2, step 5281/107898 completed (loss: 2.910761833190918, acc: 0.5)
[2025-01-30 02:20:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5283/107898 [28:41<8:53:08,  3.21it/s][2025-01-30 02:20:51][root][INFO] - Training Epoch: 1/2, step 5282/107898 completed (loss: 0.06312943249940872, acc: 1.0)
[2025-01-30 02:20:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5284/107898 [28:41<9:18:07,  3.06it/s][2025-01-30 02:20:51][root][INFO] - Training Epoch: 1/2, step 5283/107898 completed (loss: 1.1005356311798096, acc: 0.7368420958518982)
[2025-01-30 02:20:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5285/107898 [28:41<9:16:17,  3.07it/s][2025-01-30 02:20:51][root][INFO] - Training Epoch: 1/2, step 5284/107898 completed (loss: 0.2501123249530792, acc: 0.9285714030265808)
[2025-01-30 02:20:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5286/107898 [28:42<9:33:08,  2.98it/s][2025-01-30 02:20:52][root][INFO] - Training Epoch: 1/2, step 5285/107898 completed (loss: 2.9324700832366943, acc: 0.4615384638309479)
[2025-01-30 02:20:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5287/107898 [28:42<9:48:19,  2.91it/s][2025-01-30 02:20:52][root][INFO] - Training Epoch: 1/2, step 5286/107898 completed (loss: 3.3643076419830322, acc: 0.3928571343421936)
[2025-01-30 02:20:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5288/107898 [28:42<9:36:21,  2.97it/s][2025-01-30 02:20:52][root][INFO] - Training Epoch: 1/2, step 5287/107898 completed (loss: 2.659688949584961, acc: 0.20000000298023224)
[2025-01-30 02:20:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5289/107898 [28:43<9:52:43,  2.89it/s][2025-01-30 02:20:53][root][INFO] - Training Epoch: 1/2, step 5288/107898 completed (loss: 2.472334384918213, acc: 0.692307710647583)
[2025-01-30 02:20:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5290/107898 [28:43<9:43:43,  2.93it/s][2025-01-30 02:20:53][root][INFO] - Training Epoch: 1/2, step 5289/107898 completed (loss: 0.3368341028690338, acc: 0.8999999761581421)
[2025-01-30 02:20:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5291/107898 [28:43<9:35:10,  2.97it/s][2025-01-30 02:20:53][root][INFO] - Training Epoch: 1/2, step 5290/107898 completed (loss: 3.195159673690796, acc: 0.3333333432674408)
[2025-01-30 02:20:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5292/107898 [28:44<9:46:21,  2.92it/s][2025-01-30 02:20:54][root][INFO] - Training Epoch: 1/2, step 5291/107898 completed (loss: 1.1308634281158447, acc: 0.7575757503509521)
[2025-01-30 02:20:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5293/107898 [28:44<9:54:43,  2.88it/s][2025-01-30 02:20:54][root][INFO] - Training Epoch: 1/2, step 5292/107898 completed (loss: 0.8100817203521729, acc: 1.0)
[2025-01-30 02:20:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5294/107898 [28:45<10:07:19,  2.82it/s][2025-01-30 02:20:54][root][INFO] - Training Epoch: 1/2, step 5293/107898 completed (loss: 2.475144386291504, acc: 0.3333333432674408)
[2025-01-30 02:20:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5295/107898 [28:45<10:01:20,  2.84it/s][2025-01-30 02:20:55][root][INFO] - Training Epoch: 1/2, step 5294/107898 completed (loss: 1.1640474796295166, acc: 0.800000011920929)
[2025-01-30 02:20:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5296/107898 [28:45<10:02:49,  2.84it/s][2025-01-30 02:20:55][root][INFO] - Training Epoch: 1/2, step 5295/107898 completed (loss: 0.1581052988767624, acc: 0.8999999761581421)
[2025-01-30 02:20:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5297/107898 [28:46<10:02:40,  2.84it/s][2025-01-30 02:20:55][root][INFO] - Training Epoch: 1/2, step 5296/107898 completed (loss: 0.4600100517272949, acc: 0.8333333134651184)
[2025-01-30 02:20:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5298/107898 [28:46<9:51:53,  2.89it/s] [2025-01-30 02:20:56][root][INFO] - Training Epoch: 1/2, step 5297/107898 completed (loss: 3.384199857711792, acc: 0.5)
[2025-01-30 02:20:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5299/107898 [28:46<9:47:33,  2.91it/s][2025-01-30 02:20:56][root][INFO] - Training Epoch: 1/2, step 5298/107898 completed (loss: 1.5457209348678589, acc: 0.7083333134651184)
[2025-01-30 02:20:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5300/107898 [28:47<9:32:13,  2.99it/s][2025-01-30 02:20:56][root][INFO] - Training Epoch: 1/2, step 5299/107898 completed (loss: 0.01822536811232567, acc: 1.0)
[2025-01-30 02:20:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5301/107898 [28:47<9:21:46,  3.04it/s][2025-01-30 02:20:57][root][INFO] - Training Epoch: 1/2, step 5300/107898 completed (loss: 0.29976823925971985, acc: 1.0)
[2025-01-30 02:20:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5302/107898 [28:47<9:02:07,  3.15it/s][2025-01-30 02:20:57][root][INFO] - Training Epoch: 1/2, step 5301/107898 completed (loss: 0.04219339042901993, acc: 1.0)
[2025-01-30 02:20:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5303/107898 [28:48<9:23:48,  3.03it/s][2025-01-30 02:20:57][root][INFO] - Training Epoch: 1/2, step 5302/107898 completed (loss: 0.9646899104118347, acc: 0.6666666865348816)
[2025-01-30 02:20:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5304/107898 [28:48<9:23:54,  3.03it/s][2025-01-30 02:20:58][root][INFO] - Training Epoch: 1/2, step 5303/107898 completed (loss: 1.2121649980545044, acc: 0.6666666865348816)
[2025-01-30 02:20:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5305/107898 [28:48<8:58:49,  3.17it/s][2025-01-30 02:20:58][root][INFO] - Training Epoch: 1/2, step 5304/107898 completed (loss: 0.06389041244983673, acc: 1.0)
[2025-01-30 02:20:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5306/107898 [28:49<9:12:35,  3.09it/s][2025-01-30 02:20:58][root][INFO] - Training Epoch: 1/2, step 5305/107898 completed (loss: 0.157007098197937, acc: 0.9473684430122375)
[2025-01-30 02:20:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5307/107898 [28:49<9:24:40,  3.03it/s][2025-01-30 02:20:59][root][INFO] - Training Epoch: 1/2, step 5306/107898 completed (loss: 0.2231636345386505, acc: 0.9333333373069763)
[2025-01-30 02:20:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5308/107898 [28:49<9:24:50,  3.03it/s][2025-01-30 02:20:59][root][INFO] - Training Epoch: 1/2, step 5307/107898 completed (loss: 0.5557477474212646, acc: 0.8461538553237915)
[2025-01-30 02:20:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5309/107898 [28:50<9:16:59,  3.07it/s][2025-01-30 02:20:59][root][INFO] - Training Epoch: 1/2, step 5308/107898 completed (loss: 4.176492214202881, acc: 0.3125)
[2025-01-30 02:20:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5310/107898 [28:50<9:12:09,  3.10it/s][2025-01-30 02:21:00][root][INFO] - Training Epoch: 1/2, step 5309/107898 completed (loss: 0.32696783542633057, acc: 0.9599999785423279)
[2025-01-30 02:21:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5311/107898 [28:50<9:05:23,  3.13it/s][2025-01-30 02:21:00][root][INFO] - Training Epoch: 1/2, step 5310/107898 completed (loss: 0.8919172883033752, acc: 0.6666666865348816)
[2025-01-30 02:21:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5312/107898 [28:50<8:52:24,  3.21it/s][2025-01-30 02:21:00][root][INFO] - Training Epoch: 1/2, step 5311/107898 completed (loss: 2.343062162399292, acc: 0.3333333432674408)
[2025-01-30 02:21:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5313/107898 [28:51<8:58:57,  3.17it/s][2025-01-30 02:21:01][root][INFO] - Training Epoch: 1/2, step 5312/107898 completed (loss: 0.9668952226638794, acc: 0.5)
[2025-01-30 02:21:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5314/107898 [28:51<8:55:02,  3.20it/s][2025-01-30 02:21:01][root][INFO] - Training Epoch: 1/2, step 5313/107898 completed (loss: 0.05475979298353195, acc: 1.0)
[2025-01-30 02:21:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5315/107898 [28:51<8:42:15,  3.27it/s][2025-01-30 02:21:01][root][INFO] - Training Epoch: 1/2, step 5314/107898 completed (loss: 0.012859500013291836, acc: 1.0)
[2025-01-30 02:21:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5316/107898 [28:52<8:56:42,  3.19it/s][2025-01-30 02:21:01][root][INFO] - Training Epoch: 1/2, step 5315/107898 completed (loss: 2.84371280670166, acc: 0.2666666805744171)
[2025-01-30 02:21:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5317/107898 [28:52<11:44:04,  2.43it/s][2025-01-30 02:21:02][root][INFO] - Training Epoch: 1/2, step 5316/107898 completed (loss: 4.279613494873047, acc: 0.1764705926179886)
[2025-01-30 02:21:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5318/107898 [28:53<10:38:27,  2.68it/s][2025-01-30 02:21:02][root][INFO] - Training Epoch: 1/2, step 5317/107898 completed (loss: 0.01171672623604536, acc: 1.0)
[2025-01-30 02:21:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5319/107898 [28:53<10:01:23,  2.84it/s][2025-01-30 02:21:03][root][INFO] - Training Epoch: 1/2, step 5318/107898 completed (loss: 3.661895513534546, acc: 0.1428571492433548)
[2025-01-30 02:21:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5320/107898 [28:53<9:43:30,  2.93it/s] [2025-01-30 02:21:03][root][INFO] - Training Epoch: 1/2, step 5319/107898 completed (loss: 2.7891037464141846, acc: 0.4444444477558136)
[2025-01-30 02:21:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5321/107898 [28:54<9:23:44,  3.03it/s][2025-01-30 02:21:03][root][INFO] - Training Epoch: 1/2, step 5320/107898 completed (loss: 0.014432450756430626, acc: 1.0)
[2025-01-30 02:21:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5322/107898 [28:54<9:13:32,  3.09it/s][2025-01-30 02:21:04][root][INFO] - Training Epoch: 1/2, step 5321/107898 completed (loss: 2.4348604679107666, acc: 0.7142857313156128)
[2025-01-30 02:21:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5323/107898 [28:54<8:58:08,  3.18it/s][2025-01-30 02:21:04][root][INFO] - Training Epoch: 1/2, step 5322/107898 completed (loss: 2.012079954147339, acc: 0.5)
[2025-01-30 02:21:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5324/107898 [28:54<8:47:45,  3.24it/s][2025-01-30 02:21:04][root][INFO] - Training Epoch: 1/2, step 5323/107898 completed (loss: 1.873142957687378, acc: 0.6000000238418579)
[2025-01-30 02:21:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5325/107898 [28:55<9:04:45,  3.14it/s][2025-01-30 02:21:05][root][INFO] - Training Epoch: 1/2, step 5324/107898 completed (loss: 0.0934431254863739, acc: 1.0)
[2025-01-30 02:21:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5326/107898 [28:55<9:19:50,  3.05it/s][2025-01-30 02:21:05][root][INFO] - Training Epoch: 1/2, step 5325/107898 completed (loss: 2.893662691116333, acc: 0.3333333432674408)
[2025-01-30 02:21:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5327/107898 [28:55<9:06:39,  3.13it/s][2025-01-30 02:21:05][root][INFO] - Training Epoch: 1/2, step 5326/107898 completed (loss: 4.010900020599365, acc: 0.1428571492433548)
[2025-01-30 02:21:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5328/107898 [28:56<9:00:41,  3.16it/s][2025-01-30 02:21:06][root][INFO] - Training Epoch: 1/2, step 5327/107898 completed (loss: 0.24045215547084808, acc: 0.9090909361839294)
[2025-01-30 02:21:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5329/107898 [28:56<9:09:11,  3.11it/s][2025-01-30 02:21:06][root][INFO] - Training Epoch: 1/2, step 5328/107898 completed (loss: 1.0866713523864746, acc: 0.5)
[2025-01-30 02:21:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5330/107898 [28:56<9:07:44,  3.12it/s][2025-01-30 02:21:06][root][INFO] - Training Epoch: 1/2, step 5329/107898 completed (loss: 0.4974905550479889, acc: 0.6666666865348816)
[2025-01-30 02:21:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5331/107898 [28:57<9:29:47,  3.00it/s][2025-01-30 02:21:07][root][INFO] - Training Epoch: 1/2, step 5330/107898 completed (loss: 2.4174087047576904, acc: 0.3333333432674408)
[2025-01-30 02:21:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5332/107898 [28:57<9:29:55,  3.00it/s][2025-01-30 02:21:07][root][INFO] - Training Epoch: 1/2, step 5331/107898 completed (loss: 0.4331592321395874, acc: 0.6666666865348816)
[2025-01-30 02:21:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5333/107898 [28:57<9:26:54,  3.02it/s][2025-01-30 02:21:07][root][INFO] - Training Epoch: 1/2, step 5332/107898 completed (loss: 1.7562085390090942, acc: 0.7777777910232544)
[2025-01-30 02:21:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5334/107898 [28:58<9:16:17,  3.07it/s][2025-01-30 02:21:07][root][INFO] - Training Epoch: 1/2, step 5333/107898 completed (loss: 0.6120909452438354, acc: 0.8999999761581421)
[2025-01-30 02:21:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5335/107898 [28:58<9:16:34,  3.07it/s][2025-01-30 02:21:08][root][INFO] - Training Epoch: 1/2, step 5334/107898 completed (loss: 3.837805986404419, acc: 0.1599999964237213)
[2025-01-30 02:21:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5336/107898 [28:58<8:54:38,  3.20it/s][2025-01-30 02:21:08][root][INFO] - Training Epoch: 1/2, step 5335/107898 completed (loss: 2.001060724258423, acc: 0.6666666865348816)
[2025-01-30 02:21:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5337/107898 [28:59<8:48:13,  3.24it/s][2025-01-30 02:21:08][root][INFO] - Training Epoch: 1/2, step 5336/107898 completed (loss: 0.11218316107988358, acc: 1.0)
[2025-01-30 02:21:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5338/107898 [28:59<9:09:50,  3.11it/s][2025-01-30 02:21:09][root][INFO] - Training Epoch: 1/2, step 5337/107898 completed (loss: 0.5391283631324768, acc: 0.8928571343421936)
[2025-01-30 02:21:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5339/107898 [28:59<8:54:15,  3.20it/s][2025-01-30 02:21:09][root][INFO] - Training Epoch: 1/2, step 5338/107898 completed (loss: 0.3698398470878601, acc: 0.9473684430122375)
[2025-01-30 02:21:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5340/107898 [29:00<9:14:40,  3.08it/s][2025-01-30 02:21:09][root][INFO] - Training Epoch: 1/2, step 5339/107898 completed (loss: 0.003829662222415209, acc: 1.0)
[2025-01-30 02:21:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5341/107898 [29:00<10:02:26,  2.84it/s][2025-01-30 02:21:10][root][INFO] - Training Epoch: 1/2, step 5340/107898 completed (loss: 1.103786587715149, acc: 0.800000011920929)
[2025-01-30 02:21:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5342/107898 [29:00<9:48:16,  2.91it/s] [2025-01-30 02:21:10][root][INFO] - Training Epoch: 1/2, step 5341/107898 completed (loss: 0.005452428013086319, acc: 1.0)
[2025-01-30 02:21:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5343/107898 [29:01<9:46:45,  2.91it/s][2025-01-30 02:21:10][root][INFO] - Training Epoch: 1/2, step 5342/107898 completed (loss: 0.01828114315867424, acc: 1.0)
[2025-01-30 02:21:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5344/107898 [29:01<9:49:02,  2.90it/s][2025-01-30 02:21:11][root][INFO] - Training Epoch: 1/2, step 5343/107898 completed (loss: 1.1599596738815308, acc: 0.6666666865348816)
[2025-01-30 02:21:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5345/107898 [29:01<9:33:41,  2.98it/s][2025-01-30 02:21:11][root][INFO] - Training Epoch: 1/2, step 5344/107898 completed (loss: 3.587327480316162, acc: 0.2142857164144516)
[2025-01-30 02:21:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5346/107898 [29:02<9:13:53,  3.09it/s][2025-01-30 02:21:11][root][INFO] - Training Epoch: 1/2, step 5345/107898 completed (loss: 0.00929541140794754, acc: 1.0)
[2025-01-30 02:21:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5347/107898 [29:02<9:02:44,  3.15it/s][2025-01-30 02:21:12][root][INFO] - Training Epoch: 1/2, step 5346/107898 completed (loss: 0.16424629092216492, acc: 0.9599999785423279)
[2025-01-30 02:21:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5348/107898 [29:02<9:10:19,  3.11it/s][2025-01-30 02:21:12][root][INFO] - Training Epoch: 1/2, step 5347/107898 completed (loss: 0.5585500001907349, acc: 0.837837815284729)
[2025-01-30 02:21:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5349/107898 [29:03<9:12:22,  3.09it/s][2025-01-30 02:21:12][root][INFO] - Training Epoch: 1/2, step 5348/107898 completed (loss: 0.005301454104483128, acc: 1.0)
[2025-01-30 02:21:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5350/107898 [29:03<8:57:59,  3.18it/s][2025-01-30 02:21:13][root][INFO] - Training Epoch: 1/2, step 5349/107898 completed (loss: 0.13811150193214417, acc: 1.0)
[2025-01-30 02:21:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5351/107898 [29:03<8:57:40,  3.18it/s][2025-01-30 02:21:13][root][INFO] - Training Epoch: 1/2, step 5350/107898 completed (loss: 0.4381899833679199, acc: 0.875)
[2025-01-30 02:21:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5352/107898 [29:04<9:16:29,  3.07it/s][2025-01-30 02:21:13][root][INFO] - Training Epoch: 1/2, step 5351/107898 completed (loss: 1.8680291175842285, acc: 0.6666666865348816)
[2025-01-30 02:21:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5353/107898 [29:04<9:17:16,  3.07it/s][2025-01-30 02:21:14][root][INFO] - Training Epoch: 1/2, step 5352/107898 completed (loss: 1.1181206703186035, acc: 0.7272727489471436)
[2025-01-30 02:21:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5354/107898 [29:04<9:21:12,  3.05it/s][2025-01-30 02:21:14][root][INFO] - Training Epoch: 1/2, step 5353/107898 completed (loss: 0.06576048582792282, acc: 1.0)
[2025-01-30 02:21:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5355/107898 [29:05<9:53:09,  2.88it/s][2025-01-30 02:21:14][root][INFO] - Training Epoch: 1/2, step 5354/107898 completed (loss: 3.61430287361145, acc: 0.4285714328289032)
[2025-01-30 02:21:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5356/107898 [29:05<9:47:23,  2.91it/s][2025-01-30 02:21:15][root][INFO] - Training Epoch: 1/2, step 5355/107898 completed (loss: 0.08820342272520065, acc: 1.0)
[2025-01-30 02:21:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5357/107898 [29:05<9:32:33,  2.98it/s][2025-01-30 02:21:15][root][INFO] - Training Epoch: 1/2, step 5356/107898 completed (loss: 0.668287992477417, acc: 0.800000011920929)
[2025-01-30 02:21:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5358/107898 [29:06<9:23:21,  3.03it/s][2025-01-30 02:21:15][root][INFO] - Training Epoch: 1/2, step 5357/107898 completed (loss: 2.0520663261413574, acc: 0.6000000238418579)
[2025-01-30 02:21:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5359/107898 [29:06<9:12:25,  3.09it/s][2025-01-30 02:21:16][root][INFO] - Training Epoch: 1/2, step 5358/107898 completed (loss: 0.14010825753211975, acc: 1.0)
[2025-01-30 02:21:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5360/107898 [29:06<9:04:16,  3.14it/s][2025-01-30 02:21:16][root][INFO] - Training Epoch: 1/2, step 5359/107898 completed (loss: 3.6448891162872314, acc: 0.25)
[2025-01-30 02:21:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5361/107898 [29:07<9:01:04,  3.16it/s][2025-01-30 02:21:16][root][INFO] - Training Epoch: 1/2, step 5360/107898 completed (loss: 0.4075257480144501, acc: 0.8636363744735718)
[2025-01-30 02:21:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5362/107898 [29:07<8:40:58,  3.28it/s][2025-01-30 02:21:17][root][INFO] - Training Epoch: 1/2, step 5361/107898 completed (loss: 0.008299496956169605, acc: 1.0)
[2025-01-30 02:21:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5363/107898 [29:07<8:58:57,  3.17it/s][2025-01-30 02:21:17][root][INFO] - Training Epoch: 1/2, step 5362/107898 completed (loss: 0.12929454445838928, acc: 1.0)
[2025-01-30 02:21:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5364/107898 [29:07<9:02:29,  3.15it/s][2025-01-30 02:21:17][root][INFO] - Training Epoch: 1/2, step 5363/107898 completed (loss: 0.02297932282090187, acc: 1.0)
[2025-01-30 02:21:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5365/107898 [29:08<8:58:10,  3.18it/s][2025-01-30 02:21:18][root][INFO] - Training Epoch: 1/2, step 5364/107898 completed (loss: 1.344237208366394, acc: 0.75)
[2025-01-30 02:21:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5366/107898 [29:08<8:52:35,  3.21it/s][2025-01-30 02:21:18][root][INFO] - Training Epoch: 1/2, step 5365/107898 completed (loss: 0.04882767051458359, acc: 1.0)
[2025-01-30 02:21:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5367/107898 [29:08<9:15:49,  3.07it/s][2025-01-30 02:21:18][root][INFO] - Training Epoch: 1/2, step 5366/107898 completed (loss: 2.1238675117492676, acc: 0.523809552192688)
[2025-01-30 02:21:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5368/107898 [29:09<9:31:17,  2.99it/s][2025-01-30 02:21:19][root][INFO] - Training Epoch: 1/2, step 5367/107898 completed (loss: 1.035934329032898, acc: 0.8333333134651184)
[2025-01-30 02:21:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5369/107898 [29:09<9:30:54,  2.99it/s][2025-01-30 02:21:19][root][INFO] - Training Epoch: 1/2, step 5368/107898 completed (loss: 1.6345784664154053, acc: 0.5)
[2025-01-30 02:21:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5370/107898 [29:09<9:15:47,  3.07it/s][2025-01-30 02:21:19][root][INFO] - Training Epoch: 1/2, step 5369/107898 completed (loss: 0.02808966673910618, acc: 1.0)
[2025-01-30 02:21:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5371/107898 [29:10<9:21:17,  3.04it/s][2025-01-30 02:21:20][root][INFO] - Training Epoch: 1/2, step 5370/107898 completed (loss: 1.3547468185424805, acc: 0.6363636255264282)
[2025-01-30 02:21:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5372/107898 [29:10<9:18:30,  3.06it/s][2025-01-30 02:21:20][root][INFO] - Training Epoch: 1/2, step 5371/107898 completed (loss: 1.107086420059204, acc: 0.7692307829856873)
[2025-01-30 02:21:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5373/107898 [29:10<9:15:00,  3.08it/s][2025-01-30 02:21:20][root][INFO] - Training Epoch: 1/2, step 5372/107898 completed (loss: 3.836437463760376, acc: 0.2666666805744171)
[2025-01-30 02:21:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5374/107898 [29:11<9:03:51,  3.14it/s][2025-01-30 02:21:20][root][INFO] - Training Epoch: 1/2, step 5373/107898 completed (loss: 0.0528392530977726, acc: 1.0)
[2025-01-30 02:21:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5375/107898 [29:11<9:21:21,  3.04it/s][2025-01-30 02:21:21][root][INFO] - Training Epoch: 1/2, step 5374/107898 completed (loss: 0.46501395106315613, acc: 0.6666666865348816)
[2025-01-30 02:21:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5376/107898 [29:11<9:34:49,  2.97it/s][2025-01-30 02:21:21][root][INFO] - Training Epoch: 1/2, step 5375/107898 completed (loss: 1.905641794204712, acc: 0.5)
[2025-01-30 02:21:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5377/107898 [29:12<9:27:33,  3.01it/s][2025-01-30 02:21:22][root][INFO] - Training Epoch: 1/2, step 5376/107898 completed (loss: 0.04109739884734154, acc: 1.0)
[2025-01-30 02:21:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5378/107898 [29:12<9:15:31,  3.08it/s][2025-01-30 02:21:22][root][INFO] - Training Epoch: 1/2, step 5377/107898 completed (loss: 0.28087764978408813, acc: 1.0)
[2025-01-30 02:21:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5379/107898 [29:12<9:17:14,  3.07it/s][2025-01-30 02:21:22][root][INFO] - Training Epoch: 1/2, step 5378/107898 completed (loss: 0.5305191874504089, acc: 0.8888888955116272)
[2025-01-30 02:21:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5380/107898 [29:13<9:20:57,  3.05it/s][2025-01-30 02:21:22][root][INFO] - Training Epoch: 1/2, step 5379/107898 completed (loss: 0.1399030238389969, acc: 1.0)
[2025-01-30 02:21:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5381/107898 [29:13<9:23:15,  3.03it/s][2025-01-30 02:21:23][root][INFO] - Training Epoch: 1/2, step 5380/107898 completed (loss: 0.41399508714675903, acc: 1.0)
[2025-01-30 02:21:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5382/107898 [29:13<9:08:39,  3.11it/s][2025-01-30 02:21:23][root][INFO] - Training Epoch: 1/2, step 5381/107898 completed (loss: 0.005172297358512878, acc: 1.0)
[2025-01-30 02:21:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5383/107898 [29:14<9:30:20,  3.00it/s][2025-01-30 02:21:23][root][INFO] - Training Epoch: 1/2, step 5382/107898 completed (loss: 0.8648067116737366, acc: 0.8947368264198303)
[2025-01-30 02:21:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5384/107898 [29:14<9:37:08,  2.96it/s][2025-01-30 02:21:24][root][INFO] - Training Epoch: 1/2, step 5383/107898 completed (loss: 2.007267475128174, acc: 0.5)
[2025-01-30 02:21:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5385/107898 [29:14<9:35:46,  2.97it/s][2025-01-30 02:21:24][root][INFO] - Training Epoch: 1/2, step 5384/107898 completed (loss: 2.258474111557007, acc: 0.4166666567325592)
[2025-01-30 02:21:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5386/107898 [29:15<9:45:01,  2.92it/s][2025-01-30 02:21:25][root][INFO] - Training Epoch: 1/2, step 5385/107898 completed (loss: 0.002287237672135234, acc: 1.0)
[2025-01-30 02:21:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5387/107898 [29:15<10:00:59,  2.84it/s][2025-01-30 02:21:25][root][INFO] - Training Epoch: 1/2, step 5386/107898 completed (loss: 2.5292813777923584, acc: 0.20000000298023224)
[2025-01-30 02:21:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5388/107898 [29:15<9:52:09,  2.89it/s] [2025-01-30 02:21:25][root][INFO] - Training Epoch: 1/2, step 5387/107898 completed (loss: 0.026263438165187836, acc: 1.0)
[2025-01-30 02:21:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5389/107898 [29:16<9:25:06,  3.02it/s][2025-01-30 02:21:26][root][INFO] - Training Epoch: 1/2, step 5388/107898 completed (loss: 0.12752366065979004, acc: 1.0)
[2025-01-30 02:21:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5390/107898 [29:16<9:11:57,  3.10it/s][2025-01-30 02:21:26][root][INFO] - Training Epoch: 1/2, step 5389/107898 completed (loss: 1.052445888519287, acc: 0.8260869383811951)
[2025-01-30 02:21:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5391/107898 [29:16<9:08:03,  3.12it/s][2025-01-30 02:21:26][root][INFO] - Training Epoch: 1/2, step 5390/107898 completed (loss: 1.5477007627487183, acc: 0.6399999856948853)
[2025-01-30 02:21:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5392/107898 [29:17<9:15:44,  3.07it/s][2025-01-30 02:21:26][root][INFO] - Training Epoch: 1/2, step 5391/107898 completed (loss: 0.017635097727179527, acc: 1.0)
[2025-01-30 02:21:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5393/107898 [29:17<9:21:14,  3.04it/s][2025-01-30 02:21:27][root][INFO] - Training Epoch: 1/2, step 5392/107898 completed (loss: 3.3350636959075928, acc: 0.4583333432674408)
[2025-01-30 02:21:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–         [0m| 5394/107898 [29:17<9:14:22,  3.08it/s][2025-01-30 02:21:27][root][INFO] - Training Epoch: 1/2, step 5393/107898 completed (loss: 0.005282623693346977, acc: 1.0)
[2025-01-30 02:21:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5395/107898 [29:18<9:09:45,  3.11it/s][2025-01-30 02:21:27][root][INFO] - Training Epoch: 1/2, step 5394/107898 completed (loss: 1.3466845750808716, acc: 0.8214285969734192)
[2025-01-30 02:21:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5396/107898 [29:18<9:08:01,  3.12it/s][2025-01-30 02:21:28][root][INFO] - Training Epoch: 1/2, step 5395/107898 completed (loss: 0.1434667408466339, acc: 0.9411764740943909)
[2025-01-30 02:21:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5397/107898 [29:18<8:58:35,  3.17it/s][2025-01-30 02:21:28][root][INFO] - Training Epoch: 1/2, step 5396/107898 completed (loss: 0.004987996071577072, acc: 1.0)
[2025-01-30 02:21:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5398/107898 [29:19<8:29:44,  3.35it/s][2025-01-30 02:21:28][root][INFO] - Training Epoch: 1/2, step 5397/107898 completed (loss: 0.007250078022480011, acc: 1.0)
[2025-01-30 02:21:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5399/107898 [29:19<8:29:13,  3.35it/s][2025-01-30 02:21:29][root][INFO] - Training Epoch: 1/2, step 5398/107898 completed (loss: 0.0012780476827174425, acc: 1.0)
[2025-01-30 02:21:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5400/107898 [29:19<8:53:30,  3.20it/s][2025-01-30 02:21:29][root][INFO] - Training Epoch: 1/2, step 5399/107898 completed (loss: 0.961319625377655, acc: 0.7777777910232544)
[2025-01-30 02:21:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5401/107898 [29:19<8:52:02,  3.21it/s][2025-01-30 02:21:29][root][INFO] - Training Epoch: 1/2, step 5400/107898 completed (loss: 0.0008218131260946393, acc: 1.0)
[2025-01-30 02:21:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5402/107898 [29:20<9:02:59,  3.15it/s][2025-01-30 02:21:30][root][INFO] - Training Epoch: 1/2, step 5401/107898 completed (loss: 1.7499929666519165, acc: 0.7777777910232544)
[2025-01-30 02:21:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5403/107898 [29:20<9:27:13,  3.01it/s][2025-01-30 02:21:30][root][INFO] - Training Epoch: 1/2, step 5402/107898 completed (loss: 0.028271952643990517, acc: 1.0)
[2025-01-30 02:21:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5404/107898 [29:21<9:27:07,  3.01it/s][2025-01-30 02:21:30][root][INFO] - Training Epoch: 1/2, step 5403/107898 completed (loss: 0.01364722941070795, acc: 1.0)
[2025-01-30 02:21:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5405/107898 [29:21<9:24:58,  3.02it/s][2025-01-30 02:21:31][root][INFO] - Training Epoch: 1/2, step 5404/107898 completed (loss: 0.033779364079236984, acc: 1.0)
[2025-01-30 02:21:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5406/107898 [29:21<9:06:45,  3.12it/s][2025-01-30 02:21:31][root][INFO] - Training Epoch: 1/2, step 5405/107898 completed (loss: 0.027662165462970734, acc: 1.0)
[2025-01-30 02:21:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5407/107898 [29:21<9:06:16,  3.13it/s][2025-01-30 02:21:31][root][INFO] - Training Epoch: 1/2, step 5406/107898 completed (loss: 0.9845908284187317, acc: 0.7878788113594055)
[2025-01-30 02:21:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5408/107898 [29:22<9:23:08,  3.03it/s][2025-01-30 02:21:32][root][INFO] - Training Epoch: 1/2, step 5407/107898 completed (loss: 1.8682763576507568, acc: 0.6666666865348816)
[2025-01-30 02:21:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5409/107898 [29:22<9:42:37,  2.93it/s][2025-01-30 02:21:32][root][INFO] - Training Epoch: 1/2, step 5408/107898 completed (loss: 0.0966569185256958, acc: 1.0)
[2025-01-30 02:21:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5410/107898 [29:23<9:32:40,  2.98it/s][2025-01-30 02:21:32][root][INFO] - Training Epoch: 1/2, step 5409/107898 completed (loss: 0.0017385908868163824, acc: 1.0)
[2025-01-30 02:21:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5411/107898 [29:23<9:21:11,  3.04it/s][2025-01-30 02:21:33][root][INFO] - Training Epoch: 1/2, step 5410/107898 completed (loss: 0.7777096033096313, acc: 1.0)
[2025-01-30 02:21:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5412/107898 [29:23<8:59:45,  3.16it/s][2025-01-30 02:21:33][root][INFO] - Training Epoch: 1/2, step 5411/107898 completed (loss: 0.023246372118592262, acc: 1.0)
[2025-01-30 02:21:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5413/107898 [29:23<8:50:43,  3.22it/s][2025-01-30 02:21:33][root][INFO] - Training Epoch: 1/2, step 5412/107898 completed (loss: 4.421868324279785, acc: 0.2631579041481018)
[2025-01-30 02:21:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5414/107898 [29:24<8:40:49,  3.28it/s][2025-01-30 02:21:33][root][INFO] - Training Epoch: 1/2, step 5413/107898 completed (loss: 2.963865280151367, acc: 0.3333333432674408)
[2025-01-30 02:21:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5415/107898 [29:24<9:06:51,  3.12it/s][2025-01-30 02:21:34][root][INFO] - Training Epoch: 1/2, step 5414/107898 completed (loss: 0.03050781786441803, acc: 1.0)
[2025-01-30 02:21:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5416/107898 [29:24<9:45:56,  2.91it/s][2025-01-30 02:21:34][root][INFO] - Training Epoch: 1/2, step 5415/107898 completed (loss: 1.3068761825561523, acc: 0.800000011920929)
[2025-01-30 02:21:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5417/107898 [29:25<9:43:11,  2.93it/s][2025-01-30 02:21:35][root][INFO] - Training Epoch: 1/2, step 5416/107898 completed (loss: 0.6327530741691589, acc: 0.8571428656578064)
[2025-01-30 02:21:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5418/107898 [29:25<9:45:47,  2.92it/s][2025-01-30 02:21:35][root][INFO] - Training Epoch: 1/2, step 5417/107898 completed (loss: 3.511700391769409, acc: 0.3913043439388275)
[2025-01-30 02:21:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5419/107898 [29:25<9:47:32,  2.91it/s][2025-01-30 02:21:35][root][INFO] - Training Epoch: 1/2, step 5418/107898 completed (loss: 2.584812879562378, acc: 0.800000011920929)
[2025-01-30 02:21:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5420/107898 [29:26<9:39:33,  2.95it/s][2025-01-30 02:21:36][root][INFO] - Training Epoch: 1/2, step 5419/107898 completed (loss: 0.028526760637760162, acc: 1.0)
[2025-01-30 02:21:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5421/107898 [29:26<10:03:35,  2.83it/s][2025-01-30 02:21:36][root][INFO] - Training Epoch: 1/2, step 5420/107898 completed (loss: 1.3402185440063477, acc: 0.7857142686843872)
[2025-01-30 02:21:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5422/107898 [29:27<9:52:55,  2.88it/s] [2025-01-30 02:21:36][root][INFO] - Training Epoch: 1/2, step 5421/107898 completed (loss: 0.023102810606360435, acc: 1.0)
[2025-01-30 02:21:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5423/107898 [29:27<9:38:33,  2.95it/s][2025-01-30 02:21:37][root][INFO] - Training Epoch: 1/2, step 5422/107898 completed (loss: 0.11181227117776871, acc: 1.0)
[2025-01-30 02:21:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5424/107898 [29:27<9:17:12,  3.07it/s][2025-01-30 02:21:37][root][INFO] - Training Epoch: 1/2, step 5423/107898 completed (loss: 1.3459086418151855, acc: 0.8181818127632141)
[2025-01-30 02:21:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5425/107898 [29:27<9:08:17,  3.11it/s][2025-01-30 02:21:37][root][INFO] - Training Epoch: 1/2, step 5424/107898 completed (loss: 0.29093697667121887, acc: 0.8888888955116272)
[2025-01-30 02:21:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5426/107898 [29:28<9:06:33,  3.12it/s][2025-01-30 02:21:38][root][INFO] - Training Epoch: 1/2, step 5425/107898 completed (loss: 0.7000765800476074, acc: 0.8333333134651184)
[2025-01-30 02:21:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5427/107898 [29:28<9:36:12,  2.96it/s][2025-01-30 02:21:38][root][INFO] - Training Epoch: 1/2, step 5426/107898 completed (loss: 0.5747392773628235, acc: 0.8421052694320679)
[2025-01-30 02:21:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5428/107898 [29:29<9:55:08,  2.87it/s][2025-01-30 02:21:38][root][INFO] - Training Epoch: 1/2, step 5427/107898 completed (loss: 0.03195041045546532, acc: 1.0)
[2025-01-30 02:21:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5429/107898 [29:29<10:06:09,  2.82it/s][2025-01-30 02:21:39][root][INFO] - Training Epoch: 1/2, step 5428/107898 completed (loss: 6.6043548583984375, acc: 0.0)
[2025-01-30 02:21:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5430/107898 [29:29<9:47:40,  2.91it/s] [2025-01-30 02:21:39][root][INFO] - Training Epoch: 1/2, step 5429/107898 completed (loss: 0.18103264272212982, acc: 1.0)
[2025-01-30 02:21:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5431/107898 [29:30<9:24:43,  3.02it/s][2025-01-30 02:21:39][root][INFO] - Training Epoch: 1/2, step 5430/107898 completed (loss: 0.012287224642932415, acc: 1.0)
[2025-01-30 02:21:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5432/107898 [29:30<9:18:52,  3.06it/s][2025-01-30 02:21:40][root][INFO] - Training Epoch: 1/2, step 5431/107898 completed (loss: 2.56744647026062, acc: 0.0)
[2025-01-30 02:21:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5433/107898 [29:30<9:41:34,  2.94it/s][2025-01-30 02:21:40][root][INFO] - Training Epoch: 1/2, step 5432/107898 completed (loss: 1.2847065925598145, acc: 0.695652186870575)
[2025-01-30 02:21:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5434/107898 [29:31<9:23:51,  3.03it/s][2025-01-30 02:21:40][root][INFO] - Training Epoch: 1/2, step 5433/107898 completed (loss: 0.07708533108234406, acc: 1.0)
[2025-01-30 02:21:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5435/107898 [29:31<9:04:07,  3.14it/s][2025-01-30 02:21:41][root][INFO] - Training Epoch: 1/2, step 5434/107898 completed (loss: 4.497329235076904, acc: 0.3333333432674408)
[2025-01-30 02:21:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5436/107898 [29:31<9:12:31,  3.09it/s][2025-01-30 02:21:41][root][INFO] - Training Epoch: 1/2, step 5435/107898 completed (loss: 0.41900911927223206, acc: 0.6666666865348816)
[2025-01-30 02:21:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5437/107898 [29:31<9:13:00,  3.09it/s][2025-01-30 02:21:41][root][INFO] - Training Epoch: 1/2, step 5436/107898 completed (loss: 0.001142070279456675, acc: 1.0)
[2025-01-30 02:21:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5438/107898 [29:32<9:09:16,  3.11it/s][2025-01-30 02:21:42][root][INFO] - Training Epoch: 1/2, step 5437/107898 completed (loss: 0.6037819385528564, acc: 0.800000011920929)
[2025-01-30 02:21:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5439/107898 [29:32<9:20:25,  3.05it/s][2025-01-30 02:21:42][root][INFO] - Training Epoch: 1/2, step 5438/107898 completed (loss: 0.0885336622595787, acc: 0.95652174949646)
[2025-01-30 02:21:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5440/107898 [29:32<9:12:56,  3.09it/s][2025-01-30 02:21:42][root][INFO] - Training Epoch: 1/2, step 5439/107898 completed (loss: 0.08732563257217407, acc: 1.0)
[2025-01-30 02:21:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5441/107898 [29:33<9:10:40,  3.10it/s][2025-01-30 02:21:43][root][INFO] - Training Epoch: 1/2, step 5440/107898 completed (loss: 0.6493476629257202, acc: 0.8571428656578064)
[2025-01-30 02:21:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5442/107898 [29:33<9:28:59,  3.00it/s][2025-01-30 02:21:43][root][INFO] - Training Epoch: 1/2, step 5441/107898 completed (loss: 0.020861349999904633, acc: 1.0)
[2025-01-30 02:21:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5443/107898 [29:33<9:37:27,  2.96it/s][2025-01-30 02:21:43][root][INFO] - Training Epoch: 1/2, step 5442/107898 completed (loss: 0.08188600093126297, acc: 1.0)
[2025-01-30 02:21:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5444/107898 [29:34<9:20:12,  3.05it/s][2025-01-30 02:21:44][root][INFO] - Training Epoch: 1/2, step 5443/107898 completed (loss: 0.8660986423492432, acc: 0.6666666865348816)
[2025-01-30 02:21:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5445/107898 [29:34<9:33:10,  2.98it/s][2025-01-30 02:21:44][root][INFO] - Training Epoch: 1/2, step 5444/107898 completed (loss: 0.36675387620925903, acc: 0.9210526347160339)
[2025-01-30 02:21:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5446/107898 [29:34<9:32:45,  2.98it/s][2025-01-30 02:21:44][root][INFO] - Training Epoch: 1/2, step 5445/107898 completed (loss: 0.06057266891002655, acc: 1.0)
[2025-01-30 02:21:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5447/107898 [29:35<9:18:46,  3.06it/s][2025-01-30 02:21:45][root][INFO] - Training Epoch: 1/2, step 5446/107898 completed (loss: 0.8683411478996277, acc: 0.8999999761581421)
[2025-01-30 02:21:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5448/107898 [29:35<9:02:44,  3.15it/s][2025-01-30 02:21:45][root][INFO] - Training Epoch: 1/2, step 5447/107898 completed (loss: 0.09214604645967484, acc: 1.0)
[2025-01-30 02:21:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5449/107898 [29:35<9:05:11,  3.13it/s][2025-01-30 02:21:45][root][INFO] - Training Epoch: 1/2, step 5448/107898 completed (loss: 3.593693256378174, acc: 0.20000000298023224)
[2025-01-30 02:21:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5450/107898 [29:36<9:17:50,  3.06it/s][2025-01-30 02:21:46][root][INFO] - Training Epoch: 1/2, step 5449/107898 completed (loss: 1.362037181854248, acc: 0.800000011920929)
[2025-01-30 02:21:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5451/107898 [29:36<9:23:54,  3.03it/s][2025-01-30 02:21:46][root][INFO] - Training Epoch: 1/2, step 5450/107898 completed (loss: 0.6750666499137878, acc: 0.9090909361839294)
[2025-01-30 02:21:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5452/107898 [29:36<9:30:42,  2.99it/s][2025-01-30 02:21:46][root][INFO] - Training Epoch: 1/2, step 5451/107898 completed (loss: 0.8676064610481262, acc: 0.875)
[2025-01-30 02:21:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5453/107898 [29:37<9:27:27,  3.01it/s][2025-01-30 02:21:47][root][INFO] - Training Epoch: 1/2, step 5452/107898 completed (loss: 0.25683194398880005, acc: 1.0)
[2025-01-30 02:21:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5454/107898 [29:37<9:20:49,  3.04it/s][2025-01-30 02:21:47][root][INFO] - Training Epoch: 1/2, step 5453/107898 completed (loss: 0.03467506542801857, acc: 1.0)
[2025-01-30 02:21:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5455/107898 [29:37<9:13:23,  3.09it/s][2025-01-30 02:21:47][root][INFO] - Training Epoch: 1/2, step 5454/107898 completed (loss: 0.14327366650104523, acc: 1.0)
[2025-01-30 02:21:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5456/107898 [29:38<9:08:40,  3.11it/s][2025-01-30 02:21:47][root][INFO] - Training Epoch: 1/2, step 5455/107898 completed (loss: 0.6218320727348328, acc: 0.6666666865348816)
[2025-01-30 02:21:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5457/107898 [29:38<9:35:10,  2.97it/s][2025-01-30 02:21:48][root][INFO] - Training Epoch: 1/2, step 5456/107898 completed (loss: 0.117680624127388, acc: 1.0)
[2025-01-30 02:21:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5458/107898 [29:38<9:33:27,  2.98it/s][2025-01-30 02:21:48][root][INFO] - Training Epoch: 1/2, step 5457/107898 completed (loss: 0.03256085887551308, acc: 1.0)
[2025-01-30 02:21:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5459/107898 [29:39<9:44:56,  2.92it/s][2025-01-30 02:21:49][root][INFO] - Training Epoch: 1/2, step 5458/107898 completed (loss: 2.5817134380340576, acc: 0.5)
[2025-01-30 02:21:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5460/107898 [29:39<10:00:00,  2.85it/s][2025-01-30 02:21:49][root][INFO] - Training Epoch: 1/2, step 5459/107898 completed (loss: 0.7385369539260864, acc: 0.800000011920929)
[2025-01-30 02:21:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5461/107898 [29:39<10:03:37,  2.83it/s][2025-01-30 02:21:49][root][INFO] - Training Epoch: 1/2, step 5460/107898 completed (loss: 0.37799307703971863, acc: 0.9130434989929199)
[2025-01-30 02:21:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5462/107898 [29:40<9:55:28,  2.87it/s] [2025-01-30 02:21:50][root][INFO] - Training Epoch: 1/2, step 5461/107898 completed (loss: 0.0026311578694730997, acc: 1.0)
[2025-01-30 02:21:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5463/107898 [29:40<9:34:28,  2.97it/s][2025-01-30 02:21:50][root][INFO] - Training Epoch: 1/2, step 5462/107898 completed (loss: 0.0011396199697628617, acc: 1.0)
[2025-01-30 02:21:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5464/107898 [29:40<9:23:27,  3.03it/s][2025-01-30 02:21:50][root][INFO] - Training Epoch: 1/2, step 5463/107898 completed (loss: 0.09661638736724854, acc: 1.0)
[2025-01-30 02:21:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5465/107898 [29:41<9:37:01,  2.96it/s][2025-01-30 02:21:51][root][INFO] - Training Epoch: 1/2, step 5464/107898 completed (loss: 0.47909677028656006, acc: 0.6666666865348816)
[2025-01-30 02:21:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5466/107898 [29:41<9:37:18,  2.96it/s][2025-01-30 02:21:51][root][INFO] - Training Epoch: 1/2, step 5465/107898 completed (loss: 0.17230379581451416, acc: 0.9473684430122375)
[2025-01-30 02:21:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5467/107898 [29:41<9:34:14,  2.97it/s][2025-01-30 02:21:51][root][INFO] - Training Epoch: 1/2, step 5466/107898 completed (loss: 0.8796367645263672, acc: 0.8235294222831726)
[2025-01-30 02:21:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5468/107898 [29:42<9:33:53,  2.97it/s][2025-01-30 02:21:52][root][INFO] - Training Epoch: 1/2, step 5467/107898 completed (loss: 0.3739807903766632, acc: 1.0)
[2025-01-30 02:21:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5469/107898 [29:42<9:20:53,  3.04it/s][2025-01-30 02:21:52][root][INFO] - Training Epoch: 1/2, step 5468/107898 completed (loss: 0.0018514719558879733, acc: 1.0)
[2025-01-30 02:21:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5470/107898 [29:42<9:08:20,  3.11it/s][2025-01-30 02:21:52][root][INFO] - Training Epoch: 1/2, step 5469/107898 completed (loss: 0.47409626841545105, acc: 0.8333333134651184)
[2025-01-30 02:21:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5471/107898 [29:43<8:50:29,  3.22it/s][2025-01-30 02:21:52][root][INFO] - Training Epoch: 1/2, step 5470/107898 completed (loss: 1.3028457164764404, acc: 0.8260869383811951)
[2025-01-30 02:21:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5472/107898 [29:43<9:08:21,  3.11it/s][2025-01-30 02:21:53][root][INFO] - Training Epoch: 1/2, step 5471/107898 completed (loss: 0.012500114738941193, acc: 1.0)
[2025-01-30 02:21:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5473/107898 [29:43<9:08:38,  3.11it/s][2025-01-30 02:21:53][root][INFO] - Training Epoch: 1/2, step 5472/107898 completed (loss: 0.3920813202857971, acc: 0.9333333373069763)
[2025-01-30 02:21:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5474/107898 [29:44<9:11:31,  3.10it/s][2025-01-30 02:21:53][root][INFO] - Training Epoch: 1/2, step 5473/107898 completed (loss: 0.3617732524871826, acc: 0.875)
[2025-01-30 02:21:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5475/107898 [29:44<9:05:33,  3.13it/s][2025-01-30 02:21:54][root][INFO] - Training Epoch: 1/2, step 5474/107898 completed (loss: 0.23792992532253265, acc: 0.9166666865348816)
[2025-01-30 02:21:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5476/107898 [29:44<8:59:24,  3.16it/s][2025-01-30 02:21:54][root][INFO] - Training Epoch: 1/2, step 5475/107898 completed (loss: 1.887270212173462, acc: 0.4000000059604645)
[2025-01-30 02:21:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5477/107898 [29:45<9:11:41,  3.09it/s][2025-01-30 02:21:54][root][INFO] - Training Epoch: 1/2, step 5476/107898 completed (loss: 0.06714145094156265, acc: 1.0)
[2025-01-30 02:21:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5478/107898 [29:45<9:45:26,  2.92it/s][2025-01-30 02:21:55][root][INFO] - Training Epoch: 1/2, step 5477/107898 completed (loss: 1.750672698020935, acc: 0.695652186870575)
[2025-01-30 02:21:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5479/107898 [29:45<9:56:40,  2.86it/s][2025-01-30 02:21:55][root][INFO] - Training Epoch: 1/2, step 5478/107898 completed (loss: 0.14848877489566803, acc: 1.0)
[2025-01-30 02:21:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5480/107898 [29:46<9:28:46,  3.00it/s][2025-01-30 02:21:55][root][INFO] - Training Epoch: 1/2, step 5479/107898 completed (loss: 1.6667166948318481, acc: 0.7777777910232544)
[2025-01-30 02:21:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5481/107898 [29:46<9:24:36,  3.02it/s][2025-01-30 02:21:56][root][INFO] - Training Epoch: 1/2, step 5480/107898 completed (loss: 0.035651352256536484, acc: 1.0)
[2025-01-30 02:21:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5482/107898 [29:46<9:27:09,  3.01it/s][2025-01-30 02:21:56][root][INFO] - Training Epoch: 1/2, step 5481/107898 completed (loss: 0.5911906361579895, acc: 1.0)
[2025-01-30 02:21:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5483/107898 [29:47<9:56:52,  2.86it/s][2025-01-30 02:21:57][root][INFO] - Training Epoch: 1/2, step 5482/107898 completed (loss: 0.294332891702652, acc: 0.949999988079071)
[2025-01-30 02:21:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5484/107898 [29:47<10:02:46,  2.83it/s][2025-01-30 02:21:57][root][INFO] - Training Epoch: 1/2, step 5483/107898 completed (loss: 1.3448392152786255, acc: 0.75)
[2025-01-30 02:21:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5485/107898 [29:47<9:54:08,  2.87it/s] [2025-01-30 02:21:57][root][INFO] - Training Epoch: 1/2, step 5484/107898 completed (loss: 1.1560136079788208, acc: 0.699999988079071)
[2025-01-30 02:21:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5486/107898 [29:48<9:36:38,  2.96it/s][2025-01-30 02:21:58][root][INFO] - Training Epoch: 1/2, step 5485/107898 completed (loss: 2.3590786457061768, acc: 0.6666666865348816)
[2025-01-30 02:21:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5487/107898 [29:48<9:20:07,  3.05it/s][2025-01-30 02:21:58][root][INFO] - Training Epoch: 1/2, step 5486/107898 completed (loss: 0.9603617191314697, acc: 0.0)
[2025-01-30 02:21:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5488/107898 [29:48<9:45:41,  2.91it/s][2025-01-30 02:21:58][root][INFO] - Training Epoch: 1/2, step 5487/107898 completed (loss: 0.174343541264534, acc: 0.9411764740943909)
[2025-01-30 02:21:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5489/107898 [29:49<9:41:11,  2.94it/s][2025-01-30 02:21:59][root][INFO] - Training Epoch: 1/2, step 5488/107898 completed (loss: 1.204147458076477, acc: 0.7857142686843872)
[2025-01-30 02:21:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5490/107898 [29:49<9:38:46,  2.95it/s][2025-01-30 02:21:59][root][INFO] - Training Epoch: 1/2, step 5489/107898 completed (loss: 10.613089561462402, acc: 0.3333333432674408)
[2025-01-30 02:21:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5491/107898 [29:49<9:26:27,  3.01it/s][2025-01-30 02:21:59][root][INFO] - Training Epoch: 1/2, step 5490/107898 completed (loss: 0.00390373426489532, acc: 1.0)
[2025-01-30 02:21:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5492/107898 [29:50<9:10:07,  3.10it/s][2025-01-30 02:22:00][root][INFO] - Training Epoch: 1/2, step 5491/107898 completed (loss: 0.7275593280792236, acc: 0.800000011920929)
[2025-01-30 02:22:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5493/107898 [29:50<9:31:36,  2.99it/s][2025-01-30 02:22:00][root][INFO] - Training Epoch: 1/2, step 5492/107898 completed (loss: 0.141130730509758, acc: 1.0)
[2025-01-30 02:22:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5494/107898 [29:50<9:35:55,  2.96it/s][2025-01-30 02:22:00][root][INFO] - Training Epoch: 1/2, step 5493/107898 completed (loss: 3.1834850311279297, acc: 0.25)
[2025-01-30 02:22:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5495/107898 [29:51<9:35:56,  2.96it/s][2025-01-30 02:22:01][root][INFO] - Training Epoch: 1/2, step 5494/107898 completed (loss: 1.0009441375732422, acc: 0.8571428656578064)
[2025-01-30 02:22:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5496/107898 [29:51<9:18:23,  3.06it/s][2025-01-30 02:22:01][root][INFO] - Training Epoch: 1/2, step 5495/107898 completed (loss: 0.3545999228954315, acc: 0.6666666865348816)
[2025-01-30 02:22:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5497/107898 [29:51<8:58:32,  3.17it/s][2025-01-30 02:22:01][root][INFO] - Training Epoch: 1/2, step 5496/107898 completed (loss: 1.2823039293289185, acc: 0.6666666865348816)
[2025-01-30 02:22:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5498/107898 [29:52<9:04:59,  3.13it/s][2025-01-30 02:22:01][root][INFO] - Training Epoch: 1/2, step 5497/107898 completed (loss: 4.043535232543945, acc: 0.13333334028720856)
[2025-01-30 02:22:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5499/107898 [29:52<9:11:11,  3.10it/s][2025-01-30 02:22:02][root][INFO] - Training Epoch: 1/2, step 5498/107898 completed (loss: 0.9119796752929688, acc: 0.6666666865348816)
[2025-01-30 02:22:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5500/107898 [29:52<9:33:27,  2.98it/s][2025-01-30 02:22:02][root][INFO] - Training Epoch: 1/2, step 5499/107898 completed (loss: 0.3695734441280365, acc: 0.800000011920929)
[2025-01-30 02:22:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5501/107898 [29:53<9:30:12,  2.99it/s][2025-01-30 02:22:03][root][INFO] - Training Epoch: 1/2, step 5500/107898 completed (loss: 0.21550948917865753, acc: 1.0)
[2025-01-30 02:22:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5502/107898 [29:53<9:21:08,  3.04it/s][2025-01-30 02:22:03][root][INFO] - Training Epoch: 1/2, step 5501/107898 completed (loss: 0.09619765728712082, acc: 1.0)
[2025-01-30 02:22:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5503/107898 [29:53<8:57:29,  3.18it/s][2025-01-30 02:22:03][root][INFO] - Training Epoch: 1/2, step 5502/107898 completed (loss: 0.3493896424770355, acc: 1.0)
[2025-01-30 02:22:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5504/107898 [29:54<8:46:11,  3.24it/s][2025-01-30 02:22:03][root][INFO] - Training Epoch: 1/2, step 5503/107898 completed (loss: 0.11184456944465637, acc: 1.0)
[2025-01-30 02:22:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5505/107898 [29:54<8:43:28,  3.26it/s][2025-01-30 02:22:04][root][INFO] - Training Epoch: 1/2, step 5504/107898 completed (loss: 0.5926110744476318, acc: 0.8571428656578064)
[2025-01-30 02:22:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5506/107898 [29:54<9:05:47,  3.13it/s][2025-01-30 02:22:04][root][INFO] - Training Epoch: 1/2, step 5505/107898 completed (loss: 0.015336621552705765, acc: 1.0)
[2025-01-30 02:22:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5507/107898 [29:55<9:11:33,  3.09it/s][2025-01-30 02:22:04][root][INFO] - Training Epoch: 1/2, step 5506/107898 completed (loss: 6.704714775085449, acc: 0.0)
[2025-01-30 02:22:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5508/107898 [29:55<8:59:49,  3.16it/s][2025-01-30 02:22:05][root][INFO] - Training Epoch: 1/2, step 5507/107898 completed (loss: 0.01767815090715885, acc: 1.0)
[2025-01-30 02:22:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5509/107898 [29:55<8:34:01,  3.32it/s][2025-01-30 02:22:05][root][INFO] - Training Epoch: 1/2, step 5508/107898 completed (loss: 0.47302719950675964, acc: 0.9090909361839294)
[2025-01-30 02:22:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5510/107898 [29:55<8:31:11,  3.34it/s][2025-01-30 02:22:05][root][INFO] - Training Epoch: 1/2, step 5509/107898 completed (loss: 0.06272755563259125, acc: 1.0)
[2025-01-30 02:22:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5511/107898 [29:56<9:07:56,  3.11it/s][2025-01-30 02:22:06][root][INFO] - Training Epoch: 1/2, step 5510/107898 completed (loss: 1.3252235651016235, acc: 0.75)
[2025-01-30 02:22:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5512/107898 [29:56<9:17:49,  3.06it/s][2025-01-30 02:22:06][root][INFO] - Training Epoch: 1/2, step 5511/107898 completed (loss: 2.8614485263824463, acc: 0.3333333432674408)
[2025-01-30 02:22:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5513/107898 [29:56<9:00:29,  3.16it/s][2025-01-30 02:22:06][root][INFO] - Training Epoch: 1/2, step 5512/107898 completed (loss: 0.2538546323776245, acc: 1.0)
[2025-01-30 02:22:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5514/107898 [29:57<8:48:43,  3.23it/s][2025-01-30 02:22:07][root][INFO] - Training Epoch: 1/2, step 5513/107898 completed (loss: 1.4470986127853394, acc: 0.5)
[2025-01-30 02:22:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5515/107898 [29:57<8:52:33,  3.20it/s][2025-01-30 02:22:07][root][INFO] - Training Epoch: 1/2, step 5514/107898 completed (loss: 1.9358506202697754, acc: 0.5)
[2025-01-30 02:22:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5516/107898 [29:57<8:46:24,  3.24it/s][2025-01-30 02:22:07][root][INFO] - Training Epoch: 1/2, step 5515/107898 completed (loss: 0.6641786098480225, acc: 0.9333333373069763)
[2025-01-30 02:22:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5517/107898 [29:58<8:40:20,  3.28it/s][2025-01-30 02:22:07][root][INFO] - Training Epoch: 1/2, step 5516/107898 completed (loss: 1.400571584701538, acc: 0.75)
[2025-01-30 02:22:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5518/107898 [29:58<8:41:40,  3.27it/s][2025-01-30 02:22:08][root][INFO] - Training Epoch: 1/2, step 5517/107898 completed (loss: 1.614995002746582, acc: 0.6666666865348816)
[2025-01-30 02:22:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5519/107898 [29:58<8:46:02,  3.24it/s][2025-01-30 02:22:08][root][INFO] - Training Epoch: 1/2, step 5518/107898 completed (loss: 0.8906865119934082, acc: 0.7058823704719543)
[2025-01-30 02:22:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5520/107898 [29:59<8:46:07,  3.24it/s][2025-01-30 02:22:08][root][INFO] - Training Epoch: 1/2, step 5519/107898 completed (loss: 1.5699654817581177, acc: 0.692307710647583)
[2025-01-30 02:22:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5521/107898 [29:59<9:18:29,  3.06it/s][2025-01-30 02:22:09][root][INFO] - Training Epoch: 1/2, step 5520/107898 completed (loss: 0.034979913383722305, acc: 1.0)
[2025-01-30 02:22:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5522/107898 [29:59<9:23:35,  3.03it/s][2025-01-30 02:22:09][root][INFO] - Training Epoch: 1/2, step 5521/107898 completed (loss: 1.132928729057312, acc: 0.75)
[2025-01-30 02:22:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5523/107898 [30:00<9:14:33,  3.08it/s][2025-01-30 02:22:09][root][INFO] - Training Epoch: 1/2, step 5522/107898 completed (loss: 0.886484682559967, acc: 0.7272727489471436)
[2025-01-30 02:22:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5524/107898 [30:00<9:27:15,  3.01it/s][2025-01-30 02:22:10][root][INFO] - Training Epoch: 1/2, step 5523/107898 completed (loss: 0.9888388514518738, acc: 0.3333333432674408)
[2025-01-30 02:22:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5525/107898 [30:00<9:25:52,  3.02it/s][2025-01-30 02:22:10][root][INFO] - Training Epoch: 1/2, step 5524/107898 completed (loss: 2.8541901111602783, acc: 0.6000000238418579)
[2025-01-30 02:22:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5526/107898 [30:01<9:28:31,  3.00it/s][2025-01-30 02:22:10][root][INFO] - Training Epoch: 1/2, step 5525/107898 completed (loss: 0.9831170439720154, acc: 0.8181818127632141)
[2025-01-30 02:22:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5527/107898 [30:01<9:20:33,  3.04it/s][2025-01-30 02:22:11][root][INFO] - Training Epoch: 1/2, step 5526/107898 completed (loss: 1.9868913888931274, acc: 0.75)
[2025-01-30 02:22:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5528/107898 [30:01<9:02:47,  3.14it/s][2025-01-30 02:22:11][root][INFO] - Training Epoch: 1/2, step 5527/107898 completed (loss: 1.3507341146469116, acc: 0.0)
[2025-01-30 02:22:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5529/107898 [30:02<9:33:29,  2.97it/s][2025-01-30 02:22:11][root][INFO] - Training Epoch: 1/2, step 5528/107898 completed (loss: 0.6315199136734009, acc: 0.8235294222831726)
[2025-01-30 02:22:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5530/107898 [30:02<9:34:21,  2.97it/s][2025-01-30 02:22:12][root][INFO] - Training Epoch: 1/2, step 5529/107898 completed (loss: 0.7581820487976074, acc: 1.0)
[2025-01-30 02:22:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5531/107898 [30:02<9:21:02,  3.04it/s][2025-01-30 02:22:12][root][INFO] - Training Epoch: 1/2, step 5530/107898 completed (loss: 2.7914106845855713, acc: 0.5)
[2025-01-30 02:22:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5532/107898 [30:03<9:07:07,  3.12it/s][2025-01-30 02:22:12][root][INFO] - Training Epoch: 1/2, step 5531/107898 completed (loss: 1.8144571781158447, acc: 0.75)
[2025-01-30 02:22:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5533/107898 [30:03<8:58:09,  3.17it/s][2025-01-30 02:22:13][root][INFO] - Training Epoch: 1/2, step 5532/107898 completed (loss: 1.559090256690979, acc: 0.5714285969734192)
[2025-01-30 02:22:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5534/107898 [30:03<8:52:35,  3.20it/s][2025-01-30 02:22:13][root][INFO] - Training Epoch: 1/2, step 5533/107898 completed (loss: 1.2115914821624756, acc: 0.8333333134651184)
[2025-01-30 02:22:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5535/107898 [30:04<8:46:52,  3.24it/s][2025-01-30 02:22:13][root][INFO] - Training Epoch: 1/2, step 5534/107898 completed (loss: 0.8873540163040161, acc: 0.9047619104385376)
[2025-01-30 02:22:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5536/107898 [30:04<9:08:49,  3.11it/s][2025-01-30 02:22:14][root][INFO] - Training Epoch: 1/2, step 5535/107898 completed (loss: 0.12581461668014526, acc: 1.0)
[2025-01-30 02:22:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5537/107898 [30:04<9:10:04,  3.10it/s][2025-01-30 02:22:14][root][INFO] - Training Epoch: 1/2, step 5536/107898 completed (loss: 0.5966779589653015, acc: 0.8571428656578064)
[2025-01-30 02:22:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5538/107898 [30:05<9:11:59,  3.09it/s][2025-01-30 02:22:14][root][INFO] - Training Epoch: 1/2, step 5537/107898 completed (loss: 0.09759795665740967, acc: 1.0)
[2025-01-30 02:22:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5539/107898 [30:05<9:02:56,  3.14it/s][2025-01-30 02:22:15][root][INFO] - Training Epoch: 1/2, step 5538/107898 completed (loss: 0.04989786446094513, acc: 1.0)
[2025-01-30 02:22:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5540/107898 [30:05<9:29:20,  3.00it/s][2025-01-30 02:22:15][root][INFO] - Training Epoch: 1/2, step 5539/107898 completed (loss: 1.161751627922058, acc: 0.7272727489471436)
[2025-01-30 02:22:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5541/107898 [30:06<9:26:09,  3.01it/s][2025-01-30 02:22:15][root][INFO] - Training Epoch: 1/2, step 5540/107898 completed (loss: 0.10887810587882996, acc: 1.0)
[2025-01-30 02:22:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5542/107898 [30:06<9:13:48,  3.08it/s][2025-01-30 02:22:16][root][INFO] - Training Epoch: 1/2, step 5541/107898 completed (loss: 0.9632265567779541, acc: 0.8148148059844971)
[2025-01-30 02:22:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5543/107898 [30:06<9:19:53,  3.05it/s][2025-01-30 02:22:16][root][INFO] - Training Epoch: 1/2, step 5542/107898 completed (loss: 3.3535118103027344, acc: 0.2222222238779068)
[2025-01-30 02:22:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5544/107898 [30:06<9:27:16,  3.01it/s][2025-01-30 02:22:16][root][INFO] - Training Epoch: 1/2, step 5543/107898 completed (loss: 1.036227822303772, acc: 0.7333333492279053)
[2025-01-30 02:22:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5545/107898 [30:07<9:25:33,  3.02it/s][2025-01-30 02:22:17][root][INFO] - Training Epoch: 1/2, step 5544/107898 completed (loss: 0.9982664585113525, acc: 0.6666666865348816)
[2025-01-30 02:22:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5546/107898 [30:07<9:53:32,  2.87it/s][2025-01-30 02:22:17][root][INFO] - Training Epoch: 1/2, step 5545/107898 completed (loss: 0.6949970722198486, acc: 0.6666666865348816)
[2025-01-30 02:22:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5547/107898 [30:08<9:45:00,  2.92it/s][2025-01-30 02:22:17][root][INFO] - Training Epoch: 1/2, step 5546/107898 completed (loss: 0.02028920315206051, acc: 1.0)
[2025-01-30 02:22:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5548/107898 [30:08<9:32:18,  2.98it/s][2025-01-30 02:22:18][root][INFO] - Training Epoch: 1/2, step 5547/107898 completed (loss: 2.770416021347046, acc: 0.5454545617103577)
[2025-01-30 02:22:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5549/107898 [30:08<9:24:40,  3.02it/s][2025-01-30 02:22:18][root][INFO] - Training Epoch: 1/2, step 5548/107898 completed (loss: 0.0018723078537732363, acc: 1.0)
[2025-01-30 02:22:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5550/107898 [30:09<9:24:44,  3.02it/s][2025-01-30 02:22:18][root][INFO] - Training Epoch: 1/2, step 5549/107898 completed (loss: 1.1491502523422241, acc: 0.6666666865348816)
[2025-01-30 02:22:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5551/107898 [30:09<9:37:04,  2.96it/s][2025-01-30 02:22:19][root][INFO] - Training Epoch: 1/2, step 5550/107898 completed (loss: 1.5917688608169556, acc: 0.25)
[2025-01-30 02:22:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5552/107898 [30:09<10:01:14,  2.84it/s][2025-01-30 02:22:19][root][INFO] - Training Epoch: 1/2, step 5551/107898 completed (loss: 0.7420490384101868, acc: 0.6666666865348816)
[2025-01-30 02:22:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5553/107898 [30:10<9:46:15,  2.91it/s] [2025-01-30 02:22:19][root][INFO] - Training Epoch: 1/2, step 5552/107898 completed (loss: 0.06371890753507614, acc: 1.0)
[2025-01-30 02:22:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5554/107898 [30:10<9:40:44,  2.94it/s][2025-01-30 02:22:20][root][INFO] - Training Epoch: 1/2, step 5553/107898 completed (loss: 0.1780509501695633, acc: 1.0)
[2025-01-30 02:22:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5555/107898 [30:10<9:25:49,  3.01it/s][2025-01-30 02:22:20][root][INFO] - Training Epoch: 1/2, step 5554/107898 completed (loss: 0.2543959319591522, acc: 1.0)
[2025-01-30 02:22:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5556/107898 [30:11<9:07:04,  3.12it/s][2025-01-30 02:22:20][root][INFO] - Training Epoch: 1/2, step 5555/107898 completed (loss: 1.1274654865264893, acc: 0.6000000238418579)
[2025-01-30 02:22:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5557/107898 [30:11<8:54:29,  3.19it/s][2025-01-30 02:22:21][root][INFO] - Training Epoch: 1/2, step 5556/107898 completed (loss: 0.022772466763854027, acc: 1.0)
[2025-01-30 02:22:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5558/107898 [30:11<9:10:28,  3.10it/s][2025-01-30 02:22:21][root][INFO] - Training Epoch: 1/2, step 5557/107898 completed (loss: 2.1520273685455322, acc: 0.6666666865348816)
[2025-01-30 02:22:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5559/107898 [30:11<9:02:17,  3.15it/s][2025-01-30 02:22:21][root][INFO] - Training Epoch: 1/2, step 5558/107898 completed (loss: 0.7347649335861206, acc: 0.800000011920929)
[2025-01-30 02:22:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5560/107898 [30:12<9:14:10,  3.08it/s][2025-01-30 02:22:22][root][INFO] - Training Epoch: 1/2, step 5559/107898 completed (loss: 0.18107688426971436, acc: 1.0)
[2025-01-30 02:22:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5561/107898 [30:12<9:39:21,  2.94it/s][2025-01-30 02:22:22][root][INFO] - Training Epoch: 1/2, step 5560/107898 completed (loss: 2.4857594966888428, acc: 0.6666666865348816)
[2025-01-30 02:22:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5562/107898 [30:13<9:37:59,  2.95it/s][2025-01-30 02:22:22][root][INFO] - Training Epoch: 1/2, step 5561/107898 completed (loss: 3.2334837913513184, acc: 0.25)
[2025-01-30 02:22:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5563/107898 [30:13<9:51:30,  2.88it/s][2025-01-30 02:22:23][root][INFO] - Training Epoch: 1/2, step 5562/107898 completed (loss: 0.3094047009944916, acc: 0.8421052694320679)
[2025-01-30 02:22:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5564/107898 [30:13<9:38:14,  2.95it/s][2025-01-30 02:22:23][root][INFO] - Training Epoch: 1/2, step 5563/107898 completed (loss: 0.3481793701648712, acc: 0.9333333373069763)
[2025-01-30 02:22:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5565/107898 [30:13<9:14:26,  3.08it/s][2025-01-30 02:22:23][root][INFO] - Training Epoch: 1/2, step 5564/107898 completed (loss: 0.08659922331571579, acc: 1.0)
[2025-01-30 02:22:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5566/107898 [30:14<9:01:26,  3.15it/s][2025-01-30 02:22:24][root][INFO] - Training Epoch: 1/2, step 5565/107898 completed (loss: 1.068560242652893, acc: 0.7307692170143127)
[2025-01-30 02:22:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5567/107898 [30:14<8:41:27,  3.27it/s][2025-01-30 02:22:24][root][INFO] - Training Epoch: 1/2, step 5566/107898 completed (loss: 0.07884003221988678, acc: 1.0)
[2025-01-30 02:22:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5568/107898 [30:14<8:45:34,  3.25it/s][2025-01-30 02:22:24][root][INFO] - Training Epoch: 1/2, step 5567/107898 completed (loss: 0.2823975682258606, acc: 1.0)
[2025-01-30 02:22:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5569/107898 [30:15<8:46:41,  3.24it/s][2025-01-30 02:22:24][root][INFO] - Training Epoch: 1/2, step 5568/107898 completed (loss: 0.9822996854782104, acc: 0.800000011920929)
[2025-01-30 02:22:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5570/107898 [30:15<8:44:34,  3.25it/s][2025-01-30 02:22:25][root][INFO] - Training Epoch: 1/2, step 5569/107898 completed (loss: 1.0851823091506958, acc: 0.9333333373069763)
[2025-01-30 02:22:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5571/107898 [30:15<8:41:50,  3.27it/s][2025-01-30 02:22:25][root][INFO] - Training Epoch: 1/2, step 5570/107898 completed (loss: 0.01264347042888403, acc: 1.0)
[2025-01-30 02:22:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5572/107898 [30:16<8:38:39,  3.29it/s][2025-01-30 02:22:25][root][INFO] - Training Epoch: 1/2, step 5571/107898 completed (loss: 0.13713747262954712, acc: 1.0)
[2025-01-30 02:22:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5573/107898 [30:16<8:36:48,  3.30it/s][2025-01-30 02:22:26][root][INFO] - Training Epoch: 1/2, step 5572/107898 completed (loss: 2.0670177936553955, acc: 0.6000000238418579)
[2025-01-30 02:22:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5574/107898 [30:16<8:55:07,  3.19it/s][2025-01-30 02:22:26][root][INFO] - Training Epoch: 1/2, step 5573/107898 completed (loss: 0.17249344289302826, acc: 1.0)
[2025-01-30 02:22:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5575/107898 [30:17<8:54:47,  3.19it/s][2025-01-30 02:22:26][root][INFO] - Training Epoch: 1/2, step 5574/107898 completed (loss: 0.13535603880882263, acc: 1.0)
[2025-01-30 02:22:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5576/107898 [30:17<8:45:10,  3.25it/s][2025-01-30 02:22:27][root][INFO] - Training Epoch: 1/2, step 5575/107898 completed (loss: 0.45047521591186523, acc: 0.5)
[2025-01-30 02:22:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5577/107898 [30:17<8:48:12,  3.23it/s][2025-01-30 02:22:27][root][INFO] - Training Epoch: 1/2, step 5576/107898 completed (loss: 0.08970297127962112, acc: 1.0)
[2025-01-30 02:22:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5578/107898 [30:17<8:44:31,  3.25it/s][2025-01-30 02:22:27][root][INFO] - Training Epoch: 1/2, step 5577/107898 completed (loss: 0.01923094131052494, acc: 1.0)
[2025-01-30 02:22:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5579/107898 [30:18<8:45:28,  3.25it/s][2025-01-30 02:22:28][root][INFO] - Training Epoch: 1/2, step 5578/107898 completed (loss: 0.08208111673593521, acc: 1.0)
[2025-01-30 02:22:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5580/107898 [30:18<8:43:37,  3.26it/s][2025-01-30 02:22:28][root][INFO] - Training Epoch: 1/2, step 5579/107898 completed (loss: 0.9486337900161743, acc: 0.8999999761581421)
[2025-01-30 02:22:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5581/107898 [30:18<8:46:13,  3.24it/s][2025-01-30 02:22:28][root][INFO] - Training Epoch: 1/2, step 5580/107898 completed (loss: 3.1471047401428223, acc: 0.5789473652839661)
[2025-01-30 02:22:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5582/107898 [30:19<8:40:30,  3.28it/s][2025-01-30 02:22:28][root][INFO] - Training Epoch: 1/2, step 5581/107898 completed (loss: 0.11901184171438217, acc: 1.0)
[2025-01-30 02:22:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5583/107898 [30:19<8:35:18,  3.31it/s][2025-01-30 02:22:29][root][INFO] - Training Epoch: 1/2, step 5582/107898 completed (loss: 1.6199671030044556, acc: 0.6666666865348816)
[2025-01-30 02:22:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5584/107898 [30:19<8:32:52,  3.32it/s][2025-01-30 02:22:29][root][INFO] - Training Epoch: 1/2, step 5583/107898 completed (loss: 2.9389491081237793, acc: 0.5)
[2025-01-30 02:22:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5585/107898 [30:20<8:35:18,  3.31it/s][2025-01-30 02:22:29][root][INFO] - Training Epoch: 1/2, step 5584/107898 completed (loss: 0.00293167307972908, acc: 1.0)
[2025-01-30 02:22:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5586/107898 [30:20<8:58:04,  3.17it/s][2025-01-30 02:22:30][root][INFO] - Training Epoch: 1/2, step 5585/107898 completed (loss: 0.13731224834918976, acc: 1.0)
[2025-01-30 02:22:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5587/107898 [30:20<9:07:04,  3.12it/s][2025-01-30 02:22:30][root][INFO] - Training Epoch: 1/2, step 5586/107898 completed (loss: 0.4202199876308441, acc: 0.8571428656578064)
[2025-01-30 02:22:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5588/107898 [30:21<9:29:21,  2.99it/s][2025-01-30 02:22:30][root][INFO] - Training Epoch: 1/2, step 5587/107898 completed (loss: 0.23192627727985382, acc: 1.0)
[2025-01-30 02:22:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5589/107898 [30:21<9:29:11,  3.00it/s][2025-01-30 02:22:31][root][INFO] - Training Epoch: 1/2, step 5588/107898 completed (loss: 1.0534144639968872, acc: 0.6666666865348816)
[2025-01-30 02:22:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5590/107898 [30:21<9:16:59,  3.06it/s][2025-01-30 02:22:31][root][INFO] - Training Epoch: 1/2, step 5589/107898 completed (loss: 3.2158429622650146, acc: 0.4545454680919647)
[2025-01-30 02:22:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5591/107898 [30:22<9:09:10,  3.10it/s][2025-01-30 02:22:31][root][INFO] - Training Epoch: 1/2, step 5590/107898 completed (loss: 0.7318403720855713, acc: 0.5)
[2025-01-30 02:22:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5592/107898 [30:22<9:05:51,  3.12it/s][2025-01-30 02:22:32][root][INFO] - Training Epoch: 1/2, step 5591/107898 completed (loss: 0.29133641719818115, acc: 1.0)
[2025-01-30 02:22:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5593/107898 [30:22<9:16:54,  3.06it/s][2025-01-30 02:22:32][root][INFO] - Training Epoch: 1/2, step 5592/107898 completed (loss: 0.9807456135749817, acc: 0.6666666865348816)
[2025-01-30 02:22:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5594/107898 [30:23<9:39:04,  2.94it/s][2025-01-30 02:22:32][root][INFO] - Training Epoch: 1/2, step 5593/107898 completed (loss: 0.616955041885376, acc: 0.8888888955116272)
[2025-01-30 02:22:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5595/107898 [30:23<9:46:50,  2.91it/s][2025-01-30 02:22:33][root][INFO] - Training Epoch: 1/2, step 5594/107898 completed (loss: 0.05023709684610367, acc: 1.0)
[2025-01-30 02:22:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5596/107898 [30:23<9:49:15,  2.89it/s][2025-01-30 02:22:33][root][INFO] - Training Epoch: 1/2, step 5595/107898 completed (loss: 2.8402621746063232, acc: 0.75)
[2025-01-30 02:22:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5597/107898 [30:24<9:37:28,  2.95it/s][2025-01-30 02:22:33][root][INFO] - Training Epoch: 1/2, step 5596/107898 completed (loss: 0.39154312014579773, acc: 0.875)
[2025-01-30 02:22:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5598/107898 [30:24<9:47:50,  2.90it/s][2025-01-30 02:22:34][root][INFO] - Training Epoch: 1/2, step 5597/107898 completed (loss: 1.409399151802063, acc: 0.7777777910232544)
[2025-01-30 02:22:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5599/107898 [30:24<9:24:54,  3.02it/s][2025-01-30 02:22:34][root][INFO] - Training Epoch: 1/2, step 5598/107898 completed (loss: 1.1324965953826904, acc: 0.5)
[2025-01-30 02:22:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5600/107898 [30:25<9:45:32,  2.91it/s][2025-01-30 02:22:34][root][INFO] - Training Epoch: 1/2, step 5599/107898 completed (loss: 4.7956366539001465, acc: 0.3333333432674408)
[2025-01-30 02:22:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5601/107898 [30:25<9:44:51,  2.92it/s][2025-01-30 02:22:35][root][INFO] - Training Epoch: 1/2, step 5600/107898 completed (loss: 0.26202428340911865, acc: 1.0)
[2025-01-30 02:22:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5602/107898 [30:25<9:34:04,  2.97it/s][2025-01-30 02:22:35][root][INFO] - Training Epoch: 1/2, step 5601/107898 completed (loss: 0.350608766078949, acc: 0.8888888955116272)
[2025-01-30 02:22:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5603/107898 [30:26<9:22:27,  3.03it/s][2025-01-30 02:22:35][root][INFO] - Training Epoch: 1/2, step 5602/107898 completed (loss: 1.2225016355514526, acc: 0.5263158082962036)
[2025-01-30 02:22:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5604/107898 [30:26<9:38:24,  2.95it/s][2025-01-30 02:22:36][root][INFO] - Training Epoch: 1/2, step 5603/107898 completed (loss: 1.282334566116333, acc: 0.5)
[2025-01-30 02:22:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5605/107898 [30:26<9:51:34,  2.88it/s][2025-01-30 02:22:36][root][INFO] - Training Epoch: 1/2, step 5604/107898 completed (loss: 0.9931368827819824, acc: 0.75)
[2025-01-30 02:22:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5606/107898 [30:27<9:37:30,  2.95it/s][2025-01-30 02:22:36][root][INFO] - Training Epoch: 1/2, step 5605/107898 completed (loss: 0.03152233362197876, acc: 1.0)
[2025-01-30 02:22:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5607/107898 [30:27<9:19:36,  3.05it/s][2025-01-30 02:22:37][root][INFO] - Training Epoch: 1/2, step 5606/107898 completed (loss: 0.07290858775377274, acc: 1.0)
[2025-01-30 02:22:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5608/107898 [30:27<9:24:09,  3.02it/s][2025-01-30 02:22:37][root][INFO] - Training Epoch: 1/2, step 5607/107898 completed (loss: 0.38467881083488464, acc: 0.9230769276618958)
[2025-01-30 02:22:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5609/107898 [30:28<9:19:01,  3.05it/s][2025-01-30 02:22:37][root][INFO] - Training Epoch: 1/2, step 5608/107898 completed (loss: 0.01753534935414791, acc: 1.0)
[2025-01-30 02:22:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5610/107898 [30:28<9:06:09,  3.12it/s][2025-01-30 02:22:38][root][INFO] - Training Epoch: 1/2, step 5609/107898 completed (loss: 0.11217332631349564, acc: 0.9545454382896423)
[2025-01-30 02:22:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5611/107898 [30:28<8:50:22,  3.21it/s][2025-01-30 02:22:38][root][INFO] - Training Epoch: 1/2, step 5610/107898 completed (loss: 0.02327112667262554, acc: 1.0)
[2025-01-30 02:22:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5612/107898 [30:29<8:51:26,  3.21it/s][2025-01-30 02:22:38][root][INFO] - Training Epoch: 1/2, step 5611/107898 completed (loss: 0.1953769326210022, acc: 0.875)
[2025-01-30 02:22:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5613/107898 [30:29<8:36:56,  3.30it/s][2025-01-30 02:22:39][root][INFO] - Training Epoch: 1/2, step 5612/107898 completed (loss: 0.6067085266113281, acc: 0.8333333134651184)
[2025-01-30 02:22:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5614/107898 [30:29<8:31:59,  3.33it/s][2025-01-30 02:22:39][root][INFO] - Training Epoch: 1/2, step 5613/107898 completed (loss: 2.0238969326019287, acc: 0.5714285969734192)
[2025-01-30 02:22:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5615/107898 [30:29<8:32:07,  3.33it/s][2025-01-30 02:22:39][root][INFO] - Training Epoch: 1/2, step 5614/107898 completed (loss: 0.04641778767108917, acc: 1.0)
[2025-01-30 02:22:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5616/107898 [30:30<8:52:27,  3.20it/s][2025-01-30 02:22:40][root][INFO] - Training Epoch: 1/2, step 5615/107898 completed (loss: 0.1139899268746376, acc: 0.949999988079071)
[2025-01-30 02:22:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5617/107898 [30:30<8:49:29,  3.22it/s][2025-01-30 02:22:40][root][INFO] - Training Epoch: 1/2, step 5616/107898 completed (loss: 0.03421690687537193, acc: 1.0)
[2025-01-30 02:22:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5618/107898 [30:30<8:38:38,  3.29it/s][2025-01-30 02:22:40][root][INFO] - Training Epoch: 1/2, step 5617/107898 completed (loss: 0.03917382284998894, acc: 1.0)
[2025-01-30 02:22:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5619/107898 [30:31<9:03:02,  3.14it/s][2025-01-30 02:22:41][root][INFO] - Training Epoch: 1/2, step 5618/107898 completed (loss: 0.0008086856105364859, acc: 1.0)
[2025-01-30 02:22:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5620/107898 [30:31<9:04:19,  3.13it/s][2025-01-30 02:22:41][root][INFO] - Training Epoch: 1/2, step 5619/107898 completed (loss: 0.10440962761640549, acc: 1.0)
[2025-01-30 02:22:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5621/107898 [30:31<8:59:37,  3.16it/s][2025-01-30 02:22:41][root][INFO] - Training Epoch: 1/2, step 5620/107898 completed (loss: 0.3770039975643158, acc: 0.800000011920929)
[2025-01-30 02:22:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5622/107898 [30:32<8:52:18,  3.20it/s][2025-01-30 02:22:41][root][INFO] - Training Epoch: 1/2, step 5621/107898 completed (loss: 0.0029124701395630836, acc: 1.0)
[2025-01-30 02:22:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5623/107898 [30:32<8:48:19,  3.23it/s][2025-01-30 02:22:42][root][INFO] - Training Epoch: 1/2, step 5622/107898 completed (loss: 0.02305307425558567, acc: 1.0)
[2025-01-30 02:22:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5624/107898 [30:32<8:48:29,  3.23it/s][2025-01-30 02:22:42][root][INFO] - Training Epoch: 1/2, step 5623/107898 completed (loss: 1.071104884147644, acc: 0.8333333134651184)
[2025-01-30 02:22:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5625/107898 [30:33<8:45:46,  3.24it/s][2025-01-30 02:22:42][root][INFO] - Training Epoch: 1/2, step 5624/107898 completed (loss: 2.1876156330108643, acc: 0.4000000059604645)
[2025-01-30 02:22:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5626/107898 [30:33<8:40:16,  3.28it/s][2025-01-30 02:22:43][root][INFO] - Training Epoch: 1/2, step 5625/107898 completed (loss: 0.5239378809928894, acc: 0.75)
[2025-01-30 02:22:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5627/107898 [30:33<8:58:17,  3.17it/s][2025-01-30 02:22:43][root][INFO] - Training Epoch: 1/2, step 5626/107898 completed (loss: 0.006457652430981398, acc: 1.0)
[2025-01-30 02:22:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5628/107898 [30:34<9:01:40,  3.15it/s][2025-01-30 02:22:43][root][INFO] - Training Epoch: 1/2, step 5627/107898 completed (loss: 0.0981234461069107, acc: 1.0)
[2025-01-30 02:22:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5629/107898 [30:34<9:01:04,  3.15it/s][2025-01-30 02:22:44][root][INFO] - Training Epoch: 1/2, step 5628/107898 completed (loss: 0.016792071983218193, acc: 1.0)
[2025-01-30 02:22:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5630/107898 [30:34<8:55:40,  3.18it/s][2025-01-30 02:22:44][root][INFO] - Training Epoch: 1/2, step 5629/107898 completed (loss: 0.2671794295310974, acc: 1.0)
[2025-01-30 02:22:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5631/107898 [30:34<8:51:45,  3.21it/s][2025-01-30 02:22:44][root][INFO] - Training Epoch: 1/2, step 5630/107898 completed (loss: 0.07135941088199615, acc: 1.0)
[2025-01-30 02:22:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5632/107898 [30:35<8:44:08,  3.25it/s][2025-01-30 02:22:45][root][INFO] - Training Epoch: 1/2, step 5631/107898 completed (loss: 0.0016606033314019442, acc: 1.0)
[2025-01-30 02:22:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5633/107898 [30:35<8:42:31,  3.26it/s][2025-01-30 02:22:45][root][INFO] - Training Epoch: 1/2, step 5632/107898 completed (loss: 1.1334619522094727, acc: 0.800000011920929)
[2025-01-30 02:22:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5634/107898 [30:35<9:09:10,  3.10it/s][2025-01-30 02:22:45][root][INFO] - Training Epoch: 1/2, step 5633/107898 completed (loss: 0.05932173132896423, acc: 1.0)
[2025-01-30 02:22:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5635/107898 [30:36<9:08:59,  3.10it/s][2025-01-30 02:22:46][root][INFO] - Training Epoch: 1/2, step 5634/107898 completed (loss: 2.097874164581299, acc: 0.6000000238418579)
[2025-01-30 02:22:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5636/107898 [30:36<9:25:12,  3.02it/s][2025-01-30 02:22:46][root][INFO] - Training Epoch: 1/2, step 5635/107898 completed (loss: 3.373798131942749, acc: 0.2222222238779068)
[2025-01-30 02:22:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5637/107898 [30:36<9:13:11,  3.08it/s][2025-01-30 02:22:46][root][INFO] - Training Epoch: 1/2, step 5636/107898 completed (loss: 1.4129332304000854, acc: 0.8333333134651184)
[2025-01-30 02:22:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5638/107898 [30:37<8:51:27,  3.21it/s][2025-01-30 02:22:46][root][INFO] - Training Epoch: 1/2, step 5637/107898 completed (loss: 0.2349616140127182, acc: 1.0)
[2025-01-30 02:22:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5639/107898 [30:37<8:38:29,  3.29it/s][2025-01-30 02:22:47][root][INFO] - Training Epoch: 1/2, step 5638/107898 completed (loss: 3.3453328609466553, acc: 0.5)
[2025-01-30 02:22:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5640/107898 [30:37<8:44:10,  3.25it/s][2025-01-30 02:22:47][root][INFO] - Training Epoch: 1/2, step 5639/107898 completed (loss: 0.7137402892112732, acc: 0.8333333134651184)
[2025-01-30 02:22:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5641/107898 [30:38<8:50:29,  3.21it/s][2025-01-30 02:22:47][root][INFO] - Training Epoch: 1/2, step 5640/107898 completed (loss: 0.00636034132912755, acc: 1.0)
[2025-01-30 02:22:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5642/107898 [30:38<9:08:55,  3.10it/s][2025-01-30 02:22:48][root][INFO] - Training Epoch: 1/2, step 5641/107898 completed (loss: 2.80064058303833, acc: 0.3333333432674408)
[2025-01-30 02:22:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5643/107898 [30:38<8:56:46,  3.17it/s][2025-01-30 02:22:48][root][INFO] - Training Epoch: 1/2, step 5642/107898 completed (loss: 1.6021279096603394, acc: 0.6666666865348816)
[2025-01-30 02:22:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5644/107898 [30:39<8:58:04,  3.17it/s][2025-01-30 02:22:48][root][INFO] - Training Epoch: 1/2, step 5643/107898 completed (loss: 0.5488932132720947, acc: 0.9411764740943909)
[2025-01-30 02:22:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5645/107898 [30:39<8:55:11,  3.18it/s][2025-01-30 02:22:49][root][INFO] - Training Epoch: 1/2, step 5644/107898 completed (loss: 1.940724492073059, acc: 0.6190476417541504)
[2025-01-30 02:22:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5646/107898 [30:39<8:58:24,  3.17it/s][2025-01-30 02:22:49][root][INFO] - Training Epoch: 1/2, step 5645/107898 completed (loss: 1.956562876701355, acc: 0.6153846383094788)
[2025-01-30 02:22:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5647/107898 [30:40<9:26:52,  3.01it/s][2025-01-30 02:22:49][root][INFO] - Training Epoch: 1/2, step 5646/107898 completed (loss: 1.1520662307739258, acc: 0.7407407164573669)
[2025-01-30 02:22:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5648/107898 [30:40<9:02:56,  3.14it/s][2025-01-30 02:22:50][root][INFO] - Training Epoch: 1/2, step 5647/107898 completed (loss: 2.5975406169891357, acc: 0.4000000059604645)
[2025-01-30 02:22:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5649/107898 [30:40<8:49:29,  3.22it/s][2025-01-30 02:22:50][root][INFO] - Training Epoch: 1/2, step 5648/107898 completed (loss: 1.0094283819198608, acc: 0.75)
[2025-01-30 02:22:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5650/107898 [30:40<8:42:14,  3.26it/s][2025-01-30 02:22:50][root][INFO] - Training Epoch: 1/2, step 5649/107898 completed (loss: 0.7319127321243286, acc: 0.78125)
[2025-01-30 02:22:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5651/107898 [30:41<9:03:56,  3.13it/s][2025-01-30 02:22:51][root][INFO] - Training Epoch: 1/2, step 5650/107898 completed (loss: 0.009514875710010529, acc: 1.0)
[2025-01-30 02:22:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5652/107898 [30:41<9:23:30,  3.02it/s][2025-01-30 02:22:51][root][INFO] - Training Epoch: 1/2, step 5651/107898 completed (loss: 1.261273741722107, acc: 0.6499999761581421)
[2025-01-30 02:22:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5653/107898 [30:42<9:48:41,  2.89it/s][2025-01-30 02:22:51][root][INFO] - Training Epoch: 1/2, step 5652/107898 completed (loss: 1.7136573791503906, acc: 0.6666666865348816)
[2025-01-30 02:22:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5654/107898 [30:42<9:40:45,  2.93it/s][2025-01-30 02:22:52][root][INFO] - Training Epoch: 1/2, step 5653/107898 completed (loss: 0.1915379911661148, acc: 1.0)
[2025-01-30 02:22:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5655/107898 [30:42<9:51:59,  2.88it/s][2025-01-30 02:22:52][root][INFO] - Training Epoch: 1/2, step 5654/107898 completed (loss: 1.0778491497039795, acc: 0.8571428656578064)
[2025-01-30 02:22:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5656/107898 [30:43<9:34:45,  2.96it/s][2025-01-30 02:22:52][root][INFO] - Training Epoch: 1/2, step 5655/107898 completed (loss: 0.08201908320188522, acc: 1.0)
[2025-01-30 02:22:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5657/107898 [30:43<9:25:36,  3.01it/s][2025-01-30 02:22:53][root][INFO] - Training Epoch: 1/2, step 5656/107898 completed (loss: 1.1186630725860596, acc: 0.800000011920929)
[2025-01-30 02:22:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5658/107898 [30:43<9:06:32,  3.12it/s][2025-01-30 02:22:53][root][INFO] - Training Epoch: 1/2, step 5657/107898 completed (loss: 3.8714938163757324, acc: 0.0)
[2025-01-30 02:22:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5659/107898 [30:43<8:56:47,  3.17it/s][2025-01-30 02:22:53][root][INFO] - Training Epoch: 1/2, step 5658/107898 completed (loss: 0.03280195966362953, acc: 1.0)
[2025-01-30 02:22:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5660/107898 [30:44<9:28:15,  3.00it/s][2025-01-30 02:22:54][root][INFO] - Training Epoch: 1/2, step 5659/107898 completed (loss: 0.03787214681506157, acc: 1.0)
[2025-01-30 02:22:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5661/107898 [30:44<9:24:38,  3.02it/s][2025-01-30 02:22:54][root][INFO] - Training Epoch: 1/2, step 5660/107898 completed (loss: 0.2689373195171356, acc: 0.9677419066429138)
[2025-01-30 02:22:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5662/107898 [30:44<9:15:51,  3.07it/s][2025-01-30 02:22:54][root][INFO] - Training Epoch: 1/2, step 5661/107898 completed (loss: 0.17880968749523163, acc: 1.0)
[2025-01-30 02:22:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5663/107898 [30:45<9:11:04,  3.09it/s][2025-01-30 02:22:55][root][INFO] - Training Epoch: 1/2, step 5662/107898 completed (loss: 0.17913484573364258, acc: 0.9411764740943909)
[2025-01-30 02:22:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5664/107898 [30:45<8:59:15,  3.16it/s][2025-01-30 02:22:55][root][INFO] - Training Epoch: 1/2, step 5663/107898 completed (loss: 0.0019937155302613974, acc: 1.0)
[2025-01-30 02:22:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5665/107898 [30:45<9:02:43,  3.14it/s][2025-01-30 02:22:55][root][INFO] - Training Epoch: 1/2, step 5664/107898 completed (loss: 0.46010422706604004, acc: 1.0)
[2025-01-30 02:22:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5666/107898 [30:46<9:21:51,  3.03it/s][2025-01-30 02:22:56][root][INFO] - Training Epoch: 1/2, step 5665/107898 completed (loss: 0.22993455827236176, acc: 0.9545454382896423)
[2025-01-30 02:22:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5667/107898 [30:46<9:15:45,  3.07it/s][2025-01-30 02:22:56][root][INFO] - Training Epoch: 1/2, step 5666/107898 completed (loss: 1.268651008605957, acc: 0.8888888955116272)
[2025-01-30 02:22:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5668/107898 [30:46<9:17:01,  3.06it/s][2025-01-30 02:22:56][root][INFO] - Training Epoch: 1/2, step 5667/107898 completed (loss: 3.277770519256592, acc: 0.25)
[2025-01-30 02:22:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5669/107898 [30:47<9:26:34,  3.01it/s][2025-01-30 02:22:57][root][INFO] - Training Epoch: 1/2, step 5668/107898 completed (loss: 1.611402153968811, acc: 0.5)
[2025-01-30 02:22:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5670/107898 [30:47<9:12:23,  3.08it/s][2025-01-30 02:22:57][root][INFO] - Training Epoch: 1/2, step 5669/107898 completed (loss: 0.18120966851711273, acc: 1.0)
[2025-01-30 02:22:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5671/107898 [30:47<8:53:51,  3.19it/s][2025-01-30 02:22:57][root][INFO] - Training Epoch: 1/2, step 5670/107898 completed (loss: 2.219111204147339, acc: 0.75)
[2025-01-30 02:22:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5672/107898 [30:48<8:54:31,  3.19it/s][2025-01-30 02:22:57][root][INFO] - Training Epoch: 1/2, step 5671/107898 completed (loss: 1.9446290731430054, acc: 0.6000000238418579)
[2025-01-30 02:22:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5673/107898 [30:48<9:08:10,  3.11it/s][2025-01-30 02:22:58][root][INFO] - Training Epoch: 1/2, step 5672/107898 completed (loss: 0.48950743675231934, acc: 0.6666666865348816)
[2025-01-30 02:22:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5674/107898 [30:48<8:56:04,  3.18it/s][2025-01-30 02:22:58][root][INFO] - Training Epoch: 1/2, step 5673/107898 completed (loss: 0.502868115901947, acc: 0.6666666865348816)
[2025-01-30 02:22:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5675/107898 [30:49<9:15:23,  3.07it/s][2025-01-30 02:22:58][root][INFO] - Training Epoch: 1/2, step 5674/107898 completed (loss: 0.5371497273445129, acc: 0.8888888955116272)
[2025-01-30 02:22:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5676/107898 [30:49<9:19:11,  3.05it/s][2025-01-30 02:22:59][root][INFO] - Training Epoch: 1/2, step 5675/107898 completed (loss: 0.45156142115592957, acc: 0.6666666865348816)
[2025-01-30 02:22:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5677/107898 [30:49<9:09:00,  3.10it/s][2025-01-30 02:22:59][root][INFO] - Training Epoch: 1/2, step 5676/107898 completed (loss: 0.002588016679510474, acc: 1.0)
[2025-01-30 02:22:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5678/107898 [30:50<9:29:32,  2.99it/s][2025-01-30 02:22:59][root][INFO] - Training Epoch: 1/2, step 5677/107898 completed (loss: 2.9892125129699707, acc: 0.5)
[2025-01-30 02:23:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5679/107898 [30:50<9:27:54,  3.00it/s][2025-01-30 02:23:00][root][INFO] - Training Epoch: 1/2, step 5678/107898 completed (loss: 1.1912853717803955, acc: 0.5714285969734192)
[2025-01-30 02:23:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5680/107898 [30:50<9:12:13,  3.09it/s][2025-01-30 02:23:00][root][INFO] - Training Epoch: 1/2, step 5679/107898 completed (loss: 0.0014487227890640497, acc: 1.0)
[2025-01-30 02:23:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5681/107898 [30:51<9:09:26,  3.10it/s][2025-01-30 02:23:00][root][INFO] - Training Epoch: 1/2, step 5680/107898 completed (loss: 2.4080822467803955, acc: 0.0)
[2025-01-30 02:23:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5682/107898 [30:51<9:28:10,  3.00it/s][2025-01-30 02:23:01][root][INFO] - Training Epoch: 1/2, step 5681/107898 completed (loss: 0.0027814102359116077, acc: 1.0)
[2025-01-30 02:23:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5683/107898 [30:51<9:40:57,  2.93it/s][2025-01-30 02:23:01][root][INFO] - Training Epoch: 1/2, step 5682/107898 completed (loss: 0.3748185634613037, acc: 0.875)
[2025-01-30 02:23:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5684/107898 [30:52<9:14:31,  3.07it/s][2025-01-30 02:23:01][root][INFO] - Training Epoch: 1/2, step 5683/107898 completed (loss: 0.040533874183893204, acc: 1.0)
[2025-01-30 02:23:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5685/107898 [30:52<9:31:41,  2.98it/s][2025-01-30 02:23:02][root][INFO] - Training Epoch: 1/2, step 5684/107898 completed (loss: 0.0026089733000844717, acc: 1.0)
[2025-01-30 02:23:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5686/107898 [30:52<9:25:04,  3.01it/s][2025-01-30 02:23:02][root][INFO] - Training Epoch: 1/2, step 5685/107898 completed (loss: 2.7093844413757324, acc: 0.5)
[2025-01-30 02:23:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5687/107898 [30:53<9:30:31,  2.99it/s][2025-01-30 02:23:02][root][INFO] - Training Epoch: 1/2, step 5686/107898 completed (loss: 0.1550779640674591, acc: 1.0)
[2025-01-30 02:23:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5688/107898 [30:53<9:47:33,  2.90it/s][2025-01-30 02:23:03][root][INFO] - Training Epoch: 1/2, step 5687/107898 completed (loss: 0.9405000805854797, acc: 0.8181818127632141)
[2025-01-30 02:23:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5689/107898 [30:53<9:42:12,  2.93it/s][2025-01-30 02:23:03][root][INFO] - Training Epoch: 1/2, step 5688/107898 completed (loss: 0.7154036164283752, acc: 0.9230769276618958)
[2025-01-30 02:23:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5690/107898 [30:54<9:34:38,  2.96it/s][2025-01-30 02:23:03][root][INFO] - Training Epoch: 1/2, step 5689/107898 completed (loss: 0.06240462139248848, acc: 1.0)
[2025-01-30 02:23:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5691/107898 [30:54<9:37:52,  2.95it/s][2025-01-30 02:23:04][root][INFO] - Training Epoch: 1/2, step 5690/107898 completed (loss: 2.390886068344116, acc: 0.5625)
[2025-01-30 02:23:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5692/107898 [30:54<9:34:05,  2.97it/s][2025-01-30 02:23:04][root][INFO] - Training Epoch: 1/2, step 5691/107898 completed (loss: 0.6761900186538696, acc: 0.8947368264198303)
[2025-01-30 02:23:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5693/107898 [30:55<9:31:27,  2.98it/s][2025-01-30 02:23:04][root][INFO] - Training Epoch: 1/2, step 5692/107898 completed (loss: 0.19944962859153748, acc: 0.95652174949646)
[2025-01-30 02:23:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5694/107898 [30:55<9:24:05,  3.02it/s][2025-01-30 02:23:05][root][INFO] - Training Epoch: 1/2, step 5693/107898 completed (loss: 0.16872309148311615, acc: 1.0)
[2025-01-30 02:23:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5695/107898 [30:55<9:10:50,  3.09it/s][2025-01-30 02:23:05][root][INFO] - Training Epoch: 1/2, step 5694/107898 completed (loss: 0.3679783046245575, acc: 0.8888888955116272)
[2025-01-30 02:23:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5696/107898 [30:56<8:56:23,  3.18it/s][2025-01-30 02:23:05][root][INFO] - Training Epoch: 1/2, step 5695/107898 completed (loss: 0.5396493077278137, acc: 0.75)
[2025-01-30 02:23:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5697/107898 [30:56<8:46:41,  3.23it/s][2025-01-30 02:23:06][root][INFO] - Training Epoch: 1/2, step 5696/107898 completed (loss: 0.33387789130210876, acc: 0.9473684430122375)
[2025-01-30 02:23:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5698/107898 [30:56<8:42:47,  3.26it/s][2025-01-30 02:23:06][root][INFO] - Training Epoch: 1/2, step 5697/107898 completed (loss: 0.32494795322418213, acc: 0.8636363744735718)
[2025-01-30 02:23:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5699/107898 [30:57<9:14:33,  3.07it/s][2025-01-30 02:23:06][root][INFO] - Training Epoch: 1/2, step 5698/107898 completed (loss: 1.6884472370147705, acc: 0.7222222089767456)
[2025-01-30 02:23:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5700/107898 [30:57<9:14:23,  3.07it/s][2025-01-30 02:23:07][root][INFO] - Training Epoch: 1/2, step 5699/107898 completed (loss: 0.05054987221956253, acc: 1.0)
[2025-01-30 02:23:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5701/107898 [30:57<9:10:42,  3.09it/s][2025-01-30 02:23:07][root][INFO] - Training Epoch: 1/2, step 5700/107898 completed (loss: 0.6931589841842651, acc: 0.8666666746139526)
[2025-01-30 02:23:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5702/107898 [30:58<9:28:58,  2.99it/s][2025-01-30 02:23:07][root][INFO] - Training Epoch: 1/2, step 5701/107898 completed (loss: 1.4661327600479126, acc: 0.5)
[2025-01-30 02:23:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5703/107898 [30:58<9:31:58,  2.98it/s][2025-01-30 02:23:08][root][INFO] - Training Epoch: 1/2, step 5702/107898 completed (loss: 2.031463384628296, acc: 0.5)
[2025-01-30 02:23:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5704/107898 [30:58<9:22:05,  3.03it/s][2025-01-30 02:23:08][root][INFO] - Training Epoch: 1/2, step 5703/107898 completed (loss: 1.271731972694397, acc: 0.8235294222831726)
[2025-01-30 02:23:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5705/107898 [30:59<9:14:11,  3.07it/s][2025-01-30 02:23:08][root][INFO] - Training Epoch: 1/2, step 5704/107898 completed (loss: 0.0961279571056366, acc: 1.0)
[2025-01-30 02:23:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5706/107898 [30:59<9:39:45,  2.94it/s][2025-01-30 02:23:09][root][INFO] - Training Epoch: 1/2, step 5705/107898 completed (loss: 0.08816750347614288, acc: 1.0)
[2025-01-30 02:23:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5707/107898 [30:59<9:35:06,  2.96it/s][2025-01-30 02:23:09][root][INFO] - Training Epoch: 1/2, step 5706/107898 completed (loss: 0.5421391725540161, acc: 0.9285714030265808)
[2025-01-30 02:23:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5708/107898 [31:00<9:27:59,  3.00it/s][2025-01-30 02:23:09][root][INFO] - Training Epoch: 1/2, step 5707/107898 completed (loss: 0.29047566652297974, acc: 1.0)
[2025-01-30 02:23:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5709/107898 [31:00<9:37:21,  2.95it/s][2025-01-30 02:23:10][root][INFO] - Training Epoch: 1/2, step 5708/107898 completed (loss: 0.8747153282165527, acc: 0.6666666865348816)
[2025-01-30 02:23:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5710/107898 [31:00<9:49:58,  2.89it/s][2025-01-30 02:23:10][root][INFO] - Training Epoch: 1/2, step 5709/107898 completed (loss: 0.22230727970600128, acc: 1.0)
[2025-01-30 02:23:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5711/107898 [31:01<9:29:53,  2.99it/s][2025-01-30 02:23:10][root][INFO] - Training Epoch: 1/2, step 5710/107898 completed (loss: 1.1623334884643555, acc: 0.75)
[2025-01-30 02:23:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5712/107898 [31:01<9:10:30,  3.09it/s][2025-01-30 02:23:11][root][INFO] - Training Epoch: 1/2, step 5711/107898 completed (loss: 0.04025832563638687, acc: 1.0)
[2025-01-30 02:23:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5713/107898 [31:01<9:22:10,  3.03it/s][2025-01-30 02:23:11][root][INFO] - Training Epoch: 1/2, step 5712/107898 completed (loss: 0.005865859799087048, acc: 1.0)
[2025-01-30 02:23:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5714/107898 [31:02<9:15:27,  3.07it/s][2025-01-30 02:23:11][root][INFO] - Training Epoch: 1/2, step 5713/107898 completed (loss: 0.9222463369369507, acc: 0.75)
[2025-01-30 02:23:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5715/107898 [31:02<9:07:23,  3.11it/s][2025-01-30 02:23:12][root][INFO] - Training Epoch: 1/2, step 5714/107898 completed (loss: 3.186833620071411, acc: 0.3333333432674408)
[2025-01-30 02:23:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5716/107898 [31:02<8:59:02,  3.16it/s][2025-01-30 02:23:12][root][INFO] - Training Epoch: 1/2, step 5715/107898 completed (loss: 0.8529127240180969, acc: 1.0)
[2025-01-30 02:23:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5717/107898 [31:02<8:43:12,  3.25it/s][2025-01-30 02:23:12][root][INFO] - Training Epoch: 1/2, step 5716/107898 completed (loss: 0.06259804219007492, acc: 1.0)
[2025-01-30 02:23:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5718/107898 [31:03<8:57:53,  3.17it/s][2025-01-30 02:23:13][root][INFO] - Training Epoch: 1/2, step 5717/107898 completed (loss: 0.8477134108543396, acc: 0.6666666865348816)
[2025-01-30 02:23:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5719/107898 [31:03<9:07:27,  3.11it/s][2025-01-30 02:23:13][root][INFO] - Training Epoch: 1/2, step 5718/107898 completed (loss: 0.1321122646331787, acc: 1.0)
[2025-01-30 02:23:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5720/107898 [31:03<9:14:44,  3.07it/s][2025-01-30 02:23:13][root][INFO] - Training Epoch: 1/2, step 5719/107898 completed (loss: 0.12771880626678467, acc: 1.0)
[2025-01-30 02:23:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5721/107898 [31:04<9:30:03,  2.99it/s][2025-01-30 02:23:14][root][INFO] - Training Epoch: 1/2, step 5720/107898 completed (loss: 0.46770164370536804, acc: 0.8181818127632141)
[2025-01-30 02:23:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5722/107898 [31:04<9:52:28,  2.87it/s][2025-01-30 02:23:14][root][INFO] - Training Epoch: 1/2, step 5721/107898 completed (loss: 3.6247315406799316, acc: 0.26923078298568726)
[2025-01-30 02:23:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5723/107898 [31:05<9:58:09,  2.85it/s][2025-01-30 02:23:14][root][INFO] - Training Epoch: 1/2, step 5722/107898 completed (loss: 1.5796229839324951, acc: 0.625)
[2025-01-30 02:23:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5724/107898 [31:05<9:54:25,  2.86it/s][2025-01-30 02:23:15][root][INFO] - Training Epoch: 1/2, step 5723/107898 completed (loss: 0.7178404927253723, acc: 0.8461538553237915)
[2025-01-30 02:23:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5725/107898 [31:05<9:38:15,  2.94it/s][2025-01-30 02:23:15][root][INFO] - Training Epoch: 1/2, step 5724/107898 completed (loss: 3.8493049144744873, acc: 0.6000000238418579)
[2025-01-30 02:23:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5726/107898 [31:06<9:25:07,  3.01it/s][2025-01-30 02:23:15][root][INFO] - Training Epoch: 1/2, step 5725/107898 completed (loss: 0.04282112047076225, acc: 1.0)
[2025-01-30 02:23:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5727/107898 [31:06<9:43:02,  2.92it/s][2025-01-30 02:23:16][root][INFO] - Training Epoch: 1/2, step 5726/107898 completed (loss: 1.7405204772949219, acc: 0.800000011920929)
[2025-01-30 02:23:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5728/107898 [31:06<9:38:26,  2.94it/s][2025-01-30 02:23:16][root][INFO] - Training Epoch: 1/2, step 5727/107898 completed (loss: 2.488476276397705, acc: 0.6470588445663452)
[2025-01-30 02:23:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5729/107898 [31:07<9:27:37,  3.00it/s][2025-01-30 02:23:16][root][INFO] - Training Epoch: 1/2, step 5728/107898 completed (loss: 0.139918252825737, acc: 1.0)
[2025-01-30 02:23:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5730/107898 [31:07<9:14:06,  3.07it/s][2025-01-30 02:23:17][root][INFO] - Training Epoch: 1/2, step 5729/107898 completed (loss: 0.3941728472709656, acc: 0.875)
[2025-01-30 02:23:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5731/107898 [31:07<9:33:13,  2.97it/s][2025-01-30 02:23:17][root][INFO] - Training Epoch: 1/2, step 5730/107898 completed (loss: 0.19315491616725922, acc: 0.9230769276618958)
[2025-01-30 02:23:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5732/107898 [31:08<9:42:48,  2.92it/s][2025-01-30 02:23:17][root][INFO] - Training Epoch: 1/2, step 5731/107898 completed (loss: 3.8045902252197266, acc: 0.4000000059604645)
[2025-01-30 02:23:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5733/107898 [31:08<9:38:09,  2.95it/s][2025-01-30 02:23:18][root][INFO] - Training Epoch: 1/2, step 5732/107898 completed (loss: 0.0951443538069725, acc: 1.0)
[2025-01-30 02:23:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5734/107898 [31:08<9:16:02,  3.06it/s][2025-01-30 02:23:18][root][INFO] - Training Epoch: 1/2, step 5733/107898 completed (loss: 0.5033447742462158, acc: 0.8181818127632141)
[2025-01-30 02:23:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5735/107898 [31:09<9:06:11,  3.12it/s][2025-01-30 02:23:18][root][INFO] - Training Epoch: 1/2, step 5734/107898 completed (loss: 1.3538618087768555, acc: 0.5)
[2025-01-30 02:23:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5736/107898 [31:09<9:01:16,  3.15it/s][2025-01-30 02:23:19][root][INFO] - Training Epoch: 1/2, step 5735/107898 completed (loss: 0.05627311393618584, acc: 1.0)
[2025-01-30 02:23:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5737/107898 [31:09<8:51:47,  3.20it/s][2025-01-30 02:23:19][root][INFO] - Training Epoch: 1/2, step 5736/107898 completed (loss: 1.1182044744491577, acc: 0.0)
[2025-01-30 02:23:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5738/107898 [31:09<9:09:41,  3.10it/s][2025-01-30 02:23:19][root][INFO] - Training Epoch: 1/2, step 5737/107898 completed (loss: 0.16066189110279083, acc: 0.9285714030265808)
[2025-01-30 02:23:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5739/107898 [31:10<9:02:27,  3.14it/s][2025-01-30 02:23:20][root][INFO] - Training Epoch: 1/2, step 5738/107898 completed (loss: 0.05822170153260231, acc: 1.0)
[2025-01-30 02:23:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5740/107898 [31:10<9:19:55,  3.04it/s][2025-01-30 02:23:20][root][INFO] - Training Epoch: 1/2, step 5739/107898 completed (loss: 1.8829066753387451, acc: 0.5)
[2025-01-30 02:23:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5741/107898 [31:10<9:26:02,  3.01it/s][2025-01-30 02:23:20][root][INFO] - Training Epoch: 1/2, step 5740/107898 completed (loss: 0.3995668292045593, acc: 1.0)
[2025-01-30 02:23:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5742/107898 [31:11<9:13:36,  3.08it/s][2025-01-30 02:23:21][root][INFO] - Training Epoch: 1/2, step 5741/107898 completed (loss: 0.03736535832285881, acc: 1.0)
[2025-01-30 02:23:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5743/107898 [31:11<9:04:06,  3.13it/s][2025-01-30 02:23:21][root][INFO] - Training Epoch: 1/2, step 5742/107898 completed (loss: 0.38749969005584717, acc: 0.8666666746139526)
[2025-01-30 02:23:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5744/107898 [31:11<8:59:20,  3.16it/s][2025-01-30 02:23:21][root][INFO] - Training Epoch: 1/2, step 5743/107898 completed (loss: 1.2024964094161987, acc: 0.8181818127632141)
[2025-01-30 02:23:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5745/107898 [31:12<9:13:32,  3.08it/s][2025-01-30 02:23:22][root][INFO] - Training Epoch: 1/2, step 5744/107898 completed (loss: 0.43794727325439453, acc: 0.6666666865348816)
[2025-01-30 02:23:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5746/107898 [31:12<9:14:52,  3.07it/s][2025-01-30 02:23:22][root][INFO] - Training Epoch: 1/2, step 5745/107898 completed (loss: 0.09163957834243774, acc: 1.0)
[2025-01-30 02:23:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5747/107898 [31:12<9:03:01,  3.14it/s][2025-01-30 02:23:22][root][INFO] - Training Epoch: 1/2, step 5746/107898 completed (loss: 1.2011152505874634, acc: 0.5882353186607361)
[2025-01-30 02:23:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5748/107898 [31:13<8:54:58,  3.18it/s][2025-01-30 02:23:22][root][INFO] - Training Epoch: 1/2, step 5747/107898 completed (loss: 0.2662321925163269, acc: 0.8999999761581421)
[2025-01-30 02:23:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5749/107898 [31:13<8:46:54,  3.23it/s][2025-01-30 02:23:23][root][INFO] - Training Epoch: 1/2, step 5748/107898 completed (loss: 1.4142565727233887, acc: 0.75)
[2025-01-30 02:23:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5750/107898 [31:13<9:13:46,  3.07it/s][2025-01-30 02:23:23][root][INFO] - Training Epoch: 1/2, step 5749/107898 completed (loss: 0.0011124381562694907, acc: 1.0)
[2025-01-30 02:23:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5751/107898 [31:14<9:17:34,  3.05it/s][2025-01-30 02:23:23][root][INFO] - Training Epoch: 1/2, step 5750/107898 completed (loss: 0.6729428172111511, acc: 0.8333333134651184)
[2025-01-30 02:23:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5752/107898 [31:14<9:06:02,  3.12it/s][2025-01-30 02:23:24][root][INFO] - Training Epoch: 1/2, step 5751/107898 completed (loss: 0.5983278155326843, acc: 0.7857142686843872)
[2025-01-30 02:23:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5753/107898 [31:14<8:50:48,  3.21it/s][2025-01-30 02:23:24][root][INFO] - Training Epoch: 1/2, step 5752/107898 completed (loss: 3.670578956604004, acc: 0.07692307978868484)
[2025-01-30 02:23:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5754/107898 [31:15<9:16:50,  3.06it/s][2025-01-30 02:23:24][root][INFO] - Training Epoch: 1/2, step 5753/107898 completed (loss: 1.3505297899246216, acc: 0.8571428656578064)
[2025-01-30 02:23:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5755/107898 [31:15<9:21:17,  3.03it/s][2025-01-30 02:23:25][root][INFO] - Training Epoch: 1/2, step 5754/107898 completed (loss: 0.02555372565984726, acc: 1.0)
[2025-01-30 02:23:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5756/107898 [31:15<9:11:43,  3.09it/s][2025-01-30 02:23:25][root][INFO] - Training Epoch: 1/2, step 5755/107898 completed (loss: 0.9776409268379211, acc: 0.6666666865348816)
[2025-01-30 02:23:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5757/107898 [31:16<8:58:58,  3.16it/s][2025-01-30 02:23:25][root][INFO] - Training Epoch: 1/2, step 5756/107898 completed (loss: 0.3550321161746979, acc: 0.9166666865348816)
[2025-01-30 02:23:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5758/107898 [31:16<8:56:42,  3.17it/s][2025-01-30 02:23:26][root][INFO] - Training Epoch: 1/2, step 5757/107898 completed (loss: 1.2402350902557373, acc: 0.8125)
[2025-01-30 02:23:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5759/107898 [31:16<9:01:02,  3.15it/s][2025-01-30 02:23:26][root][INFO] - Training Epoch: 1/2, step 5758/107898 completed (loss: 0.48268023133277893, acc: 1.0)
[2025-01-30 02:23:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5760/107898 [31:17<9:20:19,  3.04it/s][2025-01-30 02:23:26][root][INFO] - Training Epoch: 1/2, step 5759/107898 completed (loss: 3.6231493949890137, acc: 0.22580644488334656)
[2025-01-30 02:23:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5761/107898 [31:17<9:04:45,  3.12it/s][2025-01-30 02:23:27][root][INFO] - Training Epoch: 1/2, step 5760/107898 completed (loss: 0.1723783016204834, acc: 1.0)
[2025-01-30 02:23:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5762/107898 [31:17<9:06:41,  3.11it/s][2025-01-30 02:23:27][root][INFO] - Training Epoch: 1/2, step 5761/107898 completed (loss: 0.0005308660329319537, acc: 1.0)
[2025-01-30 02:23:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5763/107898 [31:18<9:22:34,  3.03it/s][2025-01-30 02:23:27][root][INFO] - Training Epoch: 1/2, step 5762/107898 completed (loss: 0.46179914474487305, acc: 0.6666666865348816)
[2025-01-30 02:23:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5764/107898 [31:18<9:15:18,  3.07it/s][2025-01-30 02:23:28][root][INFO] - Training Epoch: 1/2, step 5763/107898 completed (loss: 0.7397356033325195, acc: 1.0)
[2025-01-30 02:23:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5765/107898 [31:18<9:23:45,  3.02it/s][2025-01-30 02:23:28][root][INFO] - Training Epoch: 1/2, step 5764/107898 completed (loss: 0.009424852207303047, acc: 1.0)
[2025-01-30 02:23:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5766/107898 [31:19<9:21:52,  3.03it/s][2025-01-30 02:23:28][root][INFO] - Training Epoch: 1/2, step 5765/107898 completed (loss: 0.0028834971599280834, acc: 1.0)
[2025-01-30 02:23:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5767/107898 [31:19<9:14:32,  3.07it/s][2025-01-30 02:23:29][root][INFO] - Training Epoch: 1/2, step 5766/107898 completed (loss: 0.0026458415668457747, acc: 1.0)
[2025-01-30 02:23:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5768/107898 [31:19<9:41:03,  2.93it/s][2025-01-30 02:23:29][root][INFO] - Training Epoch: 1/2, step 5767/107898 completed (loss: 0.15320442616939545, acc: 1.0)
[2025-01-30 02:23:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5769/107898 [31:20<9:25:24,  3.01it/s][2025-01-30 02:23:29][root][INFO] - Training Epoch: 1/2, step 5768/107898 completed (loss: 0.25764742493629456, acc: 0.9375)
[2025-01-30 02:23:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5770/107898 [31:20<9:40:12,  2.93it/s][2025-01-30 02:23:30][root][INFO] - Training Epoch: 1/2, step 5769/107898 completed (loss: 1.9416104555130005, acc: 0.7272727489471436)
[2025-01-30 02:23:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5771/107898 [31:20<9:32:05,  2.98it/s][2025-01-30 02:23:30][root][INFO] - Training Epoch: 1/2, step 5770/107898 completed (loss: 0.007677097804844379, acc: 1.0)
[2025-01-30 02:23:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5772/107898 [31:21<9:22:23,  3.03it/s][2025-01-30 02:23:30][root][INFO] - Training Epoch: 1/2, step 5771/107898 completed (loss: 0.23566997051239014, acc: 0.8695651888847351)
[2025-01-30 02:23:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5773/107898 [31:21<9:04:42,  3.12it/s][2025-01-30 02:23:31][root][INFO] - Training Epoch: 1/2, step 5772/107898 completed (loss: 0.010135672986507416, acc: 1.0)
[2025-01-30 02:23:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5774/107898 [31:21<8:55:44,  3.18it/s][2025-01-30 02:23:31][root][INFO] - Training Epoch: 1/2, step 5773/107898 completed (loss: 5.464993000030518, acc: 0.2857142984867096)
[2025-01-30 02:23:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5775/107898 [31:21<8:50:01,  3.21it/s][2025-01-30 02:23:31][root][INFO] - Training Epoch: 1/2, step 5774/107898 completed (loss: 0.9444302320480347, acc: 0.8888888955116272)
[2025-01-30 02:23:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5776/107898 [31:22<8:51:28,  3.20it/s][2025-01-30 02:23:32][root][INFO] - Training Epoch: 1/2, step 5775/107898 completed (loss: 0.5541762709617615, acc: 0.7894737124443054)
[2025-01-30 02:23:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5777/107898 [31:22<8:47:56,  3.22it/s][2025-01-30 02:23:32][root][INFO] - Training Epoch: 1/2, step 5776/107898 completed (loss: 0.030969494953751564, acc: 1.0)
[2025-01-30 02:23:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5778/107898 [31:22<8:43:35,  3.25it/s][2025-01-30 02:23:32][root][INFO] - Training Epoch: 1/2, step 5777/107898 completed (loss: 5.8833746910095215, acc: 0.1666666716337204)
[2025-01-30 02:23:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5779/107898 [31:23<8:41:51,  3.26it/s][2025-01-30 02:23:32][root][INFO] - Training Epoch: 1/2, step 5778/107898 completed (loss: 0.006862521171569824, acc: 1.0)
[2025-01-30 02:23:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5780/107898 [31:23<8:47:44,  3.23it/s][2025-01-30 02:23:33][root][INFO] - Training Epoch: 1/2, step 5779/107898 completed (loss: 0.05244820937514305, acc: 1.0)
[2025-01-30 02:23:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5781/107898 [31:23<8:45:17,  3.24it/s][2025-01-30 02:23:33][root][INFO] - Training Epoch: 1/2, step 5780/107898 completed (loss: 0.8852815628051758, acc: 0.7857142686843872)
[2025-01-30 02:23:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5782/107898 [31:24<8:56:59,  3.17it/s][2025-01-30 02:23:33][root][INFO] - Training Epoch: 1/2, step 5781/107898 completed (loss: 0.07408874481916428, acc: 1.0)
[2025-01-30 02:23:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5783/107898 [31:24<9:02:42,  3.14it/s][2025-01-30 02:23:34][root][INFO] - Training Epoch: 1/2, step 5782/107898 completed (loss: 0.5477703809738159, acc: 0.75)
[2025-01-30 02:23:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5784/107898 [31:24<9:21:21,  3.03it/s][2025-01-30 02:23:34][root][INFO] - Training Epoch: 1/2, step 5783/107898 completed (loss: 0.43783098459243774, acc: 0.8787878751754761)
[2025-01-30 02:23:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5785/107898 [31:25<9:08:07,  3.10it/s][2025-01-30 02:23:34][root][INFO] - Training Epoch: 1/2, step 5784/107898 completed (loss: 0.2969488501548767, acc: 1.0)
[2025-01-30 02:23:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5786/107898 [31:25<8:37:40,  3.29it/s][2025-01-30 02:23:35][root][INFO] - Training Epoch: 1/2, step 5785/107898 completed (loss: 0.26268550753593445, acc: 0.9090909361839294)
[2025-01-30 02:23:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5787/107898 [31:25<8:52:12,  3.20it/s][2025-01-30 02:23:35][root][INFO] - Training Epoch: 1/2, step 5786/107898 completed (loss: 0.001279327436350286, acc: 1.0)
[2025-01-30 02:23:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5788/107898 [31:26<8:55:35,  3.18it/s][2025-01-30 02:23:35][root][INFO] - Training Epoch: 1/2, step 5787/107898 completed (loss: 0.5694242119789124, acc: 0.8999999761581421)
[2025-01-30 02:23:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5789/107898 [31:26<9:04:45,  3.12it/s][2025-01-30 02:23:36][root][INFO] - Training Epoch: 1/2, step 5788/107898 completed (loss: 3.3015694618225098, acc: 0.5)
[2025-01-30 02:23:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5790/107898 [31:26<9:07:32,  3.11it/s][2025-01-30 02:23:36][root][INFO] - Training Epoch: 1/2, step 5789/107898 completed (loss: 0.018035562708973885, acc: 1.0)
[2025-01-30 02:23:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5791/107898 [31:27<9:11:36,  3.09it/s][2025-01-30 02:23:36][root][INFO] - Training Epoch: 1/2, step 5790/107898 completed (loss: 0.13416656851768494, acc: 1.0)
[2025-01-30 02:23:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5792/107898 [31:27<9:28:01,  3.00it/s][2025-01-30 02:23:37][root][INFO] - Training Epoch: 1/2, step 5791/107898 completed (loss: 0.34609559178352356, acc: 1.0)
[2025-01-30 02:23:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5793/107898 [31:27<9:33:48,  2.97it/s][2025-01-30 02:23:37][root][INFO] - Training Epoch: 1/2, step 5792/107898 completed (loss: 1.8001468181610107, acc: 0.0)
[2025-01-30 02:23:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5794/107898 [31:28<9:19:39,  3.04it/s][2025-01-30 02:23:37][root][INFO] - Training Epoch: 1/2, step 5793/107898 completed (loss: 2.051797389984131, acc: 0.6428571343421936)
[2025-01-30 02:23:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5795/107898 [31:28<9:31:42,  2.98it/s][2025-01-30 02:23:38][root][INFO] - Training Epoch: 1/2, step 5794/107898 completed (loss: 0.0006484074983745813, acc: 1.0)
[2025-01-30 02:23:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5796/107898 [31:28<9:32:50,  2.97it/s][2025-01-30 02:23:38][root][INFO] - Training Epoch: 1/2, step 5795/107898 completed (loss: 0.12079288810491562, acc: 1.0)
[2025-01-30 02:23:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5797/107898 [31:29<9:21:21,  3.03it/s][2025-01-30 02:23:38][root][INFO] - Training Epoch: 1/2, step 5796/107898 completed (loss: 1.7489346265792847, acc: 0.6896551847457886)
[2025-01-30 02:23:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5798/107898 [31:29<9:37:31,  2.95it/s][2025-01-30 02:23:39][root][INFO] - Training Epoch: 1/2, step 5797/107898 completed (loss: 0.32831934094429016, acc: 0.9090909361839294)
[2025-01-30 02:23:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5799/107898 [31:29<9:29:18,  2.99it/s][2025-01-30 02:23:39][root][INFO] - Training Epoch: 1/2, step 5798/107898 completed (loss: 1.8390759229660034, acc: 0.7083333134651184)
[2025-01-30 02:23:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5800/107898 [31:30<9:32:04,  2.97it/s][2025-01-30 02:23:39][root][INFO] - Training Epoch: 1/2, step 5799/107898 completed (loss: 5.049560546875, acc: 0.1538461595773697)
[2025-01-30 02:23:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5801/107898 [31:30<9:21:18,  3.03it/s][2025-01-30 02:23:40][root][INFO] - Training Epoch: 1/2, step 5800/107898 completed (loss: 1.2570326328277588, acc: 0.75)
[2025-01-30 02:23:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5802/107898 [31:30<9:04:07,  3.13it/s][2025-01-30 02:23:40][root][INFO] - Training Epoch: 1/2, step 5801/107898 completed (loss: 4.76101016998291, acc: 0.2857142984867096)
[2025-01-30 02:23:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5803/107898 [31:30<8:53:55,  3.19it/s][2025-01-30 02:23:40][root][INFO] - Training Epoch: 1/2, step 5802/107898 completed (loss: 0.0038148420862853527, acc: 1.0)
[2025-01-30 02:23:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5804/107898 [31:31<8:49:54,  3.21it/s][2025-01-30 02:23:41][root][INFO] - Training Epoch: 1/2, step 5803/107898 completed (loss: 0.9466270804405212, acc: 0.5)
[2025-01-30 02:23:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5805/107898 [31:31<8:58:03,  3.16it/s][2025-01-30 02:23:41][root][INFO] - Training Epoch: 1/2, step 5804/107898 completed (loss: 0.17483200132846832, acc: 0.9545454382896423)
[2025-01-30 02:23:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5806/107898 [31:31<8:52:14,  3.20it/s][2025-01-30 02:23:41][root][INFO] - Training Epoch: 1/2, step 5805/107898 completed (loss: 0.020350683480501175, acc: 1.0)
[2025-01-30 02:23:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5807/107898 [31:32<8:49:42,  3.21it/s][2025-01-30 02:23:42][root][INFO] - Training Epoch: 1/2, step 5806/107898 completed (loss: 0.2941075265407562, acc: 1.0)
[2025-01-30 02:23:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5808/107898 [31:32<8:44:08,  3.25it/s][2025-01-30 02:23:42][root][INFO] - Training Epoch: 1/2, step 5807/107898 completed (loss: 0.2848111391067505, acc: 0.9090909361839294)
[2025-01-30 02:23:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5809/107898 [31:32<8:39:53,  3.27it/s][2025-01-30 02:23:42][root][INFO] - Training Epoch: 1/2, step 5808/107898 completed (loss: 1.0686604976654053, acc: 0.6666666865348816)
[2025-01-30 02:23:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5810/107898 [31:33<9:01:03,  3.14it/s][2025-01-30 02:23:42][root][INFO] - Training Epoch: 1/2, step 5809/107898 completed (loss: 0.33777645230293274, acc: 0.9047619104385376)
[2025-01-30 02:23:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5811/107898 [31:33<9:11:39,  3.08it/s][2025-01-30 02:23:43][root][INFO] - Training Epoch: 1/2, step 5810/107898 completed (loss: 0.24121716618537903, acc: 0.90625)
[2025-01-30 02:23:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5812/107898 [31:33<8:56:22,  3.17it/s][2025-01-30 02:23:43][root][INFO] - Training Epoch: 1/2, step 5811/107898 completed (loss: 0.06341414898633957, acc: 1.0)
[2025-01-30 02:23:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5813/107898 [31:34<8:57:14,  3.17it/s][2025-01-30 02:23:43][root][INFO] - Training Epoch: 1/2, step 5812/107898 completed (loss: 0.2675403356552124, acc: 0.8823529481887817)
[2025-01-30 02:23:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5814/107898 [31:34<9:19:08,  3.04it/s][2025-01-30 02:23:44][root][INFO] - Training Epoch: 1/2, step 5813/107898 completed (loss: 0.03898202255368233, acc: 1.0)
[2025-01-30 02:23:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5815/107898 [31:34<9:47:06,  2.90it/s][2025-01-30 02:23:44][root][INFO] - Training Epoch: 1/2, step 5814/107898 completed (loss: 0.02720949985086918, acc: 1.0)
[2025-01-30 02:23:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5816/107898 [31:35<9:42:37,  2.92it/s][2025-01-30 02:23:44][root][INFO] - Training Epoch: 1/2, step 5815/107898 completed (loss: 0.10157240182161331, acc: 1.0)
[2025-01-30 02:23:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5817/107898 [31:35<9:27:04,  3.00it/s][2025-01-30 02:23:45][root][INFO] - Training Epoch: 1/2, step 5816/107898 completed (loss: 0.5000103712081909, acc: 0.8571428656578064)
[2025-01-30 02:23:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5818/107898 [31:35<9:03:37,  3.13it/s][2025-01-30 02:23:45][root][INFO] - Training Epoch: 1/2, step 5817/107898 completed (loss: 0.102473184466362, acc: 1.0)
[2025-01-30 02:23:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5819/107898 [31:36<8:57:02,  3.17it/s][2025-01-30 02:23:45][root][INFO] - Training Epoch: 1/2, step 5818/107898 completed (loss: 1.7578767538070679, acc: 0.6666666865348816)
[2025-01-30 02:23:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5820/107898 [31:36<8:54:06,  3.19it/s][2025-01-30 02:23:46][root][INFO] - Training Epoch: 1/2, step 5819/107898 completed (loss: 0.05676810070872307, acc: 1.0)
[2025-01-30 02:23:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5821/107898 [31:36<9:03:05,  3.13it/s][2025-01-30 02:23:46][root][INFO] - Training Epoch: 1/2, step 5820/107898 completed (loss: 3.4861185550689697, acc: 0.3125)
[2025-01-30 02:23:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5822/107898 [31:37<8:54:00,  3.19it/s][2025-01-30 02:23:46][root][INFO] - Training Epoch: 1/2, step 5821/107898 completed (loss: 0.24453146755695343, acc: 1.0)
[2025-01-30 02:23:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5823/107898 [31:37<8:46:18,  3.23it/s][2025-01-30 02:23:47][root][INFO] - Training Epoch: 1/2, step 5822/107898 completed (loss: 0.36072593927383423, acc: 0.8571428656578064)
[2025-01-30 02:23:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5824/107898 [31:37<9:06:19,  3.11it/s][2025-01-30 02:23:47][root][INFO] - Training Epoch: 1/2, step 5823/107898 completed (loss: 0.19598273932933807, acc: 1.0)
[2025-01-30 02:23:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5825/107898 [31:38<9:09:42,  3.09it/s][2025-01-30 02:23:47][root][INFO] - Training Epoch: 1/2, step 5824/107898 completed (loss: 0.1777225285768509, acc: 1.0)
[2025-01-30 02:23:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5826/107898 [31:38<9:12:48,  3.08it/s][2025-01-30 02:23:48][root][INFO] - Training Epoch: 1/2, step 5825/107898 completed (loss: 0.09204758703708649, acc: 1.0)
[2025-01-30 02:23:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5827/107898 [31:38<9:28:46,  2.99it/s][2025-01-30 02:23:48][root][INFO] - Training Epoch: 1/2, step 5826/107898 completed (loss: 0.07981536537408829, acc: 1.0)
[2025-01-30 02:23:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5828/107898 [31:39<9:29:53,  2.99it/s][2025-01-30 02:23:48][root][INFO] - Training Epoch: 1/2, step 5827/107898 completed (loss: 0.4734840393066406, acc: 0.6666666865348816)
[2025-01-30 02:23:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5829/107898 [31:39<9:18:50,  3.04it/s][2025-01-30 02:23:49][root][INFO] - Training Epoch: 1/2, step 5828/107898 completed (loss: 0.01107307244092226, acc: 1.0)
[2025-01-30 02:23:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5830/107898 [31:39<9:22:37,  3.02it/s][2025-01-30 02:23:49][root][INFO] - Training Epoch: 1/2, step 5829/107898 completed (loss: 3.9397900104522705, acc: 0.5)
[2025-01-30 02:23:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5831/107898 [31:39<9:12:12,  3.08it/s][2025-01-30 02:23:49][root][INFO] - Training Epoch: 1/2, step 5830/107898 completed (loss: 0.0024999282322824, acc: 1.0)
[2025-01-30 02:23:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5832/107898 [31:40<8:58:52,  3.16it/s][2025-01-30 02:23:50][root][INFO] - Training Epoch: 1/2, step 5831/107898 completed (loss: 0.08637958019971848, acc: 1.0)
[2025-01-30 02:23:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5833/107898 [31:40<9:15:19,  3.06it/s][2025-01-30 02:23:50][root][INFO] - Training Epoch: 1/2, step 5832/107898 completed (loss: 0.1996176391839981, acc: 1.0)
[2025-01-30 02:23:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5834/107898 [31:40<9:07:42,  3.11it/s][2025-01-30 02:23:50][root][INFO] - Training Epoch: 1/2, step 5833/107898 completed (loss: 0.0009408334153704345, acc: 1.0)
[2025-01-30 02:23:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5835/107898 [31:41<8:38:51,  3.28it/s][2025-01-30 02:23:51][root][INFO] - Training Epoch: 1/2, step 5834/107898 completed (loss: 0.5264991521835327, acc: 0.6666666865348816)
[2025-01-30 02:23:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5836/107898 [31:41<8:28:49,  3.34it/s][2025-01-30 02:23:51][root][INFO] - Training Epoch: 1/2, step 5835/107898 completed (loss: 0.1943305879831314, acc: 0.875)
[2025-01-30 02:23:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5837/107898 [31:41<8:40:39,  3.27it/s][2025-01-30 02:23:51][root][INFO] - Training Epoch: 1/2, step 5836/107898 completed (loss: 0.2654247283935547, acc: 0.9130434989929199)
[2025-01-30 02:23:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5838/107898 [31:42<9:06:00,  3.12it/s][2025-01-30 02:23:51][root][INFO] - Training Epoch: 1/2, step 5837/107898 completed (loss: 0.057041920721530914, acc: 1.0)
[2025-01-30 02:23:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5839/107898 [31:42<9:12:21,  3.08it/s][2025-01-30 02:23:52][root][INFO] - Training Epoch: 1/2, step 5838/107898 completed (loss: 1.0588260889053345, acc: 0.75)
[2025-01-30 02:23:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5840/107898 [31:42<9:15:49,  3.06it/s][2025-01-30 02:23:52][root][INFO] - Training Epoch: 1/2, step 5839/107898 completed (loss: 0.12526509165763855, acc: 1.0)
[2025-01-30 02:23:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5841/107898 [31:43<9:13:37,  3.07it/s][2025-01-30 02:23:52][root][INFO] - Training Epoch: 1/2, step 5840/107898 completed (loss: 0.006833500228822231, acc: 1.0)
[2025-01-30 02:23:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5842/107898 [31:43<9:46:02,  2.90it/s][2025-01-30 02:23:53][root][INFO] - Training Epoch: 1/2, step 5841/107898 completed (loss: 1.6760650873184204, acc: 0.625)
[2025-01-30 02:23:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5843/107898 [31:43<9:52:12,  2.87it/s][2025-01-30 02:23:53][root][INFO] - Training Epoch: 1/2, step 5842/107898 completed (loss: 0.030256666243076324, acc: 1.0)
[2025-01-30 02:23:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5844/107898 [31:44<9:38:59,  2.94it/s][2025-01-30 02:23:54][root][INFO] - Training Epoch: 1/2, step 5843/107898 completed (loss: 4.402708053588867, acc: 0.3333333432674408)
[2025-01-30 02:23:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5845/107898 [31:44<10:00:28,  2.83it/s][2025-01-30 02:23:54][root][INFO] - Training Epoch: 1/2, step 5844/107898 completed (loss: 1.027383804321289, acc: 0.7777777910232544)
[2025-01-30 02:23:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5846/107898 [31:44<9:48:28,  2.89it/s] [2025-01-30 02:23:54][root][INFO] - Training Epoch: 1/2, step 5845/107898 completed (loss: 1.1315419673919678, acc: 0.5)
[2025-01-30 02:23:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5847/107898 [31:45<10:06:56,  2.80it/s][2025-01-30 02:23:55][root][INFO] - Training Epoch: 1/2, step 5846/107898 completed (loss: 1.6605769395828247, acc: 0.6666666865348816)
[2025-01-30 02:23:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5848/107898 [31:45<10:18:26,  2.75it/s][2025-01-30 02:23:55][root][INFO] - Training Epoch: 1/2, step 5847/107898 completed (loss: 2.6052143573760986, acc: 0.75)
[2025-01-30 02:23:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5849/107898 [31:46<9:48:13,  2.89it/s] [2025-01-30 02:23:55][root][INFO] - Training Epoch: 1/2, step 5848/107898 completed (loss: 0.24686922132968903, acc: 0.8888888955116272)
[2025-01-30 02:23:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5850/107898 [31:46<9:35:32,  2.96it/s][2025-01-30 02:23:56][root][INFO] - Training Epoch: 1/2, step 5849/107898 completed (loss: 0.2838684022426605, acc: 1.0)
[2025-01-30 02:23:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5851/107898 [31:46<9:32:57,  2.97it/s][2025-01-30 02:23:56][root][INFO] - Training Epoch: 1/2, step 5850/107898 completed (loss: 1.809385895729065, acc: 0.75)
[2025-01-30 02:23:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5852/107898 [31:46<9:26:17,  3.00it/s][2025-01-30 02:23:56][root][INFO] - Training Epoch: 1/2, step 5851/107898 completed (loss: 0.10964637249708176, acc: 1.0)
[2025-01-30 02:23:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5853/107898 [31:47<9:44:33,  2.91it/s][2025-01-30 02:23:57][root][INFO] - Training Epoch: 1/2, step 5852/107898 completed (loss: 0.1735510230064392, acc: 0.9090909361839294)
[2025-01-30 02:23:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5854/107898 [31:47<9:25:24,  3.01it/s][2025-01-30 02:23:57][root][INFO] - Training Epoch: 1/2, step 5853/107898 completed (loss: 0.09567590802907944, acc: 1.0)
[2025-01-30 02:23:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5855/107898 [31:48<9:43:03,  2.92it/s][2025-01-30 02:23:57][root][INFO] - Training Epoch: 1/2, step 5854/107898 completed (loss: 0.10922639816999435, acc: 1.0)
[2025-01-30 02:23:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5856/107898 [31:48<10:15:09,  2.76it/s][2025-01-30 02:23:58][root][INFO] - Training Epoch: 1/2, step 5855/107898 completed (loss: 1.2367286682128906, acc: 0.699999988079071)
[2025-01-30 02:23:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5857/107898 [31:48<9:35:24,  2.96it/s] [2025-01-30 02:23:58][root][INFO] - Training Epoch: 1/2, step 5856/107898 completed (loss: 1.1025041341781616, acc: 0.7083333134651184)
[2025-01-30 02:23:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5858/107898 [31:49<9:12:32,  3.08it/s][2025-01-30 02:23:58][root][INFO] - Training Epoch: 1/2, step 5857/107898 completed (loss: 0.2987699508666992, acc: 0.9090909361839294)
[2025-01-30 02:23:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5859/107898 [31:49<9:19:43,  3.04it/s][2025-01-30 02:23:59][root][INFO] - Training Epoch: 1/2, step 5858/107898 completed (loss: 0.878954291343689, acc: 1.0)
[2025-01-30 02:23:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5860/107898 [31:49<9:19:24,  3.04it/s][2025-01-30 02:23:59][root][INFO] - Training Epoch: 1/2, step 5859/107898 completed (loss: 0.5645803213119507, acc: 0.8666666746139526)
[2025-01-30 02:23:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5861/107898 [31:49<9:01:18,  3.14it/s][2025-01-30 02:23:59][root][INFO] - Training Epoch: 1/2, step 5860/107898 completed (loss: 1.1263371706008911, acc: 0.5)
[2025-01-30 02:23:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5862/107898 [31:50<8:54:03,  3.18it/s][2025-01-30 02:24:00][root][INFO] - Training Epoch: 1/2, step 5861/107898 completed (loss: 3.21038818359375, acc: 0.6666666865348816)
[2025-01-30 02:24:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5863/107898 [31:50<9:01:31,  3.14it/s][2025-01-30 02:24:00][root][INFO] - Training Epoch: 1/2, step 5862/107898 completed (loss: 5.436977863311768, acc: 0.0)
[2025-01-30 02:24:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5864/107898 [31:50<9:16:01,  3.06it/s][2025-01-30 02:24:00][root][INFO] - Training Epoch: 1/2, step 5863/107898 completed (loss: 0.3483392894268036, acc: 0.800000011920929)
[2025-01-30 02:24:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5865/107898 [31:51<8:59:18,  3.15it/s][2025-01-30 02:24:01][root][INFO] - Training Epoch: 1/2, step 5864/107898 completed (loss: 0.08023819327354431, acc: 1.0)
[2025-01-30 02:24:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5866/107898 [31:51<9:04:15,  3.12it/s][2025-01-30 02:24:01][root][INFO] - Training Epoch: 1/2, step 5865/107898 completed (loss: 0.09730108082294464, acc: 1.0)
[2025-01-30 02:24:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5867/107898 [31:51<8:59:50,  3.15it/s][2025-01-30 02:24:01][root][INFO] - Training Epoch: 1/2, step 5866/107898 completed (loss: 0.12795913219451904, acc: 1.0)
[2025-01-30 02:24:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5868/107898 [31:52<9:25:34,  3.01it/s][2025-01-30 02:24:02][root][INFO] - Training Epoch: 1/2, step 5867/107898 completed (loss: 5.1672282218933105, acc: 0.1428571492433548)
[2025-01-30 02:24:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5869/107898 [31:52<9:35:45,  2.95it/s][2025-01-30 02:24:02][root][INFO] - Training Epoch: 1/2, step 5868/107898 completed (loss: 0.7942347526550293, acc: 0.8974359035491943)
[2025-01-30 02:24:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5870/107898 [31:52<9:47:44,  2.89it/s][2025-01-30 02:24:02][root][INFO] - Training Epoch: 1/2, step 5869/107898 completed (loss: 4.218194484710693, acc: 0.2857142984867096)
[2025-01-30 02:24:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5871/107898 [31:53<10:04:20,  2.81it/s][2025-01-30 02:24:03][root][INFO] - Training Epoch: 1/2, step 5870/107898 completed (loss: 1.5009393692016602, acc: 0.6666666865348816)
[2025-01-30 02:24:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5872/107898 [31:53<9:53:50,  2.86it/s] [2025-01-30 02:24:03][root][INFO] - Training Epoch: 1/2, step 5871/107898 completed (loss: 0.10424931347370148, acc: 1.0)
[2025-01-30 02:24:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5873/107898 [31:54<9:41:37,  2.92it/s][2025-01-30 02:24:03][root][INFO] - Training Epoch: 1/2, step 5872/107898 completed (loss: 0.3488270342350006, acc: 0.6666666865348816)
[2025-01-30 02:24:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5874/107898 [31:54<9:37:11,  2.95it/s][2025-01-30 02:24:04][root][INFO] - Training Epoch: 1/2, step 5873/107898 completed (loss: 0.14410555362701416, acc: 1.0)
[2025-01-30 02:24:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5875/107898 [31:54<9:33:00,  2.97it/s][2025-01-30 02:24:04][root][INFO] - Training Epoch: 1/2, step 5874/107898 completed (loss: 0.08567659556865692, acc: 1.0)
[2025-01-30 02:24:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5876/107898 [31:55<9:40:33,  2.93it/s][2025-01-30 02:24:04][root][INFO] - Training Epoch: 1/2, step 5875/107898 completed (loss: 0.8110717535018921, acc: 0.8695651888847351)
[2025-01-30 02:24:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5877/107898 [31:55<9:41:49,  2.92it/s][2025-01-30 02:24:05][root][INFO] - Training Epoch: 1/2, step 5876/107898 completed (loss: 0.8550063967704773, acc: 0.75)
[2025-01-30 02:24:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5878/107898 [31:55<9:37:49,  2.94it/s][2025-01-30 02:24:05][root][INFO] - Training Epoch: 1/2, step 5877/107898 completed (loss: 0.3108958303928375, acc: 0.9166666865348816)
[2025-01-30 02:24:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5879/107898 [31:56<9:40:08,  2.93it/s][2025-01-30 02:24:05][root][INFO] - Training Epoch: 1/2, step 5878/107898 completed (loss: 0.06304465234279633, acc: 1.0)
[2025-01-30 02:24:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5880/107898 [31:56<9:37:00,  2.95it/s][2025-01-30 02:24:06][root][INFO] - Training Epoch: 1/2, step 5879/107898 completed (loss: 0.047119852155447006, acc: 1.0)
[2025-01-30 02:24:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5881/107898 [31:56<9:56:13,  2.85it/s][2025-01-30 02:24:06][root][INFO] - Training Epoch: 1/2, step 5880/107898 completed (loss: 3.2144081592559814, acc: 0.4545454680919647)
[2025-01-30 02:24:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5882/107898 [31:57<9:44:08,  2.91it/s][2025-01-30 02:24:06][root][INFO] - Training Epoch: 1/2, step 5881/107898 completed (loss: 0.1606689840555191, acc: 0.9333333373069763)
[2025-01-30 02:24:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5883/107898 [31:57<9:22:11,  3.02it/s][2025-01-30 02:24:07][root][INFO] - Training Epoch: 1/2, step 5882/107898 completed (loss: 2.111936092376709, acc: 0.5)
[2025-01-30 02:24:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5884/107898 [31:57<9:19:53,  3.04it/s][2025-01-30 02:24:07][root][INFO] - Training Epoch: 1/2, step 5883/107898 completed (loss: 0.9978929162025452, acc: 0.800000011920929)
[2025-01-30 02:24:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5885/107898 [31:58<9:26:47,  3.00it/s][2025-01-30 02:24:07][root][INFO] - Training Epoch: 1/2, step 5884/107898 completed (loss: 0.9145403504371643, acc: 0.8518518805503845)
[2025-01-30 02:24:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5886/107898 [31:58<9:27:00,  3.00it/s][2025-01-30 02:24:08][root][INFO] - Training Epoch: 1/2, step 5885/107898 completed (loss: 2.014655590057373, acc: 0.625)
[2025-01-30 02:24:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5887/107898 [31:58<9:03:08,  3.13it/s][2025-01-30 02:24:08][root][INFO] - Training Epoch: 1/2, step 5886/107898 completed (loss: 0.06241146847605705, acc: 1.0)
[2025-01-30 02:24:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5888/107898 [31:58<8:57:10,  3.17it/s][2025-01-30 02:24:08][root][INFO] - Training Epoch: 1/2, step 5887/107898 completed (loss: 0.013939524069428444, acc: 1.0)
[2025-01-30 02:24:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5889/107898 [31:59<8:45:27,  3.24it/s][2025-01-30 02:24:09][root][INFO] - Training Epoch: 1/2, step 5888/107898 completed (loss: 0.9692904949188232, acc: 0.5)
[2025-01-30 02:24:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5890/107898 [31:59<8:42:01,  3.26it/s][2025-01-30 02:24:09][root][INFO] - Training Epoch: 1/2, step 5889/107898 completed (loss: 0.6698489189147949, acc: 0.8888888955116272)
[2025-01-30 02:24:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5891/107898 [31:59<8:45:08,  3.24it/s][2025-01-30 02:24:09][root][INFO] - Training Epoch: 1/2, step 5890/107898 completed (loss: 1.0659288167953491, acc: 0.8333333134651184)
[2025-01-30 02:24:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5892/107898 [32:00<8:38:17,  3.28it/s][2025-01-30 02:24:09][root][INFO] - Training Epoch: 1/2, step 5891/107898 completed (loss: 2.891554832458496, acc: 0.6666666865348816)
[2025-01-30 02:24:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5893/107898 [32:00<9:11:25,  3.08it/s][2025-01-30 02:24:10][root][INFO] - Training Epoch: 1/2, step 5892/107898 completed (loss: 1.0047690868377686, acc: 0.7777777910232544)
[2025-01-30 02:24:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5894/107898 [32:00<9:22:40,  3.02it/s][2025-01-30 02:24:10][root][INFO] - Training Epoch: 1/2, step 5893/107898 completed (loss: 1.3256454467773438, acc: 0.7777777910232544)
[2025-01-30 02:24:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5895/107898 [32:01<9:28:17,  2.99it/s][2025-01-30 02:24:11][root][INFO] - Training Epoch: 1/2, step 5894/107898 completed (loss: 0.7361698746681213, acc: 0.8461538553237915)
[2025-01-30 02:24:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5896/107898 [32:01<9:26:16,  3.00it/s][2025-01-30 02:24:11][root][INFO] - Training Epoch: 1/2, step 5895/107898 completed (loss: 0.7429003119468689, acc: 0.6666666865348816)
[2025-01-30 02:24:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5897/107898 [32:01<9:02:59,  3.13it/s][2025-01-30 02:24:11][root][INFO] - Training Epoch: 1/2, step 5896/107898 completed (loss: 0.029703577980399132, acc: 1.0)
[2025-01-30 02:24:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5898/107898 [32:02<8:55:38,  3.17it/s][2025-01-30 02:24:11][root][INFO] - Training Epoch: 1/2, step 5897/107898 completed (loss: 0.027936406433582306, acc: 1.0)
[2025-01-30 02:24:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5899/107898 [32:02<8:55:00,  3.18it/s][2025-01-30 02:24:12][root][INFO] - Training Epoch: 1/2, step 5898/107898 completed (loss: 3.505887508392334, acc: 0.25)
[2025-01-30 02:24:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5900/107898 [32:02<8:57:59,  3.16it/s][2025-01-30 02:24:12][root][INFO] - Training Epoch: 1/2, step 5899/107898 completed (loss: 0.10669177025556564, acc: 1.0)
[2025-01-30 02:24:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5901/107898 [32:03<9:10:30,  3.09it/s][2025-01-30 02:24:12][root][INFO] - Training Epoch: 1/2, step 5900/107898 completed (loss: 4.812320709228516, acc: 0.1666666716337204)
[2025-01-30 02:24:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5902/107898 [32:03<9:05:48,  3.11it/s][2025-01-30 02:24:13][root][INFO] - Training Epoch: 1/2, step 5901/107898 completed (loss: 0.4823572337627411, acc: 1.0)
[2025-01-30 02:24:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5903/107898 [32:03<8:54:27,  3.18it/s][2025-01-30 02:24:13][root][INFO] - Training Epoch: 1/2, step 5902/107898 completed (loss: 2.512451410293579, acc: 0.5)
[2025-01-30 02:24:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5904/107898 [32:04<9:20:57,  3.03it/s][2025-01-30 02:24:13][root][INFO] - Training Epoch: 1/2, step 5903/107898 completed (loss: 0.09647269546985626, acc: 0.949999988079071)
[2025-01-30 02:24:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5905/107898 [32:04<9:16:32,  3.05it/s][2025-01-30 02:24:14][root][INFO] - Training Epoch: 1/2, step 5904/107898 completed (loss: 0.6891916394233704, acc: 1.0)
[2025-01-30 02:24:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5906/107898 [32:04<9:25:58,  3.00it/s][2025-01-30 02:24:14][root][INFO] - Training Epoch: 1/2, step 5905/107898 completed (loss: 1.885610818862915, acc: 0.6666666865348816)
[2025-01-30 02:24:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5907/107898 [32:05<9:28:24,  2.99it/s][2025-01-30 02:24:14][root][INFO] - Training Epoch: 1/2, step 5906/107898 completed (loss: 1.0684107542037964, acc: 0.8333333134651184)
[2025-01-30 02:24:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5908/107898 [32:05<9:15:14,  3.06it/s][2025-01-30 02:24:15][root][INFO] - Training Epoch: 1/2, step 5907/107898 completed (loss: 1.0361608266830444, acc: 0.75)
[2025-01-30 02:24:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5909/107898 [32:05<9:21:32,  3.03it/s][2025-01-30 02:24:15][root][INFO] - Training Epoch: 1/2, step 5908/107898 completed (loss: 0.7594885230064392, acc: 0.8333333134651184)
[2025-01-30 02:24:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5910/107898 [32:06<9:15:03,  3.06it/s][2025-01-30 02:24:15][root][INFO] - Training Epoch: 1/2, step 5909/107898 completed (loss: 0.25338971614837646, acc: 0.875)
[2025-01-30 02:24:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5911/107898 [32:06<9:00:36,  3.14it/s][2025-01-30 02:24:16][root][INFO] - Training Epoch: 1/2, step 5910/107898 completed (loss: 1.8151559829711914, acc: 0.5)
[2025-01-30 02:24:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5912/107898 [32:06<9:01:24,  3.14it/s][2025-01-30 02:24:16][root][INFO] - Training Epoch: 1/2, step 5911/107898 completed (loss: 1.166110634803772, acc: 0.692307710647583)
[2025-01-30 02:24:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5913/107898 [32:07<8:58:25,  3.16it/s][2025-01-30 02:24:16][root][INFO] - Training Epoch: 1/2, step 5912/107898 completed (loss: 5.611759662628174, acc: 0.15789473056793213)
[2025-01-30 02:24:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5914/107898 [32:07<8:46:09,  3.23it/s][2025-01-30 02:24:17][root][INFO] - Training Epoch: 1/2, step 5913/107898 completed (loss: 2.035238265991211, acc: 0.0)
[2025-01-30 02:24:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5915/107898 [32:07<8:58:26,  3.16it/s][2025-01-30 02:24:17][root][INFO] - Training Epoch: 1/2, step 5914/107898 completed (loss: 0.6868523955345154, acc: 0.5)
[2025-01-30 02:24:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5916/107898 [32:07<8:58:01,  3.16it/s][2025-01-30 02:24:17][root][INFO] - Training Epoch: 1/2, step 5915/107898 completed (loss: 2.3454861640930176, acc: 0.5555555820465088)
[2025-01-30 02:24:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5917/107898 [32:08<8:56:57,  3.17it/s][2025-01-30 02:24:18][root][INFO] - Training Epoch: 1/2, step 5916/107898 completed (loss: 0.06028864532709122, acc: 1.0)
[2025-01-30 02:24:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5918/107898 [32:08<8:47:04,  3.22it/s][2025-01-30 02:24:18][root][INFO] - Training Epoch: 1/2, step 5917/107898 completed (loss: 1.5688129663467407, acc: 0.6666666865348816)
[2025-01-30 02:24:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5919/107898 [32:08<9:11:08,  3.08it/s][2025-01-30 02:24:18][root][INFO] - Training Epoch: 1/2, step 5918/107898 completed (loss: 1.1325263977050781, acc: 0.5)
[2025-01-30 02:24:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5920/107898 [32:09<9:10:02,  3.09it/s][2025-01-30 02:24:19][root][INFO] - Training Epoch: 1/2, step 5919/107898 completed (loss: 0.2946024239063263, acc: 1.0)
[2025-01-30 02:24:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5921/107898 [32:09<9:25:30,  3.01it/s][2025-01-30 02:24:19][root][INFO] - Training Epoch: 1/2, step 5920/107898 completed (loss: 1.004044532775879, acc: 0.5)
[2025-01-30 02:24:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5922/107898 [32:09<9:15:31,  3.06it/s][2025-01-30 02:24:19][root][INFO] - Training Epoch: 1/2, step 5921/107898 completed (loss: 0.4577468931674957, acc: 1.0)
[2025-01-30 02:24:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5923/107898 [32:10<9:12:37,  3.08it/s][2025-01-30 02:24:20][root][INFO] - Training Epoch: 1/2, step 5922/107898 completed (loss: 2.6177196502685547, acc: 0.625)
[2025-01-30 02:24:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5924/107898 [32:10<9:00:55,  3.14it/s][2025-01-30 02:24:20][root][INFO] - Training Epoch: 1/2, step 5923/107898 completed (loss: 0.10015696287155151, acc: 1.0)
[2025-01-30 02:24:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5925/107898 [32:10<8:53:17,  3.19it/s][2025-01-30 02:24:20][root][INFO] - Training Epoch: 1/2, step 5924/107898 completed (loss: 2.5677406787872314, acc: 0.5)
[2025-01-30 02:24:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5926/107898 [32:11<8:48:55,  3.21it/s][2025-01-30 02:24:20][root][INFO] - Training Epoch: 1/2, step 5925/107898 completed (loss: 0.0023890123702585697, acc: 1.0)
[2025-01-30 02:24:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5927/107898 [32:11<9:12:00,  3.08it/s][2025-01-30 02:24:21][root][INFO] - Training Epoch: 1/2, step 5926/107898 completed (loss: 0.4510158896446228, acc: 1.0)
[2025-01-30 02:24:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5928/107898 [32:11<9:22:22,  3.02it/s][2025-01-30 02:24:21][root][INFO] - Training Epoch: 1/2, step 5927/107898 completed (loss: 1.1765857934951782, acc: 0.7916666865348816)
[2025-01-30 02:24:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5929/107898 [32:12<9:15:38,  3.06it/s][2025-01-30 02:24:21][root][INFO] - Training Epoch: 1/2, step 5928/107898 completed (loss: 3.346095323562622, acc: 0.6666666865348816)
[2025-01-30 02:24:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5930/107898 [32:12<8:58:13,  3.16it/s][2025-01-30 02:24:22][root][INFO] - Training Epoch: 1/2, step 5929/107898 completed (loss: 2.6289639472961426, acc: 0.0)
[2025-01-30 02:24:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5931/107898 [32:12<8:53:00,  3.19it/s][2025-01-30 02:24:22][root][INFO] - Training Epoch: 1/2, step 5930/107898 completed (loss: 0.7774690389633179, acc: 0.8695651888847351)
[2025-01-30 02:24:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5932/107898 [32:13<8:52:23,  3.19it/s][2025-01-30 02:24:22][root][INFO] - Training Epoch: 1/2, step 5931/107898 completed (loss: 1.7413865327835083, acc: 0.7272727489471436)
[2025-01-30 02:24:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5933/107898 [32:13<9:00:47,  3.14it/s][2025-01-30 02:24:23][root][INFO] - Training Epoch: 1/2, step 5932/107898 completed (loss: 0.40221044421195984, acc: 0.9545454382896423)
[2025-01-30 02:24:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   5%|[34mâ–Œ         [0m| 5934/107898 [32:13<8:54:35,  3.18it/s][2025-01-30 02:24:23][root][INFO] - Training Epoch: 1/2, step 5933/107898 completed (loss: 3.6397006511688232, acc: 0.3333333432674408)
[2025-01-30 02:24:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5935/107898 [32:14<8:46:32,  3.23it/s][2025-01-30 02:24:23][root][INFO] - Training Epoch: 1/2, step 5934/107898 completed (loss: 4.629354953765869, acc: 0.27272728085517883)
[2025-01-30 02:24:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5936/107898 [32:14<8:51:50,  3.20it/s][2025-01-30 02:24:24][root][INFO] - Training Epoch: 1/2, step 5935/107898 completed (loss: 1.2050167322158813, acc: 0.8333333134651184)
[2025-01-30 02:24:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5937/107898 [32:14<8:44:44,  3.24it/s][2025-01-30 02:24:24][root][INFO] - Training Epoch: 1/2, step 5936/107898 completed (loss: 0.4963032007217407, acc: 0.6666666865348816)
[2025-01-30 02:24:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5938/107898 [32:14<8:55:03,  3.18it/s][2025-01-30 02:24:24][root][INFO] - Training Epoch: 1/2, step 5937/107898 completed (loss: 0.9502370357513428, acc: 0.782608687877655)
[2025-01-30 02:24:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5939/107898 [32:15<8:49:47,  3.21it/s][2025-01-30 02:24:25][root][INFO] - Training Epoch: 1/2, step 5938/107898 completed (loss: 2.137577772140503, acc: 0.5)
[2025-01-30 02:24:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5940/107898 [32:15<9:05:22,  3.12it/s][2025-01-30 02:24:25][root][INFO] - Training Epoch: 1/2, step 5939/107898 completed (loss: 1.6505873203277588, acc: 0.5)
[2025-01-30 02:24:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5941/107898 [32:15<9:02:41,  3.13it/s][2025-01-30 02:24:25][root][INFO] - Training Epoch: 1/2, step 5940/107898 completed (loss: 0.33709362149238586, acc: 0.9090909361839294)
[2025-01-30 02:24:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5942/107898 [32:16<9:09:37,  3.09it/s][2025-01-30 02:24:26][root][INFO] - Training Epoch: 1/2, step 5941/107898 completed (loss: 0.8499046564102173, acc: 0.7777777910232544)
[2025-01-30 02:24:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5943/107898 [32:16<9:01:37,  3.14it/s][2025-01-30 02:24:26][root][INFO] - Training Epoch: 1/2, step 5942/107898 completed (loss: 2.2389562129974365, acc: 0.5)
[2025-01-30 02:24:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5944/107898 [32:16<8:51:29,  3.20it/s][2025-01-30 02:24:26][root][INFO] - Training Epoch: 1/2, step 5943/107898 completed (loss: 2.177250862121582, acc: 0.625)
[2025-01-30 02:24:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5945/107898 [32:17<8:55:49,  3.17it/s][2025-01-30 02:24:26][root][INFO] - Training Epoch: 1/2, step 5944/107898 completed (loss: 2.3624651432037354, acc: 0.4000000059604645)
[2025-01-30 02:24:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5946/107898 [32:17<8:55:38,  3.17it/s][2025-01-30 02:24:27][root][INFO] - Training Epoch: 1/2, step 5945/107898 completed (loss: 0.2303795963525772, acc: 1.0)
[2025-01-30 02:24:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5947/107898 [32:17<8:53:38,  3.18it/s][2025-01-30 02:24:27][root][INFO] - Training Epoch: 1/2, step 5946/107898 completed (loss: 0.04419441521167755, acc: 1.0)
[2025-01-30 02:24:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5948/107898 [32:18<8:42:34,  3.25it/s][2025-01-30 02:24:27][root][INFO] - Training Epoch: 1/2, step 5947/107898 completed (loss: 0.0987594947218895, acc: 1.0)
[2025-01-30 02:24:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5949/107898 [32:18<8:35:39,  3.30it/s][2025-01-30 02:24:28][root][INFO] - Training Epoch: 1/2, step 5948/107898 completed (loss: 0.14582788944244385, acc: 0.939393937587738)
[2025-01-30 02:24:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5950/107898 [32:18<8:35:32,  3.30it/s][2025-01-30 02:24:28][root][INFO] - Training Epoch: 1/2, step 5949/107898 completed (loss: 0.6737970113754272, acc: 1.0)
[2025-01-30 02:24:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5951/107898 [32:19<9:10:12,  3.09it/s][2025-01-30 02:24:28][root][INFO] - Training Epoch: 1/2, step 5950/107898 completed (loss: 0.5326583981513977, acc: 0.930232584476471)
[2025-01-30 02:24:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5952/107898 [32:19<8:59:17,  3.15it/s][2025-01-30 02:24:29][root][INFO] - Training Epoch: 1/2, step 5951/107898 completed (loss: 2.234450340270996, acc: 0.6666666865348816)
[2025-01-30 02:24:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5953/107898 [32:19<8:55:08,  3.18it/s][2025-01-30 02:24:29][root][INFO] - Training Epoch: 1/2, step 5952/107898 completed (loss: 3.1410067081451416, acc: 0.3333333432674408)
[2025-01-30 02:24:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5954/107898 [32:20<8:46:13,  3.23it/s][2025-01-30 02:24:29][root][INFO] - Training Epoch: 1/2, step 5953/107898 completed (loss: 0.707983672618866, acc: 0.6666666865348816)
[2025-01-30 02:24:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5955/107898 [32:20<9:04:43,  3.12it/s][2025-01-30 02:24:30][root][INFO] - Training Epoch: 1/2, step 5954/107898 completed (loss: 2.448559284210205, acc: 0.6666666865348816)
[2025-01-30 02:24:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5956/107898 [32:20<9:40:02,  2.93it/s][2025-01-30 02:24:30][root][INFO] - Training Epoch: 1/2, step 5955/107898 completed (loss: 0.5144720077514648, acc: 0.8857142925262451)
[2025-01-30 02:24:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5957/107898 [32:21<9:30:57,  2.98it/s][2025-01-30 02:24:30][root][INFO] - Training Epoch: 1/2, step 5956/107898 completed (loss: 3.6926932334899902, acc: 0.3478260934352875)
[2025-01-30 02:24:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5958/107898 [32:21<9:18:33,  3.04it/s][2025-01-30 02:24:31][root][INFO] - Training Epoch: 1/2, step 5957/107898 completed (loss: 0.9485328197479248, acc: 0.7692307829856873)
[2025-01-30 02:24:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5959/107898 [32:21<9:04:57,  3.12it/s][2025-01-30 02:24:31][root][INFO] - Training Epoch: 1/2, step 5958/107898 completed (loss: 0.5446174144744873, acc: 0.6666666865348816)
[2025-01-30 02:24:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5960/107898 [32:21<9:04:36,  3.12it/s][2025-01-30 02:24:31][root][INFO] - Training Epoch: 1/2, step 5959/107898 completed (loss: 0.3826717138290405, acc: 0.6666666865348816)
[2025-01-30 02:24:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5961/107898 [32:22<8:55:28,  3.17it/s][2025-01-30 02:24:32][root][INFO] - Training Epoch: 1/2, step 5960/107898 completed (loss: 1.3852198123931885, acc: 0.6000000238418579)
[2025-01-30 02:24:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5962/107898 [32:22<9:09:50,  3.09it/s][2025-01-30 02:24:32][root][INFO] - Training Epoch: 1/2, step 5961/107898 completed (loss: 0.04137421026825905, acc: 1.0)
[2025-01-30 02:24:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5963/107898 [32:22<9:07:23,  3.10it/s][2025-01-30 02:24:32][root][INFO] - Training Epoch: 1/2, step 5962/107898 completed (loss: 0.3878697156906128, acc: 0.6666666865348816)
[2025-01-30 02:24:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5964/107898 [32:23<8:44:14,  3.24it/s][2025-01-30 02:24:33][root][INFO] - Training Epoch: 1/2, step 5963/107898 completed (loss: 0.33413416147232056, acc: 0.9411764740943909)
[2025-01-30 02:24:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5965/107898 [32:23<8:36:59,  3.29it/s][2025-01-30 02:24:33][root][INFO] - Training Epoch: 1/2, step 5964/107898 completed (loss: 0.08518533408641815, acc: 1.0)
[2025-01-30 02:24:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5966/107898 [32:23<8:44:33,  3.24it/s][2025-01-30 02:24:33][root][INFO] - Training Epoch: 1/2, step 5965/107898 completed (loss: 3.6221814155578613, acc: 0.20000000298023224)
[2025-01-30 02:24:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5967/107898 [32:24<8:44:04,  3.24it/s][2025-01-30 02:24:33][root][INFO] - Training Epoch: 1/2, step 5966/107898 completed (loss: 0.8492435812950134, acc: 0.8571428656578064)
[2025-01-30 02:24:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5968/107898 [32:24<8:38:14,  3.28it/s][2025-01-30 02:24:34][root][INFO] - Training Epoch: 1/2, step 5967/107898 completed (loss: 0.037519246339797974, acc: 1.0)
[2025-01-30 02:24:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5969/107898 [32:24<9:33:57,  2.96it/s][2025-01-30 02:24:34][root][INFO] - Training Epoch: 1/2, step 5968/107898 completed (loss: 4.257559299468994, acc: 0.23404255509376526)
[2025-01-30 02:24:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5970/107898 [32:25<9:46:07,  2.90it/s][2025-01-30 02:24:35][root][INFO] - Training Epoch: 1/2, step 5969/107898 completed (loss: 1.2132962942123413, acc: 0.6666666865348816)
[2025-01-30 02:24:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5971/107898 [32:25<9:24:22,  3.01it/s][2025-01-30 02:24:35][root][INFO] - Training Epoch: 1/2, step 5970/107898 completed (loss: 4.47158670425415, acc: 0.2083333283662796)
[2025-01-30 02:24:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5972/107898 [32:25<9:14:21,  3.06it/s][2025-01-30 02:24:35][root][INFO] - Training Epoch: 1/2, step 5971/107898 completed (loss: 1.2964228391647339, acc: 0.6666666865348816)
[2025-01-30 02:24:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5973/107898 [32:26<9:13:41,  3.07it/s][2025-01-30 02:24:35][root][INFO] - Training Epoch: 1/2, step 5972/107898 completed (loss: 1.372677206993103, acc: 0.6000000238418579)
[2025-01-30 02:24:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5974/107898 [32:26<9:50:46,  2.88it/s][2025-01-30 02:24:36][root][INFO] - Training Epoch: 1/2, step 5973/107898 completed (loss: 1.0536938905715942, acc: 0.8108108043670654)
[2025-01-30 02:24:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5975/107898 [32:26<9:25:10,  3.01it/s][2025-01-30 02:24:36][root][INFO] - Training Epoch: 1/2, step 5974/107898 completed (loss: 0.6585959792137146, acc: 0.8571428656578064)
[2025-01-30 02:24:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5976/107898 [32:27<9:08:14,  3.10it/s][2025-01-30 02:24:36][root][INFO] - Training Epoch: 1/2, step 5975/107898 completed (loss: 0.06761068105697632, acc: 1.0)
[2025-01-30 02:24:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5977/107898 [32:27<9:10:25,  3.09it/s][2025-01-30 02:24:37][root][INFO] - Training Epoch: 1/2, step 5976/107898 completed (loss: 0.579624593257904, acc: 0.8918918967247009)
[2025-01-30 02:24:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5978/107898 [32:27<9:25:58,  3.00it/s][2025-01-30 02:24:37][root][INFO] - Training Epoch: 1/2, step 5977/107898 completed (loss: 2.462953567504883, acc: 0.47058823704719543)
[2025-01-30 02:24:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5979/107898 [32:28<9:10:10,  3.09it/s][2025-01-30 02:24:37][root][INFO] - Training Epoch: 1/2, step 5978/107898 completed (loss: 0.5317100286483765, acc: 0.5)
[2025-01-30 02:24:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5980/107898 [32:28<9:06:08,  3.11it/s][2025-01-30 02:24:38][root][INFO] - Training Epoch: 1/2, step 5979/107898 completed (loss: 1.5942559242248535, acc: 0.625)
[2025-01-30 02:24:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5981/107898 [32:28<9:13:24,  3.07it/s][2025-01-30 02:24:38][root][INFO] - Training Epoch: 1/2, step 5980/107898 completed (loss: 1.0563288927078247, acc: 0.5)
[2025-01-30 02:24:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5982/107898 [32:29<9:11:09,  3.08it/s][2025-01-30 02:24:38][root][INFO] - Training Epoch: 1/2, step 5981/107898 completed (loss: 3.396181106567383, acc: 0.25)
[2025-01-30 02:24:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5983/107898 [32:29<9:03:57,  3.12it/s][2025-01-30 02:24:39][root][INFO] - Training Epoch: 1/2, step 5982/107898 completed (loss: 0.09608030319213867, acc: 1.0)
[2025-01-30 02:24:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5984/107898 [32:29<8:54:41,  3.18it/s][2025-01-30 02:24:39][root][INFO] - Training Epoch: 1/2, step 5983/107898 completed (loss: 2.7710111141204834, acc: 0.0)
[2025-01-30 02:24:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5985/107898 [32:30<8:55:04,  3.17it/s][2025-01-30 02:24:39][root][INFO] - Training Epoch: 1/2, step 5984/107898 completed (loss: 0.861399233341217, acc: 0.6666666865348816)
[2025-01-30 02:24:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5986/107898 [32:30<8:44:24,  3.24it/s][2025-01-30 02:24:40][root][INFO] - Training Epoch: 1/2, step 5985/107898 completed (loss: 0.3032022714614868, acc: 1.0)
[2025-01-30 02:24:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5987/107898 [32:30<8:37:27,  3.28it/s][2025-01-30 02:24:40][root][INFO] - Training Epoch: 1/2, step 5986/107898 completed (loss: 0.4465746581554413, acc: 0.5)
[2025-01-30 02:24:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5988/107898 [32:30<8:37:05,  3.28it/s][2025-01-30 02:24:40][root][INFO] - Training Epoch: 1/2, step 5987/107898 completed (loss: 1.1635600328445435, acc: 0.75)
[2025-01-30 02:24:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5989/107898 [32:31<8:20:32,  3.39it/s][2025-01-30 02:24:41][root][INFO] - Training Epoch: 1/2, step 5988/107898 completed (loss: 0.2842314839363098, acc: 1.0)
[2025-01-30 02:24:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5990/107898 [32:31<8:07:32,  3.48it/s][2025-01-30 02:24:41][root][INFO] - Training Epoch: 1/2, step 5989/107898 completed (loss: 0.18018202483654022, acc: 1.0)
[2025-01-30 02:24:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5991/107898 [32:31<8:37:25,  3.28it/s][2025-01-30 02:24:41][root][INFO] - Training Epoch: 1/2, step 5990/107898 completed (loss: 0.6523025631904602, acc: 0.8214285969734192)
[2025-01-30 02:24:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5992/107898 [32:32<8:37:42,  3.28it/s][2025-01-30 02:24:41][root][INFO] - Training Epoch: 1/2, step 5991/107898 completed (loss: 0.3397447466850281, acc: 0.8888888955116272)
[2025-01-30 02:24:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5993/107898 [32:32<8:41:34,  3.26it/s][2025-01-30 02:24:42][root][INFO] - Training Epoch: 1/2, step 5992/107898 completed (loss: 4.1059489250183105, acc: 0.5)
[2025-01-30 02:24:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5994/107898 [32:32<8:44:08,  3.24it/s][2025-01-30 02:24:42][root][INFO] - Training Epoch: 1/2, step 5993/107898 completed (loss: 0.0338914692401886, acc: 1.0)
[2025-01-30 02:24:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5995/107898 [32:33<8:39:12,  3.27it/s][2025-01-30 02:24:42][root][INFO] - Training Epoch: 1/2, step 5994/107898 completed (loss: 0.002578971441835165, acc: 1.0)
[2025-01-30 02:24:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5996/107898 [32:33<8:30:04,  3.33it/s][2025-01-30 02:24:43][root][INFO] - Training Epoch: 1/2, step 5995/107898 completed (loss: 1.8485842943191528, acc: 0.6363636255264282)
[2025-01-30 02:24:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5997/107898 [32:33<8:12:25,  3.45it/s][2025-01-30 02:24:43][root][INFO] - Training Epoch: 1/2, step 5996/107898 completed (loss: 1.345324158668518, acc: 0.6666666865348816)
[2025-01-30 02:24:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5998/107898 [32:33<8:15:04,  3.43it/s][2025-01-30 02:24:43][root][INFO] - Training Epoch: 1/2, step 5997/107898 completed (loss: 0.674260675907135, acc: 0.75)
[2025-01-30 02:24:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 5999/107898 [32:34<8:46:52,  3.22it/s][2025-01-30 02:24:44][root][INFO] - Training Epoch: 1/2, step 5998/107898 completed (loss: 0.12319864332675934, acc: 1.0)
[2025-01-30 02:24:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6000/107898 [32:34<8:48:26,  3.21it/s][2025-01-30 02:24:44][root][INFO] - Training Epoch: 1/2, step 5999/107898 completed (loss: 0.45589902997016907, acc: 0.6666666865348816)
[2025-01-30 02:24:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6001/107898 [32:34<9:10:11,  3.09it/s][2025-01-30 02:24:44][root][INFO] - Training Epoch: 1/2, step 6000/107898 completed (loss: 0.1451878696680069, acc: 1.0)
[2025-01-30 02:24:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6002/107898 [32:35<9:13:19,  3.07it/s][2025-01-30 02:24:45][root][INFO] - Training Epoch: 1/2, step 6001/107898 completed (loss: 1.87088942527771, acc: 0.7647058963775635)
[2025-01-30 02:24:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6003/107898 [32:35<9:10:27,  3.09it/s][2025-01-30 02:24:45][root][INFO] - Training Epoch: 1/2, step 6002/107898 completed (loss: 3.8027563095092773, acc: 0.3333333432674408)
[2025-01-30 02:24:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6004/107898 [32:35<9:14:13,  3.06it/s][2025-01-30 02:24:45][root][INFO] - Training Epoch: 1/2, step 6003/107898 completed (loss: 0.0014860203955322504, acc: 1.0)
[2025-01-30 02:24:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6005/107898 [32:36<9:16:54,  3.05it/s][2025-01-30 02:24:46][root][INFO] - Training Epoch: 1/2, step 6004/107898 completed (loss: 1.4199939966201782, acc: 0.5555555820465088)
[2025-01-30 02:24:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6006/107898 [32:36<9:18:06,  3.04it/s][2025-01-30 02:24:46][root][INFO] - Training Epoch: 1/2, step 6005/107898 completed (loss: 0.005090493243187666, acc: 1.0)
[2025-01-30 02:24:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6007/107898 [32:36<9:27:18,  2.99it/s][2025-01-30 02:24:46][root][INFO] - Training Epoch: 1/2, step 6006/107898 completed (loss: 3.7366294860839844, acc: 0.3333333432674408)
[2025-01-30 02:24:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6008/107898 [32:37<8:54:27,  3.18it/s][2025-01-30 02:24:46][root][INFO] - Training Epoch: 1/2, step 6007/107898 completed (loss: 0.1680687963962555, acc: 0.9444444179534912)
[2025-01-30 02:24:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6009/107898 [32:37<8:53:08,  3.19it/s][2025-01-30 02:24:47][root][INFO] - Training Epoch: 1/2, step 6008/107898 completed (loss: 0.04236225038766861, acc: 1.0)
[2025-01-30 02:24:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6010/107898 [32:37<9:15:46,  3.06it/s][2025-01-30 02:24:47][root][INFO] - Training Epoch: 1/2, step 6009/107898 completed (loss: 0.0023174823727458715, acc: 1.0)
[2025-01-30 02:24:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6011/107898 [32:38<9:28:39,  2.99it/s][2025-01-30 02:24:48][root][INFO] - Training Epoch: 1/2, step 6010/107898 completed (loss: 0.07593917101621628, acc: 1.0)
[2025-01-30 02:24:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6012/107898 [32:38<9:06:58,  3.10it/s][2025-01-30 02:24:48][root][INFO] - Training Epoch: 1/2, step 6011/107898 completed (loss: 0.5619845986366272, acc: 0.6666666865348816)
[2025-01-30 02:24:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6013/107898 [32:38<8:54:31,  3.18it/s][2025-01-30 02:24:48][root][INFO] - Training Epoch: 1/2, step 6012/107898 completed (loss: 1.1336497068405151, acc: 0.6666666865348816)
[2025-01-30 02:24:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6014/107898 [32:39<8:48:47,  3.21it/s][2025-01-30 02:24:48][root][INFO] - Training Epoch: 1/2, step 6013/107898 completed (loss: 0.2611373960971832, acc: 1.0)
[2025-01-30 02:24:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6015/107898 [32:39<8:42:19,  3.25it/s][2025-01-30 02:24:49][root][INFO] - Training Epoch: 1/2, step 6014/107898 completed (loss: 0.868052065372467, acc: 0.5)
[2025-01-30 02:24:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6016/107898 [32:39<8:45:36,  3.23it/s][2025-01-30 02:24:49][root][INFO] - Training Epoch: 1/2, step 6015/107898 completed (loss: 1.9536007642745972, acc: 0.6000000238418579)
[2025-01-30 02:24:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6017/107898 [32:40<8:58:53,  3.15it/s][2025-01-30 02:24:49][root][INFO] - Training Epoch: 1/2, step 6016/107898 completed (loss: 0.3003823459148407, acc: 0.9615384340286255)
[2025-01-30 02:24:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6018/107898 [32:40<8:48:54,  3.21it/s][2025-01-30 02:24:50][root][INFO] - Training Epoch: 1/2, step 6017/107898 completed (loss: 0.06280992925167084, acc: 1.0)
[2025-01-30 02:24:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6019/107898 [32:40<9:04:33,  3.12it/s][2025-01-30 02:24:50][root][INFO] - Training Epoch: 1/2, step 6018/107898 completed (loss: 0.03386465832591057, acc: 1.0)
[2025-01-30 02:24:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6020/107898 [32:41<9:03:37,  3.12it/s][2025-01-30 02:24:50][root][INFO] - Training Epoch: 1/2, step 6019/107898 completed (loss: 2.236952304840088, acc: 0.47999998927116394)
[2025-01-30 02:24:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6021/107898 [32:41<8:54:18,  3.18it/s][2025-01-30 02:24:51][root][INFO] - Training Epoch: 1/2, step 6020/107898 completed (loss: 0.15063470602035522, acc: 1.0)
[2025-01-30 02:24:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6022/107898 [32:41<8:54:14,  3.18it/s][2025-01-30 02:24:51][root][INFO] - Training Epoch: 1/2, step 6021/107898 completed (loss: 1.0983151197433472, acc: 0.6666666865348816)
[2025-01-30 02:24:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6023/107898 [32:42<9:25:00,  3.01it/s][2025-01-30 02:24:51][root][INFO] - Training Epoch: 1/2, step 6022/107898 completed (loss: 0.7259051203727722, acc: 0.5)
[2025-01-30 02:24:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6024/107898 [32:42<9:39:52,  2.93it/s][2025-01-30 02:24:52][root][INFO] - Training Epoch: 1/2, step 6023/107898 completed (loss: 0.04733419418334961, acc: 1.0)
[2025-01-30 02:24:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6025/107898 [32:42<9:32:40,  2.96it/s][2025-01-30 02:24:52][root][INFO] - Training Epoch: 1/2, step 6024/107898 completed (loss: 1.0724952220916748, acc: 0.5)
[2025-01-30 02:24:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6026/107898 [32:43<9:28:29,  2.99it/s][2025-01-30 02:24:52][root][INFO] - Training Epoch: 1/2, step 6025/107898 completed (loss: 1.3409401178359985, acc: 0.5714285969734192)
[2025-01-30 02:24:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6027/107898 [32:43<9:33:34,  2.96it/s][2025-01-30 02:24:53][root][INFO] - Training Epoch: 1/2, step 6026/107898 completed (loss: 1.0748929977416992, acc: 0.7777777910232544)
[2025-01-30 02:24:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6028/107898 [32:43<9:29:02,  2.98it/s][2025-01-30 02:24:53][root][INFO] - Training Epoch: 1/2, step 6027/107898 completed (loss: 1.3428083658218384, acc: 0.7894737124443054)
[2025-01-30 02:24:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6029/107898 [32:43<9:02:49,  3.13it/s][2025-01-30 02:24:53][root][INFO] - Training Epoch: 1/2, step 6028/107898 completed (loss: 1.4597787857055664, acc: 0.6785714030265808)
[2025-01-30 02:24:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6030/107898 [32:44<8:57:45,  3.16it/s][2025-01-30 02:24:54][root][INFO] - Training Epoch: 1/2, step 6029/107898 completed (loss: 0.06349208205938339, acc: 1.0)
[2025-01-30 02:24:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6031/107898 [32:44<9:12:33,  3.07it/s][2025-01-30 02:24:54][root][INFO] - Training Epoch: 1/2, step 6030/107898 completed (loss: 1.0015369653701782, acc: 0.75)
[2025-01-30 02:24:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6032/107898 [32:44<9:27:38,  2.99it/s][2025-01-30 02:24:54][root][INFO] - Training Epoch: 1/2, step 6031/107898 completed (loss: 2.9040846824645996, acc: 0.6000000238418579)
[2025-01-30 02:24:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6033/107898 [32:45<9:25:22,  3.00it/s][2025-01-30 02:24:55][root][INFO] - Training Epoch: 1/2, step 6032/107898 completed (loss: 0.26738524436950684, acc: 1.0)
[2025-01-30 02:24:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6034/107898 [32:45<9:13:55,  3.06it/s][2025-01-30 02:24:55][root][INFO] - Training Epoch: 1/2, step 6033/107898 completed (loss: 1.9455238580703735, acc: 0.4000000059604645)
[2025-01-30 02:24:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6035/107898 [32:45<9:19:55,  3.03it/s][2025-01-30 02:24:55][root][INFO] - Training Epoch: 1/2, step 6034/107898 completed (loss: 2.2971999645233154, acc: 0.5)
[2025-01-30 02:24:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6036/107898 [32:46<9:16:09,  3.05it/s][2025-01-30 02:24:56][root][INFO] - Training Epoch: 1/2, step 6035/107898 completed (loss: 6.83861780166626, acc: 0.3333333432674408)
[2025-01-30 02:24:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6037/107898 [32:46<9:41:12,  2.92it/s][2025-01-30 02:24:56][root][INFO] - Training Epoch: 1/2, step 6036/107898 completed (loss: 0.9359731078147888, acc: 0.8125)
[2025-01-30 02:24:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6038/107898 [32:47<10:04:59,  2.81it/s][2025-01-30 02:24:56][root][INFO] - Training Epoch: 1/2, step 6037/107898 completed (loss: 3.780726194381714, acc: 0.30000001192092896)
[2025-01-30 02:24:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6039/107898 [32:47<10:03:50,  2.81it/s][2025-01-30 02:24:57][root][INFO] - Training Epoch: 1/2, step 6038/107898 completed (loss: 0.5257805585861206, acc: 1.0)
[2025-01-30 02:24:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6040/107898 [32:47<9:52:27,  2.87it/s] [2025-01-30 02:24:57][root][INFO] - Training Epoch: 1/2, step 6039/107898 completed (loss: 0.6103502511978149, acc: 1.0)
[2025-01-30 02:24:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6041/107898 [32:48<9:43:04,  2.91it/s][2025-01-30 02:24:57][root][INFO] - Training Epoch: 1/2, step 6040/107898 completed (loss: 0.29376220703125, acc: 1.0)
[2025-01-30 02:24:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6042/107898 [32:48<9:16:29,  3.05it/s][2025-01-30 02:24:58][root][INFO] - Training Epoch: 1/2, step 6041/107898 completed (loss: 0.41670915484428406, acc: 0.6666666865348816)
[2025-01-30 02:24:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6043/107898 [32:48<9:06:25,  3.11it/s][2025-01-30 02:24:58][root][INFO] - Training Epoch: 1/2, step 6042/107898 completed (loss: 1.1995837688446045, acc: 0.6800000071525574)
[2025-01-30 02:24:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6044/107898 [32:49<9:18:52,  3.04it/s][2025-01-30 02:24:58][root][INFO] - Training Epoch: 1/2, step 6043/107898 completed (loss: 0.9695150256156921, acc: 0.7142857313156128)
[2025-01-30 02:24:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6045/107898 [32:49<9:15:21,  3.06it/s][2025-01-30 02:24:59][root][INFO] - Training Epoch: 1/2, step 6044/107898 completed (loss: 0.035205915570259094, acc: 1.0)
[2025-01-30 02:24:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6046/107898 [32:49<9:43:03,  2.91it/s][2025-01-30 02:24:59][root][INFO] - Training Epoch: 1/2, step 6045/107898 completed (loss: 0.07113392651081085, acc: 1.0)
[2025-01-30 02:24:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6047/107898 [32:50<9:49:25,  2.88it/s][2025-01-30 02:24:59][root][INFO] - Training Epoch: 1/2, step 6046/107898 completed (loss: 1.073725700378418, acc: 0.75)
[2025-01-30 02:24:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6048/107898 [32:50<9:28:13,  2.99it/s][2025-01-30 02:25:00][root][INFO] - Training Epoch: 1/2, step 6047/107898 completed (loss: 2.3916687965393066, acc: 0.5833333134651184)
[2025-01-30 02:25:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6049/107898 [32:50<9:14:17,  3.06it/s][2025-01-30 02:25:00][root][INFO] - Training Epoch: 1/2, step 6048/107898 completed (loss: 1.0525271892547607, acc: 0.8571428656578064)
[2025-01-30 02:25:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6050/107898 [32:51<9:03:46,  3.12it/s][2025-01-30 02:25:00][root][INFO] - Training Epoch: 1/2, step 6049/107898 completed (loss: 0.9938946962356567, acc: 0.800000011920929)
[2025-01-30 02:25:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6051/107898 [32:51<9:00:19,  3.14it/s][2025-01-30 02:25:01][root][INFO] - Training Epoch: 1/2, step 6050/107898 completed (loss: 1.9545518159866333, acc: 0.875)
[2025-01-30 02:25:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6052/107898 [32:51<8:51:12,  3.20it/s][2025-01-30 02:25:01][root][INFO] - Training Epoch: 1/2, step 6051/107898 completed (loss: 0.4927481412887573, acc: 0.6666666865348816)
[2025-01-30 02:25:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6053/107898 [32:51<9:00:36,  3.14it/s][2025-01-30 02:25:01][root][INFO] - Training Epoch: 1/2, step 6052/107898 completed (loss: 1.5096638202667236, acc: 0.7419354915618896)
[2025-01-30 02:25:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6054/107898 [32:52<9:06:07,  3.11it/s][2025-01-30 02:25:02][root][INFO] - Training Epoch: 1/2, step 6053/107898 completed (loss: 5.789700508117676, acc: 0.5)
[2025-01-30 02:25:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6055/107898 [32:52<9:09:07,  3.09it/s][2025-01-30 02:25:02][root][INFO] - Training Epoch: 1/2, step 6054/107898 completed (loss: 0.1032930389046669, acc: 1.0)
[2025-01-30 02:25:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6056/107898 [32:52<9:15:08,  3.06it/s][2025-01-30 02:25:02][root][INFO] - Training Epoch: 1/2, step 6055/107898 completed (loss: 0.26294535398483276, acc: 0.9333333373069763)
[2025-01-30 02:25:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6057/107898 [32:53<9:02:36,  3.13it/s][2025-01-30 02:25:03][root][INFO] - Training Epoch: 1/2, step 6056/107898 completed (loss: 0.3338334560394287, acc: 1.0)
[2025-01-30 02:25:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6058/107898 [32:53<8:58:39,  3.15it/s][2025-01-30 02:25:03][root][INFO] - Training Epoch: 1/2, step 6057/107898 completed (loss: 2.730677843093872, acc: 0.6666666865348816)
[2025-01-30 02:25:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6059/107898 [32:53<9:05:41,  3.11it/s][2025-01-30 02:25:03][root][INFO] - Training Epoch: 1/2, step 6058/107898 completed (loss: 3.942507028579712, acc: 0.23076923191547394)
[2025-01-30 02:25:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6060/107898 [32:54<9:25:53,  3.00it/s][2025-01-30 02:25:04][root][INFO] - Training Epoch: 1/2, step 6059/107898 completed (loss: 0.005228853784501553, acc: 1.0)
[2025-01-30 02:25:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6061/107898 [32:54<9:39:55,  2.93it/s][2025-01-30 02:25:04][root][INFO] - Training Epoch: 1/2, step 6060/107898 completed (loss: 1.136825680732727, acc: 0.6875)
[2025-01-30 02:25:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6062/107898 [32:54<9:49:59,  2.88it/s][2025-01-30 02:25:04][root][INFO] - Training Epoch: 1/2, step 6061/107898 completed (loss: 1.1418116092681885, acc: 0.7692307829856873)
[2025-01-30 02:25:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6063/107898 [32:55<9:42:06,  2.92it/s][2025-01-30 02:25:05][root][INFO] - Training Epoch: 1/2, step 6062/107898 completed (loss: 1.092084527015686, acc: 1.0)
[2025-01-30 02:25:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6064/107898 [32:55<9:26:54,  2.99it/s][2025-01-30 02:25:05][root][INFO] - Training Epoch: 1/2, step 6063/107898 completed (loss: 0.02073172852396965, acc: 1.0)
[2025-01-30 02:25:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6065/107898 [32:55<9:22:40,  3.02it/s][2025-01-30 02:25:05][root][INFO] - Training Epoch: 1/2, step 6064/107898 completed (loss: 1.8407431840896606, acc: 0.46666666865348816)
[2025-01-30 02:25:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6066/107898 [32:56<9:39:40,  2.93it/s][2025-01-30 02:25:06][root][INFO] - Training Epoch: 1/2, step 6065/107898 completed (loss: 0.7284483313560486, acc: 0.9411764740943909)
[2025-01-30 02:25:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6067/107898 [32:56<9:34:52,  2.95it/s][2025-01-30 02:25:06][root][INFO] - Training Epoch: 1/2, step 6066/107898 completed (loss: 0.7537298798561096, acc: 0.8636363744735718)
[2025-01-30 02:25:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6068/107898 [32:56<9:14:54,  3.06it/s][2025-01-30 02:25:06][root][INFO] - Training Epoch: 1/2, step 6067/107898 completed (loss: 0.2375132441520691, acc: 0.875)
[2025-01-30 02:25:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6069/107898 [32:57<9:39:45,  2.93it/s][2025-01-30 02:25:07][root][INFO] - Training Epoch: 1/2, step 6068/107898 completed (loss: 0.66496741771698, acc: 0.8571428656578064)
[2025-01-30 02:25:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6070/107898 [32:57<9:30:33,  2.97it/s][2025-01-30 02:25:07][root][INFO] - Training Epoch: 1/2, step 6069/107898 completed (loss: 4.402303218841553, acc: 0.29032257199287415)
[2025-01-30 02:25:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6071/107898 [32:57<9:20:15,  3.03it/s][2025-01-30 02:25:07][root][INFO] - Training Epoch: 1/2, step 6070/107898 completed (loss: 0.3665604889392853, acc: 0.9166666865348816)
[2025-01-30 02:25:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6072/107898 [32:58<9:00:51,  3.14it/s][2025-01-30 02:25:08][root][INFO] - Training Epoch: 1/2, step 6071/107898 completed (loss: 0.06725450605154037, acc: 1.0)
[2025-01-30 02:25:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6073/107898 [32:58<8:53:38,  3.18it/s][2025-01-30 02:25:08][root][INFO] - Training Epoch: 1/2, step 6072/107898 completed (loss: 1.1525404453277588, acc: 0.6842105388641357)
[2025-01-30 02:25:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6074/107898 [32:58<9:23:45,  3.01it/s][2025-01-30 02:25:08][root][INFO] - Training Epoch: 1/2, step 6073/107898 completed (loss: 2.6515941619873047, acc: 0.5454545617103577)
[2025-01-30 02:25:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6075/107898 [32:59<9:29:58,  2.98it/s][2025-01-30 02:25:09][root][INFO] - Training Epoch: 1/2, step 6074/107898 completed (loss: 0.05041896924376488, acc: 1.0)
[2025-01-30 02:25:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6076/107898 [32:59<9:31:04,  2.97it/s][2025-01-30 02:25:09][root][INFO] - Training Epoch: 1/2, step 6075/107898 completed (loss: 1.1227959394454956, acc: 0.7272727489471436)
[2025-01-30 02:25:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6077/107898 [32:59<9:27:10,  2.99it/s][2025-01-30 02:25:09][root][INFO] - Training Epoch: 1/2, step 6076/107898 completed (loss: 1.1421446800231934, acc: 0.6666666865348816)
[2025-01-30 02:25:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6078/107898 [33:00<9:08:34,  3.09it/s][2025-01-30 02:25:10][root][INFO] - Training Epoch: 1/2, step 6077/107898 completed (loss: 0.03160972148180008, acc: 1.0)
[2025-01-30 02:25:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6079/107898 [33:00<8:56:58,  3.16it/s][2025-01-30 02:25:10][root][INFO] - Training Epoch: 1/2, step 6078/107898 completed (loss: 0.6362738013267517, acc: 0.8571428656578064)
[2025-01-30 02:25:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6080/107898 [33:00<8:56:49,  3.16it/s][2025-01-30 02:25:10][root][INFO] - Training Epoch: 1/2, step 6079/107898 completed (loss: 0.023076385259628296, acc: 1.0)
[2025-01-30 02:25:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6081/107898 [33:01<9:08:19,  3.09it/s][2025-01-30 02:25:10][root][INFO] - Training Epoch: 1/2, step 6080/107898 completed (loss: 2.608628988265991, acc: 0.3333333432674408)
[2025-01-30 02:25:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6082/107898 [33:01<9:09:26,  3.09it/s][2025-01-30 02:25:11][root][INFO] - Training Epoch: 1/2, step 6081/107898 completed (loss: 3.61393666267395, acc: 0.3333333432674408)
[2025-01-30 02:25:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6083/107898 [33:01<9:00:03,  3.14it/s][2025-01-30 02:25:11][root][INFO] - Training Epoch: 1/2, step 6082/107898 completed (loss: 0.0376853421330452, acc: 1.0)
[2025-01-30 02:25:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6084/107898 [33:02<8:51:03,  3.20it/s][2025-01-30 02:25:11][root][INFO] - Training Epoch: 1/2, step 6083/107898 completed (loss: 0.7601078748703003, acc: 0.9333333373069763)
[2025-01-30 02:25:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6085/107898 [33:02<8:47:35,  3.22it/s][2025-01-30 02:25:12][root][INFO] - Training Epoch: 1/2, step 6084/107898 completed (loss: 6.182060718536377, acc: 0.25)
[2025-01-30 02:25:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6086/107898 [33:02<8:50:21,  3.20it/s][2025-01-30 02:25:12][root][INFO] - Training Epoch: 1/2, step 6085/107898 completed (loss: 0.9062103629112244, acc: 0.8421052694320679)
[2025-01-30 02:25:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6087/107898 [33:03<8:49:46,  3.20it/s][2025-01-30 02:25:12][root][INFO] - Training Epoch: 1/2, step 6086/107898 completed (loss: 0.010317830368876457, acc: 1.0)
[2025-01-30 02:25:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6088/107898 [33:03<9:17:00,  3.05it/s][2025-01-30 02:25:13][root][INFO] - Training Epoch: 1/2, step 6087/107898 completed (loss: 1.0578219890594482, acc: 0.7441860437393188)
[2025-01-30 02:25:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6089/107898 [33:03<8:57:41,  3.16it/s][2025-01-30 02:25:13][root][INFO] - Training Epoch: 1/2, step 6088/107898 completed (loss: 0.5905884504318237, acc: 0.800000011920929)
[2025-01-30 02:25:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6090/107898 [33:04<9:15:47,  3.05it/s][2025-01-30 02:25:13][root][INFO] - Training Epoch: 1/2, step 6089/107898 completed (loss: 1.21793532371521, acc: 0.7857142686843872)
[2025-01-30 02:25:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6091/107898 [33:04<9:09:47,  3.09it/s][2025-01-30 02:25:14][root][INFO] - Training Epoch: 1/2, step 6090/107898 completed (loss: 0.4438144266605377, acc: 0.8333333134651184)
[2025-01-30 02:25:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6092/107898 [33:04<8:57:20,  3.16it/s][2025-01-30 02:25:14][root][INFO] - Training Epoch: 1/2, step 6091/107898 completed (loss: 0.11829957365989685, acc: 1.0)
[2025-01-30 02:25:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6093/107898 [33:04<8:56:18,  3.16it/s][2025-01-30 02:25:14][root][INFO] - Training Epoch: 1/2, step 6092/107898 completed (loss: 0.37568697333335876, acc: 0.8823529481887817)
[2025-01-30 02:25:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6094/107898 [33:05<9:15:10,  3.06it/s][2025-01-30 02:25:15][root][INFO] - Training Epoch: 1/2, step 6093/107898 completed (loss: 0.2423911839723587, acc: 1.0)
[2025-01-30 02:25:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6095/107898 [33:05<9:39:20,  2.93it/s][2025-01-30 02:25:15][root][INFO] - Training Epoch: 1/2, step 6094/107898 completed (loss: 0.6729992628097534, acc: 0.8333333134651184)
[2025-01-30 02:25:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6096/107898 [33:06<9:55:22,  2.85it/s][2025-01-30 02:25:15][root][INFO] - Training Epoch: 1/2, step 6095/107898 completed (loss: 1.1194958686828613, acc: 0.7777777910232544)
[2025-01-30 02:25:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6097/107898 [33:06<9:47:23,  2.89it/s][2025-01-30 02:25:16][root][INFO] - Training Epoch: 1/2, step 6096/107898 completed (loss: 0.6732102036476135, acc: 0.6666666865348816)
[2025-01-30 02:25:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6098/107898 [33:06<9:29:45,  2.98it/s][2025-01-30 02:25:16][root][INFO] - Training Epoch: 1/2, step 6097/107898 completed (loss: 0.018971648067235947, acc: 1.0)
[2025-01-30 02:25:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6099/107898 [33:07<9:34:06,  2.96it/s][2025-01-30 02:25:16][root][INFO] - Training Epoch: 1/2, step 6098/107898 completed (loss: 0.15299952030181885, acc: 1.0)
[2025-01-30 02:25:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6100/107898 [33:07<9:28:35,  2.98it/s][2025-01-30 02:25:17][root][INFO] - Training Epoch: 1/2, step 6099/107898 completed (loss: 1.488371729850769, acc: 0.75)
[2025-01-30 02:25:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6101/107898 [33:07<9:43:29,  2.91it/s][2025-01-30 02:25:17][root][INFO] - Training Epoch: 1/2, step 6100/107898 completed (loss: 1.0231807231903076, acc: 0.8999999761581421)
[2025-01-30 02:25:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6102/107898 [33:08<9:34:19,  2.95it/s][2025-01-30 02:25:17][root][INFO] - Training Epoch: 1/2, step 6101/107898 completed (loss: 0.4321182668209076, acc: 1.0)
[2025-01-30 02:25:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6103/107898 [33:08<9:19:15,  3.03it/s][2025-01-30 02:25:18][root][INFO] - Training Epoch: 1/2, step 6102/107898 completed (loss: 1.1788991689682007, acc: 0.625)
[2025-01-30 02:25:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6104/107898 [33:08<9:09:29,  3.09it/s][2025-01-30 02:25:18][root][INFO] - Training Epoch: 1/2, step 6103/107898 completed (loss: 0.8948134183883667, acc: 0.75)
[2025-01-30 02:25:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6105/107898 [33:09<8:50:14,  3.20it/s][2025-01-30 02:25:18][root][INFO] - Training Epoch: 1/2, step 6104/107898 completed (loss: 0.4337810277938843, acc: 0.9230769276618958)
[2025-01-30 02:25:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6106/107898 [33:09<8:45:38,  3.23it/s][2025-01-30 02:25:19][root][INFO] - Training Epoch: 1/2, step 6105/107898 completed (loss: 0.25073641538619995, acc: 0.9166666865348816)
[2025-01-30 02:25:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6107/107898 [33:09<8:39:37,  3.26it/s][2025-01-30 02:25:19][root][INFO] - Training Epoch: 1/2, step 6106/107898 completed (loss: 1.1209973096847534, acc: 0.7777777910232544)
[2025-01-30 02:25:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6108/107898 [33:09<8:45:44,  3.23it/s][2025-01-30 02:25:19][root][INFO] - Training Epoch: 1/2, step 6107/107898 completed (loss: 0.33671966195106506, acc: 1.0)
[2025-01-30 02:25:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6109/107898 [33:10<9:10:35,  3.08it/s][2025-01-30 02:25:20][root][INFO] - Training Epoch: 1/2, step 6108/107898 completed (loss: 0.03511618822813034, acc: 1.0)
[2025-01-30 02:25:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6110/107898 [33:10<9:11:24,  3.08it/s][2025-01-30 02:25:20][root][INFO] - Training Epoch: 1/2, step 6109/107898 completed (loss: 2.5364294052124023, acc: 0.375)
[2025-01-30 02:25:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6111/107898 [33:10<9:06:48,  3.10it/s][2025-01-30 02:25:20][root][INFO] - Training Epoch: 1/2, step 6110/107898 completed (loss: 4.622635841369629, acc: 0.5)
[2025-01-30 02:25:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6112/107898 [33:11<9:13:10,  3.07it/s][2025-01-30 02:25:21][root][INFO] - Training Epoch: 1/2, step 6111/107898 completed (loss: 0.8854005336761475, acc: 0.5)
[2025-01-30 02:25:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6113/107898 [33:11<9:32:11,  2.96it/s][2025-01-30 02:25:21][root][INFO] - Training Epoch: 1/2, step 6112/107898 completed (loss: 0.20807987451553345, acc: 1.0)
[2025-01-30 02:25:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6114/107898 [33:11<9:37:18,  2.94it/s][2025-01-30 02:25:21][root][INFO] - Training Epoch: 1/2, step 6113/107898 completed (loss: 1.1398563385009766, acc: 0.761904776096344)
[2025-01-30 02:25:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6115/107898 [33:12<9:37:28,  2.94it/s][2025-01-30 02:25:22][root][INFO] - Training Epoch: 1/2, step 6114/107898 completed (loss: 1.3708232641220093, acc: 0.7333333492279053)
[2025-01-30 02:25:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6116/107898 [33:12<9:34:12,  2.95it/s][2025-01-30 02:25:22][root][INFO] - Training Epoch: 1/2, step 6115/107898 completed (loss: 2.188887596130371, acc: 0.6000000238418579)
[2025-01-30 02:25:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6117/107898 [33:13<9:48:13,  2.88it/s][2025-01-30 02:25:22][root][INFO] - Training Epoch: 1/2, step 6116/107898 completed (loss: 1.3943848609924316, acc: 0.9230769276618958)
[2025-01-30 02:25:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6118/107898 [33:13<9:48:29,  2.88it/s][2025-01-30 02:25:23][root][INFO] - Training Epoch: 1/2, step 6117/107898 completed (loss: 3.5885276794433594, acc: 0.20000000298023224)
[2025-01-30 02:25:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6119/107898 [33:13<9:38:18,  2.93it/s][2025-01-30 02:25:23][root][INFO] - Training Epoch: 1/2, step 6118/107898 completed (loss: 0.3732254207134247, acc: 0.9375)
[2025-01-30 02:25:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6120/107898 [33:14<9:47:12,  2.89it/s][2025-01-30 02:25:23][root][INFO] - Training Epoch: 1/2, step 6119/107898 completed (loss: 0.04637845605611801, acc: 1.0)
[2025-01-30 02:25:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6121/107898 [33:14<9:35:41,  2.95it/s][2025-01-30 02:25:24][root][INFO] - Training Epoch: 1/2, step 6120/107898 completed (loss: 2.030146360397339, acc: 0.5)
[2025-01-30 02:25:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6122/107898 [33:14<9:42:38,  2.91it/s][2025-01-30 02:25:24][root][INFO] - Training Epoch: 1/2, step 6121/107898 completed (loss: 3.6434438228607178, acc: 0.375)
[2025-01-30 02:25:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6123/107898 [33:15<9:56:00,  2.85it/s][2025-01-30 02:25:24][root][INFO] - Training Epoch: 1/2, step 6122/107898 completed (loss: 4.035537242889404, acc: 0.5)
[2025-01-30 02:25:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6124/107898 [33:15<9:45:54,  2.90it/s][2025-01-30 02:25:25][root][INFO] - Training Epoch: 1/2, step 6123/107898 completed (loss: 0.06780388206243515, acc: 1.0)
[2025-01-30 02:25:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6125/107898 [33:15<9:35:19,  2.95it/s][2025-01-30 02:25:25][root][INFO] - Training Epoch: 1/2, step 6124/107898 completed (loss: 1.9355891942977905, acc: 0.6000000238418579)
[2025-01-30 02:25:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6126/107898 [33:16<9:37:20,  2.94it/s][2025-01-30 02:25:25][root][INFO] - Training Epoch: 1/2, step 6125/107898 completed (loss: 1.77874755859375, acc: 0.6875)
[2025-01-30 02:25:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6127/107898 [33:16<9:43:22,  2.91it/s][2025-01-30 02:25:26][root][INFO] - Training Epoch: 1/2, step 6126/107898 completed (loss: 0.5652692317962646, acc: 1.0)
[2025-01-30 02:25:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6128/107898 [33:16<9:42:32,  2.91it/s][2025-01-30 02:25:26][root][INFO] - Training Epoch: 1/2, step 6127/107898 completed (loss: 0.09604975581169128, acc: 1.0)
[2025-01-30 02:25:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6129/107898 [33:17<9:40:14,  2.92it/s][2025-01-30 02:25:26][root][INFO] - Training Epoch: 1/2, step 6128/107898 completed (loss: 0.24168144166469574, acc: 1.0)
[2025-01-30 02:25:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6130/107898 [33:17<9:25:01,  3.00it/s][2025-01-30 02:25:27][root][INFO] - Training Epoch: 1/2, step 6129/107898 completed (loss: 0.47611910104751587, acc: 1.0)
[2025-01-30 02:25:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6131/107898 [33:17<9:34:22,  2.95it/s][2025-01-30 02:25:27][root][INFO] - Training Epoch: 1/2, step 6130/107898 completed (loss: 0.08005170524120331, acc: 1.0)
[2025-01-30 02:25:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6132/107898 [33:18<9:39:46,  2.93it/s][2025-01-30 02:25:27][root][INFO] - Training Epoch: 1/2, step 6131/107898 completed (loss: 0.03527713939547539, acc: 1.0)
[2025-01-30 02:25:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6133/107898 [33:18<9:48:36,  2.88it/s][2025-01-30 02:25:28][root][INFO] - Training Epoch: 1/2, step 6132/107898 completed (loss: 1.36932373046875, acc: 0.8181818127632141)
[2025-01-30 02:25:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6134/107898 [33:18<9:45:19,  2.90it/s][2025-01-30 02:25:28][root][INFO] - Training Epoch: 1/2, step 6133/107898 completed (loss: 1.2411214113235474, acc: 0.8125)
[2025-01-30 02:25:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6135/107898 [33:19<9:32:21,  2.96it/s][2025-01-30 02:25:28][root][INFO] - Training Epoch: 1/2, step 6134/107898 completed (loss: 1.0205693244934082, acc: 0.8571428656578064)
[2025-01-30 02:25:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6136/107898 [33:19<9:14:51,  3.06it/s][2025-01-30 02:25:29][root][INFO] - Training Epoch: 1/2, step 6135/107898 completed (loss: 2.951005458831787, acc: 0.25)
[2025-01-30 02:25:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6137/107898 [33:19<8:58:17,  3.15it/s][2025-01-30 02:25:29][root][INFO] - Training Epoch: 1/2, step 6136/107898 completed (loss: 0.6275281310081482, acc: 0.8181818127632141)
[2025-01-30 02:25:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6138/107898 [33:20<8:47:41,  3.21it/s][2025-01-30 02:25:29][root][INFO] - Training Epoch: 1/2, step 6137/107898 completed (loss: 0.11199845373630524, acc: 0.9615384340286255)
[2025-01-30 02:25:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6139/107898 [33:20<9:06:20,  3.10it/s][2025-01-30 02:25:30][root][INFO] - Training Epoch: 1/2, step 6138/107898 completed (loss: 0.8753272891044617, acc: 0.0)
[2025-01-30 02:25:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6140/107898 [33:20<9:15:45,  3.05it/s][2025-01-30 02:25:30][root][INFO] - Training Epoch: 1/2, step 6139/107898 completed (loss: 3.1756179332733154, acc: 0.6666666865348816)
[2025-01-30 02:25:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6141/107898 [33:21<9:08:01,  3.09it/s][2025-01-30 02:25:30][root][INFO] - Training Epoch: 1/2, step 6140/107898 completed (loss: 1.1757334470748901, acc: 0.7692307829856873)
[2025-01-30 02:25:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6142/107898 [33:21<9:18:33,  3.04it/s][2025-01-30 02:25:31][root][INFO] - Training Epoch: 1/2, step 6141/107898 completed (loss: 1.9338951110839844, acc: 0.625)
[2025-01-30 02:25:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6143/107898 [33:21<9:05:39,  3.11it/s][2025-01-30 02:25:31][root][INFO] - Training Epoch: 1/2, step 6142/107898 completed (loss: 1.4232219457626343, acc: 0.6818181872367859)
[2025-01-30 02:25:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6144/107898 [33:21<8:50:50,  3.19it/s][2025-01-30 02:25:31][root][INFO] - Training Epoch: 1/2, step 6143/107898 completed (loss: 0.04221469908952713, acc: 1.0)
[2025-01-30 02:25:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6145/107898 [33:22<8:52:08,  3.19it/s][2025-01-30 02:25:32][root][INFO] - Training Epoch: 1/2, step 6144/107898 completed (loss: 1.611905813217163, acc: 0.5)
[2025-01-30 02:25:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6146/107898 [33:22<9:05:27,  3.11it/s][2025-01-30 02:25:32][root][INFO] - Training Epoch: 1/2, step 6145/107898 completed (loss: 0.002916846191510558, acc: 1.0)
[2025-01-30 02:25:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6147/107898 [33:22<9:00:25,  3.14it/s][2025-01-30 02:25:32][root][INFO] - Training Epoch: 1/2, step 6146/107898 completed (loss: 0.6479976773262024, acc: 0.8636363744735718)
[2025-01-30 02:25:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6148/107898 [33:23<9:14:00,  3.06it/s][2025-01-30 02:25:33][root][INFO] - Training Epoch: 1/2, step 6147/107898 completed (loss: 0.625119149684906, acc: 0.8421052694320679)
[2025-01-30 02:25:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6149/107898 [33:23<9:05:21,  3.11it/s][2025-01-30 02:25:33][root][INFO] - Training Epoch: 1/2, step 6148/107898 completed (loss: 1.0956854820251465, acc: 0.800000011920929)
[2025-01-30 02:25:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6150/107898 [33:23<8:56:10,  3.16it/s][2025-01-30 02:25:33][root][INFO] - Training Epoch: 1/2, step 6149/107898 completed (loss: 0.0008610226213932037, acc: 1.0)
[2025-01-30 02:25:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6151/107898 [33:24<8:54:05,  3.18it/s][2025-01-30 02:25:34][root][INFO] - Training Epoch: 1/2, step 6150/107898 completed (loss: 2.577824354171753, acc: 0.4583333432674408)
[2025-01-30 02:25:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6152/107898 [33:24<9:10:44,  3.08it/s][2025-01-30 02:25:34][root][INFO] - Training Epoch: 1/2, step 6151/107898 completed (loss: 2.636000871658325, acc: 0.4399999976158142)
[2025-01-30 02:25:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6153/107898 [33:24<9:10:35,  3.08it/s][2025-01-30 02:25:34][root][INFO] - Training Epoch: 1/2, step 6152/107898 completed (loss: 0.8851314187049866, acc: 0.6666666865348816)
[2025-01-30 02:25:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6154/107898 [33:25<9:16:43,  3.05it/s][2025-01-30 02:25:35][root][INFO] - Training Epoch: 1/2, step 6153/107898 completed (loss: 4.8763957023620605, acc: 0.375)
[2025-01-30 02:25:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6155/107898 [33:25<9:20:02,  3.03it/s][2025-01-30 02:25:35][root][INFO] - Training Epoch: 1/2, step 6154/107898 completed (loss: 1.538051724433899, acc: 0.6000000238418579)
[2025-01-30 02:25:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6156/107898 [33:25<9:08:46,  3.09it/s][2025-01-30 02:25:35][root][INFO] - Training Epoch: 1/2, step 6155/107898 completed (loss: 2.109431266784668, acc: 0.7777777910232544)
[2025-01-30 02:25:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6157/107898 [33:26<9:17:24,  3.04it/s][2025-01-30 02:25:36][root][INFO] - Training Epoch: 1/2, step 6156/107898 completed (loss: 0.011422003619372845, acc: 1.0)
[2025-01-30 02:25:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6158/107898 [33:26<9:16:36,  3.05it/s][2025-01-30 02:25:36][root][INFO] - Training Epoch: 1/2, step 6157/107898 completed (loss: 0.5188379287719727, acc: 0.75)
[2025-01-30 02:25:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6159/107898 [33:26<9:14:26,  3.06it/s][2025-01-30 02:25:36][root][INFO] - Training Epoch: 1/2, step 6158/107898 completed (loss: 0.45195749402046204, acc: 0.875)
[2025-01-30 02:25:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6160/107898 [33:27<9:27:02,  2.99it/s][2025-01-30 02:25:37][root][INFO] - Training Epoch: 1/2, step 6159/107898 completed (loss: 0.39753586053848267, acc: 1.0)
[2025-01-30 02:25:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6161/107898 [33:27<9:26:13,  2.99it/s][2025-01-30 02:25:37][root][INFO] - Training Epoch: 1/2, step 6160/107898 completed (loss: 5.316540718078613, acc: 0.3333333432674408)
[2025-01-30 02:25:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6162/107898 [33:27<9:21:28,  3.02it/s][2025-01-30 02:25:37][root][INFO] - Training Epoch: 1/2, step 6161/107898 completed (loss: 2.2941744327545166, acc: 0.6666666865348816)
[2025-01-30 02:25:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6163/107898 [33:28<9:20:46,  3.02it/s][2025-01-30 02:25:38][root][INFO] - Training Epoch: 1/2, step 6162/107898 completed (loss: 0.0011252791155129671, acc: 1.0)
[2025-01-30 02:25:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6164/107898 [33:28<9:23:30,  3.01it/s][2025-01-30 02:25:38][root][INFO] - Training Epoch: 1/2, step 6163/107898 completed (loss: 0.4332115948200226, acc: 0.9333333373069763)
[2025-01-30 02:25:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6165/107898 [33:28<9:08:27,  3.09it/s][2025-01-30 02:25:38][root][INFO] - Training Epoch: 1/2, step 6164/107898 completed (loss: 3.8906588554382324, acc: 0.10000000149011612)
[2025-01-30 02:25:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6166/107898 [33:29<9:21:15,  3.02it/s][2025-01-30 02:25:38][root][INFO] - Training Epoch: 1/2, step 6165/107898 completed (loss: 1.0742939710617065, acc: 0.75)
[2025-01-30 02:25:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6167/107898 [33:29<9:47:59,  2.88it/s][2025-01-30 02:25:39][root][INFO] - Training Epoch: 1/2, step 6166/107898 completed (loss: 0.4437280595302582, acc: 0.9375)
[2025-01-30 02:25:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6168/107898 [33:29<9:36:17,  2.94it/s][2025-01-30 02:25:39][root][INFO] - Training Epoch: 1/2, step 6167/107898 completed (loss: 1.0095953941345215, acc: 0.8461538553237915)
[2025-01-30 02:25:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6169/107898 [33:30<9:42:10,  2.91it/s][2025-01-30 02:25:40][root][INFO] - Training Epoch: 1/2, step 6168/107898 completed (loss: 0.6157944202423096, acc: 0.9333333373069763)
[2025-01-30 02:25:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6170/107898 [33:30<9:50:34,  2.87it/s][2025-01-30 02:25:40][root][INFO] - Training Epoch: 1/2, step 6169/107898 completed (loss: 0.6104353070259094, acc: 0.5)
[2025-01-30 02:25:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6171/107898 [33:30<9:59:47,  2.83it/s][2025-01-30 02:25:40][root][INFO] - Training Epoch: 1/2, step 6170/107898 completed (loss: 4.350306034088135, acc: 0.5)
[2025-01-30 02:25:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6172/107898 [33:31<9:26:26,  2.99it/s][2025-01-30 02:25:41][root][INFO] - Training Epoch: 1/2, step 6171/107898 completed (loss: 4.705177307128906, acc: 0.4285714328289032)
[2025-01-30 02:25:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6173/107898 [33:31<9:06:37,  3.10it/s][2025-01-30 02:25:41][root][INFO] - Training Epoch: 1/2, step 6172/107898 completed (loss: 1.0109738111495972, acc: 0.7894737124443054)
[2025-01-30 02:25:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6174/107898 [33:31<8:57:29,  3.15it/s][2025-01-30 02:25:41][root][INFO] - Training Epoch: 1/2, step 6173/107898 completed (loss: 4.619385242462158, acc: 0.3333333432674408)
[2025-01-30 02:25:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6175/107898 [33:32<8:44:13,  3.23it/s][2025-01-30 02:25:41][root][INFO] - Training Epoch: 1/2, step 6174/107898 completed (loss: 0.30070534348487854, acc: 0.8999999761581421)
[2025-01-30 02:25:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6176/107898 [33:32<8:33:47,  3.30it/s][2025-01-30 02:25:42][root][INFO] - Training Epoch: 1/2, step 6175/107898 completed (loss: 0.35724741220474243, acc: 1.0)
[2025-01-30 02:25:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6177/107898 [33:32<8:36:19,  3.28it/s][2025-01-30 02:25:42][root][INFO] - Training Epoch: 1/2, step 6176/107898 completed (loss: 0.2759852409362793, acc: 1.0)
[2025-01-30 02:25:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6178/107898 [33:33<8:32:07,  3.31it/s][2025-01-30 02:25:42][root][INFO] - Training Epoch: 1/2, step 6177/107898 completed (loss: 0.4423188865184784, acc: 1.0)
[2025-01-30 02:25:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6179/107898 [33:33<8:41:21,  3.25it/s][2025-01-30 02:25:43][root][INFO] - Training Epoch: 1/2, step 6178/107898 completed (loss: 1.718971610069275, acc: 0.6875)
[2025-01-30 02:25:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6180/107898 [33:33<9:14:31,  3.06it/s][2025-01-30 02:25:43][root][INFO] - Training Epoch: 1/2, step 6179/107898 completed (loss: 1.5900651216506958, acc: 0.6888889074325562)
[2025-01-30 02:25:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6181/107898 [33:34<9:00:43,  3.14it/s][2025-01-30 02:25:43][root][INFO] - Training Epoch: 1/2, step 6180/107898 completed (loss: 1.0541027784347534, acc: 0.782608687877655)
[2025-01-30 02:25:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6182/107898 [33:34<8:47:50,  3.21it/s][2025-01-30 02:25:44][root][INFO] - Training Epoch: 1/2, step 6181/107898 completed (loss: 2.183156728744507, acc: 0.5)
[2025-01-30 02:25:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6183/107898 [33:34<8:48:23,  3.21it/s][2025-01-30 02:25:44][root][INFO] - Training Epoch: 1/2, step 6182/107898 completed (loss: 1.080485224723816, acc: 0.6666666865348816)
[2025-01-30 02:25:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6184/107898 [33:34<8:47:44,  3.21it/s][2025-01-30 02:25:44][root][INFO] - Training Epoch: 1/2, step 6183/107898 completed (loss: 0.4904305934906006, acc: 0.6666666865348816)
[2025-01-30 02:25:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6185/107898 [33:35<8:42:25,  3.24it/s][2025-01-30 02:25:45][root][INFO] - Training Epoch: 1/2, step 6184/107898 completed (loss: 0.6472501158714294, acc: 0.6666666865348816)
[2025-01-30 02:25:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6186/107898 [33:35<8:41:45,  3.25it/s][2025-01-30 02:25:45][root][INFO] - Training Epoch: 1/2, step 6185/107898 completed (loss: 0.039795417338609695, acc: 1.0)
[2025-01-30 02:25:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6187/107898 [33:35<8:36:16,  3.28it/s][2025-01-30 02:25:45][root][INFO] - Training Epoch: 1/2, step 6186/107898 completed (loss: 2.1754136085510254, acc: 0.5)
[2025-01-30 02:25:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6188/107898 [33:36<8:53:19,  3.18it/s][2025-01-30 02:25:45][root][INFO] - Training Epoch: 1/2, step 6187/107898 completed (loss: 1.421521544456482, acc: 0.6666666865348816)
[2025-01-30 02:25:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6189/107898 [33:36<8:20:40,  3.39it/s][2025-01-30 02:25:46][root][INFO] - Training Epoch: 1/2, step 6188/107898 completed (loss: 0.0037300423718988895, acc: 1.0)
[2025-01-30 02:25:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6190/107898 [33:36<8:30:06,  3.32it/s][2025-01-30 02:25:46][root][INFO] - Training Epoch: 1/2, step 6189/107898 completed (loss: 0.32313498854637146, acc: 0.9166666865348816)
[2025-01-30 02:25:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6191/107898 [33:37<9:01:46,  3.13it/s][2025-01-30 02:25:46][root][INFO] - Training Epoch: 1/2, step 6190/107898 completed (loss: 0.004559270106256008, acc: 1.0)
[2025-01-30 02:25:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6192/107898 [33:37<9:08:25,  3.09it/s][2025-01-30 02:25:47][root][INFO] - Training Epoch: 1/2, step 6191/107898 completed (loss: 0.007177851162850857, acc: 1.0)
[2025-01-30 02:25:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6193/107898 [33:37<8:58:02,  3.15it/s][2025-01-30 02:25:47][root][INFO] - Training Epoch: 1/2, step 6192/107898 completed (loss: 0.015578498132526875, acc: 1.0)
[2025-01-30 02:25:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6194/107898 [33:38<8:50:43,  3.19it/s][2025-01-30 02:25:47][root][INFO] - Training Epoch: 1/2, step 6193/107898 completed (loss: 0.040200408548116684, acc: 1.0)
[2025-01-30 02:25:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6195/107898 [33:38<8:42:31,  3.24it/s][2025-01-30 02:25:48][root][INFO] - Training Epoch: 1/2, step 6194/107898 completed (loss: 0.23629525303840637, acc: 1.0)
[2025-01-30 02:25:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6196/107898 [33:38<9:05:17,  3.11it/s][2025-01-30 02:25:48][root][INFO] - Training Epoch: 1/2, step 6195/107898 completed (loss: 1.122291922569275, acc: 0.6666666865348816)
[2025-01-30 02:25:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6197/107898 [33:39<9:05:39,  3.11it/s][2025-01-30 02:25:48][root][INFO] - Training Epoch: 1/2, step 6196/107898 completed (loss: 2.971677541732788, acc: 0.25)
[2025-01-30 02:25:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6198/107898 [33:39<8:57:16,  3.15it/s][2025-01-30 02:25:49][root][INFO] - Training Epoch: 1/2, step 6197/107898 completed (loss: 0.007586004212498665, acc: 1.0)
[2025-01-30 02:25:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6199/107898 [33:39<9:00:17,  3.14it/s][2025-01-30 02:25:49][root][INFO] - Training Epoch: 1/2, step 6198/107898 completed (loss: 0.38186565041542053, acc: 0.8823529481887817)
[2025-01-30 02:25:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6200/107898 [33:39<8:54:38,  3.17it/s][2025-01-30 02:25:49][root][INFO] - Training Epoch: 1/2, step 6199/107898 completed (loss: 2.4987950325012207, acc: 0.75)
[2025-01-30 02:25:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6201/107898 [33:40<9:10:30,  3.08it/s][2025-01-30 02:25:50][root][INFO] - Training Epoch: 1/2, step 6200/107898 completed (loss: 0.2628248333930969, acc: 1.0)
[2025-01-30 02:25:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6202/107898 [33:40<9:10:32,  3.08it/s][2025-01-30 02:25:50][root][INFO] - Training Epoch: 1/2, step 6201/107898 completed (loss: 0.46824583411216736, acc: 0.6666666865348816)
[2025-01-30 02:25:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6203/107898 [33:40<9:13:44,  3.06it/s][2025-01-30 02:25:50][root][INFO] - Training Epoch: 1/2, step 6202/107898 completed (loss: 2.295715093612671, acc: 0.625)
[2025-01-30 02:25:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6204/107898 [33:41<8:59:14,  3.14it/s][2025-01-30 02:25:51][root][INFO] - Training Epoch: 1/2, step 6203/107898 completed (loss: 0.2096482217311859, acc: 0.875)
[2025-01-30 02:25:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6205/107898 [33:41<8:50:31,  3.19it/s][2025-01-30 02:25:51][root][INFO] - Training Epoch: 1/2, step 6204/107898 completed (loss: 0.0031718709506094456, acc: 1.0)
[2025-01-30 02:25:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6206/107898 [33:41<8:28:00,  3.34it/s][2025-01-30 02:25:51][root][INFO] - Training Epoch: 1/2, step 6205/107898 completed (loss: 2.329699993133545, acc: 0.75)
[2025-01-30 02:25:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6207/107898 [33:42<8:28:53,  3.33it/s][2025-01-30 02:25:51][root][INFO] - Training Epoch: 1/2, step 6206/107898 completed (loss: 0.008342951536178589, acc: 1.0)
[2025-01-30 02:25:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6208/107898 [33:42<8:39:23,  3.26it/s][2025-01-30 02:25:52][root][INFO] - Training Epoch: 1/2, step 6207/107898 completed (loss: 1.418046236038208, acc: 0.5384615659713745)
[2025-01-30 02:25:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6209/107898 [33:42<9:00:14,  3.14it/s][2025-01-30 02:25:52][root][INFO] - Training Epoch: 1/2, step 6208/107898 completed (loss: 0.5729382038116455, acc: 0.75)
[2025-01-30 02:25:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6210/107898 [33:43<8:52:42,  3.18it/s][2025-01-30 02:25:52][root][INFO] - Training Epoch: 1/2, step 6209/107898 completed (loss: 0.24723078310489655, acc: 0.6666666865348816)
[2025-01-30 02:25:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6211/107898 [33:43<8:43:48,  3.24it/s][2025-01-30 02:25:53][root][INFO] - Training Epoch: 1/2, step 6210/107898 completed (loss: 0.10140740871429443, acc: 1.0)
[2025-01-30 02:25:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6212/107898 [33:43<8:43:00,  3.24it/s][2025-01-30 02:25:53][root][INFO] - Training Epoch: 1/2, step 6211/107898 completed (loss: 1.3651574850082397, acc: 0.7142857313156128)
[2025-01-30 02:25:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6213/107898 [33:44<8:44:35,  3.23it/s][2025-01-30 02:25:53][root][INFO] - Training Epoch: 1/2, step 6212/107898 completed (loss: 0.8313378095626831, acc: 0.8461538553237915)
[2025-01-30 02:25:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6214/107898 [33:44<8:46:43,  3.22it/s][2025-01-30 02:25:54][root][INFO] - Training Epoch: 1/2, step 6213/107898 completed (loss: 0.664679765701294, acc: 0.7777777910232544)
[2025-01-30 02:25:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6215/107898 [33:44<8:40:19,  3.26it/s][2025-01-30 02:25:54][root][INFO] - Training Epoch: 1/2, step 6214/107898 completed (loss: 0.9256614446640015, acc: 0.800000011920929)
[2025-01-30 02:25:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6216/107898 [33:44<8:30:05,  3.32it/s][2025-01-30 02:25:54][root][INFO] - Training Epoch: 1/2, step 6215/107898 completed (loss: 0.015656879171729088, acc: 1.0)
[2025-01-30 02:25:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6217/107898 [33:45<8:26:07,  3.35it/s][2025-01-30 02:25:55][root][INFO] - Training Epoch: 1/2, step 6216/107898 completed (loss: 0.0907415822148323, acc: 1.0)
[2025-01-30 02:25:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6218/107898 [33:45<8:53:03,  3.18it/s][2025-01-30 02:25:55][root][INFO] - Training Epoch: 1/2, step 6217/107898 completed (loss: 0.028419578447937965, acc: 1.0)
[2025-01-30 02:25:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6219/107898 [33:45<9:05:15,  3.11it/s][2025-01-30 02:25:55][root][INFO] - Training Epoch: 1/2, step 6218/107898 completed (loss: 1.3609602451324463, acc: 0.6666666865348816)
[2025-01-30 02:25:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6220/107898 [33:46<9:11:44,  3.07it/s][2025-01-30 02:25:56][root][INFO] - Training Epoch: 1/2, step 6219/107898 completed (loss: 0.3752085268497467, acc: 0.6666666865348816)
[2025-01-30 02:25:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6221/107898 [33:46<9:12:46,  3.07it/s][2025-01-30 02:25:56][root][INFO] - Training Epoch: 1/2, step 6220/107898 completed (loss: 0.11447694897651672, acc: 1.0)
[2025-01-30 02:25:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6222/107898 [33:46<8:49:13,  3.20it/s][2025-01-30 02:25:56][root][INFO] - Training Epoch: 1/2, step 6221/107898 completed (loss: 1.817662000656128, acc: 0.75)
[2025-01-30 02:25:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6223/107898 [33:47<9:05:40,  3.11it/s][2025-01-30 02:25:57][root][INFO] - Training Epoch: 1/2, step 6222/107898 completed (loss: 0.37894776463508606, acc: 0.6666666865348816)
[2025-01-30 02:25:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6224/107898 [33:47<9:32:20,  2.96it/s][2025-01-30 02:25:57][root][INFO] - Training Epoch: 1/2, step 6223/107898 completed (loss: 1.518385887145996, acc: 0.6190476417541504)
[2025-01-30 02:25:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6225/107898 [33:47<9:11:25,  3.07it/s][2025-01-30 02:25:57][root][INFO] - Training Epoch: 1/2, step 6224/107898 completed (loss: 0.0429682582616806, acc: 1.0)
[2025-01-30 02:25:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6226/107898 [33:48<9:27:34,  2.99it/s][2025-01-30 02:25:58][root][INFO] - Training Epoch: 1/2, step 6225/107898 completed (loss: 3.0156049728393555, acc: 0.5)
[2025-01-30 02:25:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6227/107898 [33:48<9:41:57,  2.91it/s][2025-01-30 02:25:58][root][INFO] - Training Epoch: 1/2, step 6226/107898 completed (loss: 3.8739006519317627, acc: 0.25)
[2025-01-30 02:25:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6228/107898 [33:48<9:36:34,  2.94it/s][2025-01-30 02:25:58][root][INFO] - Training Epoch: 1/2, step 6227/107898 completed (loss: 0.9513217806816101, acc: 0.8260869383811951)
[2025-01-30 02:25:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6229/107898 [33:49<9:18:02,  3.04it/s][2025-01-30 02:25:59][root][INFO] - Training Epoch: 1/2, step 6228/107898 completed (loss: 0.005313454195857048, acc: 1.0)
[2025-01-30 02:25:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6230/107898 [33:49<9:28:36,  2.98it/s][2025-01-30 02:25:59][root][INFO] - Training Epoch: 1/2, step 6229/107898 completed (loss: 0.010412531904876232, acc: 1.0)
[2025-01-30 02:25:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6231/107898 [33:49<9:38:13,  2.93it/s][2025-01-30 02:25:59][root][INFO] - Training Epoch: 1/2, step 6230/107898 completed (loss: 1.4462007284164429, acc: 0.7368420958518982)
[2025-01-30 02:25:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6232/107898 [33:50<9:27:37,  2.99it/s][2025-01-30 02:26:00][root][INFO] - Training Epoch: 1/2, step 6231/107898 completed (loss: 3.374876022338867, acc: 0.3333333432674408)
[2025-01-30 02:26:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6233/107898 [33:50<9:06:04,  3.10it/s][2025-01-30 02:26:00][root][INFO] - Training Epoch: 1/2, step 6232/107898 completed (loss: 1.8418605327606201, acc: 0.7368420958518982)
[2025-01-30 02:26:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6234/107898 [33:50<8:47:31,  3.21it/s][2025-01-30 02:26:00][root][INFO] - Training Epoch: 1/2, step 6233/107898 completed (loss: 0.3540377914905548, acc: 1.0)
[2025-01-30 02:26:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6235/107898 [33:51<8:39:10,  3.26it/s][2025-01-30 02:26:00][root][INFO] - Training Epoch: 1/2, step 6234/107898 completed (loss: 0.007854633964598179, acc: 1.0)
[2025-01-30 02:26:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6236/107898 [33:51<9:04:06,  3.11it/s][2025-01-30 02:26:01][root][INFO] - Training Epoch: 1/2, step 6235/107898 completed (loss: 1.1748700141906738, acc: 0.800000011920929)
[2025-01-30 02:26:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6237/107898 [33:51<9:09:19,  3.08it/s][2025-01-30 02:26:01][root][INFO] - Training Epoch: 1/2, step 6236/107898 completed (loss: 0.07405539602041245, acc: 1.0)
[2025-01-30 02:26:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6238/107898 [33:52<9:19:52,  3.03it/s][2025-01-30 02:26:01][root][INFO] - Training Epoch: 1/2, step 6237/107898 completed (loss: 1.5548986196517944, acc: 0.7857142686843872)
[2025-01-30 02:26:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6239/107898 [33:52<8:59:13,  3.14it/s][2025-01-30 02:26:02][root][INFO] - Training Epoch: 1/2, step 6238/107898 completed (loss: 1.3099501132965088, acc: 0.7142857313156128)
[2025-01-30 02:26:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6240/107898 [33:52<9:23:50,  3.00it/s][2025-01-30 02:26:02][root][INFO] - Training Epoch: 1/2, step 6239/107898 completed (loss: 1.6553714275360107, acc: 0.5)
[2025-01-30 02:26:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6241/107898 [33:53<9:28:38,  2.98it/s][2025-01-30 02:26:02][root][INFO] - Training Epoch: 1/2, step 6240/107898 completed (loss: 0.027849581092596054, acc: 1.0)
[2025-01-30 02:26:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6242/107898 [33:53<9:45:10,  2.90it/s][2025-01-30 02:26:03][root][INFO] - Training Epoch: 1/2, step 6241/107898 completed (loss: 0.608004629611969, acc: 0.8888888955116272)
[2025-01-30 02:26:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6243/107898 [33:53<9:52:27,  2.86it/s][2025-01-30 02:26:03][root][INFO] - Training Epoch: 1/2, step 6242/107898 completed (loss: 1.42037034034729, acc: 0.699999988079071)
[2025-01-30 02:26:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6244/107898 [33:54<9:49:42,  2.87it/s][2025-01-30 02:26:04][root][INFO] - Training Epoch: 1/2, step 6243/107898 completed (loss: 2.3792436122894287, acc: 0.5)
[2025-01-30 02:26:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6245/107898 [33:54<9:31:36,  2.96it/s][2025-01-30 02:26:04][root][INFO] - Training Epoch: 1/2, step 6244/107898 completed (loss: 1.0182218551635742, acc: 0.5)
[2025-01-30 02:26:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6246/107898 [33:54<9:16:30,  3.04it/s][2025-01-30 02:26:04][root][INFO] - Training Epoch: 1/2, step 6245/107898 completed (loss: 2.7701268196105957, acc: 0.625)
[2025-01-30 02:26:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6247/107898 [33:55<9:12:59,  3.06it/s][2025-01-30 02:26:04][root][INFO] - Training Epoch: 1/2, step 6246/107898 completed (loss: 2.1677634716033936, acc: 0.6666666865348816)
[2025-01-30 02:26:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6248/107898 [33:55<9:18:50,  3.03it/s][2025-01-30 02:26:05][root][INFO] - Training Epoch: 1/2, step 6247/107898 completed (loss: 2.1104347705841064, acc: 0.800000011920929)
[2025-01-30 02:26:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6249/107898 [33:55<9:08:40,  3.09it/s][2025-01-30 02:26:05][root][INFO] - Training Epoch: 1/2, step 6248/107898 completed (loss: 0.9452441930770874, acc: 0.75)
[2025-01-30 02:26:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6250/107898 [33:56<9:00:16,  3.14it/s][2025-01-30 02:26:05][root][INFO] - Training Epoch: 1/2, step 6249/107898 completed (loss: 4.080567836761475, acc: 0.0)
[2025-01-30 02:26:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6251/107898 [33:56<8:46:05,  3.22it/s][2025-01-30 02:26:06][root][INFO] - Training Epoch: 1/2, step 6250/107898 completed (loss: 0.17239870131015778, acc: 1.0)
[2025-01-30 02:26:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6252/107898 [33:56<8:38:01,  3.27it/s][2025-01-30 02:26:06][root][INFO] - Training Epoch: 1/2, step 6251/107898 completed (loss: 4.993982315063477, acc: 0.4000000059604645)
[2025-01-30 02:26:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6253/107898 [33:57<9:10:21,  3.08it/s][2025-01-30 02:26:06][root][INFO] - Training Epoch: 1/2, step 6252/107898 completed (loss: 0.5918547511100769, acc: 0.9166666865348816)
[2025-01-30 02:26:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6254/107898 [33:57<9:37:02,  2.94it/s][2025-01-30 02:26:07][root][INFO] - Training Epoch: 1/2, step 6253/107898 completed (loss: 0.7338943481445312, acc: 1.0)
[2025-01-30 02:26:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6255/107898 [33:57<9:51:13,  2.87it/s][2025-01-30 02:26:07][root][INFO] - Training Epoch: 1/2, step 6254/107898 completed (loss: 0.2559860944747925, acc: 0.6666666865348816)
[2025-01-30 02:26:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6256/107898 [33:58<10:02:29,  2.81it/s][2025-01-30 02:26:08][root][INFO] - Training Epoch: 1/2, step 6255/107898 completed (loss: 1.1482789516448975, acc: 0.800000011920929)
[2025-01-30 02:26:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6257/107898 [33:58<10:05:20,  2.80it/s][2025-01-30 02:26:08][root][INFO] - Training Epoch: 1/2, step 6256/107898 completed (loss: 2.0727739334106445, acc: 0.7222222089767456)
[2025-01-30 02:26:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6258/107898 [33:58<9:42:32,  2.91it/s] [2025-01-30 02:26:08][root][INFO] - Training Epoch: 1/2, step 6257/107898 completed (loss: 0.016995850950479507, acc: 1.0)
[2025-01-30 02:26:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6259/107898 [33:59<9:25:25,  3.00it/s][2025-01-30 02:26:08][root][INFO] - Training Epoch: 1/2, step 6258/107898 completed (loss: 0.11479105055332184, acc: 1.0)
[2025-01-30 02:26:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6260/107898 [33:59<9:04:34,  3.11it/s][2025-01-30 02:26:09][root][INFO] - Training Epoch: 1/2, step 6259/107898 completed (loss: 5.823548793792725, acc: 0.3333333432674408)
[2025-01-30 02:26:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6261/107898 [33:59<8:54:05,  3.17it/s][2025-01-30 02:26:09][root][INFO] - Training Epoch: 1/2, step 6260/107898 completed (loss: 2.4811785221099854, acc: 0.75)
[2025-01-30 02:26:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6262/107898 [34:00<8:44:40,  3.23it/s][2025-01-30 02:26:09][root][INFO] - Training Epoch: 1/2, step 6261/107898 completed (loss: 0.1581355333328247, acc: 1.0)
[2025-01-30 02:26:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6263/107898 [34:00<9:03:22,  3.12it/s][2025-01-30 02:26:10][root][INFO] - Training Epoch: 1/2, step 6262/107898 completed (loss: 1.7769874334335327, acc: 0.5)
[2025-01-30 02:26:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6264/107898 [34:00<9:14:18,  3.06it/s][2025-01-30 02:26:10][root][INFO] - Training Epoch: 1/2, step 6263/107898 completed (loss: 0.5498260855674744, acc: 0.8571428656578064)
[2025-01-30 02:26:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6265/107898 [34:01<9:31:28,  2.96it/s][2025-01-30 02:26:10][root][INFO] - Training Epoch: 1/2, step 6264/107898 completed (loss: 1.4448230266571045, acc: 0.25)
[2025-01-30 02:26:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6266/107898 [34:01<9:28:36,  2.98it/s][2025-01-30 02:26:11][root][INFO] - Training Epoch: 1/2, step 6265/107898 completed (loss: 0.002704774960875511, acc: 1.0)
[2025-01-30 02:26:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6267/107898 [34:01<9:43:39,  2.90it/s][2025-01-30 02:26:11][root][INFO] - Training Epoch: 1/2, step 6266/107898 completed (loss: 0.06636860966682434, acc: 1.0)
[2025-01-30 02:26:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6268/107898 [34:02<9:39:25,  2.92it/s][2025-01-30 02:26:11][root][INFO] - Training Epoch: 1/2, step 6267/107898 completed (loss: 3.338571786880493, acc: 0.27272728085517883)
[2025-01-30 02:26:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6269/107898 [34:02<9:59:36,  2.82it/s][2025-01-30 02:26:12][root][INFO] - Training Epoch: 1/2, step 6268/107898 completed (loss: 0.3033239245414734, acc: 0.8999999761581421)
[2025-01-30 02:26:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6270/107898 [34:02<10:06:51,  2.79it/s][2025-01-30 02:26:12][root][INFO] - Training Epoch: 1/2, step 6269/107898 completed (loss: 0.4698079526424408, acc: 0.8571428656578064)
[2025-01-30 02:26:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6271/107898 [34:03<9:49:01,  2.88it/s] [2025-01-30 02:26:13][root][INFO] - Training Epoch: 1/2, step 6270/107898 completed (loss: 0.35405850410461426, acc: 0.6666666865348816)
[2025-01-30 02:26:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6272/107898 [34:03<9:46:18,  2.89it/s][2025-01-30 02:26:13][root][INFO] - Training Epoch: 1/2, step 6271/107898 completed (loss: 2.5360894203186035, acc: 0.5555555820465088)
[2025-01-30 02:26:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6273/107898 [34:03<9:38:14,  2.93it/s][2025-01-30 02:26:13][root][INFO] - Training Epoch: 1/2, step 6272/107898 completed (loss: 0.38950586318969727, acc: 1.0)
[2025-01-30 02:26:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6274/107898 [34:04<9:26:26,  2.99it/s][2025-01-30 02:26:14][root][INFO] - Training Epoch: 1/2, step 6273/107898 completed (loss: 0.01716018281877041, acc: 1.0)
[2025-01-30 02:26:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6275/107898 [34:04<9:06:23,  3.10it/s][2025-01-30 02:26:14][root][INFO] - Training Epoch: 1/2, step 6274/107898 completed (loss: 0.21972079575061798, acc: 1.0)
[2025-01-30 02:26:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6276/107898 [34:04<9:25:05,  3.00it/s][2025-01-30 02:26:14][root][INFO] - Training Epoch: 1/2, step 6275/107898 completed (loss: 0.044991157948970795, acc: 1.0)
[2025-01-30 02:26:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6277/107898 [34:05<9:28:37,  2.98it/s][2025-01-30 02:26:15][root][INFO] - Training Epoch: 1/2, step 6276/107898 completed (loss: 0.015614486299455166, acc: 1.0)
[2025-01-30 02:26:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6278/107898 [34:05<9:17:00,  3.04it/s][2025-01-30 02:26:15][root][INFO] - Training Epoch: 1/2, step 6277/107898 completed (loss: 0.3866030275821686, acc: 0.9375)
[2025-01-30 02:26:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6279/107898 [34:05<9:00:10,  3.14it/s][2025-01-30 02:26:15][root][INFO] - Training Epoch: 1/2, step 6278/107898 completed (loss: 2.8510208129882812, acc: 0.3333333432674408)
[2025-01-30 02:26:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6280/107898 [34:06<8:52:31,  3.18it/s][2025-01-30 02:26:15][root][INFO] - Training Epoch: 1/2, step 6279/107898 completed (loss: 0.005794157274067402, acc: 1.0)
[2025-01-30 02:26:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6281/107898 [34:06<8:44:03,  3.23it/s][2025-01-30 02:26:16][root][INFO] - Training Epoch: 1/2, step 6280/107898 completed (loss: 1.2360994815826416, acc: 0.75)
[2025-01-30 02:26:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6282/107898 [34:06<8:35:11,  3.29it/s][2025-01-30 02:26:16][root][INFO] - Training Epoch: 1/2, step 6281/107898 completed (loss: 2.283395528793335, acc: 0.529411792755127)
[2025-01-30 02:26:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6283/107898 [34:07<8:42:28,  3.24it/s][2025-01-30 02:26:16][root][INFO] - Training Epoch: 1/2, step 6282/107898 completed (loss: 0.7555821537971497, acc: 0.807692289352417)
[2025-01-30 02:26:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6284/107898 [34:07<8:55:46,  3.16it/s][2025-01-30 02:26:17][root][INFO] - Training Epoch: 1/2, step 6283/107898 completed (loss: 0.14458774030208588, acc: 1.0)
[2025-01-30 02:26:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6285/107898 [34:07<9:01:50,  3.13it/s][2025-01-30 02:26:17][root][INFO] - Training Epoch: 1/2, step 6284/107898 completed (loss: 0.21603617072105408, acc: 1.0)
[2025-01-30 02:26:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6286/107898 [34:08<8:56:00,  3.16it/s][2025-01-30 02:26:17][root][INFO] - Training Epoch: 1/2, step 6285/107898 completed (loss: 0.06544578075408936, acc: 1.0)
[2025-01-30 02:26:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6287/107898 [34:08<9:05:05,  3.11it/s][2025-01-30 02:26:18][root][INFO] - Training Epoch: 1/2, step 6286/107898 completed (loss: 0.42897024750709534, acc: 0.800000011920929)
[2025-01-30 02:26:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6288/107898 [34:08<9:04:33,  3.11it/s][2025-01-30 02:26:18][root][INFO] - Training Epoch: 1/2, step 6287/107898 completed (loss: 1.6605654954910278, acc: 0.75)
[2025-01-30 02:26:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6289/107898 [34:08<8:57:15,  3.15it/s][2025-01-30 02:26:18][root][INFO] - Training Epoch: 1/2, step 6288/107898 completed (loss: 2.4409830570220947, acc: 0.5714285969734192)
[2025-01-30 02:26:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6290/107898 [34:09<9:15:03,  3.05it/s][2025-01-30 02:26:19][root][INFO] - Training Epoch: 1/2, step 6289/107898 completed (loss: 2.0545265674591064, acc: 0.3333333432674408)
[2025-01-30 02:26:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6291/107898 [34:09<9:31:00,  2.97it/s][2025-01-30 02:26:19][root][INFO] - Training Epoch: 1/2, step 6290/107898 completed (loss: 1.9633702039718628, acc: 0.5)
[2025-01-30 02:26:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6292/107898 [34:10<9:15:24,  3.05it/s][2025-01-30 02:26:19][root][INFO] - Training Epoch: 1/2, step 6291/107898 completed (loss: 3.0175747871398926, acc: 0.125)
[2025-01-30 02:26:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6293/107898 [34:10<9:21:39,  3.02it/s][2025-01-30 02:26:20][root][INFO] - Training Epoch: 1/2, step 6292/107898 completed (loss: 0.5743838548660278, acc: 0.9523809552192688)
[2025-01-30 02:26:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6294/107898 [34:10<9:19:42,  3.03it/s][2025-01-30 02:26:20][root][INFO] - Training Epoch: 1/2, step 6293/107898 completed (loss: 1.1252713203430176, acc: 0.7333333492279053)
[2025-01-30 02:26:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6295/107898 [34:10<9:10:18,  3.08it/s][2025-01-30 02:26:20][root][INFO] - Training Epoch: 1/2, step 6294/107898 completed (loss: 0.22956931591033936, acc: 1.0)
[2025-01-30 02:26:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6296/107898 [34:11<8:55:47,  3.16it/s][2025-01-30 02:26:21][root][INFO] - Training Epoch: 1/2, step 6295/107898 completed (loss: 0.03260334953665733, acc: 1.0)
[2025-01-30 02:26:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6297/107898 [34:11<9:03:09,  3.12it/s][2025-01-30 02:26:21][root][INFO] - Training Epoch: 1/2, step 6296/107898 completed (loss: 0.36956143379211426, acc: 1.0)
[2025-01-30 02:26:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6298/107898 [34:11<8:58:41,  3.14it/s][2025-01-30 02:26:21][root][INFO] - Training Epoch: 1/2, step 6297/107898 completed (loss: 0.9918990731239319, acc: 0.6666666865348816)
[2025-01-30 02:26:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6299/107898 [34:12<8:48:14,  3.21it/s][2025-01-30 02:26:22][root][INFO] - Training Epoch: 1/2, step 6298/107898 completed (loss: 2.1699044704437256, acc: 0.5)
[2025-01-30 02:26:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6300/107898 [34:12<9:02:03,  3.12it/s][2025-01-30 02:26:22][root][INFO] - Training Epoch: 1/2, step 6299/107898 completed (loss: 0.12015348672866821, acc: 1.0)
[2025-01-30 02:26:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6301/107898 [34:12<8:59:29,  3.14it/s][2025-01-30 02:26:22][root][INFO] - Training Epoch: 1/2, step 6300/107898 completed (loss: 0.4271255135536194, acc: 0.8500000238418579)
[2025-01-30 02:26:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6302/107898 [34:13<9:42:58,  2.90it/s][2025-01-30 02:26:23][root][INFO] - Training Epoch: 1/2, step 6301/107898 completed (loss: 4.245060920715332, acc: 0.1785714328289032)
[2025-01-30 02:26:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6303/107898 [34:13<10:00:55,  2.82it/s][2025-01-30 02:26:23][root][INFO] - Training Epoch: 1/2, step 6302/107898 completed (loss: 0.44017261266708374, acc: 0.9230769276618958)
[2025-01-30 02:26:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6304/107898 [34:14<9:58:43,  2.83it/s] [2025-01-30 02:26:23][root][INFO] - Training Epoch: 1/2, step 6303/107898 completed (loss: 0.8737630844116211, acc: 0.5)
[2025-01-30 02:26:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6305/107898 [34:14<9:59:38,  2.82it/s][2025-01-30 02:26:24][root][INFO] - Training Epoch: 1/2, step 6304/107898 completed (loss: 0.2668624222278595, acc: 0.9166666865348816)
[2025-01-30 02:26:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6306/107898 [34:14<10:13:12,  2.76it/s][2025-01-30 02:26:24][root][INFO] - Training Epoch: 1/2, step 6305/107898 completed (loss: 1.3532044887542725, acc: 0.6190476417541504)
[2025-01-30 02:26:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6307/107898 [34:15<10:00:24,  2.82it/s][2025-01-30 02:26:24][root][INFO] - Training Epoch: 1/2, step 6306/107898 completed (loss: 4.046138763427734, acc: 0.4545454680919647)
[2025-01-30 02:26:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6308/107898 [34:15<9:36:59,  2.93it/s] [2025-01-30 02:26:25][root][INFO] - Training Epoch: 1/2, step 6307/107898 completed (loss: 0.5173677802085876, acc: 0.9090909361839294)
[2025-01-30 02:26:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6309/107898 [34:15<9:12:46,  3.06it/s][2025-01-30 02:26:25][root][INFO] - Training Epoch: 1/2, step 6308/107898 completed (loss: 0.009600800462067127, acc: 1.0)
[2025-01-30 02:26:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6310/107898 [34:15<8:55:52,  3.16it/s][2025-01-30 02:26:25][root][INFO] - Training Epoch: 1/2, step 6309/107898 completed (loss: 0.019302476197481155, acc: 1.0)
[2025-01-30 02:26:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6311/107898 [34:16<9:17:45,  3.04it/s][2025-01-30 02:26:26][root][INFO] - Training Epoch: 1/2, step 6310/107898 completed (loss: 0.03308546170592308, acc: 1.0)
[2025-01-30 02:26:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6312/107898 [34:16<9:19:42,  3.03it/s][2025-01-30 02:26:26][root][INFO] - Training Epoch: 1/2, step 6311/107898 completed (loss: 1.434675931930542, acc: 0.699999988079071)
[2025-01-30 02:26:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6313/107898 [34:16<9:16:05,  3.04it/s][2025-01-30 02:26:26][root][INFO] - Training Epoch: 1/2, step 6312/107898 completed (loss: 4.931507110595703, acc: 0.1428571492433548)
[2025-01-30 02:26:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6314/107898 [34:17<9:06:44,  3.10it/s][2025-01-30 02:26:27][root][INFO] - Training Epoch: 1/2, step 6313/107898 completed (loss: 0.009364226832985878, acc: 1.0)
[2025-01-30 02:26:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6315/107898 [34:17<9:37:17,  2.93it/s][2025-01-30 02:26:27][root][INFO] - Training Epoch: 1/2, step 6314/107898 completed (loss: 1.6857250928878784, acc: 0.692307710647583)
[2025-01-30 02:26:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6316/107898 [34:18<9:25:16,  3.00it/s][2025-01-30 02:26:27][root][INFO] - Training Epoch: 1/2, step 6315/107898 completed (loss: 0.07511366903781891, acc: 1.0)
[2025-01-30 02:26:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6317/107898 [34:18<9:32:05,  2.96it/s][2025-01-30 02:26:28][root][INFO] - Training Epoch: 1/2, step 6316/107898 completed (loss: 3.3880083560943604, acc: 0.5)
[2025-01-30 02:26:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6318/107898 [34:18<9:29:38,  2.97it/s][2025-01-30 02:26:28][root][INFO] - Training Epoch: 1/2, step 6317/107898 completed (loss: 0.991086483001709, acc: 0.6666666865348816)
[2025-01-30 02:26:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6319/107898 [34:19<9:22:34,  3.01it/s][2025-01-30 02:26:28][root][INFO] - Training Epoch: 1/2, step 6318/107898 completed (loss: 0.22384138405323029, acc: 1.0)
[2025-01-30 02:26:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6320/107898 [34:19<9:13:14,  3.06it/s][2025-01-30 02:26:29][root][INFO] - Training Epoch: 1/2, step 6319/107898 completed (loss: 0.9904602766036987, acc: 0.7307692170143127)
[2025-01-30 02:26:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6321/107898 [34:19<8:55:29,  3.16it/s][2025-01-30 02:26:29][root][INFO] - Training Epoch: 1/2, step 6320/107898 completed (loss: 2.512174606323242, acc: 0.4000000059604645)
[2025-01-30 02:26:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6322/107898 [34:19<8:59:48,  3.14it/s][2025-01-30 02:26:29][root][INFO] - Training Epoch: 1/2, step 6321/107898 completed (loss: 3.0823140144348145, acc: 0.5)
[2025-01-30 02:26:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6323/107898 [34:20<8:58:33,  3.14it/s][2025-01-30 02:26:30][root][INFO] - Training Epoch: 1/2, step 6322/107898 completed (loss: 0.005473270546644926, acc: 1.0)
[2025-01-30 02:26:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6324/107898 [34:20<8:59:09,  3.14it/s][2025-01-30 02:26:30][root][INFO] - Training Epoch: 1/2, step 6323/107898 completed (loss: 0.2968069911003113, acc: 0.949999988079071)
[2025-01-30 02:26:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6325/107898 [34:20<9:01:59,  3.12it/s][2025-01-30 02:26:30][root][INFO] - Training Epoch: 1/2, step 6324/107898 completed (loss: 3.6837618350982666, acc: 0.3333333432674408)
[2025-01-30 02:26:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6326/107898 [34:21<8:58:02,  3.15it/s][2025-01-30 02:26:30][root][INFO] - Training Epoch: 1/2, step 6325/107898 completed (loss: 0.3619592487812042, acc: 1.0)
[2025-01-30 02:26:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6327/107898 [34:21<8:50:09,  3.19it/s][2025-01-30 02:26:31][root][INFO] - Training Epoch: 1/2, step 6326/107898 completed (loss: 0.07820798456668854, acc: 1.0)
[2025-01-30 02:26:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6328/107898 [34:21<8:44:47,  3.23it/s][2025-01-30 02:26:31][root][INFO] - Training Epoch: 1/2, step 6327/107898 completed (loss: 0.008975144475698471, acc: 1.0)
[2025-01-30 02:26:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6329/107898 [34:22<8:41:55,  3.24it/s][2025-01-30 02:26:31][root][INFO] - Training Epoch: 1/2, step 6328/107898 completed (loss: 1.6180286407470703, acc: 0.800000011920929)
[2025-01-30 02:26:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6330/107898 [34:22<8:42:32,  3.24it/s][2025-01-30 02:26:32][root][INFO] - Training Epoch: 1/2, step 6329/107898 completed (loss: 0.47823143005371094, acc: 1.0)
[2025-01-30 02:26:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6331/107898 [34:22<8:52:14,  3.18it/s][2025-01-30 02:26:32][root][INFO] - Training Epoch: 1/2, step 6330/107898 completed (loss: 0.01661130040884018, acc: 1.0)
[2025-01-30 02:26:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6332/107898 [34:23<8:51:41,  3.18it/s][2025-01-30 02:26:32][root][INFO] - Training Epoch: 1/2, step 6331/107898 completed (loss: 1.34233820438385, acc: 0.0)
[2025-01-30 02:26:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6333/107898 [34:23<9:18:01,  3.03it/s][2025-01-30 02:26:33][root][INFO] - Training Epoch: 1/2, step 6332/107898 completed (loss: 0.00730029447004199, acc: 1.0)
[2025-01-30 02:26:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6334/107898 [34:23<9:25:33,  2.99it/s][2025-01-30 02:26:33][root][INFO] - Training Epoch: 1/2, step 6333/107898 completed (loss: 0.7109054327011108, acc: 0.8500000238418579)
[2025-01-30 02:26:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6335/107898 [34:24<9:14:38,  3.05it/s][2025-01-30 02:26:33][root][INFO] - Training Epoch: 1/2, step 6334/107898 completed (loss: 1.8134602308273315, acc: 0.75)
[2025-01-30 02:26:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6336/107898 [34:24<8:57:26,  3.15it/s][2025-01-30 02:26:34][root][INFO] - Training Epoch: 1/2, step 6335/107898 completed (loss: 2.787968635559082, acc: 0.5)
[2025-01-30 02:26:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6337/107898 [34:24<8:44:54,  3.22it/s][2025-01-30 02:26:34][root][INFO] - Training Epoch: 1/2, step 6336/107898 completed (loss: 1.047010898590088, acc: 0.7272727489471436)
[2025-01-30 02:26:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6338/107898 [34:24<8:34:21,  3.29it/s][2025-01-30 02:26:34][root][INFO] - Training Epoch: 1/2, step 6337/107898 completed (loss: 0.8849321603775024, acc: 0.7857142686843872)
[2025-01-30 02:26:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6339/107898 [34:25<8:25:06,  3.35it/s][2025-01-30 02:26:35][root][INFO] - Training Epoch: 1/2, step 6338/107898 completed (loss: 0.22458486258983612, acc: 1.0)
[2025-01-30 02:26:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6340/107898 [34:25<8:31:45,  3.31it/s][2025-01-30 02:26:35][root][INFO] - Training Epoch: 1/2, step 6339/107898 completed (loss: 0.8052818179130554, acc: 0.8181818127632141)
[2025-01-30 02:26:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6341/107898 [34:25<8:26:56,  3.34it/s][2025-01-30 02:26:35][root][INFO] - Training Epoch: 1/2, step 6340/107898 completed (loss: 0.24607142806053162, acc: 0.8571428656578064)
[2025-01-30 02:26:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6342/107898 [34:26<8:18:28,  3.40it/s][2025-01-30 02:26:35][root][INFO] - Training Epoch: 1/2, step 6341/107898 completed (loss: 0.18715190887451172, acc: 1.0)
[2025-01-30 02:26:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6343/107898 [34:26<8:23:25,  3.36it/s][2025-01-30 02:26:36][root][INFO] - Training Epoch: 1/2, step 6342/107898 completed (loss: 0.027953218668699265, acc: 1.0)
[2025-01-30 02:26:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6344/107898 [34:26<8:33:21,  3.30it/s][2025-01-30 02:26:36][root][INFO] - Training Epoch: 1/2, step 6343/107898 completed (loss: 0.011788466945290565, acc: 1.0)
[2025-01-30 02:26:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6345/107898 [34:27<8:41:44,  3.24it/s][2025-01-30 02:26:36][root][INFO] - Training Epoch: 1/2, step 6344/107898 completed (loss: 0.9475648403167725, acc: 0.6666666865348816)
[2025-01-30 02:26:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6346/107898 [34:27<9:09:40,  3.08it/s][2025-01-30 02:26:37][root][INFO] - Training Epoch: 1/2, step 6345/107898 completed (loss: 1.1649523973464966, acc: 0.7222222089767456)
[2025-01-30 02:26:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6347/107898 [34:27<9:20:26,  3.02it/s][2025-01-30 02:26:37][root][INFO] - Training Epoch: 1/2, step 6346/107898 completed (loss: 1.6474480628967285, acc: 0.5)
[2025-01-30 02:26:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6348/107898 [34:28<9:40:31,  2.92it/s][2025-01-30 02:26:37][root][INFO] - Training Epoch: 1/2, step 6347/107898 completed (loss: 1.2960606813430786, acc: 0.774193525314331)
[2025-01-30 02:26:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6349/107898 [34:28<9:24:33,  3.00it/s][2025-01-30 02:26:38][root][INFO] - Training Epoch: 1/2, step 6348/107898 completed (loss: 2.8570306301116943, acc: 0.25)
[2025-01-30 02:26:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6350/107898 [34:28<9:13:59,  3.06it/s][2025-01-30 02:26:38][root][INFO] - Training Epoch: 1/2, step 6349/107898 completed (loss: 0.37358322739601135, acc: 0.8333333134651184)
[2025-01-30 02:26:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6351/107898 [34:29<9:17:50,  3.03it/s][2025-01-30 02:26:38][root][INFO] - Training Epoch: 1/2, step 6350/107898 completed (loss: 0.7874499559402466, acc: 1.0)
[2025-01-30 02:26:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6352/107898 [34:29<9:24:10,  3.00it/s][2025-01-30 02:26:39][root][INFO] - Training Epoch: 1/2, step 6351/107898 completed (loss: 0.7775669097900391, acc: 0.75)
[2025-01-30 02:26:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6353/107898 [34:29<9:30:11,  2.97it/s][2025-01-30 02:26:39][root][INFO] - Training Epoch: 1/2, step 6352/107898 completed (loss: 0.7369712591171265, acc: 0.6666666865348816)
[2025-01-30 02:26:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6354/107898 [34:30<9:14:10,  3.05it/s][2025-01-30 02:26:39][root][INFO] - Training Epoch: 1/2, step 6353/107898 completed (loss: 0.7087411284446716, acc: 0.875)
[2025-01-30 02:26:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6355/107898 [34:30<8:57:34,  3.15it/s][2025-01-30 02:26:40][root][INFO] - Training Epoch: 1/2, step 6354/107898 completed (loss: 0.29927748441696167, acc: 0.800000011920929)
[2025-01-30 02:26:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6356/107898 [34:30<8:46:46,  3.21it/s][2025-01-30 02:26:40][root][INFO] - Training Epoch: 1/2, step 6355/107898 completed (loss: 0.2399909496307373, acc: 1.0)
[2025-01-30 02:26:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6357/107898 [34:31<8:48:05,  3.20it/s][2025-01-30 02:26:40][root][INFO] - Training Epoch: 1/2, step 6356/107898 completed (loss: 0.9013043642044067, acc: 0.7586206793785095)
[2025-01-30 02:26:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6358/107898 [34:31<8:41:50,  3.24it/s][2025-01-30 02:26:41][root][INFO] - Training Epoch: 1/2, step 6357/107898 completed (loss: 0.3287929594516754, acc: 1.0)
[2025-01-30 02:26:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6359/107898 [34:31<8:35:57,  3.28it/s][2025-01-30 02:26:41][root][INFO] - Training Epoch: 1/2, step 6358/107898 completed (loss: 5.284523010253906, acc: 0.0)
[2025-01-30 02:26:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6360/107898 [34:31<8:34:42,  3.29it/s][2025-01-30 02:26:41][root][INFO] - Training Epoch: 1/2, step 6359/107898 completed (loss: 1.394834041595459, acc: 0.5)
[2025-01-30 02:26:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6361/107898 [34:32<8:32:38,  3.30it/s][2025-01-30 02:26:42][root][INFO] - Training Epoch: 1/2, step 6360/107898 completed (loss: 0.14409546554088593, acc: 1.0)
[2025-01-30 02:26:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6362/107898 [34:32<8:30:55,  3.31it/s][2025-01-30 02:26:42][root][INFO] - Training Epoch: 1/2, step 6361/107898 completed (loss: 1.0404765605926514, acc: 0.782608687877655)
[2025-01-30 02:26:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6363/107898 [34:32<8:30:34,  3.31it/s][2025-01-30 02:26:42][root][INFO] - Training Epoch: 1/2, step 6362/107898 completed (loss: 1.0230555534362793, acc: 0.5)
[2025-01-30 02:26:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6364/107898 [34:33<8:43:21,  3.23it/s][2025-01-30 02:26:42][root][INFO] - Training Epoch: 1/2, step 6363/107898 completed (loss: 2.188016653060913, acc: 0.5)
[2025-01-30 02:26:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6365/107898 [34:33<9:13:33,  3.06it/s][2025-01-30 02:26:43][root][INFO] - Training Epoch: 1/2, step 6364/107898 completed (loss: 0.7126837372779846, acc: 0.8571428656578064)
[2025-01-30 02:26:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6366/107898 [34:33<9:03:51,  3.11it/s][2025-01-30 02:26:43][root][INFO] - Training Epoch: 1/2, step 6365/107898 completed (loss: 0.04302969574928284, acc: 1.0)
[2025-01-30 02:26:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6367/107898 [34:34<9:17:13,  3.04it/s][2025-01-30 02:26:43][root][INFO] - Training Epoch: 1/2, step 6366/107898 completed (loss: 2.782613754272461, acc: 0.3333333432674408)
[2025-01-30 02:26:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6368/107898 [34:34<9:15:07,  3.05it/s][2025-01-30 02:26:44][root][INFO] - Training Epoch: 1/2, step 6367/107898 completed (loss: 0.3376905024051666, acc: 0.8999999761581421)
[2025-01-30 02:26:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6369/107898 [34:34<9:04:32,  3.11it/s][2025-01-30 02:26:44][root][INFO] - Training Epoch: 1/2, step 6368/107898 completed (loss: 5.360117435455322, acc: 0.1428571492433548)
[2025-01-30 02:26:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6370/107898 [34:35<8:48:57,  3.20it/s][2025-01-30 02:26:44][root][INFO] - Training Epoch: 1/2, step 6369/107898 completed (loss: 0.009248783811926842, acc: 1.0)
[2025-01-30 02:26:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6371/107898 [34:35<8:44:45,  3.22it/s][2025-01-30 02:26:45][root][INFO] - Training Epoch: 1/2, step 6370/107898 completed (loss: 0.1557655781507492, acc: 1.0)
[2025-01-30 02:26:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6372/107898 [34:35<9:08:11,  3.09it/s][2025-01-30 02:26:45][root][INFO] - Training Epoch: 1/2, step 6371/107898 completed (loss: 0.013688403181731701, acc: 1.0)
[2025-01-30 02:26:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6373/107898 [34:36<9:28:23,  2.98it/s][2025-01-30 02:26:45][root][INFO] - Training Epoch: 1/2, step 6372/107898 completed (loss: 3.0930638313293457, acc: 0.25)
[2025-01-30 02:26:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6374/107898 [34:36<9:31:53,  2.96it/s][2025-01-30 02:26:46][root][INFO] - Training Epoch: 1/2, step 6373/107898 completed (loss: 0.031702667474746704, acc: 1.0)
[2025-01-30 02:26:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6375/107898 [34:36<9:21:29,  3.01it/s][2025-01-30 02:26:46][root][INFO] - Training Epoch: 1/2, step 6374/107898 completed (loss: 0.007661076262593269, acc: 1.0)
[2025-01-30 02:26:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6376/107898 [34:37<9:32:31,  2.96it/s][2025-01-30 02:26:46][root][INFO] - Training Epoch: 1/2, step 6375/107898 completed (loss: 0.05253292992711067, acc: 1.0)
[2025-01-30 02:26:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6377/107898 [34:37<9:56:51,  2.83it/s][2025-01-30 02:26:47][root][INFO] - Training Epoch: 1/2, step 6376/107898 completed (loss: 0.3103253245353699, acc: 0.8999999761581421)
[2025-01-30 02:26:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6378/107898 [34:37<9:45:17,  2.89it/s][2025-01-30 02:26:47][root][INFO] - Training Epoch: 1/2, step 6377/107898 completed (loss: 0.6266368627548218, acc: 0.8333333134651184)
[2025-01-30 02:26:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6379/107898 [34:38<9:45:59,  2.89it/s][2025-01-30 02:26:47][root][INFO] - Training Epoch: 1/2, step 6378/107898 completed (loss: 4.355413913726807, acc: 0.5)
[2025-01-30 02:26:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6380/107898 [34:38<9:37:03,  2.93it/s][2025-01-30 02:26:48][root][INFO] - Training Epoch: 1/2, step 6379/107898 completed (loss: 0.19145271182060242, acc: 1.0)
[2025-01-30 02:26:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6381/107898 [34:38<9:14:57,  3.05it/s][2025-01-30 02:26:48][root][INFO] - Training Epoch: 1/2, step 6380/107898 completed (loss: 0.050099439918994904, acc: 1.0)
[2025-01-30 02:26:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6382/107898 [34:39<9:06:47,  3.09it/s][2025-01-30 02:26:48][root][INFO] - Training Epoch: 1/2, step 6381/107898 completed (loss: 1.1818807125091553, acc: 0.5)
[2025-01-30 02:26:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6383/107898 [34:39<8:52:41,  3.18it/s][2025-01-30 02:26:49][root][INFO] - Training Epoch: 1/2, step 6382/107898 completed (loss: 1.114933967590332, acc: 0.5)
[2025-01-30 02:26:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6384/107898 [34:39<8:51:31,  3.18it/s][2025-01-30 02:26:49][root][INFO] - Training Epoch: 1/2, step 6383/107898 completed (loss: 5.73707389831543, acc: 0.5)
[2025-01-30 02:26:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6385/107898 [34:40<9:04:00,  3.11it/s][2025-01-30 02:26:49][root][INFO] - Training Epoch: 1/2, step 6384/107898 completed (loss: 0.9477782249450684, acc: 0.7894737124443054)
[2025-01-30 02:26:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6386/107898 [34:40<9:08:48,  3.08it/s][2025-01-30 02:26:50][root][INFO] - Training Epoch: 1/2, step 6385/107898 completed (loss: 2.728991985321045, acc: 0.5)
[2025-01-30 02:26:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6387/107898 [34:40<8:41:36,  3.24it/s][2025-01-30 02:26:50][root][INFO] - Training Epoch: 1/2, step 6386/107898 completed (loss: 1.8752909898757935, acc: 0.3333333432674408)
[2025-01-30 02:26:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6388/107898 [34:40<8:38:40,  3.26it/s][2025-01-30 02:26:50][root][INFO] - Training Epoch: 1/2, step 6387/107898 completed (loss: 2.1646552085876465, acc: 0.5)
[2025-01-30 02:26:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6389/107898 [34:41<9:09:38,  3.08it/s][2025-01-30 02:26:51][root][INFO] - Training Epoch: 1/2, step 6388/107898 completed (loss: 1.0422120094299316, acc: 0.8181818127632141)
[2025-01-30 02:26:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6390/107898 [34:41<9:20:19,  3.02it/s][2025-01-30 02:26:51][root][INFO] - Training Epoch: 1/2, step 6389/107898 completed (loss: 1.178483247756958, acc: 0.800000011920929)
[2025-01-30 02:26:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6391/107898 [34:42<9:30:29,  2.97it/s][2025-01-30 02:26:51][root][INFO] - Training Epoch: 1/2, step 6390/107898 completed (loss: 0.028356468304991722, acc: 1.0)
[2025-01-30 02:26:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6392/107898 [34:42<9:29:45,  2.97it/s][2025-01-30 02:26:52][root][INFO] - Training Epoch: 1/2, step 6391/107898 completed (loss: 2.232404947280884, acc: 0.5)
[2025-01-30 02:26:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6393/107898 [34:42<9:21:53,  3.01it/s][2025-01-30 02:26:52][root][INFO] - Training Epoch: 1/2, step 6392/107898 completed (loss: 0.5885889530181885, acc: 1.0)
[2025-01-30 02:26:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6394/107898 [34:43<9:07:28,  3.09it/s][2025-01-30 02:26:52][root][INFO] - Training Epoch: 1/2, step 6393/107898 completed (loss: 0.43098539113998413, acc: 0.9285714030265808)
[2025-01-30 02:26:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6395/107898 [34:43<9:02:44,  3.12it/s][2025-01-30 02:26:53][root][INFO] - Training Epoch: 1/2, step 6394/107898 completed (loss: 0.186502143740654, acc: 1.0)
[2025-01-30 02:26:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6396/107898 [34:43<8:51:44,  3.18it/s][2025-01-30 02:26:53][root][INFO] - Training Epoch: 1/2, step 6395/107898 completed (loss: 0.052346277981996536, acc: 1.0)
[2025-01-30 02:26:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6397/107898 [34:43<8:42:22,  3.24it/s][2025-01-30 02:26:53][root][INFO] - Training Epoch: 1/2, step 6396/107898 completed (loss: 1.0553513765335083, acc: 0.8333333134651184)
[2025-01-30 02:26:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6398/107898 [34:44<8:37:20,  3.27it/s][2025-01-30 02:26:54][root][INFO] - Training Epoch: 1/2, step 6397/107898 completed (loss: 0.3900756537914276, acc: 0.6666666865348816)
[2025-01-30 02:26:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6399/107898 [34:44<9:05:18,  3.10it/s][2025-01-30 02:26:54][root][INFO] - Training Epoch: 1/2, step 6398/107898 completed (loss: 2.648324728012085, acc: 0.3333333432674408)
[2025-01-30 02:26:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6400/107898 [34:44<9:00:53,  3.13it/s][2025-01-30 02:26:54][root][INFO] - Training Epoch: 1/2, step 6399/107898 completed (loss: 0.39558887481689453, acc: 1.0)
[2025-01-30 02:26:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6401/107898 [34:45<8:48:30,  3.20it/s][2025-01-30 02:26:54][root][INFO] - Training Epoch: 1/2, step 6400/107898 completed (loss: 0.5432084202766418, acc: 1.0)
[2025-01-30 02:26:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6402/107898 [34:45<8:38:27,  3.26it/s][2025-01-30 02:26:55][root][INFO] - Training Epoch: 1/2, step 6401/107898 completed (loss: 0.4346712529659271, acc: 0.6666666865348816)
[2025-01-30 02:26:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6403/107898 [34:45<8:54:13,  3.17it/s][2025-01-30 02:26:55][root][INFO] - Training Epoch: 1/2, step 6402/107898 completed (loss: 1.1945266723632812, acc: 0.5)
[2025-01-30 02:26:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6404/107898 [34:46<9:01:46,  3.12it/s][2025-01-30 02:26:55][root][INFO] - Training Epoch: 1/2, step 6403/107898 completed (loss: 0.005270211957395077, acc: 1.0)
[2025-01-30 02:26:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6405/107898 [34:46<8:51:36,  3.18it/s][2025-01-30 02:26:56][root][INFO] - Training Epoch: 1/2, step 6404/107898 completed (loss: 4.462989807128906, acc: 0.4000000059604645)
[2025-01-30 02:26:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6406/107898 [34:46<8:50:51,  3.19it/s][2025-01-30 02:26:56][root][INFO] - Training Epoch: 1/2, step 6405/107898 completed (loss: 2.154953718185425, acc: 0.6666666865348816)
[2025-01-30 02:26:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6407/107898 [34:47<8:47:15,  3.21it/s][2025-01-30 02:26:56][root][INFO] - Training Epoch: 1/2, step 6406/107898 completed (loss: 3.5695717334747314, acc: 0.6666666865348816)
[2025-01-30 02:26:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6408/107898 [34:47<8:43:37,  3.23it/s][2025-01-30 02:26:57][root][INFO] - Training Epoch: 1/2, step 6407/107898 completed (loss: 0.2515032887458801, acc: 1.0)
[2025-01-30 02:26:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6409/107898 [34:47<8:35:54,  3.28it/s][2025-01-30 02:26:57][root][INFO] - Training Epoch: 1/2, step 6408/107898 completed (loss: 0.37787872552871704, acc: 1.0)
[2025-01-30 02:26:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6410/107898 [34:47<8:48:40,  3.20it/s][2025-01-30 02:26:57][root][INFO] - Training Epoch: 1/2, step 6409/107898 completed (loss: 4.6911492347717285, acc: 0.0833333358168602)
[2025-01-30 02:26:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6411/107898 [34:48<9:08:36,  3.08it/s][2025-01-30 02:26:58][root][INFO] - Training Epoch: 1/2, step 6410/107898 completed (loss: 0.005780601873993874, acc: 1.0)
[2025-01-30 02:26:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6412/107898 [34:48<9:10:31,  3.07it/s][2025-01-30 02:26:58][root][INFO] - Training Epoch: 1/2, step 6411/107898 completed (loss: 0.44678667187690735, acc: 0.6666666865348816)
[2025-01-30 02:26:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6413/107898 [34:48<9:04:51,  3.10it/s][2025-01-30 02:26:58][root][INFO] - Training Epoch: 1/2, step 6412/107898 completed (loss: 0.5204805135726929, acc: 0.9166666865348816)
[2025-01-30 02:26:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6414/107898 [34:49<9:16:58,  3.04it/s][2025-01-30 02:26:59][root][INFO] - Training Epoch: 1/2, step 6413/107898 completed (loss: 0.31257814168930054, acc: 0.6666666865348816)
[2025-01-30 02:26:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6415/107898 [34:49<9:21:05,  3.01it/s][2025-01-30 02:26:59][root][INFO] - Training Epoch: 1/2, step 6414/107898 completed (loss: 4.232494831085205, acc: 0.25)
[2025-01-30 02:26:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6416/107898 [34:50<9:21:22,  3.01it/s][2025-01-30 02:26:59][root][INFO] - Training Epoch: 1/2, step 6415/107898 completed (loss: 0.12308502942323685, acc: 1.0)
[2025-01-30 02:26:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6417/107898 [34:50<9:20:05,  3.02it/s][2025-01-30 02:27:00][root][INFO] - Training Epoch: 1/2, step 6416/107898 completed (loss: 0.13761569559574127, acc: 0.9583333134651184)
[2025-01-30 02:27:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6418/107898 [34:50<9:17:13,  3.04it/s][2025-01-30 02:27:00][root][INFO] - Training Epoch: 1/2, step 6417/107898 completed (loss: 2.627829074859619, acc: 0.4444444477558136)
[2025-01-30 02:27:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6419/107898 [34:51<9:25:56,  2.99it/s][2025-01-30 02:27:00][root][INFO] - Training Epoch: 1/2, step 6418/107898 completed (loss: 0.01692529395222664, acc: 1.0)
[2025-01-30 02:27:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6420/107898 [34:51<9:29:31,  2.97it/s][2025-01-30 02:27:01][root][INFO] - Training Epoch: 1/2, step 6419/107898 completed (loss: 0.7333581447601318, acc: 0.5)
[2025-01-30 02:27:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6421/107898 [34:51<9:47:47,  2.88it/s][2025-01-30 02:27:01][root][INFO] - Training Epoch: 1/2, step 6420/107898 completed (loss: 6.024223804473877, acc: 0.375)
[2025-01-30 02:27:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6422/107898 [34:52<9:42:13,  2.90it/s][2025-01-30 02:27:01][root][INFO] - Training Epoch: 1/2, step 6421/107898 completed (loss: 0.9369130730628967, acc: 0.6666666865348816)
[2025-01-30 02:27:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6423/107898 [34:52<9:32:59,  2.95it/s][2025-01-30 02:27:02][root][INFO] - Training Epoch: 1/2, step 6422/107898 completed (loss: 0.6107490062713623, acc: 0.8965517282485962)
[2025-01-30 02:27:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6424/107898 [34:52<9:39:44,  2.92it/s][2025-01-30 02:27:02][root][INFO] - Training Epoch: 1/2, step 6423/107898 completed (loss: 0.00742940790951252, acc: 1.0)
[2025-01-30 02:27:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6425/107898 [34:53<9:37:31,  2.93it/s][2025-01-30 02:27:02][root][INFO] - Training Epoch: 1/2, step 6424/107898 completed (loss: 0.7969839572906494, acc: 0.6000000238418579)
[2025-01-30 02:27:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6426/107898 [34:53<9:35:13,  2.94it/s][2025-01-30 02:27:03][root][INFO] - Training Epoch: 1/2, step 6425/107898 completed (loss: 2.041846990585327, acc: 0.6363636255264282)
[2025-01-30 02:27:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6427/107898 [34:53<9:50:25,  2.86it/s][2025-01-30 02:27:03][root][INFO] - Training Epoch: 1/2, step 6426/107898 completed (loss: 1.2409157752990723, acc: 0.5)
[2025-01-30 02:27:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6428/107898 [34:54<9:33:47,  2.95it/s][2025-01-30 02:27:03][root][INFO] - Training Epoch: 1/2, step 6427/107898 completed (loss: 0.01544878352433443, acc: 1.0)
[2025-01-30 02:27:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6429/107898 [34:54<9:09:40,  3.08it/s][2025-01-30 02:27:04][root][INFO] - Training Epoch: 1/2, step 6428/107898 completed (loss: 0.02125469222664833, acc: 1.0)
[2025-01-30 02:27:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6430/107898 [34:54<8:54:17,  3.17it/s][2025-01-30 02:27:04][root][INFO] - Training Epoch: 1/2, step 6429/107898 completed (loss: 1.7042948007583618, acc: 0.6000000238418579)
[2025-01-30 02:27:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6431/107898 [34:54<8:47:27,  3.21it/s][2025-01-30 02:27:04][root][INFO] - Training Epoch: 1/2, step 6430/107898 completed (loss: 0.9103029370307922, acc: 0.6666666865348816)
[2025-01-30 02:27:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6432/107898 [34:55<8:48:22,  3.20it/s][2025-01-30 02:27:05][root][INFO] - Training Epoch: 1/2, step 6431/107898 completed (loss: 0.22559142112731934, acc: 1.0)
[2025-01-30 02:27:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6433/107898 [34:55<9:20:04,  3.02it/s][2025-01-30 02:27:05][root][INFO] - Training Epoch: 1/2, step 6432/107898 completed (loss: 1.363213300704956, acc: 0.8095238208770752)
[2025-01-30 02:27:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6434/107898 [34:56<9:32:50,  2.95it/s][2025-01-30 02:27:05][root][INFO] - Training Epoch: 1/2, step 6433/107898 completed (loss: 1.4690357446670532, acc: 0.5454545617103577)
[2025-01-30 02:27:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6435/107898 [34:56<9:33:46,  2.95it/s][2025-01-30 02:27:06][root][INFO] - Training Epoch: 1/2, step 6434/107898 completed (loss: 1.3363840579986572, acc: 0.75)
[2025-01-30 02:27:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6436/107898 [34:56<9:23:04,  3.00it/s][2025-01-30 02:27:06][root][INFO] - Training Epoch: 1/2, step 6435/107898 completed (loss: 1.274344801902771, acc: 0.6666666865348816)
[2025-01-30 02:27:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6437/107898 [34:57<9:22:39,  3.01it/s][2025-01-30 02:27:06][root][INFO] - Training Epoch: 1/2, step 6436/107898 completed (loss: 0.1038152351975441, acc: 1.0)
[2025-01-30 02:27:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6438/107898 [34:57<9:22:34,  3.01it/s][2025-01-30 02:27:07][root][INFO] - Training Epoch: 1/2, step 6437/107898 completed (loss: 0.9792411923408508, acc: 0.800000011920929)
[2025-01-30 02:27:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6439/107898 [34:57<9:07:02,  3.09it/s][2025-01-30 02:27:07][root][INFO] - Training Epoch: 1/2, step 6438/107898 completed (loss: 3.447389602661133, acc: 0.5)
[2025-01-30 02:27:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6440/107898 [34:58<9:39:19,  2.92it/s][2025-01-30 02:27:07][root][INFO] - Training Epoch: 1/2, step 6439/107898 completed (loss: 1.7761579751968384, acc: 0.75)
[2025-01-30 02:27:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6441/107898 [34:58<9:32:03,  2.96it/s][2025-01-30 02:27:08][root][INFO] - Training Epoch: 1/2, step 6440/107898 completed (loss: 0.04309102147817612, acc: 1.0)
[2025-01-30 02:27:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6442/107898 [34:58<9:17:47,  3.03it/s][2025-01-30 02:27:08][root][INFO] - Training Epoch: 1/2, step 6441/107898 completed (loss: 0.10423821210861206, acc: 1.0)
[2025-01-30 02:27:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6443/107898 [34:58<9:07:43,  3.09it/s][2025-01-30 02:27:08][root][INFO] - Training Epoch: 1/2, step 6442/107898 completed (loss: 0.430769681930542, acc: 1.0)
[2025-01-30 02:27:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6444/107898 [34:59<8:55:25,  3.16it/s][2025-01-30 02:27:09][root][INFO] - Training Epoch: 1/2, step 6443/107898 completed (loss: 2.74105167388916, acc: 0.6666666865348816)
[2025-01-30 02:27:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6445/107898 [34:59<8:49:54,  3.19it/s][2025-01-30 02:27:09][root][INFO] - Training Epoch: 1/2, step 6444/107898 completed (loss: 1.9060794115066528, acc: 0.6666666865348816)
[2025-01-30 02:27:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6446/107898 [34:59<8:47:33,  3.21it/s][2025-01-30 02:27:09][root][INFO] - Training Epoch: 1/2, step 6445/107898 completed (loss: 0.8419973850250244, acc: 0.800000011920929)
[2025-01-30 02:27:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6447/107898 [35:00<8:28:55,  3.32it/s][2025-01-30 02:27:09][root][INFO] - Training Epoch: 1/2, step 6446/107898 completed (loss: 0.02850327268242836, acc: 1.0)
[2025-01-30 02:27:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6448/107898 [35:00<8:25:57,  3.34it/s][2025-01-30 02:27:10][root][INFO] - Training Epoch: 1/2, step 6447/107898 completed (loss: 5.41180944442749, acc: 0.3333333432674408)
[2025-01-30 02:27:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6449/107898 [35:00<8:22:41,  3.36it/s][2025-01-30 02:27:10][root][INFO] - Training Epoch: 1/2, step 6448/107898 completed (loss: 2.3100407123565674, acc: 0.6000000238418579)
[2025-01-30 02:27:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6450/107898 [35:01<8:26:33,  3.34it/s][2025-01-30 02:27:10][root][INFO] - Training Epoch: 1/2, step 6449/107898 completed (loss: 4.055770397186279, acc: 0.5)
[2025-01-30 02:27:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6451/107898 [35:01<8:31:21,  3.31it/s][2025-01-30 02:27:11][root][INFO] - Training Epoch: 1/2, step 6450/107898 completed (loss: 0.02335655316710472, acc: 1.0)
[2025-01-30 02:27:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6452/107898 [35:01<8:49:31,  3.19it/s][2025-01-30 02:27:11][root][INFO] - Training Epoch: 1/2, step 6451/107898 completed (loss: 1.2566373348236084, acc: 0.7857142686843872)
[2025-01-30 02:27:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6453/107898 [35:02<9:03:36,  3.11it/s][2025-01-30 02:27:11][root][INFO] - Training Epoch: 1/2, step 6452/107898 completed (loss: 1.6514177322387695, acc: 0.800000011920929)
[2025-01-30 02:27:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6454/107898 [35:02<9:08:11,  3.08it/s][2025-01-30 02:27:12][root][INFO] - Training Epoch: 1/2, step 6453/107898 completed (loss: 0.7345649003982544, acc: 0.8999999761581421)
[2025-01-30 02:27:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6455/107898 [35:02<9:23:25,  3.00it/s][2025-01-30 02:27:12][root][INFO] - Training Epoch: 1/2, step 6454/107898 completed (loss: 0.07809433341026306, acc: 1.0)
[2025-01-30 02:27:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6456/107898 [35:03<9:22:23,  3.01it/s][2025-01-30 02:27:12][root][INFO] - Training Epoch: 1/2, step 6455/107898 completed (loss: 3.819641590118408, acc: 0.25)
[2025-01-30 02:27:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6457/107898 [35:03<9:23:44,  3.00it/s][2025-01-30 02:27:13][root][INFO] - Training Epoch: 1/2, step 6456/107898 completed (loss: 0.0035733410622924566, acc: 1.0)
[2025-01-30 02:27:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6458/107898 [35:03<9:11:50,  3.06it/s][2025-01-30 02:27:13][root][INFO] - Training Epoch: 1/2, step 6457/107898 completed (loss: 0.49245235323905945, acc: 0.8571428656578064)
[2025-01-30 02:27:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6459/107898 [35:04<8:59:24,  3.13it/s][2025-01-30 02:27:13][root][INFO] - Training Epoch: 1/2, step 6458/107898 completed (loss: 3.1242940425872803, acc: 0.25)
[2025-01-30 02:27:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6460/107898 [35:04<8:53:04,  3.17it/s][2025-01-30 02:27:14][root][INFO] - Training Epoch: 1/2, step 6459/107898 completed (loss: 0.06376376748085022, acc: 1.0)
[2025-01-30 02:27:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6461/107898 [35:04<8:48:04,  3.20it/s][2025-01-30 02:27:14][root][INFO] - Training Epoch: 1/2, step 6460/107898 completed (loss: 1.0024651288986206, acc: 0.5)
[2025-01-30 02:27:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6462/107898 [35:04<8:58:29,  3.14it/s][2025-01-30 02:27:14][root][INFO] - Training Epoch: 1/2, step 6461/107898 completed (loss: 0.4059598445892334, acc: 1.0)
[2025-01-30 02:27:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6463/107898 [35:05<8:51:09,  3.18it/s][2025-01-30 02:27:15][root][INFO] - Training Epoch: 1/2, step 6462/107898 completed (loss: 0.9485327005386353, acc: 0.8571428656578064)
[2025-01-30 02:27:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6464/107898 [35:05<8:46:22,  3.21it/s][2025-01-30 02:27:15][root][INFO] - Training Epoch: 1/2, step 6463/107898 completed (loss: 1.2111515998840332, acc: 0.800000011920929)
[2025-01-30 02:27:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6465/107898 [35:05<8:41:11,  3.24it/s][2025-01-30 02:27:15][root][INFO] - Training Epoch: 1/2, step 6464/107898 completed (loss: 0.33736205101013184, acc: 1.0)
[2025-01-30 02:27:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6466/107898 [35:06<8:48:22,  3.20it/s][2025-01-30 02:27:15][root][INFO] - Training Epoch: 1/2, step 6465/107898 completed (loss: 1.245345115661621, acc: 0.6842105388641357)
[2025-01-30 02:27:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6467/107898 [35:06<8:44:05,  3.23it/s][2025-01-30 02:27:16][root][INFO] - Training Epoch: 1/2, step 6466/107898 completed (loss: 0.7452725768089294, acc: 0.8888888955116272)
[2025-01-30 02:27:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6468/107898 [35:06<8:33:56,  3.29it/s][2025-01-30 02:27:16][root][INFO] - Training Epoch: 1/2, step 6467/107898 completed (loss: 1.3127670288085938, acc: 0.6363636255264282)
[2025-01-30 02:27:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6469/107898 [35:07<8:30:04,  3.31it/s][2025-01-30 02:27:16][root][INFO] - Training Epoch: 1/2, step 6468/107898 completed (loss: 1.1303486824035645, acc: 0.8275862336158752)
[2025-01-30 02:27:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6470/107898 [35:07<8:42:35,  3.23it/s][2025-01-30 02:27:17][root][INFO] - Training Epoch: 1/2, step 6469/107898 completed (loss: 4.227879047393799, acc: 0.3636363744735718)
[2025-01-30 02:27:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6471/107898 [35:07<8:39:31,  3.25it/s][2025-01-30 02:27:17][root][INFO] - Training Epoch: 1/2, step 6470/107898 completed (loss: 3.4222660064697266, acc: 0.25)
[2025-01-30 02:27:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6472/107898 [35:08<9:05:44,  3.10it/s][2025-01-30 02:27:17][root][INFO] - Training Epoch: 1/2, step 6471/107898 completed (loss: 0.44697678089141846, acc: 1.0)
[2025-01-30 02:27:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6473/107898 [35:08<9:10:07,  3.07it/s][2025-01-30 02:27:18][root][INFO] - Training Epoch: 1/2, step 6472/107898 completed (loss: 0.5995045304298401, acc: 1.0)
[2025-01-30 02:27:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6474/107898 [35:08<9:34:47,  2.94it/s][2025-01-30 02:27:18][root][INFO] - Training Epoch: 1/2, step 6473/107898 completed (loss: 0.19061535596847534, acc: 1.0)
[2025-01-30 02:27:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6475/107898 [35:09<9:22:50,  3.00it/s][2025-01-30 02:27:18][root][INFO] - Training Epoch: 1/2, step 6474/107898 completed (loss: 0.5901982188224792, acc: 0.90625)
[2025-01-30 02:27:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6476/107898 [35:09<9:07:33,  3.09it/s][2025-01-30 02:27:19][root][INFO] - Training Epoch: 1/2, step 6475/107898 completed (loss: 1.5070470571517944, acc: 0.7777777910232544)
[2025-01-30 02:27:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6477/107898 [35:09<8:52:37,  3.17it/s][2025-01-30 02:27:19][root][INFO] - Training Epoch: 1/2, step 6476/107898 completed (loss: 0.019053667783737183, acc: 1.0)
[2025-01-30 02:27:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6478/107898 [35:10<8:50:35,  3.19it/s][2025-01-30 02:27:19][root][INFO] - Training Epoch: 1/2, step 6477/107898 completed (loss: 0.5435116291046143, acc: 1.0)
[2025-01-30 02:27:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6479/107898 [35:10<9:08:59,  3.08it/s][2025-01-30 02:27:20][root][INFO] - Training Epoch: 1/2, step 6478/107898 completed (loss: 0.4562547504901886, acc: 1.0)
[2025-01-30 02:27:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6480/107898 [35:10<9:17:36,  3.03it/s][2025-01-30 02:27:20][root][INFO] - Training Epoch: 1/2, step 6479/107898 completed (loss: 0.011592704802751541, acc: 1.0)
[2025-01-30 02:27:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6481/107898 [35:11<9:18:14,  3.03it/s][2025-01-30 02:27:20][root][INFO] - Training Epoch: 1/2, step 6480/107898 completed (loss: 0.010827967897057533, acc: 1.0)
[2025-01-30 02:27:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6482/107898 [35:11<9:13:20,  3.05it/s][2025-01-30 02:27:21][root][INFO] - Training Epoch: 1/2, step 6481/107898 completed (loss: 0.1290239542722702, acc: 1.0)
[2025-01-30 02:27:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6483/107898 [35:11<8:56:54,  3.15it/s][2025-01-30 02:27:21][root][INFO] - Training Epoch: 1/2, step 6482/107898 completed (loss: 0.08065479248762131, acc: 1.0)
[2025-01-30 02:27:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6484/107898 [35:11<9:02:25,  3.12it/s][2025-01-30 02:27:21][root][INFO] - Training Epoch: 1/2, step 6483/107898 completed (loss: 0.3713713586330414, acc: 0.9545454382896423)
[2025-01-30 02:27:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6485/107898 [35:12<8:54:34,  3.16it/s][2025-01-30 02:27:22][root][INFO] - Training Epoch: 1/2, step 6484/107898 completed (loss: 3.547605276107788, acc: 0.5)
[2025-01-30 02:27:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6486/107898 [35:12<8:51:24,  3.18it/s][2025-01-30 02:27:22][root][INFO] - Training Epoch: 1/2, step 6485/107898 completed (loss: 2.9486591815948486, acc: 0.4000000059604645)
[2025-01-30 02:27:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6487/107898 [35:12<8:45:13,  3.22it/s][2025-01-30 02:27:22][root][INFO] - Training Epoch: 1/2, step 6486/107898 completed (loss: 0.014341267757117748, acc: 1.0)
[2025-01-30 02:27:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6488/107898 [35:13<8:57:00,  3.15it/s][2025-01-30 02:27:23][root][INFO] - Training Epoch: 1/2, step 6487/107898 completed (loss: 2.0235352516174316, acc: 0.3333333432674408)
[2025-01-30 02:27:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6489/107898 [35:13<8:53:48,  3.17it/s][2025-01-30 02:27:23][root][INFO] - Training Epoch: 1/2, step 6488/107898 completed (loss: 3.7565300464630127, acc: 0.1428571492433548)
[2025-01-30 02:27:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6490/107898 [35:13<8:48:01,  3.20it/s][2025-01-30 02:27:23][root][INFO] - Training Epoch: 1/2, step 6489/107898 completed (loss: 0.0014043716946616769, acc: 1.0)
[2025-01-30 02:27:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6491/107898 [35:14<8:50:31,  3.19it/s][2025-01-30 02:27:23][root][INFO] - Training Epoch: 1/2, step 6490/107898 completed (loss: 1.2418183088302612, acc: 0.7777777910232544)
[2025-01-30 02:27:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6492/107898 [35:14<9:03:12,  3.11it/s][2025-01-30 02:27:24][root][INFO] - Training Epoch: 1/2, step 6491/107898 completed (loss: 0.3259078562259674, acc: 1.0)
[2025-01-30 02:27:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6493/107898 [35:14<9:04:37,  3.10it/s][2025-01-30 02:27:24][root][INFO] - Training Epoch: 1/2, step 6492/107898 completed (loss: 2.661102056503296, acc: 0.2857142984867096)
[2025-01-30 02:27:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6494/107898 [35:15<8:55:20,  3.16it/s][2025-01-30 02:27:24][root][INFO] - Training Epoch: 1/2, step 6493/107898 completed (loss: 1.3468354940414429, acc: 0.800000011920929)
[2025-01-30 02:27:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6495/107898 [35:15<8:53:26,  3.17it/s][2025-01-30 02:27:25][root][INFO] - Training Epoch: 1/2, step 6494/107898 completed (loss: 1.198469877243042, acc: 0.75)
[2025-01-30 02:27:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6496/107898 [35:15<8:47:20,  3.20it/s][2025-01-30 02:27:25][root][INFO] - Training Epoch: 1/2, step 6495/107898 completed (loss: 2.7339863777160645, acc: 0.6000000238418579)
[2025-01-30 02:27:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6497/107898 [35:16<8:45:59,  3.21it/s][2025-01-30 02:27:25][root][INFO] - Training Epoch: 1/2, step 6496/107898 completed (loss: 0.22397257387638092, acc: 1.0)
[2025-01-30 02:27:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6498/107898 [35:16<9:09:08,  3.08it/s][2025-01-30 02:27:26][root][INFO] - Training Epoch: 1/2, step 6497/107898 completed (loss: 0.022042935714125633, acc: 1.0)
[2025-01-30 02:27:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6499/107898 [35:16<9:11:07,  3.07it/s][2025-01-30 02:27:26][root][INFO] - Training Epoch: 1/2, step 6498/107898 completed (loss: 3.269651412963867, acc: 0.75)
[2025-01-30 02:27:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6500/107898 [35:17<8:51:10,  3.18it/s][2025-01-30 02:27:26][root][INFO] - Training Epoch: 1/2, step 6499/107898 completed (loss: 1.0719451904296875, acc: 0.7222222089767456)
[2025-01-30 02:27:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6501/107898 [35:17<9:01:34,  3.12it/s][2025-01-30 02:27:27][root][INFO] - Training Epoch: 1/2, step 6500/107898 completed (loss: 0.5454875826835632, acc: 0.9285714030265808)
[2025-01-30 02:27:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6502/107898 [35:17<9:05:21,  3.10it/s][2025-01-30 02:27:27][root][INFO] - Training Epoch: 1/2, step 6501/107898 completed (loss: 0.9195223450660706, acc: 0.7692307829856873)
[2025-01-30 02:27:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6503/107898 [35:18<9:01:12,  3.12it/s][2025-01-30 02:27:27][root][INFO] - Training Epoch: 1/2, step 6502/107898 completed (loss: 0.6482570767402649, acc: 0.6666666865348816)
[2025-01-30 02:27:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6504/107898 [35:18<9:02:43,  3.11it/s][2025-01-30 02:27:28][root][INFO] - Training Epoch: 1/2, step 6503/107898 completed (loss: 1.7531458139419556, acc: 0.6428571343421936)
[2025-01-30 02:27:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6505/107898 [35:18<8:54:45,  3.16it/s][2025-01-30 02:27:28][root][INFO] - Training Epoch: 1/2, step 6504/107898 completed (loss: 2.1358470916748047, acc: 0.6666666865348816)
[2025-01-30 02:27:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6506/107898 [35:18<8:49:12,  3.19it/s][2025-01-30 02:27:28][root][INFO] - Training Epoch: 1/2, step 6505/107898 completed (loss: 0.09524517506361008, acc: 1.0)
[2025-01-30 02:27:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6507/107898 [35:19<8:56:55,  3.15it/s][2025-01-30 02:27:29][root][INFO] - Training Epoch: 1/2, step 6506/107898 completed (loss: 1.7172785997390747, acc: 0.7142857313156128)
[2025-01-30 02:27:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6508/107898 [35:19<8:49:35,  3.19it/s][2025-01-30 02:27:29][root][INFO] - Training Epoch: 1/2, step 6507/107898 completed (loss: 0.0034477091394364834, acc: 1.0)
[2025-01-30 02:27:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6509/107898 [35:19<8:49:29,  3.19it/s][2025-01-30 02:27:29][root][INFO] - Training Epoch: 1/2, step 6508/107898 completed (loss: 0.529688835144043, acc: 0.7142857313156128)
[2025-01-30 02:27:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6510/107898 [35:20<8:46:47,  3.21it/s][2025-01-30 02:27:29][root][INFO] - Training Epoch: 1/2, step 6509/107898 completed (loss: 2.3101961612701416, acc: 0.6666666865348816)
[2025-01-30 02:27:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6511/107898 [35:20<9:04:05,  3.11it/s][2025-01-30 02:27:30][root][INFO] - Training Epoch: 1/2, step 6510/107898 completed (loss: 0.0817476212978363, acc: 1.0)
[2025-01-30 02:27:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6512/107898 [35:20<8:54:55,  3.16it/s][2025-01-30 02:27:30][root][INFO] - Training Epoch: 1/2, step 6511/107898 completed (loss: 2.344484329223633, acc: 0.5)
[2025-01-30 02:27:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6513/107898 [35:21<9:03:55,  3.11it/s][2025-01-30 02:27:30][root][INFO] - Training Epoch: 1/2, step 6512/107898 completed (loss: 0.1697946935892105, acc: 1.0)
[2025-01-30 02:27:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6514/107898 [35:21<9:11:55,  3.06it/s][2025-01-30 02:27:31][root][INFO] - Training Epoch: 1/2, step 6513/107898 completed (loss: 0.10786963254213333, acc: 1.0)
[2025-01-30 02:27:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6515/107898 [35:21<9:14:07,  3.05it/s][2025-01-30 02:27:31][root][INFO] - Training Epoch: 1/2, step 6514/107898 completed (loss: 0.5981439352035522, acc: 0.9333333373069763)
[2025-01-30 02:27:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6516/107898 [35:22<9:17:57,  3.03it/s][2025-01-30 02:27:31][root][INFO] - Training Epoch: 1/2, step 6515/107898 completed (loss: 0.8769140243530273, acc: 0.75)
[2025-01-30 02:27:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6517/107898 [35:22<9:18:52,  3.02it/s][2025-01-30 02:27:32][root][INFO] - Training Epoch: 1/2, step 6516/107898 completed (loss: 0.5044805407524109, acc: 0.800000011920929)
[2025-01-30 02:27:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6518/107898 [35:22<9:30:22,  2.96it/s][2025-01-30 02:27:32][root][INFO] - Training Epoch: 1/2, step 6517/107898 completed (loss: 2.991142511367798, acc: 0.5)
[2025-01-30 02:27:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6519/107898 [35:23<9:18:56,  3.02it/s][2025-01-30 02:27:32][root][INFO] - Training Epoch: 1/2, step 6518/107898 completed (loss: 0.03636786341667175, acc: 1.0)
[2025-01-30 02:27:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6520/107898 [35:23<9:07:43,  3.08it/s][2025-01-30 02:27:33][root][INFO] - Training Epoch: 1/2, step 6519/107898 completed (loss: 0.04321590065956116, acc: 1.0)
[2025-01-30 02:27:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6521/107898 [35:23<9:26:57,  2.98it/s][2025-01-30 02:27:33][root][INFO] - Training Epoch: 1/2, step 6520/107898 completed (loss: 0.015926938503980637, acc: 1.0)
[2025-01-30 02:27:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6522/107898 [35:24<9:31:20,  2.96it/s][2025-01-30 02:27:33][root][INFO] - Training Epoch: 1/2, step 6521/107898 completed (loss: 0.9381173253059387, acc: 0.774193525314331)
[2025-01-30 02:27:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6523/107898 [35:24<9:06:53,  3.09it/s][2025-01-30 02:27:34][root][INFO] - Training Epoch: 1/2, step 6522/107898 completed (loss: 0.7970000505447388, acc: 0.800000011920929)
[2025-01-30 02:27:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6524/107898 [35:24<9:01:00,  3.12it/s][2025-01-30 02:27:34][root][INFO] - Training Epoch: 1/2, step 6523/107898 completed (loss: 2.434976816177368, acc: 0.4000000059604645)
[2025-01-30 02:27:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6525/107898 [35:25<8:56:06,  3.15it/s][2025-01-30 02:27:34][root][INFO] - Training Epoch: 1/2, step 6524/107898 completed (loss: 0.46085312962532043, acc: 0.9230769276618958)
[2025-01-30 02:27:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6526/107898 [35:25<8:50:01,  3.19it/s][2025-01-30 02:27:35][root][INFO] - Training Epoch: 1/2, step 6525/107898 completed (loss: 0.022919952869415283, acc: 1.0)
[2025-01-30 02:27:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6527/107898 [35:25<8:37:30,  3.26it/s][2025-01-30 02:27:35][root][INFO] - Training Epoch: 1/2, step 6526/107898 completed (loss: 0.0013155722990632057, acc: 1.0)
[2025-01-30 02:27:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6528/107898 [35:26<8:42:56,  3.23it/s][2025-01-30 02:27:35][root][INFO] - Training Epoch: 1/2, step 6527/107898 completed (loss: 0.06294239312410355, acc: 1.0)
[2025-01-30 02:27:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6529/107898 [35:26<9:02:20,  3.12it/s][2025-01-30 02:27:36][root][INFO] - Training Epoch: 1/2, step 6528/107898 completed (loss: 3.3441812992095947, acc: 0.5)
[2025-01-30 02:27:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6530/107898 [35:26<9:18:02,  3.03it/s][2025-01-30 02:27:36][root][INFO] - Training Epoch: 1/2, step 6529/107898 completed (loss: 0.5908071398735046, acc: 0.7777777910232544)
[2025-01-30 02:27:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6531/107898 [35:26<8:48:29,  3.20it/s][2025-01-30 02:27:36][root][INFO] - Training Epoch: 1/2, step 6530/107898 completed (loss: 1.8402856588363647, acc: 0.625)
[2025-01-30 02:27:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6532/107898 [35:27<8:51:30,  3.18it/s][2025-01-30 02:27:37][root][INFO] - Training Epoch: 1/2, step 6531/107898 completed (loss: 0.04056287556886673, acc: 1.0)
[2025-01-30 02:27:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6533/107898 [35:27<9:26:47,  2.98it/s][2025-01-30 02:27:37][root][INFO] - Training Epoch: 1/2, step 6532/107898 completed (loss: 2.069472074508667, acc: 0.75)
[2025-01-30 02:27:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6534/107898 [35:28<9:22:49,  3.00it/s][2025-01-30 02:27:37][root][INFO] - Training Epoch: 1/2, step 6533/107898 completed (loss: 0.8077071309089661, acc: 0.8888888955116272)
[2025-01-30 02:27:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6535/107898 [35:28<9:06:51,  3.09it/s][2025-01-30 02:27:38][root][INFO] - Training Epoch: 1/2, step 6534/107898 completed (loss: 0.0844588652253151, acc: 1.0)
[2025-01-30 02:27:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6536/107898 [35:28<9:12:40,  3.06it/s][2025-01-30 02:27:38][root][INFO] - Training Epoch: 1/2, step 6535/107898 completed (loss: 3.938588857650757, acc: 0.0)
[2025-01-30 02:27:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6537/107898 [35:28<9:05:24,  3.10it/s][2025-01-30 02:27:38][root][INFO] - Training Epoch: 1/2, step 6536/107898 completed (loss: 3.219525098800659, acc: 0.25)
[2025-01-30 02:27:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6538/107898 [35:29<9:03:56,  3.11it/s][2025-01-30 02:27:39][root][INFO] - Training Epoch: 1/2, step 6537/107898 completed (loss: 0.03115440346300602, acc: 1.0)
[2025-01-30 02:27:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6539/107898 [35:29<8:59:30,  3.13it/s][2025-01-30 02:27:39][root][INFO] - Training Epoch: 1/2, step 6538/107898 completed (loss: 0.031877078115940094, acc: 1.0)
[2025-01-30 02:27:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6540/107898 [35:29<9:03:04,  3.11it/s][2025-01-30 02:27:39][root][INFO] - Training Epoch: 1/2, step 6539/107898 completed (loss: 0.4938875138759613, acc: 0.90625)
[2025-01-30 02:27:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6541/107898 [35:30<8:56:50,  3.15it/s][2025-01-30 02:27:40][root][INFO] - Training Epoch: 1/2, step 6540/107898 completed (loss: 0.027605805546045303, acc: 1.0)
[2025-01-30 02:27:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6542/107898 [35:30<8:49:10,  3.19it/s][2025-01-30 02:27:40][root][INFO] - Training Epoch: 1/2, step 6541/107898 completed (loss: 0.03872254490852356, acc: 1.0)
[2025-01-30 02:27:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6543/107898 [35:30<8:39:27,  3.25it/s][2025-01-30 02:27:40][root][INFO] - Training Epoch: 1/2, step 6542/107898 completed (loss: 0.0122316749766469, acc: 1.0)
[2025-01-30 02:27:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6544/107898 [35:31<8:29:54,  3.31it/s][2025-01-30 02:27:40][root][INFO] - Training Epoch: 1/2, step 6543/107898 completed (loss: 1.2524932622909546, acc: 0.6666666865348816)
[2025-01-30 02:27:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6545/107898 [35:31<8:32:30,  3.30it/s][2025-01-30 02:27:41][root][INFO] - Training Epoch: 1/2, step 6544/107898 completed (loss: 0.41823920607566833, acc: 1.0)
[2025-01-30 02:27:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6546/107898 [35:31<8:30:55,  3.31it/s][2025-01-30 02:27:41][root][INFO] - Training Epoch: 1/2, step 6545/107898 completed (loss: 0.409121036529541, acc: 0.5)
[2025-01-30 02:27:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6547/107898 [35:32<8:49:20,  3.19it/s][2025-01-30 02:27:41][root][INFO] - Training Epoch: 1/2, step 6546/107898 completed (loss: 1.52329683303833, acc: 0.6800000071525574)
[2025-01-30 02:27:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6548/107898 [35:32<8:59:19,  3.13it/s][2025-01-30 02:27:42][root][INFO] - Training Epoch: 1/2, step 6547/107898 completed (loss: 0.6973437070846558, acc: 0.7777777910232544)
[2025-01-30 02:27:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6549/107898 [35:32<9:07:51,  3.08it/s][2025-01-30 02:27:42][root][INFO] - Training Epoch: 1/2, step 6548/107898 completed (loss: 0.8396940231323242, acc: 0.8888888955116272)
[2025-01-30 02:27:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6550/107898 [35:33<9:19:36,  3.02it/s][2025-01-30 02:27:42][root][INFO] - Training Epoch: 1/2, step 6549/107898 completed (loss: 1.120659351348877, acc: 0.7222222089767456)
[2025-01-30 02:27:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6551/107898 [35:33<9:21:49,  3.01it/s][2025-01-30 02:27:43][root][INFO] - Training Epoch: 1/2, step 6550/107898 completed (loss: 2.5780704021453857, acc: 0.5)
[2025-01-30 02:27:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6552/107898 [35:33<9:33:37,  2.94it/s][2025-01-30 02:27:43][root][INFO] - Training Epoch: 1/2, step 6551/107898 completed (loss: 3.6991891860961914, acc: 0.3333333432674408)
[2025-01-30 02:27:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6553/107898 [35:34<9:48:20,  2.87it/s][2025-01-30 02:27:43][root][INFO] - Training Epoch: 1/2, step 6552/107898 completed (loss: 3.522895097732544, acc: 0.5)
[2025-01-30 02:27:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6554/107898 [35:34<9:52:07,  2.85it/s][2025-01-30 02:27:44][root][INFO] - Training Epoch: 1/2, step 6553/107898 completed (loss: 0.2690137028694153, acc: 1.0)
[2025-01-30 02:27:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6555/107898 [35:34<9:43:28,  2.89it/s][2025-01-30 02:27:44][root][INFO] - Training Epoch: 1/2, step 6554/107898 completed (loss: 0.0243254154920578, acc: 1.0)
[2025-01-30 02:27:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6556/107898 [35:35<9:31:22,  2.96it/s][2025-01-30 02:27:44][root][INFO] - Training Epoch: 1/2, step 6555/107898 completed (loss: 3.5420949459075928, acc: 0.6666666865348816)
[2025-01-30 02:27:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6557/107898 [35:35<9:37:03,  2.93it/s][2025-01-30 02:27:45][root][INFO] - Training Epoch: 1/2, step 6556/107898 completed (loss: 1.3375921249389648, acc: 0.695652186870575)
[2025-01-30 02:27:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6558/107898 [35:35<9:33:31,  2.94it/s][2025-01-30 02:27:45][root][INFO] - Training Epoch: 1/2, step 6557/107898 completed (loss: 0.7109290361404419, acc: 0.75)
[2025-01-30 02:27:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6559/107898 [35:36<9:30:10,  2.96it/s][2025-01-30 02:27:45][root][INFO] - Training Epoch: 1/2, step 6558/107898 completed (loss: 3.7542998790740967, acc: 0.3333333432674408)
[2025-01-30 02:27:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6560/107898 [35:36<9:24:39,  2.99it/s][2025-01-30 02:27:46][root][INFO] - Training Epoch: 1/2, step 6559/107898 completed (loss: 0.4801618158817291, acc: 0.75)
[2025-01-30 02:27:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6561/107898 [35:36<9:17:41,  3.03it/s][2025-01-30 02:27:46][root][INFO] - Training Epoch: 1/2, step 6560/107898 completed (loss: 1.0124305486679077, acc: 0.75)
[2025-01-30 02:27:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6562/107898 [35:37<8:57:20,  3.14it/s][2025-01-30 02:27:46][root][INFO] - Training Epoch: 1/2, step 6561/107898 completed (loss: 0.04256179556250572, acc: 1.0)
[2025-01-30 02:27:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6563/107898 [35:37<8:51:29,  3.18it/s][2025-01-30 02:27:47][root][INFO] - Training Epoch: 1/2, step 6562/107898 completed (loss: 1.6126009225845337, acc: 0.5)
[2025-01-30 02:27:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6564/107898 [35:37<8:39:38,  3.25it/s][2025-01-30 02:27:47][root][INFO] - Training Epoch: 1/2, step 6563/107898 completed (loss: 1.9298875331878662, acc: 0.5)
[2025-01-30 02:27:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6565/107898 [35:38<8:33:30,  3.29it/s][2025-01-30 02:27:47][root][INFO] - Training Epoch: 1/2, step 6564/107898 completed (loss: 0.4395933151245117, acc: 0.800000011920929)
[2025-01-30 02:27:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6566/107898 [35:38<8:29:01,  3.32it/s][2025-01-30 02:27:48][root][INFO] - Training Epoch: 1/2, step 6565/107898 completed (loss: 0.03909550607204437, acc: 1.0)
[2025-01-30 02:27:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6567/107898 [35:38<8:32:12,  3.30it/s][2025-01-30 02:27:48][root][INFO] - Training Epoch: 1/2, step 6566/107898 completed (loss: 1.8190311193466187, acc: 0.3333333432674408)
[2025-01-30 02:27:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6568/107898 [35:38<8:31:39,  3.30it/s][2025-01-30 02:27:48][root][INFO] - Training Epoch: 1/2, step 6567/107898 completed (loss: 2.674093723297119, acc: 0.4000000059604645)
[2025-01-30 02:27:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6569/107898 [35:39<8:36:07,  3.27it/s][2025-01-30 02:27:49][root][INFO] - Training Epoch: 1/2, step 6568/107898 completed (loss: 0.3518854081630707, acc: 0.8823529481887817)
[2025-01-30 02:27:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6570/107898 [35:39<8:35:33,  3.28it/s][2025-01-30 02:27:49][root][INFO] - Training Epoch: 1/2, step 6569/107898 completed (loss: 2.153343439102173, acc: 0.5454545617103577)
[2025-01-30 02:27:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6571/107898 [35:39<8:30:07,  3.31it/s][2025-01-30 02:27:49][root][INFO] - Training Epoch: 1/2, step 6570/107898 completed (loss: 2.7013816833496094, acc: 0.3571428656578064)
[2025-01-30 02:27:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6572/107898 [35:40<8:23:41,  3.35it/s][2025-01-30 02:27:49][root][INFO] - Training Epoch: 1/2, step 6571/107898 completed (loss: 2.2044737339019775, acc: 0.0)
[2025-01-30 02:27:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6573/107898 [35:40<8:27:50,  3.33it/s][2025-01-30 02:27:50][root][INFO] - Training Epoch: 1/2, step 6572/107898 completed (loss: 1.5841784477233887, acc: 0.6521739363670349)
[2025-01-30 02:27:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6574/107898 [35:40<8:22:41,  3.36it/s][2025-01-30 02:27:50][root][INFO] - Training Epoch: 1/2, step 6573/107898 completed (loss: 3.030395984649658, acc: 0.5)
[2025-01-30 02:27:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6575/107898 [35:41<8:23:11,  3.36it/s][2025-01-30 02:27:50][root][INFO] - Training Epoch: 1/2, step 6574/107898 completed (loss: 1.189091444015503, acc: 0.0)
[2025-01-30 02:27:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6576/107898 [35:41<8:28:50,  3.32it/s][2025-01-30 02:27:51][root][INFO] - Training Epoch: 1/2, step 6575/107898 completed (loss: 0.017359541729092598, acc: 1.0)
[2025-01-30 02:27:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6577/107898 [35:41<8:25:05,  3.34it/s][2025-01-30 02:27:51][root][INFO] - Training Epoch: 1/2, step 6576/107898 completed (loss: 1.4459158182144165, acc: 0.6666666865348816)
[2025-01-30 02:27:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6578/107898 [35:41<8:25:03,  3.34it/s][2025-01-30 02:27:51][root][INFO] - Training Epoch: 1/2, step 6577/107898 completed (loss: 0.21196600794792175, acc: 1.0)
[2025-01-30 02:27:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6579/107898 [35:42<8:28:44,  3.32it/s][2025-01-30 02:27:52][root][INFO] - Training Epoch: 1/2, step 6578/107898 completed (loss: 0.17278645932674408, acc: 1.0)
[2025-01-30 02:27:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6580/107898 [35:42<8:34:15,  3.28it/s][2025-01-30 02:27:52][root][INFO] - Training Epoch: 1/2, step 6579/107898 completed (loss: 0.7913375496864319, acc: 0.875)
[2025-01-30 02:27:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6581/107898 [35:42<8:32:36,  3.29it/s][2025-01-30 02:27:52][root][INFO] - Training Epoch: 1/2, step 6580/107898 completed (loss: 1.149294376373291, acc: 0.75)
[2025-01-30 02:27:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6582/107898 [35:43<8:55:08,  3.16it/s][2025-01-30 02:27:52][root][INFO] - Training Epoch: 1/2, step 6581/107898 completed (loss: 0.012058766558766365, acc: 1.0)
[2025-01-30 02:27:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6583/107898 [35:43<9:02:03,  3.12it/s][2025-01-30 02:27:53][root][INFO] - Training Epoch: 1/2, step 6582/107898 completed (loss: 0.016327902674674988, acc: 1.0)
[2025-01-30 02:27:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6584/107898 [35:43<9:05:02,  3.10it/s][2025-01-30 02:27:53][root][INFO] - Training Epoch: 1/2, step 6583/107898 completed (loss: 0.23812641203403473, acc: 0.9230769276618958)
[2025-01-30 02:27:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6585/107898 [35:44<9:00:33,  3.12it/s][2025-01-30 02:27:53][root][INFO] - Training Epoch: 1/2, step 6584/107898 completed (loss: 1.517845869064331, acc: 0.4545454680919647)
[2025-01-30 02:27:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6586/107898 [35:44<8:50:41,  3.18it/s][2025-01-30 02:27:54][root][INFO] - Training Epoch: 1/2, step 6585/107898 completed (loss: 2.6794698238372803, acc: 0.625)
[2025-01-30 02:27:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6587/107898 [35:44<9:08:13,  3.08it/s][2025-01-30 02:27:54][root][INFO] - Training Epoch: 1/2, step 6586/107898 completed (loss: 0.05832362174987793, acc: 1.0)
[2025-01-30 02:27:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6588/107898 [35:45<9:14:19,  3.05it/s][2025-01-30 02:27:54][root][INFO] - Training Epoch: 1/2, step 6587/107898 completed (loss: 0.07599390298128128, acc: 1.0)
[2025-01-30 02:27:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6589/107898 [35:45<9:05:39,  3.09it/s][2025-01-30 02:27:55][root][INFO] - Training Epoch: 1/2, step 6588/107898 completed (loss: 2.0062367916107178, acc: 0.3333333432674408)
[2025-01-30 02:27:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6590/107898 [35:45<9:10:08,  3.07it/s][2025-01-30 02:27:55][root][INFO] - Training Epoch: 1/2, step 6589/107898 completed (loss: 0.010713702999055386, acc: 1.0)
[2025-01-30 02:27:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6591/107898 [35:46<9:07:28,  3.08it/s][2025-01-30 02:27:55][root][INFO] - Training Epoch: 1/2, step 6590/107898 completed (loss: 1.7406737804412842, acc: 0.800000011920929)
[2025-01-30 02:27:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6592/107898 [35:46<8:56:17,  3.15it/s][2025-01-30 02:27:56][root][INFO] - Training Epoch: 1/2, step 6591/107898 completed (loss: 1.3119503259658813, acc: 0.5625)
[2025-01-30 02:27:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6593/107898 [35:46<8:52:43,  3.17it/s][2025-01-30 02:27:56][root][INFO] - Training Epoch: 1/2, step 6592/107898 completed (loss: 3.701280117034912, acc: 0.2380952388048172)
[2025-01-30 02:27:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6594/107898 [35:47<8:43:57,  3.22it/s][2025-01-30 02:27:56][root][INFO] - Training Epoch: 1/2, step 6593/107898 completed (loss: 2.2160685062408447, acc: 0.5)
[2025-01-30 02:27:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6595/107898 [35:47<8:38:13,  3.26it/s][2025-01-30 02:27:57][root][INFO] - Training Epoch: 1/2, step 6594/107898 completed (loss: 1.6866984367370605, acc: 0.6666666865348816)
[2025-01-30 02:27:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6596/107898 [35:47<9:07:38,  3.08it/s][2025-01-30 02:27:57][root][INFO] - Training Epoch: 1/2, step 6595/107898 completed (loss: 0.13741981983184814, acc: 1.0)
[2025-01-30 02:27:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6597/107898 [35:48<9:12:14,  3.06it/s][2025-01-30 02:27:57][root][INFO] - Training Epoch: 1/2, step 6596/107898 completed (loss: 0.41176334023475647, acc: 0.8461538553237915)
[2025-01-30 02:27:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6598/107898 [35:48<9:06:10,  3.09it/s][2025-01-30 02:27:58][root][INFO] - Training Epoch: 1/2, step 6597/107898 completed (loss: 0.03191675618290901, acc: 1.0)
[2025-01-30 02:27:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6599/107898 [35:48<9:28:01,  2.97it/s][2025-01-30 02:27:58][root][INFO] - Training Epoch: 1/2, step 6598/107898 completed (loss: 1.2385704517364502, acc: 0.6428571343421936)
[2025-01-30 02:27:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6600/107898 [35:49<9:30:37,  2.96it/s][2025-01-30 02:27:58][root][INFO] - Training Epoch: 1/2, step 6599/107898 completed (loss: 0.4319823682308197, acc: 0.9285714030265808)
[2025-01-30 02:27:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6601/107898 [35:49<9:22:58,  3.00it/s][2025-01-30 02:27:59][root][INFO] - Training Epoch: 1/2, step 6600/107898 completed (loss: 2.0186691284179688, acc: 0.5555555820465088)
[2025-01-30 02:27:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6602/107898 [35:49<9:15:05,  3.04it/s][2025-01-30 02:27:59][root][INFO] - Training Epoch: 1/2, step 6601/107898 completed (loss: 1.59633207321167, acc: 0.6666666865348816)
[2025-01-30 02:27:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6603/107898 [35:50<9:31:34,  2.95it/s][2025-01-30 02:27:59][root][INFO] - Training Epoch: 1/2, step 6602/107898 completed (loss: 0.07210385054349899, acc: 1.0)
[2025-01-30 02:27:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6604/107898 [35:50<9:30:05,  2.96it/s][2025-01-30 02:28:00][root][INFO] - Training Epoch: 1/2, step 6603/107898 completed (loss: 0.21393142640590668, acc: 1.0)
[2025-01-30 02:28:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6605/107898 [35:50<9:18:10,  3.02it/s][2025-01-30 02:28:00][root][INFO] - Training Epoch: 1/2, step 6604/107898 completed (loss: 1.4488334655761719, acc: 0.8571428656578064)
[2025-01-30 02:28:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6606/107898 [35:51<9:18:21,  3.02it/s][2025-01-30 02:28:00][root][INFO] - Training Epoch: 1/2, step 6605/107898 completed (loss: 1.00680673122406, acc: 0.8799999952316284)
[2025-01-30 02:28:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6607/107898 [35:51<9:07:56,  3.08it/s][2025-01-30 02:28:01][root][INFO] - Training Epoch: 1/2, step 6606/107898 completed (loss: 0.5839038491249084, acc: 1.0)
[2025-01-30 02:28:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6608/107898 [35:51<9:20:15,  3.01it/s][2025-01-30 02:28:01][root][INFO] - Training Epoch: 1/2, step 6607/107898 completed (loss: 0.44185706973075867, acc: 1.0)
[2025-01-30 02:28:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6609/107898 [35:52<9:23:22,  3.00it/s][2025-01-30 02:28:01][root][INFO] - Training Epoch: 1/2, step 6608/107898 completed (loss: 0.3022316098213196, acc: 1.0)
[2025-01-30 02:28:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6610/107898 [35:52<9:12:45,  3.05it/s][2025-01-30 02:28:02][root][INFO] - Training Epoch: 1/2, step 6609/107898 completed (loss: 0.3715975284576416, acc: 1.0)
[2025-01-30 02:28:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6611/107898 [35:52<9:16:21,  3.03it/s][2025-01-30 02:28:02][root][INFO] - Training Epoch: 1/2, step 6610/107898 completed (loss: 0.29745739698410034, acc: 1.0)
[2025-01-30 02:28:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6612/107898 [35:53<9:17:52,  3.03it/s][2025-01-30 02:28:02][root][INFO] - Training Epoch: 1/2, step 6611/107898 completed (loss: 0.009155789390206337, acc: 1.0)
[2025-01-30 02:28:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6613/107898 [35:53<9:07:20,  3.08it/s][2025-01-30 02:28:03][root][INFO] - Training Epoch: 1/2, step 6612/107898 completed (loss: 1.9891074895858765, acc: 0.800000011920929)
[2025-01-30 02:28:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6614/107898 [35:53<8:53:36,  3.16it/s][2025-01-30 02:28:03][root][INFO] - Training Epoch: 1/2, step 6613/107898 completed (loss: 2.7793362140655518, acc: 0.6666666865348816)
[2025-01-30 02:28:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6615/107898 [35:53<8:50:38,  3.18it/s][2025-01-30 02:28:03][root][INFO] - Training Epoch: 1/2, step 6614/107898 completed (loss: 1.0058894157409668, acc: 0.7222222089767456)
[2025-01-30 02:28:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6616/107898 [35:54<8:52:36,  3.17it/s][2025-01-30 02:28:04][root][INFO] - Training Epoch: 1/2, step 6615/107898 completed (loss: 0.006559900473803282, acc: 1.0)
[2025-01-30 02:28:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6617/107898 [35:54<8:48:22,  3.19it/s][2025-01-30 02:28:04][root][INFO] - Training Epoch: 1/2, step 6616/107898 completed (loss: 0.0008859244408085942, acc: 1.0)
[2025-01-30 02:28:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6618/107898 [35:54<8:38:13,  3.26it/s][2025-01-30 02:28:04][root][INFO] - Training Epoch: 1/2, step 6617/107898 completed (loss: 0.27590513229370117, acc: 1.0)
[2025-01-30 02:28:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6619/107898 [35:55<8:31:49,  3.30it/s][2025-01-30 02:28:04][root][INFO] - Training Epoch: 1/2, step 6618/107898 completed (loss: 0.02457563392817974, acc: 1.0)
[2025-01-30 02:28:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6620/107898 [35:55<8:36:32,  3.27it/s][2025-01-30 02:28:05][root][INFO] - Training Epoch: 1/2, step 6619/107898 completed (loss: 0.08515749871730804, acc: 1.0)
[2025-01-30 02:28:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6621/107898 [35:55<8:25:32,  3.34it/s][2025-01-30 02:28:05][root][INFO] - Training Epoch: 1/2, step 6620/107898 completed (loss: 2.156465768814087, acc: 0.5)
[2025-01-30 02:28:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6622/107898 [35:56<8:28:29,  3.32it/s][2025-01-30 02:28:05][root][INFO] - Training Epoch: 1/2, step 6621/107898 completed (loss: 2.4648940563201904, acc: 0.5)
[2025-01-30 02:28:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6623/107898 [35:56<8:24:01,  3.35it/s][2025-01-30 02:28:06][root][INFO] - Training Epoch: 1/2, step 6622/107898 completed (loss: 0.008242574520409107, acc: 1.0)
[2025-01-30 02:28:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6624/107898 [35:56<8:27:14,  3.33it/s][2025-01-30 02:28:06][root][INFO] - Training Epoch: 1/2, step 6623/107898 completed (loss: 2.846555709838867, acc: 0.6666666865348816)
[2025-01-30 02:28:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6625/107898 [35:56<8:47:11,  3.20it/s][2025-01-30 02:28:06][root][INFO] - Training Epoch: 1/2, step 6624/107898 completed (loss: 0.16883425414562225, acc: 1.0)
[2025-01-30 02:28:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6626/107898 [35:57<8:55:46,  3.15it/s][2025-01-30 02:28:07][root][INFO] - Training Epoch: 1/2, step 6625/107898 completed (loss: 0.0017803546506911516, acc: 1.0)
[2025-01-30 02:28:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6627/107898 [35:57<8:58:42,  3.13it/s][2025-01-30 02:28:07][root][INFO] - Training Epoch: 1/2, step 6626/107898 completed (loss: 0.013480703346431255, acc: 1.0)
[2025-01-30 02:28:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6628/107898 [35:57<8:51:04,  3.18it/s][2025-01-30 02:28:07][root][INFO] - Training Epoch: 1/2, step 6627/107898 completed (loss: 2.2206971645355225, acc: 0.75)
[2025-01-30 02:28:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6629/107898 [35:58<8:43:47,  3.22it/s][2025-01-30 02:28:08][root][INFO] - Training Epoch: 1/2, step 6628/107898 completed (loss: 1.1084706783294678, acc: 0.8999999761581421)
[2025-01-30 02:28:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6630/107898 [35:58<8:50:10,  3.18it/s][2025-01-30 02:28:08][root][INFO] - Training Epoch: 1/2, step 6629/107898 completed (loss: 1.110632061958313, acc: 0.800000011920929)
[2025-01-30 02:28:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6631/107898 [35:58<8:36:52,  3.27it/s][2025-01-30 02:28:08][root][INFO] - Training Epoch: 1/2, step 6630/107898 completed (loss: 1.0534783601760864, acc: 0.6666666865348816)
[2025-01-30 02:28:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6632/107898 [35:59<8:31:16,  3.30it/s][2025-01-30 02:28:08][root][INFO] - Training Epoch: 1/2, step 6631/107898 completed (loss: 1.1230679750442505, acc: 0.6666666865348816)
[2025-01-30 02:28:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6633/107898 [35:59<8:34:28,  3.28it/s][2025-01-30 02:28:09][root][INFO] - Training Epoch: 1/2, step 6632/107898 completed (loss: 0.0534406341612339, acc: 1.0)
[2025-01-30 02:28:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6634/107898 [35:59<8:12:07,  3.43it/s][2025-01-30 02:28:09][root][INFO] - Training Epoch: 1/2, step 6633/107898 completed (loss: 0.7205080389976501, acc: 0.800000011920929)
[2025-01-30 02:28:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6635/107898 [35:59<8:00:11,  3.51it/s][2025-01-30 02:28:09][root][INFO] - Training Epoch: 1/2, step 6634/107898 completed (loss: 0.3984066843986511, acc: 1.0)
[2025-01-30 02:28:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6636/107898 [36:00<8:09:45,  3.45it/s][2025-01-30 02:28:10][root][INFO] - Training Epoch: 1/2, step 6635/107898 completed (loss: 0.8217926025390625, acc: 0.8181818127632141)
[2025-01-30 02:28:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6637/107898 [36:00<8:32:38,  3.29it/s][2025-01-30 02:28:10][root][INFO] - Training Epoch: 1/2, step 6636/107898 completed (loss: 0.8699269890785217, acc: 0.6666666865348816)
[2025-01-30 02:28:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6638/107898 [36:00<8:48:30,  3.19it/s][2025-01-30 02:28:10][root][INFO] - Training Epoch: 1/2, step 6637/107898 completed (loss: 2.7108395099639893, acc: 0.6111111044883728)
[2025-01-30 02:28:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6639/107898 [36:01<8:49:15,  3.19it/s][2025-01-30 02:28:11][root][INFO] - Training Epoch: 1/2, step 6638/107898 completed (loss: 0.0015947017818689346, acc: 1.0)
[2025-01-30 02:28:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6640/107898 [36:01<9:06:27,  3.09it/s][2025-01-30 02:28:11][root][INFO] - Training Epoch: 1/2, step 6639/107898 completed (loss: 5.15681791305542, acc: 0.3333333432674408)
[2025-01-30 02:28:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6641/107898 [36:01<9:04:18,  3.10it/s][2025-01-30 02:28:11][root][INFO] - Training Epoch: 1/2, step 6640/107898 completed (loss: 1.981087565422058, acc: 0.6666666865348816)
[2025-01-30 02:28:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6642/107898 [36:02<9:09:24,  3.07it/s][2025-01-30 02:28:12][root][INFO] - Training Epoch: 1/2, step 6641/107898 completed (loss: 0.08768892288208008, acc: 1.0)
[2025-01-30 02:28:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6643/107898 [36:02<9:33:52,  2.94it/s][2025-01-30 02:28:12][root][INFO] - Training Epoch: 1/2, step 6642/107898 completed (loss: 1.14198637008667, acc: 0.800000011920929)
[2025-01-30 02:28:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6644/107898 [36:02<9:29:14,  2.96it/s][2025-01-30 02:28:12][root][INFO] - Training Epoch: 1/2, step 6643/107898 completed (loss: 2.3371543884277344, acc: 0.5)
[2025-01-30 02:28:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6645/107898 [36:03<9:41:02,  2.90it/s][2025-01-30 02:28:13][root][INFO] - Training Epoch: 1/2, step 6644/107898 completed (loss: 1.5035194158554077, acc: 0.800000011920929)
[2025-01-30 02:28:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6646/107898 [36:03<10:00:26,  2.81it/s][2025-01-30 02:28:13][root][INFO] - Training Epoch: 1/2, step 6645/107898 completed (loss: 0.18260717391967773, acc: 0.8999999761581421)
[2025-01-30 02:28:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6647/107898 [36:04<10:07:37,  2.78it/s][2025-01-30 02:28:13][root][INFO] - Training Epoch: 1/2, step 6646/107898 completed (loss: 0.010585229843854904, acc: 1.0)
[2025-01-30 02:28:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6648/107898 [36:04<10:17:03,  2.73it/s][2025-01-30 02:28:14][root][INFO] - Training Epoch: 1/2, step 6647/107898 completed (loss: 1.525051236152649, acc: 0.7200000286102295)
[2025-01-30 02:28:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6649/107898 [36:04<9:44:07,  2.89it/s] [2025-01-30 02:28:14][root][INFO] - Training Epoch: 1/2, step 6648/107898 completed (loss: 0.08813460171222687, acc: 1.0)
[2025-01-30 02:28:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6650/107898 [36:05<9:49:25,  2.86it/s][2025-01-30 02:28:14][root][INFO] - Training Epoch: 1/2, step 6649/107898 completed (loss: 0.5936817526817322, acc: 0.8666666746139526)
[2025-01-30 02:28:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6651/107898 [36:05<9:38:51,  2.92it/s][2025-01-30 02:28:15][root][INFO] - Training Epoch: 1/2, step 6650/107898 completed (loss: 0.24940155446529388, acc: 1.0)
[2025-01-30 02:28:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6652/107898 [36:05<9:27:24,  2.97it/s][2025-01-30 02:28:15][root][INFO] - Training Epoch: 1/2, step 6651/107898 completed (loss: 1.0730868577957153, acc: 0.7272727489471436)
[2025-01-30 02:28:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6653/107898 [36:06<8:57:46,  3.14it/s][2025-01-30 02:28:15][root][INFO] - Training Epoch: 1/2, step 6652/107898 completed (loss: 0.351296067237854, acc: 0.9090909361839294)
[2025-01-30 02:28:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6654/107898 [36:06<8:49:57,  3.18it/s][2025-01-30 02:28:16][root][INFO] - Training Epoch: 1/2, step 6653/107898 completed (loss: 2.300678014755249, acc: 0.75)
[2025-01-30 02:28:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6655/107898 [36:06<9:00:23,  3.12it/s][2025-01-30 02:28:16][root][INFO] - Training Epoch: 1/2, step 6654/107898 completed (loss: 0.8571891784667969, acc: 0.75)
[2025-01-30 02:28:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6656/107898 [36:06<8:55:45,  3.15it/s][2025-01-30 02:28:16][root][INFO] - Training Epoch: 1/2, step 6655/107898 completed (loss: 0.7225432991981506, acc: 1.0)
[2025-01-30 02:28:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6657/107898 [36:07<8:53:02,  3.17it/s][2025-01-30 02:28:17][root][INFO] - Training Epoch: 1/2, step 6656/107898 completed (loss: 1.0514644384384155, acc: 0.800000011920929)
[2025-01-30 02:28:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6658/107898 [36:07<9:09:55,  3.07it/s][2025-01-30 02:28:17][root][INFO] - Training Epoch: 1/2, step 6657/107898 completed (loss: 0.20185180008411407, acc: 1.0)
[2025-01-30 02:28:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6659/107898 [36:08<9:33:00,  2.94it/s][2025-01-30 02:28:17][root][INFO] - Training Epoch: 1/2, step 6658/107898 completed (loss: 1.0639499425888062, acc: 0.7142857313156128)
[2025-01-30 02:28:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6660/107898 [36:08<9:38:50,  2.91it/s][2025-01-30 02:28:18][root][INFO] - Training Epoch: 1/2, step 6659/107898 completed (loss: 0.3857288956642151, acc: 0.8999999761581421)
[2025-01-30 02:28:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6661/107898 [36:08<9:18:48,  3.02it/s][2025-01-30 02:28:18][root][INFO] - Training Epoch: 1/2, step 6660/107898 completed (loss: 1.0013504028320312, acc: 0.5)
[2025-01-30 02:28:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6662/107898 [36:09<9:33:11,  2.94it/s][2025-01-30 02:28:18][root][INFO] - Training Epoch: 1/2, step 6661/107898 completed (loss: 2.0099096298217773, acc: 0.6666666865348816)
[2025-01-30 02:28:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6663/107898 [36:09<9:27:53,  2.97it/s][2025-01-30 02:28:19][root][INFO] - Training Epoch: 1/2, step 6662/107898 completed (loss: 1.6174978017807007, acc: 0.5)
[2025-01-30 02:28:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6664/107898 [36:09<8:53:24,  3.16it/s][2025-01-30 02:28:19][root][INFO] - Training Epoch: 1/2, step 6663/107898 completed (loss: 0.7757160663604736, acc: 1.0)
[2025-01-30 02:28:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6665/107898 [36:09<8:51:27,  3.17it/s][2025-01-30 02:28:19][root][INFO] - Training Epoch: 1/2, step 6664/107898 completed (loss: 1.560588002204895, acc: 0.6666666865348816)
[2025-01-30 02:28:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6666/107898 [36:10<8:42:09,  3.23it/s][2025-01-30 02:28:20][root][INFO] - Training Epoch: 1/2, step 6665/107898 completed (loss: 0.6731688380241394, acc: 0.9166666865348816)
[2025-01-30 02:28:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6667/107898 [36:10<8:46:02,  3.21it/s][2025-01-30 02:28:20][root][INFO] - Training Epoch: 1/2, step 6666/107898 completed (loss: 0.9051920771598816, acc: 0.8387096524238586)
[2025-01-30 02:28:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6668/107898 [36:10<8:49:55,  3.18it/s][2025-01-30 02:28:20][root][INFO] - Training Epoch: 1/2, step 6667/107898 completed (loss: 0.6260979175567627, acc: 1.0)
[2025-01-30 02:28:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6669/107898 [36:11<8:44:32,  3.22it/s][2025-01-30 02:28:20][root][INFO] - Training Epoch: 1/2, step 6668/107898 completed (loss: 4.615962028503418, acc: 0.20000000298023224)
[2025-01-30 02:28:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6670/107898 [36:11<9:03:42,  3.10it/s][2025-01-30 02:28:21][root][INFO] - Training Epoch: 1/2, step 6669/107898 completed (loss: 0.7869422435760498, acc: 0.6666666865348816)
[2025-01-30 02:28:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6671/107898 [36:11<9:20:56,  3.01it/s][2025-01-30 02:28:21][root][INFO] - Training Epoch: 1/2, step 6670/107898 completed (loss: 3.353128671646118, acc: 0.3333333432674408)
[2025-01-30 02:28:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6672/107898 [36:12<9:31:01,  2.95it/s][2025-01-30 02:28:22][root][INFO] - Training Epoch: 1/2, step 6671/107898 completed (loss: 0.12216150760650635, acc: 1.0)
[2025-01-30 02:28:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6673/107898 [36:12<9:28:11,  2.97it/s][2025-01-30 02:28:22][root][INFO] - Training Epoch: 1/2, step 6672/107898 completed (loss: 1.0287867784500122, acc: 0.8333333134651184)
[2025-01-30 02:28:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6674/107898 [36:12<9:27:58,  2.97it/s][2025-01-30 02:28:22][root][INFO] - Training Epoch: 1/2, step 6673/107898 completed (loss: 0.2302665263414383, acc: 1.0)
[2025-01-30 02:28:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6675/107898 [36:13<9:28:09,  2.97it/s][2025-01-30 02:28:23][root][INFO] - Training Epoch: 1/2, step 6674/107898 completed (loss: 0.5436682105064392, acc: 0.6666666865348816)
[2025-01-30 02:28:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6676/107898 [36:13<9:15:13,  3.04it/s][2025-01-30 02:28:23][root][INFO] - Training Epoch: 1/2, step 6675/107898 completed (loss: 0.03368804231286049, acc: 1.0)
[2025-01-30 02:28:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6677/107898 [36:13<9:08:06,  3.08it/s][2025-01-30 02:28:23][root][INFO] - Training Epoch: 1/2, step 6676/107898 completed (loss: 1.2604864835739136, acc: 0.8571428656578064)
[2025-01-30 02:28:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6678/107898 [36:14<8:58:10,  3.13it/s][2025-01-30 02:28:23][root][INFO] - Training Epoch: 1/2, step 6677/107898 completed (loss: 0.43787556886672974, acc: 0.8148148059844971)
[2025-01-30 02:28:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6679/107898 [36:14<8:43:03,  3.23it/s][2025-01-30 02:28:24][root][INFO] - Training Epoch: 1/2, step 6678/107898 completed (loss: 0.5560874342918396, acc: 0.6666666865348816)
[2025-01-30 02:28:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6680/107898 [36:14<8:42:40,  3.23it/s][2025-01-30 02:28:24][root][INFO] - Training Epoch: 1/2, step 6679/107898 completed (loss: 0.19045092165470123, acc: 1.0)
[2025-01-30 02:28:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6681/107898 [36:15<8:17:29,  3.39it/s][2025-01-30 02:28:24][root][INFO] - Training Epoch: 1/2, step 6680/107898 completed (loss: 2.5434489250183105, acc: 0.3333333432674408)
[2025-01-30 02:28:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6682/107898 [36:15<8:11:42,  3.43it/s][2025-01-30 02:28:25][root][INFO] - Training Epoch: 1/2, step 6681/107898 completed (loss: 0.4339425563812256, acc: 0.6666666865348816)
[2025-01-30 02:28:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6683/107898 [36:15<8:41:44,  3.23it/s][2025-01-30 02:28:25][root][INFO] - Training Epoch: 1/2, step 6682/107898 completed (loss: 0.12806187570095062, acc: 1.0)
[2025-01-30 02:28:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6684/107898 [36:15<8:51:03,  3.18it/s][2025-01-30 02:28:25][root][INFO] - Training Epoch: 1/2, step 6683/107898 completed (loss: 0.012265974655747414, acc: 1.0)
[2025-01-30 02:28:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6685/107898 [36:16<8:44:26,  3.22it/s][2025-01-30 02:28:26][root][INFO] - Training Epoch: 1/2, step 6684/107898 completed (loss: 0.7167305946350098, acc: 0.7647058963775635)
[2025-01-30 02:28:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6686/107898 [36:16<9:00:46,  3.12it/s][2025-01-30 02:28:26][root][INFO] - Training Epoch: 1/2, step 6685/107898 completed (loss: 0.2880789339542389, acc: 0.6666666865348816)
[2025-01-30 02:28:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6687/107898 [36:16<9:08:10,  3.08it/s][2025-01-30 02:28:26][root][INFO] - Training Epoch: 1/2, step 6686/107898 completed (loss: 0.19252212345600128, acc: 1.0)
[2025-01-30 02:28:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6688/107898 [36:17<9:05:41,  3.09it/s][2025-01-30 02:28:27][root][INFO] - Training Epoch: 1/2, step 6687/107898 completed (loss: 0.5266724228858948, acc: 0.8500000238418579)
[2025-01-30 02:28:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6689/107898 [36:17<9:18:56,  3.02it/s][2025-01-30 02:28:27][root][INFO] - Training Epoch: 1/2, step 6688/107898 completed (loss: 0.7269871830940247, acc: 0.6666666865348816)
[2025-01-30 02:28:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6690/107898 [36:17<9:20:52,  3.01it/s][2025-01-30 02:28:27][root][INFO] - Training Epoch: 1/2, step 6689/107898 completed (loss: 0.22391556203365326, acc: 1.0)
[2025-01-30 02:28:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6691/107898 [36:18<9:26:37,  2.98it/s][2025-01-30 02:28:28][root][INFO] - Training Epoch: 1/2, step 6690/107898 completed (loss: 2.114252805709839, acc: 0.3333333432674408)
[2025-01-30 02:28:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6692/107898 [36:18<9:22:12,  3.00it/s][2025-01-30 02:28:28][root][INFO] - Training Epoch: 1/2, step 6691/107898 completed (loss: 0.5362606644630432, acc: 0.6666666865348816)
[2025-01-30 02:28:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6693/107898 [36:19<9:29:17,  2.96it/s][2025-01-30 02:28:28][root][INFO] - Training Epoch: 1/2, step 6692/107898 completed (loss: 0.04796477034687996, acc: 1.0)
[2025-01-30 02:28:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6694/107898 [36:19<9:26:57,  2.98it/s][2025-01-30 02:28:29][root][INFO] - Training Epoch: 1/2, step 6693/107898 completed (loss: 0.024971207603812218, acc: 1.0)
[2025-01-30 02:28:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6695/107898 [36:19<9:14:59,  3.04it/s][2025-01-30 02:28:29][root][INFO] - Training Epoch: 1/2, step 6694/107898 completed (loss: 1.739682912826538, acc: 0.695652186870575)
[2025-01-30 02:28:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6696/107898 [36:19<9:05:19,  3.09it/s][2025-01-30 02:28:29][root][INFO] - Training Epoch: 1/2, step 6695/107898 completed (loss: 0.05359472706913948, acc: 1.0)
[2025-01-30 02:28:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6697/107898 [36:20<8:51:50,  3.17it/s][2025-01-30 02:28:30][root][INFO] - Training Epoch: 1/2, step 6696/107898 completed (loss: 1.9311482906341553, acc: 0.7142857313156128)
[2025-01-30 02:28:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6698/107898 [36:20<9:15:28,  3.04it/s][2025-01-30 02:28:30][root][INFO] - Training Epoch: 1/2, step 6697/107898 completed (loss: 1.0094720125198364, acc: 0.7777777910232544)
[2025-01-30 02:28:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6699/107898 [36:20<9:16:37,  3.03it/s][2025-01-30 02:28:30][root][INFO] - Training Epoch: 1/2, step 6698/107898 completed (loss: 0.6042172312736511, acc: 0.8695651888847351)
[2025-01-30 02:28:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6700/107898 [36:21<9:06:37,  3.09it/s][2025-01-30 02:28:31][root][INFO] - Training Epoch: 1/2, step 6699/107898 completed (loss: 3.518376588821411, acc: 0.20000000298023224)
[2025-01-30 02:28:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6701/107898 [36:21<9:43:33,  2.89it/s][2025-01-30 02:28:31][root][INFO] - Training Epoch: 1/2, step 6700/107898 completed (loss: 0.016258686780929565, acc: 1.0)
[2025-01-30 02:28:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6702/107898 [36:21<9:30:29,  2.96it/s][2025-01-30 02:28:31][root][INFO] - Training Epoch: 1/2, step 6701/107898 completed (loss: 2.490561008453369, acc: 0.0)
[2025-01-30 02:28:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6703/107898 [36:22<9:42:06,  2.90it/s][2025-01-30 02:28:32][root][INFO] - Training Epoch: 1/2, step 6702/107898 completed (loss: 0.9609150886535645, acc: 0.8999999761581421)
[2025-01-30 02:28:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6704/107898 [36:22<9:55:16,  2.83it/s][2025-01-30 02:28:32][root][INFO] - Training Epoch: 1/2, step 6703/107898 completed (loss: 1.3291611671447754, acc: 0.75)
[2025-01-30 02:28:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6705/107898 [36:23<9:45:31,  2.88it/s][2025-01-30 02:28:32][root][INFO] - Training Epoch: 1/2, step 6704/107898 completed (loss: 0.4183157682418823, acc: 0.6666666865348816)
[2025-01-30 02:28:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6706/107898 [36:23<9:33:53,  2.94it/s][2025-01-30 02:28:33][root][INFO] - Training Epoch: 1/2, step 6705/107898 completed (loss: 2.383517265319824, acc: 0.7272727489471436)
[2025-01-30 02:28:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6707/107898 [36:23<9:44:24,  2.89it/s][2025-01-30 02:28:33][root][INFO] - Training Epoch: 1/2, step 6706/107898 completed (loss: 0.2044614851474762, acc: 1.0)
[2025-01-30 02:28:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6708/107898 [36:24<9:37:29,  2.92it/s][2025-01-30 02:28:33][root][INFO] - Training Epoch: 1/2, step 6707/107898 completed (loss: 0.018401531502604485, acc: 1.0)
[2025-01-30 02:28:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6709/107898 [36:24<9:45:05,  2.88it/s][2025-01-30 02:28:34][root][INFO] - Training Epoch: 1/2, step 6708/107898 completed (loss: 1.6793042421340942, acc: 0.7037037014961243)
[2025-01-30 02:28:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6710/107898 [36:24<9:15:51,  3.03it/s][2025-01-30 02:28:34][root][INFO] - Training Epoch: 1/2, step 6709/107898 completed (loss: 0.03561607748270035, acc: 1.0)
[2025-01-30 02:28:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6711/107898 [36:25<9:01:17,  3.12it/s][2025-01-30 02:28:34][root][INFO] - Training Epoch: 1/2, step 6710/107898 completed (loss: 0.2791003882884979, acc: 0.9090909361839294)
[2025-01-30 02:28:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6712/107898 [36:25<8:48:24,  3.19it/s][2025-01-30 02:28:35][root][INFO] - Training Epoch: 1/2, step 6711/107898 completed (loss: 0.457635760307312, acc: 1.0)
[2025-01-30 02:28:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6713/107898 [36:25<8:42:06,  3.23it/s][2025-01-30 02:28:35][root][INFO] - Training Epoch: 1/2, step 6712/107898 completed (loss: 0.6081202626228333, acc: 0.9166666865348816)
[2025-01-30 02:28:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6714/107898 [36:25<8:33:46,  3.28it/s][2025-01-30 02:28:35][root][INFO] - Training Epoch: 1/2, step 6713/107898 completed (loss: 0.04898853600025177, acc: 1.0)
[2025-01-30 02:28:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6715/107898 [36:26<8:41:48,  3.23it/s][2025-01-30 02:28:36][root][INFO] - Training Epoch: 1/2, step 6714/107898 completed (loss: 1.0703045129776, acc: 0.7857142686843872)
[2025-01-30 02:28:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6716/107898 [36:26<8:36:07,  3.27it/s][2025-01-30 02:28:36][root][INFO] - Training Epoch: 1/2, step 6715/107898 completed (loss: 0.018957417458295822, acc: 1.0)
[2025-01-30 02:28:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6717/107898 [36:26<8:33:08,  3.29it/s][2025-01-30 02:28:36][root][INFO] - Training Epoch: 1/2, step 6716/107898 completed (loss: 0.090522900223732, acc: 1.0)
[2025-01-30 02:28:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6718/107898 [36:27<8:39:26,  3.25it/s][2025-01-30 02:28:36][root][INFO] - Training Epoch: 1/2, step 6717/107898 completed (loss: 1.3677966594696045, acc: 0.8235294222831726)
[2025-01-30 02:28:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6719/107898 [36:27<8:43:23,  3.22it/s][2025-01-30 02:28:37][root][INFO] - Training Epoch: 1/2, step 6718/107898 completed (loss: 1.685181975364685, acc: 0.6666666865348816)
[2025-01-30 02:28:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6720/107898 [36:27<8:35:26,  3.27it/s][2025-01-30 02:28:37][root][INFO] - Training Epoch: 1/2, step 6719/107898 completed (loss: 0.07196944206953049, acc: 1.0)
[2025-01-30 02:28:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6721/107898 [36:28<8:53:05,  3.16it/s][2025-01-30 02:28:37][root][INFO] - Training Epoch: 1/2, step 6720/107898 completed (loss: 0.3259073793888092, acc: 0.9333333373069763)
[2025-01-30 02:28:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6722/107898 [36:28<8:57:39,  3.14it/s][2025-01-30 02:28:38][root][INFO] - Training Epoch: 1/2, step 6721/107898 completed (loss: 0.9465398788452148, acc: 0.8636363744735718)
[2025-01-30 02:28:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6723/107898 [36:28<9:10:15,  3.06it/s][2025-01-30 02:28:38][root][INFO] - Training Epoch: 1/2, step 6722/107898 completed (loss: 0.02907041274011135, acc: 1.0)
[2025-01-30 02:28:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6724/107898 [36:29<9:10:40,  3.06it/s][2025-01-30 02:28:38][root][INFO] - Training Epoch: 1/2, step 6723/107898 completed (loss: 1.8789745569229126, acc: 0.5454545617103577)
[2025-01-30 02:28:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6725/107898 [36:29<8:59:31,  3.13it/s][2025-01-30 02:28:39][root][INFO] - Training Epoch: 1/2, step 6724/107898 completed (loss: 0.03626848757266998, acc: 1.0)
[2025-01-30 02:28:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6726/107898 [36:29<9:04:59,  3.09it/s][2025-01-30 02:28:39][root][INFO] - Training Epoch: 1/2, step 6725/107898 completed (loss: 1.3247448205947876, acc: 0.6875)
[2025-01-30 02:28:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6727/107898 [36:30<8:46:58,  3.20it/s][2025-01-30 02:28:39][root][INFO] - Training Epoch: 1/2, step 6726/107898 completed (loss: 2.043466567993164, acc: 0.699999988079071)
[2025-01-30 02:28:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6728/107898 [36:30<8:39:39,  3.24it/s][2025-01-30 02:28:40][root][INFO] - Training Epoch: 1/2, step 6727/107898 completed (loss: 0.20619432628154755, acc: 0.8999999761581421)
[2025-01-30 02:28:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6729/107898 [36:30<8:48:14,  3.19it/s][2025-01-30 02:28:40][root][INFO] - Training Epoch: 1/2, step 6728/107898 completed (loss: 1.857595443725586, acc: 0.5)
[2025-01-30 02:28:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6730/107898 [36:30<9:12:35,  3.05it/s][2025-01-30 02:28:40][root][INFO] - Training Epoch: 1/2, step 6729/107898 completed (loss: 2.2852559089660645, acc: 0.6666666865348816)
[2025-01-30 02:28:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6731/107898 [36:31<9:25:05,  2.98it/s][2025-01-30 02:28:41][root][INFO] - Training Epoch: 1/2, step 6730/107898 completed (loss: 1.2966135740280151, acc: 0.6071428656578064)
[2025-01-30 02:28:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6732/107898 [36:31<9:14:08,  3.04it/s][2025-01-30 02:28:41][root][INFO] - Training Epoch: 1/2, step 6731/107898 completed (loss: 2.4202985763549805, acc: 0.3333333432674408)
[2025-01-30 02:28:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6733/107898 [36:31<9:21:20,  3.00it/s][2025-01-30 02:28:41][root][INFO] - Training Epoch: 1/2, step 6732/107898 completed (loss: 0.23419275879859924, acc: 1.0)
[2025-01-30 02:28:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6734/107898 [36:32<9:17:52,  3.02it/s][2025-01-30 02:28:42][root][INFO] - Training Epoch: 1/2, step 6733/107898 completed (loss: 1.3807247877120972, acc: 0.800000011920929)
[2025-01-30 02:28:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6735/107898 [36:32<8:59:38,  3.12it/s][2025-01-30 02:28:42][root][INFO] - Training Epoch: 1/2, step 6734/107898 completed (loss: 0.3014092743396759, acc: 1.0)
[2025-01-30 02:28:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6736/107898 [36:32<9:26:17,  2.98it/s][2025-01-30 02:28:42][root][INFO] - Training Epoch: 1/2, step 6735/107898 completed (loss: 0.2924070656299591, acc: 1.0)
[2025-01-30 02:28:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6737/107898 [36:33<9:20:23,  3.01it/s][2025-01-30 02:28:43][root][INFO] - Training Epoch: 1/2, step 6736/107898 completed (loss: 0.49138161540031433, acc: 0.800000011920929)
[2025-01-30 02:28:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6738/107898 [36:33<9:29:49,  2.96it/s][2025-01-30 02:28:43][root][INFO] - Training Epoch: 1/2, step 6737/107898 completed (loss: 0.49617767333984375, acc: 1.0)
[2025-01-30 02:28:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6739/107898 [36:33<9:17:56,  3.02it/s][2025-01-30 02:28:43][root][INFO] - Training Epoch: 1/2, step 6738/107898 completed (loss: 4.388338088989258, acc: 0.5)
[2025-01-30 02:28:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6740/107898 [36:34<9:19:18,  3.01it/s][2025-01-30 02:28:44][root][INFO] - Training Epoch: 1/2, step 6739/107898 completed (loss: 1.5489495992660522, acc: 0.7777777910232544)
[2025-01-30 02:28:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6741/107898 [36:34<9:01:15,  3.11it/s][2025-01-30 02:28:44][root][INFO] - Training Epoch: 1/2, step 6740/107898 completed (loss: 1.5255632400512695, acc: 0.6666666865348816)
[2025-01-30 02:28:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6742/107898 [36:34<8:59:49,  3.12it/s][2025-01-30 02:28:44][root][INFO] - Training Epoch: 1/2, step 6741/107898 completed (loss: 0.08783340454101562, acc: 1.0)
[2025-01-30 02:28:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–Œ         [0m| 6743/107898 [36:35<8:46:44,  3.20it/s][2025-01-30 02:28:45][root][INFO] - Training Epoch: 1/2, step 6742/107898 completed (loss: 0.23442129790782928, acc: 1.0)
[2025-01-30 02:28:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6744/107898 [36:35<8:38:55,  3.25it/s][2025-01-30 02:28:45][root][INFO] - Training Epoch: 1/2, step 6743/107898 completed (loss: 0.010124798864126205, acc: 1.0)
[2025-01-30 02:28:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6745/107898 [36:35<8:34:35,  3.28it/s][2025-01-30 02:28:45][root][INFO] - Training Epoch: 1/2, step 6744/107898 completed (loss: 2.4855406284332275, acc: 0.3636363744735718)
[2025-01-30 02:28:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6746/107898 [36:36<8:42:50,  3.22it/s][2025-01-30 02:28:45][root][INFO] - Training Epoch: 1/2, step 6745/107898 completed (loss: 0.12275911867618561, acc: 1.0)
[2025-01-30 02:28:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6747/107898 [36:36<8:50:40,  3.18it/s][2025-01-30 02:28:46][root][INFO] - Training Epoch: 1/2, step 6746/107898 completed (loss: 1.0497386455535889, acc: 0.75)
[2025-01-30 02:28:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6748/107898 [36:36<8:59:08,  3.13it/s][2025-01-30 02:28:46][root][INFO] - Training Epoch: 1/2, step 6747/107898 completed (loss: 0.13551633059978485, acc: 1.0)
[2025-01-30 02:28:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6749/107898 [36:37<9:00:54,  3.12it/s][2025-01-30 02:28:46][root][INFO] - Training Epoch: 1/2, step 6748/107898 completed (loss: 2.5284464359283447, acc: 0.6111111044883728)
[2025-01-30 02:28:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6750/107898 [36:37<9:11:27,  3.06it/s][2025-01-30 02:28:47][root][INFO] - Training Epoch: 1/2, step 6749/107898 completed (loss: 2.588682174682617, acc: 0.550000011920929)
[2025-01-30 02:28:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6751/107898 [36:37<9:13:43,  3.04it/s][2025-01-30 02:28:47][root][INFO] - Training Epoch: 1/2, step 6750/107898 completed (loss: 1.312961459159851, acc: 0.5)
[2025-01-30 02:28:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6752/107898 [36:38<9:11:37,  3.06it/s][2025-01-30 02:28:47][root][INFO] - Training Epoch: 1/2, step 6751/107898 completed (loss: 3.746060609817505, acc: 0.20000000298023224)
[2025-01-30 02:28:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6753/107898 [36:38<9:23:17,  2.99it/s][2025-01-30 02:28:48][root][INFO] - Training Epoch: 1/2, step 6752/107898 completed (loss: 1.2098898887634277, acc: 0.7777777910232544)
[2025-01-30 02:28:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6754/107898 [36:38<9:24:30,  2.99it/s][2025-01-30 02:28:48][root][INFO] - Training Epoch: 1/2, step 6753/107898 completed (loss: 0.018000980839133263, acc: 1.0)
[2025-01-30 02:28:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6755/107898 [36:39<9:12:38,  3.05it/s][2025-01-30 02:28:48][root][INFO] - Training Epoch: 1/2, step 6754/107898 completed (loss: 1.1420034170150757, acc: 0.875)
[2025-01-30 02:28:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6756/107898 [36:39<9:22:41,  3.00it/s][2025-01-30 02:28:49][root][INFO] - Training Epoch: 1/2, step 6755/107898 completed (loss: 4.014828205108643, acc: 0.3333333432674408)
[2025-01-30 02:28:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6757/107898 [36:39<9:23:36,  2.99it/s][2025-01-30 02:28:49][root][INFO] - Training Epoch: 1/2, step 6756/107898 completed (loss: 0.021702192723751068, acc: 1.0)
[2025-01-30 02:28:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6758/107898 [36:40<9:20:32,  3.01it/s][2025-01-30 02:28:49][root][INFO] - Training Epoch: 1/2, step 6757/107898 completed (loss: 2.9178993701934814, acc: 0.25)
[2025-01-30 02:28:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6759/107898 [36:40<9:22:54,  2.99it/s][2025-01-30 02:28:50][root][INFO] - Training Epoch: 1/2, step 6758/107898 completed (loss: 0.18994218111038208, acc: 1.0)
[2025-01-30 02:28:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6760/107898 [36:40<9:04:41,  3.09it/s][2025-01-30 02:28:50][root][INFO] - Training Epoch: 1/2, step 6759/107898 completed (loss: 0.025851814076304436, acc: 1.0)
[2025-01-30 02:28:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6761/107898 [36:41<8:59:44,  3.12it/s][2025-01-30 02:28:50][root][INFO] - Training Epoch: 1/2, step 6760/107898 completed (loss: 3.4963181018829346, acc: 0.5)
[2025-01-30 02:28:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6762/107898 [36:41<8:30:41,  3.30it/s][2025-01-30 02:28:51][root][INFO] - Training Epoch: 1/2, step 6761/107898 completed (loss: 1.1261461973190308, acc: 0.7142857313156128)
[2025-01-30 02:28:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6763/107898 [36:41<8:44:32,  3.21it/s][2025-01-30 02:28:51][root][INFO] - Training Epoch: 1/2, step 6762/107898 completed (loss: 0.8713486790657043, acc: 0.5)
[2025-01-30 02:28:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6764/107898 [36:41<8:42:41,  3.22it/s][2025-01-30 02:28:51][root][INFO] - Training Epoch: 1/2, step 6763/107898 completed (loss: 0.7470086216926575, acc: 0.6666666865348816)
[2025-01-30 02:28:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6765/107898 [36:42<8:35:11,  3.27it/s][2025-01-30 02:28:52][root][INFO] - Training Epoch: 1/2, step 6764/107898 completed (loss: 0.4626193940639496, acc: 0.8333333134651184)
[2025-01-30 02:28:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6766/107898 [36:42<8:52:23,  3.17it/s][2025-01-30 02:28:52][root][INFO] - Training Epoch: 1/2, step 6765/107898 completed (loss: 0.5650821924209595, acc: 0.800000011920929)
[2025-01-30 02:28:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6767/107898 [36:42<8:46:35,  3.20it/s][2025-01-30 02:28:52][root][INFO] - Training Epoch: 1/2, step 6766/107898 completed (loss: 0.1311364322900772, acc: 1.0)
[2025-01-30 02:28:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6768/107898 [36:43<8:42:59,  3.22it/s][2025-01-30 02:28:53][root][INFO] - Training Epoch: 1/2, step 6767/107898 completed (loss: 0.37166017293930054, acc: 0.9230769276618958)
[2025-01-30 02:28:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6769/107898 [36:43<8:26:33,  3.33it/s][2025-01-30 02:28:53][root][INFO] - Training Epoch: 1/2, step 6768/107898 completed (loss: 0.22432579100131989, acc: 1.0)
[2025-01-30 02:28:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6770/107898 [36:43<8:29:18,  3.31it/s][2025-01-30 02:28:53][root][INFO] - Training Epoch: 1/2, step 6769/107898 completed (loss: 1.7072772979736328, acc: 0.6666666865348816)
[2025-01-30 02:28:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6771/107898 [36:44<8:30:25,  3.30it/s][2025-01-30 02:28:53][root][INFO] - Training Epoch: 1/2, step 6770/107898 completed (loss: 1.3649989366531372, acc: 0.7083333134651184)
[2025-01-30 02:28:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6772/107898 [36:44<8:30:00,  3.30it/s][2025-01-30 02:28:54][root][INFO] - Training Epoch: 1/2, step 6771/107898 completed (loss: 1.8019136190414429, acc: 0.7222222089767456)
[2025-01-30 02:28:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6773/107898 [36:44<8:26:03,  3.33it/s][2025-01-30 02:28:54][root][INFO] - Training Epoch: 1/2, step 6772/107898 completed (loss: 0.0646212249994278, acc: 1.0)
[2025-01-30 02:28:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6774/107898 [36:45<8:26:25,  3.33it/s][2025-01-30 02:28:54][root][INFO] - Training Epoch: 1/2, step 6773/107898 completed (loss: 0.3640175759792328, acc: 1.0)
[2025-01-30 02:28:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6775/107898 [36:45<8:31:25,  3.30it/s][2025-01-30 02:28:55][root][INFO] - Training Epoch: 1/2, step 6774/107898 completed (loss: 1.14303719997406, acc: 0.7777777910232544)
[2025-01-30 02:28:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6776/107898 [36:45<8:49:46,  3.18it/s][2025-01-30 02:28:55][root][INFO] - Training Epoch: 1/2, step 6775/107898 completed (loss: 2.154865264892578, acc: 0.6363636255264282)
[2025-01-30 02:28:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6777/107898 [36:45<8:46:09,  3.20it/s][2025-01-30 02:28:55][root][INFO] - Training Epoch: 1/2, step 6776/107898 completed (loss: 1.1431232690811157, acc: 0.7142857313156128)
[2025-01-30 02:28:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6778/107898 [36:46<8:36:24,  3.26it/s][2025-01-30 02:28:56][root][INFO] - Training Epoch: 1/2, step 6777/107898 completed (loss: 1.1973795890808105, acc: 0.7692307829856873)
[2025-01-30 02:28:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6779/107898 [36:46<8:42:44,  3.22it/s][2025-01-30 02:28:56][root][INFO] - Training Epoch: 1/2, step 6778/107898 completed (loss: 0.3391728401184082, acc: 0.9047619104385376)
[2025-01-30 02:28:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6780/107898 [36:46<8:42:48,  3.22it/s][2025-01-30 02:28:56][root][INFO] - Training Epoch: 1/2, step 6779/107898 completed (loss: 0.48013871908187866, acc: 1.0)
[2025-01-30 02:28:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6781/107898 [36:47<8:37:50,  3.25it/s][2025-01-30 02:28:56][root][INFO] - Training Epoch: 1/2, step 6780/107898 completed (loss: 1.178748369216919, acc: 0.75)
[2025-01-30 02:28:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6782/107898 [36:47<8:57:11,  3.14it/s][2025-01-30 02:28:57][root][INFO] - Training Epoch: 1/2, step 6781/107898 completed (loss: 2.511699676513672, acc: 0.5714285969734192)
[2025-01-30 02:28:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6783/107898 [36:47<9:05:16,  3.09it/s][2025-01-30 02:28:57][root][INFO] - Training Epoch: 1/2, step 6782/107898 completed (loss: 1.4231617450714111, acc: 0.7692307829856873)
[2025-01-30 02:28:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6784/107898 [36:48<9:11:14,  3.06it/s][2025-01-30 02:28:57][root][INFO] - Training Epoch: 1/2, step 6783/107898 completed (loss: 0.9456475377082825, acc: 0.800000011920929)
[2025-01-30 02:28:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6785/107898 [36:48<9:15:13,  3.04it/s][2025-01-30 02:28:58][root][INFO] - Training Epoch: 1/2, step 6784/107898 completed (loss: 1.310272455215454, acc: 0.8125)
[2025-01-30 02:28:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6786/107898 [36:48<9:28:46,  2.96it/s][2025-01-30 02:28:58][root][INFO] - Training Epoch: 1/2, step 6785/107898 completed (loss: 1.7230178117752075, acc: 0.5714285969734192)
[2025-01-30 02:28:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6787/107898 [36:49<9:29:26,  2.96it/s][2025-01-30 02:28:59][root][INFO] - Training Epoch: 1/2, step 6786/107898 completed (loss: 0.759560763835907, acc: 0.9090909361839294)
[2025-01-30 02:28:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6788/107898 [36:49<9:23:25,  2.99it/s][2025-01-30 02:28:59][root][INFO] - Training Epoch: 1/2, step 6787/107898 completed (loss: 1.4937697649002075, acc: 0.782608687877655)
[2025-01-30 02:28:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6789/107898 [36:49<9:02:08,  3.11it/s][2025-01-30 02:28:59][root][INFO] - Training Epoch: 1/2, step 6788/107898 completed (loss: 0.06318443268537521, acc: 1.0)
[2025-01-30 02:28:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6790/107898 [36:50<8:54:34,  3.15it/s][2025-01-30 02:28:59][root][INFO] - Training Epoch: 1/2, step 6789/107898 completed (loss: 0.7054983377456665, acc: 0.7272727489471436)
[2025-01-30 02:29:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6791/107898 [36:50<9:13:20,  3.05it/s][2025-01-30 02:29:00][root][INFO] - Training Epoch: 1/2, step 6790/107898 completed (loss: 0.8853945732116699, acc: 1.0)
[2025-01-30 02:29:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6792/107898 [36:50<9:22:07,  3.00it/s][2025-01-30 02:29:00][root][INFO] - Training Epoch: 1/2, step 6791/107898 completed (loss: 3.530623435974121, acc: 0.5)
[2025-01-30 02:29:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6793/107898 [36:51<9:39:37,  2.91it/s][2025-01-30 02:29:01][root][INFO] - Training Epoch: 1/2, step 6792/107898 completed (loss: 0.4834917485713959, acc: 0.9230769276618958)
[2025-01-30 02:29:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6794/107898 [36:51<9:48:15,  2.86it/s][2025-01-30 02:29:01][root][INFO] - Training Epoch: 1/2, step 6793/107898 completed (loss: 0.010964330285787582, acc: 1.0)
[2025-01-30 02:29:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6795/107898 [36:51<9:36:37,  2.92it/s][2025-01-30 02:29:01][root][INFO] - Training Epoch: 1/2, step 6794/107898 completed (loss: 1.2163194417953491, acc: 0.8421052694320679)
[2025-01-30 02:29:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6796/107898 [36:52<9:27:07,  2.97it/s][2025-01-30 02:29:02][root][INFO] - Training Epoch: 1/2, step 6795/107898 completed (loss: 1.1015470027923584, acc: 0.800000011920929)
[2025-01-30 02:29:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6797/107898 [36:52<9:20:59,  3.00it/s][2025-01-30 02:29:02][root][INFO] - Training Epoch: 1/2, step 6796/107898 completed (loss: 1.4330509901046753, acc: 0.3333333432674408)
[2025-01-30 02:29:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6798/107898 [36:52<9:29:45,  2.96it/s][2025-01-30 02:29:02][root][INFO] - Training Epoch: 1/2, step 6797/107898 completed (loss: 1.7769579887390137, acc: 0.0)
[2025-01-30 02:29:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6799/107898 [36:53<9:28:23,  2.96it/s][2025-01-30 02:29:03][root][INFO] - Training Epoch: 1/2, step 6798/107898 completed (loss: 0.045973483473062515, acc: 1.0)
[2025-01-30 02:29:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6800/107898 [36:53<9:19:27,  3.01it/s][2025-01-30 02:29:03][root][INFO] - Training Epoch: 1/2, step 6799/107898 completed (loss: 1.8573156595230103, acc: 0.0)
[2025-01-30 02:29:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6801/107898 [36:53<9:15:26,  3.03it/s][2025-01-30 02:29:03][root][INFO] - Training Epoch: 1/2, step 6800/107898 completed (loss: 1.4574923515319824, acc: 0.7272727489471436)
[2025-01-30 02:29:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6802/107898 [36:54<8:59:26,  3.12it/s][2025-01-30 02:29:03][root][INFO] - Training Epoch: 1/2, step 6801/107898 completed (loss: 0.19637370109558105, acc: 1.0)
[2025-01-30 02:29:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6803/107898 [36:54<9:09:15,  3.07it/s][2025-01-30 02:29:04][root][INFO] - Training Epoch: 1/2, step 6802/107898 completed (loss: 0.14380250871181488, acc: 1.0)
[2025-01-30 02:29:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6804/107898 [36:54<9:02:15,  3.11it/s][2025-01-30 02:29:04][root][INFO] - Training Epoch: 1/2, step 6803/107898 completed (loss: 0.010341946966946125, acc: 1.0)
[2025-01-30 02:29:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6805/107898 [36:55<8:59:17,  3.12it/s][2025-01-30 02:29:04][root][INFO] - Training Epoch: 1/2, step 6804/107898 completed (loss: 0.871653139591217, acc: 0.875)
[2025-01-30 02:29:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6806/107898 [36:55<8:54:09,  3.15it/s][2025-01-30 02:29:05][root][INFO] - Training Epoch: 1/2, step 6805/107898 completed (loss: 0.1558741331100464, acc: 1.0)
[2025-01-30 02:29:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6807/107898 [36:55<8:47:10,  3.20it/s][2025-01-30 02:29:05][root][INFO] - Training Epoch: 1/2, step 6806/107898 completed (loss: 3.607527017593384, acc: 0.5)
[2025-01-30 02:29:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6808/107898 [36:56<9:16:14,  3.03it/s][2025-01-30 02:29:05][root][INFO] - Training Epoch: 1/2, step 6807/107898 completed (loss: 0.5897705554962158, acc: 0.7777777910232544)
[2025-01-30 02:29:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6809/107898 [36:56<9:34:11,  2.93it/s][2025-01-30 02:29:06][root][INFO] - Training Epoch: 1/2, step 6808/107898 completed (loss: 0.02925427444279194, acc: 1.0)
[2025-01-30 02:29:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6810/107898 [36:56<9:36:21,  2.92it/s][2025-01-30 02:29:06][root][INFO] - Training Epoch: 1/2, step 6809/107898 completed (loss: 1.2623099088668823, acc: 0.7692307829856873)
[2025-01-30 02:29:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6811/107898 [36:57<9:24:40,  2.98it/s][2025-01-30 02:29:06][root][INFO] - Training Epoch: 1/2, step 6810/107898 completed (loss: 3.056537628173828, acc: 0.5)
[2025-01-30 02:29:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6812/107898 [36:57<9:07:57,  3.07it/s][2025-01-30 02:29:07][root][INFO] - Training Epoch: 1/2, step 6811/107898 completed (loss: 2.102098226547241, acc: 0.5)
[2025-01-30 02:29:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6813/107898 [36:57<9:11:31,  3.05it/s][2025-01-30 02:29:07][root][INFO] - Training Epoch: 1/2, step 6812/107898 completed (loss: 2.573484420776367, acc: 0.6000000238418579)
[2025-01-30 02:29:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6814/107898 [36:58<9:00:13,  3.12it/s][2025-01-30 02:29:07][root][INFO] - Training Epoch: 1/2, step 6813/107898 completed (loss: 0.4208613336086273, acc: 1.0)
[2025-01-30 02:29:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6815/107898 [36:58<8:55:25,  3.15it/s][2025-01-30 02:29:08][root][INFO] - Training Epoch: 1/2, step 6814/107898 completed (loss: 1.8851852416992188, acc: 0.6499999761581421)
[2025-01-30 02:29:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6816/107898 [36:58<9:04:05,  3.10it/s][2025-01-30 02:29:08][root][INFO] - Training Epoch: 1/2, step 6815/107898 completed (loss: 0.44426000118255615, acc: 0.8947368264198303)
[2025-01-30 02:29:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6817/107898 [36:59<9:22:44,  2.99it/s][2025-01-30 02:29:08][root][INFO] - Training Epoch: 1/2, step 6816/107898 completed (loss: 0.7033182978630066, acc: 0.6000000238418579)
[2025-01-30 02:29:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6818/107898 [36:59<9:24:34,  2.98it/s][2025-01-30 02:29:09][root][INFO] - Training Epoch: 1/2, step 6817/107898 completed (loss: 0.30996182560920715, acc: 0.9090909361839294)
[2025-01-30 02:29:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6819/107898 [36:59<9:26:58,  2.97it/s][2025-01-30 02:29:09][root][INFO] - Training Epoch: 1/2, step 6818/107898 completed (loss: 0.5795871019363403, acc: 0.800000011920929)
[2025-01-30 02:29:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6820/107898 [37:00<9:13:07,  3.05it/s][2025-01-30 02:29:09][root][INFO] - Training Epoch: 1/2, step 6819/107898 completed (loss: 0.13824212551116943, acc: 1.0)
[2025-01-30 02:29:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6821/107898 [37:00<9:16:37,  3.03it/s][2025-01-30 02:29:10][root][INFO] - Training Epoch: 1/2, step 6820/107898 completed (loss: 1.3009823560714722, acc: 0.75)
[2025-01-30 02:29:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6822/107898 [37:00<9:00:59,  3.11it/s][2025-01-30 02:29:10][root][INFO] - Training Epoch: 1/2, step 6821/107898 completed (loss: 0.32971957325935364, acc: 1.0)
[2025-01-30 02:29:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6823/107898 [37:01<8:45:28,  3.21it/s][2025-01-30 02:29:10][root][INFO] - Training Epoch: 1/2, step 6822/107898 completed (loss: 0.900467574596405, acc: 0.6666666865348816)
[2025-01-30 02:29:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6824/107898 [37:01<8:45:02,  3.21it/s][2025-01-30 02:29:11][root][INFO] - Training Epoch: 1/2, step 6823/107898 completed (loss: 0.22333548963069916, acc: 1.0)
[2025-01-30 02:29:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6825/107898 [37:01<8:58:37,  3.13it/s][2025-01-30 02:29:11][root][INFO] - Training Epoch: 1/2, step 6824/107898 completed (loss: 0.48760661482810974, acc: 0.8823529481887817)
[2025-01-30 02:29:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6826/107898 [37:02<9:16:35,  3.03it/s][2025-01-30 02:29:11][root][INFO] - Training Epoch: 1/2, step 6825/107898 completed (loss: 0.013253627344965935, acc: 1.0)
[2025-01-30 02:29:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6827/107898 [37:02<9:39:18,  2.91it/s][2025-01-30 02:29:12][root][INFO] - Training Epoch: 1/2, step 6826/107898 completed (loss: 0.08704303205013275, acc: 1.0)
[2025-01-30 02:29:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6828/107898 [37:02<9:34:02,  2.93it/s][2025-01-30 02:29:12][root][INFO] - Training Epoch: 1/2, step 6827/107898 completed (loss: 0.13304446637630463, acc: 1.0)
[2025-01-30 02:29:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6829/107898 [37:03<9:36:30,  2.92it/s][2025-01-30 02:29:12][root][INFO] - Training Epoch: 1/2, step 6828/107898 completed (loss: 0.6015814542770386, acc: 0.8888888955116272)
[2025-01-30 02:29:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6830/107898 [37:03<9:34:27,  2.93it/s][2025-01-30 02:29:13][root][INFO] - Training Epoch: 1/2, step 6829/107898 completed (loss: 0.24917550384998322, acc: 0.9285714030265808)
[2025-01-30 02:29:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6831/107898 [37:03<9:31:25,  2.95it/s][2025-01-30 02:29:13][root][INFO] - Training Epoch: 1/2, step 6830/107898 completed (loss: 2.0313873291015625, acc: 0.6666666865348816)
[2025-01-30 02:29:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6832/107898 [37:04<9:31:15,  2.95it/s][2025-01-30 02:29:13][root][INFO] - Training Epoch: 1/2, step 6831/107898 completed (loss: 3.0998475551605225, acc: 0.3333333432674408)
[2025-01-30 02:29:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6833/107898 [37:04<9:17:37,  3.02it/s][2025-01-30 02:29:14][root][INFO] - Training Epoch: 1/2, step 6832/107898 completed (loss: 0.909620463848114, acc: 0.7272727489471436)
[2025-01-30 02:29:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6834/107898 [37:04<9:05:20,  3.09it/s][2025-01-30 02:29:14][root][INFO] - Training Epoch: 1/2, step 6833/107898 completed (loss: 1.2032618522644043, acc: 0.6363636255264282)
[2025-01-30 02:29:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6835/107898 [37:05<8:55:13,  3.15it/s][2025-01-30 02:29:14][root][INFO] - Training Epoch: 1/2, step 6834/107898 completed (loss: 0.37081006169319153, acc: 0.9523809552192688)
[2025-01-30 02:29:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6836/107898 [37:05<9:15:24,  3.03it/s][2025-01-30 02:29:15][root][INFO] - Training Epoch: 1/2, step 6835/107898 completed (loss: 0.021522967144846916, acc: 1.0)
[2025-01-30 02:29:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6837/107898 [37:05<9:22:13,  3.00it/s][2025-01-30 02:29:15][root][INFO] - Training Epoch: 1/2, step 6836/107898 completed (loss: 3.1268258094787598, acc: 0.5)
[2025-01-30 02:29:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6838/107898 [37:06<9:42:15,  2.89it/s][2025-01-30 02:29:15][root][INFO] - Training Epoch: 1/2, step 6837/107898 completed (loss: 1.174922227859497, acc: 0.8500000238418579)
[2025-01-30 02:29:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6839/107898 [37:06<10:05:06,  2.78it/s][2025-01-30 02:29:16][root][INFO] - Training Epoch: 1/2, step 6838/107898 completed (loss: 0.7975717782974243, acc: 0.8571428656578064)
[2025-01-30 02:29:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6840/107898 [37:06<9:35:59,  2.92it/s] [2025-01-30 02:29:16][root][INFO] - Training Epoch: 1/2, step 6839/107898 completed (loss: 0.7253738641738892, acc: 0.8461538553237915)
[2025-01-30 02:29:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6841/107898 [37:07<9:16:32,  3.03it/s][2025-01-30 02:29:16][root][INFO] - Training Epoch: 1/2, step 6840/107898 completed (loss: 1.7059193849563599, acc: 0.5625)
[2025-01-30 02:29:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6842/107898 [37:07<8:59:32,  3.12it/s][2025-01-30 02:29:17][root][INFO] - Training Epoch: 1/2, step 6841/107898 completed (loss: 0.019571634009480476, acc: 1.0)
[2025-01-30 02:29:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6843/107898 [37:07<8:51:58,  3.17it/s][2025-01-30 02:29:17][root][INFO] - Training Epoch: 1/2, step 6842/107898 completed (loss: 0.010127505287528038, acc: 1.0)
[2025-01-30 02:29:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6844/107898 [37:08<8:46:39,  3.20it/s][2025-01-30 02:29:17][root][INFO] - Training Epoch: 1/2, step 6843/107898 completed (loss: 1.1732890605926514, acc: 0.6153846383094788)
[2025-01-30 02:29:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6845/107898 [37:08<8:36:16,  3.26it/s][2025-01-30 02:29:18][root][INFO] - Training Epoch: 1/2, step 6844/107898 completed (loss: 0.008423805236816406, acc: 1.0)
[2025-01-30 02:29:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6846/107898 [37:08<8:35:26,  3.27it/s][2025-01-30 02:29:18][root][INFO] - Training Epoch: 1/2, step 6845/107898 completed (loss: 0.1696317493915558, acc: 1.0)
[2025-01-30 02:29:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6847/107898 [37:08<8:29:42,  3.30it/s][2025-01-30 02:29:18][root][INFO] - Training Epoch: 1/2, step 6846/107898 completed (loss: 0.39792001247406006, acc: 0.8333333134651184)
[2025-01-30 02:29:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6848/107898 [37:09<8:34:44,  3.27it/s][2025-01-30 02:29:18][root][INFO] - Training Epoch: 1/2, step 6847/107898 completed (loss: 2.889660358428955, acc: 0.3125)
[2025-01-30 02:29:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6849/107898 [37:09<8:54:15,  3.15it/s][2025-01-30 02:29:19][root][INFO] - Training Epoch: 1/2, step 6848/107898 completed (loss: 0.017547965049743652, acc: 1.0)
[2025-01-30 02:29:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6850/107898 [37:09<9:00:45,  3.11it/s][2025-01-30 02:29:19][root][INFO] - Training Epoch: 1/2, step 6849/107898 completed (loss: 0.5358902812004089, acc: 0.6666666865348816)
[2025-01-30 02:29:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6851/107898 [37:10<8:56:53,  3.14it/s][2025-01-30 02:29:19][root][INFO] - Training Epoch: 1/2, step 6850/107898 completed (loss: 0.10826090723276138, acc: 1.0)
[2025-01-30 02:29:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6852/107898 [37:10<9:10:24,  3.06it/s][2025-01-30 02:29:20][root][INFO] - Training Epoch: 1/2, step 6851/107898 completed (loss: 0.03805666044354439, acc: 1.0)
[2025-01-30 02:29:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6853/107898 [37:10<9:13:53,  3.04it/s][2025-01-30 02:29:20][root][INFO] - Training Epoch: 1/2, step 6852/107898 completed (loss: 0.005125668831169605, acc: 1.0)
[2025-01-30 02:29:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6854/107898 [37:11<9:03:28,  3.10it/s][2025-01-30 02:29:20][root][INFO] - Training Epoch: 1/2, step 6853/107898 completed (loss: 0.0049702622927725315, acc: 1.0)
[2025-01-30 02:29:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6855/107898 [37:11<8:54:31,  3.15it/s][2025-01-30 02:29:21][root][INFO] - Training Epoch: 1/2, step 6854/107898 completed (loss: 1.20389986038208, acc: 0.5)
[2025-01-30 02:29:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6856/107898 [37:11<9:05:08,  3.09it/s][2025-01-30 02:29:21][root][INFO] - Training Epoch: 1/2, step 6855/107898 completed (loss: 0.26381316781044006, acc: 1.0)
[2025-01-30 02:29:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6857/107898 [37:12<8:55:52,  3.14it/s][2025-01-30 02:29:21][root][INFO] - Training Epoch: 1/2, step 6856/107898 completed (loss: 0.4358521103858948, acc: 1.0)
[2025-01-30 02:29:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6858/107898 [37:12<9:17:01,  3.02it/s][2025-01-30 02:29:22][root][INFO] - Training Epoch: 1/2, step 6857/107898 completed (loss: 0.49134135246276855, acc: 0.5)
[2025-01-30 02:29:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6859/107898 [37:12<9:15:32,  3.03it/s][2025-01-30 02:29:22][root][INFO] - Training Epoch: 1/2, step 6858/107898 completed (loss: 0.511030375957489, acc: 0.6666666865348816)
[2025-01-30 02:29:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6860/107898 [37:13<9:06:19,  3.08it/s][2025-01-30 02:29:22][root][INFO] - Training Epoch: 1/2, step 6859/107898 completed (loss: 0.006340538617223501, acc: 1.0)
[2025-01-30 02:29:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6861/107898 [37:13<8:53:25,  3.16it/s][2025-01-30 02:29:23][root][INFO] - Training Epoch: 1/2, step 6860/107898 completed (loss: 0.06455828249454498, acc: 1.0)
[2025-01-30 02:29:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6862/107898 [37:13<9:14:35,  3.04it/s][2025-01-30 02:29:23][root][INFO] - Training Epoch: 1/2, step 6861/107898 completed (loss: 0.1733243465423584, acc: 1.0)
[2025-01-30 02:29:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6863/107898 [37:14<9:13:25,  3.04it/s][2025-01-30 02:29:23][root][INFO] - Training Epoch: 1/2, step 6862/107898 completed (loss: 0.030062561854720116, acc: 1.0)
[2025-01-30 02:29:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6864/107898 [37:14<9:27:03,  2.97it/s][2025-01-30 02:29:24][root][INFO] - Training Epoch: 1/2, step 6863/107898 completed (loss: 1.38106107711792, acc: 0.6666666865348816)
[2025-01-30 02:29:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6865/107898 [37:14<9:21:48,  3.00it/s][2025-01-30 02:29:24][root][INFO] - Training Epoch: 1/2, step 6864/107898 completed (loss: 2.4722740650177, acc: 0.3333333432674408)
[2025-01-30 02:29:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6866/107898 [37:15<9:13:01,  3.04it/s][2025-01-30 02:29:24][root][INFO] - Training Epoch: 1/2, step 6865/107898 completed (loss: 0.005808004178106785, acc: 1.0)
[2025-01-30 02:29:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6867/107898 [37:15<9:11:20,  3.05it/s][2025-01-30 02:29:25][root][INFO] - Training Epoch: 1/2, step 6866/107898 completed (loss: 0.6515671610832214, acc: 0.6666666865348816)
[2025-01-30 02:29:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6868/107898 [37:15<9:26:27,  2.97it/s][2025-01-30 02:29:25][root][INFO] - Training Epoch: 1/2, step 6867/107898 completed (loss: 2.5412988662719727, acc: 0.4000000059604645)
[2025-01-30 02:29:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6869/107898 [37:16<9:28:27,  2.96it/s][2025-01-30 02:29:25][root][INFO] - Training Epoch: 1/2, step 6868/107898 completed (loss: 0.43283581733703613, acc: 0.7777777910232544)
[2025-01-30 02:29:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6870/107898 [37:16<9:48:44,  2.86it/s][2025-01-30 02:29:26][root][INFO] - Training Epoch: 1/2, step 6869/107898 completed (loss: 1.007284164428711, acc: 0.8888888955116272)
[2025-01-30 02:29:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6871/107898 [37:16<10:02:21,  2.80it/s][2025-01-30 02:29:26][root][INFO] - Training Epoch: 1/2, step 6870/107898 completed (loss: 0.4514235854148865, acc: 0.9354838728904724)
[2025-01-30 02:29:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6872/107898 [37:17<9:49:42,  2.86it/s] [2025-01-30 02:29:27][root][INFO] - Training Epoch: 1/2, step 6871/107898 completed (loss: 0.9640059471130371, acc: 0.6666666865348816)
[2025-01-30 02:29:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6873/107898 [37:17<9:58:21,  2.81it/s][2025-01-30 02:29:27][root][INFO] - Training Epoch: 1/2, step 6872/107898 completed (loss: 0.5474129915237427, acc: 0.9545454382896423)
[2025-01-30 02:29:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6874/107898 [37:17<9:54:02,  2.83it/s][2025-01-30 02:29:27][root][INFO] - Training Epoch: 1/2, step 6873/107898 completed (loss: 0.23496918380260468, acc: 1.0)
[2025-01-30 02:29:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6875/107898 [37:18<9:45:59,  2.87it/s][2025-01-30 02:29:28][root][INFO] - Training Epoch: 1/2, step 6874/107898 completed (loss: 0.4758399426937103, acc: 0.8571428656578064)
[2025-01-30 02:29:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6876/107898 [37:18<10:03:11,  2.79it/s][2025-01-30 02:29:28][root][INFO] - Training Epoch: 1/2, step 6875/107898 completed (loss: 0.06850436329841614, acc: 1.0)
[2025-01-30 02:29:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6877/107898 [37:18<9:50:23,  2.85it/s] [2025-01-30 02:29:28][root][INFO] - Training Epoch: 1/2, step 6876/107898 completed (loss: 0.02165904827415943, acc: 1.0)
[2025-01-30 02:29:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6878/107898 [37:19<9:23:31,  2.99it/s][2025-01-30 02:29:29][root][INFO] - Training Epoch: 1/2, step 6877/107898 completed (loss: 2.8446877002716064, acc: 0.375)
[2025-01-30 02:29:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6879/107898 [37:19<9:06:46,  3.08it/s][2025-01-30 02:29:29][root][INFO] - Training Epoch: 1/2, step 6878/107898 completed (loss: 0.1370575726032257, acc: 1.0)
[2025-01-30 02:29:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6880/107898 [37:19<9:04:10,  3.09it/s][2025-01-30 02:29:29][root][INFO] - Training Epoch: 1/2, step 6879/107898 completed (loss: 0.0400550551712513, acc: 1.0)
[2025-01-30 02:29:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6881/107898 [37:20<8:56:01,  3.14it/s][2025-01-30 02:29:30][root][INFO] - Training Epoch: 1/2, step 6880/107898 completed (loss: 0.09978044778108597, acc: 1.0)
[2025-01-30 02:29:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6882/107898 [37:20<8:49:51,  3.18it/s][2025-01-30 02:29:30][root][INFO] - Training Epoch: 1/2, step 6881/107898 completed (loss: 0.07773517072200775, acc: 1.0)
[2025-01-30 02:29:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6883/107898 [37:20<8:52:47,  3.16it/s][2025-01-30 02:29:30][root][INFO] - Training Epoch: 1/2, step 6882/107898 completed (loss: 0.0974174365401268, acc: 1.0)
[2025-01-30 02:29:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6884/107898 [37:21<8:58:24,  3.13it/s][2025-01-30 02:29:30][root][INFO] - Training Epoch: 1/2, step 6883/107898 completed (loss: 2.002462863922119, acc: 0.0)
[2025-01-30 02:29:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6885/107898 [37:21<9:00:15,  3.12it/s][2025-01-30 02:29:31][root][INFO] - Training Epoch: 1/2, step 6884/107898 completed (loss: 0.6568917036056519, acc: 0.8666666746139526)
[2025-01-30 02:29:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6886/107898 [37:21<8:57:15,  3.13it/s][2025-01-30 02:29:31][root][INFO] - Training Epoch: 1/2, step 6885/107898 completed (loss: 1.3281103372573853, acc: 0.8235294222831726)
[2025-01-30 02:29:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6887/107898 [37:22<8:44:06,  3.21it/s][2025-01-30 02:29:31][root][INFO] - Training Epoch: 1/2, step 6886/107898 completed (loss: 2.1415088176727295, acc: 0.6363636255264282)
[2025-01-30 02:29:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6888/107898 [37:22<8:43:23,  3.22it/s][2025-01-30 02:29:32][root][INFO] - Training Epoch: 1/2, step 6887/107898 completed (loss: 0.48769834637641907, acc: 0.8888888955116272)
[2025-01-30 02:29:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6889/107898 [37:22<8:37:55,  3.25it/s][2025-01-30 02:29:32][root][INFO] - Training Epoch: 1/2, step 6888/107898 completed (loss: 1.4419121742248535, acc: 0.5909090638160706)
[2025-01-30 02:29:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6890/107898 [37:23<8:42:15,  3.22it/s][2025-01-30 02:29:32][root][INFO] - Training Epoch: 1/2, step 6889/107898 completed (loss: 1.6672756671905518, acc: 0.6666666865348816)
[2025-01-30 02:29:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6891/107898 [37:23<8:44:27,  3.21it/s][2025-01-30 02:29:33][root][INFO] - Training Epoch: 1/2, step 6890/107898 completed (loss: 0.0015593671705573797, acc: 1.0)
[2025-01-30 02:29:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6892/107898 [37:23<8:44:10,  3.21it/s][2025-01-30 02:29:33][root][INFO] - Training Epoch: 1/2, step 6891/107898 completed (loss: 0.6142497658729553, acc: 1.0)
[2025-01-30 02:29:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6893/107898 [37:23<8:47:29,  3.19it/s][2025-01-30 02:29:33][root][INFO] - Training Epoch: 1/2, step 6892/107898 completed (loss: 1.09596848487854, acc: 0.7142857313156128)
[2025-01-30 02:29:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6894/107898 [37:24<8:45:10,  3.21it/s][2025-01-30 02:29:34][root][INFO] - Training Epoch: 1/2, step 6893/107898 completed (loss: 0.011110195890069008, acc: 1.0)
[2025-01-30 02:29:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6895/107898 [37:24<9:09:53,  3.06it/s][2025-01-30 02:29:34][root][INFO] - Training Epoch: 1/2, step 6894/107898 completed (loss: 2.2178103923797607, acc: 0.5714285969734192)
[2025-01-30 02:29:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6896/107898 [37:24<9:15:24,  3.03it/s][2025-01-30 02:29:34][root][INFO] - Training Epoch: 1/2, step 6895/107898 completed (loss: 1.0443342924118042, acc: 0.6363636255264282)
[2025-01-30 02:29:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6897/107898 [37:25<9:17:26,  3.02it/s][2025-01-30 02:29:35][root][INFO] - Training Epoch: 1/2, step 6896/107898 completed (loss: 0.31731709837913513, acc: 1.0)
[2025-01-30 02:29:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6898/107898 [37:25<9:15:13,  3.03it/s][2025-01-30 02:29:35][root][INFO] - Training Epoch: 1/2, step 6897/107898 completed (loss: 0.4801054000854492, acc: 0.9166666865348816)
[2025-01-30 02:29:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6899/107898 [37:25<9:01:01,  3.11it/s][2025-01-30 02:29:35][root][INFO] - Training Epoch: 1/2, step 6898/107898 completed (loss: 0.0018889302155002952, acc: 1.0)
[2025-01-30 02:29:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6900/107898 [37:26<8:52:44,  3.16it/s][2025-01-30 02:29:36][root][INFO] - Training Epoch: 1/2, step 6899/107898 completed (loss: 0.5991955399513245, acc: 0.8947368264198303)
[2025-01-30 02:29:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6901/107898 [37:26<8:45:58,  3.20it/s][2025-01-30 02:29:36][root][INFO] - Training Epoch: 1/2, step 6900/107898 completed (loss: 0.013505217619240284, acc: 1.0)
[2025-01-30 02:29:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6902/107898 [37:26<8:43:57,  3.21it/s][2025-01-30 02:29:36][root][INFO] - Training Epoch: 1/2, step 6901/107898 completed (loss: 0.11921239644289017, acc: 1.0)
[2025-01-30 02:29:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6903/107898 [37:27<8:48:19,  3.19it/s][2025-01-30 02:29:36][root][INFO] - Training Epoch: 1/2, step 6902/107898 completed (loss: 2.0648722648620605, acc: 0.6666666865348816)
[2025-01-30 02:29:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6904/107898 [37:27<8:41:28,  3.23it/s][2025-01-30 02:29:37][root][INFO] - Training Epoch: 1/2, step 6903/107898 completed (loss: 3.1592936515808105, acc: 0.5)
[2025-01-30 02:29:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6905/107898 [37:27<8:51:42,  3.17it/s][2025-01-30 02:29:37][root][INFO] - Training Epoch: 1/2, step 6904/107898 completed (loss: 0.018951499834656715, acc: 1.0)
[2025-01-30 02:29:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6906/107898 [37:28<8:50:40,  3.17it/s][2025-01-30 02:29:37][root][INFO] - Training Epoch: 1/2, step 6905/107898 completed (loss: 8.495969772338867, acc: 0.0)
[2025-01-30 02:29:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6907/107898 [37:28<9:22:27,  2.99it/s][2025-01-30 02:29:38][root][INFO] - Training Epoch: 1/2, step 6906/107898 completed (loss: 0.6675564646720886, acc: 1.0)
[2025-01-30 02:29:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6908/107898 [37:28<9:18:43,  3.01it/s][2025-01-30 02:29:38][root][INFO] - Training Epoch: 1/2, step 6907/107898 completed (loss: 1.7327998876571655, acc: 0.695652186870575)
[2025-01-30 02:29:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6909/107898 [37:29<9:21:23,  3.00it/s][2025-01-30 02:29:38][root][INFO] - Training Epoch: 1/2, step 6908/107898 completed (loss: 0.39712557196617126, acc: 0.800000011920929)
[2025-01-30 02:29:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6910/107898 [37:29<8:56:12,  3.14it/s][2025-01-30 02:29:39][root][INFO] - Training Epoch: 1/2, step 6909/107898 completed (loss: 0.598904550075531, acc: 0.8999999761581421)
[2025-01-30 02:29:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6911/107898 [37:29<9:02:40,  3.10it/s][2025-01-30 02:29:39][root][INFO] - Training Epoch: 1/2, step 6910/107898 completed (loss: 4.032437324523926, acc: 0.5)
[2025-01-30 02:29:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6912/107898 [37:30<8:55:25,  3.14it/s][2025-01-30 02:29:39][root][INFO] - Training Epoch: 1/2, step 6911/107898 completed (loss: 0.07270539551973343, acc: 1.0)
[2025-01-30 02:29:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6913/107898 [37:30<8:45:55,  3.20it/s][2025-01-30 02:29:40][root][INFO] - Training Epoch: 1/2, step 6912/107898 completed (loss: 0.8245301842689514, acc: 0.8947368264198303)
[2025-01-30 02:29:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6914/107898 [37:30<8:32:10,  3.29it/s][2025-01-30 02:29:40][root][INFO] - Training Epoch: 1/2, step 6913/107898 completed (loss: 1.7060259580612183, acc: 0.0)
[2025-01-30 02:29:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6915/107898 [37:30<8:41:00,  3.23it/s][2025-01-30 02:29:40][root][INFO] - Training Epoch: 1/2, step 6914/107898 completed (loss: 2.3637542724609375, acc: 0.5)
[2025-01-30 02:29:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6916/107898 [37:31<9:04:40,  3.09it/s][2025-01-30 02:29:41][root][INFO] - Training Epoch: 1/2, step 6915/107898 completed (loss: 0.2223132848739624, acc: 1.0)
[2025-01-30 02:29:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6917/107898 [37:31<9:09:47,  3.06it/s][2025-01-30 02:29:41][root][INFO] - Training Epoch: 1/2, step 6916/107898 completed (loss: 2.9427707195281982, acc: 0.5)
[2025-01-30 02:29:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6918/107898 [37:31<8:59:46,  3.12it/s][2025-01-30 02:29:41][root][INFO] - Training Epoch: 1/2, step 6917/107898 completed (loss: 0.009663403034210205, acc: 1.0)
[2025-01-30 02:29:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6919/107898 [37:32<8:54:00,  3.15it/s][2025-01-30 02:29:42][root][INFO] - Training Epoch: 1/2, step 6918/107898 completed (loss: 2.407527446746826, acc: 0.6666666865348816)
[2025-01-30 02:29:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6920/107898 [37:32<8:59:22,  3.12it/s][2025-01-30 02:29:42][root][INFO] - Training Epoch: 1/2, step 6919/107898 completed (loss: 1.5066170692443848, acc: 0.7777777910232544)
[2025-01-30 02:29:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6921/107898 [37:32<8:55:47,  3.14it/s][2025-01-30 02:29:42][root][INFO] - Training Epoch: 1/2, step 6920/107898 completed (loss: 0.008622449822723866, acc: 1.0)
[2025-01-30 02:29:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6922/107898 [37:33<8:47:37,  3.19it/s][2025-01-30 02:29:43][root][INFO] - Training Epoch: 1/2, step 6921/107898 completed (loss: 0.132685586810112, acc: 1.0)
[2025-01-30 02:29:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6923/107898 [37:33<9:16:13,  3.03it/s][2025-01-30 02:29:43][root][INFO] - Training Epoch: 1/2, step 6922/107898 completed (loss: 1.5373836755752563, acc: 0.5)
[2025-01-30 02:29:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6924/107898 [37:33<9:14:53,  3.03it/s][2025-01-30 02:29:43][root][INFO] - Training Epoch: 1/2, step 6923/107898 completed (loss: 5.209200859069824, acc: 0.3333333432674408)
[2025-01-30 02:29:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6925/107898 [37:34<8:55:17,  3.14it/s][2025-01-30 02:29:44][root][INFO] - Training Epoch: 1/2, step 6924/107898 completed (loss: 4.4396467208862305, acc: 0.17391304671764374)
[2025-01-30 02:29:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6926/107898 [37:34<8:49:31,  3.18it/s][2025-01-30 02:29:44][root][INFO] - Training Epoch: 1/2, step 6925/107898 completed (loss: 0.3205810785293579, acc: 1.0)
[2025-01-30 02:29:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6927/107898 [37:34<8:50:18,  3.17it/s][2025-01-30 02:29:44][root][INFO] - Training Epoch: 1/2, step 6926/107898 completed (loss: 4.590186595916748, acc: 0.375)
[2025-01-30 02:29:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6928/107898 [37:35<8:43:23,  3.22it/s][2025-01-30 02:29:44][root][INFO] - Training Epoch: 1/2, step 6927/107898 completed (loss: 0.19136980175971985, acc: 1.0)
[2025-01-30 02:29:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6929/107898 [37:35<8:33:18,  3.28it/s][2025-01-30 02:29:45][root][INFO] - Training Epoch: 1/2, step 6928/107898 completed (loss: 2.397244691848755, acc: 0.6666666865348816)
[2025-01-30 02:29:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6930/107898 [37:35<8:28:36,  3.31it/s][2025-01-30 02:29:45][root][INFO] - Training Epoch: 1/2, step 6929/107898 completed (loss: 0.19561447203159332, acc: 1.0)
[2025-01-30 02:29:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6931/107898 [37:36<8:34:55,  3.27it/s][2025-01-30 02:29:45][root][INFO] - Training Epoch: 1/2, step 6930/107898 completed (loss: 0.09762566536664963, acc: 1.0)
[2025-01-30 02:29:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6932/107898 [37:36<8:31:08,  3.29it/s][2025-01-30 02:29:46][root][INFO] - Training Epoch: 1/2, step 6931/107898 completed (loss: 1.568878173828125, acc: 0.6363636255264282)
[2025-01-30 02:29:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6933/107898 [37:36<8:32:02,  3.29it/s][2025-01-30 02:29:46][root][INFO] - Training Epoch: 1/2, step 6932/107898 completed (loss: 0.7905811667442322, acc: 0.875)
[2025-01-30 02:29:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6934/107898 [37:36<8:18:08,  3.38it/s][2025-01-30 02:29:46][root][INFO] - Training Epoch: 1/2, step 6933/107898 completed (loss: 0.5191105604171753, acc: 0.800000011920929)
[2025-01-30 02:29:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6935/107898 [37:37<8:25:19,  3.33it/s][2025-01-30 02:29:47][root][INFO] - Training Epoch: 1/2, step 6934/107898 completed (loss: 0.8072757124900818, acc: 0.8333333134651184)
[2025-01-30 02:29:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6936/107898 [37:37<8:26:51,  3.32it/s][2025-01-30 02:29:47][root][INFO] - Training Epoch: 1/2, step 6935/107898 completed (loss: 0.30282655358314514, acc: 1.0)
[2025-01-30 02:29:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 1:   6%|[34mâ–‹         [0m| 6937/107898 [37:37<8:31:20,  3.29it/s][2025-01-30 02:29:47][root][INFO] - Training Epoch: 1/2, step 6936/107898 completed (loss: 2.3106231689453125, acc: 0.4545454680919647)
Error executing job with overrides: ['++model_config.llm_name=llama32_1b', '++model_config.llm_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', '++model_config.llm_dim=2048', '++model_config.encoder_name=wavlm', '++model_config.normalize=true', '++dataset_config.normalize=true', '++model_config.encoder_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', '++model_config.encoder2_name=', '++model_config.encoder2_path=', '++model_config.encoder_dim=1024', '++model_config.encoder_projector=linear', '++model_config.encoder_projector_ds_rate=5', '++model_config.identifier=ami_ec_wavlm_llama32_1b_linear_peft', '++dataset_config.dataset=speech_dataset', '++dataset_config.train_data_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_ec/train.jsonl', '++dataset_config.file=src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', '++dataset_config.val_data_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami_ec/validation.jsonl', '++dataset_config.input_type=raw', '++train_config.model_name=asr', '++train_config.num_epochs=2', '++train_config.freeze_encoder=true', '++train_config.freeze_encoder2=true', '++train_config.freeze_llm=false', '++train_config.batching_strategy=custom', '++train_config.warmup_steps=1000', '++train_config.total_steps=100000', '++train_config.lr=1e-4', '++train_config.validation_interval=3000', '++train_config.batch_size_training=1', '++train_config.val_batch_size=1', '++train_config.num_workers_dataloader=1', '++train_config.output_dir=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_ec_wavlm_llama32_1b_linear_peft', '++train_config.use_fp16=true', '++train_config.use_peft=true', '++train_config.resume_epoch=1', '++train_config.resume_step=0', '++log_config.use_wandb=true', '++log_config.wandb_exp_name=ami_ec_wavlm_llama32_1b_linear_peft', '++dataset_config.input_type=raw']
Traceback (most recent call last):
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/examples/asr_librispeech/finetune_asr.py", line 56, in <module>
    main_hydra()
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/core/utils.py", line 261, in return_value
    raise self._return_value
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/core/utils.py", line 187, in run_job
    ret.return_value = task_function(task_cfg)
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/examples/asr_librispeech/finetune_asr.py", line 52, in main_hydra
    train(kwargs)
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/src/slam_llm/pipeline/finetune.py", line 271, in main
    results = train(
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/src/slam_llm/utils/train_utils.py", line 118, in train
    outputs, *rest = model(**batch)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/src/slam_llm/models/slam_model.py", line 433, in forward
    encoder_outs, audio_mel_post_mask = self.extract_encoder_features(
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/src/slam_llm/models/slam_model.py", line 366, in extract_encoder_features
    encoder_outs = self.encoder.extract_features(audio, 1 - audio_mask)
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/src/slam_llm/models/encoder.py", line 120, in extract_features
    features = self.model.extract_features(source, padding_mask)[0]
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/src/slam_llm/models/wavlm/WavLM.py", line 334, in extract_features
    features = self.feature_extractor(source)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/src/slam_llm/models/wavlm/WavLM.py", line 500, in forward
    x = conv(x)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 310, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 306, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: Calculated padded input size per channel: (1). Kernel size: (2). Kernel size can't be greater than actual input size
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb: / 0.006 MB of 1.379 MB uploadedwandb: - 1.379 MB of 1.379 MB uploadedwandb: 
wandb: Run history:
wandb:                   train_inner/lr â–â–‚â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: train_inner/train_inner_accuracy â–…â–ˆâ–†â–†â–â–‚â–ˆâ–‡â–ˆâ–„â–‡â–‡â–„â–…â–ˆâ–ˆâ–‡â–ˆâ–‡â–‚â–„â–â–ˆâ–…â–…â–‡â–ˆâ–‡â–„â–†â–‡â–…â–…â–…â–„â–†â–ˆâ–†â–†â–†
wandb:     train_inner/train_inner_loss â–†â–â–ƒâ–ƒâ–ˆâ–†â–â–‚â–â–†â–‚â–‚â–†â–ƒâ–â–‚â–‚â–â–ƒâ–†â–ˆâ–†â–â–‚â–‚â–‚â–â–‚â–…â–ƒâ–ƒâ–‚â–‡â–ƒâ–…â–…â–â–„â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:                   train_inner/lr 9e-05
wandb: train_inner/train_inner_accuracy 1.0
wandb:     train_inner/train_inner_loss 0.30283
wandb: 
wandb: ðŸš€ View run ami_ec_wavlm_llama32_1b_linear_peft at: https://wandb.ai/jindaz-work/SLAM-LLM/runs/hektlxd4
wandb: â­ï¸ View project at: https://wandb.ai/jindaz-work/SLAM-LLM
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./out/log/wandb_log/wandb/run-20250130_015132-hektlxd4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
No checkpoints with loss found. Selecting the checkpoint with the latest epoch and step.
Selected checkpoint with latest epoch and step: 
No checkpoint found in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_ec_wavlm_llama32_1b_linear_peft
