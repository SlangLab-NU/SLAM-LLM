Tue Feb  4 02:35:28 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla V100-SXM2-32GB           Off | 00000000:3B:00.0 Off |                    0 |
| N/A   35C    P0              57W / 300W |      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
/work/van-speech-nlp/jindaznb/slamenv/bin/python
task_flag: all
encoder_config: wavlm-mono
num_epochs: 2
batch_size_training: 4
train_data_folder: aphasia_phoneme
test_data_folder: aphasia_phoneme
use_peft: true
seed: 
llm_name: llama32_1b
debug: 
Is test_run? 
freeze_encoder: true
encoder_projector: linear
encoder_projector_ds_rate: 6
Is save_embedding? false
projector_transfer_learning: false
transfer_data_folder: 
----------
----------
Final identifier: aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6
ckpt_folder: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6/asr_epoch_2_step_17875_loss_0.4531655013561249
Resume epoch: 2
Resume step: 17875
[2025-02-04 02:36:06][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 17875, 'resume_epoch': 2, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': False}
[2025-02-04 02:36:06][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-04 02:36:06][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 6, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6'}
[2025-02-04 02:36:06][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2025-02-04_02-36-05.txt', 'log_interval': 5}
wandb: Currently logged in as: jindaz (jindaz-work). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log/wandb/run-20250204_023609-wo8qxoi0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6
wandb: ⭐️ View project at https://wandb.ai/jindaz-work/SLAM-LLM
wandb: 🚀 View run at https://wandb.ai/jindaz-work/SLAM-LLM/runs/wo8qxoi0
[2025-02-04 02:36:31][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.
  warnings.warn("torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.")
[2025-02-04 02:36:37][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-04 02:36:37][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-02-04 02:36:37][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-04 02:36:37][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-02-04 02:36:43][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-04 02:36:43][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-04 02:36:43][slam_llm.models.slam_model][INFO] - setup peft...
trainable params: 5,636,096 || all params: 1,241,450,496 || trainable%: 0.4539928106807088
[2025-02-04 02:36:43][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-04 02:36:43][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-04 02:36:43][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-04 02:36:43][slam_llm.utils.train_utils][INFO] - --> linear has 16.781312 Million params

[2025-02-04 02:36:43][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6/asr_epoch_2_step_17875_loss_0.4531655013561249/model.pt
[2025-02-04 02:36:44][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-04 02:36:44][slam_llm.utils.train_utils][INFO] - --> asr has 22.417408 Million params

[2025-02-04 02:36:46][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/aphasia_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/aphasia_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-02-04 02:36:49][root][INFO] - --> Training Set Length = 95353
[2025-02-04 02:36:49][root][INFO] - --> Validation Set Length = 13162
[2025-02-04 02:36:49][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2025-02-04 02:36:49][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Training Epoch: 2:  75%|[34m███████▍  [0m| 17875/23838 [00:00<?, ?it/s]/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
[2025-02-04 02:36:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▍  [0m| 17876/23838 [00:03<5:21:35,  3.24s/it][2025-02-04 02:36:52][root][INFO] - Training Epoch: 2/2, step 17875/23838 completed (loss: 0.3550845682621002, acc: 0.9268292784690857)
[2025-02-04 02:36:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▍  [0m| 17877/23838 [00:03<2:35:21,  1.56s/it][2025-02-04 02:36:53][root][INFO] - Training Epoch: 2/2, step 17876/23838 completed (loss: 0.2627130150794983, acc: 0.920634925365448)
[2025-02-04 02:36:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▍  [0m| 17878/23838 [00:04<1:45:48,  1.07s/it][2025-02-04 02:36:53][root][INFO] - Training Epoch: 2/2, step 17877/23838 completed (loss: 0.0496048741042614, acc: 0.9850746393203735)
[2025-02-04 02:36:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17879/23838 [00:04<1:18:39,  1.26it/s][2025-02-04 02:36:54][root][INFO] - Training Epoch: 2/2, step 17878/23838 completed (loss: 0.19276924431324005, acc: 0.9772727489471436)
[2025-02-04 02:36:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17880/23838 [00:05<1:15:05,  1.32it/s][2025-02-04 02:36:54][root][INFO] - Training Epoch: 2/2, step 17879/23838 completed (loss: 0.3917132616043091, acc: 0.9215686321258545)
[2025-02-04 02:36:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17881/23838 [00:05<1:06:47,  1.49it/s][2025-02-04 02:36:55][root][INFO] - Training Epoch: 2/2, step 17880/23838 completed (loss: 0.9578969478607178, acc: 0.6933333277702332)
[2025-02-04 02:36:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17882/23838 [00:06<1:00:55,  1.63it/s][2025-02-04 02:36:55][root][INFO] - Training Epoch: 2/2, step 17881/23838 completed (loss: 0.7449559569358826, acc: 0.8653846383094788)
[2025-02-04 02:36:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17883/23838 [00:06<1:03:39,  1.56it/s][2025-02-04 02:36:56][root][INFO] - Training Epoch: 2/2, step 17882/23838 completed (loss: 0.6542086005210876, acc: 0.8139534592628479)
[2025-02-04 02:36:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17884/23838 [00:07<59:54,  1.66it/s]  [2025-02-04 02:36:56][root][INFO] - Training Epoch: 2/2, step 17883/23838 completed (loss: 0.7301740050315857, acc: 0.8196721076965332)
[2025-02-04 02:36:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17885/23838 [00:07<53:53,  1.84it/s][2025-02-04 02:36:57][root][INFO] - Training Epoch: 2/2, step 17884/23838 completed (loss: 0.8542372584342957, acc: 0.7962962985038757)
[2025-02-04 02:36:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17886/23838 [00:08<49:07,  2.02it/s][2025-02-04 02:36:57][root][INFO] - Training Epoch: 2/2, step 17885/23838 completed (loss: 0.3572034537792206, acc: 0.8666666746139526)
[2025-02-04 02:36:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17887/23838 [00:08<47:13,  2.10it/s][2025-02-04 02:36:58][root][INFO] - Training Epoch: 2/2, step 17886/23838 completed (loss: 0.5037665367126465, acc: 0.8545454740524292)
[2025-02-04 02:36:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17888/23838 [00:09<45:06,  2.20it/s][2025-02-04 02:36:58][root][INFO] - Training Epoch: 2/2, step 17887/23838 completed (loss: 0.16204380989074707, acc: 0.9428571462631226)
[2025-02-04 02:36:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17889/23838 [00:09<41:23,  2.40it/s][2025-02-04 02:36:58][root][INFO] - Training Epoch: 2/2, step 17888/23838 completed (loss: 0.014723067171871662, acc: 1.0)
[2025-02-04 02:36:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17890/23838 [00:09<37:58,  2.61it/s][2025-02-04 02:36:59][root][INFO] - Training Epoch: 2/2, step 17889/23838 completed (loss: 0.527202308177948, acc: 0.8428571224212646)
[2025-02-04 02:36:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17891/23838 [00:10<41:59,  2.36it/s][2025-02-04 02:36:59][root][INFO] - Training Epoch: 2/2, step 17890/23838 completed (loss: 0.6996529698371887, acc: 0.8289473652839661)
[2025-02-04 02:36:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17892/23838 [00:10<42:12,  2.35it/s][2025-02-04 02:37:00][root][INFO] - Training Epoch: 2/2, step 17891/23838 completed (loss: 0.22558148205280304, acc: 0.9387755393981934)
[2025-02-04 02:37:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17893/23838 [00:10<39:22,  2.52it/s][2025-02-04 02:37:00][root][INFO] - Training Epoch: 2/2, step 17892/23838 completed (loss: 0.11325167119503021, acc: 0.9736841917037964)
[2025-02-04 02:37:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17894/23838 [00:11<40:02,  2.47it/s][2025-02-04 02:37:00][root][INFO] - Training Epoch: 2/2, step 17893/23838 completed (loss: 0.5028066039085388, acc: 0.8805969953536987)
[2025-02-04 02:37:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17895/23838 [00:11<44:25,  2.23it/s][2025-02-04 02:37:01][root][INFO] - Training Epoch: 2/2, step 17894/23838 completed (loss: 0.5448021292686462, acc: 0.8515625)
[2025-02-04 02:37:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17896/23838 [00:12<43:53,  2.26it/s][2025-02-04 02:37:01][root][INFO] - Training Epoch: 2/2, step 17895/23838 completed (loss: 0.47492098808288574, acc: 0.8571428656578064)
[2025-02-04 02:37:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17897/23838 [00:12<44:36,  2.22it/s][2025-02-04 02:37:02][root][INFO] - Training Epoch: 2/2, step 17896/23838 completed (loss: 0.8273791670799255, acc: 0.800000011920929)
[2025-02-04 02:37:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17898/23838 [00:13<44:12,  2.24it/s][2025-02-04 02:37:02][root][INFO] - Training Epoch: 2/2, step 17897/23838 completed (loss: 0.41396158933639526, acc: 0.8999999761581421)
[2025-02-04 02:37:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17899/23838 [00:13<43:43,  2.26it/s][2025-02-04 02:37:03][root][INFO] - Training Epoch: 2/2, step 17898/23838 completed (loss: 0.32154783606529236, acc: 0.9130434989929199)
[2025-02-04 02:37:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17900/23838 [00:14<44:05,  2.24it/s][2025-02-04 02:37:03][root][INFO] - Training Epoch: 2/2, step 17899/23838 completed (loss: 0.4618869721889496, acc: 0.8765432238578796)
[2025-02-04 02:37:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17901/23838 [00:14<41:48,  2.37it/s][2025-02-04 02:37:04][root][INFO] - Training Epoch: 2/2, step 17900/23838 completed (loss: 0.5165857672691345, acc: 0.9012345671653748)
[2025-02-04 02:37:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17902/23838 [00:14<43:27,  2.28it/s][2025-02-04 02:37:04][root][INFO] - Training Epoch: 2/2, step 17901/23838 completed (loss: 0.18041987717151642, acc: 0.9404761791229248)
[2025-02-04 02:37:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17903/23838 [00:15<43:48,  2.26it/s][2025-02-04 02:37:05][root][INFO] - Training Epoch: 2/2, step 17902/23838 completed (loss: 0.554078996181488, acc: 0.8253968358039856)
[2025-02-04 02:37:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17904/23838 [00:15<43:45,  2.26it/s][2025-02-04 02:37:05][root][INFO] - Training Epoch: 2/2, step 17903/23838 completed (loss: 0.3677539527416229, acc: 0.8999999761581421)
[2025-02-04 02:37:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17905/23838 [00:16<42:05,  2.35it/s][2025-02-04 02:37:05][root][INFO] - Training Epoch: 2/2, step 17904/23838 completed (loss: 0.5209203362464905, acc: 0.837837815284729)
[2025-02-04 02:37:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17906/23838 [00:16<41:55,  2.36it/s][2025-02-04 02:37:06][root][INFO] - Training Epoch: 2/2, step 17905/23838 completed (loss: 0.9490651488304138, acc: 0.7692307829856873)
[2025-02-04 02:37:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17907/23838 [00:17<40:40,  2.43it/s][2025-02-04 02:37:06][root][INFO] - Training Epoch: 2/2, step 17906/23838 completed (loss: 0.5582121014595032, acc: 0.8666666746139526)
[2025-02-04 02:37:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17908/23838 [00:17<42:23,  2.33it/s][2025-02-04 02:37:07][root][INFO] - Training Epoch: 2/2, step 17907/23838 completed (loss: 0.8839075565338135, acc: 0.7666666507720947)
[2025-02-04 02:37:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17909/23838 [00:17<43:28,  2.27it/s][2025-02-04 02:37:07][root][INFO] - Training Epoch: 2/2, step 17908/23838 completed (loss: 1.1339229345321655, acc: 0.6428571343421936)
[2025-02-04 02:37:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17910/23838 [00:18<44:19,  2.23it/s][2025-02-04 02:37:08][root][INFO] - Training Epoch: 2/2, step 17909/23838 completed (loss: 0.5597095489501953, acc: 0.800000011920929)
[2025-02-04 02:37:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17911/23838 [00:18<43:19,  2.28it/s][2025-02-04 02:37:08][root][INFO] - Training Epoch: 2/2, step 17910/23838 completed (loss: 0.4658063054084778, acc: 0.8421052694320679)
[2025-02-04 02:37:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17912/23838 [00:19<45:00,  2.19it/s][2025-02-04 02:37:08][root][INFO] - Training Epoch: 2/2, step 17911/23838 completed (loss: 0.6183383464813232, acc: 0.800000011920929)
[2025-02-04 02:37:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17913/23838 [00:20<50:32,  1.95it/s][2025-02-04 02:37:09][root][INFO] - Training Epoch: 2/2, step 17912/23838 completed (loss: 0.5856329202651978, acc: 0.8720930218696594)
[2025-02-04 02:37:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17914/23838 [00:20<53:46,  1.84it/s][2025-02-04 02:37:10][root][INFO] - Training Epoch: 2/2, step 17913/23838 completed (loss: 0.40313708782196045, acc: 0.9215686321258545)
[2025-02-04 02:37:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17915/23838 [00:21<48:32,  2.03it/s][2025-02-04 02:37:10][root][INFO] - Training Epoch: 2/2, step 17914/23838 completed (loss: 0.051896676421165466, acc: 1.0)
[2025-02-04 02:37:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17916/23838 [00:21<44:24,  2.22it/s][2025-02-04 02:37:10][root][INFO] - Training Epoch: 2/2, step 17915/23838 completed (loss: 0.03004026785492897, acc: 1.0)
[2025-02-04 02:37:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17917/23838 [00:21<42:39,  2.31it/s][2025-02-04 02:37:11][root][INFO] - Training Epoch: 2/2, step 17916/23838 completed (loss: 0.44414106011390686, acc: 0.800000011920929)
[2025-02-04 02:37:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17918/23838 [00:22<40:40,  2.43it/s][2025-02-04 02:37:11][root][INFO] - Training Epoch: 2/2, step 17917/23838 completed (loss: 0.08460632711648941, acc: 1.0)
[2025-02-04 02:37:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17919/23838 [00:22<39:22,  2.51it/s][2025-02-04 02:37:12][root][INFO] - Training Epoch: 2/2, step 17918/23838 completed (loss: 0.4051854610443115, acc: 0.8684210777282715)
[2025-02-04 02:37:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17920/23838 [00:22<39:18,  2.51it/s][2025-02-04 02:37:12][root][INFO] - Training Epoch: 2/2, step 17919/23838 completed (loss: 0.35392239689826965, acc: 0.8999999761581421)
[2025-02-04 02:37:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17921/23838 [00:23<37:12,  2.65it/s][2025-02-04 02:37:12][root][INFO] - Training Epoch: 2/2, step 17920/23838 completed (loss: 0.046238869428634644, acc: 0.9818181991577148)
[2025-02-04 02:37:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17922/23838 [00:23<37:24,  2.64it/s][2025-02-04 02:37:13][root][INFO] - Training Epoch: 2/2, step 17921/23838 completed (loss: 0.2443697303533554, acc: 0.9230769276618958)
[2025-02-04 02:37:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17923/23838 [00:23<37:17,  2.64it/s][2025-02-04 02:37:13][root][INFO] - Training Epoch: 2/2, step 17922/23838 completed (loss: 0.1951514631509781, acc: 0.9259259104728699)
[2025-02-04 02:37:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17924/23838 [00:24<38:34,  2.55it/s][2025-02-04 02:37:13][root][INFO] - Training Epoch: 2/2, step 17923/23838 completed (loss: 0.014916719868779182, acc: 1.0)
[2025-02-04 02:37:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17925/23838 [00:24<41:09,  2.39it/s][2025-02-04 02:37:14][root][INFO] - Training Epoch: 2/2, step 17924/23838 completed (loss: 0.5231773257255554, acc: 0.8613861203193665)
[2025-02-04 02:37:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17926/23838 [00:25<40:45,  2.42it/s][2025-02-04 02:37:14][root][INFO] - Training Epoch: 2/2, step 17925/23838 completed (loss: 0.2484143078327179, acc: 0.931034505367279)
[2025-02-04 02:37:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17927/23838 [00:25<41:20,  2.38it/s][2025-02-04 02:37:15][root][INFO] - Training Epoch: 2/2, step 17926/23838 completed (loss: 0.31614580750465393, acc: 0.9189189076423645)
[2025-02-04 02:37:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17928/23838 [00:26<40:37,  2.42it/s][2025-02-04 02:37:15][root][INFO] - Training Epoch: 2/2, step 17927/23838 completed (loss: 0.23374029994010925, acc: 0.9259259104728699)
[2025-02-04 02:37:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17929/23838 [00:26<38:55,  2.53it/s][2025-02-04 02:37:16][root][INFO] - Training Epoch: 2/2, step 17928/23838 completed (loss: 0.5323155522346497, acc: 0.8765432238578796)
[2025-02-04 02:37:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17930/23838 [00:26<40:31,  2.43it/s][2025-02-04 02:37:16][root][INFO] - Training Epoch: 2/2, step 17929/23838 completed (loss: 0.15659543871879578, acc: 0.9431818127632141)
[2025-02-04 02:37:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17931/23838 [00:27<38:40,  2.55it/s][2025-02-04 02:37:16][root][INFO] - Training Epoch: 2/2, step 17930/23838 completed (loss: 0.10597116500139236, acc: 0.9716981053352356)
[2025-02-04 02:37:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17932/23838 [00:27<37:10,  2.65it/s][2025-02-04 02:37:17][root][INFO] - Training Epoch: 2/2, step 17931/23838 completed (loss: 0.1850244104862213, acc: 0.9553571343421936)
[2025-02-04 02:37:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17933/23838 [00:27<37:38,  2.61it/s][2025-02-04 02:37:17][root][INFO] - Training Epoch: 2/2, step 17932/23838 completed (loss: 0.094777911901474, acc: 0.9469026327133179)
[2025-02-04 02:37:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17934/23838 [00:28<37:56,  2.59it/s][2025-02-04 02:37:17][root][INFO] - Training Epoch: 2/2, step 17933/23838 completed (loss: 0.4152463376522064, acc: 0.8777777552604675)
[2025-02-04 02:37:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17935/23838 [00:28<39:50,  2.47it/s][2025-02-04 02:37:18][root][INFO] - Training Epoch: 2/2, step 17934/23838 completed (loss: 0.09884527325630188, acc: 0.9484536051750183)
[2025-02-04 02:37:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17936/23838 [00:29<45:33,  2.16it/s][2025-02-04 02:37:19][root][INFO] - Training Epoch: 2/2, step 17935/23838 completed (loss: 0.2560441195964813, acc: 0.925000011920929)
[2025-02-04 02:37:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17937/23838 [00:29<44:40,  2.20it/s][2025-02-04 02:37:19][root][INFO] - Training Epoch: 2/2, step 17936/23838 completed (loss: 0.2444438487291336, acc: 0.9292035102844238)
[2025-02-04 02:37:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17938/23838 [00:30<43:43,  2.25it/s][2025-02-04 02:37:19][root][INFO] - Training Epoch: 2/2, step 17937/23838 completed (loss: 0.30566710233688354, acc: 0.8901098966598511)
[2025-02-04 02:37:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17939/23838 [00:30<43:52,  2.24it/s][2025-02-04 02:37:20][root][INFO] - Training Epoch: 2/2, step 17938/23838 completed (loss: 0.28253474831581116, acc: 0.9189189076423645)
[2025-02-04 02:37:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17940/23838 [00:31<43:11,  2.28it/s][2025-02-04 02:37:20][root][INFO] - Training Epoch: 2/2, step 17939/23838 completed (loss: 0.18881234526634216, acc: 0.9154929518699646)
[2025-02-04 02:37:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17941/23838 [00:31<44:42,  2.20it/s][2025-02-04 02:37:21][root][INFO] - Training Epoch: 2/2, step 17940/23838 completed (loss: 0.1625526249408722, acc: 0.9435483813285828)
[2025-02-04 02:37:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17942/23838 [00:32<43:40,  2.25it/s][2025-02-04 02:37:21][root][INFO] - Training Epoch: 2/2, step 17941/23838 completed (loss: 0.06464926153421402, acc: 1.0)
[2025-02-04 02:37:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17943/23838 [00:32<41:04,  2.39it/s][2025-02-04 02:37:22][root][INFO] - Training Epoch: 2/2, step 17942/23838 completed (loss: 0.11690348386764526, acc: 0.9805825352668762)
[2025-02-04 02:37:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17944/23838 [00:32<40:15,  2.44it/s][2025-02-04 02:37:22][root][INFO] - Training Epoch: 2/2, step 17943/23838 completed (loss: 0.14782623946666718, acc: 0.9375)
[2025-02-04 02:37:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17945/23838 [00:33<39:55,  2.46it/s][2025-02-04 02:37:22][root][INFO] - Training Epoch: 2/2, step 17944/23838 completed (loss: 0.08108698576688766, acc: 0.9615384340286255)
[2025-02-04 02:37:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17946/23838 [00:33<38:55,  2.52it/s][2025-02-04 02:37:23][root][INFO] - Training Epoch: 2/2, step 17945/23838 completed (loss: 1.1677935123443604, acc: 0.7142857313156128)
[2025-02-04 02:37:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17947/23838 [00:34<41:24,  2.37it/s][2025-02-04 02:37:23][root][INFO] - Training Epoch: 2/2, step 17946/23838 completed (loss: 0.6817823052406311, acc: 0.800000011920929)
[2025-02-04 02:37:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17948/23838 [00:34<46:35,  2.11it/s][2025-02-04 02:37:24][root][INFO] - Training Epoch: 2/2, step 17947/23838 completed (loss: 0.81993567943573, acc: 0.71875)
[2025-02-04 02:37:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17949/23838 [00:35<47:26,  2.07it/s][2025-02-04 02:37:24][root][INFO] - Training Epoch: 2/2, step 17948/23838 completed (loss: 0.43573644757270813, acc: 0.8695651888847351)
[2025-02-04 02:37:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17950/23838 [00:35<45:14,  2.17it/s][2025-02-04 02:37:25][root][INFO] - Training Epoch: 2/2, step 17949/23838 completed (loss: 0.507239818572998, acc: 0.8846153616905212)
[2025-02-04 02:37:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17951/23838 [00:36<45:10,  2.17it/s][2025-02-04 02:37:25][root][INFO] - Training Epoch: 2/2, step 17950/23838 completed (loss: 0.7051219940185547, acc: 0.800000011920929)
[2025-02-04 02:37:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17952/23838 [00:36<45:09,  2.17it/s][2025-02-04 02:37:26][root][INFO] - Training Epoch: 2/2, step 17951/23838 completed (loss: 0.1980353444814682, acc: 0.95652174949646)
[2025-02-04 02:37:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17953/23838 [00:36<45:37,  2.15it/s][2025-02-04 02:37:26][root][INFO] - Training Epoch: 2/2, step 17952/23838 completed (loss: 0.6065884828567505, acc: 0.7966101765632629)
[2025-02-04 02:37:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17954/23838 [00:37<43:12,  2.27it/s][2025-02-04 02:37:26][root][INFO] - Training Epoch: 2/2, step 17953/23838 completed (loss: 0.17842161655426025, acc: 0.9655172228813171)
[2025-02-04 02:37:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17955/23838 [00:37<46:24,  2.11it/s][2025-02-04 02:37:27][root][INFO] - Training Epoch: 2/2, step 17954/23838 completed (loss: 0.4673178493976593, acc: 0.9259259104728699)
[2025-02-04 02:37:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17956/23838 [00:38<43:45,  2.24it/s][2025-02-04 02:37:27][root][INFO] - Training Epoch: 2/2, step 17955/23838 completed (loss: 0.8472609519958496, acc: 0.7428571581840515)
[2025-02-04 02:37:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17957/23838 [00:38<41:48,  2.34it/s][2025-02-04 02:37:28][root][INFO] - Training Epoch: 2/2, step 17956/23838 completed (loss: 0.21732664108276367, acc: 0.9473684430122375)
[2025-02-04 02:37:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17958/23838 [00:39<41:13,  2.38it/s][2025-02-04 02:37:28][root][INFO] - Training Epoch: 2/2, step 17957/23838 completed (loss: 0.2824867069721222, acc: 0.9375)
[2025-02-04 02:37:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17959/23838 [00:39<41:27,  2.36it/s][2025-02-04 02:37:29][root][INFO] - Training Epoch: 2/2, step 17958/23838 completed (loss: 0.19693847000598907, acc: 0.9285714030265808)
[2025-02-04 02:37:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17960/23838 [00:39<41:11,  2.38it/s][2025-02-04 02:37:29][root][INFO] - Training Epoch: 2/2, step 17959/23838 completed (loss: 0.12153833359479904, acc: 0.9682539701461792)
[2025-02-04 02:37:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17961/23838 [00:40<41:14,  2.38it/s][2025-02-04 02:37:29][root][INFO] - Training Epoch: 2/2, step 17960/23838 completed (loss: 0.3564087152481079, acc: 0.914893627166748)
[2025-02-04 02:37:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17962/23838 [00:40<41:00,  2.39it/s][2025-02-04 02:37:30][root][INFO] - Training Epoch: 2/2, step 17961/23838 completed (loss: 0.08570956438779831, acc: 0.9791666865348816)
[2025-02-04 02:37:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17963/23838 [00:41<43:08,  2.27it/s][2025-02-04 02:37:30][root][INFO] - Training Epoch: 2/2, step 17962/23838 completed (loss: 0.31322112679481506, acc: 0.9253731369972229)
[2025-02-04 02:37:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17964/23838 [00:41<42:57,  2.28it/s][2025-02-04 02:37:31][root][INFO] - Training Epoch: 2/2, step 17963/23838 completed (loss: 0.12580634653568268, acc: 0.95652174949646)
[2025-02-04 02:37:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17965/23838 [00:42<43:33,  2.25it/s][2025-02-04 02:37:31][root][INFO] - Training Epoch: 2/2, step 17964/23838 completed (loss: 0.20768612623214722, acc: 0.9450549483299255)
[2025-02-04 02:37:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17966/23838 [00:42<42:21,  2.31it/s][2025-02-04 02:37:32][root][INFO] - Training Epoch: 2/2, step 17965/23838 completed (loss: 0.39048561453819275, acc: 0.9154929518699646)
[2025-02-04 02:37:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17967/23838 [00:43<42:55,  2.28it/s][2025-02-04 02:37:32][root][INFO] - Training Epoch: 2/2, step 17966/23838 completed (loss: 0.05052062124013901, acc: 0.9894737005233765)
[2025-02-04 02:37:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17968/23838 [00:43<41:41,  2.35it/s][2025-02-04 02:37:32][root][INFO] - Training Epoch: 2/2, step 17967/23838 completed (loss: 0.08715013414621353, acc: 0.9871794581413269)
[2025-02-04 02:37:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17969/23838 [00:43<41:30,  2.36it/s][2025-02-04 02:37:33][root][INFO] - Training Epoch: 2/2, step 17968/23838 completed (loss: 0.05783907696604729, acc: 0.9767441749572754)
[2025-02-04 02:37:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17970/23838 [00:44<40:57,  2.39it/s][2025-02-04 02:37:33][root][INFO] - Training Epoch: 2/2, step 17969/23838 completed (loss: 0.041659992188215256, acc: 1.0)
[2025-02-04 02:37:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17971/23838 [00:44<39:12,  2.49it/s][2025-02-04 02:37:34][root][INFO] - Training Epoch: 2/2, step 17970/23838 completed (loss: 0.4525049030780792, acc: 0.9444444179534912)
[2025-02-04 02:37:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17972/23838 [00:44<38:26,  2.54it/s][2025-02-04 02:37:34][root][INFO] - Training Epoch: 2/2, step 17971/23838 completed (loss: 0.04715992137789726, acc: 1.0)
[2025-02-04 02:37:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17973/23838 [00:45<36:54,  2.65it/s][2025-02-04 02:37:34][root][INFO] - Training Epoch: 2/2, step 17972/23838 completed (loss: 0.036164022982120514, acc: 1.0)
[2025-02-04 02:37:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17974/23838 [00:45<36:31,  2.68it/s][2025-02-04 02:37:35][root][INFO] - Training Epoch: 2/2, step 17973/23838 completed (loss: 0.2376662641763687, acc: 0.9696969985961914)
[2025-02-04 02:37:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17975/23838 [00:46<37:01,  2.64it/s][2025-02-04 02:37:35][root][INFO] - Training Epoch: 2/2, step 17974/23838 completed (loss: 0.10679573565721512, acc: 1.0)
[2025-02-04 02:37:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17976/23838 [00:46<35:17,  2.77it/s][2025-02-04 02:37:35][root][INFO] - Training Epoch: 2/2, step 17975/23838 completed (loss: 0.715522289276123, acc: 0.8235294222831726)
[2025-02-04 02:37:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17977/23838 [00:46<35:51,  2.72it/s][2025-02-04 02:37:36][root][INFO] - Training Epoch: 2/2, step 17976/23838 completed (loss: 0.3174552917480469, acc: 0.9111111164093018)
[2025-02-04 02:37:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17978/23838 [00:47<35:50,  2.73it/s][2025-02-04 02:37:36][root][INFO] - Training Epoch: 2/2, step 17977/23838 completed (loss: 0.4764695167541504, acc: 0.8636363744735718)
[2025-02-04 02:37:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17979/23838 [00:47<34:37,  2.82it/s][2025-02-04 02:37:37][root][INFO] - Training Epoch: 2/2, step 17978/23838 completed (loss: 0.5248978137969971, acc: 0.800000011920929)
[2025-02-04 02:37:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17980/23838 [00:47<34:26,  2.84it/s][2025-02-04 02:37:37][root][INFO] - Training Epoch: 2/2, step 17979/23838 completed (loss: 0.2508260905742645, acc: 0.95652174949646)
[2025-02-04 02:37:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17981/23838 [00:48<34:25,  2.84it/s][2025-02-04 02:37:37][root][INFO] - Training Epoch: 2/2, step 17980/23838 completed (loss: 0.2194947898387909, acc: 0.970588207244873)
[2025-02-04 02:37:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17982/23838 [00:48<35:38,  2.74it/s][2025-02-04 02:37:38][root][INFO] - Training Epoch: 2/2, step 17981/23838 completed (loss: 0.17343178391456604, acc: 0.939393937587738)
[2025-02-04 02:37:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17983/23838 [00:48<36:30,  2.67it/s][2025-02-04 02:37:38][root][INFO] - Training Epoch: 2/2, step 17982/23838 completed (loss: 0.2191820740699768, acc: 0.8666666746139526)
[2025-02-04 02:37:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17984/23838 [00:49<36:33,  2.67it/s][2025-02-04 02:37:38][root][INFO] - Training Epoch: 2/2, step 17983/23838 completed (loss: 0.061188243329524994, acc: 1.0)
[2025-02-04 02:37:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17985/23838 [00:49<37:06,  2.63it/s][2025-02-04 02:37:39][root][INFO] - Training Epoch: 2/2, step 17984/23838 completed (loss: 0.18030035495758057, acc: 0.9411764740943909)
[2025-02-04 02:37:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17986/23838 [00:50<38:54,  2.51it/s][2025-02-04 02:37:39][root][INFO] - Training Epoch: 2/2, step 17985/23838 completed (loss: 0.2515450119972229, acc: 0.8709677457809448)
[2025-02-04 02:37:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17987/23838 [00:50<39:09,  2.49it/s][2025-02-04 02:37:40][root][INFO] - Training Epoch: 2/2, step 17986/23838 completed (loss: 0.054088205099105835, acc: 1.0)
[2025-02-04 02:37:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17988/23838 [00:50<38:50,  2.51it/s][2025-02-04 02:37:40][root][INFO] - Training Epoch: 2/2, step 17987/23838 completed (loss: 0.41030237078666687, acc: 0.8620689511299133)
[2025-02-04 02:37:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17989/23838 [00:51<37:59,  2.57it/s][2025-02-04 02:37:40][root][INFO] - Training Epoch: 2/2, step 17988/23838 completed (loss: 0.13388539850711823, acc: 0.9166666865348816)
[2025-02-04 02:37:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17990/23838 [00:51<37:21,  2.61it/s][2025-02-04 02:37:41][root][INFO] - Training Epoch: 2/2, step 17989/23838 completed (loss: 0.47583118081092834, acc: 0.9259259104728699)
[2025-02-04 02:37:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17991/23838 [00:52<37:10,  2.62it/s][2025-02-04 02:37:41][root][INFO] - Training Epoch: 2/2, step 17990/23838 completed (loss: 0.5262596607208252, acc: 0.8305084705352783)
[2025-02-04 02:37:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17992/23838 [00:52<37:22,  2.61it/s][2025-02-04 02:37:42][root][INFO] - Training Epoch: 2/2, step 17991/23838 completed (loss: 0.4704221487045288, acc: 0.8767123222351074)
[2025-02-04 02:37:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17993/23838 [00:52<38:19,  2.54it/s][2025-02-04 02:37:42][root][INFO] - Training Epoch: 2/2, step 17992/23838 completed (loss: 0.14571067690849304, acc: 0.9791666865348816)
[2025-02-04 02:37:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17994/23838 [00:53<38:31,  2.53it/s][2025-02-04 02:37:42][root][INFO] - Training Epoch: 2/2, step 17993/23838 completed (loss: 0.20654122531414032, acc: 0.9117646813392639)
[2025-02-04 02:37:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17995/23838 [00:53<40:16,  2.42it/s][2025-02-04 02:37:43][root][INFO] - Training Epoch: 2/2, step 17994/23838 completed (loss: 0.6456714868545532, acc: 0.8297872543334961)
[2025-02-04 02:37:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17996/23838 [00:54<40:44,  2.39it/s][2025-02-04 02:37:43][root][INFO] - Training Epoch: 2/2, step 17995/23838 completed (loss: 0.9058261513710022, acc: 0.7659574747085571)
[2025-02-04 02:37:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  75%|[34m███████▌  [0m| 17997/23838 [00:54<42:07,  2.31it/s][2025-02-04 02:37:44][root][INFO] - Training Epoch: 2/2, step 17996/23838 completed (loss: 0.5257436037063599, acc: 0.8658536672592163)
[2025-02-04 02:37:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 17998/23838 [00:55<40:33,  2.40it/s][2025-02-04 02:37:44][root][INFO] - Training Epoch: 2/2, step 17997/23838 completed (loss: 0.0989871472120285, acc: 0.9523809552192688)
[2025-02-04 02:37:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 17999/23838 [00:55<38:54,  2.50it/s][2025-02-04 02:37:44][root][INFO] - Training Epoch: 2/2, step 17998/23838 completed (loss: 0.14028258621692657, acc: 0.9666666388511658)
[2025-02-04 02:37:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18000/23838 [00:55<38:07,  2.55it/s][2025-02-04 02:37:45][root][INFO] - Training Epoch: 2/2, step 17999/23838 completed (loss: 0.14216271042823792, acc: 0.949999988079071)
[2025-02-04 02:37:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18001/23838 [00:56<37:57,  2.56it/s][2025-02-04 02:37:45][root][INFO] - Training Epoch: 2/2, step 18000/23838 completed (loss: 0.23478448390960693, acc: 0.9324324131011963)
[2025-02-04 02:37:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18002/23838 [00:56<37:01,  2.63it/s][2025-02-04 02:37:46][root][INFO] - Training Epoch: 2/2, step 18001/23838 completed (loss: 0.6327735781669617, acc: 0.8690476417541504)
[2025-02-04 02:37:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18003/23838 [00:56<35:57,  2.70it/s][2025-02-04 02:37:46][root][INFO] - Training Epoch: 2/2, step 18002/23838 completed (loss: 0.32572686672210693, acc: 0.9066666960716248)
[2025-02-04 02:37:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18004/23838 [00:57<37:49,  2.57it/s][2025-02-04 02:37:46][root][INFO] - Training Epoch: 2/2, step 18003/23838 completed (loss: 0.6373529434204102, acc: 0.8799999952316284)
[2025-02-04 02:37:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18005/23838 [00:57<37:17,  2.61it/s][2025-02-04 02:37:47][root][INFO] - Training Epoch: 2/2, step 18004/23838 completed (loss: 0.5513690114021301, acc: 0.8260869383811951)
[2025-02-04 02:37:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18006/23838 [00:58<38:54,  2.50it/s][2025-02-04 02:37:47][root][INFO] - Training Epoch: 2/2, step 18005/23838 completed (loss: 0.28364408016204834, acc: 0.931034505367279)
[2025-02-04 02:37:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18007/23838 [00:58<39:11,  2.48it/s][2025-02-04 02:37:48][root][INFO] - Training Epoch: 2/2, step 18006/23838 completed (loss: 0.3500424325466156, acc: 0.8809523582458496)
[2025-02-04 02:37:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18008/23838 [00:58<40:25,  2.40it/s][2025-02-04 02:37:48][root][INFO] - Training Epoch: 2/2, step 18007/23838 completed (loss: 0.20821674168109894, acc: 0.9375)
[2025-02-04 02:37:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18009/23838 [00:59<40:13,  2.41it/s][2025-02-04 02:37:48][root][INFO] - Training Epoch: 2/2, step 18008/23838 completed (loss: 0.3636358976364136, acc: 0.8796296119689941)
[2025-02-04 02:37:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18010/23838 [00:59<38:51,  2.50it/s][2025-02-04 02:37:49][root][INFO] - Training Epoch: 2/2, step 18009/23838 completed (loss: 0.39079368114471436, acc: 0.8999999761581421)
[2025-02-04 02:37:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18011/23838 [01:00<38:35,  2.52it/s][2025-02-04 02:37:49][root][INFO] - Training Epoch: 2/2, step 18010/23838 completed (loss: 0.2444022297859192, acc: 0.8974359035491943)
[2025-02-04 02:37:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18012/23838 [01:00<37:48,  2.57it/s][2025-02-04 02:37:50][root][INFO] - Training Epoch: 2/2, step 18011/23838 completed (loss: 0.30877479910850525, acc: 0.9069767594337463)
[2025-02-04 02:37:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18013/23838 [01:00<38:43,  2.51it/s][2025-02-04 02:37:50][root][INFO] - Training Epoch: 2/2, step 18012/23838 completed (loss: 0.192630797624588, acc: 0.9365079402923584)
[2025-02-04 02:37:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18014/23838 [01:01<38:44,  2.51it/s][2025-02-04 02:37:50][root][INFO] - Training Epoch: 2/2, step 18013/23838 completed (loss: 0.19477953016757965, acc: 0.9268292784690857)
[2025-02-04 02:37:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18015/23838 [01:01<38:41,  2.51it/s][2025-02-04 02:37:51][root][INFO] - Training Epoch: 2/2, step 18014/23838 completed (loss: 0.45301732420921326, acc: 0.8985507488250732)
[2025-02-04 02:37:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18016/23838 [01:02<39:34,  2.45it/s][2025-02-04 02:37:51][root][INFO] - Training Epoch: 2/2, step 18015/23838 completed (loss: 0.47141557931900024, acc: 0.8627451062202454)
[2025-02-04 02:37:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18017/23838 [01:02<36:54,  2.63it/s][2025-02-04 02:37:52][root][INFO] - Training Epoch: 2/2, step 18016/23838 completed (loss: 0.37697163224220276, acc: 0.8999999761581421)
[2025-02-04 02:37:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18018/23838 [01:02<36:22,  2.67it/s][2025-02-04 02:37:52][root][INFO] - Training Epoch: 2/2, step 18017/23838 completed (loss: 0.1499115228652954, acc: 0.9800000190734863)
[2025-02-04 02:37:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18019/23838 [01:03<34:53,  2.78it/s][2025-02-04 02:37:52][root][INFO] - Training Epoch: 2/2, step 18018/23838 completed (loss: 0.04949193820357323, acc: 1.0)
[2025-02-04 02:37:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18020/23838 [01:03<34:53,  2.78it/s][2025-02-04 02:37:53][root][INFO] - Training Epoch: 2/2, step 18019/23838 completed (loss: 0.1444547027349472, acc: 0.9722222089767456)
[2025-02-04 02:37:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18021/23838 [01:03<35:56,  2.70it/s][2025-02-04 02:37:53][root][INFO] - Training Epoch: 2/2, step 18020/23838 completed (loss: 0.15102224051952362, acc: 0.9599999785423279)
[2025-02-04 02:37:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18022/23838 [01:04<35:13,  2.75it/s][2025-02-04 02:37:53][root][INFO] - Training Epoch: 2/2, step 18021/23838 completed (loss: 0.17623203992843628, acc: 0.9298245906829834)
[2025-02-04 02:37:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18023/23838 [01:04<36:41,  2.64it/s][2025-02-04 02:37:54][root][INFO] - Training Epoch: 2/2, step 18022/23838 completed (loss: 0.4126642942428589, acc: 0.8765432238578796)
[2025-02-04 02:37:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18024/23838 [01:04<34:49,  2.78it/s][2025-02-04 02:37:54][root][INFO] - Training Epoch: 2/2, step 18023/23838 completed (loss: 0.1374165415763855, acc: 0.9130434989929199)
[2025-02-04 02:37:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18025/23838 [01:05<36:08,  2.68it/s][2025-02-04 02:37:54][root][INFO] - Training Epoch: 2/2, step 18024/23838 completed (loss: 0.05224376544356346, acc: 1.0)
[2025-02-04 02:37:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18026/23838 [01:05<38:08,  2.54it/s][2025-02-04 02:37:55][root][INFO] - Training Epoch: 2/2, step 18025/23838 completed (loss: 0.4387703835964203, acc: 0.875)
[2025-02-04 02:37:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18027/23838 [01:06<37:03,  2.61it/s][2025-02-04 02:37:55][root][INFO] - Training Epoch: 2/2, step 18026/23838 completed (loss: 0.22540108859539032, acc: 0.9166666865348816)
[2025-02-04 02:37:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18028/23838 [01:06<36:22,  2.66it/s][2025-02-04 02:37:56][root][INFO] - Training Epoch: 2/2, step 18027/23838 completed (loss: 0.5309394598007202, acc: 0.9189189076423645)
[2025-02-04 02:37:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18029/23838 [01:06<36:05,  2.68it/s][2025-02-04 02:37:56][root][INFO] - Training Epoch: 2/2, step 18028/23838 completed (loss: 0.39388003945350647, acc: 0.9024389982223511)
[2025-02-04 02:37:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18030/23838 [01:07<38:27,  2.52it/s][2025-02-04 02:37:56][root][INFO] - Training Epoch: 2/2, step 18029/23838 completed (loss: 0.042801834642887115, acc: 0.9833333492279053)
[2025-02-04 02:37:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18031/23838 [01:07<38:32,  2.51it/s][2025-02-04 02:37:57][root][INFO] - Training Epoch: 2/2, step 18030/23838 completed (loss: 0.1285816878080368, acc: 0.9871794581413269)
[2025-02-04 02:37:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18032/23838 [01:08<37:45,  2.56it/s][2025-02-04 02:37:57][root][INFO] - Training Epoch: 2/2, step 18031/23838 completed (loss: 0.319883793592453, acc: 0.8888888955116272)
[2025-02-04 02:37:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18033/23838 [01:08<36:53,  2.62it/s][2025-02-04 02:37:58][root][INFO] - Training Epoch: 2/2, step 18032/23838 completed (loss: 0.836712121963501, acc: 0.7352941036224365)
[2025-02-04 02:37:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18034/23838 [01:08<35:46,  2.70it/s][2025-02-04 02:37:58][root][INFO] - Training Epoch: 2/2, step 18033/23838 completed (loss: 0.1481751650571823, acc: 0.9090909361839294)
[2025-02-04 02:37:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18035/23838 [01:09<36:02,  2.68it/s][2025-02-04 02:37:58][root][INFO] - Training Epoch: 2/2, step 18034/23838 completed (loss: 0.3146330416202545, acc: 0.9166666865348816)
[2025-02-04 02:37:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18036/23838 [01:09<36:16,  2.67it/s][2025-02-04 02:37:59][root][INFO] - Training Epoch: 2/2, step 18035/23838 completed (loss: 0.26948225498199463, acc: 0.9655172228813171)
[2025-02-04 02:37:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18037/23838 [01:09<36:16,  2.66it/s][2025-02-04 02:37:59][root][INFO] - Training Epoch: 2/2, step 18036/23838 completed (loss: 0.12389051914215088, acc: 0.9666666388511658)
[2025-02-04 02:37:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18038/23838 [01:10<36:08,  2.67it/s][2025-02-04 02:37:59][root][INFO] - Training Epoch: 2/2, step 18037/23838 completed (loss: 0.45623335242271423, acc: 0.8461538553237915)
[2025-02-04 02:38:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18039/23838 [01:10<36:21,  2.66it/s][2025-02-04 02:38:00][root][INFO] - Training Epoch: 2/2, step 18038/23838 completed (loss: 0.0732024684548378, acc: 0.9855072498321533)
[2025-02-04 02:38:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18040/23838 [01:11<36:14,  2.67it/s][2025-02-04 02:38:00][root][INFO] - Training Epoch: 2/2, step 18039/23838 completed (loss: 0.24089862406253815, acc: 0.9509803652763367)
[2025-02-04 02:38:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18041/23838 [01:11<36:41,  2.63it/s][2025-02-04 02:38:01][root][INFO] - Training Epoch: 2/2, step 18040/23838 completed (loss: 0.24685880541801453, acc: 0.9577465057373047)
[2025-02-04 02:38:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18042/23838 [01:11<37:04,  2.61it/s][2025-02-04 02:38:01][root][INFO] - Training Epoch: 2/2, step 18041/23838 completed (loss: 0.28300443291664124, acc: 0.9107142686843872)
[2025-02-04 02:38:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18043/23838 [01:12<38:42,  2.50it/s][2025-02-04 02:38:01][root][INFO] - Training Epoch: 2/2, step 18042/23838 completed (loss: 0.7831936478614807, acc: 0.8037382960319519)
[2025-02-04 02:38:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18044/23838 [01:12<38:04,  2.54it/s][2025-02-04 02:38:02][root][INFO] - Training Epoch: 2/2, step 18043/23838 completed (loss: 0.1530422866344452, acc: 0.9354838728904724)
[2025-02-04 02:38:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18045/23838 [01:13<38:20,  2.52it/s][2025-02-04 02:38:02][root][INFO] - Training Epoch: 2/2, step 18044/23838 completed (loss: 0.10557175427675247, acc: 0.95652174949646)
[2025-02-04 02:38:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18046/23838 [01:13<38:21,  2.52it/s][2025-02-04 02:38:03][root][INFO] - Training Epoch: 2/2, step 18045/23838 completed (loss: 0.3131598234176636, acc: 0.8852459192276001)
[2025-02-04 02:38:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18047/23838 [01:13<37:25,  2.58it/s][2025-02-04 02:38:03][root][INFO] - Training Epoch: 2/2, step 18046/23838 completed (loss: 0.25644898414611816, acc: 0.918367326259613)
[2025-02-04 02:38:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18048/23838 [01:14<36:35,  2.64it/s][2025-02-04 02:38:03][root][INFO] - Training Epoch: 2/2, step 18047/23838 completed (loss: 0.46764427423477173, acc: 0.875)
[2025-02-04 02:38:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18049/23838 [01:14<36:44,  2.63it/s][2025-02-04 02:38:04][root][INFO] - Training Epoch: 2/2, step 18048/23838 completed (loss: 0.21880757808685303, acc: 0.95652174949646)
[2025-02-04 02:38:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18050/23838 [01:14<36:00,  2.68it/s][2025-02-04 02:38:04][root][INFO] - Training Epoch: 2/2, step 18049/23838 completed (loss: 0.23141226172447205, acc: 0.9545454382896423)
[2025-02-04 02:38:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18051/23838 [01:15<36:14,  2.66it/s][2025-02-04 02:38:04][root][INFO] - Training Epoch: 2/2, step 18050/23838 completed (loss: 0.32727667689323425, acc: 0.9154929518699646)
[2025-02-04 02:38:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18052/23838 [01:15<35:57,  2.68it/s][2025-02-04 02:38:05][root][INFO] - Training Epoch: 2/2, step 18051/23838 completed (loss: 0.24842897057533264, acc: 0.9113923907279968)
[2025-02-04 02:38:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18053/23838 [01:16<35:56,  2.68it/s][2025-02-04 02:38:05][root][INFO] - Training Epoch: 2/2, step 18052/23838 completed (loss: 0.22125203907489777, acc: 0.9387755393981934)
[2025-02-04 02:38:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18054/23838 [01:16<36:01,  2.68it/s][2025-02-04 02:38:06][root][INFO] - Training Epoch: 2/2, step 18053/23838 completed (loss: 0.25200459361076355, acc: 0.9318181872367859)
[2025-02-04 02:38:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18055/23838 [01:16<36:24,  2.65it/s][2025-02-04 02:38:06][root][INFO] - Training Epoch: 2/2, step 18054/23838 completed (loss: 0.13324913382530212, acc: 0.9680851101875305)
[2025-02-04 02:38:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18056/23838 [01:17<35:59,  2.68it/s][2025-02-04 02:38:06][root][INFO] - Training Epoch: 2/2, step 18055/23838 completed (loss: 0.10930438339710236, acc: 0.96875)
[2025-02-04 02:38:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18057/23838 [01:17<36:12,  2.66it/s][2025-02-04 02:38:07][root][INFO] - Training Epoch: 2/2, step 18056/23838 completed (loss: 0.5381006598472595, acc: 0.868852436542511)
[2025-02-04 02:38:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18058/23838 [01:17<35:35,  2.71it/s][2025-02-04 02:38:07][root][INFO] - Training Epoch: 2/2, step 18057/23838 completed (loss: 0.4707065522670746, acc: 0.890625)
[2025-02-04 02:38:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18059/23838 [01:18<34:31,  2.79it/s][2025-02-04 02:38:07][root][INFO] - Training Epoch: 2/2, step 18058/23838 completed (loss: 0.16534344851970673, acc: 0.949999988079071)
[2025-02-04 02:38:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18060/23838 [01:18<35:22,  2.72it/s][2025-02-04 02:38:08][root][INFO] - Training Epoch: 2/2, step 18059/23838 completed (loss: 0.3314233422279358, acc: 0.9135802388191223)
[2025-02-04 02:38:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18061/23838 [01:19<38:17,  2.51it/s][2025-02-04 02:38:08][root][INFO] - Training Epoch: 2/2, step 18060/23838 completed (loss: 0.1778249740600586, acc: 0.9555555582046509)
[2025-02-04 02:38:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18062/23838 [01:19<37:48,  2.55it/s][2025-02-04 02:38:09][root][INFO] - Training Epoch: 2/2, step 18061/23838 completed (loss: 0.2884572148323059, acc: 0.9344262480735779)
[2025-02-04 02:38:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18063/23838 [01:19<37:34,  2.56it/s][2025-02-04 02:38:09][root][INFO] - Training Epoch: 2/2, step 18062/23838 completed (loss: 0.6920432448387146, acc: 0.824999988079071)
[2025-02-04 02:38:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18064/23838 [01:20<37:03,  2.60it/s][2025-02-04 02:38:09][root][INFO] - Training Epoch: 2/2, step 18063/23838 completed (loss: 0.2616490423679352, acc: 0.9009901285171509)
[2025-02-04 02:38:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18065/23838 [01:20<36:31,  2.63it/s][2025-02-04 02:38:10][root][INFO] - Training Epoch: 2/2, step 18064/23838 completed (loss: 0.32691118121147156, acc: 0.9158878326416016)
[2025-02-04 02:38:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18066/23838 [01:21<38:34,  2.49it/s][2025-02-04 02:38:10][root][INFO] - Training Epoch: 2/2, step 18065/23838 completed (loss: 0.31698042154312134, acc: 0.8860759735107422)
[2025-02-04 02:38:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18067/23838 [01:21<36:28,  2.64it/s][2025-02-04 02:38:10][root][INFO] - Training Epoch: 2/2, step 18066/23838 completed (loss: 0.41657790541648865, acc: 0.8709677457809448)
[2025-02-04 02:38:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18068/23838 [01:21<36:31,  2.63it/s][2025-02-04 02:38:11][root][INFO] - Training Epoch: 2/2, step 18067/23838 completed (loss: 0.20235982537269592, acc: 0.9729729890823364)
[2025-02-04 02:38:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18069/23838 [01:22<36:12,  2.66it/s][2025-02-04 02:38:11][root][INFO] - Training Epoch: 2/2, step 18068/23838 completed (loss: 0.2898486852645874, acc: 0.9298245906829834)
[2025-02-04 02:38:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18070/23838 [01:22<35:33,  2.70it/s][2025-02-04 02:38:12][root][INFO] - Training Epoch: 2/2, step 18069/23838 completed (loss: 0.08665971457958221, acc: 1.0)
[2025-02-04 02:38:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18071/23838 [01:22<37:36,  2.56it/s][2025-02-04 02:38:12][root][INFO] - Training Epoch: 2/2, step 18070/23838 completed (loss: 0.3058392405509949, acc: 0.9439252614974976)
[2025-02-04 02:38:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18072/23838 [01:23<37:09,  2.59it/s][2025-02-04 02:38:12][root][INFO] - Training Epoch: 2/2, step 18071/23838 completed (loss: 0.2539815604686737, acc: 0.9404761791229248)
[2025-02-04 02:38:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18073/23838 [01:23<36:10,  2.66it/s][2025-02-04 02:38:13][root][INFO] - Training Epoch: 2/2, step 18072/23838 completed (loss: 0.5138750672340393, acc: 0.8148148059844971)
[2025-02-04 02:38:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18074/23838 [01:24<36:15,  2.65it/s][2025-02-04 02:38:13][root][INFO] - Training Epoch: 2/2, step 18073/23838 completed (loss: 0.3278416693210602, acc: 0.8648648858070374)
[2025-02-04 02:38:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18075/23838 [01:24<37:33,  2.56it/s][2025-02-04 02:38:14][root][INFO] - Training Epoch: 2/2, step 18074/23838 completed (loss: 1.0174071788787842, acc: 0.6538461446762085)
[2025-02-04 02:38:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18076/23838 [01:24<37:25,  2.57it/s][2025-02-04 02:38:14][root][INFO] - Training Epoch: 2/2, step 18075/23838 completed (loss: 0.44729575514793396, acc: 0.8518518805503845)
[2025-02-04 02:38:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18077/23838 [01:25<37:21,  2.57it/s][2025-02-04 02:38:14][root][INFO] - Training Epoch: 2/2, step 18076/23838 completed (loss: 1.0080517530441284, acc: 0.7037037014961243)
[2025-02-04 02:38:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18078/23838 [01:25<36:13,  2.65it/s][2025-02-04 02:38:15][root][INFO] - Training Epoch: 2/2, step 18077/23838 completed (loss: 0.311772882938385, acc: 0.96875)
[2025-02-04 02:38:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18079/23838 [01:25<34:22,  2.79it/s][2025-02-04 02:38:15][root][INFO] - Training Epoch: 2/2, step 18078/23838 completed (loss: 0.6802142858505249, acc: 0.8125)
[2025-02-04 02:38:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18080/23838 [01:26<37:20,  2.57it/s][2025-02-04 02:38:15][root][INFO] - Training Epoch: 2/2, step 18079/23838 completed (loss: 1.0478968620300293, acc: 0.6818181872367859)
[2025-02-04 02:38:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18081/23838 [01:26<37:10,  2.58it/s][2025-02-04 02:38:16][root][INFO] - Training Epoch: 2/2, step 18080/23838 completed (loss: 0.1166512593626976, acc: 0.9750000238418579)
[2025-02-04 02:38:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18082/23838 [01:27<36:50,  2.60it/s][2025-02-04 02:38:16][root][INFO] - Training Epoch: 2/2, step 18081/23838 completed (loss: 0.2220483273267746, acc: 0.9599999785423279)
[2025-02-04 02:38:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18083/23838 [01:27<37:31,  2.56it/s][2025-02-04 02:38:17][root][INFO] - Training Epoch: 2/2, step 18082/23838 completed (loss: 1.0565584897994995, acc: 0.6363636255264282)
[2025-02-04 02:38:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18084/23838 [01:27<35:43,  2.68it/s][2025-02-04 02:38:17][root][INFO] - Training Epoch: 2/2, step 18083/23838 completed (loss: 0.5941540002822876, acc: 0.8372092843055725)
[2025-02-04 02:38:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18085/23838 [01:28<35:47,  2.68it/s][2025-02-04 02:38:17][root][INFO] - Training Epoch: 2/2, step 18084/23838 completed (loss: 0.512959361076355, acc: 0.807692289352417)
[2025-02-04 02:38:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18086/23838 [01:28<36:53,  2.60it/s][2025-02-04 02:38:18][root][INFO] - Training Epoch: 2/2, step 18085/23838 completed (loss: 0.16361066699028015, acc: 0.9230769276618958)
[2025-02-04 02:38:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18087/23838 [01:29<36:54,  2.60it/s][2025-02-04 02:38:18][root][INFO] - Training Epoch: 2/2, step 18086/23838 completed (loss: 0.7717181444168091, acc: 0.782608687877655)
[2025-02-04 02:38:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18088/23838 [01:29<36:17,  2.64it/s][2025-02-04 02:38:18][root][INFO] - Training Epoch: 2/2, step 18087/23838 completed (loss: 0.8449959754943848, acc: 0.7142857313156128)
[2025-02-04 02:38:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18089/23838 [01:29<37:05,  2.58it/s][2025-02-04 02:38:19][root][INFO] - Training Epoch: 2/2, step 18088/23838 completed (loss: 0.08953817933797836, acc: 1.0)
[2025-02-04 02:38:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18090/23838 [01:30<37:16,  2.57it/s][2025-02-04 02:38:19][root][INFO] - Training Epoch: 2/2, step 18089/23838 completed (loss: 0.22933341562747955, acc: 0.9285714030265808)
[2025-02-04 02:38:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18091/23838 [01:30<36:55,  2.59it/s][2025-02-04 02:38:20][root][INFO] - Training Epoch: 2/2, step 18090/23838 completed (loss: 1.1289387941360474, acc: 0.6666666865348816)
[2025-02-04 02:38:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18092/23838 [01:31<38:23,  2.49it/s][2025-02-04 02:38:20][root][INFO] - Training Epoch: 2/2, step 18091/23838 completed (loss: 0.14115558564662933, acc: 0.9354838728904724)
[2025-02-04 02:38:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18093/23838 [01:31<36:25,  2.63it/s][2025-02-04 02:38:20][root][INFO] - Training Epoch: 2/2, step 18092/23838 completed (loss: 1.1876274347305298, acc: 0.7142857313156128)
[2025-02-04 02:38:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18094/23838 [01:31<36:12,  2.64it/s][2025-02-04 02:38:21][root][INFO] - Training Epoch: 2/2, step 18093/23838 completed (loss: 0.3195341229438782, acc: 0.9333333373069763)
[2025-02-04 02:38:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18095/23838 [01:32<35:02,  2.73it/s][2025-02-04 02:38:21][root][INFO] - Training Epoch: 2/2, step 18094/23838 completed (loss: 0.1493583619594574, acc: 0.9750000238418579)
[2025-02-04 02:38:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18096/23838 [01:32<34:03,  2.81it/s][2025-02-04 02:38:21][root][INFO] - Training Epoch: 2/2, step 18095/23838 completed (loss: 0.5532265901565552, acc: 0.807692289352417)
[2025-02-04 02:38:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18097/23838 [01:32<33:16,  2.88it/s][2025-02-04 02:38:22][root][INFO] - Training Epoch: 2/2, step 18096/23838 completed (loss: 0.35163965821266174, acc: 0.9032257795333862)
[2025-02-04 02:38:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18098/23838 [01:33<35:03,  2.73it/s][2025-02-04 02:38:22][root][INFO] - Training Epoch: 2/2, step 18097/23838 completed (loss: 0.7230294346809387, acc: 0.800000011920929)
[2025-02-04 02:38:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18099/23838 [01:33<33:40,  2.84it/s][2025-02-04 02:38:23][root][INFO] - Training Epoch: 2/2, step 18098/23838 completed (loss: 0.30241650342941284, acc: 0.9523809552192688)
[2025-02-04 02:38:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18100/23838 [01:33<33:47,  2.83it/s][2025-02-04 02:38:23][root][INFO] - Training Epoch: 2/2, step 18099/23838 completed (loss: 0.47703108191490173, acc: 0.8837209343910217)
[2025-02-04 02:38:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18101/23838 [01:34<34:51,  2.74it/s][2025-02-04 02:38:23][root][INFO] - Training Epoch: 2/2, step 18100/23838 completed (loss: 0.46508294343948364, acc: 0.8108108043670654)
[2025-02-04 02:38:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18102/23838 [01:34<35:20,  2.71it/s][2025-02-04 02:38:24][root][INFO] - Training Epoch: 2/2, step 18101/23838 completed (loss: 0.2776206433773041, acc: 0.9130434989929199)
[2025-02-04 02:38:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18103/23838 [01:34<35:20,  2.70it/s][2025-02-04 02:38:24][root][INFO] - Training Epoch: 2/2, step 18102/23838 completed (loss: 0.21239441633224487, acc: 0.90625)
[2025-02-04 02:38:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18104/23838 [01:35<36:20,  2.63it/s][2025-02-04 02:38:24][root][INFO] - Training Epoch: 2/2, step 18103/23838 completed (loss: 0.8273198008537292, acc: 0.699999988079071)
[2025-02-04 02:38:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18105/23838 [01:35<36:22,  2.63it/s][2025-02-04 02:38:25][root][INFO] - Training Epoch: 2/2, step 18104/23838 completed (loss: 0.5423107147216797, acc: 0.8181818127632141)
[2025-02-04 02:38:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18106/23838 [01:36<36:10,  2.64it/s][2025-02-04 02:38:25][root][INFO] - Training Epoch: 2/2, step 18105/23838 completed (loss: 0.09946062415838242, acc: 1.0)
[2025-02-04 02:38:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18107/23838 [01:36<37:28,  2.55it/s][2025-02-04 02:38:26][root][INFO] - Training Epoch: 2/2, step 18106/23838 completed (loss: 0.47400185465812683, acc: 0.75)
[2025-02-04 02:38:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18108/23838 [01:36<36:45,  2.60it/s][2025-02-04 02:38:26][root][INFO] - Training Epoch: 2/2, step 18107/23838 completed (loss: 0.5883949995040894, acc: 0.9285714030265808)
[2025-02-04 02:38:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18109/23838 [01:37<39:09,  2.44it/s][2025-02-04 02:38:26][root][INFO] - Training Epoch: 2/2, step 18108/23838 completed (loss: 0.6221402287483215, acc: 0.8157894611358643)
[2025-02-04 02:38:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18110/23838 [01:37<39:29,  2.42it/s][2025-02-04 02:38:27][root][INFO] - Training Epoch: 2/2, step 18109/23838 completed (loss: 0.7832034230232239, acc: 0.8333333134651184)
[2025-02-04 02:38:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18111/23838 [01:38<39:35,  2.41it/s][2025-02-04 02:38:27][root][INFO] - Training Epoch: 2/2, step 18110/23838 completed (loss: 0.7035765051841736, acc: 0.8181818127632141)
[2025-02-04 02:38:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18112/23838 [01:38<37:30,  2.54it/s][2025-02-04 02:38:28][root][INFO] - Training Epoch: 2/2, step 18111/23838 completed (loss: 0.4976324737071991, acc: 0.8125)
[2025-02-04 02:38:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18113/23838 [01:38<36:52,  2.59it/s][2025-02-04 02:38:28][root][INFO] - Training Epoch: 2/2, step 18112/23838 completed (loss: 0.27508413791656494, acc: 0.8799999952316284)
[2025-02-04 02:38:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18114/23838 [01:39<37:10,  2.57it/s][2025-02-04 02:38:28][root][INFO] - Training Epoch: 2/2, step 18113/23838 completed (loss: 0.33416447043418884, acc: 0.8799999952316284)
[2025-02-04 02:38:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18115/23838 [01:39<37:07,  2.57it/s][2025-02-04 02:38:29][root][INFO] - Training Epoch: 2/2, step 18114/23838 completed (loss: 0.17343004047870636, acc: 0.9791666865348816)
[2025-02-04 02:38:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18116/23838 [01:40<38:10,  2.50it/s][2025-02-04 02:38:29][root][INFO] - Training Epoch: 2/2, step 18115/23838 completed (loss: 0.15105171501636505, acc: 0.9642857313156128)
[2025-02-04 02:38:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18117/23838 [01:40<39:08,  2.44it/s][2025-02-04 02:38:30][root][INFO] - Training Epoch: 2/2, step 18116/23838 completed (loss: 0.1725078672170639, acc: 0.957446813583374)
[2025-02-04 02:38:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18118/23838 [01:41<42:15,  2.26it/s][2025-02-04 02:38:30][root][INFO] - Training Epoch: 2/2, step 18117/23838 completed (loss: 0.11935144662857056, acc: 0.9868420958518982)
[2025-02-04 02:38:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18119/23838 [01:41<39:37,  2.41it/s][2025-02-04 02:38:31][root][INFO] - Training Epoch: 2/2, step 18118/23838 completed (loss: 0.15760420262813568, acc: 0.95652174949646)
[2025-02-04 02:38:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18120/23838 [01:41<37:57,  2.51it/s][2025-02-04 02:38:31][root][INFO] - Training Epoch: 2/2, step 18119/23838 completed (loss: 0.649474024772644, acc: 0.8518518805503845)
[2025-02-04 02:38:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18121/23838 [01:42<36:56,  2.58it/s][2025-02-04 02:38:31][root][INFO] - Training Epoch: 2/2, step 18120/23838 completed (loss: 0.8182514905929565, acc: 0.7857142686843872)
[2025-02-04 02:38:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18122/23838 [01:42<35:55,  2.65it/s][2025-02-04 02:38:32][root][INFO] - Training Epoch: 2/2, step 18121/23838 completed (loss: 0.4695689380168915, acc: 0.8529411554336548)
[2025-02-04 02:38:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18123/23838 [01:42<34:54,  2.73it/s][2025-02-04 02:38:32][root][INFO] - Training Epoch: 2/2, step 18122/23838 completed (loss: 0.34735190868377686, acc: 0.875)
[2025-02-04 02:38:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18124/23838 [01:43<34:54,  2.73it/s][2025-02-04 02:38:32][root][INFO] - Training Epoch: 2/2, step 18123/23838 completed (loss: 0.45386040210723877, acc: 0.8703703880310059)
[2025-02-04 02:38:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18125/23838 [01:43<35:19,  2.70it/s][2025-02-04 02:38:33][root][INFO] - Training Epoch: 2/2, step 18124/23838 completed (loss: 0.028409413993358612, acc: 1.0)
[2025-02-04 02:38:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18126/23838 [01:44<39:45,  2.39it/s][2025-02-04 02:38:33][root][INFO] - Training Epoch: 2/2, step 18125/23838 completed (loss: 0.23027203977108002, acc: 0.9354838728904724)
[2025-02-04 02:38:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18127/23838 [01:44<38:29,  2.47it/s][2025-02-04 02:38:34][root][INFO] - Training Epoch: 2/2, step 18126/23838 completed (loss: 0.09271933138370514, acc: 1.0)
[2025-02-04 02:38:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18128/23838 [01:44<38:04,  2.50it/s][2025-02-04 02:38:34][root][INFO] - Training Epoch: 2/2, step 18127/23838 completed (loss: 0.23365040123462677, acc: 0.9230769276618958)
[2025-02-04 02:38:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18129/23838 [01:45<38:37,  2.46it/s][2025-02-04 02:38:34][root][INFO] - Training Epoch: 2/2, step 18128/23838 completed (loss: 0.1610874980688095, acc: 0.9599999785423279)
[2025-02-04 02:38:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18130/23838 [01:45<40:17,  2.36it/s][2025-02-04 02:38:35][root][INFO] - Training Epoch: 2/2, step 18129/23838 completed (loss: 0.515255868434906, acc: 0.8666666746139526)
[2025-02-04 02:38:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18131/23838 [01:46<40:06,  2.37it/s][2025-02-04 02:38:35][root][INFO] - Training Epoch: 2/2, step 18130/23838 completed (loss: 0.022447902709245682, acc: 1.0)
[2025-02-04 02:38:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18132/23838 [01:46<37:40,  2.52it/s][2025-02-04 02:38:36][root][INFO] - Training Epoch: 2/2, step 18131/23838 completed (loss: 0.5049230456352234, acc: 0.84375)
[2025-02-04 02:38:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18133/23838 [01:46<36:22,  2.61it/s][2025-02-04 02:38:36][root][INFO] - Training Epoch: 2/2, step 18132/23838 completed (loss: 0.10580208152532578, acc: 0.95652174949646)
[2025-02-04 02:38:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18134/23838 [01:47<35:48,  2.66it/s][2025-02-04 02:38:36][root][INFO] - Training Epoch: 2/2, step 18133/23838 completed (loss: 1.1955082416534424, acc: 0.7297297120094299)
[2025-02-04 02:38:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18135/23838 [01:47<33:48,  2.81it/s][2025-02-04 02:38:37][root][INFO] - Training Epoch: 2/2, step 18134/23838 completed (loss: 0.2930707633495331, acc: 0.9245283007621765)
[2025-02-04 02:38:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18136/23838 [01:47<33:20,  2.85it/s][2025-02-04 02:38:37][root][INFO] - Training Epoch: 2/2, step 18135/23838 completed (loss: 0.35506537556648254, acc: 0.9220778942108154)
[2025-02-04 02:38:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18137/23838 [01:48<33:41,  2.82it/s][2025-02-04 02:38:37][root][INFO] - Training Epoch: 2/2, step 18136/23838 completed (loss: 0.6031649708747864, acc: 0.8591549396514893)
[2025-02-04 02:38:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18138/23838 [01:48<34:34,  2.75it/s][2025-02-04 02:38:38][root][INFO] - Training Epoch: 2/2, step 18137/23838 completed (loss: 0.3691411018371582, acc: 0.8979591727256775)
[2025-02-04 02:38:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18139/23838 [01:49<35:40,  2.66it/s][2025-02-04 02:38:38][root][INFO] - Training Epoch: 2/2, step 18138/23838 completed (loss: 0.7922181487083435, acc: 0.7777777910232544)
[2025-02-04 02:38:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18140/23838 [01:49<36:18,  2.62it/s][2025-02-04 02:38:39][root][INFO] - Training Epoch: 2/2, step 18139/23838 completed (loss: 1.4463927745819092, acc: 0.5555555820465088)
[2025-02-04 02:38:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18141/23838 [01:49<37:09,  2.55it/s][2025-02-04 02:38:39][root][INFO] - Training Epoch: 2/2, step 18140/23838 completed (loss: 0.4606107473373413, acc: 0.875)
[2025-02-04 02:38:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18142/23838 [01:50<37:05,  2.56it/s][2025-02-04 02:38:39][root][INFO] - Training Epoch: 2/2, step 18141/23838 completed (loss: 0.8838818073272705, acc: 0.7021276354789734)
[2025-02-04 02:38:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18143/23838 [01:50<38:59,  2.43it/s][2025-02-04 02:38:40][root][INFO] - Training Epoch: 2/2, step 18142/23838 completed (loss: 0.08786594867706299, acc: 0.9696969985961914)
[2025-02-04 02:38:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18144/23838 [01:51<38:29,  2.47it/s][2025-02-04 02:38:40][root][INFO] - Training Epoch: 2/2, step 18143/23838 completed (loss: 0.1752740889787674, acc: 0.9767441749572754)
[2025-02-04 02:38:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18145/23838 [01:51<37:40,  2.52it/s][2025-02-04 02:38:41][root][INFO] - Training Epoch: 2/2, step 18144/23838 completed (loss: 0.4206635057926178, acc: 0.8999999761581421)
[2025-02-04 02:38:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18146/23838 [01:51<35:59,  2.64it/s][2025-02-04 02:38:41][root][INFO] - Training Epoch: 2/2, step 18145/23838 completed (loss: 0.08270175009965897, acc: 1.0)
[2025-02-04 02:38:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18147/23838 [01:52<35:53,  2.64it/s][2025-02-04 02:38:41][root][INFO] - Training Epoch: 2/2, step 18146/23838 completed (loss: 0.6349090337753296, acc: 0.8166666626930237)
[2025-02-04 02:38:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18148/23838 [01:52<35:36,  2.66it/s][2025-02-04 02:38:42][root][INFO] - Training Epoch: 2/2, step 18147/23838 completed (loss: 0.14390866458415985, acc: 0.9491525292396545)
[2025-02-04 02:38:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18149/23838 [01:52<35:02,  2.71it/s][2025-02-04 02:38:42][root][INFO] - Training Epoch: 2/2, step 18148/23838 completed (loss: 0.26853975653648376, acc: 0.9259259104728699)
[2025-02-04 02:38:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18150/23838 [01:53<36:04,  2.63it/s][2025-02-04 02:38:42][root][INFO] - Training Epoch: 2/2, step 18149/23838 completed (loss: 0.40297624468803406, acc: 0.837837815284729)
[2025-02-04 02:38:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18151/23838 [01:53<36:35,  2.59it/s][2025-02-04 02:38:43][root][INFO] - Training Epoch: 2/2, step 18150/23838 completed (loss: 0.47291794419288635, acc: 0.8529411554336548)
[2025-02-04 02:38:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18152/23838 [01:54<37:22,  2.54it/s][2025-02-04 02:38:43][root][INFO] - Training Epoch: 2/2, step 18151/23838 completed (loss: 0.09381717443466187, acc: 0.9599999785423279)
[2025-02-04 02:38:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18153/23838 [01:54<37:48,  2.51it/s][2025-02-04 02:38:44][root][INFO] - Training Epoch: 2/2, step 18152/23838 completed (loss: 0.2098957747220993, acc: 0.9473684430122375)
[2025-02-04 02:38:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18154/23838 [01:54<37:36,  2.52it/s][2025-02-04 02:38:44][root][INFO] - Training Epoch: 2/2, step 18153/23838 completed (loss: 0.2818242013454437, acc: 0.9200000166893005)
[2025-02-04 02:38:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18155/23838 [01:55<37:45,  2.51it/s][2025-02-04 02:38:44][root][INFO] - Training Epoch: 2/2, step 18154/23838 completed (loss: 0.10666652768850327, acc: 0.9740259647369385)
[2025-02-04 02:38:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18156/23838 [01:55<36:50,  2.57it/s][2025-02-04 02:38:45][root][INFO] - Training Epoch: 2/2, step 18155/23838 completed (loss: 0.2738555669784546, acc: 0.925000011920929)
[2025-02-04 02:38:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18157/23838 [01:56<36:56,  2.56it/s][2025-02-04 02:38:45][root][INFO] - Training Epoch: 2/2, step 18156/23838 completed (loss: 0.3514493405818939, acc: 0.9019607901573181)
[2025-02-04 02:38:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18158/23838 [01:56<35:55,  2.64it/s][2025-02-04 02:38:46][root][INFO] - Training Epoch: 2/2, step 18157/23838 completed (loss: 0.071855828166008, acc: 0.9772727489471436)
[2025-02-04 02:38:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18159/23838 [01:56<35:55,  2.64it/s][2025-02-04 02:38:46][root][INFO] - Training Epoch: 2/2, step 18158/23838 completed (loss: 0.12730182707309723, acc: 0.9583333134651184)
[2025-02-04 02:38:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18160/23838 [01:57<35:55,  2.63it/s][2025-02-04 02:38:46][root][INFO] - Training Epoch: 2/2, step 18159/23838 completed (loss: 0.2728152871131897, acc: 0.8888888955116272)
[2025-02-04 02:38:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18161/23838 [01:57<36:28,  2.59it/s][2025-02-04 02:38:47][root][INFO] - Training Epoch: 2/2, step 18160/23838 completed (loss: 0.1180768609046936, acc: 0.9818181991577148)
[2025-02-04 02:38:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18162/23838 [01:57<35:29,  2.67it/s][2025-02-04 02:38:47][root][INFO] - Training Epoch: 2/2, step 18161/23838 completed (loss: 0.16605323553085327, acc: 0.9482758641242981)
[2025-02-04 02:38:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18163/23838 [01:58<36:58,  2.56it/s][2025-02-04 02:38:47][root][INFO] - Training Epoch: 2/2, step 18162/23838 completed (loss: 0.4488065540790558, acc: 0.9042553305625916)
[2025-02-04 02:38:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18164/23838 [01:58<36:25,  2.60it/s][2025-02-04 02:38:48][root][INFO] - Training Epoch: 2/2, step 18163/23838 completed (loss: 0.34633868932724, acc: 0.9012345671653748)
[2025-02-04 02:38:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18165/23838 [01:59<36:26,  2.59it/s][2025-02-04 02:38:48][root][INFO] - Training Epoch: 2/2, step 18164/23838 completed (loss: 0.30923765897750854, acc: 0.9090909361839294)
[2025-02-04 02:38:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18166/23838 [01:59<36:43,  2.57it/s][2025-02-04 02:38:49][root][INFO] - Training Epoch: 2/2, step 18165/23838 completed (loss: 0.4686187505722046, acc: 0.8641975522041321)
[2025-02-04 02:38:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18167/23838 [01:59<36:24,  2.60it/s][2025-02-04 02:38:49][root][INFO] - Training Epoch: 2/2, step 18166/23838 completed (loss: 0.4544662535190582, acc: 0.9069767594337463)
[2025-02-04 02:38:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18168/23838 [02:00<36:01,  2.62it/s][2025-02-04 02:38:49][root][INFO] - Training Epoch: 2/2, step 18167/23838 completed (loss: 0.33417317271232605, acc: 0.9041095972061157)
[2025-02-04 02:38:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18169/23838 [02:00<36:52,  2.56it/s][2025-02-04 02:38:50][root][INFO] - Training Epoch: 2/2, step 18168/23838 completed (loss: 0.14027215540409088, acc: 0.9285714030265808)
[2025-02-04 02:38:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18170/23838 [02:01<37:21,  2.53it/s][2025-02-04 02:38:50][root][INFO] - Training Epoch: 2/2, step 18169/23838 completed (loss: 0.9762334823608398, acc: 0.737864077091217)
[2025-02-04 02:38:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18171/23838 [02:01<37:34,  2.51it/s][2025-02-04 02:38:51][root][INFO] - Training Epoch: 2/2, step 18170/23838 completed (loss: 0.2902039885520935, acc: 0.9175257682800293)
[2025-02-04 02:38:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18172/23838 [02:01<37:18,  2.53it/s][2025-02-04 02:38:51][root][INFO] - Training Epoch: 2/2, step 18171/23838 completed (loss: 0.5436593294143677, acc: 0.849056601524353)
[2025-02-04 02:38:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18173/23838 [02:02<36:40,  2.57it/s][2025-02-04 02:38:51][root][INFO] - Training Epoch: 2/2, step 18172/23838 completed (loss: 0.5067400932312012, acc: 0.8681318759918213)
[2025-02-04 02:38:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18174/23838 [02:02<34:46,  2.71it/s][2025-02-04 02:38:52][root][INFO] - Training Epoch: 2/2, step 18173/23838 completed (loss: 0.6254382133483887, acc: 0.875)
[2025-02-04 02:38:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18175/23838 [02:02<33:58,  2.78it/s][2025-02-04 02:38:52][root][INFO] - Training Epoch: 2/2, step 18174/23838 completed (loss: 0.6450564861297607, acc: 0.8417266011238098)
[2025-02-04 02:38:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▌  [0m| 18176/23838 [02:03<34:03,  2.77it/s][2025-02-04 02:38:52][root][INFO] - Training Epoch: 2/2, step 18175/23838 completed (loss: 0.634392499923706, acc: 0.8290598392486572)
[2025-02-04 02:38:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18177/23838 [02:03<32:42,  2.88it/s][2025-02-04 02:38:53][root][INFO] - Training Epoch: 2/2, step 18176/23838 completed (loss: 0.8424510955810547, acc: 0.800000011920929)
[2025-02-04 02:38:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18178/23838 [02:03<32:31,  2.90it/s][2025-02-04 02:38:53][root][INFO] - Training Epoch: 2/2, step 18177/23838 completed (loss: 0.38879263401031494, acc: 0.90625)
[2025-02-04 02:38:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18179/23838 [02:04<33:23,  2.82it/s][2025-02-04 02:38:53][root][INFO] - Training Epoch: 2/2, step 18178/23838 completed (loss: 0.350471168756485, acc: 0.9275362491607666)
[2025-02-04 02:38:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18180/23838 [02:04<32:22,  2.91it/s][2025-02-04 02:38:54][root][INFO] - Training Epoch: 2/2, step 18179/23838 completed (loss: 0.3034164607524872, acc: 0.9277108311653137)
[2025-02-04 02:38:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18181/23838 [02:04<32:14,  2.93it/s][2025-02-04 02:38:54][root][INFO] - Training Epoch: 2/2, step 18180/23838 completed (loss: 0.8004701137542725, acc: 0.7777777910232544)
[2025-02-04 02:38:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18182/23838 [02:05<30:57,  3.04it/s][2025-02-04 02:38:54][root][INFO] - Training Epoch: 2/2, step 18181/23838 completed (loss: 1.4397234916687012, acc: 0.6000000238418579)
[2025-02-04 02:38:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18183/23838 [02:05<30:21,  3.11it/s][2025-02-04 02:38:55][root][INFO] - Training Epoch: 2/2, step 18182/23838 completed (loss: 0.6740456819534302, acc: 0.8139534592628479)
[2025-02-04 02:38:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18184/23838 [02:05<31:53,  2.95it/s][2025-02-04 02:38:55][root][INFO] - Training Epoch: 2/2, step 18183/23838 completed (loss: 0.33458012342453003, acc: 0.9191918969154358)
[2025-02-04 02:38:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18185/23838 [02:06<33:50,  2.78it/s][2025-02-04 02:38:55][root][INFO] - Training Epoch: 2/2, step 18184/23838 completed (loss: 0.4819709360599518, acc: 0.9076923131942749)
[2025-02-04 02:38:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18186/23838 [02:06<35:07,  2.68it/s][2025-02-04 02:38:56][root][INFO] - Training Epoch: 2/2, step 18185/23838 completed (loss: 0.32503750920295715, acc: 0.8999999761581421)
[2025-02-04 02:38:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18187/23838 [02:07<36:18,  2.59it/s][2025-02-04 02:38:56][root][INFO] - Training Epoch: 2/2, step 18186/23838 completed (loss: 0.5754916667938232, acc: 0.8444444537162781)
[2025-02-04 02:38:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18188/23838 [02:07<36:09,  2.60it/s][2025-02-04 02:38:57][root][INFO] - Training Epoch: 2/2, step 18187/23838 completed (loss: 0.37033727765083313, acc: 0.9108911156654358)
[2025-02-04 02:38:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18189/23838 [02:07<36:20,  2.59it/s][2025-02-04 02:38:57][root][INFO] - Training Epoch: 2/2, step 18188/23838 completed (loss: 0.3290901780128479, acc: 0.8999999761581421)
[2025-02-04 02:38:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18190/23838 [02:08<35:24,  2.66it/s][2025-02-04 02:38:57][root][INFO] - Training Epoch: 2/2, step 18189/23838 completed (loss: 0.7468264698982239, acc: 0.7250000238418579)
[2025-02-04 02:38:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18191/23838 [02:08<35:36,  2.64it/s][2025-02-04 02:38:58][root][INFO] - Training Epoch: 2/2, step 18190/23838 completed (loss: 0.6736040115356445, acc: 0.8101266026496887)
[2025-02-04 02:38:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18192/23838 [02:09<36:20,  2.59it/s][2025-02-04 02:38:58][root][INFO] - Training Epoch: 2/2, step 18191/23838 completed (loss: 0.6572248339653015, acc: 0.8253968358039856)
[2025-02-04 02:38:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18193/23838 [02:09<35:39,  2.64it/s][2025-02-04 02:38:59][root][INFO] - Training Epoch: 2/2, step 18192/23838 completed (loss: 0.43014007806777954, acc: 0.8571428656578064)
[2025-02-04 02:38:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18194/23838 [02:09<34:57,  2.69it/s][2025-02-04 02:38:59][root][INFO] - Training Epoch: 2/2, step 18193/23838 completed (loss: 0.44141754508018494, acc: 0.9200000166893005)
[2025-02-04 02:38:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18195/23838 [02:10<34:05,  2.76it/s][2025-02-04 02:38:59][root][INFO] - Training Epoch: 2/2, step 18194/23838 completed (loss: 0.6078991889953613, acc: 0.7903226017951965)
[2025-02-04 02:38:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18196/23838 [02:10<35:13,  2.67it/s][2025-02-04 02:39:00][root][INFO] - Training Epoch: 2/2, step 18195/23838 completed (loss: 0.2635442912578583, acc: 0.9354838728904724)
[2025-02-04 02:39:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18197/23838 [02:11<37:33,  2.50it/s][2025-02-04 02:39:00][root][INFO] - Training Epoch: 2/2, step 18196/23838 completed (loss: 0.32647424936294556, acc: 0.9354838728904724)
[2025-02-04 02:39:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18198/23838 [02:11<37:04,  2.53it/s][2025-02-04 02:39:00][root][INFO] - Training Epoch: 2/2, step 18197/23838 completed (loss: 0.6112932562828064, acc: 0.7674418687820435)
[2025-02-04 02:39:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18199/23838 [02:11<36:47,  2.55it/s][2025-02-04 02:39:01][root][INFO] - Training Epoch: 2/2, step 18198/23838 completed (loss: 0.1918426752090454, acc: 0.9534883499145508)
[2025-02-04 02:39:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18200/23838 [02:12<35:37,  2.64it/s][2025-02-04 02:39:01][root][INFO] - Training Epoch: 2/2, step 18199/23838 completed (loss: 0.2885228395462036, acc: 0.8636363744735718)
[2025-02-04 02:39:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18201/23838 [02:12<35:05,  2.68it/s][2025-02-04 02:39:02][root][INFO] - Training Epoch: 2/2, step 18200/23838 completed (loss: 0.5472620725631714, acc: 0.875)
[2025-02-04 02:39:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18202/23838 [02:12<35:10,  2.67it/s][2025-02-04 02:39:02][root][INFO] - Training Epoch: 2/2, step 18201/23838 completed (loss: 0.5359654426574707, acc: 0.84375)
[2025-02-04 02:39:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18203/23838 [02:13<33:57,  2.77it/s][2025-02-04 02:39:02][root][INFO] - Training Epoch: 2/2, step 18202/23838 completed (loss: 0.8610486388206482, acc: 0.7142857313156128)
[2025-02-04 02:39:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18204/23838 [02:13<33:40,  2.79it/s][2025-02-04 02:39:03][root][INFO] - Training Epoch: 2/2, step 18203/23838 completed (loss: 0.3824065923690796, acc: 0.8867924809455872)
[2025-02-04 02:39:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18205/23838 [02:13<33:10,  2.83it/s][2025-02-04 02:39:03][root][INFO] - Training Epoch: 2/2, step 18204/23838 completed (loss: 0.612311840057373, acc: 0.8088235259056091)
[2025-02-04 02:39:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18206/23838 [02:14<34:08,  2.75it/s][2025-02-04 02:39:03][root][INFO] - Training Epoch: 2/2, step 18205/23838 completed (loss: 0.5509039163589478, acc: 0.918367326259613)
[2025-02-04 02:39:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18207/23838 [02:14<37:05,  2.53it/s][2025-02-04 02:39:04][root][INFO] - Training Epoch: 2/2, step 18206/23838 completed (loss: 0.5175552368164062, acc: 0.8787878751754761)
[2025-02-04 02:39:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18208/23838 [02:15<36:44,  2.55it/s][2025-02-04 02:39:04][root][INFO] - Training Epoch: 2/2, step 18207/23838 completed (loss: 0.4054705798625946, acc: 0.8846153616905212)
[2025-02-04 02:39:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18209/23838 [02:15<37:49,  2.48it/s][2025-02-04 02:39:05][root][INFO] - Training Epoch: 2/2, step 18208/23838 completed (loss: 0.5965651869773865, acc: 0.8571428656578064)
[2025-02-04 02:39:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18210/23838 [02:15<36:59,  2.54it/s][2025-02-04 02:39:05][root][INFO] - Training Epoch: 2/2, step 18209/23838 completed (loss: 1.4265602827072144, acc: 0.6363636255264282)
[2025-02-04 02:39:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18211/23838 [02:16<35:49,  2.62it/s][2025-02-04 02:39:05][root][INFO] - Training Epoch: 2/2, step 18210/23838 completed (loss: 0.7385701537132263, acc: 0.7727272510528564)
[2025-02-04 02:39:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18212/23838 [02:16<38:32,  2.43it/s][2025-02-04 02:39:06][root][INFO] - Training Epoch: 2/2, step 18211/23838 completed (loss: 0.5102704763412476, acc: 0.8500000238418579)
[2025-02-04 02:39:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18213/23838 [02:17<36:37,  2.56it/s][2025-02-04 02:39:06][root][INFO] - Training Epoch: 2/2, step 18212/23838 completed (loss: 0.8938908576965332, acc: 0.75)
[2025-02-04 02:39:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18214/23838 [02:17<35:09,  2.67it/s][2025-02-04 02:39:07][root][INFO] - Training Epoch: 2/2, step 18213/23838 completed (loss: 0.47285130620002747, acc: 0.8536585569381714)
[2025-02-04 02:39:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18215/23838 [02:17<34:09,  2.74it/s][2025-02-04 02:39:07][root][INFO] - Training Epoch: 2/2, step 18214/23838 completed (loss: 0.3248949646949768, acc: 0.893203854560852)
[2025-02-04 02:39:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18216/23838 [02:18<33:41,  2.78it/s][2025-02-04 02:39:07][root][INFO] - Training Epoch: 2/2, step 18215/23838 completed (loss: 0.392650306224823, acc: 0.8518518805503845)
[2025-02-04 02:39:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18217/23838 [02:18<33:50,  2.77it/s][2025-02-04 02:39:08][root][INFO] - Training Epoch: 2/2, step 18216/23838 completed (loss: 0.4217514395713806, acc: 0.824999988079071)
[2025-02-04 02:39:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18218/23838 [02:18<35:58,  2.60it/s][2025-02-04 02:39:08][root][INFO] - Training Epoch: 2/2, step 18217/23838 completed (loss: 0.41349878907203674, acc: 0.9009901285171509)
[2025-02-04 02:39:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18219/23838 [02:19<37:32,  2.49it/s][2025-02-04 02:39:08][root][INFO] - Training Epoch: 2/2, step 18218/23838 completed (loss: 0.3540666401386261, acc: 0.8880000114440918)
[2025-02-04 02:39:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18220/23838 [02:19<36:12,  2.59it/s][2025-02-04 02:39:09][root][INFO] - Training Epoch: 2/2, step 18219/23838 completed (loss: 0.23388588428497314, acc: 0.9375)
[2025-02-04 02:39:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18221/23838 [02:20<36:05,  2.59it/s][2025-02-04 02:39:09][root][INFO] - Training Epoch: 2/2, step 18220/23838 completed (loss: 0.8935458064079285, acc: 0.7704917788505554)
[2025-02-04 02:39:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18222/23838 [02:20<36:49,  2.54it/s][2025-02-04 02:39:10][root][INFO] - Training Epoch: 2/2, step 18221/23838 completed (loss: 0.4675511121749878, acc: 0.8837209343910217)
[2025-02-04 02:39:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18223/23838 [02:20<36:04,  2.59it/s][2025-02-04 02:39:10][root][INFO] - Training Epoch: 2/2, step 18222/23838 completed (loss: 0.5314130783081055, acc: 0.8799999952316284)
[2025-02-04 02:39:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18224/23838 [02:21<37:15,  2.51it/s][2025-02-04 02:39:10][root][INFO] - Training Epoch: 2/2, step 18223/23838 completed (loss: 0.5103996992111206, acc: 0.8289473652839661)
[2025-02-04 02:39:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18225/23838 [02:21<34:35,  2.70it/s][2025-02-04 02:39:11][root][INFO] - Training Epoch: 2/2, step 18224/23838 completed (loss: 0.45300647616386414, acc: 0.9080459475517273)
[2025-02-04 02:39:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18226/23838 [02:22<35:56,  2.60it/s][2025-02-04 02:39:11][root][INFO] - Training Epoch: 2/2, step 18225/23838 completed (loss: 0.2646405100822449, acc: 0.9300000071525574)
[2025-02-04 02:39:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18227/23838 [02:22<35:32,  2.63it/s][2025-02-04 02:39:12][root][INFO] - Training Epoch: 2/2, step 18226/23838 completed (loss: 0.4309038817882538, acc: 0.890625)
[2025-02-04 02:39:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18228/23838 [02:22<33:43,  2.77it/s][2025-02-04 02:39:12][root][INFO] - Training Epoch: 2/2, step 18227/23838 completed (loss: 0.6059841513633728, acc: 0.7777777910232544)
[2025-02-04 02:39:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18229/23838 [02:23<33:43,  2.77it/s][2025-02-04 02:39:12][root][INFO] - Training Epoch: 2/2, step 18228/23838 completed (loss: 0.3667106330394745, acc: 0.8703703880310059)
[2025-02-04 02:39:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18230/23838 [02:23<35:30,  2.63it/s][2025-02-04 02:39:13][root][INFO] - Training Epoch: 2/2, step 18229/23838 completed (loss: 0.2414347380399704, acc: 0.9281045794487)
[2025-02-04 02:39:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18231/23838 [02:24<38:40,  2.42it/s][2025-02-04 02:39:13][root][INFO] - Training Epoch: 2/2, step 18230/23838 completed (loss: 0.31030699610710144, acc: 0.9100000262260437)
[2025-02-04 02:39:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18232/23838 [02:24<39:28,  2.37it/s][2025-02-04 02:39:14][root][INFO] - Training Epoch: 2/2, step 18231/23838 completed (loss: 0.4485888183116913, acc: 0.8641975522041321)
[2025-02-04 02:39:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18233/23838 [02:24<37:53,  2.47it/s][2025-02-04 02:39:14][root][INFO] - Training Epoch: 2/2, step 18232/23838 completed (loss: 0.21188290417194366, acc: 0.954023003578186)
[2025-02-04 02:39:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18234/23838 [02:25<35:58,  2.60it/s][2025-02-04 02:39:14][root][INFO] - Training Epoch: 2/2, step 18233/23838 completed (loss: 0.29182446002960205, acc: 0.9259259104728699)
[2025-02-04 02:39:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18235/23838 [02:25<35:27,  2.63it/s][2025-02-04 02:39:15][root][INFO] - Training Epoch: 2/2, step 18234/23838 completed (loss: 0.5226726531982422, acc: 0.835616409778595)
[2025-02-04 02:39:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  76%|[34m███████▋  [0m| 18236/23838 [02:25<36:00,  2.59it/s][2025-02-04 02:39:15][root][INFO] - Training Epoch: 2/2, step 18235/23838 completed (loss: 0.4137031137943268, acc: 0.9081632494926453)
[2025-02-04 02:39:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18237/23838 [02:26<36:49,  2.53it/s][2025-02-04 02:39:15][root][INFO] - Training Epoch: 2/2, step 18236/23838 completed (loss: 0.3690606355667114, acc: 0.859649121761322)
[2025-02-04 02:39:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18238/23838 [02:26<36:40,  2.54it/s][2025-02-04 02:39:16][root][INFO] - Training Epoch: 2/2, step 18237/23838 completed (loss: 0.601378858089447, acc: 0.75)
[2025-02-04 02:39:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18239/23838 [02:27<37:04,  2.52it/s][2025-02-04 02:39:16][root][INFO] - Training Epoch: 2/2, step 18238/23838 completed (loss: 0.4752638339996338, acc: 0.8695651888847351)
[2025-02-04 02:39:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18240/23838 [02:27<35:59,  2.59it/s][2025-02-04 02:39:17][root][INFO] - Training Epoch: 2/2, step 18239/23838 completed (loss: 0.7317816615104675, acc: 0.7843137383460999)
[2025-02-04 02:39:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18241/23838 [02:27<35:18,  2.64it/s][2025-02-04 02:39:17][root][INFO] - Training Epoch: 2/2, step 18240/23838 completed (loss: 0.8402717113494873, acc: 0.7837837934494019)
[2025-02-04 02:39:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18242/23838 [02:28<33:50,  2.76it/s][2025-02-04 02:39:17][root][INFO] - Training Epoch: 2/2, step 18241/23838 completed (loss: 0.5728919506072998, acc: 0.8474576473236084)
[2025-02-04 02:39:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18243/23838 [02:28<33:12,  2.81it/s][2025-02-04 02:39:18][root][INFO] - Training Epoch: 2/2, step 18242/23838 completed (loss: 0.6044686436653137, acc: 0.7799999713897705)
[2025-02-04 02:39:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18244/23838 [02:28<33:27,  2.79it/s][2025-02-04 02:39:18][root][INFO] - Training Epoch: 2/2, step 18243/23838 completed (loss: 0.8945989608764648, acc: 0.765625)
[2025-02-04 02:39:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18245/23838 [02:29<33:13,  2.81it/s][2025-02-04 02:39:18][root][INFO] - Training Epoch: 2/2, step 18244/23838 completed (loss: 0.3778228461742401, acc: 0.8902438879013062)
[2025-02-04 02:39:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18246/23838 [02:29<32:10,  2.90it/s][2025-02-04 02:39:19][root][INFO] - Training Epoch: 2/2, step 18245/23838 completed (loss: 0.10976618528366089, acc: 0.9594594836235046)
[2025-02-04 02:39:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18247/23838 [02:29<32:30,  2.87it/s][2025-02-04 02:39:19][root][INFO] - Training Epoch: 2/2, step 18246/23838 completed (loss: 0.09979426115751266, acc: 0.9805825352668762)
[2025-02-04 02:39:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18248/23838 [02:30<34:06,  2.73it/s][2025-02-04 02:39:19][root][INFO] - Training Epoch: 2/2, step 18247/23838 completed (loss: 0.20203915238380432, acc: 0.967391312122345)
[2025-02-04 02:39:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18249/23838 [02:30<32:11,  2.89it/s][2025-02-04 02:39:20][root][INFO] - Training Epoch: 2/2, step 18248/23838 completed (loss: 0.1288587898015976, acc: 0.954954981803894)
[2025-02-04 02:39:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18250/23838 [02:30<32:00,  2.91it/s][2025-02-04 02:39:20][root][INFO] - Training Epoch: 2/2, step 18249/23838 completed (loss: 0.3915141224861145, acc: 0.8965517282485962)
[2025-02-04 02:39:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18251/23838 [02:31<32:10,  2.89it/s][2025-02-04 02:39:20][root][INFO] - Training Epoch: 2/2, step 18250/23838 completed (loss: 0.1886473149061203, acc: 0.9270833134651184)
[2025-02-04 02:39:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18252/23838 [02:31<33:16,  2.80it/s][2025-02-04 02:39:21][root][INFO] - Training Epoch: 2/2, step 18251/23838 completed (loss: 0.05425460636615753, acc: 0.9923664331436157)
[2025-02-04 02:39:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18253/23838 [02:32<34:07,  2.73it/s][2025-02-04 02:39:21][root][INFO] - Training Epoch: 2/2, step 18252/23838 completed (loss: 0.18484282493591309, acc: 0.9453125)
[2025-02-04 02:39:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18254/23838 [02:32<37:35,  2.48it/s][2025-02-04 02:39:22][root][INFO] - Training Epoch: 2/2, step 18253/23838 completed (loss: 0.26816174387931824, acc: 0.9277777671813965)
[2025-02-04 02:39:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18255/23838 [02:32<36:03,  2.58it/s][2025-02-04 02:39:22][root][INFO] - Training Epoch: 2/2, step 18254/23838 completed (loss: 0.20911239087581635, acc: 0.9459459185600281)
[2025-02-04 02:39:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18256/23838 [02:33<36:36,  2.54it/s][2025-02-04 02:39:22][root][INFO] - Training Epoch: 2/2, step 18255/23838 completed (loss: 0.21646034717559814, acc: 0.9266666769981384)
[2025-02-04 02:39:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18257/23838 [02:33<36:08,  2.57it/s][2025-02-04 02:39:23][root][INFO] - Training Epoch: 2/2, step 18256/23838 completed (loss: 0.3050522804260254, acc: 0.9105691313743591)
[2025-02-04 02:39:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18258/23838 [02:34<36:32,  2.55it/s][2025-02-04 02:39:23][root][INFO] - Training Epoch: 2/2, step 18257/23838 completed (loss: 0.2633014917373657, acc: 0.9433962106704712)
[2025-02-04 02:39:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18259/23838 [02:34<41:31,  2.24it/s][2025-02-04 02:39:24][root][INFO] - Training Epoch: 2/2, step 18258/23838 completed (loss: 0.37815314531326294, acc: 0.9100000262260437)
[2025-02-04 02:39:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18260/23838 [02:35<40:48,  2.28it/s][2025-02-04 02:39:24][root][INFO] - Training Epoch: 2/2, step 18259/23838 completed (loss: 0.1672368049621582, acc: 0.9615384340286255)
[2025-02-04 02:39:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18261/23838 [02:35<38:11,  2.43it/s][2025-02-04 02:39:25][root][INFO] - Training Epoch: 2/2, step 18260/23838 completed (loss: 0.2608458995819092, acc: 0.9135802388191223)
[2025-02-04 02:39:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18262/23838 [02:35<37:05,  2.50it/s][2025-02-04 02:39:25][root][INFO] - Training Epoch: 2/2, step 18261/23838 completed (loss: 0.42159923911094666, acc: 0.9016393423080444)
[2025-02-04 02:39:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18263/23838 [02:36<38:18,  2.43it/s][2025-02-04 02:39:25][root][INFO] - Training Epoch: 2/2, step 18262/23838 completed (loss: 0.5337479710578918, acc: 0.8761062026023865)
[2025-02-04 02:39:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18264/23838 [02:36<37:48,  2.46it/s][2025-02-04 02:39:26][root][INFO] - Training Epoch: 2/2, step 18263/23838 completed (loss: 0.5207307934761047, acc: 0.8921568393707275)
[2025-02-04 02:39:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18265/23838 [02:37<37:16,  2.49it/s][2025-02-04 02:39:26][root][INFO] - Training Epoch: 2/2, step 18264/23838 completed (loss: 0.1842082440853119, acc: 0.9492753744125366)
[2025-02-04 02:39:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18266/23838 [02:37<37:29,  2.48it/s][2025-02-04 02:39:27][root][INFO] - Training Epoch: 2/2, step 18265/23838 completed (loss: 0.5303196907043457, acc: 0.8600000143051147)
[2025-02-04 02:39:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18267/23838 [02:37<37:37,  2.47it/s][2025-02-04 02:39:27][root][INFO] - Training Epoch: 2/2, step 18266/23838 completed (loss: 0.11397965997457504, acc: 0.9599999785423279)
[2025-02-04 02:39:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18268/23838 [02:38<36:50,  2.52it/s][2025-02-04 02:39:27][root][INFO] - Training Epoch: 2/2, step 18267/23838 completed (loss: 0.2920292913913727, acc: 0.9214285612106323)
[2025-02-04 02:39:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18269/23838 [02:38<36:00,  2.58it/s][2025-02-04 02:39:28][root][INFO] - Training Epoch: 2/2, step 18268/23838 completed (loss: 0.2228674739599228, acc: 0.9253731369972229)
[2025-02-04 02:39:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18270/23838 [02:38<35:35,  2.61it/s][2025-02-04 02:39:28][root][INFO] - Training Epoch: 2/2, step 18269/23838 completed (loss: 0.3950367569923401, acc: 0.9014084339141846)
[2025-02-04 02:39:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18271/23838 [02:39<36:15,  2.56it/s][2025-02-04 02:39:28][root][INFO] - Training Epoch: 2/2, step 18270/23838 completed (loss: 0.42467817664146423, acc: 0.886956512928009)
[2025-02-04 02:39:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18272/23838 [02:39<39:05,  2.37it/s][2025-02-04 02:39:29][root][INFO] - Training Epoch: 2/2, step 18271/23838 completed (loss: 0.21717846393585205, acc: 0.9125000238418579)
[2025-02-04 02:39:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18273/23838 [02:40<41:25,  2.24it/s][2025-02-04 02:39:29][root][INFO] - Training Epoch: 2/2, step 18272/23838 completed (loss: 0.5980818271636963, acc: 0.8333333134651184)
[2025-02-04 02:39:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18274/23838 [02:40<38:49,  2.39it/s][2025-02-04 02:39:30][root][INFO] - Training Epoch: 2/2, step 18273/23838 completed (loss: 0.3739410638809204, acc: 0.9047619104385376)
[2025-02-04 02:39:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18275/23838 [02:41<37:08,  2.50it/s][2025-02-04 02:39:30][root][INFO] - Training Epoch: 2/2, step 18274/23838 completed (loss: 0.4054793417453766, acc: 0.8947368264198303)
[2025-02-04 02:39:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18276/23838 [02:41<37:29,  2.47it/s][2025-02-04 02:39:31][root][INFO] - Training Epoch: 2/2, step 18275/23838 completed (loss: 0.4154864251613617, acc: 0.8768116235733032)
[2025-02-04 02:39:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18277/23838 [02:41<38:06,  2.43it/s][2025-02-04 02:39:31][root][INFO] - Training Epoch: 2/2, step 18276/23838 completed (loss: 0.5007306933403015, acc: 0.8324872851371765)
[2025-02-04 02:39:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18278/23838 [02:42<37:48,  2.45it/s][2025-02-04 02:39:31][root][INFO] - Training Epoch: 2/2, step 18277/23838 completed (loss: 0.293254554271698, acc: 0.945652186870575)
[2025-02-04 02:39:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18279/23838 [02:42<36:29,  2.54it/s][2025-02-04 02:39:32][root][INFO] - Training Epoch: 2/2, step 18278/23838 completed (loss: 0.4638102948665619, acc: 0.8695651888847351)
[2025-02-04 02:39:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18280/23838 [02:43<35:56,  2.58it/s][2025-02-04 02:39:32][root][INFO] - Training Epoch: 2/2, step 18279/23838 completed (loss: 0.5275911688804626, acc: 0.8461538553237915)
[2025-02-04 02:39:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18281/23838 [02:43<34:36,  2.68it/s][2025-02-04 02:39:33][root][INFO] - Training Epoch: 2/2, step 18280/23838 completed (loss: 0.7686948180198669, acc: 0.7746478915214539)
[2025-02-04 02:39:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18282/23838 [02:43<34:01,  2.72it/s][2025-02-04 02:39:33][root][INFO] - Training Epoch: 2/2, step 18281/23838 completed (loss: 0.7143676280975342, acc: 0.8421052694320679)
[2025-02-04 02:39:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18283/23838 [02:44<34:03,  2.72it/s][2025-02-04 02:39:33][root][INFO] - Training Epoch: 2/2, step 18282/23838 completed (loss: 0.7727041244506836, acc: 0.7777777910232544)
[2025-02-04 02:39:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18284/23838 [02:44<32:50,  2.82it/s][2025-02-04 02:39:34][root][INFO] - Training Epoch: 2/2, step 18283/23838 completed (loss: 0.43916046619415283, acc: 0.9215686321258545)
[2025-02-04 02:39:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18285/23838 [02:44<32:39,  2.83it/s][2025-02-04 02:39:34][root][INFO] - Training Epoch: 2/2, step 18284/23838 completed (loss: 0.4841241240501404, acc: 0.8125)
[2025-02-04 02:39:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18286/23838 [02:45<33:05,  2.80it/s][2025-02-04 02:39:34][root][INFO] - Training Epoch: 2/2, step 18285/23838 completed (loss: 0.45326292514801025, acc: 0.8666666746139526)
[2025-02-04 02:39:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18287/23838 [02:45<31:26,  2.94it/s][2025-02-04 02:39:35][root][INFO] - Training Epoch: 2/2, step 18286/23838 completed (loss: 0.8420657515525818, acc: 0.795918345451355)
[2025-02-04 02:39:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18288/23838 [02:45<32:23,  2.86it/s][2025-02-04 02:39:35][root][INFO] - Training Epoch: 2/2, step 18287/23838 completed (loss: 0.2893674969673157, acc: 0.8888888955116272)
[2025-02-04 02:39:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18289/23838 [02:46<33:21,  2.77it/s][2025-02-04 02:39:35][root][INFO] - Training Epoch: 2/2, step 18288/23838 completed (loss: 0.7504963874816895, acc: 0.8095238208770752)
[2025-02-04 02:39:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18290/23838 [02:46<33:54,  2.73it/s][2025-02-04 02:39:36][root][INFO] - Training Epoch: 2/2, step 18289/23838 completed (loss: 0.18160846829414368, acc: 0.9444444179534912)
[2025-02-04 02:39:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18291/23838 [02:46<30:42,  3.01it/s][2025-02-04 02:39:36][root][INFO] - Training Epoch: 2/2, step 18290/23838 completed (loss: 0.8071210384368896, acc: 0.8285714387893677)
[2025-02-04 02:39:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18292/23838 [02:47<30:37,  3.02it/s][2025-02-04 02:39:36][root][INFO] - Training Epoch: 2/2, step 18291/23838 completed (loss: 0.9463753700256348, acc: 0.7636363506317139)
[2025-02-04 02:39:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18293/23838 [02:47<31:14,  2.96it/s][2025-02-04 02:39:37][root][INFO] - Training Epoch: 2/2, step 18292/23838 completed (loss: 0.5290277600288391, acc: 0.8100000023841858)
[2025-02-04 02:39:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18294/23838 [02:47<31:49,  2.90it/s][2025-02-04 02:39:37][root][INFO] - Training Epoch: 2/2, step 18293/23838 completed (loss: 0.7767278552055359, acc: 0.6944444179534912)
[2025-02-04 02:39:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18295/23838 [02:48<31:39,  2.92it/s][2025-02-04 02:39:37][root][INFO] - Training Epoch: 2/2, step 18294/23838 completed (loss: 0.6978360414505005, acc: 0.800000011920929)
[2025-02-04 02:39:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18296/23838 [02:48<31:20,  2.95it/s][2025-02-04 02:39:38][root][INFO] - Training Epoch: 2/2, step 18295/23838 completed (loss: 0.9777061939239502, acc: 0.6829268336296082)
[2025-02-04 02:39:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18297/23838 [02:48<31:14,  2.96it/s][2025-02-04 02:39:38][root][INFO] - Training Epoch: 2/2, step 18296/23838 completed (loss: 0.7760100960731506, acc: 0.7820512652397156)
[2025-02-04 02:39:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18298/23838 [02:49<31:55,  2.89it/s][2025-02-04 02:39:38][root][INFO] - Training Epoch: 2/2, step 18297/23838 completed (loss: 0.6089240908622742, acc: 0.8125)
[2025-02-04 02:39:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18299/23838 [02:49<32:35,  2.83it/s][2025-02-04 02:39:39][root][INFO] - Training Epoch: 2/2, step 18298/23838 completed (loss: 0.7674384713172913, acc: 0.7831325531005859)
[2025-02-04 02:39:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18300/23838 [02:49<30:34,  3.02it/s][2025-02-04 02:39:39][root][INFO] - Training Epoch: 2/2, step 18299/23838 completed (loss: 0.5860771536827087, acc: 0.7903226017951965)
[2025-02-04 02:39:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18301/23838 [02:50<29:56,  3.08it/s][2025-02-04 02:39:39][root][INFO] - Training Epoch: 2/2, step 18300/23838 completed (loss: 0.7324116826057434, acc: 0.8666666746139526)
[2025-02-04 02:39:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18302/23838 [02:50<31:31,  2.93it/s][2025-02-04 02:39:40][root][INFO] - Training Epoch: 2/2, step 18301/23838 completed (loss: 1.4208729267120361, acc: 0.75)
[2025-02-04 02:39:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18303/23838 [02:50<31:54,  2.89it/s][2025-02-04 02:39:40][root][INFO] - Training Epoch: 2/2, step 18302/23838 completed (loss: 0.4481281042098999, acc: 0.8333333134651184)
[2025-02-04 02:39:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18304/23838 [02:51<31:32,  2.92it/s][2025-02-04 02:39:40][root][INFO] - Training Epoch: 2/2, step 18303/23838 completed (loss: 0.35921749472618103, acc: 0.9166666865348816)
[2025-02-04 02:39:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18305/23838 [02:51<34:56,  2.64it/s][2025-02-04 02:39:41][root][INFO] - Training Epoch: 2/2, step 18304/23838 completed (loss: 1.2928812503814697, acc: 0.4545454680919647)
[2025-02-04 02:39:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18306/23838 [02:52<35:13,  2.62it/s][2025-02-04 02:39:41][root][INFO] - Training Epoch: 2/2, step 18305/23838 completed (loss: 0.37752747535705566, acc: 0.9090909361839294)
[2025-02-04 02:39:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18307/23838 [02:52<35:50,  2.57it/s][2025-02-04 02:39:42][root][INFO] - Training Epoch: 2/2, step 18306/23838 completed (loss: 0.3360695242881775, acc: 0.9101123809814453)
[2025-02-04 02:39:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18308/23838 [02:52<34:47,  2.65it/s][2025-02-04 02:39:42][root][INFO] - Training Epoch: 2/2, step 18307/23838 completed (loss: 0.5012873411178589, acc: 0.8454545736312866)
[2025-02-04 02:39:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18309/23838 [02:53<34:54,  2.64it/s][2025-02-04 02:39:42][root][INFO] - Training Epoch: 2/2, step 18308/23838 completed (loss: 0.3311910331249237, acc: 0.8888888955116272)
[2025-02-04 02:39:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18310/23838 [02:53<34:56,  2.64it/s][2025-02-04 02:39:43][root][INFO] - Training Epoch: 2/2, step 18309/23838 completed (loss: 0.37054163217544556, acc: 0.8941176533699036)
[2025-02-04 02:39:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18311/23838 [02:54<35:21,  2.61it/s][2025-02-04 02:39:43][root][INFO] - Training Epoch: 2/2, step 18310/23838 completed (loss: 0.33990800380706787, acc: 0.892307698726654)
[2025-02-04 02:39:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18312/23838 [02:54<34:15,  2.69it/s][2025-02-04 02:39:44][root][INFO] - Training Epoch: 2/2, step 18311/23838 completed (loss: 0.430937796831131, acc: 0.8536585569381714)
[2025-02-04 02:39:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18313/23838 [02:54<33:36,  2.74it/s][2025-02-04 02:39:44][root][INFO] - Training Epoch: 2/2, step 18312/23838 completed (loss: 0.35918083786964417, acc: 0.895652174949646)
[2025-02-04 02:39:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18314/23838 [02:55<34:06,  2.70it/s][2025-02-04 02:39:44][root][INFO] - Training Epoch: 2/2, step 18313/23838 completed (loss: 0.41004401445388794, acc: 0.8793103694915771)
[2025-02-04 02:39:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18315/23838 [02:55<33:13,  2.77it/s][2025-02-04 02:39:45][root][INFO] - Training Epoch: 2/2, step 18314/23838 completed (loss: 0.38317370414733887, acc: 0.8877550959587097)
[2025-02-04 02:39:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18316/23838 [02:55<32:10,  2.86it/s][2025-02-04 02:39:45][root][INFO] - Training Epoch: 2/2, step 18315/23838 completed (loss: 0.29801037907600403, acc: 0.920634925365448)
[2025-02-04 02:39:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18317/23838 [02:56<31:43,  2.90it/s][2025-02-04 02:39:45][root][INFO] - Training Epoch: 2/2, step 18316/23838 completed (loss: 0.7221687436103821, acc: 0.782608687877655)
[2025-02-04 02:39:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18318/23838 [02:56<31:57,  2.88it/s][2025-02-04 02:39:46][root][INFO] - Training Epoch: 2/2, step 18317/23838 completed (loss: 0.09595004469156265, acc: 0.9850746393203735)
[2025-02-04 02:39:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18319/23838 [02:56<32:59,  2.79it/s][2025-02-04 02:39:46][root][INFO] - Training Epoch: 2/2, step 18318/23838 completed (loss: 0.24894623458385468, acc: 0.9272727370262146)
[2025-02-04 02:39:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18320/23838 [02:57<33:45,  2.72it/s][2025-02-04 02:39:46][root][INFO] - Training Epoch: 2/2, step 18319/23838 completed (loss: 0.6518277525901794, acc: 0.7922077775001526)
[2025-02-04 02:39:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18321/23838 [02:57<32:47,  2.80it/s][2025-02-04 02:39:47][root][INFO] - Training Epoch: 2/2, step 18320/23838 completed (loss: 1.1118849515914917, acc: 0.6704545617103577)
[2025-02-04 02:39:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18322/23838 [02:57<31:36,  2.91it/s][2025-02-04 02:39:47][root][INFO] - Training Epoch: 2/2, step 18321/23838 completed (loss: 0.6380134224891663, acc: 0.8034188151359558)
[2025-02-04 02:39:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18323/23838 [02:58<31:32,  2.91it/s][2025-02-04 02:39:47][root][INFO] - Training Epoch: 2/2, step 18322/23838 completed (loss: 0.47407615184783936, acc: 0.8409090638160706)
[2025-02-04 02:39:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18324/23838 [02:58<33:05,  2.78it/s][2025-02-04 02:39:48][root][INFO] - Training Epoch: 2/2, step 18323/23838 completed (loss: 0.6097477078437805, acc: 0.8181818127632141)
[2025-02-04 02:39:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18325/23838 [02:59<32:49,  2.80it/s][2025-02-04 02:39:48][root][INFO] - Training Epoch: 2/2, step 18324/23838 completed (loss: 0.36448487639427185, acc: 0.8799999952316284)
[2025-02-04 02:39:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18326/23838 [02:59<33:07,  2.77it/s][2025-02-04 02:39:48][root][INFO] - Training Epoch: 2/2, step 18325/23838 completed (loss: 0.4016800820827484, acc: 0.8799999952316284)
[2025-02-04 02:39:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18327/23838 [02:59<37:03,  2.48it/s][2025-02-04 02:39:49][root][INFO] - Training Epoch: 2/2, step 18326/23838 completed (loss: 0.23561705648899078, acc: 0.9255319237709045)
[2025-02-04 02:39:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18328/23838 [03:00<35:51,  2.56it/s][2025-02-04 02:39:49][root][INFO] - Training Epoch: 2/2, step 18327/23838 completed (loss: 0.2290055900812149, acc: 0.9351851940155029)
[2025-02-04 02:39:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18329/23838 [03:00<36:31,  2.51it/s][2025-02-04 02:39:50][root][INFO] - Training Epoch: 2/2, step 18328/23838 completed (loss: 0.2905696928501129, acc: 0.9296875)
[2025-02-04 02:39:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18330/23838 [03:01<36:07,  2.54it/s][2025-02-04 02:39:50][root][INFO] - Training Epoch: 2/2, step 18329/23838 completed (loss: 0.5481385588645935, acc: 0.8404255509376526)
[2025-02-04 02:39:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18331/23838 [03:01<34:54,  2.63it/s][2025-02-04 02:39:50][root][INFO] - Training Epoch: 2/2, step 18330/23838 completed (loss: 0.7518377900123596, acc: 0.7804877758026123)
[2025-02-04 02:39:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18332/23838 [03:01<34:36,  2.65it/s][2025-02-04 02:39:51][root][INFO] - Training Epoch: 2/2, step 18331/23838 completed (loss: 0.16468240320682526, acc: 0.947826087474823)
[2025-02-04 02:39:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18333/23838 [03:02<36:35,  2.51it/s][2025-02-04 02:39:51][root][INFO] - Training Epoch: 2/2, step 18332/23838 completed (loss: 0.46249833703041077, acc: 0.8606557250022888)
[2025-02-04 02:39:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18334/23838 [03:02<35:23,  2.59it/s][2025-02-04 02:39:52][root][INFO] - Training Epoch: 2/2, step 18333/23838 completed (loss: 0.6017451286315918, acc: 0.847328245639801)
[2025-02-04 02:39:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18335/23838 [03:02<34:46,  2.64it/s][2025-02-04 02:39:52][root][INFO] - Training Epoch: 2/2, step 18334/23838 completed (loss: 0.31249234080314636, acc: 0.9032257795333862)
[2025-02-04 02:39:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18336/23838 [03:03<33:30,  2.74it/s][2025-02-04 02:39:52][root][INFO] - Training Epoch: 2/2, step 18335/23838 completed (loss: 0.4390921890735626, acc: 0.8681318759918213)
[2025-02-04 02:39:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18337/23838 [03:03<32:52,  2.79it/s][2025-02-04 02:39:53][root][INFO] - Training Epoch: 2/2, step 18336/23838 completed (loss: 0.43939584493637085, acc: 0.8773584961891174)
[2025-02-04 02:39:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18338/23838 [03:03<32:07,  2.85it/s][2025-02-04 02:39:53][root][INFO] - Training Epoch: 2/2, step 18337/23838 completed (loss: 0.5233749151229858, acc: 0.8440366983413696)
[2025-02-04 02:39:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18339/23838 [03:04<32:15,  2.84it/s][2025-02-04 02:39:53][root][INFO] - Training Epoch: 2/2, step 18338/23838 completed (loss: 0.23660513758659363, acc: 0.9509803652763367)
[2025-02-04 02:39:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18340/23838 [03:04<34:07,  2.69it/s][2025-02-04 02:39:54][root][INFO] - Training Epoch: 2/2, step 18339/23838 completed (loss: 0.48578837513923645, acc: 0.782608687877655)
[2025-02-04 02:39:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18341/23838 [03:05<34:05,  2.69it/s][2025-02-04 02:39:54][root][INFO] - Training Epoch: 2/2, step 18340/23838 completed (loss: 0.5600691437721252, acc: 0.828125)
[2025-02-04 02:39:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18342/23838 [03:05<35:25,  2.59it/s][2025-02-04 02:39:55][root][INFO] - Training Epoch: 2/2, step 18341/23838 completed (loss: 0.637042760848999, acc: 0.8225806355476379)
[2025-02-04 02:39:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18343/23838 [03:05<36:49,  2.49it/s][2025-02-04 02:39:55][root][INFO] - Training Epoch: 2/2, step 18342/23838 completed (loss: 0.5398444533348083, acc: 0.848739504814148)
[2025-02-04 02:39:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18344/23838 [03:06<37:24,  2.45it/s][2025-02-04 02:39:55][root][INFO] - Training Epoch: 2/2, step 18343/23838 completed (loss: 0.4217812716960907, acc: 0.8961039185523987)
[2025-02-04 02:39:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18345/23838 [03:06<35:24,  2.59it/s][2025-02-04 02:39:56][root][INFO] - Training Epoch: 2/2, step 18344/23838 completed (loss: 0.3359985649585724, acc: 0.8285714387893677)
[2025-02-04 02:39:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18346/23838 [03:07<34:55,  2.62it/s][2025-02-04 02:39:56][root][INFO] - Training Epoch: 2/2, step 18345/23838 completed (loss: 0.6300907135009766, acc: 0.8089887499809265)
[2025-02-04 02:39:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18347/23838 [03:07<36:32,  2.50it/s][2025-02-04 02:39:57][root][INFO] - Training Epoch: 2/2, step 18346/23838 completed (loss: 0.532187819480896, acc: 0.849056601524353)
[2025-02-04 02:39:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18348/23838 [03:07<38:33,  2.37it/s][2025-02-04 02:39:57][root][INFO] - Training Epoch: 2/2, step 18347/23838 completed (loss: 0.29741448163986206, acc: 0.9245283007621765)
[2025-02-04 02:39:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18349/23838 [03:08<39:23,  2.32it/s][2025-02-04 02:39:58][root][INFO] - Training Epoch: 2/2, step 18348/23838 completed (loss: 0.6270534992218018, acc: 0.7763158082962036)
[2025-02-04 02:39:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18350/23838 [03:08<38:37,  2.37it/s][2025-02-04 02:39:58][root][INFO] - Training Epoch: 2/2, step 18349/23838 completed (loss: 0.5634247660636902, acc: 0.8285714387893677)
[2025-02-04 02:39:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18351/23838 [03:09<37:07,  2.46it/s][2025-02-04 02:39:58][root][INFO] - Training Epoch: 2/2, step 18350/23838 completed (loss: 0.49037736654281616, acc: 0.8598130941390991)
[2025-02-04 02:39:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18352/23838 [03:09<38:02,  2.40it/s][2025-02-04 02:39:59][root][INFO] - Training Epoch: 2/2, step 18351/23838 completed (loss: 0.3201654851436615, acc: 0.9156626462936401)
[2025-02-04 02:39:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18353/23838 [03:10<45:35,  2.01it/s][2025-02-04 02:39:59][root][INFO] - Training Epoch: 2/2, step 18352/23838 completed (loss: 0.31805285811424255, acc: 0.9029126167297363)
[2025-02-04 02:40:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18354/23838 [03:10<44:26,  2.06it/s][2025-02-04 02:40:00][root][INFO] - Training Epoch: 2/2, step 18353/23838 completed (loss: 0.5140387415885925, acc: 0.8425197005271912)
[2025-02-04 02:40:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18355/23838 [03:11<41:27,  2.20it/s][2025-02-04 02:40:00][root][INFO] - Training Epoch: 2/2, step 18354/23838 completed (loss: 0.34946203231811523, acc: 0.9047619104385376)
[2025-02-04 02:40:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18356/23838 [03:11<41:28,  2.20it/s][2025-02-04 02:40:01][root][INFO] - Training Epoch: 2/2, step 18355/23838 completed (loss: 0.2887134552001953, acc: 0.9147287011146545)
[2025-02-04 02:40:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18357/23838 [03:12<41:05,  2.22it/s][2025-02-04 02:40:01][root][INFO] - Training Epoch: 2/2, step 18356/23838 completed (loss: 0.15421560406684875, acc: 0.9459459185600281)
[2025-02-04 02:40:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18358/23838 [03:12<38:00,  2.40it/s][2025-02-04 02:40:02][root][INFO] - Training Epoch: 2/2, step 18357/23838 completed (loss: 0.7898820042610168, acc: 0.8055555820465088)
[2025-02-04 02:40:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18359/23838 [03:12<36:02,  2.53it/s][2025-02-04 02:40:02][root][INFO] - Training Epoch: 2/2, step 18358/23838 completed (loss: 0.5258409380912781, acc: 0.8615384697914124)
[2025-02-04 02:40:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18360/23838 [03:13<37:37,  2.43it/s][2025-02-04 02:40:02][root][INFO] - Training Epoch: 2/2, step 18359/23838 completed (loss: 0.7712482810020447, acc: 0.8103448152542114)
[2025-02-04 02:40:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18361/23838 [03:13<35:42,  2.56it/s][2025-02-04 02:40:03][root][INFO] - Training Epoch: 2/2, step 18360/23838 completed (loss: 0.4733338952064514, acc: 0.9180327653884888)
[2025-02-04 02:40:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18362/23838 [03:13<33:57,  2.69it/s][2025-02-04 02:40:03][root][INFO] - Training Epoch: 2/2, step 18361/23838 completed (loss: 0.12421409785747528, acc: 0.9402984976768494)
[2025-02-04 02:40:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18363/23838 [03:14<34:24,  2.65it/s][2025-02-04 02:40:03][root][INFO] - Training Epoch: 2/2, step 18362/23838 completed (loss: 0.47180357575416565, acc: 0.8289473652839661)
[2025-02-04 02:40:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18364/23838 [03:14<35:44,  2.55it/s][2025-02-04 02:40:04][root][INFO] - Training Epoch: 2/2, step 18363/23838 completed (loss: 0.1919020265340805, acc: 0.9154929518699646)
[2025-02-04 02:40:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18365/23838 [03:15<34:38,  2.63it/s][2025-02-04 02:40:04][root][INFO] - Training Epoch: 2/2, step 18364/23838 completed (loss: 0.16933614015579224, acc: 0.948051929473877)
[2025-02-04 02:40:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18366/23838 [03:15<34:35,  2.64it/s][2025-02-04 02:40:05][root][INFO] - Training Epoch: 2/2, step 18365/23838 completed (loss: 0.4001340866088867, acc: 0.8701298832893372)
[2025-02-04 02:40:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18367/23838 [03:15<34:28,  2.64it/s][2025-02-04 02:40:05][root][INFO] - Training Epoch: 2/2, step 18366/23838 completed (loss: 0.38847845792770386, acc: 0.8533333539962769)
[2025-02-04 02:40:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18368/23838 [03:16<34:14,  2.66it/s][2025-02-04 02:40:05][root][INFO] - Training Epoch: 2/2, step 18367/23838 completed (loss: 0.33603084087371826, acc: 0.875)
[2025-02-04 02:40:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18369/23838 [03:16<33:05,  2.75it/s][2025-02-04 02:40:06][root][INFO] - Training Epoch: 2/2, step 18368/23838 completed (loss: 0.30263087153434753, acc: 0.9076923131942749)
[2025-02-04 02:40:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18370/23838 [03:16<34:17,  2.66it/s][2025-02-04 02:40:06][root][INFO] - Training Epoch: 2/2, step 18369/23838 completed (loss: 0.41059011220932007, acc: 0.8799999952316284)
[2025-02-04 02:40:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18371/23838 [03:17<34:45,  2.62it/s][2025-02-04 02:40:06][root][INFO] - Training Epoch: 2/2, step 18370/23838 completed (loss: 0.45969659090042114, acc: 0.8823529481887817)
[2025-02-04 02:40:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18372/23838 [03:17<35:48,  2.54it/s][2025-02-04 02:40:07][root][INFO] - Training Epoch: 2/2, step 18371/23838 completed (loss: 0.16524067521095276, acc: 0.9166666865348816)
[2025-02-04 02:40:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18373/23838 [03:18<35:43,  2.55it/s][2025-02-04 02:40:07][root][INFO] - Training Epoch: 2/2, step 18372/23838 completed (loss: 0.4003419578075409, acc: 0.8888888955116272)
[2025-02-04 02:40:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18374/23838 [03:18<34:22,  2.65it/s][2025-02-04 02:40:08][root][INFO] - Training Epoch: 2/2, step 18373/23838 completed (loss: 0.4306001663208008, acc: 0.8333333134651184)
[2025-02-04 02:40:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18375/23838 [03:19<42:46,  2.13it/s][2025-02-04 02:40:08][root][INFO] - Training Epoch: 2/2, step 18374/23838 completed (loss: 0.46356210112571716, acc: 0.8780487775802612)
[2025-02-04 02:40:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18376/23838 [03:19<40:45,  2.23it/s][2025-02-04 02:40:09][root][INFO] - Training Epoch: 2/2, step 18375/23838 completed (loss: 0.33129215240478516, acc: 0.8839285969734192)
[2025-02-04 02:40:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18377/23838 [03:19<38:57,  2.34it/s][2025-02-04 02:40:09][root][INFO] - Training Epoch: 2/2, step 18376/23838 completed (loss: 0.23103734850883484, acc: 0.9375)
[2025-02-04 02:40:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18378/23838 [03:20<38:09,  2.38it/s][2025-02-04 02:40:09][root][INFO] - Training Epoch: 2/2, step 18377/23838 completed (loss: 0.287430077791214, acc: 0.907216489315033)
[2025-02-04 02:40:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18379/23838 [03:20<36:32,  2.49it/s][2025-02-04 02:40:10][root][INFO] - Training Epoch: 2/2, step 18378/23838 completed (loss: 0.3677089214324951, acc: 0.8983050584793091)
[2025-02-04 02:40:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18380/23838 [03:21<35:15,  2.58it/s][2025-02-04 02:40:10][root][INFO] - Training Epoch: 2/2, step 18379/23838 completed (loss: 0.16065937280654907, acc: 0.9285714030265808)
[2025-02-04 02:40:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18381/23838 [03:21<35:17,  2.58it/s][2025-02-04 02:40:11][root][INFO] - Training Epoch: 2/2, step 18380/23838 completed (loss: 0.24898812174797058, acc: 0.9396551847457886)
[2025-02-04 02:40:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18382/23838 [03:21<34:17,  2.65it/s][2025-02-04 02:40:11][root][INFO] - Training Epoch: 2/2, step 18381/23838 completed (loss: 0.18293152749538422, acc: 0.8983050584793091)
[2025-02-04 02:40:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18383/23838 [03:22<35:59,  2.53it/s][2025-02-04 02:40:11][root][INFO] - Training Epoch: 2/2, step 18382/23838 completed (loss: 0.19223199784755707, acc: 0.930232584476471)
[2025-02-04 02:40:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18384/23838 [03:22<34:48,  2.61it/s][2025-02-04 02:40:12][root][INFO] - Training Epoch: 2/2, step 18383/23838 completed (loss: 0.1610637903213501, acc: 0.9210526347160339)
[2025-02-04 02:40:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18385/23838 [03:23<36:19,  2.50it/s][2025-02-04 02:40:12][root][INFO] - Training Epoch: 2/2, step 18384/23838 completed (loss: 0.3772497773170471, acc: 0.8644067645072937)
[2025-02-04 02:40:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18386/23838 [03:23<36:37,  2.48it/s][2025-02-04 02:40:13][root][INFO] - Training Epoch: 2/2, step 18385/23838 completed (loss: 0.36818644404411316, acc: 0.8656716346740723)
[2025-02-04 02:40:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18387/23838 [03:23<36:02,  2.52it/s][2025-02-04 02:40:13][root][INFO] - Training Epoch: 2/2, step 18386/23838 completed (loss: 0.3584696352481842, acc: 0.9038461446762085)
[2025-02-04 02:40:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18388/23838 [03:24<35:20,  2.57it/s][2025-02-04 02:40:13][root][INFO] - Training Epoch: 2/2, step 18387/23838 completed (loss: 0.3709985017776489, acc: 0.8611111044883728)
[2025-02-04 02:40:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18389/23838 [03:24<36:13,  2.51it/s][2025-02-04 02:40:14][root][INFO] - Training Epoch: 2/2, step 18388/23838 completed (loss: 0.7705290913581848, acc: 0.7777777910232544)
[2025-02-04 02:40:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18390/23838 [03:25<36:22,  2.50it/s][2025-02-04 02:40:14][root][INFO] - Training Epoch: 2/2, step 18389/23838 completed (loss: 0.42413464188575745, acc: 0.8796296119689941)
[2025-02-04 02:40:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18391/23838 [03:25<38:13,  2.37it/s][2025-02-04 02:40:15][root][INFO] - Training Epoch: 2/2, step 18390/23838 completed (loss: 0.34859368205070496, acc: 0.9166666865348816)
[2025-02-04 02:40:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18392/23838 [03:25<36:49,  2.46it/s][2025-02-04 02:40:15][root][INFO] - Training Epoch: 2/2, step 18391/23838 completed (loss: 0.35832127928733826, acc: 0.9036144614219666)
[2025-02-04 02:40:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18393/23838 [03:26<35:05,  2.59it/s][2025-02-04 02:40:15][root][INFO] - Training Epoch: 2/2, step 18392/23838 completed (loss: 0.1277482807636261, acc: 0.9464285969734192)
[2025-02-04 02:40:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18394/23838 [03:26<36:10,  2.51it/s][2025-02-04 02:40:16][root][INFO] - Training Epoch: 2/2, step 18393/23838 completed (loss: 0.35126516222953796, acc: 0.874015748500824)
[2025-02-04 02:40:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18395/23838 [03:27<35:58,  2.52it/s][2025-02-04 02:40:16][root][INFO] - Training Epoch: 2/2, step 18394/23838 completed (loss: 0.3791264295578003, acc: 0.8421052694320679)
[2025-02-04 02:40:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18396/23838 [03:27<35:58,  2.52it/s][2025-02-04 02:40:16][root][INFO] - Training Epoch: 2/2, step 18395/23838 completed (loss: 0.4808684289455414, acc: 0.8640000224113464)
[2025-02-04 02:40:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18397/23838 [03:27<41:16,  2.20it/s][2025-02-04 02:40:17][root][INFO] - Training Epoch: 2/2, step 18396/23838 completed (loss: 0.4113452434539795, acc: 0.8392857313156128)
[2025-02-04 02:40:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18398/23838 [03:28<38:19,  2.37it/s][2025-02-04 02:40:17][root][INFO] - Training Epoch: 2/2, step 18397/23838 completed (loss: 0.07495328783988953, acc: 0.9629629850387573)
[2025-02-04 02:40:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18399/23838 [03:28<40:47,  2.22it/s][2025-02-04 02:40:18][root][INFO] - Training Epoch: 2/2, step 18398/23838 completed (loss: 0.4574499726295471, acc: 0.8496732115745544)
[2025-02-04 02:40:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18400/23838 [03:29<40:01,  2.26it/s][2025-02-04 02:40:18][root][INFO] - Training Epoch: 2/2, step 18399/23838 completed (loss: 0.2034563422203064, acc: 0.9722222089767456)
[2025-02-04 02:40:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18401/23838 [03:29<38:28,  2.35it/s][2025-02-04 02:40:19][root][INFO] - Training Epoch: 2/2, step 18400/23838 completed (loss: 0.46661385893821716, acc: 0.8645833134651184)
[2025-02-04 02:40:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18402/23838 [03:30<37:47,  2.40it/s][2025-02-04 02:40:19][root][INFO] - Training Epoch: 2/2, step 18401/23838 completed (loss: 0.09146305918693542, acc: 0.9626168012619019)
[2025-02-04 02:40:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18403/23838 [03:30<37:45,  2.40it/s][2025-02-04 02:40:20][root][INFO] - Training Epoch: 2/2, step 18402/23838 completed (loss: 0.30967944860458374, acc: 0.8799999952316284)
[2025-02-04 02:40:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18404/23838 [03:30<38:02,  2.38it/s][2025-02-04 02:40:20][root][INFO] - Training Epoch: 2/2, step 18403/23838 completed (loss: 0.5236714482307434, acc: 0.8928571343421936)
[2025-02-04 02:40:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18405/23838 [03:31<37:32,  2.41it/s][2025-02-04 02:40:20][root][INFO] - Training Epoch: 2/2, step 18404/23838 completed (loss: 0.21798346936702728, acc: 0.9370078444480896)
[2025-02-04 02:40:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18406/23838 [03:31<38:01,  2.38it/s][2025-02-04 02:40:21][root][INFO] - Training Epoch: 2/2, step 18405/23838 completed (loss: 0.27269068360328674, acc: 0.9090909361839294)
[2025-02-04 02:40:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18407/23838 [03:32<39:08,  2.31it/s][2025-02-04 02:40:21][root][INFO] - Training Epoch: 2/2, step 18406/23838 completed (loss: 0.448660284280777, acc: 0.8533333539962769)
[2025-02-04 02:40:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18408/23838 [03:32<39:04,  2.32it/s][2025-02-04 02:40:22][root][INFO] - Training Epoch: 2/2, step 18407/23838 completed (loss: 0.3456301689147949, acc: 0.8928571343421936)
[2025-02-04 02:40:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18409/23838 [03:33<40:11,  2.25it/s][2025-02-04 02:40:22][root][INFO] - Training Epoch: 2/2, step 18408/23838 completed (loss: 0.683441698551178, acc: 0.8474576473236084)
[2025-02-04 02:40:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18410/23838 [03:33<37:07,  2.44it/s][2025-02-04 02:40:23][root][INFO] - Training Epoch: 2/2, step 18409/23838 completed (loss: 0.18799139559268951, acc: 0.9224137663841248)
[2025-02-04 02:40:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18411/23838 [03:33<34:26,  2.63it/s][2025-02-04 02:40:23][root][INFO] - Training Epoch: 2/2, step 18410/23838 completed (loss: 0.34872230887413025, acc: 0.8979591727256775)
[2025-02-04 02:40:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18412/23838 [03:34<35:34,  2.54it/s][2025-02-04 02:40:23][root][INFO] - Training Epoch: 2/2, step 18411/23838 completed (loss: 0.42979663610458374, acc: 0.868686854839325)
[2025-02-04 02:40:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18413/23838 [03:34<40:09,  2.25it/s][2025-02-04 02:40:24][root][INFO] - Training Epoch: 2/2, step 18412/23838 completed (loss: 0.4613340198993683, acc: 0.8723404407501221)
[2025-02-04 02:40:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18414/23838 [03:35<36:36,  2.47it/s][2025-02-04 02:40:24][root][INFO] - Training Epoch: 2/2, step 18413/23838 completed (loss: 0.5285704731941223, acc: 0.8571428656578064)
[2025-02-04 02:40:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18415/23838 [03:35<36:43,  2.46it/s][2025-02-04 02:40:25][root][INFO] - Training Epoch: 2/2, step 18414/23838 completed (loss: 0.23688657581806183, acc: 0.8837209343910217)
[2025-02-04 02:40:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18416/23838 [03:35<36:28,  2.48it/s][2025-02-04 02:40:25][root][INFO] - Training Epoch: 2/2, step 18415/23838 completed (loss: 0.2456488460302353, acc: 0.9363636374473572)
[2025-02-04 02:40:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18417/23838 [03:36<41:51,  2.16it/s][2025-02-04 02:40:26][root][INFO] - Training Epoch: 2/2, step 18416/23838 completed (loss: 0.3216225504875183, acc: 0.9054054021835327)
[2025-02-04 02:40:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18418/23838 [03:36<39:12,  2.30it/s][2025-02-04 02:40:26][root][INFO] - Training Epoch: 2/2, step 18417/23838 completed (loss: 0.24486525356769562, acc: 0.9253731369972229)
[2025-02-04 02:40:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18419/23838 [03:37<38:12,  2.36it/s][2025-02-04 02:40:26][root][INFO] - Training Epoch: 2/2, step 18418/23838 completed (loss: 0.44893214106559753, acc: 0.8983050584793091)
[2025-02-04 02:40:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18420/23838 [03:37<37:35,  2.40it/s][2025-02-04 02:40:27][root][INFO] - Training Epoch: 2/2, step 18419/23838 completed (loss: 0.5289521813392639, acc: 0.901098906993866)
[2025-02-04 02:40:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18421/23838 [03:38<37:00,  2.44it/s][2025-02-04 02:40:27][root][INFO] - Training Epoch: 2/2, step 18420/23838 completed (loss: 0.49661847949028015, acc: 0.8790322542190552)
[2025-02-04 02:40:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18422/23838 [03:38<34:12,  2.64it/s][2025-02-04 02:40:27][root][INFO] - Training Epoch: 2/2, step 18421/23838 completed (loss: 0.41656020283699036, acc: 0.9230769276618958)
[2025-02-04 02:40:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18423/23838 [03:38<34:54,  2.59it/s][2025-02-04 02:40:28][root][INFO] - Training Epoch: 2/2, step 18422/23838 completed (loss: 0.18900272250175476, acc: 0.9263157844543457)
[2025-02-04 02:40:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18424/23838 [03:39<35:31,  2.54it/s][2025-02-04 02:40:28][root][INFO] - Training Epoch: 2/2, step 18423/23838 completed (loss: 0.41973310708999634, acc: 0.8780487775802612)
[2025-02-04 02:40:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18425/23838 [03:39<38:05,  2.37it/s][2025-02-04 02:40:29][root][INFO] - Training Epoch: 2/2, step 18424/23838 completed (loss: 0.9282600283622742, acc: 0.7564102411270142)
[2025-02-04 02:40:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18426/23838 [03:40<38:42,  2.33it/s][2025-02-04 02:40:29][root][INFO] - Training Epoch: 2/2, step 18425/23838 completed (loss: 0.25867941975593567, acc: 0.9166666865348816)
[2025-02-04 02:40:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18427/23838 [03:40<38:43,  2.33it/s][2025-02-04 02:40:30][root][INFO] - Training Epoch: 2/2, step 18426/23838 completed (loss: 0.5982924103736877, acc: 0.8068181872367859)
[2025-02-04 02:40:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18428/23838 [03:40<35:41,  2.53it/s][2025-02-04 02:40:30][root][INFO] - Training Epoch: 2/2, step 18427/23838 completed (loss: 0.6020317077636719, acc: 0.875)
[2025-02-04 02:40:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18429/23838 [03:41<34:36,  2.61it/s][2025-02-04 02:40:30][root][INFO] - Training Epoch: 2/2, step 18428/23838 completed (loss: 0.25934886932373047, acc: 0.9333333373069763)
[2025-02-04 02:40:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18430/23838 [03:41<35:15,  2.56it/s][2025-02-04 02:40:31][root][INFO] - Training Epoch: 2/2, step 18429/23838 completed (loss: 0.24369943141937256, acc: 0.9298245906829834)
[2025-02-04 02:40:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18431/23838 [03:41<35:10,  2.56it/s][2025-02-04 02:40:31][root][INFO] - Training Epoch: 2/2, step 18430/23838 completed (loss: 0.6842257976531982, acc: 0.7881355881690979)
[2025-02-04 02:40:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18432/23838 [03:42<36:18,  2.48it/s][2025-02-04 02:40:31][root][INFO] - Training Epoch: 2/2, step 18431/23838 completed (loss: 0.42612916231155396, acc: 0.8783783912658691)
[2025-02-04 02:40:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18433/23838 [03:42<34:39,  2.60it/s][2025-02-04 02:40:32][root][INFO] - Training Epoch: 2/2, step 18432/23838 completed (loss: 0.16634324193000793, acc: 0.9556962251663208)
[2025-02-04 02:40:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18434/23838 [03:43<35:37,  2.53it/s][2025-02-04 02:40:32][root][INFO] - Training Epoch: 2/2, step 18433/23838 completed (loss: 0.278343141078949, acc: 0.9375)
[2025-02-04 02:40:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18435/23838 [03:43<33:55,  2.65it/s][2025-02-04 02:40:33][root][INFO] - Training Epoch: 2/2, step 18434/23838 completed (loss: 0.6113561391830444, acc: 0.8421052694320679)
[2025-02-04 02:40:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18436/23838 [03:43<32:26,  2.78it/s][2025-02-04 02:40:33][root][INFO] - Training Epoch: 2/2, step 18435/23838 completed (loss: 0.34507763385772705, acc: 0.890625)
[2025-02-04 02:40:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18437/23838 [03:44<32:47,  2.75it/s][2025-02-04 02:40:33][root][INFO] - Training Epoch: 2/2, step 18436/23838 completed (loss: 0.4894183874130249, acc: 0.8611111044883728)
[2025-02-04 02:40:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18438/23838 [03:44<32:16,  2.79it/s][2025-02-04 02:40:34][root][INFO] - Training Epoch: 2/2, step 18437/23838 completed (loss: 0.41927284002304077, acc: 0.835616409778595)
[2025-02-04 02:40:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18439/23838 [03:44<30:06,  2.99it/s][2025-02-04 02:40:34][root][INFO] - Training Epoch: 2/2, step 18438/23838 completed (loss: 0.3343579173088074, acc: 0.8947368264198303)
[2025-02-04 02:40:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18440/23838 [03:45<31:41,  2.84it/s][2025-02-04 02:40:34][root][INFO] - Training Epoch: 2/2, step 18439/23838 completed (loss: 0.339194118976593, acc: 0.9126983880996704)
[2025-02-04 02:40:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18441/23838 [03:45<32:58,  2.73it/s][2025-02-04 02:40:35][root][INFO] - Training Epoch: 2/2, step 18440/23838 completed (loss: 0.49134474992752075, acc: 0.8513513803482056)
[2025-02-04 02:40:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18442/23838 [03:45<32:06,  2.80it/s][2025-02-04 02:40:35][root][INFO] - Training Epoch: 2/2, step 18441/23838 completed (loss: 0.6061083078384399, acc: 0.8367347121238708)
[2025-02-04 02:40:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18443/23838 [03:46<32:58,  2.73it/s][2025-02-04 02:40:35][root][INFO] - Training Epoch: 2/2, step 18442/23838 completed (loss: 0.6036590337753296, acc: 0.7962962985038757)
[2025-02-04 02:40:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18444/23838 [03:46<32:20,  2.78it/s][2025-02-04 02:40:36][root][INFO] - Training Epoch: 2/2, step 18443/23838 completed (loss: 0.6347346305847168, acc: 0.795918345451355)
[2025-02-04 02:40:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18445/23838 [03:47<32:25,  2.77it/s][2025-02-04 02:40:36][root][INFO] - Training Epoch: 2/2, step 18444/23838 completed (loss: 0.47508057951927185, acc: 0.8399999737739563)
[2025-02-04 02:40:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18446/23838 [03:47<32:28,  2.77it/s][2025-02-04 02:40:36][root][INFO] - Training Epoch: 2/2, step 18445/23838 completed (loss: 0.3004724681377411, acc: 0.8888888955116272)
[2025-02-04 02:40:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18447/23838 [03:47<32:57,  2.73it/s][2025-02-04 02:40:37][root][INFO] - Training Epoch: 2/2, step 18446/23838 completed (loss: 0.3089141547679901, acc: 0.8985507488250732)
[2025-02-04 02:40:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18448/23838 [03:48<35:39,  2.52it/s][2025-02-04 02:40:37][root][INFO] - Training Epoch: 2/2, step 18447/23838 completed (loss: 0.286443829536438, acc: 0.936170220375061)
[2025-02-04 02:40:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18449/23838 [03:48<34:52,  2.57it/s][2025-02-04 02:40:38][root][INFO] - Training Epoch: 2/2, step 18448/23838 completed (loss: 0.34318819642066956, acc: 0.9245283007621765)
[2025-02-04 02:40:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18450/23838 [03:48<32:45,  2.74it/s][2025-02-04 02:40:38][root][INFO] - Training Epoch: 2/2, step 18449/23838 completed (loss: 0.41304299235343933, acc: 0.8666666746139526)
[2025-02-04 02:40:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18451/23838 [03:49<33:25,  2.69it/s][2025-02-04 02:40:38][root][INFO] - Training Epoch: 2/2, step 18450/23838 completed (loss: 0.6435362100601196, acc: 0.7818182110786438)
[2025-02-04 02:40:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18452/23838 [03:49<31:51,  2.82it/s][2025-02-04 02:40:39][root][INFO] - Training Epoch: 2/2, step 18451/23838 completed (loss: 0.7294276356697083, acc: 0.8148148059844971)
[2025-02-04 02:40:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18453/23838 [03:49<31:34,  2.84it/s][2025-02-04 02:40:39][root][INFO] - Training Epoch: 2/2, step 18452/23838 completed (loss: 0.28750598430633545, acc: 0.9032257795333862)
[2025-02-04 02:40:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18454/23838 [03:50<31:56,  2.81it/s][2025-02-04 02:40:39][root][INFO] - Training Epoch: 2/2, step 18453/23838 completed (loss: 0.3215331435203552, acc: 0.96875)
[2025-02-04 02:40:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18455/23838 [03:50<32:39,  2.75it/s][2025-02-04 02:40:40][root][INFO] - Training Epoch: 2/2, step 18454/23838 completed (loss: 0.4916762411594391, acc: 0.7666666507720947)
[2025-02-04 02:40:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18456/23838 [03:51<32:32,  2.76it/s][2025-02-04 02:40:40][root][INFO] - Training Epoch: 2/2, step 18455/23838 completed (loss: 0.5133303999900818, acc: 0.8235294222831726)
[2025-02-04 02:40:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18457/23838 [03:51<32:57,  2.72it/s][2025-02-04 02:40:41][root][INFO] - Training Epoch: 2/2, step 18456/23838 completed (loss: 0.31468549370765686, acc: 0.8965517282485962)
[2025-02-04 02:40:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18458/23838 [03:51<32:23,  2.77it/s][2025-02-04 02:40:41][root][INFO] - Training Epoch: 2/2, step 18457/23838 completed (loss: 0.6774792075157166, acc: 0.7777777910232544)
[2025-02-04 02:40:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18459/23838 [03:52<31:46,  2.82it/s][2025-02-04 02:40:41][root][INFO] - Training Epoch: 2/2, step 18458/23838 completed (loss: 0.4471186697483063, acc: 0.875)
[2025-02-04 02:40:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18460/23838 [03:52<31:51,  2.81it/s][2025-02-04 02:40:42][root][INFO] - Training Epoch: 2/2, step 18459/23838 completed (loss: 1.026519536972046, acc: 0.7560975551605225)
[2025-02-04 02:40:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18461/23838 [03:52<32:19,  2.77it/s][2025-02-04 02:40:42][root][INFO] - Training Epoch: 2/2, step 18460/23838 completed (loss: 0.6014660596847534, acc: 0.8333333134651184)
[2025-02-04 02:40:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18462/23838 [03:53<33:54,  2.64it/s][2025-02-04 02:40:42][root][INFO] - Training Epoch: 2/2, step 18461/23838 completed (loss: 0.2547730505466461, acc: 0.920634925365448)
[2025-02-04 02:40:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18463/23838 [03:53<34:01,  2.63it/s][2025-02-04 02:40:43][root][INFO] - Training Epoch: 2/2, step 18462/23838 completed (loss: 0.2991655468940735, acc: 0.9090909361839294)
[2025-02-04 02:40:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18464/23838 [03:54<33:48,  2.65it/s][2025-02-04 02:40:43][root][INFO] - Training Epoch: 2/2, step 18463/23838 completed (loss: 0.23616613447666168, acc: 0.9375)
[2025-02-04 02:40:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18465/23838 [03:54<33:54,  2.64it/s][2025-02-04 02:40:44][root][INFO] - Training Epoch: 2/2, step 18464/23838 completed (loss: 0.27720245718955994, acc: 0.9354838728904724)
[2025-02-04 02:40:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18466/23838 [03:54<34:02,  2.63it/s][2025-02-04 02:40:44][root][INFO] - Training Epoch: 2/2, step 18465/23838 completed (loss: 0.0838581994175911, acc: 0.9666666388511658)
[2025-02-04 02:40:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18467/23838 [03:55<38:31,  2.32it/s][2025-02-04 02:40:44][root][INFO] - Training Epoch: 2/2, step 18466/23838 completed (loss: 0.42711779475212097, acc: 0.9041095972061157)
[2025-02-04 02:40:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18468/23838 [03:55<36:40,  2.44it/s][2025-02-04 02:40:45][root][INFO] - Training Epoch: 2/2, step 18467/23838 completed (loss: 0.051458653062582016, acc: 0.9883720874786377)
[2025-02-04 02:40:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18469/23838 [03:56<37:41,  2.37it/s][2025-02-04 02:40:45][root][INFO] - Training Epoch: 2/2, step 18468/23838 completed (loss: 0.19321420788764954, acc: 0.9407894611358643)
[2025-02-04 02:40:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18470/23838 [03:56<41:32,  2.15it/s][2025-02-04 02:40:46][root][INFO] - Training Epoch: 2/2, step 18469/23838 completed (loss: 0.7057604193687439, acc: 0.8290598392486572)
[2025-02-04 02:40:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18471/23838 [03:57<41:57,  2.13it/s][2025-02-04 02:40:46][root][INFO] - Training Epoch: 2/2, step 18470/23838 completed (loss: 0.04203394055366516, acc: 1.0)
[2025-02-04 02:40:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18472/23838 [03:57<40:48,  2.19it/s][2025-02-04 02:40:47][root][INFO] - Training Epoch: 2/2, step 18471/23838 completed (loss: 0.0576329380273819, acc: 0.977011501789093)
[2025-02-04 02:40:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18473/23838 [03:58<38:23,  2.33it/s][2025-02-04 02:40:47][root][INFO] - Training Epoch: 2/2, step 18472/23838 completed (loss: 0.10901886969804764, acc: 0.9791666865348816)
[2025-02-04 02:40:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  77%|[34m███████▋  [0m| 18474/23838 [03:58<36:06,  2.48it/s][2025-02-04 02:40:47][root][INFO] - Training Epoch: 2/2, step 18473/23838 completed (loss: 0.02131815068423748, acc: 1.0)
[2025-02-04 02:40:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18475/23838 [03:58<34:50,  2.57it/s][2025-02-04 02:40:48][root][INFO] - Training Epoch: 2/2, step 18474/23838 completed (loss: 0.39750370383262634, acc: 0.9222221970558167)
[2025-02-04 02:40:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18476/23838 [03:59<35:39,  2.51it/s][2025-02-04 02:40:48][root][INFO] - Training Epoch: 2/2, step 18475/23838 completed (loss: 0.03858114033937454, acc: 1.0)
[2025-02-04 02:40:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18477/23838 [03:59<36:00,  2.48it/s][2025-02-04 02:40:49][root][INFO] - Training Epoch: 2/2, step 18476/23838 completed (loss: 0.02160082571208477, acc: 1.0)
[2025-02-04 02:40:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18478/23838 [04:00<37:29,  2.38it/s][2025-02-04 02:40:49][root][INFO] - Training Epoch: 2/2, step 18477/23838 completed (loss: 0.12049207836389542, acc: 0.961904764175415)
[2025-02-04 02:40:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18479/23838 [04:00<36:57,  2.42it/s][2025-02-04 02:40:49][root][INFO] - Training Epoch: 2/2, step 18478/23838 completed (loss: 0.06173068284988403, acc: 0.9767441749572754)
[2025-02-04 02:40:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18480/23838 [04:00<36:47,  2.43it/s][2025-02-04 02:40:50][root][INFO] - Training Epoch: 2/2, step 18479/23838 completed (loss: 0.19168831408023834, acc: 0.949367105960846)
[2025-02-04 02:40:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18481/23838 [04:01<41:19,  2.16it/s][2025-02-04 02:40:50][root][INFO] - Training Epoch: 2/2, step 18480/23838 completed (loss: 0.07835929095745087, acc: 0.9715909361839294)
[2025-02-04 02:40:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18482/23838 [04:01<39:02,  2.29it/s][2025-02-04 02:40:51][root][INFO] - Training Epoch: 2/2, step 18481/23838 completed (loss: 0.8082038760185242, acc: 0.7604166865348816)
[2025-02-04 02:40:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18483/23838 [04:02<36:41,  2.43it/s][2025-02-04 02:40:51][root][INFO] - Training Epoch: 2/2, step 18482/23838 completed (loss: 0.21754112839698792, acc: 0.9555555582046509)
[2025-02-04 02:40:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18484/23838 [04:02<34:49,  2.56it/s][2025-02-04 02:40:52][root][INFO] - Training Epoch: 2/2, step 18483/23838 completed (loss: 0.04429975524544716, acc: 0.9821428656578064)
[2025-02-04 02:40:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18485/23838 [04:02<34:33,  2.58it/s][2025-02-04 02:40:52][root][INFO] - Training Epoch: 2/2, step 18484/23838 completed (loss: 0.1014978289604187, acc: 0.9885057210922241)
[2025-02-04 02:40:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18486/23838 [04:03<33:05,  2.69it/s][2025-02-04 02:40:52][root][INFO] - Training Epoch: 2/2, step 18485/23838 completed (loss: 0.0602855458855629, acc: 0.9922480583190918)
[2025-02-04 02:40:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18487/23838 [04:03<32:45,  2.72it/s][2025-02-04 02:40:53][root][INFO] - Training Epoch: 2/2, step 18486/23838 completed (loss: 0.04213109239935875, acc: 1.0)
[2025-02-04 02:40:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18488/23838 [04:03<32:21,  2.76it/s][2025-02-04 02:40:53][root][INFO] - Training Epoch: 2/2, step 18487/23838 completed (loss: 0.01618577539920807, acc: 1.0)
[2025-02-04 02:40:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18489/23838 [04:04<31:54,  2.79it/s][2025-02-04 02:40:53][root][INFO] - Training Epoch: 2/2, step 18488/23838 completed (loss: 0.19721196591854095, acc: 0.9529411792755127)
[2025-02-04 02:40:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18490/23838 [04:04<31:08,  2.86it/s][2025-02-04 02:40:54][root][INFO] - Training Epoch: 2/2, step 18489/23838 completed (loss: 0.10716243088245392, acc: 0.9529411792755127)
[2025-02-04 02:40:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18491/23838 [04:04<31:51,  2.80it/s][2025-02-04 02:40:54][root][INFO] - Training Epoch: 2/2, step 18490/23838 completed (loss: 0.045100681483745575, acc: 0.9914529919624329)
[2025-02-04 02:40:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18492/23838 [04:05<31:07,  2.86it/s][2025-02-04 02:40:54][root][INFO] - Training Epoch: 2/2, step 18491/23838 completed (loss: 0.027040719985961914, acc: 0.9848484992980957)
[2025-02-04 02:40:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18493/23838 [04:05<31:44,  2.81it/s][2025-02-04 02:40:55][root][INFO] - Training Epoch: 2/2, step 18492/23838 completed (loss: 0.024993406608700752, acc: 0.9934210777282715)
[2025-02-04 02:40:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18494/23838 [04:06<31:52,  2.79it/s][2025-02-04 02:40:55][root][INFO] - Training Epoch: 2/2, step 18493/23838 completed (loss: 0.1252298802137375, acc: 0.9692307710647583)
[2025-02-04 02:40:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18495/23838 [04:06<30:34,  2.91it/s][2025-02-04 02:40:55][root][INFO] - Training Epoch: 2/2, step 18494/23838 completed (loss: 0.029502706602215767, acc: 0.9933333396911621)
[2025-02-04 02:40:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18496/23838 [04:06<30:34,  2.91it/s][2025-02-04 02:40:56][root][INFO] - Training Epoch: 2/2, step 18495/23838 completed (loss: 0.20628763735294342, acc: 0.96875)
[2025-02-04 02:40:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18497/23838 [04:06<28:50,  3.09it/s][2025-02-04 02:40:56][root][INFO] - Training Epoch: 2/2, step 18496/23838 completed (loss: 0.04277965798974037, acc: 1.0)
[2025-02-04 02:40:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18498/23838 [04:07<29:57,  2.97it/s][2025-02-04 02:40:56][root][INFO] - Training Epoch: 2/2, step 18497/23838 completed (loss: 0.1583588719367981, acc: 0.9636363387107849)
[2025-02-04 02:40:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18499/23838 [04:07<31:22,  2.84it/s][2025-02-04 02:40:57][root][INFO] - Training Epoch: 2/2, step 18498/23838 completed (loss: 0.11701266467571259, acc: 0.9594594836235046)
[2025-02-04 02:40:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18500/23838 [04:08<30:44,  2.89it/s][2025-02-04 02:40:57][root][INFO] - Training Epoch: 2/2, step 18499/23838 completed (loss: 0.012675785459578037, acc: 1.0)
[2025-02-04 02:40:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18501/23838 [04:08<30:17,  2.94it/s][2025-02-04 02:40:57][root][INFO] - Training Epoch: 2/2, step 18500/23838 completed (loss: 0.23662540316581726, acc: 0.9245283007621765)
[2025-02-04 02:40:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18502/23838 [04:08<29:40,  3.00it/s][2025-02-04 02:40:58][root][INFO] - Training Epoch: 2/2, step 18501/23838 completed (loss: 0.04814859852194786, acc: 0.9767441749572754)
[2025-02-04 02:40:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18503/23838 [04:08<29:11,  3.05it/s][2025-02-04 02:40:58][root][INFO] - Training Epoch: 2/2, step 18502/23838 completed (loss: 0.04480107128620148, acc: 0.9855072498321533)
[2025-02-04 02:40:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18504/23838 [04:09<28:20,  3.14it/s][2025-02-04 02:40:58][root][INFO] - Training Epoch: 2/2, step 18503/23838 completed (loss: 0.19831757247447968, acc: 0.978723406791687)
[2025-02-04 02:40:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18505/23838 [04:09<27:35,  3.22it/s][2025-02-04 02:40:59][root][INFO] - Training Epoch: 2/2, step 18504/23838 completed (loss: 0.12302856147289276, acc: 0.9589040875434875)
[2025-02-04 02:40:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18506/23838 [04:09<28:25,  3.13it/s][2025-02-04 02:40:59][root][INFO] - Training Epoch: 2/2, step 18505/23838 completed (loss: 0.42546457052230835, acc: 0.8421052694320679)
[2025-02-04 02:40:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18507/23838 [04:10<32:35,  2.73it/s][2025-02-04 02:40:59][root][INFO] - Training Epoch: 2/2, step 18506/23838 completed (loss: 0.09814047068357468, acc: 0.9411764740943909)
[2025-02-04 02:41:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18508/23838 [04:10<31:52,  2.79it/s][2025-02-04 02:41:00][root][INFO] - Training Epoch: 2/2, step 18507/23838 completed (loss: 0.20711387693881989, acc: 0.9200000166893005)
[2025-02-04 02:41:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18509/23838 [04:11<31:32,  2.82it/s][2025-02-04 02:41:00][root][INFO] - Training Epoch: 2/2, step 18508/23838 completed (loss: 0.11129536479711533, acc: 0.9708737730979919)
[2025-02-04 02:41:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18510/23838 [04:11<30:23,  2.92it/s][2025-02-04 02:41:00][root][INFO] - Training Epoch: 2/2, step 18509/23838 completed (loss: 0.06681844592094421, acc: 0.9736841917037964)
[2025-02-04 02:41:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18511/23838 [04:11<29:29,  3.01it/s][2025-02-04 02:41:01][root][INFO] - Training Epoch: 2/2, step 18510/23838 completed (loss: 0.05046851560473442, acc: 0.9696969985961914)
[2025-02-04 02:41:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18512/23838 [04:12<29:12,  3.04it/s][2025-02-04 02:41:01][root][INFO] - Training Epoch: 2/2, step 18511/23838 completed (loss: 0.3483631908893585, acc: 0.9047619104385376)
[2025-02-04 02:41:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18513/23838 [04:12<30:50,  2.88it/s][2025-02-04 02:41:01][root][INFO] - Training Epoch: 2/2, step 18512/23838 completed (loss: 0.008881094865500927, acc: 1.0)
[2025-02-04 02:41:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18514/23838 [04:12<31:30,  2.82it/s][2025-02-04 02:41:02][root][INFO] - Training Epoch: 2/2, step 18513/23838 completed (loss: 0.038693707436323166, acc: 1.0)
[2025-02-04 02:41:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18515/23838 [04:13<32:23,  2.74it/s][2025-02-04 02:41:02][root][INFO] - Training Epoch: 2/2, step 18514/23838 completed (loss: 0.0430244542658329, acc: 0.9879518151283264)
[2025-02-04 02:41:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18516/23838 [04:13<30:55,  2.87it/s][2025-02-04 02:41:03][root][INFO] - Training Epoch: 2/2, step 18515/23838 completed (loss: 0.02298748679459095, acc: 0.9863013625144958)
[2025-02-04 02:41:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18517/23838 [04:13<29:58,  2.96it/s][2025-02-04 02:41:03][root][INFO] - Training Epoch: 2/2, step 18516/23838 completed (loss: 0.04202035441994667, acc: 0.9857142567634583)
[2025-02-04 02:41:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18518/23838 [04:14<29:28,  3.01it/s][2025-02-04 02:41:03][root][INFO] - Training Epoch: 2/2, step 18517/23838 completed (loss: 0.08668342977762222, acc: 0.98591548204422)
[2025-02-04 02:41:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18519/23838 [04:14<29:19,  3.02it/s][2025-02-04 02:41:04][root][INFO] - Training Epoch: 2/2, step 18518/23838 completed (loss: 0.01427556574344635, acc: 0.9918032884597778)
[2025-02-04 02:41:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18520/23838 [04:14<33:05,  2.68it/s][2025-02-04 02:41:04][root][INFO] - Training Epoch: 2/2, step 18519/23838 completed (loss: 0.16251255571842194, acc: 0.9743589758872986)
[2025-02-04 02:41:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18521/23838 [04:15<34:04,  2.60it/s][2025-02-04 02:41:04][root][INFO] - Training Epoch: 2/2, step 18520/23838 completed (loss: 0.41159865260124207, acc: 0.8620689511299133)
[2025-02-04 02:41:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18522/23838 [04:15<33:35,  2.64it/s][2025-02-04 02:41:05][root][INFO] - Training Epoch: 2/2, step 18521/23838 completed (loss: 0.018203139305114746, acc: 0.9897959232330322)
[2025-02-04 02:41:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18523/23838 [04:16<32:41,  2.71it/s][2025-02-04 02:41:05][root][INFO] - Training Epoch: 2/2, step 18522/23838 completed (loss: 0.028443172574043274, acc: 0.9925373196601868)
[2025-02-04 02:41:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18524/23838 [04:16<31:40,  2.80it/s][2025-02-04 02:41:05][root][INFO] - Training Epoch: 2/2, step 18523/23838 completed (loss: 0.07651762664318085, acc: 0.9733333587646484)
[2025-02-04 02:41:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18525/23838 [04:16<30:23,  2.91it/s][2025-02-04 02:41:06][root][INFO] - Training Epoch: 2/2, step 18524/23838 completed (loss: 0.04494938626885414, acc: 0.9655172228813171)
[2025-02-04 02:41:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18526/23838 [04:17<30:17,  2.92it/s][2025-02-04 02:41:06][root][INFO] - Training Epoch: 2/2, step 18525/23838 completed (loss: 0.12733758985996246, acc: 0.9740259647369385)
[2025-02-04 02:41:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18527/23838 [04:17<29:18,  3.02it/s][2025-02-04 02:41:06][root][INFO] - Training Epoch: 2/2, step 18526/23838 completed (loss: 0.09259713441133499, acc: 0.9732142686843872)
[2025-02-04 02:41:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18528/23838 [04:17<29:20,  3.02it/s][2025-02-04 02:41:07][root][INFO] - Training Epoch: 2/2, step 18527/23838 completed (loss: 0.27716702222824097, acc: 0.9473684430122375)
[2025-02-04 02:41:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18529/23838 [04:17<29:03,  3.04it/s][2025-02-04 02:41:07][root][INFO] - Training Epoch: 2/2, step 18528/23838 completed (loss: 0.028329046443104744, acc: 0.984375)
[2025-02-04 02:41:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18530/23838 [04:18<30:58,  2.86it/s][2025-02-04 02:41:07][root][INFO] - Training Epoch: 2/2, step 18529/23838 completed (loss: 0.012885842472314835, acc: 1.0)
[2025-02-04 02:41:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18531/23838 [04:18<30:53,  2.86it/s][2025-02-04 02:41:08][root][INFO] - Training Epoch: 2/2, step 18530/23838 completed (loss: 0.020747438073158264, acc: 0.9917355179786682)
[2025-02-04 02:41:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18532/23838 [04:19<31:14,  2.83it/s][2025-02-04 02:41:08][root][INFO] - Training Epoch: 2/2, step 18531/23838 completed (loss: 0.06146805360913277, acc: 0.9824561476707458)
[2025-02-04 02:41:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18533/23838 [04:19<32:14,  2.74it/s][2025-02-04 02:41:09][root][INFO] - Training Epoch: 2/2, step 18532/23838 completed (loss: 0.10361217707395554, acc: 0.9659090638160706)
[2025-02-04 02:41:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18534/23838 [04:19<32:50,  2.69it/s][2025-02-04 02:41:09][root][INFO] - Training Epoch: 2/2, step 18533/23838 completed (loss: 0.03713203966617584, acc: 0.9811320900917053)
[2025-02-04 02:41:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18535/23838 [04:20<33:06,  2.67it/s][2025-02-04 02:41:09][root][INFO] - Training Epoch: 2/2, step 18534/23838 completed (loss: 0.12164407223463058, acc: 0.9807692170143127)
[2025-02-04 02:41:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18536/23838 [04:20<32:54,  2.69it/s][2025-02-04 02:41:10][root][INFO] - Training Epoch: 2/2, step 18535/23838 completed (loss: 0.023968178778886795, acc: 0.9916666746139526)
[2025-02-04 02:41:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18537/23838 [04:20<31:55,  2.77it/s][2025-02-04 02:41:10][root][INFO] - Training Epoch: 2/2, step 18536/23838 completed (loss: 0.1622856855392456, acc: 0.9433962106704712)
[2025-02-04 02:41:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18538/23838 [04:21<34:19,  2.57it/s][2025-02-04 02:41:10][root][INFO] - Training Epoch: 2/2, step 18537/23838 completed (loss: 0.1508783996105194, acc: 0.9780219793319702)
[2025-02-04 02:41:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18539/23838 [04:21<35:11,  2.51it/s][2025-02-04 02:41:11][root][INFO] - Training Epoch: 2/2, step 18538/23838 completed (loss: 0.10824017226696014, acc: 0.9712643623352051)
[2025-02-04 02:41:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18540/23838 [04:22<32:01,  2.76it/s][2025-02-04 02:41:11][root][INFO] - Training Epoch: 2/2, step 18539/23838 completed (loss: 0.059017930179834366, acc: 0.9861111044883728)
[2025-02-04 02:41:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18541/23838 [04:22<31:17,  2.82it/s][2025-02-04 02:41:12][root][INFO] - Training Epoch: 2/2, step 18540/23838 completed (loss: 0.12883585691452026, acc: 0.9754601120948792)
[2025-02-04 02:41:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18542/23838 [04:22<31:40,  2.79it/s][2025-02-04 02:41:12][root][INFO] - Training Epoch: 2/2, step 18541/23838 completed (loss: 0.028917919844388962, acc: 0.9819819927215576)
[2025-02-04 02:41:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18543/23838 [04:23<30:28,  2.90it/s][2025-02-04 02:41:12][root][INFO] - Training Epoch: 2/2, step 18542/23838 completed (loss: 0.09446091949939728, acc: 0.9818181991577148)
[2025-02-04 02:41:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18544/23838 [04:23<30:37,  2.88it/s][2025-02-04 02:41:13][root][INFO] - Training Epoch: 2/2, step 18543/23838 completed (loss: 0.11788153648376465, acc: 0.9558823704719543)
[2025-02-04 02:41:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18545/23838 [04:23<30:24,  2.90it/s][2025-02-04 02:41:13][root][INFO] - Training Epoch: 2/2, step 18544/23838 completed (loss: 0.027007566764950752, acc: 0.9933333396911621)
[2025-02-04 02:41:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18546/23838 [04:24<30:25,  2.90it/s][2025-02-04 02:41:13][root][INFO] - Training Epoch: 2/2, step 18545/23838 completed (loss: 0.050789911299943924, acc: 0.9803921580314636)
[2025-02-04 02:41:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18547/23838 [04:24<31:21,  2.81it/s][2025-02-04 02:41:14][root][INFO] - Training Epoch: 2/2, step 18546/23838 completed (loss: 0.26519775390625, acc: 0.9200000166893005)
[2025-02-04 02:41:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18548/23838 [04:24<31:39,  2.79it/s][2025-02-04 02:41:14][root][INFO] - Training Epoch: 2/2, step 18547/23838 completed (loss: 0.040638551115989685, acc: 0.9907407164573669)
[2025-02-04 02:41:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18549/23838 [04:25<32:20,  2.73it/s][2025-02-04 02:41:14][root][INFO] - Training Epoch: 2/2, step 18548/23838 completed (loss: 0.04864265024662018, acc: 0.9902912378311157)
[2025-02-04 02:41:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18550/23838 [04:25<31:38,  2.78it/s][2025-02-04 02:41:15][root][INFO] - Training Epoch: 2/2, step 18549/23838 completed (loss: 0.18460559844970703, acc: 0.9347826242446899)
[2025-02-04 02:41:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18551/23838 [04:25<31:31,  2.79it/s][2025-02-04 02:41:15][root][INFO] - Training Epoch: 2/2, step 18550/23838 completed (loss: 0.05968611314892769, acc: 0.982300877571106)
[2025-02-04 02:41:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18552/23838 [04:26<31:20,  2.81it/s][2025-02-04 02:41:15][root][INFO] - Training Epoch: 2/2, step 18551/23838 completed (loss: 0.11558333784341812, acc: 0.9750000238418579)
[2025-02-04 02:41:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18553/23838 [04:26<32:12,  2.74it/s][2025-02-04 02:41:16][root][INFO] - Training Epoch: 2/2, step 18552/23838 completed (loss: 0.04892505332827568, acc: 0.9702970385551453)
[2025-02-04 02:41:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18554/23838 [04:27<32:14,  2.73it/s][2025-02-04 02:41:16][root][INFO] - Training Epoch: 2/2, step 18553/23838 completed (loss: 0.04548316448926926, acc: 1.0)
[2025-02-04 02:41:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18555/23838 [04:27<31:04,  2.83it/s][2025-02-04 02:41:16][root][INFO] - Training Epoch: 2/2, step 18554/23838 completed (loss: 0.18409912288188934, acc: 0.9538461565971375)
[2025-02-04 02:41:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18556/23838 [04:27<30:44,  2.86it/s][2025-02-04 02:41:17][root][INFO] - Training Epoch: 2/2, step 18555/23838 completed (loss: 0.02419668436050415, acc: 1.0)
[2025-02-04 02:41:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18557/23838 [04:28<30:47,  2.86it/s][2025-02-04 02:41:17][root][INFO] - Training Epoch: 2/2, step 18556/23838 completed (loss: 0.06122543290257454, acc: 0.9816513657569885)
[2025-02-04 02:41:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18558/23838 [04:28<31:23,  2.80it/s][2025-02-04 02:41:18][root][INFO] - Training Epoch: 2/2, step 18557/23838 completed (loss: 0.3333253264427185, acc: 0.9090909361839294)
[2025-02-04 02:41:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18559/23838 [04:28<31:56,  2.75it/s][2025-02-04 02:41:18][root][INFO] - Training Epoch: 2/2, step 18558/23838 completed (loss: 0.03377837315201759, acc: 0.9856114983558655)
[2025-02-04 02:41:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18560/23838 [04:29<33:27,  2.63it/s][2025-02-04 02:41:18][root][INFO] - Training Epoch: 2/2, step 18559/23838 completed (loss: 0.04321126267313957, acc: 0.9828571677207947)
[2025-02-04 02:41:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18561/23838 [04:29<35:11,  2.50it/s][2025-02-04 02:41:19][root][INFO] - Training Epoch: 2/2, step 18560/23838 completed (loss: 0.2698064148426056, acc: 0.9438202381134033)
[2025-02-04 02:41:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18562/23838 [04:30<34:16,  2.57it/s][2025-02-04 02:41:19][root][INFO] - Training Epoch: 2/2, step 18561/23838 completed (loss: 0.22822317481040955, acc: 0.9611650705337524)
[2025-02-04 02:41:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18563/23838 [04:30<33:50,  2.60it/s][2025-02-04 02:41:20][root][INFO] - Training Epoch: 2/2, step 18562/23838 completed (loss: 0.07936719059944153, acc: 0.9763779640197754)
[2025-02-04 02:41:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18564/23838 [04:30<33:13,  2.65it/s][2025-02-04 02:41:20][root][INFO] - Training Epoch: 2/2, step 18563/23838 completed (loss: 0.12926238775253296, acc: 0.9655172228813171)
[2025-02-04 02:41:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18565/23838 [04:31<34:47,  2.53it/s][2025-02-04 02:41:20][root][INFO] - Training Epoch: 2/2, step 18564/23838 completed (loss: 0.02438080869615078, acc: 0.9864864945411682)
[2025-02-04 02:41:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18566/23838 [04:31<35:47,  2.46it/s][2025-02-04 02:41:21][root][INFO] - Training Epoch: 2/2, step 18565/23838 completed (loss: 0.11242357641458511, acc: 0.9545454382896423)
[2025-02-04 02:41:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18567/23838 [04:32<35:17,  2.49it/s][2025-02-04 02:41:21][root][INFO] - Training Epoch: 2/2, step 18566/23838 completed (loss: 0.09064609557390213, acc: 0.9696969985961914)
[2025-02-04 02:41:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18568/23838 [04:32<35:06,  2.50it/s][2025-02-04 02:41:22][root][INFO] - Training Epoch: 2/2, step 18567/23838 completed (loss: 0.11329422891139984, acc: 0.957446813583374)
[2025-02-04 02:41:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18569/23838 [04:32<32:05,  2.74it/s][2025-02-04 02:41:22][root][INFO] - Training Epoch: 2/2, step 18568/23838 completed (loss: 0.008312813937664032, acc: 1.0)
[2025-02-04 02:41:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18570/23838 [04:33<31:49,  2.76it/s][2025-02-04 02:41:22][root][INFO] - Training Epoch: 2/2, step 18569/23838 completed (loss: 0.13611356914043427, acc: 0.9583333134651184)
[2025-02-04 02:41:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18571/23838 [04:33<30:52,  2.84it/s][2025-02-04 02:41:23][root][INFO] - Training Epoch: 2/2, step 18570/23838 completed (loss: 0.3434874713420868, acc: 0.9108911156654358)
[2025-02-04 02:41:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18572/23838 [04:33<32:41,  2.69it/s][2025-02-04 02:41:23][root][INFO] - Training Epoch: 2/2, step 18571/23838 completed (loss: 0.017353927716612816, acc: 1.0)
[2025-02-04 02:41:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18573/23838 [04:34<32:04,  2.74it/s][2025-02-04 02:41:23][root][INFO] - Training Epoch: 2/2, step 18572/23838 completed (loss: 0.17500008642673492, acc: 0.9659090638160706)
[2025-02-04 02:41:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18574/23838 [04:34<34:06,  2.57it/s][2025-02-04 02:41:24][root][INFO] - Training Epoch: 2/2, step 18573/23838 completed (loss: 0.09740527719259262, acc: 0.9552238583564758)
[2025-02-04 02:41:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18575/23838 [04:35<33:58,  2.58it/s][2025-02-04 02:41:24][root][INFO] - Training Epoch: 2/2, step 18574/23838 completed (loss: 0.06622625142335892, acc: 0.982758641242981)
[2025-02-04 02:41:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18576/23838 [04:35<32:09,  2.73it/s][2025-02-04 02:41:24][root][INFO] - Training Epoch: 2/2, step 18575/23838 completed (loss: 0.1263185739517212, acc: 0.9684210419654846)
[2025-02-04 02:41:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18577/23838 [04:35<31:34,  2.78it/s][2025-02-04 02:41:25][root][INFO] - Training Epoch: 2/2, step 18576/23838 completed (loss: 0.14732283353805542, acc: 0.9696969985961914)
[2025-02-04 02:41:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18578/23838 [04:36<33:17,  2.63it/s][2025-02-04 02:41:25][root][INFO] - Training Epoch: 2/2, step 18577/23838 completed (loss: 0.027140526100993156, acc: 0.9855072498321533)
[2025-02-04 02:41:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18579/23838 [04:36<36:25,  2.41it/s][2025-02-04 02:41:26][root][INFO] - Training Epoch: 2/2, step 18578/23838 completed (loss: 0.23355279862880707, acc: 0.9417475461959839)
[2025-02-04 02:41:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18580/23838 [04:36<34:55,  2.51it/s][2025-02-04 02:41:26][root][INFO] - Training Epoch: 2/2, step 18579/23838 completed (loss: 0.0278631579130888, acc: 1.0)
[2025-02-04 02:41:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18581/23838 [04:37<32:40,  2.68it/s][2025-02-04 02:41:26][root][INFO] - Training Epoch: 2/2, step 18580/23838 completed (loss: 0.03540049120783806, acc: 0.9824561476707458)
[2025-02-04 02:41:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18582/23838 [04:37<33:24,  2.62it/s][2025-02-04 02:41:27][root][INFO] - Training Epoch: 2/2, step 18581/23838 completed (loss: 0.024757154285907745, acc: 0.9883720874786377)
[2025-02-04 02:41:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18583/23838 [04:38<31:38,  2.77it/s][2025-02-04 02:41:27][root][INFO] - Training Epoch: 2/2, step 18582/23838 completed (loss: 0.5362288951873779, acc: 0.8571428656578064)
[2025-02-04 02:41:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18584/23838 [04:38<30:41,  2.85it/s][2025-02-04 02:41:27][root][INFO] - Training Epoch: 2/2, step 18583/23838 completed (loss: 0.18458110094070435, acc: 0.9444444179534912)
[2025-02-04 02:41:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18585/23838 [04:38<30:46,  2.84it/s][2025-02-04 02:41:28][root][INFO] - Training Epoch: 2/2, step 18584/23838 completed (loss: 0.11675065755844116, acc: 0.9557521939277649)
[2025-02-04 02:41:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18586/23838 [04:39<32:13,  2.72it/s][2025-02-04 02:41:28][root][INFO] - Training Epoch: 2/2, step 18585/23838 completed (loss: 0.14207199215888977, acc: 0.9420289993286133)
[2025-02-04 02:41:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18587/23838 [04:39<32:45,  2.67it/s][2025-02-04 02:41:29][root][INFO] - Training Epoch: 2/2, step 18586/23838 completed (loss: 0.34440919756889343, acc: 0.9402984976768494)
[2025-02-04 02:41:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18588/23838 [04:39<32:22,  2.70it/s][2025-02-04 02:41:29][root][INFO] - Training Epoch: 2/2, step 18587/23838 completed (loss: 0.10000792890787125, acc: 0.9791666865348816)
[2025-02-04 02:41:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18589/23838 [04:40<31:08,  2.81it/s][2025-02-04 02:41:29][root][INFO] - Training Epoch: 2/2, step 18588/23838 completed (loss: 0.12985315918922424, acc: 0.9444444179534912)
[2025-02-04 02:41:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18590/23838 [04:40<31:39,  2.76it/s][2025-02-04 02:41:30][root][INFO] - Training Epoch: 2/2, step 18589/23838 completed (loss: 0.18933792412281036, acc: 0.9484536051750183)
[2025-02-04 02:41:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18591/23838 [04:40<31:32,  2.77it/s][2025-02-04 02:41:30][root][INFO] - Training Epoch: 2/2, step 18590/23838 completed (loss: 0.12745091319084167, acc: 0.9729729890823364)
[2025-02-04 02:41:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18592/23838 [04:41<32:50,  2.66it/s][2025-02-04 02:41:30][root][INFO] - Training Epoch: 2/2, step 18591/23838 completed (loss: 0.041665539145469666, acc: 1.0)
[2025-02-04 02:41:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18593/23838 [04:41<37:31,  2.33it/s][2025-02-04 02:41:31][root][INFO] - Training Epoch: 2/2, step 18592/23838 completed (loss: 0.07016506791114807, acc: 0.9900000095367432)
[2025-02-04 02:41:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18594/23838 [04:42<39:39,  2.20it/s][2025-02-04 02:41:31][root][INFO] - Training Epoch: 2/2, step 18593/23838 completed (loss: 0.14893141388893127, acc: 0.961904764175415)
[2025-02-04 02:41:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18595/23838 [04:42<36:54,  2.37it/s][2025-02-04 02:41:32][root][INFO] - Training Epoch: 2/2, step 18594/23838 completed (loss: 0.08135844022035599, acc: 0.9677419066429138)
[2025-02-04 02:41:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18596/23838 [04:43<35:38,  2.45it/s][2025-02-04 02:41:32][root][INFO] - Training Epoch: 2/2, step 18595/23838 completed (loss: 0.41187044978141785, acc: 0.8727272748947144)
[2025-02-04 02:41:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18597/23838 [04:43<38:26,  2.27it/s][2025-02-04 02:41:33][root][INFO] - Training Epoch: 2/2, step 18596/23838 completed (loss: 0.15766865015029907, acc: 0.9375)
[2025-02-04 02:41:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18598/23838 [04:43<35:10,  2.48it/s][2025-02-04 02:41:33][root][INFO] - Training Epoch: 2/2, step 18597/23838 completed (loss: 0.0634688064455986, acc: 0.9659090638160706)
[2025-02-04 02:41:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18599/23838 [04:44<32:53,  2.65it/s][2025-02-04 02:41:33][root][INFO] - Training Epoch: 2/2, step 18598/23838 completed (loss: 0.35770729184150696, acc: 0.8987341523170471)
[2025-02-04 02:41:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18600/23838 [04:44<31:00,  2.82it/s][2025-02-04 02:41:34][root][INFO] - Training Epoch: 2/2, step 18599/23838 completed (loss: 0.00964080635458231, acc: 1.0)
[2025-02-04 02:41:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18601/23838 [04:45<38:27,  2.27it/s][2025-02-04 02:41:34][root][INFO] - Training Epoch: 2/2, step 18600/23838 completed (loss: 0.14416001737117767, acc: 0.9594594836235046)
[2025-02-04 02:41:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18602/23838 [04:45<36:20,  2.40it/s][2025-02-04 02:41:35][root][INFO] - Training Epoch: 2/2, step 18601/23838 completed (loss: 0.15891896188259125, acc: 0.9651162624359131)
[2025-02-04 02:41:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18603/23838 [04:45<35:11,  2.48it/s][2025-02-04 02:41:35][root][INFO] - Training Epoch: 2/2, step 18602/23838 completed (loss: 0.1276870220899582, acc: 0.9627659320831299)
[2025-02-04 02:41:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18604/23838 [04:46<35:51,  2.43it/s][2025-02-04 02:41:35][root][INFO] - Training Epoch: 2/2, step 18603/23838 completed (loss: 0.09425829350948334, acc: 0.9801324605941772)
[2025-02-04 02:41:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18605/23838 [04:46<34:02,  2.56it/s][2025-02-04 02:41:36][root][INFO] - Training Epoch: 2/2, step 18604/23838 completed (loss: 0.2580244541168213, acc: 0.9347826242446899)
[2025-02-04 02:41:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18606/23838 [04:47<33:50,  2.58it/s][2025-02-04 02:41:36][root][INFO] - Training Epoch: 2/2, step 18605/23838 completed (loss: 0.1164337769150734, acc: 0.9444444179534912)
[2025-02-04 02:41:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18607/23838 [04:47<35:29,  2.46it/s][2025-02-04 02:41:37][root][INFO] - Training Epoch: 2/2, step 18606/23838 completed (loss: 0.19516009092330933, acc: 0.9404761791229248)
[2025-02-04 02:41:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18608/23838 [04:48<40:35,  2.15it/s][2025-02-04 02:41:37][root][INFO] - Training Epoch: 2/2, step 18607/23838 completed (loss: 0.07581692934036255, acc: 0.9669421315193176)
[2025-02-04 02:41:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18609/23838 [04:48<38:38,  2.26it/s][2025-02-04 02:41:38][root][INFO] - Training Epoch: 2/2, step 18608/23838 completed (loss: 0.1756047159433365, acc: 0.9591836929321289)
[2025-02-04 02:41:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18610/23838 [04:49<41:53,  2.08it/s][2025-02-04 02:41:38][root][INFO] - Training Epoch: 2/2, step 18609/23838 completed (loss: 0.34485742449760437, acc: 0.9014084339141846)
[2025-02-04 02:41:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18611/23838 [04:49<40:08,  2.17it/s][2025-02-04 02:41:39][root][INFO] - Training Epoch: 2/2, step 18610/23838 completed (loss: 0.12474605441093445, acc: 0.9743589758872986)
[2025-02-04 02:41:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18612/23838 [04:49<36:31,  2.39it/s][2025-02-04 02:41:39][root][INFO] - Training Epoch: 2/2, step 18611/23838 completed (loss: 0.35104817152023315, acc: 0.9285714030265808)
[2025-02-04 02:41:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18613/23838 [04:50<39:56,  2.18it/s][2025-02-04 02:41:39][root][INFO] - Training Epoch: 2/2, step 18612/23838 completed (loss: 0.1755063533782959, acc: 0.9545454382896423)
[2025-02-04 02:41:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18614/23838 [04:50<38:54,  2.24it/s][2025-02-04 02:41:40][root][INFO] - Training Epoch: 2/2, step 18613/23838 completed (loss: 0.11408445239067078, acc: 0.9696969985961914)
[2025-02-04 02:41:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18615/23838 [04:51<40:33,  2.15it/s][2025-02-04 02:41:40][root][INFO] - Training Epoch: 2/2, step 18614/23838 completed (loss: 0.2398889809846878, acc: 0.9541284441947937)
[2025-02-04 02:41:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18616/23838 [04:51<36:44,  2.37it/s][2025-02-04 02:41:41][root][INFO] - Training Epoch: 2/2, step 18615/23838 completed (loss: 0.3474775552749634, acc: 0.9166666865348816)
[2025-02-04 02:41:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18617/23838 [04:52<36:46,  2.37it/s][2025-02-04 02:41:41][root][INFO] - Training Epoch: 2/2, step 18616/23838 completed (loss: 0.0668586865067482, acc: 0.9772727489471436)
[2025-02-04 02:41:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18618/23838 [04:52<33:32,  2.59it/s][2025-02-04 02:41:41][root][INFO] - Training Epoch: 2/2, step 18617/23838 completed (loss: 0.323676198720932, acc: 0.8627451062202454)
[2025-02-04 02:41:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18619/23838 [04:52<31:53,  2.73it/s][2025-02-04 02:41:42][root][INFO] - Training Epoch: 2/2, step 18618/23838 completed (loss: 0.3160385489463806, acc: 0.9333333373069763)
[2025-02-04 02:41:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18620/23838 [04:53<33:58,  2.56it/s][2025-02-04 02:41:42][root][INFO] - Training Epoch: 2/2, step 18619/23838 completed (loss: 0.07480571419000626, acc: 0.9746835231781006)
[2025-02-04 02:41:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18621/23838 [04:53<33:44,  2.58it/s][2025-02-04 02:41:43][root][INFO] - Training Epoch: 2/2, step 18620/23838 completed (loss: 0.03370632976293564, acc: 0.991150438785553)
[2025-02-04 02:41:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18622/23838 [04:54<38:43,  2.25it/s][2025-02-04 02:41:43][root][INFO] - Training Epoch: 2/2, step 18621/23838 completed (loss: 0.27989253401756287, acc: 0.9457364082336426)
[2025-02-04 02:41:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18623/23838 [04:54<39:43,  2.19it/s][2025-02-04 02:41:44][root][INFO] - Training Epoch: 2/2, step 18622/23838 completed (loss: 0.13599362969398499, acc: 0.9532710313796997)
[2025-02-04 02:41:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18624/23838 [04:55<45:03,  1.93it/s][2025-02-04 02:41:44][root][INFO] - Training Epoch: 2/2, step 18623/23838 completed (loss: 0.21887743473052979, acc: 0.9275362491607666)
[2025-02-04 02:41:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18625/23838 [04:55<41:34,  2.09it/s][2025-02-04 02:41:45][root][INFO] - Training Epoch: 2/2, step 18624/23838 completed (loss: 0.3852921426296234, acc: 0.8837209343910217)
[2025-02-04 02:41:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18626/23838 [04:56<43:39,  1.99it/s][2025-02-04 02:41:45][root][INFO] - Training Epoch: 2/2, step 18625/23838 completed (loss: 0.18817414343357086, acc: 0.9692307710647583)
[2025-02-04 02:41:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18627/23838 [04:56<41:28,  2.09it/s][2025-02-04 02:41:46][root][INFO] - Training Epoch: 2/2, step 18626/23838 completed (loss: 0.15837012231349945, acc: 0.9655172228813171)
[2025-02-04 02:41:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18628/23838 [04:57<49:13,  1.76it/s][2025-02-04 02:41:46][root][INFO] - Training Epoch: 2/2, step 18627/23838 completed (loss: 0.13303887844085693, acc: 0.9710144996643066)
[2025-02-04 02:41:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18629/23838 [04:57<49:50,  1.74it/s][2025-02-04 02:41:47][root][INFO] - Training Epoch: 2/2, step 18628/23838 completed (loss: 0.1728154420852661, acc: 0.9658119678497314)
[2025-02-04 02:41:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18630/23838 [04:58<43:27,  2.00it/s][2025-02-04 02:41:47][root][INFO] - Training Epoch: 2/2, step 18629/23838 completed (loss: 0.15674147009849548, acc: 0.9596773982048035)
[2025-02-04 02:41:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18631/23838 [04:58<43:31,  1.99it/s][2025-02-04 02:41:48][root][INFO] - Training Epoch: 2/2, step 18630/23838 completed (loss: 0.1429184526205063, acc: 0.961904764175415)
[2025-02-04 02:41:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18632/23838 [04:59<40:19,  2.15it/s][2025-02-04 02:41:48][root][INFO] - Training Epoch: 2/2, step 18631/23838 completed (loss: 0.12076421827077866, acc: 0.969072163105011)
[2025-02-04 02:41:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18633/23838 [04:59<40:44,  2.13it/s][2025-02-04 02:41:49][root][INFO] - Training Epoch: 2/2, step 18632/23838 completed (loss: 0.07832866162061691, acc: 0.98591548204422)
[2025-02-04 02:41:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18634/23838 [04:59<36:30,  2.38it/s][2025-02-04 02:41:49][root][INFO] - Training Epoch: 2/2, step 18633/23838 completed (loss: 0.22447410225868225, acc: 0.949999988079071)
[2025-02-04 02:41:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18635/23838 [05:00<40:14,  2.15it/s][2025-02-04 02:41:50][root][INFO] - Training Epoch: 2/2, step 18634/23838 completed (loss: 0.26290780305862427, acc: 0.907216489315033)
[2025-02-04 02:41:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18636/23838 [05:00<40:07,  2.16it/s][2025-02-04 02:41:50][root][INFO] - Training Epoch: 2/2, step 18635/23838 completed (loss: 0.05940276384353638, acc: 0.9777777791023254)
[2025-02-04 02:41:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18637/23838 [05:01<38:51,  2.23it/s][2025-02-04 02:41:50][root][INFO] - Training Epoch: 2/2, step 18636/23838 completed (loss: 0.2941240966320038, acc: 0.8943089246749878)
[2025-02-04 02:41:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18638/23838 [05:01<37:35,  2.31it/s][2025-02-04 02:41:51][root][INFO] - Training Epoch: 2/2, step 18637/23838 completed (loss: 0.5145431756973267, acc: 0.8701298832893372)
[2025-02-04 02:41:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18639/23838 [05:02<38:13,  2.27it/s][2025-02-04 02:41:51][root][INFO] - Training Epoch: 2/2, step 18638/23838 completed (loss: 0.2730633020401001, acc: 0.8901098966598511)
[2025-02-04 02:41:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18640/23838 [05:02<37:11,  2.33it/s][2025-02-04 02:41:52][root][INFO] - Training Epoch: 2/2, step 18639/23838 completed (loss: 0.4613690972328186, acc: 0.8484848737716675)
[2025-02-04 02:41:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18641/23838 [05:03<36:11,  2.39it/s][2025-02-04 02:41:52][root][INFO] - Training Epoch: 2/2, step 18640/23838 completed (loss: 0.257030725479126, acc: 0.9113923907279968)
[2025-02-04 02:41:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18642/23838 [05:03<39:14,  2.21it/s][2025-02-04 02:41:53][root][INFO] - Training Epoch: 2/2, step 18641/23838 completed (loss: 0.06668704003095627, acc: 0.9711538553237915)
[2025-02-04 02:41:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18643/23838 [05:04<38:12,  2.27it/s][2025-02-04 02:41:53][root][INFO] - Training Epoch: 2/2, step 18642/23838 completed (loss: 0.20903462171554565, acc: 0.9494949579238892)
[2025-02-04 02:41:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18644/23838 [05:04<41:07,  2.10it/s][2025-02-04 02:41:54][root][INFO] - Training Epoch: 2/2, step 18643/23838 completed (loss: 0.13524296879768372, acc: 0.9691358208656311)
[2025-02-04 02:41:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18645/23838 [05:05<42:23,  2.04it/s][2025-02-04 02:41:54][root][INFO] - Training Epoch: 2/2, step 18644/23838 completed (loss: 0.7243752479553223, acc: 0.8030303120613098)
[2025-02-04 02:41:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18646/23838 [05:05<42:00,  2.06it/s][2025-02-04 02:41:55][root][INFO] - Training Epoch: 2/2, step 18645/23838 completed (loss: 0.3939479887485504, acc: 0.8620689511299133)
[2025-02-04 02:41:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18647/23838 [05:05<39:58,  2.16it/s][2025-02-04 02:41:55][root][INFO] - Training Epoch: 2/2, step 18646/23838 completed (loss: 0.31741395592689514, acc: 0.8904109597206116)
[2025-02-04 02:41:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18648/23838 [05:06<37:11,  2.33it/s][2025-02-04 02:41:55][root][INFO] - Training Epoch: 2/2, step 18647/23838 completed (loss: 0.09510035067796707, acc: 0.9791666865348816)
[2025-02-04 02:41:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18649/23838 [05:06<36:16,  2.38it/s][2025-02-04 02:41:56][root][INFO] - Training Epoch: 2/2, step 18648/23838 completed (loss: 0.3554205596446991, acc: 0.8641975522041321)
[2025-02-04 02:41:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18650/23838 [05:07<36:06,  2.39it/s][2025-02-04 02:41:56][root][INFO] - Training Epoch: 2/2, step 18649/23838 completed (loss: 0.15611132979393005, acc: 0.9032257795333862)
[2025-02-04 02:41:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18651/23838 [05:07<35:31,  2.43it/s][2025-02-04 02:41:57][root][INFO] - Training Epoch: 2/2, step 18650/23838 completed (loss: 0.22425724565982819, acc: 0.9411764740943909)
[2025-02-04 02:41:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18652/23838 [05:07<34:49,  2.48it/s][2025-02-04 02:41:57][root][INFO] - Training Epoch: 2/2, step 18651/23838 completed (loss: 0.25147145986557007, acc: 0.9285714030265808)
[2025-02-04 02:41:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18653/23838 [05:08<34:01,  2.54it/s][2025-02-04 02:41:57][root][INFO] - Training Epoch: 2/2, step 18652/23838 completed (loss: 0.38332152366638184, acc: 0.8857142925262451)
[2025-02-04 02:41:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18654/23838 [05:08<33:14,  2.60it/s][2025-02-04 02:41:58][root][INFO] - Training Epoch: 2/2, step 18653/23838 completed (loss: 0.08583454042673111, acc: 0.9838709831237793)
[2025-02-04 02:41:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18655/23838 [05:09<33:18,  2.59it/s][2025-02-04 02:41:58][root][INFO] - Training Epoch: 2/2, step 18654/23838 completed (loss: 0.1613919585943222, acc: 0.9615384340286255)
[2025-02-04 02:41:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18656/23838 [05:09<33:42,  2.56it/s][2025-02-04 02:41:59][root][INFO] - Training Epoch: 2/2, step 18655/23838 completed (loss: 0.12927113473415375, acc: 0.9583333134651184)
[2025-02-04 02:41:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18657/23838 [05:10<38:30,  2.24it/s][2025-02-04 02:41:59][root][INFO] - Training Epoch: 2/2, step 18656/23838 completed (loss: 0.35519564151763916, acc: 0.8723404407501221)
[2025-02-04 02:41:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18658/23838 [05:10<35:29,  2.43it/s][2025-02-04 02:41:59][root][INFO] - Training Epoch: 2/2, step 18657/23838 completed (loss: 0.26741960644721985, acc: 0.8888888955116272)
[2025-02-04 02:42:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18659/23838 [05:10<34:14,  2.52it/s][2025-02-04 02:42:00][root][INFO] - Training Epoch: 2/2, step 18658/23838 completed (loss: 0.03387202322483063, acc: 1.0)
[2025-02-04 02:42:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18660/23838 [05:11<34:10,  2.53it/s][2025-02-04 02:42:00][root][INFO] - Training Epoch: 2/2, step 18659/23838 completed (loss: 0.08169939368963242, acc: 0.9607843160629272)
[2025-02-04 02:42:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18661/23838 [05:11<33:07,  2.60it/s][2025-02-04 02:42:01][root][INFO] - Training Epoch: 2/2, step 18660/23838 completed (loss: 0.40656042098999023, acc: 0.8571428656578064)
[2025-02-04 02:42:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18662/23838 [05:11<33:23,  2.58it/s][2025-02-04 02:42:01][root][INFO] - Training Epoch: 2/2, step 18661/23838 completed (loss: 0.21786977350711823, acc: 0.9318181872367859)
[2025-02-04 02:42:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18663/23838 [05:12<34:44,  2.48it/s][2025-02-04 02:42:01][root][INFO] - Training Epoch: 2/2, step 18662/23838 completed (loss: 0.3438037633895874, acc: 0.9166666865348816)
[2025-02-04 02:42:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18664/23838 [05:12<34:16,  2.52it/s][2025-02-04 02:42:02][root][INFO] - Training Epoch: 2/2, step 18663/23838 completed (loss: 0.22483223676681519, acc: 0.9454545378684998)
[2025-02-04 02:42:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18665/23838 [05:13<34:45,  2.48it/s][2025-02-04 02:42:02][root][INFO] - Training Epoch: 2/2, step 18664/23838 completed (loss: 1.2422212362289429, acc: 0.7142857313156128)
[2025-02-04 02:42:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18666/23838 [05:13<35:04,  2.46it/s][2025-02-04 02:42:03][root][INFO] - Training Epoch: 2/2, step 18665/23838 completed (loss: 0.11512534320354462, acc: 0.9545454382896423)
[2025-02-04 02:42:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18667/23838 [05:13<33:01,  2.61it/s][2025-02-04 02:42:03][root][INFO] - Training Epoch: 2/2, step 18666/23838 completed (loss: 0.1086060106754303, acc: 1.0)
[2025-02-04 02:42:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18668/23838 [05:14<31:07,  2.77it/s][2025-02-04 02:42:03][root][INFO] - Training Epoch: 2/2, step 18667/23838 completed (loss: 0.20815442502498627, acc: 0.9333333373069763)
[2025-02-04 02:42:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18669/23838 [05:14<31:26,  2.74it/s][2025-02-04 02:42:04][root][INFO] - Training Epoch: 2/2, step 18668/23838 completed (loss: 0.1478237509727478, acc: 0.9333333373069763)
[2025-02-04 02:42:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18670/23838 [05:14<30:55,  2.79it/s][2025-02-04 02:42:04][root][INFO] - Training Epoch: 2/2, step 18669/23838 completed (loss: 0.24847987294197083, acc: 0.9193548560142517)
[2025-02-04 02:42:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18671/23838 [05:15<30:46,  2.80it/s][2025-02-04 02:42:04][root][INFO] - Training Epoch: 2/2, step 18670/23838 completed (loss: 0.04180580750107765, acc: 1.0)
[2025-02-04 02:42:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18672/23838 [05:15<30:43,  2.80it/s][2025-02-04 02:42:05][root][INFO] - Training Epoch: 2/2, step 18671/23838 completed (loss: 0.698465883731842, acc: 0.8863636255264282)
[2025-02-04 02:42:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18673/23838 [05:15<30:14,  2.85it/s][2025-02-04 02:42:05][root][INFO] - Training Epoch: 2/2, step 18672/23838 completed (loss: 0.07585030049085617, acc: 1.0)
[2025-02-04 02:42:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18674/23838 [05:16<29:39,  2.90it/s][2025-02-04 02:42:05][root][INFO] - Training Epoch: 2/2, step 18673/23838 completed (loss: 0.6372836232185364, acc: 0.8333333134651184)
[2025-02-04 02:42:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18675/23838 [05:16<29:41,  2.90it/s][2025-02-04 02:42:06][root][INFO] - Training Epoch: 2/2, step 18674/23838 completed (loss: 0.6924446225166321, acc: 0.8461538553237915)
[2025-02-04 02:42:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18676/23838 [05:16<29:08,  2.95it/s][2025-02-04 02:42:06][root][INFO] - Training Epoch: 2/2, step 18675/23838 completed (loss: 0.23482392728328705, acc: 0.8947368264198303)
[2025-02-04 02:42:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18677/23838 [05:17<29:19,  2.93it/s][2025-02-04 02:42:06][root][INFO] - Training Epoch: 2/2, step 18676/23838 completed (loss: 0.49347782135009766, acc: 0.8275862336158752)
[2025-02-04 02:42:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18678/23838 [05:17<28:57,  2.97it/s][2025-02-04 02:42:07][root][INFO] - Training Epoch: 2/2, step 18677/23838 completed (loss: 0.3894123136997223, acc: 0.95652174949646)
[2025-02-04 02:42:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18679/23838 [05:17<29:41,  2.90it/s][2025-02-04 02:42:07][root][INFO] - Training Epoch: 2/2, step 18678/23838 completed (loss: 0.6627292633056641, acc: 0.8846153616905212)
[2025-02-04 02:42:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18680/23838 [05:18<29:16,  2.94it/s][2025-02-04 02:42:07][root][INFO] - Training Epoch: 2/2, step 18679/23838 completed (loss: 0.7771509289741516, acc: 0.8235294222831726)
[2025-02-04 02:42:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18681/23838 [05:18<29:30,  2.91it/s][2025-02-04 02:42:08][root][INFO] - Training Epoch: 2/2, step 18680/23838 completed (loss: 0.1785612255334854, acc: 0.9375)
[2025-02-04 02:42:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18682/23838 [05:18<28:56,  2.97it/s][2025-02-04 02:42:08][root][INFO] - Training Epoch: 2/2, step 18681/23838 completed (loss: 0.23617464303970337, acc: 0.95652174949646)
[2025-02-04 02:42:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18683/23838 [05:19<28:18,  3.03it/s][2025-02-04 02:42:08][root][INFO] - Training Epoch: 2/2, step 18682/23838 completed (loss: 0.3328765332698822, acc: 0.8888888955116272)
[2025-02-04 02:42:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18684/23838 [05:19<27:36,  3.11it/s][2025-02-04 02:42:09][root][INFO] - Training Epoch: 2/2, step 18683/23838 completed (loss: 0.8600403666496277, acc: 0.8727272748947144)
[2025-02-04 02:42:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18685/23838 [05:19<27:45,  3.09it/s][2025-02-04 02:42:09][root][INFO] - Training Epoch: 2/2, step 18684/23838 completed (loss: 0.10057926923036575, acc: 0.9718309640884399)
[2025-02-04 02:42:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18686/23838 [05:20<28:25,  3.02it/s][2025-02-04 02:42:09][root][INFO] - Training Epoch: 2/2, step 18685/23838 completed (loss: 0.21969805657863617, acc: 0.9350649118423462)
[2025-02-04 02:42:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18687/23838 [05:20<30:07,  2.85it/s][2025-02-04 02:42:10][root][INFO] - Training Epoch: 2/2, step 18686/23838 completed (loss: 0.0310357678681612, acc: 0.9833333492279053)
[2025-02-04 02:42:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18688/23838 [05:20<30:13,  2.84it/s][2025-02-04 02:42:10][root][INFO] - Training Epoch: 2/2, step 18687/23838 completed (loss: 0.09925729781389236, acc: 0.9851852059364319)
[2025-02-04 02:42:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18689/23838 [05:21<31:14,  2.75it/s][2025-02-04 02:42:10][root][INFO] - Training Epoch: 2/2, step 18688/23838 completed (loss: 0.039970554411411285, acc: 0.994535505771637)
[2025-02-04 02:42:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18690/23838 [05:21<30:06,  2.85it/s][2025-02-04 02:42:11][root][INFO] - Training Epoch: 2/2, step 18689/23838 completed (loss: 0.3371058702468872, acc: 0.9324324131011963)
[2025-02-04 02:42:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18691/23838 [05:22<30:40,  2.80it/s][2025-02-04 02:42:11][root][INFO] - Training Epoch: 2/2, step 18690/23838 completed (loss: 0.023086421191692352, acc: 1.0)
[2025-02-04 02:42:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18692/23838 [05:22<31:01,  2.76it/s][2025-02-04 02:42:12][root][INFO] - Training Epoch: 2/2, step 18691/23838 completed (loss: 0.17757272720336914, acc: 0.9382715821266174)
[2025-02-04 02:42:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18693/23838 [05:22<30:31,  2.81it/s][2025-02-04 02:42:12][root][INFO] - Training Epoch: 2/2, step 18692/23838 completed (loss: 0.04507840424776077, acc: 0.9765625)
[2025-02-04 02:42:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18694/23838 [05:23<29:58,  2.86it/s][2025-02-04 02:42:12][root][INFO] - Training Epoch: 2/2, step 18693/23838 completed (loss: 0.06262309104204178, acc: 0.9890109896659851)
[2025-02-04 02:42:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18695/23838 [05:23<30:02,  2.85it/s][2025-02-04 02:42:13][root][INFO] - Training Epoch: 2/2, step 18694/23838 completed (loss: 0.14331375062465668, acc: 0.970370352268219)
[2025-02-04 02:42:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18696/23838 [05:23<30:32,  2.81it/s][2025-02-04 02:42:13][root][INFO] - Training Epoch: 2/2, step 18695/23838 completed (loss: 0.1112920269370079, acc: 0.9599999785423279)
[2025-02-04 02:42:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18697/23838 [05:24<31:04,  2.76it/s][2025-02-04 02:42:13][root][INFO] - Training Epoch: 2/2, step 18696/23838 completed (loss: 0.10451406240463257, acc: 0.9719626307487488)
[2025-02-04 02:42:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18698/23838 [05:24<29:44,  2.88it/s][2025-02-04 02:42:14][root][INFO] - Training Epoch: 2/2, step 18697/23838 completed (loss: 0.03325490280985832, acc: 0.9922480583190918)
[2025-02-04 02:42:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18699/23838 [05:24<29:27,  2.91it/s][2025-02-04 02:42:14][root][INFO] - Training Epoch: 2/2, step 18698/23838 completed (loss: 0.06892973929643631, acc: 0.9702970385551453)
[2025-02-04 02:42:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18700/23838 [05:25<29:42,  2.88it/s][2025-02-04 02:42:14][root][INFO] - Training Epoch: 2/2, step 18699/23838 completed (loss: 0.047636859118938446, acc: 0.9871794581413269)
[2025-02-04 02:42:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18701/23838 [05:25<29:03,  2.95it/s][2025-02-04 02:42:15][root][INFO] - Training Epoch: 2/2, step 18700/23838 completed (loss: 0.19920353591442108, acc: 0.9512194991111755)
[2025-02-04 02:42:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18702/23838 [05:25<27:48,  3.08it/s][2025-02-04 02:42:15][root][INFO] - Training Epoch: 2/2, step 18701/23838 completed (loss: 0.02945145033299923, acc: 0.9879518151283264)
[2025-02-04 02:42:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18703/23838 [05:26<29:20,  2.92it/s][2025-02-04 02:42:15][root][INFO] - Training Epoch: 2/2, step 18702/23838 completed (loss: 0.056097645312547684, acc: 0.9775280952453613)
[2025-02-04 02:42:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18704/23838 [05:26<34:50,  2.46it/s][2025-02-04 02:42:16][root][INFO] - Training Epoch: 2/2, step 18703/23838 completed (loss: 0.06691437214612961, acc: 0.9915966391563416)
[2025-02-04 02:42:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18705/23838 [05:27<33:11,  2.58it/s][2025-02-04 02:42:16][root][INFO] - Training Epoch: 2/2, step 18704/23838 completed (loss: 0.3761802911758423, acc: 0.8805969953536987)
[2025-02-04 02:42:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18706/23838 [05:27<33:33,  2.55it/s][2025-02-04 02:42:17][root][INFO] - Training Epoch: 2/2, step 18705/23838 completed (loss: 0.059527892619371414, acc: 0.9870129823684692)
[2025-02-04 02:42:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18707/23838 [05:27<33:14,  2.57it/s][2025-02-04 02:42:17][root][INFO] - Training Epoch: 2/2, step 18706/23838 completed (loss: 0.3317331373691559, acc: 0.914893627166748)
[2025-02-04 02:42:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18708/23838 [05:28<33:59,  2.52it/s][2025-02-04 02:42:17][root][INFO] - Training Epoch: 2/2, step 18707/23838 completed (loss: 0.4590572714805603, acc: 0.875)
[2025-02-04 02:42:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18709/23838 [05:28<32:35,  2.62it/s][2025-02-04 02:42:18][root][INFO] - Training Epoch: 2/2, step 18708/23838 completed (loss: 0.17554031312465668, acc: 0.9659090638160706)
[2025-02-04 02:42:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18710/23838 [05:29<34:09,  2.50it/s][2025-02-04 02:42:18][root][INFO] - Training Epoch: 2/2, step 18709/23838 completed (loss: 0.1704842448234558, acc: 0.949367105960846)
[2025-02-04 02:42:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18711/23838 [05:29<33:18,  2.56it/s][2025-02-04 02:42:19][root][INFO] - Training Epoch: 2/2, step 18710/23838 completed (loss: 0.623322069644928, acc: 0.8095238208770752)
[2025-02-04 02:42:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  78%|[34m███████▊  [0m| 18712/23838 [05:29<33:01,  2.59it/s][2025-02-04 02:42:19][root][INFO] - Training Epoch: 2/2, step 18711/23838 completed (loss: 0.13533641397953033, acc: 0.9591836929321289)
[2025-02-04 02:42:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18713/23838 [05:30<32:37,  2.62it/s][2025-02-04 02:42:19][root][INFO] - Training Epoch: 2/2, step 18712/23838 completed (loss: 0.060891564935445786, acc: 0.9765625)
[2025-02-04 02:42:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18714/23838 [05:30<31:10,  2.74it/s][2025-02-04 02:42:20][root][INFO] - Training Epoch: 2/2, step 18713/23838 completed (loss: 0.22892051935195923, acc: 0.9375)
[2025-02-04 02:42:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18715/23838 [05:30<30:15,  2.82it/s][2025-02-04 02:42:20][root][INFO] - Training Epoch: 2/2, step 18714/23838 completed (loss: 0.07927479594945908, acc: 0.9876543283462524)
[2025-02-04 02:42:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18716/23838 [05:31<28:52,  2.96it/s][2025-02-04 02:42:20][root][INFO] - Training Epoch: 2/2, step 18715/23838 completed (loss: 0.29278063774108887, acc: 0.9444444179534912)
[2025-02-04 02:42:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18717/23838 [05:31<28:30,  2.99it/s][2025-02-04 02:42:21][root][INFO] - Training Epoch: 2/2, step 18716/23838 completed (loss: 0.03022867441177368, acc: 0.9915966391563416)
[2025-02-04 02:42:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18718/23838 [05:32<33:36,  2.54it/s][2025-02-04 02:42:21][root][INFO] - Training Epoch: 2/2, step 18717/23838 completed (loss: 0.3252613842487335, acc: 0.930232584476471)
[2025-02-04 02:42:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18719/23838 [05:32<34:19,  2.49it/s][2025-02-04 02:42:22][root][INFO] - Training Epoch: 2/2, step 18718/23838 completed (loss: 0.09994890540838242, acc: 0.9716312289237976)
[2025-02-04 02:42:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18720/23838 [05:32<31:56,  2.67it/s][2025-02-04 02:42:22][root][INFO] - Training Epoch: 2/2, step 18719/23838 completed (loss: 0.20981578528881073, acc: 0.9659090638160706)
[2025-02-04 02:42:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18721/23838 [05:33<30:34,  2.79it/s][2025-02-04 02:42:22][root][INFO] - Training Epoch: 2/2, step 18720/23838 completed (loss: 0.09189198911190033, acc: 0.9603960514068604)
[2025-02-04 02:42:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18722/23838 [05:33<33:02,  2.58it/s][2025-02-04 02:42:23][root][INFO] - Training Epoch: 2/2, step 18721/23838 completed (loss: 0.32653316855430603, acc: 0.9387755393981934)
[2025-02-04 02:42:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18723/23838 [05:33<33:27,  2.55it/s][2025-02-04 02:42:23][root][INFO] - Training Epoch: 2/2, step 18722/23838 completed (loss: 0.5180791020393372, acc: 0.837837815284729)
[2025-02-04 02:42:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18724/23838 [05:34<33:10,  2.57it/s][2025-02-04 02:42:23][root][INFO] - Training Epoch: 2/2, step 18723/23838 completed (loss: 0.5531030893325806, acc: 0.9090909361839294)
[2025-02-04 02:42:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18725/23838 [05:34<33:47,  2.52it/s][2025-02-04 02:42:24][root][INFO] - Training Epoch: 2/2, step 18724/23838 completed (loss: 0.06519465893507004, acc: 0.970588207244873)
[2025-02-04 02:42:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18726/23838 [05:35<31:54,  2.67it/s][2025-02-04 02:42:24][root][INFO] - Training Epoch: 2/2, step 18725/23838 completed (loss: 0.018932005390524864, acc: 1.0)
[2025-02-04 02:42:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18727/23838 [05:35<30:27,  2.80it/s][2025-02-04 02:42:24][root][INFO] - Training Epoch: 2/2, step 18726/23838 completed (loss: 0.2165692299604416, acc: 0.939393937587738)
[2025-02-04 02:42:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18728/23838 [05:35<30:48,  2.76it/s][2025-02-04 02:42:25][root][INFO] - Training Epoch: 2/2, step 18727/23838 completed (loss: 0.41223081946372986, acc: 0.9629629850387573)
[2025-02-04 02:42:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18729/23838 [05:36<30:55,  2.75it/s][2025-02-04 02:42:25][root][INFO] - Training Epoch: 2/2, step 18728/23838 completed (loss: 0.29051849246025085, acc: 0.9629629850387573)
[2025-02-04 02:42:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18730/23838 [05:36<30:17,  2.81it/s][2025-02-04 02:42:26][root][INFO] - Training Epoch: 2/2, step 18729/23838 completed (loss: 0.012697077356278896, acc: 1.0)
[2025-02-04 02:42:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18731/23838 [05:36<30:27,  2.79it/s][2025-02-04 02:42:26][root][INFO] - Training Epoch: 2/2, step 18730/23838 completed (loss: 0.020782938227057457, acc: 1.0)
[2025-02-04 02:42:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18732/23838 [05:37<29:34,  2.88it/s][2025-02-04 02:42:26][root][INFO] - Training Epoch: 2/2, step 18731/23838 completed (loss: 0.1168459802865982, acc: 0.9696969985961914)
[2025-02-04 02:42:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18733/23838 [05:37<30:30,  2.79it/s][2025-02-04 02:42:27][root][INFO] - Training Epoch: 2/2, step 18732/23838 completed (loss: 0.024041349068284035, acc: 1.0)
[2025-02-04 02:42:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18734/23838 [05:37<31:42,  2.68it/s][2025-02-04 02:42:27][root][INFO] - Training Epoch: 2/2, step 18733/23838 completed (loss: 0.21429972350597382, acc: 0.9473684430122375)
[2025-02-04 02:42:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18735/23838 [05:38<30:32,  2.78it/s][2025-02-04 02:42:27][root][INFO] - Training Epoch: 2/2, step 18734/23838 completed (loss: 0.04512939602136612, acc: 0.9800000190734863)
[2025-02-04 02:42:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18736/23838 [05:38<31:14,  2.72it/s][2025-02-04 02:42:28][root][INFO] - Training Epoch: 2/2, step 18735/23838 completed (loss: 0.541128933429718, acc: 0.875)
[2025-02-04 02:42:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18737/23838 [05:39<30:33,  2.78it/s][2025-02-04 02:42:28][root][INFO] - Training Epoch: 2/2, step 18736/23838 completed (loss: 0.8647910356521606, acc: 0.800000011920929)
[2025-02-04 02:42:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18738/23838 [05:39<29:48,  2.85it/s][2025-02-04 02:42:28][root][INFO] - Training Epoch: 2/2, step 18737/23838 completed (loss: 0.1519201099872589, acc: 0.9333333373069763)
[2025-02-04 02:42:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18739/23838 [05:39<29:38,  2.87it/s][2025-02-04 02:42:29][root][INFO] - Training Epoch: 2/2, step 18738/23838 completed (loss: 0.4636557996273041, acc: 0.8888888955116272)
[2025-02-04 02:42:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18740/23838 [05:40<30:21,  2.80it/s][2025-02-04 02:42:29][root][INFO] - Training Epoch: 2/2, step 18739/23838 completed (loss: 0.26930031180381775, acc: 0.8571428656578064)
[2025-02-04 02:42:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18741/23838 [05:40<29:20,  2.89it/s][2025-02-04 02:42:29][root][INFO] - Training Epoch: 2/2, step 18740/23838 completed (loss: 0.12540504336357117, acc: 0.9444444179534912)
[2025-02-04 02:42:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18742/23838 [05:40<29:25,  2.89it/s][2025-02-04 02:42:30][root][INFO] - Training Epoch: 2/2, step 18741/23838 completed (loss: 0.2865005135536194, acc: 0.9130434989929199)
[2025-02-04 02:42:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18743/23838 [05:41<29:58,  2.83it/s][2025-02-04 02:42:30][root][INFO] - Training Epoch: 2/2, step 18742/23838 completed (loss: 0.11577214300632477, acc: 0.95652174949646)
[2025-02-04 02:42:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18744/23838 [05:41<30:11,  2.81it/s][2025-02-04 02:42:31][root][INFO] - Training Epoch: 2/2, step 18743/23838 completed (loss: 0.08601441979408264, acc: 1.0)
[2025-02-04 02:42:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18745/23838 [05:41<29:29,  2.88it/s][2025-02-04 02:42:31][root][INFO] - Training Epoch: 2/2, step 18744/23838 completed (loss: 0.12480178475379944, acc: 0.9677419066429138)
[2025-02-04 02:42:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18746/23838 [05:42<27:52,  3.04it/s][2025-02-04 02:42:31][root][INFO] - Training Epoch: 2/2, step 18745/23838 completed (loss: 0.025716030970215797, acc: 1.0)
[2025-02-04 02:42:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18747/23838 [05:42<28:58,  2.93it/s][2025-02-04 02:42:32][root][INFO] - Training Epoch: 2/2, step 18746/23838 completed (loss: 0.018983926624059677, acc: 1.0)
[2025-02-04 02:42:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18748/23838 [05:42<28:36,  2.97it/s][2025-02-04 02:42:32][root][INFO] - Training Epoch: 2/2, step 18747/23838 completed (loss: 0.025922119617462158, acc: 1.0)
[2025-02-04 02:42:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18749/23838 [05:43<28:56,  2.93it/s][2025-02-04 02:42:32][root][INFO] - Training Epoch: 2/2, step 18748/23838 completed (loss: 0.24834531545639038, acc: 0.9259259104728699)
[2025-02-04 02:42:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18750/23838 [05:43<29:10,  2.91it/s][2025-02-04 02:42:33][root][INFO] - Training Epoch: 2/2, step 18749/23838 completed (loss: 0.12810824811458588, acc: 0.9411764740943909)
[2025-02-04 02:42:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18751/23838 [05:43<29:15,  2.90it/s][2025-02-04 02:42:33][root][INFO] - Training Epoch: 2/2, step 18750/23838 completed (loss: 0.009651120752096176, acc: 1.0)
[2025-02-04 02:42:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18752/23838 [05:44<29:28,  2.88it/s][2025-02-04 02:42:33][root][INFO] - Training Epoch: 2/2, step 18751/23838 completed (loss: 0.19111117720603943, acc: 0.9444444179534912)
[2025-02-04 02:42:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18753/23838 [05:44<29:27,  2.88it/s][2025-02-04 02:42:34][root][INFO] - Training Epoch: 2/2, step 18752/23838 completed (loss: 0.29661646485328674, acc: 0.9200000166893005)
[2025-02-04 02:42:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18754/23838 [05:44<29:24,  2.88it/s][2025-02-04 02:42:34][root][INFO] - Training Epoch: 2/2, step 18753/23838 completed (loss: 0.015705853700637817, acc: 1.0)
[2025-02-04 02:42:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18755/23838 [05:45<31:15,  2.71it/s][2025-02-04 02:42:34][root][INFO] - Training Epoch: 2/2, step 18754/23838 completed (loss: 0.03499548137187958, acc: 1.0)
[2025-02-04 02:42:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18756/23838 [05:45<29:25,  2.88it/s][2025-02-04 02:42:35][root][INFO] - Training Epoch: 2/2, step 18755/23838 completed (loss: 0.054627757519483566, acc: 0.9714285731315613)
[2025-02-04 02:42:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18757/23838 [05:45<28:19,  2.99it/s][2025-02-04 02:42:35][root][INFO] - Training Epoch: 2/2, step 18756/23838 completed (loss: 0.4310060143470764, acc: 0.75)
[2025-02-04 02:42:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18758/23838 [05:46<27:39,  3.06it/s][2025-02-04 02:42:35][root][INFO] - Training Epoch: 2/2, step 18757/23838 completed (loss: 0.2524244487285614, acc: 0.939393937587738)
[2025-02-04 02:42:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18759/23838 [05:46<27:00,  3.13it/s][2025-02-04 02:42:36][root][INFO] - Training Epoch: 2/2, step 18758/23838 completed (loss: 0.16877101361751556, acc: 0.95652174949646)
[2025-02-04 02:42:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18760/23838 [05:46<26:33,  3.19it/s][2025-02-04 02:42:36][root][INFO] - Training Epoch: 2/2, step 18759/23838 completed (loss: 0.42893415689468384, acc: 0.8999999761581421)
[2025-02-04 02:42:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18761/23838 [05:47<26:47,  3.16it/s][2025-02-04 02:42:36][root][INFO] - Training Epoch: 2/2, step 18760/23838 completed (loss: 0.30043235421180725, acc: 0.9166666865348816)
[2025-02-04 02:42:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18762/23838 [05:47<28:23,  2.98it/s][2025-02-04 02:42:37][root][INFO] - Training Epoch: 2/2, step 18761/23838 completed (loss: 0.7728564143180847, acc: 0.7543859481811523)
[2025-02-04 02:42:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18763/23838 [05:47<28:43,  2.95it/s][2025-02-04 02:42:37][root][INFO] - Training Epoch: 2/2, step 18762/23838 completed (loss: 0.3521918058395386, acc: 0.8787878751754761)
[2025-02-04 02:42:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18764/23838 [05:48<28:22,  2.98it/s][2025-02-04 02:42:37][root][INFO] - Training Epoch: 2/2, step 18763/23838 completed (loss: 0.34467747807502747, acc: 0.9090909361839294)
[2025-02-04 02:42:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18765/23838 [05:48<29:21,  2.88it/s][2025-02-04 02:42:38][root][INFO] - Training Epoch: 2/2, step 18764/23838 completed (loss: 0.05973443761467934, acc: 1.0)
[2025-02-04 02:42:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18766/23838 [05:48<30:27,  2.77it/s][2025-02-04 02:42:38][root][INFO] - Training Epoch: 2/2, step 18765/23838 completed (loss: 0.10379882901906967, acc: 0.9696969985961914)
[2025-02-04 02:42:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18767/23838 [05:49<31:20,  2.70it/s][2025-02-04 02:42:38][root][INFO] - Training Epoch: 2/2, step 18766/23838 completed (loss: 0.1873675435781479, acc: 0.9411764740943909)
[2025-02-04 02:42:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18768/23838 [05:49<30:37,  2.76it/s][2025-02-04 02:42:39][root][INFO] - Training Epoch: 2/2, step 18767/23838 completed (loss: 0.7893232703208923, acc: 0.8028169274330139)
[2025-02-04 02:42:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18769/23838 [05:50<30:42,  2.75it/s][2025-02-04 02:42:39][root][INFO] - Training Epoch: 2/2, step 18768/23838 completed (loss: 0.03938020020723343, acc: 1.0)
[2025-02-04 02:42:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18770/23838 [05:50<30:24,  2.78it/s][2025-02-04 02:42:39][root][INFO] - Training Epoch: 2/2, step 18769/23838 completed (loss: 0.326303094625473, acc: 0.875)
[2025-02-04 02:42:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18771/23838 [05:50<29:59,  2.82it/s][2025-02-04 02:42:40][root][INFO] - Training Epoch: 2/2, step 18770/23838 completed (loss: 0.12829120457172394, acc: 0.9599999785423279)
[2025-02-04 02:42:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▊  [0m| 18772/23838 [05:51<31:28,  2.68it/s][2025-02-04 02:42:40][root][INFO] - Training Epoch: 2/2, step 18771/23838 completed (loss: 0.23434166610240936, acc: 0.9333333373069763)
[2025-02-04 02:42:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18773/23838 [05:51<31:12,  2.70it/s][2025-02-04 02:42:41][root][INFO] - Training Epoch: 2/2, step 18772/23838 completed (loss: 0.012878344394266605, acc: 1.0)
[2025-02-04 02:42:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18774/23838 [05:51<31:41,  2.66it/s][2025-02-04 02:42:41][root][INFO] - Training Epoch: 2/2, step 18773/23838 completed (loss: 0.1772131472826004, acc: 0.9130434989929199)
[2025-02-04 02:42:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18775/23838 [05:52<30:43,  2.75it/s][2025-02-04 02:42:41][root][INFO] - Training Epoch: 2/2, step 18774/23838 completed (loss: 0.955608606338501, acc: 0.8235294222831726)
[2025-02-04 02:42:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18776/23838 [05:52<30:51,  2.73it/s][2025-02-04 02:42:42][root][INFO] - Training Epoch: 2/2, step 18775/23838 completed (loss: 0.3254142701625824, acc: 0.8965517282485962)
[2025-02-04 02:42:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18777/23838 [05:52<29:18,  2.88it/s][2025-02-04 02:42:42][root][INFO] - Training Epoch: 2/2, step 18776/23838 completed (loss: 0.26708927750587463, acc: 0.8965517282485962)
[2025-02-04 02:42:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18778/23838 [05:53<29:32,  2.85it/s][2025-02-04 02:42:42][root][INFO] - Training Epoch: 2/2, step 18777/23838 completed (loss: 0.4526970684528351, acc: 0.9090909361839294)
[2025-02-04 02:42:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18779/23838 [05:53<30:07,  2.80it/s][2025-02-04 02:42:43][root][INFO] - Training Epoch: 2/2, step 18778/23838 completed (loss: 0.39459699392318726, acc: 0.8684210777282715)
[2025-02-04 02:42:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18780/23838 [05:53<30:02,  2.81it/s][2025-02-04 02:42:43][root][INFO] - Training Epoch: 2/2, step 18779/23838 completed (loss: 0.13206300139427185, acc: 0.9189189076423645)
[2025-02-04 02:42:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18781/23838 [05:54<30:11,  2.79it/s][2025-02-04 02:42:43][root][INFO] - Training Epoch: 2/2, step 18780/23838 completed (loss: 0.04696715250611305, acc: 1.0)
[2025-02-04 02:42:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18782/23838 [05:54<30:13,  2.79it/s][2025-02-04 02:42:44][root][INFO] - Training Epoch: 2/2, step 18781/23838 completed (loss: 0.27253034710884094, acc: 0.9444444179534912)
[2025-02-04 02:42:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18783/23838 [05:55<30:52,  2.73it/s][2025-02-04 02:42:44][root][INFO] - Training Epoch: 2/2, step 18782/23838 completed (loss: 0.19957858324050903, acc: 0.957446813583374)
[2025-02-04 02:42:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18784/23838 [05:55<31:45,  2.65it/s][2025-02-04 02:42:45][root][INFO] - Training Epoch: 2/2, step 18783/23838 completed (loss: 0.05161670222878456, acc: 1.0)
[2025-02-04 02:42:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18785/23838 [05:55<30:54,  2.73it/s][2025-02-04 02:42:45][root][INFO] - Training Epoch: 2/2, step 18784/23838 completed (loss: 0.08558894693851471, acc: 0.9615384340286255)
[2025-02-04 02:42:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18786/23838 [05:56<30:44,  2.74it/s][2025-02-04 02:42:45][root][INFO] - Training Epoch: 2/2, step 18785/23838 completed (loss: 0.06432361900806427, acc: 1.0)
[2025-02-04 02:42:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18787/23838 [05:56<31:42,  2.65it/s][2025-02-04 02:42:46][root][INFO] - Training Epoch: 2/2, step 18786/23838 completed (loss: 0.33932721614837646, acc: 0.9259259104728699)
[2025-02-04 02:42:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18788/23838 [05:56<31:14,  2.69it/s][2025-02-04 02:42:46][root][INFO] - Training Epoch: 2/2, step 18787/23838 completed (loss: 0.6016944646835327, acc: 0.8518518805503845)
[2025-02-04 02:42:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18789/23838 [05:57<31:56,  2.63it/s][2025-02-04 02:42:46][root][INFO] - Training Epoch: 2/2, step 18788/23838 completed (loss: 0.5193285942077637, acc: 0.9047619104385376)
[2025-02-04 02:42:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18790/23838 [05:57<30:25,  2.77it/s][2025-02-04 02:42:47][root][INFO] - Training Epoch: 2/2, step 18789/23838 completed (loss: 0.12843595445156097, acc: 0.9615384340286255)
[2025-02-04 02:42:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18791/23838 [05:58<31:17,  2.69it/s][2025-02-04 02:42:47][root][INFO] - Training Epoch: 2/2, step 18790/23838 completed (loss: 0.23607298731803894, acc: 0.8888888955116272)
[2025-02-04 02:42:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18792/23838 [05:58<32:03,  2.62it/s][2025-02-04 02:42:48][root][INFO] - Training Epoch: 2/2, step 18791/23838 completed (loss: 0.16813012957572937, acc: 0.949999988079071)
[2025-02-04 02:42:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18793/23838 [05:58<33:27,  2.51it/s][2025-02-04 02:42:48][root][INFO] - Training Epoch: 2/2, step 18792/23838 completed (loss: 0.1917739063501358, acc: 0.9736841917037964)
[2025-02-04 02:42:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18794/23838 [05:59<32:26,  2.59it/s][2025-02-04 02:42:48][root][INFO] - Training Epoch: 2/2, step 18793/23838 completed (loss: 0.7005151510238647, acc: 0.800000011920929)
[2025-02-04 02:42:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18795/23838 [05:59<31:53,  2.64it/s][2025-02-04 02:42:49][root][INFO] - Training Epoch: 2/2, step 18794/23838 completed (loss: 0.13633938133716583, acc: 0.9523809552192688)
[2025-02-04 02:42:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18796/23838 [06:00<31:22,  2.68it/s][2025-02-04 02:42:49][root][INFO] - Training Epoch: 2/2, step 18795/23838 completed (loss: 0.039392780512571335, acc: 1.0)
[2025-02-04 02:42:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18797/23838 [06:00<30:59,  2.71it/s][2025-02-04 02:42:49][root][INFO] - Training Epoch: 2/2, step 18796/23838 completed (loss: 0.35698699951171875, acc: 0.9411764740943909)
[2025-02-04 02:42:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18798/23838 [06:00<29:57,  2.80it/s][2025-02-04 02:42:50][root][INFO] - Training Epoch: 2/2, step 18797/23838 completed (loss: 0.7943477630615234, acc: 0.7727272510528564)
[2025-02-04 02:42:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18799/23838 [06:01<29:25,  2.85it/s][2025-02-04 02:42:50][root][INFO] - Training Epoch: 2/2, step 18798/23838 completed (loss: 0.03317445516586304, acc: 1.0)
[2025-02-04 02:42:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18800/23838 [06:01<28:59,  2.90it/s][2025-02-04 02:42:50][root][INFO] - Training Epoch: 2/2, step 18799/23838 completed (loss: 0.04179218411445618, acc: 1.0)
[2025-02-04 02:42:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18801/23838 [06:01<28:22,  2.96it/s][2025-02-04 02:42:51][root][INFO] - Training Epoch: 2/2, step 18800/23838 completed (loss: 0.03146221488714218, acc: 1.0)
[2025-02-04 02:42:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18802/23838 [06:02<28:03,  2.99it/s][2025-02-04 02:42:51][root][INFO] - Training Epoch: 2/2, step 18801/23838 completed (loss: 0.08194155246019363, acc: 0.9666666388511658)
[2025-02-04 02:42:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18803/23838 [06:02<27:49,  3.02it/s][2025-02-04 02:42:51][root][INFO] - Training Epoch: 2/2, step 18802/23838 completed (loss: 0.30663421750068665, acc: 0.8947368264198303)
[2025-02-04 02:42:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18804/23838 [06:02<27:13,  3.08it/s][2025-02-04 02:42:52][root][INFO] - Training Epoch: 2/2, step 18803/23838 completed (loss: 0.34370166063308716, acc: 0.90625)
[2025-02-04 02:42:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18805/23838 [06:03<28:24,  2.95it/s][2025-02-04 02:42:52][root][INFO] - Training Epoch: 2/2, step 18804/23838 completed (loss: 0.2601698935031891, acc: 0.9259259104728699)
[2025-02-04 02:42:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18806/23838 [06:03<29:24,  2.85it/s][2025-02-04 02:42:52][root][INFO] - Training Epoch: 2/2, step 18805/23838 completed (loss: 0.2839282155036926, acc: 0.9629629850387573)
[2025-02-04 02:42:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18807/23838 [06:03<30:22,  2.76it/s][2025-02-04 02:42:53][root][INFO] - Training Epoch: 2/2, step 18806/23838 completed (loss: 0.27720165252685547, acc: 0.8799999952316284)
[2025-02-04 02:42:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18808/23838 [06:04<30:38,  2.74it/s][2025-02-04 02:42:53][root][INFO] - Training Epoch: 2/2, step 18807/23838 completed (loss: 0.21394889056682587, acc: 0.931034505367279)
[2025-02-04 02:42:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18809/23838 [06:04<29:22,  2.85it/s][2025-02-04 02:42:54][root][INFO] - Training Epoch: 2/2, step 18808/23838 completed (loss: 0.4188559651374817, acc: 0.8799999952316284)
[2025-02-04 02:42:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18810/23838 [06:04<30:52,  2.71it/s][2025-02-04 02:42:54][root][INFO] - Training Epoch: 2/2, step 18809/23838 completed (loss: 0.03205721080303192, acc: 0.9722222089767456)
[2025-02-04 02:42:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18811/23838 [06:05<29:53,  2.80it/s][2025-02-04 02:42:54][root][INFO] - Training Epoch: 2/2, step 18810/23838 completed (loss: 0.11734803766012192, acc: 0.9767441749572754)
[2025-02-04 02:42:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18812/23838 [06:05<28:47,  2.91it/s][2025-02-04 02:42:55][root][INFO] - Training Epoch: 2/2, step 18811/23838 completed (loss: 0.4451843798160553, acc: 0.9166666865348816)
[2025-02-04 02:42:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18813/23838 [06:05<28:08,  2.98it/s][2025-02-04 02:42:55][root][INFO] - Training Epoch: 2/2, step 18812/23838 completed (loss: 0.7753746509552002, acc: 0.7272727489471436)
[2025-02-04 02:42:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18814/23838 [06:06<27:20,  3.06it/s][2025-02-04 02:42:55][root][INFO] - Training Epoch: 2/2, step 18813/23838 completed (loss: 0.22425174713134766, acc: 0.9545454382896423)
[2025-02-04 02:42:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18815/23838 [06:06<27:44,  3.02it/s][2025-02-04 02:42:56][root][INFO] - Training Epoch: 2/2, step 18814/23838 completed (loss: 0.27561014890670776, acc: 0.8695651888847351)
[2025-02-04 02:42:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18816/23838 [06:06<27:33,  3.04it/s][2025-02-04 02:42:56][root][INFO] - Training Epoch: 2/2, step 18815/23838 completed (loss: 0.36139023303985596, acc: 0.859375)
[2025-02-04 02:42:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18817/23838 [06:07<27:07,  3.09it/s][2025-02-04 02:42:56][root][INFO] - Training Epoch: 2/2, step 18816/23838 completed (loss: 0.6536308526992798, acc: 0.8316831588745117)
[2025-02-04 02:42:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18818/23838 [06:07<26:23,  3.17it/s][2025-02-04 02:42:57][root][INFO] - Training Epoch: 2/2, step 18817/23838 completed (loss: 0.7827827334403992, acc: 0.7878788113594055)
[2025-02-04 02:42:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18819/23838 [06:07<26:43,  3.13it/s][2025-02-04 02:42:57][root][INFO] - Training Epoch: 2/2, step 18818/23838 completed (loss: 0.6979009509086609, acc: 0.8225806355476379)
[2025-02-04 02:42:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18820/23838 [06:08<27:08,  3.08it/s][2025-02-04 02:42:57][root][INFO] - Training Epoch: 2/2, step 18819/23838 completed (loss: 0.41812461614608765, acc: 0.8999999761581421)
[2025-02-04 02:42:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18821/23838 [06:08<27:48,  3.01it/s][2025-02-04 02:42:58][root][INFO] - Training Epoch: 2/2, step 18820/23838 completed (loss: 0.37925824522972107, acc: 0.9021739363670349)
[2025-02-04 02:42:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18822/23838 [06:08<27:34,  3.03it/s][2025-02-04 02:42:58][root][INFO] - Training Epoch: 2/2, step 18821/23838 completed (loss: 0.8059132695198059, acc: 0.78125)
[2025-02-04 02:42:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18823/23838 [06:09<27:48,  3.01it/s][2025-02-04 02:42:58][root][INFO] - Training Epoch: 2/2, step 18822/23838 completed (loss: 0.3539362847805023, acc: 0.8857142925262451)
[2025-02-04 02:42:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18824/23838 [06:09<28:48,  2.90it/s][2025-02-04 02:42:59][root][INFO] - Training Epoch: 2/2, step 18823/23838 completed (loss: 0.6394519209861755, acc: 0.7666666507720947)
[2025-02-04 02:42:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18825/23838 [06:09<30:51,  2.71it/s][2025-02-04 02:42:59][root][INFO] - Training Epoch: 2/2, step 18824/23838 completed (loss: 0.2114875316619873, acc: 0.9599999785423279)
[2025-02-04 02:42:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18826/23838 [06:10<30:48,  2.71it/s][2025-02-04 02:42:59][root][INFO] - Training Epoch: 2/2, step 18825/23838 completed (loss: 0.43063968420028687, acc: 0.8695651888847351)
[2025-02-04 02:43:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18827/23838 [06:10<31:08,  2.68it/s][2025-02-04 02:43:00][root][INFO] - Training Epoch: 2/2, step 18826/23838 completed (loss: 0.4084542989730835, acc: 0.875)
[2025-02-04 02:43:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18828/23838 [06:11<31:12,  2.68it/s][2025-02-04 02:43:00][root][INFO] - Training Epoch: 2/2, step 18827/23838 completed (loss: 0.4657467007637024, acc: 0.8617021441459656)
[2025-02-04 02:43:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18829/23838 [06:11<31:03,  2.69it/s][2025-02-04 02:43:00][root][INFO] - Training Epoch: 2/2, step 18828/23838 completed (loss: 0.8336359858512878, acc: 0.7777777910232544)
[2025-02-04 02:43:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18830/23838 [06:11<31:18,  2.67it/s][2025-02-04 02:43:01][root][INFO] - Training Epoch: 2/2, step 18829/23838 completed (loss: 0.19660045206546783, acc: 0.9426229596138)
[2025-02-04 02:43:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18831/23838 [06:12<32:31,  2.57it/s][2025-02-04 02:43:01][root][INFO] - Training Epoch: 2/2, step 18830/23838 completed (loss: 0.39846593141555786, acc: 0.9242424368858337)
[2025-02-04 02:43:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18832/23838 [06:12<33:03,  2.52it/s][2025-02-04 02:43:02][root][INFO] - Training Epoch: 2/2, step 18831/23838 completed (loss: 0.5279414057731628, acc: 0.8646616339683533)
[2025-02-04 02:43:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18833/23838 [06:12<32:08,  2.59it/s][2025-02-04 02:43:02][root][INFO] - Training Epoch: 2/2, step 18832/23838 completed (loss: 0.234705850481987, acc: 0.9425287246704102)
[2025-02-04 02:43:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18834/23838 [06:13<30:39,  2.72it/s][2025-02-04 02:43:02][root][INFO] - Training Epoch: 2/2, step 18833/23838 completed (loss: 0.39253002405166626, acc: 0.8484848737716675)
[2025-02-04 02:43:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18835/23838 [06:13<28:39,  2.91it/s][2025-02-04 02:43:03][root][INFO] - Training Epoch: 2/2, step 18834/23838 completed (loss: 0.2090838998556137, acc: 0.9508196711540222)
[2025-02-04 02:43:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18836/23838 [06:13<28:36,  2.91it/s][2025-02-04 02:43:03][root][INFO] - Training Epoch: 2/2, step 18835/23838 completed (loss: 0.4307277798652649, acc: 0.8846153616905212)
[2025-02-04 02:43:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18837/23838 [06:14<28:47,  2.90it/s][2025-02-04 02:43:03][root][INFO] - Training Epoch: 2/2, step 18836/23838 completed (loss: 0.4727238416671753, acc: 0.8604651093482971)
[2025-02-04 02:43:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18838/23838 [06:14<29:29,  2.83it/s][2025-02-04 02:43:04][root][INFO] - Training Epoch: 2/2, step 18837/23838 completed (loss: 0.315893292427063, acc: 0.9189189076423645)
[2025-02-04 02:43:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18839/23838 [06:15<29:55,  2.78it/s][2025-02-04 02:43:04][root][INFO] - Training Epoch: 2/2, step 18838/23838 completed (loss: 0.9311568737030029, acc: 0.7101449370384216)
[2025-02-04 02:43:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18840/23838 [06:15<30:56,  2.69it/s][2025-02-04 02:43:05][root][INFO] - Training Epoch: 2/2, step 18839/23838 completed (loss: 0.3164568245410919, acc: 0.9230769276618958)
[2025-02-04 02:43:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18841/23838 [06:15<30:55,  2.69it/s][2025-02-04 02:43:05][root][INFO] - Training Epoch: 2/2, step 18840/23838 completed (loss: 0.798521101474762, acc: 0.7638888955116272)
[2025-02-04 02:43:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18842/23838 [06:16<32:10,  2.59it/s][2025-02-04 02:43:05][root][INFO] - Training Epoch: 2/2, step 18841/23838 completed (loss: 0.35684171319007874, acc: 0.9032257795333862)
[2025-02-04 02:43:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18843/23838 [06:16<31:27,  2.65it/s][2025-02-04 02:43:06][root][INFO] - Training Epoch: 2/2, step 18842/23838 completed (loss: 0.4990294277667999, acc: 0.8799999952316284)
[2025-02-04 02:43:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18844/23838 [06:16<29:48,  2.79it/s][2025-02-04 02:43:06][root][INFO] - Training Epoch: 2/2, step 18843/23838 completed (loss: 0.3550250232219696, acc: 0.875)
[2025-02-04 02:43:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18845/23838 [06:17<28:57,  2.87it/s][2025-02-04 02:43:06][root][INFO] - Training Epoch: 2/2, step 18844/23838 completed (loss: 0.6675096154212952, acc: 0.7840909361839294)
[2025-02-04 02:43:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18846/23838 [06:17<27:46,  3.00it/s][2025-02-04 02:43:07][root][INFO] - Training Epoch: 2/2, step 18845/23838 completed (loss: 0.5296298265457153, acc: 0.8343949317932129)
[2025-02-04 02:43:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18847/23838 [06:17<27:27,  3.03it/s][2025-02-04 02:43:07][root][INFO] - Training Epoch: 2/2, step 18846/23838 completed (loss: 0.44411444664001465, acc: 0.8428571224212646)
[2025-02-04 02:43:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18848/23838 [06:18<28:16,  2.94it/s][2025-02-04 02:43:07][root][INFO] - Training Epoch: 2/2, step 18847/23838 completed (loss: 0.28765830397605896, acc: 0.8905109763145447)
[2025-02-04 02:43:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18849/23838 [06:18<28:13,  2.95it/s][2025-02-04 02:43:08][root][INFO] - Training Epoch: 2/2, step 18848/23838 completed (loss: 0.4153498411178589, acc: 0.9012345671653748)
[2025-02-04 02:43:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18850/23838 [06:18<27:52,  2.98it/s][2025-02-04 02:43:08][root][INFO] - Training Epoch: 2/2, step 18849/23838 completed (loss: 0.2126118689775467, acc: 0.9462365508079529)
[2025-02-04 02:43:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18851/23838 [06:19<27:35,  3.01it/s][2025-02-04 02:43:08][root][INFO] - Training Epoch: 2/2, step 18850/23838 completed (loss: 0.30013659596443176, acc: 0.9245283007621765)
[2025-02-04 02:43:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18852/23838 [06:19<28:16,  2.94it/s][2025-02-04 02:43:09][root][INFO] - Training Epoch: 2/2, step 18851/23838 completed (loss: 1.0206809043884277, acc: 0.7037037014961243)
[2025-02-04 02:43:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18853/23838 [06:19<28:43,  2.89it/s][2025-02-04 02:43:09][root][INFO] - Training Epoch: 2/2, step 18852/23838 completed (loss: 0.5822119116783142, acc: 0.8055555820465088)
[2025-02-04 02:43:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18854/23838 [06:20<29:19,  2.83it/s][2025-02-04 02:43:09][root][INFO] - Training Epoch: 2/2, step 18853/23838 completed (loss: 0.8999227285385132, acc: 0.7368420958518982)
[2025-02-04 02:43:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18855/23838 [06:20<30:28,  2.72it/s][2025-02-04 02:43:10][root][INFO] - Training Epoch: 2/2, step 18854/23838 completed (loss: 0.5316905379295349, acc: 0.8640776872634888)
[2025-02-04 02:43:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18856/23838 [06:20<28:28,  2.92it/s][2025-02-04 02:43:10][root][INFO] - Training Epoch: 2/2, step 18855/23838 completed (loss: 0.7950364947319031, acc: 0.75)
[2025-02-04 02:43:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18857/23838 [06:21<28:16,  2.94it/s][2025-02-04 02:43:10][root][INFO] - Training Epoch: 2/2, step 18856/23838 completed (loss: 1.0023022890090942, acc: 0.7246376872062683)
[2025-02-04 02:43:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18858/23838 [06:21<29:16,  2.84it/s][2025-02-04 02:43:11][root][INFO] - Training Epoch: 2/2, step 18857/23838 completed (loss: 0.1438794881105423, acc: 0.9599999785423279)
[2025-02-04 02:43:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18859/23838 [06:22<28:57,  2.87it/s][2025-02-04 02:43:11][root][INFO] - Training Epoch: 2/2, step 18858/23838 completed (loss: 0.42678093910217285, acc: 0.9117646813392639)
[2025-02-04 02:43:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18860/23838 [06:22<30:09,  2.75it/s][2025-02-04 02:43:11][root][INFO] - Training Epoch: 2/2, step 18859/23838 completed (loss: 0.6845957040786743, acc: 0.8311688303947449)
[2025-02-04 02:43:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18861/23838 [06:22<30:51,  2.69it/s][2025-02-04 02:43:12][root][INFO] - Training Epoch: 2/2, step 18860/23838 completed (loss: 0.4745563566684723, acc: 0.8600000143051147)
[2025-02-04 02:43:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18862/23838 [06:23<31:12,  2.66it/s][2025-02-04 02:43:12][root][INFO] - Training Epoch: 2/2, step 18861/23838 completed (loss: 0.44029974937438965, acc: 0.8961039185523987)
[2025-02-04 02:43:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18863/23838 [06:23<30:13,  2.74it/s][2025-02-04 02:43:13][root][INFO] - Training Epoch: 2/2, step 18862/23838 completed (loss: 0.6695556640625, acc: 0.8142856955528259)
[2025-02-04 02:43:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18864/23838 [06:23<30:32,  2.71it/s][2025-02-04 02:43:13][root][INFO] - Training Epoch: 2/2, step 18863/23838 completed (loss: 0.397196501493454, acc: 0.8888888955116272)
[2025-02-04 02:43:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18865/23838 [06:24<30:28,  2.72it/s][2025-02-04 02:43:13][root][INFO] - Training Epoch: 2/2, step 18864/23838 completed (loss: 0.4153318405151367, acc: 0.859375)
[2025-02-04 02:43:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18866/23838 [06:24<31:50,  2.60it/s][2025-02-04 02:43:14][root][INFO] - Training Epoch: 2/2, step 18865/23838 completed (loss: 0.20818522572517395, acc: 0.9333333373069763)
[2025-02-04 02:43:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18867/23838 [06:25<32:08,  2.58it/s][2025-02-04 02:43:14][root][INFO] - Training Epoch: 2/2, step 18866/23838 completed (loss: 0.4741642475128174, acc: 0.8488371968269348)
[2025-02-04 02:43:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18868/23838 [06:25<32:32,  2.55it/s][2025-02-04 02:43:15][root][INFO] - Training Epoch: 2/2, step 18867/23838 completed (loss: 0.5107526779174805, acc: 0.8550724387168884)
[2025-02-04 02:43:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18869/23838 [06:25<30:41,  2.70it/s][2025-02-04 02:43:15][root][INFO] - Training Epoch: 2/2, step 18868/23838 completed (loss: 0.21663273870944977, acc: 0.954023003578186)
[2025-02-04 02:43:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18870/23838 [06:26<32:10,  2.57it/s][2025-02-04 02:43:15][root][INFO] - Training Epoch: 2/2, step 18869/23838 completed (loss: 0.4718155562877655, acc: 0.8977272510528564)
[2025-02-04 02:43:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18871/23838 [06:26<31:52,  2.60it/s][2025-02-04 02:43:16][root][INFO] - Training Epoch: 2/2, step 18870/23838 completed (loss: 0.25460413098335266, acc: 0.9056603908538818)
[2025-02-04 02:43:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18872/23838 [06:26<31:22,  2.64it/s][2025-02-04 02:43:16][root][INFO] - Training Epoch: 2/2, step 18871/23838 completed (loss: 0.411367267370224, acc: 0.8785046935081482)
[2025-02-04 02:43:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18873/23838 [06:27<30:39,  2.70it/s][2025-02-04 02:43:16][root][INFO] - Training Epoch: 2/2, step 18872/23838 completed (loss: 0.23091812431812286, acc: 0.9363636374473572)
[2025-02-04 02:43:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18874/23838 [06:27<30:18,  2.73it/s][2025-02-04 02:43:17][root][INFO] - Training Epoch: 2/2, step 18873/23838 completed (loss: 0.542310893535614, acc: 0.8534482717514038)
[2025-02-04 02:43:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18875/23838 [06:27<28:47,  2.87it/s][2025-02-04 02:43:17][root][INFO] - Training Epoch: 2/2, step 18874/23838 completed (loss: 0.3280448913574219, acc: 0.8965517282485962)
[2025-02-04 02:43:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18876/23838 [06:28<28:42,  2.88it/s][2025-02-04 02:43:17][root][INFO] - Training Epoch: 2/2, step 18875/23838 completed (loss: 0.4600282609462738, acc: 0.875)
[2025-02-04 02:43:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18877/23838 [06:28<28:42,  2.88it/s][2025-02-04 02:43:18][root][INFO] - Training Epoch: 2/2, step 18876/23838 completed (loss: 0.564003586769104, acc: 0.8735632300376892)
[2025-02-04 02:43:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18878/23838 [06:29<29:52,  2.77it/s][2025-02-04 02:43:18][root][INFO] - Training Epoch: 2/2, step 18877/23838 completed (loss: 0.24450142681598663, acc: 0.9240506291389465)
[2025-02-04 02:43:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18879/23838 [06:29<31:04,  2.66it/s][2025-02-04 02:43:19][root][INFO] - Training Epoch: 2/2, step 18878/23838 completed (loss: 0.24080030620098114, acc: 0.938144326210022)
[2025-02-04 02:43:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18880/23838 [06:29<29:44,  2.78it/s][2025-02-04 02:43:19][root][INFO] - Training Epoch: 2/2, step 18879/23838 completed (loss: 0.44829100370407104, acc: 0.8674699068069458)
[2025-02-04 02:43:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18881/23838 [06:30<29:42,  2.78it/s][2025-02-04 02:43:19][root][INFO] - Training Epoch: 2/2, step 18880/23838 completed (loss: 0.5168952941894531, acc: 0.8815789222717285)
[2025-02-04 02:43:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18882/23838 [06:30<30:16,  2.73it/s][2025-02-04 02:43:20][root][INFO] - Training Epoch: 2/2, step 18881/23838 completed (loss: 0.25936099886894226, acc: 0.934959352016449)
[2025-02-04 02:43:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18883/23838 [06:30<30:53,  2.67it/s][2025-02-04 02:43:20][root][INFO] - Training Epoch: 2/2, step 18882/23838 completed (loss: 0.25576621294021606, acc: 0.9090909361839294)
[2025-02-04 02:43:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18884/23838 [06:31<30:25,  2.71it/s][2025-02-04 02:43:20][root][INFO] - Training Epoch: 2/2, step 18883/23838 completed (loss: 0.357799768447876, acc: 0.9375)
[2025-02-04 02:43:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18885/23838 [06:31<31:33,  2.62it/s][2025-02-04 02:43:21][root][INFO] - Training Epoch: 2/2, step 18884/23838 completed (loss: 0.2677445411682129, acc: 0.914893627166748)
[2025-02-04 02:43:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18886/23838 [06:32<31:18,  2.64it/s][2025-02-04 02:43:21][root][INFO] - Training Epoch: 2/2, step 18885/23838 completed (loss: 0.4827781915664673, acc: 0.807692289352417)
[2025-02-04 02:43:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18887/23838 [06:32<31:03,  2.66it/s][2025-02-04 02:43:22][root][INFO] - Training Epoch: 2/2, step 18886/23838 completed (loss: 0.37934887409210205, acc: 0.9213483333587646)
[2025-02-04 02:43:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18888/23838 [06:32<30:14,  2.73it/s][2025-02-04 02:43:22][root][INFO] - Training Epoch: 2/2, step 18887/23838 completed (loss: 0.8691837191581726, acc: 0.779411792755127)
[2025-02-04 02:43:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18889/23838 [06:33<29:39,  2.78it/s][2025-02-04 02:43:22][root][INFO] - Training Epoch: 2/2, step 18888/23838 completed (loss: 0.4716823399066925, acc: 0.875)
[2025-02-04 02:43:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18890/23838 [06:33<29:57,  2.75it/s][2025-02-04 02:43:23][root][INFO] - Training Epoch: 2/2, step 18889/23838 completed (loss: 0.5351072549819946, acc: 0.8783783912658691)
[2025-02-04 02:43:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18891/23838 [06:33<30:57,  2.66it/s][2025-02-04 02:43:23][root][INFO] - Training Epoch: 2/2, step 18890/23838 completed (loss: 0.6164697408676147, acc: 0.8139534592628479)
[2025-02-04 02:43:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18892/23838 [06:34<31:25,  2.62it/s][2025-02-04 02:43:23][root][INFO] - Training Epoch: 2/2, step 18891/23838 completed (loss: 0.2390761524438858, acc: 0.9318181872367859)
[2025-02-04 02:43:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18893/23838 [06:34<31:38,  2.60it/s][2025-02-04 02:43:24][root][INFO] - Training Epoch: 2/2, step 18892/23838 completed (loss: 0.11970912665128708, acc: 0.9772727489471436)
[2025-02-04 02:43:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18894/23838 [06:34<29:08,  2.83it/s][2025-02-04 02:43:24][root][INFO] - Training Epoch: 2/2, step 18893/23838 completed (loss: 0.31926441192626953, acc: 0.922535240650177)
[2025-02-04 02:43:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18895/23838 [06:35<28:55,  2.85it/s][2025-02-04 02:43:24][root][INFO] - Training Epoch: 2/2, step 18894/23838 completed (loss: 0.24251428246498108, acc: 0.9253731369972229)
[2025-02-04 02:43:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18896/23838 [06:35<29:24,  2.80it/s][2025-02-04 02:43:25][root][INFO] - Training Epoch: 2/2, step 18895/23838 completed (loss: 0.491973876953125, acc: 0.8709677457809448)
[2025-02-04 02:43:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18897/23838 [06:36<28:19,  2.91it/s][2025-02-04 02:43:25][root][INFO] - Training Epoch: 2/2, step 18896/23838 completed (loss: 0.4029766917228699, acc: 0.9200000166893005)
[2025-02-04 02:43:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18898/23838 [06:36<27:59,  2.94it/s][2025-02-04 02:43:25][root][INFO] - Training Epoch: 2/2, step 18897/23838 completed (loss: 0.4520721435546875, acc: 0.859649121761322)
[2025-02-04 02:43:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18899/23838 [06:36<28:57,  2.84it/s][2025-02-04 02:43:26][root][INFO] - Training Epoch: 2/2, step 18898/23838 completed (loss: 0.5396469831466675, acc: 0.8108108043670654)
[2025-02-04 02:43:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18900/23838 [06:37<27:51,  2.95it/s][2025-02-04 02:43:26][root][INFO] - Training Epoch: 2/2, step 18899/23838 completed (loss: 0.1723783314228058, acc: 0.9689922332763672)
[2025-02-04 02:43:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18901/23838 [06:37<27:34,  2.98it/s][2025-02-04 02:43:26][root][INFO] - Training Epoch: 2/2, step 18900/23838 completed (loss: 0.38002389669418335, acc: 0.8857142925262451)
[2025-02-04 02:43:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18902/23838 [06:37<29:40,  2.77it/s][2025-02-04 02:43:27][root][INFO] - Training Epoch: 2/2, step 18901/23838 completed (loss: 0.2600255310535431, acc: 0.9366196990013123)
[2025-02-04 02:43:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18903/23838 [06:38<29:07,  2.82it/s][2025-02-04 02:43:27][root][INFO] - Training Epoch: 2/2, step 18902/23838 completed (loss: 0.30705392360687256, acc: 0.9230769276618958)
[2025-02-04 02:43:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18904/23838 [06:38<28:48,  2.85it/s][2025-02-04 02:43:28][root][INFO] - Training Epoch: 2/2, step 18903/23838 completed (loss: 0.4213651120662689, acc: 0.9115646481513977)
[2025-02-04 02:43:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18905/23838 [06:38<28:42,  2.86it/s][2025-02-04 02:43:28][root][INFO] - Training Epoch: 2/2, step 18904/23838 completed (loss: 0.4703488051891327, acc: 0.9069767594337463)
[2025-02-04 02:43:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18906/23838 [06:39<29:26,  2.79it/s][2025-02-04 02:43:28][root][INFO] - Training Epoch: 2/2, step 18905/23838 completed (loss: 0.18048855662345886, acc: 0.9532710313796997)
[2025-02-04 02:43:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18907/23838 [06:39<30:23,  2.70it/s][2025-02-04 02:43:29][root][INFO] - Training Epoch: 2/2, step 18906/23838 completed (loss: 0.03632183372974396, acc: 0.9917355179786682)
[2025-02-04 02:43:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18908/23838 [06:39<30:02,  2.73it/s][2025-02-04 02:43:29][root][INFO] - Training Epoch: 2/2, step 18907/23838 completed (loss: 0.11410414427518845, acc: 0.976331353187561)
[2025-02-04 02:43:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18909/23838 [06:40<29:44,  2.76it/s][2025-02-04 02:43:29][root][INFO] - Training Epoch: 2/2, step 18908/23838 completed (loss: 0.6344463229179382, acc: 0.8227847814559937)
[2025-02-04 02:43:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18910/23838 [06:40<29:23,  2.79it/s][2025-02-04 02:43:30][root][INFO] - Training Epoch: 2/2, step 18909/23838 completed (loss: 0.42423397302627563, acc: 0.9024389982223511)
[2025-02-04 02:43:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18911/23838 [06:41<29:34,  2.78it/s][2025-02-04 02:43:30][root][INFO] - Training Epoch: 2/2, step 18910/23838 completed (loss: 0.6342499852180481, acc: 0.862500011920929)
[2025-02-04 02:43:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18912/23838 [06:41<29:54,  2.75it/s][2025-02-04 02:43:30][root][INFO] - Training Epoch: 2/2, step 18911/23838 completed (loss: 0.3464430570602417, acc: 0.9009901285171509)
[2025-02-04 02:43:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18913/23838 [06:41<30:11,  2.72it/s][2025-02-04 02:43:31][root][INFO] - Training Epoch: 2/2, step 18912/23838 completed (loss: 0.16491292417049408, acc: 0.9510869383811951)
[2025-02-04 02:43:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18914/23838 [06:42<30:13,  2.72it/s][2025-02-04 02:43:31][root][INFO] - Training Epoch: 2/2, step 18913/23838 completed (loss: 0.07822507619857788, acc: 0.9829059839248657)
[2025-02-04 02:43:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18915/23838 [06:42<30:41,  2.67it/s][2025-02-04 02:43:32][root][INFO] - Training Epoch: 2/2, step 18914/23838 completed (loss: 0.4145711660385132, acc: 0.8829787373542786)
[2025-02-04 02:43:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18916/23838 [06:42<31:47,  2.58it/s][2025-02-04 02:43:32][root][INFO] - Training Epoch: 2/2, step 18915/23838 completed (loss: 0.29524171352386475, acc: 0.9202898740768433)
[2025-02-04 02:43:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18917/23838 [06:43<31:37,  2.59it/s][2025-02-04 02:43:32][root][INFO] - Training Epoch: 2/2, step 18916/23838 completed (loss: 0.20033982396125793, acc: 0.95333331823349)
[2025-02-04 02:43:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18918/23838 [06:43<35:52,  2.29it/s][2025-02-04 02:43:33][root][INFO] - Training Epoch: 2/2, step 18917/23838 completed (loss: 0.34746983647346497, acc: 0.8920863270759583)
[2025-02-04 02:43:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18919/23838 [06:44<37:29,  2.19it/s][2025-02-04 02:43:33][root][INFO] - Training Epoch: 2/2, step 18918/23838 completed (loss: 0.24234654009342194, acc: 0.9418604373931885)
[2025-02-04 02:43:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18920/23838 [06:44<35:33,  2.30it/s][2025-02-04 02:43:34][root][INFO] - Training Epoch: 2/2, step 18919/23838 completed (loss: 0.15416529774665833, acc: 0.9701492786407471)
[2025-02-04 02:43:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18921/23838 [06:45<34:01,  2.41it/s][2025-02-04 02:43:34][root][INFO] - Training Epoch: 2/2, step 18920/23838 completed (loss: 0.39468181133270264, acc: 0.890625)
[2025-02-04 02:43:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18922/23838 [06:45<33:13,  2.47it/s][2025-02-04 02:43:35][root][INFO] - Training Epoch: 2/2, step 18921/23838 completed (loss: 0.13277259469032288, acc: 0.9491525292396545)
[2025-02-04 02:43:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18923/23838 [06:45<33:33,  2.44it/s][2025-02-04 02:43:35][root][INFO] - Training Epoch: 2/2, step 18922/23838 completed (loss: 0.43284881114959717, acc: 0.7833333611488342)
[2025-02-04 02:43:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18924/23838 [06:46<34:05,  2.40it/s][2025-02-04 02:43:35][root][INFO] - Training Epoch: 2/2, step 18923/23838 completed (loss: 0.247262105345726, acc: 0.8913043737411499)
[2025-02-04 02:43:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18925/23838 [06:46<33:13,  2.46it/s][2025-02-04 02:43:36][root][INFO] - Training Epoch: 2/2, step 18924/23838 completed (loss: 0.19826146960258484, acc: 0.9363636374473572)
[2025-02-04 02:43:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18926/23838 [06:47<32:49,  2.49it/s][2025-02-04 02:43:36][root][INFO] - Training Epoch: 2/2, step 18925/23838 completed (loss: 0.1289076954126358, acc: 0.9607843160629272)
[2025-02-04 02:43:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18927/23838 [06:47<31:30,  2.60it/s][2025-02-04 02:43:37][root][INFO] - Training Epoch: 2/2, step 18926/23838 completed (loss: 0.1832447201013565, acc: 0.936170220375061)
[2025-02-04 02:43:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18928/23838 [06:47<33:43,  2.43it/s][2025-02-04 02:43:37][root][INFO] - Training Epoch: 2/2, step 18927/23838 completed (loss: 0.3013487756252289, acc: 0.9014084339141846)
[2025-02-04 02:43:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18929/23838 [06:48<32:30,  2.52it/s][2025-02-04 02:43:37][root][INFO] - Training Epoch: 2/2, step 18928/23838 completed (loss: 0.14038607478141785, acc: 0.9479166865348816)
[2025-02-04 02:43:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18930/23838 [06:48<31:40,  2.58it/s][2025-02-04 02:43:38][root][INFO] - Training Epoch: 2/2, step 18929/23838 completed (loss: 0.19881318509578705, acc: 0.9433962106704712)
[2025-02-04 02:43:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18931/23838 [06:48<29:42,  2.75it/s][2025-02-04 02:43:38][root][INFO] - Training Epoch: 2/2, step 18930/23838 completed (loss: 0.22448818385601044, acc: 0.9259259104728699)
[2025-02-04 02:43:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18932/23838 [06:49<28:51,  2.83it/s][2025-02-04 02:43:38][root][INFO] - Training Epoch: 2/2, step 18931/23838 completed (loss: 0.13232116401195526, acc: 0.9622641801834106)
[2025-02-04 02:43:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18933/23838 [06:49<27:55,  2.93it/s][2025-02-04 02:43:39][root][INFO] - Training Epoch: 2/2, step 18932/23838 completed (loss: 0.1769789755344391, acc: 0.9333333373069763)
[2025-02-04 02:43:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18934/23838 [06:49<27:18,  2.99it/s][2025-02-04 02:43:39][root][INFO] - Training Epoch: 2/2, step 18933/23838 completed (loss: 0.11359693109989166, acc: 0.9743589758872986)
[2025-02-04 02:43:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18935/23838 [06:50<27:21,  2.99it/s][2025-02-04 02:43:39][root][INFO] - Training Epoch: 2/2, step 18934/23838 completed (loss: 0.28523725271224976, acc: 0.93388432264328)
[2025-02-04 02:43:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18936/23838 [06:50<27:53,  2.93it/s][2025-02-04 02:43:40][root][INFO] - Training Epoch: 2/2, step 18935/23838 completed (loss: 0.5378310680389404, acc: 0.8690476417541504)
[2025-02-04 02:43:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18937/23838 [06:50<28:05,  2.91it/s][2025-02-04 02:43:40][root][INFO] - Training Epoch: 2/2, step 18936/23838 completed (loss: 0.09840098023414612, acc: 0.9696969985961914)
[2025-02-04 02:43:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18938/23838 [06:51<28:18,  2.89it/s][2025-02-04 02:43:40][root][INFO] - Training Epoch: 2/2, step 18937/23838 completed (loss: 0.15383347868919373, acc: 0.949999988079071)
[2025-02-04 02:43:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18939/23838 [06:51<28:58,  2.82it/s][2025-02-04 02:43:41][root][INFO] - Training Epoch: 2/2, step 18938/23838 completed (loss: 0.20440882444381714, acc: 0.9285714030265808)
[2025-02-04 02:43:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18940/23838 [06:52<29:05,  2.81it/s][2025-02-04 02:43:41][root][INFO] - Training Epoch: 2/2, step 18939/23838 completed (loss: 0.1571381539106369, acc: 0.9718309640884399)
[2025-02-04 02:43:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18941/23838 [06:52<29:27,  2.77it/s][2025-02-04 02:43:42][root][INFO] - Training Epoch: 2/2, step 18940/23838 completed (loss: 0.5516248345375061, acc: 0.8362069129943848)
[2025-02-04 02:43:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18942/23838 [06:52<29:22,  2.78it/s][2025-02-04 02:43:42][root][INFO] - Training Epoch: 2/2, step 18941/23838 completed (loss: 0.32430776953697205, acc: 0.9291338324546814)
[2025-02-04 02:43:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18943/23838 [06:53<29:15,  2.79it/s][2025-02-04 02:43:42][root][INFO] - Training Epoch: 2/2, step 18942/23838 completed (loss: 0.34812918305397034, acc: 0.9595959782600403)
[2025-02-04 02:43:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18944/23838 [06:53<28:50,  2.83it/s][2025-02-04 02:43:43][root][INFO] - Training Epoch: 2/2, step 18943/23838 completed (loss: 0.4790014326572418, acc: 0.868852436542511)
[2025-02-04 02:43:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18945/23838 [06:53<31:16,  2.61it/s][2025-02-04 02:43:43][root][INFO] - Training Epoch: 2/2, step 18944/23838 completed (loss: 0.314780056476593, acc: 0.8982036113739014)
[2025-02-04 02:43:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18946/23838 [06:54<32:26,  2.51it/s][2025-02-04 02:43:43][root][INFO] - Training Epoch: 2/2, step 18945/23838 completed (loss: 0.395037978887558, acc: 0.9113923907279968)
[2025-02-04 02:43:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18947/23838 [06:54<34:23,  2.37it/s][2025-02-04 02:43:44][root][INFO] - Training Epoch: 2/2, step 18946/23838 completed (loss: 0.13501228392124176, acc: 0.9590163826942444)
[2025-02-04 02:43:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18948/23838 [06:55<33:53,  2.41it/s][2025-02-04 02:43:44][root][INFO] - Training Epoch: 2/2, step 18947/23838 completed (loss: 0.24785293638706207, acc: 0.9344262480735779)
[2025-02-04 02:43:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18949/23838 [06:55<33:19,  2.45it/s][2025-02-04 02:43:45][root][INFO] - Training Epoch: 2/2, step 18948/23838 completed (loss: 0.11566834151744843, acc: 0.977011501789093)
[2025-02-04 02:43:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18950/23838 [06:56<34:27,  2.36it/s][2025-02-04 02:43:45][root][INFO] - Training Epoch: 2/2, step 18949/23838 completed (loss: 0.10839729011058807, acc: 0.9629629850387573)
[2025-02-04 02:43:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  79%|[34m███████▉  [0m| 18951/23838 [06:56<33:25,  2.44it/s][2025-02-04 02:43:46][root][INFO] - Training Epoch: 2/2, step 18950/23838 completed (loss: 0.2888861894607544, acc: 0.9074074029922485)
[2025-02-04 02:43:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18952/23838 [06:56<33:51,  2.40it/s][2025-02-04 02:43:46][root][INFO] - Training Epoch: 2/2, step 18951/23838 completed (loss: 0.494430810213089, acc: 0.884393036365509)
[2025-02-04 02:43:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18953/23838 [06:57<33:47,  2.41it/s][2025-02-04 02:43:46][root][INFO] - Training Epoch: 2/2, step 18952/23838 completed (loss: 0.22053460776805878, acc: 0.9547738432884216)
[2025-02-04 02:43:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18954/23838 [06:57<31:42,  2.57it/s][2025-02-04 02:43:47][root][INFO] - Training Epoch: 2/2, step 18953/23838 completed (loss: 0.2807219922542572, acc: 0.8947368264198303)
[2025-02-04 02:43:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18955/23838 [06:58<31:21,  2.59it/s][2025-02-04 02:43:47][root][INFO] - Training Epoch: 2/2, step 18954/23838 completed (loss: 0.25047606229782104, acc: 0.9278350472450256)
[2025-02-04 02:43:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18956/23838 [06:58<30:46,  2.64it/s][2025-02-04 02:43:47][root][INFO] - Training Epoch: 2/2, step 18955/23838 completed (loss: 0.5587631464004517, acc: 0.8548387289047241)
[2025-02-04 02:43:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18957/23838 [06:58<33:57,  2.40it/s][2025-02-04 02:43:48][root][INFO] - Training Epoch: 2/2, step 18956/23838 completed (loss: 0.23388031125068665, acc: 0.9193548560142517)
[2025-02-04 02:43:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18958/23838 [06:59<31:40,  2.57it/s][2025-02-04 02:43:48][root][INFO] - Training Epoch: 2/2, step 18957/23838 completed (loss: 0.3228520452976227, acc: 0.9014084339141846)
[2025-02-04 02:43:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18959/23838 [06:59<30:05,  2.70it/s][2025-02-04 02:43:49][root][INFO] - Training Epoch: 2/2, step 18958/23838 completed (loss: 0.6455042958259583, acc: 0.8068181872367859)
[2025-02-04 02:43:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18960/23838 [06:59<28:50,  2.82it/s][2025-02-04 02:43:49][root][INFO] - Training Epoch: 2/2, step 18959/23838 completed (loss: 0.5485808253288269, acc: 0.875)
[2025-02-04 02:43:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18961/23838 [07:00<27:55,  2.91it/s][2025-02-04 02:43:49][root][INFO] - Training Epoch: 2/2, step 18960/23838 completed (loss: 0.4268992245197296, acc: 0.8809523582458496)
[2025-02-04 02:43:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18962/23838 [07:00<29:13,  2.78it/s][2025-02-04 02:43:50][root][INFO] - Training Epoch: 2/2, step 18961/23838 completed (loss: 0.3843769431114197, acc: 0.8823529481887817)
[2025-02-04 02:43:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18963/23838 [07:00<28:43,  2.83it/s][2025-02-04 02:43:50][root][INFO] - Training Epoch: 2/2, step 18962/23838 completed (loss: 0.34182143211364746, acc: 0.9016393423080444)
[2025-02-04 02:43:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18964/23838 [07:01<28:09,  2.88it/s][2025-02-04 02:43:50][root][INFO] - Training Epoch: 2/2, step 18963/23838 completed (loss: 1.1561989784240723, acc: 0.7058823704719543)
[2025-02-04 02:43:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18965/23838 [07:01<27:49,  2.92it/s][2025-02-04 02:43:51][root][INFO] - Training Epoch: 2/2, step 18964/23838 completed (loss: 0.3862026631832123, acc: 0.8461538553237915)
[2025-02-04 02:43:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18966/23838 [07:01<28:38,  2.84it/s][2025-02-04 02:43:51][root][INFO] - Training Epoch: 2/2, step 18965/23838 completed (loss: 0.4948946535587311, acc: 0.8804348111152649)
[2025-02-04 02:43:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18967/23838 [07:02<27:43,  2.93it/s][2025-02-04 02:43:51][root][INFO] - Training Epoch: 2/2, step 18966/23838 completed (loss: 0.7559195160865784, acc: 0.797468364238739)
[2025-02-04 02:43:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18968/23838 [07:02<27:23,  2.96it/s][2025-02-04 02:43:52][root][INFO] - Training Epoch: 2/2, step 18967/23838 completed (loss: 0.5857431888580322, acc: 0.8148148059844971)
[2025-02-04 02:43:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18969/23838 [07:02<28:00,  2.90it/s][2025-02-04 02:43:52][root][INFO] - Training Epoch: 2/2, step 18968/23838 completed (loss: 0.336897611618042, acc: 0.8529411554336548)
[2025-02-04 02:43:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18970/23838 [07:03<28:00,  2.90it/s][2025-02-04 02:43:52][root][INFO] - Training Epoch: 2/2, step 18969/23838 completed (loss: 0.8636327981948853, acc: 0.7368420958518982)
[2025-02-04 02:43:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18971/23838 [07:03<28:29,  2.85it/s][2025-02-04 02:43:53][root][INFO] - Training Epoch: 2/2, step 18970/23838 completed (loss: 0.56020587682724, acc: 0.859649121761322)
[2025-02-04 02:43:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18972/23838 [07:04<27:31,  2.95it/s][2025-02-04 02:43:53][root][INFO] - Training Epoch: 2/2, step 18971/23838 completed (loss: 0.2899310290813446, acc: 0.9487179517745972)
[2025-02-04 02:43:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18973/23838 [07:04<28:30,  2.84it/s][2025-02-04 02:43:53][root][INFO] - Training Epoch: 2/2, step 18972/23838 completed (loss: 0.2913365662097931, acc: 0.8951612710952759)
[2025-02-04 02:43:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18974/23838 [07:04<27:51,  2.91it/s][2025-02-04 02:43:54][root][INFO] - Training Epoch: 2/2, step 18973/23838 completed (loss: 0.2595604360103607, acc: 0.8979591727256775)
[2025-02-04 02:43:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18975/23838 [07:05<27:36,  2.94it/s][2025-02-04 02:43:54][root][INFO] - Training Epoch: 2/2, step 18974/23838 completed (loss: 0.30228808522224426, acc: 0.8888888955116272)
[2025-02-04 02:43:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18976/23838 [07:05<27:10,  2.98it/s][2025-02-04 02:43:54][root][INFO] - Training Epoch: 2/2, step 18975/23838 completed (loss: 0.8405691385269165, acc: 0.8199999928474426)
[2025-02-04 02:43:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18977/23838 [07:05<28:18,  2.86it/s][2025-02-04 02:43:55][root][INFO] - Training Epoch: 2/2, step 18976/23838 completed (loss: 1.0589754581451416, acc: 0.7321428656578064)
[2025-02-04 02:43:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18978/23838 [07:06<28:37,  2.83it/s][2025-02-04 02:43:55][root][INFO] - Training Epoch: 2/2, step 18977/23838 completed (loss: 0.5615485310554504, acc: 0.8333333134651184)
[2025-02-04 02:43:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18979/23838 [07:06<28:22,  2.85it/s][2025-02-04 02:43:56][root][INFO] - Training Epoch: 2/2, step 18978/23838 completed (loss: 0.5627634525299072, acc: 0.8536585569381714)
[2025-02-04 02:43:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18980/23838 [07:06<27:49,  2.91it/s][2025-02-04 02:43:56][root][INFO] - Training Epoch: 2/2, step 18979/23838 completed (loss: 0.27228468656539917, acc: 0.9545454382896423)
[2025-02-04 02:43:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18981/23838 [07:07<28:09,  2.87it/s][2025-02-04 02:43:56][root][INFO] - Training Epoch: 2/2, step 18980/23838 completed (loss: 0.5081621408462524, acc: 0.8857142925262451)
[2025-02-04 02:43:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18982/23838 [07:07<27:46,  2.91it/s][2025-02-04 02:43:57][root][INFO] - Training Epoch: 2/2, step 18981/23838 completed (loss: 0.9796746373176575, acc: 0.7916666865348816)
[2025-02-04 02:43:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18983/23838 [07:07<27:56,  2.90it/s][2025-02-04 02:43:57][root][INFO] - Training Epoch: 2/2, step 18982/23838 completed (loss: 1.5762624740600586, acc: 0.5526315569877625)
[2025-02-04 02:43:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18984/23838 [07:08<27:57,  2.89it/s][2025-02-04 02:43:57][root][INFO] - Training Epoch: 2/2, step 18983/23838 completed (loss: 0.5635754466056824, acc: 0.8108108043670654)
[2025-02-04 02:43:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18985/23838 [07:08<27:57,  2.89it/s][2025-02-04 02:43:58][root][INFO] - Training Epoch: 2/2, step 18984/23838 completed (loss: 0.3295823335647583, acc: 0.9333333373069763)
[2025-02-04 02:43:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18986/23838 [07:08<28:24,  2.85it/s][2025-02-04 02:43:58][root][INFO] - Training Epoch: 2/2, step 18985/23838 completed (loss: 0.26948657631874084, acc: 0.970588207244873)
[2025-02-04 02:43:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18987/23838 [07:09<29:27,  2.74it/s][2025-02-04 02:43:58][root][INFO] - Training Epoch: 2/2, step 18986/23838 completed (loss: 0.49650847911834717, acc: 0.8695651888847351)
[2025-02-04 02:43:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18988/23838 [07:09<30:09,  2.68it/s][2025-02-04 02:43:59][root][INFO] - Training Epoch: 2/2, step 18987/23838 completed (loss: 1.1482470035552979, acc: 0.6779661178588867)
[2025-02-04 02:43:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18989/23838 [07:10<30:06,  2.68it/s][2025-02-04 02:43:59][root][INFO] - Training Epoch: 2/2, step 18988/23838 completed (loss: 0.5510439872741699, acc: 1.0)
[2025-02-04 02:43:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18990/23838 [07:10<29:34,  2.73it/s][2025-02-04 02:43:59][root][INFO] - Training Epoch: 2/2, step 18989/23838 completed (loss: 0.5160497426986694, acc: 0.9090909361839294)
[2025-02-04 02:44:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18991/23838 [07:10<29:25,  2.75it/s][2025-02-04 02:44:00][root][INFO] - Training Epoch: 2/2, step 18990/23838 completed (loss: 0.6510457992553711, acc: 0.8333333134651184)
[2025-02-04 02:44:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18992/23838 [07:11<30:03,  2.69it/s][2025-02-04 02:44:00][root][INFO] - Training Epoch: 2/2, step 18991/23838 completed (loss: 0.8909469842910767, acc: 0.7580645084381104)
[2025-02-04 02:44:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18993/23838 [07:11<30:04,  2.69it/s][2025-02-04 02:44:01][root][INFO] - Training Epoch: 2/2, step 18992/23838 completed (loss: 0.41450995206832886, acc: 0.8857142925262451)
[2025-02-04 02:44:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18994/23838 [07:11<30:32,  2.64it/s][2025-02-04 02:44:01][root][INFO] - Training Epoch: 2/2, step 18993/23838 completed (loss: 0.6129398941993713, acc: 0.800000011920929)
[2025-02-04 02:44:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18995/23838 [07:12<30:54,  2.61it/s][2025-02-04 02:44:01][root][INFO] - Training Epoch: 2/2, step 18994/23838 completed (loss: 0.4432990849018097, acc: 0.8709677457809448)
[2025-02-04 02:44:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18996/23838 [07:12<30:22,  2.66it/s][2025-02-04 02:44:02][root][INFO] - Training Epoch: 2/2, step 18995/23838 completed (loss: 0.9110580086708069, acc: 0.8051947951316833)
[2025-02-04 02:44:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18997/23838 [07:13<30:59,  2.60it/s][2025-02-04 02:44:02][root][INFO] - Training Epoch: 2/2, step 18996/23838 completed (loss: 0.1124887689948082, acc: 0.9473684430122375)
[2025-02-04 02:44:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18998/23838 [07:13<29:58,  2.69it/s][2025-02-04 02:44:03][root][INFO] - Training Epoch: 2/2, step 18997/23838 completed (loss: 0.4132945239543915, acc: 0.8805969953536987)
[2025-02-04 02:44:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 18999/23838 [07:13<30:27,  2.65it/s][2025-02-04 02:44:03][root][INFO] - Training Epoch: 2/2, step 18998/23838 completed (loss: 0.6079904437065125, acc: 0.8481012582778931)
[2025-02-04 02:44:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19000/23838 [07:14<30:28,  2.65it/s][2025-02-04 02:44:03][root][INFO] - Training Epoch: 2/2, step 18999/23838 completed (loss: 1.04825758934021, acc: 0.7076923251152039)
[2025-02-04 02:44:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19001/23838 [07:14<29:33,  2.73it/s][2025-02-04 02:44:04][root][INFO] - Training Epoch: 2/2, step 19000/23838 completed (loss: 0.5670298933982849, acc: 0.8571428656578064)
[2025-02-04 02:44:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19002/23838 [07:14<29:41,  2.71it/s][2025-02-04 02:44:04][root][INFO] - Training Epoch: 2/2, step 19001/23838 completed (loss: 0.9118051528930664, acc: 0.7297297120094299)
[2025-02-04 02:44:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19003/23838 [07:15<31:32,  2.55it/s][2025-02-04 02:44:04][root][INFO] - Training Epoch: 2/2, step 19002/23838 completed (loss: 0.7522262930870056, acc: 0.7792207598686218)
[2025-02-04 02:44:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19004/23838 [07:15<32:09,  2.50it/s][2025-02-04 02:44:05][root][INFO] - Training Epoch: 2/2, step 19003/23838 completed (loss: 0.5113659501075745, acc: 0.8152173757553101)
[2025-02-04 02:44:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19005/23838 [07:16<30:42,  2.62it/s][2025-02-04 02:44:05][root][INFO] - Training Epoch: 2/2, step 19004/23838 completed (loss: 0.1228727251291275, acc: 0.9615384340286255)
[2025-02-04 02:44:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19006/23838 [07:16<30:46,  2.62it/s][2025-02-04 02:44:06][root][INFO] - Training Epoch: 2/2, step 19005/23838 completed (loss: 1.0247392654418945, acc: 0.7543859481811523)
[2025-02-04 02:44:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19007/23838 [07:16<30:57,  2.60it/s][2025-02-04 02:44:06][root][INFO] - Training Epoch: 2/2, step 19006/23838 completed (loss: 0.5405253767967224, acc: 0.837837815284729)
[2025-02-04 02:44:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19008/23838 [07:17<31:57,  2.52it/s][2025-02-04 02:44:06][root][INFO] - Training Epoch: 2/2, step 19007/23838 completed (loss: 0.5790696740150452, acc: 0.8888888955116272)
[2025-02-04 02:44:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19009/23838 [07:17<30:25,  2.64it/s][2025-02-04 02:44:07][root][INFO] - Training Epoch: 2/2, step 19008/23838 completed (loss: 0.5254114270210266, acc: 0.8313252925872803)
[2025-02-04 02:44:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19010/23838 [07:17<29:51,  2.70it/s][2025-02-04 02:44:07][root][INFO] - Training Epoch: 2/2, step 19009/23838 completed (loss: 0.31744277477264404, acc: 0.9090909361839294)
[2025-02-04 02:44:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19011/23838 [07:18<28:51,  2.79it/s][2025-02-04 02:44:07][root][INFO] - Training Epoch: 2/2, step 19010/23838 completed (loss: 0.7026057243347168, acc: 0.8194444179534912)
[2025-02-04 02:44:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19012/23838 [07:18<27:35,  2.92it/s][2025-02-04 02:44:08][root][INFO] - Training Epoch: 2/2, step 19011/23838 completed (loss: 0.47783225774765015, acc: 0.8620689511299133)
[2025-02-04 02:44:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19013/23838 [07:18<27:49,  2.89it/s][2025-02-04 02:44:08][root][INFO] - Training Epoch: 2/2, step 19012/23838 completed (loss: 0.2892398238182068, acc: 0.9387755393981934)
[2025-02-04 02:44:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19014/23838 [07:19<27:55,  2.88it/s][2025-02-04 02:44:08][root][INFO] - Training Epoch: 2/2, step 19013/23838 completed (loss: 0.3982401490211487, acc: 0.8833333253860474)
[2025-02-04 02:44:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19015/23838 [07:19<29:17,  2.74it/s][2025-02-04 02:44:09][root][INFO] - Training Epoch: 2/2, step 19014/23838 completed (loss: 0.711214542388916, acc: 0.8048780560493469)
[2025-02-04 02:44:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19016/23838 [07:20<29:17,  2.74it/s][2025-02-04 02:44:09][root][INFO] - Training Epoch: 2/2, step 19015/23838 completed (loss: 0.6086982488632202, acc: 0.8160919547080994)
[2025-02-04 02:44:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19017/23838 [07:20<29:18,  2.74it/s][2025-02-04 02:44:10][root][INFO] - Training Epoch: 2/2, step 19016/23838 completed (loss: 0.82944256067276, acc: 0.7666666507720947)
[2025-02-04 02:44:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19018/23838 [07:20<28:50,  2.79it/s][2025-02-04 02:44:10][root][INFO] - Training Epoch: 2/2, step 19017/23838 completed (loss: 0.6105003952980042, acc: 0.875)
[2025-02-04 02:44:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19019/23838 [07:21<30:29,  2.63it/s][2025-02-04 02:44:10][root][INFO] - Training Epoch: 2/2, step 19018/23838 completed (loss: 0.606329619884491, acc: 0.859649121761322)
[2025-02-04 02:44:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19020/23838 [07:21<32:28,  2.47it/s][2025-02-04 02:44:11][root][INFO] - Training Epoch: 2/2, step 19019/23838 completed (loss: 0.7335057258605957, acc: 0.843137264251709)
[2025-02-04 02:44:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19021/23838 [07:22<32:17,  2.49it/s][2025-02-04 02:44:11][root][INFO] - Training Epoch: 2/2, step 19020/23838 completed (loss: 0.9906997680664062, acc: 0.7213114500045776)
[2025-02-04 02:44:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19022/23838 [07:22<31:31,  2.55it/s][2025-02-04 02:44:12][root][INFO] - Training Epoch: 2/2, step 19021/23838 completed (loss: 0.7430857419967651, acc: 0.7419354915618896)
[2025-02-04 02:44:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19023/23838 [07:22<30:10,  2.66it/s][2025-02-04 02:44:12][root][INFO] - Training Epoch: 2/2, step 19022/23838 completed (loss: 0.6850138306617737, acc: 0.8072289228439331)
[2025-02-04 02:44:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19024/23838 [07:23<37:22,  2.15it/s][2025-02-04 02:44:13][root][INFO] - Training Epoch: 2/2, step 19023/23838 completed (loss: 0.4886833429336548, acc: 0.8780487775802612)
[2025-02-04 02:44:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19025/23838 [07:23<34:11,  2.35it/s][2025-02-04 02:44:13][root][INFO] - Training Epoch: 2/2, step 19024/23838 completed (loss: 0.22779341042041779, acc: 0.949367105960846)
[2025-02-04 02:44:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19026/23838 [07:24<31:59,  2.51it/s][2025-02-04 02:44:13][root][INFO] - Training Epoch: 2/2, step 19025/23838 completed (loss: 0.18248964846134186, acc: 0.9523809552192688)
[2025-02-04 02:44:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19027/23838 [07:24<30:29,  2.63it/s][2025-02-04 02:44:14][root][INFO] - Training Epoch: 2/2, step 19026/23838 completed (loss: 0.1348334401845932, acc: 0.9489796161651611)
[2025-02-04 02:44:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19028/23838 [07:24<27:38,  2.90it/s][2025-02-04 02:44:14][root][INFO] - Training Epoch: 2/2, step 19027/23838 completed (loss: 0.049827564507722855, acc: 0.9753086566925049)
[2025-02-04 02:44:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19029/23838 [07:25<26:36,  3.01it/s][2025-02-04 02:44:14][root][INFO] - Training Epoch: 2/2, step 19028/23838 completed (loss: 0.593999445438385, acc: 0.8181818127632141)
[2025-02-04 02:44:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19030/23838 [07:25<27:43,  2.89it/s][2025-02-04 02:44:15][root][INFO] - Training Epoch: 2/2, step 19029/23838 completed (loss: 0.07095469534397125, acc: 0.9764705896377563)
[2025-02-04 02:44:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19031/23838 [07:25<27:20,  2.93it/s][2025-02-04 02:44:15][root][INFO] - Training Epoch: 2/2, step 19030/23838 completed (loss: 0.18936100602149963, acc: 0.9740259647369385)
[2025-02-04 02:44:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19032/23838 [07:26<27:05,  2.96it/s][2025-02-04 02:44:15][root][INFO] - Training Epoch: 2/2, step 19031/23838 completed (loss: 0.2049759477376938, acc: 0.9508196711540222)
[2025-02-04 02:44:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19033/23838 [07:26<27:21,  2.93it/s][2025-02-04 02:44:16][root][INFO] - Training Epoch: 2/2, step 19032/23838 completed (loss: 0.322868674993515, acc: 0.9029126167297363)
[2025-02-04 02:44:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19034/23838 [07:26<30:01,  2.67it/s][2025-02-04 02:44:16][root][INFO] - Training Epoch: 2/2, step 19033/23838 completed (loss: 0.3716960549354553, acc: 0.8898305296897888)
[2025-02-04 02:44:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19035/23838 [07:27<34:59,  2.29it/s][2025-02-04 02:44:17][root][INFO] - Training Epoch: 2/2, step 19034/23838 completed (loss: 0.17363247275352478, acc: 0.957446813583374)
[2025-02-04 02:44:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19036/23838 [07:27<32:39,  2.45it/s][2025-02-04 02:44:17][root][INFO] - Training Epoch: 2/2, step 19035/23838 completed (loss: 0.09285111725330353, acc: 0.9814814925193787)
[2025-02-04 02:44:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19037/23838 [07:28<32:37,  2.45it/s][2025-02-04 02:44:17][root][INFO] - Training Epoch: 2/2, step 19036/23838 completed (loss: 0.42760056257247925, acc: 0.918367326259613)
[2025-02-04 02:44:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19038/23838 [07:28<31:39,  2.53it/s][2025-02-04 02:44:18][root][INFO] - Training Epoch: 2/2, step 19037/23838 completed (loss: 0.10202787071466446, acc: 0.9764705896377563)
[2025-02-04 02:44:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19039/23838 [07:29<32:56,  2.43it/s][2025-02-04 02:44:18][root][INFO] - Training Epoch: 2/2, step 19038/23838 completed (loss: 0.06866379827260971, acc: 0.9887640476226807)
[2025-02-04 02:44:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19040/23838 [07:29<32:35,  2.45it/s][2025-02-04 02:44:19][root][INFO] - Training Epoch: 2/2, step 19039/23838 completed (loss: 0.7843708395957947, acc: 0.8305084705352783)
[2025-02-04 02:44:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19041/23838 [07:29<32:57,  2.43it/s][2025-02-04 02:44:19][root][INFO] - Training Epoch: 2/2, step 19040/23838 completed (loss: 0.29982632398605347, acc: 0.9555555582046509)
[2025-02-04 02:44:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19042/23838 [07:30<34:19,  2.33it/s][2025-02-04 02:44:19][root][INFO] - Training Epoch: 2/2, step 19041/23838 completed (loss: 0.305040180683136, acc: 0.9122806787490845)
[2025-02-04 02:44:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19043/23838 [07:31<41:46,  1.91it/s][2025-02-04 02:44:20][root][INFO] - Training Epoch: 2/2, step 19042/23838 completed (loss: 0.21078579127788544, acc: 0.9487179517745972)
[2025-02-04 02:44:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19044/23838 [07:31<39:30,  2.02it/s][2025-02-04 02:44:21][root][INFO] - Training Epoch: 2/2, step 19043/23838 completed (loss: 0.17326052486896515, acc: 0.9615384340286255)
[2025-02-04 02:44:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19045/23838 [07:31<37:07,  2.15it/s][2025-02-04 02:44:21][root][INFO] - Training Epoch: 2/2, step 19044/23838 completed (loss: 0.21967393159866333, acc: 0.9594594836235046)
[2025-02-04 02:44:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19046/23838 [07:32<37:09,  2.15it/s][2025-02-04 02:44:21][root][INFO] - Training Epoch: 2/2, step 19045/23838 completed (loss: 0.0589175708591938, acc: 1.0)
[2025-02-04 02:44:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19047/23838 [07:33<43:13,  1.85it/s][2025-02-04 02:44:22][root][INFO] - Training Epoch: 2/2, step 19046/23838 completed (loss: 0.21083933115005493, acc: 0.9545454382896423)
[2025-02-04 02:44:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19048/23838 [07:33<40:39,  1.96it/s][2025-02-04 02:44:23][root][INFO] - Training Epoch: 2/2, step 19047/23838 completed (loss: 0.2100253701210022, acc: 0.9411764740943909)
[2025-02-04 02:44:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19049/23838 [07:34<47:09,  1.69it/s][2025-02-04 02:44:23][root][INFO] - Training Epoch: 2/2, step 19048/23838 completed (loss: 0.3506357669830322, acc: 0.939393937587738)
[2025-02-04 02:44:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19050/23838 [07:34<42:42,  1.87it/s][2025-02-04 02:44:24][root][INFO] - Training Epoch: 2/2, step 19049/23838 completed (loss: 0.1092388704419136, acc: 0.9651162624359131)
[2025-02-04 02:44:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19051/23838 [07:35<39:10,  2.04it/s][2025-02-04 02:44:24][root][INFO] - Training Epoch: 2/2, step 19050/23838 completed (loss: 0.6868309378623962, acc: 0.8476190567016602)
[2025-02-04 02:44:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19052/23838 [07:35<36:10,  2.20it/s][2025-02-04 02:44:25][root][INFO] - Training Epoch: 2/2, step 19051/23838 completed (loss: 0.2769703269004822, acc: 0.9240506291389465)
[2025-02-04 02:44:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19053/23838 [07:35<33:33,  2.38it/s][2025-02-04 02:44:25][root][INFO] - Training Epoch: 2/2, step 19052/23838 completed (loss: 0.023719197139143944, acc: 1.0)
[2025-02-04 02:44:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19054/23838 [07:36<33:00,  2.42it/s][2025-02-04 02:44:25][root][INFO] - Training Epoch: 2/2, step 19053/23838 completed (loss: 0.0568627268075943, acc: 0.9904761910438538)
[2025-02-04 02:44:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19055/23838 [07:36<31:14,  2.55it/s][2025-02-04 02:44:26][root][INFO] - Training Epoch: 2/2, step 19054/23838 completed (loss: 0.3318628966808319, acc: 0.9285714030265808)
[2025-02-04 02:44:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19056/23838 [07:36<32:25,  2.46it/s][2025-02-04 02:44:26][root][INFO] - Training Epoch: 2/2, step 19055/23838 completed (loss: 0.13042886555194855, acc: 0.9818181991577148)
[2025-02-04 02:44:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19057/23838 [07:37<35:37,  2.24it/s][2025-02-04 02:44:27][root][INFO] - Training Epoch: 2/2, step 19056/23838 completed (loss: 0.37563207745552063, acc: 0.9120879173278809)
[2025-02-04 02:44:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19058/23838 [07:38<37:44,  2.11it/s][2025-02-04 02:44:27][root][INFO] - Training Epoch: 2/2, step 19057/23838 completed (loss: 0.2985498011112213, acc: 0.931506872177124)
[2025-02-04 02:44:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19059/23838 [07:38<35:25,  2.25it/s][2025-02-04 02:44:28][root][INFO] - Training Epoch: 2/2, step 19058/23838 completed (loss: 0.044829536229372025, acc: 0.9857142567634583)
[2025-02-04 02:44:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19060/23838 [07:38<32:14,  2.47it/s][2025-02-04 02:44:28][root][INFO] - Training Epoch: 2/2, step 19059/23838 completed (loss: 0.3099261522293091, acc: 0.9082568883895874)
[2025-02-04 02:44:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19061/23838 [07:39<32:38,  2.44it/s][2025-02-04 02:44:28][root][INFO] - Training Epoch: 2/2, step 19060/23838 completed (loss: 0.23509465157985687, acc: 0.94017094373703)
[2025-02-04 02:44:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19062/23838 [07:39<32:16,  2.47it/s][2025-02-04 02:44:29][root][INFO] - Training Epoch: 2/2, step 19061/23838 completed (loss: 0.08469592034816742, acc: 0.9807692170143127)
[2025-02-04 02:44:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19063/23838 [07:39<30:58,  2.57it/s][2025-02-04 02:44:29][root][INFO] - Training Epoch: 2/2, step 19062/23838 completed (loss: 0.04184254631400108, acc: 1.0)
[2025-02-04 02:44:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19064/23838 [07:40<31:17,  2.54it/s][2025-02-04 02:44:29][root][INFO] - Training Epoch: 2/2, step 19063/23838 completed (loss: 0.2496902048587799, acc: 0.9428571462631226)
[2025-02-04 02:44:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19065/23838 [07:40<30:28,  2.61it/s][2025-02-04 02:44:30][root][INFO] - Training Epoch: 2/2, step 19064/23838 completed (loss: 0.19496746361255646, acc: 0.948051929473877)
[2025-02-04 02:44:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19066/23838 [07:41<36:27,  2.18it/s][2025-02-04 02:44:30][root][INFO] - Training Epoch: 2/2, step 19065/23838 completed (loss: 0.12904320657253265, acc: 0.9677419066429138)
[2025-02-04 02:44:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19067/23838 [07:41<33:27,  2.38it/s][2025-02-04 02:44:31][root][INFO] - Training Epoch: 2/2, step 19066/23838 completed (loss: 0.4050411581993103, acc: 0.9047619104385376)
[2025-02-04 02:44:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19068/23838 [07:42<33:00,  2.41it/s][2025-02-04 02:44:31][root][INFO] - Training Epoch: 2/2, step 19067/23838 completed (loss: 0.36289316415786743, acc: 0.9186992049217224)
[2025-02-04 02:44:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19069/23838 [07:42<39:09,  2.03it/s][2025-02-04 02:44:32][root][INFO] - Training Epoch: 2/2, step 19068/23838 completed (loss: 0.2128801792860031, acc: 0.939393937587738)
[2025-02-04 02:44:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m███████▉  [0m| 19070/23838 [07:43<36:52,  2.15it/s][2025-02-04 02:44:32][root][INFO] - Training Epoch: 2/2, step 19069/23838 completed (loss: 0.3568912148475647, acc: 0.9090909361839294)
[2025-02-04 02:44:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19071/23838 [07:43<34:31,  2.30it/s][2025-02-04 02:44:33][root][INFO] - Training Epoch: 2/2, step 19070/23838 completed (loss: 0.13606548309326172, acc: 0.95652174949646)
[2025-02-04 02:44:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19072/23838 [07:43<34:45,  2.29it/s][2025-02-04 02:44:33][root][INFO] - Training Epoch: 2/2, step 19071/23838 completed (loss: 0.10051033645868301, acc: 0.9848484992980957)
[2025-02-04 02:44:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19073/23838 [07:44<34:05,  2.33it/s][2025-02-04 02:44:33][root][INFO] - Training Epoch: 2/2, step 19072/23838 completed (loss: 0.2595694363117218, acc: 0.9230769276618958)
[2025-02-04 02:44:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19074/23838 [07:44<33:08,  2.40it/s][2025-02-04 02:44:34][root][INFO] - Training Epoch: 2/2, step 19073/23838 completed (loss: 0.08448894321918488, acc: 0.9722222089767456)
[2025-02-04 02:44:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19075/23838 [07:45<31:24,  2.53it/s][2025-02-04 02:44:34][root][INFO] - Training Epoch: 2/2, step 19074/23838 completed (loss: 0.21143639087677002, acc: 0.9137930870056152)
[2025-02-04 02:44:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19076/23838 [07:45<33:15,  2.39it/s][2025-02-04 02:44:35][root][INFO] - Training Epoch: 2/2, step 19075/23838 completed (loss: 0.36529454588890076, acc: 0.9200000166893005)
[2025-02-04 02:44:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19077/23838 [07:46<36:37,  2.17it/s][2025-02-04 02:44:35][root][INFO] - Training Epoch: 2/2, step 19076/23838 completed (loss: 0.48176804184913635, acc: 0.8828125)
[2025-02-04 02:44:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19078/23838 [07:46<36:48,  2.16it/s][2025-02-04 02:44:36][root][INFO] - Training Epoch: 2/2, step 19077/23838 completed (loss: 0.27028122544288635, acc: 0.9266666769981384)
[2025-02-04 02:44:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19079/23838 [07:47<36:36,  2.17it/s][2025-02-04 02:44:36][root][INFO] - Training Epoch: 2/2, step 19078/23838 completed (loss: 0.20473867654800415, acc: 0.938144326210022)
[2025-02-04 02:44:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19080/23838 [07:47<34:59,  2.27it/s][2025-02-04 02:44:37][root][INFO] - Training Epoch: 2/2, step 19079/23838 completed (loss: 0.5655919909477234, acc: 0.8536585569381714)
[2025-02-04 02:44:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19081/23838 [07:47<33:44,  2.35it/s][2025-02-04 02:44:37][root][INFO] - Training Epoch: 2/2, step 19080/23838 completed (loss: 0.07588736712932587, acc: 0.9682539701461792)
[2025-02-04 02:44:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19082/23838 [07:48<32:49,  2.41it/s][2025-02-04 02:44:37][root][INFO] - Training Epoch: 2/2, step 19081/23838 completed (loss: 0.04432719945907593, acc: 0.9916666746139526)
[2025-02-04 02:44:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19083/23838 [07:48<32:11,  2.46it/s][2025-02-04 02:44:38][root][INFO] - Training Epoch: 2/2, step 19082/23838 completed (loss: 0.10037077963352203, acc: 0.9682539701461792)
[2025-02-04 02:44:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19084/23838 [07:48<30:47,  2.57it/s][2025-02-04 02:44:38][root][INFO] - Training Epoch: 2/2, step 19083/23838 completed (loss: 0.1315142959356308, acc: 0.9534883499145508)
[2025-02-04 02:44:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19085/23838 [07:49<29:50,  2.65it/s][2025-02-04 02:44:38][root][INFO] - Training Epoch: 2/2, step 19084/23838 completed (loss: 0.6512017250061035, acc: 0.8815789222717285)
[2025-02-04 02:44:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19086/23838 [07:49<29:33,  2.68it/s][2025-02-04 02:44:39][root][INFO] - Training Epoch: 2/2, step 19085/23838 completed (loss: 0.1416148543357849, acc: 0.9680851101875305)
[2025-02-04 02:44:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19087/23838 [07:50<30:23,  2.61it/s][2025-02-04 02:44:39][root][INFO] - Training Epoch: 2/2, step 19086/23838 completed (loss: 0.08134769648313522, acc: 0.9700000286102295)
[2025-02-04 02:44:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19088/23838 [07:50<29:12,  2.71it/s][2025-02-04 02:44:39][root][INFO] - Training Epoch: 2/2, step 19087/23838 completed (loss: 0.058879490941762924, acc: 0.9816513657569885)
[2025-02-04 02:44:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19089/23838 [07:50<30:19,  2.61it/s][2025-02-04 02:44:40][root][INFO] - Training Epoch: 2/2, step 19088/23838 completed (loss: 0.22060224413871765, acc: 0.9239130616188049)
[2025-02-04 02:44:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19090/23838 [07:51<31:34,  2.51it/s][2025-02-04 02:44:40][root][INFO] - Training Epoch: 2/2, step 19089/23838 completed (loss: 0.4312037229537964, acc: 0.9268292784690857)
[2025-02-04 02:44:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19091/23838 [07:51<30:39,  2.58it/s][2025-02-04 02:44:41][root][INFO] - Training Epoch: 2/2, step 19090/23838 completed (loss: 0.29220953583717346, acc: 0.9431818127632141)
[2025-02-04 02:44:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19092/23838 [07:52<32:42,  2.42it/s][2025-02-04 02:44:41][root][INFO] - Training Epoch: 2/2, step 19091/23838 completed (loss: 0.0686069056391716, acc: 0.9779411554336548)
[2025-02-04 02:44:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19093/23838 [07:52<30:59,  2.55it/s][2025-02-04 02:44:42][root][INFO] - Training Epoch: 2/2, step 19092/23838 completed (loss: 0.3765048682689667, acc: 0.8979591727256775)
[2025-02-04 02:44:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19094/23838 [07:52<30:09,  2.62it/s][2025-02-04 02:44:42][root][INFO] - Training Epoch: 2/2, step 19093/23838 completed (loss: 0.262393981218338, acc: 0.9264705777168274)
[2025-02-04 02:44:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19095/23838 [07:53<29:54,  2.64it/s][2025-02-04 02:44:42][root][INFO] - Training Epoch: 2/2, step 19094/23838 completed (loss: 0.6289759278297424, acc: 0.9154929518699646)
[2025-02-04 02:44:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19096/23838 [07:53<28:47,  2.75it/s][2025-02-04 02:44:43][root][INFO] - Training Epoch: 2/2, step 19095/23838 completed (loss: 0.6935540437698364, acc: 0.835616409778595)
[2025-02-04 02:44:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19097/23838 [07:53<28:15,  2.80it/s][2025-02-04 02:44:43][root][INFO] - Training Epoch: 2/2, step 19096/23838 completed (loss: 0.41967999935150146, acc: 0.953125)
[2025-02-04 02:44:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19098/23838 [07:54<27:29,  2.87it/s][2025-02-04 02:44:43][root][INFO] - Training Epoch: 2/2, step 19097/23838 completed (loss: 0.28216537833213806, acc: 0.8924731016159058)
[2025-02-04 02:44:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19099/23838 [07:54<27:10,  2.91it/s][2025-02-04 02:44:44][root][INFO] - Training Epoch: 2/2, step 19098/23838 completed (loss: 0.22068601846694946, acc: 0.8947368264198303)
[2025-02-04 02:44:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19100/23838 [07:54<30:13,  2.61it/s][2025-02-04 02:44:44][root][INFO] - Training Epoch: 2/2, step 19099/23838 completed (loss: 0.1631731241941452, acc: 0.9523809552192688)
[2025-02-04 02:44:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19101/23838 [07:55<29:44,  2.66it/s][2025-02-04 02:44:44][root][INFO] - Training Epoch: 2/2, step 19100/23838 completed (loss: 0.4044680893421173, acc: 0.9270833134651184)
[2025-02-04 02:44:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19102/23838 [07:55<29:08,  2.71it/s][2025-02-04 02:44:45][root][INFO] - Training Epoch: 2/2, step 19101/23838 completed (loss: 0.17093679308891296, acc: 1.0)
[2025-02-04 02:44:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19103/23838 [07:56<28:43,  2.75it/s][2025-02-04 02:44:45][root][INFO] - Training Epoch: 2/2, step 19102/23838 completed (loss: 0.17347271740436554, acc: 0.9354838728904724)
[2025-02-04 02:44:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19104/23838 [07:56<28:40,  2.75it/s][2025-02-04 02:44:45][root][INFO] - Training Epoch: 2/2, step 19103/23838 completed (loss: 0.09680287539958954, acc: 0.9811320900917053)
[2025-02-04 02:44:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19105/23838 [07:56<28:58,  2.72it/s][2025-02-04 02:44:46][root][INFO] - Training Epoch: 2/2, step 19104/23838 completed (loss: 0.3030183017253876, acc: 0.9191918969154358)
[2025-02-04 02:44:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19106/23838 [07:57<28:34,  2.76it/s][2025-02-04 02:44:46][root][INFO] - Training Epoch: 2/2, step 19105/23838 completed (loss: 0.033969324082136154, acc: 1.0)
[2025-02-04 02:44:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19107/23838 [07:57<28:09,  2.80it/s][2025-02-04 02:44:47][root][INFO] - Training Epoch: 2/2, step 19106/23838 completed (loss: 0.8412256836891174, acc: 0.7560975551605225)
[2025-02-04 02:44:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19108/23838 [07:57<28:01,  2.81it/s][2025-02-04 02:44:47][root][INFO] - Training Epoch: 2/2, step 19107/23838 completed (loss: 0.11768578737974167, acc: 0.9595959782600403)
[2025-02-04 02:44:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19109/23838 [07:58<27:27,  2.87it/s][2025-02-04 02:44:47][root][INFO] - Training Epoch: 2/2, step 19108/23838 completed (loss: 0.04881953448057175, acc: 0.9864864945411682)
[2025-02-04 02:44:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19110/23838 [07:58<27:04,  2.91it/s][2025-02-04 02:44:48][root][INFO] - Training Epoch: 2/2, step 19109/23838 completed (loss: 0.12383551150560379, acc: 0.95652174949646)
[2025-02-04 02:44:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19111/23838 [07:58<27:07,  2.90it/s][2025-02-04 02:44:48][root][INFO] - Training Epoch: 2/2, step 19110/23838 completed (loss: 0.07994798570871353, acc: 0.9772727489471436)
[2025-02-04 02:44:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19112/23838 [07:59<27:09,  2.90it/s][2025-02-04 02:44:48][root][INFO] - Training Epoch: 2/2, step 19111/23838 completed (loss: 0.49490562081336975, acc: 0.8877550959587097)
[2025-02-04 02:44:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19113/23838 [07:59<28:08,  2.80it/s][2025-02-04 02:44:49][root][INFO] - Training Epoch: 2/2, step 19112/23838 completed (loss: 0.05219968408346176, acc: 0.9863013625144958)
[2025-02-04 02:44:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19114/23838 [08:00<34:03,  2.31it/s][2025-02-04 02:44:49][root][INFO] - Training Epoch: 2/2, step 19113/23838 completed (loss: 0.13591791689395905, acc: 0.9636363387107849)
[2025-02-04 02:44:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19115/23838 [08:00<32:50,  2.40it/s][2025-02-04 02:44:50][root][INFO] - Training Epoch: 2/2, step 19114/23838 completed (loss: 0.402055948972702, acc: 0.9130434989929199)
[2025-02-04 02:44:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19116/23838 [08:00<32:47,  2.40it/s][2025-02-04 02:44:50][root][INFO] - Training Epoch: 2/2, step 19115/23838 completed (loss: 0.25561225414276123, acc: 0.9399999976158142)
[2025-02-04 02:44:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19117/23838 [08:01<30:26,  2.58it/s][2025-02-04 02:44:50][root][INFO] - Training Epoch: 2/2, step 19116/23838 completed (loss: 0.3056914210319519, acc: 0.8974359035491943)
[2025-02-04 02:44:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19118/23838 [08:01<29:30,  2.67it/s][2025-02-04 02:44:51][root][INFO] - Training Epoch: 2/2, step 19117/23838 completed (loss: 1.5040980577468872, acc: 0.6470588445663452)
[2025-02-04 02:44:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19119/23838 [08:01<28:46,  2.73it/s][2025-02-04 02:44:51][root][INFO] - Training Epoch: 2/2, step 19118/23838 completed (loss: 0.4987452030181885, acc: 0.8536585569381714)
[2025-02-04 02:44:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19120/23838 [08:02<29:12,  2.69it/s][2025-02-04 02:44:51][root][INFO] - Training Epoch: 2/2, step 19119/23838 completed (loss: 0.5621267557144165, acc: 0.8235294222831726)
[2025-02-04 02:44:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19121/23838 [08:02<30:03,  2.62it/s][2025-02-04 02:44:52][root][INFO] - Training Epoch: 2/2, step 19120/23838 completed (loss: 0.7554146647453308, acc: 0.7407407164573669)
[2025-02-04 02:44:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19122/23838 [08:03<28:27,  2.76it/s][2025-02-04 02:44:52][root][INFO] - Training Epoch: 2/2, step 19121/23838 completed (loss: 1.3230472803115845, acc: 0.6071428656578064)
[2025-02-04 02:44:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19123/23838 [08:03<29:16,  2.68it/s][2025-02-04 02:44:53][root][INFO] - Training Epoch: 2/2, step 19122/23838 completed (loss: 1.2238513231277466, acc: 0.5625)
[2025-02-04 02:44:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19124/23838 [08:03<28:53,  2.72it/s][2025-02-04 02:44:53][root][INFO] - Training Epoch: 2/2, step 19123/23838 completed (loss: 0.2918456196784973, acc: 0.9444444179534912)
[2025-02-04 02:44:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19125/23838 [08:04<29:29,  2.66it/s][2025-02-04 02:44:53][root][INFO] - Training Epoch: 2/2, step 19124/23838 completed (loss: 0.5976341962814331, acc: 0.8461538553237915)
[2025-02-04 02:44:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19126/23838 [08:04<29:39,  2.65it/s][2025-02-04 02:44:54][root][INFO] - Training Epoch: 2/2, step 19125/23838 completed (loss: 1.1102454662322998, acc: 0.7692307829856873)
[2025-02-04 02:44:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19127/23838 [08:04<29:42,  2.64it/s][2025-02-04 02:44:54][root][INFO] - Training Epoch: 2/2, step 19126/23838 completed (loss: 0.8951133489608765, acc: 0.7575757503509521)
[2025-02-04 02:44:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19128/23838 [08:05<29:31,  2.66it/s][2025-02-04 02:44:54][root][INFO] - Training Epoch: 2/2, step 19127/23838 completed (loss: 1.1030969619750977, acc: 0.7032257914543152)
[2025-02-04 02:44:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19129/23838 [08:05<29:20,  2.68it/s][2025-02-04 02:44:55][root][INFO] - Training Epoch: 2/2, step 19128/23838 completed (loss: 0.46217742562294006, acc: 0.8703703880310059)
[2025-02-04 02:44:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19130/23838 [08:06<28:34,  2.75it/s][2025-02-04 02:44:55][root][INFO] - Training Epoch: 2/2, step 19129/23838 completed (loss: 0.7821177244186401, acc: 0.7911392450332642)
[2025-02-04 02:44:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19131/23838 [08:06<28:59,  2.71it/s][2025-02-04 02:44:56][root][INFO] - Training Epoch: 2/2, step 19130/23838 completed (loss: 0.9048458933830261, acc: 0.8225806355476379)
[2025-02-04 02:44:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19132/23838 [08:06<30:21,  2.58it/s][2025-02-04 02:44:56][root][INFO] - Training Epoch: 2/2, step 19131/23838 completed (loss: 1.1273729801177979, acc: 0.6666666865348816)
[2025-02-04 02:44:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19133/23838 [08:07<29:45,  2.64it/s][2025-02-04 02:44:56][root][INFO] - Training Epoch: 2/2, step 19132/23838 completed (loss: 0.4307858943939209, acc: 0.876288652420044)
[2025-02-04 02:44:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19134/23838 [08:07<28:45,  2.73it/s][2025-02-04 02:44:57][root][INFO] - Training Epoch: 2/2, step 19133/23838 completed (loss: 0.5909097790718079, acc: 0.8214285969734192)
[2025-02-04 02:44:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19135/23838 [08:07<28:25,  2.76it/s][2025-02-04 02:44:57][root][INFO] - Training Epoch: 2/2, step 19134/23838 completed (loss: 0.5243735313415527, acc: 0.8695651888847351)
[2025-02-04 02:44:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19136/23838 [08:08<27:24,  2.86it/s][2025-02-04 02:44:57][root][INFO] - Training Epoch: 2/2, step 19135/23838 completed (loss: 0.7140862941741943, acc: 0.8152173757553101)
[2025-02-04 02:44:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19137/23838 [08:08<27:15,  2.88it/s][2025-02-04 02:44:58][root][INFO] - Training Epoch: 2/2, step 19136/23838 completed (loss: 0.7900394201278687, acc: 0.7752808928489685)
[2025-02-04 02:44:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19138/23838 [08:09<29:03,  2.70it/s][2025-02-04 02:44:58][root][INFO] - Training Epoch: 2/2, step 19137/23838 completed (loss: 0.26335206627845764, acc: 0.9158878326416016)
[2025-02-04 02:44:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19139/23838 [08:09<29:43,  2.64it/s][2025-02-04 02:44:58][root][INFO] - Training Epoch: 2/2, step 19138/23838 completed (loss: 0.6837586760520935, acc: 0.8275862336158752)
[2025-02-04 02:44:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19140/23838 [08:09<28:32,  2.74it/s][2025-02-04 02:44:59][root][INFO] - Training Epoch: 2/2, step 19139/23838 completed (loss: 0.5049123764038086, acc: 0.807692289352417)
[2025-02-04 02:44:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19141/23838 [08:10<29:35,  2.65it/s][2025-02-04 02:44:59][root][INFO] - Training Epoch: 2/2, step 19140/23838 completed (loss: 0.8182556629180908, acc: 0.7830188870429993)
[2025-02-04 02:44:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19142/23838 [08:10<30:29,  2.57it/s][2025-02-04 02:45:00][root][INFO] - Training Epoch: 2/2, step 19141/23838 completed (loss: 0.5980097651481628, acc: 0.8195488452911377)
[2025-02-04 02:45:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19143/23838 [08:10<31:09,  2.51it/s][2025-02-04 02:45:00][root][INFO] - Training Epoch: 2/2, step 19142/23838 completed (loss: 0.32243916392326355, acc: 0.9032257795333862)
[2025-02-04 02:45:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19144/23838 [08:11<30:24,  2.57it/s][2025-02-04 02:45:00][root][INFO] - Training Epoch: 2/2, step 19143/23838 completed (loss: 0.3735700845718384, acc: 0.9285714030265808)
[2025-02-04 02:45:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19145/23838 [08:11<30:32,  2.56it/s][2025-02-04 02:45:01][root][INFO] - Training Epoch: 2/2, step 19144/23838 completed (loss: 0.9789385795593262, acc: 0.6966292262077332)
[2025-02-04 02:45:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19146/23838 [08:12<29:28,  2.65it/s][2025-02-04 02:45:01][root][INFO] - Training Epoch: 2/2, step 19145/23838 completed (loss: 0.5445449352264404, acc: 0.8552631735801697)
[2025-02-04 02:45:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19147/23838 [08:12<30:11,  2.59it/s][2025-02-04 02:45:02][root][INFO] - Training Epoch: 2/2, step 19146/23838 completed (loss: 0.7763665318489075, acc: 0.8017241358757019)
[2025-02-04 02:45:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19148/23838 [08:12<28:59,  2.70it/s][2025-02-04 02:45:02][root][INFO] - Training Epoch: 2/2, step 19147/23838 completed (loss: 0.5632438659667969, acc: 0.8461538553237915)
[2025-02-04 02:45:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19149/23838 [08:13<28:42,  2.72it/s][2025-02-04 02:45:02][root][INFO] - Training Epoch: 2/2, step 19148/23838 completed (loss: 0.8389015793800354, acc: 0.7866666913032532)
[2025-02-04 02:45:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19150/23838 [08:13<29:45,  2.63it/s][2025-02-04 02:45:03][root][INFO] - Training Epoch: 2/2, step 19149/23838 completed (loss: 0.44122549891471863, acc: 0.8829787373542786)
[2025-02-04 02:45:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19151/23838 [08:13<29:28,  2.65it/s][2025-02-04 02:45:03][root][INFO] - Training Epoch: 2/2, step 19150/23838 completed (loss: 0.4460667371749878, acc: 0.8867924809455872)
[2025-02-04 02:45:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19152/23838 [08:14<28:51,  2.71it/s][2025-02-04 02:45:03][root][INFO] - Training Epoch: 2/2, step 19151/23838 completed (loss: 0.4051331877708435, acc: 0.9137930870056152)
[2025-02-04 02:45:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19153/23838 [08:14<28:36,  2.73it/s][2025-02-04 02:45:04][root][INFO] - Training Epoch: 2/2, step 19152/23838 completed (loss: 0.5584615468978882, acc: 0.8095238208770752)
[2025-02-04 02:45:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19154/23838 [08:15<28:49,  2.71it/s][2025-02-04 02:45:04][root][INFO] - Training Epoch: 2/2, step 19153/23838 completed (loss: 0.2790539860725403, acc: 0.9277108311653137)
[2025-02-04 02:45:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19155/23838 [08:15<26:59,  2.89it/s][2025-02-04 02:45:04][root][INFO] - Training Epoch: 2/2, step 19154/23838 completed (loss: 0.38657957315444946, acc: 0.9047619104385376)
[2025-02-04 02:45:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19156/23838 [08:15<27:40,  2.82it/s][2025-02-04 02:45:05][root][INFO] - Training Epoch: 2/2, step 19155/23838 completed (loss: 0.516352117061615, acc: 0.8545454740524292)
[2025-02-04 02:45:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19157/23838 [08:16<28:11,  2.77it/s][2025-02-04 02:45:05][root][INFO] - Training Epoch: 2/2, step 19156/23838 completed (loss: 0.5201787948608398, acc: 0.8589743375778198)
[2025-02-04 02:45:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19158/23838 [08:16<27:11,  2.87it/s][2025-02-04 02:45:06][root][INFO] - Training Epoch: 2/2, step 19157/23838 completed (loss: 0.6749286651611328, acc: 0.7799999713897705)
[2025-02-04 02:45:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19159/23838 [08:16<28:31,  2.73it/s][2025-02-04 02:45:06][root][INFO] - Training Epoch: 2/2, step 19158/23838 completed (loss: 0.2143866866827011, acc: 0.9468598961830139)
[2025-02-04 02:45:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19160/23838 [08:17<28:29,  2.74it/s][2025-02-04 02:45:06][root][INFO] - Training Epoch: 2/2, step 19159/23838 completed (loss: 0.2344312071800232, acc: 0.9354838728904724)
[2025-02-04 02:45:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19161/23838 [08:17<27:51,  2.80it/s][2025-02-04 02:45:07][root][INFO] - Training Epoch: 2/2, step 19160/23838 completed (loss: 0.5950368642807007, acc: 0.8415841460227966)
[2025-02-04 02:45:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19162/23838 [08:17<27:40,  2.82it/s][2025-02-04 02:45:07][root][INFO] - Training Epoch: 2/2, step 19161/23838 completed (loss: 0.41276875138282776, acc: 0.8853503465652466)
[2025-02-04 02:45:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19163/23838 [08:18<28:00,  2.78it/s][2025-02-04 02:45:07][root][INFO] - Training Epoch: 2/2, step 19162/23838 completed (loss: 0.35131940245628357, acc: 0.9178082346916199)
[2025-02-04 02:45:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19164/23838 [08:18<27:22,  2.85it/s][2025-02-04 02:45:08][root][INFO] - Training Epoch: 2/2, step 19163/23838 completed (loss: 0.3320830166339874, acc: 0.9117646813392639)
[2025-02-04 02:45:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19165/23838 [08:18<26:44,  2.91it/s][2025-02-04 02:45:08][root][INFO] - Training Epoch: 2/2, step 19164/23838 completed (loss: 0.24508894979953766, acc: 0.9347826242446899)
[2025-02-04 02:45:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19166/23838 [08:19<28:46,  2.71it/s][2025-02-04 02:45:08][root][INFO] - Training Epoch: 2/2, step 19165/23838 completed (loss: 0.3974902629852295, acc: 0.8849557638168335)
[2025-02-04 02:45:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19167/23838 [08:19<29:01,  2.68it/s][2025-02-04 02:45:09][root][INFO] - Training Epoch: 2/2, step 19166/23838 completed (loss: 0.3699653744697571, acc: 0.9239130616188049)
[2025-02-04 02:45:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19168/23838 [08:20<28:39,  2.72it/s][2025-02-04 02:45:09][root][INFO] - Training Epoch: 2/2, step 19167/23838 completed (loss: 0.23497487604618073, acc: 0.9343065619468689)
[2025-02-04 02:45:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19169/23838 [08:20<28:07,  2.77it/s][2025-02-04 02:45:10][root][INFO] - Training Epoch: 2/2, step 19168/23838 completed (loss: 1.2122851610183716, acc: 0.6909090876579285)
[2025-02-04 02:45:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19170/23838 [08:20<26:58,  2.88it/s][2025-02-04 02:45:10][root][INFO] - Training Epoch: 2/2, step 19169/23838 completed (loss: 0.8411417603492737, acc: 0.7045454382896423)
[2025-02-04 02:45:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19171/23838 [08:21<26:34,  2.93it/s][2025-02-04 02:45:10][root][INFO] - Training Epoch: 2/2, step 19170/23838 completed (loss: 0.3332711458206177, acc: 0.8846153616905212)
[2025-02-04 02:45:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19172/23838 [08:21<27:22,  2.84it/s][2025-02-04 02:45:11][root][INFO] - Training Epoch: 2/2, step 19171/23838 completed (loss: 0.3578574061393738, acc: 0.9012345671653748)
[2025-02-04 02:45:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19173/23838 [08:21<27:10,  2.86it/s][2025-02-04 02:45:11][root][INFO] - Training Epoch: 2/2, step 19172/23838 completed (loss: 0.4063982665538788, acc: 0.9016393423080444)
[2025-02-04 02:45:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19174/23838 [08:22<26:58,  2.88it/s][2025-02-04 02:45:11][root][INFO] - Training Epoch: 2/2, step 19173/23838 completed (loss: 0.44373464584350586, acc: 0.8533333539962769)
[2025-02-04 02:45:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19175/23838 [08:22<26:57,  2.88it/s][2025-02-04 02:45:12][root][INFO] - Training Epoch: 2/2, step 19174/23838 completed (loss: 0.5828234553337097, acc: 0.8260869383811951)
[2025-02-04 02:45:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19176/23838 [08:22<28:08,  2.76it/s][2025-02-04 02:45:12][root][INFO] - Training Epoch: 2/2, step 19175/23838 completed (loss: 0.40912672877311707, acc: 0.8931297659873962)
[2025-02-04 02:45:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19177/23838 [08:23<28:27,  2.73it/s][2025-02-04 02:45:12][root][INFO] - Training Epoch: 2/2, step 19176/23838 completed (loss: 0.3070469796657562, acc: 0.9021739363670349)
[2025-02-04 02:45:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19178/23838 [08:23<27:58,  2.78it/s][2025-02-04 02:45:13][root][INFO] - Training Epoch: 2/2, step 19177/23838 completed (loss: 0.46921712160110474, acc: 0.9032257795333862)
[2025-02-04 02:45:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19179/23838 [08:23<27:31,  2.82it/s][2025-02-04 02:45:13][root][INFO] - Training Epoch: 2/2, step 19178/23838 completed (loss: 0.4740945100784302, acc: 0.8897058963775635)
[2025-02-04 02:45:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19180/23838 [08:24<28:31,  2.72it/s][2025-02-04 02:45:13][root][INFO] - Training Epoch: 2/2, step 19179/23838 completed (loss: 0.3391571640968323, acc: 0.8888888955116272)
[2025-02-04 02:45:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19181/23838 [08:24<28:49,  2.69it/s][2025-02-04 02:45:14][root][INFO] - Training Epoch: 2/2, step 19180/23838 completed (loss: 0.2840821146965027, acc: 0.9182389974594116)
[2025-02-04 02:45:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19182/23838 [08:25<28:25,  2.73it/s][2025-02-04 02:45:14][root][INFO] - Training Epoch: 2/2, step 19181/23838 completed (loss: 0.3253513276576996, acc: 0.9009009003639221)
[2025-02-04 02:45:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19183/23838 [08:25<29:17,  2.65it/s][2025-02-04 02:45:15][root][INFO] - Training Epoch: 2/2, step 19182/23838 completed (loss: 0.42617276310920715, acc: 0.9222221970558167)
[2025-02-04 02:45:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19184/23838 [08:25<29:34,  2.62it/s][2025-02-04 02:45:15][root][INFO] - Training Epoch: 2/2, step 19183/23838 completed (loss: 0.4190649688243866, acc: 0.8823529481887817)
[2025-02-04 02:45:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19185/23838 [08:26<29:11,  2.66it/s][2025-02-04 02:45:15][root][INFO] - Training Epoch: 2/2, step 19184/23838 completed (loss: 0.43092113733291626, acc: 0.8425197005271912)
[2025-02-04 02:45:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19186/23838 [08:26<27:36,  2.81it/s][2025-02-04 02:45:16][root][INFO] - Training Epoch: 2/2, step 19185/23838 completed (loss: 0.5398348569869995, acc: 0.8666666746139526)
[2025-02-04 02:45:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19187/23838 [08:26<26:11,  2.96it/s][2025-02-04 02:45:16][root][INFO] - Training Epoch: 2/2, step 19186/23838 completed (loss: 0.31609609723091125, acc: 0.9113923907279968)
[2025-02-04 02:45:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19188/23838 [08:27<26:03,  2.97it/s][2025-02-04 02:45:16][root][INFO] - Training Epoch: 2/2, step 19187/23838 completed (loss: 0.3508714437484741, acc: 0.9059829115867615)
[2025-02-04 02:45:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  80%|[34m████████  [0m| 19189/23838 [08:27<25:28,  3.04it/s][2025-02-04 02:45:17][root][INFO] - Training Epoch: 2/2, step 19188/23838 completed (loss: 0.2962070107460022, acc: 0.9099099040031433)
[2025-02-04 02:45:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19190/23838 [08:27<25:47,  3.00it/s][2025-02-04 02:45:17][root][INFO] - Training Epoch: 2/2, step 19189/23838 completed (loss: 0.3620372712612152, acc: 0.8860759735107422)
[2025-02-04 02:45:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19191/23838 [08:28<26:15,  2.95it/s][2025-02-04 02:45:17][root][INFO] - Training Epoch: 2/2, step 19190/23838 completed (loss: 0.37487727403640747, acc: 0.90625)
[2025-02-04 02:45:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19192/23838 [08:28<26:33,  2.92it/s][2025-02-04 02:45:18][root][INFO] - Training Epoch: 2/2, step 19191/23838 completed (loss: 0.40815937519073486, acc: 0.8588235378265381)
[2025-02-04 02:45:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19193/23838 [08:28<27:08,  2.85it/s][2025-02-04 02:45:18][root][INFO] - Training Epoch: 2/2, step 19192/23838 completed (loss: 0.34708213806152344, acc: 0.8942307829856873)
[2025-02-04 02:45:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19194/23838 [08:29<28:07,  2.75it/s][2025-02-04 02:45:18][root][INFO] - Training Epoch: 2/2, step 19193/23838 completed (loss: 0.5340642929077148, acc: 0.8938053250312805)
[2025-02-04 02:45:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19195/23838 [08:29<27:09,  2.85it/s][2025-02-04 02:45:19][root][INFO] - Training Epoch: 2/2, step 19194/23838 completed (loss: 0.162705197930336, acc: 0.9473684430122375)
[2025-02-04 02:45:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19196/23838 [08:29<26:45,  2.89it/s][2025-02-04 02:45:19][root][INFO] - Training Epoch: 2/2, step 19195/23838 completed (loss: 0.24246349930763245, acc: 0.9285714030265808)
[2025-02-04 02:45:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19197/23838 [08:30<26:43,  2.89it/s][2025-02-04 02:45:19][root][INFO] - Training Epoch: 2/2, step 19196/23838 completed (loss: 0.2763459086418152, acc: 0.9102563858032227)
[2025-02-04 02:45:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19198/23838 [08:30<26:42,  2.90it/s][2025-02-04 02:45:20][root][INFO] - Training Epoch: 2/2, step 19197/23838 completed (loss: 0.4958455264568329, acc: 0.8666666746139526)
[2025-02-04 02:45:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19199/23838 [08:30<27:07,  2.85it/s][2025-02-04 02:45:20][root][INFO] - Training Epoch: 2/2, step 19198/23838 completed (loss: 0.6243142485618591, acc: 0.8510638475418091)
[2025-02-04 02:45:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19200/23838 [08:31<27:45,  2.79it/s][2025-02-04 02:45:20][root][INFO] - Training Epoch: 2/2, step 19199/23838 completed (loss: 0.7334603071212769, acc: 0.800000011920929)
[2025-02-04 02:45:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19201/23838 [08:31<27:12,  2.84it/s][2025-02-04 02:45:21][root][INFO] - Training Epoch: 2/2, step 19200/23838 completed (loss: 0.30913928151130676, acc: 0.9278350472450256)
[2025-02-04 02:45:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19202/23838 [08:32<27:04,  2.85it/s][2025-02-04 02:45:21][root][INFO] - Training Epoch: 2/2, step 19201/23838 completed (loss: 0.2621876001358032, acc: 0.9375)
[2025-02-04 02:45:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19203/23838 [08:32<26:52,  2.87it/s][2025-02-04 02:45:21][root][INFO] - Training Epoch: 2/2, step 19202/23838 completed (loss: 0.2358330339193344, acc: 0.9367088675498962)
[2025-02-04 02:45:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19204/23838 [08:32<27:45,  2.78it/s][2025-02-04 02:45:22][root][INFO] - Training Epoch: 2/2, step 19203/23838 completed (loss: 0.1545550376176834, acc: 0.9638554453849792)
[2025-02-04 02:45:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19205/23838 [08:33<29:39,  2.60it/s][2025-02-04 02:45:22][root][INFO] - Training Epoch: 2/2, step 19204/23838 completed (loss: 0.3825324773788452, acc: 0.8815789222717285)
[2025-02-04 02:45:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19206/23838 [08:33<29:36,  2.61it/s][2025-02-04 02:45:23][root][INFO] - Training Epoch: 2/2, step 19205/23838 completed (loss: 0.38329243659973145, acc: 0.8987341523170471)
[2025-02-04 02:45:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19207/23838 [08:33<28:56,  2.67it/s][2025-02-04 02:45:23][root][INFO] - Training Epoch: 2/2, step 19206/23838 completed (loss: 0.27658361196517944, acc: 0.9318181872367859)
[2025-02-04 02:45:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19208/23838 [08:34<28:44,  2.68it/s][2025-02-04 02:45:23][root][INFO] - Training Epoch: 2/2, step 19207/23838 completed (loss: 0.28031378984451294, acc: 0.8965517282485962)
[2025-02-04 02:45:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19209/23838 [08:34<27:54,  2.76it/s][2025-02-04 02:45:24][root][INFO] - Training Epoch: 2/2, step 19208/23838 completed (loss: 0.3120817244052887, acc: 0.9019607901573181)
[2025-02-04 02:45:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19210/23838 [08:34<26:55,  2.86it/s][2025-02-04 02:45:24][root][INFO] - Training Epoch: 2/2, step 19209/23838 completed (loss: 0.6333916783332825, acc: 0.8139534592628479)
[2025-02-04 02:45:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19211/23838 [08:35<26:54,  2.87it/s][2025-02-04 02:45:24][root][INFO] - Training Epoch: 2/2, step 19210/23838 completed (loss: 0.13071465492248535, acc: 0.9370078444480896)
[2025-02-04 02:45:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19212/23838 [08:35<26:05,  2.96it/s][2025-02-04 02:45:25][root][INFO] - Training Epoch: 2/2, step 19211/23838 completed (loss: 0.14867818355560303, acc: 0.9358974099159241)
[2025-02-04 02:45:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19213/23838 [08:35<26:01,  2.96it/s][2025-02-04 02:45:25][root][INFO] - Training Epoch: 2/2, step 19212/23838 completed (loss: 0.2891322374343872, acc: 0.9078947305679321)
[2025-02-04 02:45:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19214/23838 [08:36<25:25,  3.03it/s][2025-02-04 02:45:25][root][INFO] - Training Epoch: 2/2, step 19213/23838 completed (loss: 0.3793392777442932, acc: 0.921875)
[2025-02-04 02:45:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19215/23838 [08:36<25:21,  3.04it/s][2025-02-04 02:45:26][root][INFO] - Training Epoch: 2/2, step 19214/23838 completed (loss: 0.6098092198371887, acc: 0.8208954930305481)
[2025-02-04 02:45:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19216/23838 [08:36<24:57,  3.09it/s][2025-02-04 02:45:26][root][INFO] - Training Epoch: 2/2, step 19215/23838 completed (loss: 0.9974424839019775, acc: 0.7543859481811523)
[2025-02-04 02:45:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19217/23838 [08:37<25:20,  3.04it/s][2025-02-04 02:45:26][root][INFO] - Training Epoch: 2/2, step 19216/23838 completed (loss: 0.7141361236572266, acc: 0.807692289352417)
[2025-02-04 02:45:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19218/23838 [08:37<25:22,  3.03it/s][2025-02-04 02:45:27][root][INFO] - Training Epoch: 2/2, step 19217/23838 completed (loss: 0.16759540140628815, acc: 0.9629629850387573)
[2025-02-04 02:45:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19219/23838 [08:37<26:21,  2.92it/s][2025-02-04 02:45:27][root][INFO] - Training Epoch: 2/2, step 19218/23838 completed (loss: 0.1848616600036621, acc: 0.9230769276618958)
[2025-02-04 02:45:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19220/23838 [08:38<27:05,  2.84it/s][2025-02-04 02:45:27][root][INFO] - Training Epoch: 2/2, step 19219/23838 completed (loss: 0.8170791864395142, acc: 0.800000011920929)
[2025-02-04 02:45:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19221/23838 [08:38<26:48,  2.87it/s][2025-02-04 02:45:28][root][INFO] - Training Epoch: 2/2, step 19220/23838 completed (loss: 0.4759618043899536, acc: 0.8235294222831726)
[2025-02-04 02:45:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19222/23838 [08:39<26:17,  2.93it/s][2025-02-04 02:45:28][root][INFO] - Training Epoch: 2/2, step 19221/23838 completed (loss: 0.39531686902046204, acc: 0.9069767594337463)
[2025-02-04 02:45:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19223/23838 [08:39<26:55,  2.86it/s][2025-02-04 02:45:28][root][INFO] - Training Epoch: 2/2, step 19222/23838 completed (loss: 0.4305189549922943, acc: 0.8589743375778198)
[2025-02-04 02:45:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19224/23838 [08:39<26:44,  2.88it/s][2025-02-04 02:45:29][root][INFO] - Training Epoch: 2/2, step 19223/23838 completed (loss: 0.6019723415374756, acc: 0.8333333134651184)
[2025-02-04 02:45:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19225/23838 [08:40<25:28,  3.02it/s][2025-02-04 02:45:29][root][INFO] - Training Epoch: 2/2, step 19224/23838 completed (loss: 0.4127601385116577, acc: 0.859375)
[2025-02-04 02:45:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19226/23838 [08:40<24:12,  3.17it/s][2025-02-04 02:45:29][root][INFO] - Training Epoch: 2/2, step 19225/23838 completed (loss: 0.9579437375068665, acc: 0.7571428418159485)
[2025-02-04 02:45:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19227/23838 [08:40<26:08,  2.94it/s][2025-02-04 02:45:30][root][INFO] - Training Epoch: 2/2, step 19226/23838 completed (loss: 0.6347612142562866, acc: 0.8390804529190063)
[2025-02-04 02:45:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19228/23838 [08:41<28:34,  2.69it/s][2025-02-04 02:45:30][root][INFO] - Training Epoch: 2/2, step 19227/23838 completed (loss: 0.845964789390564, acc: 0.7432432174682617)
[2025-02-04 02:45:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19229/23838 [08:41<29:33,  2.60it/s][2025-02-04 02:45:31][root][INFO] - Training Epoch: 2/2, step 19228/23838 completed (loss: 0.3795441687107086, acc: 0.9285714030265808)
[2025-02-04 02:45:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19230/23838 [08:41<29:17,  2.62it/s][2025-02-04 02:45:31][root][INFO] - Training Epoch: 2/2, step 19229/23838 completed (loss: 0.48546168208122253, acc: 0.8702290058135986)
[2025-02-04 02:45:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19231/23838 [08:42<28:46,  2.67it/s][2025-02-04 02:45:31][root][INFO] - Training Epoch: 2/2, step 19230/23838 completed (loss: 0.41087648272514343, acc: 0.875)
[2025-02-04 02:45:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19232/23838 [08:42<28:12,  2.72it/s][2025-02-04 02:45:32][root][INFO] - Training Epoch: 2/2, step 19231/23838 completed (loss: 0.31507426500320435, acc: 0.9333333373069763)
[2025-02-04 02:45:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19233/23838 [08:42<27:05,  2.83it/s][2025-02-04 02:45:32][root][INFO] - Training Epoch: 2/2, step 19232/23838 completed (loss: 0.8087901473045349, acc: 0.8199999928474426)
[2025-02-04 02:45:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19234/23838 [08:43<28:02,  2.74it/s][2025-02-04 02:45:32][root][INFO] - Training Epoch: 2/2, step 19233/23838 completed (loss: 0.48588964343070984, acc: 0.835616409778595)
[2025-02-04 02:45:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19235/23838 [08:43<28:53,  2.66it/s][2025-02-04 02:45:33][root][INFO] - Training Epoch: 2/2, step 19234/23838 completed (loss: 0.5917358994483948, acc: 0.8571428656578064)
[2025-02-04 02:45:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19236/23838 [08:44<28:30,  2.69it/s][2025-02-04 02:45:33][root][INFO] - Training Epoch: 2/2, step 19235/23838 completed (loss: 0.3520537316799164, acc: 0.9014084339141846)
[2025-02-04 02:45:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19237/23838 [08:44<27:55,  2.75it/s][2025-02-04 02:45:34][root][INFO] - Training Epoch: 2/2, step 19236/23838 completed (loss: 0.34508180618286133, acc: 0.9272727370262146)
[2025-02-04 02:45:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19238/23838 [08:44<27:00,  2.84it/s][2025-02-04 02:45:34][root][INFO] - Training Epoch: 2/2, step 19237/23838 completed (loss: 0.08166324347257614, acc: 0.9649122953414917)
[2025-02-04 02:45:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19239/23838 [08:45<26:43,  2.87it/s][2025-02-04 02:45:34][root][INFO] - Training Epoch: 2/2, step 19238/23838 completed (loss: 0.1266542226076126, acc: 0.9583333134651184)
[2025-02-04 02:45:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19240/23838 [08:45<26:05,  2.94it/s][2025-02-04 02:45:35][root][INFO] - Training Epoch: 2/2, step 19239/23838 completed (loss: 0.45142218470573425, acc: 0.9047619104385376)
[2025-02-04 02:45:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19241/23838 [08:45<26:28,  2.89it/s][2025-02-04 02:45:35][root][INFO] - Training Epoch: 2/2, step 19240/23838 completed (loss: 0.453141450881958, acc: 0.8780487775802612)
[2025-02-04 02:45:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19242/23838 [08:46<25:59,  2.95it/s][2025-02-04 02:45:35][root][INFO] - Training Epoch: 2/2, step 19241/23838 completed (loss: 0.10939402878284454, acc: 0.9784172773361206)
[2025-02-04 02:45:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19243/23838 [08:46<25:26,  3.01it/s][2025-02-04 02:45:36][root][INFO] - Training Epoch: 2/2, step 19242/23838 completed (loss: 0.19365674257278442, acc: 0.9579831957817078)
[2025-02-04 02:45:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19244/23838 [08:46<25:27,  3.01it/s][2025-02-04 02:45:36][root][INFO] - Training Epoch: 2/2, step 19243/23838 completed (loss: 0.14374300837516785, acc: 0.9438202381134033)
[2025-02-04 02:45:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19245/23838 [08:47<26:28,  2.89it/s][2025-02-04 02:45:36][root][INFO] - Training Epoch: 2/2, step 19244/23838 completed (loss: 0.30031922459602356, acc: 0.8999999761581421)
[2025-02-04 02:45:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19246/23838 [08:47<27:00,  2.83it/s][2025-02-04 02:45:37][root][INFO] - Training Epoch: 2/2, step 19245/23838 completed (loss: 0.3664756715297699, acc: 0.8775510191917419)
[2025-02-04 02:45:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19247/23838 [08:47<26:11,  2.92it/s][2025-02-04 02:45:37][root][INFO] - Training Epoch: 2/2, step 19246/23838 completed (loss: 0.4267040193080902, acc: 0.8961039185523987)
[2025-02-04 02:45:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19248/23838 [08:48<25:57,  2.95it/s][2025-02-04 02:45:37][root][INFO] - Training Epoch: 2/2, step 19247/23838 completed (loss: 0.2925906181335449, acc: 0.9158878326416016)
[2025-02-04 02:45:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19249/23838 [08:48<25:47,  2.97it/s][2025-02-04 02:45:38][root][INFO] - Training Epoch: 2/2, step 19248/23838 completed (loss: 0.12397564947605133, acc: 0.95652174949646)
[2025-02-04 02:45:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19250/23838 [08:48<25:53,  2.95it/s][2025-02-04 02:45:38][root][INFO] - Training Epoch: 2/2, step 19249/23838 completed (loss: 0.15761308372020721, acc: 0.9444444179534912)
[2025-02-04 02:45:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19251/23838 [08:49<25:13,  3.03it/s][2025-02-04 02:45:38][root][INFO] - Training Epoch: 2/2, step 19250/23838 completed (loss: 0.27737778425216675, acc: 0.9552238583564758)
[2025-02-04 02:45:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19252/23838 [08:49<26:43,  2.86it/s][2025-02-04 02:45:39][root][INFO] - Training Epoch: 2/2, step 19251/23838 completed (loss: 0.29518187046051025, acc: 0.9333333373069763)
[2025-02-04 02:45:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19253/23838 [08:49<27:33,  2.77it/s][2025-02-04 02:45:39][root][INFO] - Training Epoch: 2/2, step 19252/23838 completed (loss: 0.139983668923378, acc: 0.9636363387107849)
[2025-02-04 02:45:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19254/23838 [08:50<25:49,  2.96it/s][2025-02-04 02:45:39][root][INFO] - Training Epoch: 2/2, step 19253/23838 completed (loss: 0.6462160348892212, acc: 0.8035714030265808)
[2025-02-04 02:45:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19255/23838 [08:50<25:48,  2.96it/s][2025-02-04 02:45:40][root][INFO] - Training Epoch: 2/2, step 19254/23838 completed (loss: 0.7155966758728027, acc: 0.782608687877655)
[2025-02-04 02:45:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19256/23838 [08:50<26:58,  2.83it/s][2025-02-04 02:45:40][root][INFO] - Training Epoch: 2/2, step 19255/23838 completed (loss: 0.3178206980228424, acc: 0.8979591727256775)
[2025-02-04 02:45:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19257/23838 [08:51<25:35,  2.98it/s][2025-02-04 02:45:40][root][INFO] - Training Epoch: 2/2, step 19256/23838 completed (loss: 0.19168171286582947, acc: 0.942148745059967)
[2025-02-04 02:45:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19258/23838 [08:51<25:44,  2.97it/s][2025-02-04 02:45:41][root][INFO] - Training Epoch: 2/2, step 19257/23838 completed (loss: 0.4837813377380371, acc: 0.8857142925262451)
[2025-02-04 02:45:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19259/23838 [08:51<26:43,  2.86it/s][2025-02-04 02:45:41][root][INFO] - Training Epoch: 2/2, step 19258/23838 completed (loss: 0.23297739028930664, acc: 0.9333333373069763)
[2025-02-04 02:45:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19260/23838 [08:52<26:45,  2.85it/s][2025-02-04 02:45:41][root][INFO] - Training Epoch: 2/2, step 19259/23838 completed (loss: 0.1919548064470291, acc: 0.9512194991111755)
[2025-02-04 02:45:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19261/23838 [08:52<26:45,  2.85it/s][2025-02-04 02:45:42][root][INFO] - Training Epoch: 2/2, step 19260/23838 completed (loss: 0.8921059370040894, acc: 0.7627118825912476)
[2025-02-04 02:45:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19262/23838 [08:53<26:41,  2.86it/s][2025-02-04 02:45:42][root][INFO] - Training Epoch: 2/2, step 19261/23838 completed (loss: 0.5867390632629395, acc: 0.8125)
[2025-02-04 02:45:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19263/23838 [08:53<27:07,  2.81it/s][2025-02-04 02:45:42][root][INFO] - Training Epoch: 2/2, step 19262/23838 completed (loss: 0.7802695631980896, acc: 0.8100000023841858)
[2025-02-04 02:45:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19264/23838 [08:53<27:00,  2.82it/s][2025-02-04 02:45:43][root][INFO] - Training Epoch: 2/2, step 19263/23838 completed (loss: 0.3596818149089813, acc: 0.9115646481513977)
[2025-02-04 02:45:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19265/23838 [08:54<27:32,  2.77it/s][2025-02-04 02:45:43][root][INFO] - Training Epoch: 2/2, step 19264/23838 completed (loss: 0.1348225176334381, acc: 0.9482758641242981)
[2025-02-04 02:45:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19266/23838 [08:54<29:22,  2.59it/s][2025-02-04 02:45:44][root][INFO] - Training Epoch: 2/2, step 19265/23838 completed (loss: 0.3699568510055542, acc: 0.8802083134651184)
[2025-02-04 02:45:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19267/23838 [08:54<29:47,  2.56it/s][2025-02-04 02:45:44][root][INFO] - Training Epoch: 2/2, step 19266/23838 completed (loss: 0.3336942493915558, acc: 0.8735632300376892)
[2025-02-04 02:45:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19268/23838 [08:55<31:31,  2.42it/s][2025-02-04 02:45:45][root][INFO] - Training Epoch: 2/2, step 19267/23838 completed (loss: 0.06770458817481995, acc: 0.9793814420700073)
[2025-02-04 02:45:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19269/23838 [08:55<31:19,  2.43it/s][2025-02-04 02:45:45][root][INFO] - Training Epoch: 2/2, step 19268/23838 completed (loss: 0.2204463630914688, acc: 0.9347826242446899)
[2025-02-04 02:45:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19270/23838 [08:56<31:35,  2.41it/s][2025-02-04 02:45:45][root][INFO] - Training Epoch: 2/2, step 19269/23838 completed (loss: 0.24463416635990143, acc: 0.942307710647583)
[2025-02-04 02:45:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19271/23838 [08:56<31:43,  2.40it/s][2025-02-04 02:45:46][root][INFO] - Training Epoch: 2/2, step 19270/23838 completed (loss: 0.17733538150787354, acc: 0.945652186870575)
[2025-02-04 02:45:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19272/23838 [08:57<32:46,  2.32it/s][2025-02-04 02:45:46][root][INFO] - Training Epoch: 2/2, step 19271/23838 completed (loss: 0.13893064856529236, acc: 0.949999988079071)
[2025-02-04 02:45:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19273/23838 [08:57<30:17,  2.51it/s][2025-02-04 02:45:47][root][INFO] - Training Epoch: 2/2, step 19272/23838 completed (loss: 0.2282290756702423, acc: 0.930232584476471)
[2025-02-04 02:45:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19274/23838 [08:57<29:13,  2.60it/s][2025-02-04 02:45:47][root][INFO] - Training Epoch: 2/2, step 19273/23838 completed (loss: 0.14818662405014038, acc: 0.9659090638160706)
[2025-02-04 02:45:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19275/23838 [08:58<29:05,  2.61it/s][2025-02-04 02:45:47][root][INFO] - Training Epoch: 2/2, step 19274/23838 completed (loss: 0.4143296778202057, acc: 0.9012345671653748)
[2025-02-04 02:45:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19276/23838 [08:58<30:26,  2.50it/s][2025-02-04 02:45:48][root][INFO] - Training Epoch: 2/2, step 19275/23838 completed (loss: 0.09194308519363403, acc: 0.9684210419654846)
[2025-02-04 02:45:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19277/23838 [08:59<31:06,  2.44it/s][2025-02-04 02:45:48][root][INFO] - Training Epoch: 2/2, step 19276/23838 completed (loss: 0.4976538121700287, acc: 0.8684210777282715)
[2025-02-04 02:45:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19278/23838 [08:59<33:45,  2.25it/s][2025-02-04 02:45:49][root][INFO] - Training Epoch: 2/2, step 19277/23838 completed (loss: 0.33443573117256165, acc: 0.9120879173278809)
[2025-02-04 02:45:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19279/23838 [09:00<34:12,  2.22it/s][2025-02-04 02:45:49][root][INFO] - Training Epoch: 2/2, step 19278/23838 completed (loss: 0.21406641602516174, acc: 0.9333333373069763)
[2025-02-04 02:45:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19280/23838 [09:00<34:39,  2.19it/s][2025-02-04 02:45:50][root][INFO] - Training Epoch: 2/2, step 19279/23838 completed (loss: 0.1260962039232254, acc: 0.9567901492118835)
[2025-02-04 02:45:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19281/23838 [09:00<34:04,  2.23it/s][2025-02-04 02:45:50][root][INFO] - Training Epoch: 2/2, step 19280/23838 completed (loss: 0.15215247869491577, acc: 0.9803921580314636)
[2025-02-04 02:45:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19282/23838 [09:01<32:49,  2.31it/s][2025-02-04 02:45:50][root][INFO] - Training Epoch: 2/2, step 19281/23838 completed (loss: 0.11848783493041992, acc: 0.9838709831237793)
[2025-02-04 02:45:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19283/23838 [09:01<30:03,  2.53it/s][2025-02-04 02:45:51][root][INFO] - Training Epoch: 2/2, step 19282/23838 completed (loss: 0.1242581233382225, acc: 0.9593495726585388)
[2025-02-04 02:45:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19284/23838 [09:02<31:08,  2.44it/s][2025-02-04 02:45:51][root][INFO] - Training Epoch: 2/2, step 19283/23838 completed (loss: 0.21006886661052704, acc: 0.9398496150970459)
[2025-02-04 02:45:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19285/23838 [09:02<28:46,  2.64it/s][2025-02-04 02:45:52][root][INFO] - Training Epoch: 2/2, step 19284/23838 completed (loss: 0.026592347770929337, acc: 0.987500011920929)
[2025-02-04 02:45:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19286/23838 [09:02<26:48,  2.83it/s][2025-02-04 02:45:52][root][INFO] - Training Epoch: 2/2, step 19285/23838 completed (loss: 0.08004085719585419, acc: 0.9649122953414917)
[2025-02-04 02:45:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19287/23838 [09:02<25:01,  3.03it/s][2025-02-04 02:45:52][root][INFO] - Training Epoch: 2/2, step 19286/23838 completed (loss: 0.02323279157280922, acc: 1.0)
[2025-02-04 02:45:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19288/23838 [09:03<25:01,  3.03it/s][2025-02-04 02:45:52][root][INFO] - Training Epoch: 2/2, step 19287/23838 completed (loss: 0.0411982387304306, acc: 0.9904761910438538)
[2025-02-04 02:45:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19289/23838 [09:03<26:18,  2.88it/s][2025-02-04 02:45:53][root][INFO] - Training Epoch: 2/2, step 19288/23838 completed (loss: 0.13299691677093506, acc: 0.9852941036224365)
[2025-02-04 02:45:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19290/23838 [09:04<27:11,  2.79it/s][2025-02-04 02:45:53][root][INFO] - Training Epoch: 2/2, step 19289/23838 completed (loss: 0.12136740237474442, acc: 0.9661017060279846)
[2025-02-04 02:45:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19291/23838 [09:04<26:38,  2.84it/s][2025-02-04 02:45:54][root][INFO] - Training Epoch: 2/2, step 19290/23838 completed (loss: 0.14905384182929993, acc: 0.969072163105011)
[2025-02-04 02:45:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19292/23838 [09:04<27:03,  2.80it/s][2025-02-04 02:45:54][root][INFO] - Training Epoch: 2/2, step 19291/23838 completed (loss: 0.16024157404899597, acc: 0.9594594836235046)
[2025-02-04 02:45:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19293/23838 [09:05<26:51,  2.82it/s][2025-02-04 02:45:54][root][INFO] - Training Epoch: 2/2, step 19292/23838 completed (loss: 0.09810653328895569, acc: 0.9765625)
[2025-02-04 02:45:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19294/23838 [09:05<27:55,  2.71it/s][2025-02-04 02:45:55][root][INFO] - Training Epoch: 2/2, step 19293/23838 completed (loss: 0.05253985896706581, acc: 0.9789473414421082)
[2025-02-04 02:45:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19295/23838 [09:05<25:59,  2.91it/s][2025-02-04 02:45:55][root][INFO] - Training Epoch: 2/2, step 19294/23838 completed (loss: 0.08160480111837387, acc: 0.9716312289237976)
[2025-02-04 02:45:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19296/23838 [09:06<26:19,  2.88it/s][2025-02-04 02:45:55][root][INFO] - Training Epoch: 2/2, step 19295/23838 completed (loss: 0.15858522057533264, acc: 0.9662162065505981)
[2025-02-04 02:45:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19297/23838 [09:06<26:41,  2.84it/s][2025-02-04 02:45:56][root][INFO] - Training Epoch: 2/2, step 19296/23838 completed (loss: 0.1557268351316452, acc: 0.9714285731315613)
[2025-02-04 02:45:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19298/23838 [09:06<26:12,  2.89it/s][2025-02-04 02:45:56][root][INFO] - Training Epoch: 2/2, step 19297/23838 completed (loss: 0.18437913060188293, acc: 0.9624999761581421)
[2025-02-04 02:45:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19299/23838 [09:07<25:49,  2.93it/s][2025-02-04 02:45:56][root][INFO] - Training Epoch: 2/2, step 19298/23838 completed (loss: 0.0616861991584301, acc: 0.9803921580314636)
[2025-02-04 02:45:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19300/23838 [09:07<25:35,  2.96it/s][2025-02-04 02:45:57][root][INFO] - Training Epoch: 2/2, step 19299/23838 completed (loss: 0.007748127449303865, acc: 1.0)
[2025-02-04 02:45:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19301/23838 [09:07<25:12,  3.00it/s][2025-02-04 02:45:57][root][INFO] - Training Epoch: 2/2, step 19300/23838 completed (loss: 0.046692755073308945, acc: 0.9906542301177979)
[2025-02-04 02:45:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19302/23838 [09:08<25:46,  2.93it/s][2025-02-04 02:45:57][root][INFO] - Training Epoch: 2/2, step 19301/23838 completed (loss: 0.26675620675086975, acc: 0.9142857193946838)
[2025-02-04 02:45:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19303/23838 [09:08<25:26,  2.97it/s][2025-02-04 02:45:58][root][INFO] - Training Epoch: 2/2, step 19302/23838 completed (loss: 0.48653122782707214, acc: 0.8541666865348816)
[2025-02-04 02:45:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19304/23838 [09:08<26:31,  2.85it/s][2025-02-04 02:45:58][root][INFO] - Training Epoch: 2/2, step 19303/23838 completed (loss: 0.025833532214164734, acc: 0.989130437374115)
[2025-02-04 02:45:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19305/23838 [09:09<25:21,  2.98it/s][2025-02-04 02:45:58][root][INFO] - Training Epoch: 2/2, step 19304/23838 completed (loss: 0.37768417596817017, acc: 0.9032257795333862)
[2025-02-04 02:45:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19306/23838 [09:09<25:28,  2.97it/s][2025-02-04 02:45:59][root][INFO] - Training Epoch: 2/2, step 19305/23838 completed (loss: 0.038940317928791046, acc: 1.0)
[2025-02-04 02:45:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19307/23838 [09:09<25:53,  2.92it/s][2025-02-04 02:45:59][root][INFO] - Training Epoch: 2/2, step 19306/23838 completed (loss: 0.07596074044704437, acc: 0.9708737730979919)
[2025-02-04 02:45:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19308/23838 [09:10<25:12,  2.99it/s][2025-02-04 02:45:59][root][INFO] - Training Epoch: 2/2, step 19307/23838 completed (loss: 0.017239974811673164, acc: 1.0)
[2025-02-04 02:45:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19309/23838 [09:10<24:15,  3.11it/s][2025-02-04 02:46:00][root][INFO] - Training Epoch: 2/2, step 19308/23838 completed (loss: 0.15278780460357666, acc: 0.9516128897666931)
[2025-02-04 02:46:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19310/23838 [09:10<25:19,  2.98it/s][2025-02-04 02:46:00][root][INFO] - Training Epoch: 2/2, step 19309/23838 completed (loss: 0.14780817925930023, acc: 0.9722222089767456)
[2025-02-04 02:46:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19311/23838 [09:11<24:09,  3.12it/s][2025-02-04 02:46:00][root][INFO] - Training Epoch: 2/2, step 19310/23838 completed (loss: 0.13452592492103577, acc: 0.9846153855323792)
[2025-02-04 02:46:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19312/23838 [09:11<23:31,  3.21it/s][2025-02-04 02:46:01][root][INFO] - Training Epoch: 2/2, step 19311/23838 completed (loss: 0.01234150305390358, acc: 1.0)
[2025-02-04 02:46:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19313/23838 [09:11<23:36,  3.19it/s][2025-02-04 02:46:01][root][INFO] - Training Epoch: 2/2, step 19312/23838 completed (loss: 0.09241166710853577, acc: 0.9729729890823364)
[2025-02-04 02:46:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19314/23838 [09:12<31:50,  2.37it/s][2025-02-04 02:46:02][root][INFO] - Training Epoch: 2/2, step 19313/23838 completed (loss: 0.051135070621967316, acc: 0.9904305934906006)
[2025-02-04 02:46:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19315/23838 [09:12<29:43,  2.54it/s][2025-02-04 02:46:02][root][INFO] - Training Epoch: 2/2, step 19314/23838 completed (loss: 0.038760676980018616, acc: 0.9912280440330505)
[2025-02-04 02:46:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19316/23838 [09:13<28:59,  2.60it/s][2025-02-04 02:46:02][root][INFO] - Training Epoch: 2/2, step 19315/23838 completed (loss: 0.20204214751720428, acc: 0.940397322177887)
[2025-02-04 02:46:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19317/23838 [09:13<26:08,  2.88it/s][2025-02-04 02:46:03][root][INFO] - Training Epoch: 2/2, step 19316/23838 completed (loss: 0.10785538703203201, acc: 0.9701492786407471)
[2025-02-04 02:46:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19318/23838 [09:13<27:45,  2.71it/s][2025-02-04 02:46:03][root][INFO] - Training Epoch: 2/2, step 19317/23838 completed (loss: 0.09165474772453308, acc: 0.9693877696990967)
[2025-02-04 02:46:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19319/23838 [09:14<26:58,  2.79it/s][2025-02-04 02:46:03][root][INFO] - Training Epoch: 2/2, step 19318/23838 completed (loss: 0.007257661782205105, acc: 1.0)
[2025-02-04 02:46:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19320/23838 [09:14<28:52,  2.61it/s][2025-02-04 02:46:04][root][INFO] - Training Epoch: 2/2, step 19319/23838 completed (loss: 0.11488422751426697, acc: 0.9700000286102295)
[2025-02-04 02:46:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19321/23838 [09:14<28:39,  2.63it/s][2025-02-04 02:46:04][root][INFO] - Training Epoch: 2/2, step 19320/23838 completed (loss: 0.010288351215422153, acc: 1.0)
[2025-02-04 02:46:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19322/23838 [09:15<28:01,  2.69it/s][2025-02-04 02:46:04][root][INFO] - Training Epoch: 2/2, step 19321/23838 completed (loss: 0.02802371419966221, acc: 1.0)
[2025-02-04 02:46:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19323/23838 [09:15<28:43,  2.62it/s][2025-02-04 02:46:05][root][INFO] - Training Epoch: 2/2, step 19322/23838 completed (loss: 0.07916706055402756, acc: 0.9848484992980957)
[2025-02-04 02:46:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19324/23838 [09:16<29:05,  2.59it/s][2025-02-04 02:46:05][root][INFO] - Training Epoch: 2/2, step 19323/23838 completed (loss: 0.12366518378257751, acc: 0.9818181991577148)
[2025-02-04 02:46:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19325/23838 [09:16<28:30,  2.64it/s][2025-02-04 02:46:06][root][INFO] - Training Epoch: 2/2, step 19324/23838 completed (loss: 0.44507721066474915, acc: 0.9411764740943909)
[2025-02-04 02:46:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19326/23838 [09:16<28:46,  2.61it/s][2025-02-04 02:46:06][root][INFO] - Training Epoch: 2/2, step 19325/23838 completed (loss: 0.16344082355499268, acc: 0.9583333134651184)
[2025-02-04 02:46:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19327/23838 [09:17<29:27,  2.55it/s][2025-02-04 02:46:06][root][INFO] - Training Epoch: 2/2, step 19326/23838 completed (loss: 0.18910562992095947, acc: 0.96875)
[2025-02-04 02:46:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19328/23838 [09:17<28:22,  2.65it/s][2025-02-04 02:46:07][root][INFO] - Training Epoch: 2/2, step 19327/23838 completed (loss: 0.41544026136398315, acc: 0.8775510191917419)
[2025-02-04 02:46:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19329/23838 [09:17<27:00,  2.78it/s][2025-02-04 02:46:07][root][INFO] - Training Epoch: 2/2, step 19328/23838 completed (loss: 0.3802010118961334, acc: 0.8928571343421936)
[2025-02-04 02:46:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19330/23838 [09:18<26:17,  2.86it/s][2025-02-04 02:46:07][root][INFO] - Training Epoch: 2/2, step 19329/23838 completed (loss: 0.36117666959762573, acc: 0.9047619104385376)
[2025-02-04 02:46:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19331/23838 [09:18<26:23,  2.85it/s][2025-02-04 02:46:08][root][INFO] - Training Epoch: 2/2, step 19330/23838 completed (loss: 0.22846464812755585, acc: 0.8947368264198303)
[2025-02-04 02:46:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19332/23838 [09:18<25:19,  2.96it/s][2025-02-04 02:46:08][root][INFO] - Training Epoch: 2/2, step 19331/23838 completed (loss: 0.8816394805908203, acc: 0.7692307829856873)
[2025-02-04 02:46:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19333/23838 [09:19<25:42,  2.92it/s][2025-02-04 02:46:08][root][INFO] - Training Epoch: 2/2, step 19332/23838 completed (loss: 0.5389686226844788, acc: 0.8333333134651184)
[2025-02-04 02:46:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19334/23838 [09:19<25:06,  2.99it/s][2025-02-04 02:46:09][root][INFO] - Training Epoch: 2/2, step 19333/23838 completed (loss: 0.2545574903488159, acc: 0.9318181872367859)
[2025-02-04 02:46:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19335/23838 [09:19<23:30,  3.19it/s][2025-02-04 02:46:09][root][INFO] - Training Epoch: 2/2, step 19334/23838 completed (loss: 0.44951504468917847, acc: 0.8846153616905212)
[2025-02-04 02:46:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19336/23838 [09:20<23:56,  3.13it/s][2025-02-04 02:46:09][root][INFO] - Training Epoch: 2/2, step 19335/23838 completed (loss: 0.32418110966682434, acc: 0.8260869383811951)
[2025-02-04 02:46:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19337/23838 [09:20<24:32,  3.06it/s][2025-02-04 02:46:10][root][INFO] - Training Epoch: 2/2, step 19336/23838 completed (loss: 0.502593457698822, acc: 0.8548387289047241)
[2025-02-04 02:46:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19338/23838 [09:20<25:13,  2.97it/s][2025-02-04 02:46:10][root][INFO] - Training Epoch: 2/2, step 19337/23838 completed (loss: 0.6139543056488037, acc: 0.8857142925262451)
[2025-02-04 02:46:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19339/23838 [09:21<25:37,  2.93it/s][2025-02-04 02:46:10][root][INFO] - Training Epoch: 2/2, step 19338/23838 completed (loss: 0.22460487484931946, acc: 0.9285714030265808)
[2025-02-04 02:46:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19340/23838 [09:21<26:08,  2.87it/s][2025-02-04 02:46:11][root][INFO] - Training Epoch: 2/2, step 19339/23838 completed (loss: 0.8736993670463562, acc: 0.6764705777168274)
[2025-02-04 02:46:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19341/23838 [09:21<25:49,  2.90it/s][2025-02-04 02:46:11][root][INFO] - Training Epoch: 2/2, step 19340/23838 completed (loss: 0.4722888767719269, acc: 0.8846153616905212)
[2025-02-04 02:46:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19342/23838 [09:22<26:04,  2.87it/s][2025-02-04 02:46:11][root][INFO] - Training Epoch: 2/2, step 19341/23838 completed (loss: 0.3954048156738281, acc: 0.875)
[2025-02-04 02:46:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19343/23838 [09:22<26:13,  2.86it/s][2025-02-04 02:46:12][root][INFO] - Training Epoch: 2/2, step 19342/23838 completed (loss: 0.9577817320823669, acc: 0.7857142686843872)
[2025-02-04 02:46:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19344/23838 [09:23<26:04,  2.87it/s][2025-02-04 02:46:12][root][INFO] - Training Epoch: 2/2, step 19343/23838 completed (loss: 0.5400629639625549, acc: 0.8846153616905212)
[2025-02-04 02:46:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19345/23838 [09:23<26:32,  2.82it/s][2025-02-04 02:46:12][root][INFO] - Training Epoch: 2/2, step 19344/23838 completed (loss: 0.251272976398468, acc: 0.9210526347160339)
[2025-02-04 02:46:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19346/23838 [09:23<26:12,  2.86it/s][2025-02-04 02:46:13][root][INFO] - Training Epoch: 2/2, step 19345/23838 completed (loss: 0.2400049865245819, acc: 0.949999988079071)
[2025-02-04 02:46:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19347/23838 [09:24<24:28,  3.06it/s][2025-02-04 02:46:13][root][INFO] - Training Epoch: 2/2, step 19346/23838 completed (loss: 0.2699556052684784, acc: 0.932584285736084)
[2025-02-04 02:46:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19348/23838 [09:24<25:00,  2.99it/s][2025-02-04 02:46:13][root][INFO] - Training Epoch: 2/2, step 19347/23838 completed (loss: 0.5425753593444824, acc: 0.8425925970077515)
[2025-02-04 02:46:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19349/23838 [09:24<26:12,  2.85it/s][2025-02-04 02:46:14][root][INFO] - Training Epoch: 2/2, step 19348/23838 completed (loss: 0.11847743391990662, acc: 0.9636363387107849)
[2025-02-04 02:46:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19350/23838 [09:25<28:00,  2.67it/s][2025-02-04 02:46:14][root][INFO] - Training Epoch: 2/2, step 19349/23838 completed (loss: 0.14043310284614563, acc: 0.9615384340286255)
[2025-02-04 02:46:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19351/23838 [09:25<28:04,  2.66it/s][2025-02-04 02:46:15][root][INFO] - Training Epoch: 2/2, step 19350/23838 completed (loss: 0.29600414633750916, acc: 0.914893627166748)
[2025-02-04 02:46:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19352/23838 [09:25<27:08,  2.75it/s][2025-02-04 02:46:15][root][INFO] - Training Epoch: 2/2, step 19351/23838 completed (loss: 0.5344498157501221, acc: 0.8333333134651184)
[2025-02-04 02:46:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19353/23838 [09:26<25:20,  2.95it/s][2025-02-04 02:46:15][root][INFO] - Training Epoch: 2/2, step 19352/23838 completed (loss: 0.20325005054473877, acc: 0.9411764740943909)
[2025-02-04 02:46:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19354/23838 [09:26<25:25,  2.94it/s][2025-02-04 02:46:16][root][INFO] - Training Epoch: 2/2, step 19353/23838 completed (loss: 0.14182987809181213, acc: 1.0)
[2025-02-04 02:46:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19355/23838 [09:26<27:20,  2.73it/s][2025-02-04 02:46:16][root][INFO] - Training Epoch: 2/2, step 19354/23838 completed (loss: 0.2052757889032364, acc: 0.9200000166893005)
[2025-02-04 02:46:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19356/23838 [09:27<25:55,  2.88it/s][2025-02-04 02:46:16][root][INFO] - Training Epoch: 2/2, step 19355/23838 completed (loss: 0.445822149515152, acc: 0.8636363744735718)
[2025-02-04 02:46:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19357/23838 [09:27<26:34,  2.81it/s][2025-02-04 02:46:17][root][INFO] - Training Epoch: 2/2, step 19356/23838 completed (loss: 0.49836841225624084, acc: 0.800000011920929)
[2025-02-04 02:46:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19358/23838 [09:28<27:03,  2.76it/s][2025-02-04 02:46:17][root][INFO] - Training Epoch: 2/2, step 19357/23838 completed (loss: 0.05244946479797363, acc: 1.0)
[2025-02-04 02:46:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19359/23838 [09:28<26:12,  2.85it/s][2025-02-04 02:46:17][root][INFO] - Training Epoch: 2/2, step 19358/23838 completed (loss: 0.14768986403942108, acc: 0.95652174949646)
[2025-02-04 02:46:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19360/23838 [09:28<25:57,  2.87it/s][2025-02-04 02:46:18][root][INFO] - Training Epoch: 2/2, step 19359/23838 completed (loss: 0.13935475051403046, acc: 0.9473684430122375)
[2025-02-04 02:46:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19361/23838 [09:29<26:28,  2.82it/s][2025-02-04 02:46:18][root][INFO] - Training Epoch: 2/2, step 19360/23838 completed (loss: 0.33650296926498413, acc: 0.9230769276618958)
[2025-02-04 02:46:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19362/23838 [09:29<26:28,  2.82it/s][2025-02-04 02:46:18][root][INFO] - Training Epoch: 2/2, step 19361/23838 completed (loss: 0.1373877078294754, acc: 0.9591836929321289)
[2025-02-04 02:46:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19363/23838 [09:29<26:32,  2.81it/s][2025-02-04 02:46:19][root][INFO] - Training Epoch: 2/2, step 19362/23838 completed (loss: 0.33527377247810364, acc: 0.8793103694915771)
[2025-02-04 02:46:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19364/23838 [09:30<26:26,  2.82it/s][2025-02-04 02:46:19][root][INFO] - Training Epoch: 2/2, step 19363/23838 completed (loss: 1.0965931415557861, acc: 0.6774193644523621)
[2025-02-04 02:46:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19365/23838 [09:30<26:05,  2.86it/s][2025-02-04 02:46:20][root][INFO] - Training Epoch: 2/2, step 19364/23838 completed (loss: 0.9130904078483582, acc: 0.7777777910232544)
[2025-02-04 02:46:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19366/23838 [09:30<26:19,  2.83it/s][2025-02-04 02:46:20][root][INFO] - Training Epoch: 2/2, step 19365/23838 completed (loss: 0.17879751324653625, acc: 0.9347826242446899)
[2025-02-04 02:46:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19367/23838 [09:31<26:51,  2.78it/s][2025-02-04 02:46:20][root][INFO] - Training Epoch: 2/2, step 19366/23838 completed (loss: 0.01678421162068844, acc: 1.0)
[2025-02-04 02:46:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████  [0m| 19368/23838 [09:31<26:19,  2.83it/s][2025-02-04 02:46:21][root][INFO] - Training Epoch: 2/2, step 19367/23838 completed (loss: 0.04432136192917824, acc: 0.976190447807312)
[2025-02-04 02:46:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19369/23838 [09:31<26:47,  2.78it/s][2025-02-04 02:46:21][root][INFO] - Training Epoch: 2/2, step 19368/23838 completed (loss: 0.040654148906469345, acc: 0.9772727489471436)
[2025-02-04 02:46:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19370/23838 [09:32<26:19,  2.83it/s][2025-02-04 02:46:21][root][INFO] - Training Epoch: 2/2, step 19369/23838 completed (loss: 0.023259231820702553, acc: 1.0)
[2025-02-04 02:46:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19371/23838 [09:32<25:48,  2.88it/s][2025-02-04 02:46:22][root][INFO] - Training Epoch: 2/2, step 19370/23838 completed (loss: 0.4686090350151062, acc: 0.8387096524238586)
[2025-02-04 02:46:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19372/23838 [09:32<26:03,  2.86it/s][2025-02-04 02:46:22][root][INFO] - Training Epoch: 2/2, step 19371/23838 completed (loss: 0.06853215396404266, acc: 1.0)
[2025-02-04 02:46:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19373/23838 [09:33<27:07,  2.74it/s][2025-02-04 02:46:22][root][INFO] - Training Epoch: 2/2, step 19372/23838 completed (loss: 0.3026611804962158, acc: 0.9285714030265808)
[2025-02-04 02:46:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19374/23838 [09:33<27:09,  2.74it/s][2025-02-04 02:46:23][root][INFO] - Training Epoch: 2/2, step 19373/23838 completed (loss: 0.10929267108440399, acc: 0.9767441749572754)
[2025-02-04 02:46:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19375/23838 [09:34<27:09,  2.74it/s][2025-02-04 02:46:23][root][INFO] - Training Epoch: 2/2, step 19374/23838 completed (loss: 0.08744767308235168, acc: 1.0)
[2025-02-04 02:46:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19376/23838 [09:34<26:35,  2.80it/s][2025-02-04 02:46:23][root][INFO] - Training Epoch: 2/2, step 19375/23838 completed (loss: 0.636634111404419, acc: 0.8484848737716675)
[2025-02-04 02:46:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19377/23838 [09:34<26:32,  2.80it/s][2025-02-04 02:46:24][root][INFO] - Training Epoch: 2/2, step 19376/23838 completed (loss: 0.5740012526512146, acc: 0.8695651888847351)
[2025-02-04 02:46:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19378/23838 [09:35<25:45,  2.89it/s][2025-02-04 02:46:24][root][INFO] - Training Epoch: 2/2, step 19377/23838 completed (loss: 0.45326483249664307, acc: 0.8947368264198303)
[2025-02-04 02:46:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19379/23838 [09:35<25:26,  2.92it/s][2025-02-04 02:46:24][root][INFO] - Training Epoch: 2/2, step 19378/23838 completed (loss: 0.21241497993469238, acc: 0.9411764740943909)
[2025-02-04 02:46:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19380/23838 [09:35<25:05,  2.96it/s][2025-02-04 02:46:25][root][INFO] - Training Epoch: 2/2, step 19379/23838 completed (loss: 0.3519824743270874, acc: 0.8799999952316284)
[2025-02-04 02:46:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19381/23838 [09:36<24:29,  3.03it/s][2025-02-04 02:46:25][root][INFO] - Training Epoch: 2/2, step 19380/23838 completed (loss: 0.11457132548093796, acc: 0.9428571462631226)
[2025-02-04 02:46:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19382/23838 [09:36<24:48,  2.99it/s][2025-02-04 02:46:25][root][INFO] - Training Epoch: 2/2, step 19381/23838 completed (loss: 0.29468435049057007, acc: 0.9189189076423645)
[2025-02-04 02:46:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19383/23838 [09:36<25:14,  2.94it/s][2025-02-04 02:46:26][root][INFO] - Training Epoch: 2/2, step 19382/23838 completed (loss: 0.3449772596359253, acc: 0.8799999952316284)
[2025-02-04 02:46:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19384/23838 [09:37<25:37,  2.90it/s][2025-02-04 02:46:26][root][INFO] - Training Epoch: 2/2, step 19383/23838 completed (loss: 0.06081373989582062, acc: 0.9838709831237793)
[2025-02-04 02:46:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19385/23838 [09:37<25:44,  2.88it/s][2025-02-04 02:46:27][root][INFO] - Training Epoch: 2/2, step 19384/23838 completed (loss: 0.2873677611351013, acc: 0.9464285969734192)
[2025-02-04 02:46:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19386/23838 [09:37<26:36,  2.79it/s][2025-02-04 02:46:27][root][INFO] - Training Epoch: 2/2, step 19385/23838 completed (loss: 0.005465541500598192, acc: 1.0)
[2025-02-04 02:46:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19387/23838 [09:38<27:04,  2.74it/s][2025-02-04 02:46:27][root][INFO] - Training Epoch: 2/2, step 19386/23838 completed (loss: 0.009893331676721573, acc: 1.0)
[2025-02-04 02:46:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19388/23838 [09:38<27:45,  2.67it/s][2025-02-04 02:46:28][root][INFO] - Training Epoch: 2/2, step 19387/23838 completed (loss: 0.04951309412717819, acc: 0.976190447807312)
[2025-02-04 02:46:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19389/23838 [09:38<27:55,  2.66it/s][2025-02-04 02:46:28][root][INFO] - Training Epoch: 2/2, step 19388/23838 completed (loss: 0.19360831379890442, acc: 0.925000011920929)
[2025-02-04 02:46:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19390/23838 [09:39<26:55,  2.75it/s][2025-02-04 02:46:28][root][INFO] - Training Epoch: 2/2, step 19389/23838 completed (loss: 0.12854185700416565, acc: 0.9772727489471436)
[2025-02-04 02:46:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19391/23838 [09:39<26:40,  2.78it/s][2025-02-04 02:46:29][root][INFO] - Training Epoch: 2/2, step 19390/23838 completed (loss: 0.6607496738433838, acc: 0.7916666865348816)
[2025-02-04 02:46:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19392/23838 [09:40<27:09,  2.73it/s][2025-02-04 02:46:29][root][INFO] - Training Epoch: 2/2, step 19391/23838 completed (loss: 0.23437067866325378, acc: 0.970588207244873)
[2025-02-04 02:46:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19393/23838 [09:40<26:45,  2.77it/s][2025-02-04 02:46:30][root][INFO] - Training Epoch: 2/2, step 19392/23838 completed (loss: 0.3753563463687897, acc: 0.8387096524238586)
[2025-02-04 02:46:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19394/23838 [09:40<27:48,  2.66it/s][2025-02-04 02:46:30][root][INFO] - Training Epoch: 2/2, step 19393/23838 completed (loss: 0.20999573171138763, acc: 0.942307710647583)
[2025-02-04 02:46:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19395/23838 [09:41<27:45,  2.67it/s][2025-02-04 02:46:30][root][INFO] - Training Epoch: 2/2, step 19394/23838 completed (loss: 0.46614572405815125, acc: 0.9166666865348816)
[2025-02-04 02:46:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19396/23838 [09:41<28:23,  2.61it/s][2025-02-04 02:46:31][root][INFO] - Training Epoch: 2/2, step 19395/23838 completed (loss: 0.13789649307727814, acc: 0.9468085169792175)
[2025-02-04 02:46:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19397/23838 [09:42<28:58,  2.55it/s][2025-02-04 02:46:31][root][INFO] - Training Epoch: 2/2, step 19396/23838 completed (loss: 0.31466785073280334, acc: 0.9399999976158142)
[2025-02-04 02:46:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19398/23838 [09:42<28:40,  2.58it/s][2025-02-04 02:46:31][root][INFO] - Training Epoch: 2/2, step 19397/23838 completed (loss: 0.6509363651275635, acc: 0.761904776096344)
[2025-02-04 02:46:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19399/23838 [09:42<27:53,  2.65it/s][2025-02-04 02:46:32][root][INFO] - Training Epoch: 2/2, step 19398/23838 completed (loss: 0.8890554308891296, acc: 0.8157894611358643)
[2025-02-04 02:46:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19400/23838 [09:43<28:07,  2.63it/s][2025-02-04 02:46:32][root][INFO] - Training Epoch: 2/2, step 19399/23838 completed (loss: 0.4048632085323334, acc: 0.9024389982223511)
[2025-02-04 02:46:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19401/23838 [09:43<27:27,  2.69it/s][2025-02-04 02:46:33][root][INFO] - Training Epoch: 2/2, step 19400/23838 completed (loss: 0.06823796033859253, acc: 1.0)
[2025-02-04 02:46:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19402/23838 [09:43<26:37,  2.78it/s][2025-02-04 02:46:33][root][INFO] - Training Epoch: 2/2, step 19401/23838 completed (loss: 0.23640967905521393, acc: 0.90625)
[2025-02-04 02:46:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19403/23838 [09:44<26:20,  2.81it/s][2025-02-04 02:46:33][root][INFO] - Training Epoch: 2/2, step 19402/23838 completed (loss: 0.8947122693061829, acc: 0.8095238208770752)
[2025-02-04 02:46:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19404/23838 [09:44<28:02,  2.64it/s][2025-02-04 02:46:34][root][INFO] - Training Epoch: 2/2, step 19403/23838 completed (loss: 0.6231385469436646, acc: 0.8607594966888428)
[2025-02-04 02:46:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19405/23838 [09:44<28:27,  2.60it/s][2025-02-04 02:46:34][root][INFO] - Training Epoch: 2/2, step 19404/23838 completed (loss: 0.20047780871391296, acc: 0.95652174949646)
[2025-02-04 02:46:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19406/23838 [09:45<27:43,  2.66it/s][2025-02-04 02:46:34][root][INFO] - Training Epoch: 2/2, step 19405/23838 completed (loss: 0.5845091938972473, acc: 0.800000011920929)
[2025-02-04 02:46:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19407/23838 [09:45<26:54,  2.74it/s][2025-02-04 02:46:35][root][INFO] - Training Epoch: 2/2, step 19406/23838 completed (loss: 0.4344213008880615, acc: 0.8684210777282715)
[2025-02-04 02:46:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19408/23838 [09:46<26:54,  2.74it/s][2025-02-04 02:46:35][root][INFO] - Training Epoch: 2/2, step 19407/23838 completed (loss: 0.0799517035484314, acc: 1.0)
[2025-02-04 02:46:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19409/23838 [09:46<26:39,  2.77it/s][2025-02-04 02:46:35][root][INFO] - Training Epoch: 2/2, step 19408/23838 completed (loss: 0.27724578976631165, acc: 0.931034505367279)
[2025-02-04 02:46:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19410/23838 [09:46<25:03,  2.95it/s][2025-02-04 02:46:36][root][INFO] - Training Epoch: 2/2, step 19409/23838 completed (loss: 0.39082637429237366, acc: 0.9032257795333862)
[2025-02-04 02:46:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19411/23838 [09:47<25:20,  2.91it/s][2025-02-04 02:46:36][root][INFO] - Training Epoch: 2/2, step 19410/23838 completed (loss: 0.9231229424476624, acc: 0.7428571581840515)
[2025-02-04 02:46:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19412/23838 [09:47<26:54,  2.74it/s][2025-02-04 02:46:37][root][INFO] - Training Epoch: 2/2, step 19411/23838 completed (loss: 0.5843929648399353, acc: 0.8484848737716675)
[2025-02-04 02:46:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19413/23838 [09:47<26:33,  2.78it/s][2025-02-04 02:46:37][root][INFO] - Training Epoch: 2/2, step 19412/23838 completed (loss: 0.18375426530838013, acc: 0.9736841917037964)
[2025-02-04 02:46:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19414/23838 [09:48<26:32,  2.78it/s][2025-02-04 02:46:37][root][INFO] - Training Epoch: 2/2, step 19413/23838 completed (loss: 0.11006905138492584, acc: 0.9629629850387573)
[2025-02-04 02:46:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19415/23838 [09:48<26:04,  2.83it/s][2025-02-04 02:46:38][root][INFO] - Training Epoch: 2/2, step 19414/23838 completed (loss: 0.274959921836853, acc: 0.9090909361839294)
[2025-02-04 02:46:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19416/23838 [09:48<25:43,  2.87it/s][2025-02-04 02:46:38][root][INFO] - Training Epoch: 2/2, step 19415/23838 completed (loss: 0.4307776391506195, acc: 0.8648648858070374)
[2025-02-04 02:46:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19417/23838 [09:49<25:52,  2.85it/s][2025-02-04 02:46:38][root][INFO] - Training Epoch: 2/2, step 19416/23838 completed (loss: 0.11532631516456604, acc: 0.970588207244873)
[2025-02-04 02:46:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19418/23838 [09:49<27:01,  2.73it/s][2025-02-04 02:46:39][root][INFO] - Training Epoch: 2/2, step 19417/23838 completed (loss: 0.07370644062757492, acc: 0.9821428656578064)
[2025-02-04 02:46:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19419/23838 [09:49<26:54,  2.74it/s][2025-02-04 02:46:39][root][INFO] - Training Epoch: 2/2, step 19418/23838 completed (loss: 0.09276584535837173, acc: 0.9523809552192688)
[2025-02-04 02:46:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19420/23838 [09:50<25:58,  2.83it/s][2025-02-04 02:46:39][root][INFO] - Training Epoch: 2/2, step 19419/23838 completed (loss: 0.2862606644630432, acc: 0.8918918967247009)
[2025-02-04 02:46:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19421/23838 [09:50<28:56,  2.54it/s][2025-02-04 02:46:40][root][INFO] - Training Epoch: 2/2, step 19420/23838 completed (loss: 0.4206676185131073, acc: 0.8826530575752258)
[2025-02-04 02:46:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19422/23838 [09:51<28:33,  2.58it/s][2025-02-04 02:46:40][root][INFO] - Training Epoch: 2/2, step 19421/23838 completed (loss: 0.2724066376686096, acc: 0.9375)
[2025-02-04 02:46:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19423/23838 [09:51<27:50,  2.64it/s][2025-02-04 02:46:41][root][INFO] - Training Epoch: 2/2, step 19422/23838 completed (loss: 0.3255648910999298, acc: 0.9126213788986206)
[2025-02-04 02:46:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19424/23838 [09:51<28:17,  2.60it/s][2025-02-04 02:46:41][root][INFO] - Training Epoch: 2/2, step 19423/23838 completed (loss: 0.19637438654899597, acc: 0.9417475461959839)
[2025-02-04 02:46:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19425/23838 [09:52<29:30,  2.49it/s][2025-02-04 02:46:41][root][INFO] - Training Epoch: 2/2, step 19424/23838 completed (loss: 0.3630180358886719, acc: 0.8958333134651184)
[2025-02-04 02:46:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19426/23838 [09:52<29:02,  2.53it/s][2025-02-04 02:46:42][root][INFO] - Training Epoch: 2/2, step 19425/23838 completed (loss: 0.1867457628250122, acc: 0.9375)
[2025-02-04 02:46:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  81%|[34m████████▏ [0m| 19427/23838 [09:53<27:53,  2.64it/s][2025-02-04 02:46:42][root][INFO] - Training Epoch: 2/2, step 19426/23838 completed (loss: 0.4920502305030823, acc: 0.8607594966888428)
[2025-02-04 02:46:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19428/23838 [09:53<28:15,  2.60it/s][2025-02-04 02:46:43][root][INFO] - Training Epoch: 2/2, step 19427/23838 completed (loss: 0.3006150424480438, acc: 0.9464285969734192)
[2025-02-04 02:46:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19429/23838 [09:53<31:16,  2.35it/s][2025-02-04 02:46:43][root][INFO] - Training Epoch: 2/2, step 19428/23838 completed (loss: 0.28698283433914185, acc: 0.912162184715271)
[2025-02-04 02:46:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19430/23838 [09:54<32:05,  2.29it/s][2025-02-04 02:46:44][root][INFO] - Training Epoch: 2/2, step 19429/23838 completed (loss: 0.3245803415775299, acc: 0.9127516746520996)
[2025-02-04 02:46:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19431/23838 [09:55<36:38,  2.00it/s][2025-02-04 02:46:44][root][INFO] - Training Epoch: 2/2, step 19430/23838 completed (loss: 0.2680164575576782, acc: 0.906862735748291)
[2025-02-04 02:46:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19432/23838 [09:55<33:37,  2.18it/s][2025-02-04 02:46:45][root][INFO] - Training Epoch: 2/2, step 19431/23838 completed (loss: 0.2704159617424011, acc: 0.9193548560142517)
[2025-02-04 02:46:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19433/23838 [09:55<31:14,  2.35it/s][2025-02-04 02:46:45][root][INFO] - Training Epoch: 2/2, step 19432/23838 completed (loss: 0.6221171617507935, acc: 0.8586956262588501)
[2025-02-04 02:46:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19434/23838 [09:56<30:06,  2.44it/s][2025-02-04 02:46:45][root][INFO] - Training Epoch: 2/2, step 19433/23838 completed (loss: 1.029376745223999, acc: 0.7241379022598267)
[2025-02-04 02:46:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19435/23838 [09:56<28:20,  2.59it/s][2025-02-04 02:46:46][root][INFO] - Training Epoch: 2/2, step 19434/23838 completed (loss: 0.849886953830719, acc: 0.8333333134651184)
[2025-02-04 02:46:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19436/23838 [09:56<28:00,  2.62it/s][2025-02-04 02:46:46][root][INFO] - Training Epoch: 2/2, step 19435/23838 completed (loss: 0.3498243987560272, acc: 0.8769230842590332)
[2025-02-04 02:46:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19437/23838 [09:57<26:57,  2.72it/s][2025-02-04 02:46:46][root][INFO] - Training Epoch: 2/2, step 19436/23838 completed (loss: 0.44670960307121277, acc: 0.9047619104385376)
[2025-02-04 02:46:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19438/23838 [09:57<26:22,  2.78it/s][2025-02-04 02:46:47][root][INFO] - Training Epoch: 2/2, step 19437/23838 completed (loss: 0.8097595572471619, acc: 0.75)
[2025-02-04 02:46:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19439/23838 [09:57<27:05,  2.71it/s][2025-02-04 02:46:47][root][INFO] - Training Epoch: 2/2, step 19438/23838 completed (loss: 0.3094404339790344, acc: 0.929411768913269)
[2025-02-04 02:46:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19440/23838 [09:58<26:53,  2.73it/s][2025-02-04 02:46:47][root][INFO] - Training Epoch: 2/2, step 19439/23838 completed (loss: 0.25836482644081116, acc: 0.9350649118423462)
[2025-02-04 02:46:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19441/23838 [09:58<26:21,  2.78it/s][2025-02-04 02:46:48][root][INFO] - Training Epoch: 2/2, step 19440/23838 completed (loss: 0.36844760179519653, acc: 0.8928571343421936)
[2025-02-04 02:46:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19442/23838 [09:58<25:45,  2.84it/s][2025-02-04 02:46:48][root][INFO] - Training Epoch: 2/2, step 19441/23838 completed (loss: 0.5701913237571716, acc: 0.8307692408561707)
[2025-02-04 02:46:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19443/23838 [09:59<28:17,  2.59it/s][2025-02-04 02:46:49][root][INFO] - Training Epoch: 2/2, step 19442/23838 completed (loss: 0.35992664098739624, acc: 0.8969696760177612)
[2025-02-04 02:46:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19444/23838 [09:59<30:26,  2.41it/s][2025-02-04 02:46:49][root][INFO] - Training Epoch: 2/2, step 19443/23838 completed (loss: 0.8174363970756531, acc: 0.75)
[2025-02-04 02:46:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19445/23838 [10:00<29:02,  2.52it/s][2025-02-04 02:46:49][root][INFO] - Training Epoch: 2/2, step 19444/23838 completed (loss: 0.460583359003067, acc: 0.8620689511299133)
[2025-02-04 02:46:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19446/23838 [10:00<33:06,  2.21it/s][2025-02-04 02:46:50][root][INFO] - Training Epoch: 2/2, step 19445/23838 completed (loss: 0.9089710116386414, acc: 0.7603305578231812)
[2025-02-04 02:46:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19447/23838 [10:01<30:45,  2.38it/s][2025-02-04 02:46:50][root][INFO] - Training Epoch: 2/2, step 19446/23838 completed (loss: 0.35825416445732117, acc: 0.868852436542511)
[2025-02-04 02:46:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19448/23838 [10:01<31:21,  2.33it/s][2025-02-04 02:46:51][root][INFO] - Training Epoch: 2/2, step 19447/23838 completed (loss: 0.3718496561050415, acc: 0.886956512928009)
[2025-02-04 02:46:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19449/23838 [10:02<31:39,  2.31it/s][2025-02-04 02:46:51][root][INFO] - Training Epoch: 2/2, step 19448/23838 completed (loss: 0.37056964635849, acc: 0.9124087691307068)
[2025-02-04 02:46:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19450/23838 [10:02<30:12,  2.42it/s][2025-02-04 02:46:52][root][INFO] - Training Epoch: 2/2, step 19449/23838 completed (loss: 0.6517703533172607, acc: 0.8701298832893372)
[2025-02-04 02:46:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19451/23838 [10:02<29:48,  2.45it/s][2025-02-04 02:46:52][root][INFO] - Training Epoch: 2/2, step 19450/23838 completed (loss: 0.4146701991558075, acc: 0.8797468543052673)
[2025-02-04 02:46:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19452/23838 [10:03<30:49,  2.37it/s][2025-02-04 02:46:52][root][INFO] - Training Epoch: 2/2, step 19451/23838 completed (loss: 0.4772072732448578, acc: 0.8814814686775208)
[2025-02-04 02:46:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19453/23838 [10:04<36:30,  2.00it/s][2025-02-04 02:46:53][root][INFO] - Training Epoch: 2/2, step 19452/23838 completed (loss: 0.2975899279117584, acc: 0.9354838728904724)
[2025-02-04 02:46:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19454/23838 [10:04<36:03,  2.03it/s][2025-02-04 02:46:54][root][INFO] - Training Epoch: 2/2, step 19453/23838 completed (loss: 0.3857726752758026, acc: 0.8921568393707275)
[2025-02-04 02:46:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19455/23838 [10:04<32:57,  2.22it/s][2025-02-04 02:46:54][root][INFO] - Training Epoch: 2/2, step 19454/23838 completed (loss: 0.49294692277908325, acc: 0.8372092843055725)
[2025-02-04 02:46:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19456/23838 [10:05<31:04,  2.35it/s][2025-02-04 02:46:54][root][INFO] - Training Epoch: 2/2, step 19455/23838 completed (loss: 0.7786310911178589, acc: 0.7575757503509521)
[2025-02-04 02:46:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19457/23838 [10:05<31:02,  2.35it/s][2025-02-04 02:46:55][root][INFO] - Training Epoch: 2/2, step 19456/23838 completed (loss: 0.26834121346473694, acc: 0.924369752407074)
[2025-02-04 02:46:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19458/23838 [10:05<28:55,  2.52it/s][2025-02-04 02:46:55][root][INFO] - Training Epoch: 2/2, step 19457/23838 completed (loss: 0.1100991815328598, acc: 0.970588207244873)
[2025-02-04 02:46:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19459/23838 [10:06<27:28,  2.66it/s][2025-02-04 02:46:55][root][INFO] - Training Epoch: 2/2, step 19458/23838 completed (loss: 0.5171549320220947, acc: 0.875)
[2025-02-04 02:46:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19460/23838 [10:06<27:37,  2.64it/s][2025-02-04 02:46:56][root][INFO] - Training Epoch: 2/2, step 19459/23838 completed (loss: 0.7044903635978699, acc: 0.8285714387893677)
[2025-02-04 02:46:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19461/23838 [10:07<26:47,  2.72it/s][2025-02-04 02:46:56][root][INFO] - Training Epoch: 2/2, step 19460/23838 completed (loss: 0.216886967420578, acc: 0.9107142686843872)
[2025-02-04 02:46:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19462/23838 [10:07<27:39,  2.64it/s][2025-02-04 02:46:57][root][INFO] - Training Epoch: 2/2, step 19461/23838 completed (loss: 0.2480970174074173, acc: 0.921875)
[2025-02-04 02:46:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19463/23838 [10:07<26:51,  2.71it/s][2025-02-04 02:46:57][root][INFO] - Training Epoch: 2/2, step 19462/23838 completed (loss: 0.3251475393772125, acc: 0.9178082346916199)
[2025-02-04 02:46:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19464/23838 [10:08<26:11,  2.78it/s][2025-02-04 02:46:57][root][INFO] - Training Epoch: 2/2, step 19463/23838 completed (loss: 0.5770572423934937, acc: 0.8805969953536987)
[2025-02-04 02:46:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19465/23838 [10:08<27:30,  2.65it/s][2025-02-04 02:46:58][root][INFO] - Training Epoch: 2/2, step 19464/23838 completed (loss: 0.16844645142555237, acc: 0.9367088675498962)
[2025-02-04 02:46:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19466/23838 [10:08<27:42,  2.63it/s][2025-02-04 02:46:58][root][INFO] - Training Epoch: 2/2, step 19465/23838 completed (loss: 0.32796236872673035, acc: 0.9029850959777832)
[2025-02-04 02:46:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19467/23838 [10:09<27:24,  2.66it/s][2025-02-04 02:46:58][root][INFO] - Training Epoch: 2/2, step 19466/23838 completed (loss: 0.09802455455064774, acc: 0.96875)
[2025-02-04 02:46:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19468/23838 [10:09<28:01,  2.60it/s][2025-02-04 02:46:59][root][INFO] - Training Epoch: 2/2, step 19467/23838 completed (loss: 0.21029476821422577, acc: 0.9452054500579834)
[2025-02-04 02:46:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19469/23838 [10:10<26:41,  2.73it/s][2025-02-04 02:46:59][root][INFO] - Training Epoch: 2/2, step 19468/23838 completed (loss: 0.19282428920269012, acc: 0.9292929172515869)
[2025-02-04 02:46:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19470/23838 [10:10<26:23,  2.76it/s][2025-02-04 02:46:59][root][INFO] - Training Epoch: 2/2, step 19469/23838 completed (loss: 0.07841187715530396, acc: 0.9718309640884399)
[2025-02-04 02:47:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19471/23838 [10:10<28:07,  2.59it/s][2025-02-04 02:47:00][root][INFO] - Training Epoch: 2/2, step 19470/23838 completed (loss: 0.34320423007011414, acc: 0.9009009003639221)
[2025-02-04 02:47:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19472/23838 [10:11<27:46,  2.62it/s][2025-02-04 02:47:00][root][INFO] - Training Epoch: 2/2, step 19471/23838 completed (loss: 0.22698257863521576, acc: 0.9512194991111755)
[2025-02-04 02:47:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19473/23838 [10:11<26:40,  2.73it/s][2025-02-04 02:47:01][root][INFO] - Training Epoch: 2/2, step 19472/23838 completed (loss: 0.3767705261707306, acc: 0.886956512928009)
[2025-02-04 02:47:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19474/23838 [10:11<26:00,  2.80it/s][2025-02-04 02:47:01][root][INFO] - Training Epoch: 2/2, step 19473/23838 completed (loss: 0.39457836747169495, acc: 0.8709677457809448)
[2025-02-04 02:47:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19475/23838 [10:12<25:01,  2.91it/s][2025-02-04 02:47:01][root][INFO] - Training Epoch: 2/2, step 19474/23838 completed (loss: 0.3197174370288849, acc: 0.8857142925262451)
[2025-02-04 02:47:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19476/23838 [10:12<24:29,  2.97it/s][2025-02-04 02:47:02][root][INFO] - Training Epoch: 2/2, step 19475/23838 completed (loss: 0.15805445611476898, acc: 0.9318181872367859)
[2025-02-04 02:47:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19477/23838 [10:12<23:21,  3.11it/s][2025-02-04 02:47:02][root][INFO] - Training Epoch: 2/2, step 19476/23838 completed (loss: 0.32112184166908264, acc: 0.8870967626571655)
[2025-02-04 02:47:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19478/23838 [10:13<23:42,  3.06it/s][2025-02-04 02:47:02][root][INFO] - Training Epoch: 2/2, step 19477/23838 completed (loss: 0.3691871166229248, acc: 0.8627451062202454)
[2025-02-04 02:47:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19479/23838 [10:13<23:54,  3.04it/s][2025-02-04 02:47:03][root][INFO] - Training Epoch: 2/2, step 19478/23838 completed (loss: 0.22866930067539215, acc: 0.9462365508079529)
[2025-02-04 02:47:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19480/23838 [10:13<24:33,  2.96it/s][2025-02-04 02:47:03][root][INFO] - Training Epoch: 2/2, step 19479/23838 completed (loss: 0.18488788604736328, acc: 0.982758641242981)
[2025-02-04 02:47:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19481/23838 [10:14<27:02,  2.69it/s][2025-02-04 02:47:03][root][INFO] - Training Epoch: 2/2, step 19480/23838 completed (loss: 0.168121799826622, acc: 0.95652174949646)
[2025-02-04 02:47:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19482/23838 [10:14<27:06,  2.68it/s][2025-02-04 02:47:04][root][INFO] - Training Epoch: 2/2, step 19481/23838 completed (loss: 0.2776526212692261, acc: 0.9300000071525574)
[2025-02-04 02:47:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19483/23838 [10:14<24:54,  2.91it/s][2025-02-04 02:47:04][root][INFO] - Training Epoch: 2/2, step 19482/23838 completed (loss: 0.573030412197113, acc: 0.8529411554336548)
[2025-02-04 02:47:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19484/23838 [10:15<26:01,  2.79it/s][2025-02-04 02:47:04][root][INFO] - Training Epoch: 2/2, step 19483/23838 completed (loss: 0.15390242636203766, acc: 0.9333333373069763)
[2025-02-04 02:47:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19485/23838 [10:15<25:42,  2.82it/s][2025-02-04 02:47:05][root][INFO] - Training Epoch: 2/2, step 19484/23838 completed (loss: 0.24080687761306763, acc: 0.9316239356994629)
[2025-02-04 02:47:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19486/23838 [10:15<25:35,  2.83it/s][2025-02-04 02:47:05][root][INFO] - Training Epoch: 2/2, step 19485/23838 completed (loss: 0.3541952967643738, acc: 0.8999999761581421)
[2025-02-04 02:47:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19487/23838 [10:16<25:57,  2.79it/s][2025-02-04 02:47:05][root][INFO] - Training Epoch: 2/2, step 19486/23838 completed (loss: 0.25325971841812134, acc: 0.9185185432434082)
[2025-02-04 02:47:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19488/23838 [10:16<27:15,  2.66it/s][2025-02-04 02:47:06][root][INFO] - Training Epoch: 2/2, step 19487/23838 completed (loss: 0.5696697235107422, acc: 0.8521126508712769)
[2025-02-04 02:47:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19489/23838 [10:17<28:28,  2.55it/s][2025-02-04 02:47:06][root][INFO] - Training Epoch: 2/2, step 19488/23838 completed (loss: 0.30286893248558044, acc: 0.9107142686843872)
[2025-02-04 02:47:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19490/23838 [10:17<28:33,  2.54it/s][2025-02-04 02:47:07][root][INFO] - Training Epoch: 2/2, step 19489/23838 completed (loss: 0.5717406868934631, acc: 0.8387096524238586)
[2025-02-04 02:47:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19491/23838 [10:17<28:21,  2.55it/s][2025-02-04 02:47:07][root][INFO] - Training Epoch: 2/2, step 19490/23838 completed (loss: 0.2556171715259552, acc: 0.9178082346916199)
[2025-02-04 02:47:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19492/23838 [10:18<26:53,  2.69it/s][2025-02-04 02:47:07][root][INFO] - Training Epoch: 2/2, step 19491/23838 completed (loss: 0.45763590931892395, acc: 0.8913043737411499)
[2025-02-04 02:47:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19493/23838 [10:18<26:54,  2.69it/s][2025-02-04 02:47:08][root][INFO] - Training Epoch: 2/2, step 19492/23838 completed (loss: 0.6014158129692078, acc: 0.8513513803482056)
[2025-02-04 02:47:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19494/23838 [10:19<26:32,  2.73it/s][2025-02-04 02:47:08][root][INFO] - Training Epoch: 2/2, step 19493/23838 completed (loss: 0.4275640547275543, acc: 0.8840579986572266)
[2025-02-04 02:47:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19495/23838 [10:19<28:42,  2.52it/s][2025-02-04 02:47:09][root][INFO] - Training Epoch: 2/2, step 19494/23838 completed (loss: 0.30395182967185974, acc: 0.9032257795333862)
[2025-02-04 02:47:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19496/23838 [10:19<28:14,  2.56it/s][2025-02-04 02:47:09][root][INFO] - Training Epoch: 2/2, step 19495/23838 completed (loss: 0.16261334717273712, acc: 0.9530201554298401)
[2025-02-04 02:47:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19497/23838 [10:20<28:35,  2.53it/s][2025-02-04 02:47:09][root][INFO] - Training Epoch: 2/2, step 19496/23838 completed (loss: 0.07726611196994781, acc: 0.9797979593276978)
[2025-02-04 02:47:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19498/23838 [10:20<27:38,  2.62it/s][2025-02-04 02:47:10][root][INFO] - Training Epoch: 2/2, step 19497/23838 completed (loss: 0.2883109748363495, acc: 0.9238095283508301)
[2025-02-04 02:47:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19499/23838 [10:20<26:00,  2.78it/s][2025-02-04 02:47:10][root][INFO] - Training Epoch: 2/2, step 19498/23838 completed (loss: 0.11562038958072662, acc: 0.9670329689979553)
[2025-02-04 02:47:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19500/23838 [10:21<27:41,  2.61it/s][2025-02-04 02:47:10][root][INFO] - Training Epoch: 2/2, step 19499/23838 completed (loss: 0.13473908603191376, acc: 0.954954981803894)
[2025-02-04 02:47:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19501/23838 [10:21<29:00,  2.49it/s][2025-02-04 02:47:11][root][INFO] - Training Epoch: 2/2, step 19500/23838 completed (loss: 0.22546571493148804, acc: 0.9354838728904724)
[2025-02-04 02:47:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19502/23838 [10:22<28:00,  2.58it/s][2025-02-04 02:47:11][root][INFO] - Training Epoch: 2/2, step 19501/23838 completed (loss: 0.11077243834733963, acc: 0.9811320900917053)
[2025-02-04 02:47:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19503/23838 [10:22<30:12,  2.39it/s][2025-02-04 02:47:12][root][INFO] - Training Epoch: 2/2, step 19502/23838 completed (loss: 0.1540829986333847, acc: 0.9440000057220459)
[2025-02-04 02:47:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19504/23838 [10:23<30:42,  2.35it/s][2025-02-04 02:47:12][root][INFO] - Training Epoch: 2/2, step 19503/23838 completed (loss: 0.4098849594593048, acc: 0.8823529481887817)
[2025-02-04 02:47:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19505/23838 [10:23<27:25,  2.63it/s][2025-02-04 02:47:12][root][INFO] - Training Epoch: 2/2, step 19504/23838 completed (loss: 0.03653559461236, acc: 1.0)
[2025-02-04 02:47:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19506/23838 [10:23<26:20,  2.74it/s][2025-02-04 02:47:13][root][INFO] - Training Epoch: 2/2, step 19505/23838 completed (loss: 0.22210593521595, acc: 0.9677419066429138)
[2025-02-04 02:47:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19507/23838 [10:24<25:20,  2.85it/s][2025-02-04 02:47:13][root][INFO] - Training Epoch: 2/2, step 19506/23838 completed (loss: 0.09479648619890213, acc: 0.9864864945411682)
[2025-02-04 02:47:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19508/23838 [10:24<25:51,  2.79it/s][2025-02-04 02:47:13][root][INFO] - Training Epoch: 2/2, step 19507/23838 completed (loss: 0.15726499259471893, acc: 0.9459459185600281)
[2025-02-04 02:47:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19509/23838 [10:24<25:47,  2.80it/s][2025-02-04 02:47:14][root][INFO] - Training Epoch: 2/2, step 19508/23838 completed (loss: 0.17588716745376587, acc: 0.957446813583374)
[2025-02-04 02:47:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19510/23838 [10:25<25:33,  2.82it/s][2025-02-04 02:47:14][root][INFO] - Training Epoch: 2/2, step 19509/23838 completed (loss: 0.2785946726799011, acc: 0.9090909361839294)
[2025-02-04 02:47:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19511/23838 [10:25<26:09,  2.76it/s][2025-02-04 02:47:15][root][INFO] - Training Epoch: 2/2, step 19510/23838 completed (loss: 0.1601247638463974, acc: 0.9375)
[2025-02-04 02:47:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19512/23838 [10:25<28:14,  2.55it/s][2025-02-04 02:47:15][root][INFO] - Training Epoch: 2/2, step 19511/23838 completed (loss: 0.2711103558540344, acc: 0.9193548560142517)
[2025-02-04 02:47:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19513/23838 [10:26<29:23,  2.45it/s][2025-02-04 02:47:15][root][INFO] - Training Epoch: 2/2, step 19512/23838 completed (loss: 0.20845834910869598, acc: 0.9298245906829834)
[2025-02-04 02:47:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19514/23838 [10:26<28:03,  2.57it/s][2025-02-04 02:47:16][root][INFO] - Training Epoch: 2/2, step 19513/23838 completed (loss: 0.13307854533195496, acc: 0.9743589758872986)
[2025-02-04 02:47:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19515/23838 [10:27<31:47,  2.27it/s][2025-02-04 02:47:16][root][INFO] - Training Epoch: 2/2, step 19514/23838 completed (loss: 0.2558102607727051, acc: 0.9230769276618958)
[2025-02-04 02:47:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19516/23838 [10:27<30:26,  2.37it/s][2025-02-04 02:47:17][root][INFO] - Training Epoch: 2/2, step 19515/23838 completed (loss: 0.0828719288110733, acc: 0.9818181991577148)
[2025-02-04 02:47:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19517/23838 [10:28<29:30,  2.44it/s][2025-02-04 02:47:17][root][INFO] - Training Epoch: 2/2, step 19516/23838 completed (loss: 0.7721558213233948, acc: 0.7551020383834839)
[2025-02-04 02:47:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19518/23838 [10:28<29:34,  2.43it/s][2025-02-04 02:47:18][root][INFO] - Training Epoch: 2/2, step 19517/23838 completed (loss: 0.45260921120643616, acc: 0.8727272748947144)
[2025-02-04 02:47:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19519/23838 [10:28<28:01,  2.57it/s][2025-02-04 02:47:18][root][INFO] - Training Epoch: 2/2, step 19518/23838 completed (loss: 0.29958999156951904, acc: 0.8947368264198303)
[2025-02-04 02:47:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19520/23838 [10:29<27:19,  2.63it/s][2025-02-04 02:47:18][root][INFO] - Training Epoch: 2/2, step 19519/23838 completed (loss: 0.5215266942977905, acc: 0.8513513803482056)
[2025-02-04 02:47:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19521/23838 [10:29<26:32,  2.71it/s][2025-02-04 02:47:19][root][INFO] - Training Epoch: 2/2, step 19520/23838 completed (loss: 0.04258536919951439, acc: 0.9882352948188782)
[2025-02-04 02:47:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19522/23838 [10:29<25:52,  2.78it/s][2025-02-04 02:47:19][root][INFO] - Training Epoch: 2/2, step 19521/23838 completed (loss: 0.21009068191051483, acc: 0.9542483687400818)
[2025-02-04 02:47:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19523/23838 [10:30<27:51,  2.58it/s][2025-02-04 02:47:19][root][INFO] - Training Epoch: 2/2, step 19522/23838 completed (loss: 0.1922888159751892, acc: 0.9239130616188049)
[2025-02-04 02:47:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19524/23838 [10:30<27:19,  2.63it/s][2025-02-04 02:47:20][root][INFO] - Training Epoch: 2/2, step 19523/23838 completed (loss: 0.09678265452384949, acc: 0.9811320900917053)
[2025-02-04 02:47:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19525/23838 [10:31<27:02,  2.66it/s][2025-02-04 02:47:20][root][INFO] - Training Epoch: 2/2, step 19524/23838 completed (loss: 0.0988982617855072, acc: 0.9607843160629272)
[2025-02-04 02:47:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19526/23838 [10:31<26:22,  2.73it/s][2025-02-04 02:47:20][root][INFO] - Training Epoch: 2/2, step 19525/23838 completed (loss: 0.12602131068706512, acc: 0.9677419066429138)
[2025-02-04 02:47:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19527/23838 [10:31<26:56,  2.67it/s][2025-02-04 02:47:21][root][INFO] - Training Epoch: 2/2, step 19526/23838 completed (loss: 0.4286218583583832, acc: 0.8831169009208679)
[2025-02-04 02:47:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19528/23838 [10:32<27:16,  2.63it/s][2025-02-04 02:47:21][root][INFO] - Training Epoch: 2/2, step 19527/23838 completed (loss: 0.4707011282444, acc: 0.841269850730896)
[2025-02-04 02:47:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19529/23838 [10:32<27:07,  2.65it/s][2025-02-04 02:47:22][root][INFO] - Training Epoch: 2/2, step 19528/23838 completed (loss: 0.20540611445903778, acc: 0.9166666865348816)
[2025-02-04 02:47:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19530/23838 [10:32<26:00,  2.76it/s][2025-02-04 02:47:22][root][INFO] - Training Epoch: 2/2, step 19529/23838 completed (loss: 0.04625789076089859, acc: 1.0)
[2025-02-04 02:47:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19531/23838 [10:33<25:29,  2.82it/s][2025-02-04 02:47:22][root][INFO] - Training Epoch: 2/2, step 19530/23838 completed (loss: 0.15708306431770325, acc: 0.949999988079071)
[2025-02-04 02:47:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19532/23838 [10:33<26:42,  2.69it/s][2025-02-04 02:47:23][root][INFO] - Training Epoch: 2/2, step 19531/23838 completed (loss: 0.4758531153202057, acc: 0.8925619721412659)
[2025-02-04 02:47:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19533/23838 [10:33<25:49,  2.78it/s][2025-02-04 02:47:23][root][INFO] - Training Epoch: 2/2, step 19532/23838 completed (loss: 0.15411294996738434, acc: 0.9692307710647583)
[2025-02-04 02:47:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19534/23838 [10:34<25:38,  2.80it/s][2025-02-04 02:47:23][root][INFO] - Training Epoch: 2/2, step 19533/23838 completed (loss: 0.31185680627822876, acc: 0.9038461446762085)
[2025-02-04 02:47:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19535/23838 [10:34<25:26,  2.82it/s][2025-02-04 02:47:24][root][INFO] - Training Epoch: 2/2, step 19534/23838 completed (loss: 0.29115092754364014, acc: 0.8837209343910217)
[2025-02-04 02:47:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19536/23838 [10:34<25:23,  2.82it/s][2025-02-04 02:47:24][root][INFO] - Training Epoch: 2/2, step 19535/23838 completed (loss: 0.24458108842372894, acc: 0.8840579986572266)
[2025-02-04 02:47:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19537/23838 [10:35<25:51,  2.77it/s][2025-02-04 02:47:24][root][INFO] - Training Epoch: 2/2, step 19536/23838 completed (loss: 0.25197452306747437, acc: 0.9390243887901306)
[2025-02-04 02:47:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19538/23838 [10:35<25:31,  2.81it/s][2025-02-04 02:47:25][root][INFO] - Training Epoch: 2/2, step 19537/23838 completed (loss: 0.3091055750846863, acc: 0.8999999761581421)
[2025-02-04 02:47:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19539/23838 [10:36<25:23,  2.82it/s][2025-02-04 02:47:25][root][INFO] - Training Epoch: 2/2, step 19538/23838 completed (loss: 0.060326214879751205, acc: 0.9733333587646484)
[2025-02-04 02:47:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19540/23838 [10:36<26:19,  2.72it/s][2025-02-04 02:47:26][root][INFO] - Training Epoch: 2/2, step 19539/23838 completed (loss: 0.23038943111896515, acc: 0.9111111164093018)
[2025-02-04 02:47:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19541/23838 [10:36<26:15,  2.73it/s][2025-02-04 02:47:26][root][INFO] - Training Epoch: 2/2, step 19540/23838 completed (loss: 0.47512245178222656, acc: 0.875)
[2025-02-04 02:47:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19542/23838 [10:37<25:43,  2.78it/s][2025-02-04 02:47:26][root][INFO] - Training Epoch: 2/2, step 19541/23838 completed (loss: 0.16006138920783997, acc: 0.9684210419654846)
[2025-02-04 02:47:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19543/23838 [10:37<25:59,  2.75it/s][2025-02-04 02:47:27][root][INFO] - Training Epoch: 2/2, step 19542/23838 completed (loss: 0.3947519063949585, acc: 0.914893627166748)
[2025-02-04 02:47:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19544/23838 [10:37<26:28,  2.70it/s][2025-02-04 02:47:27][root][INFO] - Training Epoch: 2/2, step 19543/23838 completed (loss: 0.1107906773686409, acc: 0.9732142686843872)
[2025-02-04 02:47:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19545/23838 [10:38<25:45,  2.78it/s][2025-02-04 02:47:27][root][INFO] - Training Epoch: 2/2, step 19544/23838 completed (loss: 0.5925233960151672, acc: 0.8571428656578064)
[2025-02-04 02:47:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19546/23838 [10:38<25:41,  2.78it/s][2025-02-04 02:47:28][root][INFO] - Training Epoch: 2/2, step 19545/23838 completed (loss: 0.162561297416687, acc: 0.9473684430122375)
[2025-02-04 02:47:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19547/23838 [10:39<28:01,  2.55it/s][2025-02-04 02:47:28][root][INFO] - Training Epoch: 2/2, step 19546/23838 completed (loss: 0.31769075989723206, acc: 0.8928571343421936)
[2025-02-04 02:47:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19548/23838 [10:39<28:20,  2.52it/s][2025-02-04 02:47:29][root][INFO] - Training Epoch: 2/2, step 19547/23838 completed (loss: 0.18028271198272705, acc: 0.9545454382896423)
[2025-02-04 02:47:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19549/23838 [10:39<27:59,  2.55it/s][2025-02-04 02:47:29][root][INFO] - Training Epoch: 2/2, step 19548/23838 completed (loss: 0.11696506291627884, acc: 0.977011501789093)
[2025-02-04 02:47:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19550/23838 [10:40<26:26,  2.70it/s][2025-02-04 02:47:29][root][INFO] - Training Epoch: 2/2, step 19549/23838 completed (loss: 0.06118264049291611, acc: 0.9914529919624329)
[2025-02-04 02:47:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19551/23838 [10:40<24:59,  2.86it/s][2025-02-04 02:47:30][root][INFO] - Training Epoch: 2/2, step 19550/23838 completed (loss: 0.11492069810628891, acc: 0.9375)
[2025-02-04 02:47:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19552/23838 [10:41<33:05,  2.16it/s][2025-02-04 02:47:30][root][INFO] - Training Epoch: 2/2, step 19551/23838 completed (loss: 0.1837632656097412, acc: 0.950276255607605)
[2025-02-04 02:47:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19553/23838 [10:41<32:09,  2.22it/s][2025-02-04 02:47:31][root][INFO] - Training Epoch: 2/2, step 19552/23838 completed (loss: 0.08475492149591446, acc: 0.9829059839248657)
[2025-02-04 02:47:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19554/23838 [10:42<31:06,  2.29it/s][2025-02-04 02:47:31][root][INFO] - Training Epoch: 2/2, step 19553/23838 completed (loss: 0.3127540946006775, acc: 0.8846153616905212)
[2025-02-04 02:47:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19555/23838 [10:42<35:28,  2.01it/s][2025-02-04 02:47:32][root][INFO] - Training Epoch: 2/2, step 19554/23838 completed (loss: 0.14386732876300812, acc: 0.9729729890823364)
[2025-02-04 02:47:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19556/23838 [10:43<35:08,  2.03it/s][2025-02-04 02:47:32][root][INFO] - Training Epoch: 2/2, step 19555/23838 completed (loss: 0.26466891169548035, acc: 0.9389312863349915)
[2025-02-04 02:47:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19557/23838 [10:43<31:05,  2.29it/s][2025-02-04 02:47:33][root][INFO] - Training Epoch: 2/2, step 19556/23838 completed (loss: 0.6105604767799377, acc: 0.800000011920929)
[2025-02-04 02:47:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19558/23838 [10:43<30:25,  2.35it/s][2025-02-04 02:47:33][root][INFO] - Training Epoch: 2/2, step 19557/23838 completed (loss: 0.24667519330978394, acc: 0.922535240650177)
[2025-02-04 02:47:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19559/23838 [10:44<28:23,  2.51it/s][2025-02-04 02:47:33][root][INFO] - Training Epoch: 2/2, step 19558/23838 completed (loss: 0.33374688029289246, acc: 0.8888888955116272)
[2025-02-04 02:47:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19560/23838 [10:44<27:11,  2.62it/s][2025-02-04 02:47:34][root][INFO] - Training Epoch: 2/2, step 19559/23838 completed (loss: 0.09546945244073868, acc: 0.9655172228813171)
[2025-02-04 02:47:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19561/23838 [10:44<27:39,  2.58it/s][2025-02-04 02:47:34][root][INFO] - Training Epoch: 2/2, step 19560/23838 completed (loss: 0.22389991581439972, acc: 0.9586777091026306)
[2025-02-04 02:47:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19562/23838 [10:45<30:47,  2.31it/s][2025-02-04 02:47:35][root][INFO] - Training Epoch: 2/2, step 19561/23838 completed (loss: 0.14586253464221954, acc: 0.949999988079071)
[2025-02-04 02:47:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19563/23838 [10:45<29:01,  2.45it/s][2025-02-04 02:47:35][root][INFO] - Training Epoch: 2/2, step 19562/23838 completed (loss: 0.5373291969299316, acc: 0.8529411554336548)
[2025-02-04 02:47:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19564/23838 [10:46<26:40,  2.67it/s][2025-02-04 02:47:35][root][INFO] - Training Epoch: 2/2, step 19563/23838 completed (loss: 0.4084346890449524, acc: 0.8897058963775635)
[2025-02-04 02:47:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19565/23838 [10:46<26:15,  2.71it/s][2025-02-04 02:47:36][root][INFO] - Training Epoch: 2/2, step 19564/23838 completed (loss: 0.16753606498241425, acc: 0.95652174949646)
[2025-02-04 02:47:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19566/23838 [10:46<26:26,  2.69it/s][2025-02-04 02:47:36][root][INFO] - Training Epoch: 2/2, step 19565/23838 completed (loss: 0.22609837353229523, acc: 0.9337748289108276)
[2025-02-04 02:47:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19567/23838 [10:47<28:15,  2.52it/s][2025-02-04 02:47:36][root][INFO] - Training Epoch: 2/2, step 19566/23838 completed (loss: 1.0981907844543457, acc: 0.694915235042572)
[2025-02-04 02:47:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19568/23838 [10:47<31:06,  2.29it/s][2025-02-04 02:47:37][root][INFO] - Training Epoch: 2/2, step 19567/23838 completed (loss: 1.565089225769043, acc: 0.5655737519264221)
[2025-02-04 02:47:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19569/23838 [10:48<30:05,  2.36it/s][2025-02-04 02:47:37][root][INFO] - Training Epoch: 2/2, step 19568/23838 completed (loss: 0.7775998711585999, acc: 0.7866666913032532)
[2025-02-04 02:47:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19570/23838 [10:48<31:43,  2.24it/s][2025-02-04 02:47:38][root][INFO] - Training Epoch: 2/2, step 19569/23838 completed (loss: 0.9653263092041016, acc: 0.7819548845291138)
[2025-02-04 02:47:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19571/23838 [10:49<30:00,  2.37it/s][2025-02-04 02:47:38][root][INFO] - Training Epoch: 2/2, step 19570/23838 completed (loss: 0.19239076972007751, acc: 0.9245283007621765)
[2025-02-04 02:47:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19572/23838 [10:49<27:44,  2.56it/s][2025-02-04 02:47:39][root][INFO] - Training Epoch: 2/2, step 19571/23838 completed (loss: 0.16118450462818146, acc: 0.9444444179534912)
[2025-02-04 02:47:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19573/23838 [10:49<26:29,  2.68it/s][2025-02-04 02:47:39][root][INFO] - Training Epoch: 2/2, step 19572/23838 completed (loss: 0.24352142214775085, acc: 0.938144326210022)
[2025-02-04 02:47:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19574/23838 [10:50<25:30,  2.79it/s][2025-02-04 02:47:39][root][INFO] - Training Epoch: 2/2, step 19573/23838 completed (loss: 0.37859129905700684, acc: 0.8979591727256775)
[2025-02-04 02:47:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19575/23838 [10:50<25:23,  2.80it/s][2025-02-04 02:47:40][root][INFO] - Training Epoch: 2/2, step 19574/23838 completed (loss: 0.4304714500904083, acc: 0.8571428656578064)
[2025-02-04 02:47:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19576/23838 [10:50<24:42,  2.88it/s][2025-02-04 02:47:40][root][INFO] - Training Epoch: 2/2, step 19575/23838 completed (loss: 0.20447662472724915, acc: 0.9433962106704712)
[2025-02-04 02:47:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19577/23838 [10:51<25:16,  2.81it/s][2025-02-04 02:47:40][root][INFO] - Training Epoch: 2/2, step 19576/23838 completed (loss: 0.5383996963500977, acc: 0.8194444179534912)
[2025-02-04 02:47:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19578/23838 [10:51<25:42,  2.76it/s][2025-02-04 02:47:41][root][INFO] - Training Epoch: 2/2, step 19577/23838 completed (loss: 0.07613875716924667, acc: 0.97826087474823)
[2025-02-04 02:47:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19579/23838 [10:51<25:14,  2.81it/s][2025-02-04 02:47:41][root][INFO] - Training Epoch: 2/2, step 19578/23838 completed (loss: 0.2537800073623657, acc: 0.9090909361839294)
[2025-02-04 02:47:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19580/23838 [10:52<24:46,  2.86it/s][2025-02-04 02:47:41][root][INFO] - Training Epoch: 2/2, step 19579/23838 completed (loss: 0.5857465863227844, acc: 0.8266666531562805)
[2025-02-04 02:47:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19581/23838 [10:52<24:35,  2.88it/s][2025-02-04 02:47:42][root][INFO] - Training Epoch: 2/2, step 19580/23838 completed (loss: 0.3399518132209778, acc: 0.8734177350997925)
[2025-02-04 02:47:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19582/23838 [10:52<24:42,  2.87it/s][2025-02-04 02:47:42][root][INFO] - Training Epoch: 2/2, step 19581/23838 completed (loss: 0.24507910013198853, acc: 0.9117646813392639)
[2025-02-04 02:47:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19583/23838 [10:53<24:22,  2.91it/s][2025-02-04 02:47:42][root][INFO] - Training Epoch: 2/2, step 19582/23838 completed (loss: 0.39218541979789734, acc: 0.8681318759918213)
[2025-02-04 02:47:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19584/23838 [10:53<24:48,  2.86it/s][2025-02-04 02:47:43][root][INFO] - Training Epoch: 2/2, step 19583/23838 completed (loss: 0.31524989008903503, acc: 0.9075630307197571)
[2025-02-04 02:47:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19585/23838 [10:53<24:45,  2.86it/s][2025-02-04 02:47:43][root][INFO] - Training Epoch: 2/2, step 19584/23838 completed (loss: 0.25497928261756897, acc: 0.8916666507720947)
[2025-02-04 02:47:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19586/23838 [10:54<25:02,  2.83it/s][2025-02-04 02:47:43][root][INFO] - Training Epoch: 2/2, step 19585/23838 completed (loss: 0.36457014083862305, acc: 0.9130434989929199)
[2025-02-04 02:47:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19587/23838 [10:54<24:46,  2.86it/s][2025-02-04 02:47:44][root][INFO] - Training Epoch: 2/2, step 19586/23838 completed (loss: 0.15681308507919312, acc: 0.9629629850387573)
[2025-02-04 02:47:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19588/23838 [10:55<25:28,  2.78it/s][2025-02-04 02:47:44][root][INFO] - Training Epoch: 2/2, step 19587/23838 completed (loss: 0.3922556936740875, acc: 0.9166666865348816)
[2025-02-04 02:47:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19589/23838 [10:55<25:39,  2.76it/s][2025-02-04 02:47:44][root][INFO] - Training Epoch: 2/2, step 19588/23838 completed (loss: 0.5359251499176025, acc: 0.8602150678634644)
[2025-02-04 02:47:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19590/23838 [10:55<26:48,  2.64it/s][2025-02-04 02:47:45][root][INFO] - Training Epoch: 2/2, step 19589/23838 completed (loss: 0.3887309432029724, acc: 0.901098906993866)
[2025-02-04 02:47:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19591/23838 [10:56<25:17,  2.80it/s][2025-02-04 02:47:45][root][INFO] - Training Epoch: 2/2, step 19590/23838 completed (loss: 0.3913753032684326, acc: 0.8450704216957092)
[2025-02-04 02:47:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19592/23838 [10:56<24:36,  2.88it/s][2025-02-04 02:47:46][root][INFO] - Training Epoch: 2/2, step 19591/23838 completed (loss: 0.3116021156311035, acc: 0.8941176533699036)
[2025-02-04 02:47:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19593/23838 [10:56<25:35,  2.76it/s][2025-02-04 02:47:46][root][INFO] - Training Epoch: 2/2, step 19592/23838 completed (loss: 0.20309975743293762, acc: 0.953125)
[2025-02-04 02:47:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19594/23838 [10:57<25:14,  2.80it/s][2025-02-04 02:47:46][root][INFO] - Training Epoch: 2/2, step 19593/23838 completed (loss: 0.3026295304298401, acc: 0.9322034120559692)
[2025-02-04 02:47:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19595/23838 [10:57<24:33,  2.88it/s][2025-02-04 02:47:47][root][INFO] - Training Epoch: 2/2, step 19594/23838 completed (loss: 0.3727237284183502, acc: 0.9056603908538818)
[2025-02-04 02:47:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19596/23838 [10:57<24:38,  2.87it/s][2025-02-04 02:47:47][root][INFO] - Training Epoch: 2/2, step 19595/23838 completed (loss: 0.3126319944858551, acc: 0.931034505367279)
[2025-02-04 02:47:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19597/23838 [10:58<24:31,  2.88it/s][2025-02-04 02:47:47][root][INFO] - Training Epoch: 2/2, step 19596/23838 completed (loss: 0.1498507857322693, acc: 0.9595375657081604)
[2025-02-04 02:47:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19598/23838 [10:58<25:04,  2.82it/s][2025-02-04 02:47:48][root][INFO] - Training Epoch: 2/2, step 19597/23838 completed (loss: 0.09054729342460632, acc: 0.9696969985961914)
[2025-02-04 02:47:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19599/23838 [10:58<25:22,  2.78it/s][2025-02-04 02:47:48][root][INFO] - Training Epoch: 2/2, step 19598/23838 completed (loss: 0.15711484849452972, acc: 0.9545454382896423)
[2025-02-04 02:47:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19600/23838 [10:59<24:09,  2.92it/s][2025-02-04 02:47:48][root][INFO] - Training Epoch: 2/2, step 19599/23838 completed (loss: 0.1624208688735962, acc: 0.9642857313156128)
[2025-02-04 02:47:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19601/23838 [10:59<25:02,  2.82it/s][2025-02-04 02:47:49][root][INFO] - Training Epoch: 2/2, step 19600/23838 completed (loss: 0.18993157148361206, acc: 0.9516128897666931)
[2025-02-04 02:47:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19602/23838 [11:00<25:39,  2.75it/s][2025-02-04 02:47:49][root][INFO] - Training Epoch: 2/2, step 19601/23838 completed (loss: 0.2601003646850586, acc: 0.9322034120559692)
[2025-02-04 02:47:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19603/23838 [11:00<24:29,  2.88it/s][2025-02-04 02:47:49][root][INFO] - Training Epoch: 2/2, step 19602/23838 completed (loss: 0.1699889600276947, acc: 0.9253731369972229)
[2025-02-04 02:47:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19604/23838 [11:00<23:55,  2.95it/s][2025-02-04 02:47:50][root][INFO] - Training Epoch: 2/2, step 19603/23838 completed (loss: 0.5468873977661133, acc: 0.8653846383094788)
[2025-02-04 02:47:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19605/23838 [11:00<23:38,  2.98it/s][2025-02-04 02:47:50][root][INFO] - Training Epoch: 2/2, step 19604/23838 completed (loss: 0.04700389876961708, acc: 0.9847328066825867)
[2025-02-04 02:47:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19606/23838 [11:01<23:09,  3.05it/s][2025-02-04 02:47:50][root][INFO] - Training Epoch: 2/2, step 19605/23838 completed (loss: 0.15434303879737854, acc: 0.961240291595459)
[2025-02-04 02:47:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19607/23838 [11:01<23:05,  3.05it/s][2025-02-04 02:47:51][root][INFO] - Training Epoch: 2/2, step 19606/23838 completed (loss: 0.3766237199306488, acc: 0.8961039185523987)
[2025-02-04 02:47:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19608/23838 [11:01<23:15,  3.03it/s][2025-02-04 02:47:51][root][INFO] - Training Epoch: 2/2, step 19607/23838 completed (loss: 0.05989839881658554, acc: 0.9892473220825195)
[2025-02-04 02:47:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19609/23838 [11:02<24:33,  2.87it/s][2025-02-04 02:47:51][root][INFO] - Training Epoch: 2/2, step 19608/23838 completed (loss: 0.02410527877509594, acc: 1.0)
[2025-02-04 02:47:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19610/23838 [11:02<25:16,  2.79it/s][2025-02-04 02:47:52][root][INFO] - Training Epoch: 2/2, step 19609/23838 completed (loss: 0.1461814045906067, acc: 0.9512194991111755)
[2025-02-04 02:47:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19611/23838 [11:03<24:50,  2.84it/s][2025-02-04 02:47:52][root][INFO] - Training Epoch: 2/2, step 19610/23838 completed (loss: 0.28815340995788574, acc: 0.90625)
[2025-02-04 02:47:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19612/23838 [11:03<25:17,  2.78it/s][2025-02-04 02:47:53][root][INFO] - Training Epoch: 2/2, step 19611/23838 completed (loss: 0.17958255112171173, acc: 0.9454545378684998)
[2025-02-04 02:47:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19613/23838 [11:03<25:10,  2.80it/s][2025-02-04 02:47:53][root][INFO] - Training Epoch: 2/2, step 19612/23838 completed (loss: 0.14271129667758942, acc: 0.939393937587738)
[2025-02-04 02:47:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19614/23838 [11:04<24:52,  2.83it/s][2025-02-04 02:47:53][root][INFO] - Training Epoch: 2/2, step 19613/23838 completed (loss: 0.07240691035985947, acc: 0.9927536249160767)
[2025-02-04 02:47:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19615/23838 [11:04<23:58,  2.94it/s][2025-02-04 02:47:54][root][INFO] - Training Epoch: 2/2, step 19614/23838 completed (loss: 0.3821909427642822, acc: 0.90625)
[2025-02-04 02:47:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19616/23838 [11:04<26:40,  2.64it/s][2025-02-04 02:47:54][root][INFO] - Training Epoch: 2/2, step 19615/23838 completed (loss: 0.18472012877464294, acc: 0.9402390718460083)
[2025-02-04 02:47:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19617/23838 [11:05<26:22,  2.67it/s][2025-02-04 02:47:54][root][INFO] - Training Epoch: 2/2, step 19616/23838 completed (loss: 0.06374775618314743, acc: 0.9800000190734863)
[2025-02-04 02:47:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19618/23838 [11:05<30:52,  2.28it/s][2025-02-04 02:47:55][root][INFO] - Training Epoch: 2/2, step 19617/23838 completed (loss: 0.16439610719680786, acc: 0.9504132270812988)
[2025-02-04 02:47:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19619/23838 [11:06<29:49,  2.36it/s][2025-02-04 02:47:55][root][INFO] - Training Epoch: 2/2, step 19618/23838 completed (loss: 0.12545159459114075, acc: 0.96875)
[2025-02-04 02:47:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19620/23838 [11:06<28:34,  2.46it/s][2025-02-04 02:47:56][root][INFO] - Training Epoch: 2/2, step 19619/23838 completed (loss: 0.19219237565994263, acc: 0.929411768913269)
[2025-02-04 02:47:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19621/23838 [11:06<27:14,  2.58it/s][2025-02-04 02:47:56][root][INFO] - Training Epoch: 2/2, step 19620/23838 completed (loss: 0.23040542006492615, acc: 0.9431818127632141)
[2025-02-04 02:47:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19622/23838 [11:07<26:10,  2.68it/s][2025-02-04 02:47:56][root][INFO] - Training Epoch: 2/2, step 19621/23838 completed (loss: 0.10225661098957062, acc: 0.97826087474823)
[2025-02-04 02:47:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19623/23838 [11:07<26:09,  2.68it/s][2025-02-04 02:47:57][root][INFO] - Training Epoch: 2/2, step 19622/23838 completed (loss: 0.2744947373867035, acc: 0.925000011920929)
[2025-02-04 02:47:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19624/23838 [11:08<26:21,  2.66it/s][2025-02-04 02:47:57][root][INFO] - Training Epoch: 2/2, step 19623/23838 completed (loss: 0.09801153093576431, acc: 0.976190447807312)
[2025-02-04 02:47:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19625/23838 [11:08<26:25,  2.66it/s][2025-02-04 02:47:58][root][INFO] - Training Epoch: 2/2, step 19624/23838 completed (loss: 0.3728201985359192, acc: 0.8799999952316284)
[2025-02-04 02:47:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19626/23838 [11:08<26:08,  2.68it/s][2025-02-04 02:47:58][root][INFO] - Training Epoch: 2/2, step 19625/23838 completed (loss: 0.16539351642131805, acc: 0.9639639854431152)
[2025-02-04 02:47:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19627/23838 [11:09<26:22,  2.66it/s][2025-02-04 02:47:58][root][INFO] - Training Epoch: 2/2, step 19626/23838 completed (loss: 0.15192608535289764, acc: 0.9603960514068604)
[2025-02-04 02:47:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19628/23838 [11:09<26:31,  2.64it/s][2025-02-04 02:47:59][root][INFO] - Training Epoch: 2/2, step 19627/23838 completed (loss: 0.12925368547439575, acc: 0.9545454382896423)
[2025-02-04 02:47:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19629/23838 [11:09<25:53,  2.71it/s][2025-02-04 02:47:59][root][INFO] - Training Epoch: 2/2, step 19628/23838 completed (loss: 0.28931841254234314, acc: 0.9027777910232544)
[2025-02-04 02:47:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19630/23838 [11:10<25:15,  2.78it/s][2025-02-04 02:47:59][root][INFO] - Training Epoch: 2/2, step 19629/23838 completed (loss: 0.2188231348991394, acc: 0.9375)
[2025-02-04 02:47:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19631/23838 [11:10<24:58,  2.81it/s][2025-02-04 02:48:00][root][INFO] - Training Epoch: 2/2, step 19630/23838 completed (loss: 0.20404769480228424, acc: 0.9327731132507324)
[2025-02-04 02:48:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19632/23838 [11:10<24:24,  2.87it/s][2025-02-04 02:48:00][root][INFO] - Training Epoch: 2/2, step 19631/23838 completed (loss: 0.21244387328624725, acc: 0.918367326259613)
[2025-02-04 02:48:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19633/23838 [11:11<23:40,  2.96it/s][2025-02-04 02:48:00][root][INFO] - Training Epoch: 2/2, step 19632/23838 completed (loss: 0.06416410207748413, acc: 0.9719626307487488)
[2025-02-04 02:48:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19634/23838 [11:11<24:05,  2.91it/s][2025-02-04 02:48:01][root][INFO] - Training Epoch: 2/2, step 19633/23838 completed (loss: 0.038560837507247925, acc: 0.98591548204422)
[2025-02-04 02:48:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19635/23838 [11:11<24:08,  2.90it/s][2025-02-04 02:48:01][root][INFO] - Training Epoch: 2/2, step 19634/23838 completed (loss: 0.12989695370197296, acc: 0.9411764740943909)
[2025-02-04 02:48:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19636/23838 [11:12<23:45,  2.95it/s][2025-02-04 02:48:01][root][INFO] - Training Epoch: 2/2, step 19635/23838 completed (loss: 0.12826381623744965, acc: 0.9756097793579102)
[2025-02-04 02:48:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19637/23838 [11:12<23:37,  2.96it/s][2025-02-04 02:48:02][root][INFO] - Training Epoch: 2/2, step 19636/23838 completed (loss: 0.04313257709145546, acc: 0.9890109896659851)
[2025-02-04 02:48:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19638/23838 [11:13<25:10,  2.78it/s][2025-02-04 02:48:02][root][INFO] - Training Epoch: 2/2, step 19637/23838 completed (loss: 0.17150558531284332, acc: 0.9271523356437683)
[2025-02-04 02:48:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19639/23838 [11:13<24:59,  2.80it/s][2025-02-04 02:48:02][root][INFO] - Training Epoch: 2/2, step 19638/23838 completed (loss: 0.23322734236717224, acc: 0.9142857193946838)
[2025-02-04 02:48:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19640/23838 [11:13<24:46,  2.82it/s][2025-02-04 02:48:03][root][INFO] - Training Epoch: 2/2, step 19639/23838 completed (loss: 0.5887486934661865, acc: 0.8571428656578064)
[2025-02-04 02:48:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19641/23838 [11:14<25:39,  2.73it/s][2025-02-04 02:48:03][root][INFO] - Training Epoch: 2/2, step 19640/23838 completed (loss: 0.4345146119594574, acc: 0.8857142925262451)
[2025-02-04 02:48:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19642/23838 [11:14<25:49,  2.71it/s][2025-02-04 02:48:04][root][INFO] - Training Epoch: 2/2, step 19641/23838 completed (loss: 0.26954391598701477, acc: 0.9075630307197571)
[2025-02-04 02:48:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19643/23838 [11:14<25:20,  2.76it/s][2025-02-04 02:48:04][root][INFO] - Training Epoch: 2/2, step 19642/23838 completed (loss: 0.10473541170358658, acc: 0.9700000286102295)
[2025-02-04 02:48:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19644/23838 [11:15<24:57,  2.80it/s][2025-02-04 02:48:04][root][INFO] - Training Epoch: 2/2, step 19643/23838 completed (loss: 0.08355720341205597, acc: 0.9871794581413269)
[2025-02-04 02:48:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19645/23838 [11:15<25:47,  2.71it/s][2025-02-04 02:48:05][root][INFO] - Training Epoch: 2/2, step 19644/23838 completed (loss: 0.2988080382347107, acc: 0.9166666865348816)
[2025-02-04 02:48:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19646/23838 [11:15<25:51,  2.70it/s][2025-02-04 02:48:05][root][INFO] - Training Epoch: 2/2, step 19645/23838 completed (loss: 0.3292793333530426, acc: 0.8947368264198303)
[2025-02-04 02:48:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19647/23838 [11:16<26:21,  2.65it/s][2025-02-04 02:48:05][root][INFO] - Training Epoch: 2/2, step 19646/23838 completed (loss: 0.2596472203731537, acc: 0.9130434989929199)
[2025-02-04 02:48:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19648/23838 [11:16<25:54,  2.69it/s][2025-02-04 02:48:06][root][INFO] - Training Epoch: 2/2, step 19647/23838 completed (loss: 0.18901894986629486, acc: 0.9599999785423279)
[2025-02-04 02:48:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19649/23838 [11:17<25:18,  2.76it/s][2025-02-04 02:48:06][root][INFO] - Training Epoch: 2/2, step 19648/23838 completed (loss: 0.12120681256055832, acc: 0.9819819927215576)
[2025-02-04 02:48:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19650/23838 [11:17<24:57,  2.80it/s][2025-02-04 02:48:06][root][INFO] - Training Epoch: 2/2, step 19649/23838 completed (loss: 0.2388763427734375, acc: 0.9367088675498962)
[2025-02-04 02:48:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19651/23838 [11:17<24:44,  2.82it/s][2025-02-04 02:48:07][root][INFO] - Training Epoch: 2/2, step 19650/23838 completed (loss: 0.4666759967803955, acc: 0.8888888955116272)
[2025-02-04 02:48:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19652/23838 [11:18<24:00,  2.91it/s][2025-02-04 02:48:07][root][INFO] - Training Epoch: 2/2, step 19651/23838 completed (loss: 0.5656200647354126, acc: 0.8709677457809448)
[2025-02-04 02:48:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19653/23838 [11:18<23:10,  3.01it/s][2025-02-04 02:48:07][root][INFO] - Training Epoch: 2/2, step 19652/23838 completed (loss: 0.5786389112472534, acc: 0.8461538553237915)
[2025-02-04 02:48:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19654/23838 [11:18<22:58,  3.03it/s][2025-02-04 02:48:08][root][INFO] - Training Epoch: 2/2, step 19653/23838 completed (loss: 0.10327638685703278, acc: 0.9700000286102295)
[2025-02-04 02:48:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19655/23838 [11:19<22:46,  3.06it/s][2025-02-04 02:48:08][root][INFO] - Training Epoch: 2/2, step 19654/23838 completed (loss: 0.10009118914604187, acc: 0.9726027250289917)
[2025-02-04 02:48:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19656/23838 [11:19<22:44,  3.07it/s][2025-02-04 02:48:08][root][INFO] - Training Epoch: 2/2, step 19655/23838 completed (loss: 0.14658500254154205, acc: 0.9620253443717957)
[2025-02-04 02:48:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19657/23838 [11:19<23:24,  2.98it/s][2025-02-04 02:48:09][root][INFO] - Training Epoch: 2/2, step 19656/23838 completed (loss: 0.1114000678062439, acc: 0.9618320465087891)
[2025-02-04 02:48:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19658/23838 [11:20<23:06,  3.01it/s][2025-02-04 02:48:09][root][INFO] - Training Epoch: 2/2, step 19657/23838 completed (loss: 0.147906094789505, acc: 0.9550561904907227)
[2025-02-04 02:48:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19659/23838 [11:20<22:55,  3.04it/s][2025-02-04 02:48:09][root][INFO] - Training Epoch: 2/2, step 19658/23838 completed (loss: 0.37909701466560364, acc: 0.9230769276618958)
[2025-02-04 02:48:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19660/23838 [11:20<23:10,  3.00it/s][2025-02-04 02:48:10][root][INFO] - Training Epoch: 2/2, step 19659/23838 completed (loss: 0.06452585756778717, acc: 1.0)
[2025-02-04 02:48:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19661/23838 [11:20<22:50,  3.05it/s][2025-02-04 02:48:10][root][INFO] - Training Epoch: 2/2, step 19660/23838 completed (loss: 0.8108853101730347, acc: 0.8095238208770752)
[2025-02-04 02:48:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19662/23838 [11:21<22:39,  3.07it/s][2025-02-04 02:48:10][root][INFO] - Training Epoch: 2/2, step 19661/23838 completed (loss: 0.3037864863872528, acc: 0.9090909361839294)
[2025-02-04 02:48:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19663/23838 [11:21<22:53,  3.04it/s][2025-02-04 02:48:11][root][INFO] - Training Epoch: 2/2, step 19662/23838 completed (loss: 0.20580598711967468, acc: 0.9111111164093018)
[2025-02-04 02:48:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19664/23838 [11:21<23:10,  3.00it/s][2025-02-04 02:48:11][root][INFO] - Training Epoch: 2/2, step 19663/23838 completed (loss: 0.18962198495864868, acc: 0.9318181872367859)
[2025-02-04 02:48:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19665/23838 [11:22<23:53,  2.91it/s][2025-02-04 02:48:11][root][INFO] - Training Epoch: 2/2, step 19664/23838 completed (loss: 0.17711631953716278, acc: 0.9580419659614563)
[2025-02-04 02:48:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  82%|[34m████████▏ [0m| 19666/23838 [11:22<25:48,  2.69it/s][2025-02-04 02:48:12][root][INFO] - Training Epoch: 2/2, step 19665/23838 completed (loss: 0.26167935132980347, acc: 0.9216867685317993)
[2025-02-04 02:48:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19667/23838 [11:23<25:14,  2.75it/s][2025-02-04 02:48:12][root][INFO] - Training Epoch: 2/2, step 19666/23838 completed (loss: 0.3456476032733917, acc: 0.9166666865348816)
[2025-02-04 02:48:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19668/23838 [11:23<24:51,  2.80it/s][2025-02-04 02:48:13][root][INFO] - Training Epoch: 2/2, step 19667/23838 completed (loss: 0.13270732760429382, acc: 0.9722222089767456)
[2025-02-04 02:48:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19669/23838 [11:23<25:01,  2.78it/s][2025-02-04 02:48:13][root][INFO] - Training Epoch: 2/2, step 19668/23838 completed (loss: 0.25311169028282166, acc: 0.9354838728904724)
[2025-02-04 02:48:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19670/23838 [11:24<25:00,  2.78it/s][2025-02-04 02:48:13][root][INFO] - Training Epoch: 2/2, step 19669/23838 completed (loss: 0.3884645104408264, acc: 0.8589743375778198)
[2025-02-04 02:48:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19671/23838 [11:24<24:30,  2.83it/s][2025-02-04 02:48:14][root][INFO] - Training Epoch: 2/2, step 19670/23838 completed (loss: 0.2675909101963043, acc: 0.9318181872367859)
[2025-02-04 02:48:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19672/23838 [11:24<24:19,  2.85it/s][2025-02-04 02:48:14][root][INFO] - Training Epoch: 2/2, step 19671/23838 completed (loss: 0.03826016187667847, acc: 0.9846153855323792)
[2025-02-04 02:48:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19673/23838 [11:25<24:27,  2.84it/s][2025-02-04 02:48:14][root][INFO] - Training Epoch: 2/2, step 19672/23838 completed (loss: 0.12144647538661957, acc: 0.95652174949646)
[2025-02-04 02:48:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19674/23838 [11:25<24:55,  2.78it/s][2025-02-04 02:48:15][root][INFO] - Training Epoch: 2/2, step 19673/23838 completed (loss: 0.027374396100640297, acc: 0.9878048896789551)
[2025-02-04 02:48:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19675/23838 [11:26<26:55,  2.58it/s][2025-02-04 02:48:15][root][INFO] - Training Epoch: 2/2, step 19674/23838 completed (loss: 0.22555053234100342, acc: 0.9200000166893005)
[2025-02-04 02:48:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19676/23838 [11:26<26:07,  2.65it/s][2025-02-04 02:48:16][root][INFO] - Training Epoch: 2/2, step 19675/23838 completed (loss: 0.2317807376384735, acc: 0.9113923907279968)
[2025-02-04 02:48:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19677/23838 [11:26<25:23,  2.73it/s][2025-02-04 02:48:16][root][INFO] - Training Epoch: 2/2, step 19676/23838 completed (loss: 0.47126704454421997, acc: 0.9125000238418579)
[2025-02-04 02:48:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19678/23838 [11:27<25:18,  2.74it/s][2025-02-04 02:48:16][root][INFO] - Training Epoch: 2/2, step 19677/23838 completed (loss: 0.1099032312631607, acc: 0.95652174949646)
[2025-02-04 02:48:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19679/23838 [11:27<26:03,  2.66it/s][2025-02-04 02:48:17][root][INFO] - Training Epoch: 2/2, step 19678/23838 completed (loss: 0.0708063468337059, acc: 0.9814814925193787)
[2025-02-04 02:48:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19680/23838 [11:27<25:11,  2.75it/s][2025-02-04 02:48:17][root][INFO] - Training Epoch: 2/2, step 19679/23838 completed (loss: 0.17973802983760834, acc: 0.9090909361839294)
[2025-02-04 02:48:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19681/23838 [11:28<23:10,  2.99it/s][2025-02-04 02:48:17][root][INFO] - Training Epoch: 2/2, step 19680/23838 completed (loss: 0.009391560219228268, acc: 1.0)
[2025-02-04 02:48:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19682/23838 [11:28<22:23,  3.09it/s][2025-02-04 02:48:18][root][INFO] - Training Epoch: 2/2, step 19681/23838 completed (loss: 0.10611196607351303, acc: 0.9560439586639404)
[2025-02-04 02:48:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19683/23838 [11:28<24:25,  2.84it/s][2025-02-04 02:48:18][root][INFO] - Training Epoch: 2/2, step 19682/23838 completed (loss: 0.17571943998336792, acc: 0.9465240836143494)
[2025-02-04 02:48:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19684/23838 [11:29<28:43,  2.41it/s][2025-02-04 02:48:18][root][INFO] - Training Epoch: 2/2, step 19683/23838 completed (loss: 0.19439472258090973, acc: 0.957446813583374)
[2025-02-04 02:48:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19685/23838 [11:29<27:17,  2.54it/s][2025-02-04 02:48:19][root][INFO] - Training Epoch: 2/2, step 19684/23838 completed (loss: 0.056967269629240036, acc: 0.9818181991577148)
[2025-02-04 02:48:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19686/23838 [11:30<28:14,  2.45it/s][2025-02-04 02:48:19][root][INFO] - Training Epoch: 2/2, step 19685/23838 completed (loss: 0.12344716489315033, acc: 0.9624999761581421)
[2025-02-04 02:48:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19687/23838 [11:30<27:48,  2.49it/s][2025-02-04 02:48:20][root][INFO] - Training Epoch: 2/2, step 19686/23838 completed (loss: 0.11454855650663376, acc: 0.9594594836235046)
[2025-02-04 02:48:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19688/23838 [11:31<28:30,  2.43it/s][2025-02-04 02:48:20][root][INFO] - Training Epoch: 2/2, step 19687/23838 completed (loss: 0.2014748454093933, acc: 0.9534883499145508)
[2025-02-04 02:48:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19689/23838 [11:31<29:11,  2.37it/s][2025-02-04 02:48:21][root][INFO] - Training Epoch: 2/2, step 19688/23838 completed (loss: 0.04543055593967438, acc: 0.9896907210350037)
[2025-02-04 02:48:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19690/23838 [11:31<29:50,  2.32it/s][2025-02-04 02:48:21][root][INFO] - Training Epoch: 2/2, step 19689/23838 completed (loss: 0.07674352824687958, acc: 0.970370352268219)
[2025-02-04 02:48:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19691/23838 [11:32<29:19,  2.36it/s][2025-02-04 02:48:21][root][INFO] - Training Epoch: 2/2, step 19690/23838 completed (loss: 0.05274515971541405, acc: 0.96875)
[2025-02-04 02:48:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19692/23838 [11:32<28:57,  2.39it/s][2025-02-04 02:48:22][root][INFO] - Training Epoch: 2/2, step 19691/23838 completed (loss: 0.053448550403118134, acc: 0.9830508232116699)
[2025-02-04 02:48:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19693/23838 [11:33<28:36,  2.42it/s][2025-02-04 02:48:22][root][INFO] - Training Epoch: 2/2, step 19692/23838 completed (loss: 0.08298598229885101, acc: 0.9685534834861755)
[2025-02-04 02:48:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19694/23838 [11:33<29:01,  2.38it/s][2025-02-04 02:48:23][root][INFO] - Training Epoch: 2/2, step 19693/23838 completed (loss: 0.18653638660907745, acc: 0.9452054500579834)
[2025-02-04 02:48:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19695/23838 [11:33<29:09,  2.37it/s][2025-02-04 02:48:23][root][INFO] - Training Epoch: 2/2, step 19694/23838 completed (loss: 0.12560170888900757, acc: 0.9718309640884399)
[2025-02-04 02:48:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19696/23838 [11:34<28:30,  2.42it/s][2025-02-04 02:48:23][root][INFO] - Training Epoch: 2/2, step 19695/23838 completed (loss: 0.09999942034482956, acc: 0.9800000190734863)
[2025-02-04 02:48:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19697/23838 [11:34<28:36,  2.41it/s][2025-02-04 02:48:24][root][INFO] - Training Epoch: 2/2, step 19696/23838 completed (loss: 0.07273253053426743, acc: 0.9806451797485352)
[2025-02-04 02:48:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19698/23838 [11:35<27:53,  2.47it/s][2025-02-04 02:48:24][root][INFO] - Training Epoch: 2/2, step 19697/23838 completed (loss: 0.20166721940040588, acc: 0.9157894849777222)
[2025-02-04 02:48:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19699/23838 [11:35<27:25,  2.51it/s][2025-02-04 02:48:25][root][INFO] - Training Epoch: 2/2, step 19698/23838 completed (loss: 0.1305774301290512, acc: 0.9583333134651184)
[2025-02-04 02:48:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19700/23838 [11:35<26:44,  2.58it/s][2025-02-04 02:48:25][root][INFO] - Training Epoch: 2/2, step 19699/23838 completed (loss: 0.1824173927307129, acc: 0.9577465057373047)
[2025-02-04 02:48:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19701/23838 [11:36<26:57,  2.56it/s][2025-02-04 02:48:25][root][INFO] - Training Epoch: 2/2, step 19700/23838 completed (loss: 0.4055160582065582, acc: 0.895652174949646)
[2025-02-04 02:48:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19702/23838 [11:36<25:55,  2.66it/s][2025-02-04 02:48:26][root][INFO] - Training Epoch: 2/2, step 19701/23838 completed (loss: 0.0964566096663475, acc: 0.9811320900917053)
[2025-02-04 02:48:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19703/23838 [11:37<25:23,  2.71it/s][2025-02-04 02:48:26][root][INFO] - Training Epoch: 2/2, step 19702/23838 completed (loss: 0.2760046720504761, acc: 0.918367326259613)
[2025-02-04 02:48:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19704/23838 [11:37<26:17,  2.62it/s][2025-02-04 02:48:27][root][INFO] - Training Epoch: 2/2, step 19703/23838 completed (loss: 0.22489312291145325, acc: 0.949999988079071)
[2025-02-04 02:48:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19705/23838 [11:37<26:11,  2.63it/s][2025-02-04 02:48:27][root][INFO] - Training Epoch: 2/2, step 19704/23838 completed (loss: 0.12212587147951126, acc: 0.9469696879386902)
[2025-02-04 02:48:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19706/23838 [11:38<26:04,  2.64it/s][2025-02-04 02:48:27][root][INFO] - Training Epoch: 2/2, step 19705/23838 completed (loss: 0.3202945590019226, acc: 0.9272727370262146)
[2025-02-04 02:48:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19707/23838 [11:38<25:20,  2.72it/s][2025-02-04 02:48:28][root][INFO] - Training Epoch: 2/2, step 19706/23838 completed (loss: 1.2037785053253174, acc: 0.7749999761581421)
[2025-02-04 02:48:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19708/23838 [11:38<24:50,  2.77it/s][2025-02-04 02:48:28][root][INFO] - Training Epoch: 2/2, step 19707/23838 completed (loss: 0.469414621591568, acc: 0.8672566413879395)
[2025-02-04 02:48:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19709/23838 [11:39<26:12,  2.63it/s][2025-02-04 02:48:28][root][INFO] - Training Epoch: 2/2, step 19708/23838 completed (loss: 0.6893603205680847, acc: 0.8034188151359558)
[2025-02-04 02:48:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19710/23838 [11:39<25:46,  2.67it/s][2025-02-04 02:48:29][root][INFO] - Training Epoch: 2/2, step 19709/23838 completed (loss: 0.4498123526573181, acc: 0.8399999737739563)
[2025-02-04 02:48:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19711/23838 [11:40<25:47,  2.67it/s][2025-02-04 02:48:29][root][INFO] - Training Epoch: 2/2, step 19710/23838 completed (loss: 0.10907181352376938, acc: 0.9714285731315613)
[2025-02-04 02:48:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19712/23838 [11:40<25:49,  2.66it/s][2025-02-04 02:48:30][root][INFO] - Training Epoch: 2/2, step 19711/23838 completed (loss: 0.25894248485565186, acc: 0.9157894849777222)
[2025-02-04 02:48:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19713/23838 [11:40<25:38,  2.68it/s][2025-02-04 02:48:30][root][INFO] - Training Epoch: 2/2, step 19712/23838 completed (loss: 0.43102726340293884, acc: 0.8958333134651184)
[2025-02-04 02:48:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19714/23838 [11:41<25:26,  2.70it/s][2025-02-04 02:48:30][root][INFO] - Training Epoch: 2/2, step 19713/23838 completed (loss: 0.21174731850624084, acc: 0.9285714030265808)
[2025-02-04 02:48:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19715/23838 [11:41<26:14,  2.62it/s][2025-02-04 02:48:31][root][INFO] - Training Epoch: 2/2, step 19714/23838 completed (loss: 0.25293514132499695, acc: 0.9223300814628601)
[2025-02-04 02:48:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19716/23838 [11:41<25:31,  2.69it/s][2025-02-04 02:48:31][root][INFO] - Training Epoch: 2/2, step 19715/23838 completed (loss: 0.5038947463035583, acc: 0.8600000143051147)
[2025-02-04 02:48:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19717/23838 [11:42<26:36,  2.58it/s][2025-02-04 02:48:31][root][INFO] - Training Epoch: 2/2, step 19716/23838 completed (loss: 0.31753599643707275, acc: 0.9230769276618958)
[2025-02-04 02:48:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19718/23838 [11:42<25:01,  2.74it/s][2025-02-04 02:48:32][root][INFO] - Training Epoch: 2/2, step 19717/23838 completed (loss: 0.19159598648548126, acc: 0.9512194991111755)
[2025-02-04 02:48:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19719/23838 [11:42<24:45,  2.77it/s][2025-02-04 02:48:32][root][INFO] - Training Epoch: 2/2, step 19718/23838 completed (loss: 0.3566979169845581, acc: 0.9061224460601807)
[2025-02-04 02:48:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19720/23838 [11:43<23:34,  2.91it/s][2025-02-04 02:48:32][root][INFO] - Training Epoch: 2/2, step 19719/23838 completed (loss: 0.21920932829380035, acc: 0.9363636374473572)
[2025-02-04 02:48:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19721/23838 [11:43<23:15,  2.95it/s][2025-02-04 02:48:33][root][INFO] - Training Epoch: 2/2, step 19720/23838 completed (loss: 0.24552267789840698, acc: 0.9285714030265808)
[2025-02-04 02:48:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19722/23838 [11:43<23:36,  2.91it/s][2025-02-04 02:48:33][root][INFO] - Training Epoch: 2/2, step 19721/23838 completed (loss: 0.6879193782806396, acc: 0.761904776096344)
[2025-02-04 02:48:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19723/23838 [11:44<23:05,  2.97it/s][2025-02-04 02:48:33][root][INFO] - Training Epoch: 2/2, step 19722/23838 completed (loss: 0.289218932390213, acc: 0.9367088675498962)
[2025-02-04 02:48:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19724/23838 [11:44<24:03,  2.85it/s][2025-02-04 02:48:34][root][INFO] - Training Epoch: 2/2, step 19723/23838 completed (loss: 0.6359482407569885, acc: 0.7894737124443054)
[2025-02-04 02:48:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19725/23838 [11:45<25:35,  2.68it/s][2025-02-04 02:48:34][root][INFO] - Training Epoch: 2/2, step 19724/23838 completed (loss: 0.3584417700767517, acc: 0.8913043737411499)
[2025-02-04 02:48:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19726/23838 [11:45<26:43,  2.56it/s][2025-02-04 02:48:35][root][INFO] - Training Epoch: 2/2, step 19725/23838 completed (loss: 0.2051689624786377, acc: 0.9313725233078003)
[2025-02-04 02:48:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19727/23838 [11:46<29:36,  2.31it/s][2025-02-04 02:48:35][root][INFO] - Training Epoch: 2/2, step 19726/23838 completed (loss: 0.37278497219085693, acc: 0.8787878751754761)
[2025-02-04 02:48:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19728/23838 [11:46<28:29,  2.40it/s][2025-02-04 02:48:36][root][INFO] - Training Epoch: 2/2, step 19727/23838 completed (loss: 0.25774532556533813, acc: 0.9189189076423645)
[2025-02-04 02:48:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19729/23838 [11:46<28:16,  2.42it/s][2025-02-04 02:48:36][root][INFO] - Training Epoch: 2/2, step 19728/23838 completed (loss: 0.3333125710487366, acc: 0.8979591727256775)
[2025-02-04 02:48:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19730/23838 [11:47<32:45,  2.09it/s][2025-02-04 02:48:37][root][INFO] - Training Epoch: 2/2, step 19729/23838 completed (loss: 0.33614304661750793, acc: 0.8661417365074158)
[2025-02-04 02:48:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19731/23838 [11:47<30:42,  2.23it/s][2025-02-04 02:48:37][root][INFO] - Training Epoch: 2/2, step 19730/23838 completed (loss: 0.4251161217689514, acc: 0.8828828930854797)
[2025-02-04 02:48:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19732/23838 [11:48<28:36,  2.39it/s][2025-02-04 02:48:37][root][INFO] - Training Epoch: 2/2, step 19731/23838 completed (loss: 0.27068057656288147, acc: 0.9166666865348816)
[2025-02-04 02:48:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19733/23838 [11:48<26:59,  2.53it/s][2025-02-04 02:48:38][root][INFO] - Training Epoch: 2/2, step 19732/23838 completed (loss: 0.22660255432128906, acc: 0.9279279112815857)
[2025-02-04 02:48:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19734/23838 [11:48<26:20,  2.60it/s][2025-02-04 02:48:38][root][INFO] - Training Epoch: 2/2, step 19733/23838 completed (loss: 0.13812938332557678, acc: 0.9539473652839661)
[2025-02-04 02:48:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19735/23838 [11:49<23:35,  2.90it/s][2025-02-04 02:48:38][root][INFO] - Training Epoch: 2/2, step 19734/23838 completed (loss: 0.47167667746543884, acc: 0.8705882430076599)
[2025-02-04 02:48:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19736/23838 [11:49<25:27,  2.69it/s][2025-02-04 02:48:39][root][INFO] - Training Epoch: 2/2, step 19735/23838 completed (loss: 0.24560101330280304, acc: 0.925000011920929)
[2025-02-04 02:48:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19737/23838 [11:49<24:55,  2.74it/s][2025-02-04 02:48:39][root][INFO] - Training Epoch: 2/2, step 19736/23838 completed (loss: 0.1618308275938034, acc: 0.9638554453849792)
[2025-02-04 02:48:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19738/23838 [11:50<24:08,  2.83it/s][2025-02-04 02:48:39][root][INFO] - Training Epoch: 2/2, step 19737/23838 completed (loss: 0.30548834800720215, acc: 0.90625)
[2025-02-04 02:48:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19739/23838 [11:50<23:45,  2.88it/s][2025-02-04 02:48:40][root][INFO] - Training Epoch: 2/2, step 19738/23838 completed (loss: 0.17570047080516815, acc: 0.95652174949646)
[2025-02-04 02:48:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19740/23838 [11:50<24:15,  2.82it/s][2025-02-04 02:48:40][root][INFO] - Training Epoch: 2/2, step 19739/23838 completed (loss: 0.2353988140821457, acc: 0.9197080135345459)
[2025-02-04 02:48:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19741/23838 [11:51<23:18,  2.93it/s][2025-02-04 02:48:40][root][INFO] - Training Epoch: 2/2, step 19740/23838 completed (loss: 0.22480033338069916, acc: 0.8985507488250732)
[2025-02-04 02:48:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19742/23838 [11:51<23:38,  2.89it/s][2025-02-04 02:48:41][root][INFO] - Training Epoch: 2/2, step 19741/23838 completed (loss: 0.2562077045440674, acc: 0.9347826242446899)
[2025-02-04 02:48:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19743/23838 [11:51<23:08,  2.95it/s][2025-02-04 02:48:41][root][INFO] - Training Epoch: 2/2, step 19742/23838 completed (loss: 0.3561193645000458, acc: 0.8695651888847351)
[2025-02-04 02:48:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19744/23838 [11:52<24:44,  2.76it/s][2025-02-04 02:48:41][root][INFO] - Training Epoch: 2/2, step 19743/23838 completed (loss: 0.09002742916345596, acc: 0.9682539701461792)
[2025-02-04 02:48:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19745/23838 [11:52<26:24,  2.58it/s][2025-02-04 02:48:42][root][INFO] - Training Epoch: 2/2, step 19744/23838 completed (loss: 0.3269968330860138, acc: 0.9097744226455688)
[2025-02-04 02:48:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19746/23838 [11:53<25:25,  2.68it/s][2025-02-04 02:48:42][root][INFO] - Training Epoch: 2/2, step 19745/23838 completed (loss: 0.2649930715560913, acc: 0.9180327653884888)
[2025-02-04 02:48:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19747/23838 [11:53<24:32,  2.78it/s][2025-02-04 02:48:43][root][INFO] - Training Epoch: 2/2, step 19746/23838 completed (loss: 0.15287044644355774, acc: 0.9589040875434875)
[2025-02-04 02:48:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19748/23838 [11:53<23:58,  2.84it/s][2025-02-04 02:48:43][root][INFO] - Training Epoch: 2/2, step 19747/23838 completed (loss: 0.13764715194702148, acc: 0.9452054500579834)
[2025-02-04 02:48:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19749/23838 [11:54<24:00,  2.84it/s][2025-02-04 02:48:43][root][INFO] - Training Epoch: 2/2, step 19748/23838 completed (loss: 0.17909644544124603, acc: 0.9333333373069763)
[2025-02-04 02:48:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19750/23838 [11:54<24:03,  2.83it/s][2025-02-04 02:48:44][root][INFO] - Training Epoch: 2/2, step 19749/23838 completed (loss: 0.41738760471343994, acc: 0.8644067645072937)
[2025-02-04 02:48:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19751/23838 [11:54<24:46,  2.75it/s][2025-02-04 02:48:44][root][INFO] - Training Epoch: 2/2, step 19750/23838 completed (loss: 0.24722833931446075, acc: 0.9130434989929199)
[2025-02-04 02:48:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19752/23838 [11:55<25:09,  2.71it/s][2025-02-04 02:48:44][root][INFO] - Training Epoch: 2/2, step 19751/23838 completed (loss: 0.38741645216941833, acc: 0.8679245114326477)
[2025-02-04 02:48:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19753/23838 [11:55<25:15,  2.70it/s][2025-02-04 02:48:45][root][INFO] - Training Epoch: 2/2, step 19752/23838 completed (loss: 0.37675154209136963, acc: 0.8863636255264282)
[2025-02-04 02:48:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19754/23838 [11:56<24:54,  2.73it/s][2025-02-04 02:48:45][root][INFO] - Training Epoch: 2/2, step 19753/23838 completed (loss: 0.6952918171882629, acc: 0.7592592835426331)
[2025-02-04 02:48:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19755/23838 [11:56<25:30,  2.67it/s][2025-02-04 02:48:46][root][INFO] - Training Epoch: 2/2, step 19754/23838 completed (loss: 0.21503080427646637, acc: 0.9069767594337463)
[2025-02-04 02:48:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19756/23838 [11:56<24:38,  2.76it/s][2025-02-04 02:48:46][root][INFO] - Training Epoch: 2/2, step 19755/23838 completed (loss: 0.29057803750038147, acc: 0.8999999761581421)
[2025-02-04 02:48:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19757/23838 [11:57<24:01,  2.83it/s][2025-02-04 02:48:46][root][INFO] - Training Epoch: 2/2, step 19756/23838 completed (loss: 0.5348498225212097, acc: 0.8214285969734192)
[2025-02-04 02:48:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19758/23838 [11:57<23:04,  2.95it/s][2025-02-04 02:48:46][root][INFO] - Training Epoch: 2/2, step 19757/23838 completed (loss: 0.29740458726882935, acc: 0.8461538553237915)
[2025-02-04 02:48:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19759/23838 [11:57<24:15,  2.80it/s][2025-02-04 02:48:47][root][INFO] - Training Epoch: 2/2, step 19758/23838 completed (loss: 0.6939002275466919, acc: 0.8305084705352783)
[2025-02-04 02:48:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19760/23838 [11:58<25:21,  2.68it/s][2025-02-04 02:48:47][root][INFO] - Training Epoch: 2/2, step 19759/23838 completed (loss: 0.7585765719413757, acc: 0.7647058963775635)
[2025-02-04 02:48:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19761/23838 [11:58<25:07,  2.70it/s][2025-02-04 02:48:48][root][INFO] - Training Epoch: 2/2, step 19760/23838 completed (loss: 1.0386013984680176, acc: 0.6888889074325562)
[2025-02-04 02:48:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19762/23838 [11:58<24:58,  2.72it/s][2025-02-04 02:48:48][root][INFO] - Training Epoch: 2/2, step 19761/23838 completed (loss: 0.8238635659217834, acc: 0.7291666865348816)
[2025-02-04 02:48:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19763/23838 [11:59<25:12,  2.69it/s][2025-02-04 02:48:48][root][INFO] - Training Epoch: 2/2, step 19762/23838 completed (loss: 0.3575899600982666, acc: 0.8936170339584351)
[2025-02-04 02:48:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19764/23838 [11:59<24:53,  2.73it/s][2025-02-04 02:48:49][root][INFO] - Training Epoch: 2/2, step 19763/23838 completed (loss: 0.45490434765815735, acc: 0.8979591727256775)
[2025-02-04 02:48:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19765/23838 [12:00<26:05,  2.60it/s][2025-02-04 02:48:49][root][INFO] - Training Epoch: 2/2, step 19764/23838 completed (loss: 0.3178349733352661, acc: 0.8620689511299133)
[2025-02-04 02:48:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19766/23838 [12:00<27:18,  2.48it/s][2025-02-04 02:48:50][root][INFO] - Training Epoch: 2/2, step 19765/23838 completed (loss: 1.0392645597457886, acc: 0.7042253613471985)
[2025-02-04 02:48:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19767/23838 [12:00<27:40,  2.45it/s][2025-02-04 02:48:50][root][INFO] - Training Epoch: 2/2, step 19766/23838 completed (loss: 0.21350029110908508, acc: 0.9230769276618958)
[2025-02-04 02:48:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19768/23838 [12:01<27:28,  2.47it/s][2025-02-04 02:48:50][root][INFO] - Training Epoch: 2/2, step 19767/23838 completed (loss: 0.6966279745101929, acc: 0.8399999737739563)
[2025-02-04 02:48:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19769/23838 [12:01<26:24,  2.57it/s][2025-02-04 02:48:51][root][INFO] - Training Epoch: 2/2, step 19768/23838 completed (loss: 0.4865646958351135, acc: 0.8571428656578064)
[2025-02-04 02:48:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19770/23838 [12:02<27:03,  2.51it/s][2025-02-04 02:48:51][root][INFO] - Training Epoch: 2/2, step 19769/23838 completed (loss: 0.21945974230766296, acc: 0.9523809552192688)
[2025-02-04 02:48:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19771/23838 [12:02<25:43,  2.64it/s][2025-02-04 02:48:52][root][INFO] - Training Epoch: 2/2, step 19770/23838 completed (loss: 0.47708386182785034, acc: 0.930232584476471)
[2025-02-04 02:48:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19772/23838 [12:02<25:09,  2.69it/s][2025-02-04 02:48:52][root][INFO] - Training Epoch: 2/2, step 19771/23838 completed (loss: 0.4398905038833618, acc: 0.8387096524238586)
[2025-02-04 02:48:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19773/23838 [12:03<26:07,  2.59it/s][2025-02-04 02:48:52][root][INFO] - Training Epoch: 2/2, step 19772/23838 completed (loss: 0.7884650826454163, acc: 0.84375)
[2025-02-04 02:48:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19774/23838 [12:03<25:41,  2.64it/s][2025-02-04 02:48:53][root][INFO] - Training Epoch: 2/2, step 19773/23838 completed (loss: 0.3417212665081024, acc: 0.9215686321258545)
[2025-02-04 02:48:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19775/23838 [12:04<26:21,  2.57it/s][2025-02-04 02:48:53][root][INFO] - Training Epoch: 2/2, step 19774/23838 completed (loss: 0.1561255156993866, acc: 0.9428571462631226)
[2025-02-04 02:48:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19776/23838 [12:04<24:56,  2.71it/s][2025-02-04 02:48:53][root][INFO] - Training Epoch: 2/2, step 19775/23838 completed (loss: 0.16916424036026, acc: 0.9750000238418579)
[2025-02-04 02:48:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19777/23838 [12:04<23:39,  2.86it/s][2025-02-04 02:48:54][root][INFO] - Training Epoch: 2/2, step 19776/23838 completed (loss: 0.43815597891807556, acc: 0.8684210777282715)
[2025-02-04 02:48:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19778/23838 [12:04<23:16,  2.91it/s][2025-02-04 02:48:54][root][INFO] - Training Epoch: 2/2, step 19777/23838 completed (loss: 0.6605980396270752, acc: 0.8333333134651184)
[2025-02-04 02:48:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19779/23838 [12:05<22:46,  2.97it/s][2025-02-04 02:48:54][root][INFO] - Training Epoch: 2/2, step 19778/23838 completed (loss: 0.10953938961029053, acc: 0.96875)
[2025-02-04 02:48:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19780/23838 [12:05<22:39,  2.99it/s][2025-02-04 02:48:55][root][INFO] - Training Epoch: 2/2, step 19779/23838 completed (loss: 0.3885160982608795, acc: 0.9210526347160339)
[2025-02-04 02:48:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19781/23838 [12:05<22:41,  2.98it/s][2025-02-04 02:48:55][root][INFO] - Training Epoch: 2/2, step 19780/23838 completed (loss: 0.5509898662567139, acc: 0.8529411554336548)
[2025-02-04 02:48:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19782/23838 [12:06<23:01,  2.94it/s][2025-02-04 02:48:55][root][INFO] - Training Epoch: 2/2, step 19781/23838 completed (loss: 0.3816526532173157, acc: 0.9285714030265808)
[2025-02-04 02:48:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19783/23838 [12:06<24:51,  2.72it/s][2025-02-04 02:48:56][root][INFO] - Training Epoch: 2/2, step 19782/23838 completed (loss: 0.3253632187843323, acc: 0.8990825414657593)
[2025-02-04 02:48:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19784/23838 [12:07<27:32,  2.45it/s][2025-02-04 02:48:56][root][INFO] - Training Epoch: 2/2, step 19783/23838 completed (loss: 0.20591005682945251, acc: 0.9428571462631226)
[2025-02-04 02:48:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19785/23838 [12:07<27:41,  2.44it/s][2025-02-04 02:48:57][root][INFO] - Training Epoch: 2/2, step 19784/23838 completed (loss: 0.2404782921075821, acc: 0.9473684430122375)
[2025-02-04 02:48:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19786/23838 [12:08<26:48,  2.52it/s][2025-02-04 02:48:57][root][INFO] - Training Epoch: 2/2, step 19785/23838 completed (loss: 0.1436968445777893, acc: 0.9780219793319702)
[2025-02-04 02:48:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19787/23838 [12:08<25:59,  2.60it/s][2025-02-04 02:48:57][root][INFO] - Training Epoch: 2/2, step 19786/23838 completed (loss: 0.33517569303512573, acc: 0.8727272748947144)
[2025-02-04 02:48:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19788/23838 [12:08<24:51,  2.72it/s][2025-02-04 02:48:58][root][INFO] - Training Epoch: 2/2, step 19787/23838 completed (loss: 0.4071437120437622, acc: 0.8421052694320679)
[2025-02-04 02:48:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19789/23838 [12:09<26:56,  2.50it/s][2025-02-04 02:48:58][root][INFO] - Training Epoch: 2/2, step 19788/23838 completed (loss: 0.7030054926872253, acc: 0.9130434989929199)
[2025-02-04 02:48:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19790/23838 [12:09<25:12,  2.68it/s][2025-02-04 02:48:59][root][INFO] - Training Epoch: 2/2, step 19789/23838 completed (loss: 0.8113793730735779, acc: 0.7419354915618896)
[2025-02-04 02:48:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19791/23838 [12:09<24:48,  2.72it/s][2025-02-04 02:48:59][root][INFO] - Training Epoch: 2/2, step 19790/23838 completed (loss: 0.3035585880279541, acc: 0.9142857193946838)
[2025-02-04 02:48:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19792/23838 [12:10<24:54,  2.71it/s][2025-02-04 02:48:59][root][INFO] - Training Epoch: 2/2, step 19791/23838 completed (loss: 0.44928625226020813, acc: 0.8732394576072693)
[2025-02-04 02:48:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19793/23838 [12:10<23:44,  2.84it/s][2025-02-04 02:49:00][root][INFO] - Training Epoch: 2/2, step 19792/23838 completed (loss: 0.39306336641311646, acc: 0.918367326259613)
[2025-02-04 02:49:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19794/23838 [12:11<27:33,  2.45it/s][2025-02-04 02:49:00][root][INFO] - Training Epoch: 2/2, step 19793/23838 completed (loss: 0.6678927540779114, acc: 0.8313252925872803)
[2025-02-04 02:49:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19795/23838 [12:11<25:18,  2.66it/s][2025-02-04 02:49:00][root][INFO] - Training Epoch: 2/2, step 19794/23838 completed (loss: 0.30573850870132446, acc: 0.8958333134651184)
[2025-02-04 02:49:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19796/23838 [12:11<24:09,  2.79it/s][2025-02-04 02:49:01][root][INFO] - Training Epoch: 2/2, step 19795/23838 completed (loss: 0.20412012934684753, acc: 0.9534883499145508)
[2025-02-04 02:49:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19797/23838 [12:12<24:00,  2.80it/s][2025-02-04 02:49:01][root][INFO] - Training Epoch: 2/2, step 19796/23838 completed (loss: 0.10654226690530777, acc: 0.9599999785423279)
[2025-02-04 02:49:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19798/23838 [12:12<27:10,  2.48it/s][2025-02-04 02:49:02][root][INFO] - Training Epoch: 2/2, step 19797/23838 completed (loss: 0.4724145829677582, acc: 0.8450704216957092)
[2025-02-04 02:49:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19799/23838 [12:12<26:52,  2.50it/s][2025-02-04 02:49:02][root][INFO] - Training Epoch: 2/2, step 19798/23838 completed (loss: 0.28996092081069946, acc: 0.875)
[2025-02-04 02:49:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19800/23838 [12:13<29:15,  2.30it/s][2025-02-04 02:49:03][root][INFO] - Training Epoch: 2/2, step 19799/23838 completed (loss: 0.46796852350234985, acc: 0.9056603908538818)
[2025-02-04 02:49:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19801/23838 [12:13<28:03,  2.40it/s][2025-02-04 02:49:03][root][INFO] - Training Epoch: 2/2, step 19800/23838 completed (loss: 0.2891399562358856, acc: 0.8999999761581421)
[2025-02-04 02:49:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19802/23838 [12:14<26:41,  2.52it/s][2025-02-04 02:49:03][root][INFO] - Training Epoch: 2/2, step 19801/23838 completed (loss: 0.6517838835716248, acc: 0.8518518805503845)
[2025-02-04 02:49:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19803/23838 [12:14<26:27,  2.54it/s][2025-02-04 02:49:04][root][INFO] - Training Epoch: 2/2, step 19802/23838 completed (loss: 0.29103365540504456, acc: 0.920634925365448)
[2025-02-04 02:49:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19804/23838 [12:14<25:49,  2.60it/s][2025-02-04 02:49:04][root][INFO] - Training Epoch: 2/2, step 19803/23838 completed (loss: 0.19435866177082062, acc: 0.9375)
[2025-02-04 02:49:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19805/23838 [12:15<25:54,  2.59it/s][2025-02-04 02:49:04][root][INFO] - Training Epoch: 2/2, step 19804/23838 completed (loss: 0.08591917157173157, acc: 0.9696969985961914)
[2025-02-04 02:49:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19806/23838 [12:15<24:41,  2.72it/s][2025-02-04 02:49:05][root][INFO] - Training Epoch: 2/2, step 19805/23838 completed (loss: 0.26370906829833984, acc: 0.8974359035491943)
[2025-02-04 02:49:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19807/23838 [12:16<24:20,  2.76it/s][2025-02-04 02:49:05][root][INFO] - Training Epoch: 2/2, step 19806/23838 completed (loss: 0.11929117888212204, acc: 0.9555555582046509)
[2025-02-04 02:49:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19808/23838 [12:16<25:31,  2.63it/s][2025-02-04 02:49:06][root][INFO] - Training Epoch: 2/2, step 19807/23838 completed (loss: 0.35423895716667175, acc: 0.9047619104385376)
[2025-02-04 02:49:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19809/23838 [12:16<25:22,  2.65it/s][2025-02-04 02:49:06][root][INFO] - Training Epoch: 2/2, step 19808/23838 completed (loss: 0.43323856592178345, acc: 0.8936170339584351)
[2025-02-04 02:49:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19810/23838 [12:17<24:20,  2.76it/s][2025-02-04 02:49:06][root][INFO] - Training Epoch: 2/2, step 19809/23838 completed (loss: 0.6657267808914185, acc: 0.8285714387893677)
[2025-02-04 02:49:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19811/23838 [12:17<23:14,  2.89it/s][2025-02-04 02:49:07][root][INFO] - Training Epoch: 2/2, step 19810/23838 completed (loss: 0.6382047533988953, acc: 0.8695651888847351)
[2025-02-04 02:49:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19812/23838 [12:17<22:39,  2.96it/s][2025-02-04 02:49:07][root][INFO] - Training Epoch: 2/2, step 19811/23838 completed (loss: 0.964445948600769, acc: 0.7333333492279053)
[2025-02-04 02:49:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19813/23838 [12:18<23:47,  2.82it/s][2025-02-04 02:49:07][root][INFO] - Training Epoch: 2/2, step 19812/23838 completed (loss: 0.14999768137931824, acc: 0.9464285969734192)
[2025-02-04 02:49:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19814/23838 [12:18<23:54,  2.81it/s][2025-02-04 02:49:08][root][INFO] - Training Epoch: 2/2, step 19813/23838 completed (loss: 0.9921005964279175, acc: 0.6875)
[2025-02-04 02:49:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19815/23838 [12:18<24:06,  2.78it/s][2025-02-04 02:49:08][root][INFO] - Training Epoch: 2/2, step 19814/23838 completed (loss: 0.31677374243736267, acc: 0.9230769276618958)
[2025-02-04 02:49:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19816/23838 [12:19<23:51,  2.81it/s][2025-02-04 02:49:08][root][INFO] - Training Epoch: 2/2, step 19815/23838 completed (loss: 0.9169666767120361, acc: 0.8823529481887817)
[2025-02-04 02:49:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19817/23838 [12:19<24:39,  2.72it/s][2025-02-04 02:49:09][root][INFO] - Training Epoch: 2/2, step 19816/23838 completed (loss: 0.36656537652015686, acc: 0.9468085169792175)
[2025-02-04 02:49:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19818/23838 [12:20<31:22,  2.14it/s][2025-02-04 02:49:09][root][INFO] - Training Epoch: 2/2, step 19817/23838 completed (loss: 0.1750265508890152, acc: 0.9727272987365723)
[2025-02-04 02:49:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19819/23838 [12:20<28:34,  2.34it/s][2025-02-04 02:49:10][root][INFO] - Training Epoch: 2/2, step 19818/23838 completed (loss: 0.03657931834459305, acc: 1.0)
[2025-02-04 02:49:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19820/23838 [12:21<27:23,  2.44it/s][2025-02-04 02:49:10][root][INFO] - Training Epoch: 2/2, step 19819/23838 completed (loss: 0.25738078355789185, acc: 0.949999988079071)
[2025-02-04 02:49:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19821/23838 [12:21<26:47,  2.50it/s][2025-02-04 02:49:10][root][INFO] - Training Epoch: 2/2, step 19820/23838 completed (loss: 0.26496195793151855, acc: 0.9047619104385376)
[2025-02-04 02:49:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19822/23838 [12:21<26:14,  2.55it/s][2025-02-04 02:49:11][root][INFO] - Training Epoch: 2/2, step 19821/23838 completed (loss: 0.2191961407661438, acc: 0.9047619104385376)
[2025-02-04 02:49:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19823/23838 [12:22<25:13,  2.65it/s][2025-02-04 02:49:11][root][INFO] - Training Epoch: 2/2, step 19822/23838 completed (loss: 0.2940376102924347, acc: 0.9090909361839294)
[2025-02-04 02:49:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19824/23838 [12:22<24:57,  2.68it/s][2025-02-04 02:49:12][root][INFO] - Training Epoch: 2/2, step 19823/23838 completed (loss: 0.12048432976007462, acc: 1.0)
[2025-02-04 02:49:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19825/23838 [12:22<24:43,  2.70it/s][2025-02-04 02:49:12][root][INFO] - Training Epoch: 2/2, step 19824/23838 completed (loss: 0.32573723793029785, acc: 0.8947368264198303)
[2025-02-04 02:49:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19826/23838 [12:23<24:44,  2.70it/s][2025-02-04 02:49:12][root][INFO] - Training Epoch: 2/2, step 19825/23838 completed (loss: 0.06554345041513443, acc: 1.0)
[2025-02-04 02:49:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19827/23838 [12:23<24:27,  2.73it/s][2025-02-04 02:49:13][root][INFO] - Training Epoch: 2/2, step 19826/23838 completed (loss: 0.11141282320022583, acc: 0.95652174949646)
[2025-02-04 02:49:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19828/23838 [12:23<23:38,  2.83it/s][2025-02-04 02:49:13][root][INFO] - Training Epoch: 2/2, step 19827/23838 completed (loss: 0.2458103448152542, acc: 0.9375)
[2025-02-04 02:49:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19829/23838 [12:24<23:24,  2.85it/s][2025-02-04 02:49:13][root][INFO] - Training Epoch: 2/2, step 19828/23838 completed (loss: 0.20389720797538757, acc: 0.8999999761581421)
[2025-02-04 02:49:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19830/23838 [12:24<22:33,  2.96it/s][2025-02-04 02:49:14][root][INFO] - Training Epoch: 2/2, step 19829/23838 completed (loss: 0.0193460863083601, acc: 1.0)
[2025-02-04 02:49:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19831/23838 [12:25<25:23,  2.63it/s][2025-02-04 02:49:14][root][INFO] - Training Epoch: 2/2, step 19830/23838 completed (loss: 0.12361716479063034, acc: 0.9333333373069763)
[2025-02-04 02:49:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19832/23838 [12:25<24:47,  2.69it/s][2025-02-04 02:49:14][root][INFO] - Training Epoch: 2/2, step 19831/23838 completed (loss: 0.13455824553966522, acc: 0.9473684430122375)
[2025-02-04 02:49:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19833/23838 [12:25<24:27,  2.73it/s][2025-02-04 02:49:15][root][INFO] - Training Epoch: 2/2, step 19832/23838 completed (loss: 0.0550837516784668, acc: 1.0)
[2025-02-04 02:49:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19834/23838 [12:26<24:33,  2.72it/s][2025-02-04 02:49:15][root][INFO] - Training Epoch: 2/2, step 19833/23838 completed (loss: 1.02733314037323, acc: 0.7142857313156128)
[2025-02-04 02:49:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19835/23838 [12:26<24:56,  2.68it/s][2025-02-04 02:49:16][root][INFO] - Training Epoch: 2/2, step 19834/23838 completed (loss: 0.022015120834112167, acc: 1.0)
[2025-02-04 02:49:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19836/23838 [12:26<24:24,  2.73it/s][2025-02-04 02:49:16][root][INFO] - Training Epoch: 2/2, step 19835/23838 completed (loss: 0.7701231241226196, acc: 0.8108108043670654)
[2025-02-04 02:49:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19837/23838 [12:27<23:12,  2.87it/s][2025-02-04 02:49:16][root][INFO] - Training Epoch: 2/2, step 19836/23838 completed (loss: 0.02215052954852581, acc: 0.97826087474823)
[2025-02-04 02:49:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19838/23838 [12:27<24:31,  2.72it/s][2025-02-04 02:49:17][root][INFO] - Training Epoch: 2/2, step 19837/23838 completed (loss: 0.2791061997413635, acc: 0.9047619104385376)
[2025-02-04 02:49:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19839/23838 [12:27<23:26,  2.84it/s][2025-02-04 02:49:17][root][INFO] - Training Epoch: 2/2, step 19838/23838 completed (loss: 0.1431370973587036, acc: 0.9583333134651184)
[2025-02-04 02:49:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19840/23838 [12:28<22:30,  2.96it/s][2025-02-04 02:49:17][root][INFO] - Training Epoch: 2/2, step 19839/23838 completed (loss: 0.135832279920578, acc: 0.9670329689979553)
[2025-02-04 02:49:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19841/23838 [12:28<24:52,  2.68it/s][2025-02-04 02:49:18][root][INFO] - Training Epoch: 2/2, step 19840/23838 completed (loss: 0.16534671187400818, acc: 0.9389312863349915)
[2025-02-04 02:49:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19842/23838 [12:28<24:32,  2.71it/s][2025-02-04 02:49:18][root][INFO] - Training Epoch: 2/2, step 19841/23838 completed (loss: 0.1389835923910141, acc: 0.9777777791023254)
[2025-02-04 02:49:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19843/23838 [12:29<28:16,  2.35it/s][2025-02-04 02:49:19][root][INFO] - Training Epoch: 2/2, step 19842/23838 completed (loss: 0.252993106842041, acc: 0.9430894255638123)
[2025-02-04 02:49:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19844/23838 [12:30<31:11,  2.13it/s][2025-02-04 02:49:19][root][INFO] - Training Epoch: 2/2, step 19843/23838 completed (loss: 0.7556359767913818, acc: 0.7945205569267273)
[2025-02-04 02:49:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19845/23838 [12:30<28:18,  2.35it/s][2025-02-04 02:49:20][root][INFO] - Training Epoch: 2/2, step 19844/23838 completed (loss: 0.009369962848722935, acc: 1.0)
[2025-02-04 02:49:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19846/23838 [12:30<27:35,  2.41it/s][2025-02-04 02:49:20][root][INFO] - Training Epoch: 2/2, step 19845/23838 completed (loss: 0.09476342797279358, acc: 0.9836065769195557)
[2025-02-04 02:49:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19847/23838 [12:31<26:55,  2.47it/s][2025-02-04 02:49:20][root][INFO] - Training Epoch: 2/2, step 19846/23838 completed (loss: 0.14219476282596588, acc: 0.969072163105011)
[2025-02-04 02:49:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19848/23838 [12:31<25:38,  2.59it/s][2025-02-04 02:49:21][root][INFO] - Training Epoch: 2/2, step 19847/23838 completed (loss: 0.1441737860441208, acc: 0.9666666388511658)
[2025-02-04 02:49:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19849/23838 [12:31<24:46,  2.68it/s][2025-02-04 02:49:21][root][INFO] - Training Epoch: 2/2, step 19848/23838 completed (loss: 0.05838901922106743, acc: 0.9780219793319702)
[2025-02-04 02:49:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19850/23838 [12:32<24:04,  2.76it/s][2025-02-04 02:49:21][root][INFO] - Training Epoch: 2/2, step 19849/23838 completed (loss: 0.40427643060684204, acc: 0.9041095972061157)
[2025-02-04 02:49:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19851/23838 [12:32<22:54,  2.90it/s][2025-02-04 02:49:22][root][INFO] - Training Epoch: 2/2, step 19850/23838 completed (loss: 0.2531537115573883, acc: 0.9459459185600281)
[2025-02-04 02:49:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19852/23838 [12:32<22:09,  3.00it/s][2025-02-04 02:49:22][root][INFO] - Training Epoch: 2/2, step 19851/23838 completed (loss: 0.3322044610977173, acc: 0.8727272748947144)
[2025-02-04 02:49:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19853/23838 [12:33<22:34,  2.94it/s][2025-02-04 02:49:22][root][INFO] - Training Epoch: 2/2, step 19852/23838 completed (loss: 0.5078541040420532, acc: 0.8125)
[2025-02-04 02:49:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19854/23838 [12:33<22:27,  2.96it/s][2025-02-04 02:49:23][root][INFO] - Training Epoch: 2/2, step 19853/23838 completed (loss: 0.35776039958000183, acc: 0.9285714030265808)
[2025-02-04 02:49:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19855/23838 [12:33<22:24,  2.96it/s][2025-02-04 02:49:23][root][INFO] - Training Epoch: 2/2, step 19854/23838 completed (loss: 0.5673072934150696, acc: 0.8888888955116272)
[2025-02-04 02:49:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19856/23838 [12:34<23:12,  2.86it/s][2025-02-04 02:49:23][root][INFO] - Training Epoch: 2/2, step 19855/23838 completed (loss: 0.3846290707588196, acc: 0.8809523582458496)
[2025-02-04 02:49:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19857/23838 [12:34<21:54,  3.03it/s][2025-02-04 02:49:24][root][INFO] - Training Epoch: 2/2, step 19856/23838 completed (loss: 0.6015977263450623, acc: 0.7878788113594055)
[2025-02-04 02:49:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19858/23838 [12:34<21:29,  3.09it/s][2025-02-04 02:49:24][root][INFO] - Training Epoch: 2/2, step 19857/23838 completed (loss: 0.5673885345458984, acc: 0.8717948794364929)
[2025-02-04 02:49:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19859/23838 [12:35<22:47,  2.91it/s][2025-02-04 02:49:24][root][INFO] - Training Epoch: 2/2, step 19858/23838 completed (loss: 0.3948609232902527, acc: 0.8627451062202454)
[2025-02-04 02:49:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19860/23838 [12:35<23:56,  2.77it/s][2025-02-04 02:49:25][root][INFO] - Training Epoch: 2/2, step 19859/23838 completed (loss: 0.720727801322937, acc: 0.75)
[2025-02-04 02:49:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19861/23838 [12:35<23:42,  2.80it/s][2025-02-04 02:49:25][root][INFO] - Training Epoch: 2/2, step 19860/23838 completed (loss: 0.47233057022094727, acc: 0.8627451062202454)
[2025-02-04 02:49:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19862/23838 [12:36<23:33,  2.81it/s][2025-02-04 02:49:25][root][INFO] - Training Epoch: 2/2, step 19861/23838 completed (loss: 1.2128418684005737, acc: 0.6111111044883728)
[2025-02-04 02:49:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19863/23838 [12:36<25:24,  2.61it/s][2025-02-04 02:49:26][root][INFO] - Training Epoch: 2/2, step 19862/23838 completed (loss: 0.4417906701564789, acc: 0.8478260636329651)
[2025-02-04 02:49:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19864/23838 [12:37<25:00,  2.65it/s][2025-02-04 02:49:26][root][INFO] - Training Epoch: 2/2, step 19863/23838 completed (loss: 0.2955152988433838, acc: 0.8571428656578064)
[2025-02-04 02:49:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19865/23838 [12:37<24:00,  2.76it/s][2025-02-04 02:49:27][root][INFO] - Training Epoch: 2/2, step 19864/23838 completed (loss: 0.8262256979942322, acc: 0.7575757503509521)
[2025-02-04 02:49:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19866/23838 [12:37<23:52,  2.77it/s][2025-02-04 02:49:27][root][INFO] - Training Epoch: 2/2, step 19865/23838 completed (loss: 0.9337490200996399, acc: 0.75)
[2025-02-04 02:49:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19867/23838 [12:38<23:41,  2.79it/s][2025-02-04 02:49:27][root][INFO] - Training Epoch: 2/2, step 19866/23838 completed (loss: 0.05731635168194771, acc: 0.9767441749572754)
[2025-02-04 02:49:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19868/23838 [12:38<24:06,  2.74it/s][2025-02-04 02:49:28][root][INFO] - Training Epoch: 2/2, step 19867/23838 completed (loss: 0.11384903639554977, acc: 0.9506173133850098)
[2025-02-04 02:49:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19869/23838 [12:38<25:08,  2.63it/s][2025-02-04 02:49:28][root][INFO] - Training Epoch: 2/2, step 19868/23838 completed (loss: 0.08218715339899063, acc: 0.9795918464660645)
[2025-02-04 02:49:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19870/23838 [12:39<29:19,  2.25it/s][2025-02-04 02:49:29][root][INFO] - Training Epoch: 2/2, step 19869/23838 completed (loss: 0.14306077361106873, acc: 0.9551020264625549)
[2025-02-04 02:49:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19871/23838 [12:39<27:07,  2.44it/s][2025-02-04 02:49:29][root][INFO] - Training Epoch: 2/2, step 19870/23838 completed (loss: 0.2665925920009613, acc: 0.9318181872367859)
[2025-02-04 02:49:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19872/23838 [12:40<24:59,  2.64it/s][2025-02-04 02:49:29][root][INFO] - Training Epoch: 2/2, step 19871/23838 completed (loss: 0.5609201788902283, acc: 0.8354430198669434)
[2025-02-04 02:49:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19873/23838 [12:40<24:36,  2.69it/s][2025-02-04 02:49:30][root][INFO] - Training Epoch: 2/2, step 19872/23838 completed (loss: 0.3991997539997101, acc: 0.8692307472229004)
[2025-02-04 02:49:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19874/23838 [12:40<24:22,  2.71it/s][2025-02-04 02:49:30][root][INFO] - Training Epoch: 2/2, step 19873/23838 completed (loss: 0.8082879185676575, acc: 0.8088235259056091)
[2025-02-04 02:49:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19875/23838 [12:41<24:20,  2.71it/s][2025-02-04 02:49:30][root][INFO] - Training Epoch: 2/2, step 19874/23838 completed (loss: 0.51630038022995, acc: 0.8064516186714172)
[2025-02-04 02:49:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19876/23838 [12:41<24:01,  2.75it/s][2025-02-04 02:49:31][root][INFO] - Training Epoch: 2/2, step 19875/23838 completed (loss: 0.8267618417739868, acc: 0.75)
[2025-02-04 02:49:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19877/23838 [12:41<23:28,  2.81it/s][2025-02-04 02:49:31][root][INFO] - Training Epoch: 2/2, step 19876/23838 completed (loss: 0.7788684964179993, acc: 0.7948718070983887)
[2025-02-04 02:49:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19878/23838 [12:42<23:50,  2.77it/s][2025-02-04 02:49:31][root][INFO] - Training Epoch: 2/2, step 19877/23838 completed (loss: 0.4135938584804535, acc: 0.9041095972061157)
[2025-02-04 02:49:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19879/23838 [12:42<23:42,  2.78it/s][2025-02-04 02:49:32][root][INFO] - Training Epoch: 2/2, step 19878/23838 completed (loss: 0.19046273827552795, acc: 0.9459459185600281)
[2025-02-04 02:49:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19880/23838 [12:43<23:58,  2.75it/s][2025-02-04 02:49:32][root][INFO] - Training Epoch: 2/2, step 19879/23838 completed (loss: 0.22692358493804932, acc: 0.9545454382896423)
[2025-02-04 02:49:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19881/23838 [12:43<23:22,  2.82it/s][2025-02-04 02:49:33][root][INFO] - Training Epoch: 2/2, step 19880/23838 completed (loss: 0.21292857825756073, acc: 0.938144326210022)
[2025-02-04 02:49:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19882/23838 [12:43<23:01,  2.86it/s][2025-02-04 02:49:33][root][INFO] - Training Epoch: 2/2, step 19881/23838 completed (loss: 0.13307422399520874, acc: 0.942307710647583)
[2025-02-04 02:49:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19883/23838 [12:44<23:41,  2.78it/s][2025-02-04 02:49:33][root][INFO] - Training Epoch: 2/2, step 19882/23838 completed (loss: 0.6978108286857605, acc: 0.8351648449897766)
[2025-02-04 02:49:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19884/23838 [12:44<23:04,  2.86it/s][2025-02-04 02:49:34][root][INFO] - Training Epoch: 2/2, step 19883/23838 completed (loss: 0.1351536363363266, acc: 0.9587628841400146)
[2025-02-04 02:49:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19885/23838 [12:44<22:42,  2.90it/s][2025-02-04 02:49:34][root][INFO] - Training Epoch: 2/2, step 19884/23838 completed (loss: 0.3201267421245575, acc: 0.9051724076271057)
[2025-02-04 02:49:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19886/23838 [12:45<21:12,  3.10it/s][2025-02-04 02:49:34][root][INFO] - Training Epoch: 2/2, step 19885/23838 completed (loss: 0.231037899851799, acc: 0.9411764740943909)
[2025-02-04 02:49:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19887/23838 [12:45<20:30,  3.21it/s][2025-02-04 02:49:34][root][INFO] - Training Epoch: 2/2, step 19886/23838 completed (loss: 0.18731990456581116, acc: 0.95652174949646)
[2025-02-04 02:49:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19888/23838 [12:45<20:42,  3.18it/s][2025-02-04 02:49:35][root][INFO] - Training Epoch: 2/2, step 19887/23838 completed (loss: 0.31663042306900024, acc: 0.8846153616905212)
[2025-02-04 02:49:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19889/23838 [12:45<20:47,  3.16it/s][2025-02-04 02:49:35][root][INFO] - Training Epoch: 2/2, step 19888/23838 completed (loss: 0.24764031171798706, acc: 0.8999999761581421)
[2025-02-04 02:49:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19890/23838 [12:46<20:30,  3.21it/s][2025-02-04 02:49:35][root][INFO] - Training Epoch: 2/2, step 19889/23838 completed (loss: 0.3449501693248749, acc: 0.904411792755127)
[2025-02-04 02:49:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19891/23838 [12:46<20:14,  3.25it/s][2025-02-04 02:49:36][root][INFO] - Training Epoch: 2/2, step 19890/23838 completed (loss: 0.30622372031211853, acc: 0.9259259104728699)
[2025-02-04 02:49:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19892/23838 [12:46<20:04,  3.28it/s][2025-02-04 02:49:36][root][INFO] - Training Epoch: 2/2, step 19891/23838 completed (loss: 0.3985759913921356, acc: 0.8653846383094788)
[2025-02-04 02:49:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19893/23838 [12:47<20:12,  3.25it/s][2025-02-04 02:49:36][root][INFO] - Training Epoch: 2/2, step 19892/23838 completed (loss: 0.14918479323387146, acc: 0.9482758641242981)
[2025-02-04 02:49:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19894/23838 [12:47<21:25,  3.07it/s][2025-02-04 02:49:37][root][INFO] - Training Epoch: 2/2, step 19893/23838 completed (loss: 0.19504225254058838, acc: 0.9292035102844238)
[2025-02-04 02:49:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19895/23838 [12:47<21:49,  3.01it/s][2025-02-04 02:49:37][root][INFO] - Training Epoch: 2/2, step 19894/23838 completed (loss: 0.2757361829280853, acc: 0.9019607901573181)
[2025-02-04 02:49:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19896/23838 [12:48<21:55,  3.00it/s][2025-02-04 02:49:37][root][INFO] - Training Epoch: 2/2, step 19895/23838 completed (loss: 0.30646926164627075, acc: 0.8684210777282715)
[2025-02-04 02:49:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19897/23838 [12:48<22:04,  2.97it/s][2025-02-04 02:49:38][root][INFO] - Training Epoch: 2/2, step 19896/23838 completed (loss: 0.3274529278278351, acc: 0.8842105269432068)
[2025-02-04 02:49:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19898/23838 [12:48<21:41,  3.03it/s][2025-02-04 02:49:38][root][INFO] - Training Epoch: 2/2, step 19897/23838 completed (loss: 0.13365252315998077, acc: 0.9512194991111755)
[2025-02-04 02:49:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19899/23838 [12:49<21:57,  2.99it/s][2025-02-04 02:49:38][root][INFO] - Training Epoch: 2/2, step 19898/23838 completed (loss: 0.13314960896968842, acc: 1.0)
[2025-02-04 02:49:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19900/23838 [12:49<22:55,  2.86it/s][2025-02-04 02:49:39][root][INFO] - Training Epoch: 2/2, step 19899/23838 completed (loss: 0.16517296433448792, acc: 0.95652174949646)
[2025-02-04 02:49:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19901/23838 [12:50<23:39,  2.77it/s][2025-02-04 02:49:39][root][INFO] - Training Epoch: 2/2, step 19900/23838 completed (loss: 0.2884722948074341, acc: 0.9015151262283325)
[2025-02-04 02:49:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19902/23838 [12:50<24:10,  2.71it/s][2025-02-04 02:49:40][root][INFO] - Training Epoch: 2/2, step 19901/23838 completed (loss: 0.10071968287229538, acc: 1.0)
[2025-02-04 02:49:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19903/23838 [12:50<24:21,  2.69it/s][2025-02-04 02:49:40][root][INFO] - Training Epoch: 2/2, step 19902/23838 completed (loss: 0.20011861622333527, acc: 0.9166666865348816)
[2025-02-04 02:49:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  83%|[34m████████▎ [0m| 19904/23838 [12:51<23:37,  2.77it/s][2025-02-04 02:49:40][root][INFO] - Training Epoch: 2/2, step 19903/23838 completed (loss: 0.25251418352127075, acc: 0.9411764740943909)
[2025-02-04 02:49:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19905/23838 [12:51<24:47,  2.64it/s][2025-02-04 02:49:41][root][INFO] - Training Epoch: 2/2, step 19904/23838 completed (loss: 0.14283694326877594, acc: 0.96875)
[2025-02-04 02:49:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19906/23838 [12:51<23:33,  2.78it/s][2025-02-04 02:49:41][root][INFO] - Training Epoch: 2/2, step 19905/23838 completed (loss: 0.21077516674995422, acc: 0.9519230723381042)
[2025-02-04 02:49:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19907/23838 [12:52<22:47,  2.87it/s][2025-02-04 02:49:41][root][INFO] - Training Epoch: 2/2, step 19906/23838 completed (loss: 0.2152988612651825, acc: 0.9449541568756104)
[2025-02-04 02:49:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19908/23838 [12:52<22:31,  2.91it/s][2025-02-04 02:49:42][root][INFO] - Training Epoch: 2/2, step 19907/23838 completed (loss: 0.1765022575855255, acc: 0.9333333373069763)
[2025-02-04 02:49:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19909/23838 [12:52<23:26,  2.79it/s][2025-02-04 02:49:42][root][INFO] - Training Epoch: 2/2, step 19908/23838 completed (loss: 0.23038806021213531, acc: 0.9435483813285828)
[2025-02-04 02:49:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19910/23838 [12:53<23:50,  2.75it/s][2025-02-04 02:49:42][root][INFO] - Training Epoch: 2/2, step 19909/23838 completed (loss: 0.11989760398864746, acc: 0.9759036302566528)
[2025-02-04 02:49:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19911/23838 [12:53<24:53,  2.63it/s][2025-02-04 02:49:43][root][INFO] - Training Epoch: 2/2, step 19910/23838 completed (loss: 0.10007894039154053, acc: 0.9745762944221497)
[2025-02-04 02:49:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19912/23838 [12:54<25:36,  2.56it/s][2025-02-04 02:49:43][root][INFO] - Training Epoch: 2/2, step 19911/23838 completed (loss: 0.2481188029050827, acc: 0.9139785170555115)
[2025-02-04 02:49:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19913/23838 [12:54<24:28,  2.67it/s][2025-02-04 02:49:44][root][INFO] - Training Epoch: 2/2, step 19912/23838 completed (loss: 0.16230399906635284, acc: 0.9506173133850098)
[2025-02-04 02:49:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19914/23838 [12:54<24:38,  2.65it/s][2025-02-04 02:49:44][root][INFO] - Training Epoch: 2/2, step 19913/23838 completed (loss: 0.3022926151752472, acc: 0.9207921028137207)
[2025-02-04 02:49:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19915/23838 [12:55<25:06,  2.60it/s][2025-02-04 02:49:44][root][INFO] - Training Epoch: 2/2, step 19914/23838 completed (loss: 0.16880163550376892, acc: 0.9649122953414917)
[2025-02-04 02:49:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19916/23838 [12:55<25:05,  2.61it/s][2025-02-04 02:49:45][root][INFO] - Training Epoch: 2/2, step 19915/23838 completed (loss: 0.09061264246702194, acc: 0.9851852059364319)
[2025-02-04 02:49:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19917/23838 [12:55<24:34,  2.66it/s][2025-02-04 02:49:45][root][INFO] - Training Epoch: 2/2, step 19916/23838 completed (loss: 0.20109334588050842, acc: 0.9552238583564758)
[2025-02-04 02:49:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19918/23838 [12:56<23:37,  2.76it/s][2025-02-04 02:49:45][root][INFO] - Training Epoch: 2/2, step 19917/23838 completed (loss: 0.09060794860124588, acc: 0.976190447807312)
[2025-02-04 02:49:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19919/23838 [12:56<24:26,  2.67it/s][2025-02-04 02:49:46][root][INFO] - Training Epoch: 2/2, step 19918/23838 completed (loss: 0.09689660370349884, acc: 0.9555555582046509)
[2025-02-04 02:49:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19920/23838 [12:57<25:38,  2.55it/s][2025-02-04 02:49:46][root][INFO] - Training Epoch: 2/2, step 19919/23838 completed (loss: 0.09442050755023956, acc: 0.9709302186965942)
[2025-02-04 02:49:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19921/23838 [12:57<25:14,  2.59it/s][2025-02-04 02:49:47][root][INFO] - Training Epoch: 2/2, step 19920/23838 completed (loss: 0.2149847447872162, acc: 0.9639639854431152)
[2025-02-04 02:49:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19922/23838 [12:57<24:51,  2.63it/s][2025-02-04 02:49:47][root][INFO] - Training Epoch: 2/2, step 19921/23838 completed (loss: 0.0867704451084137, acc: 0.9837398529052734)
[2025-02-04 02:49:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19923/23838 [12:58<24:46,  2.63it/s][2025-02-04 02:49:47][root][INFO] - Training Epoch: 2/2, step 19922/23838 completed (loss: 0.12336466461420059, acc: 0.9652174115180969)
[2025-02-04 02:49:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19924/23838 [12:58<24:20,  2.68it/s][2025-02-04 02:49:48][root][INFO] - Training Epoch: 2/2, step 19923/23838 completed (loss: 0.12193199247121811, acc: 0.9608938694000244)
[2025-02-04 02:49:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19925/23838 [12:58<23:51,  2.73it/s][2025-02-04 02:49:48][root][INFO] - Training Epoch: 2/2, step 19924/23838 completed (loss: 0.07923465967178345, acc: 0.9760000109672546)
[2025-02-04 02:49:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19926/23838 [12:59<23:33,  2.77it/s][2025-02-04 02:49:48][root][INFO] - Training Epoch: 2/2, step 19925/23838 completed (loss: 0.21815066039562225, acc: 0.9185185432434082)
[2025-02-04 02:49:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19927/23838 [12:59<23:41,  2.75it/s][2025-02-04 02:49:49][root][INFO] - Training Epoch: 2/2, step 19926/23838 completed (loss: 0.16929002106189728, acc: 0.9583333134651184)
[2025-02-04 02:49:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19928/23838 [13:00<23:17,  2.80it/s][2025-02-04 02:49:49][root][INFO] - Training Epoch: 2/2, step 19927/23838 completed (loss: 0.09900834411382675, acc: 0.9836065769195557)
[2025-02-04 02:49:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19929/23838 [13:00<23:32,  2.77it/s][2025-02-04 02:49:50][root][INFO] - Training Epoch: 2/2, step 19928/23838 completed (loss: 0.03930836543440819, acc: 0.9750000238418579)
[2025-02-04 02:49:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19930/23838 [13:00<23:20,  2.79it/s][2025-02-04 02:49:50][root][INFO] - Training Epoch: 2/2, step 19929/23838 completed (loss: 0.19290338456630707, acc: 0.9453125)
[2025-02-04 02:49:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19931/23838 [13:01<23:33,  2.76it/s][2025-02-04 02:49:50][root][INFO] - Training Epoch: 2/2, step 19930/23838 completed (loss: 0.03369489312171936, acc: 0.989130437374115)
[2025-02-04 02:49:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19932/23838 [13:01<22:20,  2.91it/s][2025-02-04 02:49:51][root][INFO] - Training Epoch: 2/2, step 19931/23838 completed (loss: 0.08852719515562057, acc: 0.9800000190734863)
[2025-02-04 02:49:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19933/23838 [13:01<22:31,  2.89it/s][2025-02-04 02:49:51][root][INFO] - Training Epoch: 2/2, step 19932/23838 completed (loss: 0.05901776999235153, acc: 0.9931507110595703)
[2025-02-04 02:49:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19934/23838 [13:02<24:06,  2.70it/s][2025-02-04 02:49:51][root][INFO] - Training Epoch: 2/2, step 19933/23838 completed (loss: 0.10748359560966492, acc: 0.9743589758872986)
[2025-02-04 02:49:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19935/23838 [13:02<24:00,  2.71it/s][2025-02-04 02:49:52][root][INFO] - Training Epoch: 2/2, step 19934/23838 completed (loss: 0.12405963242053986, acc: 0.9772727489471436)
[2025-02-04 02:49:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19936/23838 [13:02<23:44,  2.74it/s][2025-02-04 02:49:52][root][INFO] - Training Epoch: 2/2, step 19935/23838 completed (loss: 0.028513425961136818, acc: 0.991525411605835)
[2025-02-04 02:49:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19937/23838 [13:03<22:44,  2.86it/s][2025-02-04 02:49:52][root][INFO] - Training Epoch: 2/2, step 19936/23838 completed (loss: 0.056227460503578186, acc: 0.9777777791023254)
[2025-02-04 02:49:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19938/23838 [13:03<23:21,  2.78it/s][2025-02-04 02:49:53][root][INFO] - Training Epoch: 2/2, step 19937/23838 completed (loss: 0.006388399749994278, acc: 1.0)
[2025-02-04 02:49:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19939/23838 [13:03<22:09,  2.93it/s][2025-02-04 02:49:53][root][INFO] - Training Epoch: 2/2, step 19938/23838 completed (loss: 0.0610426589846611, acc: 0.9750000238418579)
[2025-02-04 02:49:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19940/23838 [13:04<21:42,  2.99it/s][2025-02-04 02:49:53][root][INFO] - Training Epoch: 2/2, step 19939/23838 completed (loss: 0.055233947932720184, acc: 0.9882352948188782)
[2025-02-04 02:49:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19941/23838 [13:04<22:08,  2.93it/s][2025-02-04 02:49:54][root][INFO] - Training Epoch: 2/2, step 19940/23838 completed (loss: 0.021586671471595764, acc: 1.0)
[2025-02-04 02:49:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19942/23838 [13:04<21:09,  3.07it/s][2025-02-04 02:49:54][root][INFO] - Training Epoch: 2/2, step 19941/23838 completed (loss: 0.17616701126098633, acc: 0.9494949579238892)
[2025-02-04 02:49:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19943/23838 [13:05<21:55,  2.96it/s][2025-02-04 02:49:54][root][INFO] - Training Epoch: 2/2, step 19942/23838 completed (loss: 0.07386751472949982, acc: 0.9849624037742615)
[2025-02-04 02:49:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19944/23838 [13:05<24:49,  2.61it/s][2025-02-04 02:49:55][root][INFO] - Training Epoch: 2/2, step 19943/23838 completed (loss: 0.13951203227043152, acc: 0.9833333492279053)
[2025-02-04 02:49:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19945/23838 [13:06<24:18,  2.67it/s][2025-02-04 02:49:55][root][INFO] - Training Epoch: 2/2, step 19944/23838 completed (loss: 0.1564660668373108, acc: 0.96875)
[2025-02-04 02:49:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19946/23838 [13:06<23:32,  2.76it/s][2025-02-04 02:49:56][root][INFO] - Training Epoch: 2/2, step 19945/23838 completed (loss: 0.034666869789361954, acc: 0.9931507110595703)
[2025-02-04 02:49:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19947/23838 [13:06<22:34,  2.87it/s][2025-02-04 02:49:56][root][INFO] - Training Epoch: 2/2, step 19946/23838 completed (loss: 0.10985737293958664, acc: 0.9886363744735718)
[2025-02-04 02:49:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19948/23838 [13:07<23:25,  2.77it/s][2025-02-04 02:49:56][root][INFO] - Training Epoch: 2/2, step 19947/23838 completed (loss: 0.145456463098526, acc: 0.95652174949646)
[2025-02-04 02:49:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19949/23838 [13:07<23:23,  2.77it/s][2025-02-04 02:49:57][root][INFO] - Training Epoch: 2/2, step 19948/23838 completed (loss: 0.1126336008310318, acc: 0.9708737730979919)
[2025-02-04 02:49:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19950/23838 [13:07<23:02,  2.81it/s][2025-02-04 02:49:57][root][INFO] - Training Epoch: 2/2, step 19949/23838 completed (loss: 0.1277695596218109, acc: 0.9747899174690247)
[2025-02-04 02:49:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19951/23838 [13:08<21:48,  2.97it/s][2025-02-04 02:49:57][root][INFO] - Training Epoch: 2/2, step 19950/23838 completed (loss: 0.20159253478050232, acc: 0.939393937587738)
[2025-02-04 02:49:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19952/23838 [13:08<21:08,  3.06it/s][2025-02-04 02:49:58][root][INFO] - Training Epoch: 2/2, step 19951/23838 completed (loss: 0.14003774523735046, acc: 0.9569892287254333)
[2025-02-04 02:49:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19953/23838 [13:08<20:45,  3.12it/s][2025-02-04 02:49:58][root][INFO] - Training Epoch: 2/2, step 19952/23838 completed (loss: 0.4417581558227539, acc: 0.8947368264198303)
[2025-02-04 02:49:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19954/23838 [13:09<25:40,  2.52it/s][2025-02-04 02:49:58][root][INFO] - Training Epoch: 2/2, step 19953/23838 completed (loss: 0.1003287062048912, acc: 0.9567901492118835)
[2025-02-04 02:49:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19955/23838 [13:09<23:54,  2.71it/s][2025-02-04 02:49:59][root][INFO] - Training Epoch: 2/2, step 19954/23838 completed (loss: 0.05823482945561409, acc: 0.9818181991577148)
[2025-02-04 02:49:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19956/23838 [13:09<23:13,  2.79it/s][2025-02-04 02:49:59][root][INFO] - Training Epoch: 2/2, step 19955/23838 completed (loss: 0.18042857944965363, acc: 0.9680851101875305)
[2025-02-04 02:49:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19957/23838 [13:10<22:38,  2.86it/s][2025-02-04 02:49:59][root][INFO] - Training Epoch: 2/2, step 19956/23838 completed (loss: 0.20076489448547363, acc: 0.9125000238418579)
[2025-02-04 02:49:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19958/23838 [13:10<22:42,  2.85it/s][2025-02-04 02:50:00][root][INFO] - Training Epoch: 2/2, step 19957/23838 completed (loss: 1.0958195924758911, acc: 0.6818181872367859)
[2025-02-04 02:50:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19959/23838 [13:10<22:24,  2.89it/s][2025-02-04 02:50:00][root][INFO] - Training Epoch: 2/2, step 19958/23838 completed (loss: 0.15917204320430756, acc: 0.936170220375061)
[2025-02-04 02:50:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19960/23838 [13:11<22:19,  2.89it/s][2025-02-04 02:50:00][root][INFO] - Training Epoch: 2/2, step 19959/23838 completed (loss: 0.23486793041229248, acc: 0.9230769276618958)
[2025-02-04 02:50:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19961/23838 [13:11<22:37,  2.86it/s][2025-02-04 02:50:01][root][INFO] - Training Epoch: 2/2, step 19960/23838 completed (loss: 0.1514916568994522, acc: 0.9204545617103577)
[2025-02-04 02:50:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19962/23838 [13:12<23:52,  2.71it/s][2025-02-04 02:50:01][root][INFO] - Training Epoch: 2/2, step 19961/23838 completed (loss: 0.4922041594982147, acc: 0.8571428656578064)
[2025-02-04 02:50:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19963/23838 [13:12<22:05,  2.92it/s][2025-02-04 02:50:01][root][INFO] - Training Epoch: 2/2, step 19962/23838 completed (loss: 0.2659473121166229, acc: 0.9166666865348816)
[2025-02-04 02:50:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▎ [0m| 19964/23838 [13:12<21:16,  3.03it/s][2025-02-04 02:50:02][root][INFO] - Training Epoch: 2/2, step 19963/23838 completed (loss: 0.13888917863368988, acc: 0.9523809552192688)
[2025-02-04 02:50:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19965/23838 [13:13<22:08,  2.92it/s][2025-02-04 02:50:02][root][INFO] - Training Epoch: 2/2, step 19964/23838 completed (loss: 0.17282071709632874, acc: 0.9661017060279846)
[2025-02-04 02:50:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19966/23838 [13:13<22:19,  2.89it/s][2025-02-04 02:50:02][root][INFO] - Training Epoch: 2/2, step 19965/23838 completed (loss: 0.6587845087051392, acc: 0.7701149582862854)
[2025-02-04 02:50:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19967/23838 [13:13<21:36,  2.99it/s][2025-02-04 02:50:03][root][INFO] - Training Epoch: 2/2, step 19966/23838 completed (loss: 0.6958532333374023, acc: 0.800000011920929)
[2025-02-04 02:50:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19968/23838 [13:14<21:32,  2.99it/s][2025-02-04 02:50:03][root][INFO] - Training Epoch: 2/2, step 19967/23838 completed (loss: 0.821442723274231, acc: 0.7820512652397156)
[2025-02-04 02:50:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19969/23838 [13:14<21:32,  2.99it/s][2025-02-04 02:50:03][root][INFO] - Training Epoch: 2/2, step 19968/23838 completed (loss: 0.7065222263336182, acc: 0.7708333134651184)
[2025-02-04 02:50:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19970/23838 [13:14<21:46,  2.96it/s][2025-02-04 02:50:04][root][INFO] - Training Epoch: 2/2, step 19969/23838 completed (loss: 0.3823252022266388, acc: 0.8854166865348816)
[2025-02-04 02:50:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19971/23838 [13:15<24:27,  2.63it/s][2025-02-04 02:50:04][root][INFO] - Training Epoch: 2/2, step 19970/23838 completed (loss: 0.5559130311012268, acc: 0.824999988079071)
[2025-02-04 02:50:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19972/23838 [13:15<24:21,  2.64it/s][2025-02-04 02:50:05][root][INFO] - Training Epoch: 2/2, step 19971/23838 completed (loss: 0.6761035919189453, acc: 0.8450704216957092)
[2025-02-04 02:50:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19973/23838 [13:16<25:08,  2.56it/s][2025-02-04 02:50:05][root][INFO] - Training Epoch: 2/2, step 19972/23838 completed (loss: 0.24852833151817322, acc: 0.9052631855010986)
[2025-02-04 02:50:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19974/23838 [13:16<26:57,  2.39it/s][2025-02-04 02:50:06][root][INFO] - Training Epoch: 2/2, step 19973/23838 completed (loss: 0.7961945533752441, acc: 0.8199999928474426)
[2025-02-04 02:50:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19975/23838 [13:16<26:56,  2.39it/s][2025-02-04 02:50:06][root][INFO] - Training Epoch: 2/2, step 19974/23838 completed (loss: 0.29984137415885925, acc: 0.9322034120559692)
[2025-02-04 02:50:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19976/23838 [13:17<25:06,  2.56it/s][2025-02-04 02:50:06][root][INFO] - Training Epoch: 2/2, step 19975/23838 completed (loss: 0.27515748143196106, acc: 0.9047619104385376)
[2025-02-04 02:50:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19977/23838 [13:17<24:00,  2.68it/s][2025-02-04 02:50:07][root][INFO] - Training Epoch: 2/2, step 19976/23838 completed (loss: 0.31440290808677673, acc: 0.8730158805847168)
[2025-02-04 02:50:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19978/23838 [13:17<23:38,  2.72it/s][2025-02-04 02:50:07][root][INFO] - Training Epoch: 2/2, step 19977/23838 completed (loss: 0.35955023765563965, acc: 0.8849557638168335)
[2025-02-04 02:50:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19979/23838 [13:18<26:34,  2.42it/s][2025-02-04 02:50:08][root][INFO] - Training Epoch: 2/2, step 19978/23838 completed (loss: 0.3981589376926422, acc: 0.895652174949646)
[2025-02-04 02:50:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19980/23838 [13:18<25:45,  2.50it/s][2025-02-04 02:50:08][root][INFO] - Training Epoch: 2/2, step 19979/23838 completed (loss: 0.4072546064853668, acc: 0.8928571343421936)
[2025-02-04 02:50:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19981/23838 [13:19<25:30,  2.52it/s][2025-02-04 02:50:08][root][INFO] - Training Epoch: 2/2, step 19980/23838 completed (loss: 0.4593052566051483, acc: 0.8350515365600586)
[2025-02-04 02:50:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19982/23838 [13:19<24:28,  2.63it/s][2025-02-04 02:50:09][root][INFO] - Training Epoch: 2/2, step 19981/23838 completed (loss: 0.7869038581848145, acc: 0.7843137383460999)
[2025-02-04 02:50:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19983/23838 [13:19<23:11,  2.77it/s][2025-02-04 02:50:09][root][INFO] - Training Epoch: 2/2, step 19982/23838 completed (loss: 0.4149779677391052, acc: 0.8690476417541504)
[2025-02-04 02:50:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19984/23838 [13:20<23:53,  2.69it/s][2025-02-04 02:50:09][root][INFO] - Training Epoch: 2/2, step 19983/23838 completed (loss: 0.5244580507278442, acc: 0.8449612259864807)
[2025-02-04 02:50:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19985/23838 [13:20<23:40,  2.71it/s][2025-02-04 02:50:10][root][INFO] - Training Epoch: 2/2, step 19984/23838 completed (loss: 0.4559999406337738, acc: 0.8878504633903503)
[2025-02-04 02:50:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19986/23838 [13:21<25:41,  2.50it/s][2025-02-04 02:50:10][root][INFO] - Training Epoch: 2/2, step 19985/23838 completed (loss: 0.6314773559570312, acc: 0.8518518805503845)
[2025-02-04 02:50:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19987/23838 [13:21<25:53,  2.48it/s][2025-02-04 02:50:11][root][INFO] - Training Epoch: 2/2, step 19986/23838 completed (loss: 0.3866637349128723, acc: 0.8829787373542786)
[2025-02-04 02:50:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19988/23838 [13:21<25:37,  2.50it/s][2025-02-04 02:50:11][root][INFO] - Training Epoch: 2/2, step 19987/23838 completed (loss: 0.37423479557037354, acc: 0.9152542352676392)
[2025-02-04 02:50:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19989/23838 [13:22<25:17,  2.54it/s][2025-02-04 02:50:11][root][INFO] - Training Epoch: 2/2, step 19988/23838 completed (loss: 0.28604796528816223, acc: 0.9027777910232544)
[2025-02-04 02:50:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19990/23838 [13:22<30:55,  2.07it/s][2025-02-04 02:50:12][root][INFO] - Training Epoch: 2/2, step 19989/23838 completed (loss: 0.5117937922477722, acc: 0.8818897604942322)
[2025-02-04 02:50:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19991/23838 [13:23<30:47,  2.08it/s][2025-02-04 02:50:13][root][INFO] - Training Epoch: 2/2, step 19990/23838 completed (loss: 0.23964905738830566, acc: 0.9357798099517822)
[2025-02-04 02:50:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19992/23838 [13:23<30:17,  2.12it/s][2025-02-04 02:50:13][root][INFO] - Training Epoch: 2/2, step 19991/23838 completed (loss: 0.4638335406780243, acc: 0.8675496578216553)
[2025-02-04 02:50:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19993/23838 [13:24<28:15,  2.27it/s][2025-02-04 02:50:13][root][INFO] - Training Epoch: 2/2, step 19992/23838 completed (loss: 0.42698168754577637, acc: 0.8888888955116272)
[2025-02-04 02:50:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19994/23838 [13:24<26:19,  2.43it/s][2025-02-04 02:50:14][root][INFO] - Training Epoch: 2/2, step 19993/23838 completed (loss: 0.3042471408843994, acc: 0.9295774698257446)
[2025-02-04 02:50:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19995/23838 [13:24<25:19,  2.53it/s][2025-02-04 02:50:14][root][INFO] - Training Epoch: 2/2, step 19994/23838 completed (loss: 0.43370068073272705, acc: 0.795918345451355)
[2025-02-04 02:50:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19996/23838 [13:25<24:26,  2.62it/s][2025-02-04 02:50:14][root][INFO] - Training Epoch: 2/2, step 19995/23838 completed (loss: 0.2862779200077057, acc: 0.8840579986572266)
[2025-02-04 02:50:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19997/23838 [13:25<24:36,  2.60it/s][2025-02-04 02:50:15][root][INFO] - Training Epoch: 2/2, step 19996/23838 completed (loss: 0.8243669271469116, acc: 0.7837837934494019)
[2025-02-04 02:50:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19998/23838 [13:26<24:55,  2.57it/s][2025-02-04 02:50:15][root][INFO] - Training Epoch: 2/2, step 19997/23838 completed (loss: 0.38520538806915283, acc: 0.849056601524353)
[2025-02-04 02:50:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 19999/23838 [13:26<23:53,  2.68it/s][2025-02-04 02:50:16][root][INFO] - Training Epoch: 2/2, step 19998/23838 completed (loss: 0.4969661831855774, acc: 0.8399999737739563)
[2025-02-04 02:50:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20000/23838 [13:26<22:47,  2.81it/s][2025-02-04 02:50:16][root][INFO] - Training Epoch: 2/2, step 19999/23838 completed (loss: 0.45250535011291504, acc: 0.8723404407501221)
[2025-02-04 02:50:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20001/23838 [13:27<23:25,  2.73it/s][2025-02-04 02:50:16][root][INFO] - Training Epoch: 2/2, step 20000/23838 completed (loss: 0.5272423028945923, acc: 0.8627451062202454)
[2025-02-04 02:50:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20002/23838 [13:27<24:30,  2.61it/s][2025-02-04 02:50:17][root][INFO] - Training Epoch: 2/2, step 20001/23838 completed (loss: 0.5922351479530334, acc: 0.7678571343421936)
[2025-02-04 02:50:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20003/23838 [13:27<23:58,  2.67it/s][2025-02-04 02:50:17][root][INFO] - Training Epoch: 2/2, step 20002/23838 completed (loss: 0.5707127451896667, acc: 0.8333333134651184)
[2025-02-04 02:50:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20004/23838 [13:28<24:26,  2.61it/s][2025-02-04 02:50:17][root][INFO] - Training Epoch: 2/2, step 20003/23838 completed (loss: 0.34125056862831116, acc: 0.9032257795333862)
[2025-02-04 02:50:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20005/23838 [13:28<24:06,  2.65it/s][2025-02-04 02:50:18][root][INFO] - Training Epoch: 2/2, step 20004/23838 completed (loss: 0.2274644523859024, acc: 0.9649122953414917)
[2025-02-04 02:50:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20006/23838 [13:29<27:10,  2.35it/s][2025-02-04 02:50:18][root][INFO] - Training Epoch: 2/2, step 20005/23838 completed (loss: 0.31148794293403625, acc: 0.8999999761581421)
[2025-02-04 02:50:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20007/23838 [13:29<27:44,  2.30it/s][2025-02-04 02:50:19][root][INFO] - Training Epoch: 2/2, step 20006/23838 completed (loss: 0.07960180938243866, acc: 0.9803921580314636)
[2025-02-04 02:50:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20008/23838 [13:30<27:56,  2.28it/s][2025-02-04 02:50:19][root][INFO] - Training Epoch: 2/2, step 20007/23838 completed (loss: 0.21850819885730743, acc: 0.9252336621284485)
[2025-02-04 02:50:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20009/23838 [13:30<27:29,  2.32it/s][2025-02-04 02:50:20][root][INFO] - Training Epoch: 2/2, step 20008/23838 completed (loss: 0.533562183380127, acc: 0.8372092843055725)
[2025-02-04 02:50:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20010/23838 [13:31<29:54,  2.13it/s][2025-02-04 02:50:20][root][INFO] - Training Epoch: 2/2, step 20009/23838 completed (loss: 0.46422135829925537, acc: 0.8925619721412659)
[2025-02-04 02:50:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20011/23838 [13:31<27:35,  2.31it/s][2025-02-04 02:50:21][root][INFO] - Training Epoch: 2/2, step 20010/23838 completed (loss: 0.5007559657096863, acc: 0.9193548560142517)
[2025-02-04 02:50:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20012/23838 [13:31<25:57,  2.46it/s][2025-02-04 02:50:21][root][INFO] - Training Epoch: 2/2, step 20011/23838 completed (loss: 0.13469143211841583, acc: 0.961904764175415)
[2025-02-04 02:50:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20013/23838 [13:32<25:16,  2.52it/s][2025-02-04 02:50:21][root][INFO] - Training Epoch: 2/2, step 20012/23838 completed (loss: 0.30547305941581726, acc: 0.9108911156654358)
[2025-02-04 02:50:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20014/23838 [13:32<25:09,  2.53it/s][2025-02-04 02:50:22][root][INFO] - Training Epoch: 2/2, step 20013/23838 completed (loss: 0.12151647359132767, acc: 0.9589040875434875)
[2025-02-04 02:50:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20015/23838 [13:32<25:13,  2.53it/s][2025-02-04 02:50:22][root][INFO] - Training Epoch: 2/2, step 20014/23838 completed (loss: 0.0895194485783577, acc: 0.9769230484962463)
[2025-02-04 02:50:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20016/23838 [13:33<23:27,  2.72it/s][2025-02-04 02:50:22][root][INFO] - Training Epoch: 2/2, step 20015/23838 completed (loss: 0.013592320494353771, acc: 1.0)
[2025-02-04 02:50:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20017/23838 [13:33<23:00,  2.77it/s][2025-02-04 02:50:23][root][INFO] - Training Epoch: 2/2, step 20016/23838 completed (loss: 0.06510129570960999, acc: 0.9907407164573669)
[2025-02-04 02:50:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20018/23838 [13:33<22:29,  2.83it/s][2025-02-04 02:50:23][root][INFO] - Training Epoch: 2/2, step 20017/23838 completed (loss: 0.16278763115406036, acc: 0.9363636374473572)
[2025-02-04 02:50:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20019/23838 [13:34<23:23,  2.72it/s][2025-02-04 02:50:23][root][INFO] - Training Epoch: 2/2, step 20018/23838 completed (loss: 0.2773166596889496, acc: 0.9137930870056152)
[2025-02-04 02:50:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20020/23838 [13:34<22:21,  2.85it/s][2025-02-04 02:50:24][root][INFO] - Training Epoch: 2/2, step 20019/23838 completed (loss: 0.38437026739120483, acc: 0.8829787373542786)
[2025-02-04 02:50:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20021/23838 [13:34<22:03,  2.88it/s][2025-02-04 02:50:24][root][INFO] - Training Epoch: 2/2, step 20020/23838 completed (loss: 0.22102877497673035, acc: 0.9280575513839722)
[2025-02-04 02:50:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20022/23838 [13:35<22:00,  2.89it/s][2025-02-04 02:50:24][root][INFO] - Training Epoch: 2/2, step 20021/23838 completed (loss: 0.5999044179916382, acc: 0.804347813129425)
[2025-02-04 02:50:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20023/23838 [13:35<21:16,  2.99it/s][2025-02-04 02:50:25][root][INFO] - Training Epoch: 2/2, step 20022/23838 completed (loss: 0.48331937193870544, acc: 0.8348624110221863)
[2025-02-04 02:50:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20024/23838 [13:35<21:11,  3.00it/s][2025-02-04 02:50:25][root][INFO] - Training Epoch: 2/2, step 20023/23838 completed (loss: 0.9154080152511597, acc: 0.7250000238418579)
[2025-02-04 02:50:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20025/23838 [13:36<21:05,  3.01it/s][2025-02-04 02:50:25][root][INFO] - Training Epoch: 2/2, step 20024/23838 completed (loss: 0.35234835743904114, acc: 0.8888888955116272)
[2025-02-04 02:50:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20026/23838 [13:36<22:11,  2.86it/s][2025-02-04 02:50:26][root][INFO] - Training Epoch: 2/2, step 20025/23838 completed (loss: 0.37062761187553406, acc: 0.8947368264198303)
[2025-02-04 02:50:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20027/23838 [13:37<23:02,  2.76it/s][2025-02-04 02:50:26][root][INFO] - Training Epoch: 2/2, step 20026/23838 completed (loss: 0.19237583875656128, acc: 0.9583333134651184)
[2025-02-04 02:50:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20028/23838 [13:37<22:54,  2.77it/s][2025-02-04 02:50:27][root][INFO] - Training Epoch: 2/2, step 20027/23838 completed (loss: 0.7200316190719604, acc: 0.7272727489471436)
[2025-02-04 02:50:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20029/23838 [13:37<23:41,  2.68it/s][2025-02-04 02:50:27][root][INFO] - Training Epoch: 2/2, step 20028/23838 completed (loss: 0.4666595160961151, acc: 0.9166666865348816)
[2025-02-04 02:50:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20030/23838 [13:38<23:10,  2.74it/s][2025-02-04 02:50:27][root][INFO] - Training Epoch: 2/2, step 20029/23838 completed (loss: 0.037080761045217514, acc: 1.0)
[2025-02-04 02:50:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20031/23838 [13:38<22:38,  2.80it/s][2025-02-04 02:50:28][root][INFO] - Training Epoch: 2/2, step 20030/23838 completed (loss: 0.4237314760684967, acc: 0.875)
[2025-02-04 02:50:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20032/23838 [13:38<22:46,  2.78it/s][2025-02-04 02:50:28][root][INFO] - Training Epoch: 2/2, step 20031/23838 completed (loss: 0.20001433789730072, acc: 0.9473684430122375)
[2025-02-04 02:50:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20033/23838 [13:39<23:02,  2.75it/s][2025-02-04 02:50:28][root][INFO] - Training Epoch: 2/2, step 20032/23838 completed (loss: 0.9826950430870056, acc: 0.7916666865348816)
[2025-02-04 02:50:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20034/23838 [13:39<23:05,  2.75it/s][2025-02-04 02:50:29][root][INFO] - Training Epoch: 2/2, step 20033/23838 completed (loss: 0.1346733570098877, acc: 0.9523809552192688)
[2025-02-04 02:50:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20035/23838 [13:39<22:42,  2.79it/s][2025-02-04 02:50:29][root][INFO] - Training Epoch: 2/2, step 20034/23838 completed (loss: 0.12003199011087418, acc: 0.9583333134651184)
[2025-02-04 02:50:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20036/23838 [13:40<22:33,  2.81it/s][2025-02-04 02:50:29][root][INFO] - Training Epoch: 2/2, step 20035/23838 completed (loss: 0.9674170017242432, acc: 0.7096773982048035)
[2025-02-04 02:50:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20037/23838 [13:40<22:30,  2.81it/s][2025-02-04 02:50:30][root][INFO] - Training Epoch: 2/2, step 20036/23838 completed (loss: 0.5118797421455383, acc: 0.8799999952316284)
[2025-02-04 02:50:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20038/23838 [13:41<23:05,  2.74it/s][2025-02-04 02:50:30][root][INFO] - Training Epoch: 2/2, step 20037/23838 completed (loss: 0.5566194653511047, acc: 0.8695651888847351)
[2025-02-04 02:50:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20039/23838 [13:41<23:15,  2.72it/s][2025-02-04 02:50:31][root][INFO] - Training Epoch: 2/2, step 20038/23838 completed (loss: 0.8888596296310425, acc: 0.9047619104385376)
[2025-02-04 02:50:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20040/23838 [13:41<23:33,  2.69it/s][2025-02-04 02:50:31][root][INFO] - Training Epoch: 2/2, step 20039/23838 completed (loss: 0.2621749937534332, acc: 0.8999999761581421)
[2025-02-04 02:50:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20041/23838 [13:42<22:57,  2.76it/s][2025-02-04 02:50:31][root][INFO] - Training Epoch: 2/2, step 20040/23838 completed (loss: 0.3652288317680359, acc: 0.9130434989929199)
[2025-02-04 02:50:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20042/23838 [13:42<22:43,  2.78it/s][2025-02-04 02:50:32][root][INFO] - Training Epoch: 2/2, step 20041/23838 completed (loss: 0.5518726706504822, acc: 0.8904109597206116)
[2025-02-04 02:50:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20043/23838 [13:42<22:51,  2.77it/s][2025-02-04 02:50:32][root][INFO] - Training Epoch: 2/2, step 20042/23838 completed (loss: 0.19523486495018005, acc: 0.9568965435028076)
[2025-02-04 02:50:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20044/23838 [13:43<23:46,  2.66it/s][2025-02-04 02:50:32][root][INFO] - Training Epoch: 2/2, step 20043/23838 completed (loss: 0.8341496586799622, acc: 0.7887324094772339)
[2025-02-04 02:50:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20045/23838 [13:43<25:06,  2.52it/s][2025-02-04 02:50:33][root][INFO] - Training Epoch: 2/2, step 20044/23838 completed (loss: 0.39118868112564087, acc: 0.8909090757369995)
[2025-02-04 02:50:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20046/23838 [13:44<25:14,  2.50it/s][2025-02-04 02:50:33][root][INFO] - Training Epoch: 2/2, step 20045/23838 completed (loss: 0.4927380383014679, acc: 0.875)
[2025-02-04 02:50:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20047/23838 [13:44<24:01,  2.63it/s][2025-02-04 02:50:34][root][INFO] - Training Epoch: 2/2, step 20046/23838 completed (loss: 0.46699896454811096, acc: 0.8399999737739563)
[2025-02-04 02:50:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20048/23838 [13:44<23:20,  2.71it/s][2025-02-04 02:50:34][root][INFO] - Training Epoch: 2/2, step 20047/23838 completed (loss: 0.34013429284095764, acc: 0.9010416865348816)
[2025-02-04 02:50:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20049/23838 [13:45<23:15,  2.71it/s][2025-02-04 02:50:34][root][INFO] - Training Epoch: 2/2, step 20048/23838 completed (loss: 0.10180959850549698, acc: 0.9578947424888611)
[2025-02-04 02:50:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20050/23838 [13:45<22:02,  2.86it/s][2025-02-04 02:50:35][root][INFO] - Training Epoch: 2/2, step 20049/23838 completed (loss: 0.24729211628437042, acc: 0.9285714030265808)
[2025-02-04 02:50:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20051/23838 [13:45<21:38,  2.92it/s][2025-02-04 02:50:35][root][INFO] - Training Epoch: 2/2, step 20050/23838 completed (loss: 0.1778121292591095, acc: 0.9603174328804016)
[2025-02-04 02:50:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20052/23838 [13:46<21:39,  2.91it/s][2025-02-04 02:50:35][root][INFO] - Training Epoch: 2/2, step 20051/23838 completed (loss: 0.29609403014183044, acc: 0.929729700088501)
[2025-02-04 02:50:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20053/23838 [13:46<21:04,  2.99it/s][2025-02-04 02:50:36][root][INFO] - Training Epoch: 2/2, step 20052/23838 completed (loss: 0.28509682416915894, acc: 0.9083333611488342)
[2025-02-04 02:50:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20054/23838 [13:46<21:08,  2.98it/s][2025-02-04 02:50:36][root][INFO] - Training Epoch: 2/2, step 20053/23838 completed (loss: 0.3895663022994995, acc: 0.8918918967247009)
[2025-02-04 02:50:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20055/23838 [13:47<21:12,  2.97it/s][2025-02-04 02:50:36][root][INFO] - Training Epoch: 2/2, step 20054/23838 completed (loss: 0.17952334880828857, acc: 0.9395973086357117)
[2025-02-04 02:50:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20056/23838 [13:47<21:57,  2.87it/s][2025-02-04 02:50:37][root][INFO] - Training Epoch: 2/2, step 20055/23838 completed (loss: 0.3967103362083435, acc: 0.8986486196517944)
[2025-02-04 02:50:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20057/23838 [13:47<22:13,  2.83it/s][2025-02-04 02:50:37][root][INFO] - Training Epoch: 2/2, step 20056/23838 completed (loss: 0.16806529462337494, acc: 0.9455782175064087)
[2025-02-04 02:50:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20058/23838 [13:48<22:01,  2.86it/s][2025-02-04 02:50:37][root][INFO] - Training Epoch: 2/2, step 20057/23838 completed (loss: 0.3443996012210846, acc: 0.9223300814628601)
[2025-02-04 02:50:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20059/23838 [13:48<21:36,  2.92it/s][2025-02-04 02:50:38][root][INFO] - Training Epoch: 2/2, step 20058/23838 completed (loss: 0.23232893645763397, acc: 0.9285714030265808)
[2025-02-04 02:50:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20060/23838 [13:48<22:12,  2.84it/s][2025-02-04 02:50:38][root][INFO] - Training Epoch: 2/2, step 20059/23838 completed (loss: 0.9297971725463867, acc: 0.7227723002433777)
[2025-02-04 02:50:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20061/23838 [13:49<22:23,  2.81it/s][2025-02-04 02:50:38][root][INFO] - Training Epoch: 2/2, step 20060/23838 completed (loss: 0.25619152188301086, acc: 0.9126983880996704)
[2025-02-04 02:50:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20062/23838 [13:49<23:27,  2.68it/s][2025-02-04 02:50:39][root][INFO] - Training Epoch: 2/2, step 20061/23838 completed (loss: 0.27567481994628906, acc: 0.9435483813285828)
[2025-02-04 02:50:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20063/23838 [13:50<24:10,  2.60it/s][2025-02-04 02:50:39][root][INFO] - Training Epoch: 2/2, step 20062/23838 completed (loss: 0.22914066910743713, acc: 0.9387755393981934)
[2025-02-04 02:50:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20064/23838 [13:50<23:05,  2.72it/s][2025-02-04 02:50:40][root][INFO] - Training Epoch: 2/2, step 20063/23838 completed (loss: 0.22431042790412903, acc: 0.9444444179534912)
[2025-02-04 02:50:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20065/23838 [13:50<24:15,  2.59it/s][2025-02-04 02:50:40][root][INFO] - Training Epoch: 2/2, step 20064/23838 completed (loss: 0.13561561703681946, acc: 0.9727891087532043)
[2025-02-04 02:50:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20066/23838 [13:51<24:12,  2.60it/s][2025-02-04 02:50:40][root][INFO] - Training Epoch: 2/2, step 20065/23838 completed (loss: 0.508823037147522, acc: 0.8651685118675232)
[2025-02-04 02:50:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20067/23838 [13:51<24:43,  2.54it/s][2025-02-04 02:50:41][root][INFO] - Training Epoch: 2/2, step 20066/23838 completed (loss: 0.18340745568275452, acc: 0.9575757384300232)
[2025-02-04 02:50:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20068/23838 [13:52<24:37,  2.55it/s][2025-02-04 02:50:41][root][INFO] - Training Epoch: 2/2, step 20067/23838 completed (loss: 0.18715567886829376, acc: 0.9428571462631226)
[2025-02-04 02:50:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20069/23838 [13:52<23:48,  2.64it/s][2025-02-04 02:50:41][root][INFO] - Training Epoch: 2/2, step 20068/23838 completed (loss: 0.09384448081254959, acc: 0.9610389471054077)
[2025-02-04 02:50:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20070/23838 [13:52<24:02,  2.61it/s][2025-02-04 02:50:42][root][INFO] - Training Epoch: 2/2, step 20069/23838 completed (loss: 0.3706519603729248, acc: 0.918367326259613)
[2025-02-04 02:50:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20071/23838 [13:53<23:23,  2.68it/s][2025-02-04 02:50:42][root][INFO] - Training Epoch: 2/2, step 20070/23838 completed (loss: 0.2723078429698944, acc: 0.9354838728904724)
[2025-02-04 02:50:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20072/23838 [13:53<24:07,  2.60it/s][2025-02-04 02:50:43][root][INFO] - Training Epoch: 2/2, step 20071/23838 completed (loss: 0.17014166712760925, acc: 0.9634146094322205)
[2025-02-04 02:50:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20073/23838 [13:53<24:27,  2.57it/s][2025-02-04 02:50:43][root][INFO] - Training Epoch: 2/2, step 20072/23838 completed (loss: 0.18348489701747894, acc: 0.9411764740943909)
[2025-02-04 02:50:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20074/23838 [13:54<23:25,  2.68it/s][2025-02-04 02:50:43][root][INFO] - Training Epoch: 2/2, step 20073/23838 completed (loss: 0.6259417533874512, acc: 0.7954545617103577)
[2025-02-04 02:50:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20075/23838 [13:54<22:44,  2.76it/s][2025-02-04 02:50:44][root][INFO] - Training Epoch: 2/2, step 20074/23838 completed (loss: 0.6111032962799072, acc: 0.8503401279449463)
[2025-02-04 02:50:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20076/23838 [13:54<21:52,  2.87it/s][2025-02-04 02:50:44][root][INFO] - Training Epoch: 2/2, step 20075/23838 completed (loss: 0.36517947912216187, acc: 0.8909090757369995)
[2025-02-04 02:50:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20077/23838 [13:55<22:07,  2.83it/s][2025-02-04 02:50:44][root][INFO] - Training Epoch: 2/2, step 20076/23838 completed (loss: 0.536798357963562, acc: 0.8606557250022888)
[2025-02-04 02:50:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20078/23838 [13:55<22:45,  2.75it/s][2025-02-04 02:50:45][root][INFO] - Training Epoch: 2/2, step 20077/23838 completed (loss: 0.7046366930007935, acc: 0.7894737124443054)
[2025-02-04 02:50:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20079/23838 [13:56<24:19,  2.58it/s][2025-02-04 02:50:45][root][INFO] - Training Epoch: 2/2, step 20078/23838 completed (loss: 0.37165367603302, acc: 0.8867924809455872)
[2025-02-04 02:50:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20080/23838 [13:56<23:36,  2.65it/s][2025-02-04 02:50:46][root][INFO] - Training Epoch: 2/2, step 20079/23838 completed (loss: 0.5528236627578735, acc: 0.8059701323509216)
[2025-02-04 02:50:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20081/23838 [13:56<23:55,  2.62it/s][2025-02-04 02:50:46][root][INFO] - Training Epoch: 2/2, step 20080/23838 completed (loss: 0.29982295632362366, acc: 0.9146341681480408)
[2025-02-04 02:50:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20082/23838 [13:57<26:09,  2.39it/s][2025-02-04 02:50:46][root][INFO] - Training Epoch: 2/2, step 20081/23838 completed (loss: 0.29085278511047363, acc: 0.8987341523170471)
[2025-02-04 02:50:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20083/23838 [13:57<25:15,  2.48it/s][2025-02-04 02:50:47][root][INFO] - Training Epoch: 2/2, step 20082/23838 completed (loss: 0.17638352513313293, acc: 0.957317054271698)
[2025-02-04 02:50:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20084/23838 [13:58<25:05,  2.49it/s][2025-02-04 02:50:47][root][INFO] - Training Epoch: 2/2, step 20083/23838 completed (loss: 0.6379309892654419, acc: 0.8305084705352783)
[2025-02-04 02:50:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20085/23838 [13:58<24:06,  2.59it/s][2025-02-04 02:50:48][root][INFO] - Training Epoch: 2/2, step 20084/23838 completed (loss: 0.36879363656044006, acc: 0.9047619104385376)
[2025-02-04 02:50:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20086/23838 [13:58<23:33,  2.65it/s][2025-02-04 02:50:48][root][INFO] - Training Epoch: 2/2, step 20085/23838 completed (loss: 0.2653190791606903, acc: 0.9491525292396545)
[2025-02-04 02:50:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20087/23838 [13:59<22:59,  2.72it/s][2025-02-04 02:50:48][root][INFO] - Training Epoch: 2/2, step 20086/23838 completed (loss: 0.09198775142431259, acc: 0.967391312122345)
[2025-02-04 02:50:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20088/23838 [13:59<22:31,  2.77it/s][2025-02-04 02:50:49][root][INFO] - Training Epoch: 2/2, step 20087/23838 completed (loss: 0.2753918766975403, acc: 0.9329268336296082)
[2025-02-04 02:50:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20089/23838 [13:59<22:39,  2.76it/s][2025-02-04 02:50:49][root][INFO] - Training Epoch: 2/2, step 20088/23838 completed (loss: 0.12075233459472656, acc: 0.9599999785423279)
[2025-02-04 02:50:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20090/23838 [14:00<22:42,  2.75it/s][2025-02-04 02:50:49][root][INFO] - Training Epoch: 2/2, step 20089/23838 completed (loss: 0.502034068107605, acc: 0.8881118893623352)
[2025-02-04 02:50:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20091/23838 [14:00<22:48,  2.74it/s][2025-02-04 02:50:50][root][INFO] - Training Epoch: 2/2, step 20090/23838 completed (loss: 0.19728270173072815, acc: 0.9683544039726257)
[2025-02-04 02:50:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20092/23838 [14:01<23:48,  2.62it/s][2025-02-04 02:50:50][root][INFO] - Training Epoch: 2/2, step 20091/23838 completed (loss: 0.3694932758808136, acc: 0.9083333611488342)
[2025-02-04 02:50:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20093/23838 [14:01<23:31,  2.65it/s][2025-02-04 02:50:51][root][INFO] - Training Epoch: 2/2, step 20092/23838 completed (loss: 0.379171222448349, acc: 0.8907563090324402)
[2025-02-04 02:50:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20094/23838 [14:01<23:26,  2.66it/s][2025-02-04 02:50:51][root][INFO] - Training Epoch: 2/2, step 20093/23838 completed (loss: 0.26959583163261414, acc: 0.9333333373069763)
[2025-02-04 02:50:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20095/23838 [14:02<22:27,  2.78it/s][2025-02-04 02:50:51][root][INFO] - Training Epoch: 2/2, step 20094/23838 completed (loss: 0.4071093499660492, acc: 0.8807339668273926)
[2025-02-04 02:50:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20096/23838 [14:02<21:52,  2.85it/s][2025-02-04 02:50:52][root][INFO] - Training Epoch: 2/2, step 20095/23838 completed (loss: 0.15937869250774384, acc: 0.9666666388511658)
[2025-02-04 02:50:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20097/23838 [14:02<22:54,  2.72it/s][2025-02-04 02:50:52][root][INFO] - Training Epoch: 2/2, step 20096/23838 completed (loss: 0.6885030269622803, acc: 0.8229166865348816)
[2025-02-04 02:50:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20098/23838 [14:03<23:32,  2.65it/s][2025-02-04 02:50:52][root][INFO] - Training Epoch: 2/2, step 20097/23838 completed (loss: 0.2543827295303345, acc: 0.8799999952316284)
[2025-02-04 02:50:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20099/23838 [14:03<21:44,  2.87it/s][2025-02-04 02:50:53][root][INFO] - Training Epoch: 2/2, step 20098/23838 completed (loss: 0.3209763467311859, acc: 0.9197080135345459)
[2025-02-04 02:50:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20100/23838 [14:03<21:17,  2.93it/s][2025-02-04 02:50:53][root][INFO] - Training Epoch: 2/2, step 20099/23838 completed (loss: 0.4314657151699066, acc: 0.8879310488700867)
[2025-02-04 02:50:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20101/23838 [14:04<20:59,  2.97it/s][2025-02-04 02:50:53][root][INFO] - Training Epoch: 2/2, step 20100/23838 completed (loss: 0.15536433458328247, acc: 0.9439252614974976)
[2025-02-04 02:50:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20102/23838 [14:04<20:40,  3.01it/s][2025-02-04 02:50:54][root][INFO] - Training Epoch: 2/2, step 20101/23838 completed (loss: 0.34606435894966125, acc: 0.9082568883895874)
[2025-02-04 02:50:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20103/23838 [14:04<21:14,  2.93it/s][2025-02-04 02:50:54][root][INFO] - Training Epoch: 2/2, step 20102/23838 completed (loss: 0.09430143237113953, acc: 0.9710144996643066)
[2025-02-04 02:50:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20104/23838 [14:05<21:58,  2.83it/s][2025-02-04 02:50:54][root][INFO] - Training Epoch: 2/2, step 20103/23838 completed (loss: 0.2625221610069275, acc: 0.9210526347160339)
[2025-02-04 02:50:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20105/23838 [14:05<20:57,  2.97it/s][2025-02-04 02:50:55][root][INFO] - Training Epoch: 2/2, step 20104/23838 completed (loss: 0.16368648409843445, acc: 0.936170220375061)
[2025-02-04 02:50:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20106/23838 [14:05<21:20,  2.91it/s][2025-02-04 02:50:55][root][INFO] - Training Epoch: 2/2, step 20105/23838 completed (loss: 0.14282673597335815, acc: 0.9606741666793823)
[2025-02-04 02:50:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20107/23838 [14:06<22:14,  2.80it/s][2025-02-04 02:50:55][root][INFO] - Training Epoch: 2/2, step 20106/23838 completed (loss: 0.29933321475982666, acc: 0.93034827709198)
[2025-02-04 02:50:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20108/23838 [14:06<21:56,  2.83it/s][2025-02-04 02:50:56][root][INFO] - Training Epoch: 2/2, step 20107/23838 completed (loss: 0.4740637540817261, acc: 0.858208954334259)
[2025-02-04 02:50:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20109/23838 [14:07<21:51,  2.84it/s][2025-02-04 02:50:56][root][INFO] - Training Epoch: 2/2, step 20108/23838 completed (loss: 0.480064332485199, acc: 0.8602941036224365)
[2025-02-04 02:50:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20110/23838 [14:07<21:09,  2.94it/s][2025-02-04 02:50:56][root][INFO] - Training Epoch: 2/2, step 20109/23838 completed (loss: 0.18043221533298492, acc: 0.9622641801834106)
[2025-02-04 02:50:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20111/23838 [14:07<20:52,  2.98it/s][2025-02-04 02:50:57][root][INFO] - Training Epoch: 2/2, step 20110/23838 completed (loss: 0.667308509349823, acc: 0.8421052694320679)
[2025-02-04 02:50:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20112/23838 [14:07<20:07,  3.08it/s][2025-02-04 02:50:57][root][INFO] - Training Epoch: 2/2, step 20111/23838 completed (loss: 0.552187979221344, acc: 0.7894737124443054)
[2025-02-04 02:50:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20113/23838 [14:08<20:54,  2.97it/s][2025-02-04 02:50:57][root][INFO] - Training Epoch: 2/2, step 20112/23838 completed (loss: 0.27650487422943115, acc: 0.9216867685317993)
[2025-02-04 02:50:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20114/23838 [14:08<21:41,  2.86it/s][2025-02-04 02:50:58][root][INFO] - Training Epoch: 2/2, step 20113/23838 completed (loss: 0.1384953111410141, acc: 0.9375)
[2025-02-04 02:50:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20115/23838 [14:09<21:30,  2.89it/s][2025-02-04 02:50:58][root][INFO] - Training Epoch: 2/2, step 20114/23838 completed (loss: 0.3366101384162903, acc: 0.8918918967247009)
[2025-02-04 02:50:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20116/23838 [14:09<20:51,  2.97it/s][2025-02-04 02:50:58][root][INFO] - Training Epoch: 2/2, step 20115/23838 completed (loss: 0.21589575707912445, acc: 0.9465649127960205)
[2025-02-04 02:50:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20117/23838 [14:09<21:02,  2.95it/s][2025-02-04 02:50:59][root][INFO] - Training Epoch: 2/2, step 20116/23838 completed (loss: 0.3716580867767334, acc: 0.8909090757369995)
[2025-02-04 02:50:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20118/23838 [14:10<20:56,  2.96it/s][2025-02-04 02:50:59][root][INFO] - Training Epoch: 2/2, step 20117/23838 completed (loss: 0.8102788925170898, acc: 0.7733333110809326)
[2025-02-04 02:50:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20119/23838 [14:10<20:20,  3.05it/s][2025-02-04 02:50:59][root][INFO] - Training Epoch: 2/2, step 20118/23838 completed (loss: 0.26184532046318054, acc: 0.9545454382896423)
[2025-02-04 02:51:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20120/23838 [14:10<20:37,  3.01it/s][2025-02-04 02:51:00][root][INFO] - Training Epoch: 2/2, step 20119/23838 completed (loss: 0.3895098865032196, acc: 0.8846153616905212)
[2025-02-04 02:51:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20121/23838 [14:11<21:23,  2.90it/s][2025-02-04 02:51:00][root][INFO] - Training Epoch: 2/2, step 20120/23838 completed (loss: 0.7557557225227356, acc: 0.8208954930305481)
[2025-02-04 02:51:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20122/23838 [14:11<21:38,  2.86it/s][2025-02-04 02:51:00][root][INFO] - Training Epoch: 2/2, step 20121/23838 completed (loss: 0.6920478343963623, acc: 0.7878788113594055)
[2025-02-04 02:51:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20123/23838 [14:11<22:41,  2.73it/s][2025-02-04 02:51:01][root][INFO] - Training Epoch: 2/2, step 20122/23838 completed (loss: 0.4237266480922699, acc: 0.824999988079071)
[2025-02-04 02:51:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20124/23838 [14:12<25:23,  2.44it/s][2025-02-04 02:51:01][root][INFO] - Training Epoch: 2/2, step 20123/23838 completed (loss: 0.3321787416934967, acc: 0.9372549057006836)
[2025-02-04 02:51:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20125/23838 [14:12<24:59,  2.48it/s][2025-02-04 02:51:02][root][INFO] - Training Epoch: 2/2, step 20124/23838 completed (loss: 0.6039427518844604, acc: 0.8701298832893372)
[2025-02-04 02:51:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20126/23838 [14:13<26:29,  2.34it/s][2025-02-04 02:51:02][root][INFO] - Training Epoch: 2/2, step 20125/23838 completed (loss: 0.5465903878211975, acc: 0.8761062026023865)
[2025-02-04 02:51:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20127/23838 [14:13<25:34,  2.42it/s][2025-02-04 02:51:03][root][INFO] - Training Epoch: 2/2, step 20126/23838 completed (loss: 0.2317478358745575, acc: 0.9307692050933838)
[2025-02-04 02:51:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20128/23838 [14:13<24:09,  2.56it/s][2025-02-04 02:51:03][root][INFO] - Training Epoch: 2/2, step 20127/23838 completed (loss: 0.10509072989225388, acc: 0.9607843160629272)
[2025-02-04 02:51:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20129/23838 [14:14<27:18,  2.26it/s][2025-02-04 02:51:04][root][INFO] - Training Epoch: 2/2, step 20128/23838 completed (loss: 0.5986769795417786, acc: 0.8325581550598145)
[2025-02-04 02:51:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20130/23838 [14:14<26:36,  2.32it/s][2025-02-04 02:51:04][root][INFO] - Training Epoch: 2/2, step 20129/23838 completed (loss: 0.5045085549354553, acc: 0.8872180581092834)
[2025-02-04 02:51:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20131/23838 [14:15<26:34,  2.33it/s][2025-02-04 02:51:04][root][INFO] - Training Epoch: 2/2, step 20130/23838 completed (loss: 0.7249972224235535, acc: 0.7777777910232544)
[2025-02-04 02:51:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20132/23838 [14:15<25:57,  2.38it/s][2025-02-04 02:51:05][root][INFO] - Training Epoch: 2/2, step 20131/23838 completed (loss: 0.35421910881996155, acc: 0.8880000114440918)
[2025-02-04 02:51:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20133/23838 [14:16<25:28,  2.42it/s][2025-02-04 02:51:05][root][INFO] - Training Epoch: 2/2, step 20132/23838 completed (loss: 0.3401360511779785, acc: 0.9215686321258545)
[2025-02-04 02:51:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20134/23838 [14:16<26:07,  2.36it/s][2025-02-04 02:51:06][root][INFO] - Training Epoch: 2/2, step 20133/23838 completed (loss: 0.389771431684494, acc: 0.875)
[2025-02-04 02:51:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20135/23838 [14:17<27:52,  2.21it/s][2025-02-04 02:51:06][root][INFO] - Training Epoch: 2/2, step 20134/23838 completed (loss: 0.21064990758895874, acc: 0.948616623878479)
[2025-02-04 02:51:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20136/23838 [14:17<26:21,  2.34it/s][2025-02-04 02:51:07][root][INFO] - Training Epoch: 2/2, step 20135/23838 completed (loss: 0.480337917804718, acc: 0.8723404407501221)
[2025-02-04 02:51:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20137/23838 [14:17<24:14,  2.54it/s][2025-02-04 02:51:07][root][INFO] - Training Epoch: 2/2, step 20136/23838 completed (loss: 0.35680702328681946, acc: 0.8990825414657593)
[2025-02-04 02:51:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20138/23838 [14:18<23:35,  2.61it/s][2025-02-04 02:51:07][root][INFO] - Training Epoch: 2/2, step 20137/23838 completed (loss: 0.28306853771209717, acc: 0.9204545617103577)
[2025-02-04 02:51:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20139/23838 [14:18<23:17,  2.65it/s][2025-02-04 02:51:08][root][INFO] - Training Epoch: 2/2, step 20138/23838 completed (loss: 0.3672894239425659, acc: 0.9067796468734741)
[2025-02-04 02:51:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20140/23838 [14:18<22:37,  2.72it/s][2025-02-04 02:51:08][root][INFO] - Training Epoch: 2/2, step 20139/23838 completed (loss: 0.22568435966968536, acc: 0.9444444179534912)
[2025-02-04 02:51:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20141/23838 [14:19<22:39,  2.72it/s][2025-02-04 02:51:08][root][INFO] - Training Epoch: 2/2, step 20140/23838 completed (loss: 0.5818653702735901, acc: 0.8405796885490417)
[2025-02-04 02:51:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20142/23838 [14:19<22:21,  2.75it/s][2025-02-04 02:51:09][root][INFO] - Training Epoch: 2/2, step 20141/23838 completed (loss: 0.24636146426200867, acc: 0.9111111164093018)
[2025-02-04 02:51:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  84%|[34m████████▍ [0m| 20143/23838 [14:19<23:03,  2.67it/s][2025-02-04 02:51:09][root][INFO] - Training Epoch: 2/2, step 20142/23838 completed (loss: 0.1921989917755127, acc: 0.9318181872367859)
[2025-02-04 02:51:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20144/23838 [14:20<22:54,  2.69it/s][2025-02-04 02:51:09][root][INFO] - Training Epoch: 2/2, step 20143/23838 completed (loss: 0.3139943778514862, acc: 0.9365079402923584)
[2025-02-04 02:51:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20145/23838 [14:20<24:10,  2.55it/s][2025-02-04 02:51:10][root][INFO] - Training Epoch: 2/2, step 20144/23838 completed (loss: 0.7153505682945251, acc: 0.8030303120613098)
[2025-02-04 02:51:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20146/23838 [14:21<23:44,  2.59it/s][2025-02-04 02:51:10][root][INFO] - Training Epoch: 2/2, step 20145/23838 completed (loss: 0.21172313392162323, acc: 0.9382715821266174)
[2025-02-04 02:51:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20147/23838 [14:21<24:02,  2.56it/s][2025-02-04 02:51:11][root][INFO] - Training Epoch: 2/2, step 20146/23838 completed (loss: 0.4386994540691376, acc: 0.901098906993866)
[2025-02-04 02:51:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20148/23838 [14:21<24:28,  2.51it/s][2025-02-04 02:51:11][root][INFO] - Training Epoch: 2/2, step 20147/23838 completed (loss: 0.6309677958488464, acc: 0.837837815284729)
[2025-02-04 02:51:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20149/23838 [14:22<24:35,  2.50it/s][2025-02-04 02:51:11][root][INFO] - Training Epoch: 2/2, step 20148/23838 completed (loss: 0.14259496331214905, acc: 0.9651162624359131)
[2025-02-04 02:51:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20150/23838 [14:22<24:29,  2.51it/s][2025-02-04 02:51:12][root][INFO] - Training Epoch: 2/2, step 20149/23838 completed (loss: 0.1860840618610382, acc: 0.95652174949646)
[2025-02-04 02:51:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20151/23838 [14:23<25:12,  2.44it/s][2025-02-04 02:51:12][root][INFO] - Training Epoch: 2/2, step 20150/23838 completed (loss: 0.37948620319366455, acc: 0.8846153616905212)
[2025-02-04 02:51:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20152/23838 [14:23<24:40,  2.49it/s][2025-02-04 02:51:13][root][INFO] - Training Epoch: 2/2, step 20151/23838 completed (loss: 0.037299953401088715, acc: 1.0)
[2025-02-04 02:51:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20153/23838 [14:23<25:17,  2.43it/s][2025-02-04 02:51:13][root][INFO] - Training Epoch: 2/2, step 20152/23838 completed (loss: 0.34227830171585083, acc: 0.8775510191917419)
[2025-02-04 02:51:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20154/23838 [14:24<24:52,  2.47it/s][2025-02-04 02:51:13][root][INFO] - Training Epoch: 2/2, step 20153/23838 completed (loss: 0.6018773913383484, acc: 0.7857142686843872)
[2025-02-04 02:51:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20155/23838 [14:24<24:01,  2.56it/s][2025-02-04 02:51:14][root][INFO] - Training Epoch: 2/2, step 20154/23838 completed (loss: 0.3591853976249695, acc: 0.9142857193946838)
[2025-02-04 02:51:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20156/23838 [14:25<24:21,  2.52it/s][2025-02-04 02:51:14][root][INFO] - Training Epoch: 2/2, step 20155/23838 completed (loss: 0.5730204582214355, acc: 0.8313252925872803)
[2025-02-04 02:51:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20157/23838 [14:25<24:16,  2.53it/s][2025-02-04 02:51:15][root][INFO] - Training Epoch: 2/2, step 20156/23838 completed (loss: 0.5106562972068787, acc: 0.8765432238578796)
[2025-02-04 02:51:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20158/23838 [14:25<23:29,  2.61it/s][2025-02-04 02:51:15][root][INFO] - Training Epoch: 2/2, step 20157/23838 completed (loss: 0.4735744595527649, acc: 0.9111111164093018)
[2025-02-04 02:51:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20159/23838 [14:26<23:10,  2.65it/s][2025-02-04 02:51:15][root][INFO] - Training Epoch: 2/2, step 20158/23838 completed (loss: 0.18666991591453552, acc: 0.9417475461959839)
[2025-02-04 02:51:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20160/23838 [14:26<23:23,  2.62it/s][2025-02-04 02:51:16][root][INFO] - Training Epoch: 2/2, step 20159/23838 completed (loss: 0.33770668506622314, acc: 0.9080459475517273)
[2025-02-04 02:51:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20161/23838 [14:27<25:15,  2.43it/s][2025-02-04 02:51:16][root][INFO] - Training Epoch: 2/2, step 20160/23838 completed (loss: 0.2649816572666168, acc: 0.9122806787490845)
[2025-02-04 02:51:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20162/23838 [14:27<24:39,  2.48it/s][2025-02-04 02:51:17][root][INFO] - Training Epoch: 2/2, step 20161/23838 completed (loss: 0.12797512114048004, acc: 0.9682539701461792)
[2025-02-04 02:51:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20163/23838 [14:27<24:29,  2.50it/s][2025-02-04 02:51:17][root][INFO] - Training Epoch: 2/2, step 20162/23838 completed (loss: 0.45124730467796326, acc: 0.8723404407501221)
[2025-02-04 02:51:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20164/23838 [14:28<23:31,  2.60it/s][2025-02-04 02:51:17][root][INFO] - Training Epoch: 2/2, step 20163/23838 completed (loss: 0.1761903613805771, acc: 0.949999988079071)
[2025-02-04 02:51:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20165/23838 [14:28<24:12,  2.53it/s][2025-02-04 02:51:18][root][INFO] - Training Epoch: 2/2, step 20164/23838 completed (loss: 0.20993833243846893, acc: 0.9473684430122375)
[2025-02-04 02:51:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20166/23838 [14:29<24:38,  2.48it/s][2025-02-04 02:51:18][root][INFO] - Training Epoch: 2/2, step 20165/23838 completed (loss: 0.30200788378715515, acc: 0.8636363744735718)
[2025-02-04 02:51:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20167/23838 [14:29<25:02,  2.44it/s][2025-02-04 02:51:19][root][INFO] - Training Epoch: 2/2, step 20166/23838 completed (loss: 0.07695420831441879, acc: 0.9855072498321533)
[2025-02-04 02:51:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20168/23838 [14:29<24:14,  2.52it/s][2025-02-04 02:51:19][root][INFO] - Training Epoch: 2/2, step 20167/23838 completed (loss: 0.06621093302965164, acc: 0.978723406791687)
[2025-02-04 02:51:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20169/23838 [14:30<23:54,  2.56it/s][2025-02-04 02:51:19][root][INFO] - Training Epoch: 2/2, step 20168/23838 completed (loss: 0.17862547934055328, acc: 0.9532710313796997)
[2025-02-04 02:51:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20170/23838 [14:30<23:57,  2.55it/s][2025-02-04 02:51:20][root][INFO] - Training Epoch: 2/2, step 20169/23838 completed (loss: 0.1750885397195816, acc: 0.9436619877815247)
[2025-02-04 02:51:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20171/23838 [14:31<23:22,  2.61it/s][2025-02-04 02:51:20][root][INFO] - Training Epoch: 2/2, step 20170/23838 completed (loss: 0.714547336101532, acc: 0.774193525314331)
[2025-02-04 02:51:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20172/23838 [14:31<22:44,  2.69it/s][2025-02-04 02:51:20][root][INFO] - Training Epoch: 2/2, step 20171/23838 completed (loss: 0.49111929535865784, acc: 0.855555534362793)
[2025-02-04 02:51:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20173/23838 [14:31<22:26,  2.72it/s][2025-02-04 02:51:21][root][INFO] - Training Epoch: 2/2, step 20172/23838 completed (loss: 0.6314349174499512, acc: 0.7941176295280457)
[2025-02-04 02:51:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20174/23838 [14:32<23:00,  2.65it/s][2025-02-04 02:51:21][root][INFO] - Training Epoch: 2/2, step 20173/23838 completed (loss: 0.18606525659561157, acc: 0.9305555820465088)
[2025-02-04 02:51:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20175/23838 [14:32<23:36,  2.59it/s][2025-02-04 02:51:22][root][INFO] - Training Epoch: 2/2, step 20174/23838 completed (loss: 0.17867958545684814, acc: 0.9491525292396545)
[2025-02-04 02:51:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20176/23838 [14:32<23:11,  2.63it/s][2025-02-04 02:51:22][root][INFO] - Training Epoch: 2/2, step 20175/23838 completed (loss: 0.20162387192249298, acc: 0.9142857193946838)
[2025-02-04 02:51:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20177/23838 [14:33<23:54,  2.55it/s][2025-02-04 02:51:22][root][INFO] - Training Epoch: 2/2, step 20176/23838 completed (loss: 0.33317652344703674, acc: 0.9076923131942749)
[2025-02-04 02:51:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20178/23838 [14:33<23:03,  2.65it/s][2025-02-04 02:51:23][root][INFO] - Training Epoch: 2/2, step 20177/23838 completed (loss: 0.18953733146190643, acc: 0.9444444179534912)
[2025-02-04 02:51:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20179/23838 [14:34<22:42,  2.68it/s][2025-02-04 02:51:23][root][INFO] - Training Epoch: 2/2, step 20178/23838 completed (loss: 0.6084511280059814, acc: 0.8387096524238586)
[2025-02-04 02:51:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20180/23838 [14:34<22:44,  2.68it/s][2025-02-04 02:51:23][root][INFO] - Training Epoch: 2/2, step 20179/23838 completed (loss: 0.2844310998916626, acc: 0.9523809552192688)
[2025-02-04 02:51:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20181/23838 [14:34<22:16,  2.74it/s][2025-02-04 02:51:24][root][INFO] - Training Epoch: 2/2, step 20180/23838 completed (loss: 0.5133160352706909, acc: 0.8867924809455872)
[2025-02-04 02:51:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20182/23838 [14:35<22:11,  2.75it/s][2025-02-04 02:51:24][root][INFO] - Training Epoch: 2/2, step 20181/23838 completed (loss: 0.4180522561073303, acc: 0.875)
[2025-02-04 02:51:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20183/23838 [14:35<22:01,  2.77it/s][2025-02-04 02:51:25][root][INFO] - Training Epoch: 2/2, step 20182/23838 completed (loss: 0.16023240983486176, acc: 0.9230769276618958)
[2025-02-04 02:51:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20184/23838 [14:35<22:23,  2.72it/s][2025-02-04 02:51:25][root][INFO] - Training Epoch: 2/2, step 20183/23838 completed (loss: 0.13074059784412384, acc: 0.9775280952453613)
[2025-02-04 02:51:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20185/23838 [14:36<22:50,  2.66it/s][2025-02-04 02:51:25][root][INFO] - Training Epoch: 2/2, step 20184/23838 completed (loss: 0.16857826709747314, acc: 0.949999988079071)
[2025-02-04 02:51:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20186/23838 [14:36<22:55,  2.65it/s][2025-02-04 02:51:26][root][INFO] - Training Epoch: 2/2, step 20185/23838 completed (loss: 0.3270617425441742, acc: 0.9264705777168274)
[2025-02-04 02:51:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20187/23838 [14:36<21:47,  2.79it/s][2025-02-04 02:51:26][root][INFO] - Training Epoch: 2/2, step 20186/23838 completed (loss: 0.6132041811943054, acc: 0.875)
[2025-02-04 02:51:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20188/23838 [14:37<28:12,  2.16it/s][2025-02-04 02:51:27][root][INFO] - Training Epoch: 2/2, step 20187/23838 completed (loss: 0.6705449223518372, acc: 0.8333333134651184)
[2025-02-04 02:51:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20189/23838 [14:37<25:53,  2.35it/s][2025-02-04 02:51:27][root][INFO] - Training Epoch: 2/2, step 20188/23838 completed (loss: 0.33453309535980225, acc: 0.8969072103500366)
[2025-02-04 02:51:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20190/23838 [14:38<24:42,  2.46it/s][2025-02-04 02:51:27][root][INFO] - Training Epoch: 2/2, step 20189/23838 completed (loss: 0.18654151260852814, acc: 0.9646017551422119)
[2025-02-04 02:51:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20191/23838 [14:39<29:43,  2.05it/s][2025-02-04 02:51:28][root][INFO] - Training Epoch: 2/2, step 20190/23838 completed (loss: 0.7640780806541443, acc: 0.8260869383811951)
[2025-02-04 02:51:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20192/23838 [14:39<27:08,  2.24it/s][2025-02-04 02:51:28][root][INFO] - Training Epoch: 2/2, step 20191/23838 completed (loss: 0.31239792704582214, acc: 0.9333333373069763)
[2025-02-04 02:51:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20193/23838 [14:39<24:20,  2.50it/s][2025-02-04 02:51:29][root][INFO] - Training Epoch: 2/2, step 20192/23838 completed (loss: 0.5560122132301331, acc: 0.8695651888847351)
[2025-02-04 02:51:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20194/23838 [14:40<26:58,  2.25it/s][2025-02-04 02:51:29][root][INFO] - Training Epoch: 2/2, step 20193/23838 completed (loss: 0.2888137996196747, acc: 0.935251772403717)
[2025-02-04 02:51:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20195/23838 [14:40<25:03,  2.42it/s][2025-02-04 02:51:30][root][INFO] - Training Epoch: 2/2, step 20194/23838 completed (loss: 0.5898323059082031, acc: 0.8358209133148193)
[2025-02-04 02:51:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20196/23838 [14:40<25:09,  2.41it/s][2025-02-04 02:51:30][root][INFO] - Training Epoch: 2/2, step 20195/23838 completed (loss: 0.29039496183395386, acc: 0.9038461446762085)
[2025-02-04 02:51:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20197/23838 [14:41<27:45,  2.19it/s][2025-02-04 02:51:31][root][INFO] - Training Epoch: 2/2, step 20196/23838 completed (loss: 0.10581919550895691, acc: 0.9764705896377563)
[2025-02-04 02:51:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20198/23838 [14:42<31:38,  1.92it/s][2025-02-04 02:51:31][root][INFO] - Training Epoch: 2/2, step 20197/23838 completed (loss: 0.4041285812854767, acc: 0.8571428656578064)
[2025-02-04 02:51:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20199/23838 [14:42<30:26,  1.99it/s][2025-02-04 02:51:32][root][INFO] - Training Epoch: 2/2, step 20198/23838 completed (loss: 0.6422058343887329, acc: 0.8374999761581421)
[2025-02-04 02:51:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20200/23838 [14:43<33:28,  1.81it/s][2025-02-04 02:51:32][root][INFO] - Training Epoch: 2/2, step 20199/23838 completed (loss: 0.24878311157226562, acc: 0.954023003578186)
[2025-02-04 02:51:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20201/23838 [14:43<30:44,  1.97it/s][2025-02-04 02:51:33][root][INFO] - Training Epoch: 2/2, step 20200/23838 completed (loss: 0.3025081157684326, acc: 0.9262295365333557)
[2025-02-04 02:51:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20202/23838 [14:44<29:42,  2.04it/s][2025-02-04 02:51:33][root][INFO] - Training Epoch: 2/2, step 20201/23838 completed (loss: 0.1440402865409851, acc: 0.9674796462059021)
[2025-02-04 02:51:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20203/23838 [14:44<27:39,  2.19it/s][2025-02-04 02:51:34][root][INFO] - Training Epoch: 2/2, step 20202/23838 completed (loss: 0.28073573112487793, acc: 0.9041095972061157)
[2025-02-04 02:51:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20204/23838 [14:44<26:06,  2.32it/s][2025-02-04 02:51:34][root][INFO] - Training Epoch: 2/2, step 20203/23838 completed (loss: 0.6447736024856567, acc: 0.8039215803146362)
[2025-02-04 02:51:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20205/23838 [14:45<24:15,  2.50it/s][2025-02-04 02:51:34][root][INFO] - Training Epoch: 2/2, step 20204/23838 completed (loss: 0.8324260711669922, acc: 0.8529411554336548)
[2025-02-04 02:51:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20206/23838 [14:45<24:38,  2.46it/s][2025-02-04 02:51:35][root][INFO] - Training Epoch: 2/2, step 20205/23838 completed (loss: 0.8517583012580872, acc: 0.8108108043670654)
[2025-02-04 02:51:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20207/23838 [14:46<24:16,  2.49it/s][2025-02-04 02:51:35][root][INFO] - Training Epoch: 2/2, step 20206/23838 completed (loss: 1.3265831470489502, acc: 0.75)
[2025-02-04 02:51:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20208/23838 [14:46<24:14,  2.50it/s][2025-02-04 02:51:36][root][INFO] - Training Epoch: 2/2, step 20207/23838 completed (loss: 0.5249814987182617, acc: 0.8260869383811951)
[2025-02-04 02:51:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20209/23838 [14:46<26:25,  2.29it/s][2025-02-04 02:51:36][root][INFO] - Training Epoch: 2/2, step 20208/23838 completed (loss: 0.18296726047992706, acc: 0.957446813583374)
[2025-02-04 02:51:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20210/23838 [14:47<25:02,  2.41it/s][2025-02-04 02:51:36][root][INFO] - Training Epoch: 2/2, step 20209/23838 completed (loss: 0.5698533058166504, acc: 0.8529411554336548)
[2025-02-04 02:51:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20211/23838 [14:47<24:10,  2.50it/s][2025-02-04 02:51:37][root][INFO] - Training Epoch: 2/2, step 20210/23838 completed (loss: 0.20430032908916473, acc: 0.9438202381134033)
[2025-02-04 02:51:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20212/23838 [14:48<25:52,  2.34it/s][2025-02-04 02:51:37][root][INFO] - Training Epoch: 2/2, step 20211/23838 completed (loss: 0.32063066959381104, acc: 0.9053254723548889)
[2025-02-04 02:51:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20213/23838 [14:48<25:46,  2.34it/s][2025-02-04 02:51:38][root][INFO] - Training Epoch: 2/2, step 20212/23838 completed (loss: 0.6190195679664612, acc: 0.8360655903816223)
[2025-02-04 02:51:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20214/23838 [14:49<27:28,  2.20it/s][2025-02-04 02:51:38][root][INFO] - Training Epoch: 2/2, step 20213/23838 completed (loss: 0.6099494695663452, acc: 0.8333333134651184)
[2025-02-04 02:51:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20215/23838 [14:49<26:27,  2.28it/s][2025-02-04 02:51:39][root][INFO] - Training Epoch: 2/2, step 20214/23838 completed (loss: 0.3919965922832489, acc: 0.8965517282485962)
[2025-02-04 02:51:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20216/23838 [14:49<25:27,  2.37it/s][2025-02-04 02:51:39][root][INFO] - Training Epoch: 2/2, step 20215/23838 completed (loss: 0.34236663579940796, acc: 0.9076923131942749)
[2025-02-04 02:51:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20217/23838 [14:50<24:22,  2.48it/s][2025-02-04 02:51:39][root][INFO] - Training Epoch: 2/2, step 20216/23838 completed (loss: 0.1791764497756958, acc: 0.9411764740943909)
[2025-02-04 02:51:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20218/23838 [14:50<24:27,  2.47it/s][2025-02-04 02:51:40][root][INFO] - Training Epoch: 2/2, step 20217/23838 completed (loss: 0.4477798640727997, acc: 0.8767123222351074)
[2025-02-04 02:51:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20219/23838 [14:51<25:24,  2.37it/s][2025-02-04 02:51:40][root][INFO] - Training Epoch: 2/2, step 20218/23838 completed (loss: 0.1599944829940796, acc: 0.9605262875556946)
[2025-02-04 02:51:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20220/23838 [14:51<24:22,  2.47it/s][2025-02-04 02:51:41][root][INFO] - Training Epoch: 2/2, step 20219/23838 completed (loss: 0.723241925239563, acc: 0.7627118825912476)
[2025-02-04 02:51:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20221/23838 [14:51<24:28,  2.46it/s][2025-02-04 02:51:41][root][INFO] - Training Epoch: 2/2, step 20220/23838 completed (loss: 0.6349337697029114, acc: 0.8265306353569031)
[2025-02-04 02:51:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20222/23838 [14:52<23:15,  2.59it/s][2025-02-04 02:51:41][root][INFO] - Training Epoch: 2/2, step 20221/23838 completed (loss: 0.27204015851020813, acc: 0.9230769276618958)
[2025-02-04 02:51:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20223/23838 [14:52<23:27,  2.57it/s][2025-02-04 02:51:42][root][INFO] - Training Epoch: 2/2, step 20222/23838 completed (loss: 0.1787053495645523, acc: 0.9509803652763367)
[2025-02-04 02:51:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20224/23838 [14:53<24:38,  2.44it/s][2025-02-04 02:51:42][root][INFO] - Training Epoch: 2/2, step 20223/23838 completed (loss: 0.1400793194770813, acc: 0.9634146094322205)
[2025-02-04 02:51:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20225/23838 [14:53<24:28,  2.46it/s][2025-02-04 02:51:43][root][INFO] - Training Epoch: 2/2, step 20224/23838 completed (loss: 0.21745982766151428, acc: 0.9337748289108276)
[2025-02-04 02:51:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20226/23838 [14:53<23:46,  2.53it/s][2025-02-04 02:51:43][root][INFO] - Training Epoch: 2/2, step 20225/23838 completed (loss: 0.05084753781557083, acc: 1.0)
[2025-02-04 02:51:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20227/23838 [14:54<22:55,  2.63it/s][2025-02-04 02:51:43][root][INFO] - Training Epoch: 2/2, step 20226/23838 completed (loss: 0.12127465009689331, acc: 0.9624060392379761)
[2025-02-04 02:51:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20228/23838 [14:54<21:55,  2.74it/s][2025-02-04 02:51:44][root][INFO] - Training Epoch: 2/2, step 20227/23838 completed (loss: 0.2750459313392639, acc: 0.9174311757087708)
[2025-02-04 02:51:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20229/23838 [14:54<22:33,  2.67it/s][2025-02-04 02:51:44][root][INFO] - Training Epoch: 2/2, step 20228/23838 completed (loss: 0.14153705537319183, acc: 0.9617486596107483)
[2025-02-04 02:51:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20230/23838 [14:55<22:47,  2.64it/s][2025-02-04 02:51:44][root][INFO] - Training Epoch: 2/2, step 20229/23838 completed (loss: 0.5262820720672607, acc: 0.8611111044883728)
[2025-02-04 02:51:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20231/23838 [14:55<22:09,  2.71it/s][2025-02-04 02:51:45][root][INFO] - Training Epoch: 2/2, step 20230/23838 completed (loss: 0.6801394820213318, acc: 0.8260869383811951)
[2025-02-04 02:51:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20232/23838 [14:56<23:09,  2.60it/s][2025-02-04 02:51:45][root][INFO] - Training Epoch: 2/2, step 20231/23838 completed (loss: 0.4406718909740448, acc: 0.904411792755127)
[2025-02-04 02:51:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20233/23838 [14:56<23:05,  2.60it/s][2025-02-04 02:51:46][root][INFO] - Training Epoch: 2/2, step 20232/23838 completed (loss: 0.38103464245796204, acc: 0.9166666865348816)
[2025-02-04 02:51:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20234/23838 [14:56<22:15,  2.70it/s][2025-02-04 02:51:46][root][INFO] - Training Epoch: 2/2, step 20233/23838 completed (loss: 1.0272938013076782, acc: 0.7283950448036194)
[2025-02-04 02:51:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20235/23838 [14:57<22:53,  2.62it/s][2025-02-04 02:51:46][root][INFO] - Training Epoch: 2/2, step 20234/23838 completed (loss: 0.48716843128204346, acc: 0.8543689250946045)
[2025-02-04 02:51:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20236/23838 [14:57<22:18,  2.69it/s][2025-02-04 02:51:47][root][INFO] - Training Epoch: 2/2, step 20235/23838 completed (loss: 0.5632021427154541, acc: 0.8461538553237915)
[2025-02-04 02:51:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20237/23838 [14:57<21:56,  2.74it/s][2025-02-04 02:51:47][root][INFO] - Training Epoch: 2/2, step 20236/23838 completed (loss: 0.2686096429824829, acc: 0.9166666865348816)
[2025-02-04 02:51:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20238/23838 [14:58<22:13,  2.70it/s][2025-02-04 02:51:47][root][INFO] - Training Epoch: 2/2, step 20237/23838 completed (loss: 0.07286758720874786, acc: 1.0)
[2025-02-04 02:51:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20239/23838 [14:58<21:29,  2.79it/s][2025-02-04 02:51:48][root][INFO] - Training Epoch: 2/2, step 20238/23838 completed (loss: 0.10238167643547058, acc: 0.9659090638160706)
[2025-02-04 02:51:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20240/23838 [14:59<21:36,  2.78it/s][2025-02-04 02:51:48][root][INFO] - Training Epoch: 2/2, step 20239/23838 completed (loss: 0.18064607679843903, acc: 0.9425837397575378)
[2025-02-04 02:51:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20241/23838 [14:59<22:06,  2.71it/s][2025-02-04 02:51:49][root][INFO] - Training Epoch: 2/2, step 20240/23838 completed (loss: 0.2232351005077362, acc: 0.9342105388641357)
[2025-02-04 02:51:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20242/23838 [14:59<22:12,  2.70it/s][2025-02-04 02:51:49][root][INFO] - Training Epoch: 2/2, step 20241/23838 completed (loss: 0.16432420909404755, acc: 0.9435483813285828)
[2025-02-04 02:51:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20243/23838 [15:00<22:40,  2.64it/s][2025-02-04 02:51:49][root][INFO] - Training Epoch: 2/2, step 20242/23838 completed (loss: 0.23452812433242798, acc: 0.9469696879386902)
[2025-02-04 02:51:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20244/23838 [15:00<22:12,  2.70it/s][2025-02-04 02:51:50][root][INFO] - Training Epoch: 2/2, step 20243/23838 completed (loss: 0.1464548259973526, acc: 0.9622641801834106)
[2025-02-04 02:51:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20245/23838 [15:00<21:33,  2.78it/s][2025-02-04 02:51:50][root][INFO] - Training Epoch: 2/2, step 20244/23838 completed (loss: 0.27408328652381897, acc: 0.9583333134651184)
[2025-02-04 02:51:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20246/23838 [15:01<22:29,  2.66it/s][2025-02-04 02:51:50][root][INFO] - Training Epoch: 2/2, step 20245/23838 completed (loss: 0.3545357286930084, acc: 0.9113923907279968)
[2025-02-04 02:51:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20247/23838 [15:01<21:31,  2.78it/s][2025-02-04 02:51:51][root][INFO] - Training Epoch: 2/2, step 20246/23838 completed (loss: 0.14440204203128815, acc: 0.9603174328804016)
[2025-02-04 02:51:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20248/23838 [15:02<22:10,  2.70it/s][2025-02-04 02:51:51][root][INFO] - Training Epoch: 2/2, step 20247/23838 completed (loss: 0.07307739555835724, acc: 0.9858155846595764)
[2025-02-04 02:51:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20249/23838 [15:02<24:09,  2.48it/s][2025-02-04 02:51:52][root][INFO] - Training Epoch: 2/2, step 20248/23838 completed (loss: 0.14514248073101044, acc: 0.9646017551422119)
[2025-02-04 02:51:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20250/23838 [15:02<24:10,  2.47it/s][2025-02-04 02:51:52][root][INFO] - Training Epoch: 2/2, step 20249/23838 completed (loss: 0.19288700819015503, acc: 0.9487179517745972)
[2025-02-04 02:51:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20251/23838 [15:03<23:57,  2.50it/s][2025-02-04 02:51:52][root][INFO] - Training Epoch: 2/2, step 20250/23838 completed (loss: 0.2139318883419037, acc: 0.9477611780166626)
[2025-02-04 02:51:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20252/23838 [15:03<24:15,  2.46it/s][2025-02-04 02:51:53][root][INFO] - Training Epoch: 2/2, step 20251/23838 completed (loss: 0.3806925117969513, acc: 0.9074074029922485)
[2025-02-04 02:51:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20253/23838 [15:04<23:10,  2.58it/s][2025-02-04 02:51:53][root][INFO] - Training Epoch: 2/2, step 20252/23838 completed (loss: 0.01654297672212124, acc: 1.0)
[2025-02-04 02:51:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20254/23838 [15:04<25:08,  2.38it/s][2025-02-04 02:51:54][root][INFO] - Training Epoch: 2/2, step 20253/23838 completed (loss: 0.2372477799654007, acc: 0.9180327653884888)
[2025-02-04 02:51:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20255/23838 [15:04<24:40,  2.42it/s][2025-02-04 02:51:54][root][INFO] - Training Epoch: 2/2, step 20254/23838 completed (loss: 0.30823495984077454, acc: 0.8928571343421936)
[2025-02-04 02:51:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20256/23838 [15:05<23:56,  2.49it/s][2025-02-04 02:51:54][root][INFO] - Training Epoch: 2/2, step 20255/23838 completed (loss: 0.9412286281585693, acc: 0.6153846383094788)
[2025-02-04 02:51:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20257/23838 [15:05<23:43,  2.52it/s][2025-02-04 02:51:55][root][INFO] - Training Epoch: 2/2, step 20256/23838 completed (loss: 0.6152605414390564, acc: 0.8285714387893677)
[2025-02-04 02:51:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20258/23838 [15:06<23:05,  2.58it/s][2025-02-04 02:51:55][root][INFO] - Training Epoch: 2/2, step 20257/23838 completed (loss: 0.4772571623325348, acc: 0.800000011920929)
[2025-02-04 02:51:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20259/23838 [15:06<22:23,  2.66it/s][2025-02-04 02:51:56][root][INFO] - Training Epoch: 2/2, step 20258/23838 completed (loss: 0.433145135641098, acc: 0.8529411554336548)
[2025-02-04 02:51:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20260/23838 [15:06<22:13,  2.68it/s][2025-02-04 02:51:56][root][INFO] - Training Epoch: 2/2, step 20259/23838 completed (loss: 0.32272082567214966, acc: 0.8648648858070374)
[2025-02-04 02:51:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20261/23838 [15:07<21:55,  2.72it/s][2025-02-04 02:51:56][root][INFO] - Training Epoch: 2/2, step 20260/23838 completed (loss: 0.8922739624977112, acc: 0.7400000095367432)
[2025-02-04 02:51:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▍ [0m| 20262/23838 [15:07<22:13,  2.68it/s][2025-02-04 02:51:57][root][INFO] - Training Epoch: 2/2, step 20261/23838 completed (loss: 0.3589400351047516, acc: 0.9069767594337463)
[2025-02-04 02:51:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20263/23838 [15:07<21:37,  2.75it/s][2025-02-04 02:51:57][root][INFO] - Training Epoch: 2/2, step 20262/23838 completed (loss: 0.6571483612060547, acc: 0.8441558480262756)
[2025-02-04 02:51:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20264/23838 [15:08<21:23,  2.78it/s][2025-02-04 02:51:57][root][INFO] - Training Epoch: 2/2, step 20263/23838 completed (loss: 0.3438471257686615, acc: 0.8799999952316284)
[2025-02-04 02:51:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20265/23838 [15:08<21:10,  2.81it/s][2025-02-04 02:51:58][root][INFO] - Training Epoch: 2/2, step 20264/23838 completed (loss: 0.5636001825332642, acc: 0.8166666626930237)
[2025-02-04 02:51:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20266/23838 [15:08<21:22,  2.78it/s][2025-02-04 02:51:58][root][INFO] - Training Epoch: 2/2, step 20265/23838 completed (loss: 0.370839387178421, acc: 0.9090909361839294)
[2025-02-04 02:51:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20267/23838 [15:09<20:52,  2.85it/s][2025-02-04 02:51:58][root][INFO] - Training Epoch: 2/2, step 20266/23838 completed (loss: 0.531546413898468, acc: 0.8676470518112183)
[2025-02-04 02:51:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20268/23838 [15:09<21:08,  2.81it/s][2025-02-04 02:51:59][root][INFO] - Training Epoch: 2/2, step 20267/23838 completed (loss: 0.441253662109375, acc: 0.8409090638160706)
[2025-02-04 02:51:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20269/23838 [15:09<20:29,  2.90it/s][2025-02-04 02:51:59][root][INFO] - Training Epoch: 2/2, step 20268/23838 completed (loss: 0.037778448313474655, acc: 0.9868420958518982)
[2025-02-04 02:51:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20270/23838 [15:10<20:47,  2.86it/s][2025-02-04 02:51:59][root][INFO] - Training Epoch: 2/2, step 20269/23838 completed (loss: 0.5227694511413574, acc: 0.843137264251709)
[2025-02-04 02:52:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20271/23838 [15:10<21:34,  2.76it/s][2025-02-04 02:52:00][root][INFO] - Training Epoch: 2/2, step 20270/23838 completed (loss: 0.46627873182296753, acc: 0.8115941882133484)
[2025-02-04 02:52:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20272/23838 [15:11<22:08,  2.68it/s][2025-02-04 02:52:00][root][INFO] - Training Epoch: 2/2, step 20271/23838 completed (loss: 0.7160365581512451, acc: 0.7799999713897705)
[2025-02-04 02:52:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20273/23838 [15:11<22:38,  2.62it/s][2025-02-04 02:52:01][root][INFO] - Training Epoch: 2/2, step 20272/23838 completed (loss: 0.38546958565711975, acc: 0.8888888955116272)
[2025-02-04 02:52:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20274/23838 [15:11<22:39,  2.62it/s][2025-02-04 02:52:01][root][INFO] - Training Epoch: 2/2, step 20273/23838 completed (loss: 0.8326260447502136, acc: 0.7833333611488342)
[2025-02-04 02:52:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20275/23838 [15:12<23:35,  2.52it/s][2025-02-04 02:52:01][root][INFO] - Training Epoch: 2/2, step 20274/23838 completed (loss: 0.4926048815250397, acc: 0.8888888955116272)
[2025-02-04 02:52:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20276/23838 [15:12<23:19,  2.54it/s][2025-02-04 02:52:02][root][INFO] - Training Epoch: 2/2, step 20275/23838 completed (loss: 0.3700559735298157, acc: 0.901098906993866)
[2025-02-04 02:52:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20277/23838 [15:13<22:59,  2.58it/s][2025-02-04 02:52:02][root][INFO] - Training Epoch: 2/2, step 20276/23838 completed (loss: 0.271114706993103, acc: 0.9729729890823364)
[2025-02-04 02:52:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20278/23838 [15:13<22:56,  2.59it/s][2025-02-04 02:52:03][root][INFO] - Training Epoch: 2/2, step 20277/23838 completed (loss: 0.21872980892658234, acc: 0.9259259104728699)
[2025-02-04 02:52:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20279/23838 [15:13<22:32,  2.63it/s][2025-02-04 02:52:03][root][INFO] - Training Epoch: 2/2, step 20278/23838 completed (loss: 0.8523275852203369, acc: 0.75)
[2025-02-04 02:52:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20280/23838 [15:14<21:31,  2.75it/s][2025-02-04 02:52:03][root][INFO] - Training Epoch: 2/2, step 20279/23838 completed (loss: 0.3369470238685608, acc: 0.8888888955116272)
[2025-02-04 02:52:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20281/23838 [15:14<21:19,  2.78it/s][2025-02-04 02:52:04][root][INFO] - Training Epoch: 2/2, step 20280/23838 completed (loss: 0.5809726715087891, acc: 0.807692289352417)
[2025-02-04 02:52:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20282/23838 [15:14<21:47,  2.72it/s][2025-02-04 02:52:04][root][INFO] - Training Epoch: 2/2, step 20281/23838 completed (loss: 0.3507380485534668, acc: 0.8857142925262451)
[2025-02-04 02:52:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20283/23838 [15:15<21:27,  2.76it/s][2025-02-04 02:52:04][root][INFO] - Training Epoch: 2/2, step 20282/23838 completed (loss: 0.5653501749038696, acc: 0.75)
[2025-02-04 02:52:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20284/23838 [15:15<21:31,  2.75it/s][2025-02-04 02:52:05][root][INFO] - Training Epoch: 2/2, step 20283/23838 completed (loss: 0.1120370626449585, acc: 1.0)
[2025-02-04 02:52:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20285/23838 [15:15<21:32,  2.75it/s][2025-02-04 02:52:05][root][INFO] - Training Epoch: 2/2, step 20284/23838 completed (loss: 0.9266743063926697, acc: 0.6666666865348816)
[2025-02-04 02:52:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20286/23838 [15:16<21:45,  2.72it/s][2025-02-04 02:52:05][root][INFO] - Training Epoch: 2/2, step 20285/23838 completed (loss: 0.44910457730293274, acc: 0.8620689511299133)
[2025-02-04 02:52:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20287/23838 [15:16<22:18,  2.65it/s][2025-02-04 02:52:06][root][INFO] - Training Epoch: 2/2, step 20286/23838 completed (loss: 0.0700700581073761, acc: 0.9750000238418579)
[2025-02-04 02:52:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20288/23838 [15:17<22:47,  2.60it/s][2025-02-04 02:52:06][root][INFO] - Training Epoch: 2/2, step 20287/23838 completed (loss: 0.17421062290668488, acc: 0.9634146094322205)
[2025-02-04 02:52:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20289/23838 [15:17<22:25,  2.64it/s][2025-02-04 02:52:07][root][INFO] - Training Epoch: 2/2, step 20288/23838 completed (loss: 0.4861171245574951, acc: 0.8604651093482971)
[2025-02-04 02:52:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20290/23838 [15:17<23:44,  2.49it/s][2025-02-04 02:52:07][root][INFO] - Training Epoch: 2/2, step 20289/23838 completed (loss: 0.5016927719116211, acc: 0.8095238208770752)
[2025-02-04 02:52:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20291/23838 [15:18<23:46,  2.49it/s][2025-02-04 02:52:07][root][INFO] - Training Epoch: 2/2, step 20290/23838 completed (loss: 0.43106186389923096, acc: 0.9090909361839294)
[2025-02-04 02:52:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20292/23838 [15:18<24:39,  2.40it/s][2025-02-04 02:52:08][root][INFO] - Training Epoch: 2/2, step 20291/23838 completed (loss: 0.7584829330444336, acc: 0.7971014380455017)
[2025-02-04 02:52:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20293/23838 [15:19<24:21,  2.43it/s][2025-02-04 02:52:08][root][INFO] - Training Epoch: 2/2, step 20292/23838 completed (loss: 0.5526604056358337, acc: 0.8253968358039856)
[2025-02-04 02:52:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20294/23838 [15:19<23:26,  2.52it/s][2025-02-04 02:52:09][root][INFO] - Training Epoch: 2/2, step 20293/23838 completed (loss: 0.478481262922287, acc: 0.8787878751754761)
[2025-02-04 02:52:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20295/23838 [15:19<23:42,  2.49it/s][2025-02-04 02:52:09][root][INFO] - Training Epoch: 2/2, step 20294/23838 completed (loss: 0.5112422108650208, acc: 0.8679245114326477)
[2025-02-04 02:52:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20296/23838 [15:20<23:44,  2.49it/s][2025-02-04 02:52:09][root][INFO] - Training Epoch: 2/2, step 20295/23838 completed (loss: 0.6109246611595154, acc: 0.8059701323509216)
[2025-02-04 02:52:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20297/23838 [15:20<23:55,  2.47it/s][2025-02-04 02:52:10][root][INFO] - Training Epoch: 2/2, step 20296/23838 completed (loss: 0.143729105591774, acc: 0.95652174949646)
[2025-02-04 02:52:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20298/23838 [15:21<24:23,  2.42it/s][2025-02-04 02:52:10][root][INFO] - Training Epoch: 2/2, step 20297/23838 completed (loss: 0.42469215393066406, acc: 0.8999999761581421)
[2025-02-04 02:52:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20299/23838 [15:21<25:01,  2.36it/s][2025-02-04 02:52:11][root][INFO] - Training Epoch: 2/2, step 20298/23838 completed (loss: 0.4599931836128235, acc: 0.8823529481887817)
[2025-02-04 02:52:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20300/23838 [15:22<25:49,  2.28it/s][2025-02-04 02:52:11][root][INFO] - Training Epoch: 2/2, step 20299/23838 completed (loss: 0.34824854135513306, acc: 0.8666666746139526)
[2025-02-04 02:52:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20301/23838 [15:22<24:50,  2.37it/s][2025-02-04 02:52:12][root][INFO] - Training Epoch: 2/2, step 20300/23838 completed (loss: 0.19821058213710785, acc: 0.970588207244873)
[2025-02-04 02:52:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20302/23838 [15:22<23:45,  2.48it/s][2025-02-04 02:52:12][root][INFO] - Training Epoch: 2/2, step 20301/23838 completed (loss: 0.31535375118255615, acc: 0.9117646813392639)
[2025-02-04 02:52:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20303/23838 [15:23<23:49,  2.47it/s][2025-02-04 02:52:12][root][INFO] - Training Epoch: 2/2, step 20302/23838 completed (loss: 1.0588624477386475, acc: 0.6808510422706604)
[2025-02-04 02:52:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20304/23838 [15:23<22:40,  2.60it/s][2025-02-04 02:52:13][root][INFO] - Training Epoch: 2/2, step 20303/23838 completed (loss: 0.9747960567474365, acc: 0.686274528503418)
[2025-02-04 02:52:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20305/23838 [15:24<22:20,  2.64it/s][2025-02-04 02:52:13][root][INFO] - Training Epoch: 2/2, step 20304/23838 completed (loss: 0.8273932337760925, acc: 0.7297297120094299)
[2025-02-04 02:52:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20306/23838 [15:24<21:22,  2.75it/s][2025-02-04 02:52:13][root][INFO] - Training Epoch: 2/2, step 20305/23838 completed (loss: 1.027240514755249, acc: 0.7560975551605225)
[2025-02-04 02:52:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20307/23838 [15:24<20:38,  2.85it/s][2025-02-04 02:52:14][root][INFO] - Training Epoch: 2/2, step 20306/23838 completed (loss: 0.27065303921699524, acc: 0.949999988079071)
[2025-02-04 02:52:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20308/23838 [15:25<21:53,  2.69it/s][2025-02-04 02:52:14][root][INFO] - Training Epoch: 2/2, step 20307/23838 completed (loss: 0.8264691829681396, acc: 0.7777777910232544)
[2025-02-04 02:52:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20309/23838 [15:25<22:15,  2.64it/s][2025-02-04 02:52:15][root][INFO] - Training Epoch: 2/2, step 20308/23838 completed (loss: 0.44356879591941833, acc: 0.8500000238418579)
[2025-02-04 02:52:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20310/23838 [15:25<22:49,  2.58it/s][2025-02-04 02:52:15][root][INFO] - Training Epoch: 2/2, step 20309/23838 completed (loss: 0.5652660131454468, acc: 0.8600000143051147)
[2025-02-04 02:52:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20311/23838 [15:26<22:43,  2.59it/s][2025-02-04 02:52:15][root][INFO] - Training Epoch: 2/2, step 20310/23838 completed (loss: 0.7244240641593933, acc: 0.7777777910232544)
[2025-02-04 02:52:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20312/23838 [15:26<22:11,  2.65it/s][2025-02-04 02:52:16][root][INFO] - Training Epoch: 2/2, step 20311/23838 completed (loss: 0.08225956559181213, acc: 1.0)
[2025-02-04 02:52:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20313/23838 [15:27<23:25,  2.51it/s][2025-02-04 02:52:16][root][INFO] - Training Epoch: 2/2, step 20312/23838 completed (loss: 0.21602700650691986, acc: 0.9387755393981934)
[2025-02-04 02:52:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20314/23838 [15:27<21:44,  2.70it/s][2025-02-04 02:52:16][root][INFO] - Training Epoch: 2/2, step 20313/23838 completed (loss: 0.8071924448013306, acc: 0.8103448152542114)
[2025-02-04 02:52:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20315/23838 [15:27<21:08,  2.78it/s][2025-02-04 02:52:17][root][INFO] - Training Epoch: 2/2, step 20314/23838 completed (loss: 0.4833371937274933, acc: 0.8409090638160706)
[2025-02-04 02:52:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20316/23838 [15:28<21:42,  2.70it/s][2025-02-04 02:52:17][root][INFO] - Training Epoch: 2/2, step 20315/23838 completed (loss: 1.1367018222808838, acc: 0.7333333492279053)
[2025-02-04 02:52:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20317/23838 [15:28<21:09,  2.77it/s][2025-02-04 02:52:18][root][INFO] - Training Epoch: 2/2, step 20316/23838 completed (loss: 0.6797212958335876, acc: 0.8148148059844971)
[2025-02-04 02:52:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20318/23838 [15:28<20:38,  2.84it/s][2025-02-04 02:52:18][root][INFO] - Training Epoch: 2/2, step 20317/23838 completed (loss: 0.7007943391799927, acc: 0.8285714387893677)
[2025-02-04 02:52:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20319/23838 [15:29<21:15,  2.76it/s][2025-02-04 02:52:18][root][INFO] - Training Epoch: 2/2, step 20318/23838 completed (loss: 0.4896091818809509, acc: 0.914893627166748)
[2025-02-04 02:52:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20320/23838 [15:29<21:03,  2.78it/s][2025-02-04 02:52:19][root][INFO] - Training Epoch: 2/2, step 20319/23838 completed (loss: 0.6990785002708435, acc: 0.8799999952316284)
[2025-02-04 02:52:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20321/23838 [15:29<20:51,  2.81it/s][2025-02-04 02:52:19][root][INFO] - Training Epoch: 2/2, step 20320/23838 completed (loss: 0.5657980442047119, acc: 0.8095238208770752)
[2025-02-04 02:52:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20322/23838 [15:30<21:35,  2.72it/s][2025-02-04 02:52:19][root][INFO] - Training Epoch: 2/2, step 20321/23838 completed (loss: 0.3482978343963623, acc: 0.8809523582458496)
[2025-02-04 02:52:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20323/23838 [15:30<20:54,  2.80it/s][2025-02-04 02:52:20][root][INFO] - Training Epoch: 2/2, step 20322/23838 completed (loss: 0.5335909128189087, acc: 0.7291666865348816)
[2025-02-04 02:52:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20324/23838 [15:31<22:00,  2.66it/s][2025-02-04 02:52:20][root][INFO] - Training Epoch: 2/2, step 20323/23838 completed (loss: 0.45808660984039307, acc: 0.8205128312110901)
[2025-02-04 02:52:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20325/23838 [15:31<22:08,  2.64it/s][2025-02-04 02:52:20][root][INFO] - Training Epoch: 2/2, step 20324/23838 completed (loss: 0.4651152193546295, acc: 0.8461538553237915)
[2025-02-04 02:52:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20326/23838 [15:31<22:10,  2.64it/s][2025-02-04 02:52:21][root][INFO] - Training Epoch: 2/2, step 20325/23838 completed (loss: 0.7414834499359131, acc: 0.8072289228439331)
[2025-02-04 02:52:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20327/23838 [15:32<21:33,  2.71it/s][2025-02-04 02:52:21][root][INFO] - Training Epoch: 2/2, step 20326/23838 completed (loss: 0.4731465280056, acc: 0.8214285969734192)
[2025-02-04 02:52:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20328/23838 [15:32<21:03,  2.78it/s][2025-02-04 02:52:22][root][INFO] - Training Epoch: 2/2, step 20327/23838 completed (loss: 0.958747148513794, acc: 0.7575757503509521)
[2025-02-04 02:52:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20329/23838 [15:32<22:41,  2.58it/s][2025-02-04 02:52:22][root][INFO] - Training Epoch: 2/2, step 20328/23838 completed (loss: 0.5905059576034546, acc: 0.8421052694320679)
[2025-02-04 02:52:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20330/23838 [15:33<22:39,  2.58it/s][2025-02-04 02:52:22][root][INFO] - Training Epoch: 2/2, step 20329/23838 completed (loss: 0.6306029558181763, acc: 0.8510638475418091)
[2025-02-04 02:52:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20331/23838 [15:33<21:29,  2.72it/s][2025-02-04 02:52:23][root][INFO] - Training Epoch: 2/2, step 20330/23838 completed (loss: 0.6443427205085754, acc: 0.7599999904632568)
[2025-02-04 02:52:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20332/23838 [15:33<20:06,  2.90it/s][2025-02-04 02:52:23][root][INFO] - Training Epoch: 2/2, step 20331/23838 completed (loss: 0.3581554889678955, acc: 0.8962264060974121)
[2025-02-04 02:52:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20333/23838 [15:34<19:25,  3.01it/s][2025-02-04 02:52:23][root][INFO] - Training Epoch: 2/2, step 20332/23838 completed (loss: 0.18230566382408142, acc: 0.9090909361839294)
[2025-02-04 02:52:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20334/23838 [15:34<19:17,  3.03it/s][2025-02-04 02:52:24][root][INFO] - Training Epoch: 2/2, step 20333/23838 completed (loss: 0.2132357507944107, acc: 0.9345794320106506)
[2025-02-04 02:52:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20335/23838 [15:34<19:13,  3.04it/s][2025-02-04 02:52:24][root][INFO] - Training Epoch: 2/2, step 20334/23838 completed (loss: 0.28884440660476685, acc: 0.9203540086746216)
[2025-02-04 02:52:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20336/23838 [15:35<19:26,  3.00it/s][2025-02-04 02:52:24][root][INFO] - Training Epoch: 2/2, step 20335/23838 completed (loss: 0.4105498492717743, acc: 0.9166666865348816)
[2025-02-04 02:52:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20337/23838 [15:35<18:45,  3.11it/s][2025-02-04 02:52:25][root][INFO] - Training Epoch: 2/2, step 20336/23838 completed (loss: 0.2824758291244507, acc: 0.9318181872367859)
[2025-02-04 02:52:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20338/23838 [15:35<19:05,  3.06it/s][2025-02-04 02:52:25][root][INFO] - Training Epoch: 2/2, step 20337/23838 completed (loss: 0.8031980395317078, acc: 0.7837837934494019)
[2025-02-04 02:52:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20339/23838 [15:36<19:39,  2.97it/s][2025-02-04 02:52:25][root][INFO] - Training Epoch: 2/2, step 20338/23838 completed (loss: 0.4555591642856598, acc: 0.8275862336158752)
[2025-02-04 02:52:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20340/23838 [15:36<23:08,  2.52it/s][2025-02-04 02:52:26][root][INFO] - Training Epoch: 2/2, step 20339/23838 completed (loss: 0.10054689645767212, acc: 0.969072163105011)
[2025-02-04 02:52:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20341/23838 [15:37<23:21,  2.50it/s][2025-02-04 02:52:26][root][INFO] - Training Epoch: 2/2, step 20340/23838 completed (loss: 0.31393587589263916, acc: 0.8518518805503845)
[2025-02-04 02:52:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20342/23838 [15:37<23:56,  2.43it/s][2025-02-04 02:52:27][root][INFO] - Training Epoch: 2/2, step 20341/23838 completed (loss: 0.4146353304386139, acc: 0.8913043737411499)
[2025-02-04 02:52:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20343/23838 [15:38<24:38,  2.36it/s][2025-02-04 02:52:27][root][INFO] - Training Epoch: 2/2, step 20342/23838 completed (loss: 0.4253729581832886, acc: 0.8720930218696594)
[2025-02-04 02:52:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20344/23838 [15:38<23:05,  2.52it/s][2025-02-04 02:52:27][root][INFO] - Training Epoch: 2/2, step 20343/23838 completed (loss: 0.31221461296081543, acc: 0.9024389982223511)
[2025-02-04 02:52:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20345/23838 [15:38<21:20,  2.73it/s][2025-02-04 02:52:28][root][INFO] - Training Epoch: 2/2, step 20344/23838 completed (loss: 0.19047312438488007, acc: 0.9571428298950195)
[2025-02-04 02:52:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20346/23838 [15:39<21:58,  2.65it/s][2025-02-04 02:52:28][root][INFO] - Training Epoch: 2/2, step 20345/23838 completed (loss: 0.13420003652572632, acc: 0.9534883499145508)
[2025-02-04 02:52:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20347/23838 [15:39<21:20,  2.73it/s][2025-02-04 02:52:29][root][INFO] - Training Epoch: 2/2, step 20346/23838 completed (loss: 0.3692997097969055, acc: 0.8999999761581421)
[2025-02-04 02:52:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20348/23838 [15:39<21:12,  2.74it/s][2025-02-04 02:52:29][root][INFO] - Training Epoch: 2/2, step 20347/23838 completed (loss: 0.4220820367336273, acc: 0.8759689927101135)
[2025-02-04 02:52:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20349/23838 [15:40<22:11,  2.62it/s][2025-02-04 02:52:29][root][INFO] - Training Epoch: 2/2, step 20348/23838 completed (loss: 0.22844533622264862, acc: 0.9506173133850098)
[2025-02-04 02:52:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20350/23838 [15:40<23:12,  2.50it/s][2025-02-04 02:52:30][root][INFO] - Training Epoch: 2/2, step 20349/23838 completed (loss: 0.19383446872234344, acc: 0.9516128897666931)
[2025-02-04 02:52:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20351/23838 [15:41<24:23,  2.38it/s][2025-02-04 02:52:30][root][INFO] - Training Epoch: 2/2, step 20350/23838 completed (loss: 0.23195484280586243, acc: 0.9396551847457886)
[2025-02-04 02:52:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20352/23838 [15:41<23:43,  2.45it/s][2025-02-04 02:52:31][root][INFO] - Training Epoch: 2/2, step 20351/23838 completed (loss: 0.2450142353773117, acc: 0.895348846912384)
[2025-02-04 02:52:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20353/23838 [15:41<23:07,  2.51it/s][2025-02-04 02:52:31][root][INFO] - Training Epoch: 2/2, step 20352/23838 completed (loss: 0.36567986011505127, acc: 0.8958333134651184)
[2025-02-04 02:52:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20354/23838 [15:42<22:32,  2.58it/s][2025-02-04 02:52:31][root][INFO] - Training Epoch: 2/2, step 20353/23838 completed (loss: 0.5030491948127747, acc: 0.8444444537162781)
[2025-02-04 02:52:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20355/23838 [15:42<22:00,  2.64it/s][2025-02-04 02:52:32][root][INFO] - Training Epoch: 2/2, step 20354/23838 completed (loss: 0.5734316110610962, acc: 0.8648648858070374)
[2025-02-04 02:52:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20356/23838 [15:42<21:42,  2.67it/s][2025-02-04 02:52:32][root][INFO] - Training Epoch: 2/2, step 20355/23838 completed (loss: 0.7040916085243225, acc: 0.9047619104385376)
[2025-02-04 02:52:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20357/23838 [15:43<21:11,  2.74it/s][2025-02-04 02:52:32][root][INFO] - Training Epoch: 2/2, step 20356/23838 completed (loss: 0.2599906027317047, acc: 0.9285714030265808)
[2025-02-04 02:52:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20358/23838 [15:43<21:01,  2.76it/s][2025-02-04 02:52:33][root][INFO] - Training Epoch: 2/2, step 20357/23838 completed (loss: 0.46834754943847656, acc: 0.925000011920929)
[2025-02-04 02:52:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20359/23838 [15:43<19:46,  2.93it/s][2025-02-04 02:52:33][root][INFO] - Training Epoch: 2/2, step 20358/23838 completed (loss: 0.6406590938568115, acc: 0.8333333134651184)
[2025-02-04 02:52:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20360/23838 [15:44<20:38,  2.81it/s][2025-02-04 02:52:33][root][INFO] - Training Epoch: 2/2, step 20359/23838 completed (loss: 0.4650551676750183, acc: 0.9052631855010986)
[2025-02-04 02:52:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20361/23838 [15:44<20:04,  2.89it/s][2025-02-04 02:52:34][root][INFO] - Training Epoch: 2/2, step 20360/23838 completed (loss: 0.36562037467956543, acc: 0.8666666746139526)
[2025-02-04 02:52:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20362/23838 [15:44<19:29,  2.97it/s][2025-02-04 02:52:34][root][INFO] - Training Epoch: 2/2, step 20361/23838 completed (loss: 0.3829987049102783, acc: 0.9444444179534912)
[2025-02-04 02:52:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20363/23838 [15:45<20:06,  2.88it/s][2025-02-04 02:52:34][root][INFO] - Training Epoch: 2/2, step 20362/23838 completed (loss: 0.5193470120429993, acc: 0.8675496578216553)
[2025-02-04 02:52:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20364/23838 [15:45<20:10,  2.87it/s][2025-02-04 02:52:35][root][INFO] - Training Epoch: 2/2, step 20363/23838 completed (loss: 0.3110077381134033, acc: 0.9306930899620056)
[2025-02-04 02:52:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20365/23838 [15:46<21:10,  2.73it/s][2025-02-04 02:52:35][root][INFO] - Training Epoch: 2/2, step 20364/23838 completed (loss: 0.2834100127220154, acc: 0.9333333373069763)
[2025-02-04 02:52:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20366/23838 [15:46<19:58,  2.90it/s][2025-02-04 02:52:35][root][INFO] - Training Epoch: 2/2, step 20365/23838 completed (loss: 0.09840093553066254, acc: 0.9831932783126831)
[2025-02-04 02:52:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20367/23838 [15:46<19:25,  2.98it/s][2025-02-04 02:52:36][root][INFO] - Training Epoch: 2/2, step 20366/23838 completed (loss: 0.0674452856183052, acc: 0.9821428656578064)
[2025-02-04 02:52:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20368/23838 [15:47<20:21,  2.84it/s][2025-02-04 02:52:36][root][INFO] - Training Epoch: 2/2, step 20367/23838 completed (loss: 0.18542280793190002, acc: 0.9411764740943909)
[2025-02-04 02:52:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20369/23838 [15:47<19:50,  2.91it/s][2025-02-04 02:52:37][root][INFO] - Training Epoch: 2/2, step 20368/23838 completed (loss: 0.2721920907497406, acc: 0.9387755393981934)
[2025-02-04 02:52:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20370/23838 [15:47<20:40,  2.80it/s][2025-02-04 02:52:37][root][INFO] - Training Epoch: 2/2, step 20369/23838 completed (loss: 0.19887207448482513, acc: 0.9342105388641357)
[2025-02-04 02:52:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20371/23838 [15:48<19:59,  2.89it/s][2025-02-04 02:52:37][root][INFO] - Training Epoch: 2/2, step 20370/23838 completed (loss: 0.8827275037765503, acc: 0.6744186282157898)
[2025-02-04 02:52:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20372/23838 [15:48<22:29,  2.57it/s][2025-02-04 02:52:38][root][INFO] - Training Epoch: 2/2, step 20371/23838 completed (loss: 0.3634542226791382, acc: 0.8970588445663452)
[2025-02-04 02:52:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20373/23838 [15:48<21:26,  2.69it/s][2025-02-04 02:52:38][root][INFO] - Training Epoch: 2/2, step 20372/23838 completed (loss: 0.07919708639383316, acc: 0.9638554453849792)
[2025-02-04 02:52:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20374/23838 [15:49<20:30,  2.81it/s][2025-02-04 02:52:38][root][INFO] - Training Epoch: 2/2, step 20373/23838 completed (loss: 0.2296527922153473, acc: 0.9200000166893005)
[2025-02-04 02:52:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20375/23838 [15:49<22:10,  2.60it/s][2025-02-04 02:52:39][root][INFO] - Training Epoch: 2/2, step 20374/23838 completed (loss: 0.20040230453014374, acc: 0.930232584476471)
[2025-02-04 02:52:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20376/23838 [15:50<22:33,  2.56it/s][2025-02-04 02:52:39][root][INFO] - Training Epoch: 2/2, step 20375/23838 completed (loss: 0.1764243096113205, acc: 0.9438202381134033)
[2025-02-04 02:52:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20377/23838 [15:50<22:09,  2.60it/s][2025-02-04 02:52:40][root][INFO] - Training Epoch: 2/2, step 20376/23838 completed (loss: 0.15307670831680298, acc: 0.9666666388511658)
[2025-02-04 02:52:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20378/23838 [15:50<22:50,  2.53it/s][2025-02-04 02:52:40][root][INFO] - Training Epoch: 2/2, step 20377/23838 completed (loss: 0.12251737713813782, acc: 0.9541284441947937)
[2025-02-04 02:52:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20379/23838 [15:51<23:03,  2.50it/s][2025-02-04 02:52:40][root][INFO] - Training Epoch: 2/2, step 20378/23838 completed (loss: 0.39400985836982727, acc: 0.8965517282485962)
[2025-02-04 02:52:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20380/23838 [15:51<22:41,  2.54it/s][2025-02-04 02:52:41][root][INFO] - Training Epoch: 2/2, step 20379/23838 completed (loss: 0.2734014689922333, acc: 0.9420289993286133)
[2025-02-04 02:52:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  85%|[34m████████▌ [0m| 20381/23838 [15:52<25:44,  2.24it/s][2025-02-04 02:52:41][root][INFO] - Training Epoch: 2/2, step 20380/23838 completed (loss: 0.38341134786605835, acc: 0.8888888955116272)
[2025-02-04 02:52:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20382/23838 [15:52<24:04,  2.39it/s][2025-02-04 02:52:42][root][INFO] - Training Epoch: 2/2, step 20381/23838 completed (loss: 0.0596354603767395, acc: 1.0)
[2025-02-04 02:52:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20383/23838 [15:53<24:01,  2.40it/s][2025-02-04 02:52:42][root][INFO] - Training Epoch: 2/2, step 20382/23838 completed (loss: 0.18340468406677246, acc: 0.9494949579238892)
[2025-02-04 02:52:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20384/23838 [15:53<24:03,  2.39it/s][2025-02-04 02:52:43][root][INFO] - Training Epoch: 2/2, step 20383/23838 completed (loss: 0.3018574118614197, acc: 0.9354838728904724)
[2025-02-04 02:52:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20385/23838 [15:53<24:00,  2.40it/s][2025-02-04 02:52:43][root][INFO] - Training Epoch: 2/2, step 20384/23838 completed (loss: 0.18914912641048431, acc: 0.9354838728904724)
[2025-02-04 02:52:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20386/23838 [15:54<26:14,  2.19it/s][2025-02-04 02:52:44][root][INFO] - Training Epoch: 2/2, step 20385/23838 completed (loss: 0.5157762765884399, acc: 0.8497652411460876)
[2025-02-04 02:52:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20387/23838 [15:55<28:51,  1.99it/s][2025-02-04 02:52:44][root][INFO] - Training Epoch: 2/2, step 20386/23838 completed (loss: 0.6366320848464966, acc: 0.8153846263885498)
[2025-02-04 02:52:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20388/23838 [15:55<28:51,  1.99it/s][2025-02-04 02:52:45][root][INFO] - Training Epoch: 2/2, step 20387/23838 completed (loss: 0.4778137505054474, acc: 0.8876404762268066)
[2025-02-04 02:52:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20389/23838 [15:55<27:10,  2.12it/s][2025-02-04 02:52:45][root][INFO] - Training Epoch: 2/2, step 20388/23838 completed (loss: 1.1451640129089355, acc: 0.7006802558898926)
[2025-02-04 02:52:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20390/23838 [15:56<25:09,  2.28it/s][2025-02-04 02:52:45][root][INFO] - Training Epoch: 2/2, step 20389/23838 completed (loss: 0.3038879334926605, acc: 0.938144326210022)
[2025-02-04 02:52:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20391/23838 [15:56<25:01,  2.30it/s][2025-02-04 02:52:46][root][INFO] - Training Epoch: 2/2, step 20390/23838 completed (loss: 0.5553891658782959, acc: 0.8620689511299133)
[2025-02-04 02:52:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20392/23838 [15:57<24:28,  2.35it/s][2025-02-04 02:52:46][root][INFO] - Training Epoch: 2/2, step 20391/23838 completed (loss: 0.5620189309120178, acc: 0.8383838534355164)
[2025-02-04 02:52:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20393/23838 [15:57<22:54,  2.51it/s][2025-02-04 02:52:47][root][INFO] - Training Epoch: 2/2, step 20392/23838 completed (loss: 0.4924127757549286, acc: 0.8814814686775208)
[2025-02-04 02:52:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20394/23838 [15:57<22:17,  2.57it/s][2025-02-04 02:52:47][root][INFO] - Training Epoch: 2/2, step 20393/23838 completed (loss: 0.6944312453269958, acc: 0.8453608155250549)
[2025-02-04 02:52:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20395/23838 [15:58<21:53,  2.62it/s][2025-02-04 02:52:47][root][INFO] - Training Epoch: 2/2, step 20394/23838 completed (loss: 0.816561758518219, acc: 0.7821782231330872)
[2025-02-04 02:52:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20396/23838 [15:58<22:26,  2.56it/s][2025-02-04 02:52:48][root][INFO] - Training Epoch: 2/2, step 20395/23838 completed (loss: 0.4062318205833435, acc: 0.8741258978843689)
[2025-02-04 02:52:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20397/23838 [15:59<22:27,  2.55it/s][2025-02-04 02:52:48][root][INFO] - Training Epoch: 2/2, step 20396/23838 completed (loss: 0.47310757637023926, acc: 0.8796680569648743)
[2025-02-04 02:52:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20398/23838 [15:59<25:37,  2.24it/s][2025-02-04 02:52:49][root][INFO] - Training Epoch: 2/2, step 20397/23838 completed (loss: 0.8597661852836609, acc: 0.8040540814399719)
[2025-02-04 02:52:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20399/23838 [16:00<25:40,  2.23it/s][2025-02-04 02:52:49][root][INFO] - Training Epoch: 2/2, step 20398/23838 completed (loss: 0.20847351849079132, acc: 0.9426751732826233)
[2025-02-04 02:52:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20400/23838 [16:00<23:31,  2.44it/s][2025-02-04 02:52:49][root][INFO] - Training Epoch: 2/2, step 20399/23838 completed (loss: 0.5245869159698486, acc: 0.8448275923728943)
[2025-02-04 02:52:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20401/23838 [16:00<27:00,  2.12it/s][2025-02-04 02:52:50][root][INFO] - Training Epoch: 2/2, step 20400/23838 completed (loss: 0.5114566683769226, acc: 0.8692810535430908)
[2025-02-04 02:52:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20402/23838 [16:01<25:50,  2.22it/s][2025-02-04 02:52:50][root][INFO] - Training Epoch: 2/2, step 20401/23838 completed (loss: 0.573682963848114, acc: 0.8421052694320679)
[2025-02-04 02:52:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20403/23838 [16:01<23:48,  2.41it/s][2025-02-04 02:52:51][root][INFO] - Training Epoch: 2/2, step 20402/23838 completed (loss: 0.36448365449905396, acc: 0.9285714030265808)
[2025-02-04 02:52:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20404/23838 [16:02<23:50,  2.40it/s][2025-02-04 02:52:51][root][INFO] - Training Epoch: 2/2, step 20403/23838 completed (loss: 0.4792950749397278, acc: 0.8651685118675232)
[2025-02-04 02:52:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20405/23838 [16:02<24:05,  2.38it/s][2025-02-04 02:52:52][root][INFO] - Training Epoch: 2/2, step 20404/23838 completed (loss: 0.11535046994686127, acc: 0.970370352268219)
[2025-02-04 02:52:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20406/23838 [16:02<23:39,  2.42it/s][2025-02-04 02:52:52][root][INFO] - Training Epoch: 2/2, step 20405/23838 completed (loss: 0.6583331823348999, acc: 0.8536585569381714)
[2025-02-04 02:52:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20407/23838 [16:03<23:20,  2.45it/s][2025-02-04 02:52:52][root][INFO] - Training Epoch: 2/2, step 20406/23838 completed (loss: 0.1905273050069809, acc: 0.9166666865348816)
[2025-02-04 02:52:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20408/23838 [16:03<23:32,  2.43it/s][2025-02-04 02:52:53][root][INFO] - Training Epoch: 2/2, step 20407/23838 completed (loss: 0.3013383448123932, acc: 0.8833333253860474)
[2025-02-04 02:52:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20409/23838 [16:04<22:43,  2.51it/s][2025-02-04 02:52:53][root][INFO] - Training Epoch: 2/2, step 20408/23838 completed (loss: 0.2592620253562927, acc: 0.9152542352676392)
[2025-02-04 02:52:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20410/23838 [16:04<23:07,  2.47it/s][2025-02-04 02:52:54][root][INFO] - Training Epoch: 2/2, step 20409/23838 completed (loss: 0.4384426176548004, acc: 0.8909090757369995)
[2025-02-04 02:52:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20411/23838 [16:04<23:34,  2.42it/s][2025-02-04 02:52:54][root][INFO] - Training Epoch: 2/2, step 20410/23838 completed (loss: 0.046262431889772415, acc: 0.982758641242981)
[2025-02-04 02:52:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20412/23838 [16:05<23:02,  2.48it/s][2025-02-04 02:52:54][root][INFO] - Training Epoch: 2/2, step 20411/23838 completed (loss: 0.024783315137028694, acc: 0.9918032884597778)
[2025-02-04 02:52:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20413/23838 [16:05<22:44,  2.51it/s][2025-02-04 02:52:55][root][INFO] - Training Epoch: 2/2, step 20412/23838 completed (loss: 1.0619370937347412, acc: 0.7250000238418579)
[2025-02-04 02:52:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20414/23838 [16:06<21:10,  2.70it/s][2025-02-04 02:52:55][root][INFO] - Training Epoch: 2/2, step 20413/23838 completed (loss: 0.19464817643165588, acc: 0.948051929473877)
[2025-02-04 02:52:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20415/23838 [16:06<24:04,  2.37it/s][2025-02-04 02:52:56][root][INFO] - Training Epoch: 2/2, step 20414/23838 completed (loss: 0.28769975900650024, acc: 0.9032257795333862)
[2025-02-04 02:52:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20416/23838 [16:07<24:06,  2.37it/s][2025-02-04 02:52:56][root][INFO] - Training Epoch: 2/2, step 20415/23838 completed (loss: 0.30263999104499817, acc: 0.895348846912384)
[2025-02-04 02:52:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20417/23838 [16:07<23:03,  2.47it/s][2025-02-04 02:52:56][root][INFO] - Training Epoch: 2/2, step 20416/23838 completed (loss: 0.14243875443935394, acc: 0.9534883499145508)
[2025-02-04 02:52:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20418/23838 [16:07<22:00,  2.59it/s][2025-02-04 02:52:57][root][INFO] - Training Epoch: 2/2, step 20417/23838 completed (loss: 0.27131763100624084, acc: 0.9459459185600281)
[2025-02-04 02:52:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20419/23838 [16:08<22:18,  2.55it/s][2025-02-04 02:52:57][root][INFO] - Training Epoch: 2/2, step 20418/23838 completed (loss: 0.1871056854724884, acc: 0.9264705777168274)
[2025-02-04 02:52:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20420/23838 [16:08<22:03,  2.58it/s][2025-02-04 02:52:58][root][INFO] - Training Epoch: 2/2, step 20419/23838 completed (loss: 0.21085309982299805, acc: 0.9538461565971375)
[2025-02-04 02:52:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20421/23838 [16:08<21:47,  2.61it/s][2025-02-04 02:52:58][root][INFO] - Training Epoch: 2/2, step 20420/23838 completed (loss: 0.03878806158900261, acc: 0.9879518151283264)
[2025-02-04 02:52:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20422/23838 [16:09<21:26,  2.66it/s][2025-02-04 02:52:58][root][INFO] - Training Epoch: 2/2, step 20421/23838 completed (loss: 0.5970742106437683, acc: 0.8732394576072693)
[2025-02-04 02:52:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20423/23838 [16:09<21:47,  2.61it/s][2025-02-04 02:52:59][root][INFO] - Training Epoch: 2/2, step 20422/23838 completed (loss: 0.5251848101615906, acc: 0.8679245114326477)
[2025-02-04 02:52:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20424/23838 [16:10<21:23,  2.66it/s][2025-02-04 02:52:59][root][INFO] - Training Epoch: 2/2, step 20423/23838 completed (loss: 0.4140671491622925, acc: 0.9038461446762085)
[2025-02-04 02:52:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20425/23838 [16:10<21:12,  2.68it/s][2025-02-04 02:52:59][root][INFO] - Training Epoch: 2/2, step 20424/23838 completed (loss: 0.7050877809524536, acc: 0.8518518805503845)
[2025-02-04 02:53:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20426/23838 [16:10<21:14,  2.68it/s][2025-02-04 02:53:00][root][INFO] - Training Epoch: 2/2, step 20425/23838 completed (loss: 0.5069729685783386, acc: 0.8780487775802612)
[2025-02-04 02:53:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20427/23838 [16:11<20:38,  2.75it/s][2025-02-04 02:53:00][root][INFO] - Training Epoch: 2/2, step 20426/23838 completed (loss: 0.6644672155380249, acc: 0.8846153616905212)
[2025-02-04 02:53:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20428/23838 [16:11<20:44,  2.74it/s][2025-02-04 02:53:01][root][INFO] - Training Epoch: 2/2, step 20427/23838 completed (loss: 0.6389354467391968, acc: 0.8787878751754761)
[2025-02-04 02:53:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20429/23838 [16:11<20:49,  2.73it/s][2025-02-04 02:53:01][root][INFO] - Training Epoch: 2/2, step 20428/23838 completed (loss: 0.32969945669174194, acc: 0.9074074029922485)
[2025-02-04 02:53:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20430/23838 [16:12<20:16,  2.80it/s][2025-02-04 02:53:01][root][INFO] - Training Epoch: 2/2, step 20429/23838 completed (loss: 1.0149095058441162, acc: 0.7727272510528564)
[2025-02-04 02:53:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20431/23838 [16:12<19:03,  2.98it/s][2025-02-04 02:53:02][root][INFO] - Training Epoch: 2/2, step 20430/23838 completed (loss: 0.6234918832778931, acc: 0.8876404762268066)
[2025-02-04 02:53:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20432/23838 [16:12<18:14,  3.11it/s][2025-02-04 02:53:02][root][INFO] - Training Epoch: 2/2, step 20431/23838 completed (loss: 0.2736344039440155, acc: 0.949999988079071)
[2025-02-04 02:53:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20433/23838 [16:13<19:07,  2.97it/s][2025-02-04 02:53:02][root][INFO] - Training Epoch: 2/2, step 20432/23838 completed (loss: 0.5331887006759644, acc: 0.8837209343910217)
[2025-02-04 02:53:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20434/23838 [16:13<18:13,  3.11it/s][2025-02-04 02:53:02][root][INFO] - Training Epoch: 2/2, step 20433/23838 completed (loss: 0.6659832000732422, acc: 0.8148148059844971)
[2025-02-04 02:53:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20435/23838 [16:13<19:52,  2.85it/s][2025-02-04 02:53:03][root][INFO] - Training Epoch: 2/2, step 20434/23838 completed (loss: 0.9244252443313599, acc: 0.7802197933197021)
[2025-02-04 02:53:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20436/23838 [16:14<20:15,  2.80it/s][2025-02-04 02:53:03][root][INFO] - Training Epoch: 2/2, step 20435/23838 completed (loss: 0.19597484171390533, acc: 0.9677419066429138)
[2025-02-04 02:53:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20437/23838 [16:14<20:58,  2.70it/s][2025-02-04 02:53:04][root][INFO] - Training Epoch: 2/2, step 20436/23838 completed (loss: 0.372685968875885, acc: 0.8888888955116272)
[2025-02-04 02:53:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20438/23838 [16:14<20:38,  2.74it/s][2025-02-04 02:53:04][root][INFO] - Training Epoch: 2/2, step 20437/23838 completed (loss: 0.10342139005661011, acc: 0.9791666865348816)
[2025-02-04 02:53:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20439/23838 [16:15<20:44,  2.73it/s][2025-02-04 02:53:04][root][INFO] - Training Epoch: 2/2, step 20438/23838 completed (loss: 0.1103794276714325, acc: 0.9838709831237793)
[2025-02-04 02:53:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20440/23838 [16:15<23:12,  2.44it/s][2025-02-04 02:53:05][root][INFO] - Training Epoch: 2/2, step 20439/23838 completed (loss: 0.24097205698490143, acc: 0.931034505367279)
[2025-02-04 02:53:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20441/23838 [16:16<22:16,  2.54it/s][2025-02-04 02:53:05][root][INFO] - Training Epoch: 2/2, step 20440/23838 completed (loss: 0.4357987344264984, acc: 0.9047619104385376)
[2025-02-04 02:53:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20442/23838 [16:16<20:49,  2.72it/s][2025-02-04 02:53:06][root][INFO] - Training Epoch: 2/2, step 20441/23838 completed (loss: 0.3680601418018341, acc: 0.9090909361839294)
[2025-02-04 02:53:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20443/23838 [16:16<19:33,  2.89it/s][2025-02-04 02:53:06][root][INFO] - Training Epoch: 2/2, step 20442/23838 completed (loss: 0.2256363183259964, acc: 0.8947368264198303)
[2025-02-04 02:53:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20444/23838 [16:17<19:26,  2.91it/s][2025-02-04 02:53:06][root][INFO] - Training Epoch: 2/2, step 20443/23838 completed (loss: 0.1495073288679123, acc: 0.9558823704719543)
[2025-02-04 02:53:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20445/23838 [16:17<19:15,  2.94it/s][2025-02-04 02:53:07][root][INFO] - Training Epoch: 2/2, step 20444/23838 completed (loss: 0.7498371005058289, acc: 0.8409090638160706)
[2025-02-04 02:53:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20446/23838 [16:17<19:10,  2.95it/s][2025-02-04 02:53:07][root][INFO] - Training Epoch: 2/2, step 20445/23838 completed (loss: 0.3278481066226959, acc: 0.9354838728904724)
[2025-02-04 02:53:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20447/23838 [16:18<19:42,  2.87it/s][2025-02-04 02:53:07][root][INFO] - Training Epoch: 2/2, step 20446/23838 completed (loss: 0.2741759419441223, acc: 0.931506872177124)
[2025-02-04 02:53:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20448/23838 [16:18<19:43,  2.86it/s][2025-02-04 02:53:08][root][INFO] - Training Epoch: 2/2, step 20447/23838 completed (loss: 0.5262546539306641, acc: 0.8387096524238586)
[2025-02-04 02:53:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20449/23838 [16:18<21:25,  2.64it/s][2025-02-04 02:53:08][root][INFO] - Training Epoch: 2/2, step 20448/23838 completed (loss: 1.0997164249420166, acc: 0.7058823704719543)
[2025-02-04 02:53:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20450/23838 [16:19<21:13,  2.66it/s][2025-02-04 02:53:08][root][INFO] - Training Epoch: 2/2, step 20449/23838 completed (loss: 1.0015820264816284, acc: 0.692307710647583)
[2025-02-04 02:53:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20451/23838 [16:19<20:34,  2.74it/s][2025-02-04 02:53:09][root][INFO] - Training Epoch: 2/2, step 20450/23838 completed (loss: 0.2739057242870331, acc: 0.9411764740943909)
[2025-02-04 02:53:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20452/23838 [16:20<20:26,  2.76it/s][2025-02-04 02:53:09][root][INFO] - Training Epoch: 2/2, step 20451/23838 completed (loss: 0.9689487814903259, acc: 0.7297297120094299)
[2025-02-04 02:53:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20453/23838 [16:20<21:28,  2.63it/s][2025-02-04 02:53:10][root][INFO] - Training Epoch: 2/2, step 20452/23838 completed (loss: 0.8978606462478638, acc: 0.7653061151504517)
[2025-02-04 02:53:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20454/23838 [16:20<22:29,  2.51it/s][2025-02-04 02:53:10][root][INFO] - Training Epoch: 2/2, step 20453/23838 completed (loss: 0.5257025957107544, acc: 0.8734177350997925)
[2025-02-04 02:53:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20455/23838 [16:21<22:02,  2.56it/s][2025-02-04 02:53:10][root][INFO] - Training Epoch: 2/2, step 20454/23838 completed (loss: 0.7260655760765076, acc: 0.7777777910232544)
[2025-02-04 02:53:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20456/23838 [16:21<22:10,  2.54it/s][2025-02-04 02:53:11][root][INFO] - Training Epoch: 2/2, step 20455/23838 completed (loss: 0.48370665311813354, acc: 0.800000011920929)
[2025-02-04 02:53:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20457/23838 [16:22<21:56,  2.57it/s][2025-02-04 02:53:11][root][INFO] - Training Epoch: 2/2, step 20456/23838 completed (loss: 0.653449296951294, acc: 0.7777777910232544)
[2025-02-04 02:53:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20458/23838 [16:22<21:22,  2.64it/s][2025-02-04 02:53:11][root][INFO] - Training Epoch: 2/2, step 20457/23838 completed (loss: 0.9629956483840942, acc: 0.75)
[2025-02-04 02:53:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20459/23838 [16:22<24:04,  2.34it/s][2025-02-04 02:53:12][root][INFO] - Training Epoch: 2/2, step 20458/23838 completed (loss: 0.9427549839019775, acc: 0.7272727489471436)
[2025-02-04 02:53:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20460/23838 [16:23<22:14,  2.53it/s][2025-02-04 02:53:12][root][INFO] - Training Epoch: 2/2, step 20459/23838 completed (loss: 0.9535742998123169, acc: 0.7142857313156128)
[2025-02-04 02:53:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20461/23838 [16:23<21:14,  2.65it/s][2025-02-04 02:53:13][root][INFO] - Training Epoch: 2/2, step 20460/23838 completed (loss: 0.38908547163009644, acc: 0.9142857193946838)
[2025-02-04 02:53:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20462/23838 [16:23<20:27,  2.75it/s][2025-02-04 02:53:13][root][INFO] - Training Epoch: 2/2, step 20461/23838 completed (loss: 0.7369205951690674, acc: 0.8059701323509216)
[2025-02-04 02:53:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20463/23838 [16:24<21:13,  2.65it/s][2025-02-04 02:53:13][root][INFO] - Training Epoch: 2/2, step 20462/23838 completed (loss: 0.9881969094276428, acc: 0.6666666865348816)
[2025-02-04 02:53:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20464/23838 [16:24<21:27,  2.62it/s][2025-02-04 02:53:14][root][INFO] - Training Epoch: 2/2, step 20463/23838 completed (loss: 0.4540524184703827, acc: 0.8461538553237915)
[2025-02-04 02:53:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20465/23838 [16:25<22:58,  2.45it/s][2025-02-04 02:53:14][root][INFO] - Training Epoch: 2/2, step 20464/23838 completed (loss: 0.6130837202072144, acc: 0.8297872543334961)
[2025-02-04 02:53:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20466/23838 [16:25<23:15,  2.42it/s][2025-02-04 02:53:15][root][INFO] - Training Epoch: 2/2, step 20465/23838 completed (loss: 0.3789212703704834, acc: 0.8888888955116272)
[2025-02-04 02:53:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20467/23838 [16:25<22:02,  2.55it/s][2025-02-04 02:53:15][root][INFO] - Training Epoch: 2/2, step 20466/23838 completed (loss: 0.7189539074897766, acc: 0.779411792755127)
[2025-02-04 02:53:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20468/23838 [16:26<22:46,  2.47it/s][2025-02-04 02:53:15][root][INFO] - Training Epoch: 2/2, step 20467/23838 completed (loss: 1.0043443441390991, acc: 0.7450980544090271)
[2025-02-04 02:53:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20469/23838 [16:26<22:03,  2.54it/s][2025-02-04 02:53:16][root][INFO] - Training Epoch: 2/2, step 20468/23838 completed (loss: 0.7078045606613159, acc: 0.8409090638160706)
[2025-02-04 02:53:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20470/23838 [16:27<20:57,  2.68it/s][2025-02-04 02:53:16][root][INFO] - Training Epoch: 2/2, step 20469/23838 completed (loss: 1.4825949668884277, acc: 0.550000011920929)
[2025-02-04 02:53:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20471/23838 [16:27<20:13,  2.77it/s][2025-02-04 02:53:17][root][INFO] - Training Epoch: 2/2, step 20470/23838 completed (loss: 0.992455005645752, acc: 0.703125)
[2025-02-04 02:53:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20472/23838 [16:27<19:46,  2.84it/s][2025-02-04 02:53:17][root][INFO] - Training Epoch: 2/2, step 20471/23838 completed (loss: 0.8753582239151001, acc: 0.804347813129425)
[2025-02-04 02:53:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20473/23838 [16:28<20:04,  2.79it/s][2025-02-04 02:53:17][root][INFO] - Training Epoch: 2/2, step 20472/23838 completed (loss: 0.6529389023780823, acc: 0.800000011920929)
[2025-02-04 02:53:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20474/23838 [16:28<20:49,  2.69it/s][2025-02-04 02:53:18][root][INFO] - Training Epoch: 2/2, step 20473/23838 completed (loss: 0.9259087443351746, acc: 0.6470588445663452)
[2025-02-04 02:53:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20475/23838 [16:28<21:46,  2.57it/s][2025-02-04 02:53:18][root][INFO] - Training Epoch: 2/2, step 20474/23838 completed (loss: 0.7212446331977844, acc: 0.739130437374115)
[2025-02-04 02:53:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20476/23838 [16:29<20:48,  2.69it/s][2025-02-04 02:53:18][root][INFO] - Training Epoch: 2/2, step 20475/23838 completed (loss: 1.1995548009872437, acc: 0.5454545617103577)
[2025-02-04 02:53:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20477/23838 [16:29<19:39,  2.85it/s][2025-02-04 02:53:19][root][INFO] - Training Epoch: 2/2, step 20476/23838 completed (loss: 0.35054394602775574, acc: 0.8888888955116272)
[2025-02-04 02:53:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20478/23838 [16:30<22:05,  2.54it/s][2025-02-04 02:53:19][root][INFO] - Training Epoch: 2/2, step 20477/23838 completed (loss: 0.40552929043769836, acc: 0.8823529481887817)
[2025-02-04 02:53:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20479/23838 [16:30<21:57,  2.55it/s][2025-02-04 02:53:20][root][INFO] - Training Epoch: 2/2, step 20478/23838 completed (loss: 0.7878260016441345, acc: 0.7413793206214905)
[2025-02-04 02:53:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20480/23838 [16:30<22:37,  2.47it/s][2025-02-04 02:53:20][root][INFO] - Training Epoch: 2/2, step 20479/23838 completed (loss: 0.4975939691066742, acc: 0.837837815284729)
[2025-02-04 02:53:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20481/23838 [16:31<21:50,  2.56it/s][2025-02-04 02:53:20][root][INFO] - Training Epoch: 2/2, step 20480/23838 completed (loss: 0.5142281651496887, acc: 0.837837815284729)
[2025-02-04 02:53:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20482/23838 [16:31<20:59,  2.66it/s][2025-02-04 02:53:21][root][INFO] - Training Epoch: 2/2, step 20481/23838 completed (loss: 0.7687923908233643, acc: 0.7428571581840515)
[2025-02-04 02:53:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20483/23838 [16:31<19:45,  2.83it/s][2025-02-04 02:53:21][root][INFO] - Training Epoch: 2/2, step 20482/23838 completed (loss: 0.562713623046875, acc: 0.8666666746139526)
[2025-02-04 02:53:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20484/23838 [16:32<20:04,  2.79it/s][2025-02-04 02:53:21][root][INFO] - Training Epoch: 2/2, step 20483/23838 completed (loss: 0.3467717170715332, acc: 0.8571428656578064)
[2025-02-04 02:53:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20485/23838 [16:32<20:51,  2.68it/s][2025-02-04 02:53:22][root][INFO] - Training Epoch: 2/2, step 20484/23838 completed (loss: 0.8766475915908813, acc: 0.7840909361839294)
[2025-02-04 02:53:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20486/23838 [16:32<19:52,  2.81it/s][2025-02-04 02:53:22][root][INFO] - Training Epoch: 2/2, step 20485/23838 completed (loss: 0.7683857083320618, acc: 0.782608687877655)
[2025-02-04 02:53:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20487/23838 [16:33<18:59,  2.94it/s][2025-02-04 02:53:22][root][INFO] - Training Epoch: 2/2, step 20486/23838 completed (loss: 0.45159298181533813, acc: 0.8571428656578064)
[2025-02-04 02:53:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20488/23838 [16:33<19:10,  2.91it/s][2025-02-04 02:53:23][root][INFO] - Training Epoch: 2/2, step 20487/23838 completed (loss: 0.5445542335510254, acc: 0.8602150678634644)
[2025-02-04 02:53:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20489/23838 [16:33<18:28,  3.02it/s][2025-02-04 02:53:23][root][INFO] - Training Epoch: 2/2, step 20488/23838 completed (loss: 0.7777619361877441, acc: 0.7532467246055603)
[2025-02-04 02:53:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20490/23838 [16:34<17:51,  3.12it/s][2025-02-04 02:53:23][root][INFO] - Training Epoch: 2/2, step 20489/23838 completed (loss: 1.2319458723068237, acc: 0.6764705777168274)
[2025-02-04 02:53:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20491/23838 [16:34<17:53,  3.12it/s][2025-02-04 02:53:24][root][INFO] - Training Epoch: 2/2, step 20490/23838 completed (loss: 0.7743207216262817, acc: 0.7457627058029175)
[2025-02-04 02:53:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20492/23838 [16:34<18:14,  3.06it/s][2025-02-04 02:53:24][root][INFO] - Training Epoch: 2/2, step 20491/23838 completed (loss: 0.8741834163665771, acc: 0.7200000286102295)
[2025-02-04 02:53:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20493/23838 [16:35<19:36,  2.84it/s][2025-02-04 02:53:24][root][INFO] - Training Epoch: 2/2, step 20492/23838 completed (loss: 0.6394200921058655, acc: 0.8292682766914368)
[2025-02-04 02:53:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20494/23838 [16:35<19:03,  2.93it/s][2025-02-04 02:53:25][root][INFO] - Training Epoch: 2/2, step 20493/23838 completed (loss: 1.1327451467514038, acc: 0.7435897588729858)
[2025-02-04 02:53:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20495/23838 [16:35<18:30,  3.01it/s][2025-02-04 02:53:25][root][INFO] - Training Epoch: 2/2, step 20494/23838 completed (loss: 0.7590466141700745, acc: 0.7755101919174194)
[2025-02-04 02:53:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20496/23838 [16:36<18:14,  3.05it/s][2025-02-04 02:53:25][root][INFO] - Training Epoch: 2/2, step 20495/23838 completed (loss: 0.47170889377593994, acc: 0.875)
[2025-02-04 02:53:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20497/23838 [16:36<18:08,  3.07it/s][2025-02-04 02:53:26][root][INFO] - Training Epoch: 2/2, step 20496/23838 completed (loss: 0.15301360189914703, acc: 0.9485714435577393)
[2025-02-04 02:53:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20498/23838 [16:36<18:20,  3.03it/s][2025-02-04 02:53:26][root][INFO] - Training Epoch: 2/2, step 20497/23838 completed (loss: 0.09218491613864899, acc: 0.9508196711540222)
[2025-02-04 02:53:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20499/23838 [16:37<18:28,  3.01it/s][2025-02-04 02:53:26][root][INFO] - Training Epoch: 2/2, step 20498/23838 completed (loss: 0.36980441212654114, acc: 0.8910890817642212)
[2025-02-04 02:53:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20500/23838 [16:37<18:38,  2.99it/s][2025-02-04 02:53:27][root][INFO] - Training Epoch: 2/2, step 20499/23838 completed (loss: 0.6237620711326599, acc: 0.7857142686843872)
[2025-02-04 02:53:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20501/23838 [16:37<18:22,  3.03it/s][2025-02-04 02:53:27][root][INFO] - Training Epoch: 2/2, step 20500/23838 completed (loss: 0.18775714933872223, acc: 0.9236640930175781)
[2025-02-04 02:53:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20502/23838 [16:38<18:09,  3.06it/s][2025-02-04 02:53:27][root][INFO] - Training Epoch: 2/2, step 20501/23838 completed (loss: 0.404226690530777, acc: 0.8717948794364929)
[2025-02-04 02:53:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20503/23838 [16:38<18:12,  3.05it/s][2025-02-04 02:53:28][root][INFO] - Training Epoch: 2/2, step 20502/23838 completed (loss: 0.437021404504776, acc: 0.875)
[2025-02-04 02:53:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20504/23838 [16:38<18:27,  3.01it/s][2025-02-04 02:53:28][root][INFO] - Training Epoch: 2/2, step 20503/23838 completed (loss: 0.7090557217597961, acc: 0.7931034564971924)
[2025-02-04 02:53:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20505/23838 [16:39<18:37,  2.98it/s][2025-02-04 02:53:28][root][INFO] - Training Epoch: 2/2, step 20504/23838 completed (loss: 0.3344610929489136, acc: 0.888059675693512)
[2025-02-04 02:53:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20506/23838 [16:39<18:29,  3.00it/s][2025-02-04 02:53:29][root][INFO] - Training Epoch: 2/2, step 20505/23838 completed (loss: 0.3791736662387848, acc: 0.887417197227478)
[2025-02-04 02:53:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20507/23838 [16:39<18:21,  3.02it/s][2025-02-04 02:53:29][root][INFO] - Training Epoch: 2/2, step 20506/23838 completed (loss: 0.4643956124782562, acc: 0.8936170339584351)
[2025-02-04 02:53:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20508/23838 [16:40<19:18,  2.87it/s][2025-02-04 02:53:29][root][INFO] - Training Epoch: 2/2, step 20507/23838 completed (loss: 0.24425756931304932, acc: 0.939130425453186)
[2025-02-04 02:53:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20509/23838 [16:40<19:20,  2.87it/s][2025-02-04 02:53:30][root][INFO] - Training Epoch: 2/2, step 20508/23838 completed (loss: 0.38765284419059753, acc: 0.8734939694404602)
[2025-02-04 02:53:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20510/23838 [16:40<18:13,  3.04it/s][2025-02-04 02:53:30][root][INFO] - Training Epoch: 2/2, step 20509/23838 completed (loss: 0.45910194516181946, acc: 0.8780487775802612)
[2025-02-04 02:53:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20511/23838 [16:41<18:07,  3.06it/s][2025-02-04 02:53:30][root][INFO] - Training Epoch: 2/2, step 20510/23838 completed (loss: 0.8226616382598877, acc: 0.7769784331321716)
[2025-02-04 02:53:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20512/23838 [16:41<18:05,  3.06it/s][2025-02-04 02:53:31][root][INFO] - Training Epoch: 2/2, step 20511/23838 completed (loss: 0.4123217463493347, acc: 0.9354838728904724)
[2025-02-04 02:53:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20513/23838 [16:41<18:43,  2.96it/s][2025-02-04 02:53:31][root][INFO] - Training Epoch: 2/2, step 20512/23838 completed (loss: 0.3804546594619751, acc: 0.9024389982223511)
[2025-02-04 02:53:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20514/23838 [16:42<19:16,  2.88it/s][2025-02-04 02:53:31][root][INFO] - Training Epoch: 2/2, step 20513/23838 completed (loss: 0.5055158138275146, acc: 0.8651685118675232)
[2025-02-04 02:53:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20515/23838 [16:42<20:09,  2.75it/s][2025-02-04 02:53:32][root][INFO] - Training Epoch: 2/2, step 20514/23838 completed (loss: 0.4068196415901184, acc: 0.875)
[2025-02-04 02:53:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20516/23838 [16:43<20:17,  2.73it/s][2025-02-04 02:53:32][root][INFO] - Training Epoch: 2/2, step 20515/23838 completed (loss: 0.35712260007858276, acc: 0.9075144529342651)
[2025-02-04 02:53:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20517/23838 [16:43<19:55,  2.78it/s][2025-02-04 02:53:33][root][INFO] - Training Epoch: 2/2, step 20516/23838 completed (loss: 0.34843525290489197, acc: 0.89552241563797)
[2025-02-04 02:53:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20518/23838 [16:43<19:31,  2.83it/s][2025-02-04 02:53:33][root][INFO] - Training Epoch: 2/2, step 20517/23838 completed (loss: 0.6511189341545105, acc: 0.738095223903656)
[2025-02-04 02:53:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20519/23838 [16:44<19:03,  2.90it/s][2025-02-04 02:53:33][root][INFO] - Training Epoch: 2/2, step 20518/23838 completed (loss: 0.5720224976539612, acc: 0.8030303120613098)
[2025-02-04 02:53:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20520/23838 [16:44<18:38,  2.97it/s][2025-02-04 02:53:33][root][INFO] - Training Epoch: 2/2, step 20519/23838 completed (loss: 0.22309042513370514, acc: 0.9359999895095825)
[2025-02-04 02:53:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20521/23838 [16:44<17:36,  3.14it/s][2025-02-04 02:53:34][root][INFO] - Training Epoch: 2/2, step 20520/23838 completed (loss: 0.5756815671920776, acc: 0.8315789699554443)
[2025-02-04 02:53:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20522/23838 [16:44<17:23,  3.18it/s][2025-02-04 02:53:34][root][INFO] - Training Epoch: 2/2, step 20521/23838 completed (loss: 0.3982542157173157, acc: 0.875)
[2025-02-04 02:53:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20523/23838 [16:45<17:07,  3.22it/s][2025-02-04 02:53:34][root][INFO] - Training Epoch: 2/2, step 20522/23838 completed (loss: 0.2116234004497528, acc: 0.9205297827720642)
[2025-02-04 02:53:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20524/23838 [16:45<17:08,  3.22it/s][2025-02-04 02:53:35][root][INFO] - Training Epoch: 2/2, step 20523/23838 completed (loss: 0.4071979522705078, acc: 0.8888888955116272)
[2025-02-04 02:53:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20525/23838 [16:45<17:36,  3.14it/s][2025-02-04 02:53:35][root][INFO] - Training Epoch: 2/2, step 20524/23838 completed (loss: 0.3505423963069916, acc: 0.8989899158477783)
[2025-02-04 02:53:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20526/23838 [16:46<17:36,  3.13it/s][2025-02-04 02:53:35][root][INFO] - Training Epoch: 2/2, step 20525/23838 completed (loss: 0.4859866797924042, acc: 0.852173924446106)
[2025-02-04 02:53:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20527/23838 [16:46<17:05,  3.23it/s][2025-02-04 02:53:36][root][INFO] - Training Epoch: 2/2, step 20526/23838 completed (loss: 0.245460644364357, acc: 0.929411768913269)
[2025-02-04 02:53:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20528/23838 [16:46<18:23,  3.00it/s][2025-02-04 02:53:36][root][INFO] - Training Epoch: 2/2, step 20527/23838 completed (loss: 0.5664618611335754, acc: 0.8396226167678833)
[2025-02-04 02:53:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20529/23838 [16:47<19:08,  2.88it/s][2025-02-04 02:53:36][root][INFO] - Training Epoch: 2/2, step 20528/23838 completed (loss: 0.645226776599884, acc: 0.8333333134651184)
[2025-02-04 02:53:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20530/23838 [16:47<19:16,  2.86it/s][2025-02-04 02:53:37][root][INFO] - Training Epoch: 2/2, step 20529/23838 completed (loss: 0.5835855603218079, acc: 0.8392857313156128)
[2025-02-04 02:53:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20531/23838 [16:48<18:57,  2.91it/s][2025-02-04 02:53:37][root][INFO] - Training Epoch: 2/2, step 20530/23838 completed (loss: 0.3693253993988037, acc: 0.8947368264198303)
[2025-02-04 02:53:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20532/23838 [16:48<18:57,  2.91it/s][2025-02-04 02:53:37][root][INFO] - Training Epoch: 2/2, step 20531/23838 completed (loss: 0.56288081407547, acc: 0.8352941274642944)
[2025-02-04 02:53:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20533/23838 [16:48<19:57,  2.76it/s][2025-02-04 02:53:38][root][INFO] - Training Epoch: 2/2, step 20532/23838 completed (loss: 0.6625989079475403, acc: 0.7950310707092285)
[2025-02-04 02:53:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20534/23838 [16:49<19:18,  2.85it/s][2025-02-04 02:53:38][root][INFO] - Training Epoch: 2/2, step 20533/23838 completed (loss: 0.22410279512405396, acc: 0.9545454382896423)
[2025-02-04 02:53:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20535/23838 [16:49<19:07,  2.88it/s][2025-02-04 02:53:39][root][INFO] - Training Epoch: 2/2, step 20534/23838 completed (loss: 0.6952807307243347, acc: 0.8253968358039856)
[2025-02-04 02:53:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20536/23838 [16:49<18:42,  2.94it/s][2025-02-04 02:53:39][root][INFO] - Training Epoch: 2/2, step 20535/23838 completed (loss: 0.22608883678913116, acc: 0.9398496150970459)
[2025-02-04 02:53:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20537/23838 [16:50<18:26,  2.98it/s][2025-02-04 02:53:39][root][INFO] - Training Epoch: 2/2, step 20536/23838 completed (loss: 0.5023480653762817, acc: 0.8552631735801697)
[2025-02-04 02:53:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20538/23838 [16:50<18:29,  2.97it/s][2025-02-04 02:53:39][root][INFO] - Training Epoch: 2/2, step 20537/23838 completed (loss: 0.6703211069107056, acc: 0.8421052694320679)
[2025-02-04 02:53:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20539/23838 [16:50<18:18,  3.00it/s][2025-02-04 02:53:40][root][INFO] - Training Epoch: 2/2, step 20538/23838 completed (loss: 0.7144688963890076, acc: 0.795918345451355)
[2025-02-04 02:53:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20540/23838 [16:51<18:14,  3.01it/s][2025-02-04 02:53:40][root][INFO] - Training Epoch: 2/2, step 20539/23838 completed (loss: 0.34506431221961975, acc: 0.8999999761581421)
[2025-02-04 02:53:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20541/23838 [16:51<18:37,  2.95it/s][2025-02-04 02:53:40][root][INFO] - Training Epoch: 2/2, step 20540/23838 completed (loss: 0.6036241054534912, acc: 0.8409090638160706)
[2025-02-04 02:53:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20542/23838 [16:51<18:31,  2.96it/s][2025-02-04 02:53:41][root][INFO] - Training Epoch: 2/2, step 20541/23838 completed (loss: 0.6629843711853027, acc: 0.804347813129425)
[2025-02-04 02:53:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20543/23838 [16:52<18:28,  2.97it/s][2025-02-04 02:53:41][root][INFO] - Training Epoch: 2/2, step 20542/23838 completed (loss: 0.24048134684562683, acc: 0.9375)
[2025-02-04 02:53:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20544/23838 [16:52<18:42,  2.93it/s][2025-02-04 02:53:42][root][INFO] - Training Epoch: 2/2, step 20543/23838 completed (loss: 0.36217001080513, acc: 0.8877550959587097)
[2025-02-04 02:53:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20545/23838 [16:52<18:09,  3.02it/s][2025-02-04 02:53:42][root][INFO] - Training Epoch: 2/2, step 20544/23838 completed (loss: 0.6449267864227295, acc: 0.8196721076965332)
[2025-02-04 02:53:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20546/23838 [16:53<18:36,  2.95it/s][2025-02-04 02:53:42][root][INFO] - Training Epoch: 2/2, step 20545/23838 completed (loss: 0.47340553998947144, acc: 0.8362069129943848)
[2025-02-04 02:53:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20547/23838 [16:53<17:49,  3.08it/s][2025-02-04 02:53:42][root][INFO] - Training Epoch: 2/2, step 20546/23838 completed (loss: 0.42265433073043823, acc: 0.8269230723381042)
[2025-02-04 02:53:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20548/23838 [16:53<18:35,  2.95it/s][2025-02-04 02:53:43][root][INFO] - Training Epoch: 2/2, step 20547/23838 completed (loss: 0.3492216467857361, acc: 0.9224137663841248)
[2025-02-04 02:53:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20549/23838 [16:54<19:36,  2.79it/s][2025-02-04 02:53:43][root][INFO] - Training Epoch: 2/2, step 20548/23838 completed (loss: 0.5781474113464355, acc: 0.8484848737716675)
[2025-02-04 02:53:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20550/23838 [16:54<18:45,  2.92it/s][2025-02-04 02:53:44][root][INFO] - Training Epoch: 2/2, step 20549/23838 completed (loss: 0.40066125988960266, acc: 0.8974359035491943)
[2025-02-04 02:53:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20551/23838 [16:54<19:30,  2.81it/s][2025-02-04 02:53:44][root][INFO] - Training Epoch: 2/2, step 20550/23838 completed (loss: 0.6630945205688477, acc: 0.8130841255187988)
[2025-02-04 02:53:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20552/23838 [16:55<19:54,  2.75it/s][2025-02-04 02:53:44][root][INFO] - Training Epoch: 2/2, step 20551/23838 completed (loss: 0.29023316502571106, acc: 0.9166666865348816)
[2025-02-04 02:53:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20553/23838 [16:55<21:25,  2.56it/s][2025-02-04 02:53:45][root][INFO] - Training Epoch: 2/2, step 20552/23838 completed (loss: 0.4794449210166931, acc: 0.8410256505012512)
[2025-02-04 02:53:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20554/23838 [16:56<20:55,  2.62it/s][2025-02-04 02:53:45][root][INFO] - Training Epoch: 2/2, step 20553/23838 completed (loss: 0.2565172016620636, acc: 0.939130425453186)
[2025-02-04 02:53:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20555/23838 [16:56<20:12,  2.71it/s][2025-02-04 02:53:45][root][INFO] - Training Epoch: 2/2, step 20554/23838 completed (loss: 0.730334460735321, acc: 0.7894737124443054)
[2025-02-04 02:53:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20556/23838 [16:56<19:54,  2.75it/s][2025-02-04 02:53:46][root][INFO] - Training Epoch: 2/2, step 20555/23838 completed (loss: 0.9119811058044434, acc: 0.7325581312179565)
[2025-02-04 02:53:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20557/23838 [16:57<19:53,  2.75it/s][2025-02-04 02:53:46][root][INFO] - Training Epoch: 2/2, step 20556/23838 completed (loss: 0.4291936457157135, acc: 0.8653846383094788)
[2025-02-04 02:53:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20558/23838 [16:57<20:18,  2.69it/s][2025-02-04 02:53:47][root][INFO] - Training Epoch: 2/2, step 20557/23838 completed (loss: 0.6052051186561584, acc: 0.8504672646522522)
[2025-02-04 02:53:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20559/23838 [16:57<20:34,  2.66it/s][2025-02-04 02:53:47][root][INFO] - Training Epoch: 2/2, step 20558/23838 completed (loss: 0.4262830913066864, acc: 0.868852436542511)
[2025-02-04 02:53:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▌ [0m| 20560/23838 [16:58<21:15,  2.57it/s][2025-02-04 02:53:47][root][INFO] - Training Epoch: 2/2, step 20559/23838 completed (loss: 0.24521195888519287, acc: 0.921875)
[2025-02-04 02:53:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20561/23838 [16:58<21:21,  2.56it/s][2025-02-04 02:53:48][root][INFO] - Training Epoch: 2/2, step 20560/23838 completed (loss: 0.2806887924671173, acc: 0.9230769276618958)
[2025-02-04 02:53:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20562/23838 [16:59<22:15,  2.45it/s][2025-02-04 02:53:48][root][INFO] - Training Epoch: 2/2, step 20561/23838 completed (loss: 0.44319573044776917, acc: 0.8773584961891174)
[2025-02-04 02:53:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20563/23838 [16:59<21:51,  2.50it/s][2025-02-04 02:53:49][root][INFO] - Training Epoch: 2/2, step 20562/23838 completed (loss: 0.5326555371284485, acc: 0.8476190567016602)
[2025-02-04 02:53:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20564/23838 [16:59<21:44,  2.51it/s][2025-02-04 02:53:49][root][INFO] - Training Epoch: 2/2, step 20563/23838 completed (loss: 0.4433561861515045, acc: 0.8854166865348816)
[2025-02-04 02:53:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20565/23838 [17:00<21:54,  2.49it/s][2025-02-04 02:53:49][root][INFO] - Training Epoch: 2/2, step 20564/23838 completed (loss: 0.41293734312057495, acc: 0.8773584961891174)
[2025-02-04 02:53:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20566/23838 [17:00<20:58,  2.60it/s][2025-02-04 02:53:50][root][INFO] - Training Epoch: 2/2, step 20565/23838 completed (loss: 0.39375290274620056, acc: 0.8888888955116272)
[2025-02-04 02:53:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20567/23838 [17:01<20:09,  2.70it/s][2025-02-04 02:53:50][root][INFO] - Training Epoch: 2/2, step 20566/23838 completed (loss: 0.246892511844635, acc: 0.9270833134651184)
[2025-02-04 02:53:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20568/23838 [17:01<19:17,  2.82it/s][2025-02-04 02:53:50][root][INFO] - Training Epoch: 2/2, step 20567/23838 completed (loss: 0.4127529561519623, acc: 0.8805969953536987)
[2025-02-04 02:53:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20569/23838 [17:01<18:36,  2.93it/s][2025-02-04 02:53:51][root][INFO] - Training Epoch: 2/2, step 20568/23838 completed (loss: 0.33045974373817444, acc: 0.9230769276618958)
[2025-02-04 02:53:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20570/23838 [17:02<19:22,  2.81it/s][2025-02-04 02:53:51][root][INFO] - Training Epoch: 2/2, step 20569/23838 completed (loss: 0.49385085701942444, acc: 0.8571428656578064)
[2025-02-04 02:53:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20571/23838 [17:02<19:47,  2.75it/s][2025-02-04 02:53:51][root][INFO] - Training Epoch: 2/2, step 20570/23838 completed (loss: 0.28026697039604187, acc: 0.885496199131012)
[2025-02-04 02:53:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20572/23838 [17:02<20:21,  2.67it/s][2025-02-04 02:53:52][root][INFO] - Training Epoch: 2/2, step 20571/23838 completed (loss: 0.46946829557418823, acc: 0.8620689511299133)
[2025-02-04 02:53:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20573/23838 [17:03<19:48,  2.75it/s][2025-02-04 02:53:52][root][INFO] - Training Epoch: 2/2, step 20572/23838 completed (loss: 1.4637553691864014, acc: 0.6333333253860474)
[2025-02-04 02:53:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20574/23838 [17:03<18:08,  3.00it/s][2025-02-04 02:53:53][root][INFO] - Training Epoch: 2/2, step 20573/23838 completed (loss: 0.4867748022079468, acc: 0.8965517282485962)
[2025-02-04 02:53:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20575/23838 [17:03<18:18,  2.97it/s][2025-02-04 02:53:53][root][INFO] - Training Epoch: 2/2, step 20574/23838 completed (loss: 0.7486407160758972, acc: 0.7681159377098083)
[2025-02-04 02:53:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20576/23838 [17:04<18:28,  2.94it/s][2025-02-04 02:53:53][root][INFO] - Training Epoch: 2/2, step 20575/23838 completed (loss: 0.442206472158432, acc: 0.8666666746139526)
[2025-02-04 02:53:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20577/23838 [17:04<18:14,  2.98it/s][2025-02-04 02:53:54][root][INFO] - Training Epoch: 2/2, step 20576/23838 completed (loss: 0.3542615473270416, acc: 0.8987341523170471)
[2025-02-04 02:53:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20578/23838 [17:04<18:18,  2.97it/s][2025-02-04 02:53:54][root][INFO] - Training Epoch: 2/2, step 20577/23838 completed (loss: 0.7067322731018066, acc: 0.8041236996650696)
[2025-02-04 02:53:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20579/23838 [17:05<19:35,  2.77it/s][2025-02-04 02:53:54][root][INFO] - Training Epoch: 2/2, step 20578/23838 completed (loss: 0.5899523496627808, acc: 0.8452380895614624)
[2025-02-04 02:53:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20580/23838 [17:05<20:24,  2.66it/s][2025-02-04 02:53:55][root][INFO] - Training Epoch: 2/2, step 20579/23838 completed (loss: 0.7019686102867126, acc: 0.8166666626930237)
[2025-02-04 02:53:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20581/23838 [17:05<20:27,  2.65it/s][2025-02-04 02:53:55][root][INFO] - Training Epoch: 2/2, step 20580/23838 completed (loss: 0.9997566342353821, acc: 0.7283950448036194)
[2025-02-04 02:53:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20582/23838 [17:06<20:02,  2.71it/s][2025-02-04 02:53:55][root][INFO] - Training Epoch: 2/2, step 20581/23838 completed (loss: 0.31627127528190613, acc: 0.9450549483299255)
[2025-02-04 02:53:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20583/23838 [17:06<19:30,  2.78it/s][2025-02-04 02:53:56][root][INFO] - Training Epoch: 2/2, step 20582/23838 completed (loss: 0.5003759264945984, acc: 0.8764045238494873)
[2025-02-04 02:53:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20584/23838 [17:07<19:13,  2.82it/s][2025-02-04 02:53:56][root][INFO] - Training Epoch: 2/2, step 20583/23838 completed (loss: 0.33388423919677734, acc: 0.9247311949729919)
[2025-02-04 02:53:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20585/23838 [17:07<18:47,  2.89it/s][2025-02-04 02:53:56][root][INFO] - Training Epoch: 2/2, step 20584/23838 completed (loss: 0.11273476481437683, acc: 0.967391312122345)
[2025-02-04 02:53:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20586/23838 [17:07<19:22,  2.80it/s][2025-02-04 02:53:57][root][INFO] - Training Epoch: 2/2, step 20585/23838 completed (loss: 0.2906239628791809, acc: 0.9252336621284485)
[2025-02-04 02:53:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20587/23838 [17:08<19:15,  2.81it/s][2025-02-04 02:53:57][root][INFO] - Training Epoch: 2/2, step 20586/23838 completed (loss: 0.4886675477027893, acc: 0.8794326186180115)
[2025-02-04 02:53:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20588/23838 [17:08<18:54,  2.87it/s][2025-02-04 02:53:57][root][INFO] - Training Epoch: 2/2, step 20587/23838 completed (loss: 0.7404794096946716, acc: 0.8133333325386047)
[2025-02-04 02:53:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20589/23838 [17:08<18:18,  2.96it/s][2025-02-04 02:53:58][root][INFO] - Training Epoch: 2/2, step 20588/23838 completed (loss: 0.738918662071228, acc: 0.7428571581840515)
[2025-02-04 02:53:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20590/23838 [17:09<18:02,  3.00it/s][2025-02-04 02:53:58][root][INFO] - Training Epoch: 2/2, step 20589/23838 completed (loss: 0.4970606565475464, acc: 0.8666666746139526)
[2025-02-04 02:53:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20591/23838 [17:09<18:13,  2.97it/s][2025-02-04 02:53:58][root][INFO] - Training Epoch: 2/2, step 20590/23838 completed (loss: 0.4213810861110687, acc: 0.8620689511299133)
[2025-02-04 02:53:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20592/23838 [17:09<18:18,  2.96it/s][2025-02-04 02:53:59][root][INFO] - Training Epoch: 2/2, step 20591/23838 completed (loss: 0.2958362400531769, acc: 0.9172413945198059)
[2025-02-04 02:53:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20593/23838 [17:10<18:27,  2.93it/s][2025-02-04 02:53:59][root][INFO] - Training Epoch: 2/2, step 20592/23838 completed (loss: 0.2558327317237854, acc: 0.9207317233085632)
[2025-02-04 02:53:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20594/23838 [17:10<19:10,  2.82it/s][2025-02-04 02:54:00][root][INFO] - Training Epoch: 2/2, step 20593/23838 completed (loss: 0.3980081379413605, acc: 0.9009901285171509)
[2025-02-04 02:54:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20595/23838 [17:10<19:32,  2.77it/s][2025-02-04 02:54:00][root][INFO] - Training Epoch: 2/2, step 20594/23838 completed (loss: 0.3432241380214691, acc: 0.9122806787490845)
[2025-02-04 02:54:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20596/23838 [17:11<20:26,  2.64it/s][2025-02-04 02:54:00][root][INFO] - Training Epoch: 2/2, step 20595/23838 completed (loss: 0.3625158965587616, acc: 0.9032257795333862)
[2025-02-04 02:54:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20597/23838 [17:11<20:30,  2.63it/s][2025-02-04 02:54:01][root][INFO] - Training Epoch: 2/2, step 20596/23838 completed (loss: 0.6516141295433044, acc: 0.8333333134651184)
[2025-02-04 02:54:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20598/23838 [17:12<20:34,  2.62it/s][2025-02-04 02:54:01][root][INFO] - Training Epoch: 2/2, step 20597/23838 completed (loss: 0.7277191281318665, acc: 0.8163265585899353)
[2025-02-04 02:54:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20599/23838 [17:12<21:32,  2.51it/s][2025-02-04 02:54:02][root][INFO] - Training Epoch: 2/2, step 20598/23838 completed (loss: 0.46994367241859436, acc: 0.8899082541465759)
[2025-02-04 02:54:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20600/23838 [17:12<20:49,  2.59it/s][2025-02-04 02:54:02][root][INFO] - Training Epoch: 2/2, step 20599/23838 completed (loss: 0.20472624897956848, acc: 0.9279999732971191)
[2025-02-04 02:54:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20601/23838 [17:13<20:19,  2.65it/s][2025-02-04 02:54:02][root][INFO] - Training Epoch: 2/2, step 20600/23838 completed (loss: 0.5309500694274902, acc: 0.9007633328437805)
[2025-02-04 02:54:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20602/23838 [17:13<19:42,  2.74it/s][2025-02-04 02:54:03][root][INFO] - Training Epoch: 2/2, step 20601/23838 completed (loss: 0.21192719042301178, acc: 0.9395604133605957)
[2025-02-04 02:54:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20603/23838 [17:13<19:34,  2.75it/s][2025-02-04 02:54:03][root][INFO] - Training Epoch: 2/2, step 20602/23838 completed (loss: 0.2856750190258026, acc: 0.9026548862457275)
[2025-02-04 02:54:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20604/23838 [17:14<19:33,  2.76it/s][2025-02-04 02:54:03][root][INFO] - Training Epoch: 2/2, step 20603/23838 completed (loss: 0.5301647186279297, acc: 0.8225806355476379)
[2025-02-04 02:54:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20605/23838 [17:14<19:06,  2.82it/s][2025-02-04 02:54:04][root][INFO] - Training Epoch: 2/2, step 20604/23838 completed (loss: 0.6685760617256165, acc: 0.7777777910232544)
[2025-02-04 02:54:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20606/23838 [17:14<19:34,  2.75it/s][2025-02-04 02:54:04][root][INFO] - Training Epoch: 2/2, step 20605/23838 completed (loss: 0.2965690791606903, acc: 0.8839285969734192)
[2025-02-04 02:54:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20607/23838 [17:15<19:01,  2.83it/s][2025-02-04 02:54:04][root][INFO] - Training Epoch: 2/2, step 20606/23838 completed (loss: 0.48439905047416687, acc: 0.8939393758773804)
[2025-02-04 02:54:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20608/23838 [17:15<18:44,  2.87it/s][2025-02-04 02:54:05][root][INFO] - Training Epoch: 2/2, step 20607/23838 completed (loss: 1.0795127153396606, acc: 0.75)
[2025-02-04 02:54:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20609/23838 [17:15<18:39,  2.88it/s][2025-02-04 02:54:05][root][INFO] - Training Epoch: 2/2, step 20608/23838 completed (loss: 0.7826645970344543, acc: 0.782608687877655)
[2025-02-04 02:54:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20610/23838 [17:16<18:53,  2.85it/s][2025-02-04 02:54:05][root][INFO] - Training Epoch: 2/2, step 20609/23838 completed (loss: 0.34977322816848755, acc: 0.9358974099159241)
[2025-02-04 02:54:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20611/23838 [17:16<19:06,  2.82it/s][2025-02-04 02:54:06][root][INFO] - Training Epoch: 2/2, step 20610/23838 completed (loss: 0.7379875779151917, acc: 0.84375)
[2025-02-04 02:54:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20612/23838 [17:17<19:10,  2.80it/s][2025-02-04 02:54:06][root][INFO] - Training Epoch: 2/2, step 20611/23838 completed (loss: 0.3169364631175995, acc: 0.9019607901573181)
[2025-02-04 02:54:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20613/23838 [17:17<19:41,  2.73it/s][2025-02-04 02:54:07][root][INFO] - Training Epoch: 2/2, step 20612/23838 completed (loss: 0.8098472356796265, acc: 0.7446808218955994)
[2025-02-04 02:54:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20614/23838 [17:17<19:09,  2.81it/s][2025-02-04 02:54:07][root][INFO] - Training Epoch: 2/2, step 20613/23838 completed (loss: 0.5905982851982117, acc: 0.8035714030265808)
[2025-02-04 02:54:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20615/23838 [17:18<21:45,  2.47it/s][2025-02-04 02:54:07][root][INFO] - Training Epoch: 2/2, step 20614/23838 completed (loss: 0.7800125479698181, acc: 0.7241379022598267)
[2025-02-04 02:54:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20616/23838 [17:18<20:43,  2.59it/s][2025-02-04 02:54:08][root][INFO] - Training Epoch: 2/2, step 20615/23838 completed (loss: 0.9826560616493225, acc: 0.739130437374115)
[2025-02-04 02:54:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20617/23838 [17:19<21:15,  2.52it/s][2025-02-04 02:54:08][root][INFO] - Training Epoch: 2/2, step 20616/23838 completed (loss: 0.7140440940856934, acc: 0.7575757503509521)
[2025-02-04 02:54:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20618/23838 [17:19<21:14,  2.53it/s][2025-02-04 02:54:09][root][INFO] - Training Epoch: 2/2, step 20617/23838 completed (loss: 0.7667726874351501, acc: 0.7377049326896667)
[2025-02-04 02:54:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  86%|[34m████████▋ [0m| 20619/23838 [17:19<20:29,  2.62it/s][2025-02-04 02:54:09][root][INFO] - Training Epoch: 2/2, step 20618/23838 completed (loss: 1.1074199676513672, acc: 0.7121211886405945)
[2025-02-04 02:54:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20620/23838 [17:20<20:10,  2.66it/s][2025-02-04 02:54:09][root][INFO] - Training Epoch: 2/2, step 20619/23838 completed (loss: 1.0721018314361572, acc: 0.7317073345184326)
[2025-02-04 02:54:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20621/23838 [17:20<20:13,  2.65it/s][2025-02-04 02:54:10][root][INFO] - Training Epoch: 2/2, step 20620/23838 completed (loss: 0.888411819934845, acc: 0.7283950448036194)
[2025-02-04 02:54:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20622/23838 [17:20<20:33,  2.61it/s][2025-02-04 02:54:10][root][INFO] - Training Epoch: 2/2, step 20621/23838 completed (loss: 0.4390435814857483, acc: 0.8888888955116272)
[2025-02-04 02:54:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20623/23838 [17:21<25:27,  2.10it/s][2025-02-04 02:54:11][root][INFO] - Training Epoch: 2/2, step 20622/23838 completed (loss: 0.9078584313392639, acc: 0.7200000286102295)
[2025-02-04 02:54:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20624/23838 [17:22<24:59,  2.14it/s][2025-02-04 02:54:11][root][INFO] - Training Epoch: 2/2, step 20623/23838 completed (loss: 0.9780290126800537, acc: 0.7297297120094299)
[2025-02-04 02:54:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20625/23838 [17:22<23:03,  2.32it/s][2025-02-04 02:54:12][root][INFO] - Training Epoch: 2/2, step 20624/23838 completed (loss: 0.3533947467803955, acc: 0.8928571343421936)
[2025-02-04 02:54:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20626/23838 [17:22<20:29,  2.61it/s][2025-02-04 02:54:12][root][INFO] - Training Epoch: 2/2, step 20625/23838 completed (loss: 0.6594418287277222, acc: 0.8070175647735596)
[2025-02-04 02:54:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20627/23838 [17:23<20:02,  2.67it/s][2025-02-04 02:54:12][root][INFO] - Training Epoch: 2/2, step 20626/23838 completed (loss: 0.9458882808685303, acc: 0.7209302186965942)
[2025-02-04 02:54:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20628/23838 [17:23<19:12,  2.78it/s][2025-02-04 02:54:12][root][INFO] - Training Epoch: 2/2, step 20627/23838 completed (loss: 0.6068523526191711, acc: 0.8645833134651184)
[2025-02-04 02:54:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20629/23838 [17:23<18:36,  2.87it/s][2025-02-04 02:54:13][root][INFO] - Training Epoch: 2/2, step 20628/23838 completed (loss: 1.2259718179702759, acc: 0.6447368264198303)
[2025-02-04 02:54:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20630/23838 [17:24<18:50,  2.84it/s][2025-02-04 02:54:13][root][INFO] - Training Epoch: 2/2, step 20629/23838 completed (loss: 0.29075637459754944, acc: 0.891566276550293)
[2025-02-04 02:54:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20631/23838 [17:24<19:27,  2.75it/s][2025-02-04 02:54:14][root][INFO] - Training Epoch: 2/2, step 20630/23838 completed (loss: 0.4000880718231201, acc: 0.9032257795333862)
[2025-02-04 02:54:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20632/23838 [17:24<18:08,  2.95it/s][2025-02-04 02:54:14][root][INFO] - Training Epoch: 2/2, step 20631/23838 completed (loss: 0.6583713889122009, acc: 0.795918345451355)
[2025-02-04 02:54:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20633/23838 [17:25<17:41,  3.02it/s][2025-02-04 02:54:14][root][INFO] - Training Epoch: 2/2, step 20632/23838 completed (loss: 0.9207310676574707, acc: 0.7735849022865295)
[2025-02-04 02:54:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20634/23838 [17:25<17:52,  2.99it/s][2025-02-04 02:54:14][root][INFO] - Training Epoch: 2/2, step 20633/23838 completed (loss: 0.546177327632904, acc: 0.8780487775802612)
[2025-02-04 02:54:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20635/23838 [17:25<17:57,  2.97it/s][2025-02-04 02:54:15][root][INFO] - Training Epoch: 2/2, step 20634/23838 completed (loss: 0.5641876459121704, acc: 0.807692289352417)
[2025-02-04 02:54:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20636/23838 [17:26<17:43,  3.01it/s][2025-02-04 02:54:15][root][INFO] - Training Epoch: 2/2, step 20635/23838 completed (loss: 0.7461303472518921, acc: 0.8444444537162781)
[2025-02-04 02:54:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20637/23838 [17:26<18:10,  2.93it/s][2025-02-04 02:54:15][root][INFO] - Training Epoch: 2/2, step 20636/23838 completed (loss: 0.6774036288261414, acc: 0.8024691343307495)
[2025-02-04 02:54:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20638/23838 [17:26<19:29,  2.74it/s][2025-02-04 02:54:16][root][INFO] - Training Epoch: 2/2, step 20637/23838 completed (loss: 0.8233529329299927, acc: 0.7876105904579163)
[2025-02-04 02:54:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20639/23838 [17:27<20:10,  2.64it/s][2025-02-04 02:54:16][root][INFO] - Training Epoch: 2/2, step 20638/23838 completed (loss: 0.8467570543289185, acc: 0.7894737124443054)
[2025-02-04 02:54:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20640/23838 [17:27<19:11,  2.78it/s][2025-02-04 02:54:17][root][INFO] - Training Epoch: 2/2, step 20639/23838 completed (loss: 0.6428428292274475, acc: 0.8030303120613098)
[2025-02-04 02:54:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20641/23838 [17:27<19:10,  2.78it/s][2025-02-04 02:54:17][root][INFO] - Training Epoch: 2/2, step 20640/23838 completed (loss: 0.5337182283401489, acc: 0.8870967626571655)
[2025-02-04 02:54:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20642/23838 [17:28<18:53,  2.82it/s][2025-02-04 02:54:17][root][INFO] - Training Epoch: 2/2, step 20641/23838 completed (loss: 0.8863784670829773, acc: 0.7283950448036194)
[2025-02-04 02:54:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20643/23838 [17:28<19:55,  2.67it/s][2025-02-04 02:54:18][root][INFO] - Training Epoch: 2/2, step 20642/23838 completed (loss: 0.7913086414337158, acc: 0.8166666626930237)
[2025-02-04 02:54:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20644/23838 [17:29<20:31,  2.59it/s][2025-02-04 02:54:18][root][INFO] - Training Epoch: 2/2, step 20643/23838 completed (loss: 0.5272810459136963, acc: 0.835616409778595)
[2025-02-04 02:54:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20645/23838 [17:29<19:52,  2.68it/s][2025-02-04 02:54:19][root][INFO] - Training Epoch: 2/2, step 20644/23838 completed (loss: 0.7815822958946228, acc: 0.8139534592628479)
[2025-02-04 02:54:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20646/23838 [17:29<20:54,  2.54it/s][2025-02-04 02:54:19][root][INFO] - Training Epoch: 2/2, step 20645/23838 completed (loss: 0.5120896100997925, acc: 0.8705882430076599)
[2025-02-04 02:54:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20647/23838 [17:30<20:02,  2.65it/s][2025-02-04 02:54:19][root][INFO] - Training Epoch: 2/2, step 20646/23838 completed (loss: 0.7515918612480164, acc: 0.774193525314331)
[2025-02-04 02:54:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20648/23838 [17:30<19:47,  2.69it/s][2025-02-04 02:54:20][root][INFO] - Training Epoch: 2/2, step 20647/23838 completed (loss: 0.536780834197998, acc: 0.8709677457809448)
[2025-02-04 02:54:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20649/23838 [17:30<20:19,  2.61it/s][2025-02-04 02:54:20][root][INFO] - Training Epoch: 2/2, step 20648/23838 completed (loss: 0.5210259556770325, acc: 0.8833333253860474)
[2025-02-04 02:54:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20650/23838 [17:31<20:54,  2.54it/s][2025-02-04 02:54:20][root][INFO] - Training Epoch: 2/2, step 20649/23838 completed (loss: 0.49812692403793335, acc: 0.807692289352417)
[2025-02-04 02:54:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20651/23838 [17:31<22:08,  2.40it/s][2025-02-04 02:54:21][root][INFO] - Training Epoch: 2/2, step 20650/23838 completed (loss: 0.6055898070335388, acc: 0.8208954930305481)
[2025-02-04 02:54:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20652/23838 [17:32<21:20,  2.49it/s][2025-02-04 02:54:21][root][INFO] - Training Epoch: 2/2, step 20651/23838 completed (loss: 0.5941355228424072, acc: 0.8241758346557617)
[2025-02-04 02:54:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20653/23838 [17:32<21:40,  2.45it/s][2025-02-04 02:54:22][root][INFO] - Training Epoch: 2/2, step 20652/23838 completed (loss: 1.1502727270126343, acc: 0.6865671873092651)
[2025-02-04 02:54:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20654/23838 [17:33<24:48,  2.14it/s][2025-02-04 02:54:22][root][INFO] - Training Epoch: 2/2, step 20653/23838 completed (loss: 1.219517469406128, acc: 0.6739130616188049)
[2025-02-04 02:54:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20655/23838 [17:33<24:34,  2.16it/s][2025-02-04 02:54:23][root][INFO] - Training Epoch: 2/2, step 20654/23838 completed (loss: 0.29755932092666626, acc: 0.925000011920929)
[2025-02-04 02:54:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20656/23838 [17:34<23:29,  2.26it/s][2025-02-04 02:54:23][root][INFO] - Training Epoch: 2/2, step 20655/23838 completed (loss: 0.7652387022972107, acc: 0.7954545617103577)
[2025-02-04 02:54:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20657/23838 [17:34<22:09,  2.39it/s][2025-02-04 02:54:24][root][INFO] - Training Epoch: 2/2, step 20656/23838 completed (loss: 0.6293954253196716, acc: 0.8235294222831726)
[2025-02-04 02:54:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20658/23838 [17:34<20:59,  2.52it/s][2025-02-04 02:54:24][root][INFO] - Training Epoch: 2/2, step 20657/23838 completed (loss: 0.895241379737854, acc: 0.7241379022598267)
[2025-02-04 02:54:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20659/23838 [17:35<21:23,  2.48it/s][2025-02-04 02:54:24][root][INFO] - Training Epoch: 2/2, step 20658/23838 completed (loss: 0.6006914973258972, acc: 0.8181818127632141)
[2025-02-04 02:54:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20660/23838 [17:35<19:24,  2.73it/s][2025-02-04 02:54:25][root][INFO] - Training Epoch: 2/2, step 20659/23838 completed (loss: 1.2922767400741577, acc: 0.6461538672447205)
[2025-02-04 02:54:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20661/23838 [17:35<19:53,  2.66it/s][2025-02-04 02:54:25][root][INFO] - Training Epoch: 2/2, step 20660/23838 completed (loss: 0.8789282441139221, acc: 0.7758620977401733)
[2025-02-04 02:54:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20662/23838 [17:36<22:53,  2.31it/s][2025-02-04 02:54:26][root][INFO] - Training Epoch: 2/2, step 20661/23838 completed (loss: 0.9323375821113586, acc: 0.7297297120094299)
[2025-02-04 02:54:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20663/23838 [17:36<21:10,  2.50it/s][2025-02-04 02:54:26][root][INFO] - Training Epoch: 2/2, step 20662/23838 completed (loss: 0.5525033473968506, acc: 0.8500000238418579)
[2025-02-04 02:54:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20664/23838 [17:37<20:08,  2.63it/s][2025-02-04 02:54:26][root][INFO] - Training Epoch: 2/2, step 20663/23838 completed (loss: 0.7828893661499023, acc: 0.7936508059501648)
[2025-02-04 02:54:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20665/23838 [17:37<19:56,  2.65it/s][2025-02-04 02:54:27][root][INFO] - Training Epoch: 2/2, step 20664/23838 completed (loss: 0.6790314316749573, acc: 0.7882353067398071)
[2025-02-04 02:54:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20666/23838 [17:37<19:20,  2.73it/s][2025-02-04 02:54:27][root][INFO] - Training Epoch: 2/2, step 20665/23838 completed (loss: 0.8900743126869202, acc: 0.7317073345184326)
[2025-02-04 02:54:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20667/23838 [17:38<21:47,  2.43it/s][2025-02-04 02:54:27][root][INFO] - Training Epoch: 2/2, step 20666/23838 completed (loss: 0.968546450138092, acc: 0.6829268336296082)
[2025-02-04 02:54:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20668/23838 [17:38<21:19,  2.48it/s][2025-02-04 02:54:28][root][INFO] - Training Epoch: 2/2, step 20667/23838 completed (loss: 0.7208544015884399, acc: 0.7659574747085571)
[2025-02-04 02:54:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20669/23838 [17:39<20:28,  2.58it/s][2025-02-04 02:54:28][root][INFO] - Training Epoch: 2/2, step 20668/23838 completed (loss: 0.9145630598068237, acc: 0.725806474685669)
[2025-02-04 02:54:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20670/23838 [17:39<20:35,  2.56it/s][2025-02-04 02:54:29][root][INFO] - Training Epoch: 2/2, step 20669/23838 completed (loss: 0.6025686860084534, acc: 0.8399999737739563)
[2025-02-04 02:54:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20671/23838 [17:40<23:42,  2.23it/s][2025-02-04 02:54:29][root][INFO] - Training Epoch: 2/2, step 20670/23838 completed (loss: 0.8163458108901978, acc: 0.7567567825317383)
[2025-02-04 02:54:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20672/23838 [17:40<23:01,  2.29it/s][2025-02-04 02:54:30][root][INFO] - Training Epoch: 2/2, step 20671/23838 completed (loss: 1.071424126625061, acc: 0.7704917788505554)
[2025-02-04 02:54:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20673/23838 [17:40<21:56,  2.40it/s][2025-02-04 02:54:30][root][INFO] - Training Epoch: 2/2, step 20672/23838 completed (loss: 0.31887224316596985, acc: 0.9275362491607666)
[2025-02-04 02:54:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20674/23838 [17:41<21:05,  2.50it/s][2025-02-04 02:54:30][root][INFO] - Training Epoch: 2/2, step 20673/23838 completed (loss: 0.10082041472196579, acc: 0.983146071434021)
[2025-02-04 02:54:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20675/23838 [17:41<19:54,  2.65it/s][2025-02-04 02:54:31][root][INFO] - Training Epoch: 2/2, step 20674/23838 completed (loss: 0.34247180819511414, acc: 0.9200000166893005)
[2025-02-04 02:54:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20676/23838 [17:41<18:34,  2.84it/s][2025-02-04 02:54:31][root][INFO] - Training Epoch: 2/2, step 20675/23838 completed (loss: 0.17183561623096466, acc: 0.9503546357154846)
[2025-02-04 02:54:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20677/23838 [17:42<17:57,  2.93it/s][2025-02-04 02:54:31][root][INFO] - Training Epoch: 2/2, step 20676/23838 completed (loss: 0.13749560713768005, acc: 0.925000011920929)
[2025-02-04 02:54:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20678/23838 [17:42<18:12,  2.89it/s][2025-02-04 02:54:32][root][INFO] - Training Epoch: 2/2, step 20677/23838 completed (loss: 0.27558794617652893, acc: 0.9189189076423645)
[2025-02-04 02:54:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20679/23838 [17:42<18:11,  2.89it/s][2025-02-04 02:54:32][root][INFO] - Training Epoch: 2/2, step 20678/23838 completed (loss: 0.05508657917380333, acc: 0.9824561476707458)
[2025-02-04 02:54:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20680/23838 [17:43<17:49,  2.95it/s][2025-02-04 02:54:32][root][INFO] - Training Epoch: 2/2, step 20679/23838 completed (loss: 0.0879291296005249, acc: 0.9732142686843872)
[2025-02-04 02:54:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20681/23838 [17:43<17:18,  3.04it/s][2025-02-04 02:54:33][root][INFO] - Training Epoch: 2/2, step 20680/23838 completed (loss: 0.24549350142478943, acc: 0.945652186870575)
[2025-02-04 02:54:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20682/23838 [17:43<16:48,  3.13it/s][2025-02-04 02:54:33][root][INFO] - Training Epoch: 2/2, step 20681/23838 completed (loss: 0.3138987421989441, acc: 0.9135802388191223)
[2025-02-04 02:54:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20683/23838 [17:44<16:52,  3.12it/s][2025-02-04 02:54:33][root][INFO] - Training Epoch: 2/2, step 20682/23838 completed (loss: 0.05640551075339317, acc: 0.9764705896377563)
[2025-02-04 02:54:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20684/23838 [17:44<17:02,  3.09it/s][2025-02-04 02:54:34][root][INFO] - Training Epoch: 2/2, step 20683/23838 completed (loss: 0.1113882064819336, acc: 0.976190447807312)
[2025-02-04 02:54:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20685/23838 [17:44<18:16,  2.88it/s][2025-02-04 02:54:34][root][INFO] - Training Epoch: 2/2, step 20684/23838 completed (loss: 0.06134964898228645, acc: 0.9908257126808167)
[2025-02-04 02:54:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20686/23838 [17:45<19:18,  2.72it/s][2025-02-04 02:54:34][root][INFO] - Training Epoch: 2/2, step 20685/23838 completed (loss: 0.05051397159695625, acc: 0.984000027179718)
[2025-02-04 02:54:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20687/23838 [17:45<18:42,  2.81it/s][2025-02-04 02:54:35][root][INFO] - Training Epoch: 2/2, step 20686/23838 completed (loss: 0.2656194269657135, acc: 0.9354838728904724)
[2025-02-04 02:54:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20688/23838 [17:45<18:38,  2.82it/s][2025-02-04 02:54:35][root][INFO] - Training Epoch: 2/2, step 20687/23838 completed (loss: 0.25410211086273193, acc: 0.9268292784690857)
[2025-02-04 02:54:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20689/23838 [17:46<17:58,  2.92it/s][2025-02-04 02:54:35][root][INFO] - Training Epoch: 2/2, step 20688/23838 completed (loss: 0.18398970365524292, acc: 0.9520000219345093)
[2025-02-04 02:54:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20690/23838 [17:46<18:13,  2.88it/s][2025-02-04 02:54:36][root][INFO] - Training Epoch: 2/2, step 20689/23838 completed (loss: 0.32775765657424927, acc: 0.9108911156654358)
[2025-02-04 02:54:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20691/23838 [17:47<19:35,  2.68it/s][2025-02-04 02:54:36][root][INFO] - Training Epoch: 2/2, step 20690/23838 completed (loss: 0.23938842117786407, acc: 0.9389312863349915)
[2025-02-04 02:54:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20692/23838 [17:47<19:59,  2.62it/s][2025-02-04 02:54:37][root][INFO] - Training Epoch: 2/2, step 20691/23838 completed (loss: 0.2515784800052643, acc: 0.9617834687232971)
[2025-02-04 02:54:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20693/23838 [17:47<18:55,  2.77it/s][2025-02-04 02:54:37][root][INFO] - Training Epoch: 2/2, step 20692/23838 completed (loss: 0.12553569674491882, acc: 0.9428571462631226)
[2025-02-04 02:54:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20694/23838 [17:48<19:45,  2.65it/s][2025-02-04 02:54:37][root][INFO] - Training Epoch: 2/2, step 20693/23838 completed (loss: 0.13545866310596466, acc: 0.9760000109672546)
[2025-02-04 02:54:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20695/23838 [17:48<19:24,  2.70it/s][2025-02-04 02:54:38][root][INFO] - Training Epoch: 2/2, step 20694/23838 completed (loss: 0.2924900949001312, acc: 0.9270073175430298)
[2025-02-04 02:54:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20696/23838 [17:49<21:46,  2.40it/s][2025-02-04 02:54:38][root][INFO] - Training Epoch: 2/2, step 20695/23838 completed (loss: 0.16413189470767975, acc: 0.9615384340286255)
[2025-02-04 02:54:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20697/23838 [17:49<20:52,  2.51it/s][2025-02-04 02:54:38][root][INFO] - Training Epoch: 2/2, step 20696/23838 completed (loss: 0.23161907494068146, acc: 0.9289617538452148)
[2025-02-04 02:54:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20698/23838 [17:49<20:11,  2.59it/s][2025-02-04 02:54:39][root][INFO] - Training Epoch: 2/2, step 20697/23838 completed (loss: 0.13714927434921265, acc: 0.9473684430122375)
[2025-02-04 02:54:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20699/23838 [17:50<20:13,  2.59it/s][2025-02-04 02:54:39][root][INFO] - Training Epoch: 2/2, step 20698/23838 completed (loss: 0.14722058176994324, acc: 0.9558823704719543)
[2025-02-04 02:54:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20700/23838 [17:50<20:21,  2.57it/s][2025-02-04 02:54:40][root][INFO] - Training Epoch: 2/2, step 20699/23838 completed (loss: 0.15209561586380005, acc: 0.9492753744125366)
[2025-02-04 02:54:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20701/23838 [17:50<19:33,  2.67it/s][2025-02-04 02:54:40][root][INFO] - Training Epoch: 2/2, step 20700/23838 completed (loss: 0.41685110330581665, acc: 0.8761062026023865)
[2025-02-04 02:54:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20702/23838 [17:51<18:39,  2.80it/s][2025-02-04 02:54:40][root][INFO] - Training Epoch: 2/2, step 20701/23838 completed (loss: 0.11171979457139969, acc: 0.9895833134651184)
[2025-02-04 02:54:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20703/23838 [17:51<18:33,  2.82it/s][2025-02-04 02:54:41][root][INFO] - Training Epoch: 2/2, step 20702/23838 completed (loss: 0.09480924159288406, acc: 0.9767441749572754)
[2025-02-04 02:54:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20704/23838 [17:51<18:43,  2.79it/s][2025-02-04 02:54:41][root][INFO] - Training Epoch: 2/2, step 20703/23838 completed (loss: 0.35307928919792175, acc: 0.8936170339584351)
[2025-02-04 02:54:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20705/23838 [17:52<19:22,  2.69it/s][2025-02-04 02:54:41][root][INFO] - Training Epoch: 2/2, step 20704/23838 completed (loss: 0.426518052816391, acc: 0.8902438879013062)
[2025-02-04 02:54:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20706/23838 [17:52<18:34,  2.81it/s][2025-02-04 02:54:42][root][INFO] - Training Epoch: 2/2, step 20705/23838 completed (loss: 0.13126474618911743, acc: 0.9830508232116699)
[2025-02-04 02:54:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20707/23838 [17:52<17:49,  2.93it/s][2025-02-04 02:54:42][root][INFO] - Training Epoch: 2/2, step 20706/23838 completed (loss: 0.2051190584897995, acc: 0.9696969985961914)
[2025-02-04 02:54:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20708/23838 [17:53<18:22,  2.84it/s][2025-02-04 02:54:42][root][INFO] - Training Epoch: 2/2, step 20707/23838 completed (loss: 0.08064969629049301, acc: 0.970588207244873)
[2025-02-04 02:54:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20709/23838 [17:53<17:10,  3.04it/s][2025-02-04 02:54:43][root][INFO] - Training Epoch: 2/2, step 20708/23838 completed (loss: 0.20650863647460938, acc: 0.9230769276618958)
[2025-02-04 02:54:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20710/23838 [17:53<16:17,  3.20it/s][2025-02-04 02:54:43][root][INFO] - Training Epoch: 2/2, step 20709/23838 completed (loss: 0.13890127837657928, acc: 0.9692307710647583)
[2025-02-04 02:54:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20711/23838 [17:54<16:34,  3.15it/s][2025-02-04 02:54:43][root][INFO] - Training Epoch: 2/2, step 20710/23838 completed (loss: 0.24268285930156708, acc: 0.9379844665527344)
[2025-02-04 02:54:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20712/23838 [17:54<17:18,  3.01it/s][2025-02-04 02:54:44][root][INFO] - Training Epoch: 2/2, step 20711/23838 completed (loss: 0.16052134335041046, acc: 0.9554139971733093)
[2025-02-04 02:54:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20713/23838 [17:54<16:36,  3.14it/s][2025-02-04 02:54:44][root][INFO] - Training Epoch: 2/2, step 20712/23838 completed (loss: 0.3730696141719818, acc: 0.9107142686843872)
[2025-02-04 02:54:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20714/23838 [17:55<16:48,  3.10it/s][2025-02-04 02:54:44][root][INFO] - Training Epoch: 2/2, step 20713/23838 completed (loss: 0.17321693897247314, acc: 0.9611111283302307)
[2025-02-04 02:54:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20715/23838 [17:55<18:06,  2.88it/s][2025-02-04 02:54:45][root][INFO] - Training Epoch: 2/2, step 20714/23838 completed (loss: 0.1347484439611435, acc: 0.9629629850387573)
[2025-02-04 02:54:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20716/23838 [17:55<18:04,  2.88it/s][2025-02-04 02:54:45][root][INFO] - Training Epoch: 2/2, step 20715/23838 completed (loss: 0.3660481870174408, acc: 0.8813559412956238)
[2025-02-04 02:54:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20717/23838 [17:56<17:55,  2.90it/s][2025-02-04 02:54:45][root][INFO] - Training Epoch: 2/2, step 20716/23838 completed (loss: 0.24033480882644653, acc: 0.9152542352676392)
[2025-02-04 02:54:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20718/23838 [17:56<18:14,  2.85it/s][2025-02-04 02:54:46][root][INFO] - Training Epoch: 2/2, step 20717/23838 completed (loss: 0.31980228424072266, acc: 0.9156626462936401)
[2025-02-04 02:54:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20719/23838 [17:57<19:23,  2.68it/s][2025-02-04 02:54:46][root][INFO] - Training Epoch: 2/2, step 20718/23838 completed (loss: 0.2694850564002991, acc: 0.939130425453186)
[2025-02-04 02:54:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20720/23838 [17:57<19:51,  2.62it/s][2025-02-04 02:54:47][root][INFO] - Training Epoch: 2/2, step 20719/23838 completed (loss: 0.08357639610767365, acc: 0.9824561476707458)
[2025-02-04 02:54:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20721/23838 [17:57<21:14,  2.44it/s][2025-02-04 02:54:47][root][INFO] - Training Epoch: 2/2, step 20720/23838 completed (loss: 0.4345210790634155, acc: 0.9119496941566467)
[2025-02-04 02:54:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20722/23838 [17:58<20:02,  2.59it/s][2025-02-04 02:54:47][root][INFO] - Training Epoch: 2/2, step 20721/23838 completed (loss: 0.2056030035018921, acc: 0.9555555582046509)
[2025-02-04 02:54:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20723/23838 [17:58<20:08,  2.58it/s][2025-02-04 02:54:48][root][INFO] - Training Epoch: 2/2, step 20722/23838 completed (loss: 0.294893741607666, acc: 0.9237288236618042)
[2025-02-04 02:54:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20724/23838 [17:58<18:50,  2.75it/s][2025-02-04 02:54:48][root][INFO] - Training Epoch: 2/2, step 20723/23838 completed (loss: 0.12190160900354385, acc: 0.9473684430122375)
[2025-02-04 02:54:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20725/23838 [17:59<18:18,  2.83it/s][2025-02-04 02:54:48][root][INFO] - Training Epoch: 2/2, step 20724/23838 completed (loss: 0.18953008949756622, acc: 0.945652186870575)
[2025-02-04 02:54:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20726/23838 [17:59<17:44,  2.92it/s][2025-02-04 02:54:49][root][INFO] - Training Epoch: 2/2, step 20725/23838 completed (loss: 0.268170028924942, acc: 0.9491525292396545)
[2025-02-04 02:54:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20727/23838 [17:59<16:29,  3.14it/s][2025-02-04 02:54:49][root][INFO] - Training Epoch: 2/2, step 20726/23838 completed (loss: 0.04855410009622574, acc: 0.9866666793823242)
[2025-02-04 02:54:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20728/23838 [18:00<16:01,  3.23it/s][2025-02-04 02:54:49][root][INFO] - Training Epoch: 2/2, step 20727/23838 completed (loss: 0.22235921025276184, acc: 0.9375)
[2025-02-04 02:54:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20729/23838 [18:00<16:15,  3.19it/s][2025-02-04 02:54:50][root][INFO] - Training Epoch: 2/2, step 20728/23838 completed (loss: 0.2943752110004425, acc: 0.9193548560142517)
[2025-02-04 02:54:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20730/23838 [18:00<17:08,  3.02it/s][2025-02-04 02:54:50][root][INFO] - Training Epoch: 2/2, step 20729/23838 completed (loss: 0.4000557065010071, acc: 0.9036144614219666)
[2025-02-04 02:54:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20731/23838 [18:01<16:44,  3.09it/s][2025-02-04 02:54:50][root][INFO] - Training Epoch: 2/2, step 20730/23838 completed (loss: 0.27476221323013306, acc: 0.9428571462631226)
[2025-02-04 02:54:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20732/23838 [18:01<17:16,  3.00it/s][2025-02-04 02:54:51][root][INFO] - Training Epoch: 2/2, step 20731/23838 completed (loss: 0.22501376271247864, acc: 0.9166666865348816)
[2025-02-04 02:54:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20733/23838 [18:01<18:11,  2.84it/s][2025-02-04 02:54:51][root][INFO] - Training Epoch: 2/2, step 20732/23838 completed (loss: 0.09455300122499466, acc: 0.978723406791687)
[2025-02-04 02:54:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20734/23838 [18:02<18:17,  2.83it/s][2025-02-04 02:54:51][root][INFO] - Training Epoch: 2/2, step 20733/23838 completed (loss: 0.1498033106327057, acc: 0.9529411792755127)
[2025-02-04 02:54:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20735/23838 [18:02<17:42,  2.92it/s][2025-02-04 02:54:52][root][INFO] - Training Epoch: 2/2, step 20734/23838 completed (loss: 0.03348717838525772, acc: 1.0)
[2025-02-04 02:54:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20736/23838 [18:02<17:47,  2.91it/s][2025-02-04 02:54:52][root][INFO] - Training Epoch: 2/2, step 20735/23838 completed (loss: 0.16790549457073212, acc: 0.9622641801834106)
[2025-02-04 02:54:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20737/23838 [18:03<16:54,  3.06it/s][2025-02-04 02:54:52][root][INFO] - Training Epoch: 2/2, step 20736/23838 completed (loss: 0.11509153991937637, acc: 0.9701492786407471)
[2025-02-04 02:54:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20738/23838 [18:03<16:37,  3.11it/s][2025-02-04 02:54:53][root][INFO] - Training Epoch: 2/2, step 20737/23838 completed (loss: 0.14737063646316528, acc: 0.9672130942344666)
[2025-02-04 02:54:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20739/23838 [18:03<17:15,  2.99it/s][2025-02-04 02:54:53][root][INFO] - Training Epoch: 2/2, step 20738/23838 completed (loss: 0.09076913446187973, acc: 0.9784172773361206)
[2025-02-04 02:54:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20740/23838 [18:04<17:14,  3.00it/s][2025-02-04 02:54:53][root][INFO] - Training Epoch: 2/2, step 20739/23838 completed (loss: 0.23915402591228485, acc: 0.9473684430122375)
[2025-02-04 02:54:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20741/23838 [18:04<18:22,  2.81it/s][2025-02-04 02:54:54][root][INFO] - Training Epoch: 2/2, step 20740/23838 completed (loss: 0.09155172854661942, acc: 0.982758641242981)
[2025-02-04 02:54:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20742/23838 [18:04<18:14,  2.83it/s][2025-02-04 02:54:54][root][INFO] - Training Epoch: 2/2, step 20741/23838 completed (loss: 0.15809780359268188, acc: 0.9545454382896423)
[2025-02-04 02:54:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20743/23838 [18:05<18:42,  2.76it/s][2025-02-04 02:54:54][root][INFO] - Training Epoch: 2/2, step 20742/23838 completed (loss: 0.12128075212240219, acc: 0.9569892287254333)
[2025-02-04 02:54:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20744/23838 [18:05<18:57,  2.72it/s][2025-02-04 02:54:55][root][INFO] - Training Epoch: 2/2, step 20743/23838 completed (loss: 0.09774843603372574, acc: 0.9844961166381836)
[2025-02-04 02:54:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20745/23838 [18:06<20:53,  2.47it/s][2025-02-04 02:54:55][root][INFO] - Training Epoch: 2/2, step 20744/23838 completed (loss: 0.24251288175582886, acc: 0.9459459185600281)
[2025-02-04 02:54:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20746/23838 [18:06<20:02,  2.57it/s][2025-02-04 02:54:56][root][INFO] - Training Epoch: 2/2, step 20745/23838 completed (loss: 0.060162268579006195, acc: 0.9912280440330505)
[2025-02-04 02:54:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20747/23838 [18:07<20:59,  2.45it/s][2025-02-04 02:54:56][root][INFO] - Training Epoch: 2/2, step 20746/23838 completed (loss: 0.03619878366589546, acc: 0.9826086759567261)
[2025-02-04 02:54:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20748/23838 [18:07<21:51,  2.36it/s][2025-02-04 02:54:57][root][INFO] - Training Epoch: 2/2, step 20747/23838 completed (loss: 0.17389196157455444, acc: 0.9612069129943848)
[2025-02-04 02:54:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20749/23838 [18:07<21:43,  2.37it/s][2025-02-04 02:54:57][root][INFO] - Training Epoch: 2/2, step 20748/23838 completed (loss: 0.13833588361740112, acc: 0.9708737730979919)
[2025-02-04 02:54:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20750/23838 [18:08<20:50,  2.47it/s][2025-02-04 02:54:57][root][INFO] - Training Epoch: 2/2, step 20749/23838 completed (loss: 0.14875301718711853, acc: 0.953125)
[2025-02-04 02:54:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20751/23838 [18:08<20:38,  2.49it/s][2025-02-04 02:54:58][root][INFO] - Training Epoch: 2/2, step 20750/23838 completed (loss: 0.04094864800572395, acc: 0.9801324605941772)
[2025-02-04 02:54:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20752/23838 [18:09<20:33,  2.50it/s][2025-02-04 02:54:58][root][INFO] - Training Epoch: 2/2, step 20751/23838 completed (loss: 0.12921494245529175, acc: 0.9672130942344666)
[2025-02-04 02:54:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20753/23838 [18:09<19:53,  2.59it/s][2025-02-04 02:54:59][root][INFO] - Training Epoch: 2/2, step 20752/23838 completed (loss: 0.08316236734390259, acc: 0.9779411554336548)
[2025-02-04 02:54:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20754/23838 [18:09<19:13,  2.67it/s][2025-02-04 02:54:59][root][INFO] - Training Epoch: 2/2, step 20753/23838 completed (loss: 0.07300235331058502, acc: 0.9776119589805603)
[2025-02-04 02:54:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20755/23838 [18:10<19:11,  2.68it/s][2025-02-04 02:54:59][root][INFO] - Training Epoch: 2/2, step 20754/23838 completed (loss: 0.1570345163345337, acc: 0.9624999761581421)
[2025-02-04 02:54:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20756/23838 [18:10<19:14,  2.67it/s][2025-02-04 02:55:00][root][INFO] - Training Epoch: 2/2, step 20755/23838 completed (loss: 0.16279157996177673, acc: 0.9568965435028076)
[2025-02-04 02:55:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20757/23838 [18:10<19:51,  2.59it/s][2025-02-04 02:55:00][root][INFO] - Training Epoch: 2/2, step 20756/23838 completed (loss: 0.15555982291698456, acc: 0.9671052694320679)
[2025-02-04 02:55:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20758/23838 [18:11<19:14,  2.67it/s][2025-02-04 02:55:00][root][INFO] - Training Epoch: 2/2, step 20757/23838 completed (loss: 0.05658363178372383, acc: 0.9776119589805603)
[2025-02-04 02:55:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20759/23838 [18:11<19:12,  2.67it/s][2025-02-04 02:55:01][root][INFO] - Training Epoch: 2/2, step 20758/23838 completed (loss: 0.3783116936683655, acc: 0.8795180916786194)
[2025-02-04 02:55:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20760/23838 [18:12<20:33,  2.50it/s][2025-02-04 02:55:01][root][INFO] - Training Epoch: 2/2, step 20759/23838 completed (loss: 0.095551498234272, acc: 0.96875)
[2025-02-04 02:55:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20761/23838 [18:12<20:07,  2.55it/s][2025-02-04 02:55:02][root][INFO] - Training Epoch: 2/2, step 20760/23838 completed (loss: 0.06012571603059769, acc: 0.9836065769195557)
[2025-02-04 02:55:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20762/23838 [18:12<20:49,  2.46it/s][2025-02-04 02:55:02][root][INFO] - Training Epoch: 2/2, step 20761/23838 completed (loss: 0.23436862230300903, acc: 0.9556962251663208)
[2025-02-04 02:55:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20763/23838 [18:13<21:52,  2.34it/s][2025-02-04 02:55:03][root][INFO] - Training Epoch: 2/2, step 20762/23838 completed (loss: 0.05767066404223442, acc: 0.9851852059364319)
[2025-02-04 02:55:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20764/23838 [18:13<22:18,  2.30it/s][2025-02-04 02:55:03][root][INFO] - Training Epoch: 2/2, step 20763/23838 completed (loss: 0.023833557963371277, acc: 0.9945651888847351)
[2025-02-04 02:55:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20765/23838 [18:14<22:28,  2.28it/s][2025-02-04 02:55:03][root][INFO] - Training Epoch: 2/2, step 20764/23838 completed (loss: 0.06182721257209778, acc: 0.9826086759567261)
[2025-02-04 02:55:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20766/23838 [18:14<22:09,  2.31it/s][2025-02-04 02:55:04][root][INFO] - Training Epoch: 2/2, step 20765/23838 completed (loss: 0.32707470655441284, acc: 0.9125000238418579)
[2025-02-04 02:55:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20767/23838 [18:15<21:43,  2.36it/s][2025-02-04 02:55:04][root][INFO] - Training Epoch: 2/2, step 20766/23838 completed (loss: 0.14181382954120636, acc: 0.9609375)
[2025-02-04 02:55:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20768/23838 [18:15<21:17,  2.40it/s][2025-02-04 02:55:05][root][INFO] - Training Epoch: 2/2, step 20767/23838 completed (loss: 0.22829978168010712, acc: 0.9640287756919861)
[2025-02-04 02:55:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20769/23838 [18:15<19:57,  2.56it/s][2025-02-04 02:55:05][root][INFO] - Training Epoch: 2/2, step 20768/23838 completed (loss: 0.5273625254631042, acc: 0.858208954334259)
[2025-02-04 02:55:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20770/23838 [18:16<20:05,  2.55it/s][2025-02-04 02:55:05][root][INFO] - Training Epoch: 2/2, step 20769/23838 completed (loss: 0.29024431109428406, acc: 0.8913043737411499)
[2025-02-04 02:55:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20771/23838 [18:16<19:08,  2.67it/s][2025-02-04 02:55:06][root][INFO] - Training Epoch: 2/2, step 20770/23838 completed (loss: 0.4351150095462799, acc: 0.8901098966598511)
[2025-02-04 02:55:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20772/23838 [18:16<19:12,  2.66it/s][2025-02-04 02:55:06][root][INFO] - Training Epoch: 2/2, step 20771/23838 completed (loss: 0.17590337991714478, acc: 0.9041095972061157)
[2025-02-04 02:55:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20773/23838 [18:17<20:22,  2.51it/s][2025-02-04 02:55:07][root][INFO] - Training Epoch: 2/2, step 20772/23838 completed (loss: 0.18108990788459778, acc: 0.954285740852356)
[2025-02-04 02:55:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20774/23838 [18:17<19:48,  2.58it/s][2025-02-04 02:55:07][root][INFO] - Training Epoch: 2/2, step 20773/23838 completed (loss: 0.3580554127693176, acc: 0.8539325594902039)
[2025-02-04 02:55:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20775/23838 [18:18<19:53,  2.57it/s][2025-02-04 02:55:07][root][INFO] - Training Epoch: 2/2, step 20774/23838 completed (loss: 0.37073370814323425, acc: 0.8846153616905212)
[2025-02-04 02:55:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20776/23838 [18:18<19:37,  2.60it/s][2025-02-04 02:55:08][root][INFO] - Training Epoch: 2/2, step 20775/23838 completed (loss: 0.17444993555545807, acc: 0.9420289993286133)
[2025-02-04 02:55:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20777/23838 [18:18<17:52,  2.85it/s][2025-02-04 02:55:08][root][INFO] - Training Epoch: 2/2, step 20776/23838 completed (loss: 0.07087253779172897, acc: 0.9905660152435303)
[2025-02-04 02:55:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20778/23838 [18:19<17:20,  2.94it/s][2025-02-04 02:55:08][root][INFO] - Training Epoch: 2/2, step 20777/23838 completed (loss: 0.17280834913253784, acc: 0.9387755393981934)
[2025-02-04 02:55:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20779/23838 [18:19<16:55,  3.01it/s][2025-02-04 02:55:09][root][INFO] - Training Epoch: 2/2, step 20778/23838 completed (loss: 0.4600820541381836, acc: 0.8764045238494873)
[2025-02-04 02:55:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20780/23838 [18:19<17:03,  2.99it/s][2025-02-04 02:55:09][root][INFO] - Training Epoch: 2/2, step 20779/23838 completed (loss: 0.19497907161712646, acc: 0.9473684430122375)
[2025-02-04 02:55:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20781/23838 [18:20<16:57,  3.00it/s][2025-02-04 02:55:09][root][INFO] - Training Epoch: 2/2, step 20780/23838 completed (loss: 0.17055612802505493, acc: 0.9404761791229248)
[2025-02-04 02:55:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20782/23838 [18:20<17:23,  2.93it/s][2025-02-04 02:55:10][root][INFO] - Training Epoch: 2/2, step 20781/23838 completed (loss: 0.37612780928611755, acc: 0.9204545617103577)
[2025-02-04 02:55:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20783/23838 [18:20<16:54,  3.01it/s][2025-02-04 02:55:10][root][INFO] - Training Epoch: 2/2, step 20782/23838 completed (loss: 0.07929745316505432, acc: 0.9740259647369385)
[2025-02-04 02:55:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20784/23838 [18:21<17:10,  2.96it/s][2025-02-04 02:55:10][root][INFO] - Training Epoch: 2/2, step 20783/23838 completed (loss: 0.4224338233470917, acc: 0.8611111044883728)
[2025-02-04 02:55:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20785/23838 [18:21<17:14,  2.95it/s][2025-02-04 02:55:11][root][INFO] - Training Epoch: 2/2, step 20784/23838 completed (loss: 0.5314107537269592, acc: 0.8533333539962769)
[2025-02-04 02:55:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20786/23838 [18:21<16:50,  3.02it/s][2025-02-04 02:55:11][root][INFO] - Training Epoch: 2/2, step 20785/23838 completed (loss: 0.3512200117111206, acc: 0.9090909361839294)
[2025-02-04 02:55:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20787/23838 [18:22<17:21,  2.93it/s][2025-02-04 02:55:11][root][INFO] - Training Epoch: 2/2, step 20786/23838 completed (loss: 0.3866029977798462, acc: 0.8888888955116272)
[2025-02-04 02:55:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20788/23838 [18:22<19:17,  2.64it/s][2025-02-04 02:55:12][root][INFO] - Training Epoch: 2/2, step 20787/23838 completed (loss: 0.2758744955062866, acc: 0.936170220375061)
[2025-02-04 02:55:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20789/23838 [18:23<19:27,  2.61it/s][2025-02-04 02:55:12][root][INFO] - Training Epoch: 2/2, step 20788/23838 completed (loss: 0.32388919591903687, acc: 0.8990825414657593)
[2025-02-04 02:55:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20790/23838 [18:23<19:37,  2.59it/s][2025-02-04 02:55:13][root][INFO] - Training Epoch: 2/2, step 20789/23838 completed (loss: 0.23071721196174622, acc: 0.9495798349380493)
[2025-02-04 02:55:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20791/23838 [18:23<20:17,  2.50it/s][2025-02-04 02:55:13][root][INFO] - Training Epoch: 2/2, step 20790/23838 completed (loss: 0.2972159683704376, acc: 0.9113923907279968)
[2025-02-04 02:55:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20792/23838 [18:24<19:58,  2.54it/s][2025-02-04 02:55:13][root][INFO] - Training Epoch: 2/2, step 20791/23838 completed (loss: 0.2679499387741089, acc: 0.9186046719551086)
[2025-02-04 02:55:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20793/23838 [18:24<19:04,  2.66it/s][2025-02-04 02:55:14][root][INFO] - Training Epoch: 2/2, step 20792/23838 completed (loss: 0.17366063594818115, acc: 0.96875)
[2025-02-04 02:55:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20794/23838 [18:24<19:06,  2.66it/s][2025-02-04 02:55:14][root][INFO] - Training Epoch: 2/2, step 20793/23838 completed (loss: 0.11511226743459702, acc: 0.9878048896789551)
[2025-02-04 02:55:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20795/23838 [18:25<19:56,  2.54it/s][2025-02-04 02:55:14][root][INFO] - Training Epoch: 2/2, step 20794/23838 completed (loss: 0.09736861288547516, acc: 0.984375)
[2025-02-04 02:55:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20796/23838 [18:25<20:27,  2.48it/s][2025-02-04 02:55:15][root][INFO] - Training Epoch: 2/2, step 20795/23838 completed (loss: 0.34315821528434753, acc: 0.9268292784690857)
[2025-02-04 02:55:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20797/23838 [18:26<20:56,  2.42it/s][2025-02-04 02:55:15][root][INFO] - Training Epoch: 2/2, step 20796/23838 completed (loss: 0.36882370710372925, acc: 0.9102563858032227)
[2025-02-04 02:55:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20798/23838 [18:26<22:03,  2.30it/s][2025-02-04 02:55:16][root][INFO] - Training Epoch: 2/2, step 20797/23838 completed (loss: 0.06376263499259949, acc: 0.9772727489471436)
[2025-02-04 02:55:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20799/23838 [18:27<20:52,  2.43it/s][2025-02-04 02:55:16][root][INFO] - Training Epoch: 2/2, step 20798/23838 completed (loss: 0.038906361907720566, acc: 1.0)
[2025-02-04 02:55:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20800/23838 [18:27<20:29,  2.47it/s][2025-02-04 02:55:17][root][INFO] - Training Epoch: 2/2, step 20799/23838 completed (loss: 0.08595336228609085, acc: 0.9650349617004395)
[2025-02-04 02:55:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20801/23838 [18:27<19:15,  2.63it/s][2025-02-04 02:55:17][root][INFO] - Training Epoch: 2/2, step 20800/23838 completed (loss: 0.15225273370742798, acc: 0.9428571462631226)
[2025-02-04 02:55:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20802/23838 [18:28<18:51,  2.68it/s][2025-02-04 02:55:17][root][INFO] - Training Epoch: 2/2, step 20801/23838 completed (loss: 0.41697070002555847, acc: 0.8850574493408203)
[2025-02-04 02:55:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20803/23838 [18:28<20:38,  2.45it/s][2025-02-04 02:55:18][root][INFO] - Training Epoch: 2/2, step 20802/23838 completed (loss: 0.0572705939412117, acc: 0.9836065769195557)
[2025-02-04 02:55:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20804/23838 [18:28<19:41,  2.57it/s][2025-02-04 02:55:18][root][INFO] - Training Epoch: 2/2, step 20803/23838 completed (loss: 0.040107108652591705, acc: 0.9917355179786682)
[2025-02-04 02:55:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20805/23838 [18:29<19:27,  2.60it/s][2025-02-04 02:55:18][root][INFO] - Training Epoch: 2/2, step 20804/23838 completed (loss: 0.2683632969856262, acc: 0.9146341681480408)
[2025-02-04 02:55:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20806/23838 [18:29<18:25,  2.74it/s][2025-02-04 02:55:19][root][INFO] - Training Epoch: 2/2, step 20805/23838 completed (loss: 0.2098914235830307, acc: 0.9333333373069763)
[2025-02-04 02:55:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20807/23838 [18:29<17:32,  2.88it/s][2025-02-04 02:55:19][root][INFO] - Training Epoch: 2/2, step 20806/23838 completed (loss: 0.13684745132923126, acc: 0.9846153855323792)
[2025-02-04 02:55:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20808/23838 [18:30<17:51,  2.83it/s][2025-02-04 02:55:19][root][INFO] - Training Epoch: 2/2, step 20807/23838 completed (loss: 0.6182042956352234, acc: 0.800000011920929)
[2025-02-04 02:55:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20809/23838 [18:30<18:08,  2.78it/s][2025-02-04 02:55:20][root][INFO] - Training Epoch: 2/2, step 20808/23838 completed (loss: 0.8128935098648071, acc: 0.7692307829856873)
[2025-02-04 02:55:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20810/23838 [18:31<17:33,  2.87it/s][2025-02-04 02:55:20][root][INFO] - Training Epoch: 2/2, step 20809/23838 completed (loss: 0.24808253347873688, acc: 0.9230769276618958)
[2025-02-04 02:55:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20811/23838 [18:31<18:00,  2.80it/s][2025-02-04 02:55:21][root][INFO] - Training Epoch: 2/2, step 20810/23838 completed (loss: 0.2205403745174408, acc: 0.9307692050933838)
[2025-02-04 02:55:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20812/23838 [18:31<19:55,  2.53it/s][2025-02-04 02:55:21][root][INFO] - Training Epoch: 2/2, step 20811/23838 completed (loss: 0.2360401153564453, acc: 0.9433962106704712)
[2025-02-04 02:55:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20813/23838 [18:32<20:52,  2.42it/s][2025-02-04 02:55:21][root][INFO] - Training Epoch: 2/2, step 20812/23838 completed (loss: 0.25106605887413025, acc: 0.936170220375061)
[2025-02-04 02:55:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20814/23838 [18:32<20:05,  2.51it/s][2025-02-04 02:55:22][root][INFO] - Training Epoch: 2/2, step 20813/23838 completed (loss: 0.22300966084003448, acc: 0.9622641801834106)
[2025-02-04 02:55:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20815/23838 [18:33<19:18,  2.61it/s][2025-02-04 02:55:22][root][INFO] - Training Epoch: 2/2, step 20814/23838 completed (loss: 0.0795263946056366, acc: 0.9777777791023254)
[2025-02-04 02:55:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20816/23838 [18:33<18:21,  2.74it/s][2025-02-04 02:55:22][root][INFO] - Training Epoch: 2/2, step 20815/23838 completed (loss: 0.35140496492385864, acc: 0.8780487775802612)
[2025-02-04 02:55:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20817/23838 [18:33<17:35,  2.86it/s][2025-02-04 02:55:23][root][INFO] - Training Epoch: 2/2, step 20816/23838 completed (loss: 0.16178438067436218, acc: 0.9516128897666931)
[2025-02-04 02:55:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20818/23838 [18:34<17:21,  2.90it/s][2025-02-04 02:55:23][root][INFO] - Training Epoch: 2/2, step 20817/23838 completed (loss: 0.12101102620363235, acc: 0.9615384340286255)
[2025-02-04 02:55:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20819/23838 [18:34<17:46,  2.83it/s][2025-02-04 02:55:24][root][INFO] - Training Epoch: 2/2, step 20818/23838 completed (loss: 0.05137410759925842, acc: 0.991525411605835)
[2025-02-04 02:55:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20820/23838 [18:34<17:33,  2.87it/s][2025-02-04 02:55:24][root][INFO] - Training Epoch: 2/2, step 20819/23838 completed (loss: 0.16137918829917908, acc: 0.9615384340286255)
[2025-02-04 02:55:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20821/23838 [18:35<17:31,  2.87it/s][2025-02-04 02:55:24][root][INFO] - Training Epoch: 2/2, step 20820/23838 completed (loss: 1.1391911506652832, acc: 0.6829268336296082)
[2025-02-04 02:55:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20822/23838 [18:35<17:25,  2.89it/s][2025-02-04 02:55:25][root][INFO] - Training Epoch: 2/2, step 20821/23838 completed (loss: 0.8721409440040588, acc: 0.7272727489471436)
[2025-02-04 02:55:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20823/23838 [18:35<17:18,  2.90it/s][2025-02-04 02:55:25][root][INFO] - Training Epoch: 2/2, step 20822/23838 completed (loss: 0.15978118777275085, acc: 0.921875)
[2025-02-04 02:55:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20824/23838 [18:36<17:17,  2.90it/s][2025-02-04 02:55:25][root][INFO] - Training Epoch: 2/2, step 20823/23838 completed (loss: 0.13676875829696655, acc: 0.9506173133850098)
[2025-02-04 02:55:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20825/23838 [18:36<18:00,  2.79it/s][2025-02-04 02:55:26][root][INFO] - Training Epoch: 2/2, step 20824/23838 completed (loss: 0.13998618721961975, acc: 0.9655172228813171)
[2025-02-04 02:55:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20826/23838 [18:36<17:49,  2.82it/s][2025-02-04 02:55:26][root][INFO] - Training Epoch: 2/2, step 20825/23838 completed (loss: 0.7043874859809875, acc: 0.800000011920929)
[2025-02-04 02:55:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20827/23838 [18:37<17:11,  2.92it/s][2025-02-04 02:55:26][root][INFO] - Training Epoch: 2/2, step 20826/23838 completed (loss: 0.4544489085674286, acc: 0.8552631735801697)
[2025-02-04 02:55:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20828/23838 [18:37<17:35,  2.85it/s][2025-02-04 02:55:27][root][INFO] - Training Epoch: 2/2, step 20827/23838 completed (loss: 0.1911759376525879, acc: 0.949999988079071)
[2025-02-04 02:55:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20829/23838 [18:37<18:08,  2.76it/s][2025-02-04 02:55:27][root][INFO] - Training Epoch: 2/2, step 20828/23838 completed (loss: 0.20714092254638672, acc: 0.9337748289108276)
[2025-02-04 02:55:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20830/23838 [18:38<17:11,  2.92it/s][2025-02-04 02:55:27][root][INFO] - Training Epoch: 2/2, step 20829/23838 completed (loss: 0.34048551321029663, acc: 0.9268292784690857)
[2025-02-04 02:55:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20831/23838 [18:38<16:44,  2.99it/s][2025-02-04 02:55:28][root][INFO] - Training Epoch: 2/2, step 20830/23838 completed (loss: 0.15534363687038422, acc: 0.9599999785423279)
[2025-02-04 02:55:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20832/23838 [18:38<16:21,  3.06it/s][2025-02-04 02:55:28][root][INFO] - Training Epoch: 2/2, step 20831/23838 completed (loss: 0.1305031180381775, acc: 0.9599999785423279)
[2025-02-04 02:55:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20833/23838 [18:39<17:09,  2.92it/s][2025-02-04 02:55:28][root][INFO] - Training Epoch: 2/2, step 20832/23838 completed (loss: 0.12620316445827484, acc: 0.9589040875434875)
[2025-02-04 02:55:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20834/23838 [18:39<17:42,  2.83it/s][2025-02-04 02:55:29][root][INFO] - Training Epoch: 2/2, step 20833/23838 completed (loss: 0.47170576453208923, acc: 0.8846153616905212)
[2025-02-04 02:55:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20835/23838 [18:40<18:35,  2.69it/s][2025-02-04 02:55:29][root][INFO] - Training Epoch: 2/2, step 20834/23838 completed (loss: 0.8765373229980469, acc: 0.7681159377098083)
[2025-02-04 02:55:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20836/23838 [18:40<18:08,  2.76it/s][2025-02-04 02:55:29][root][INFO] - Training Epoch: 2/2, step 20835/23838 completed (loss: 0.40370452404022217, acc: 0.9027777910232544)
[2025-02-04 02:55:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20837/23838 [18:40<17:31,  2.85it/s][2025-02-04 02:55:30][root][INFO] - Training Epoch: 2/2, step 20836/23838 completed (loss: 0.21544857323169708, acc: 0.8999999761581421)
[2025-02-04 02:55:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20838/23838 [18:41<17:07,  2.92it/s][2025-02-04 02:55:30][root][INFO] - Training Epoch: 2/2, step 20837/23838 completed (loss: 0.19281239807605743, acc: 0.96875)
[2025-02-04 02:55:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20839/23838 [18:41<17:19,  2.88it/s][2025-02-04 02:55:30][root][INFO] - Training Epoch: 2/2, step 20838/23838 completed (loss: 0.3627053201198578, acc: 0.921875)
[2025-02-04 02:55:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20840/23838 [18:41<17:03,  2.93it/s][2025-02-04 02:55:31][root][INFO] - Training Epoch: 2/2, step 20839/23838 completed (loss: 0.1601676046848297, acc: 0.9399999976158142)
[2025-02-04 02:55:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20841/23838 [18:42<17:13,  2.90it/s][2025-02-04 02:55:31][root][INFO] - Training Epoch: 2/2, step 20840/23838 completed (loss: 0.3015930652618408, acc: 0.875)
[2025-02-04 02:55:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20842/23838 [18:42<17:09,  2.91it/s][2025-02-04 02:55:31][root][INFO] - Training Epoch: 2/2, step 20841/23838 completed (loss: 0.2223089039325714, acc: 0.9056603908538818)
[2025-02-04 02:55:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20843/23838 [18:42<18:05,  2.76it/s][2025-02-04 02:55:32][root][INFO] - Training Epoch: 2/2, step 20842/23838 completed (loss: 0.11175264418125153, acc: 1.0)
[2025-02-04 02:55:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20844/23838 [18:43<18:17,  2.73it/s][2025-02-04 02:55:32][root][INFO] - Training Epoch: 2/2, step 20843/23838 completed (loss: 0.3736550807952881, acc: 0.8199999928474426)
[2025-02-04 02:55:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20845/23838 [18:43<18:19,  2.72it/s][2025-02-04 02:55:33][root][INFO] - Training Epoch: 2/2, step 20844/23838 completed (loss: 0.33381253480911255, acc: 0.8524590134620667)
[2025-02-04 02:55:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20846/23838 [18:43<18:02,  2.76it/s][2025-02-04 02:55:33][root][INFO] - Training Epoch: 2/2, step 20845/23838 completed (loss: 0.3517172932624817, acc: 0.8904109597206116)
[2025-02-04 02:55:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20847/23838 [18:44<17:57,  2.78it/s][2025-02-04 02:55:33][root][INFO] - Training Epoch: 2/2, step 20846/23838 completed (loss: 0.2681891918182373, acc: 0.9166666865348816)
[2025-02-04 02:55:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20848/23838 [18:44<17:03,  2.92it/s][2025-02-04 02:55:34][root][INFO] - Training Epoch: 2/2, step 20847/23838 completed (loss: 0.378542959690094, acc: 0.8545454740524292)
[2025-02-04 02:55:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20849/23838 [18:44<16:49,  2.96it/s][2025-02-04 02:55:34][root][INFO] - Training Epoch: 2/2, step 20848/23838 completed (loss: 0.7413037419319153, acc: 0.8387096524238586)
[2025-02-04 02:55:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20850/23838 [18:45<16:54,  2.94it/s][2025-02-04 02:55:34][root][INFO] - Training Epoch: 2/2, step 20849/23838 completed (loss: 0.19062307476997375, acc: 0.949999988079071)
[2025-02-04 02:55:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20851/23838 [18:45<16:57,  2.93it/s][2025-02-04 02:55:35][root][INFO] - Training Epoch: 2/2, step 20850/23838 completed (loss: 0.744591474533081, acc: 0.7659574747085571)
[2025-02-04 02:55:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20852/23838 [18:45<17:32,  2.84it/s][2025-02-04 02:55:35][root][INFO] - Training Epoch: 2/2, step 20851/23838 completed (loss: 0.16656288504600525, acc: 0.9777777791023254)
[2025-02-04 02:55:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20853/23838 [18:46<22:28,  2.21it/s][2025-02-04 02:55:36][root][INFO] - Training Epoch: 2/2, step 20852/23838 completed (loss: 0.04085296019911766, acc: 1.0)
[2025-02-04 02:55:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20854/23838 [18:47<20:59,  2.37it/s][2025-02-04 02:55:36][root][INFO] - Training Epoch: 2/2, step 20853/23838 completed (loss: 0.26509562134742737, acc: 0.970588207244873)
[2025-02-04 02:55:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20855/23838 [18:47<19:41,  2.52it/s][2025-02-04 02:55:36][root][INFO] - Training Epoch: 2/2, step 20854/23838 completed (loss: 0.2733665704727173, acc: 0.8399999737739563)
[2025-02-04 02:55:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20856/23838 [18:47<18:28,  2.69it/s][2025-02-04 02:55:37][root][INFO] - Training Epoch: 2/2, step 20855/23838 completed (loss: 0.49633100628852844, acc: 0.875)
[2025-02-04 02:55:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20857/23838 [18:48<19:13,  2.58it/s][2025-02-04 02:55:37][root][INFO] - Training Epoch: 2/2, step 20856/23838 completed (loss: 0.2191321849822998, acc: 0.9512194991111755)
[2025-02-04 02:55:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  87%|[34m████████▋ [0m| 20858/23838 [18:48<18:38,  2.66it/s][2025-02-04 02:55:38][root][INFO] - Training Epoch: 2/2, step 20857/23838 completed (loss: 0.11723841726779938, acc: 0.9555555582046509)
[2025-02-04 02:55:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20859/23838 [18:48<18:20,  2.71it/s][2025-02-04 02:55:38][root][INFO] - Training Epoch: 2/2, step 20858/23838 completed (loss: 0.33077219128608704, acc: 0.891566276550293)
[2025-02-04 02:55:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20860/23838 [18:49<18:50,  2.63it/s][2025-02-04 02:55:38][root][INFO] - Training Epoch: 2/2, step 20859/23838 completed (loss: 0.4883921444416046, acc: 0.8453608155250549)
[2025-02-04 02:55:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20861/23838 [18:49<18:08,  2.73it/s][2025-02-04 02:55:39][root][INFO] - Training Epoch: 2/2, step 20860/23838 completed (loss: 0.12941500544548035, acc: 0.9512194991111755)
[2025-02-04 02:55:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20862/23838 [18:49<18:16,  2.72it/s][2025-02-04 02:55:39][root][INFO] - Training Epoch: 2/2, step 20861/23838 completed (loss: 0.3596467077732086, acc: 0.8985507488250732)
[2025-02-04 02:55:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20863/23838 [18:50<18:41,  2.65it/s][2025-02-04 02:55:39][root][INFO] - Training Epoch: 2/2, step 20862/23838 completed (loss: 0.36743608117103577, acc: 0.8909090757369995)
[2025-02-04 02:55:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20864/23838 [18:50<18:14,  2.72it/s][2025-02-04 02:55:40][root][INFO] - Training Epoch: 2/2, step 20863/23838 completed (loss: 0.3970787525177002, acc: 0.8888888955116272)
[2025-02-04 02:55:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20865/23838 [18:51<19:02,  2.60it/s][2025-02-04 02:55:40][root][INFO] - Training Epoch: 2/2, step 20864/23838 completed (loss: 0.5066949129104614, acc: 0.8627451062202454)
[2025-02-04 02:55:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20866/23838 [18:51<19:13,  2.58it/s][2025-02-04 02:55:41][root][INFO] - Training Epoch: 2/2, step 20865/23838 completed (loss: 0.46211299300193787, acc: 0.862500011920929)
[2025-02-04 02:55:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20867/23838 [18:51<18:52,  2.62it/s][2025-02-04 02:55:41][root][INFO] - Training Epoch: 2/2, step 20866/23838 completed (loss: 0.5402378439903259, acc: 0.8732394576072693)
[2025-02-04 02:55:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20868/23838 [18:52<17:20,  2.86it/s][2025-02-04 02:55:41][root][INFO] - Training Epoch: 2/2, step 20867/23838 completed (loss: 0.16513176262378693, acc: 0.8913043737411499)
[2025-02-04 02:55:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20869/23838 [18:52<17:11,  2.88it/s][2025-02-04 02:55:42][root][INFO] - Training Epoch: 2/2, step 20868/23838 completed (loss: 0.5727985501289368, acc: 0.8863636255264282)
[2025-02-04 02:55:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20870/23838 [18:52<17:11,  2.88it/s][2025-02-04 02:55:42][root][INFO] - Training Epoch: 2/2, step 20869/23838 completed (loss: 0.18881608545780182, acc: 0.9677419066429138)
[2025-02-04 02:55:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20871/23838 [18:53<17:07,  2.89it/s][2025-02-04 02:55:42][root][INFO] - Training Epoch: 2/2, step 20870/23838 completed (loss: 0.37840431928634644, acc: 0.8846153616905212)
[2025-02-04 02:55:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20872/23838 [18:53<16:47,  2.94it/s][2025-02-04 02:55:43][root][INFO] - Training Epoch: 2/2, step 20871/23838 completed (loss: 0.04385966807603836, acc: 1.0)
[2025-02-04 02:55:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20873/23838 [18:53<16:36,  2.97it/s][2025-02-04 02:55:43][root][INFO] - Training Epoch: 2/2, step 20872/23838 completed (loss: 0.17288902401924133, acc: 0.9333333373069763)
[2025-02-04 02:55:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20874/23838 [18:54<16:16,  3.03it/s][2025-02-04 02:55:43][root][INFO] - Training Epoch: 2/2, step 20873/23838 completed (loss: 0.2003529667854309, acc: 0.9200000166893005)
[2025-02-04 02:55:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20875/23838 [18:54<16:25,  3.01it/s][2025-02-04 02:55:44][root][INFO] - Training Epoch: 2/2, step 20874/23838 completed (loss: 0.11766801029443741, acc: 0.95652174949646)
[2025-02-04 02:55:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20876/23838 [18:54<16:09,  3.06it/s][2025-02-04 02:55:44][root][INFO] - Training Epoch: 2/2, step 20875/23838 completed (loss: 0.2204264998435974, acc: 0.9259259104728699)
[2025-02-04 02:55:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20877/23838 [18:55<15:59,  3.09it/s][2025-02-04 02:55:44][root][INFO] - Training Epoch: 2/2, step 20876/23838 completed (loss: 0.28417012095451355, acc: 0.8857142925262451)
[2025-02-04 02:55:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20878/23838 [18:55<15:50,  3.11it/s][2025-02-04 02:55:44][root][INFO] - Training Epoch: 2/2, step 20877/23838 completed (loss: 0.5286921858787537, acc: 0.8500000238418579)
[2025-02-04 02:55:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20879/23838 [18:55<16:01,  3.08it/s][2025-02-04 02:55:45][root][INFO] - Training Epoch: 2/2, step 20878/23838 completed (loss: 0.22606804966926575, acc: 0.9032257795333862)
[2025-02-04 02:55:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20880/23838 [18:56<15:47,  3.12it/s][2025-02-04 02:55:45][root][INFO] - Training Epoch: 2/2, step 20879/23838 completed (loss: 0.5303279757499695, acc: 0.8928571343421936)
[2025-02-04 02:55:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20881/23838 [18:56<16:03,  3.07it/s][2025-02-04 02:55:45][root][INFO] - Training Epoch: 2/2, step 20880/23838 completed (loss: 0.19988657534122467, acc: 0.9583333134651184)
[2025-02-04 02:55:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20882/23838 [18:56<16:58,  2.90it/s][2025-02-04 02:55:46][root][INFO] - Training Epoch: 2/2, step 20881/23838 completed (loss: 0.08365930616855621, acc: 1.0)
[2025-02-04 02:55:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20883/23838 [18:57<17:14,  2.86it/s][2025-02-04 02:55:46][root][INFO] - Training Epoch: 2/2, step 20882/23838 completed (loss: 0.46171802282333374, acc: 0.8709677457809448)
[2025-02-04 02:55:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20884/23838 [18:57<16:56,  2.91it/s][2025-02-04 02:55:47][root][INFO] - Training Epoch: 2/2, step 20883/23838 completed (loss: 0.056583207100629807, acc: 1.0)
[2025-02-04 02:55:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20885/23838 [18:57<16:14,  3.03it/s][2025-02-04 02:55:47][root][INFO] - Training Epoch: 2/2, step 20884/23838 completed (loss: 0.5467787384986877, acc: 0.8181818127632141)
[2025-02-04 02:55:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20886/23838 [18:58<16:32,  2.98it/s][2025-02-04 02:55:47][root][INFO] - Training Epoch: 2/2, step 20885/23838 completed (loss: 0.06513269245624542, acc: 1.0)
[2025-02-04 02:55:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20887/23838 [18:58<16:27,  2.99it/s][2025-02-04 02:55:48][root][INFO] - Training Epoch: 2/2, step 20886/23838 completed (loss: 0.4635421335697174, acc: 0.9166666865348816)
[2025-02-04 02:55:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20888/23838 [18:58<15:42,  3.13it/s][2025-02-04 02:55:48][root][INFO] - Training Epoch: 2/2, step 20887/23838 completed (loss: 0.23607631027698517, acc: 0.9655172228813171)
[2025-02-04 02:55:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20889/23838 [18:59<16:05,  3.05it/s][2025-02-04 02:55:48][root][INFO] - Training Epoch: 2/2, step 20888/23838 completed (loss: 0.27300775051116943, acc: 0.8571428656578064)
[2025-02-04 02:55:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20890/23838 [18:59<16:25,  2.99it/s][2025-02-04 02:55:48][root][INFO] - Training Epoch: 2/2, step 20889/23838 completed (loss: 0.2802015542984009, acc: 0.9230769276618958)
[2025-02-04 02:55:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20891/23838 [18:59<16:18,  3.01it/s][2025-02-04 02:55:49][root][INFO] - Training Epoch: 2/2, step 20890/23838 completed (loss: 0.02870127372443676, acc: 1.0)
[2025-02-04 02:55:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20892/23838 [19:00<16:53,  2.91it/s][2025-02-04 02:55:49][root][INFO] - Training Epoch: 2/2, step 20891/23838 completed (loss: 0.5115489363670349, acc: 0.8333333134651184)
[2025-02-04 02:55:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20893/23838 [19:00<17:18,  2.84it/s][2025-02-04 02:55:50][root][INFO] - Training Epoch: 2/2, step 20892/23838 completed (loss: 0.7465081810951233, acc: 0.7058823704719543)
[2025-02-04 02:55:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20894/23838 [19:00<16:47,  2.92it/s][2025-02-04 02:55:50][root][INFO] - Training Epoch: 2/2, step 20893/23838 completed (loss: 0.8125399351119995, acc: 0.8235294222831726)
[2025-02-04 02:55:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20895/23838 [19:01<17:28,  2.81it/s][2025-02-04 02:55:50][root][INFO] - Training Epoch: 2/2, step 20894/23838 completed (loss: 0.27409568428993225, acc: 0.9166666865348816)
[2025-02-04 02:55:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20896/23838 [19:01<17:21,  2.82it/s][2025-02-04 02:55:51][root][INFO] - Training Epoch: 2/2, step 20895/23838 completed (loss: 0.31683677434921265, acc: 0.8947368264198303)
[2025-02-04 02:55:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20897/23838 [19:01<17:13,  2.85it/s][2025-02-04 02:55:51][root][INFO] - Training Epoch: 2/2, step 20896/23838 completed (loss: 0.2529444694519043, acc: 0.9545454382896423)
[2025-02-04 02:55:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20898/23838 [19:02<16:43,  2.93it/s][2025-02-04 02:55:51][root][INFO] - Training Epoch: 2/2, step 20897/23838 completed (loss: 0.18690478801727295, acc: 0.9583333134651184)
[2025-02-04 02:55:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20899/23838 [19:02<16:43,  2.93it/s][2025-02-04 02:55:52][root][INFO] - Training Epoch: 2/2, step 20898/23838 completed (loss: 0.5116810202598572, acc: 0.8888888955116272)
[2025-02-04 02:55:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20900/23838 [19:02<16:50,  2.91it/s][2025-02-04 02:55:52][root][INFO] - Training Epoch: 2/2, step 20899/23838 completed (loss: 0.2682458162307739, acc: 0.9444444179534912)
[2025-02-04 02:55:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20901/23838 [19:03<16:38,  2.94it/s][2025-02-04 02:55:52][root][INFO] - Training Epoch: 2/2, step 20900/23838 completed (loss: 0.14135225117206573, acc: 1.0)
[2025-02-04 02:55:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20902/23838 [19:03<16:41,  2.93it/s][2025-02-04 02:55:53][root][INFO] - Training Epoch: 2/2, step 20901/23838 completed (loss: 0.3942525088787079, acc: 0.8636363744735718)
[2025-02-04 02:55:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20903/23838 [19:03<17:19,  2.82it/s][2025-02-04 02:55:53][root][INFO] - Training Epoch: 2/2, step 20902/23838 completed (loss: 0.17258727550506592, acc: 0.9285714030265808)
[2025-02-04 02:55:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20904/23838 [19:04<17:29,  2.80it/s][2025-02-04 02:55:53][root][INFO] - Training Epoch: 2/2, step 20903/23838 completed (loss: 0.4654465913772583, acc: 0.8285714387893677)
[2025-02-04 02:55:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20905/23838 [19:04<17:16,  2.83it/s][2025-02-04 02:55:54][root][INFO] - Training Epoch: 2/2, step 20904/23838 completed (loss: 0.14822126924991608, acc: 1.0)
[2025-02-04 02:55:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20906/23838 [19:04<17:08,  2.85it/s][2025-02-04 02:55:54][root][INFO] - Training Epoch: 2/2, step 20905/23838 completed (loss: 0.6158506274223328, acc: 0.8947368264198303)
[2025-02-04 02:55:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20907/23838 [19:05<17:51,  2.74it/s][2025-02-04 02:55:54][root][INFO] - Training Epoch: 2/2, step 20906/23838 completed (loss: 0.5729989409446716, acc: 0.8260869383811951)
[2025-02-04 02:55:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20908/23838 [19:05<17:23,  2.81it/s][2025-02-04 02:55:55][root][INFO] - Training Epoch: 2/2, step 20907/23838 completed (loss: 1.1107569932937622, acc: 0.7115384340286255)
[2025-02-04 02:55:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20909/23838 [19:06<17:23,  2.81it/s][2025-02-04 02:55:55][root][INFO] - Training Epoch: 2/2, step 20908/23838 completed (loss: 0.5969406366348267, acc: 0.8148148059844971)
[2025-02-04 02:55:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20910/23838 [19:06<17:56,  2.72it/s][2025-02-04 02:55:56][root][INFO] - Training Epoch: 2/2, step 20909/23838 completed (loss: 0.5605456233024597, acc: 0.800000011920929)
[2025-02-04 02:55:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20911/23838 [19:06<17:32,  2.78it/s][2025-02-04 02:55:56][root][INFO] - Training Epoch: 2/2, step 20910/23838 completed (loss: 0.4266361892223358, acc: 0.90625)
[2025-02-04 02:55:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20912/23838 [19:07<17:45,  2.75it/s][2025-02-04 02:55:56][root][INFO] - Training Epoch: 2/2, step 20911/23838 completed (loss: 0.6048816442489624, acc: 0.7777777910232544)
[2025-02-04 02:55:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20913/23838 [19:07<17:27,  2.79it/s][2025-02-04 02:55:57][root][INFO] - Training Epoch: 2/2, step 20912/23838 completed (loss: 0.49954742193222046, acc: 0.8571428656578064)
[2025-02-04 02:55:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20914/23838 [19:07<17:09,  2.84it/s][2025-02-04 02:55:57][root][INFO] - Training Epoch: 2/2, step 20913/23838 completed (loss: 1.2172605991363525, acc: 0.7272727489471436)
[2025-02-04 02:55:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20915/23838 [19:08<16:36,  2.93it/s][2025-02-04 02:55:57][root][INFO] - Training Epoch: 2/2, step 20914/23838 completed (loss: 0.31058287620544434, acc: 0.9130434989929199)
[2025-02-04 02:55:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20916/23838 [19:08<16:12,  3.01it/s][2025-02-04 02:55:58][root][INFO] - Training Epoch: 2/2, step 20915/23838 completed (loss: 0.19219648838043213, acc: 1.0)
[2025-02-04 02:55:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20917/23838 [19:08<16:01,  3.04it/s][2025-02-04 02:55:58][root][INFO] - Training Epoch: 2/2, step 20916/23838 completed (loss: 0.5620892643928528, acc: 0.761904776096344)
[2025-02-04 02:55:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20918/23838 [19:09<15:48,  3.08it/s][2025-02-04 02:55:58][root][INFO] - Training Epoch: 2/2, step 20917/23838 completed (loss: 0.26244691014289856, acc: 0.875)
[2025-02-04 02:55:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20919/23838 [19:09<16:53,  2.88it/s][2025-02-04 02:55:59][root][INFO] - Training Epoch: 2/2, step 20918/23838 completed (loss: 0.9546627402305603, acc: 0.5714285969734192)
[2025-02-04 02:55:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20920/23838 [19:09<16:40,  2.92it/s][2025-02-04 02:55:59][root][INFO] - Training Epoch: 2/2, step 20919/23838 completed (loss: 0.4224281907081604, acc: 0.8918918967247009)
[2025-02-04 02:55:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20921/23838 [19:10<16:43,  2.91it/s][2025-02-04 02:55:59][root][INFO] - Training Epoch: 2/2, step 20920/23838 completed (loss: 0.20605601370334625, acc: 0.9090909361839294)
[2025-02-04 02:55:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20922/23838 [19:10<16:07,  3.02it/s][2025-02-04 02:56:00][root][INFO] - Training Epoch: 2/2, step 20921/23838 completed (loss: 0.36373162269592285, acc: 0.8518518805503845)
[2025-02-04 02:56:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20923/23838 [19:10<15:49,  3.07it/s][2025-02-04 02:56:00][root][INFO] - Training Epoch: 2/2, step 20922/23838 completed (loss: 0.3085419833660126, acc: 0.90625)
[2025-02-04 02:56:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20924/23838 [19:11<17:15,  2.81it/s][2025-02-04 02:56:00][root][INFO] - Training Epoch: 2/2, step 20923/23838 completed (loss: 0.6214200258255005, acc: 0.8048780560493469)
[2025-02-04 02:56:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20925/23838 [19:11<17:24,  2.79it/s][2025-02-04 02:56:01][root][INFO] - Training Epoch: 2/2, step 20924/23838 completed (loss: 0.800409197807312, acc: 0.8139534592628479)
[2025-02-04 02:56:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20926/23838 [19:11<17:29,  2.77it/s][2025-02-04 02:56:01][root][INFO] - Training Epoch: 2/2, step 20925/23838 completed (loss: 0.7501530051231384, acc: 0.8085106611251831)
[2025-02-04 02:56:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20927/23838 [19:12<17:42,  2.74it/s][2025-02-04 02:56:01][root][INFO] - Training Epoch: 2/2, step 20926/23838 completed (loss: 0.702309250831604, acc: 0.7674418687820435)
[2025-02-04 02:56:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20928/23838 [19:12<17:40,  2.74it/s][2025-02-04 02:56:02][root][INFO] - Training Epoch: 2/2, step 20927/23838 completed (loss: 0.35620424151420593, acc: 0.9069767594337463)
[2025-02-04 02:56:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20929/23838 [19:13<17:19,  2.80it/s][2025-02-04 02:56:02][root][INFO] - Training Epoch: 2/2, step 20928/23838 completed (loss: 0.7079675793647766, acc: 0.8333333134651184)
[2025-02-04 02:56:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20930/23838 [19:13<17:45,  2.73it/s][2025-02-04 02:56:03][root][INFO] - Training Epoch: 2/2, step 20929/23838 completed (loss: 0.5227596759796143, acc: 0.8709677457809448)
[2025-02-04 02:56:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20931/23838 [19:13<17:43,  2.73it/s][2025-02-04 02:56:03][root][INFO] - Training Epoch: 2/2, step 20930/23838 completed (loss: 0.6905249953269958, acc: 0.7906976938247681)
[2025-02-04 02:56:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20932/23838 [19:14<19:12,  2.52it/s][2025-02-04 02:56:03][root][INFO] - Training Epoch: 2/2, step 20931/23838 completed (loss: 0.22485658526420593, acc: 0.9433962106704712)
[2025-02-04 02:56:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20933/23838 [19:14<17:58,  2.69it/s][2025-02-04 02:56:04][root][INFO] - Training Epoch: 2/2, step 20932/23838 completed (loss: 0.4644291400909424, acc: 0.875)
[2025-02-04 02:56:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20934/23838 [19:14<17:19,  2.79it/s][2025-02-04 02:56:04][root][INFO] - Training Epoch: 2/2, step 20933/23838 completed (loss: 0.6408844590187073, acc: 0.7560975551605225)
[2025-02-04 02:56:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20935/23838 [19:15<17:01,  2.84it/s][2025-02-04 02:56:04][root][INFO] - Training Epoch: 2/2, step 20934/23838 completed (loss: 0.5253694653511047, acc: 0.8333333134651184)
[2025-02-04 02:56:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20936/23838 [19:15<16:37,  2.91it/s][2025-02-04 02:56:05][root][INFO] - Training Epoch: 2/2, step 20935/23838 completed (loss: 0.3505115509033203, acc: 0.8518518805503845)
[2025-02-04 02:56:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20937/23838 [19:15<16:53,  2.86it/s][2025-02-04 02:56:05][root][INFO] - Training Epoch: 2/2, step 20936/23838 completed (loss: 0.2940160930156708, acc: 0.9259259104728699)
[2025-02-04 02:56:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20938/23838 [19:16<16:38,  2.90it/s][2025-02-04 02:56:05][root][INFO] - Training Epoch: 2/2, step 20937/23838 completed (loss: 0.3574545383453369, acc: 0.9200000166893005)
[2025-02-04 02:56:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20939/23838 [19:16<15:55,  3.03it/s][2025-02-04 02:56:06][root][INFO] - Training Epoch: 2/2, step 20938/23838 completed (loss: 0.20307640731334686, acc: 0.9534883499145508)
[2025-02-04 02:56:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20940/23838 [19:16<16:01,  3.01it/s][2025-02-04 02:56:06][root][INFO] - Training Epoch: 2/2, step 20939/23838 completed (loss: 0.3481018841266632, acc: 0.8571428656578064)
[2025-02-04 02:56:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20941/23838 [19:17<16:09,  2.99it/s][2025-02-04 02:56:06][root][INFO] - Training Epoch: 2/2, step 20940/23838 completed (loss: 0.7535169124603271, acc: 0.8387096524238586)
[2025-02-04 02:56:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20942/23838 [19:17<15:54,  3.04it/s][2025-02-04 02:56:07][root][INFO] - Training Epoch: 2/2, step 20941/23838 completed (loss: 0.9958469867706299, acc: 0.7799999713897705)
[2025-02-04 02:56:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20943/23838 [19:17<16:19,  2.96it/s][2025-02-04 02:56:07][root][INFO] - Training Epoch: 2/2, step 20942/23838 completed (loss: 0.8795201182365417, acc: 0.8421052694320679)
[2025-02-04 02:56:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20944/23838 [19:18<16:16,  2.96it/s][2025-02-04 02:56:07][root][INFO] - Training Epoch: 2/2, step 20943/23838 completed (loss: 0.03813228756189346, acc: 1.0)
[2025-02-04 02:56:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20945/23838 [19:18<16:57,  2.84it/s][2025-02-04 02:56:08][root][INFO] - Training Epoch: 2/2, step 20944/23838 completed (loss: 0.589290201663971, acc: 0.8913043737411499)
[2025-02-04 02:56:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20946/23838 [19:19<17:16,  2.79it/s][2025-02-04 02:56:08][root][INFO] - Training Epoch: 2/2, step 20945/23838 completed (loss: 0.867606520652771, acc: 0.7096773982048035)
[2025-02-04 02:56:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20947/23838 [19:19<16:31,  2.92it/s][2025-02-04 02:56:08][root][INFO] - Training Epoch: 2/2, step 20946/23838 completed (loss: 0.2464020997285843, acc: 0.8999999761581421)
[2025-02-04 02:56:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20948/23838 [19:19<17:43,  2.72it/s][2025-02-04 02:56:09][root][INFO] - Training Epoch: 2/2, step 20947/23838 completed (loss: 0.27361565828323364, acc: 0.949999988079071)
[2025-02-04 02:56:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20949/23838 [19:20<17:27,  2.76it/s][2025-02-04 02:56:09][root][INFO] - Training Epoch: 2/2, step 20948/23838 completed (loss: 0.492888480424881, acc: 0.8399999737739563)
[2025-02-04 02:56:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20950/23838 [19:20<16:54,  2.85it/s][2025-02-04 02:56:10][root][INFO] - Training Epoch: 2/2, step 20949/23838 completed (loss: 0.5941712260246277, acc: 0.8928571343421936)
[2025-02-04 02:56:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20951/23838 [19:20<16:27,  2.92it/s][2025-02-04 02:56:10][root][INFO] - Training Epoch: 2/2, step 20950/23838 completed (loss: 1.4590920209884644, acc: 0.5428571701049805)
[2025-02-04 02:56:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20952/23838 [19:21<17:53,  2.69it/s][2025-02-04 02:56:10][root][INFO] - Training Epoch: 2/2, step 20951/23838 completed (loss: 0.8831785917282104, acc: 0.774193525314331)
[2025-02-04 02:56:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20953/23838 [19:21<17:45,  2.71it/s][2025-02-04 02:56:11][root][INFO] - Training Epoch: 2/2, step 20952/23838 completed (loss: 0.6870138049125671, acc: 0.7272727489471436)
[2025-02-04 02:56:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20954/23838 [19:21<17:22,  2.77it/s][2025-02-04 02:56:11][root][INFO] - Training Epoch: 2/2, step 20953/23838 completed (loss: 0.3488452136516571, acc: 0.8823529481887817)
[2025-02-04 02:56:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20955/23838 [19:22<16:32,  2.90it/s][2025-02-04 02:56:11][root][INFO] - Training Epoch: 2/2, step 20954/23838 completed (loss: 0.20759591460227966, acc: 0.9677419066429138)
[2025-02-04 02:56:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20956/23838 [19:22<16:29,  2.91it/s][2025-02-04 02:56:12][root][INFO] - Training Epoch: 2/2, step 20955/23838 completed (loss: 0.09116820991039276, acc: 1.0)
[2025-02-04 02:56:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20957/23838 [19:22<16:46,  2.86it/s][2025-02-04 02:56:12][root][INFO] - Training Epoch: 2/2, step 20956/23838 completed (loss: 0.3547200560569763, acc: 0.8518518805503845)
[2025-02-04 02:56:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20958/23838 [19:23<16:43,  2.87it/s][2025-02-04 02:56:12][root][INFO] - Training Epoch: 2/2, step 20957/23838 completed (loss: 0.6591567993164062, acc: 0.7777777910232544)
[2025-02-04 02:56:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20959/23838 [19:23<16:53,  2.84it/s][2025-02-04 02:56:13][root][INFO] - Training Epoch: 2/2, step 20958/23838 completed (loss: 0.21732081472873688, acc: 0.9512194991111755)
[2025-02-04 02:56:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20960/23838 [19:23<16:49,  2.85it/s][2025-02-04 02:56:13][root][INFO] - Training Epoch: 2/2, step 20959/23838 completed (loss: 0.8190373778343201, acc: 0.75)
[2025-02-04 02:56:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20961/23838 [19:24<17:07,  2.80it/s][2025-02-04 02:56:13][root][INFO] - Training Epoch: 2/2, step 20960/23838 completed (loss: 0.975130558013916, acc: 0.6964285969734192)
[2025-02-04 02:56:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20962/23838 [19:24<17:00,  2.82it/s][2025-02-04 02:56:14][root][INFO] - Training Epoch: 2/2, step 20961/23838 completed (loss: 0.4604216516017914, acc: 0.9142857193946838)
[2025-02-04 02:56:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20963/23838 [19:25<17:23,  2.76it/s][2025-02-04 02:56:14][root][INFO] - Training Epoch: 2/2, step 20962/23838 completed (loss: 0.9677010774612427, acc: 0.75)
[2025-02-04 02:56:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20964/23838 [19:25<17:11,  2.79it/s][2025-02-04 02:56:15][root][INFO] - Training Epoch: 2/2, step 20963/23838 completed (loss: 0.24489769339561462, acc: 0.9375)
[2025-02-04 02:56:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20965/23838 [19:25<16:45,  2.86it/s][2025-02-04 02:56:15][root][INFO] - Training Epoch: 2/2, step 20964/23838 completed (loss: 0.5928075313568115, acc: 0.8305084705352783)
[2025-02-04 02:56:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20966/23838 [19:26<17:47,  2.69it/s][2025-02-04 02:56:15][root][INFO] - Training Epoch: 2/2, step 20965/23838 completed (loss: 0.2787720263004303, acc: 0.90625)
[2025-02-04 02:56:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20967/23838 [19:26<17:25,  2.75it/s][2025-02-04 02:56:16][root][INFO] - Training Epoch: 2/2, step 20966/23838 completed (loss: 0.06728363782167435, acc: 0.9841269850730896)
[2025-02-04 02:56:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20968/23838 [19:26<17:42,  2.70it/s][2025-02-04 02:56:16][root][INFO] - Training Epoch: 2/2, step 20967/23838 completed (loss: 0.3436158001422882, acc: 0.9017857313156128)
[2025-02-04 02:56:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20969/23838 [19:27<18:09,  2.63it/s][2025-02-04 02:56:16][root][INFO] - Training Epoch: 2/2, step 20968/23838 completed (loss: 0.7436676025390625, acc: 0.8089887499809265)
[2025-02-04 02:56:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20970/23838 [19:27<18:58,  2.52it/s][2025-02-04 02:56:17][root][INFO] - Training Epoch: 2/2, step 20969/23838 completed (loss: 0.41859427094459534, acc: 0.8510638475418091)
[2025-02-04 02:56:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20971/23838 [19:28<18:08,  2.64it/s][2025-02-04 02:56:17][root][INFO] - Training Epoch: 2/2, step 20970/23838 completed (loss: 0.21500547230243683, acc: 0.9300000071525574)
[2025-02-04 02:56:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20972/23838 [19:28<17:57,  2.66it/s][2025-02-04 02:56:18][root][INFO] - Training Epoch: 2/2, step 20971/23838 completed (loss: 0.18467451632022858, acc: 0.9230769276618958)
[2025-02-04 02:56:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20973/23838 [19:28<16:48,  2.84it/s][2025-02-04 02:56:18][root][INFO] - Training Epoch: 2/2, step 20972/23838 completed (loss: 0.15468290448188782, acc: 0.9322034120559692)
[2025-02-04 02:56:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20974/23838 [19:29<17:53,  2.67it/s][2025-02-04 02:56:18][root][INFO] - Training Epoch: 2/2, step 20973/23838 completed (loss: 0.16493292152881622, acc: 0.9905660152435303)
[2025-02-04 02:56:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20975/23838 [19:29<17:28,  2.73it/s][2025-02-04 02:56:19][root][INFO] - Training Epoch: 2/2, step 20974/23838 completed (loss: 0.1376536786556244, acc: 0.9677419066429138)
[2025-02-04 02:56:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20976/23838 [19:29<18:10,  2.62it/s][2025-02-04 02:56:19][root][INFO] - Training Epoch: 2/2, step 20975/23838 completed (loss: 0.20434589684009552, acc: 0.9264705777168274)
[2025-02-04 02:56:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20977/23838 [19:30<18:11,  2.62it/s][2025-02-04 02:56:19][root][INFO] - Training Epoch: 2/2, step 20976/23838 completed (loss: 0.0692182183265686, acc: 0.9850746393203735)
[2025-02-04 02:56:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20978/23838 [19:30<17:51,  2.67it/s][2025-02-04 02:56:20][root][INFO] - Training Epoch: 2/2, step 20977/23838 completed (loss: 0.14971056580543518, acc: 0.9647058844566345)
[2025-02-04 02:56:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20979/23838 [19:31<18:18,  2.60it/s][2025-02-04 02:56:20][root][INFO] - Training Epoch: 2/2, step 20978/23838 completed (loss: 0.2733156085014343, acc: 0.9277108311653137)
[2025-02-04 02:56:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20980/23838 [19:31<20:28,  2.33it/s][2025-02-04 02:56:21][root][INFO] - Training Epoch: 2/2, step 20979/23838 completed (loss: 0.3580246865749359, acc: 0.9137930870056152)
[2025-02-04 02:56:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20981/23838 [19:31<19:15,  2.47it/s][2025-02-04 02:56:21][root][INFO] - Training Epoch: 2/2, step 20980/23838 completed (loss: 0.27993232011795044, acc: 0.8999999761581421)
[2025-02-04 02:56:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20982/23838 [19:32<19:20,  2.46it/s][2025-02-04 02:56:21][root][INFO] - Training Epoch: 2/2, step 20981/23838 completed (loss: 0.8051393628120422, acc: 0.7611940503120422)
[2025-02-04 02:56:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20983/23838 [19:32<19:25,  2.45it/s][2025-02-04 02:56:22][root][INFO] - Training Epoch: 2/2, step 20982/23838 completed (loss: 1.1446782350540161, acc: 0.7179487347602844)
[2025-02-04 02:56:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20984/23838 [19:33<19:08,  2.48it/s][2025-02-04 02:56:22][root][INFO] - Training Epoch: 2/2, step 20983/23838 completed (loss: 0.38766777515411377, acc: 0.8974359035491943)
[2025-02-04 02:56:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20985/23838 [19:33<18:25,  2.58it/s][2025-02-04 02:56:23][root][INFO] - Training Epoch: 2/2, step 20984/23838 completed (loss: 0.16025272011756897, acc: 0.9433962106704712)
[2025-02-04 02:56:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20986/23838 [19:33<19:30,  2.44it/s][2025-02-04 02:56:23][root][INFO] - Training Epoch: 2/2, step 20985/23838 completed (loss: 0.2510972321033478, acc: 0.929411768913269)
[2025-02-04 02:56:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20987/23838 [19:34<20:04,  2.37it/s][2025-02-04 02:56:24][root][INFO] - Training Epoch: 2/2, step 20986/23838 completed (loss: 0.08973029255867004, acc: 0.9807692170143127)
[2025-02-04 02:56:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20988/23838 [19:34<19:05,  2.49it/s][2025-02-04 02:56:24][root][INFO] - Training Epoch: 2/2, step 20987/23838 completed (loss: 0.16241349279880524, acc: 0.9514563083648682)
[2025-02-04 02:56:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20989/23838 [19:35<18:05,  2.62it/s][2025-02-04 02:56:24][root][INFO] - Training Epoch: 2/2, step 20988/23838 completed (loss: 0.05848507955670357, acc: 0.9885057210922241)
[2025-02-04 02:56:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20990/23838 [19:35<17:13,  2.76it/s][2025-02-04 02:56:25][root][INFO] - Training Epoch: 2/2, step 20989/23838 completed (loss: 0.5971508622169495, acc: 0.8876404762268066)
[2025-02-04 02:56:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20991/23838 [19:35<17:20,  2.74it/s][2025-02-04 02:56:25][root][INFO] - Training Epoch: 2/2, step 20990/23838 completed (loss: 0.17056384682655334, acc: 0.96875)
[2025-02-04 02:56:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20992/23838 [19:36<18:36,  2.55it/s][2025-02-04 02:56:25][root][INFO] - Training Epoch: 2/2, step 20991/23838 completed (loss: 0.20316016674041748, acc: 0.9200000166893005)
[2025-02-04 02:56:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20993/23838 [19:36<18:29,  2.56it/s][2025-02-04 02:56:26][root][INFO] - Training Epoch: 2/2, step 20992/23838 completed (loss: 0.16155245900154114, acc: 0.9285714030265808)
[2025-02-04 02:56:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20994/23838 [19:37<18:07,  2.61it/s][2025-02-04 02:56:26][root][INFO] - Training Epoch: 2/2, step 20993/23838 completed (loss: 0.2425771951675415, acc: 0.9090909361839294)
[2025-02-04 02:56:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20995/23838 [19:37<18:11,  2.61it/s][2025-02-04 02:56:27][root][INFO] - Training Epoch: 2/2, step 20994/23838 completed (loss: 0.3801865577697754, acc: 0.9069767594337463)
[2025-02-04 02:56:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20996/23838 [19:37<17:44,  2.67it/s][2025-02-04 02:56:27][root][INFO] - Training Epoch: 2/2, step 20995/23838 completed (loss: 0.20721733570098877, acc: 0.9487179517745972)
[2025-02-04 02:56:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20997/23838 [19:38<17:53,  2.65it/s][2025-02-04 02:56:27][root][INFO] - Training Epoch: 2/2, step 20996/23838 completed (loss: 0.08438529074192047, acc: 0.9577465057373047)
[2025-02-04 02:56:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20998/23838 [19:38<17:44,  2.67it/s][2025-02-04 02:56:28][root][INFO] - Training Epoch: 2/2, step 20997/23838 completed (loss: 0.6876441836357117, acc: 0.7758620977401733)
[2025-02-04 02:56:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 20999/23838 [19:38<17:32,  2.70it/s][2025-02-04 02:56:28][root][INFO] - Training Epoch: 2/2, step 20998/23838 completed (loss: 0.48044881224632263, acc: 0.9090909361839294)
[2025-02-04 02:56:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21000/23838 [19:39<17:48,  2.66it/s][2025-02-04 02:56:28][root][INFO] - Training Epoch: 2/2, step 20999/23838 completed (loss: 0.6719813346862793, acc: 0.761904776096344)
[2025-02-04 02:56:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21001/23838 [19:39<17:01,  2.78it/s][2025-02-04 02:56:29][root][INFO] - Training Epoch: 2/2, step 21000/23838 completed (loss: 0.31969723105430603, acc: 0.8974359035491943)
[2025-02-04 02:56:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21002/23838 [19:39<16:56,  2.79it/s][2025-02-04 02:56:29][root][INFO] - Training Epoch: 2/2, step 21001/23838 completed (loss: 0.23589715361595154, acc: 0.9069767594337463)
[2025-02-04 02:56:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21003/23838 [19:40<18:27,  2.56it/s][2025-02-04 02:56:30][root][INFO] - Training Epoch: 2/2, step 21002/23838 completed (loss: 0.11576458811759949, acc: 0.9560439586639404)
[2025-02-04 02:56:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21004/23838 [19:40<18:35,  2.54it/s][2025-02-04 02:56:30][root][INFO] - Training Epoch: 2/2, step 21003/23838 completed (loss: 0.23248708248138428, acc: 0.8952381014823914)
[2025-02-04 02:56:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21005/23838 [19:41<19:11,  2.46it/s][2025-02-04 02:56:30][root][INFO] - Training Epoch: 2/2, step 21004/23838 completed (loss: 0.275389164686203, acc: 0.9354838728904724)
[2025-02-04 02:56:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21006/23838 [19:41<19:08,  2.47it/s][2025-02-04 02:56:31][root][INFO] - Training Epoch: 2/2, step 21005/23838 completed (loss: 0.2573730945587158, acc: 0.9285714030265808)
[2025-02-04 02:56:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21007/23838 [19:42<18:51,  2.50it/s][2025-02-04 02:56:31][root][INFO] - Training Epoch: 2/2, step 21006/23838 completed (loss: 0.337825745344162, acc: 0.9538461565971375)
[2025-02-04 02:56:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21008/23838 [19:42<18:14,  2.59it/s][2025-02-04 02:56:31][root][INFO] - Training Epoch: 2/2, step 21007/23838 completed (loss: 0.17166556417942047, acc: 0.9541284441947937)
[2025-02-04 02:56:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21009/23838 [19:42<17:39,  2.67it/s][2025-02-04 02:56:32][root][INFO] - Training Epoch: 2/2, step 21008/23838 completed (loss: 0.6150314211845398, acc: 0.8500000238418579)
[2025-02-04 02:56:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21010/23838 [19:43<17:17,  2.73it/s][2025-02-04 02:56:32][root][INFO] - Training Epoch: 2/2, step 21009/23838 completed (loss: 0.036759428679943085, acc: 1.0)
[2025-02-04 02:56:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21011/23838 [19:43<17:05,  2.76it/s][2025-02-04 02:56:33][root][INFO] - Training Epoch: 2/2, step 21010/23838 completed (loss: 0.36917105317115784, acc: 0.8793103694915771)
[2025-02-04 02:56:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21012/23838 [19:43<16:54,  2.79it/s][2025-02-04 02:56:33][root][INFO] - Training Epoch: 2/2, step 21011/23838 completed (loss: 0.05474955961108208, acc: 0.9811320900917053)
[2025-02-04 02:56:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21013/23838 [19:44<17:12,  2.74it/s][2025-02-04 02:56:33][root][INFO] - Training Epoch: 2/2, step 21012/23838 completed (loss: 0.13932934403419495, acc: 1.0)
[2025-02-04 02:56:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21014/23838 [19:44<16:41,  2.82it/s][2025-02-04 02:56:34][root][INFO] - Training Epoch: 2/2, step 21013/23838 completed (loss: 0.06508202850818634, acc: 0.9791666865348816)
[2025-02-04 02:56:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21015/23838 [19:44<16:53,  2.79it/s][2025-02-04 02:56:34][root][INFO] - Training Epoch: 2/2, step 21014/23838 completed (loss: 0.1143667921423912, acc: 0.9318181872367859)
[2025-02-04 02:56:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21016/23838 [19:45<16:37,  2.83it/s][2025-02-04 02:56:34][root][INFO] - Training Epoch: 2/2, step 21015/23838 completed (loss: 0.20472033321857452, acc: 0.9041095972061157)
[2025-02-04 02:56:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21017/23838 [19:45<15:56,  2.95it/s][2025-02-04 02:56:35][root][INFO] - Training Epoch: 2/2, step 21016/23838 completed (loss: 0.09315856546163559, acc: 0.9814814925193787)
[2025-02-04 02:56:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21018/23838 [19:45<15:38,  3.00it/s][2025-02-04 02:56:35][root][INFO] - Training Epoch: 2/2, step 21017/23838 completed (loss: 0.11037648469209671, acc: 0.9701492786407471)
[2025-02-04 02:56:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21019/23838 [19:46<15:12,  3.09it/s][2025-02-04 02:56:35][root][INFO] - Training Epoch: 2/2, step 21018/23838 completed (loss: 0.27112698554992676, acc: 0.9459459185600281)
[2025-02-04 02:56:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21020/23838 [19:46<15:01,  3.13it/s][2025-02-04 02:56:36][root][INFO] - Training Epoch: 2/2, step 21019/23838 completed (loss: 0.03769082948565483, acc: 1.0)
[2025-02-04 02:56:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21021/23838 [19:46<14:40,  3.20it/s][2025-02-04 02:56:36][root][INFO] - Training Epoch: 2/2, step 21020/23838 completed (loss: 0.19856566190719604, acc: 0.9610389471054077)
[2025-02-04 02:56:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21022/23838 [19:47<15:43,  2.98it/s][2025-02-04 02:56:36][root][INFO] - Training Epoch: 2/2, step 21021/23838 completed (loss: 0.27373531460762024, acc: 0.9236640930175781)
[2025-02-04 02:56:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21023/23838 [19:47<16:03,  2.92it/s][2025-02-04 02:56:37][root][INFO] - Training Epoch: 2/2, step 21022/23838 completed (loss: 0.14538255333900452, acc: 0.9399999976158142)
[2025-02-04 02:56:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21024/23838 [19:47<15:37,  3.00it/s][2025-02-04 02:56:37][root][INFO] - Training Epoch: 2/2, step 21023/23838 completed (loss: 0.8781216740608215, acc: 0.8333333134651184)
[2025-02-04 02:56:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21025/23838 [19:48<15:20,  3.05it/s][2025-02-04 02:56:37][root][INFO] - Training Epoch: 2/2, step 21024/23838 completed (loss: 0.2402019202709198, acc: 0.9380530714988708)
[2025-02-04 02:56:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21026/23838 [19:48<15:31,  3.02it/s][2025-02-04 02:56:38][root][INFO] - Training Epoch: 2/2, step 21025/23838 completed (loss: 0.1494372934103012, acc: 0.9736841917037964)
[2025-02-04 02:56:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21027/23838 [19:48<15:13,  3.08it/s][2025-02-04 02:56:38][root][INFO] - Training Epoch: 2/2, step 21026/23838 completed (loss: 0.03922097384929657, acc: 1.0)
[2025-02-04 02:56:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21028/23838 [19:49<16:19,  2.87it/s][2025-02-04 02:56:38][root][INFO] - Training Epoch: 2/2, step 21027/23838 completed (loss: 0.09826823323965073, acc: 0.9634146094322205)
[2025-02-04 02:56:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21029/23838 [19:49<16:48,  2.78it/s][2025-02-04 02:56:39][root][INFO] - Training Epoch: 2/2, step 21028/23838 completed (loss: 0.21252167224884033, acc: 0.9239130616188049)
[2025-02-04 02:56:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21030/23838 [19:49<17:35,  2.66it/s][2025-02-04 02:56:39][root][INFO] - Training Epoch: 2/2, step 21029/23838 completed (loss: 0.1431288719177246, acc: 0.9629629850387573)
[2025-02-04 02:56:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21031/23838 [19:50<17:19,  2.70it/s][2025-02-04 02:56:39][root][INFO] - Training Epoch: 2/2, step 21030/23838 completed (loss: 0.2458433210849762, acc: 0.9038461446762085)
[2025-02-04 02:56:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21032/23838 [19:50<16:49,  2.78it/s][2025-02-04 02:56:40][root][INFO] - Training Epoch: 2/2, step 21031/23838 completed (loss: 0.09006206691265106, acc: 0.9589040875434875)
[2025-02-04 02:56:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21033/23838 [19:51<16:29,  2.83it/s][2025-02-04 02:56:40][root][INFO] - Training Epoch: 2/2, step 21032/23838 completed (loss: 0.6400185227394104, acc: 0.7846153974533081)
[2025-02-04 02:56:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21034/23838 [19:51<16:05,  2.90it/s][2025-02-04 02:56:40][root][INFO] - Training Epoch: 2/2, step 21033/23838 completed (loss: 0.24651895463466644, acc: 0.932584285736084)
[2025-02-04 02:56:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21035/23838 [19:51<16:32,  2.82it/s][2025-02-04 02:56:41][root][INFO] - Training Epoch: 2/2, step 21034/23838 completed (loss: 0.11152902990579605, acc: 0.9629629850387573)
[2025-02-04 02:56:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21036/23838 [19:52<16:04,  2.90it/s][2025-02-04 02:56:41][root][INFO] - Training Epoch: 2/2, step 21035/23838 completed (loss: 0.02930196188390255, acc: 1.0)
[2025-02-04 02:56:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21037/23838 [19:52<15:39,  2.98it/s][2025-02-04 02:56:41][root][INFO] - Training Epoch: 2/2, step 21036/23838 completed (loss: 0.1837567389011383, acc: 0.9545454382896423)
[2025-02-04 02:56:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21038/23838 [19:52<15:33,  3.00it/s][2025-02-04 02:56:42][root][INFO] - Training Epoch: 2/2, step 21037/23838 completed (loss: 0.10889884829521179, acc: 0.9666666388511658)
[2025-02-04 02:56:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21039/23838 [19:52<15:19,  3.04it/s][2025-02-04 02:56:42][root][INFO] - Training Epoch: 2/2, step 21038/23838 completed (loss: 0.10285301506519318, acc: 0.9555555582046509)
[2025-02-04 02:56:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21040/23838 [19:53<15:16,  3.05it/s][2025-02-04 02:56:42][root][INFO] - Training Epoch: 2/2, step 21039/23838 completed (loss: 0.48166805505752563, acc: 0.8620689511299133)
[2025-02-04 02:56:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21041/23838 [19:53<16:03,  2.90it/s][2025-02-04 02:56:43][root][INFO] - Training Epoch: 2/2, step 21040/23838 completed (loss: 0.27968379855155945, acc: 0.925000011920929)
[2025-02-04 02:56:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21042/23838 [19:54<15:34,  2.99it/s][2025-02-04 02:56:43][root][INFO] - Training Epoch: 2/2, step 21041/23838 completed (loss: 0.7153274416923523, acc: 0.7575757503509521)
[2025-02-04 02:56:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21043/23838 [19:54<15:14,  3.06it/s][2025-02-04 02:56:43][root][INFO] - Training Epoch: 2/2, step 21042/23838 completed (loss: 0.3755050003528595, acc: 0.90625)
[2025-02-04 02:56:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21044/23838 [19:54<15:21,  3.03it/s][2025-02-04 02:56:44][root][INFO] - Training Epoch: 2/2, step 21043/23838 completed (loss: 0.9738490581512451, acc: 0.7096773982048035)
[2025-02-04 02:56:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21045/23838 [19:54<15:28,  3.01it/s][2025-02-04 02:56:44][root][INFO] - Training Epoch: 2/2, step 21044/23838 completed (loss: 0.4154934585094452, acc: 0.8627451062202454)
[2025-02-04 02:56:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21046/23838 [19:55<15:08,  3.07it/s][2025-02-04 02:56:44][root][INFO] - Training Epoch: 2/2, step 21045/23838 completed (loss: 0.7803085446357727, acc: 0.7906976938247681)
[2025-02-04 02:56:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21047/23838 [19:55<14:52,  3.13it/s][2025-02-04 02:56:45][root][INFO] - Training Epoch: 2/2, step 21046/23838 completed (loss: 0.04922887310385704, acc: 1.0)
[2025-02-04 02:56:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21048/23838 [19:55<15:03,  3.09it/s][2025-02-04 02:56:45][root][INFO] - Training Epoch: 2/2, step 21047/23838 completed (loss: 0.3901802599430084, acc: 0.8636363744735718)
[2025-02-04 02:56:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21049/23838 [19:56<15:17,  3.04it/s][2025-02-04 02:56:45][root][INFO] - Training Epoch: 2/2, step 21048/23838 completed (loss: 0.3095143139362335, acc: 0.8918918967247009)
[2025-02-04 02:56:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21050/23838 [19:56<14:59,  3.10it/s][2025-02-04 02:56:46][root][INFO] - Training Epoch: 2/2, step 21049/23838 completed (loss: 0.15347722172737122, acc: 1.0)
[2025-02-04 02:56:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21051/23838 [19:56<15:27,  3.00it/s][2025-02-04 02:56:46][root][INFO] - Training Epoch: 2/2, step 21050/23838 completed (loss: 0.5700349807739258, acc: 0.8636363744735718)
[2025-02-04 02:56:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21052/23838 [19:57<15:10,  3.06it/s][2025-02-04 02:56:46][root][INFO] - Training Epoch: 2/2, step 21051/23838 completed (loss: 0.6049707531929016, acc: 0.7884615659713745)
[2025-02-04 02:56:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21053/23838 [19:57<15:19,  3.03it/s][2025-02-04 02:56:47][root][INFO] - Training Epoch: 2/2, step 21052/23838 completed (loss: 0.4687604308128357, acc: 0.8461538553237915)
[2025-02-04 02:56:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21054/23838 [19:57<14:33,  3.19it/s][2025-02-04 02:56:47][root][INFO] - Training Epoch: 2/2, step 21053/23838 completed (loss: 0.17737780511379242, acc: 0.9484536051750183)
[2025-02-04 02:56:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21055/23838 [19:58<15:00,  3.09it/s][2025-02-04 02:56:47][root][INFO] - Training Epoch: 2/2, step 21054/23838 completed (loss: 0.34890294075012207, acc: 0.8850574493408203)
[2025-02-04 02:56:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21056/23838 [19:58<15:20,  3.02it/s][2025-02-04 02:56:48][root][INFO] - Training Epoch: 2/2, step 21055/23838 completed (loss: 0.41396257281303406, acc: 0.8787878751754761)
[2025-02-04 02:56:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21057/23838 [19:58<16:04,  2.88it/s][2025-02-04 02:56:48][root][INFO] - Training Epoch: 2/2, step 21056/23838 completed (loss: 0.276611328125, acc: 0.9523809552192688)
[2025-02-04 02:56:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21058/23838 [19:59<16:29,  2.81it/s][2025-02-04 02:56:48][root][INFO] - Training Epoch: 2/2, step 21057/23838 completed (loss: 0.17969772219657898, acc: 0.9512194991111755)
[2025-02-04 02:56:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21059/23838 [19:59<16:45,  2.76it/s][2025-02-04 02:56:49][root][INFO] - Training Epoch: 2/2, step 21058/23838 completed (loss: 0.43949541449546814, acc: 0.8387096524238586)
[2025-02-04 02:56:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21060/23838 [20:00<16:08,  2.87it/s][2025-02-04 02:56:49][root][INFO] - Training Epoch: 2/2, step 21059/23838 completed (loss: 0.11322099715471268, acc: 0.9571428298950195)
[2025-02-04 02:56:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21061/23838 [20:00<16:02,  2.89it/s][2025-02-04 02:56:49][root][INFO] - Training Epoch: 2/2, step 21060/23838 completed (loss: 0.09592828899621964, acc: 0.9740259647369385)
[2025-02-04 02:56:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21062/23838 [20:00<16:08,  2.87it/s][2025-02-04 02:56:50][root][INFO] - Training Epoch: 2/2, step 21061/23838 completed (loss: 0.2130248248577118, acc: 0.932692289352417)
[2025-02-04 02:56:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21063/23838 [20:01<16:21,  2.83it/s][2025-02-04 02:56:50][root][INFO] - Training Epoch: 2/2, step 21062/23838 completed (loss: 0.6117833852767944, acc: 0.8550724387168884)
[2025-02-04 02:56:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21064/23838 [20:01<16:43,  2.76it/s][2025-02-04 02:56:51][root][INFO] - Training Epoch: 2/2, step 21063/23838 completed (loss: 0.7135512828826904, acc: 0.8723404407501221)
[2025-02-04 02:56:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21065/23838 [20:01<16:58,  2.72it/s][2025-02-04 02:56:51][root][INFO] - Training Epoch: 2/2, step 21064/23838 completed (loss: 0.16172869503498077, acc: 0.931034505367279)
[2025-02-04 02:56:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21066/23838 [20:02<16:48,  2.75it/s][2025-02-04 02:56:51][root][INFO] - Training Epoch: 2/2, step 21065/23838 completed (loss: 0.21532563865184784, acc: 0.9272727370262146)
[2025-02-04 02:56:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21067/23838 [20:02<16:02,  2.88it/s][2025-02-04 02:56:52][root][INFO] - Training Epoch: 2/2, step 21066/23838 completed (loss: 0.4736374020576477, acc: 0.9090909361839294)
[2025-02-04 02:56:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21068/23838 [20:02<15:47,  2.92it/s][2025-02-04 02:56:52][root][INFO] - Training Epoch: 2/2, step 21067/23838 completed (loss: 0.1774226278066635, acc: 0.9555555582046509)
[2025-02-04 02:56:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21069/23838 [20:03<15:54,  2.90it/s][2025-02-04 02:56:52][root][INFO] - Training Epoch: 2/2, step 21068/23838 completed (loss: 0.22541046142578125, acc: 0.8958333134651184)
[2025-02-04 02:56:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21070/23838 [20:03<15:48,  2.92it/s][2025-02-04 02:56:53][root][INFO] - Training Epoch: 2/2, step 21069/23838 completed (loss: 0.0454564094543457, acc: 0.9833333492279053)
[2025-02-04 02:56:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21071/23838 [20:03<15:54,  2.90it/s][2025-02-04 02:56:53][root][INFO] - Training Epoch: 2/2, step 21070/23838 completed (loss: 0.22999362647533417, acc: 0.9428571462631226)
[2025-02-04 02:56:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21072/23838 [20:04<17:11,  2.68it/s][2025-02-04 02:56:53][root][INFO] - Training Epoch: 2/2, step 21071/23838 completed (loss: 0.1507231891155243, acc: 0.9663865566253662)
[2025-02-04 02:56:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21073/23838 [20:04<16:56,  2.72it/s][2025-02-04 02:56:54][root][INFO] - Training Epoch: 2/2, step 21072/23838 completed (loss: 0.5029522776603699, acc: 0.84375)
[2025-02-04 02:56:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21074/23838 [20:05<17:18,  2.66it/s][2025-02-04 02:56:54][root][INFO] - Training Epoch: 2/2, step 21073/23838 completed (loss: 0.41190803050994873, acc: 0.800000011920929)
[2025-02-04 02:56:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21075/23838 [20:05<18:07,  2.54it/s][2025-02-04 02:56:55][root][INFO] - Training Epoch: 2/2, step 21074/23838 completed (loss: 0.2548917829990387, acc: 0.8947368264198303)
[2025-02-04 02:56:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21076/23838 [20:05<18:36,  2.47it/s][2025-02-04 02:56:55][root][INFO] - Training Epoch: 2/2, step 21075/23838 completed (loss: 0.27033743262290955, acc: 0.9350649118423462)
[2025-02-04 02:56:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21077/23838 [20:06<18:22,  2.50it/s][2025-02-04 02:56:55][root][INFO] - Training Epoch: 2/2, step 21076/23838 completed (loss: 0.34785032272338867, acc: 0.9135802388191223)
[2025-02-04 02:56:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21078/23838 [20:06<17:45,  2.59it/s][2025-02-04 02:56:56][root][INFO] - Training Epoch: 2/2, step 21077/23838 completed (loss: 0.2706623375415802, acc: 0.9159663915634155)
[2025-02-04 02:56:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21079/23838 [20:07<16:58,  2.71it/s][2025-02-04 02:56:56][root][INFO] - Training Epoch: 2/2, step 21078/23838 completed (loss: 0.3550955653190613, acc: 0.8888888955116272)
[2025-02-04 02:56:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21080/23838 [20:07<16:15,  2.83it/s][2025-02-04 02:56:56][root][INFO] - Training Epoch: 2/2, step 21079/23838 completed (loss: 0.2092134952545166, acc: 0.9550561904907227)
[2025-02-04 02:56:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21081/23838 [20:07<15:47,  2.91it/s][2025-02-04 02:56:57][root][INFO] - Training Epoch: 2/2, step 21080/23838 completed (loss: 0.32982829213142395, acc: 0.8989899158477783)
[2025-02-04 02:56:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21082/23838 [20:07<15:09,  3.03it/s][2025-02-04 02:56:57][root][INFO] - Training Epoch: 2/2, step 21081/23838 completed (loss: 0.044833917170763016, acc: 0.9753086566925049)
[2025-02-04 02:56:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21083/23838 [20:08<15:21,  2.99it/s][2025-02-04 02:56:57][root][INFO] - Training Epoch: 2/2, step 21082/23838 completed (loss: 0.4096554219722748, acc: 0.8870967626571655)
[2025-02-04 02:56:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21084/23838 [20:08<15:23,  2.98it/s][2025-02-04 02:56:58][root][INFO] - Training Epoch: 2/2, step 21083/23838 completed (loss: 0.2817082107067108, acc: 0.9186046719551086)
[2025-02-04 02:56:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21085/23838 [20:08<15:25,  2.98it/s][2025-02-04 02:56:58][root][INFO] - Training Epoch: 2/2, step 21084/23838 completed (loss: 0.47756487131118774, acc: 0.8823529481887817)
[2025-02-04 02:56:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21086/23838 [20:09<15:31,  2.95it/s][2025-02-04 02:56:58][root][INFO] - Training Epoch: 2/2, step 21085/23838 completed (loss: 0.30613866448402405, acc: 0.9156626462936401)
[2025-02-04 02:56:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21087/23838 [20:09<15:31,  2.95it/s][2025-02-04 02:56:59][root][INFO] - Training Epoch: 2/2, step 21086/23838 completed (loss: 0.6368987560272217, acc: 0.78125)
[2025-02-04 02:56:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21088/23838 [20:09<15:38,  2.93it/s][2025-02-04 02:56:59][root][INFO] - Training Epoch: 2/2, step 21087/23838 completed (loss: 0.3378601372241974, acc: 0.9111111164093018)
[2025-02-04 02:56:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21089/23838 [20:10<15:25,  2.97it/s][2025-02-04 02:56:59][root][INFO] - Training Epoch: 2/2, step 21088/23838 completed (loss: 0.1888340711593628, acc: 0.929411768913269)
[2025-02-04 02:57:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21090/23838 [20:10<16:13,  2.82it/s][2025-02-04 02:57:00][root][INFO] - Training Epoch: 2/2, step 21089/23838 completed (loss: 0.36274686455726624, acc: 0.8676470518112183)
[2025-02-04 02:57:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21091/23838 [20:11<15:44,  2.91it/s][2025-02-04 02:57:00][root][INFO] - Training Epoch: 2/2, step 21090/23838 completed (loss: 0.32496750354766846, acc: 0.90625)
[2025-02-04 02:57:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21092/23838 [20:11<15:17,  2.99it/s][2025-02-04 02:57:00][root][INFO] - Training Epoch: 2/2, step 21091/23838 completed (loss: 0.0885297954082489, acc: 0.9428571462631226)
[2025-02-04 02:57:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21093/23838 [20:11<14:56,  3.06it/s][2025-02-04 02:57:01][root][INFO] - Training Epoch: 2/2, step 21092/23838 completed (loss: 0.23356418311595917, acc: 0.9295774698257446)
[2025-02-04 02:57:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21094/23838 [20:11<14:43,  3.10it/s][2025-02-04 02:57:01][root][INFO] - Training Epoch: 2/2, step 21093/23838 completed (loss: 0.2738783359527588, acc: 0.9354838728904724)
[2025-02-04 02:57:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21095/23838 [20:12<14:41,  3.11it/s][2025-02-04 02:57:01][root][INFO] - Training Epoch: 2/2, step 21094/23838 completed (loss: 0.6312776803970337, acc: 0.800000011920929)
[2025-02-04 02:57:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  88%|[34m████████▊ [0m| 21096/23838 [20:12<15:07,  3.02it/s][2025-02-04 02:57:02][root][INFO] - Training Epoch: 2/2, step 21095/23838 completed (loss: 0.8461028933525085, acc: 0.7333333492279053)
[2025-02-04 02:57:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21097/23838 [20:13<15:33,  2.94it/s][2025-02-04 02:57:02][root][INFO] - Training Epoch: 2/2, step 21096/23838 completed (loss: 0.831491231918335, acc: 0.7692307829856873)
[2025-02-04 02:57:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21098/23838 [20:13<15:50,  2.88it/s][2025-02-04 02:57:02][root][INFO] - Training Epoch: 2/2, step 21097/23838 completed (loss: 0.42435938119888306, acc: 0.8888888955116272)
[2025-02-04 02:57:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21099/23838 [20:13<16:02,  2.85it/s][2025-02-04 02:57:03][root][INFO] - Training Epoch: 2/2, step 21098/23838 completed (loss: 0.3562665283679962, acc: 0.8846153616905212)
[2025-02-04 02:57:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21100/23838 [20:14<16:08,  2.83it/s][2025-02-04 02:57:03][root][INFO] - Training Epoch: 2/2, step 21099/23838 completed (loss: 1.009110927581787, acc: 0.75)
[2025-02-04 02:57:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21101/23838 [20:14<16:40,  2.74it/s][2025-02-04 02:57:04][root][INFO] - Training Epoch: 2/2, step 21100/23838 completed (loss: 0.4723376929759979, acc: 0.939393937587738)
[2025-02-04 02:57:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21102/23838 [20:14<17:02,  2.67it/s][2025-02-04 02:57:04][root][INFO] - Training Epoch: 2/2, step 21101/23838 completed (loss: 0.48560336232185364, acc: 0.8999999761581421)
[2025-02-04 02:57:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21103/23838 [20:15<16:34,  2.75it/s][2025-02-04 02:57:04][root][INFO] - Training Epoch: 2/2, step 21102/23838 completed (loss: 0.6367493271827698, acc: 0.84375)
[2025-02-04 02:57:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21104/23838 [20:15<16:15,  2.80it/s][2025-02-04 02:57:05][root][INFO] - Training Epoch: 2/2, step 21103/23838 completed (loss: 0.39766156673431396, acc: 0.8809523582458496)
[2025-02-04 02:57:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21105/23838 [20:15<16:50,  2.71it/s][2025-02-04 02:57:05][root][INFO] - Training Epoch: 2/2, step 21104/23838 completed (loss: 0.4902329444885254, acc: 0.9090909361839294)
[2025-02-04 02:57:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21106/23838 [20:16<17:13,  2.64it/s][2025-02-04 02:57:05][root][INFO] - Training Epoch: 2/2, step 21105/23838 completed (loss: 0.5554519295692444, acc: 0.8222222328186035)
[2025-02-04 02:57:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21107/23838 [20:16<19:01,  2.39it/s][2025-02-04 02:57:06][root][INFO] - Training Epoch: 2/2, step 21106/23838 completed (loss: 0.39548805356025696, acc: 0.8461538553237915)
[2025-02-04 02:57:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21108/23838 [20:17<18:02,  2.52it/s][2025-02-04 02:57:06][root][INFO] - Training Epoch: 2/2, step 21107/23838 completed (loss: 0.5034570097923279, acc: 0.8999999761581421)
[2025-02-04 02:57:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21109/23838 [20:17<17:27,  2.61it/s][2025-02-04 02:57:07][root][INFO] - Training Epoch: 2/2, step 21108/23838 completed (loss: 0.6090185046195984, acc: 0.7894737124443054)
[2025-02-04 02:57:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21110/23838 [20:17<17:11,  2.65it/s][2025-02-04 02:57:07][root][INFO] - Training Epoch: 2/2, step 21109/23838 completed (loss: 0.283565491437912, acc: 0.8666666746139526)
[2025-02-04 02:57:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21111/23838 [20:18<16:32,  2.75it/s][2025-02-04 02:57:07][root][INFO] - Training Epoch: 2/2, step 21110/23838 completed (loss: 0.31888383626937866, acc: 0.8857142925262451)
[2025-02-04 02:57:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21112/23838 [20:18<15:13,  2.98it/s][2025-02-04 02:57:08][root][INFO] - Training Epoch: 2/2, step 21111/23838 completed (loss: 0.6975962519645691, acc: 0.8360655903816223)
[2025-02-04 02:57:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21113/23838 [20:18<14:53,  3.05it/s][2025-02-04 02:57:08][root][INFO] - Training Epoch: 2/2, step 21112/23838 completed (loss: 0.10852765291929245, acc: 0.9791666865348816)
[2025-02-04 02:57:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21114/23838 [20:19<15:24,  2.94it/s][2025-02-04 02:57:08][root][INFO] - Training Epoch: 2/2, step 21113/23838 completed (loss: 0.4573739469051361, acc: 0.8947368264198303)
[2025-02-04 02:57:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21115/23838 [20:19<15:10,  2.99it/s][2025-02-04 02:57:09][root][INFO] - Training Epoch: 2/2, step 21114/23838 completed (loss: 0.8690381050109863, acc: 0.7916666865348816)
[2025-02-04 02:57:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21116/23838 [20:19<14:41,  3.09it/s][2025-02-04 02:57:09][root][INFO] - Training Epoch: 2/2, step 21115/23838 completed (loss: 0.5956252217292786, acc: 0.8253968358039856)
[2025-02-04 02:57:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21117/23838 [20:20<14:44,  3.08it/s][2025-02-04 02:57:09][root][INFO] - Training Epoch: 2/2, step 21116/23838 completed (loss: 0.5857343077659607, acc: 0.8333333134651184)
[2025-02-04 02:57:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21118/23838 [20:20<14:43,  3.08it/s][2025-02-04 02:57:10][root][INFO] - Training Epoch: 2/2, step 21117/23838 completed (loss: 0.5272426009178162, acc: 0.8636363744735718)
[2025-02-04 02:57:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21119/23838 [20:20<14:31,  3.12it/s][2025-02-04 02:57:10][root][INFO] - Training Epoch: 2/2, step 21118/23838 completed (loss: 0.404984712600708, acc: 0.8888888955116272)
[2025-02-04 02:57:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21120/23838 [20:21<14:25,  3.14it/s][2025-02-04 02:57:10][root][INFO] - Training Epoch: 2/2, step 21119/23838 completed (loss: 0.5041681528091431, acc: 0.8939393758773804)
[2025-02-04 02:57:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21121/23838 [20:21<14:29,  3.12it/s][2025-02-04 02:57:11][root][INFO] - Training Epoch: 2/2, step 21120/23838 completed (loss: 0.16009007394313812, acc: 0.95652174949646)
[2025-02-04 02:57:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21122/23838 [20:21<14:21,  3.15it/s][2025-02-04 02:57:11][root][INFO] - Training Epoch: 2/2, step 21121/23838 completed (loss: 1.046553373336792, acc: 0.698113203048706)
[2025-02-04 02:57:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21123/23838 [20:22<13:57,  3.24it/s][2025-02-04 02:57:11][root][INFO] - Training Epoch: 2/2, step 21122/23838 completed (loss: 0.5526472330093384, acc: 0.8541666865348816)
[2025-02-04 02:57:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21124/23838 [20:22<14:29,  3.12it/s][2025-02-04 02:57:11][root][INFO] - Training Epoch: 2/2, step 21123/23838 completed (loss: 0.478482723236084, acc: 0.8402777910232544)
[2025-02-04 02:57:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21125/23838 [20:22<14:21,  3.15it/s][2025-02-04 02:57:12][root][INFO] - Training Epoch: 2/2, step 21124/23838 completed (loss: 0.5968570113182068, acc: 0.8292682766914368)
[2025-02-04 02:57:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21126/23838 [20:23<15:58,  2.83it/s][2025-02-04 02:57:12][root][INFO] - Training Epoch: 2/2, step 21125/23838 completed (loss: 0.7471186518669128, acc: 0.7755101919174194)
[2025-02-04 02:57:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21127/23838 [20:23<16:31,  2.73it/s][2025-02-04 02:57:13][root][INFO] - Training Epoch: 2/2, step 21126/23838 completed (loss: 0.4234815835952759, acc: 0.8888888955116272)
[2025-02-04 02:57:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21128/23838 [20:23<16:20,  2.76it/s][2025-02-04 02:57:13][root][INFO] - Training Epoch: 2/2, step 21127/23838 completed (loss: 1.3601305484771729, acc: 0.6382978558540344)
[2025-02-04 02:57:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21129/23838 [20:24<16:50,  2.68it/s][2025-02-04 02:57:13][root][INFO] - Training Epoch: 2/2, step 21128/23838 completed (loss: 0.8819581866264343, acc: 0.7659574747085571)
[2025-02-04 02:57:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21130/23838 [20:24<16:34,  2.72it/s][2025-02-04 02:57:14][root][INFO] - Training Epoch: 2/2, step 21129/23838 completed (loss: 0.5368953347206116, acc: 0.8333333134651184)
[2025-02-04 02:57:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21131/23838 [20:25<17:19,  2.60it/s][2025-02-04 02:57:14][root][INFO] - Training Epoch: 2/2, step 21130/23838 completed (loss: 0.4436579942703247, acc: 0.8833333253860474)
[2025-02-04 02:57:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21132/23838 [20:25<17:37,  2.56it/s][2025-02-04 02:57:15][root][INFO] - Training Epoch: 2/2, step 21131/23838 completed (loss: 0.5769711136817932, acc: 0.824999988079071)
[2025-02-04 02:57:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21133/23838 [20:25<17:11,  2.62it/s][2025-02-04 02:57:15][root][INFO] - Training Epoch: 2/2, step 21132/23838 completed (loss: 0.2171146273612976, acc: 0.9459459185600281)
[2025-02-04 02:57:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21134/23838 [20:26<16:04,  2.80it/s][2025-02-04 02:57:15][root][INFO] - Training Epoch: 2/2, step 21133/23838 completed (loss: 0.31457000970840454, acc: 0.875)
[2025-02-04 02:57:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21135/23838 [20:26<16:21,  2.75it/s][2025-02-04 02:57:16][root][INFO] - Training Epoch: 2/2, step 21134/23838 completed (loss: 0.31251633167266846, acc: 0.8924731016159058)
[2025-02-04 02:57:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21136/23838 [20:26<17:19,  2.60it/s][2025-02-04 02:57:16][root][INFO] - Training Epoch: 2/2, step 21135/23838 completed (loss: 0.5853970050811768, acc: 0.807692289352417)
[2025-02-04 02:57:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21137/23838 [20:27<17:21,  2.59it/s][2025-02-04 02:57:16][root][INFO] - Training Epoch: 2/2, step 21136/23838 completed (loss: 1.1625229120254517, acc: 0.653333306312561)
[2025-02-04 02:57:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21138/23838 [20:27<16:48,  2.68it/s][2025-02-04 02:57:17][root][INFO] - Training Epoch: 2/2, step 21137/23838 completed (loss: 0.5968626737594604, acc: 0.8518518805503845)
[2025-02-04 02:57:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21139/23838 [20:27<16:24,  2.74it/s][2025-02-04 02:57:17][root][INFO] - Training Epoch: 2/2, step 21138/23838 completed (loss: 1.0128339529037476, acc: 0.7222222089767456)
[2025-02-04 02:57:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21140/23838 [20:28<16:04,  2.80it/s][2025-02-04 02:57:17][root][INFO] - Training Epoch: 2/2, step 21139/23838 completed (loss: 0.7490536570549011, acc: 0.7857142686843872)
[2025-02-04 02:57:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21141/23838 [20:28<15:48,  2.84it/s][2025-02-04 02:57:18][root][INFO] - Training Epoch: 2/2, step 21140/23838 completed (loss: 0.5381873846054077, acc: 0.8181818127632141)
[2025-02-04 02:57:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21142/23838 [20:29<15:35,  2.88it/s][2025-02-04 02:57:18][root][INFO] - Training Epoch: 2/2, step 21141/23838 completed (loss: 0.6403120756149292, acc: 0.8032786846160889)
[2025-02-04 02:57:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21143/23838 [20:29<15:30,  2.90it/s][2025-02-04 02:57:18][root][INFO] - Training Epoch: 2/2, step 21142/23838 completed (loss: 0.7020376920700073, acc: 0.8730158805847168)
[2025-02-04 02:57:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21144/23838 [20:29<15:22,  2.92it/s][2025-02-04 02:57:19][root][INFO] - Training Epoch: 2/2, step 21143/23838 completed (loss: 0.2174064666032791, acc: 0.9629629850387573)
[2025-02-04 02:57:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21145/23838 [20:30<17:25,  2.58it/s][2025-02-04 02:57:19][root][INFO] - Training Epoch: 2/2, step 21144/23838 completed (loss: 0.5454473495483398, acc: 0.8695651888847351)
[2025-02-04 02:57:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21146/23838 [20:30<17:15,  2.60it/s][2025-02-04 02:57:20][root][INFO] - Training Epoch: 2/2, step 21145/23838 completed (loss: 0.8281072974205017, acc: 0.7352941036224365)
[2025-02-04 02:57:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21147/23838 [20:31<18:20,  2.44it/s][2025-02-04 02:57:20][root][INFO] - Training Epoch: 2/2, step 21146/23838 completed (loss: 0.6193477511405945, acc: 0.7882353067398071)
[2025-02-04 02:57:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21148/23838 [20:31<18:36,  2.41it/s][2025-02-04 02:57:21][root][INFO] - Training Epoch: 2/2, step 21147/23838 completed (loss: 0.4936937987804413, acc: 0.8666666746139526)
[2025-02-04 02:57:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21149/23838 [20:31<19:23,  2.31it/s][2025-02-04 02:57:21][root][INFO] - Training Epoch: 2/2, step 21148/23838 completed (loss: 0.42505303025245667, acc: 0.9142857193946838)
[2025-02-04 02:57:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21150/23838 [20:32<19:11,  2.34it/s][2025-02-04 02:57:21][root][INFO] - Training Epoch: 2/2, step 21149/23838 completed (loss: 0.546955406665802, acc: 0.8793103694915771)
[2025-02-04 02:57:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21151/23838 [20:32<18:51,  2.37it/s][2025-02-04 02:57:22][root][INFO] - Training Epoch: 2/2, step 21150/23838 completed (loss: 0.6002822518348694, acc: 0.8524590134620667)
[2025-02-04 02:57:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21152/23838 [20:33<18:26,  2.43it/s][2025-02-04 02:57:22][root][INFO] - Training Epoch: 2/2, step 21151/23838 completed (loss: 0.6234862804412842, acc: 0.7755101919174194)
[2025-02-04 02:57:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21153/23838 [20:33<18:04,  2.48it/s][2025-02-04 02:57:23][root][INFO] - Training Epoch: 2/2, step 21152/23838 completed (loss: 0.7257723808288574, acc: 0.8125)
[2025-02-04 02:57:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21154/23838 [20:33<18:43,  2.39it/s][2025-02-04 02:57:23][root][INFO] - Training Epoch: 2/2, step 21153/23838 completed (loss: 0.6024494171142578, acc: 0.8561643958091736)
[2025-02-04 02:57:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21155/23838 [20:34<18:31,  2.41it/s][2025-02-04 02:57:23][root][INFO] - Training Epoch: 2/2, step 21154/23838 completed (loss: 0.4721197783946991, acc: 0.9047619104385376)
[2025-02-04 02:57:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▊ [0m| 21156/23838 [20:34<17:31,  2.55it/s][2025-02-04 02:57:24][root][INFO] - Training Epoch: 2/2, step 21155/23838 completed (loss: 0.5898972153663635, acc: 0.7666666507720947)
[2025-02-04 02:57:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21157/23838 [20:35<17:19,  2.58it/s][2025-02-04 02:57:24][root][INFO] - Training Epoch: 2/2, step 21156/23838 completed (loss: 0.36608344316482544, acc: 0.9245283007621765)
[2025-02-04 02:57:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21158/23838 [20:35<16:41,  2.68it/s][2025-02-04 02:57:25][root][INFO] - Training Epoch: 2/2, step 21157/23838 completed (loss: 0.683744490146637, acc: 0.7966101765632629)
[2025-02-04 02:57:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21159/23838 [20:35<16:35,  2.69it/s][2025-02-04 02:57:25][root][INFO] - Training Epoch: 2/2, step 21158/23838 completed (loss: 0.45927295088768005, acc: 0.875)
[2025-02-04 02:57:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21160/23838 [20:36<16:10,  2.76it/s][2025-02-04 02:57:25][root][INFO] - Training Epoch: 2/2, step 21159/23838 completed (loss: 0.7456735372543335, acc: 0.8082191944122314)
[2025-02-04 02:57:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21161/23838 [20:36<16:02,  2.78it/s][2025-02-04 02:57:26][root][INFO] - Training Epoch: 2/2, step 21160/23838 completed (loss: 0.4953688383102417, acc: 0.774193525314331)
[2025-02-04 02:57:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21162/23838 [20:36<16:15,  2.74it/s][2025-02-04 02:57:26][root][INFO] - Training Epoch: 2/2, step 21161/23838 completed (loss: 0.5930363535881042, acc: 0.828125)
[2025-02-04 02:57:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21163/23838 [20:37<16:48,  2.65it/s][2025-02-04 02:57:26][root][INFO] - Training Epoch: 2/2, step 21162/23838 completed (loss: 0.4397975504398346, acc: 0.8488371968269348)
[2025-02-04 02:57:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21164/23838 [20:37<16:18,  2.73it/s][2025-02-04 02:57:27][root][INFO] - Training Epoch: 2/2, step 21163/23838 completed (loss: 0.6328459978103638, acc: 0.7710843086242676)
[2025-02-04 02:57:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21165/23838 [20:38<16:26,  2.71it/s][2025-02-04 02:57:27][root][INFO] - Training Epoch: 2/2, step 21164/23838 completed (loss: 0.9227121472358704, acc: 0.7448979616165161)
[2025-02-04 02:57:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21166/23838 [20:38<16:31,  2.70it/s][2025-02-04 02:57:27][root][INFO] - Training Epoch: 2/2, step 21165/23838 completed (loss: 0.4088592231273651, acc: 0.9056603908538818)
[2025-02-04 02:57:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21167/23838 [20:38<16:58,  2.62it/s][2025-02-04 02:57:28][root][INFO] - Training Epoch: 2/2, step 21166/23838 completed (loss: 0.17046530544757843, acc: 0.9452054500579834)
[2025-02-04 02:57:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21168/23838 [20:39<16:03,  2.77it/s][2025-02-04 02:57:28][root][INFO] - Training Epoch: 2/2, step 21167/23838 completed (loss: 0.15112240612506866, acc: 0.9777777791023254)
[2025-02-04 02:57:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21169/23838 [20:39<17:27,  2.55it/s][2025-02-04 02:57:29][root][INFO] - Training Epoch: 2/2, step 21168/23838 completed (loss: 0.22430814802646637, acc: 0.9285714030265808)
[2025-02-04 02:57:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21170/23838 [20:39<16:55,  2.63it/s][2025-02-04 02:57:29][root][INFO] - Training Epoch: 2/2, step 21169/23838 completed (loss: 1.114660620689392, acc: 0.6800000071525574)
[2025-02-04 02:57:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21171/23838 [20:40<16:11,  2.74it/s][2025-02-04 02:57:29][root][INFO] - Training Epoch: 2/2, step 21170/23838 completed (loss: 0.2352885603904724, acc: 0.9347826242446899)
[2025-02-04 02:57:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21172/23838 [20:40<18:32,  2.40it/s][2025-02-04 02:57:30][root][INFO] - Training Epoch: 2/2, step 21171/23838 completed (loss: 0.5202009677886963, acc: 0.8507462739944458)
[2025-02-04 02:57:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21173/23838 [20:41<17:07,  2.59it/s][2025-02-04 02:57:30][root][INFO] - Training Epoch: 2/2, step 21172/23838 completed (loss: 0.15448051691055298, acc: 0.9411764740943909)
[2025-02-04 02:57:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21174/23838 [20:41<16:40,  2.66it/s][2025-02-04 02:57:31][root][INFO] - Training Epoch: 2/2, step 21173/23838 completed (loss: 0.6112840175628662, acc: 0.8275862336158752)
[2025-02-04 02:57:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21175/23838 [20:41<15:35,  2.85it/s][2025-02-04 02:57:31][root][INFO] - Training Epoch: 2/2, step 21174/23838 completed (loss: 0.07601298391819, acc: 1.0)
[2025-02-04 02:57:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21176/23838 [20:42<15:26,  2.87it/s][2025-02-04 02:57:31][root][INFO] - Training Epoch: 2/2, step 21175/23838 completed (loss: 0.11842834949493408, acc: 0.9545454382896423)
[2025-02-04 02:57:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21177/23838 [20:42<15:31,  2.86it/s][2025-02-04 02:57:32][root][INFO] - Training Epoch: 2/2, step 21176/23838 completed (loss: 0.5615653991699219, acc: 0.90625)
[2025-02-04 02:57:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21178/23838 [20:42<16:24,  2.70it/s][2025-02-04 02:57:32][root][INFO] - Training Epoch: 2/2, step 21177/23838 completed (loss: 1.0171221494674683, acc: 0.765625)
[2025-02-04 02:57:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21179/23838 [20:43<16:16,  2.72it/s][2025-02-04 02:57:32][root][INFO] - Training Epoch: 2/2, step 21178/23838 completed (loss: 0.17148131132125854, acc: 1.0)
[2025-02-04 02:57:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21180/23838 [20:43<16:22,  2.70it/s][2025-02-04 02:57:33][root][INFO] - Training Epoch: 2/2, step 21179/23838 completed (loss: 1.1405941247940063, acc: 0.688524603843689)
[2025-02-04 02:57:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21181/23838 [20:44<17:54,  2.47it/s][2025-02-04 02:57:33][root][INFO] - Training Epoch: 2/2, step 21180/23838 completed (loss: 0.26115044951438904, acc: 0.942307710647583)
[2025-02-04 02:57:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21182/23838 [20:44<18:02,  2.45it/s][2025-02-04 02:57:34][root][INFO] - Training Epoch: 2/2, step 21181/23838 completed (loss: 0.31510594487190247, acc: 0.9285714030265808)
[2025-02-04 02:57:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21183/23838 [20:44<17:41,  2.50it/s][2025-02-04 02:57:34][root][INFO] - Training Epoch: 2/2, step 21182/23838 completed (loss: 0.21946541965007782, acc: 0.9666666388511658)
[2025-02-04 02:57:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21184/23838 [20:45<18:33,  2.38it/s][2025-02-04 02:57:34][root][INFO] - Training Epoch: 2/2, step 21183/23838 completed (loss: 0.5883777737617493, acc: 0.8271604776382446)
[2025-02-04 02:57:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21185/23838 [20:45<18:33,  2.38it/s][2025-02-04 02:57:35][root][INFO] - Training Epoch: 2/2, step 21184/23838 completed (loss: 0.615275502204895, acc: 0.8630136847496033)
[2025-02-04 02:57:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21186/23838 [20:46<18:24,  2.40it/s][2025-02-04 02:57:35][root][INFO] - Training Epoch: 2/2, step 21185/23838 completed (loss: 0.12865020334720612, acc: 0.9736841917037964)
[2025-02-04 02:57:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21187/23838 [20:46<17:56,  2.46it/s][2025-02-04 02:57:36][root][INFO] - Training Epoch: 2/2, step 21186/23838 completed (loss: 0.1701001226902008, acc: 0.9655172228813171)
[2025-02-04 02:57:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21188/23838 [20:46<17:14,  2.56it/s][2025-02-04 02:57:36][root][INFO] - Training Epoch: 2/2, step 21187/23838 completed (loss: 0.461037278175354, acc: 0.9230769276618958)
[2025-02-04 02:57:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21189/23838 [20:47<16:30,  2.67it/s][2025-02-04 02:57:36][root][INFO] - Training Epoch: 2/2, step 21188/23838 completed (loss: 0.17720311880111694, acc: 0.9545454382896423)
[2025-02-04 02:57:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21190/23838 [20:47<16:02,  2.75it/s][2025-02-04 02:57:37][root][INFO] - Training Epoch: 2/2, step 21189/23838 completed (loss: 0.09292150288820267, acc: 0.9736841917037964)
[2025-02-04 02:57:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21191/23838 [20:47<16:18,  2.71it/s][2025-02-04 02:57:37][root][INFO] - Training Epoch: 2/2, step 21190/23838 completed (loss: 0.2860317528247833, acc: 0.9545454382896423)
[2025-02-04 02:57:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21192/23838 [20:48<15:54,  2.77it/s][2025-02-04 02:57:37][root][INFO] - Training Epoch: 2/2, step 21191/23838 completed (loss: 0.8726126551628113, acc: 0.8461538553237915)
[2025-02-04 02:57:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21193/23838 [20:48<15:59,  2.76it/s][2025-02-04 02:57:38][root][INFO] - Training Epoch: 2/2, step 21192/23838 completed (loss: 0.3101537823677063, acc: 0.949999988079071)
[2025-02-04 02:57:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21194/23838 [20:49<16:17,  2.70it/s][2025-02-04 02:57:38][root][INFO] - Training Epoch: 2/2, step 21193/23838 completed (loss: 0.30674928426742554, acc: 0.9090909361839294)
[2025-02-04 02:57:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21195/23838 [20:49<15:25,  2.85it/s][2025-02-04 02:57:38][root][INFO] - Training Epoch: 2/2, step 21194/23838 completed (loss: 0.07369889318943024, acc: 1.0)
[2025-02-04 02:57:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21196/23838 [20:49<16:21,  2.69it/s][2025-02-04 02:57:39][root][INFO] - Training Epoch: 2/2, step 21195/23838 completed (loss: 0.8421014547348022, acc: 0.7900000214576721)
[2025-02-04 02:57:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21197/23838 [20:50<15:48,  2.78it/s][2025-02-04 02:57:39][root][INFO] - Training Epoch: 2/2, step 21196/23838 completed (loss: 0.2167501449584961, acc: 0.9772727489471436)
[2025-02-04 02:57:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21198/23838 [20:50<16:42,  2.63it/s][2025-02-04 02:57:40][root][INFO] - Training Epoch: 2/2, step 21197/23838 completed (loss: 0.547534167766571, acc: 0.8695651888847351)
[2025-02-04 02:57:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21199/23838 [20:50<16:24,  2.68it/s][2025-02-04 02:57:40][root][INFO] - Training Epoch: 2/2, step 21198/23838 completed (loss: 0.19143423438072205, acc: 0.9729729890823364)
[2025-02-04 02:57:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21200/23838 [20:51<14:56,  2.94it/s][2025-02-04 02:57:40][root][INFO] - Training Epoch: 2/2, step 21199/23838 completed (loss: 0.07160743325948715, acc: 0.9791666865348816)
[2025-02-04 02:57:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21201/23838 [20:51<14:31,  3.03it/s][2025-02-04 02:57:41][root][INFO] - Training Epoch: 2/2, step 21200/23838 completed (loss: 0.12421518564224243, acc: 0.9814814925193787)
[2025-02-04 02:57:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21202/23838 [20:51<14:22,  3.05it/s][2025-02-04 02:57:41][root][INFO] - Training Epoch: 2/2, step 21201/23838 completed (loss: 0.10226704925298691, acc: 0.9655172228813171)
[2025-02-04 02:57:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21203/23838 [20:52<13:36,  3.23it/s][2025-02-04 02:57:41][root][INFO] - Training Epoch: 2/2, step 21202/23838 completed (loss: 0.07656356692314148, acc: 0.9722222089767456)
[2025-02-04 02:57:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21204/23838 [20:52<16:02,  2.74it/s][2025-02-04 02:57:42][root][INFO] - Training Epoch: 2/2, step 21203/23838 completed (loss: 0.7262025475502014, acc: 0.805031418800354)
[2025-02-04 02:57:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21205/23838 [20:52<16:33,  2.65it/s][2025-02-04 02:57:42][root][INFO] - Training Epoch: 2/2, step 21204/23838 completed (loss: 0.05577077716588974, acc: 0.9795918464660645)
[2025-02-04 02:57:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21206/23838 [20:53<17:41,  2.48it/s][2025-02-04 02:57:43][root][INFO] - Training Epoch: 2/2, step 21205/23838 completed (loss: 0.5039576888084412, acc: 0.8421052694320679)
[2025-02-04 02:57:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21207/23838 [20:53<16:56,  2.59it/s][2025-02-04 02:57:43][root][INFO] - Training Epoch: 2/2, step 21206/23838 completed (loss: 0.2973596751689911, acc: 0.8709677457809448)
[2025-02-04 02:57:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21208/23838 [20:54<16:14,  2.70it/s][2025-02-04 02:57:43][root][INFO] - Training Epoch: 2/2, step 21207/23838 completed (loss: 0.3555179536342621, acc: 0.8823529481887817)
[2025-02-04 02:57:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21209/23838 [20:54<15:30,  2.83it/s][2025-02-04 02:57:44][root][INFO] - Training Epoch: 2/2, step 21208/23838 completed (loss: 0.02942473255097866, acc: 1.0)
[2025-02-04 02:57:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21210/23838 [20:55<18:45,  2.33it/s][2025-02-04 02:57:44][root][INFO] - Training Epoch: 2/2, step 21209/23838 completed (loss: 0.6312736868858337, acc: 0.8474576473236084)
[2025-02-04 02:57:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21211/23838 [20:55<17:16,  2.53it/s][2025-02-04 02:57:44][root][INFO] - Training Epoch: 2/2, step 21210/23838 completed (loss: 0.46190088987350464, acc: 0.8780487775802612)
[2025-02-04 02:57:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21212/23838 [20:55<16:24,  2.67it/s][2025-02-04 02:57:45][root][INFO] - Training Epoch: 2/2, step 21211/23838 completed (loss: 0.6703564524650574, acc: 0.8536585569381714)
[2025-02-04 02:57:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21213/23838 [20:55<15:52,  2.75it/s][2025-02-04 02:57:45][root][INFO] - Training Epoch: 2/2, step 21212/23838 completed (loss: 0.40823304653167725, acc: 0.8974359035491943)
[2025-02-04 02:57:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21214/23838 [20:56<15:38,  2.80it/s][2025-02-04 02:57:45][root][INFO] - Training Epoch: 2/2, step 21213/23838 completed (loss: 0.2516852021217346, acc: 0.9512194991111755)
[2025-02-04 02:57:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21215/23838 [20:56<15:23,  2.84it/s][2025-02-04 02:57:46][root][INFO] - Training Epoch: 2/2, step 21214/23838 completed (loss: 0.12770530581474304, acc: 0.9285714030265808)
[2025-02-04 02:57:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21216/23838 [20:57<15:18,  2.86it/s][2025-02-04 02:57:46][root][INFO] - Training Epoch: 2/2, step 21215/23838 completed (loss: 0.14471951127052307, acc: 0.9375)
[2025-02-04 02:57:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21217/23838 [20:57<15:43,  2.78it/s][2025-02-04 02:57:46][root][INFO] - Training Epoch: 2/2, step 21216/23838 completed (loss: 0.060140445828437805, acc: 0.978723406791687)
[2025-02-04 02:57:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21218/23838 [20:57<15:44,  2.77it/s][2025-02-04 02:57:47][root][INFO] - Training Epoch: 2/2, step 21217/23838 completed (loss: 0.22486580908298492, acc: 0.9303797483444214)
[2025-02-04 02:57:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21219/23838 [20:58<15:31,  2.81it/s][2025-02-04 02:57:47][root][INFO] - Training Epoch: 2/2, step 21218/23838 completed (loss: 0.3004639148712158, acc: 0.9142857193946838)
[2025-02-04 02:57:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21220/23838 [20:58<15:09,  2.88it/s][2025-02-04 02:57:48][root][INFO] - Training Epoch: 2/2, step 21219/23838 completed (loss: 0.0936800017952919, acc: 0.9841269850730896)
[2025-02-04 02:57:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21221/23838 [20:58<15:09,  2.88it/s][2025-02-04 02:57:48][root][INFO] - Training Epoch: 2/2, step 21220/23838 completed (loss: 0.45749911665916443, acc: 0.8861788511276245)
[2025-02-04 02:57:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21222/23838 [20:59<15:17,  2.85it/s][2025-02-04 02:57:48][root][INFO] - Training Epoch: 2/2, step 21221/23838 completed (loss: 0.11878848820924759, acc: 0.9910714030265808)
[2025-02-04 02:57:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21223/23838 [20:59<15:28,  2.82it/s][2025-02-04 02:57:49][root][INFO] - Training Epoch: 2/2, step 21222/23838 completed (loss: 0.44035714864730835, acc: 0.8709677457809448)
[2025-02-04 02:57:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21224/23838 [20:59<15:55,  2.74it/s][2025-02-04 02:57:49][root][INFO] - Training Epoch: 2/2, step 21223/23838 completed (loss: 0.10395433008670807, acc: 0.978723406791687)
[2025-02-04 02:57:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21225/23838 [21:00<15:47,  2.76it/s][2025-02-04 02:57:49][root][INFO] - Training Epoch: 2/2, step 21224/23838 completed (loss: 0.18429157137870789, acc: 0.9541284441947937)
[2025-02-04 02:57:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21226/23838 [21:00<16:06,  2.70it/s][2025-02-04 02:57:50][root][INFO] - Training Epoch: 2/2, step 21225/23838 completed (loss: 0.4679163098335266, acc: 0.871999979019165)
[2025-02-04 02:57:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21227/23838 [21:01<16:03,  2.71it/s][2025-02-04 02:57:50][root][INFO] - Training Epoch: 2/2, step 21226/23838 completed (loss: 0.4957338571548462, acc: 0.8793103694915771)
[2025-02-04 02:57:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21228/23838 [21:01<16:59,  2.56it/s][2025-02-04 02:57:51][root][INFO] - Training Epoch: 2/2, step 21227/23838 completed (loss: 0.13764190673828125, acc: 0.9653846025466919)
[2025-02-04 02:57:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21229/23838 [21:01<16:29,  2.64it/s][2025-02-04 02:57:51][root][INFO] - Training Epoch: 2/2, step 21228/23838 completed (loss: 0.3902379870414734, acc: 0.8715596199035645)
[2025-02-04 02:57:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21230/23838 [21:02<16:26,  2.64it/s][2025-02-04 02:57:51][root][INFO] - Training Epoch: 2/2, step 21229/23838 completed (loss: 0.5352079272270203, acc: 0.8648648858070374)
[2025-02-04 02:57:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21231/23838 [21:02<17:21,  2.50it/s][2025-02-04 02:57:52][root][INFO] - Training Epoch: 2/2, step 21230/23838 completed (loss: 0.3071887791156769, acc: 0.931034505367279)
[2025-02-04 02:57:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21232/23838 [21:02<16:02,  2.71it/s][2025-02-04 02:57:52][root][INFO] - Training Epoch: 2/2, step 21231/23838 completed (loss: 0.4990846514701843, acc: 0.8676470518112183)
[2025-02-04 02:57:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21233/23838 [21:03<15:23,  2.82it/s][2025-02-04 02:57:52][root][INFO] - Training Epoch: 2/2, step 21232/23838 completed (loss: 0.43701666593551636, acc: 0.8701298832893372)
[2025-02-04 02:57:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21234/23838 [21:03<15:40,  2.77it/s][2025-02-04 02:57:53][root][INFO] - Training Epoch: 2/2, step 21233/23838 completed (loss: 0.2737417221069336, acc: 0.8999999761581421)
[2025-02-04 02:57:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21235/23838 [21:03<15:28,  2.80it/s][2025-02-04 02:57:53][root][INFO] - Training Epoch: 2/2, step 21234/23838 completed (loss: 0.20588847994804382, acc: 0.9402984976768494)
[2025-02-04 02:57:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21236/23838 [21:04<15:59,  2.71it/s][2025-02-04 02:57:53][root][INFO] - Training Epoch: 2/2, step 21235/23838 completed (loss: 0.20994865894317627, acc: 0.9450549483299255)
[2025-02-04 02:57:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21237/23838 [21:04<15:37,  2.78it/s][2025-02-04 02:57:54][root][INFO] - Training Epoch: 2/2, step 21236/23838 completed (loss: 0.18425552546977997, acc: 0.96875)
[2025-02-04 02:57:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21238/23838 [21:05<16:28,  2.63it/s][2025-02-04 02:57:54][root][INFO] - Training Epoch: 2/2, step 21237/23838 completed (loss: 0.16897274553775787, acc: 0.9515151381492615)
[2025-02-04 02:57:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21239/23838 [21:05<16:28,  2.63it/s][2025-02-04 02:57:55][root][INFO] - Training Epoch: 2/2, step 21238/23838 completed (loss: 0.16874684393405914, acc: 0.9469026327133179)
[2025-02-04 02:57:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21240/23838 [21:05<16:52,  2.57it/s][2025-02-04 02:57:55][root][INFO] - Training Epoch: 2/2, step 21239/23838 completed (loss: 0.2872580289840698, acc: 0.9137930870056152)
[2025-02-04 02:57:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21241/23838 [21:06<16:32,  2.62it/s][2025-02-04 02:57:55][root][INFO] - Training Epoch: 2/2, step 21240/23838 completed (loss: 0.16460150480270386, acc: 0.9449541568756104)
[2025-02-04 02:57:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21242/23838 [21:06<17:00,  2.54it/s][2025-02-04 02:57:56][root][INFO] - Training Epoch: 2/2, step 21241/23838 completed (loss: 0.14915543794631958, acc: 0.942307710647583)
[2025-02-04 02:57:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21243/23838 [21:07<16:35,  2.61it/s][2025-02-04 02:57:56][root][INFO] - Training Epoch: 2/2, step 21242/23838 completed (loss: 0.1656903773546219, acc: 0.9541984796524048)
[2025-02-04 02:57:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21244/23838 [21:07<16:35,  2.61it/s][2025-02-04 02:57:57][root][INFO] - Training Epoch: 2/2, step 21243/23838 completed (loss: 0.0869402065873146, acc: 0.9629629850387573)
[2025-02-04 02:57:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21245/23838 [21:07<16:06,  2.68it/s][2025-02-04 02:57:57][root][INFO] - Training Epoch: 2/2, step 21244/23838 completed (loss: 0.246259406208992, acc: 0.9213483333587646)
[2025-02-04 02:57:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21246/23838 [21:08<15:42,  2.75it/s][2025-02-04 02:57:57][root][INFO] - Training Epoch: 2/2, step 21245/23838 completed (loss: 0.27174341678619385, acc: 0.921875)
[2025-02-04 02:57:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21247/23838 [21:08<15:21,  2.81it/s][2025-02-04 02:57:58][root][INFO] - Training Epoch: 2/2, step 21246/23838 completed (loss: 0.26254189014434814, acc: 0.892307698726654)
[2025-02-04 02:57:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21248/23838 [21:08<17:10,  2.51it/s][2025-02-04 02:57:58][root][INFO] - Training Epoch: 2/2, step 21247/23838 completed (loss: 0.022208580747246742, acc: 1.0)
[2025-02-04 02:57:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21249/23838 [21:09<16:37,  2.60it/s][2025-02-04 02:57:58][root][INFO] - Training Epoch: 2/2, step 21248/23838 completed (loss: 0.33639970421791077, acc: 0.9150943160057068)
[2025-02-04 02:57:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21250/23838 [21:09<17:12,  2.51it/s][2025-02-04 02:57:59][root][INFO] - Training Epoch: 2/2, step 21249/23838 completed (loss: 0.13712956011295319, acc: 0.9605262875556946)
[2025-02-04 02:57:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21251/23838 [21:10<17:12,  2.50it/s][2025-02-04 02:57:59][root][INFO] - Training Epoch: 2/2, step 21250/23838 completed (loss: 0.650253415107727, acc: 0.8641975522041321)
[2025-02-04 02:57:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21252/23838 [21:10<16:34,  2.60it/s][2025-02-04 02:58:00][root][INFO] - Training Epoch: 2/2, step 21251/23838 completed (loss: 0.3387110233306885, acc: 0.9130434989929199)
[2025-02-04 02:58:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21253/23838 [21:10<17:29,  2.46it/s][2025-02-04 02:58:00][root][INFO] - Training Epoch: 2/2, step 21252/23838 completed (loss: 0.40012603998184204, acc: 0.8813559412956238)
[2025-02-04 02:58:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21254/23838 [21:11<17:12,  2.50it/s][2025-02-04 02:58:00][root][INFO] - Training Epoch: 2/2, step 21253/23838 completed (loss: 0.4075680375099182, acc: 0.8873239159584045)
[2025-02-04 02:58:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21255/23838 [21:11<16:39,  2.58it/s][2025-02-04 02:58:01][root][INFO] - Training Epoch: 2/2, step 21254/23838 completed (loss: 0.12553317844867706, acc: 0.984000027179718)
[2025-02-04 02:58:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21256/23838 [21:12<17:24,  2.47it/s][2025-02-04 02:58:01][root][INFO] - Training Epoch: 2/2, step 21255/23838 completed (loss: 0.027868950739502907, acc: 0.9876543283462524)
[2025-02-04 02:58:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21257/23838 [21:12<19:23,  2.22it/s][2025-02-04 02:58:02][root][INFO] - Training Epoch: 2/2, step 21256/23838 completed (loss: 0.09676182270050049, acc: 0.9732142686843872)
[2025-02-04 02:58:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21258/23838 [21:13<19:07,  2.25it/s][2025-02-04 02:58:02][root][INFO] - Training Epoch: 2/2, step 21257/23838 completed (loss: 0.049500465393066406, acc: 0.9890109896659851)
[2025-02-04 02:58:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21259/23838 [21:13<18:52,  2.28it/s][2025-02-04 02:58:03][root][INFO] - Training Epoch: 2/2, step 21258/23838 completed (loss: 0.3239014446735382, acc: 0.9100000262260437)
[2025-02-04 02:58:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21260/23838 [21:13<18:11,  2.36it/s][2025-02-04 02:58:03][root][INFO] - Training Epoch: 2/2, step 21259/23838 completed (loss: 0.27276450395584106, acc: 0.9104477763175964)
[2025-02-04 02:58:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21261/23838 [21:14<18:00,  2.39it/s][2025-02-04 02:58:03][root][INFO] - Training Epoch: 2/2, step 21260/23838 completed (loss: 0.07210736721754074, acc: 0.9824561476707458)
[2025-02-04 02:58:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21262/23838 [21:14<20:08,  2.13it/s][2025-02-04 02:58:04][root][INFO] - Training Epoch: 2/2, step 21261/23838 completed (loss: 0.13615906238555908, acc: 0.9727272987365723)
[2025-02-04 02:58:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21263/23838 [21:15<19:19,  2.22it/s][2025-02-04 02:58:04][root][INFO] - Training Epoch: 2/2, step 21262/23838 completed (loss: 0.014416225254535675, acc: 1.0)
[2025-02-04 02:58:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21264/23838 [21:15<20:19,  2.11it/s][2025-02-04 02:58:05][root][INFO] - Training Epoch: 2/2, step 21263/23838 completed (loss: 0.08546683937311172, acc: 0.9781022071838379)
[2025-02-04 02:58:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21265/23838 [21:16<22:43,  1.89it/s][2025-02-04 02:58:06][root][INFO] - Training Epoch: 2/2, step 21264/23838 completed (loss: 0.06501869112253189, acc: 0.9701492786407471)
[2025-02-04 02:58:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21266/23838 [21:16<20:42,  2.07it/s][2025-02-04 02:58:06][root][INFO] - Training Epoch: 2/2, step 21265/23838 completed (loss: 0.00925736129283905, acc: 1.0)
[2025-02-04 02:58:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21267/23838 [21:17<19:35,  2.19it/s][2025-02-04 02:58:06][root][INFO] - Training Epoch: 2/2, step 21266/23838 completed (loss: 0.08207058161497116, acc: 0.967391312122345)
[2025-02-04 02:58:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21268/23838 [21:17<18:20,  2.34it/s][2025-02-04 02:58:07][root][INFO] - Training Epoch: 2/2, step 21267/23838 completed (loss: 0.5569814443588257, acc: 0.8488371968269348)
[2025-02-04 02:58:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21269/23838 [21:18<22:46,  1.88it/s][2025-02-04 02:58:08][root][INFO] - Training Epoch: 2/2, step 21268/23838 completed (loss: 0.35931840538978577, acc: 0.8803418874740601)
[2025-02-04 02:58:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21270/23838 [21:19<25:17,  1.69it/s][2025-02-04 02:58:08][root][INFO] - Training Epoch: 2/2, step 21269/23838 completed (loss: 0.20114019513130188, acc: 0.9473684430122375)
[2025-02-04 02:58:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21271/23838 [21:19<24:54,  1.72it/s][2025-02-04 02:58:09][root][INFO] - Training Epoch: 2/2, step 21270/23838 completed (loss: 0.33527135848999023, acc: 0.9196428656578064)
[2025-02-04 02:58:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21272/23838 [21:20<26:35,  1.61it/s][2025-02-04 02:58:10][root][INFO] - Training Epoch: 2/2, step 21271/23838 completed (loss: 1.2451726198196411, acc: 0.6896551847457886)
[2025-02-04 02:58:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21273/23838 [21:20<23:14,  1.84it/s][2025-02-04 02:58:10][root][INFO] - Training Epoch: 2/2, step 21272/23838 completed (loss: 0.11103388667106628, acc: 0.9777777791023254)
[2025-02-04 02:58:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21274/23838 [21:21<20:09,  2.12it/s][2025-02-04 02:58:10][root][INFO] - Training Epoch: 2/2, step 21273/23838 completed (loss: 0.5687931180000305, acc: 0.804347813129425)
[2025-02-04 02:58:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21275/23838 [21:21<18:58,  2.25it/s][2025-02-04 02:58:11][root][INFO] - Training Epoch: 2/2, step 21274/23838 completed (loss: 0.5177206993103027, acc: 0.8611111044883728)
[2025-02-04 02:58:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21276/23838 [21:21<18:11,  2.35it/s][2025-02-04 02:58:11][root][INFO] - Training Epoch: 2/2, step 21275/23838 completed (loss: 0.08263830840587616, acc: 0.9873417615890503)
[2025-02-04 02:58:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21277/23838 [21:22<16:46,  2.55it/s][2025-02-04 02:58:11][root][INFO] - Training Epoch: 2/2, step 21276/23838 completed (loss: 0.2116759866476059, acc: 0.9444444179534912)
[2025-02-04 02:58:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21278/23838 [21:22<16:09,  2.64it/s][2025-02-04 02:58:12][root][INFO] - Training Epoch: 2/2, step 21277/23838 completed (loss: 0.3466258645057678, acc: 0.9090909361839294)
[2025-02-04 02:58:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21279/23838 [21:22<15:44,  2.71it/s][2025-02-04 02:58:12][root][INFO] - Training Epoch: 2/2, step 21278/23838 completed (loss: 0.26876699924468994, acc: 1.0)
[2025-02-04 02:58:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21280/23838 [21:23<14:50,  2.87it/s][2025-02-04 02:58:12][root][INFO] - Training Epoch: 2/2, step 21279/23838 completed (loss: 0.3118997812271118, acc: 1.0)
[2025-02-04 02:58:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21281/23838 [21:23<14:39,  2.91it/s][2025-02-04 02:58:13][root][INFO] - Training Epoch: 2/2, step 21280/23838 completed (loss: 0.03410450741648674, acc: 1.0)
[2025-02-04 02:58:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21282/23838 [21:23<14:57,  2.85it/s][2025-02-04 02:58:13][root][INFO] - Training Epoch: 2/2, step 21281/23838 completed (loss: 0.25873053073883057, acc: 1.0)
[2025-02-04 02:58:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21283/23838 [21:24<13:57,  3.05it/s][2025-02-04 02:58:13][root][INFO] - Training Epoch: 2/2, step 21282/23838 completed (loss: 0.021161429584026337, acc: 1.0)
[2025-02-04 02:58:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21284/23838 [21:24<14:09,  3.01it/s][2025-02-04 02:58:14][root][INFO] - Training Epoch: 2/2, step 21283/23838 completed (loss: 0.4527091979980469, acc: 0.8888888955116272)
[2025-02-04 02:58:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21285/23838 [21:24<13:50,  3.07it/s][2025-02-04 02:58:14][root][INFO] - Training Epoch: 2/2, step 21284/23838 completed (loss: 0.07254506647586823, acc: 0.9764705896377563)
[2025-02-04 02:58:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21286/23838 [21:25<14:07,  3.01it/s][2025-02-04 02:58:14][root][INFO] - Training Epoch: 2/2, step 21285/23838 completed (loss: 0.16149987280368805, acc: 0.9561403393745422)
[2025-02-04 02:58:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21287/23838 [21:25<14:13,  2.99it/s][2025-02-04 02:58:15][root][INFO] - Training Epoch: 2/2, step 21286/23838 completed (loss: 0.10427097976207733, acc: 0.9753086566925049)
[2025-02-04 02:58:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21288/23838 [21:25<14:07,  3.01it/s][2025-02-04 02:58:15][root][INFO] - Training Epoch: 2/2, step 21287/23838 completed (loss: 0.2568911910057068, acc: 0.9189189076423645)
[2025-02-04 02:58:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21289/23838 [21:26<14:16,  2.98it/s][2025-02-04 02:58:15][root][INFO] - Training Epoch: 2/2, step 21288/23838 completed (loss: 0.15766380727291107, acc: 0.967391312122345)
[2025-02-04 02:58:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21290/23838 [21:26<14:06,  3.01it/s][2025-02-04 02:58:16][root][INFO] - Training Epoch: 2/2, step 21289/23838 completed (loss: 0.0704343244433403, acc: 0.9701492786407471)
[2025-02-04 02:58:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21291/23838 [21:26<13:54,  3.05it/s][2025-02-04 02:58:16][root][INFO] - Training Epoch: 2/2, step 21290/23838 completed (loss: 0.1796039491891861, acc: 0.9692307710647583)
[2025-02-04 02:58:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21292/23838 [21:27<14:41,  2.89it/s][2025-02-04 02:58:16][root][INFO] - Training Epoch: 2/2, step 21291/23838 completed (loss: 0.0954560786485672, acc: 0.9740259647369385)
[2025-02-04 02:58:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21293/23838 [21:27<14:44,  2.88it/s][2025-02-04 02:58:17][root][INFO] - Training Epoch: 2/2, step 21292/23838 completed (loss: 0.09232478588819504, acc: 0.948051929473877)
[2025-02-04 02:58:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21294/23838 [21:28<16:09,  2.62it/s][2025-02-04 02:58:17][root][INFO] - Training Epoch: 2/2, step 21293/23838 completed (loss: 0.06014067307114601, acc: 0.9866666793823242)
[2025-02-04 02:58:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21295/23838 [21:28<15:50,  2.68it/s][2025-02-04 02:58:17][root][INFO] - Training Epoch: 2/2, step 21294/23838 completed (loss: 0.07333329319953918, acc: 0.9714285731315613)
[2025-02-04 02:58:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21296/23838 [21:28<15:58,  2.65it/s][2025-02-04 02:58:18][root][INFO] - Training Epoch: 2/2, step 21295/23838 completed (loss: 0.1933700293302536, acc: 0.9538461565971375)
[2025-02-04 02:58:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21297/23838 [21:29<16:12,  2.61it/s][2025-02-04 02:58:18][root][INFO] - Training Epoch: 2/2, step 21296/23838 completed (loss: 0.4360218942165375, acc: 0.9122806787490845)
[2025-02-04 02:58:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21298/23838 [21:29<15:29,  2.73it/s][2025-02-04 02:58:19][root][INFO] - Training Epoch: 2/2, step 21297/23838 completed (loss: 0.004137880634516478, acc: 1.0)
[2025-02-04 02:58:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21299/23838 [21:29<14:57,  2.83it/s][2025-02-04 02:58:19][root][INFO] - Training Epoch: 2/2, step 21298/23838 completed (loss: 0.714586079120636, acc: 0.8809523582458496)
[2025-02-04 02:58:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21300/23838 [21:30<14:08,  2.99it/s][2025-02-04 02:58:19][root][INFO] - Training Epoch: 2/2, step 21299/23838 completed (loss: 0.04720083624124527, acc: 0.9767441749572754)
[2025-02-04 02:58:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21301/23838 [21:30<13:14,  3.19it/s][2025-02-04 02:58:19][root][INFO] - Training Epoch: 2/2, step 21300/23838 completed (loss: 0.2692766487598419, acc: 0.8666666746139526)
[2025-02-04 02:58:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21302/23838 [21:30<13:03,  3.24it/s][2025-02-04 02:58:20][root][INFO] - Training Epoch: 2/2, step 21301/23838 completed (loss: 0.026488984003663063, acc: 1.0)
[2025-02-04 02:58:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21303/23838 [21:30<13:06,  3.22it/s][2025-02-04 02:58:20][root][INFO] - Training Epoch: 2/2, step 21302/23838 completed (loss: 0.35358214378356934, acc: 0.9210526347160339)
[2025-02-04 02:58:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21304/23838 [21:31<13:36,  3.10it/s][2025-02-04 02:58:20][root][INFO] - Training Epoch: 2/2, step 21303/23838 completed (loss: 0.1175340861082077, acc: 0.9459459185600281)
[2025-02-04 02:58:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21305/23838 [21:31<13:30,  3.13it/s][2025-02-04 02:58:21][root][INFO] - Training Epoch: 2/2, step 21304/23838 completed (loss: 0.015127642080187798, acc: 1.0)
[2025-02-04 02:58:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21306/23838 [21:32<14:02,  3.00it/s][2025-02-04 02:58:21][root][INFO] - Training Epoch: 2/2, step 21305/23838 completed (loss: 0.006897191051393747, acc: 1.0)
[2025-02-04 02:58:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21307/23838 [21:32<15:20,  2.75it/s][2025-02-04 02:58:22][root][INFO] - Training Epoch: 2/2, step 21306/23838 completed (loss: 0.1796169877052307, acc: 0.9473684430122375)
[2025-02-04 02:58:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21308/23838 [21:32<15:41,  2.69it/s][2025-02-04 02:58:22][root][INFO] - Training Epoch: 2/2, step 21307/23838 completed (loss: 0.2945711314678192, acc: 0.9090909361839294)
[2025-02-04 02:58:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21309/23838 [21:33<16:06,  2.62it/s][2025-02-04 02:58:22][root][INFO] - Training Epoch: 2/2, step 21308/23838 completed (loss: 0.17642922699451447, acc: 0.9528301954269409)
[2025-02-04 02:58:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21310/23838 [21:33<16:17,  2.59it/s][2025-02-04 02:58:23][root][INFO] - Training Epoch: 2/2, step 21309/23838 completed (loss: 0.20068925619125366, acc: 0.9333333373069763)
[2025-02-04 02:58:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21311/23838 [21:33<15:32,  2.71it/s][2025-02-04 02:58:23][root][INFO] - Training Epoch: 2/2, step 21310/23838 completed (loss: 0.43349114060401917, acc: 0.9012345671653748)
[2025-02-04 02:58:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21312/23838 [21:34<15:14,  2.76it/s][2025-02-04 02:58:23][root][INFO] - Training Epoch: 2/2, step 21311/23838 completed (loss: 0.42464661598205566, acc: 0.90625)
[2025-02-04 02:58:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21313/23838 [21:34<14:25,  2.92it/s][2025-02-04 02:58:24][root][INFO] - Training Epoch: 2/2, step 21312/23838 completed (loss: 0.1790739744901657, acc: 0.9215686321258545)
[2025-02-04 02:58:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21314/23838 [21:34<13:54,  3.03it/s][2025-02-04 02:58:24][root][INFO] - Training Epoch: 2/2, step 21313/23838 completed (loss: 0.1569368690252304, acc: 0.9333333373069763)
[2025-02-04 02:58:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21315/23838 [21:35<13:47,  3.05it/s][2025-02-04 02:58:24][root][INFO] - Training Epoch: 2/2, step 21314/23838 completed (loss: 0.0737607330083847, acc: 0.9605262875556946)
[2025-02-04 02:58:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21316/23838 [21:35<14:23,  2.92it/s][2025-02-04 02:58:25][root][INFO] - Training Epoch: 2/2, step 21315/23838 completed (loss: 0.18724846839904785, acc: 0.9555555582046509)
[2025-02-04 02:58:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21317/23838 [21:35<14:54,  2.82it/s][2025-02-04 02:58:25][root][INFO] - Training Epoch: 2/2, step 21316/23838 completed (loss: 0.3677271008491516, acc: 0.9090909361839294)
[2025-02-04 02:58:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21318/23838 [21:36<15:03,  2.79it/s][2025-02-04 02:58:25][root][INFO] - Training Epoch: 2/2, step 21317/23838 completed (loss: 0.19805443286895752, acc: 0.9242424368858337)
[2025-02-04 02:58:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21319/23838 [21:36<14:13,  2.95it/s][2025-02-04 02:58:26][root][INFO] - Training Epoch: 2/2, step 21318/23838 completed (loss: 0.0825505256652832, acc: 0.9649122953414917)
[2025-02-04 02:58:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21320/23838 [21:37<15:04,  2.78it/s][2025-02-04 02:58:26][root][INFO] - Training Epoch: 2/2, step 21319/23838 completed (loss: 0.10519388318061829, acc: 0.9672130942344666)
[2025-02-04 02:58:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21321/23838 [21:37<16:08,  2.60it/s][2025-02-04 02:58:27][root][INFO] - Training Epoch: 2/2, step 21320/23838 completed (loss: 0.22019287943840027, acc: 0.9333333373069763)
[2025-02-04 02:58:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21322/23838 [21:37<16:58,  2.47it/s][2025-02-04 02:58:27][root][INFO] - Training Epoch: 2/2, step 21321/23838 completed (loss: 0.9612255692481995, acc: 0.7560975551605225)
[2025-02-04 02:58:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21323/23838 [21:38<16:35,  2.53it/s][2025-02-04 02:58:27][root][INFO] - Training Epoch: 2/2, step 21322/23838 completed (loss: 0.5633640289306641, acc: 0.8787878751754761)
[2025-02-04 02:58:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21324/23838 [21:38<16:04,  2.61it/s][2025-02-04 02:58:28][root][INFO] - Training Epoch: 2/2, step 21323/23838 completed (loss: 0.23472696542739868, acc: 0.978723406791687)
[2025-02-04 02:58:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21325/23838 [21:39<15:35,  2.69it/s][2025-02-04 02:58:28][root][INFO] - Training Epoch: 2/2, step 21324/23838 completed (loss: 0.10698813945055008, acc: 0.9384615421295166)
[2025-02-04 02:58:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21326/23838 [21:39<14:41,  2.85it/s][2025-02-04 02:58:28][root][INFO] - Training Epoch: 2/2, step 21325/23838 completed (loss: 0.3339197635650635, acc: 0.8399999737739563)
[2025-02-04 02:58:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21327/23838 [21:39<14:41,  2.85it/s][2025-02-04 02:58:29][root][INFO] - Training Epoch: 2/2, step 21326/23838 completed (loss: 0.3136904835700989, acc: 0.8709677457809448)
[2025-02-04 02:58:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21328/23838 [21:40<14:49,  2.82it/s][2025-02-04 02:58:29][root][INFO] - Training Epoch: 2/2, step 21327/23838 completed (loss: 0.4950859248638153, acc: 0.8730158805847168)
[2025-02-04 02:58:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21329/23838 [21:40<14:25,  2.90it/s][2025-02-04 02:58:29][root][INFO] - Training Epoch: 2/2, step 21328/23838 completed (loss: 0.3876883089542389, acc: 0.8571428656578064)
[2025-02-04 02:58:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21330/23838 [21:40<14:48,  2.82it/s][2025-02-04 02:58:30][root][INFO] - Training Epoch: 2/2, step 21329/23838 completed (loss: 0.4832628667354584, acc: 0.8936170339584351)
[2025-02-04 02:58:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21331/23838 [21:41<13:51,  3.02it/s][2025-02-04 02:58:30][root][INFO] - Training Epoch: 2/2, step 21330/23838 completed (loss: 0.3540419340133667, acc: 0.8999999761581421)
[2025-02-04 02:58:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21332/23838 [21:41<13:53,  3.01it/s][2025-02-04 02:58:30][root][INFO] - Training Epoch: 2/2, step 21331/23838 completed (loss: 0.12917739152908325, acc: 0.9538461565971375)
[2025-02-04 02:58:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21333/23838 [21:41<13:48,  3.02it/s][2025-02-04 02:58:31][root][INFO] - Training Epoch: 2/2, step 21332/23838 completed (loss: 0.22943982481956482, acc: 0.9384615421295166)
[2025-02-04 02:58:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21334/23838 [21:42<15:07,  2.76it/s][2025-02-04 02:58:31][root][INFO] - Training Epoch: 2/2, step 21333/23838 completed (loss: 0.3344229459762573, acc: 0.9069767594337463)
[2025-02-04 02:58:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  89%|[34m████████▉ [0m| 21335/23838 [21:42<15:23,  2.71it/s][2025-02-04 02:58:32][root][INFO] - Training Epoch: 2/2, step 21334/23838 completed (loss: 0.14834219217300415, acc: 0.9777777791023254)
[2025-02-04 02:58:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21336/23838 [21:42<16:04,  2.59it/s][2025-02-04 02:58:32][root][INFO] - Training Epoch: 2/2, step 21335/23838 completed (loss: 0.20971596240997314, acc: 0.95652174949646)
[2025-02-04 02:58:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21337/23838 [21:43<16:53,  2.47it/s][2025-02-04 02:58:32][root][INFO] - Training Epoch: 2/2, step 21336/23838 completed (loss: 0.6870012879371643, acc: 0.8444444537162781)
[2025-02-04 02:58:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21338/23838 [21:43<16:35,  2.51it/s][2025-02-04 02:58:33][root][INFO] - Training Epoch: 2/2, step 21337/23838 completed (loss: 0.3605814576148987, acc: 0.8928571343421936)
[2025-02-04 02:58:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21339/23838 [21:44<16:12,  2.57it/s][2025-02-04 02:58:33][root][INFO] - Training Epoch: 2/2, step 21338/23838 completed (loss: 0.16366712749004364, acc: 0.9696969985961914)
[2025-02-04 02:58:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21340/23838 [21:44<16:30,  2.52it/s][2025-02-04 02:58:34][root][INFO] - Training Epoch: 2/2, step 21339/23838 completed (loss: 0.250047504901886, acc: 0.95652174949646)
[2025-02-04 02:58:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21341/23838 [21:44<17:08,  2.43it/s][2025-02-04 02:58:34][root][INFO] - Training Epoch: 2/2, step 21340/23838 completed (loss: 0.2528510093688965, acc: 0.9189189076423645)
[2025-02-04 02:58:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21342/23838 [21:45<16:50,  2.47it/s][2025-02-04 02:58:34][root][INFO] - Training Epoch: 2/2, step 21341/23838 completed (loss: 0.30711349844932556, acc: 0.8999999761581421)
[2025-02-04 02:58:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21343/23838 [21:45<17:25,  2.39it/s][2025-02-04 02:58:35][root][INFO] - Training Epoch: 2/2, step 21342/23838 completed (loss: 0.2332678586244583, acc: 0.9487179517745972)
[2025-02-04 02:58:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21344/23838 [21:46<17:12,  2.42it/s][2025-02-04 02:58:35][root][INFO] - Training Epoch: 2/2, step 21343/23838 completed (loss: 0.22558972239494324, acc: 0.9571428298950195)
[2025-02-04 02:58:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21345/23838 [21:46<19:22,  2.14it/s][2025-02-04 02:58:36][root][INFO] - Training Epoch: 2/2, step 21344/23838 completed (loss: 0.3622869551181793, acc: 0.890625)
[2025-02-04 02:58:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21346/23838 [21:47<18:05,  2.29it/s][2025-02-04 02:58:36][root][INFO] - Training Epoch: 2/2, step 21345/23838 completed (loss: 0.5236774682998657, acc: 0.8199999928474426)
[2025-02-04 02:58:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21347/23838 [21:47<16:50,  2.47it/s][2025-02-04 02:58:37][root][INFO] - Training Epoch: 2/2, step 21346/23838 completed (loss: 0.25725802779197693, acc: 0.9160305261611938)
[2025-02-04 02:58:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21348/23838 [21:47<16:36,  2.50it/s][2025-02-04 02:58:37][root][INFO] - Training Epoch: 2/2, step 21347/23838 completed (loss: 0.5216836333274841, acc: 0.8550724387168884)
[2025-02-04 02:58:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21349/23838 [21:48<16:08,  2.57it/s][2025-02-04 02:58:37][root][INFO] - Training Epoch: 2/2, step 21348/23838 completed (loss: 0.20018649101257324, acc: 0.9275362491607666)
[2025-02-04 02:58:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21350/23838 [21:48<15:34,  2.66it/s][2025-02-04 02:58:38][root][INFO] - Training Epoch: 2/2, step 21349/23838 completed (loss: 0.09740236401557922, acc: 0.9803921580314636)
[2025-02-04 02:58:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21351/23838 [21:48<15:33,  2.66it/s][2025-02-04 02:58:38][root][INFO] - Training Epoch: 2/2, step 21350/23838 completed (loss: 0.4824652075767517, acc: 0.8888888955116272)
[2025-02-04 02:58:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21352/23838 [21:49<15:49,  2.62it/s][2025-02-04 02:58:38][root][INFO] - Training Epoch: 2/2, step 21351/23838 completed (loss: 0.17481543123722076, acc: 0.9595959782600403)
[2025-02-04 02:58:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21353/23838 [21:49<15:50,  2.62it/s][2025-02-04 02:58:39][root][INFO] - Training Epoch: 2/2, step 21352/23838 completed (loss: 0.7994531989097595, acc: 0.761904776096344)
[2025-02-04 02:58:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21354/23838 [21:50<16:10,  2.56it/s][2025-02-04 02:58:39][root][INFO] - Training Epoch: 2/2, step 21353/23838 completed (loss: 0.4592117965221405, acc: 0.9032257795333862)
[2025-02-04 02:58:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21355/23838 [21:50<15:43,  2.63it/s][2025-02-04 02:58:40][root][INFO] - Training Epoch: 2/2, step 21354/23838 completed (loss: 0.39232829213142395, acc: 0.90625)
[2025-02-04 02:58:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21356/23838 [21:50<14:58,  2.76it/s][2025-02-04 02:58:40][root][INFO] - Training Epoch: 2/2, step 21355/23838 completed (loss: 0.02941838838160038, acc: 1.0)
[2025-02-04 02:58:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21357/23838 [21:51<15:24,  2.68it/s][2025-02-04 02:58:40][root][INFO] - Training Epoch: 2/2, step 21356/23838 completed (loss: 0.2722703516483307, acc: 0.9195402264595032)
[2025-02-04 02:58:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21358/23838 [21:51<15:34,  2.65it/s][2025-02-04 02:58:41][root][INFO] - Training Epoch: 2/2, step 21357/23838 completed (loss: 0.009731819853186607, acc: 1.0)
[2025-02-04 02:58:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21359/23838 [21:52<15:36,  2.65it/s][2025-02-04 02:58:41][root][INFO] - Training Epoch: 2/2, step 21358/23838 completed (loss: 0.07080504298210144, acc: 0.9629629850387573)
[2025-02-04 02:58:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21360/23838 [21:52<15:43,  2.63it/s][2025-02-04 02:58:42][root][INFO] - Training Epoch: 2/2, step 21359/23838 completed (loss: 0.50002121925354, acc: 0.8653846383094788)
[2025-02-04 02:58:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21361/23838 [21:52<15:33,  2.65it/s][2025-02-04 02:58:42][root][INFO] - Training Epoch: 2/2, step 21360/23838 completed (loss: 0.02301200106739998, acc: 1.0)
[2025-02-04 02:58:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21362/23838 [21:53<15:10,  2.72it/s][2025-02-04 02:58:42][root][INFO] - Training Epoch: 2/2, step 21361/23838 completed (loss: 0.037068817764520645, acc: 1.0)
[2025-02-04 02:58:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21363/23838 [21:53<14:52,  2.77it/s][2025-02-04 02:58:43][root][INFO] - Training Epoch: 2/2, step 21362/23838 completed (loss: 0.08895435184240341, acc: 1.0)
[2025-02-04 02:58:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21364/23838 [21:53<14:31,  2.84it/s][2025-02-04 02:58:43][root][INFO] - Training Epoch: 2/2, step 21363/23838 completed (loss: 0.40770429372787476, acc: 0.875)
[2025-02-04 02:58:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21365/23838 [21:54<14:50,  2.78it/s][2025-02-04 02:58:43][root][INFO] - Training Epoch: 2/2, step 21364/23838 completed (loss: 0.22426161170005798, acc: 0.9038461446762085)
[2025-02-04 02:58:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21366/23838 [21:54<14:03,  2.93it/s][2025-02-04 02:58:44][root][INFO] - Training Epoch: 2/2, step 21365/23838 completed (loss: 0.10916387289762497, acc: 0.97826087474823)
[2025-02-04 02:58:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21367/23838 [21:54<14:00,  2.94it/s][2025-02-04 02:58:44][root][INFO] - Training Epoch: 2/2, step 21366/23838 completed (loss: 0.03579050302505493, acc: 1.0)
[2025-02-04 02:58:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21368/23838 [21:55<14:11,  2.90it/s][2025-02-04 02:58:44][root][INFO] - Training Epoch: 2/2, step 21367/23838 completed (loss: 0.0160897895693779, acc: 1.0)
[2025-02-04 02:58:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21369/23838 [21:55<14:07,  2.91it/s][2025-02-04 02:58:45][root][INFO] - Training Epoch: 2/2, step 21368/23838 completed (loss: 0.019606508314609528, acc: 1.0)
[2025-02-04 02:58:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21370/23838 [21:55<14:13,  2.89it/s][2025-02-04 02:58:45][root][INFO] - Training Epoch: 2/2, step 21369/23838 completed (loss: 0.11132004857063293, acc: 0.9772727489471436)
[2025-02-04 02:58:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21371/23838 [21:56<15:00,  2.74it/s][2025-02-04 02:58:45][root][INFO] - Training Epoch: 2/2, step 21370/23838 completed (loss: 0.4442671239376068, acc: 0.8787878751754761)
[2025-02-04 02:58:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21372/23838 [21:56<14:08,  2.91it/s][2025-02-04 02:58:46][root][INFO] - Training Epoch: 2/2, step 21371/23838 completed (loss: 0.16554367542266846, acc: 0.9473684430122375)
[2025-02-04 02:58:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21373/23838 [21:56<13:54,  2.96it/s][2025-02-04 02:58:46][root][INFO] - Training Epoch: 2/2, step 21372/23838 completed (loss: 0.29627782106399536, acc: 0.9333333373069763)
[2025-02-04 02:58:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21374/23838 [21:57<15:24,  2.67it/s][2025-02-04 02:58:46][root][INFO] - Training Epoch: 2/2, step 21373/23838 completed (loss: 0.07359174638986588, acc: 0.978723406791687)
[2025-02-04 02:58:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21375/23838 [21:57<15:27,  2.66it/s][2025-02-04 02:58:47][root][INFO] - Training Epoch: 2/2, step 21374/23838 completed (loss: 0.27023327350616455, acc: 0.9047619104385376)
[2025-02-04 02:58:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21376/23838 [21:58<15:48,  2.60it/s][2025-02-04 02:58:47][root][INFO] - Training Epoch: 2/2, step 21375/23838 completed (loss: 0.26202693581581116, acc: 0.9166666865348816)
[2025-02-04 02:58:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21377/23838 [21:58<16:01,  2.56it/s][2025-02-04 02:58:48][root][INFO] - Training Epoch: 2/2, step 21376/23838 completed (loss: 0.33396226167678833, acc: 0.9230769276618958)
[2025-02-04 02:58:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21378/23838 [21:58<15:48,  2.59it/s][2025-02-04 02:58:48][root][INFO] - Training Epoch: 2/2, step 21377/23838 completed (loss: 0.15054339170455933, acc: 0.914893627166748)
[2025-02-04 02:58:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21379/23838 [21:59<15:21,  2.67it/s][2025-02-04 02:58:48][root][INFO] - Training Epoch: 2/2, step 21378/23838 completed (loss: 0.3785799443721771, acc: 0.9052631855010986)
[2025-02-04 02:58:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21380/23838 [21:59<15:06,  2.71it/s][2025-02-04 02:58:49][root][INFO] - Training Epoch: 2/2, step 21379/23838 completed (loss: 0.125559002161026, acc: 0.9729729890823364)
[2025-02-04 02:58:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21381/23838 [21:59<15:05,  2.71it/s][2025-02-04 02:58:49][root][INFO] - Training Epoch: 2/2, step 21380/23838 completed (loss: 0.1683262139558792, acc: 0.976190447807312)
[2025-02-04 02:58:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21382/23838 [22:00<14:49,  2.76it/s][2025-02-04 02:58:49][root][INFO] - Training Epoch: 2/2, step 21381/23838 completed (loss: 0.005757003091275692, acc: 1.0)
[2025-02-04 02:58:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21383/23838 [22:00<14:48,  2.76it/s][2025-02-04 02:58:50][root][INFO] - Training Epoch: 2/2, step 21382/23838 completed (loss: 0.04862084239721298, acc: 0.9772727489471436)
[2025-02-04 02:58:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21384/23838 [22:01<15:03,  2.72it/s][2025-02-04 02:58:50][root][INFO] - Training Epoch: 2/2, step 21383/23838 completed (loss: 0.18283705413341522, acc: 0.9387755393981934)
[2025-02-04 02:58:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21385/23838 [22:01<15:35,  2.62it/s][2025-02-04 02:58:51][root][INFO] - Training Epoch: 2/2, step 21384/23838 completed (loss: 0.16568592190742493, acc: 0.949999988079071)
[2025-02-04 02:58:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21386/23838 [22:01<15:10,  2.69it/s][2025-02-04 02:58:51][root][INFO] - Training Epoch: 2/2, step 21385/23838 completed (loss: 0.09977614134550095, acc: 0.9677419066429138)
[2025-02-04 02:58:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21387/23838 [22:02<14:49,  2.76it/s][2025-02-04 02:58:51][root][INFO] - Training Epoch: 2/2, step 21386/23838 completed (loss: 0.11524386703968048, acc: 0.95652174949646)
[2025-02-04 02:58:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21388/23838 [22:02<14:33,  2.80it/s][2025-02-04 02:58:52][root][INFO] - Training Epoch: 2/2, step 21387/23838 completed (loss: 0.11366444081068039, acc: 0.97826087474823)
[2025-02-04 02:58:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21389/23838 [22:02<14:42,  2.78it/s][2025-02-04 02:58:52][root][INFO] - Training Epoch: 2/2, step 21388/23838 completed (loss: 0.02383439429104328, acc: 1.0)
[2025-02-04 02:58:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21390/23838 [22:03<14:44,  2.77it/s][2025-02-04 02:58:52][root][INFO] - Training Epoch: 2/2, step 21389/23838 completed (loss: 0.012409096583724022, acc: 1.0)
[2025-02-04 02:58:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21391/23838 [22:03<15:17,  2.67it/s][2025-02-04 02:58:53][root][INFO] - Training Epoch: 2/2, step 21390/23838 completed (loss: 0.008558151312172413, acc: 1.0)
[2025-02-04 02:58:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21392/23838 [22:04<15:12,  2.68it/s][2025-02-04 02:58:53][root][INFO] - Training Epoch: 2/2, step 21391/23838 completed (loss: 0.3668423295021057, acc: 0.9210526347160339)
[2025-02-04 02:58:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21393/23838 [22:04<14:56,  2.73it/s][2025-02-04 02:58:53][root][INFO] - Training Epoch: 2/2, step 21392/23838 completed (loss: 0.07323096692562103, acc: 0.9841269850730896)
[2025-02-04 02:58:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21394/23838 [22:04<14:59,  2.72it/s][2025-02-04 02:58:54][root][INFO] - Training Epoch: 2/2, step 21393/23838 completed (loss: 0.06536686420440674, acc: 0.978723406791687)
[2025-02-04 02:58:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21395/23838 [22:05<14:48,  2.75it/s][2025-02-04 02:58:54][root][INFO] - Training Epoch: 2/2, step 21394/23838 completed (loss: 0.002792652929201722, acc: 1.0)
[2025-02-04 02:58:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21396/23838 [22:05<14:14,  2.86it/s][2025-02-04 02:58:55][root][INFO] - Training Epoch: 2/2, step 21395/23838 completed (loss: 0.12159646302461624, acc: 0.9558823704719543)
[2025-02-04 02:58:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21397/23838 [22:05<14:08,  2.88it/s][2025-02-04 02:58:55][root][INFO] - Training Epoch: 2/2, step 21396/23838 completed (loss: 0.21851615607738495, acc: 0.9482758641242981)
[2025-02-04 02:58:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21398/23838 [22:06<14:06,  2.88it/s][2025-02-04 02:58:55][root][INFO] - Training Epoch: 2/2, step 21397/23838 completed (loss: 1.3200174570083618, acc: 0.686274528503418)
[2025-02-04 02:58:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21399/23838 [22:06<14:38,  2.78it/s][2025-02-04 02:58:56][root][INFO] - Training Epoch: 2/2, step 21398/23838 completed (loss: 0.7419787645339966, acc: 0.75)
[2025-02-04 02:58:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21400/23838 [22:06<14:33,  2.79it/s][2025-02-04 02:58:56][root][INFO] - Training Epoch: 2/2, step 21399/23838 completed (loss: 0.5047825574874878, acc: 0.8139534592628479)
[2025-02-04 02:58:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21401/23838 [22:07<14:25,  2.82it/s][2025-02-04 02:58:56][root][INFO] - Training Epoch: 2/2, step 21400/23838 completed (loss: 0.376437783241272, acc: 0.8709677457809448)
[2025-02-04 02:58:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21402/23838 [22:07<14:52,  2.73it/s][2025-02-04 02:58:57][root][INFO] - Training Epoch: 2/2, step 21401/23838 completed (loss: 0.7892423868179321, acc: 0.7551020383834839)
[2025-02-04 02:58:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21403/23838 [22:08<15:19,  2.65it/s][2025-02-04 02:58:57][root][INFO] - Training Epoch: 2/2, step 21402/23838 completed (loss: 0.6835486888885498, acc: 0.75)
[2025-02-04 02:58:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21404/23838 [22:08<15:10,  2.67it/s][2025-02-04 02:58:57][root][INFO] - Training Epoch: 2/2, step 21403/23838 completed (loss: 1.0612491369247437, acc: 0.6779661178588867)
[2025-02-04 02:58:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21405/23838 [22:08<15:23,  2.63it/s][2025-02-04 02:58:58][root][INFO] - Training Epoch: 2/2, step 21404/23838 completed (loss: 1.4767457246780396, acc: 0.5686274766921997)
[2025-02-04 02:58:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21406/23838 [22:09<15:17,  2.65it/s][2025-02-04 02:58:58][root][INFO] - Training Epoch: 2/2, step 21405/23838 completed (loss: 0.7736787796020508, acc: 0.7875000238418579)
[2025-02-04 02:58:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21407/23838 [22:09<15:21,  2.64it/s][2025-02-04 02:58:59][root][INFO] - Training Epoch: 2/2, step 21406/23838 completed (loss: 0.22547727823257446, acc: 0.9230769276618958)
[2025-02-04 02:58:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21408/23838 [22:09<16:05,  2.52it/s][2025-02-04 02:58:59][root][INFO] - Training Epoch: 2/2, step 21407/23838 completed (loss: 0.930018961429596, acc: 0.7551020383834839)
[2025-02-04 02:58:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21409/23838 [22:10<16:01,  2.53it/s][2025-02-04 02:58:59][root][INFO] - Training Epoch: 2/2, step 21408/23838 completed (loss: 1.037501335144043, acc: 0.7083333134651184)
[2025-02-04 02:59:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21410/23838 [22:10<15:12,  2.66it/s][2025-02-04 02:59:00][root][INFO] - Training Epoch: 2/2, step 21409/23838 completed (loss: 0.5399067401885986, acc: 0.84375)
[2025-02-04 02:59:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21411/23838 [22:11<14:38,  2.76it/s][2025-02-04 02:59:00][root][INFO] - Training Epoch: 2/2, step 21410/23838 completed (loss: 0.9653971195220947, acc: 0.7254902124404907)
[2025-02-04 02:59:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21412/23838 [22:11<14:20,  2.82it/s][2025-02-04 02:59:00][root][INFO] - Training Epoch: 2/2, step 21411/23838 completed (loss: 0.9161985516548157, acc: 0.7647058963775635)
[2025-02-04 02:59:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21413/23838 [22:11<13:52,  2.91it/s][2025-02-04 02:59:01][root][INFO] - Training Epoch: 2/2, step 21412/23838 completed (loss: 0.8559050559997559, acc: 0.7142857313156128)
[2025-02-04 02:59:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21414/23838 [22:11<13:30,  2.99it/s][2025-02-04 02:59:01][root][INFO] - Training Epoch: 2/2, step 21413/23838 completed (loss: 0.8048093318939209, acc: 0.7083333134651184)
[2025-02-04 02:59:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21415/23838 [22:12<13:15,  3.05it/s][2025-02-04 02:59:01][root][INFO] - Training Epoch: 2/2, step 21414/23838 completed (loss: 0.9162581562995911, acc: 0.8333333134651184)
[2025-02-04 02:59:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21416/23838 [22:12<12:54,  3.13it/s][2025-02-04 02:59:02][root][INFO] - Training Epoch: 2/2, step 21415/23838 completed (loss: 0.5666726231575012, acc: 0.8139534592628479)
[2025-02-04 02:59:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21417/23838 [22:12<12:52,  3.13it/s][2025-02-04 02:59:02][root][INFO] - Training Epoch: 2/2, step 21416/23838 completed (loss: 0.7682644128799438, acc: 0.7580645084381104)
[2025-02-04 02:59:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21418/23838 [22:13<13:00,  3.10it/s][2025-02-04 02:59:02][root][INFO] - Training Epoch: 2/2, step 21417/23838 completed (loss: 0.7679978013038635, acc: 0.7313432693481445)
[2025-02-04 02:59:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21419/23838 [22:13<13:58,  2.89it/s][2025-02-04 02:59:03][root][INFO] - Training Epoch: 2/2, step 21418/23838 completed (loss: 0.8216081857681274, acc: 0.7636363506317139)
[2025-02-04 02:59:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21420/23838 [22:14<15:06,  2.67it/s][2025-02-04 02:59:03][root][INFO] - Training Epoch: 2/2, step 21419/23838 completed (loss: 0.7234558463096619, acc: 0.8421052694320679)
[2025-02-04 02:59:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21421/23838 [22:14<15:49,  2.55it/s][2025-02-04 02:59:04][root][INFO] - Training Epoch: 2/2, step 21420/23838 completed (loss: 0.9343991875648499, acc: 0.75)
[2025-02-04 02:59:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21422/23838 [22:14<15:53,  2.53it/s][2025-02-04 02:59:04][root][INFO] - Training Epoch: 2/2, step 21421/23838 completed (loss: 0.522719144821167, acc: 0.8055555820465088)
[2025-02-04 02:59:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21423/23838 [22:15<16:30,  2.44it/s][2025-02-04 02:59:04][root][INFO] - Training Epoch: 2/2, step 21422/23838 completed (loss: 0.9876542687416077, acc: 0.7647058963775635)
[2025-02-04 02:59:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21424/23838 [22:15<16:14,  2.48it/s][2025-02-04 02:59:05][root][INFO] - Training Epoch: 2/2, step 21423/23838 completed (loss: 0.4327791631221771, acc: 0.8958333134651184)
[2025-02-04 02:59:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21425/23838 [22:16<16:38,  2.42it/s][2025-02-04 02:59:05][root][INFO] - Training Epoch: 2/2, step 21424/23838 completed (loss: 0.05869017168879509, acc: 0.9861111044883728)
[2025-02-04 02:59:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21426/23838 [22:16<16:11,  2.48it/s][2025-02-04 02:59:06][root][INFO] - Training Epoch: 2/2, step 21425/23838 completed (loss: 0.5004442930221558, acc: 0.8636363744735718)
[2025-02-04 02:59:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21427/23838 [22:16<15:57,  2.52it/s][2025-02-04 02:59:06][root][INFO] - Training Epoch: 2/2, step 21426/23838 completed (loss: 0.501406729221344, acc: 0.8620689511299133)
[2025-02-04 02:59:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21428/23838 [22:17<15:27,  2.60it/s][2025-02-04 02:59:06][root][INFO] - Training Epoch: 2/2, step 21427/23838 completed (loss: 1.0447537899017334, acc: 0.6603773832321167)
[2025-02-04 02:59:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21429/23838 [22:17<14:59,  2.68it/s][2025-02-04 02:59:07][root][INFO] - Training Epoch: 2/2, step 21428/23838 completed (loss: 0.42542576789855957, acc: 0.875)
[2025-02-04 02:59:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21430/23838 [22:17<14:24,  2.78it/s][2025-02-04 02:59:07][root][INFO] - Training Epoch: 2/2, step 21429/23838 completed (loss: 0.5273614525794983, acc: 0.8552631735801697)
[2025-02-04 02:59:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21431/23838 [22:18<15:16,  2.63it/s][2025-02-04 02:59:08][root][INFO] - Training Epoch: 2/2, step 21430/23838 completed (loss: 0.6741009950637817, acc: 0.8461538553237915)
[2025-02-04 02:59:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21432/23838 [22:18<15:53,  2.52it/s][2025-02-04 02:59:08][root][INFO] - Training Epoch: 2/2, step 21431/23838 completed (loss: 0.3953249752521515, acc: 0.837837815284729)
[2025-02-04 02:59:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21433/23838 [22:19<15:17,  2.62it/s][2025-02-04 02:59:08][root][INFO] - Training Epoch: 2/2, step 21432/23838 completed (loss: 0.28451842069625854, acc: 0.8823529481887817)
[2025-02-04 02:59:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21434/23838 [22:19<14:51,  2.70it/s][2025-02-04 02:59:09][root][INFO] - Training Epoch: 2/2, step 21433/23838 completed (loss: 0.19643862545490265, acc: 0.9473684430122375)
[2025-02-04 02:59:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21435/23838 [22:19<15:09,  2.64it/s][2025-02-04 02:59:09][root][INFO] - Training Epoch: 2/2, step 21434/23838 completed (loss: 0.6753748059272766, acc: 0.7647058963775635)
[2025-02-04 02:59:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21436/23838 [22:20<15:02,  2.66it/s][2025-02-04 02:59:09][root][INFO] - Training Epoch: 2/2, step 21435/23838 completed (loss: 0.518681526184082, acc: 0.8799999952316284)
[2025-02-04 02:59:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21437/23838 [22:20<15:09,  2.64it/s][2025-02-04 02:59:10][root][INFO] - Training Epoch: 2/2, step 21436/23838 completed (loss: 0.5095757246017456, acc: 0.8536585569381714)
[2025-02-04 02:59:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21438/23838 [22:21<15:33,  2.57it/s][2025-02-04 02:59:10][root][INFO] - Training Epoch: 2/2, step 21437/23838 completed (loss: 0.330793172121048, acc: 0.875)
[2025-02-04 02:59:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21439/23838 [22:21<15:36,  2.56it/s][2025-02-04 02:59:11][root][INFO] - Training Epoch: 2/2, step 21438/23838 completed (loss: 0.5848664045333862, acc: 0.8636363744735718)
[2025-02-04 02:59:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21440/23838 [22:21<16:33,  2.41it/s][2025-02-04 02:59:11][root][INFO] - Training Epoch: 2/2, step 21439/23838 completed (loss: 0.9199985861778259, acc: 0.7222222089767456)
[2025-02-04 02:59:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21441/23838 [22:22<16:09,  2.47it/s][2025-02-04 02:59:11][root][INFO] - Training Epoch: 2/2, step 21440/23838 completed (loss: 0.3431498110294342, acc: 0.8857142925262451)
[2025-02-04 02:59:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21442/23838 [22:22<16:38,  2.40it/s][2025-02-04 02:59:12][root][INFO] - Training Epoch: 2/2, step 21441/23838 completed (loss: 0.9796808958053589, acc: 0.8225806355476379)
[2025-02-04 02:59:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21443/23838 [22:23<15:33,  2.57it/s][2025-02-04 02:59:12][root][INFO] - Training Epoch: 2/2, step 21442/23838 completed (loss: 0.20803947746753693, acc: 0.949999988079071)
[2025-02-04 02:59:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21444/23838 [22:23<14:41,  2.72it/s][2025-02-04 02:59:13][root][INFO] - Training Epoch: 2/2, step 21443/23838 completed (loss: 0.20079529285430908, acc: 0.9375)
[2025-02-04 02:59:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21445/23838 [22:23<15:26,  2.58it/s][2025-02-04 02:59:13][root][INFO] - Training Epoch: 2/2, step 21444/23838 completed (loss: 0.6779925227165222, acc: 0.761904776096344)
[2025-02-04 02:59:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21446/23838 [22:24<16:35,  2.40it/s][2025-02-04 02:59:13][root][INFO] - Training Epoch: 2/2, step 21445/23838 completed (loss: 0.14783602952957153, acc: 0.9800000190734863)
[2025-02-04 02:59:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21447/23838 [22:24<16:22,  2.43it/s][2025-02-04 02:59:14][root][INFO] - Training Epoch: 2/2, step 21446/23838 completed (loss: 0.4360540509223938, acc: 0.8448275923728943)
[2025-02-04 02:59:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21448/23838 [22:25<16:07,  2.47it/s][2025-02-04 02:59:14][root][INFO] - Training Epoch: 2/2, step 21447/23838 completed (loss: 0.8870643973350525, acc: 0.8157894611358643)
[2025-02-04 02:59:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21449/23838 [22:25<14:55,  2.67it/s][2025-02-04 02:59:15][root][INFO] - Training Epoch: 2/2, step 21448/23838 completed (loss: 0.46317926049232483, acc: 0.8846153616905212)
[2025-02-04 02:59:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21450/23838 [22:25<14:55,  2.67it/s][2025-02-04 02:59:15][root][INFO] - Training Epoch: 2/2, step 21449/23838 completed (loss: 0.45681264996528625, acc: 0.8799999952316284)
[2025-02-04 02:59:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21451/23838 [22:26<15:33,  2.56it/s][2025-02-04 02:59:15][root][INFO] - Training Epoch: 2/2, step 21450/23838 completed (loss: 0.3643522560596466, acc: 0.8902438879013062)
[2025-02-04 02:59:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21452/23838 [22:26<14:51,  2.68it/s][2025-02-04 02:59:16][root][INFO] - Training Epoch: 2/2, step 21451/23838 completed (loss: 0.3132765591144562, acc: 0.890625)
[2025-02-04 02:59:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21453/23838 [22:27<15:22,  2.58it/s][2025-02-04 02:59:16][root][INFO] - Training Epoch: 2/2, step 21452/23838 completed (loss: 0.30042973160743713, acc: 0.9130434989929199)
[2025-02-04 02:59:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m████████▉ [0m| 21454/23838 [22:27<15:00,  2.65it/s][2025-02-04 02:59:16][root][INFO] - Training Epoch: 2/2, step 21453/23838 completed (loss: 0.6263839602470398, acc: 0.8316831588745117)
[2025-02-04 02:59:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21455/23838 [22:27<14:43,  2.70it/s][2025-02-04 02:59:17][root][INFO] - Training Epoch: 2/2, step 21454/23838 completed (loss: 0.6333744525909424, acc: 0.8055555820465088)
[2025-02-04 02:59:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21456/23838 [22:28<14:55,  2.66it/s][2025-02-04 02:59:17][root][INFO] - Training Epoch: 2/2, step 21455/23838 completed (loss: 0.20809398591518402, acc: 0.9459459185600281)
[2025-02-04 02:59:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21457/23838 [22:28<15:43,  2.52it/s][2025-02-04 02:59:18][root][INFO] - Training Epoch: 2/2, step 21456/23838 completed (loss: 0.398039847612381, acc: 0.875)
[2025-02-04 02:59:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21458/23838 [22:29<16:27,  2.41it/s][2025-02-04 02:59:18][root][INFO] - Training Epoch: 2/2, step 21457/23838 completed (loss: 0.3510739803314209, acc: 0.8799999952316284)
[2025-02-04 02:59:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21459/23838 [22:29<15:22,  2.58it/s][2025-02-04 02:59:18][root][INFO] - Training Epoch: 2/2, step 21458/23838 completed (loss: 0.5476351976394653, acc: 0.8965517282485962)
[2025-02-04 02:59:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21460/23838 [22:29<16:01,  2.47it/s][2025-02-04 02:59:19][root][INFO] - Training Epoch: 2/2, step 21459/23838 completed (loss: 0.22623494267463684, acc: 0.9504132270812988)
[2025-02-04 02:59:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21461/23838 [22:30<16:15,  2.44it/s][2025-02-04 02:59:19][root][INFO] - Training Epoch: 2/2, step 21460/23838 completed (loss: 0.21712084114551544, acc: 0.9279999732971191)
[2025-02-04 02:59:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21462/23838 [22:30<16:29,  2.40it/s][2025-02-04 02:59:20][root][INFO] - Training Epoch: 2/2, step 21461/23838 completed (loss: 0.16578394174575806, acc: 0.975806474685669)
[2025-02-04 02:59:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21463/23838 [22:31<17:29,  2.26it/s][2025-02-04 02:59:20][root][INFO] - Training Epoch: 2/2, step 21462/23838 completed (loss: 0.29621678590774536, acc: 0.9356725215911865)
[2025-02-04 02:59:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21464/23838 [22:31<17:12,  2.30it/s][2025-02-04 02:59:21][root][INFO] - Training Epoch: 2/2, step 21463/23838 completed (loss: 0.1608772724866867, acc: 0.9655172228813171)
[2025-02-04 02:59:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21465/23838 [22:31<16:54,  2.34it/s][2025-02-04 02:59:21][root][INFO] - Training Epoch: 2/2, step 21464/23838 completed (loss: 0.1301199346780777, acc: 0.9589040875434875)
[2025-02-04 02:59:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21466/23838 [22:32<16:36,  2.38it/s][2025-02-04 02:59:21][root][INFO] - Training Epoch: 2/2, step 21465/23838 completed (loss: 0.2696520984172821, acc: 0.9189189076423645)
[2025-02-04 02:59:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21467/23838 [22:32<16:22,  2.41it/s][2025-02-04 02:59:22][root][INFO] - Training Epoch: 2/2, step 21466/23838 completed (loss: 0.3200840950012207, acc: 0.907216489315033)
[2025-02-04 02:59:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21468/23838 [22:33<16:17,  2.42it/s][2025-02-04 02:59:22][root][INFO] - Training Epoch: 2/2, step 21467/23838 completed (loss: 0.26039475202560425, acc: 0.9436619877815247)
[2025-02-04 02:59:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21469/23838 [22:33<15:52,  2.49it/s][2025-02-04 02:59:23][root][INFO] - Training Epoch: 2/2, step 21468/23838 completed (loss: 0.28427547216415405, acc: 0.8909090757369995)
[2025-02-04 02:59:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21470/23838 [22:33<15:48,  2.50it/s][2025-02-04 02:59:23][root][INFO] - Training Epoch: 2/2, step 21469/23838 completed (loss: 0.41182941198349, acc: 0.8970588445663452)
[2025-02-04 02:59:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21471/23838 [22:34<15:16,  2.58it/s][2025-02-04 02:59:23][root][INFO] - Training Epoch: 2/2, step 21470/23838 completed (loss: 0.1550212949514389, acc: 0.9494949579238892)
[2025-02-04 02:59:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21472/23838 [22:34<14:57,  2.64it/s][2025-02-04 02:59:24][root][INFO] - Training Epoch: 2/2, step 21471/23838 completed (loss: 0.25777238607406616, acc: 0.9230769276618958)
[2025-02-04 02:59:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21473/23838 [22:35<14:55,  2.64it/s][2025-02-04 02:59:24][root][INFO] - Training Epoch: 2/2, step 21472/23838 completed (loss: 0.4045587480068207, acc: 0.875)
[2025-02-04 02:59:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21474/23838 [22:35<14:38,  2.69it/s][2025-02-04 02:59:24][root][INFO] - Training Epoch: 2/2, step 21473/23838 completed (loss: 0.12808692455291748, acc: 0.9610389471054077)
[2025-02-04 02:59:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21475/23838 [22:35<14:45,  2.67it/s][2025-02-04 02:59:25][root][INFO] - Training Epoch: 2/2, step 21474/23838 completed (loss: 0.4024273455142975, acc: 0.8861788511276245)
[2025-02-04 02:59:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21476/23838 [22:36<14:24,  2.73it/s][2025-02-04 02:59:25][root][INFO] - Training Epoch: 2/2, step 21475/23838 completed (loss: 0.05163338780403137, acc: 0.9718309640884399)
[2025-02-04 02:59:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21477/23838 [22:36<13:59,  2.81it/s][2025-02-04 02:59:26][root][INFO] - Training Epoch: 2/2, step 21476/23838 completed (loss: 0.08733495324850082, acc: 0.9855072498321533)
[2025-02-04 02:59:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21478/23838 [22:36<15:35,  2.52it/s][2025-02-04 02:59:26][root][INFO] - Training Epoch: 2/2, step 21477/23838 completed (loss: 0.13253045082092285, acc: 0.9837398529052734)
[2025-02-04 02:59:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21479/23838 [22:37<16:04,  2.44it/s][2025-02-04 02:59:26][root][INFO] - Training Epoch: 2/2, step 21478/23838 completed (loss: 0.1160091906785965, acc: 0.9597315192222595)
[2025-02-04 02:59:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21480/23838 [22:37<16:46,  2.34it/s][2025-02-04 02:59:27][root][INFO] - Training Epoch: 2/2, step 21479/23838 completed (loss: 0.16510580480098724, acc: 0.930232584476471)
[2025-02-04 02:59:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21481/23838 [22:38<15:51,  2.48it/s][2025-02-04 02:59:27][root][INFO] - Training Epoch: 2/2, step 21480/23838 completed (loss: 0.7743286490440369, acc: 0.7876105904579163)
[2025-02-04 02:59:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21482/23838 [22:38<15:46,  2.49it/s][2025-02-04 02:59:28][root][INFO] - Training Epoch: 2/2, step 21481/23838 completed (loss: 0.13506056368350983, acc: 0.9800000190734863)
[2025-02-04 02:59:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21483/23838 [22:39<16:33,  2.37it/s][2025-02-04 02:59:28][root][INFO] - Training Epoch: 2/2, step 21482/23838 completed (loss: 0.1564977765083313, acc: 0.9615384340286255)
[2025-02-04 02:59:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21484/23838 [22:39<15:51,  2.47it/s][2025-02-04 02:59:29][root][INFO] - Training Epoch: 2/2, step 21483/23838 completed (loss: 0.11580243706703186, acc: 0.954023003578186)
[2025-02-04 02:59:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21485/23838 [22:39<15:16,  2.57it/s][2025-02-04 02:59:29][root][INFO] - Training Epoch: 2/2, step 21484/23838 completed (loss: 0.07303676009178162, acc: 0.9746835231781006)
[2025-02-04 02:59:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21486/23838 [22:40<14:41,  2.67it/s][2025-02-04 02:59:29][root][INFO] - Training Epoch: 2/2, step 21485/23838 completed (loss: 0.18685594201087952, acc: 0.9545454382896423)
[2025-02-04 02:59:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21487/23838 [22:40<14:45,  2.66it/s][2025-02-04 02:59:30][root][INFO] - Training Epoch: 2/2, step 21486/23838 completed (loss: 0.009396402165293694, acc: 1.0)
[2025-02-04 02:59:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21488/23838 [22:40<15:15,  2.57it/s][2025-02-04 02:59:30][root][INFO] - Training Epoch: 2/2, step 21487/23838 completed (loss: 0.4134157598018646, acc: 0.8918918967247009)
[2025-02-04 02:59:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21489/23838 [22:41<15:12,  2.57it/s][2025-02-04 02:59:30][root][INFO] - Training Epoch: 2/2, step 21488/23838 completed (loss: 0.2280615270137787, acc: 0.9473684430122375)
[2025-02-04 02:59:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21490/23838 [22:41<15:05,  2.59it/s][2025-02-04 02:59:31][root][INFO] - Training Epoch: 2/2, step 21489/23838 completed (loss: 0.4044164717197418, acc: 0.8648648858070374)
[2025-02-04 02:59:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21491/23838 [22:42<14:50,  2.64it/s][2025-02-04 02:59:31][root][INFO] - Training Epoch: 2/2, step 21490/23838 completed (loss: 0.3263576328754425, acc: 0.8863636255264282)
[2025-02-04 02:59:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21492/23838 [22:42<13:57,  2.80it/s][2025-02-04 02:59:31][root][INFO] - Training Epoch: 2/2, step 21491/23838 completed (loss: 0.3072422742843628, acc: 0.930232584476471)
[2025-02-04 02:59:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21493/23838 [22:42<13:29,  2.90it/s][2025-02-04 02:59:32][root][INFO] - Training Epoch: 2/2, step 21492/23838 completed (loss: 0.054299160838127136, acc: 1.0)
[2025-02-04 02:59:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21494/23838 [22:43<13:44,  2.84it/s][2025-02-04 02:59:32][root][INFO] - Training Epoch: 2/2, step 21493/23838 completed (loss: 0.321615993976593, acc: 0.8857142925262451)
[2025-02-04 02:59:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21495/23838 [22:43<17:57,  2.17it/s][2025-02-04 02:59:33][root][INFO] - Training Epoch: 2/2, step 21494/23838 completed (loss: 0.5786352753639221, acc: 0.8526315689086914)
[2025-02-04 02:59:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21496/23838 [22:44<16:40,  2.34it/s][2025-02-04 02:59:33][root][INFO] - Training Epoch: 2/2, step 21495/23838 completed (loss: 0.007550023961812258, acc: 1.0)
[2025-02-04 02:59:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21497/23838 [22:44<16:31,  2.36it/s][2025-02-04 02:59:34][root][INFO] - Training Epoch: 2/2, step 21496/23838 completed (loss: 0.14402058720588684, acc: 0.9672130942344666)
[2025-02-04 02:59:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21498/23838 [22:44<17:04,  2.28it/s][2025-02-04 02:59:34][root][INFO] - Training Epoch: 2/2, step 21497/23838 completed (loss: 0.13232479989528656, acc: 1.0)
[2025-02-04 02:59:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21499/23838 [22:45<17:09,  2.27it/s][2025-02-04 02:59:35][root][INFO] - Training Epoch: 2/2, step 21498/23838 completed (loss: 0.6417485475540161, acc: 0.8285714387893677)
[2025-02-04 02:59:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21500/23838 [22:45<17:04,  2.28it/s][2025-02-04 02:59:35][root][INFO] - Training Epoch: 2/2, step 21499/23838 completed (loss: 0.677516520023346, acc: 0.8292682766914368)
[2025-02-04 02:59:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21501/23838 [22:46<16:36,  2.34it/s][2025-02-04 02:59:35][root][INFO] - Training Epoch: 2/2, step 21500/23838 completed (loss: 0.16177859902381897, acc: 0.9545454382896423)
[2025-02-04 02:59:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21502/23838 [22:46<15:53,  2.45it/s][2025-02-04 02:59:36][root][INFO] - Training Epoch: 2/2, step 21501/23838 completed (loss: 0.1500164121389389, acc: 0.9444444179534912)
[2025-02-04 02:59:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21503/23838 [22:46<15:11,  2.56it/s][2025-02-04 02:59:36][root][INFO] - Training Epoch: 2/2, step 21502/23838 completed (loss: 0.016460344195365906, acc: 1.0)
[2025-02-04 02:59:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21504/23838 [22:47<15:23,  2.53it/s][2025-02-04 02:59:36][root][INFO] - Training Epoch: 2/2, step 21503/23838 completed (loss: 0.26998668909072876, acc: 0.8936170339584351)
[2025-02-04 02:59:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21505/23838 [22:47<14:27,  2.69it/s][2025-02-04 02:59:37][root][INFO] - Training Epoch: 2/2, step 21504/23838 completed (loss: 0.59103924036026, acc: 0.800000011920929)
[2025-02-04 02:59:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21506/23838 [22:48<13:55,  2.79it/s][2025-02-04 02:59:37][root][INFO] - Training Epoch: 2/2, step 21505/23838 completed (loss: 0.06374240666627884, acc: 1.0)
[2025-02-04 02:59:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21507/23838 [22:48<13:42,  2.83it/s][2025-02-04 02:59:37][root][INFO] - Training Epoch: 2/2, step 21506/23838 completed (loss: 0.2761431932449341, acc: 0.8684210777282715)
[2025-02-04 02:59:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21508/23838 [22:48<13:19,  2.91it/s][2025-02-04 02:59:38][root][INFO] - Training Epoch: 2/2, step 21507/23838 completed (loss: 0.011152450926601887, acc: 1.0)
[2025-02-04 02:59:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21509/23838 [22:49<13:08,  2.96it/s][2025-02-04 02:59:38][root][INFO] - Training Epoch: 2/2, step 21508/23838 completed (loss: 0.46168211102485657, acc: 0.9090909361839294)
[2025-02-04 02:59:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21510/23838 [22:49<13:33,  2.86it/s][2025-02-04 02:59:38][root][INFO] - Training Epoch: 2/2, step 21509/23838 completed (loss: 0.09868563711643219, acc: 0.9722222089767456)
[2025-02-04 02:59:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21511/23838 [22:49<13:20,  2.91it/s][2025-02-04 02:59:39][root][INFO] - Training Epoch: 2/2, step 21510/23838 completed (loss: 0.12362078577280045, acc: 0.9811320900917053)
[2025-02-04 02:59:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21512/23838 [22:50<13:38,  2.84it/s][2025-02-04 02:59:39][root][INFO] - Training Epoch: 2/2, step 21511/23838 completed (loss: 0.5042441487312317, acc: 0.800000011920929)
[2025-02-04 02:59:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21513/23838 [22:50<14:46,  2.62it/s][2025-02-04 02:59:40][root][INFO] - Training Epoch: 2/2, step 21512/23838 completed (loss: 0.04008963331580162, acc: 0.9811320900917053)
[2025-02-04 02:59:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21514/23838 [22:51<15:53,  2.44it/s][2025-02-04 02:59:40][root][INFO] - Training Epoch: 2/2, step 21513/23838 completed (loss: 0.5339239239692688, acc: 0.8823529481887817)
[2025-02-04 02:59:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21515/23838 [22:51<15:55,  2.43it/s][2025-02-04 02:59:41][root][INFO] - Training Epoch: 2/2, step 21514/23838 completed (loss: 0.04625937342643738, acc: 0.970588207244873)
[2025-02-04 02:59:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21516/23838 [22:52<18:02,  2.14it/s][2025-02-04 02:59:41][root][INFO] - Training Epoch: 2/2, step 21515/23838 completed (loss: 0.2515470087528229, acc: 0.9436619877815247)
[2025-02-04 02:59:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21517/23838 [22:52<17:11,  2.25it/s][2025-02-04 02:59:42][root][INFO] - Training Epoch: 2/2, step 21516/23838 completed (loss: 0.9084568023681641, acc: 0.7291666865348816)
[2025-02-04 02:59:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21518/23838 [22:52<17:35,  2.20it/s][2025-02-04 02:59:42][root][INFO] - Training Epoch: 2/2, step 21517/23838 completed (loss: 0.8171368837356567, acc: 0.796875)
[2025-02-04 02:59:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21519/23838 [22:53<17:09,  2.25it/s][2025-02-04 02:59:42][root][INFO] - Training Epoch: 2/2, step 21518/23838 completed (loss: 0.18649794161319733, acc: 0.9433962106704712)
[2025-02-04 02:59:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21520/23838 [22:53<16:12,  2.38it/s][2025-02-04 02:59:43][root][INFO] - Training Epoch: 2/2, step 21519/23838 completed (loss: 0.4682098925113678, acc: 0.9444444179534912)
[2025-02-04 02:59:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21521/23838 [22:54<16:05,  2.40it/s][2025-02-04 02:59:43][root][INFO] - Training Epoch: 2/2, step 21520/23838 completed (loss: 0.4432384967803955, acc: 0.9122806787490845)
[2025-02-04 02:59:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21522/23838 [22:54<16:10,  2.39it/s][2025-02-04 02:59:44][root][INFO] - Training Epoch: 2/2, step 21521/23838 completed (loss: 0.07431330531835556, acc: 0.9784946441650391)
[2025-02-04 02:59:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21523/23838 [22:55<17:10,  2.25it/s][2025-02-04 02:59:44][root][INFO] - Training Epoch: 2/2, step 21522/23838 completed (loss: 0.2390449047088623, acc: 0.9333333373069763)
[2025-02-04 02:59:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21524/23838 [22:55<17:46,  2.17it/s][2025-02-04 02:59:45][root][INFO] - Training Epoch: 2/2, step 21523/23838 completed (loss: 0.42637643218040466, acc: 0.9014084339141846)
[2025-02-04 02:59:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21525/23838 [22:56<17:55,  2.15it/s][2025-02-04 02:59:45][root][INFO] - Training Epoch: 2/2, step 21524/23838 completed (loss: 0.05913408100605011, acc: 0.9777777791023254)
[2025-02-04 02:59:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21526/23838 [22:56<17:23,  2.21it/s][2025-02-04 02:59:46][root][INFO] - Training Epoch: 2/2, step 21525/23838 completed (loss: 0.1856110543012619, acc: 0.9285714030265808)
[2025-02-04 02:59:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21527/23838 [22:56<17:25,  2.21it/s][2025-02-04 02:59:46][root][INFO] - Training Epoch: 2/2, step 21526/23838 completed (loss: 0.236575186252594, acc: 0.9444444179534912)
[2025-02-04 02:59:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21528/23838 [22:57<17:26,  2.21it/s][2025-02-04 02:59:46][root][INFO] - Training Epoch: 2/2, step 21527/23838 completed (loss: 0.02758154459297657, acc: 1.0)
[2025-02-04 02:59:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21529/23838 [22:57<16:26,  2.34it/s][2025-02-04 02:59:47][root][INFO] - Training Epoch: 2/2, step 21528/23838 completed (loss: 0.6786490082740784, acc: 0.9130434989929199)
[2025-02-04 02:59:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21530/23838 [22:58<16:04,  2.39it/s][2025-02-04 02:59:47][root][INFO] - Training Epoch: 2/2, step 21529/23838 completed (loss: 0.35041651129722595, acc: 0.9230769276618958)
[2025-02-04 02:59:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21531/23838 [22:58<16:26,  2.34it/s][2025-02-04 02:59:48][root][INFO] - Training Epoch: 2/2, step 21530/23838 completed (loss: 0.2748236358165741, acc: 0.9473684430122375)
[2025-02-04 02:59:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21532/23838 [22:58<16:20,  2.35it/s][2025-02-04 02:59:48][root][INFO] - Training Epoch: 2/2, step 21531/23838 completed (loss: 0.3963322639465332, acc: 0.9069767594337463)
[2025-02-04 02:59:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21533/23838 [22:59<15:24,  2.49it/s][2025-02-04 02:59:48][root][INFO] - Training Epoch: 2/2, step 21532/23838 completed (loss: 0.36271533370018005, acc: 0.8823529481887817)
[2025-02-04 02:59:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21534/23838 [22:59<14:40,  2.62it/s][2025-02-04 02:59:49][root][INFO] - Training Epoch: 2/2, step 21533/23838 completed (loss: 0.6888636350631714, acc: 0.7586206793785095)
[2025-02-04 02:59:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21535/23838 [23:00<14:27,  2.65it/s][2025-02-04 02:59:49][root][INFO] - Training Epoch: 2/2, step 21534/23838 completed (loss: 0.11545111238956451, acc: 1.0)
[2025-02-04 02:59:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21536/23838 [23:00<14:32,  2.64it/s][2025-02-04 02:59:49][root][INFO] - Training Epoch: 2/2, step 21535/23838 completed (loss: 0.1664074808359146, acc: 0.9756097793579102)
[2025-02-04 02:59:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21537/23838 [23:00<14:05,  2.72it/s][2025-02-04 02:59:50][root][INFO] - Training Epoch: 2/2, step 21536/23838 completed (loss: 0.4846353828907013, acc: 0.875)
[2025-02-04 02:59:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21538/23838 [23:01<13:30,  2.84it/s][2025-02-04 02:59:50][root][INFO] - Training Epoch: 2/2, step 21537/23838 completed (loss: 0.08239828795194626, acc: 0.9777777791023254)
[2025-02-04 02:59:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21539/23838 [23:01<13:16,  2.89it/s][2025-02-04 02:59:50][root][INFO] - Training Epoch: 2/2, step 21538/23838 completed (loss: 0.10683638602495193, acc: 0.976190447807312)
[2025-02-04 02:59:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21540/23838 [23:01<13:50,  2.77it/s][2025-02-04 02:59:51][root][INFO] - Training Epoch: 2/2, step 21539/23838 completed (loss: 0.024231521412730217, acc: 1.0)
[2025-02-04 02:59:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21541/23838 [23:02<13:38,  2.81it/s][2025-02-04 02:59:51][root][INFO] - Training Epoch: 2/2, step 21540/23838 completed (loss: 0.2853309214115143, acc: 0.9268292784690857)
[2025-02-04 02:59:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21542/23838 [23:02<13:58,  2.74it/s][2025-02-04 02:59:52][root][INFO] - Training Epoch: 2/2, step 21541/23838 completed (loss: 0.20837777853012085, acc: 0.9399999976158142)
[2025-02-04 02:59:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21543/23838 [23:02<14:20,  2.67it/s][2025-02-04 02:59:52][root][INFO] - Training Epoch: 2/2, step 21542/23838 completed (loss: 0.6509838700294495, acc: 0.8372092843055725)
[2025-02-04 02:59:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21544/23838 [23:03<13:47,  2.77it/s][2025-02-04 02:59:52][root][INFO] - Training Epoch: 2/2, step 21543/23838 completed (loss: 0.07237531989812851, acc: 1.0)
[2025-02-04 02:59:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21545/23838 [23:03<13:21,  2.86it/s][2025-02-04 02:59:53][root][INFO] - Training Epoch: 2/2, step 21544/23838 completed (loss: 0.9203383326530457, acc: 0.6666666865348816)
[2025-02-04 02:59:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21546/23838 [23:03<13:24,  2.85it/s][2025-02-04 02:59:53][root][INFO] - Training Epoch: 2/2, step 21545/23838 completed (loss: 0.23798389732837677, acc: 0.9411764740943909)
[2025-02-04 02:59:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21547/23838 [23:04<13:48,  2.77it/s][2025-02-04 02:59:53][root][INFO] - Training Epoch: 2/2, step 21546/23838 completed (loss: 0.07553627341985703, acc: 0.9746835231781006)
[2025-02-04 02:59:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21548/23838 [23:04<14:02,  2.72it/s][2025-02-04 02:59:54][root][INFO] - Training Epoch: 2/2, step 21547/23838 completed (loss: 0.3152545988559723, acc: 0.9166666865348816)
[2025-02-04 02:59:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21549/23838 [23:05<16:00,  2.38it/s][2025-02-04 02:59:54][root][INFO] - Training Epoch: 2/2, step 21548/23838 completed (loss: 0.4301479160785675, acc: 0.8769230842590332)
[2025-02-04 02:59:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21550/23838 [23:05<15:11,  2.51it/s][2025-02-04 02:59:55][root][INFO] - Training Epoch: 2/2, step 21549/23838 completed (loss: 0.787982702255249, acc: 0.7209302186965942)
[2025-02-04 02:59:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21551/23838 [23:06<17:17,  2.21it/s][2025-02-04 02:59:55][root][INFO] - Training Epoch: 2/2, step 21550/23838 completed (loss: 0.2990586757659912, acc: 0.9240506291389465)
[2025-02-04 02:59:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21552/23838 [23:06<16:25,  2.32it/s][2025-02-04 02:59:56][root][INFO] - Training Epoch: 2/2, step 21551/23838 completed (loss: 0.16229930520057678, acc: 0.9333333373069763)
[2025-02-04 02:59:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21553/23838 [23:06<15:50,  2.40it/s][2025-02-04 02:59:56][root][INFO] - Training Epoch: 2/2, step 21552/23838 completed (loss: 0.11499188840389252, acc: 0.9555555582046509)
[2025-02-04 02:59:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21554/23838 [23:07<16:19,  2.33it/s][2025-02-04 02:59:56][root][INFO] - Training Epoch: 2/2, step 21553/23838 completed (loss: 0.3489883840084076, acc: 0.8947368264198303)
[2025-02-04 02:59:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21555/23838 [23:07<16:46,  2.27it/s][2025-02-04 02:59:57][root][INFO] - Training Epoch: 2/2, step 21554/23838 completed (loss: 0.307087242603302, acc: 0.8846153616905212)
[2025-02-04 02:59:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21556/23838 [23:08<16:16,  2.34it/s][2025-02-04 02:59:57][root][INFO] - Training Epoch: 2/2, step 21555/23838 completed (loss: 0.1909332275390625, acc: 0.9636363387107849)
[2025-02-04 02:59:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21557/23838 [23:08<16:41,  2.28it/s][2025-02-04 02:59:58][root][INFO] - Training Epoch: 2/2, step 21556/23838 completed (loss: 0.3550149202346802, acc: 0.9387755393981934)
[2025-02-04 02:59:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21558/23838 [23:09<16:05,  2.36it/s][2025-02-04 02:59:58][root][INFO] - Training Epoch: 2/2, step 21557/23838 completed (loss: 0.08123242855072021, acc: 0.96875)
[2025-02-04 02:59:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21559/23838 [23:09<14:58,  2.54it/s][2025-02-04 02:59:59][root][INFO] - Training Epoch: 2/2, step 21558/23838 completed (loss: 0.041291676461696625, acc: 1.0)
[2025-02-04 02:59:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21560/23838 [23:09<14:50,  2.56it/s][2025-02-04 02:59:59][root][INFO] - Training Epoch: 2/2, step 21559/23838 completed (loss: 0.3906921446323395, acc: 0.8205128312110901)
[2025-02-04 02:59:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21561/23838 [23:10<15:19,  2.48it/s][2025-02-04 02:59:59][root][INFO] - Training Epoch: 2/2, step 21560/23838 completed (loss: 0.08001983910799026, acc: 0.9677419066429138)
[2025-02-04 03:00:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21562/23838 [23:10<17:00,  2.23it/s][2025-02-04 03:00:00][root][INFO] - Training Epoch: 2/2, step 21561/23838 completed (loss: 0.3975338637828827, acc: 0.8799999952316284)
[2025-02-04 03:00:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21563/23838 [23:11<17:15,  2.20it/s][2025-02-04 03:00:00][root][INFO] - Training Epoch: 2/2, step 21562/23838 completed (loss: 0.2173406481742859, acc: 0.9090909361839294)
[2025-02-04 03:00:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21564/23838 [23:11<17:08,  2.21it/s][2025-02-04 03:00:01][root][INFO] - Training Epoch: 2/2, step 21563/23838 completed (loss: 0.4316318929195404, acc: 0.8987341523170471)
[2025-02-04 03:00:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21565/23838 [23:12<16:06,  2.35it/s][2025-02-04 03:00:01][root][INFO] - Training Epoch: 2/2, step 21564/23838 completed (loss: 0.22078143060207367, acc: 0.9038461446762085)
[2025-02-04 03:00:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21566/23838 [23:12<15:52,  2.39it/s][2025-02-04 03:00:02][root][INFO] - Training Epoch: 2/2, step 21565/23838 completed (loss: 0.33983081579208374, acc: 0.8918918967247009)
[2025-02-04 03:00:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21567/23838 [23:12<15:53,  2.38it/s][2025-02-04 03:00:02][root][INFO] - Training Epoch: 2/2, step 21566/23838 completed (loss: 0.46104323863983154, acc: 0.8799999952316284)
[2025-02-04 03:00:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21568/23838 [23:13<15:44,  2.40it/s][2025-02-04 03:00:02][root][INFO] - Training Epoch: 2/2, step 21567/23838 completed (loss: 0.18905508518218994, acc: 0.930232584476471)
[2025-02-04 03:00:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21569/23838 [23:13<16:28,  2.29it/s][2025-02-04 03:00:03][root][INFO] - Training Epoch: 2/2, step 21568/23838 completed (loss: 0.15094998478889465, acc: 0.9523809552192688)
[2025-02-04 03:00:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21570/23838 [23:14<16:24,  2.30it/s][2025-02-04 03:00:03][root][INFO] - Training Epoch: 2/2, step 21569/23838 completed (loss: 0.10248853266239166, acc: 0.9756097793579102)
[2025-02-04 03:00:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21571/23838 [23:14<16:05,  2.35it/s][2025-02-04 03:00:04][root][INFO] - Training Epoch: 2/2, step 21570/23838 completed (loss: 0.1217569038271904, acc: 0.9726027250289917)
[2025-02-04 03:00:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21572/23838 [23:15<16:04,  2.35it/s][2025-02-04 03:00:04][root][INFO] - Training Epoch: 2/2, step 21571/23838 completed (loss: 0.047137029469013214, acc: 1.0)
[2025-02-04 03:00:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  90%|[34m█████████ [0m| 21573/23838 [23:15<15:08,  2.49it/s][2025-02-04 03:00:04][root][INFO] - Training Epoch: 2/2, step 21572/23838 completed (loss: 0.20377422869205475, acc: 0.9714285731315613)
[2025-02-04 03:00:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21574/23838 [23:16<18:16,  2.06it/s][2025-02-04 03:00:05][root][INFO] - Training Epoch: 2/2, step 21573/23838 completed (loss: 0.22381898760795593, acc: 0.9263157844543457)
[2025-02-04 03:00:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21575/23838 [23:16<17:57,  2.10it/s][2025-02-04 03:00:06][root][INFO] - Training Epoch: 2/2, step 21574/23838 completed (loss: 0.07389503717422485, acc: 0.970588207244873)
[2025-02-04 03:00:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21576/23838 [23:17<18:35,  2.03it/s][2025-02-04 03:00:06][root][INFO] - Training Epoch: 2/2, step 21575/23838 completed (loss: 0.134315624833107, acc: 0.9634146094322205)
[2025-02-04 03:00:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21577/23838 [23:17<19:45,  1.91it/s][2025-02-04 03:00:07][root][INFO] - Training Epoch: 2/2, step 21576/23838 completed (loss: 0.28737184405326843, acc: 0.9189189076423645)
[2025-02-04 03:00:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21578/23838 [23:18<22:15,  1.69it/s][2025-02-04 03:00:07][root][INFO] - Training Epoch: 2/2, step 21577/23838 completed (loss: 0.09841694682836533, acc: 0.9428571462631226)
[2025-02-04 03:00:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21579/23838 [23:18<20:16,  1.86it/s][2025-02-04 03:00:08][root][INFO] - Training Epoch: 2/2, step 21578/23838 completed (loss: 0.09387921541929245, acc: 0.9583333134651184)
[2025-02-04 03:00:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21580/23838 [23:19<19:41,  1.91it/s][2025-02-04 03:00:08][root][INFO] - Training Epoch: 2/2, step 21579/23838 completed (loss: 0.36840543150901794, acc: 0.9215686321258545)
[2025-02-04 03:00:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21581/23838 [23:19<18:21,  2.05it/s][2025-02-04 03:00:09][root][INFO] - Training Epoch: 2/2, step 21580/23838 completed (loss: 0.11342321336269379, acc: 0.9583333134651184)
[2025-02-04 03:00:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21582/23838 [23:20<16:58,  2.21it/s][2025-02-04 03:00:09][root][INFO] - Training Epoch: 2/2, step 21581/23838 completed (loss: 0.6505641341209412, acc: 0.8541666865348816)
[2025-02-04 03:00:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21583/23838 [23:20<16:08,  2.33it/s][2025-02-04 03:00:10][root][INFO] - Training Epoch: 2/2, step 21582/23838 completed (loss: 0.17416635155677795, acc: 0.9545454382896423)
[2025-02-04 03:00:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21584/23838 [23:20<15:21,  2.45it/s][2025-02-04 03:00:10][root][INFO] - Training Epoch: 2/2, step 21583/23838 completed (loss: 0.20875218510627747, acc: 0.9306930899620056)
[2025-02-04 03:00:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21585/23838 [23:21<14:43,  2.55it/s][2025-02-04 03:00:10][root][INFO] - Training Epoch: 2/2, step 21584/23838 completed (loss: 0.5250926613807678, acc: 0.8778625726699829)
[2025-02-04 03:00:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21586/23838 [23:21<14:54,  2.52it/s][2025-02-04 03:00:11][root][INFO] - Training Epoch: 2/2, step 21585/23838 completed (loss: 0.14843028783798218, acc: 0.9516128897666931)
[2025-02-04 03:00:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21587/23838 [23:21<14:46,  2.54it/s][2025-02-04 03:00:11][root][INFO] - Training Epoch: 2/2, step 21586/23838 completed (loss: 0.37856701016426086, acc: 0.8933333158493042)
[2025-02-04 03:00:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21588/23838 [23:22<14:51,  2.52it/s][2025-02-04 03:00:11][root][INFO] - Training Epoch: 2/2, step 21587/23838 completed (loss: 0.36893147230148315, acc: 0.9175257682800293)
[2025-02-04 03:00:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21589/23838 [23:22<14:50,  2.53it/s][2025-02-04 03:00:12][root][INFO] - Training Epoch: 2/2, step 21588/23838 completed (loss: 0.6966370940208435, acc: 0.8484848737716675)
[2025-02-04 03:00:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21590/23838 [23:23<14:54,  2.51it/s][2025-02-04 03:00:12][root][INFO] - Training Epoch: 2/2, step 21589/23838 completed (loss: 0.3440822958946228, acc: 0.9103448390960693)
[2025-02-04 03:00:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21591/23838 [23:23<14:23,  2.60it/s][2025-02-04 03:00:13][root][INFO] - Training Epoch: 2/2, step 21590/23838 completed (loss: 0.3781628906726837, acc: 0.8888888955116272)
[2025-02-04 03:00:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21592/23838 [23:23<14:29,  2.58it/s][2025-02-04 03:00:13][root][INFO] - Training Epoch: 2/2, step 21591/23838 completed (loss: 0.22446182370185852, acc: 0.9277108311653137)
[2025-02-04 03:00:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21593/23838 [23:24<14:49,  2.52it/s][2025-02-04 03:00:13][root][INFO] - Training Epoch: 2/2, step 21592/23838 completed (loss: 0.12268130481243134, acc: 0.9375)
[2025-02-04 03:00:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21594/23838 [23:24<14:56,  2.50it/s][2025-02-04 03:00:14][root][INFO] - Training Epoch: 2/2, step 21593/23838 completed (loss: 0.4368145763874054, acc: 0.9047619104385376)
[2025-02-04 03:00:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21595/23838 [23:25<14:40,  2.55it/s][2025-02-04 03:00:14][root][INFO] - Training Epoch: 2/2, step 21594/23838 completed (loss: 0.2013559490442276, acc: 0.9599999785423279)
[2025-02-04 03:00:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21596/23838 [23:25<14:18,  2.61it/s][2025-02-04 03:00:15][root][INFO] - Training Epoch: 2/2, step 21595/23838 completed (loss: 0.18087896704673767, acc: 0.9322034120559692)
[2025-02-04 03:00:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21597/23838 [23:25<14:00,  2.67it/s][2025-02-04 03:00:15][root][INFO] - Training Epoch: 2/2, step 21596/23838 completed (loss: 0.24616223573684692, acc: 0.9156626462936401)
[2025-02-04 03:00:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21598/23838 [23:26<13:50,  2.70it/s][2025-02-04 03:00:15][root][INFO] - Training Epoch: 2/2, step 21597/23838 completed (loss: 0.28197181224823, acc: 0.9299362897872925)
[2025-02-04 03:00:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21599/23838 [23:26<13:52,  2.69it/s][2025-02-04 03:00:16][root][INFO] - Training Epoch: 2/2, step 21598/23838 completed (loss: 0.10396216064691544, acc: 0.9803921580314636)
[2025-02-04 03:00:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21600/23838 [23:27<14:48,  2.52it/s][2025-02-04 03:00:16][root][INFO] - Training Epoch: 2/2, step 21599/23838 completed (loss: 0.3547314405441284, acc: 0.9074074029922485)
[2025-02-04 03:00:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21601/23838 [23:27<14:45,  2.53it/s][2025-02-04 03:00:17][root][INFO] - Training Epoch: 2/2, step 21600/23838 completed (loss: 0.1889307200908661, acc: 0.9193548560142517)
[2025-02-04 03:00:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21602/23838 [23:27<14:34,  2.56it/s][2025-02-04 03:00:17][root][INFO] - Training Epoch: 2/2, step 21601/23838 completed (loss: 0.2243274599313736, acc: 0.9387755393981934)
[2025-02-04 03:00:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21603/23838 [23:28<14:25,  2.58it/s][2025-02-04 03:00:17][root][INFO] - Training Epoch: 2/2, step 21602/23838 completed (loss: 0.07794300466775894, acc: 0.96875)
[2025-02-04 03:00:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21604/23838 [23:28<14:00,  2.66it/s][2025-02-04 03:00:18][root][INFO] - Training Epoch: 2/2, step 21603/23838 completed (loss: 0.19126436114311218, acc: 0.9550561904907227)
[2025-02-04 03:00:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21605/23838 [23:28<13:59,  2.66it/s][2025-02-04 03:00:18][root][INFO] - Training Epoch: 2/2, step 21604/23838 completed (loss: 0.14571386575698853, acc: 0.9729729890823364)
[2025-02-04 03:00:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21606/23838 [23:29<13:53,  2.68it/s][2025-02-04 03:00:18][root][INFO] - Training Epoch: 2/2, step 21605/23838 completed (loss: 0.2778029441833496, acc: 0.9139785170555115)
[2025-02-04 03:00:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21607/23838 [23:29<13:44,  2.70it/s][2025-02-04 03:00:19][root][INFO] - Training Epoch: 2/2, step 21606/23838 completed (loss: 0.0783640444278717, acc: 0.9876543283462524)
[2025-02-04 03:00:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21608/23838 [23:29<13:23,  2.78it/s][2025-02-04 03:00:19][root][INFO] - Training Epoch: 2/2, step 21607/23838 completed (loss: 0.18414722383022308, acc: 0.9718309640884399)
[2025-02-04 03:00:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21609/23838 [23:30<13:19,  2.79it/s][2025-02-04 03:00:19][root][INFO] - Training Epoch: 2/2, step 21608/23838 completed (loss: 0.26263344287872314, acc: 0.9305555820465088)
[2025-02-04 03:00:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21610/23838 [23:30<13:23,  2.77it/s][2025-02-04 03:00:20][root][INFO] - Training Epoch: 2/2, step 21609/23838 completed (loss: 0.4879691004753113, acc: 0.9029126167297363)
[2025-02-04 03:00:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21611/23838 [23:31<13:42,  2.71it/s][2025-02-04 03:00:20][root][INFO] - Training Epoch: 2/2, step 21610/23838 completed (loss: 0.5684374570846558, acc: 0.8032786846160889)
[2025-02-04 03:00:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21612/23838 [23:31<13:24,  2.77it/s][2025-02-04 03:00:21][root][INFO] - Training Epoch: 2/2, step 21611/23838 completed (loss: 0.3769945800304413, acc: 0.89552241563797)
[2025-02-04 03:00:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21613/23838 [23:31<13:28,  2.75it/s][2025-02-04 03:00:21][root][INFO] - Training Epoch: 2/2, step 21612/23838 completed (loss: 0.2959069311618805, acc: 0.9101123809814453)
[2025-02-04 03:00:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21614/23838 [23:32<13:46,  2.69it/s][2025-02-04 03:00:21][root][INFO] - Training Epoch: 2/2, step 21613/23838 completed (loss: 0.4981899857521057, acc: 0.8823529481887817)
[2025-02-04 03:00:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21615/23838 [23:32<13:32,  2.74it/s][2025-02-04 03:00:22][root][INFO] - Training Epoch: 2/2, step 21614/23838 completed (loss: 0.07563208788633347, acc: 0.9583333134651184)
[2025-02-04 03:00:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21616/23838 [23:32<13:15,  2.79it/s][2025-02-04 03:00:22][root][INFO] - Training Epoch: 2/2, step 21615/23838 completed (loss: 0.06626344472169876, acc: 0.9821428656578064)
[2025-02-04 03:00:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21617/23838 [23:33<13:14,  2.79it/s][2025-02-04 03:00:22][root][INFO] - Training Epoch: 2/2, step 21616/23838 completed (loss: 0.2099706530570984, acc: 0.9523809552192688)
[2025-02-04 03:00:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21618/23838 [23:33<13:07,  2.82it/s][2025-02-04 03:00:23][root][INFO] - Training Epoch: 2/2, step 21617/23838 completed (loss: 0.23915676772594452, acc: 0.9450549483299255)
[2025-02-04 03:00:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21619/23838 [23:33<12:50,  2.88it/s][2025-02-04 03:00:23][root][INFO] - Training Epoch: 2/2, step 21618/23838 completed (loss: 0.31567874550819397, acc: 0.918181836605072)
[2025-02-04 03:00:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21620/23838 [23:34<12:14,  3.02it/s][2025-02-04 03:00:23][root][INFO] - Training Epoch: 2/2, step 21619/23838 completed (loss: 0.5882355570793152, acc: 0.8474576473236084)
[2025-02-04 03:00:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21621/23838 [23:34<12:10,  3.03it/s][2025-02-04 03:00:24][root][INFO] - Training Epoch: 2/2, step 21620/23838 completed (loss: 0.25524911284446716, acc: 0.8714285492897034)
[2025-02-04 03:00:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21622/23838 [23:34<12:48,  2.88it/s][2025-02-04 03:00:24][root][INFO] - Training Epoch: 2/2, step 21621/23838 completed (loss: 0.09070569276809692, acc: 0.9800000190734863)
[2025-02-04 03:00:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21623/23838 [23:35<12:39,  2.92it/s][2025-02-04 03:00:24][root][INFO] - Training Epoch: 2/2, step 21622/23838 completed (loss: 0.21989372372627258, acc: 0.9405940771102905)
[2025-02-04 03:00:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21624/23838 [23:35<12:26,  2.97it/s][2025-02-04 03:00:25][root][INFO] - Training Epoch: 2/2, step 21623/23838 completed (loss: 0.4751022756099701, acc: 0.9014084339141846)
[2025-02-04 03:00:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21625/23838 [23:35<12:23,  2.98it/s][2025-02-04 03:00:25][root][INFO] - Training Epoch: 2/2, step 21624/23838 completed (loss: 0.15964311361312866, acc: 0.9558823704719543)
[2025-02-04 03:00:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21626/23838 [23:36<13:26,  2.74it/s][2025-02-04 03:00:25][root][INFO] - Training Epoch: 2/2, step 21625/23838 completed (loss: 0.6537953019142151, acc: 0.8539325594902039)
[2025-02-04 03:00:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21627/23838 [23:36<13:34,  2.71it/s][2025-02-04 03:00:26][root][INFO] - Training Epoch: 2/2, step 21626/23838 completed (loss: 0.39841848611831665, acc: 0.890625)
[2025-02-04 03:00:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21628/23838 [23:37<13:25,  2.74it/s][2025-02-04 03:00:26][root][INFO] - Training Epoch: 2/2, step 21627/23838 completed (loss: 0.24268846213817596, acc: 0.9210526347160339)
[2025-02-04 03:00:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21629/23838 [23:37<13:24,  2.75it/s][2025-02-04 03:00:27][root][INFO] - Training Epoch: 2/2, step 21628/23838 completed (loss: 0.16226281225681305, acc: 0.978723406791687)
[2025-02-04 03:00:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21630/23838 [23:37<13:22,  2.75it/s][2025-02-04 03:00:27][root][INFO] - Training Epoch: 2/2, step 21629/23838 completed (loss: 0.20576609671115875, acc: 0.9469026327133179)
[2025-02-04 03:00:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21631/23838 [23:38<13:23,  2.75it/s][2025-02-04 03:00:27][root][INFO] - Training Epoch: 2/2, step 21630/23838 completed (loss: 0.0742315948009491, acc: 0.9727891087532043)
[2025-02-04 03:00:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21632/23838 [23:38<13:43,  2.68it/s][2025-02-04 03:00:28][root][INFO] - Training Epoch: 2/2, step 21631/23838 completed (loss: 0.5541348457336426, acc: 0.8527131676673889)
[2025-02-04 03:00:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21633/23838 [23:38<14:20,  2.56it/s][2025-02-04 03:00:28][root][INFO] - Training Epoch: 2/2, step 21632/23838 completed (loss: 0.40088483691215515, acc: 0.8865979313850403)
[2025-02-04 03:00:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21634/23838 [23:39<13:50,  2.65it/s][2025-02-04 03:00:28][root][INFO] - Training Epoch: 2/2, step 21633/23838 completed (loss: 0.1849394142627716, acc: 0.9740259647369385)
[2025-02-04 03:00:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21635/23838 [23:39<13:50,  2.65it/s][2025-02-04 03:00:29][root][INFO] - Training Epoch: 2/2, step 21634/23838 completed (loss: 0.13528048992156982, acc: 0.9491525292396545)
[2025-02-04 03:00:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21636/23838 [23:40<13:25,  2.73it/s][2025-02-04 03:00:29][root][INFO] - Training Epoch: 2/2, step 21635/23838 completed (loss: 0.2897200584411621, acc: 0.9333333373069763)
[2025-02-04 03:00:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21637/23838 [23:40<13:33,  2.71it/s][2025-02-04 03:00:30][root][INFO] - Training Epoch: 2/2, step 21636/23838 completed (loss: 0.24844138324260712, acc: 0.954954981803894)
[2025-02-04 03:00:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21638/23838 [23:40<12:59,  2.82it/s][2025-02-04 03:00:30][root][INFO] - Training Epoch: 2/2, step 21637/23838 completed (loss: 0.323474645614624, acc: 0.9411764740943909)
[2025-02-04 03:00:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21639/23838 [23:41<13:03,  2.81it/s][2025-02-04 03:00:30][root][INFO] - Training Epoch: 2/2, step 21638/23838 completed (loss: 0.221259206533432, acc: 0.9333333373069763)
[2025-02-04 03:00:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21640/23838 [23:41<12:58,  2.83it/s][2025-02-04 03:00:31][root][INFO] - Training Epoch: 2/2, step 21639/23838 completed (loss: 0.2097967267036438, acc: 0.9479166865348816)
[2025-02-04 03:00:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21641/23838 [23:41<13:02,  2.81it/s][2025-02-04 03:00:31][root][INFO] - Training Epoch: 2/2, step 21640/23838 completed (loss: 0.3117614686489105, acc: 0.9215686321258545)
[2025-02-04 03:00:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21642/23838 [23:42<12:57,  2.82it/s][2025-02-04 03:00:31][root][INFO] - Training Epoch: 2/2, step 21641/23838 completed (loss: 0.37188956141471863, acc: 0.9158878326416016)
[2025-02-04 03:00:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21643/23838 [23:42<12:47,  2.86it/s][2025-02-04 03:00:32][root][INFO] - Training Epoch: 2/2, step 21642/23838 completed (loss: 0.6745980978012085, acc: 0.8023256063461304)
[2025-02-04 03:00:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21644/23838 [23:42<13:12,  2.77it/s][2025-02-04 03:00:32][root][INFO] - Training Epoch: 2/2, step 21643/23838 completed (loss: 0.3260195553302765, acc: 0.9122806787490845)
[2025-02-04 03:00:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21645/23838 [23:43<14:22,  2.54it/s][2025-02-04 03:00:32][root][INFO] - Training Epoch: 2/2, step 21644/23838 completed (loss: 0.20280040800571442, acc: 0.930232584476471)
[2025-02-04 03:00:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21646/23838 [23:43<13:49,  2.64it/s][2025-02-04 03:00:33][root][INFO] - Training Epoch: 2/2, step 21645/23838 completed (loss: 0.25915226340293884, acc: 0.9117646813392639)
[2025-02-04 03:00:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21647/23838 [23:44<13:25,  2.72it/s][2025-02-04 03:00:33][root][INFO] - Training Epoch: 2/2, step 21646/23838 completed (loss: 0.17414695024490356, acc: 0.9589040875434875)
[2025-02-04 03:00:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21648/23838 [23:44<13:13,  2.76it/s][2025-02-04 03:00:33][root][INFO] - Training Epoch: 2/2, step 21647/23838 completed (loss: 0.33184224367141724, acc: 0.9074074029922485)
[2025-02-04 03:00:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21649/23838 [23:44<12:49,  2.84it/s][2025-02-04 03:00:34][root][INFO] - Training Epoch: 2/2, step 21648/23838 completed (loss: 0.24000388383865356, acc: 0.9175257682800293)
[2025-02-04 03:00:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21650/23838 [23:45<12:39,  2.88it/s][2025-02-04 03:00:34][root][INFO] - Training Epoch: 2/2, step 21649/23838 completed (loss: 0.30864280462265015, acc: 0.8823529481887817)
[2025-02-04 03:00:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21651/23838 [23:45<12:38,  2.89it/s][2025-02-04 03:00:34][root][INFO] - Training Epoch: 2/2, step 21650/23838 completed (loss: 0.1824704110622406, acc: 0.9702970385551453)
[2025-02-04 03:00:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21652/23838 [23:45<12:34,  2.90it/s][2025-02-04 03:00:35][root][INFO] - Training Epoch: 2/2, step 21651/23838 completed (loss: 0.1528729647397995, acc: 0.9670329689979553)
[2025-02-04 03:00:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21653/23838 [23:46<12:29,  2.92it/s][2025-02-04 03:00:35][root][INFO] - Training Epoch: 2/2, step 21652/23838 completed (loss: 0.6078812479972839, acc: 0.8205128312110901)
[2025-02-04 03:00:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21654/23838 [23:46<12:45,  2.85it/s][2025-02-04 03:00:36][root][INFO] - Training Epoch: 2/2, step 21653/23838 completed (loss: 0.18804426491260529, acc: 0.9438202381134033)
[2025-02-04 03:00:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21655/23838 [23:46<12:19,  2.95it/s][2025-02-04 03:00:36][root][INFO] - Training Epoch: 2/2, step 21654/23838 completed (loss: 0.5730568766593933, acc: 0.84375)
[2025-02-04 03:00:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21656/23838 [23:47<12:31,  2.90it/s][2025-02-04 03:00:36][root][INFO] - Training Epoch: 2/2, step 21655/23838 completed (loss: 0.17803087830543518, acc: 0.9545454382896423)
[2025-02-04 03:00:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21657/23838 [23:47<14:16,  2.55it/s][2025-02-04 03:00:37][root][INFO] - Training Epoch: 2/2, step 21656/23838 completed (loss: 0.12890192866325378, acc: 0.9741935729980469)
[2025-02-04 03:00:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21658/23838 [23:48<14:05,  2.58it/s][2025-02-04 03:00:37][root][INFO] - Training Epoch: 2/2, step 21657/23838 completed (loss: 0.257183313369751, acc: 0.9222221970558167)
[2025-02-04 03:00:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21659/23838 [23:48<14:19,  2.53it/s][2025-02-04 03:00:37][root][INFO] - Training Epoch: 2/2, step 21658/23838 completed (loss: 0.44934436678886414, acc: 0.8495575189590454)
[2025-02-04 03:00:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21660/23838 [23:48<13:35,  2.67it/s][2025-02-04 03:00:38][root][INFO] - Training Epoch: 2/2, step 21659/23838 completed (loss: 0.5284427404403687, acc: 0.8461538553237915)
[2025-02-04 03:00:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21661/23838 [23:49<13:26,  2.70it/s][2025-02-04 03:00:38][root][INFO] - Training Epoch: 2/2, step 21660/23838 completed (loss: 0.584518313407898, acc: 0.8507462739944458)
[2025-02-04 03:00:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21662/23838 [23:49<13:19,  2.72it/s][2025-02-04 03:00:39][root][INFO] - Training Epoch: 2/2, step 21661/23838 completed (loss: 0.09151066839694977, acc: 0.9599999785423279)
[2025-02-04 03:00:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21663/23838 [23:49<13:31,  2.68it/s][2025-02-04 03:00:39][root][INFO] - Training Epoch: 2/2, step 21662/23838 completed (loss: 0.21231427788734436, acc: 0.9629629850387573)
[2025-02-04 03:00:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21664/23838 [23:50<13:14,  2.74it/s][2025-02-04 03:00:39][root][INFO] - Training Epoch: 2/2, step 21663/23838 completed (loss: 0.5862302780151367, acc: 0.8823529481887817)
[2025-02-04 03:00:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21665/23838 [23:50<13:02,  2.78it/s][2025-02-04 03:00:40][root][INFO] - Training Epoch: 2/2, step 21664/23838 completed (loss: 0.21766838431358337, acc: 0.9772727489471436)
[2025-02-04 03:00:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21666/23838 [23:50<12:33,  2.88it/s][2025-02-04 03:00:40][root][INFO] - Training Epoch: 2/2, step 21665/23838 completed (loss: 0.07778903096914291, acc: 0.957446813583374)
[2025-02-04 03:00:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21667/23838 [23:51<12:50,  2.82it/s][2025-02-04 03:00:40][root][INFO] - Training Epoch: 2/2, step 21666/23838 completed (loss: 0.13464412093162537, acc: 0.9459459185600281)
[2025-02-04 03:00:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21668/23838 [23:51<12:55,  2.80it/s][2025-02-04 03:00:41][root][INFO] - Training Epoch: 2/2, step 21667/23838 completed (loss: 0.5461528301239014, acc: 0.8983050584793091)
[2025-02-04 03:00:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21669/23838 [23:51<13:08,  2.75it/s][2025-02-04 03:00:41][root][INFO] - Training Epoch: 2/2, step 21668/23838 completed (loss: 0.3433709740638733, acc: 0.875)
[2025-02-04 03:00:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21670/23838 [23:52<12:55,  2.79it/s][2025-02-04 03:00:41][root][INFO] - Training Epoch: 2/2, step 21669/23838 completed (loss: 0.165574848651886, acc: 0.9696969985961914)
[2025-02-04 03:00:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21671/23838 [23:52<13:37,  2.65it/s][2025-02-04 03:00:42][root][INFO] - Training Epoch: 2/2, step 21670/23838 completed (loss: 1.2920926809310913, acc: 0.6666666865348816)
[2025-02-04 03:00:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21672/23838 [23:53<13:15,  2.72it/s][2025-02-04 03:00:42][root][INFO] - Training Epoch: 2/2, step 21671/23838 completed (loss: 0.3545384705066681, acc: 0.875)
[2025-02-04 03:00:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21673/23838 [23:53<12:59,  2.78it/s][2025-02-04 03:00:43][root][INFO] - Training Epoch: 2/2, step 21672/23838 completed (loss: 0.5570027828216553, acc: 0.8709677457809448)
[2025-02-04 03:00:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21674/23838 [23:53<13:10,  2.74it/s][2025-02-04 03:00:43][root][INFO] - Training Epoch: 2/2, step 21673/23838 completed (loss: 0.20980370044708252, acc: 0.9473684430122375)
[2025-02-04 03:00:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21675/23838 [23:54<12:41,  2.84it/s][2025-02-04 03:00:43][root][INFO] - Training Epoch: 2/2, step 21674/23838 completed (loss: 0.34213635325431824, acc: 0.8653846383094788)
[2025-02-04 03:00:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21676/23838 [23:54<12:49,  2.81it/s][2025-02-04 03:00:44][root][INFO] - Training Epoch: 2/2, step 21675/23838 completed (loss: 0.651827335357666, acc: 0.8611111044883728)
[2025-02-04 03:00:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21677/23838 [23:54<13:05,  2.75it/s][2025-02-04 03:00:44][root][INFO] - Training Epoch: 2/2, step 21676/23838 completed (loss: 0.4585496187210083, acc: 0.8857142925262451)
[2025-02-04 03:00:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21678/23838 [23:55<13:08,  2.74it/s][2025-02-04 03:00:44][root][INFO] - Training Epoch: 2/2, step 21677/23838 completed (loss: 0.24180418252944946, acc: 0.8846153616905212)
[2025-02-04 03:00:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21679/23838 [23:55<12:31,  2.87it/s][2025-02-04 03:00:45][root][INFO] - Training Epoch: 2/2, step 21678/23838 completed (loss: 0.1849256306886673, acc: 0.9193548560142517)
[2025-02-04 03:00:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21680/23838 [23:55<12:34,  2.86it/s][2025-02-04 03:00:45][root][INFO] - Training Epoch: 2/2, step 21679/23838 completed (loss: 0.46833422780036926, acc: 0.804347813129425)
[2025-02-04 03:00:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21681/23838 [23:56<13:15,  2.71it/s][2025-02-04 03:00:45][root][INFO] - Training Epoch: 2/2, step 21680/23838 completed (loss: 0.6808829307556152, acc: 0.8125)
[2025-02-04 03:00:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21682/23838 [23:56<13:33,  2.65it/s][2025-02-04 03:00:46][root][INFO] - Training Epoch: 2/2, step 21681/23838 completed (loss: 0.39609670639038086, acc: 0.9333333373069763)
[2025-02-04 03:00:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21683/23838 [23:57<13:40,  2.63it/s][2025-02-04 03:00:46][root][INFO] - Training Epoch: 2/2, step 21682/23838 completed (loss: 0.20464937388896942, acc: 0.949999988079071)
[2025-02-04 03:00:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21684/23838 [23:57<14:14,  2.52it/s][2025-02-04 03:00:47][root][INFO] - Training Epoch: 2/2, step 21683/23838 completed (loss: 0.46934807300567627, acc: 0.875)
[2025-02-04 03:00:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21685/23838 [23:57<13:36,  2.64it/s][2025-02-04 03:00:47][root][INFO] - Training Epoch: 2/2, step 21684/23838 completed (loss: 0.7241154313087463, acc: 0.7777777910232544)
[2025-02-04 03:00:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21686/23838 [23:58<12:54,  2.78it/s][2025-02-04 03:00:47][root][INFO] - Training Epoch: 2/2, step 21685/23838 completed (loss: 0.5483201146125793, acc: 0.84375)
[2025-02-04 03:00:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21687/23838 [23:58<12:08,  2.95it/s][2025-02-04 03:00:48][root][INFO] - Training Epoch: 2/2, step 21686/23838 completed (loss: 0.649048388004303, acc: 0.7916666865348816)
[2025-02-04 03:00:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21688/23838 [23:58<12:20,  2.90it/s][2025-02-04 03:00:48][root][INFO] - Training Epoch: 2/2, step 21687/23838 completed (loss: 1.717111349105835, acc: 0.5714285969734192)
[2025-02-04 03:00:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21689/23838 [23:59<12:19,  2.90it/s][2025-02-04 03:00:48][root][INFO] - Training Epoch: 2/2, step 21688/23838 completed (loss: 0.33702147006988525, acc: 0.8999999761581421)
[2025-02-04 03:00:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21690/23838 [23:59<11:59,  2.99it/s][2025-02-04 03:00:49][root][INFO] - Training Epoch: 2/2, step 21689/23838 completed (loss: 0.4814121127128601, acc: 0.8235294222831726)
[2025-02-04 03:00:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21691/23838 [23:59<12:04,  2.96it/s][2025-02-04 03:00:49][root][INFO] - Training Epoch: 2/2, step 21690/23838 completed (loss: 0.23172889649868011, acc: 0.8965517282485962)
[2025-02-04 03:00:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21692/23838 [24:00<12:09,  2.94it/s][2025-02-04 03:00:49][root][INFO] - Training Epoch: 2/2, step 21691/23838 completed (loss: 0.4970638155937195, acc: 0.9090909361839294)
[2025-02-04 03:00:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21693/23838 [24:00<11:54,  3.00it/s][2025-02-04 03:00:50][root][INFO] - Training Epoch: 2/2, step 21692/23838 completed (loss: 0.300872266292572, acc: 0.9375)
[2025-02-04 03:00:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21694/23838 [24:00<11:58,  2.98it/s][2025-02-04 03:00:50][root][INFO] - Training Epoch: 2/2, step 21693/23838 completed (loss: 0.15025782585144043, acc: 0.9230769276618958)
[2025-02-04 03:00:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21695/23838 [24:01<11:47,  3.03it/s][2025-02-04 03:00:50][root][INFO] - Training Epoch: 2/2, step 21694/23838 completed (loss: 0.06992850452661514, acc: 1.0)
[2025-02-04 03:00:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21696/23838 [24:01<11:37,  3.07it/s][2025-02-04 03:00:51][root][INFO] - Training Epoch: 2/2, step 21695/23838 completed (loss: 0.32037222385406494, acc: 0.9487179517745972)
[2025-02-04 03:00:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21697/23838 [24:01<11:24,  3.13it/s][2025-02-04 03:00:51][root][INFO] - Training Epoch: 2/2, step 21696/23838 completed (loss: 0.157127246260643, acc: 0.9428571462631226)
[2025-02-04 03:00:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21698/23838 [24:02<11:09,  3.20it/s][2025-02-04 03:00:51][root][INFO] - Training Epoch: 2/2, step 21697/23838 completed (loss: 0.5004221796989441, acc: 0.8913043737411499)
[2025-02-04 03:00:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21699/23838 [24:02<11:15,  3.17it/s][2025-02-04 03:00:51][root][INFO] - Training Epoch: 2/2, step 21698/23838 completed (loss: 0.11505565047264099, acc: 1.0)
[2025-02-04 03:00:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21700/23838 [24:02<11:39,  3.06it/s][2025-02-04 03:00:52][root][INFO] - Training Epoch: 2/2, step 21699/23838 completed (loss: 0.7610509395599365, acc: 0.8333333134651184)
[2025-02-04 03:00:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21701/23838 [24:03<11:55,  2.99it/s][2025-02-04 03:00:52][root][INFO] - Training Epoch: 2/2, step 21700/23838 completed (loss: 0.19689203798770905, acc: 0.949999988079071)
[2025-02-04 03:00:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21702/23838 [24:03<11:53,  2.99it/s][2025-02-04 03:00:53][root][INFO] - Training Epoch: 2/2, step 21701/23838 completed (loss: 0.2475738823413849, acc: 0.9402984976768494)
[2025-02-04 03:00:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21703/23838 [24:03<11:47,  3.02it/s][2025-02-04 03:00:53][root][INFO] - Training Epoch: 2/2, step 21702/23838 completed (loss: 0.7618696093559265, acc: 0.8260869383811951)
[2025-02-04 03:00:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21704/23838 [24:04<11:50,  3.00it/s][2025-02-04 03:00:53][root][INFO] - Training Epoch: 2/2, step 21703/23838 completed (loss: 0.8454080820083618, acc: 0.7142857313156128)
[2025-02-04 03:00:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21705/23838 [24:04<12:11,  2.92it/s][2025-02-04 03:00:54][root][INFO] - Training Epoch: 2/2, step 21704/23838 completed (loss: 0.8968202471733093, acc: 0.7083333134651184)
[2025-02-04 03:00:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21706/23838 [24:04<12:09,  2.92it/s][2025-02-04 03:00:54][root][INFO] - Training Epoch: 2/2, step 21705/23838 completed (loss: 0.3345411419868469, acc: 0.9285714030265808)
[2025-02-04 03:00:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21707/23838 [24:05<12:34,  2.82it/s][2025-02-04 03:00:54][root][INFO] - Training Epoch: 2/2, step 21706/23838 completed (loss: 0.2642698884010315, acc: 0.8888888955116272)
[2025-02-04 03:00:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21708/23838 [24:05<12:43,  2.79it/s][2025-02-04 03:00:55][root][INFO] - Training Epoch: 2/2, step 21707/23838 completed (loss: 0.15808895230293274, acc: 0.9285714030265808)
[2025-02-04 03:00:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21709/23838 [24:05<13:24,  2.65it/s][2025-02-04 03:00:55][root][INFO] - Training Epoch: 2/2, step 21708/23838 completed (loss: 0.1790235936641693, acc: 0.9428571462631226)
[2025-02-04 03:00:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21710/23838 [24:06<13:28,  2.63it/s][2025-02-04 03:00:55][root][INFO] - Training Epoch: 2/2, step 21709/23838 completed (loss: 0.1959802210330963, acc: 0.9032257795333862)
[2025-02-04 03:00:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21711/23838 [24:06<13:41,  2.59it/s][2025-02-04 03:00:56][root][INFO] - Training Epoch: 2/2, step 21710/23838 completed (loss: 0.5939661264419556, acc: 0.8367347121238708)
[2025-02-04 03:00:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21712/23838 [24:07<14:08,  2.51it/s][2025-02-04 03:00:56][root][INFO] - Training Epoch: 2/2, step 21711/23838 completed (loss: 0.2734668254852295, acc: 0.9142857193946838)
[2025-02-04 03:00:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21713/23838 [24:07<13:51,  2.55it/s][2025-02-04 03:00:57][root][INFO] - Training Epoch: 2/2, step 21712/23838 completed (loss: 0.7711947560310364, acc: 0.761904776096344)
[2025-02-04 03:00:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21714/23838 [24:07<13:47,  2.57it/s][2025-02-04 03:00:57][root][INFO] - Training Epoch: 2/2, step 21713/23838 completed (loss: 0.24803698062896729, acc: 0.9354838728904724)
[2025-02-04 03:00:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21715/23838 [24:08<13:03,  2.71it/s][2025-02-04 03:00:57][root][INFO] - Training Epoch: 2/2, step 21714/23838 completed (loss: 0.5817185640335083, acc: 0.8771929740905762)
[2025-02-04 03:00:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21716/23838 [24:08<12:33,  2.81it/s][2025-02-04 03:00:58][root][INFO] - Training Epoch: 2/2, step 21715/23838 completed (loss: 1.0351558923721313, acc: 0.75)
[2025-02-04 03:00:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21717/23838 [24:08<12:11,  2.90it/s][2025-02-04 03:00:58][root][INFO] - Training Epoch: 2/2, step 21716/23838 completed (loss: 0.2658158242702484, acc: 0.9069767594337463)
[2025-02-04 03:00:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21718/23838 [24:09<11:37,  3.04it/s][2025-02-04 03:00:58][root][INFO] - Training Epoch: 2/2, step 21717/23838 completed (loss: 0.6599023342132568, acc: 0.7916666865348816)
[2025-02-04 03:00:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21719/23838 [24:09<11:36,  3.04it/s][2025-02-04 03:00:59][root][INFO] - Training Epoch: 2/2, step 21718/23838 completed (loss: 0.4558163583278656, acc: 0.8421052694320679)
[2025-02-04 03:00:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21720/23838 [24:09<12:13,  2.89it/s][2025-02-04 03:00:59][root][INFO] - Training Epoch: 2/2, step 21719/23838 completed (loss: 0.553188145160675, acc: 0.8108108043670654)
[2025-02-04 03:00:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21721/23838 [24:10<12:14,  2.88it/s][2025-02-04 03:00:59][root][INFO] - Training Epoch: 2/2, step 21720/23838 completed (loss: 0.5589527487754822, acc: 0.8222222328186035)
[2025-02-04 03:00:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21722/23838 [24:10<11:55,  2.96it/s][2025-02-04 03:01:00][root][INFO] - Training Epoch: 2/2, step 21721/23838 completed (loss: 0.40721580386161804, acc: 0.8709677457809448)
[2025-02-04 03:01:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21723/23838 [24:10<11:35,  3.04it/s][2025-02-04 03:01:00][root][INFO] - Training Epoch: 2/2, step 21722/23838 completed (loss: 0.44394031167030334, acc: 0.8055555820465088)
[2025-02-04 03:01:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21724/23838 [24:11<11:26,  3.08it/s][2025-02-04 03:01:00][root][INFO] - Training Epoch: 2/2, step 21723/23838 completed (loss: 0.0879240408539772, acc: 1.0)
[2025-02-04 03:01:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21725/23838 [24:11<11:27,  3.07it/s][2025-02-04 03:01:01][root][INFO] - Training Epoch: 2/2, step 21724/23838 completed (loss: 0.5395528078079224, acc: 0.8888888955116272)
[2025-02-04 03:01:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21726/23838 [24:11<12:26,  2.83it/s][2025-02-04 03:01:01][root][INFO] - Training Epoch: 2/2, step 21725/23838 completed (loss: 0.22181765735149384, acc: 0.9152542352676392)
[2025-02-04 03:01:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21727/23838 [24:12<13:18,  2.65it/s][2025-02-04 03:01:01][root][INFO] - Training Epoch: 2/2, step 21726/23838 completed (loss: 0.22436033189296722, acc: 0.8780487775802612)
[2025-02-04 03:01:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21728/23838 [24:12<13:20,  2.64it/s][2025-02-04 03:01:02][root][INFO] - Training Epoch: 2/2, step 21727/23838 completed (loss: 0.25997835397720337, acc: 0.9358974099159241)
[2025-02-04 03:01:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21729/23838 [24:13<13:42,  2.56it/s][2025-02-04 03:01:02][root][INFO] - Training Epoch: 2/2, step 21728/23838 completed (loss: 0.38713642954826355, acc: 0.9191918969154358)
[2025-02-04 03:01:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21730/23838 [24:13<13:41,  2.57it/s][2025-02-04 03:01:03][root][INFO] - Training Epoch: 2/2, step 21729/23838 completed (loss: 0.49647611379623413, acc: 0.8608695864677429)
[2025-02-04 03:01:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21731/23838 [24:13<13:14,  2.65it/s][2025-02-04 03:01:03][root][INFO] - Training Epoch: 2/2, step 21730/23838 completed (loss: 0.8851163387298584, acc: 0.7272727489471436)
[2025-02-04 03:01:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21732/23838 [24:14<12:53,  2.72it/s][2025-02-04 03:01:03][root][INFO] - Training Epoch: 2/2, step 21731/23838 completed (loss: 0.43479329347610474, acc: 0.8961039185523987)
[2025-02-04 03:01:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21733/23838 [24:14<12:47,  2.74it/s][2025-02-04 03:01:04][root][INFO] - Training Epoch: 2/2, step 21732/23838 completed (loss: 0.699528694152832, acc: 0.7872340679168701)
[2025-02-04 03:01:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21734/23838 [24:15<13:35,  2.58it/s][2025-02-04 03:01:04][root][INFO] - Training Epoch: 2/2, step 21733/23838 completed (loss: 0.4970351755619049, acc: 0.8901098966598511)
[2025-02-04 03:01:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21735/23838 [24:15<13:14,  2.65it/s][2025-02-04 03:01:05][root][INFO] - Training Epoch: 2/2, step 21734/23838 completed (loss: 1.1650314331054688, acc: 0.6323529481887817)
[2025-02-04 03:01:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21736/23838 [24:15<14:32,  2.41it/s][2025-02-04 03:01:05][root][INFO] - Training Epoch: 2/2, step 21735/23838 completed (loss: 0.6857116222381592, acc: 0.8192771077156067)
[2025-02-04 03:01:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21737/23838 [24:16<17:04,  2.05it/s][2025-02-04 03:01:06][root][INFO] - Training Epoch: 2/2, step 21736/23838 completed (loss: 0.9487821459770203, acc: 0.7529411911964417)
[2025-02-04 03:01:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21738/23838 [24:16<16:10,  2.16it/s][2025-02-04 03:01:06][root][INFO] - Training Epoch: 2/2, step 21737/23838 completed (loss: 0.3979269862174988, acc: 0.8876404762268066)
[2025-02-04 03:01:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21739/23838 [24:17<16:11,  2.16it/s][2025-02-04 03:01:07][root][INFO] - Training Epoch: 2/2, step 21738/23838 completed (loss: 0.34042567014694214, acc: 0.925000011920929)
[2025-02-04 03:01:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21740/23838 [24:18<18:43,  1.87it/s][2025-02-04 03:01:07][root][INFO] - Training Epoch: 2/2, step 21739/23838 completed (loss: 0.5099498629570007, acc: 0.8476821184158325)
[2025-02-04 03:01:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21741/23838 [24:18<20:26,  1.71it/s][2025-02-04 03:01:08][root][INFO] - Training Epoch: 2/2, step 21740/23838 completed (loss: 0.5542174577713013, acc: 0.800000011920929)
[2025-02-04 03:01:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21742/23838 [24:19<20:06,  1.74it/s][2025-02-04 03:01:09][root][INFO] - Training Epoch: 2/2, step 21741/23838 completed (loss: 0.9148008823394775, acc: 0.7333333492279053)
[2025-02-04 03:01:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21743/23838 [24:19<18:35,  1.88it/s][2025-02-04 03:01:09][root][INFO] - Training Epoch: 2/2, step 21742/23838 completed (loss: 0.9245488047599792, acc: 0.7638888955116272)
[2025-02-04 03:01:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21744/23838 [24:20<16:02,  2.18it/s][2025-02-04 03:01:09][root][INFO] - Training Epoch: 2/2, step 21743/23838 completed (loss: 0.40754276514053345, acc: 0.8181818127632141)
[2025-02-04 03:01:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21745/23838 [24:20<15:18,  2.28it/s][2025-02-04 03:01:10][root][INFO] - Training Epoch: 2/2, step 21744/23838 completed (loss: 0.11686434596776962, acc: 0.970588207244873)
[2025-02-04 03:01:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21746/23838 [24:21<18:00,  1.94it/s][2025-02-04 03:01:10][root][INFO] - Training Epoch: 2/2, step 21745/23838 completed (loss: 0.6838482618331909, acc: 0.7857142686843872)
[2025-02-04 03:01:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21747/23838 [24:21<16:13,  2.15it/s][2025-02-04 03:01:11][root][INFO] - Training Epoch: 2/2, step 21746/23838 completed (loss: 0.3780480921268463, acc: 0.8834951519966125)
[2025-02-04 03:01:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21748/23838 [24:21<15:46,  2.21it/s][2025-02-04 03:01:11][root][INFO] - Training Epoch: 2/2, step 21747/23838 completed (loss: 0.5150290131568909, acc: 0.8467153310775757)
[2025-02-04 03:01:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21749/23838 [24:22<14:41,  2.37it/s][2025-02-04 03:01:11][root][INFO] - Training Epoch: 2/2, step 21748/23838 completed (loss: 0.48135432600975037, acc: 0.8840579986572266)
[2025-02-04 03:01:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21750/23838 [24:22<14:03,  2.48it/s][2025-02-04 03:01:12][root][INFO] - Training Epoch: 2/2, step 21749/23838 completed (loss: 0.5003772974014282, acc: 0.8554216623306274)
[2025-02-04 03:01:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21751/23838 [24:23<13:34,  2.56it/s][2025-02-04 03:01:12][root][INFO] - Training Epoch: 2/2, step 21750/23838 completed (loss: 0.3640451431274414, acc: 0.8985507488250732)
[2025-02-04 03:01:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████ [0m| 21752/23838 [24:23<13:20,  2.60it/s][2025-02-04 03:01:13][root][INFO] - Training Epoch: 2/2, step 21751/23838 completed (loss: 0.3434641361236572, acc: 0.9239130616188049)
[2025-02-04 03:01:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21753/23838 [24:23<13:22,  2.60it/s][2025-02-04 03:01:13][root][INFO] - Training Epoch: 2/2, step 21752/23838 completed (loss: 0.6120469570159912, acc: 0.8315789699554443)
[2025-02-04 03:01:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21754/23838 [24:24<13:54,  2.50it/s][2025-02-04 03:01:13][root][INFO] - Training Epoch: 2/2, step 21753/23838 completed (loss: 0.3529265224933624, acc: 0.9133333563804626)
[2025-02-04 03:01:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21755/23838 [24:24<12:46,  2.72it/s][2025-02-04 03:01:14][root][INFO] - Training Epoch: 2/2, step 21754/23838 completed (loss: 0.4688747227191925, acc: 0.8414633870124817)
[2025-02-04 03:01:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21756/23838 [24:24<12:41,  2.74it/s][2025-02-04 03:01:14][root][INFO] - Training Epoch: 2/2, step 21755/23838 completed (loss: 0.643406867980957, acc: 0.8135592937469482)
[2025-02-04 03:01:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21757/23838 [24:25<12:19,  2.81it/s][2025-02-04 03:01:14][root][INFO] - Training Epoch: 2/2, step 21756/23838 completed (loss: 0.2799132764339447, acc: 0.9101123809814453)
[2025-02-04 03:01:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21758/23838 [24:25<12:08,  2.85it/s][2025-02-04 03:01:15][root][INFO] - Training Epoch: 2/2, step 21757/23838 completed (loss: 0.380070298910141, acc: 0.895348846912384)
[2025-02-04 03:01:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21759/23838 [24:26<13:04,  2.65it/s][2025-02-04 03:01:15][root][INFO] - Training Epoch: 2/2, step 21758/23838 completed (loss: 0.5038555860519409, acc: 0.8909090757369995)
[2025-02-04 03:01:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21760/23838 [24:26<13:07,  2.64it/s][2025-02-04 03:01:15][root][INFO] - Training Epoch: 2/2, step 21759/23838 completed (loss: 0.29782989621162415, acc: 0.9120879173278809)
[2025-02-04 03:01:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21761/23838 [24:26<12:39,  2.74it/s][2025-02-04 03:01:16][root][INFO] - Training Epoch: 2/2, step 21760/23838 completed (loss: 0.32247400283813477, acc: 0.8771929740905762)
[2025-02-04 03:01:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21762/23838 [24:27<12:25,  2.78it/s][2025-02-04 03:01:16][root][INFO] - Training Epoch: 2/2, step 21761/23838 completed (loss: 0.43801647424697876, acc: 0.8545454740524292)
[2025-02-04 03:01:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21763/23838 [24:27<12:00,  2.88it/s][2025-02-04 03:01:16][root][INFO] - Training Epoch: 2/2, step 21762/23838 completed (loss: 0.5622777342796326, acc: 0.8108108043670654)
[2025-02-04 03:01:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21764/23838 [24:27<12:00,  2.88it/s][2025-02-04 03:01:17][root][INFO] - Training Epoch: 2/2, step 21763/23838 completed (loss: 0.5896757245063782, acc: 0.8730158805847168)
[2025-02-04 03:01:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21765/23838 [24:28<12:12,  2.83it/s][2025-02-04 03:01:17][root][INFO] - Training Epoch: 2/2, step 21764/23838 completed (loss: 0.20978954434394836, acc: 0.932692289352417)
[2025-02-04 03:01:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21766/23838 [24:28<12:16,  2.81it/s][2025-02-04 03:01:18][root][INFO] - Training Epoch: 2/2, step 21765/23838 completed (loss: 0.2483004629611969, acc: 0.9130434989929199)
[2025-02-04 03:01:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21767/23838 [24:28<12:28,  2.77it/s][2025-02-04 03:01:18][root][INFO] - Training Epoch: 2/2, step 21766/23838 completed (loss: 0.2506901025772095, acc: 0.9126983880996704)
[2025-02-04 03:01:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21768/23838 [24:29<12:13,  2.82it/s][2025-02-04 03:01:18][root][INFO] - Training Epoch: 2/2, step 21767/23838 completed (loss: 0.7590707540512085, acc: 0.8108108043670654)
[2025-02-04 03:01:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21769/23838 [24:29<12:15,  2.81it/s][2025-02-04 03:01:19][root][INFO] - Training Epoch: 2/2, step 21768/23838 completed (loss: 0.5408055186271667, acc: 0.855555534362793)
[2025-02-04 03:01:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21770/23838 [24:29<12:06,  2.85it/s][2025-02-04 03:01:19][root][INFO] - Training Epoch: 2/2, step 21769/23838 completed (loss: 0.19738031923770905, acc: 0.9595959782600403)
[2025-02-04 03:01:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21771/23838 [24:30<12:40,  2.72it/s][2025-02-04 03:01:19][root][INFO] - Training Epoch: 2/2, step 21770/23838 completed (loss: 0.23075655102729797, acc: 0.9248120188713074)
[2025-02-04 03:01:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21772/23838 [24:30<12:32,  2.75it/s][2025-02-04 03:01:20][root][INFO] - Training Epoch: 2/2, step 21771/23838 completed (loss: 0.48376473784446716, acc: 0.8333333134651184)
[2025-02-04 03:01:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21773/23838 [24:30<12:17,  2.80it/s][2025-02-04 03:01:20][root][INFO] - Training Epoch: 2/2, step 21772/23838 completed (loss: 0.31219035387039185, acc: 0.9102563858032227)
[2025-02-04 03:01:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21774/23838 [24:31<12:02,  2.86it/s][2025-02-04 03:01:20][root][INFO] - Training Epoch: 2/2, step 21773/23838 completed (loss: 0.5605548024177551, acc: 0.8115941882133484)
[2025-02-04 03:01:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21775/23838 [24:31<11:55,  2.88it/s][2025-02-04 03:01:21][root][INFO] - Training Epoch: 2/2, step 21774/23838 completed (loss: 0.26977789402008057, acc: 0.8991596698760986)
[2025-02-04 03:01:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21776/23838 [24:32<12:13,  2.81it/s][2025-02-04 03:01:21][root][INFO] - Training Epoch: 2/2, step 21775/23838 completed (loss: 0.45336586236953735, acc: 0.8857142925262451)
[2025-02-04 03:01:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21777/23838 [24:32<12:19,  2.79it/s][2025-02-04 03:01:21][root][INFO] - Training Epoch: 2/2, step 21776/23838 completed (loss: 0.487246036529541, acc: 0.8611111044883728)
[2025-02-04 03:01:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21778/23838 [24:32<12:16,  2.80it/s][2025-02-04 03:01:22][root][INFO] - Training Epoch: 2/2, step 21777/23838 completed (loss: 0.30950430035591125, acc: 0.9108911156654358)
[2025-02-04 03:01:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21779/23838 [24:33<11:57,  2.87it/s][2025-02-04 03:01:22][root][INFO] - Training Epoch: 2/2, step 21778/23838 completed (loss: 0.45687615871429443, acc: 0.8620689511299133)
[2025-02-04 03:01:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21780/23838 [24:33<12:23,  2.77it/s][2025-02-04 03:01:23][root][INFO] - Training Epoch: 2/2, step 21779/23838 completed (loss: 0.5291792750358582, acc: 0.8636363744735718)
[2025-02-04 03:01:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21781/23838 [24:33<12:23,  2.77it/s][2025-02-04 03:01:23][root][INFO] - Training Epoch: 2/2, step 21780/23838 completed (loss: 0.5926482081413269, acc: 0.852173924446106)
[2025-02-04 03:01:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21782/23838 [24:34<12:08,  2.82it/s][2025-02-04 03:01:23][root][INFO] - Training Epoch: 2/2, step 21781/23838 completed (loss: 0.27855736017227173, acc: 0.9012345671653748)
[2025-02-04 03:01:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21783/23838 [24:34<11:57,  2.87it/s][2025-02-04 03:01:24][root][INFO] - Training Epoch: 2/2, step 21782/23838 completed (loss: 0.41100773215293884, acc: 0.8936170339584351)
[2025-02-04 03:01:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21784/23838 [24:34<11:56,  2.87it/s][2025-02-04 03:01:24][root][INFO] - Training Epoch: 2/2, step 21783/23838 completed (loss: 0.46287745237350464, acc: 0.9019607901573181)
[2025-02-04 03:01:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21785/23838 [24:35<11:58,  2.86it/s][2025-02-04 03:01:24][root][INFO] - Training Epoch: 2/2, step 21784/23838 completed (loss: 0.3370200991630554, acc: 0.8807339668273926)
[2025-02-04 03:01:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21786/23838 [24:35<12:01,  2.84it/s][2025-02-04 03:01:25][root][INFO] - Training Epoch: 2/2, step 21785/23838 completed (loss: 0.5257256031036377, acc: 0.8617886304855347)
[2025-02-04 03:01:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21787/23838 [24:35<11:57,  2.86it/s][2025-02-04 03:01:25][root][INFO] - Training Epoch: 2/2, step 21786/23838 completed (loss: 0.23597930371761322, acc: 0.9450549483299255)
[2025-02-04 03:01:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21788/23838 [24:36<11:50,  2.89it/s][2025-02-04 03:01:25][root][INFO] - Training Epoch: 2/2, step 21787/23838 completed (loss: 0.305887371301651, acc: 0.9022988677024841)
[2025-02-04 03:01:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21789/23838 [24:36<11:56,  2.86it/s][2025-02-04 03:01:26][root][INFO] - Training Epoch: 2/2, step 21788/23838 completed (loss: 0.5080837607383728, acc: 0.849056601524353)
[2025-02-04 03:01:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21790/23838 [24:36<12:06,  2.82it/s][2025-02-04 03:01:26][root][INFO] - Training Epoch: 2/2, step 21789/23838 completed (loss: 0.3342354893684387, acc: 0.9130434989929199)
[2025-02-04 03:01:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21791/23838 [24:37<12:43,  2.68it/s][2025-02-04 03:01:26][root][INFO] - Training Epoch: 2/2, step 21790/23838 completed (loss: 0.22993461787700653, acc: 0.9285714030265808)
[2025-02-04 03:01:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21792/23838 [24:37<12:23,  2.75it/s][2025-02-04 03:01:27][root][INFO] - Training Epoch: 2/2, step 21791/23838 completed (loss: 0.4444858133792877, acc: 0.8372092843055725)
[2025-02-04 03:01:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21793/23838 [24:38<12:43,  2.68it/s][2025-02-04 03:01:27][root][INFO] - Training Epoch: 2/2, step 21792/23838 completed (loss: 0.23844857513904572, acc: 0.931034505367279)
[2025-02-04 03:01:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21794/23838 [24:38<12:28,  2.73it/s][2025-02-04 03:01:28][root][INFO] - Training Epoch: 2/2, step 21793/23838 completed (loss: 0.431672602891922, acc: 0.8909090757369995)
[2025-02-04 03:01:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21795/23838 [24:38<12:34,  2.71it/s][2025-02-04 03:01:28][root][INFO] - Training Epoch: 2/2, step 21794/23838 completed (loss: 0.0550670251250267, acc: 0.977011501789093)
[2025-02-04 03:01:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21796/23838 [24:39<13:05,  2.60it/s][2025-02-04 03:01:28][root][INFO] - Training Epoch: 2/2, step 21795/23838 completed (loss: 0.41356712579727173, acc: 0.9193548560142517)
[2025-02-04 03:01:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21797/23838 [24:39<12:30,  2.72it/s][2025-02-04 03:01:29][root][INFO] - Training Epoch: 2/2, step 21796/23838 completed (loss: 0.6356030106544495, acc: 0.782608687877655)
[2025-02-04 03:01:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21798/23838 [24:39<12:15,  2.77it/s][2025-02-04 03:01:29][root][INFO] - Training Epoch: 2/2, step 21797/23838 completed (loss: 0.5038630962371826, acc: 0.8583333492279053)
[2025-02-04 03:01:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21799/23838 [24:40<11:46,  2.89it/s][2025-02-04 03:01:29][root][INFO] - Training Epoch: 2/2, step 21798/23838 completed (loss: 0.16737854480743408, acc: 0.9444444179534912)
[2025-02-04 03:01:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21800/23838 [24:40<11:36,  2.93it/s][2025-02-04 03:01:30][root][INFO] - Training Epoch: 2/2, step 21799/23838 completed (loss: 0.22220706939697266, acc: 0.9166666865348816)
[2025-02-04 03:01:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21801/23838 [24:40<11:26,  2.97it/s][2025-02-04 03:01:30][root][INFO] - Training Epoch: 2/2, step 21800/23838 completed (loss: 0.49818092584609985, acc: 0.8630136847496033)
[2025-02-04 03:01:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21802/23838 [24:41<11:22,  2.98it/s][2025-02-04 03:01:30][root][INFO] - Training Epoch: 2/2, step 21801/23838 completed (loss: 0.4164506793022156, acc: 0.8805969953536987)
[2025-02-04 03:01:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21803/23838 [24:41<11:12,  3.03it/s][2025-02-04 03:01:31][root][INFO] - Training Epoch: 2/2, step 21802/23838 completed (loss: 0.5709776282310486, acc: 0.8533333539962769)
[2025-02-04 03:01:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21804/23838 [24:41<10:59,  3.09it/s][2025-02-04 03:01:31][root][INFO] - Training Epoch: 2/2, step 21803/23838 completed (loss: 0.20198553800582886, acc: 0.930232584476471)
[2025-02-04 03:01:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21805/23838 [24:42<11:15,  3.01it/s][2025-02-04 03:01:31][root][INFO] - Training Epoch: 2/2, step 21804/23838 completed (loss: 0.5447927713394165, acc: 0.8045976758003235)
[2025-02-04 03:01:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21806/23838 [24:42<11:18,  3.00it/s][2025-02-04 03:01:32][root][INFO] - Training Epoch: 2/2, step 21805/23838 completed (loss: 0.2581806480884552, acc: 0.9292929172515869)
[2025-02-04 03:01:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21807/23838 [24:42<11:04,  3.06it/s][2025-02-04 03:01:32][root][INFO] - Training Epoch: 2/2, step 21806/23838 completed (loss: 0.2643600404262543, acc: 0.9122806787490845)
[2025-02-04 03:01:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21808/23838 [24:43<10:59,  3.08it/s][2025-02-04 03:01:32][root][INFO] - Training Epoch: 2/2, step 21807/23838 completed (loss: 0.7251127362251282, acc: 0.7875000238418579)
[2025-02-04 03:01:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21809/23838 [24:43<11:07,  3.04it/s][2025-02-04 03:01:33][root][INFO] - Training Epoch: 2/2, step 21808/23838 completed (loss: 0.620023250579834, acc: 0.8783783912658691)
[2025-02-04 03:01:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21810/23838 [24:43<11:10,  3.02it/s][2025-02-04 03:01:33][root][INFO] - Training Epoch: 2/2, step 21809/23838 completed (loss: 0.3912973403930664, acc: 0.8666666746139526)
[2025-02-04 03:01:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  91%|[34m█████████▏[0m| 21811/23838 [24:44<11:06,  3.04it/s][2025-02-04 03:01:33][root][INFO] - Training Epoch: 2/2, step 21810/23838 completed (loss: 0.14360368251800537, acc: 0.9803921580314636)
[2025-02-04 03:01:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21812/23838 [24:44<11:07,  3.04it/s][2025-02-04 03:01:34][root][INFO] - Training Epoch: 2/2, step 21811/23838 completed (loss: 0.26652124524116516, acc: 0.931034505367279)
[2025-02-04 03:01:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21813/23838 [24:44<11:13,  3.01it/s][2025-02-04 03:01:34][root][INFO] - Training Epoch: 2/2, step 21812/23838 completed (loss: 0.4536641240119934, acc: 0.8701298832893372)
[2025-02-04 03:01:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21814/23838 [24:45<11:17,  2.99it/s][2025-02-04 03:01:34][root][INFO] - Training Epoch: 2/2, step 21813/23838 completed (loss: 0.3339404761791229, acc: 0.8775510191917419)
[2025-02-04 03:01:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21815/23838 [24:45<11:43,  2.88it/s][2025-02-04 03:01:35][root][INFO] - Training Epoch: 2/2, step 21814/23838 completed (loss: 0.3044172525405884, acc: 0.9130434989929199)
[2025-02-04 03:01:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21816/23838 [24:45<12:06,  2.78it/s][2025-02-04 03:01:35][root][INFO] - Training Epoch: 2/2, step 21815/23838 completed (loss: 0.4080539643764496, acc: 0.8787878751754761)
[2025-02-04 03:01:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21817/23838 [24:46<12:00,  2.81it/s][2025-02-04 03:01:35][root][INFO] - Training Epoch: 2/2, step 21816/23838 completed (loss: 0.28726375102996826, acc: 0.931034505367279)
[2025-02-04 03:01:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21818/23838 [24:46<12:02,  2.79it/s][2025-02-04 03:01:36][root][INFO] - Training Epoch: 2/2, step 21817/23838 completed (loss: 0.40278923511505127, acc: 0.9304347634315491)
[2025-02-04 03:01:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21819/23838 [24:47<12:08,  2.77it/s][2025-02-04 03:01:36][root][INFO] - Training Epoch: 2/2, step 21818/23838 completed (loss: 0.28850245475769043, acc: 0.890625)
[2025-02-04 03:01:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21820/23838 [24:47<12:31,  2.69it/s][2025-02-04 03:01:37][root][INFO] - Training Epoch: 2/2, step 21819/23838 completed (loss: 0.7355074882507324, acc: 0.8117647171020508)
[2025-02-04 03:01:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21821/23838 [24:47<11:53,  2.83it/s][2025-02-04 03:01:37][root][INFO] - Training Epoch: 2/2, step 21820/23838 completed (loss: 0.4107312560081482, acc: 0.9080459475517273)
[2025-02-04 03:01:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21822/23838 [24:48<11:40,  2.88it/s][2025-02-04 03:01:37][root][INFO] - Training Epoch: 2/2, step 21821/23838 completed (loss: 0.8929551839828491, acc: 0.7777777910232544)
[2025-02-04 03:01:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21823/23838 [24:48<11:41,  2.87it/s][2025-02-04 03:01:38][root][INFO] - Training Epoch: 2/2, step 21822/23838 completed (loss: 0.6406459808349609, acc: 0.75)
[2025-02-04 03:01:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21824/23838 [24:49<14:49,  2.26it/s][2025-02-04 03:01:38][root][INFO] - Training Epoch: 2/2, step 21823/23838 completed (loss: 0.7980462908744812, acc: 0.7828947305679321)
[2025-02-04 03:01:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21825/23838 [24:49<13:56,  2.41it/s][2025-02-04 03:01:39][root][INFO] - Training Epoch: 2/2, step 21824/23838 completed (loss: 1.0794390439987183, acc: 0.7037037014961243)
[2025-02-04 03:01:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21826/23838 [24:49<13:27,  2.49it/s][2025-02-04 03:01:39][root][INFO] - Training Epoch: 2/2, step 21825/23838 completed (loss: 0.7223033308982849, acc: 0.7241379022598267)
[2025-02-04 03:01:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21827/23838 [24:50<12:45,  2.63it/s][2025-02-04 03:01:39][root][INFO] - Training Epoch: 2/2, step 21826/23838 completed (loss: 0.6983457803726196, acc: 0.8367347121238708)
[2025-02-04 03:01:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21828/23838 [24:50<12:07,  2.76it/s][2025-02-04 03:01:40][root][INFO] - Training Epoch: 2/2, step 21827/23838 completed (loss: 0.5981008410453796, acc: 0.8529411554336548)
[2025-02-04 03:01:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21829/23838 [24:50<12:00,  2.79it/s][2025-02-04 03:01:40][root][INFO] - Training Epoch: 2/2, step 21828/23838 completed (loss: 0.3072032034397125, acc: 0.8999999761581421)
[2025-02-04 03:01:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21830/23838 [24:51<11:38,  2.87it/s][2025-02-04 03:01:40][root][INFO] - Training Epoch: 2/2, step 21829/23838 completed (loss: 0.5839414596557617, acc: 0.8282828330993652)
[2025-02-04 03:01:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21831/23838 [24:51<11:28,  2.92it/s][2025-02-04 03:01:41][root][INFO] - Training Epoch: 2/2, step 21830/23838 completed (loss: 1.0327153205871582, acc: 0.6388888955116272)
[2025-02-04 03:01:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21832/23838 [24:51<11:29,  2.91it/s][2025-02-04 03:01:41][root][INFO] - Training Epoch: 2/2, step 21831/23838 completed (loss: 0.21129266917705536, acc: 0.9180327653884888)
[2025-02-04 03:01:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21833/23838 [24:52<11:01,  3.03it/s][2025-02-04 03:01:41][root][INFO] - Training Epoch: 2/2, step 21832/23838 completed (loss: 1.2176240682601929, acc: 0.6575342416763306)
[2025-02-04 03:01:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21834/23838 [24:52<10:59,  3.04it/s][2025-02-04 03:01:42][root][INFO] - Training Epoch: 2/2, step 21833/23838 completed (loss: 0.39231088757514954, acc: 0.8863636255264282)
[2025-02-04 03:01:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21835/23838 [24:52<11:06,  3.01it/s][2025-02-04 03:01:42][root][INFO] - Training Epoch: 2/2, step 21834/23838 completed (loss: 0.4675326347351074, acc: 0.859375)
[2025-02-04 03:01:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21836/23838 [24:53<10:31,  3.17it/s][2025-02-04 03:01:42][root][INFO] - Training Epoch: 2/2, step 21835/23838 completed (loss: 0.36136385798454285, acc: 0.9166666865348816)
[2025-02-04 03:01:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21837/23838 [24:53<10:00,  3.33it/s][2025-02-04 03:01:42][root][INFO] - Training Epoch: 2/2, step 21836/23838 completed (loss: 0.4383324980735779, acc: 0.8983050584793091)
[2025-02-04 03:01:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21838/23838 [24:53<10:01,  3.32it/s][2025-02-04 03:01:43][root][INFO] - Training Epoch: 2/2, step 21837/23838 completed (loss: 0.4042817950248718, acc: 0.9090909361839294)
[2025-02-04 03:01:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21839/23838 [24:53<10:09,  3.28it/s][2025-02-04 03:01:43][root][INFO] - Training Epoch: 2/2, step 21838/23838 completed (loss: 0.6614360213279724, acc: 0.8387096524238586)
[2025-02-04 03:01:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21840/23838 [24:54<09:36,  3.47it/s][2025-02-04 03:01:43][root][INFO] - Training Epoch: 2/2, step 21839/23838 completed (loss: 0.5256503820419312, acc: 0.8409090638160706)
[2025-02-04 03:01:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21841/23838 [24:54<10:05,  3.30it/s][2025-02-04 03:01:44][root][INFO] - Training Epoch: 2/2, step 21840/23838 completed (loss: 0.3441055417060852, acc: 0.8965517282485962)
[2025-02-04 03:01:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21842/23838 [24:54<10:50,  3.07it/s][2025-02-04 03:01:44][root][INFO] - Training Epoch: 2/2, step 21841/23838 completed (loss: 0.87049800157547, acc: 0.7659574747085571)
[2025-02-04 03:01:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21843/23838 [24:55<10:37,  3.13it/s][2025-02-04 03:01:44][root][INFO] - Training Epoch: 2/2, step 21842/23838 completed (loss: 0.7753859162330627, acc: 0.8125)
[2025-02-04 03:01:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21844/23838 [24:55<10:27,  3.18it/s][2025-02-04 03:01:45][root][INFO] - Training Epoch: 2/2, step 21843/23838 completed (loss: 0.5569479465484619, acc: 0.8125)
[2025-02-04 03:01:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21845/23838 [24:55<10:48,  3.07it/s][2025-02-04 03:01:45][root][INFO] - Training Epoch: 2/2, step 21844/23838 completed (loss: 0.49733766913414, acc: 0.8387096524238586)
[2025-02-04 03:01:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21846/23838 [24:56<10:49,  3.07it/s][2025-02-04 03:01:45][root][INFO] - Training Epoch: 2/2, step 21845/23838 completed (loss: 0.3516164720058441, acc: 0.875)
[2025-02-04 03:01:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21847/23838 [24:56<10:13,  3.25it/s][2025-02-04 03:01:46][root][INFO] - Training Epoch: 2/2, step 21846/23838 completed (loss: 0.2251419723033905, acc: 0.9259259104728699)
[2025-02-04 03:01:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21848/23838 [24:56<10:40,  3.11it/s][2025-02-04 03:01:46][root][INFO] - Training Epoch: 2/2, step 21847/23838 completed (loss: 0.3685760498046875, acc: 0.8804348111152649)
[2025-02-04 03:01:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21849/23838 [24:57<11:04,  2.99it/s][2025-02-04 03:01:46][root][INFO] - Training Epoch: 2/2, step 21848/23838 completed (loss: 0.7082937359809875, acc: 0.7878788113594055)
[2025-02-04 03:01:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21850/23838 [24:57<11:29,  2.89it/s][2025-02-04 03:01:47][root][INFO] - Training Epoch: 2/2, step 21849/23838 completed (loss: 0.9886282086372375, acc: 0.800000011920929)
[2025-02-04 03:01:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21851/23838 [24:57<11:36,  2.85it/s][2025-02-04 03:01:47][root][INFO] - Training Epoch: 2/2, step 21850/23838 completed (loss: 0.6475463509559631, acc: 0.8474576473236084)
[2025-02-04 03:01:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21852/23838 [24:58<11:11,  2.96it/s][2025-02-04 03:01:47][root][INFO] - Training Epoch: 2/2, step 21851/23838 completed (loss: 0.6154367327690125, acc: 0.8157894611358643)
[2025-02-04 03:01:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21853/23838 [24:58<10:54,  3.03it/s][2025-02-04 03:01:48][root][INFO] - Training Epoch: 2/2, step 21852/23838 completed (loss: 0.42263999581336975, acc: 0.8703703880310059)
[2025-02-04 03:01:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21854/23838 [24:58<10:51,  3.04it/s][2025-02-04 03:01:48][root][INFO] - Training Epoch: 2/2, step 21853/23838 completed (loss: 0.33647364377975464, acc: 0.8999999761581421)
[2025-02-04 03:01:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21855/23838 [24:59<11:47,  2.80it/s][2025-02-04 03:01:48][root][INFO] - Training Epoch: 2/2, step 21854/23838 completed (loss: 0.4209311604499817, acc: 0.8571428656578064)
[2025-02-04 03:01:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21856/23838 [24:59<11:58,  2.76it/s][2025-02-04 03:01:49][root][INFO] - Training Epoch: 2/2, step 21855/23838 completed (loss: 0.5619898438453674, acc: 0.8524590134620667)
[2025-02-04 03:01:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21857/23838 [25:00<12:29,  2.64it/s][2025-02-04 03:01:49][root][INFO] - Training Epoch: 2/2, step 21856/23838 completed (loss: 0.7401774525642395, acc: 0.7606837749481201)
[2025-02-04 03:01:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21858/23838 [25:00<12:28,  2.65it/s][2025-02-04 03:01:50][root][INFO] - Training Epoch: 2/2, step 21857/23838 completed (loss: 0.31551387906074524, acc: 0.90625)
[2025-02-04 03:01:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21859/23838 [25:00<12:39,  2.61it/s][2025-02-04 03:01:50][root][INFO] - Training Epoch: 2/2, step 21858/23838 completed (loss: 0.5626921653747559, acc: 0.7818182110786438)
[2025-02-04 03:01:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21860/23838 [25:01<12:08,  2.72it/s][2025-02-04 03:01:50][root][INFO] - Training Epoch: 2/2, step 21859/23838 completed (loss: 0.9320917725563049, acc: 0.7283950448036194)
[2025-02-04 03:01:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21861/23838 [25:01<13:02,  2.53it/s][2025-02-04 03:01:51][root][INFO] - Training Epoch: 2/2, step 21860/23838 completed (loss: 0.5997710824012756, acc: 0.8676470518112183)
[2025-02-04 03:01:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21862/23838 [25:01<12:33,  2.62it/s][2025-02-04 03:01:51][root][INFO] - Training Epoch: 2/2, step 21861/23838 completed (loss: 0.1596553921699524, acc: 0.9791666865348816)
[2025-02-04 03:01:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21863/23838 [25:02<12:11,  2.70it/s][2025-02-04 03:01:51][root][INFO] - Training Epoch: 2/2, step 21862/23838 completed (loss: 0.4287433326244354, acc: 0.8666666746139526)
[2025-02-04 03:01:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21864/23838 [25:02<11:45,  2.80it/s][2025-02-04 03:01:52][root][INFO] - Training Epoch: 2/2, step 21863/23838 completed (loss: 0.5600852966308594, acc: 0.8550724387168884)
[2025-02-04 03:01:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21865/23838 [25:02<11:04,  2.97it/s][2025-02-04 03:01:52][root][INFO] - Training Epoch: 2/2, step 21864/23838 completed (loss: 0.6852571368217468, acc: 0.7721518874168396)
[2025-02-04 03:01:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21866/23838 [25:03<11:07,  2.95it/s][2025-02-04 03:01:52][root][INFO] - Training Epoch: 2/2, step 21865/23838 completed (loss: 0.49417585134506226, acc: 0.8333333134651184)
[2025-02-04 03:01:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21867/23838 [25:03<11:37,  2.83it/s][2025-02-04 03:01:53][root][INFO] - Training Epoch: 2/2, step 21866/23838 completed (loss: 0.4968823492527008, acc: 0.8941176533699036)
[2025-02-04 03:01:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21868/23838 [25:04<11:59,  2.74it/s][2025-02-04 03:01:53][root][INFO] - Training Epoch: 2/2, step 21867/23838 completed (loss: 0.644110918045044, acc: 0.818965494632721)
[2025-02-04 03:01:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21869/23838 [25:04<11:56,  2.75it/s][2025-02-04 03:01:54][root][INFO] - Training Epoch: 2/2, step 21868/23838 completed (loss: 0.955968976020813, acc: 0.7352941036224365)
[2025-02-04 03:01:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21870/23838 [25:04<12:35,  2.60it/s][2025-02-04 03:01:54][root][INFO] - Training Epoch: 2/2, step 21869/23838 completed (loss: 0.30706360936164856, acc: 0.948051929473877)
[2025-02-04 03:01:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21871/23838 [25:05<12:45,  2.57it/s][2025-02-04 03:01:54][root][INFO] - Training Epoch: 2/2, step 21870/23838 completed (loss: 0.7469284534454346, acc: 0.795918345451355)
[2025-02-04 03:01:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21872/23838 [25:05<13:03,  2.51it/s][2025-02-04 03:01:55][root][INFO] - Training Epoch: 2/2, step 21871/23838 completed (loss: 1.1356772184371948, acc: 0.6000000238418579)
[2025-02-04 03:01:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21873/23838 [25:06<12:56,  2.53it/s][2025-02-04 03:01:55][root][INFO] - Training Epoch: 2/2, step 21872/23838 completed (loss: 0.8292276859283447, acc: 0.7692307829856873)
[2025-02-04 03:01:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21874/23838 [25:06<12:43,  2.57it/s][2025-02-04 03:01:56][root][INFO] - Training Epoch: 2/2, step 21873/23838 completed (loss: 0.624255895614624, acc: 0.7954545617103577)
[2025-02-04 03:01:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21875/23838 [25:06<12:25,  2.63it/s][2025-02-04 03:01:56][root][INFO] - Training Epoch: 2/2, step 21874/23838 completed (loss: 0.2869941294193268, acc: 0.936170220375061)
[2025-02-04 03:01:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21876/23838 [25:07<12:35,  2.60it/s][2025-02-04 03:01:56][root][INFO] - Training Epoch: 2/2, step 21875/23838 completed (loss: 0.6752326488494873, acc: 0.7714285850524902)
[2025-02-04 03:01:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21877/23838 [25:07<12:57,  2.52it/s][2025-02-04 03:01:57][root][INFO] - Training Epoch: 2/2, step 21876/23838 completed (loss: 0.7049102187156677, acc: 0.7936508059501648)
[2025-02-04 03:01:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21878/23838 [25:08<13:25,  2.43it/s][2025-02-04 03:01:57][root][INFO] - Training Epoch: 2/2, step 21877/23838 completed (loss: 0.6780185103416443, acc: 0.8051947951316833)
[2025-02-04 03:01:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21879/23838 [25:08<13:38,  2.39it/s][2025-02-04 03:01:58][root][INFO] - Training Epoch: 2/2, step 21878/23838 completed (loss: 0.6288896203041077, acc: 0.8103448152542114)
[2025-02-04 03:01:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21880/23838 [25:08<13:24,  2.43it/s][2025-02-04 03:01:58][root][INFO] - Training Epoch: 2/2, step 21879/23838 completed (loss: 0.9770609736442566, acc: 0.7142857313156128)
[2025-02-04 03:01:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21881/23838 [25:09<12:48,  2.55it/s][2025-02-04 03:01:58][root][INFO] - Training Epoch: 2/2, step 21880/23838 completed (loss: 0.735541045665741, acc: 0.7291666865348816)
[2025-02-04 03:01:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21882/23838 [25:09<12:30,  2.61it/s][2025-02-04 03:01:59][root][INFO] - Training Epoch: 2/2, step 21881/23838 completed (loss: 0.7344533205032349, acc: 0.7903226017951965)
[2025-02-04 03:01:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21883/23838 [25:09<12:12,  2.67it/s][2025-02-04 03:01:59][root][INFO] - Training Epoch: 2/2, step 21882/23838 completed (loss: 0.4032065272331238, acc: 0.8600000143051147)
[2025-02-04 03:01:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21884/23838 [25:10<11:30,  2.83it/s][2025-02-04 03:01:59][root][INFO] - Training Epoch: 2/2, step 21883/23838 completed (loss: 0.9571549892425537, acc: 0.7090908885002136)
[2025-02-04 03:01:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21885/23838 [25:10<11:02,  2.95it/s][2025-02-04 03:02:00][root][INFO] - Training Epoch: 2/2, step 21884/23838 completed (loss: 0.8064509630203247, acc: 0.8100000023841858)
[2025-02-04 03:02:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21886/23838 [25:10<10:42,  3.04it/s][2025-02-04 03:02:00][root][INFO] - Training Epoch: 2/2, step 21885/23838 completed (loss: 0.8195962309837341, acc: 0.7931034564971924)
[2025-02-04 03:02:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21887/23838 [25:11<10:32,  3.08it/s][2025-02-04 03:02:00][root][INFO] - Training Epoch: 2/2, step 21886/23838 completed (loss: 0.8255260586738586, acc: 0.7422680258750916)
[2025-02-04 03:02:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21888/23838 [25:11<11:08,  2.92it/s][2025-02-04 03:02:01][root][INFO] - Training Epoch: 2/2, step 21887/23838 completed (loss: 0.9473540186882019, acc: 0.6896551847457886)
[2025-02-04 03:02:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21889/23838 [25:11<11:27,  2.84it/s][2025-02-04 03:02:01][root][INFO] - Training Epoch: 2/2, step 21888/23838 completed (loss: 0.6937443614006042, acc: 0.7659574747085571)
[2025-02-04 03:02:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21890/23838 [25:12<10:51,  2.99it/s][2025-02-04 03:02:01][root][INFO] - Training Epoch: 2/2, step 21889/23838 completed (loss: 0.7047604322433472, acc: 0.7804877758026123)
[2025-02-04 03:02:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21891/23838 [25:12<10:36,  3.06it/s][2025-02-04 03:02:02][root][INFO] - Training Epoch: 2/2, step 21890/23838 completed (loss: 1.0261982679367065, acc: 0.7209302186965942)
[2025-02-04 03:02:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21892/23838 [25:12<10:33,  3.07it/s][2025-02-04 03:02:02][root][INFO] - Training Epoch: 2/2, step 21891/23838 completed (loss: 0.3976834714412689, acc: 0.9259259104728699)
[2025-02-04 03:02:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21893/23838 [25:13<10:49,  3.00it/s][2025-02-04 03:02:02][root][INFO] - Training Epoch: 2/2, step 21892/23838 completed (loss: 0.5556493997573853, acc: 0.8837209343910217)
[2025-02-04 03:02:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21894/23838 [25:13<10:44,  3.02it/s][2025-02-04 03:02:03][root][INFO] - Training Epoch: 2/2, step 21893/23838 completed (loss: 0.09635742753744125, acc: 0.9729729890823364)
[2025-02-04 03:02:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21895/23838 [25:13<11:15,  2.88it/s][2025-02-04 03:02:03][root][INFO] - Training Epoch: 2/2, step 21894/23838 completed (loss: 0.10624740272760391, acc: 0.9669421315193176)
[2025-02-04 03:02:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21896/23838 [25:14<11:35,  2.79it/s][2025-02-04 03:02:03][root][INFO] - Training Epoch: 2/2, step 21895/23838 completed (loss: 0.08392709493637085, acc: 0.9746835231781006)
[2025-02-04 03:02:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21897/23838 [25:14<11:02,  2.93it/s][2025-02-04 03:02:04][root][INFO] - Training Epoch: 2/2, step 21896/23838 completed (loss: 0.15807987749576569, acc: 0.9411764740943909)
[2025-02-04 03:02:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21898/23838 [25:14<10:53,  2.97it/s][2025-02-04 03:02:04][root][INFO] - Training Epoch: 2/2, step 21897/23838 completed (loss: 0.23430104553699493, acc: 0.9304347634315491)
[2025-02-04 03:02:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21899/23838 [25:15<10:49,  2.99it/s][2025-02-04 03:02:04][root][INFO] - Training Epoch: 2/2, step 21898/23838 completed (loss: 0.1294012814760208, acc: 0.930232584476471)
[2025-02-04 03:02:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21900/23838 [25:15<10:56,  2.95it/s][2025-02-04 03:02:05][root][INFO] - Training Epoch: 2/2, step 21899/23838 completed (loss: 0.0774487555027008, acc: 0.9743589758872986)
[2025-02-04 03:02:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21901/23838 [25:15<10:38,  3.03it/s][2025-02-04 03:02:05][root][INFO] - Training Epoch: 2/2, step 21900/23838 completed (loss: 0.04220762103796005, acc: 1.0)
[2025-02-04 03:02:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21902/23838 [25:16<10:56,  2.95it/s][2025-02-04 03:02:05][root][INFO] - Training Epoch: 2/2, step 21901/23838 completed (loss: 0.24152064323425293, acc: 0.9428571462631226)
[2025-02-04 03:02:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21903/23838 [25:16<11:13,  2.87it/s][2025-02-04 03:02:06][root][INFO] - Training Epoch: 2/2, step 21902/23838 completed (loss: 0.16292886435985565, acc: 0.9436619877815247)
[2025-02-04 03:02:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21904/23838 [25:17<11:26,  2.82it/s][2025-02-04 03:02:06][root][INFO] - Training Epoch: 2/2, step 21903/23838 completed (loss: 0.10774887353181839, acc: 0.9655172228813171)
[2025-02-04 03:02:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21905/23838 [25:17<11:38,  2.77it/s][2025-02-04 03:02:07][root][INFO] - Training Epoch: 2/2, step 21904/23838 completed (loss: 0.39033636450767517, acc: 0.8478260636329651)
[2025-02-04 03:02:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21906/23838 [25:17<11:16,  2.85it/s][2025-02-04 03:02:07][root][INFO] - Training Epoch: 2/2, step 21905/23838 completed (loss: 0.1488216370344162, acc: 0.9841269850730896)
[2025-02-04 03:02:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21907/23838 [25:18<11:42,  2.75it/s][2025-02-04 03:02:07][root][INFO] - Training Epoch: 2/2, step 21906/23838 completed (loss: 0.14278918504714966, acc: 0.9430894255638123)
[2025-02-04 03:02:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21908/23838 [25:18<11:46,  2.73it/s][2025-02-04 03:02:08][root][INFO] - Training Epoch: 2/2, step 21907/23838 completed (loss: 0.13239681720733643, acc: 0.9545454382896423)
[2025-02-04 03:02:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21909/23838 [25:18<11:16,  2.85it/s][2025-02-04 03:02:08][root][INFO] - Training Epoch: 2/2, step 21908/23838 completed (loss: 0.33409354090690613, acc: 0.9375)
[2025-02-04 03:02:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21910/23838 [25:19<11:49,  2.72it/s][2025-02-04 03:02:08][root][INFO] - Training Epoch: 2/2, step 21909/23838 completed (loss: 0.08360619097948074, acc: 0.9638554453849792)
[2025-02-04 03:02:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21911/23838 [25:19<12:11,  2.64it/s][2025-02-04 03:02:09][root][INFO] - Training Epoch: 2/2, step 21910/23838 completed (loss: 0.29960158467292786, acc: 0.942148745059967)
[2025-02-04 03:02:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21912/23838 [25:20<12:40,  2.53it/s][2025-02-04 03:02:09][root][INFO] - Training Epoch: 2/2, step 21911/23838 completed (loss: 0.1429022252559662, acc: 0.9649122953414917)
[2025-02-04 03:02:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21913/23838 [25:20<14:14,  2.25it/s][2025-02-04 03:02:10][root][INFO] - Training Epoch: 2/2, step 21912/23838 completed (loss: 0.21165136992931366, acc: 0.9465649127960205)
[2025-02-04 03:02:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21914/23838 [25:20<13:25,  2.39it/s][2025-02-04 03:02:10][root][INFO] - Training Epoch: 2/2, step 21913/23838 completed (loss: 0.06724298000335693, acc: 1.0)
[2025-02-04 03:02:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21915/23838 [25:21<12:29,  2.57it/s][2025-02-04 03:02:10][root][INFO] - Training Epoch: 2/2, step 21914/23838 completed (loss: 0.30193784832954407, acc: 0.8974359035491943)
[2025-02-04 03:02:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21916/23838 [25:21<12:01,  2.66it/s][2025-02-04 03:02:11][root][INFO] - Training Epoch: 2/2, step 21915/23838 completed (loss: 0.12704777717590332, acc: 0.9682539701461792)
[2025-02-04 03:02:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21917/23838 [25:22<13:34,  2.36it/s][2025-02-04 03:02:11][root][INFO] - Training Epoch: 2/2, step 21916/23838 completed (loss: 0.1795005351305008, acc: 0.9455782175064087)
[2025-02-04 03:02:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21918/23838 [25:22<13:02,  2.45it/s][2025-02-04 03:02:12][root][INFO] - Training Epoch: 2/2, step 21917/23838 completed (loss: 0.1749117225408554, acc: 0.957446813583374)
[2025-02-04 03:02:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21919/23838 [25:23<14:51,  2.15it/s][2025-02-04 03:02:12][root][INFO] - Training Epoch: 2/2, step 21918/23838 completed (loss: 0.256765216588974, acc: 0.9529411792755127)
[2025-02-04 03:02:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21920/23838 [25:23<14:12,  2.25it/s][2025-02-04 03:02:13][root][INFO] - Training Epoch: 2/2, step 21919/23838 completed (loss: 0.07918963581323624, acc: 0.9569892287254333)
[2025-02-04 03:02:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21921/23838 [25:23<12:20,  2.59it/s][2025-02-04 03:02:13][root][INFO] - Training Epoch: 2/2, step 21920/23838 completed (loss: 0.269441694021225, acc: 0.9137930870056152)
[2025-02-04 03:02:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21922/23838 [25:24<12:14,  2.61it/s][2025-02-04 03:02:13][root][INFO] - Training Epoch: 2/2, step 21921/23838 completed (loss: 0.23860296607017517, acc: 0.9230769276618958)
[2025-02-04 03:02:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21923/23838 [25:24<11:42,  2.72it/s][2025-02-04 03:02:14][root][INFO] - Training Epoch: 2/2, step 21922/23838 completed (loss: 0.16483893990516663, acc: 0.9642857313156128)
[2025-02-04 03:02:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21924/23838 [25:24<12:27,  2.56it/s][2025-02-04 03:02:14][root][INFO] - Training Epoch: 2/2, step 21923/23838 completed (loss: 0.15469324588775635, acc: 0.9375)
[2025-02-04 03:02:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21925/23838 [25:25<12:16,  2.60it/s][2025-02-04 03:02:14][root][INFO] - Training Epoch: 2/2, step 21924/23838 completed (loss: 0.6316413879394531, acc: 0.807692289352417)
[2025-02-04 03:02:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21926/23838 [25:25<12:19,  2.58it/s][2025-02-04 03:02:15][root][INFO] - Training Epoch: 2/2, step 21925/23838 completed (loss: 1.1923882961273193, acc: 0.698113203048706)
[2025-02-04 03:02:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21927/23838 [25:26<12:08,  2.62it/s][2025-02-04 03:02:15][root][INFO] - Training Epoch: 2/2, step 21926/23838 completed (loss: 0.7657321691513062, acc: 0.7735849022865295)
[2025-02-04 03:02:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21928/23838 [25:26<11:52,  2.68it/s][2025-02-04 03:02:16][root][INFO] - Training Epoch: 2/2, step 21927/23838 completed (loss: 0.7484825253486633, acc: 0.800000011920929)
[2025-02-04 03:02:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21929/23838 [25:26<11:05,  2.87it/s][2025-02-04 03:02:16][root][INFO] - Training Epoch: 2/2, step 21928/23838 completed (loss: 1.2451115846633911, acc: 0.6363636255264282)
[2025-02-04 03:02:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21930/23838 [25:27<10:44,  2.96it/s][2025-02-04 03:02:16][root][INFO] - Training Epoch: 2/2, step 21929/23838 completed (loss: 0.7930880784988403, acc: 0.8260869383811951)
[2025-02-04 03:02:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21931/23838 [25:27<11:04,  2.87it/s][2025-02-04 03:02:17][root][INFO] - Training Epoch: 2/2, step 21930/23838 completed (loss: 0.3453601598739624, acc: 0.8787878751754761)
[2025-02-04 03:02:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21932/23838 [25:27<10:56,  2.90it/s][2025-02-04 03:02:17][root][INFO] - Training Epoch: 2/2, step 21931/23838 completed (loss: 0.26202186942100525, acc: 0.939393937587738)
[2025-02-04 03:02:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21933/23838 [25:28<10:49,  2.93it/s][2025-02-04 03:02:17][root][INFO] - Training Epoch: 2/2, step 21932/23838 completed (loss: 0.7170023322105408, acc: 0.800000011920929)
[2025-02-04 03:02:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21934/23838 [25:28<10:52,  2.92it/s][2025-02-04 03:02:18][root][INFO] - Training Epoch: 2/2, step 21933/23838 completed (loss: 0.1944955289363861, acc: 0.96875)
[2025-02-04 03:02:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21935/23838 [25:28<11:07,  2.85it/s][2025-02-04 03:02:18][root][INFO] - Training Epoch: 2/2, step 21934/23838 completed (loss: 0.35047581791877747, acc: 0.9636363387107849)
[2025-02-04 03:02:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21936/23838 [25:29<10:49,  2.93it/s][2025-02-04 03:02:18][root][INFO] - Training Epoch: 2/2, step 21935/23838 completed (loss: 0.9308409094810486, acc: 0.7435897588729858)
[2025-02-04 03:02:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21937/23838 [25:29<10:29,  3.02it/s][2025-02-04 03:02:19][root][INFO] - Training Epoch: 2/2, step 21936/23838 completed (loss: 1.044656753540039, acc: 0.7692307829856873)
[2025-02-04 03:02:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21938/23838 [25:29<10:36,  2.99it/s][2025-02-04 03:02:19][root][INFO] - Training Epoch: 2/2, step 21937/23838 completed (loss: 0.12053332477807999, acc: 0.9729729890823364)
[2025-02-04 03:02:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21939/23838 [25:30<10:33,  3.00it/s][2025-02-04 03:02:19][root][INFO] - Training Epoch: 2/2, step 21938/23838 completed (loss: 0.2763224244117737, acc: 0.9428571462631226)
[2025-02-04 03:02:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21940/23838 [25:30<11:21,  2.79it/s][2025-02-04 03:02:20][root][INFO] - Training Epoch: 2/2, step 21939/23838 completed (loss: 0.8281993865966797, acc: 0.8307692408561707)
[2025-02-04 03:02:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21941/23838 [25:30<11:07,  2.84it/s][2025-02-04 03:02:20][root][INFO] - Training Epoch: 2/2, step 21940/23838 completed (loss: 0.5380128622055054, acc: 0.8518518805503845)
[2025-02-04 03:02:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21942/23838 [25:31<11:02,  2.86it/s][2025-02-04 03:02:20][root][INFO] - Training Epoch: 2/2, step 21941/23838 completed (loss: 0.32646241784095764, acc: 0.9473684430122375)
[2025-02-04 03:02:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21943/23838 [25:31<10:45,  2.94it/s][2025-02-04 03:02:21][root][INFO] - Training Epoch: 2/2, step 21942/23838 completed (loss: 0.22870852053165436, acc: 0.95652174949646)
[2025-02-04 03:02:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21944/23838 [25:31<11:21,  2.78it/s][2025-02-04 03:02:21][root][INFO] - Training Epoch: 2/2, step 21943/23838 completed (loss: 0.2472420036792755, acc: 0.9259259104728699)
[2025-02-04 03:02:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21945/23838 [25:32<11:36,  2.72it/s][2025-02-04 03:02:21][root][INFO] - Training Epoch: 2/2, step 21944/23838 completed (loss: 0.5532315969467163, acc: 0.8545454740524292)
[2025-02-04 03:02:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21946/23838 [25:32<11:40,  2.70it/s][2025-02-04 03:02:22][root][INFO] - Training Epoch: 2/2, step 21945/23838 completed (loss: 0.2929995656013489, acc: 0.9047619104385376)
[2025-02-04 03:02:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21947/23838 [25:33<11:44,  2.69it/s][2025-02-04 03:02:22][root][INFO] - Training Epoch: 2/2, step 21946/23838 completed (loss: 0.5927748680114746, acc: 0.8709677457809448)
[2025-02-04 03:02:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21948/23838 [25:33<11:46,  2.67it/s][2025-02-04 03:02:23][root][INFO] - Training Epoch: 2/2, step 21947/23838 completed (loss: 0.26100680232048035, acc: 0.95652174949646)
[2025-02-04 03:02:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21949/23838 [25:33<11:33,  2.72it/s][2025-02-04 03:02:23][root][INFO] - Training Epoch: 2/2, step 21948/23838 completed (loss: 0.4770425260066986, acc: 0.824999988079071)
[2025-02-04 03:02:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21950/23838 [25:34<11:42,  2.69it/s][2025-02-04 03:02:23][root][INFO] - Training Epoch: 2/2, step 21949/23838 completed (loss: 0.6909582614898682, acc: 0.8604651093482971)
[2025-02-04 03:02:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21951/23838 [25:34<11:32,  2.72it/s][2025-02-04 03:02:24][root][INFO] - Training Epoch: 2/2, step 21950/23838 completed (loss: 0.8120478391647339, acc: 0.7250000238418579)
[2025-02-04 03:02:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21952/23838 [25:34<11:37,  2.70it/s][2025-02-04 03:02:24][root][INFO] - Training Epoch: 2/2, step 21951/23838 completed (loss: 0.3638140559196472, acc: 0.8461538553237915)
[2025-02-04 03:02:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21953/23838 [25:35<12:02,  2.61it/s][2025-02-04 03:02:24][root][INFO] - Training Epoch: 2/2, step 21952/23838 completed (loss: 0.38897261023521423, acc: 0.9473684430122375)
[2025-02-04 03:02:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21954/23838 [25:35<12:08,  2.59it/s][2025-02-04 03:02:25][root][INFO] - Training Epoch: 2/2, step 21953/23838 completed (loss: 0.44643092155456543, acc: 0.8679245114326477)
[2025-02-04 03:02:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21955/23838 [25:36<12:20,  2.54it/s][2025-02-04 03:02:25][root][INFO] - Training Epoch: 2/2, step 21954/23838 completed (loss: 0.3503706753253937, acc: 0.9016393423080444)
[2025-02-04 03:02:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21956/23838 [25:36<12:22,  2.53it/s][2025-02-04 03:02:26][root][INFO] - Training Epoch: 2/2, step 21955/23838 completed (loss: 0.5667522549629211, acc: 0.8611111044883728)
[2025-02-04 03:02:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21957/23838 [25:36<11:59,  2.62it/s][2025-02-04 03:02:26][root][INFO] - Training Epoch: 2/2, step 21956/23838 completed (loss: 0.6304813623428345, acc: 0.8333333134651184)
[2025-02-04 03:02:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21958/23838 [25:37<11:46,  2.66it/s][2025-02-04 03:02:26][root][INFO] - Training Epoch: 2/2, step 21957/23838 completed (loss: 0.1418759524822235, acc: 0.9655172228813171)
[2025-02-04 03:02:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21959/23838 [25:37<11:31,  2.72it/s][2025-02-04 03:02:27][root][INFO] - Training Epoch: 2/2, step 21958/23838 completed (loss: 0.26907652616500854, acc: 0.9262295365333557)
[2025-02-04 03:02:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21960/23838 [25:37<11:00,  2.84it/s][2025-02-04 03:02:27][root][INFO] - Training Epoch: 2/2, step 21959/23838 completed (loss: 0.3679981529712677, acc: 0.9090909361839294)
[2025-02-04 03:02:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21961/23838 [25:38<10:29,  2.98it/s][2025-02-04 03:02:27][root][INFO] - Training Epoch: 2/2, step 21960/23838 completed (loss: 0.26281923055648804, acc: 0.9285714030265808)
[2025-02-04 03:02:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21962/23838 [25:38<10:29,  2.98it/s][2025-02-04 03:02:28][root][INFO] - Training Epoch: 2/2, step 21961/23838 completed (loss: 0.055711645632982254, acc: 0.9791666865348816)
[2025-02-04 03:02:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21963/23838 [25:38<11:24,  2.74it/s][2025-02-04 03:02:28][root][INFO] - Training Epoch: 2/2, step 21962/23838 completed (loss: 0.14927193522453308, acc: 0.9444444179534912)
[2025-02-04 03:02:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21964/23838 [25:39<11:34,  2.70it/s][2025-02-04 03:02:28][root][INFO] - Training Epoch: 2/2, step 21963/23838 completed (loss: 0.4694502353668213, acc: 0.8775510191917419)
[2025-02-04 03:02:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21965/23838 [25:39<12:11,  2.56it/s][2025-02-04 03:02:29][root][INFO] - Training Epoch: 2/2, step 21964/23838 completed (loss: 0.5187110900878906, acc: 0.858208954334259)
[2025-02-04 03:02:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21966/23838 [25:40<11:49,  2.64it/s][2025-02-04 03:02:29][root][INFO] - Training Epoch: 2/2, step 21965/23838 completed (loss: 0.6312552690505981, acc: 0.8214285969734192)
[2025-02-04 03:02:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21967/23838 [25:40<11:34,  2.70it/s][2025-02-04 03:02:30][root][INFO] - Training Epoch: 2/2, step 21966/23838 completed (loss: 0.21212376654148102, acc: 0.9743589758872986)
[2025-02-04 03:02:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21968/23838 [25:40<11:40,  2.67it/s][2025-02-04 03:02:30][root][INFO] - Training Epoch: 2/2, step 21967/23838 completed (loss: 0.11246466636657715, acc: 0.9583333134651184)
[2025-02-04 03:02:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21969/23838 [25:41<12:32,  2.48it/s][2025-02-04 03:02:30][root][INFO] - Training Epoch: 2/2, step 21968/23838 completed (loss: 0.5395845174789429, acc: 0.8541666865348816)
[2025-02-04 03:02:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21970/23838 [25:41<12:30,  2.49it/s][2025-02-04 03:02:31][root][INFO] - Training Epoch: 2/2, step 21969/23838 completed (loss: 0.369390606880188, acc: 0.8833333253860474)
[2025-02-04 03:02:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21971/23838 [25:42<12:33,  2.48it/s][2025-02-04 03:02:31][root][INFO] - Training Epoch: 2/2, step 21970/23838 completed (loss: 0.7364009618759155, acc: 0.8108108043670654)
[2025-02-04 03:02:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21972/23838 [25:42<13:25,  2.32it/s][2025-02-04 03:02:32][root][INFO] - Training Epoch: 2/2, step 21971/23838 completed (loss: 0.4642696976661682, acc: 0.9145299196243286)
[2025-02-04 03:02:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21973/23838 [25:43<12:36,  2.47it/s][2025-02-04 03:02:32][root][INFO] - Training Epoch: 2/2, step 21972/23838 completed (loss: 0.7200825214385986, acc: 0.875)
[2025-02-04 03:02:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21974/23838 [25:43<12:10,  2.55it/s][2025-02-04 03:02:32][root][INFO] - Training Epoch: 2/2, step 21973/23838 completed (loss: 0.7306007742881775, acc: 0.8333333134651184)
[2025-02-04 03:02:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21975/23838 [25:43<11:47,  2.64it/s][2025-02-04 03:02:33][root][INFO] - Training Epoch: 2/2, step 21974/23838 completed (loss: 0.3311561048030853, acc: 0.8965517282485962)
[2025-02-04 03:02:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21976/23838 [25:44<11:25,  2.72it/s][2025-02-04 03:02:33][root][INFO] - Training Epoch: 2/2, step 21975/23838 completed (loss: 0.5606637597084045, acc: 0.8478260636329651)
[2025-02-04 03:02:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21977/23838 [25:44<10:43,  2.89it/s][2025-02-04 03:02:33][root][INFO] - Training Epoch: 2/2, step 21976/23838 completed (loss: 0.71761155128479, acc: 0.739130437374115)
[2025-02-04 03:02:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21978/23838 [25:44<10:36,  2.92it/s][2025-02-04 03:02:34][root][INFO] - Training Epoch: 2/2, step 21977/23838 completed (loss: 0.7305573225021362, acc: 0.782608687877655)
[2025-02-04 03:02:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21979/23838 [25:45<10:49,  2.86it/s][2025-02-04 03:02:34][root][INFO] - Training Epoch: 2/2, step 21978/23838 completed (loss: 0.5462276935577393, acc: 0.8313252925872803)
[2025-02-04 03:02:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21980/23838 [25:45<10:54,  2.84it/s][2025-02-04 03:02:34][root][INFO] - Training Epoch: 2/2, step 21979/23838 completed (loss: 0.34278586506843567, acc: 0.8936170339584351)
[2025-02-04 03:02:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21981/23838 [25:45<10:26,  2.96it/s][2025-02-04 03:02:35][root][INFO] - Training Epoch: 2/2, step 21980/23838 completed (loss: 0.3542522192001343, acc: 0.8904109597206116)
[2025-02-04 03:02:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21982/23838 [25:46<10:14,  3.02it/s][2025-02-04 03:02:35][root][INFO] - Training Epoch: 2/2, step 21981/23838 completed (loss: 0.5182821750640869, acc: 0.8723404407501221)
[2025-02-04 03:02:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21983/23838 [25:46<10:47,  2.87it/s][2025-02-04 03:02:36][root][INFO] - Training Epoch: 2/2, step 21982/23838 completed (loss: 0.2721423804759979, acc: 0.9166666865348816)
[2025-02-04 03:02:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21984/23838 [25:46<10:43,  2.88it/s][2025-02-04 03:02:36][root][INFO] - Training Epoch: 2/2, step 21983/23838 completed (loss: 0.14221930503845215, acc: 0.9494949579238892)
[2025-02-04 03:02:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21985/23838 [25:47<10:34,  2.92it/s][2025-02-04 03:02:36][root][INFO] - Training Epoch: 2/2, step 21984/23838 completed (loss: 0.28928419947624207, acc: 0.9215686321258545)
[2025-02-04 03:02:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21986/23838 [25:47<10:35,  2.92it/s][2025-02-04 03:02:37][root][INFO] - Training Epoch: 2/2, step 21985/23838 completed (loss: 0.12694145739078522, acc: 0.949999988079071)
[2025-02-04 03:02:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21987/23838 [25:47<11:01,  2.80it/s][2025-02-04 03:02:37][root][INFO] - Training Epoch: 2/2, step 21986/23838 completed (loss: 0.16729579865932465, acc: 0.9603960514068604)
[2025-02-04 03:02:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21988/23838 [25:48<10:41,  2.89it/s][2025-02-04 03:02:37][root][INFO] - Training Epoch: 2/2, step 21987/23838 completed (loss: 0.19899241626262665, acc: 0.9482758641242981)
[2025-02-04 03:02:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21989/23838 [25:48<11:42,  2.63it/s][2025-02-04 03:02:38][root][INFO] - Training Epoch: 2/2, step 21988/23838 completed (loss: 0.22415068745613098, acc: 0.9120879173278809)
[2025-02-04 03:02:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21990/23838 [25:48<11:47,  2.61it/s][2025-02-04 03:02:38][root][INFO] - Training Epoch: 2/2, step 21989/23838 completed (loss: 0.575576901435852, acc: 0.8611111044883728)
[2025-02-04 03:02:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21991/23838 [25:49<11:24,  2.70it/s][2025-02-04 03:02:38][root][INFO] - Training Epoch: 2/2, step 21990/23838 completed (loss: 0.4321766197681427, acc: 0.8775510191917419)
[2025-02-04 03:02:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21992/23838 [25:49<10:54,  2.82it/s][2025-02-04 03:02:39][root][INFO] - Training Epoch: 2/2, step 21991/23838 completed (loss: 0.24042801558971405, acc: 0.925000011920929)
[2025-02-04 03:02:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21993/23838 [25:49<10:38,  2.89it/s][2025-02-04 03:02:39][root][INFO] - Training Epoch: 2/2, step 21992/23838 completed (loss: 0.33529141545295715, acc: 0.931506872177124)
[2025-02-04 03:02:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21994/23838 [25:50<10:46,  2.85it/s][2025-02-04 03:02:39][root][INFO] - Training Epoch: 2/2, step 21993/23838 completed (loss: 0.5602201223373413, acc: 0.8870967626571655)
[2025-02-04 03:02:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21995/23838 [25:50<10:59,  2.80it/s][2025-02-04 03:02:40][root][INFO] - Training Epoch: 2/2, step 21994/23838 completed (loss: 0.5061795711517334, acc: 0.8644067645072937)
[2025-02-04 03:02:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21996/23838 [25:51<10:40,  2.87it/s][2025-02-04 03:02:40][root][INFO] - Training Epoch: 2/2, step 21995/23838 completed (loss: 0.1631738692522049, acc: 0.9649122953414917)
[2025-02-04 03:02:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21997/23838 [25:51<10:48,  2.84it/s][2025-02-04 03:02:40][root][INFO] - Training Epoch: 2/2, step 21996/23838 completed (loss: 0.3717533349990845, acc: 0.895348846912384)
[2025-02-04 03:02:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21998/23838 [25:51<10:32,  2.91it/s][2025-02-04 03:02:41][root][INFO] - Training Epoch: 2/2, step 21997/23838 completed (loss: 0.5328676104545593, acc: 0.8617886304855347)
[2025-02-04 03:02:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 21999/23838 [25:52<10:23,  2.95it/s][2025-02-04 03:02:41][root][INFO] - Training Epoch: 2/2, step 21998/23838 completed (loss: 0.39262905716896057, acc: 0.9090909361839294)
[2025-02-04 03:02:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22000/23838 [25:52<10:22,  2.95it/s][2025-02-04 03:02:41][root][INFO] - Training Epoch: 2/2, step 21999/23838 completed (loss: 0.31491148471832275, acc: 0.8723404407501221)
[2025-02-04 03:02:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22001/23838 [25:52<10:15,  2.99it/s][2025-02-04 03:02:42][root][INFO] - Training Epoch: 2/2, step 22000/23838 completed (loss: 0.1851404905319214, acc: 0.9736841917037964)
[2025-02-04 03:02:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22002/23838 [25:53<10:10,  3.01it/s][2025-02-04 03:02:42][root][INFO] - Training Epoch: 2/2, step 22001/23838 completed (loss: 0.4715396463871002, acc: 0.8571428656578064)
[2025-02-04 03:02:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22003/23838 [25:53<10:36,  2.88it/s][2025-02-04 03:02:43][root][INFO] - Training Epoch: 2/2, step 22002/23838 completed (loss: 0.30993103981018066, acc: 0.892307698726654)
[2025-02-04 03:02:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22004/23838 [25:53<10:15,  2.98it/s][2025-02-04 03:02:43][root][INFO] - Training Epoch: 2/2, step 22003/23838 completed (loss: 0.23355630040168762, acc: 0.9122806787490845)
[2025-02-04 03:02:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22005/23838 [25:54<10:19,  2.96it/s][2025-02-04 03:02:43][root][INFO] - Training Epoch: 2/2, step 22004/23838 completed (loss: 0.6239627003669739, acc: 0.796875)
[2025-02-04 03:02:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22006/23838 [25:54<10:20,  2.95it/s][2025-02-04 03:02:44][root][INFO] - Training Epoch: 2/2, step 22005/23838 completed (loss: 0.2344169318675995, acc: 0.9285714030265808)
[2025-02-04 03:02:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22007/23838 [25:54<10:02,  3.04it/s][2025-02-04 03:02:44][root][INFO] - Training Epoch: 2/2, step 22006/23838 completed (loss: 0.09998129308223724, acc: 0.9682539701461792)
[2025-02-04 03:02:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22008/23838 [25:55<10:39,  2.86it/s][2025-02-04 03:02:44][root][INFO] - Training Epoch: 2/2, step 22007/23838 completed (loss: 0.38825559616088867, acc: 0.8921568393707275)
[2025-02-04 03:02:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22009/23838 [25:55<10:49,  2.82it/s][2025-02-04 03:02:45][root][INFO] - Training Epoch: 2/2, step 22008/23838 completed (loss: 0.3966086506843567, acc: 0.8829787373542786)
[2025-02-04 03:02:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22010/23838 [25:55<11:02,  2.76it/s][2025-02-04 03:02:45][root][INFO] - Training Epoch: 2/2, step 22009/23838 completed (loss: 0.6088067889213562, acc: 0.796875)
[2025-02-04 03:02:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22011/23838 [25:56<10:45,  2.83it/s][2025-02-04 03:02:45][root][INFO] - Training Epoch: 2/2, step 22010/23838 completed (loss: 0.36601731181144714, acc: 0.9054054021835327)
[2025-02-04 03:02:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22012/23838 [25:56<11:00,  2.77it/s][2025-02-04 03:02:46][root][INFO] - Training Epoch: 2/2, step 22011/23838 completed (loss: 0.6184967756271362, acc: 0.800000011920929)
[2025-02-04 03:02:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22013/23838 [25:56<10:56,  2.78it/s][2025-02-04 03:02:46][root][INFO] - Training Epoch: 2/2, step 22012/23838 completed (loss: 0.2243272215127945, acc: 0.9137930870056152)
[2025-02-04 03:02:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22014/23838 [25:57<11:14,  2.70it/s][2025-02-04 03:02:46][root][INFO] - Training Epoch: 2/2, step 22013/23838 completed (loss: 0.5710363984107971, acc: 0.8548387289047241)
[2025-02-04 03:02:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22015/23838 [25:57<12:10,  2.49it/s][2025-02-04 03:02:47][root][INFO] - Training Epoch: 2/2, step 22014/23838 completed (loss: 0.4533267915248871, acc: 0.8913043737411499)
[2025-02-04 03:02:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22016/23838 [25:58<11:56,  2.54it/s][2025-02-04 03:02:47][root][INFO] - Training Epoch: 2/2, step 22015/23838 completed (loss: 0.12201789021492004, acc: 0.9830508232116699)
[2025-02-04 03:02:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22017/23838 [25:58<11:30,  2.64it/s][2025-02-04 03:02:48][root][INFO] - Training Epoch: 2/2, step 22016/23838 completed (loss: 0.5811176896095276, acc: 0.8666666746139526)
[2025-02-04 03:02:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22018/23838 [25:58<11:40,  2.60it/s][2025-02-04 03:02:48][root][INFO] - Training Epoch: 2/2, step 22017/23838 completed (loss: 0.2952398359775543, acc: 0.9024389982223511)
[2025-02-04 03:02:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22019/23838 [25:59<11:34,  2.62it/s][2025-02-04 03:02:48][root][INFO] - Training Epoch: 2/2, step 22018/23838 completed (loss: 0.6488347053527832, acc: 0.8571428656578064)
[2025-02-04 03:02:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22020/23838 [25:59<11:10,  2.71it/s][2025-02-04 03:02:49][root][INFO] - Training Epoch: 2/2, step 22019/23838 completed (loss: 0.46334344148635864, acc: 0.9130434989929199)
[2025-02-04 03:02:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22021/23838 [26:00<11:11,  2.71it/s][2025-02-04 03:02:49][root][INFO] - Training Epoch: 2/2, step 22020/23838 completed (loss: 0.17937879264354706, acc: 0.9756097793579102)
[2025-02-04 03:02:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22022/23838 [26:00<10:49,  2.79it/s][2025-02-04 03:02:49][root][INFO] - Training Epoch: 2/2, step 22021/23838 completed (loss: 0.21983997523784637, acc: 0.9512194991111755)
[2025-02-04 03:02:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22023/23838 [26:00<10:44,  2.81it/s][2025-02-04 03:02:50][root][INFO] - Training Epoch: 2/2, step 22022/23838 completed (loss: 0.5790616869926453, acc: 0.855555534362793)
[2025-02-04 03:02:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22024/23838 [26:00<10:17,  2.94it/s][2025-02-04 03:02:50][root][INFO] - Training Epoch: 2/2, step 22023/23838 completed (loss: 0.20472626388072968, acc: 0.939393937587738)
[2025-02-04 03:02:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22025/23838 [26:01<10:26,  2.89it/s][2025-02-04 03:02:50][root][INFO] - Training Epoch: 2/2, step 22024/23838 completed (loss: 0.43614110350608826, acc: 0.8823529481887817)
[2025-02-04 03:02:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22026/23838 [26:01<10:20,  2.92it/s][2025-02-04 03:02:51][root][INFO] - Training Epoch: 2/2, step 22025/23838 completed (loss: 0.23563653230667114, acc: 0.9090909361839294)
[2025-02-04 03:02:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22027/23838 [26:02<10:34,  2.85it/s][2025-02-04 03:02:51][root][INFO] - Training Epoch: 2/2, step 22026/23838 completed (loss: 0.4770022928714752, acc: 0.8461538553237915)
[2025-02-04 03:02:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22028/23838 [26:02<10:35,  2.85it/s][2025-02-04 03:02:52][root][INFO] - Training Epoch: 2/2, step 22027/23838 completed (loss: 0.6986823081970215, acc: 0.78125)
[2025-02-04 03:02:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22029/23838 [26:02<10:34,  2.85it/s][2025-02-04 03:02:52][root][INFO] - Training Epoch: 2/2, step 22028/23838 completed (loss: 1.1264573335647583, acc: 0.6860465407371521)
[2025-02-04 03:02:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22030/23838 [26:03<10:27,  2.88it/s][2025-02-04 03:02:52][root][INFO] - Training Epoch: 2/2, step 22029/23838 completed (loss: 1.2886085510253906, acc: 0.6707317233085632)
[2025-02-04 03:02:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22031/23838 [26:03<10:20,  2.91it/s][2025-02-04 03:02:53][root][INFO] - Training Epoch: 2/2, step 22030/23838 completed (loss: 0.6716498136520386, acc: 0.7808219194412231)
[2025-02-04 03:02:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22032/23838 [26:03<10:31,  2.86it/s][2025-02-04 03:02:53][root][INFO] - Training Epoch: 2/2, step 22031/23838 completed (loss: 0.9531829953193665, acc: 0.7476635575294495)
[2025-02-04 03:02:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22033/23838 [26:04<10:29,  2.87it/s][2025-02-04 03:02:53][root][INFO] - Training Epoch: 2/2, step 22032/23838 completed (loss: 0.8796713948249817, acc: 0.7592592835426331)
[2025-02-04 03:02:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22034/23838 [26:04<10:33,  2.85it/s][2025-02-04 03:02:54][root][INFO] - Training Epoch: 2/2, step 22033/23838 completed (loss: 0.955763041973114, acc: 0.6904761791229248)
[2025-02-04 03:02:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22035/23838 [26:04<10:48,  2.78it/s][2025-02-04 03:02:54][root][INFO] - Training Epoch: 2/2, step 22034/23838 completed (loss: 0.8681179285049438, acc: 0.7254902124404907)
[2025-02-04 03:02:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22036/23838 [26:05<10:40,  2.82it/s][2025-02-04 03:02:54][root][INFO] - Training Epoch: 2/2, step 22035/23838 completed (loss: 0.5997132062911987, acc: 0.7816091775894165)
[2025-02-04 03:02:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22037/23838 [26:05<10:58,  2.74it/s][2025-02-04 03:02:55][root][INFO] - Training Epoch: 2/2, step 22036/23838 completed (loss: 0.4957440495491028, acc: 0.8536585569381714)
[2025-02-04 03:02:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22038/23838 [26:06<11:35,  2.59it/s][2025-02-04 03:02:55][root][INFO] - Training Epoch: 2/2, step 22037/23838 completed (loss: 0.7484409213066101, acc: 0.7472527623176575)
[2025-02-04 03:02:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22039/23838 [26:06<11:28,  2.61it/s][2025-02-04 03:02:56][root][INFO] - Training Epoch: 2/2, step 22038/23838 completed (loss: 0.7523807883262634, acc: 0.746666669845581)
[2025-02-04 03:02:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22040/23838 [26:06<10:59,  2.72it/s][2025-02-04 03:02:56][root][INFO] - Training Epoch: 2/2, step 22039/23838 completed (loss: 1.1628884077072144, acc: 0.694915235042572)
[2025-02-04 03:02:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22041/23838 [26:07<11:28,  2.61it/s][2025-02-04 03:02:56][root][INFO] - Training Epoch: 2/2, step 22040/23838 completed (loss: 0.39616861939430237, acc: 0.8426966071128845)
[2025-02-04 03:02:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22042/23838 [26:07<11:21,  2.64it/s][2025-02-04 03:02:57][root][INFO] - Training Epoch: 2/2, step 22041/23838 completed (loss: 1.0845441818237305, acc: 0.707317054271698)
[2025-02-04 03:02:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22043/23838 [26:07<11:06,  2.69it/s][2025-02-04 03:02:57][root][INFO] - Training Epoch: 2/2, step 22042/23838 completed (loss: 0.542026937007904, acc: 0.8404255509376526)
[2025-02-04 03:02:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22044/23838 [26:08<10:52,  2.75it/s][2025-02-04 03:02:57][root][INFO] - Training Epoch: 2/2, step 22043/23838 completed (loss: 0.9224775433540344, acc: 0.7674418687820435)
[2025-02-04 03:02:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22045/23838 [26:08<10:41,  2.80it/s][2025-02-04 03:02:58][root][INFO] - Training Epoch: 2/2, step 22044/23838 completed (loss: 0.8204277753829956, acc: 0.7222222089767456)
[2025-02-04 03:02:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22046/23838 [26:08<10:26,  2.86it/s][2025-02-04 03:02:58][root][INFO] - Training Epoch: 2/2, step 22045/23838 completed (loss: 0.6607576608657837, acc: 0.8311688303947449)
[2025-02-04 03:02:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22047/23838 [26:09<10:14,  2.92it/s][2025-02-04 03:02:58][root][INFO] - Training Epoch: 2/2, step 22046/23838 completed (loss: 0.4200916290283203, acc: 0.8947368264198303)
[2025-02-04 03:02:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22048/23838 [26:09<10:44,  2.78it/s][2025-02-04 03:02:59][root][INFO] - Training Epoch: 2/2, step 22047/23838 completed (loss: 0.47011637687683105, acc: 0.8765432238578796)
[2025-02-04 03:02:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22049/23838 [26:10<10:44,  2.77it/s][2025-02-04 03:02:59][root][INFO] - Training Epoch: 2/2, step 22048/23838 completed (loss: 0.5056948065757751, acc: 0.8850574493408203)
[2025-02-04 03:02:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  92%|[34m█████████▏[0m| 22050/23838 [26:10<10:35,  2.81it/s][2025-02-04 03:02:59][root][INFO] - Training Epoch: 2/2, step 22049/23838 completed (loss: 1.121758222579956, acc: 0.6764705777168274)
[2025-02-04 03:03:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22051/23838 [26:10<10:32,  2.83it/s][2025-02-04 03:03:00][root][INFO] - Training Epoch: 2/2, step 22050/23838 completed (loss: 0.6063408255577087, acc: 0.8510638475418091)
[2025-02-04 03:03:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22052/23838 [26:11<10:18,  2.89it/s][2025-02-04 03:03:00][root][INFO] - Training Epoch: 2/2, step 22051/23838 completed (loss: 0.7674697041511536, acc: 0.7407407164573669)
[2025-02-04 03:03:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22053/23838 [26:11<10:27,  2.84it/s][2025-02-04 03:03:00][root][INFO] - Training Epoch: 2/2, step 22052/23838 completed (loss: 0.9420662522315979, acc: 0.7397260069847107)
[2025-02-04 03:03:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22054/23838 [26:11<10:19,  2.88it/s][2025-02-04 03:03:01][root][INFO] - Training Epoch: 2/2, step 22053/23838 completed (loss: 1.1085267066955566, acc: 0.6704545617103577)
[2025-02-04 03:03:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22055/23838 [26:12<10:31,  2.82it/s][2025-02-04 03:03:01][root][INFO] - Training Epoch: 2/2, step 22054/23838 completed (loss: 0.8712554574012756, acc: 0.7936508059501648)
[2025-02-04 03:03:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22056/23838 [26:12<10:44,  2.77it/s][2025-02-04 03:03:02][root][INFO] - Training Epoch: 2/2, step 22055/23838 completed (loss: 0.705003559589386, acc: 0.7835051417350769)
[2025-02-04 03:03:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22057/23838 [26:12<10:31,  2.82it/s][2025-02-04 03:03:02][root][INFO] - Training Epoch: 2/2, step 22056/23838 completed (loss: 0.9106944799423218, acc: 0.800000011920929)
[2025-02-04 03:03:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22058/23838 [26:13<10:13,  2.90it/s][2025-02-04 03:03:02][root][INFO] - Training Epoch: 2/2, step 22057/23838 completed (loss: 0.8941549062728882, acc: 0.699999988079071)
[2025-02-04 03:03:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22059/23838 [26:13<10:29,  2.83it/s][2025-02-04 03:03:03][root][INFO] - Training Epoch: 2/2, step 22058/23838 completed (loss: 0.7659446597099304, acc: 0.7662337422370911)
[2025-02-04 03:03:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22060/23838 [26:13<10:24,  2.84it/s][2025-02-04 03:03:03][root][INFO] - Training Epoch: 2/2, step 22059/23838 completed (loss: 0.6813631653785706, acc: 0.7916666865348816)
[2025-02-04 03:03:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22061/23838 [26:14<10:26,  2.84it/s][2025-02-04 03:03:03][root][INFO] - Training Epoch: 2/2, step 22060/23838 completed (loss: 0.7404570579528809, acc: 0.7653061151504517)
[2025-02-04 03:03:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22062/23838 [26:14<10:15,  2.89it/s][2025-02-04 03:03:04][root][INFO] - Training Epoch: 2/2, step 22061/23838 completed (loss: 0.8998517394065857, acc: 0.7622950673103333)
[2025-02-04 03:03:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22063/23838 [26:14<10:02,  2.95it/s][2025-02-04 03:03:04][root][INFO] - Training Epoch: 2/2, step 22062/23838 completed (loss: 0.8813443183898926, acc: 0.75)
[2025-02-04 03:03:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22064/23838 [26:15<10:15,  2.88it/s][2025-02-04 03:03:04][root][INFO] - Training Epoch: 2/2, step 22063/23838 completed (loss: 0.6224532723426819, acc: 0.8260869383811951)
[2025-02-04 03:03:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22065/23838 [26:15<10:27,  2.83it/s][2025-02-04 03:03:05][root][INFO] - Training Epoch: 2/2, step 22064/23838 completed (loss: 0.6644149422645569, acc: 0.7777777910232544)
[2025-02-04 03:03:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22066/23838 [26:16<11:11,  2.64it/s][2025-02-04 03:03:05][root][INFO] - Training Epoch: 2/2, step 22065/23838 completed (loss: 0.6637218594551086, acc: 0.8157894611358643)
[2025-02-04 03:03:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22067/23838 [26:16<10:58,  2.69it/s][2025-02-04 03:03:05][root][INFO] - Training Epoch: 2/2, step 22066/23838 completed (loss: 0.5678755044937134, acc: 0.8641975522041321)
[2025-02-04 03:03:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22068/23838 [26:16<11:02,  2.67it/s][2025-02-04 03:03:06][root][INFO] - Training Epoch: 2/2, step 22067/23838 completed (loss: 0.8295190334320068, acc: 0.7692307829856873)
[2025-02-04 03:03:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22069/23838 [26:17<10:42,  2.75it/s][2025-02-04 03:03:06][root][INFO] - Training Epoch: 2/2, step 22068/23838 completed (loss: 0.9992169737815857, acc: 0.7215189933776855)
[2025-02-04 03:03:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22070/23838 [26:17<11:00,  2.68it/s][2025-02-04 03:03:07][root][INFO] - Training Epoch: 2/2, step 22069/23838 completed (loss: 1.0445481538772583, acc: 0.738095223903656)
[2025-02-04 03:03:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22071/23838 [26:17<11:02,  2.67it/s][2025-02-04 03:03:07][root][INFO] - Training Epoch: 2/2, step 22070/23838 completed (loss: 0.8369464874267578, acc: 0.7894737124443054)
[2025-02-04 03:03:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22072/23838 [26:18<10:59,  2.68it/s][2025-02-04 03:03:07][root][INFO] - Training Epoch: 2/2, step 22071/23838 completed (loss: 0.47799837589263916, acc: 0.8354430198669434)
[2025-02-04 03:03:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22073/23838 [26:18<10:39,  2.76it/s][2025-02-04 03:03:08][root][INFO] - Training Epoch: 2/2, step 22072/23838 completed (loss: 0.9430964589118958, acc: 0.7692307829856873)
[2025-02-04 03:03:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22074/23838 [26:18<10:25,  2.82it/s][2025-02-04 03:03:08][root][INFO] - Training Epoch: 2/2, step 22073/23838 completed (loss: 0.7109386920928955, acc: 0.8028169274330139)
[2025-02-04 03:03:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22075/23838 [26:19<10:19,  2.85it/s][2025-02-04 03:03:08][root][INFO] - Training Epoch: 2/2, step 22074/23838 completed (loss: 0.7254266142845154, acc: 0.75)
[2025-02-04 03:03:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22076/23838 [26:19<10:48,  2.72it/s][2025-02-04 03:03:09][root][INFO] - Training Epoch: 2/2, step 22075/23838 completed (loss: 0.49826931953430176, acc: 0.8701298832893372)
[2025-02-04 03:03:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22077/23838 [26:20<10:52,  2.70it/s][2025-02-04 03:03:09][root][INFO] - Training Epoch: 2/2, step 22076/23838 completed (loss: 0.9225461483001709, acc: 0.760869562625885)
[2025-02-04 03:03:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22078/23838 [26:20<10:56,  2.68it/s][2025-02-04 03:03:10][root][INFO] - Training Epoch: 2/2, step 22077/23838 completed (loss: 0.7254830598831177, acc: 0.800000011920929)
[2025-02-04 03:03:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22079/23838 [26:20<11:14,  2.61it/s][2025-02-04 03:03:10][root][INFO] - Training Epoch: 2/2, step 22078/23838 completed (loss: 0.6201068758964539, acc: 0.8433734774589539)
[2025-02-04 03:03:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22080/23838 [26:21<11:44,  2.50it/s][2025-02-04 03:03:10][root][INFO] - Training Epoch: 2/2, step 22079/23838 completed (loss: 0.7797627449035645, acc: 0.7972972989082336)
[2025-02-04 03:03:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22081/23838 [26:21<11:11,  2.62it/s][2025-02-04 03:03:11][root][INFO] - Training Epoch: 2/2, step 22080/23838 completed (loss: 0.810322642326355, acc: 0.7875000238418579)
[2025-02-04 03:03:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22082/23838 [26:21<10:41,  2.74it/s][2025-02-04 03:03:11][root][INFO] - Training Epoch: 2/2, step 22081/23838 completed (loss: 0.9440237879753113, acc: 0.7129629850387573)
[2025-02-04 03:03:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22083/23838 [26:22<10:53,  2.69it/s][2025-02-04 03:03:11][root][INFO] - Training Epoch: 2/2, step 22082/23838 completed (loss: 1.0423160791397095, acc: 0.6880733966827393)
[2025-02-04 03:03:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22084/23838 [26:22<11:14,  2.60it/s][2025-02-04 03:03:12][root][INFO] - Training Epoch: 2/2, step 22083/23838 completed (loss: 0.7610725164413452, acc: 0.7555555701255798)
[2025-02-04 03:03:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22085/23838 [26:23<11:11,  2.61it/s][2025-02-04 03:03:12][root][INFO] - Training Epoch: 2/2, step 22084/23838 completed (loss: 0.4490543603897095, acc: 0.8714285492897034)
[2025-02-04 03:03:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22086/23838 [26:23<10:46,  2.71it/s][2025-02-04 03:03:13][root][INFO] - Training Epoch: 2/2, step 22085/23838 completed (loss: 0.5550174117088318, acc: 0.8428571224212646)
[2025-02-04 03:03:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22087/23838 [26:23<10:21,  2.82it/s][2025-02-04 03:03:13][root][INFO] - Training Epoch: 2/2, step 22086/23838 completed (loss: 0.529745876789093, acc: 0.8863636255264282)
[2025-02-04 03:03:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22088/23838 [26:24<10:08,  2.88it/s][2025-02-04 03:03:13][root][INFO] - Training Epoch: 2/2, step 22087/23838 completed (loss: 0.4776439964771271, acc: 0.8651685118675232)
[2025-02-04 03:03:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22089/23838 [26:24<10:15,  2.84it/s][2025-02-04 03:03:14][root][INFO] - Training Epoch: 2/2, step 22088/23838 completed (loss: 0.3401240110397339, acc: 0.9242424368858337)
[2025-02-04 03:03:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22090/23838 [26:24<09:51,  2.96it/s][2025-02-04 03:03:14][root][INFO] - Training Epoch: 2/2, step 22089/23838 completed (loss: 0.621399998664856, acc: 0.8684210777282715)
[2025-02-04 03:03:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22091/23838 [26:25<09:54,  2.94it/s][2025-02-04 03:03:14][root][INFO] - Training Epoch: 2/2, step 22090/23838 completed (loss: 1.118246078491211, acc: 0.698113203048706)
[2025-02-04 03:03:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22092/23838 [26:25<09:58,  2.92it/s][2025-02-04 03:03:15][root][INFO] - Training Epoch: 2/2, step 22091/23838 completed (loss: 0.38416388630867004, acc: 0.8823529481887817)
[2025-02-04 03:03:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22093/23838 [26:25<09:54,  2.93it/s][2025-02-04 03:03:15][root][INFO] - Training Epoch: 2/2, step 22092/23838 completed (loss: 0.46566399931907654, acc: 0.8571428656578064)
[2025-02-04 03:03:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22094/23838 [26:26<09:56,  2.92it/s][2025-02-04 03:03:15][root][INFO] - Training Epoch: 2/2, step 22093/23838 completed (loss: 0.5815244913101196, acc: 0.8048780560493469)
[2025-02-04 03:03:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22095/23838 [26:26<10:06,  2.87it/s][2025-02-04 03:03:16][root][INFO] - Training Epoch: 2/2, step 22094/23838 completed (loss: 0.4431810677051544, acc: 0.8999999761581421)
[2025-02-04 03:03:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22096/23838 [26:27<11:55,  2.43it/s][2025-02-04 03:03:16][root][INFO] - Training Epoch: 2/2, step 22095/23838 completed (loss: 0.6362664103507996, acc: 0.792682945728302)
[2025-02-04 03:03:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22097/23838 [26:27<11:44,  2.47it/s][2025-02-04 03:03:17][root][INFO] - Training Epoch: 2/2, step 22096/23838 completed (loss: 0.6836984157562256, acc: 0.7745097875595093)
[2025-02-04 03:03:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22098/23838 [26:27<11:44,  2.47it/s][2025-02-04 03:03:17][root][INFO] - Training Epoch: 2/2, step 22097/23838 completed (loss: 0.5555621981620789, acc: 0.8349514603614807)
[2025-02-04 03:03:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22099/23838 [26:28<12:00,  2.41it/s][2025-02-04 03:03:17][root][INFO] - Training Epoch: 2/2, step 22098/23838 completed (loss: 1.0588058233261108, acc: 0.6913580298423767)
[2025-02-04 03:03:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22100/23838 [26:28<11:37,  2.49it/s][2025-02-04 03:03:18][root][INFO] - Training Epoch: 2/2, step 22099/23838 completed (loss: 0.5566213130950928, acc: 0.8651685118675232)
[2025-02-04 03:03:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22101/23838 [26:29<12:43,  2.27it/s][2025-02-04 03:03:18][root][INFO] - Training Epoch: 2/2, step 22100/23838 completed (loss: 0.6453209519386292, acc: 0.8600000143051147)
[2025-02-04 03:03:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22102/23838 [26:29<11:55,  2.43it/s][2025-02-04 03:03:19][root][INFO] - Training Epoch: 2/2, step 22101/23838 completed (loss: 0.5012425780296326, acc: 0.8799999952316284)
[2025-02-04 03:03:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22103/23838 [26:29<11:56,  2.42it/s][2025-02-04 03:03:19][root][INFO] - Training Epoch: 2/2, step 22102/23838 completed (loss: 0.09590502828359604, acc: 0.9692307710647583)
[2025-02-04 03:03:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22104/23838 [26:30<11:45,  2.46it/s][2025-02-04 03:03:19][root][INFO] - Training Epoch: 2/2, step 22103/23838 completed (loss: 0.2529454529285431, acc: 0.9285714030265808)
[2025-02-04 03:03:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22105/23838 [26:30<11:08,  2.59it/s][2025-02-04 03:03:20][root][INFO] - Training Epoch: 2/2, step 22104/23838 completed (loss: 0.19342006742954254, acc: 0.9369369149208069)
[2025-02-04 03:03:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22106/23838 [26:31<10:44,  2.69it/s][2025-02-04 03:03:20][root][INFO] - Training Epoch: 2/2, step 22105/23838 completed (loss: 0.1123725175857544, acc: 0.9666666388511658)
[2025-02-04 03:03:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22107/23838 [26:31<11:12,  2.58it/s][2025-02-04 03:03:21][root][INFO] - Training Epoch: 2/2, step 22106/23838 completed (loss: 0.24264192581176758, acc: 0.930232584476471)
[2025-02-04 03:03:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22108/23838 [26:31<10:57,  2.63it/s][2025-02-04 03:03:21][root][INFO] - Training Epoch: 2/2, step 22107/23838 completed (loss: 0.1916419416666031, acc: 0.9245283007621765)
[2025-02-04 03:03:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22109/23838 [26:32<10:37,  2.71it/s][2025-02-04 03:03:21][root][INFO] - Training Epoch: 2/2, step 22108/23838 completed (loss: 0.2543141543865204, acc: 0.9259259104728699)
[2025-02-04 03:03:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22110/23838 [26:32<10:32,  2.73it/s][2025-02-04 03:03:22][root][INFO] - Training Epoch: 2/2, step 22109/23838 completed (loss: 0.1133972704410553, acc: 0.9659863710403442)
[2025-02-04 03:03:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22111/23838 [26:32<10:41,  2.69it/s][2025-02-04 03:03:22][root][INFO] - Training Epoch: 2/2, step 22110/23838 completed (loss: 0.17971278727054596, acc: 0.9333333373069763)
[2025-02-04 03:03:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22112/23838 [26:33<10:35,  2.72it/s][2025-02-04 03:03:22][root][INFO] - Training Epoch: 2/2, step 22111/23838 completed (loss: 0.2841144800186157, acc: 0.8888888955116272)
[2025-02-04 03:03:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22113/23838 [26:33<11:00,  2.61it/s][2025-02-04 03:03:23][root][INFO] - Training Epoch: 2/2, step 22112/23838 completed (loss: 0.2881680727005005, acc: 0.9069767594337463)
[2025-02-04 03:03:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22114/23838 [26:34<11:09,  2.57it/s][2025-02-04 03:03:23][root][INFO] - Training Epoch: 2/2, step 22113/23838 completed (loss: 0.25853756070137024, acc: 0.9285714030265808)
[2025-02-04 03:03:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22115/23838 [26:34<11:13,  2.56it/s][2025-02-04 03:03:24][root][INFO] - Training Epoch: 2/2, step 22114/23838 completed (loss: 0.25690460205078125, acc: 0.948051929473877)
[2025-02-04 03:03:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22116/23838 [26:35<14:01,  2.05it/s][2025-02-04 03:03:24][root][INFO] - Training Epoch: 2/2, step 22115/23838 completed (loss: 0.24184836447238922, acc: 0.9252336621284485)
[2025-02-04 03:03:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22117/23838 [26:35<13:33,  2.12it/s][2025-02-04 03:03:25][root][INFO] - Training Epoch: 2/2, step 22116/23838 completed (loss: 0.4778684079647064, acc: 0.8804348111152649)
[2025-02-04 03:03:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22118/23838 [26:36<13:27,  2.13it/s][2025-02-04 03:03:25][root][INFO] - Training Epoch: 2/2, step 22117/23838 completed (loss: 0.23778820037841797, acc: 0.9375)
[2025-02-04 03:03:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22119/23838 [26:36<13:18,  2.15it/s][2025-02-04 03:03:26][root][INFO] - Training Epoch: 2/2, step 22118/23838 completed (loss: 0.28377509117126465, acc: 0.9462365508079529)
[2025-02-04 03:03:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22120/23838 [26:37<13:12,  2.17it/s][2025-02-04 03:03:26][root][INFO] - Training Epoch: 2/2, step 22119/23838 completed (loss: 0.24349109828472137, acc: 0.9125683307647705)
[2025-02-04 03:03:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22121/23838 [26:37<14:13,  2.01it/s][2025-02-04 03:03:27][root][INFO] - Training Epoch: 2/2, step 22120/23838 completed (loss: 0.21676023304462433, acc: 0.9555555582046509)
[2025-02-04 03:03:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22122/23838 [26:38<14:44,  1.94it/s][2025-02-04 03:03:27][root][INFO] - Training Epoch: 2/2, step 22121/23838 completed (loss: 0.14860203862190247, acc: 0.9587628841400146)
[2025-02-04 03:03:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22123/23838 [26:38<13:33,  2.11it/s][2025-02-04 03:03:28][root][INFO] - Training Epoch: 2/2, step 22122/23838 completed (loss: 0.2692226767539978, acc: 0.9504950642585754)
[2025-02-04 03:03:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22124/23838 [26:38<13:05,  2.18it/s][2025-02-04 03:03:28][root][INFO] - Training Epoch: 2/2, step 22123/23838 completed (loss: 0.47595956921577454, acc: 0.8482142686843872)
[2025-02-04 03:03:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22125/23838 [26:39<12:41,  2.25it/s][2025-02-04 03:03:28][root][INFO] - Training Epoch: 2/2, step 22124/23838 completed (loss: 0.19332829117774963, acc: 0.9803921580314636)
[2025-02-04 03:03:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22126/23838 [26:39<12:26,  2.29it/s][2025-02-04 03:03:29][root][INFO] - Training Epoch: 2/2, step 22125/23838 completed (loss: 0.13549034297466278, acc: 0.9611650705337524)
[2025-02-04 03:03:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22127/23838 [26:40<13:34,  2.10it/s][2025-02-04 03:03:29][root][INFO] - Training Epoch: 2/2, step 22126/23838 completed (loss: 0.5334988832473755, acc: 0.8585858345031738)
[2025-02-04 03:03:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22128/23838 [26:40<12:46,  2.23it/s][2025-02-04 03:03:30][root][INFO] - Training Epoch: 2/2, step 22127/23838 completed (loss: 0.49189770221710205, acc: 0.8309859037399292)
[2025-02-04 03:03:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22129/23838 [26:41<12:15,  2.33it/s][2025-02-04 03:03:30][root][INFO] - Training Epoch: 2/2, step 22128/23838 completed (loss: 0.4133676588535309, acc: 0.8981481194496155)
[2025-02-04 03:03:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22130/23838 [26:41<11:19,  2.51it/s][2025-02-04 03:03:31][root][INFO] - Training Epoch: 2/2, step 22129/23838 completed (loss: 0.2511812150478363, acc: 0.9215686321258545)
[2025-02-04 03:03:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22131/23838 [26:41<10:41,  2.66it/s][2025-02-04 03:03:31][root][INFO] - Training Epoch: 2/2, step 22130/23838 completed (loss: 0.14553087949752808, acc: 0.9365079402923584)
[2025-02-04 03:03:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22132/23838 [26:42<10:24,  2.73it/s][2025-02-04 03:03:31][root][INFO] - Training Epoch: 2/2, step 22131/23838 completed (loss: 0.2962770462036133, acc: 0.9352940917015076)
[2025-02-04 03:03:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22133/23838 [26:42<11:28,  2.48it/s][2025-02-04 03:03:32][root][INFO] - Training Epoch: 2/2, step 22132/23838 completed (loss: 0.3904604911804199, acc: 0.8797468543052673)
[2025-02-04 03:03:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22134/23838 [26:42<10:45,  2.64it/s][2025-02-04 03:03:32][root][INFO] - Training Epoch: 2/2, step 22133/23838 completed (loss: 0.17764008045196533, acc: 0.9727272987365723)
[2025-02-04 03:03:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22135/23838 [26:43<10:14,  2.77it/s][2025-02-04 03:03:32][root][INFO] - Training Epoch: 2/2, step 22134/23838 completed (loss: 0.280959814786911, acc: 0.9154929518699646)
[2025-02-04 03:03:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22136/23838 [26:43<12:05,  2.35it/s][2025-02-04 03:03:33][root][INFO] - Training Epoch: 2/2, step 22135/23838 completed (loss: 0.24709630012512207, acc: 0.9230769276618958)
[2025-02-04 03:03:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22137/23838 [26:44<13:22,  2.12it/s][2025-02-04 03:03:33][root][INFO] - Training Epoch: 2/2, step 22136/23838 completed (loss: 0.12250314652919769, acc: 0.9626168012619019)
[2025-02-04 03:03:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22138/23838 [26:45<14:40,  1.93it/s][2025-02-04 03:03:34][root][INFO] - Training Epoch: 2/2, step 22137/23838 completed (loss: 0.35029736161231995, acc: 0.8742138147354126)
[2025-02-04 03:03:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22139/23838 [26:45<14:29,  1.95it/s][2025-02-04 03:03:35][root][INFO] - Training Epoch: 2/2, step 22138/23838 completed (loss: 0.17087878286838531, acc: 0.9551281929016113)
[2025-02-04 03:03:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22140/23838 [26:45<13:10,  2.15it/s][2025-02-04 03:03:35][root][INFO] - Training Epoch: 2/2, step 22139/23838 completed (loss: 0.1617717742919922, acc: 0.9390243887901306)
[2025-02-04 03:03:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22141/23838 [26:46<12:36,  2.24it/s][2025-02-04 03:03:35][root][INFO] - Training Epoch: 2/2, step 22140/23838 completed (loss: 0.4245128929615021, acc: 0.8971962332725525)
[2025-02-04 03:03:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22142/23838 [26:46<12:01,  2.35it/s][2025-02-04 03:03:36][root][INFO] - Training Epoch: 2/2, step 22141/23838 completed (loss: 1.346539855003357, acc: 0.5)
[2025-02-04 03:03:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22143/23838 [26:47<11:56,  2.36it/s][2025-02-04 03:03:36][root][INFO] - Training Epoch: 2/2, step 22142/23838 completed (loss: 0.8751220107078552, acc: 0.7227723002433777)
[2025-02-04 03:03:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22144/23838 [26:47<11:40,  2.42it/s][2025-02-04 03:03:37][root][INFO] - Training Epoch: 2/2, step 22143/23838 completed (loss: 0.9126076102256775, acc: 0.7692307829856873)
[2025-02-04 03:03:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22145/23838 [26:47<11:24,  2.47it/s][2025-02-04 03:03:37][root][INFO] - Training Epoch: 2/2, step 22144/23838 completed (loss: 0.5647637844085693, acc: 0.8780487775802612)
[2025-02-04 03:03:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22146/23838 [26:48<10:54,  2.59it/s][2025-02-04 03:03:37][root][INFO] - Training Epoch: 2/2, step 22145/23838 completed (loss: 0.9608134031295776, acc: 0.7547169923782349)
[2025-02-04 03:03:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22147/23838 [26:48<10:08,  2.78it/s][2025-02-04 03:03:38][root][INFO] - Training Epoch: 2/2, step 22146/23838 completed (loss: 0.9767913222312927, acc: 0.7333333492279053)
[2025-02-04 03:03:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22148/23838 [26:48<10:08,  2.78it/s][2025-02-04 03:03:38][root][INFO] - Training Epoch: 2/2, step 22147/23838 completed (loss: 0.8290296792984009, acc: 0.7894737124443054)
[2025-02-04 03:03:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22149/23838 [26:49<10:07,  2.78it/s][2025-02-04 03:03:38][root][INFO] - Training Epoch: 2/2, step 22148/23838 completed (loss: 0.6878836750984192, acc: 0.7804877758026123)
[2025-02-04 03:03:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22150/23838 [26:49<10:18,  2.73it/s][2025-02-04 03:03:39][root][INFO] - Training Epoch: 2/2, step 22149/23838 completed (loss: 1.0396349430084229, acc: 0.7142857313156128)
[2025-02-04 03:03:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22151/23838 [26:49<10:14,  2.74it/s][2025-02-04 03:03:39][root][INFO] - Training Epoch: 2/2, step 22150/23838 completed (loss: 0.5568852424621582, acc: 0.7843137383460999)
[2025-02-04 03:03:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22152/23838 [26:50<10:10,  2.76it/s][2025-02-04 03:03:39][root][INFO] - Training Epoch: 2/2, step 22151/23838 completed (loss: 0.49360719323158264, acc: 0.8333333134651184)
[2025-02-04 03:03:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22153/23838 [26:50<09:55,  2.83it/s][2025-02-04 03:03:40][root][INFO] - Training Epoch: 2/2, step 22152/23838 completed (loss: 0.40327852964401245, acc: 0.9069767594337463)
[2025-02-04 03:03:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22154/23838 [26:51<10:01,  2.80it/s][2025-02-04 03:03:40][root][INFO] - Training Epoch: 2/2, step 22153/23838 completed (loss: 0.9698002338409424, acc: 0.761904776096344)
[2025-02-04 03:03:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22155/23838 [26:51<09:56,  2.82it/s][2025-02-04 03:03:40][root][INFO] - Training Epoch: 2/2, step 22154/23838 completed (loss: 0.8754462599754333, acc: 0.6153846383094788)
[2025-02-04 03:03:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22156/23838 [26:51<09:53,  2.83it/s][2025-02-04 03:03:41][root][INFO] - Training Epoch: 2/2, step 22155/23838 completed (loss: 0.6826571822166443, acc: 0.7735849022865295)
[2025-02-04 03:03:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22157/23838 [26:52<10:12,  2.74it/s][2025-02-04 03:03:41][root][INFO] - Training Epoch: 2/2, step 22156/23838 completed (loss: 0.6724891066551208, acc: 0.807692289352417)
[2025-02-04 03:03:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22158/23838 [26:52<09:57,  2.81it/s][2025-02-04 03:03:42][root][INFO] - Training Epoch: 2/2, step 22157/23838 completed (loss: 0.9199820160865784, acc: 0.7674418687820435)
[2025-02-04 03:03:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22159/23838 [26:52<10:06,  2.77it/s][2025-02-04 03:03:42][root][INFO] - Training Epoch: 2/2, step 22158/23838 completed (loss: 0.7976312041282654, acc: 0.7708333134651184)
[2025-02-04 03:03:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22160/23838 [26:53<09:51,  2.84it/s][2025-02-04 03:03:42][root][INFO] - Training Epoch: 2/2, step 22159/23838 completed (loss: 0.9633895754814148, acc: 0.65625)
[2025-02-04 03:03:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22161/23838 [26:53<09:01,  3.10it/s][2025-02-04 03:03:42][root][INFO] - Training Epoch: 2/2, step 22160/23838 completed (loss: 0.9202483296394348, acc: 0.7285714149475098)
[2025-02-04 03:03:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22162/23838 [26:53<08:46,  3.18it/s][2025-02-04 03:03:43][root][INFO] - Training Epoch: 2/2, step 22161/23838 completed (loss: 0.6822549700737, acc: 0.8399999737739563)
[2025-02-04 03:03:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22163/23838 [26:54<09:11,  3.04it/s][2025-02-04 03:03:43][root][INFO] - Training Epoch: 2/2, step 22162/23838 completed (loss: 1.1272639036178589, acc: 0.6470588445663452)
[2025-02-04 03:03:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22164/23838 [26:54<09:54,  2.82it/s][2025-02-04 03:03:44][root][INFO] - Training Epoch: 2/2, step 22163/23838 completed (loss: 0.2446247637271881, acc: 0.9545454382896423)
[2025-02-04 03:03:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22165/23838 [26:54<09:37,  2.90it/s][2025-02-04 03:03:44][root][INFO] - Training Epoch: 2/2, step 22164/23838 completed (loss: 0.22462712228298187, acc: 0.9107142686843872)
[2025-02-04 03:03:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22166/23838 [26:55<09:57,  2.80it/s][2025-02-04 03:03:44][root][INFO] - Training Epoch: 2/2, step 22165/23838 completed (loss: 0.6716790795326233, acc: 0.7708333134651184)
[2025-02-04 03:03:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22167/23838 [26:55<09:39,  2.89it/s][2025-02-04 03:03:45][root][INFO] - Training Epoch: 2/2, step 22166/23838 completed (loss: 0.598301351070404, acc: 0.8571428656578064)
[2025-02-04 03:03:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22168/23838 [26:55<09:35,  2.90it/s][2025-02-04 03:03:45][root][INFO] - Training Epoch: 2/2, step 22167/23838 completed (loss: 0.35364529490470886, acc: 0.8846153616905212)
[2025-02-04 03:03:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22169/23838 [26:56<09:35,  2.90it/s][2025-02-04 03:03:45][root][INFO] - Training Epoch: 2/2, step 22168/23838 completed (loss: 0.44741347432136536, acc: 0.8225806355476379)
[2025-02-04 03:03:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22170/23838 [26:56<09:34,  2.90it/s][2025-02-04 03:03:46][root][INFO] - Training Epoch: 2/2, step 22169/23838 completed (loss: 0.4122190475463867, acc: 0.8571428656578064)
[2025-02-04 03:03:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22171/23838 [26:56<09:50,  2.83it/s][2025-02-04 03:03:46][root][INFO] - Training Epoch: 2/2, step 22170/23838 completed (loss: 0.550642728805542, acc: 0.8416666388511658)
[2025-02-04 03:03:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22172/23838 [26:57<10:29,  2.65it/s][2025-02-04 03:03:46][root][INFO] - Training Epoch: 2/2, step 22171/23838 completed (loss: 0.6528207659721375, acc: 0.8461538553237915)
[2025-02-04 03:03:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22173/23838 [26:57<10:46,  2.57it/s][2025-02-04 03:03:47][root][INFO] - Training Epoch: 2/2, step 22172/23838 completed (loss: 0.8870677947998047, acc: 0.7066666483879089)
[2025-02-04 03:03:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22174/23838 [26:58<10:24,  2.67it/s][2025-02-04 03:03:47][root][INFO] - Training Epoch: 2/2, step 22173/23838 completed (loss: 0.6532688736915588, acc: 0.7962962985038757)
[2025-02-04 03:03:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22175/23838 [26:58<10:32,  2.63it/s][2025-02-04 03:03:48][root][INFO] - Training Epoch: 2/2, step 22174/23838 completed (loss: 0.4255966544151306, acc: 0.8691588640213013)
[2025-02-04 03:03:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22176/23838 [26:58<10:06,  2.74it/s][2025-02-04 03:03:48][root][INFO] - Training Epoch: 2/2, step 22175/23838 completed (loss: 0.615699827671051, acc: 0.8072289228439331)
[2025-02-04 03:03:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22177/23838 [26:59<09:12,  3.01it/s][2025-02-04 03:03:48][root][INFO] - Training Epoch: 2/2, step 22176/23838 completed (loss: 0.9763639569282532, acc: 0.6428571343421936)
[2025-02-04 03:03:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22178/23838 [26:59<09:34,  2.89it/s][2025-02-04 03:03:49][root][INFO] - Training Epoch: 2/2, step 22177/23838 completed (loss: 0.638670027256012, acc: 0.8073394298553467)
[2025-02-04 03:03:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22179/23838 [26:59<09:41,  2.85it/s][2025-02-04 03:03:49][root][INFO] - Training Epoch: 2/2, step 22178/23838 completed (loss: 0.7705919146537781, acc: 0.7699999809265137)
[2025-02-04 03:03:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22180/23838 [27:00<09:21,  2.95it/s][2025-02-04 03:03:49][root][INFO] - Training Epoch: 2/2, step 22179/23838 completed (loss: 0.5637383460998535, acc: 0.800000011920929)
[2025-02-04 03:03:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22181/23838 [27:00<10:23,  2.66it/s][2025-02-04 03:03:50][root][INFO] - Training Epoch: 2/2, step 22180/23838 completed (loss: 0.7128739356994629, acc: 0.8041236996650696)
[2025-02-04 03:03:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22182/23838 [27:00<10:24,  2.65it/s][2025-02-04 03:03:50][root][INFO] - Training Epoch: 2/2, step 22181/23838 completed (loss: 2.0090415477752686, acc: 0.6222222447395325)
[2025-02-04 03:03:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22183/23838 [27:01<10:00,  2.75it/s][2025-02-04 03:03:50][root][INFO] - Training Epoch: 2/2, step 22182/23838 completed (loss: 0.988505482673645, acc: 0.6779661178588867)
[2025-02-04 03:03:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22184/23838 [27:01<10:11,  2.71it/s][2025-02-04 03:03:51][root][INFO] - Training Epoch: 2/2, step 22183/23838 completed (loss: 0.670832097530365, acc: 0.8055555820465088)
[2025-02-04 03:03:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22185/23838 [27:02<10:20,  2.67it/s][2025-02-04 03:03:51][root][INFO] - Training Epoch: 2/2, step 22184/23838 completed (loss: 0.8437302708625793, acc: 0.7903226017951965)
[2025-02-04 03:03:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22186/23838 [27:02<10:00,  2.75it/s][2025-02-04 03:03:52][root][INFO] - Training Epoch: 2/2, step 22185/23838 completed (loss: 0.8396303057670593, acc: 0.7818182110786438)
[2025-02-04 03:03:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22187/23838 [27:02<10:10,  2.70it/s][2025-02-04 03:03:52][root][INFO] - Training Epoch: 2/2, step 22186/23838 completed (loss: 0.7763912081718445, acc: 0.7209302186965942)
[2025-02-04 03:03:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22188/23838 [27:03<10:19,  2.66it/s][2025-02-04 03:03:52][root][INFO] - Training Epoch: 2/2, step 22187/23838 completed (loss: 0.6347667574882507, acc: 0.8055555820465088)
[2025-02-04 03:03:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22189/23838 [27:03<10:19,  2.66it/s][2025-02-04 03:03:53][root][INFO] - Training Epoch: 2/2, step 22188/23838 completed (loss: 0.9279006123542786, acc: 0.7647058963775635)
[2025-02-04 03:03:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22190/23838 [27:03<10:41,  2.57it/s][2025-02-04 03:03:53][root][INFO] - Training Epoch: 2/2, step 22189/23838 completed (loss: 0.7372022867202759, acc: 0.7910447716712952)
[2025-02-04 03:03:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22191/23838 [27:04<10:20,  2.66it/s][2025-02-04 03:03:53][root][INFO] - Training Epoch: 2/2, step 22190/23838 completed (loss: 0.9684596061706543, acc: 0.7037037014961243)
[2025-02-04 03:03:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22192/23838 [27:04<10:06,  2.71it/s][2025-02-04 03:03:54][root][INFO] - Training Epoch: 2/2, step 22191/23838 completed (loss: 0.6541034579277039, acc: 0.8301886916160583)
[2025-02-04 03:03:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22193/23838 [27:05<09:57,  2.75it/s][2025-02-04 03:03:54][root][INFO] - Training Epoch: 2/2, step 22192/23838 completed (loss: 0.4257357716560364, acc: 0.9056603908538818)
[2025-02-04 03:03:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22194/23838 [27:05<09:50,  2.78it/s][2025-02-04 03:03:54][root][INFO] - Training Epoch: 2/2, step 22193/23838 completed (loss: 0.4639788866043091, acc: 0.8409090638160706)
[2025-02-04 03:03:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22195/23838 [27:05<09:40,  2.83it/s][2025-02-04 03:03:55][root][INFO] - Training Epoch: 2/2, step 22194/23838 completed (loss: 0.2934991419315338, acc: 0.8909090757369995)
[2025-02-04 03:03:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22196/23838 [27:06<09:32,  2.87it/s][2025-02-04 03:03:55][root][INFO] - Training Epoch: 2/2, step 22195/23838 completed (loss: 0.667980968952179, acc: 0.761904776096344)
[2025-02-04 03:03:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22197/23838 [27:06<09:26,  2.89it/s][2025-02-04 03:03:55][root][INFO] - Training Epoch: 2/2, step 22196/23838 completed (loss: 0.6234086155891418, acc: 0.8214285969734192)
[2025-02-04 03:03:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22198/23838 [27:06<10:00,  2.73it/s][2025-02-04 03:03:56][root][INFO] - Training Epoch: 2/2, step 22197/23838 completed (loss: 0.3316217064857483, acc: 0.8888888955116272)
[2025-02-04 03:03:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22199/23838 [27:07<10:20,  2.64it/s][2025-02-04 03:03:56][root][INFO] - Training Epoch: 2/2, step 22198/23838 completed (loss: 0.5475649237632751, acc: 0.8529411554336548)
[2025-02-04 03:03:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22200/23838 [27:07<10:09,  2.69it/s][2025-02-04 03:03:57][root][INFO] - Training Epoch: 2/2, step 22199/23838 completed (loss: 0.4239208698272705, acc: 0.8918918967247009)
[2025-02-04 03:03:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22201/23838 [27:08<10:40,  2.56it/s][2025-02-04 03:03:57][root][INFO] - Training Epoch: 2/2, step 22200/23838 completed (loss: 0.9117588996887207, acc: 0.746268630027771)
[2025-02-04 03:03:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22202/23838 [27:08<10:19,  2.64it/s][2025-02-04 03:03:57][root][INFO] - Training Epoch: 2/2, step 22201/23838 completed (loss: 1.238618016242981, acc: 0.625)
[2025-02-04 03:03:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22203/23838 [27:08<10:44,  2.54it/s][2025-02-04 03:03:58][root][INFO] - Training Epoch: 2/2, step 22202/23838 completed (loss: 0.8944657444953918, acc: 0.7708333134651184)
[2025-02-04 03:03:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22204/23838 [27:09<10:38,  2.56it/s][2025-02-04 03:03:58][root][INFO] - Training Epoch: 2/2, step 22203/23838 completed (loss: 0.45431044697761536, acc: 0.8070175647735596)
[2025-02-04 03:03:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22205/23838 [27:09<10:00,  2.72it/s][2025-02-04 03:03:59][root][INFO] - Training Epoch: 2/2, step 22204/23838 completed (loss: 0.6999248266220093, acc: 0.813725471496582)
[2025-02-04 03:03:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22206/23838 [27:09<09:40,  2.81it/s][2025-02-04 03:03:59][root][INFO] - Training Epoch: 2/2, step 22205/23838 completed (loss: 0.7961452603340149, acc: 0.7916666865348816)
[2025-02-04 03:03:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22207/23838 [27:10<09:32,  2.85it/s][2025-02-04 03:03:59][root][INFO] - Training Epoch: 2/2, step 22206/23838 completed (loss: 0.8839083313941956, acc: 0.739130437374115)
[2025-02-04 03:03:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22208/23838 [27:10<09:32,  2.85it/s][2025-02-04 03:04:00][root][INFO] - Training Epoch: 2/2, step 22207/23838 completed (loss: 0.6286263465881348, acc: 0.8181818127632141)
[2025-02-04 03:04:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22209/23838 [27:10<09:41,  2.80it/s][2025-02-04 03:04:00][root][INFO] - Training Epoch: 2/2, step 22208/23838 completed (loss: 0.7046558260917664, acc: 0.7586206793785095)
[2025-02-04 03:04:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22210/23838 [27:11<09:52,  2.75it/s][2025-02-04 03:04:00][root][INFO] - Training Epoch: 2/2, step 22209/23838 completed (loss: 0.7201390266418457, acc: 0.7804877758026123)
[2025-02-04 03:04:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22211/23838 [27:11<10:06,  2.68it/s][2025-02-04 03:04:01][root][INFO] - Training Epoch: 2/2, step 22210/23838 completed (loss: 0.8217242956161499, acc: 0.782608687877655)
[2025-02-04 03:04:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22212/23838 [27:12<09:57,  2.72it/s][2025-02-04 03:04:01][root][INFO] - Training Epoch: 2/2, step 22211/23838 completed (loss: 0.5873975157737732, acc: 0.8409090638160706)
[2025-02-04 03:04:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22213/23838 [27:12<09:46,  2.77it/s][2025-02-04 03:04:01][root][INFO] - Training Epoch: 2/2, step 22212/23838 completed (loss: 0.29605066776275635, acc: 0.931034505367279)
[2025-02-04 03:04:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22214/23838 [27:12<09:31,  2.84it/s][2025-02-04 03:04:02][root][INFO] - Training Epoch: 2/2, step 22213/23838 completed (loss: 0.1880636066198349, acc: 0.9200000166893005)
[2025-02-04 03:04:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22215/23838 [27:12<09:05,  2.97it/s][2025-02-04 03:04:02][root][INFO] - Training Epoch: 2/2, step 22214/23838 completed (loss: 0.6014099717140198, acc: 0.8035714030265808)
[2025-02-04 03:04:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22216/23838 [27:13<08:59,  3.01it/s][2025-02-04 03:04:02][root][INFO] - Training Epoch: 2/2, step 22215/23838 completed (loss: 0.29593172669410706, acc: 0.8783783912658691)
[2025-02-04 03:04:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22217/23838 [27:13<08:57,  3.01it/s][2025-02-04 03:04:03][root][INFO] - Training Epoch: 2/2, step 22216/23838 completed (loss: 1.3727648258209229, acc: 0.5652173757553101)
[2025-02-04 03:04:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22218/23838 [27:13<08:48,  3.06it/s][2025-02-04 03:04:03][root][INFO] - Training Epoch: 2/2, step 22217/23838 completed (loss: 0.4880908131599426, acc: 0.8666666746139526)
[2025-02-04 03:04:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22219/23838 [27:14<08:52,  3.04it/s][2025-02-04 03:04:03][root][INFO] - Training Epoch: 2/2, step 22218/23838 completed (loss: 0.4939478039741516, acc: 0.8823529481887817)
[2025-02-04 03:04:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22220/23838 [27:14<08:48,  3.06it/s][2025-02-04 03:04:04][root][INFO] - Training Epoch: 2/2, step 22219/23838 completed (loss: 0.2724270224571228, acc: 0.875)
[2025-02-04 03:04:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22221/23838 [27:14<08:54,  3.02it/s][2025-02-04 03:04:04][root][INFO] - Training Epoch: 2/2, step 22220/23838 completed (loss: 0.5522347688674927, acc: 0.8999999761581421)
[2025-02-04 03:04:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22222/23838 [27:15<08:56,  3.01it/s][2025-02-04 03:04:04][root][INFO] - Training Epoch: 2/2, step 22221/23838 completed (loss: 0.6345208883285522, acc: 0.7571428418159485)
[2025-02-04 03:04:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22223/23838 [27:15<09:04,  2.97it/s][2025-02-04 03:04:05][root][INFO] - Training Epoch: 2/2, step 22222/23838 completed (loss: 0.7862743139266968, acc: 0.7636363506317139)
[2025-02-04 03:04:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22224/23838 [27:16<09:25,  2.85it/s][2025-02-04 03:04:05][root][INFO] - Training Epoch: 2/2, step 22223/23838 completed (loss: 0.43684491515159607, acc: 0.8615384697914124)
[2025-02-04 03:04:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22225/23838 [27:16<09:44,  2.76it/s][2025-02-04 03:04:05][root][INFO] - Training Epoch: 2/2, step 22224/23838 completed (loss: 0.8109614253044128, acc: 0.7681159377098083)
[2025-02-04 03:04:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22226/23838 [27:16<10:07,  2.65it/s][2025-02-04 03:04:06][root][INFO] - Training Epoch: 2/2, step 22225/23838 completed (loss: 0.6900875568389893, acc: 0.8461538553237915)
[2025-02-04 03:04:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22227/23838 [27:17<10:05,  2.66it/s][2025-02-04 03:04:06][root][INFO] - Training Epoch: 2/2, step 22226/23838 completed (loss: 0.4442710876464844, acc: 0.8867924809455872)
[2025-02-04 03:04:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22228/23838 [27:17<09:58,  2.69it/s][2025-02-04 03:04:07][root][INFO] - Training Epoch: 2/2, step 22227/23838 completed (loss: 0.6599791049957275, acc: 0.8125)
[2025-02-04 03:04:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22229/23838 [27:17<09:44,  2.75it/s][2025-02-04 03:04:07][root][INFO] - Training Epoch: 2/2, step 22228/23838 completed (loss: 0.5797650814056396, acc: 0.8333333134651184)
[2025-02-04 03:04:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22230/23838 [27:18<09:42,  2.76it/s][2025-02-04 03:04:07][root][INFO] - Training Epoch: 2/2, step 22229/23838 completed (loss: 0.37807294726371765, acc: 0.8780487775802612)
[2025-02-04 03:04:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22231/23838 [27:18<09:13,  2.91it/s][2025-02-04 03:04:08][root][INFO] - Training Epoch: 2/2, step 22230/23838 completed (loss: 0.44517794251441956, acc: 0.9090909361839294)
[2025-02-04 03:04:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22232/23838 [27:18<08:59,  2.97it/s][2025-02-04 03:04:08][root][INFO] - Training Epoch: 2/2, step 22231/23838 completed (loss: 0.9219653606414795, acc: 0.6875)
[2025-02-04 03:04:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22233/23838 [27:19<08:58,  2.98it/s][2025-02-04 03:04:08][root][INFO] - Training Epoch: 2/2, step 22232/23838 completed (loss: 0.6878937482833862, acc: 0.7586206793785095)
[2025-02-04 03:04:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22234/23838 [27:19<09:11,  2.91it/s][2025-02-04 03:04:09][root][INFO] - Training Epoch: 2/2, step 22233/23838 completed (loss: 0.312587708234787, acc: 0.9375)
[2025-02-04 03:04:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22235/23838 [27:19<09:09,  2.91it/s][2025-02-04 03:04:09][root][INFO] - Training Epoch: 2/2, step 22234/23838 completed (loss: 0.7559231519699097, acc: 0.800000011920929)
[2025-02-04 03:04:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22236/23838 [27:20<09:24,  2.84it/s][2025-02-04 03:04:09][root][INFO] - Training Epoch: 2/2, step 22235/23838 completed (loss: 0.14020183682441711, acc: 0.95652174949646)
[2025-02-04 03:04:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22237/23838 [27:20<09:21,  2.85it/s][2025-02-04 03:04:10][root][INFO] - Training Epoch: 2/2, step 22236/23838 completed (loss: 0.7230613231658936, acc: 0.761904776096344)
[2025-02-04 03:04:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22238/23838 [27:20<09:15,  2.88it/s][2025-02-04 03:04:10][root][INFO] - Training Epoch: 2/2, step 22237/23838 completed (loss: 0.13092578947544098, acc: 1.0)
[2025-02-04 03:04:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22239/23838 [27:21<09:10,  2.91it/s][2025-02-04 03:04:10][root][INFO] - Training Epoch: 2/2, step 22238/23838 completed (loss: 0.5336011052131653, acc: 0.7857142686843872)
[2025-02-04 03:04:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22240/23838 [27:21<09:30,  2.80it/s][2025-02-04 03:04:11][root][INFO] - Training Epoch: 2/2, step 22239/23838 completed (loss: 0.3380829095840454, acc: 0.9230769276618958)
[2025-02-04 03:04:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22241/23838 [27:22<09:47,  2.72it/s][2025-02-04 03:04:11][root][INFO] - Training Epoch: 2/2, step 22240/23838 completed (loss: 0.37701013684272766, acc: 0.8965517282485962)
[2025-02-04 03:04:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22242/23838 [27:22<10:11,  2.61it/s][2025-02-04 03:04:12][root][INFO] - Training Epoch: 2/2, step 22241/23838 completed (loss: 0.408875435590744, acc: 0.9189189076423645)
[2025-02-04 03:04:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22243/23838 [27:22<09:55,  2.68it/s][2025-02-04 03:04:12][root][INFO] - Training Epoch: 2/2, step 22242/23838 completed (loss: 0.2968018352985382, acc: 0.9285714030265808)
[2025-02-04 03:04:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22244/23838 [27:23<09:32,  2.79it/s][2025-02-04 03:04:12][root][INFO] - Training Epoch: 2/2, step 22243/23838 completed (loss: 0.5939531922340393, acc: 0.8717948794364929)
[2025-02-04 03:04:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22245/23838 [27:23<09:10,  2.89it/s][2025-02-04 03:04:13][root][INFO] - Training Epoch: 2/2, step 22244/23838 completed (loss: 0.30630624294281006, acc: 0.9444444179534912)
[2025-02-04 03:04:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22246/23838 [27:23<09:15,  2.87it/s][2025-02-04 03:04:13][root][INFO] - Training Epoch: 2/2, step 22245/23838 completed (loss: 0.6200572848320007, acc: 0.7894737124443054)
[2025-02-04 03:04:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22247/23838 [27:24<09:18,  2.85it/s][2025-02-04 03:04:13][root][INFO] - Training Epoch: 2/2, step 22246/23838 completed (loss: 0.24746012687683105, acc: 0.875)
[2025-02-04 03:04:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22248/23838 [27:24<09:00,  2.94it/s][2025-02-04 03:04:14][root][INFO] - Training Epoch: 2/2, step 22247/23838 completed (loss: 0.3562309741973877, acc: 0.9473684430122375)
[2025-02-04 03:04:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22249/23838 [27:24<08:48,  3.01it/s][2025-02-04 03:04:14][root][INFO] - Training Epoch: 2/2, step 22248/23838 completed (loss: 0.45679405331611633, acc: 0.8717948794364929)
[2025-02-04 03:04:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22250/23838 [27:25<09:33,  2.77it/s][2025-02-04 03:04:14][root][INFO] - Training Epoch: 2/2, step 22249/23838 completed (loss: 0.28517869114875793, acc: 0.90625)
[2025-02-04 03:04:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22251/23838 [27:25<09:43,  2.72it/s][2025-02-04 03:04:15][root][INFO] - Training Epoch: 2/2, step 22250/23838 completed (loss: 0.28745967149734497, acc: 0.9104477763175964)
[2025-02-04 03:04:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22252/23838 [27:26<09:53,  2.67it/s][2025-02-04 03:04:15][root][INFO] - Training Epoch: 2/2, step 22251/23838 completed (loss: 0.17529761791229248, acc: 0.96875)
[2025-02-04 03:04:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22253/23838 [27:26<09:57,  2.65it/s][2025-02-04 03:04:16][root][INFO] - Training Epoch: 2/2, step 22252/23838 completed (loss: 0.42697998881340027, acc: 0.8333333134651184)
[2025-02-04 03:04:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22254/23838 [27:26<09:42,  2.72it/s][2025-02-04 03:04:16][root][INFO] - Training Epoch: 2/2, step 22253/23838 completed (loss: 0.35984522104263306, acc: 0.9259259104728699)
[2025-02-04 03:04:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22255/23838 [27:27<09:34,  2.76it/s][2025-02-04 03:04:16][root][INFO] - Training Epoch: 2/2, step 22254/23838 completed (loss: 0.37674790620803833, acc: 0.8787878751754761)
[2025-02-04 03:04:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22256/23838 [27:27<09:19,  2.83it/s][2025-02-04 03:04:17][root][INFO] - Training Epoch: 2/2, step 22255/23838 completed (loss: 1.165808081626892, acc: 0.7894737124443054)
[2025-02-04 03:04:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22257/23838 [27:27<09:15,  2.84it/s][2025-02-04 03:04:17][root][INFO] - Training Epoch: 2/2, step 22256/23838 completed (loss: 0.7348704934120178, acc: 0.8536585569381714)
[2025-02-04 03:04:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22258/23838 [27:28<09:07,  2.89it/s][2025-02-04 03:04:17][root][INFO] - Training Epoch: 2/2, step 22257/23838 completed (loss: 0.7548794150352478, acc: 0.75)
[2025-02-04 03:04:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22259/23838 [27:28<08:50,  2.98it/s][2025-02-04 03:04:18][root][INFO] - Training Epoch: 2/2, step 22258/23838 completed (loss: 0.5689171552658081, acc: 0.8723404407501221)
[2025-02-04 03:04:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22260/23838 [27:28<08:40,  3.03it/s][2025-02-04 03:04:18][root][INFO] - Training Epoch: 2/2, step 22259/23838 completed (loss: 0.25953230261802673, acc: 0.9117646813392639)
[2025-02-04 03:04:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22261/23838 [27:29<08:34,  3.07it/s][2025-02-04 03:04:18][root][INFO] - Training Epoch: 2/2, step 22260/23838 completed (loss: 0.34410470724105835, acc: 0.8999999761581421)
[2025-02-04 03:04:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22262/23838 [27:29<08:18,  3.16it/s][2025-02-04 03:04:18][root][INFO] - Training Epoch: 2/2, step 22261/23838 completed (loss: 1.079723834991455, acc: 0.625)
[2025-02-04 03:04:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22263/23838 [27:29<08:22,  3.13it/s][2025-02-04 03:04:19][root][INFO] - Training Epoch: 2/2, step 22262/23838 completed (loss: 0.3980787694454193, acc: 0.9142857193946838)
[2025-02-04 03:04:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22264/23838 [27:30<08:16,  3.17it/s][2025-02-04 03:04:19][root][INFO] - Training Epoch: 2/2, step 22263/23838 completed (loss: 0.7788400053977966, acc: 0.8148148059844971)
[2025-02-04 03:04:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22265/23838 [27:30<08:16,  3.17it/s][2025-02-04 03:04:19][root][INFO] - Training Epoch: 2/2, step 22264/23838 completed (loss: 0.4375380873680115, acc: 0.8780487775802612)
[2025-02-04 03:04:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22266/23838 [27:30<08:16,  3.17it/s][2025-02-04 03:04:20][root][INFO] - Training Epoch: 2/2, step 22265/23838 completed (loss: 0.6466844081878662, acc: 0.8108108043670654)
[2025-02-04 03:04:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22267/23838 [27:30<08:22,  3.13it/s][2025-02-04 03:04:20][root][INFO] - Training Epoch: 2/2, step 22266/23838 completed (loss: 0.5572375655174255, acc: 0.8222222328186035)
[2025-02-04 03:04:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22268/23838 [27:31<08:31,  3.07it/s][2025-02-04 03:04:20][root][INFO] - Training Epoch: 2/2, step 22267/23838 completed (loss: 0.903663694858551, acc: 0.7727272510528564)
[2025-02-04 03:04:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22269/23838 [27:31<08:38,  3.02it/s][2025-02-04 03:04:21][root][INFO] - Training Epoch: 2/2, step 22268/23838 completed (loss: 0.12352029234170914, acc: 0.957446813583374)
[2025-02-04 03:04:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22270/23838 [27:32<09:05,  2.87it/s][2025-02-04 03:04:21][root][INFO] - Training Epoch: 2/2, step 22269/23838 completed (loss: 0.41130906343460083, acc: 0.8666666746139526)
[2025-02-04 03:04:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22271/23838 [27:32<09:05,  2.87it/s][2025-02-04 03:04:21][root][INFO] - Training Epoch: 2/2, step 22270/23838 completed (loss: 0.3217594027519226, acc: 0.8636363744735718)
[2025-02-04 03:04:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22272/23838 [27:32<09:10,  2.85it/s][2025-02-04 03:04:22][root][INFO] - Training Epoch: 2/2, step 22271/23838 completed (loss: 0.07710947841405869, acc: 0.9642857313156128)
[2025-02-04 03:04:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22273/23838 [27:33<09:26,  2.76it/s][2025-02-04 03:04:22][root][INFO] - Training Epoch: 2/2, step 22272/23838 completed (loss: 0.5688536167144775, acc: 0.8333333134651184)
[2025-02-04 03:04:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22274/23838 [27:33<09:34,  2.72it/s][2025-02-04 03:04:23][root][INFO] - Training Epoch: 2/2, step 22273/23838 completed (loss: 0.36219415068626404, acc: 0.8500000238418579)
[2025-02-04 03:04:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22275/23838 [27:33<09:22,  2.78it/s][2025-02-04 03:04:23][root][INFO] - Training Epoch: 2/2, step 22274/23838 completed (loss: 0.6337804794311523, acc: 0.8055555820465088)
[2025-02-04 03:04:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22276/23838 [27:34<09:04,  2.87it/s][2025-02-04 03:04:23][root][INFO] - Training Epoch: 2/2, step 22275/23838 completed (loss: 0.3225634694099426, acc: 0.8571428656578064)
[2025-02-04 03:04:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22277/23838 [27:34<08:54,  2.92it/s][2025-02-04 03:04:24][root][INFO] - Training Epoch: 2/2, step 22276/23838 completed (loss: 0.13541655242443085, acc: 0.957446813583374)
[2025-02-04 03:04:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22278/23838 [27:34<08:58,  2.90it/s][2025-02-04 03:04:24][root][INFO] - Training Epoch: 2/2, step 22277/23838 completed (loss: 0.32093510031700134, acc: 0.8974359035491943)
[2025-02-04 03:04:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22279/23838 [27:35<08:46,  2.96it/s][2025-02-04 03:04:24][root][INFO] - Training Epoch: 2/2, step 22278/23838 completed (loss: 0.16614098846912384, acc: 0.9411764740943909)
[2025-02-04 03:04:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22280/23838 [27:35<09:11,  2.83it/s][2025-02-04 03:04:25][root][INFO] - Training Epoch: 2/2, step 22279/23838 completed (loss: 0.08063437044620514, acc: 0.9714285731315613)
[2025-02-04 03:04:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22281/23838 [27:35<09:04,  2.86it/s][2025-02-04 03:04:25][root][INFO] - Training Epoch: 2/2, step 22280/23838 completed (loss: 0.2112729251384735, acc: 0.9615384340286255)
[2025-02-04 03:04:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22282/23838 [27:36<09:31,  2.72it/s][2025-02-04 03:04:25][root][INFO] - Training Epoch: 2/2, step 22281/23838 completed (loss: 0.41613855957984924, acc: 0.8478260636329651)
[2025-02-04 03:04:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22283/23838 [27:36<10:31,  2.46it/s][2025-02-04 03:04:26][root][INFO] - Training Epoch: 2/2, step 22282/23838 completed (loss: 0.6045440435409546, acc: 0.8888888955116272)
[2025-02-04 03:04:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22284/23838 [27:37<10:13,  2.53it/s][2025-02-04 03:04:26][root][INFO] - Training Epoch: 2/2, step 22283/23838 completed (loss: 0.08561799675226212, acc: 0.9772727489471436)
[2025-02-04 03:04:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22285/23838 [27:37<09:50,  2.63it/s][2025-02-04 03:04:27][root][INFO] - Training Epoch: 2/2, step 22284/23838 completed (loss: 0.2812809646129608, acc: 0.8939393758773804)
[2025-02-04 03:04:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22286/23838 [27:37<09:21,  2.76it/s][2025-02-04 03:04:27][root][INFO] - Training Epoch: 2/2, step 22285/23838 completed (loss: 0.2332952320575714, acc: 0.8846153616905212)
[2025-02-04 03:04:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22287/23838 [27:38<09:02,  2.86it/s][2025-02-04 03:04:27][root][INFO] - Training Epoch: 2/2, step 22286/23838 completed (loss: 0.38431602716445923, acc: 0.8979591727256775)
[2025-02-04 03:04:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  93%|[34m█████████▎[0m| 22288/23838 [27:38<09:02,  2.86it/s][2025-02-04 03:04:28][root][INFO] - Training Epoch: 2/2, step 22287/23838 completed (loss: 0.632541835308075, acc: 0.8500000238418579)
[2025-02-04 03:04:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22289/23838 [27:38<09:49,  2.63it/s][2025-02-04 03:04:28][root][INFO] - Training Epoch: 2/2, step 22288/23838 completed (loss: 0.44447576999664307, acc: 0.9019607901573181)
[2025-02-04 03:04:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22290/23838 [27:39<09:48,  2.63it/s][2025-02-04 03:04:28][root][INFO] - Training Epoch: 2/2, step 22289/23838 completed (loss: 0.4885145127773285, acc: 0.7941176295280457)
[2025-02-04 03:04:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22291/23838 [27:39<09:25,  2.73it/s][2025-02-04 03:04:29][root][INFO] - Training Epoch: 2/2, step 22290/23838 completed (loss: 0.3123767375946045, acc: 0.9189189076423645)
[2025-02-04 03:04:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22292/23838 [27:40<09:10,  2.81it/s][2025-02-04 03:04:29][root][INFO] - Training Epoch: 2/2, step 22291/23838 completed (loss: 0.40570276975631714, acc: 0.8947368264198303)
[2025-02-04 03:04:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22293/23838 [27:40<09:04,  2.84it/s][2025-02-04 03:04:29][root][INFO] - Training Epoch: 2/2, step 22292/23838 completed (loss: 0.8453746438026428, acc: 0.8085106611251831)
[2025-02-04 03:04:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22294/23838 [27:40<09:00,  2.86it/s][2025-02-04 03:04:30][root][INFO] - Training Epoch: 2/2, step 22293/23838 completed (loss: 0.6258983016014099, acc: 0.8571428656578064)
[2025-02-04 03:04:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22295/23838 [27:41<09:02,  2.85it/s][2025-02-04 03:04:30][root][INFO] - Training Epoch: 2/2, step 22294/23838 completed (loss: 0.3764705955982208, acc: 0.8181818127632141)
[2025-02-04 03:04:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22296/23838 [27:41<09:09,  2.81it/s][2025-02-04 03:04:31][root][INFO] - Training Epoch: 2/2, step 22295/23838 completed (loss: 1.1431514024734497, acc: 0.7377049326896667)
[2025-02-04 03:04:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22297/23838 [27:41<08:58,  2.86it/s][2025-02-04 03:04:31][root][INFO] - Training Epoch: 2/2, step 22296/23838 completed (loss: 0.341791570186615, acc: 0.9024389982223511)
[2025-02-04 03:04:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22298/23838 [27:42<08:56,  2.87it/s][2025-02-04 03:04:31][root][INFO] - Training Epoch: 2/2, step 22297/23838 completed (loss: 0.3835752606391907, acc: 0.8125)
[2025-02-04 03:04:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22299/23838 [27:42<08:51,  2.89it/s][2025-02-04 03:04:32][root][INFO] - Training Epoch: 2/2, step 22298/23838 completed (loss: 0.5007667541503906, acc: 0.8620689511299133)
[2025-02-04 03:04:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22300/23838 [27:42<08:46,  2.92it/s][2025-02-04 03:04:32][root][INFO] - Training Epoch: 2/2, step 22299/23838 completed (loss: 0.3863106369972229, acc: 0.8947368264198303)
[2025-02-04 03:04:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22301/23838 [27:43<08:58,  2.86it/s][2025-02-04 03:04:32][root][INFO] - Training Epoch: 2/2, step 22300/23838 completed (loss: 0.6290252804756165, acc: 0.7674418687820435)
[2025-02-04 03:04:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22302/23838 [27:43<09:01,  2.84it/s][2025-02-04 03:04:33][root][INFO] - Training Epoch: 2/2, step 22301/23838 completed (loss: 0.20866413414478302, acc: 0.9200000166893005)
[2025-02-04 03:04:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22303/23838 [27:43<09:11,  2.78it/s][2025-02-04 03:04:33][root][INFO] - Training Epoch: 2/2, step 22302/23838 completed (loss: 0.7270690202713013, acc: 0.8157894611358643)
[2025-02-04 03:04:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22304/23838 [27:44<09:20,  2.74it/s][2025-02-04 03:04:33][root][INFO] - Training Epoch: 2/2, step 22303/23838 completed (loss: 0.5773888230323792, acc: 0.8888888955116272)
[2025-02-04 03:04:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22305/23838 [27:44<09:18,  2.74it/s][2025-02-04 03:04:34][root][INFO] - Training Epoch: 2/2, step 22304/23838 completed (loss: 0.5370596051216125, acc: 0.9333333373069763)
[2025-02-04 03:04:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22306/23838 [27:44<09:22,  2.72it/s][2025-02-04 03:04:34][root][INFO] - Training Epoch: 2/2, step 22305/23838 completed (loss: 0.13726283609867096, acc: 0.9729729890823364)
[2025-02-04 03:04:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22307/23838 [27:45<09:28,  2.69it/s][2025-02-04 03:04:34][root][INFO] - Training Epoch: 2/2, step 22306/23838 completed (loss: 0.25343137979507446, acc: 0.9245283007621765)
[2025-02-04 03:04:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22308/23838 [27:45<09:31,  2.68it/s][2025-02-04 03:04:35][root][INFO] - Training Epoch: 2/2, step 22307/23838 completed (loss: 0.5711256265640259, acc: 0.9117646813392639)
[2025-02-04 03:04:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22309/23838 [27:46<09:35,  2.66it/s][2025-02-04 03:04:35][root][INFO] - Training Epoch: 2/2, step 22308/23838 completed (loss: 0.8883400559425354, acc: 0.75)
[2025-02-04 03:04:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22310/23838 [27:46<09:53,  2.58it/s][2025-02-04 03:04:36][root][INFO] - Training Epoch: 2/2, step 22309/23838 completed (loss: 0.45642390847206116, acc: 0.8979591727256775)
[2025-02-04 03:04:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22311/23838 [27:46<09:22,  2.72it/s][2025-02-04 03:04:36][root][INFO] - Training Epoch: 2/2, step 22310/23838 completed (loss: 0.18602672219276428, acc: 0.9285714030265808)
[2025-02-04 03:04:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22312/23838 [27:47<09:03,  2.81it/s][2025-02-04 03:04:36][root][INFO] - Training Epoch: 2/2, step 22311/23838 completed (loss: 0.5162660479545593, acc: 0.8872180581092834)
[2025-02-04 03:04:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22313/23838 [27:47<08:51,  2.87it/s][2025-02-04 03:04:37][root][INFO] - Training Epoch: 2/2, step 22312/23838 completed (loss: 0.09422686696052551, acc: 0.9788732528686523)
[2025-02-04 03:04:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22314/23838 [27:47<09:21,  2.72it/s][2025-02-04 03:04:37][root][INFO] - Training Epoch: 2/2, step 22313/23838 completed (loss: 0.2364300787448883, acc: 0.9222221970558167)
[2025-02-04 03:04:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22315/23838 [27:48<09:26,  2.69it/s][2025-02-04 03:04:37][root][INFO] - Training Epoch: 2/2, step 22314/23838 completed (loss: 0.3160034120082855, acc: 0.8839285969734192)
[2025-02-04 03:04:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22316/23838 [27:48<09:49,  2.58it/s][2025-02-04 03:04:38][root][INFO] - Training Epoch: 2/2, step 22315/23838 completed (loss: 0.4765905737876892, acc: 0.8974359035491943)
[2025-02-04 03:04:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22317/23838 [27:49<09:45,  2.60it/s][2025-02-04 03:04:38][root][INFO] - Training Epoch: 2/2, step 22316/23838 completed (loss: 0.10286756604909897, acc: 0.9722222089767456)
[2025-02-04 03:04:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22318/23838 [27:49<09:56,  2.55it/s][2025-02-04 03:04:39][root][INFO] - Training Epoch: 2/2, step 22317/23838 completed (loss: 0.24685299396514893, acc: 0.9354838728904724)
[2025-02-04 03:04:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22319/23838 [27:49<09:39,  2.62it/s][2025-02-04 03:04:39][root][INFO] - Training Epoch: 2/2, step 22318/23838 completed (loss: 0.17930899560451508, acc: 0.9375)
[2025-02-04 03:04:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22320/23838 [27:50<09:06,  2.78it/s][2025-02-04 03:04:39][root][INFO] - Training Epoch: 2/2, step 22319/23838 completed (loss: 0.1212623193860054, acc: 0.949999988079071)
[2025-02-04 03:04:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22321/23838 [27:50<08:41,  2.91it/s][2025-02-04 03:04:40][root][INFO] - Training Epoch: 2/2, step 22320/23838 completed (loss: 0.15512150526046753, acc: 0.953125)
[2025-02-04 03:04:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22322/23838 [27:50<08:24,  3.00it/s][2025-02-04 03:04:40][root][INFO] - Training Epoch: 2/2, step 22321/23838 completed (loss: 0.12557397782802582, acc: 0.9666666388511658)
[2025-02-04 03:04:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22323/23838 [27:51<08:38,  2.92it/s][2025-02-04 03:04:40][root][INFO] - Training Epoch: 2/2, step 22322/23838 completed (loss: 0.2059517800807953, acc: 0.9516128897666931)
[2025-02-04 03:04:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22324/23838 [27:51<08:33,  2.95it/s][2025-02-04 03:04:41][root][INFO] - Training Epoch: 2/2, step 22323/23838 completed (loss: 0.16638417541980743, acc: 0.929347813129425)
[2025-02-04 03:04:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22325/23838 [27:51<09:02,  2.79it/s][2025-02-04 03:04:41][root][INFO] - Training Epoch: 2/2, step 22324/23838 completed (loss: 0.11777552962303162, acc: 0.9824561476707458)
[2025-02-04 03:04:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22326/23838 [27:52<08:47,  2.87it/s][2025-02-04 03:04:41][root][INFO] - Training Epoch: 2/2, step 22325/23838 completed (loss: 0.14223940670490265, acc: 0.9615384340286255)
[2025-02-04 03:04:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22327/23838 [27:52<08:34,  2.94it/s][2025-02-04 03:04:42][root][INFO] - Training Epoch: 2/2, step 22326/23838 completed (loss: 0.20118002593517303, acc: 0.9461538195610046)
[2025-02-04 03:04:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22328/23838 [27:52<08:51,  2.84it/s][2025-02-04 03:04:42][root][INFO] - Training Epoch: 2/2, step 22327/23838 completed (loss: 0.221716046333313, acc: 0.9365853667259216)
[2025-02-04 03:04:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22329/23838 [27:53<08:28,  2.97it/s][2025-02-04 03:04:42][root][INFO] - Training Epoch: 2/2, step 22328/23838 completed (loss: 0.1577295958995819, acc: 0.9337349534034729)
[2025-02-04 03:04:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22330/23838 [27:53<07:40,  3.28it/s][2025-02-04 03:04:43][root][INFO] - Training Epoch: 2/2, step 22329/23838 completed (loss: 0.36086297035217285, acc: 0.8611111044883728)
[2025-02-04 03:04:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22331/23838 [27:53<07:44,  3.24it/s][2025-02-04 03:04:43][root][INFO] - Training Epoch: 2/2, step 22330/23838 completed (loss: 0.2339191436767578, acc: 0.9333333373069763)
[2025-02-04 03:04:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22332/23838 [27:54<07:52,  3.19it/s][2025-02-04 03:04:43][root][INFO] - Training Epoch: 2/2, step 22331/23838 completed (loss: 0.1563708484172821, acc: 0.9554139971733093)
[2025-02-04 03:04:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22333/23838 [27:54<07:53,  3.18it/s][2025-02-04 03:04:44][root][INFO] - Training Epoch: 2/2, step 22332/23838 completed (loss: 0.1960649937391281, acc: 0.9305555820465088)
[2025-02-04 03:04:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22334/23838 [27:54<07:55,  3.16it/s][2025-02-04 03:04:44][root][INFO] - Training Epoch: 2/2, step 22333/23838 completed (loss: 0.20810441672801971, acc: 0.9333333373069763)
[2025-02-04 03:04:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22335/23838 [27:55<07:59,  3.13it/s][2025-02-04 03:04:44][root][INFO] - Training Epoch: 2/2, step 22334/23838 completed (loss: 0.13710364699363708, acc: 0.963302731513977)
[2025-02-04 03:04:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22336/23838 [27:55<08:02,  3.12it/s][2025-02-04 03:04:44][root][INFO] - Training Epoch: 2/2, step 22335/23838 completed (loss: 0.327378511428833, acc: 0.9223300814628601)
[2025-02-04 03:04:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22337/23838 [27:55<07:54,  3.16it/s][2025-02-04 03:04:45][root][INFO] - Training Epoch: 2/2, step 22336/23838 completed (loss: 0.29651716351509094, acc: 0.9130434989929199)
[2025-02-04 03:04:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22338/23838 [27:56<07:57,  3.14it/s][2025-02-04 03:04:45][root][INFO] - Training Epoch: 2/2, step 22337/23838 completed (loss: 0.07434071600437164, acc: 0.9677419066429138)
[2025-02-04 03:04:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22339/23838 [27:56<08:16,  3.02it/s][2025-02-04 03:04:45][root][INFO] - Training Epoch: 2/2, step 22338/23838 completed (loss: 0.25954142212867737, acc: 0.9253731369972229)
[2025-02-04 03:04:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22340/23838 [27:56<08:08,  3.07it/s][2025-02-04 03:04:46][root][INFO] - Training Epoch: 2/2, step 22339/23838 completed (loss: 0.1301208883523941, acc: 0.9523809552192688)
[2025-02-04 03:04:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22341/23838 [27:57<08:20,  2.99it/s][2025-02-04 03:04:46][root][INFO] - Training Epoch: 2/2, step 22340/23838 completed (loss: 0.07261814922094345, acc: 0.9908257126808167)
[2025-02-04 03:04:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22342/23838 [27:57<08:25,  2.96it/s][2025-02-04 03:04:46][root][INFO] - Training Epoch: 2/2, step 22341/23838 completed (loss: 0.10213056951761246, acc: 0.9682539701461792)
[2025-02-04 03:04:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22343/23838 [27:57<08:36,  2.90it/s][2025-02-04 03:04:47][root][INFO] - Training Epoch: 2/2, step 22342/23838 completed (loss: 0.15676504373550415, acc: 0.945652186870575)
[2025-02-04 03:04:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22344/23838 [27:58<08:35,  2.90it/s][2025-02-04 03:04:47][root][INFO] - Training Epoch: 2/2, step 22343/23838 completed (loss: 0.3244380056858063, acc: 0.9014084339141846)
[2025-02-04 03:04:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22345/23838 [27:58<08:37,  2.89it/s][2025-02-04 03:04:48][root][INFO] - Training Epoch: 2/2, step 22344/23838 completed (loss: 0.13769711554050446, acc: 0.9585798978805542)
[2025-02-04 03:04:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22346/23838 [27:58<08:37,  2.88it/s][2025-02-04 03:04:48][root][INFO] - Training Epoch: 2/2, step 22345/23838 completed (loss: 0.2307148277759552, acc: 0.9285714030265808)
[2025-02-04 03:04:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22347/23838 [27:59<08:36,  2.89it/s][2025-02-04 03:04:48][root][INFO] - Training Epoch: 2/2, step 22346/23838 completed (loss: 0.17456366121768951, acc: 0.9631578922271729)
[2025-02-04 03:04:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▎[0m| 22348/23838 [27:59<08:26,  2.94it/s][2025-02-04 03:04:49][root][INFO] - Training Epoch: 2/2, step 22347/23838 completed (loss: 0.05643395707011223, acc: 0.9805825352668762)
[2025-02-04 03:04:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22349/23838 [27:59<08:40,  2.86it/s][2025-02-04 03:04:49][root][INFO] - Training Epoch: 2/2, step 22348/23838 completed (loss: 0.20813898742198944, acc: 0.9561403393745422)
[2025-02-04 03:04:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22350/23838 [28:00<08:47,  2.82it/s][2025-02-04 03:04:49][root][INFO] - Training Epoch: 2/2, step 22349/23838 completed (loss: 0.4034954309463501, acc: 0.868686854839325)
[2025-02-04 03:04:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22351/23838 [28:00<09:06,  2.72it/s][2025-02-04 03:04:50][root][INFO] - Training Epoch: 2/2, step 22350/23838 completed (loss: 0.11173252016305923, acc: 0.9727272987365723)
[2025-02-04 03:04:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22352/23838 [28:00<08:45,  2.83it/s][2025-02-04 03:04:50][root][INFO] - Training Epoch: 2/2, step 22351/23838 completed (loss: 0.38962215185165405, acc: 0.9057971239089966)
[2025-02-04 03:04:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22353/23838 [28:01<08:27,  2.92it/s][2025-02-04 03:04:50][root][INFO] - Training Epoch: 2/2, step 22352/23838 completed (loss: 0.10299944877624512, acc: 0.9577465057373047)
[2025-02-04 03:04:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22354/23838 [28:01<08:10,  3.03it/s][2025-02-04 03:04:51][root][INFO] - Training Epoch: 2/2, step 22353/23838 completed (loss: 0.3960690498352051, acc: 0.8985507488250732)
[2025-02-04 03:04:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22355/23838 [28:01<08:01,  3.08it/s][2025-02-04 03:04:51][root][INFO] - Training Epoch: 2/2, step 22354/23838 completed (loss: 0.5692230463027954, acc: 0.8275862336158752)
[2025-02-04 03:04:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22356/23838 [28:02<08:07,  3.04it/s][2025-02-04 03:04:51][root][INFO] - Training Epoch: 2/2, step 22355/23838 completed (loss: 0.3160865008831024, acc: 0.9433962106704712)
[2025-02-04 03:04:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22357/23838 [28:02<08:30,  2.90it/s][2025-02-04 03:04:52][root][INFO] - Training Epoch: 2/2, step 22356/23838 completed (loss: 0.2839373052120209, acc: 0.901098906993866)
[2025-02-04 03:04:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22358/23838 [28:03<09:19,  2.64it/s][2025-02-04 03:04:52][root][INFO] - Training Epoch: 2/2, step 22357/23838 completed (loss: 0.7644401788711548, acc: 0.824999988079071)
[2025-02-04 03:04:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22359/23838 [28:03<09:02,  2.72it/s][2025-02-04 03:04:52][root][INFO] - Training Epoch: 2/2, step 22358/23838 completed (loss: 0.46072813868522644, acc: 0.8983050584793091)
[2025-02-04 03:04:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22360/23838 [28:03<08:47,  2.80it/s][2025-02-04 03:04:53][root][INFO] - Training Epoch: 2/2, step 22359/23838 completed (loss: 0.5918453931808472, acc: 0.8510638475418091)
[2025-02-04 03:04:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22361/23838 [28:04<08:49,  2.79it/s][2025-02-04 03:04:53][root][INFO] - Training Epoch: 2/2, step 22360/23838 completed (loss: 0.49183762073516846, acc: 0.8039215803146362)
[2025-02-04 03:04:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22362/23838 [28:04<08:57,  2.75it/s][2025-02-04 03:04:54][root][INFO] - Training Epoch: 2/2, step 22361/23838 completed (loss: 0.9257626533508301, acc: 0.7037037014961243)
[2025-02-04 03:04:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22363/23838 [28:04<08:57,  2.74it/s][2025-02-04 03:04:54][root][INFO] - Training Epoch: 2/2, step 22362/23838 completed (loss: 0.4519132077693939, acc: 0.8809523582458496)
[2025-02-04 03:04:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22364/23838 [28:05<08:59,  2.73it/s][2025-02-04 03:04:54][root][INFO] - Training Epoch: 2/2, step 22363/23838 completed (loss: 0.4579775333404541, acc: 0.8974359035491943)
[2025-02-04 03:04:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22365/23838 [28:05<08:33,  2.87it/s][2025-02-04 03:04:55][root][INFO] - Training Epoch: 2/2, step 22364/23838 completed (loss: 0.49958211183547974, acc: 0.8604651093482971)
[2025-02-04 03:04:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22366/23838 [28:05<08:38,  2.84it/s][2025-02-04 03:04:55][root][INFO] - Training Epoch: 2/2, step 22365/23838 completed (loss: 0.4478452205657959, acc: 0.8860759735107422)
[2025-02-04 03:04:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22367/23838 [28:06<09:15,  2.65it/s][2025-02-04 03:04:55][root][INFO] - Training Epoch: 2/2, step 22366/23838 completed (loss: 0.9754865169525146, acc: 0.6724137663841248)
[2025-02-04 03:04:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22368/23838 [28:06<09:10,  2.67it/s][2025-02-04 03:04:56][root][INFO] - Training Epoch: 2/2, step 22367/23838 completed (loss: 0.33842262625694275, acc: 0.8983050584793091)
[2025-02-04 03:04:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22369/23838 [28:07<09:27,  2.59it/s][2025-02-04 03:04:56][root][INFO] - Training Epoch: 2/2, step 22368/23838 completed (loss: 0.7429485321044922, acc: 0.7941176295280457)
[2025-02-04 03:04:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22370/23838 [28:07<09:21,  2.61it/s][2025-02-04 03:04:57][root][INFO] - Training Epoch: 2/2, step 22369/23838 completed (loss: 0.34592685103416443, acc: 0.914893627166748)
[2025-02-04 03:04:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22371/23838 [28:07<09:08,  2.67it/s][2025-02-04 03:04:57][root][INFO] - Training Epoch: 2/2, step 22370/23838 completed (loss: 0.6372780203819275, acc: 0.890625)
[2025-02-04 03:04:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22372/23838 [28:08<09:19,  2.62it/s][2025-02-04 03:04:57][root][INFO] - Training Epoch: 2/2, step 22371/23838 completed (loss: 0.15618796646595, acc: 0.9473684430122375)
[2025-02-04 03:04:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22373/23838 [28:08<09:21,  2.61it/s][2025-02-04 03:04:58][root][INFO] - Training Epoch: 2/2, step 22372/23838 completed (loss: 0.7019867897033691, acc: 0.7735849022865295)
[2025-02-04 03:04:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22374/23838 [28:08<09:18,  2.62it/s][2025-02-04 03:04:58][root][INFO] - Training Epoch: 2/2, step 22373/23838 completed (loss: 0.5544997453689575, acc: 0.8474576473236084)
[2025-02-04 03:04:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22375/23838 [28:09<08:51,  2.75it/s][2025-02-04 03:04:58][root][INFO] - Training Epoch: 2/2, step 22374/23838 completed (loss: 0.5036278367042542, acc: 0.8448275923728943)
[2025-02-04 03:04:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22376/23838 [28:09<08:49,  2.76it/s][2025-02-04 03:04:59][root][INFO] - Training Epoch: 2/2, step 22375/23838 completed (loss: 0.31331947445869446, acc: 0.9220778942108154)
[2025-02-04 03:04:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22377/23838 [28:09<08:38,  2.82it/s][2025-02-04 03:04:59][root][INFO] - Training Epoch: 2/2, step 22376/23838 completed (loss: 0.37802502512931824, acc: 0.9347826242446899)
[2025-02-04 03:04:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22378/23838 [28:10<08:35,  2.83it/s][2025-02-04 03:04:59][root][INFO] - Training Epoch: 2/2, step 22377/23838 completed (loss: 0.7315234541893005, acc: 0.7872340679168701)
[2025-02-04 03:05:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22379/23838 [28:10<08:42,  2.79it/s][2025-02-04 03:05:00][root][INFO] - Training Epoch: 2/2, step 22378/23838 completed (loss: 0.8893173933029175, acc: 0.797468364238739)
[2025-02-04 03:05:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22380/23838 [28:11<08:32,  2.85it/s][2025-02-04 03:05:00][root][INFO] - Training Epoch: 2/2, step 22379/23838 completed (loss: 0.8390085697174072, acc: 0.800000011920929)
[2025-02-04 03:05:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22381/23838 [28:11<08:34,  2.83it/s][2025-02-04 03:05:00][root][INFO] - Training Epoch: 2/2, step 22380/23838 completed (loss: 0.3582841753959656, acc: 0.9080459475517273)
[2025-02-04 03:05:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22382/23838 [28:11<08:36,  2.82it/s][2025-02-04 03:05:01][root][INFO] - Training Epoch: 2/2, step 22381/23838 completed (loss: 0.8141771554946899, acc: 0.800000011920929)
[2025-02-04 03:05:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22383/23838 [28:12<08:30,  2.85it/s][2025-02-04 03:05:01][root][INFO] - Training Epoch: 2/2, step 22382/23838 completed (loss: 0.6210355758666992, acc: 0.84375)
[2025-02-04 03:05:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22384/23838 [28:12<08:31,  2.84it/s][2025-02-04 03:05:02][root][INFO] - Training Epoch: 2/2, step 22383/23838 completed (loss: 0.7685123682022095, acc: 0.8461538553237915)
[2025-02-04 03:05:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22385/23838 [28:12<08:26,  2.87it/s][2025-02-04 03:05:02][root][INFO] - Training Epoch: 2/2, step 22384/23838 completed (loss: 0.6178611516952515, acc: 0.8611111044883728)
[2025-02-04 03:05:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22386/23838 [28:13<08:18,  2.91it/s][2025-02-04 03:05:02][root][INFO] - Training Epoch: 2/2, step 22385/23838 completed (loss: 0.5724164843559265, acc: 0.8358209133148193)
[2025-02-04 03:05:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22387/23838 [28:13<08:43,  2.77it/s][2025-02-04 03:05:03][root][INFO] - Training Epoch: 2/2, step 22386/23838 completed (loss: 0.6141019463539124, acc: 0.7951807379722595)
[2025-02-04 03:05:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22388/23838 [28:13<09:13,  2.62it/s][2025-02-04 03:05:03][root][INFO] - Training Epoch: 2/2, step 22387/23838 completed (loss: 0.5337804555892944, acc: 0.8909090757369995)
[2025-02-04 03:05:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22389/23838 [28:14<08:56,  2.70it/s][2025-02-04 03:05:03][root][INFO] - Training Epoch: 2/2, step 22388/23838 completed (loss: 0.5929741263389587, acc: 0.8333333134651184)
[2025-02-04 03:05:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22390/23838 [28:14<08:57,  2.69it/s][2025-02-04 03:05:04][root][INFO] - Training Epoch: 2/2, step 22389/23838 completed (loss: 0.7651926279067993, acc: 0.7027027010917664)
[2025-02-04 03:05:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22391/23838 [28:15<08:50,  2.73it/s][2025-02-04 03:05:04][root][INFO] - Training Epoch: 2/2, step 22390/23838 completed (loss: 0.5398371815681458, acc: 0.78125)
[2025-02-04 03:05:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22392/23838 [28:15<08:44,  2.76it/s][2025-02-04 03:05:04][root][INFO] - Training Epoch: 2/2, step 22391/23838 completed (loss: 0.6152778267860413, acc: 0.8529411554336548)
[2025-02-04 03:05:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22393/23838 [28:15<08:34,  2.81it/s][2025-02-04 03:05:05][root][INFO] - Training Epoch: 2/2, step 22392/23838 completed (loss: 0.5406016111373901, acc: 0.8367347121238708)
[2025-02-04 03:05:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22394/23838 [28:16<08:34,  2.80it/s][2025-02-04 03:05:05][root][INFO] - Training Epoch: 2/2, step 22393/23838 completed (loss: 0.3604138195514679, acc: 0.875)
[2025-02-04 03:05:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22395/23838 [28:16<08:52,  2.71it/s][2025-02-04 03:05:06][root][INFO] - Training Epoch: 2/2, step 22394/23838 completed (loss: 0.9267605543136597, acc: 0.7058823704719543)
[2025-02-04 03:05:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22396/23838 [28:16<08:59,  2.67it/s][2025-02-04 03:05:06][root][INFO] - Training Epoch: 2/2, step 22395/23838 completed (loss: 0.44781774282455444, acc: 0.875)
[2025-02-04 03:05:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22397/23838 [28:17<08:56,  2.69it/s][2025-02-04 03:05:06][root][INFO] - Training Epoch: 2/2, step 22396/23838 completed (loss: 0.5493194460868835, acc: 0.7846153974533081)
[2025-02-04 03:05:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22398/23838 [28:17<08:55,  2.69it/s][2025-02-04 03:05:07][root][INFO] - Training Epoch: 2/2, step 22397/23838 completed (loss: 0.3285263180732727, acc: 0.9117646813392639)
[2025-02-04 03:05:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22399/23838 [28:18<09:06,  2.63it/s][2025-02-04 03:05:07][root][INFO] - Training Epoch: 2/2, step 22398/23838 completed (loss: 0.8741735219955444, acc: 0.725806474685669)
[2025-02-04 03:05:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22400/23838 [28:18<08:40,  2.76it/s][2025-02-04 03:05:07][root][INFO] - Training Epoch: 2/2, step 22399/23838 completed (loss: 0.8358200788497925, acc: 0.7419354915618896)
[2025-02-04 03:05:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22401/23838 [28:18<08:15,  2.90it/s][2025-02-04 03:05:08][root][INFO] - Training Epoch: 2/2, step 22400/23838 completed (loss: 0.503333568572998, acc: 0.8548387289047241)
[2025-02-04 03:05:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22402/23838 [28:19<08:29,  2.82it/s][2025-02-04 03:05:08][root][INFO] - Training Epoch: 2/2, step 22401/23838 completed (loss: 0.31865525245666504, acc: 0.8823529481887817)
[2025-02-04 03:05:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22403/23838 [28:19<08:49,  2.71it/s][2025-02-04 03:05:09][root][INFO] - Training Epoch: 2/2, step 22402/23838 completed (loss: 0.9137002229690552, acc: 0.725806474685669)
[2025-02-04 03:05:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22404/23838 [28:19<08:41,  2.75it/s][2025-02-04 03:05:09][root][INFO] - Training Epoch: 2/2, step 22403/23838 completed (loss: 0.1797301322221756, acc: 0.949367105960846)
[2025-02-04 03:05:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22405/23838 [28:20<08:36,  2.77it/s][2025-02-04 03:05:09][root][INFO] - Training Epoch: 2/2, step 22404/23838 completed (loss: 0.5170886516571045, acc: 0.8469387888908386)
[2025-02-04 03:05:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22406/23838 [28:20<08:29,  2.81it/s][2025-02-04 03:05:10][root][INFO] - Training Epoch: 2/2, step 22405/23838 completed (loss: 0.545793354511261, acc: 0.8478260636329651)
[2025-02-04 03:05:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22407/23838 [28:20<08:21,  2.85it/s][2025-02-04 03:05:10][root][INFO] - Training Epoch: 2/2, step 22406/23838 completed (loss: 0.5273371934890747, acc: 0.8275862336158752)
[2025-02-04 03:05:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22408/23838 [28:21<08:24,  2.83it/s][2025-02-04 03:05:10][root][INFO] - Training Epoch: 2/2, step 22407/23838 completed (loss: 0.9943773150444031, acc: 0.6666666865348816)
[2025-02-04 03:05:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22409/23838 [28:21<08:04,  2.95it/s][2025-02-04 03:05:11][root][INFO] - Training Epoch: 2/2, step 22408/23838 completed (loss: 0.5505586862564087, acc: 0.8604651093482971)
[2025-02-04 03:05:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22410/23838 [28:21<08:06,  2.93it/s][2025-02-04 03:05:11][root][INFO] - Training Epoch: 2/2, step 22409/23838 completed (loss: 0.6152451634407043, acc: 0.7777777910232544)
[2025-02-04 03:05:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22411/23838 [28:22<07:59,  2.98it/s][2025-02-04 03:05:11][root][INFO] - Training Epoch: 2/2, step 22410/23838 completed (loss: 0.4798606336116791, acc: 0.9166666865348816)
[2025-02-04 03:05:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22412/23838 [28:22<07:54,  3.01it/s][2025-02-04 03:05:12][root][INFO] - Training Epoch: 2/2, step 22411/23838 completed (loss: 0.45497846603393555, acc: 0.8717948794364929)
[2025-02-04 03:05:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22413/23838 [28:22<07:53,  3.01it/s][2025-02-04 03:05:12][root][INFO] - Training Epoch: 2/2, step 22412/23838 completed (loss: 0.44485998153686523, acc: 0.8644067645072937)
[2025-02-04 03:05:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22414/23838 [28:23<07:54,  3.00it/s][2025-02-04 03:05:12][root][INFO] - Training Epoch: 2/2, step 22413/23838 completed (loss: 0.6049008369445801, acc: 0.8548387289047241)
[2025-02-04 03:05:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22415/23838 [28:23<07:54,  3.00it/s][2025-02-04 03:05:13][root][INFO] - Training Epoch: 2/2, step 22414/23838 completed (loss: 0.7881184816360474, acc: 0.7352941036224365)
[2025-02-04 03:05:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22416/23838 [28:23<07:51,  3.02it/s][2025-02-04 03:05:13][root][INFO] - Training Epoch: 2/2, step 22415/23838 completed (loss: 0.5140253901481628, acc: 0.9047619104385376)
[2025-02-04 03:05:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22417/23838 [28:24<07:54,  2.99it/s][2025-02-04 03:05:13][root][INFO] - Training Epoch: 2/2, step 22416/23838 completed (loss: 0.4846380949020386, acc: 0.8181818127632141)
[2025-02-04 03:05:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22418/23838 [28:24<08:48,  2.69it/s][2025-02-04 03:05:14][root][INFO] - Training Epoch: 2/2, step 22417/23838 completed (loss: 0.9709379076957703, acc: 0.6847826242446899)
[2025-02-04 03:05:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22419/23838 [28:24<08:53,  2.66it/s][2025-02-04 03:05:14][root][INFO] - Training Epoch: 2/2, step 22418/23838 completed (loss: 0.7391738891601562, acc: 0.807692289352417)
[2025-02-04 03:05:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22420/23838 [28:25<08:34,  2.76it/s][2025-02-04 03:05:14][root][INFO] - Training Epoch: 2/2, step 22419/23838 completed (loss: 0.3719940483570099, acc: 0.9120879173278809)
[2025-02-04 03:05:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22421/23838 [28:25<08:57,  2.64it/s][2025-02-04 03:05:15][root][INFO] - Training Epoch: 2/2, step 22420/23838 completed (loss: 0.7257585525512695, acc: 0.746835470199585)
[2025-02-04 03:05:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22422/23838 [28:26<08:51,  2.66it/s][2025-02-04 03:05:15][root][INFO] - Training Epoch: 2/2, step 22421/23838 completed (loss: 0.28155097365379333, acc: 0.9624999761581421)
[2025-02-04 03:05:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22423/23838 [28:26<08:55,  2.64it/s][2025-02-04 03:05:16][root][INFO] - Training Epoch: 2/2, step 22422/23838 completed (loss: 0.28297773003578186, acc: 0.9120879173278809)
[2025-02-04 03:05:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22424/23838 [28:26<08:38,  2.73it/s][2025-02-04 03:05:16][root][INFO] - Training Epoch: 2/2, step 22423/23838 completed (loss: 0.19572308659553528, acc: 0.949999988079071)
[2025-02-04 03:05:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22425/23838 [28:27<08:44,  2.69it/s][2025-02-04 03:05:16][root][INFO] - Training Epoch: 2/2, step 22424/23838 completed (loss: 0.256184846162796, acc: 0.9166666865348816)
[2025-02-04 03:05:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22426/23838 [28:27<08:35,  2.74it/s][2025-02-04 03:05:17][root][INFO] - Training Epoch: 2/2, step 22425/23838 completed (loss: 0.9938254356384277, acc: 0.6756756901741028)
[2025-02-04 03:05:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22427/23838 [28:27<08:53,  2.64it/s][2025-02-04 03:05:17][root][INFO] - Training Epoch: 2/2, step 22426/23838 completed (loss: 0.31205302476882935, acc: 0.8831169009208679)
[2025-02-04 03:05:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22428/23838 [28:28<08:32,  2.75it/s][2025-02-04 03:05:17][root][INFO] - Training Epoch: 2/2, step 22427/23838 completed (loss: 0.36060184240341187, acc: 0.9253731369972229)
[2025-02-04 03:05:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22429/23838 [28:28<08:28,  2.77it/s][2025-02-04 03:05:18][root][INFO] - Training Epoch: 2/2, step 22428/23838 completed (loss: 0.19371329247951508, acc: 0.9743589758872986)
[2025-02-04 03:05:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22430/23838 [28:29<08:54,  2.63it/s][2025-02-04 03:05:18][root][INFO] - Training Epoch: 2/2, step 22429/23838 completed (loss: 0.35202187299728394, acc: 0.89682537317276)
[2025-02-04 03:05:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22431/23838 [28:29<09:21,  2.51it/s][2025-02-04 03:05:19][root][INFO] - Training Epoch: 2/2, step 22430/23838 completed (loss: 0.9598425030708313, acc: 0.7956989407539368)
[2025-02-04 03:05:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22432/23838 [28:29<09:13,  2.54it/s][2025-02-04 03:05:19][root][INFO] - Training Epoch: 2/2, step 22431/23838 completed (loss: 0.7925753593444824, acc: 0.7647058963775635)
[2025-02-04 03:05:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22433/23838 [28:30<08:54,  2.63it/s][2025-02-04 03:05:19][root][INFO] - Training Epoch: 2/2, step 22432/23838 completed (loss: 0.49147579073905945, acc: 0.8666666746139526)
[2025-02-04 03:05:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22434/23838 [28:30<09:07,  2.56it/s][2025-02-04 03:05:20][root][INFO] - Training Epoch: 2/2, step 22433/23838 completed (loss: 0.47311630845069885, acc: 0.8387096524238586)
[2025-02-04 03:05:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22435/23838 [28:31<08:51,  2.64it/s][2025-02-04 03:05:20][root][INFO] - Training Epoch: 2/2, step 22434/23838 completed (loss: 0.22064648568630219, acc: 0.9230769276618958)
[2025-02-04 03:05:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22436/23838 [28:31<08:50,  2.64it/s][2025-02-04 03:05:20][root][INFO] - Training Epoch: 2/2, step 22435/23838 completed (loss: 0.15564985573291779, acc: 0.9365079402923584)
[2025-02-04 03:05:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22437/23838 [28:31<08:26,  2.77it/s][2025-02-04 03:05:21][root][INFO] - Training Epoch: 2/2, step 22436/23838 completed (loss: 0.14794155955314636, acc: 0.95652174949646)
[2025-02-04 03:05:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22438/23838 [28:32<08:29,  2.75it/s][2025-02-04 03:05:21][root][INFO] - Training Epoch: 2/2, step 22437/23838 completed (loss: 0.4644978940486908, acc: 0.8505747318267822)
[2025-02-04 03:05:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22439/23838 [28:32<08:24,  2.77it/s][2025-02-04 03:05:22][root][INFO] - Training Epoch: 2/2, step 22438/23838 completed (loss: 0.47681745886802673, acc: 0.875)
[2025-02-04 03:05:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22440/23838 [28:32<08:26,  2.76it/s][2025-02-04 03:05:22][root][INFO] - Training Epoch: 2/2, step 22439/23838 completed (loss: 0.23498733341693878, acc: 0.9230769276618958)
[2025-02-04 03:05:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22441/23838 [28:33<09:06,  2.56it/s][2025-02-04 03:05:22][root][INFO] - Training Epoch: 2/2, step 22440/23838 completed (loss: 0.4989416301250458, acc: 0.8717948794364929)
[2025-02-04 03:05:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22442/23838 [28:33<09:22,  2.48it/s][2025-02-04 03:05:23][root][INFO] - Training Epoch: 2/2, step 22441/23838 completed (loss: 0.9167972207069397, acc: 0.8295454382896423)
[2025-02-04 03:05:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22443/23838 [28:34<09:07,  2.55it/s][2025-02-04 03:05:23][root][INFO] - Training Epoch: 2/2, step 22442/23838 completed (loss: 0.33140456676483154, acc: 0.931034505367279)
[2025-02-04 03:05:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22444/23838 [28:34<08:40,  2.68it/s][2025-02-04 03:05:23][root][INFO] - Training Epoch: 2/2, step 22443/23838 completed (loss: 0.8896956443786621, acc: 0.7799999713897705)
[2025-02-04 03:05:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22445/23838 [28:34<09:03,  2.56it/s][2025-02-04 03:05:24][root][INFO] - Training Epoch: 2/2, step 22444/23838 completed (loss: 0.507902979850769, acc: 0.8518518805503845)
[2025-02-04 03:05:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22446/23838 [28:35<08:33,  2.71it/s][2025-02-04 03:05:24][root][INFO] - Training Epoch: 2/2, step 22445/23838 completed (loss: 0.4253745973110199, acc: 0.8543689250946045)
[2025-02-04 03:05:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22447/23838 [28:35<08:30,  2.73it/s][2025-02-04 03:05:25][root][INFO] - Training Epoch: 2/2, step 22446/23838 completed (loss: 0.36642056703567505, acc: 0.9130434989929199)
[2025-02-04 03:05:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22448/23838 [28:35<08:20,  2.77it/s][2025-02-04 03:05:25][root][INFO] - Training Epoch: 2/2, step 22447/23838 completed (loss: 0.6955866813659668, acc: 0.7708333134651184)
[2025-02-04 03:05:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22449/23838 [28:36<07:57,  2.91it/s][2025-02-04 03:05:25][root][INFO] - Training Epoch: 2/2, step 22448/23838 completed (loss: 0.3700943887233734, acc: 0.8644067645072937)
[2025-02-04 03:05:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22450/23838 [28:36<08:19,  2.78it/s][2025-02-04 03:05:26][root][INFO] - Training Epoch: 2/2, step 22449/23838 completed (loss: 0.49855512380599976, acc: 0.7904762029647827)
[2025-02-04 03:05:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22451/23838 [28:36<08:46,  2.64it/s][2025-02-04 03:05:26][root][INFO] - Training Epoch: 2/2, step 22450/23838 completed (loss: 0.3570147156715393, acc: 0.8888888955116272)
[2025-02-04 03:05:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22452/23838 [28:37<08:37,  2.68it/s][2025-02-04 03:05:26][root][INFO] - Training Epoch: 2/2, step 22451/23838 completed (loss: 0.37592387199401855, acc: 0.8965517282485962)
[2025-02-04 03:05:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22453/23838 [28:37<08:20,  2.77it/s][2025-02-04 03:05:27][root][INFO] - Training Epoch: 2/2, step 22452/23838 completed (loss: 0.3735184073448181, acc: 0.8813559412956238)
[2025-02-04 03:05:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22454/23838 [28:38<08:26,  2.73it/s][2025-02-04 03:05:27][root][INFO] - Training Epoch: 2/2, step 22453/23838 completed (loss: 0.4008692502975464, acc: 0.8372092843055725)
[2025-02-04 03:05:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22455/23838 [28:38<08:05,  2.85it/s][2025-02-04 03:05:27][root][INFO] - Training Epoch: 2/2, step 22454/23838 completed (loss: 0.594746470451355, acc: 0.7976190447807312)
[2025-02-04 03:05:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22456/23838 [28:38<07:59,  2.88it/s][2025-02-04 03:05:28][root][INFO] - Training Epoch: 2/2, step 22455/23838 completed (loss: 1.0612043142318726, acc: 0.7872340679168701)
[2025-02-04 03:05:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22457/23838 [28:39<07:44,  2.97it/s][2025-02-04 03:05:28][root][INFO] - Training Epoch: 2/2, step 22456/23838 completed (loss: 1.036651611328125, acc: 0.6363636255264282)
[2025-02-04 03:05:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22458/23838 [28:39<07:23,  3.11it/s][2025-02-04 03:05:28][root][INFO] - Training Epoch: 2/2, step 22457/23838 completed (loss: 0.9740983843803406, acc: 0.7419354915618896)
[2025-02-04 03:05:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22459/23838 [28:39<07:39,  3.00it/s][2025-02-04 03:05:29][root][INFO] - Training Epoch: 2/2, step 22458/23838 completed (loss: 0.6595561504364014, acc: 0.800000011920929)
[2025-02-04 03:05:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22460/23838 [28:39<07:41,  2.98it/s][2025-02-04 03:05:29][root][INFO] - Training Epoch: 2/2, step 22459/23838 completed (loss: 0.9852030277252197, acc: 0.7115384340286255)
[2025-02-04 03:05:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22461/23838 [28:40<07:51,  2.92it/s][2025-02-04 03:05:29][root][INFO] - Training Epoch: 2/2, step 22460/23838 completed (loss: 0.47991424798965454, acc: 0.8301886916160583)
[2025-02-04 03:05:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22462/23838 [28:40<07:56,  2.89it/s][2025-02-04 03:05:30][root][INFO] - Training Epoch: 2/2, step 22461/23838 completed (loss: 0.7822686433792114, acc: 0.8059701323509216)
[2025-02-04 03:05:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22463/23838 [28:41<07:59,  2.86it/s][2025-02-04 03:05:30][root][INFO] - Training Epoch: 2/2, step 22462/23838 completed (loss: 0.5422590374946594, acc: 0.8421052694320679)
[2025-02-04 03:05:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22464/23838 [28:41<08:11,  2.80it/s][2025-02-04 03:05:31][root][INFO] - Training Epoch: 2/2, step 22463/23838 completed (loss: 0.7717524170875549, acc: 0.7977527976036072)
[2025-02-04 03:05:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22465/23838 [28:41<08:02,  2.85it/s][2025-02-04 03:05:31][root][INFO] - Training Epoch: 2/2, step 22464/23838 completed (loss: 1.3949130773544312, acc: 0.6447368264198303)
[2025-02-04 03:05:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22466/23838 [28:42<08:11,  2.79it/s][2025-02-04 03:05:31][root][INFO] - Training Epoch: 2/2, step 22465/23838 completed (loss: 1.4034167528152466, acc: 0.6447368264198303)
[2025-02-04 03:05:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22467/23838 [28:42<08:24,  2.72it/s][2025-02-04 03:05:32][root][INFO] - Training Epoch: 2/2, step 22466/23838 completed (loss: 1.104385256767273, acc: 0.7045454382896423)
[2025-02-04 03:05:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22468/23838 [28:42<08:25,  2.71it/s][2025-02-04 03:05:32][root][INFO] - Training Epoch: 2/2, step 22467/23838 completed (loss: 0.9645788073539734, acc: 0.75)
[2025-02-04 03:05:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22469/23838 [28:43<08:12,  2.78it/s][2025-02-04 03:05:32][root][INFO] - Training Epoch: 2/2, step 22468/23838 completed (loss: 0.7191388010978699, acc: 0.8117647171020508)
[2025-02-04 03:05:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22470/23838 [28:43<07:52,  2.89it/s][2025-02-04 03:05:33][root][INFO] - Training Epoch: 2/2, step 22469/23838 completed (loss: 1.3223263025283813, acc: 0.6470588445663452)
[2025-02-04 03:05:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22471/23838 [28:43<07:38,  2.98it/s][2025-02-04 03:05:33][root][INFO] - Training Epoch: 2/2, step 22470/23838 completed (loss: 0.9751026630401611, acc: 0.6896551847457886)
[2025-02-04 03:05:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22472/23838 [28:44<07:55,  2.87it/s][2025-02-04 03:05:33][root][INFO] - Training Epoch: 2/2, step 22471/23838 completed (loss: 1.1812902688980103, acc: 0.6071428656578064)
[2025-02-04 03:05:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22473/23838 [28:44<07:36,  2.99it/s][2025-02-04 03:05:34][root][INFO] - Training Epoch: 2/2, step 22472/23838 completed (loss: 0.6242064237594604, acc: 0.8387096524238586)
[2025-02-04 03:05:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22474/23838 [28:44<07:48,  2.91it/s][2025-02-04 03:05:34][root][INFO] - Training Epoch: 2/2, step 22473/23838 completed (loss: 1.1386460065841675, acc: 0.7027027010917664)
[2025-02-04 03:05:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22475/23838 [28:45<07:41,  2.96it/s][2025-02-04 03:05:34][root][INFO] - Training Epoch: 2/2, step 22474/23838 completed (loss: 0.7664556503295898, acc: 0.7868852615356445)
[2025-02-04 03:05:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22476/23838 [28:45<07:34,  3.00it/s][2025-02-04 03:05:35][root][INFO] - Training Epoch: 2/2, step 22475/23838 completed (loss: 0.7287845611572266, acc: 0.8399999737739563)
[2025-02-04 03:05:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22477/23838 [28:45<07:43,  2.94it/s][2025-02-04 03:05:35][root][INFO] - Training Epoch: 2/2, step 22476/23838 completed (loss: 0.440238356590271, acc: 0.875)
[2025-02-04 03:05:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22478/23838 [28:46<07:43,  2.94it/s][2025-02-04 03:05:35][root][INFO] - Training Epoch: 2/2, step 22477/23838 completed (loss: 0.7185592651367188, acc: 0.7599999904632568)
[2025-02-04 03:05:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22479/23838 [28:46<07:17,  3.10it/s][2025-02-04 03:05:36][root][INFO] - Training Epoch: 2/2, step 22478/23838 completed (loss: 0.7690037488937378, acc: 0.782608687877655)
[2025-02-04 03:05:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22480/23838 [28:46<06:58,  3.24it/s][2025-02-04 03:05:36][root][INFO] - Training Epoch: 2/2, step 22479/23838 completed (loss: 0.8796608448028564, acc: 0.7567567825317383)
[2025-02-04 03:05:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22481/23838 [28:47<07:09,  3.16it/s][2025-02-04 03:05:36][root][INFO] - Training Epoch: 2/2, step 22480/23838 completed (loss: 0.800692081451416, acc: 0.800000011920929)
[2025-02-04 03:05:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22482/23838 [28:47<07:12,  3.14it/s][2025-02-04 03:05:37][root][INFO] - Training Epoch: 2/2, step 22481/23838 completed (loss: 0.7320652008056641, acc: 0.7692307829856873)
[2025-02-04 03:05:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22483/23838 [28:47<07:07,  3.17it/s][2025-02-04 03:05:37][root][INFO] - Training Epoch: 2/2, step 22482/23838 completed (loss: 0.9484081864356995, acc: 0.692307710647583)
[2025-02-04 03:05:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22484/23838 [28:48<07:11,  3.14it/s][2025-02-04 03:05:37][root][INFO] - Training Epoch: 2/2, step 22483/23838 completed (loss: 1.1185414791107178, acc: 0.6721311211585999)
[2025-02-04 03:05:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22485/23838 [28:48<07:01,  3.21it/s][2025-02-04 03:05:37][root][INFO] - Training Epoch: 2/2, step 22484/23838 completed (loss: 0.672356128692627, acc: 0.800000011920929)
[2025-02-04 03:05:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22486/23838 [28:48<07:30,  3.00it/s][2025-02-04 03:05:38][root][INFO] - Training Epoch: 2/2, step 22485/23838 completed (loss: 0.9975122213363647, acc: 0.6734693646430969)
[2025-02-04 03:05:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22487/23838 [28:49<07:52,  2.86it/s][2025-02-04 03:05:38][root][INFO] - Training Epoch: 2/2, step 22486/23838 completed (loss: 0.8574070930480957, acc: 0.7843137383460999)
[2025-02-04 03:05:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22488/23838 [28:49<08:08,  2.76it/s][2025-02-04 03:05:39][root][INFO] - Training Epoch: 2/2, step 22487/23838 completed (loss: 1.4488974809646606, acc: 0.5909090638160706)
[2025-02-04 03:05:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22489/23838 [28:49<08:18,  2.71it/s][2025-02-04 03:05:39][root][INFO] - Training Epoch: 2/2, step 22488/23838 completed (loss: 1.2771642208099365, acc: 0.625)
[2025-02-04 03:05:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22490/23838 [28:50<08:11,  2.74it/s][2025-02-04 03:05:39][root][INFO] - Training Epoch: 2/2, step 22489/23838 completed (loss: 0.48425841331481934, acc: 0.9056603908538818)
[2025-02-04 03:05:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22491/23838 [28:50<07:49,  2.87it/s][2025-02-04 03:05:40][root][INFO] - Training Epoch: 2/2, step 22490/23838 completed (loss: 0.5639088749885559, acc: 0.8301886916160583)
[2025-02-04 03:05:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22492/23838 [28:50<07:35,  2.96it/s][2025-02-04 03:05:40][root][INFO] - Training Epoch: 2/2, step 22491/23838 completed (loss: 0.730686366558075, acc: 0.804347813129425)
[2025-02-04 03:05:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22493/23838 [28:51<07:35,  2.95it/s][2025-02-04 03:05:40][root][INFO] - Training Epoch: 2/2, step 22492/23838 completed (loss: 1.151139497756958, acc: 0.644444465637207)
[2025-02-04 03:05:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22494/23838 [28:51<07:33,  2.96it/s][2025-02-04 03:05:41][root][INFO] - Training Epoch: 2/2, step 22493/23838 completed (loss: 0.8427253365516663, acc: 0.75)
[2025-02-04 03:05:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22495/23838 [28:51<07:38,  2.93it/s][2025-02-04 03:05:41][root][INFO] - Training Epoch: 2/2, step 22494/23838 completed (loss: 0.6702440977096558, acc: 0.8225806355476379)
[2025-02-04 03:05:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22496/23838 [28:52<07:29,  2.99it/s][2025-02-04 03:05:41][root][INFO] - Training Epoch: 2/2, step 22495/23838 completed (loss: 0.5245133638381958, acc: 0.8965517282485962)
[2025-02-04 03:05:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22497/23838 [28:52<07:13,  3.09it/s][2025-02-04 03:05:42][root][INFO] - Training Epoch: 2/2, step 22496/23838 completed (loss: 0.7495390176773071, acc: 0.807692289352417)
[2025-02-04 03:05:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22498/23838 [28:52<07:10,  3.12it/s][2025-02-04 03:05:42][root][INFO] - Training Epoch: 2/2, step 22497/23838 completed (loss: 0.7054305076599121, acc: 0.8840579986572266)
[2025-02-04 03:05:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22499/23838 [28:53<07:05,  3.15it/s][2025-02-04 03:05:42][root][INFO] - Training Epoch: 2/2, step 22498/23838 completed (loss: 0.28692078590393066, acc: 0.9210526347160339)
[2025-02-04 03:05:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22500/23838 [28:53<06:57,  3.20it/s][2025-02-04 03:05:43][root][INFO] - Training Epoch: 2/2, step 22499/23838 completed (loss: 0.3012522757053375, acc: 0.8947368264198303)
[2025-02-04 03:05:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22501/23838 [28:53<07:06,  3.13it/s][2025-02-04 03:05:43][root][INFO] - Training Epoch: 2/2, step 22500/23838 completed (loss: 0.6329218149185181, acc: 0.7241379022598267)
[2025-02-04 03:05:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22502/23838 [28:54<06:38,  3.35it/s][2025-02-04 03:05:43][root][INFO] - Training Epoch: 2/2, step 22501/23838 completed (loss: 0.7096479535102844, acc: 0.7931034564971924)
[2025-02-04 03:05:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22503/23838 [28:54<06:39,  3.34it/s][2025-02-04 03:05:43][root][INFO] - Training Epoch: 2/2, step 22502/23838 completed (loss: 0.6326732039451599, acc: 0.7796609997749329)
[2025-02-04 03:05:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22504/23838 [28:54<06:49,  3.26it/s][2025-02-04 03:05:44][root][INFO] - Training Epoch: 2/2, step 22503/23838 completed (loss: 0.22473177313804626, acc: 0.9466666579246521)
[2025-02-04 03:05:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22505/23838 [28:55<06:56,  3.20it/s][2025-02-04 03:05:44][root][INFO] - Training Epoch: 2/2, step 22504/23838 completed (loss: 0.6174370646476746, acc: 0.7682926654815674)
[2025-02-04 03:05:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22506/23838 [28:55<06:55,  3.21it/s][2025-02-04 03:05:44][root][INFO] - Training Epoch: 2/2, step 22505/23838 completed (loss: 0.6175111532211304, acc: 0.8196721076965332)
[2025-02-04 03:05:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22507/23838 [28:55<07:21,  3.02it/s][2025-02-04 03:05:45][root][INFO] - Training Epoch: 2/2, step 22506/23838 completed (loss: 0.5292983651161194, acc: 0.875)
[2025-02-04 03:05:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22508/23838 [28:56<07:25,  2.99it/s][2025-02-04 03:05:45][root][INFO] - Training Epoch: 2/2, step 22507/23838 completed (loss: 0.6541808247566223, acc: 0.8088235259056091)
[2025-02-04 03:05:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22509/23838 [28:56<06:59,  3.16it/s][2025-02-04 03:05:45][root][INFO] - Training Epoch: 2/2, step 22508/23838 completed (loss: 0.8939194083213806, acc: 0.7857142686843872)
[2025-02-04 03:05:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22510/23838 [28:56<06:54,  3.20it/s][2025-02-04 03:05:46][root][INFO] - Training Epoch: 2/2, step 22509/23838 completed (loss: 0.5040464997291565, acc: 0.8571428656578064)
[2025-02-04 03:05:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22511/23838 [28:56<07:02,  3.14it/s][2025-02-04 03:05:46][root][INFO] - Training Epoch: 2/2, step 22510/23838 completed (loss: 0.5722998976707458, acc: 0.8048780560493469)
[2025-02-04 03:05:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22512/23838 [28:57<07:16,  3.04it/s][2025-02-04 03:05:46][root][INFO] - Training Epoch: 2/2, step 22511/23838 completed (loss: 0.9463754296302795, acc: 0.7049180269241333)
[2025-02-04 03:05:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22513/23838 [28:57<07:23,  2.99it/s][2025-02-04 03:05:47][root][INFO] - Training Epoch: 2/2, step 22512/23838 completed (loss: 0.24215002357959747, acc: 0.9210526347160339)
[2025-02-04 03:05:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22514/23838 [28:58<07:31,  2.93it/s][2025-02-04 03:05:47][root][INFO] - Training Epoch: 2/2, step 22513/23838 completed (loss: 1.006360650062561, acc: 0.7142857313156128)
[2025-02-04 03:05:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22515/23838 [28:58<07:53,  2.80it/s][2025-02-04 03:05:48][root][INFO] - Training Epoch: 2/2, step 22514/23838 completed (loss: 0.6972513794898987, acc: 0.8051947951316833)
[2025-02-04 03:05:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22516/23838 [28:58<08:44,  2.52it/s][2025-02-04 03:05:48][root][INFO] - Training Epoch: 2/2, step 22515/23838 completed (loss: 0.8064876794815063, acc: 0.8620689511299133)
[2025-02-04 03:05:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22517/23838 [28:59<08:32,  2.58it/s][2025-02-04 03:05:48][root][INFO] - Training Epoch: 2/2, step 22516/23838 completed (loss: 0.22672812640666962, acc: 0.9117646813392639)
[2025-02-04 03:05:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22518/23838 [28:59<08:41,  2.53it/s][2025-02-04 03:05:49][root][INFO] - Training Epoch: 2/2, step 22517/23838 completed (loss: 0.8518676161766052, acc: 0.7638888955116272)
[2025-02-04 03:05:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22519/23838 [29:00<09:09,  2.40it/s][2025-02-04 03:05:49][root][INFO] - Training Epoch: 2/2, step 22518/23838 completed (loss: 1.098936915397644, acc: 0.701298713684082)
[2025-02-04 03:05:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22520/23838 [29:00<09:31,  2.30it/s][2025-02-04 03:05:50][root][INFO] - Training Epoch: 2/2, step 22519/23838 completed (loss: 1.0002996921539307, acc: 0.760869562625885)
[2025-02-04 03:05:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22521/23838 [29:00<08:57,  2.45it/s][2025-02-04 03:05:50][root][INFO] - Training Epoch: 2/2, step 22520/23838 completed (loss: 0.6404569149017334, acc: 0.8160919547080994)
[2025-02-04 03:05:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22522/23838 [29:01<08:34,  2.56it/s][2025-02-04 03:05:50][root][INFO] - Training Epoch: 2/2, step 22521/23838 completed (loss: 0.4919467866420746, acc: 0.8641975522041321)
[2025-02-04 03:05:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22523/23838 [29:01<08:24,  2.60it/s][2025-02-04 03:05:51][root][INFO] - Training Epoch: 2/2, step 22522/23838 completed (loss: 0.37199410796165466, acc: 0.8936170339584351)
[2025-02-04 03:05:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22524/23838 [29:02<07:50,  2.79it/s][2025-02-04 03:05:51][root][INFO] - Training Epoch: 2/2, step 22523/23838 completed (loss: 1.0462820529937744, acc: 0.6971830725669861)
[2025-02-04 03:05:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22525/23838 [29:02<07:21,  2.98it/s][2025-02-04 03:05:51][root][INFO] - Training Epoch: 2/2, step 22524/23838 completed (loss: 0.6451419591903687, acc: 0.8500000238418579)
[2025-02-04 03:05:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  94%|[34m█████████▍[0m| 22526/23838 [29:02<08:02,  2.72it/s][2025-02-04 03:05:52][root][INFO] - Training Epoch: 2/2, step 22525/23838 completed (loss: 0.4327297806739807, acc: 0.8878504633903503)
[2025-02-04 03:05:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22527/23838 [29:03<07:54,  2.76it/s][2025-02-04 03:05:52][root][INFO] - Training Epoch: 2/2, step 22526/23838 completed (loss: 0.6763970851898193, acc: 0.8253968358039856)
[2025-02-04 03:05:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22528/23838 [29:03<07:51,  2.78it/s][2025-02-04 03:05:53][root][INFO] - Training Epoch: 2/2, step 22527/23838 completed (loss: 0.33681705594062805, acc: 0.8942307829856873)
[2025-02-04 03:05:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22529/23838 [29:03<07:44,  2.82it/s][2025-02-04 03:05:53][root][INFO] - Training Epoch: 2/2, step 22528/23838 completed (loss: 0.6735613942146301, acc: 0.8198198080062866)
[2025-02-04 03:05:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22530/23838 [29:04<07:34,  2.88it/s][2025-02-04 03:05:53][root][INFO] - Training Epoch: 2/2, step 22529/23838 completed (loss: 0.5639552474021912, acc: 0.7962962985038757)
[2025-02-04 03:05:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22531/23838 [29:04<07:31,  2.89it/s][2025-02-04 03:05:54][root][INFO] - Training Epoch: 2/2, step 22530/23838 completed (loss: 0.561458170413971, acc: 0.862500011920929)
[2025-02-04 03:05:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22532/23838 [29:04<07:36,  2.86it/s][2025-02-04 03:05:54][root][INFO] - Training Epoch: 2/2, step 22531/23838 completed (loss: 0.8397116661071777, acc: 0.75)
[2025-02-04 03:05:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22533/23838 [29:05<07:38,  2.85it/s][2025-02-04 03:05:54][root][INFO] - Training Epoch: 2/2, step 22532/23838 completed (loss: 1.5141541957855225, acc: 0.5882353186607361)
[2025-02-04 03:05:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22534/23838 [29:05<07:34,  2.87it/s][2025-02-04 03:05:55][root][INFO] - Training Epoch: 2/2, step 22533/23838 completed (loss: 0.8758277893066406, acc: 0.6739130616188049)
[2025-02-04 03:05:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22535/23838 [29:05<07:50,  2.77it/s][2025-02-04 03:05:55][root][INFO] - Training Epoch: 2/2, step 22534/23838 completed (loss: 0.4128338098526001, acc: 0.8536585569381714)
[2025-02-04 03:05:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22536/23838 [29:06<07:51,  2.76it/s][2025-02-04 03:05:55][root][INFO] - Training Epoch: 2/2, step 22535/23838 completed (loss: 0.8819891810417175, acc: 0.75)
[2025-02-04 03:05:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22537/23838 [29:06<07:59,  2.71it/s][2025-02-04 03:05:56][root][INFO] - Training Epoch: 2/2, step 22536/23838 completed (loss: 0.977556049823761, acc: 0.7142857313156128)
[2025-02-04 03:05:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22538/23838 [29:06<07:44,  2.80it/s][2025-02-04 03:05:56][root][INFO] - Training Epoch: 2/2, step 22537/23838 completed (loss: 0.5818162560462952, acc: 0.7666666507720947)
[2025-02-04 03:05:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22539/23838 [29:07<07:35,  2.85it/s][2025-02-04 03:05:56][root][INFO] - Training Epoch: 2/2, step 22538/23838 completed (loss: 0.4691512882709503, acc: 0.8823529481887817)
[2025-02-04 03:05:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22540/23838 [29:07<07:23,  2.93it/s][2025-02-04 03:05:57][root][INFO] - Training Epoch: 2/2, step 22539/23838 completed (loss: 0.3405766189098358, acc: 0.9054054021835327)
[2025-02-04 03:05:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22541/23838 [29:07<07:31,  2.87it/s][2025-02-04 03:05:57][root][INFO] - Training Epoch: 2/2, step 22540/23838 completed (loss: 0.2007112056016922, acc: 0.9649122953414917)
[2025-02-04 03:05:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22542/23838 [29:08<07:40,  2.81it/s][2025-02-04 03:05:57][root][INFO] - Training Epoch: 2/2, step 22541/23838 completed (loss: 0.1313619464635849, acc: 0.9435483813285828)
[2025-02-04 03:05:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22543/23838 [29:08<07:42,  2.80it/s][2025-02-04 03:05:58][root][INFO] - Training Epoch: 2/2, step 22542/23838 completed (loss: 0.5396607518196106, acc: 0.8461538553237915)
[2025-02-04 03:05:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22544/23838 [29:09<07:33,  2.85it/s][2025-02-04 03:05:58][root][INFO] - Training Epoch: 2/2, step 22543/23838 completed (loss: 0.09573690593242645, acc: 0.9750000238418579)
[2025-02-04 03:05:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22545/23838 [29:09<07:31,  2.87it/s][2025-02-04 03:05:58][root][INFO] - Training Epoch: 2/2, step 22544/23838 completed (loss: 0.5874975919723511, acc: 0.8214285969734192)
[2025-02-04 03:05:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22546/23838 [29:09<07:34,  2.84it/s][2025-02-04 03:05:59][root][INFO] - Training Epoch: 2/2, step 22545/23838 completed (loss: 0.581854522228241, acc: 0.8512396812438965)
[2025-02-04 03:05:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22547/23838 [29:10<07:36,  2.83it/s][2025-02-04 03:05:59][root][INFO] - Training Epoch: 2/2, step 22546/23838 completed (loss: 0.5258761048316956, acc: 0.8735632300376892)
[2025-02-04 03:05:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22548/23838 [29:10<07:21,  2.92it/s][2025-02-04 03:06:00][root][INFO] - Training Epoch: 2/2, step 22547/23838 completed (loss: 0.10403019934892654, acc: 0.9672130942344666)
[2025-02-04 03:06:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22549/23838 [29:10<07:04,  3.04it/s][2025-02-04 03:06:00][root][INFO] - Training Epoch: 2/2, step 22548/23838 completed (loss: 0.2653978765010834, acc: 0.9024389982223511)
[2025-02-04 03:06:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22550/23838 [29:11<07:42,  2.79it/s][2025-02-04 03:06:00][root][INFO] - Training Epoch: 2/2, step 22549/23838 completed (loss: 0.15040689706802368, acc: 0.9532710313796997)
[2025-02-04 03:06:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22551/23838 [29:11<08:22,  2.56it/s][2025-02-04 03:06:01][root][INFO] - Training Epoch: 2/2, step 22550/23838 completed (loss: 0.21102911233901978, acc: 0.938144326210022)
[2025-02-04 03:06:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22552/23838 [29:11<08:13,  2.61it/s][2025-02-04 03:06:01][root][INFO] - Training Epoch: 2/2, step 22551/23838 completed (loss: 0.2791609466075897, acc: 0.949999988079071)
[2025-02-04 03:06:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22553/23838 [29:12<08:08,  2.63it/s][2025-02-04 03:06:01][root][INFO] - Training Epoch: 2/2, step 22552/23838 completed (loss: 0.6117024421691895, acc: 0.8055555820465088)
[2025-02-04 03:06:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22554/23838 [29:12<08:05,  2.65it/s][2025-02-04 03:06:02][root][INFO] - Training Epoch: 2/2, step 22553/23838 completed (loss: 0.5436121225357056, acc: 0.8606557250022888)
[2025-02-04 03:06:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22555/23838 [29:13<08:30,  2.51it/s][2025-02-04 03:06:02][root][INFO] - Training Epoch: 2/2, step 22554/23838 completed (loss: 0.4467165768146515, acc: 0.8958333134651184)
[2025-02-04 03:06:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22556/23838 [29:13<07:59,  2.68it/s][2025-02-04 03:06:03][root][INFO] - Training Epoch: 2/2, step 22555/23838 completed (loss: 0.2736494541168213, acc: 0.9268292784690857)
[2025-02-04 03:06:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22557/23838 [29:13<07:31,  2.84it/s][2025-02-04 03:06:03][root][INFO] - Training Epoch: 2/2, step 22556/23838 completed (loss: 1.4287134408950806, acc: 0.7272727489471436)
[2025-02-04 03:06:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22558/23838 [29:14<07:10,  2.97it/s][2025-02-04 03:06:03][root][INFO] - Training Epoch: 2/2, step 22557/23838 completed (loss: 1.5780659914016724, acc: 0.6153846383094788)
[2025-02-04 03:06:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22559/23838 [29:14<07:43,  2.76it/s][2025-02-04 03:06:04][root][INFO] - Training Epoch: 2/2, step 22558/23838 completed (loss: 0.22245469689369202, acc: 0.9599999785423279)
[2025-02-04 03:06:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22560/23838 [29:14<07:43,  2.76it/s][2025-02-04 03:06:04][root][INFO] - Training Epoch: 2/2, step 22559/23838 completed (loss: 0.9407700300216675, acc: 0.75)
[2025-02-04 03:06:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22561/23838 [29:15<07:32,  2.82it/s][2025-02-04 03:06:04][root][INFO] - Training Epoch: 2/2, step 22560/23838 completed (loss: 0.7120718955993652, acc: 0.8421052694320679)
[2025-02-04 03:06:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22562/23838 [29:15<07:45,  2.74it/s][2025-02-04 03:06:05][root][INFO] - Training Epoch: 2/2, step 22561/23838 completed (loss: 1.5246082544326782, acc: 0.6578947305679321)
[2025-02-04 03:06:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22563/23838 [29:16<08:21,  2.54it/s][2025-02-04 03:06:05][root][INFO] - Training Epoch: 2/2, step 22562/23838 completed (loss: 0.285195529460907, acc: 0.8695651888847351)
[2025-02-04 03:06:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22564/23838 [29:16<08:03,  2.63it/s][2025-02-04 03:06:06][root][INFO] - Training Epoch: 2/2, step 22563/23838 completed (loss: 0.04850044474005699, acc: 1.0)
[2025-02-04 03:06:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22565/23838 [29:16<07:39,  2.77it/s][2025-02-04 03:06:06][root][INFO] - Training Epoch: 2/2, step 22564/23838 completed (loss: 0.4913557469844818, acc: 0.8461538553237915)
[2025-02-04 03:06:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22566/23838 [29:17<07:36,  2.79it/s][2025-02-04 03:06:06][root][INFO] - Training Epoch: 2/2, step 22565/23838 completed (loss: 0.33929240703582764, acc: 0.8181818127632141)
[2025-02-04 03:06:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22567/23838 [29:17<07:35,  2.79it/s][2025-02-04 03:06:07][root][INFO] - Training Epoch: 2/2, step 22566/23838 completed (loss: 0.21735115349292755, acc: 0.9642857313156128)
[2025-02-04 03:06:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22568/23838 [29:17<07:48,  2.71it/s][2025-02-04 03:06:07][root][INFO] - Training Epoch: 2/2, step 22567/23838 completed (loss: 0.07883542031049728, acc: 0.9658119678497314)
[2025-02-04 03:06:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22569/23838 [29:18<07:43,  2.74it/s][2025-02-04 03:06:07][root][INFO] - Training Epoch: 2/2, step 22568/23838 completed (loss: 0.2956351935863495, acc: 0.9056603908538818)
[2025-02-04 03:06:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22570/23838 [29:18<07:34,  2.79it/s][2025-02-04 03:06:08][root][INFO] - Training Epoch: 2/2, step 22569/23838 completed (loss: 0.07423561811447144, acc: 0.9716981053352356)
[2025-02-04 03:06:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22571/23838 [29:18<07:25,  2.84it/s][2025-02-04 03:06:08][root][INFO] - Training Epoch: 2/2, step 22570/23838 completed (loss: 0.1050334945321083, acc: 0.9555555582046509)
[2025-02-04 03:06:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22572/23838 [29:19<07:24,  2.85it/s][2025-02-04 03:06:08][root][INFO] - Training Epoch: 2/2, step 22571/23838 completed (loss: 0.1306862235069275, acc: 0.9590163826942444)
[2025-02-04 03:06:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22573/23838 [29:19<07:37,  2.76it/s][2025-02-04 03:06:09][root][INFO] - Training Epoch: 2/2, step 22572/23838 completed (loss: 0.10914454609155655, acc: 0.9714285731315613)
[2025-02-04 03:06:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22574/23838 [29:19<07:27,  2.82it/s][2025-02-04 03:06:09][root][INFO] - Training Epoch: 2/2, step 22573/23838 completed (loss: 0.059867966920137405, acc: 0.9912280440330505)
[2025-02-04 03:06:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22575/23838 [29:20<07:26,  2.83it/s][2025-02-04 03:06:09][root][INFO] - Training Epoch: 2/2, step 22574/23838 completed (loss: 0.42885497212409973, acc: 0.881118893623352)
[2025-02-04 03:06:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22576/23838 [29:20<07:31,  2.79it/s][2025-02-04 03:06:10][root][INFO] - Training Epoch: 2/2, step 22575/23838 completed (loss: 0.14988191425800323, acc: 0.9657142758369446)
[2025-02-04 03:06:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22577/23838 [29:20<07:18,  2.87it/s][2025-02-04 03:06:10][root][INFO] - Training Epoch: 2/2, step 22576/23838 completed (loss: 0.07741834223270416, acc: 0.9824561476707458)
[2025-02-04 03:06:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22578/23838 [29:21<07:13,  2.91it/s][2025-02-04 03:06:10][root][INFO] - Training Epoch: 2/2, step 22577/23838 completed (loss: 0.16848935186862946, acc: 0.9642857313156128)
[2025-02-04 03:06:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22579/23838 [29:21<07:29,  2.80it/s][2025-02-04 03:06:11][root][INFO] - Training Epoch: 2/2, step 22578/23838 completed (loss: 0.13958977162837982, acc: 0.9605262875556946)
[2025-02-04 03:06:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22580/23838 [29:22<07:29,  2.80it/s][2025-02-04 03:06:11][root][INFO] - Training Epoch: 2/2, step 22579/23838 completed (loss: 0.06720619648694992, acc: 0.9696969985961914)
[2025-02-04 03:06:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22581/23838 [29:22<07:35,  2.76it/s][2025-02-04 03:06:12][root][INFO] - Training Epoch: 2/2, step 22580/23838 completed (loss: 0.31715962290763855, acc: 0.9130434989929199)
[2025-02-04 03:06:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22582/23838 [29:22<07:23,  2.83it/s][2025-02-04 03:06:12][root][INFO] - Training Epoch: 2/2, step 22581/23838 completed (loss: 0.2742275893688202, acc: 0.9124087691307068)
[2025-02-04 03:06:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22583/23838 [29:23<07:19,  2.85it/s][2025-02-04 03:06:12][root][INFO] - Training Epoch: 2/2, step 22582/23838 completed (loss: 0.5038016438484192, acc: 0.8888888955116272)
[2025-02-04 03:06:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22584/23838 [29:23<07:53,  2.65it/s][2025-02-04 03:06:13][root][INFO] - Training Epoch: 2/2, step 22583/23838 completed (loss: 0.42665427923202515, acc: 0.9083333611488342)
[2025-02-04 03:06:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22585/23838 [29:23<08:03,  2.59it/s][2025-02-04 03:06:13][root][INFO] - Training Epoch: 2/2, step 22584/23838 completed (loss: 0.16578619182109833, acc: 0.9642857313156128)
[2025-02-04 03:06:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22586/23838 [29:24<07:37,  2.74it/s][2025-02-04 03:06:13][root][INFO] - Training Epoch: 2/2, step 22585/23838 completed (loss: 0.5203717350959778, acc: 0.8785046935081482)
[2025-02-04 03:06:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22587/23838 [29:24<07:44,  2.70it/s][2025-02-04 03:06:14][root][INFO] - Training Epoch: 2/2, step 22586/23838 completed (loss: 0.26021748781204224, acc: 0.9390243887901306)
[2025-02-04 03:06:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22588/23838 [29:25<08:03,  2.58it/s][2025-02-04 03:06:14][root][INFO] - Training Epoch: 2/2, step 22587/23838 completed (loss: 0.24492980539798737, acc: 0.9375)
[2025-02-04 03:06:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22589/23838 [29:25<08:02,  2.59it/s][2025-02-04 03:06:15][root][INFO] - Training Epoch: 2/2, step 22588/23838 completed (loss: 0.2088789939880371, acc: 0.9552238583564758)
[2025-02-04 03:06:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22590/23838 [29:25<07:53,  2.64it/s][2025-02-04 03:06:15][root][INFO] - Training Epoch: 2/2, step 22589/23838 completed (loss: 0.19835998117923737, acc: 0.9646017551422119)
[2025-02-04 03:06:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22591/23838 [29:26<07:43,  2.69it/s][2025-02-04 03:06:15][root][INFO] - Training Epoch: 2/2, step 22590/23838 completed (loss: 0.3818628191947937, acc: 0.9223300814628601)
[2025-02-04 03:06:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22592/23838 [29:26<07:58,  2.60it/s][2025-02-04 03:06:16][root][INFO] - Training Epoch: 2/2, step 22591/23838 completed (loss: 0.16599741578102112, acc: 0.9557521939277649)
[2025-02-04 03:06:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22593/23838 [29:26<07:54,  2.62it/s][2025-02-04 03:06:16][root][INFO] - Training Epoch: 2/2, step 22592/23838 completed (loss: 0.27311787009239197, acc: 0.9438202381134033)
[2025-02-04 03:06:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22594/23838 [29:27<08:16,  2.51it/s][2025-02-04 03:06:17][root][INFO] - Training Epoch: 2/2, step 22593/23838 completed (loss: 0.37433120608329773, acc: 0.9405405521392822)
[2025-02-04 03:06:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22595/23838 [29:27<08:05,  2.56it/s][2025-02-04 03:06:17][root][INFO] - Training Epoch: 2/2, step 22594/23838 completed (loss: 0.38716551661491394, acc: 0.8909090757369995)
[2025-02-04 03:06:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22596/23838 [29:28<07:50,  2.64it/s][2025-02-04 03:06:17][root][INFO] - Training Epoch: 2/2, step 22595/23838 completed (loss: 0.07612816244363785, acc: 0.9722222089767456)
[2025-02-04 03:06:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22597/23838 [29:28<07:32,  2.74it/s][2025-02-04 03:06:18][root][INFO] - Training Epoch: 2/2, step 22596/23838 completed (loss: 0.0815374106168747, acc: 0.9887640476226807)
[2025-02-04 03:06:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22598/23838 [29:28<07:20,  2.82it/s][2025-02-04 03:06:18][root][INFO] - Training Epoch: 2/2, step 22597/23838 completed (loss: 0.09045515209436417, acc: 0.97826087474823)
[2025-02-04 03:06:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22599/23838 [29:29<07:41,  2.69it/s][2025-02-04 03:06:18][root][INFO] - Training Epoch: 2/2, step 22598/23838 completed (loss: 0.10233604907989502, acc: 0.9822221994400024)
[2025-02-04 03:06:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22600/23838 [29:29<07:22,  2.80it/s][2025-02-04 03:06:19][root][INFO] - Training Epoch: 2/2, step 22599/23838 completed (loss: 0.04299648106098175, acc: 0.9917355179786682)
[2025-02-04 03:06:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22601/23838 [29:29<07:16,  2.83it/s][2025-02-04 03:06:19][root][INFO] - Training Epoch: 2/2, step 22600/23838 completed (loss: 0.08914124220609665, acc: 0.98591548204422)
[2025-02-04 03:06:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22602/23838 [29:30<07:22,  2.79it/s][2025-02-04 03:06:19][root][INFO] - Training Epoch: 2/2, step 22601/23838 completed (loss: 0.15618623793125153, acc: 0.9599999785423279)
[2025-02-04 03:06:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22603/23838 [29:30<07:01,  2.93it/s][2025-02-04 03:06:20][root][INFO] - Training Epoch: 2/2, step 22602/23838 completed (loss: 0.0777268186211586, acc: 0.9659090638160706)
[2025-02-04 03:06:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22604/23838 [29:30<06:55,  2.97it/s][2025-02-04 03:06:20][root][INFO] - Training Epoch: 2/2, step 22603/23838 completed (loss: 0.05006134510040283, acc: 0.9928571581840515)
[2025-02-04 03:06:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22605/23838 [29:31<07:00,  2.94it/s][2025-02-04 03:06:20][root][INFO] - Training Epoch: 2/2, step 22604/23838 completed (loss: 0.04913969710469246, acc: 0.9936708807945251)
[2025-02-04 03:06:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22606/23838 [29:31<06:57,  2.95it/s][2025-02-04 03:06:21][root][INFO] - Training Epoch: 2/2, step 22605/23838 completed (loss: 0.05349439010024071, acc: 0.9882352948188782)
[2025-02-04 03:06:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22607/23838 [29:31<06:55,  2.96it/s][2025-02-04 03:06:21][root][INFO] - Training Epoch: 2/2, step 22606/23838 completed (loss: 0.1392403244972229, acc: 0.9615384340286255)
[2025-02-04 03:06:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22608/23838 [29:32<06:52,  2.99it/s][2025-02-04 03:06:21][root][INFO] - Training Epoch: 2/2, step 22607/23838 completed (loss: 0.7209779620170593, acc: 0.7222222089767456)
[2025-02-04 03:06:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22609/23838 [29:32<06:45,  3.03it/s][2025-02-04 03:06:22][root][INFO] - Training Epoch: 2/2, step 22608/23838 completed (loss: 0.7186563611030579, acc: 0.71875)
[2025-02-04 03:06:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22610/23838 [29:32<06:41,  3.06it/s][2025-02-04 03:06:22][root][INFO] - Training Epoch: 2/2, step 22609/23838 completed (loss: 0.7982083559036255, acc: 0.6315789222717285)
[2025-02-04 03:06:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22611/23838 [29:33<06:33,  3.12it/s][2025-02-04 03:06:22][root][INFO] - Training Epoch: 2/2, step 22610/23838 completed (loss: 0.5787250399589539, acc: 0.8333333134651184)
[2025-02-04 03:06:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22612/23838 [29:33<06:26,  3.17it/s][2025-02-04 03:06:23][root][INFO] - Training Epoch: 2/2, step 22611/23838 completed (loss: 0.8374142646789551, acc: 0.75)
[2025-02-04 03:06:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22613/23838 [29:33<06:28,  3.16it/s][2025-02-04 03:06:23][root][INFO] - Training Epoch: 2/2, step 22612/23838 completed (loss: 0.3291413187980652, acc: 0.925000011920929)
[2025-02-04 03:06:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22614/23838 [29:34<06:41,  3.05it/s][2025-02-04 03:06:23][root][INFO] - Training Epoch: 2/2, step 22613/23838 completed (loss: 0.7192279696464539, acc: 0.782608687877655)
[2025-02-04 03:06:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22615/23838 [29:34<06:51,  2.97it/s][2025-02-04 03:06:24][root][INFO] - Training Epoch: 2/2, step 22614/23838 completed (loss: 0.9223998785018921, acc: 0.7555555701255798)
[2025-02-04 03:06:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22616/23838 [29:34<06:55,  2.94it/s][2025-02-04 03:06:24][root][INFO] - Training Epoch: 2/2, step 22615/23838 completed (loss: 0.6943958401679993, acc: 0.8297872543334961)
[2025-02-04 03:06:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22617/23838 [29:35<06:46,  3.01it/s][2025-02-04 03:06:24][root][INFO] - Training Epoch: 2/2, step 22616/23838 completed (loss: 0.9779675602912903, acc: 0.78125)
[2025-02-04 03:06:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22618/23838 [29:35<07:04,  2.88it/s][2025-02-04 03:06:25][root][INFO] - Training Epoch: 2/2, step 22617/23838 completed (loss: 0.743080198764801, acc: 0.8095238208770752)
[2025-02-04 03:06:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22619/23838 [29:35<07:31,  2.70it/s][2025-02-04 03:06:25][root][INFO] - Training Epoch: 2/2, step 22618/23838 completed (loss: 1.2790699005126953, acc: 0.6363636255264282)
[2025-02-04 03:06:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22620/23838 [29:36<07:22,  2.75it/s][2025-02-04 03:06:25][root][INFO] - Training Epoch: 2/2, step 22619/23838 completed (loss: 1.1463662385940552, acc: 0.695652186870575)
[2025-02-04 03:06:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22621/23838 [29:36<07:11,  2.82it/s][2025-02-04 03:06:26][root][INFO] - Training Epoch: 2/2, step 22620/23838 completed (loss: 0.8697224259376526, acc: 0.7567567825317383)
[2025-02-04 03:06:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22622/23838 [29:37<07:26,  2.72it/s][2025-02-04 03:06:26][root][INFO] - Training Epoch: 2/2, step 22621/23838 completed (loss: 0.4964233636856079, acc: 0.8181818127632141)
[2025-02-04 03:06:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22623/23838 [29:37<09:14,  2.19it/s][2025-02-04 03:06:27][root][INFO] - Training Epoch: 2/2, step 22622/23838 completed (loss: 1.1414954662322998, acc: 0.7250000238418579)
[2025-02-04 03:06:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22624/23838 [29:38<10:23,  1.95it/s][2025-02-04 03:06:27][root][INFO] - Training Epoch: 2/2, step 22623/23838 completed (loss: 1.1156203746795654, acc: 0.6666666865348816)
[2025-02-04 03:06:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22625/23838 [29:38<09:15,  2.19it/s][2025-02-04 03:06:28][root][INFO] - Training Epoch: 2/2, step 22624/23838 completed (loss: 0.37358322739601135, acc: 0.8947368264198303)
[2025-02-04 03:06:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22626/23838 [29:39<09:01,  2.24it/s][2025-02-04 03:06:28][root][INFO] - Training Epoch: 2/2, step 22625/23838 completed (loss: 0.11990060657262802, acc: 0.9830508232116699)
[2025-02-04 03:06:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22627/23838 [29:39<08:19,  2.42it/s][2025-02-04 03:06:29][root][INFO] - Training Epoch: 2/2, step 22626/23838 completed (loss: 1.0676732063293457, acc: 0.699999988079071)
[2025-02-04 03:06:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22628/23838 [29:39<07:58,  2.53it/s][2025-02-04 03:06:29][root][INFO] - Training Epoch: 2/2, step 22627/23838 completed (loss: 0.11847694218158722, acc: 0.9599999785423279)
[2025-02-04 03:06:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22629/23838 [29:40<07:56,  2.54it/s][2025-02-04 03:06:29][root][INFO] - Training Epoch: 2/2, step 22628/23838 completed (loss: 0.6839433908462524, acc: 0.8108108043670654)
[2025-02-04 03:06:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22630/23838 [29:40<07:42,  2.61it/s][2025-02-04 03:06:30][root][INFO] - Training Epoch: 2/2, step 22629/23838 completed (loss: 0.43373212218284607, acc: 0.8795180916786194)
[2025-02-04 03:06:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22631/23838 [29:40<07:49,  2.57it/s][2025-02-04 03:06:30][root][INFO] - Training Epoch: 2/2, step 22630/23838 completed (loss: 0.3818527162075043, acc: 0.8833333253860474)
[2025-02-04 03:06:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22632/23838 [29:41<07:37,  2.64it/s][2025-02-04 03:06:30][root][INFO] - Training Epoch: 2/2, step 22631/23838 completed (loss: 0.2890758216381073, acc: 0.9222221970558167)
[2025-02-04 03:06:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22633/23838 [29:41<07:44,  2.60it/s][2025-02-04 03:06:31][root][INFO] - Training Epoch: 2/2, step 22632/23838 completed (loss: 0.28164270520210266, acc: 0.9312499761581421)
[2025-02-04 03:06:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22634/23838 [29:42<07:36,  2.64it/s][2025-02-04 03:06:31][root][INFO] - Training Epoch: 2/2, step 22633/23838 completed (loss: 0.20317281782627106, acc: 0.9599999785423279)
[2025-02-04 03:06:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22635/23838 [29:42<08:02,  2.49it/s][2025-02-04 03:06:32][root][INFO] - Training Epoch: 2/2, step 22634/23838 completed (loss: 0.3214096426963806, acc: 0.8951048851013184)
[2025-02-04 03:06:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22636/23838 [29:42<08:05,  2.48it/s][2025-02-04 03:06:32][root][INFO] - Training Epoch: 2/2, step 22635/23838 completed (loss: 0.3089887499809265, acc: 0.9272727370262146)
[2025-02-04 03:06:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22637/23838 [29:43<07:54,  2.53it/s][2025-02-04 03:06:32][root][INFO] - Training Epoch: 2/2, step 22636/23838 completed (loss: 0.39238932728767395, acc: 0.8865247964859009)
[2025-02-04 03:06:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22638/23838 [29:43<07:34,  2.64it/s][2025-02-04 03:06:33][root][INFO] - Training Epoch: 2/2, step 22637/23838 completed (loss: 0.22256828844547272, acc: 0.949999988079071)
[2025-02-04 03:06:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22639/23838 [29:43<07:08,  2.80it/s][2025-02-04 03:06:33][root][INFO] - Training Epoch: 2/2, step 22638/23838 completed (loss: 0.3628665506839752, acc: 0.920634925365448)
[2025-02-04 03:06:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22640/23838 [29:44<07:09,  2.79it/s][2025-02-04 03:06:33][root][INFO] - Training Epoch: 2/2, step 22639/23838 completed (loss: 0.35013696551322937, acc: 0.9104477763175964)
[2025-02-04 03:06:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22641/23838 [29:44<07:00,  2.85it/s][2025-02-04 03:06:34][root][INFO] - Training Epoch: 2/2, step 22640/23838 completed (loss: 0.32882627844810486, acc: 0.8999999761581421)
[2025-02-04 03:06:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22642/23838 [29:45<07:02,  2.83it/s][2025-02-04 03:06:34][root][INFO] - Training Epoch: 2/2, step 22641/23838 completed (loss: 0.25975510478019714, acc: 0.9468085169792175)
[2025-02-04 03:06:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22643/23838 [29:45<07:04,  2.81it/s][2025-02-04 03:06:34][root][INFO] - Training Epoch: 2/2, step 22642/23838 completed (loss: 0.38269975781440735, acc: 0.9142857193946838)
[2025-02-04 03:06:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22644/23838 [29:45<07:03,  2.82it/s][2025-02-04 03:06:35][root][INFO] - Training Epoch: 2/2, step 22643/23838 completed (loss: 0.26792827248573303, acc: 0.9178082346916199)
[2025-02-04 03:06:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22645/23838 [29:46<06:41,  2.97it/s][2025-02-04 03:06:35][root][INFO] - Training Epoch: 2/2, step 22644/23838 completed (loss: 0.23141451179981232, acc: 0.9520547986030579)
[2025-02-04 03:06:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▍[0m| 22646/23838 [29:46<06:55,  2.87it/s][2025-02-04 03:06:35][root][INFO] - Training Epoch: 2/2, step 22645/23838 completed (loss: 0.19921503961086273, acc: 0.9448275566101074)
[2025-02-04 03:06:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22647/23838 [29:46<07:07,  2.78it/s][2025-02-04 03:06:36][root][INFO] - Training Epoch: 2/2, step 22646/23838 completed (loss: 0.6079338788986206, acc: 0.8095238208770752)
[2025-02-04 03:06:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22648/23838 [29:47<07:04,  2.81it/s][2025-02-04 03:06:36][root][INFO] - Training Epoch: 2/2, step 22647/23838 completed (loss: 0.18397212028503418, acc: 0.9626168012619019)
[2025-02-04 03:06:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22649/23838 [29:47<07:25,  2.67it/s][2025-02-04 03:06:37][root][INFO] - Training Epoch: 2/2, step 22648/23838 completed (loss: 0.3487749993801117, acc: 0.8895705342292786)
[2025-02-04 03:06:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22650/23838 [29:47<07:28,  2.65it/s][2025-02-04 03:06:37][root][INFO] - Training Epoch: 2/2, step 22649/23838 completed (loss: 0.27196893095970154, acc: 0.9354838728904724)
[2025-02-04 03:06:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22651/23838 [29:48<07:05,  2.79it/s][2025-02-04 03:06:37][root][INFO] - Training Epoch: 2/2, step 22650/23838 completed (loss: 0.3617735505104065, acc: 0.8983050584793091)
[2025-02-04 03:06:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22652/23838 [29:48<06:47,  2.91it/s][2025-02-04 03:06:38][root][INFO] - Training Epoch: 2/2, step 22651/23838 completed (loss: 0.29715973138809204, acc: 0.9215686321258545)
[2025-02-04 03:06:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22653/23838 [29:48<07:12,  2.74it/s][2025-02-04 03:06:38][root][INFO] - Training Epoch: 2/2, step 22652/23838 completed (loss: 0.18652474880218506, acc: 0.9354838728904724)
[2025-02-04 03:06:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22654/23838 [29:49<07:31,  2.62it/s][2025-02-04 03:06:38][root][INFO] - Training Epoch: 2/2, step 22653/23838 completed (loss: 0.23223493993282318, acc: 0.9210526347160339)
[2025-02-04 03:06:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22655/23838 [29:49<07:32,  2.61it/s][2025-02-04 03:06:39][root][INFO] - Training Epoch: 2/2, step 22654/23838 completed (loss: 0.37351763248443604, acc: 0.867132842540741)
[2025-02-04 03:06:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22656/23838 [29:50<07:41,  2.56it/s][2025-02-04 03:06:39][root][INFO] - Training Epoch: 2/2, step 22655/23838 completed (loss: 0.2852567136287689, acc: 0.9028571248054504)
[2025-02-04 03:06:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22657/23838 [29:50<07:22,  2.67it/s][2025-02-04 03:06:40][root][INFO] - Training Epoch: 2/2, step 22656/23838 completed (loss: 0.25439900159835815, acc: 0.89552241563797)
[2025-02-04 03:06:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22658/23838 [29:50<07:29,  2.63it/s][2025-02-04 03:06:40][root][INFO] - Training Epoch: 2/2, step 22657/23838 completed (loss: 0.33223190903663635, acc: 0.8969072103500366)
[2025-02-04 03:06:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22659/23838 [29:51<07:45,  2.54it/s][2025-02-04 03:06:40][root][INFO] - Training Epoch: 2/2, step 22658/23838 completed (loss: 0.14128687977790833, acc: 0.9615384340286255)
[2025-02-04 03:06:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22660/23838 [29:51<07:42,  2.54it/s][2025-02-04 03:06:41][root][INFO] - Training Epoch: 2/2, step 22659/23838 completed (loss: 0.5580240488052368, acc: 0.8500000238418579)
[2025-02-04 03:06:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22661/23838 [29:52<07:31,  2.61it/s][2025-02-04 03:06:41][root][INFO] - Training Epoch: 2/2, step 22660/23838 completed (loss: 0.31974804401397705, acc: 0.9197530746459961)
[2025-02-04 03:06:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22662/23838 [29:52<06:55,  2.83it/s][2025-02-04 03:06:41][root][INFO] - Training Epoch: 2/2, step 22661/23838 completed (loss: 0.5056809186935425, acc: 0.8139534592628479)
[2025-02-04 03:06:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22663/23838 [29:52<07:09,  2.74it/s][2025-02-04 03:06:42][root][INFO] - Training Epoch: 2/2, step 22662/23838 completed (loss: 0.31288301944732666, acc: 0.9193548560142517)
[2025-02-04 03:06:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22664/23838 [29:53<07:24,  2.64it/s][2025-02-04 03:06:42][root][INFO] - Training Epoch: 2/2, step 22663/23838 completed (loss: 0.6859902143478394, acc: 0.8240740895271301)
[2025-02-04 03:06:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22665/23838 [29:53<06:51,  2.85it/s][2025-02-04 03:06:43][root][INFO] - Training Epoch: 2/2, step 22664/23838 completed (loss: 0.22336366772651672, acc: 0.9555555582046509)
[2025-02-04 03:06:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22666/23838 [29:53<06:40,  2.93it/s][2025-02-04 03:06:43][root][INFO] - Training Epoch: 2/2, step 22665/23838 completed (loss: 0.1357002556324005, acc: 0.9624999761581421)
[2025-02-04 03:06:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22667/23838 [29:54<06:34,  2.97it/s][2025-02-04 03:06:43][root][INFO] - Training Epoch: 2/2, step 22666/23838 completed (loss: 0.22716476023197174, acc: 0.9150943160057068)
[2025-02-04 03:06:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22668/23838 [29:54<06:17,  3.10it/s][2025-02-04 03:06:43][root][INFO] - Training Epoch: 2/2, step 22667/23838 completed (loss: 0.22856804728507996, acc: 0.9238095283508301)
[2025-02-04 03:06:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22669/23838 [29:54<06:21,  3.06it/s][2025-02-04 03:06:44][root][INFO] - Training Epoch: 2/2, step 22668/23838 completed (loss: 0.1414269655942917, acc: 0.9550561904907227)
[2025-02-04 03:06:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22670/23838 [29:55<06:54,  2.82it/s][2025-02-04 03:06:44][root][INFO] - Training Epoch: 2/2, step 22669/23838 completed (loss: 0.21967321634292603, acc: 0.9384615421295166)
[2025-02-04 03:06:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22671/23838 [29:55<07:30,  2.59it/s][2025-02-04 03:06:45][root][INFO] - Training Epoch: 2/2, step 22670/23838 completed (loss: 0.4358644187450409, acc: 0.8759689927101135)
[2025-02-04 03:06:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22672/23838 [29:55<07:24,  2.62it/s][2025-02-04 03:06:45][root][INFO] - Training Epoch: 2/2, step 22671/23838 completed (loss: 0.2886488139629364, acc: 0.916167676448822)
[2025-02-04 03:06:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22673/23838 [29:56<07:00,  2.77it/s][2025-02-04 03:06:45][root][INFO] - Training Epoch: 2/2, step 22672/23838 completed (loss: 0.7474610209465027, acc: 0.8120300769805908)
[2025-02-04 03:06:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22674/23838 [29:56<07:45,  2.50it/s][2025-02-04 03:06:46][root][INFO] - Training Epoch: 2/2, step 22673/23838 completed (loss: 0.24960622191429138, acc: 0.8764045238494873)
[2025-02-04 03:06:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22675/23838 [29:57<07:27,  2.60it/s][2025-02-04 03:06:46][root][INFO] - Training Epoch: 2/2, step 22674/23838 completed (loss: 0.5475582480430603, acc: 0.7872340679168701)
[2025-02-04 03:06:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22676/23838 [29:57<07:24,  2.62it/s][2025-02-04 03:06:47][root][INFO] - Training Epoch: 2/2, step 22675/23838 completed (loss: 0.5500335693359375, acc: 0.8380952477455139)
[2025-02-04 03:06:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22677/23838 [29:57<07:14,  2.67it/s][2025-02-04 03:06:47][root][INFO] - Training Epoch: 2/2, step 22676/23838 completed (loss: 0.02620949037373066, acc: 1.0)
[2025-02-04 03:06:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22678/23838 [29:58<07:06,  2.72it/s][2025-02-04 03:06:47][root][INFO] - Training Epoch: 2/2, step 22677/23838 completed (loss: 0.36746782064437866, acc: 0.9333333373069763)
[2025-02-04 03:06:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22679/23838 [29:58<07:06,  2.72it/s][2025-02-04 03:06:48][root][INFO] - Training Epoch: 2/2, step 22678/23838 completed (loss: 0.403272420167923, acc: 0.8910890817642212)
[2025-02-04 03:06:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22680/23838 [29:59<07:46,  2.48it/s][2025-02-04 03:06:48][root][INFO] - Training Epoch: 2/2, step 22679/23838 completed (loss: 0.2125559002161026, acc: 0.9455445408821106)
[2025-02-04 03:06:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22681/23838 [29:59<07:41,  2.51it/s][2025-02-04 03:06:49][root][INFO] - Training Epoch: 2/2, step 22680/23838 completed (loss: 0.3420800268650055, acc: 0.9155844449996948)
[2025-02-04 03:06:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22682/23838 [29:59<08:08,  2.37it/s][2025-02-04 03:06:49][root][INFO] - Training Epoch: 2/2, step 22681/23838 completed (loss: 0.40720105171203613, acc: 0.8775510191917419)
[2025-02-04 03:06:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22683/23838 [30:00<07:46,  2.48it/s][2025-02-04 03:06:49][root][INFO] - Training Epoch: 2/2, step 22682/23838 completed (loss: 0.2398315817117691, acc: 0.914893627166748)
[2025-02-04 03:06:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22684/23838 [30:00<07:31,  2.56it/s][2025-02-04 03:06:50][root][INFO] - Training Epoch: 2/2, step 22683/23838 completed (loss: 0.4502533972263336, acc: 0.8759689927101135)
[2025-02-04 03:06:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22685/23838 [30:01<08:12,  2.34it/s][2025-02-04 03:06:50][root][INFO] - Training Epoch: 2/2, step 22684/23838 completed (loss: 0.2567322254180908, acc: 0.9436619877815247)
[2025-02-04 03:06:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22686/23838 [30:01<07:41,  2.49it/s][2025-02-04 03:06:51][root][INFO] - Training Epoch: 2/2, step 22685/23838 completed (loss: 0.22736424207687378, acc: 0.9318181872367859)
[2025-02-04 03:06:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22687/23838 [30:02<08:26,  2.27it/s][2025-02-04 03:06:51][root][INFO] - Training Epoch: 2/2, step 22686/23838 completed (loss: 0.2754775583744049, acc: 0.9234693646430969)
[2025-02-04 03:06:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22688/23838 [30:02<07:56,  2.41it/s][2025-02-04 03:06:52][root][INFO] - Training Epoch: 2/2, step 22687/23838 completed (loss: 0.27033013105392456, acc: 0.925000011920929)
[2025-02-04 03:06:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22689/23838 [30:02<08:08,  2.35it/s][2025-02-04 03:06:52][root][INFO] - Training Epoch: 2/2, step 22688/23838 completed (loss: 0.25383561849594116, acc: 0.94017094373703)
[2025-02-04 03:06:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22690/23838 [30:03<08:33,  2.23it/s][2025-02-04 03:06:52][root][INFO] - Training Epoch: 2/2, step 22689/23838 completed (loss: 0.46458056569099426, acc: 0.8980891704559326)
[2025-02-04 03:06:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22691/23838 [30:04<10:11,  1.88it/s][2025-02-04 03:06:53][root][INFO] - Training Epoch: 2/2, step 22690/23838 completed (loss: 0.47941112518310547, acc: 0.8732394576072693)
[2025-02-04 03:06:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22692/23838 [30:04<09:24,  2.03it/s][2025-02-04 03:06:54][root][INFO] - Training Epoch: 2/2, step 22691/23838 completed (loss: 0.28538715839385986, acc: 0.9272727370262146)
[2025-02-04 03:06:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22693/23838 [30:04<09:00,  2.12it/s][2025-02-04 03:06:54][root][INFO] - Training Epoch: 2/2, step 22692/23838 completed (loss: 0.3815061151981354, acc: 0.8852459192276001)
[2025-02-04 03:06:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22694/23838 [30:05<08:35,  2.22it/s][2025-02-04 03:06:54][root][INFO] - Training Epoch: 2/2, step 22693/23838 completed (loss: 0.4502667188644409, acc: 0.8910256624221802)
[2025-02-04 03:06:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22695/23838 [30:05<08:02,  2.37it/s][2025-02-04 03:06:55][root][INFO] - Training Epoch: 2/2, step 22694/23838 completed (loss: 0.21464452147483826, acc: 0.9212598204612732)
[2025-02-04 03:06:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22696/23838 [30:06<07:51,  2.42it/s][2025-02-04 03:06:55][root][INFO] - Training Epoch: 2/2, step 22695/23838 completed (loss: 0.4116547107696533, acc: 0.8866666555404663)
[2025-02-04 03:06:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22697/23838 [30:06<07:16,  2.62it/s][2025-02-04 03:06:55][root][INFO] - Training Epoch: 2/2, step 22696/23838 completed (loss: 1.0125181674957275, acc: 0.7042253613471985)
[2025-02-04 03:06:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22698/23838 [30:06<06:41,  2.84it/s][2025-02-04 03:06:56][root][INFO] - Training Epoch: 2/2, step 22697/23838 completed (loss: 0.2328784167766571, acc: 0.9504950642585754)
[2025-02-04 03:06:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22699/23838 [30:06<06:23,  2.97it/s][2025-02-04 03:06:56][root][INFO] - Training Epoch: 2/2, step 22698/23838 completed (loss: 0.0843643844127655, acc: 0.9599999785423279)
[2025-02-04 03:06:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22700/23838 [30:07<06:17,  3.01it/s][2025-02-04 03:06:56][root][INFO] - Training Epoch: 2/2, step 22699/23838 completed (loss: 0.2564052641391754, acc: 0.9368420839309692)
[2025-02-04 03:06:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22701/23838 [30:07<06:22,  2.97it/s][2025-02-04 03:06:57][root][INFO] - Training Epoch: 2/2, step 22700/23838 completed (loss: 0.1298418641090393, acc: 0.9454545378684998)
[2025-02-04 03:06:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22702/23838 [30:07<06:24,  2.95it/s][2025-02-04 03:06:57][root][INFO] - Training Epoch: 2/2, step 22701/23838 completed (loss: 0.3253689408302307, acc: 0.9523809552192688)
[2025-02-04 03:06:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22703/23838 [30:08<06:29,  2.92it/s][2025-02-04 03:06:57][root][INFO] - Training Epoch: 2/2, step 22702/23838 completed (loss: 0.2567121982574463, acc: 0.9268292784690857)
[2025-02-04 03:06:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22704/23838 [30:08<06:16,  3.01it/s][2025-02-04 03:06:58][root][INFO] - Training Epoch: 2/2, step 22703/23838 completed (loss: 0.48622870445251465, acc: 0.8679245114326477)
[2025-02-04 03:06:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22705/23838 [30:08<06:16,  3.01it/s][2025-02-04 03:06:58][root][INFO] - Training Epoch: 2/2, step 22704/23838 completed (loss: 0.12962400913238525, acc: 0.9545454382896423)
[2025-02-04 03:06:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22706/23838 [30:09<06:18,  2.99it/s][2025-02-04 03:06:58][root][INFO] - Training Epoch: 2/2, step 22705/23838 completed (loss: 0.7851601243019104, acc: 0.75)
[2025-02-04 03:06:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22707/23838 [30:09<06:16,  3.01it/s][2025-02-04 03:06:59][root][INFO] - Training Epoch: 2/2, step 22706/23838 completed (loss: 0.6286646723747253, acc: 0.8235294222831726)
[2025-02-04 03:06:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22708/23838 [30:10<06:44,  2.80it/s][2025-02-04 03:06:59][root][INFO] - Training Epoch: 2/2, step 22707/23838 completed (loss: 0.2495560348033905, acc: 0.9111111164093018)
[2025-02-04 03:06:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22709/23838 [30:10<06:31,  2.89it/s][2025-02-04 03:06:59][root][INFO] - Training Epoch: 2/2, step 22708/23838 completed (loss: 0.3337850272655487, acc: 0.9142857193946838)
[2025-02-04 03:07:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22710/23838 [30:10<06:26,  2.92it/s][2025-02-04 03:07:00][root][INFO] - Training Epoch: 2/2, step 22709/23838 completed (loss: 0.8161130547523499, acc: 0.7804877758026123)
[2025-02-04 03:07:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22711/23838 [30:11<06:11,  3.03it/s][2025-02-04 03:07:00][root][INFO] - Training Epoch: 2/2, step 22710/23838 completed (loss: 0.5595687031745911, acc: 0.8630136847496033)
[2025-02-04 03:07:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22712/23838 [30:11<06:17,  2.98it/s][2025-02-04 03:07:00][root][INFO] - Training Epoch: 2/2, step 22711/23838 completed (loss: 0.23426274955272675, acc: 0.9090909361839294)
[2025-02-04 03:07:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22713/23838 [30:11<06:20,  2.96it/s][2025-02-04 03:07:01][root][INFO] - Training Epoch: 2/2, step 22712/23838 completed (loss: 0.38599881529808044, acc: 0.9016393423080444)
[2025-02-04 03:07:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22714/23838 [30:11<05:59,  3.13it/s][2025-02-04 03:07:01][root][INFO] - Training Epoch: 2/2, step 22713/23838 completed (loss: 0.8462983965873718, acc: 0.7611940503120422)
[2025-02-04 03:07:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22715/23838 [30:12<06:03,  3.09it/s][2025-02-04 03:07:01][root][INFO] - Training Epoch: 2/2, step 22714/23838 completed (loss: 0.7908228039741516, acc: 0.8166666626930237)
[2025-02-04 03:07:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22716/23838 [30:12<06:19,  2.96it/s][2025-02-04 03:07:02][root][INFO] - Training Epoch: 2/2, step 22715/23838 completed (loss: 0.5879430770874023, acc: 0.8712871074676514)
[2025-02-04 03:07:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22717/23838 [30:13<06:33,  2.85it/s][2025-02-04 03:07:02][root][INFO] - Training Epoch: 2/2, step 22716/23838 completed (loss: 0.4313209354877472, acc: 0.9154929518699646)
[2025-02-04 03:07:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22718/23838 [30:13<06:59,  2.67it/s][2025-02-04 03:07:03][root][INFO] - Training Epoch: 2/2, step 22717/23838 completed (loss: 0.23304644227027893, acc: 0.9607843160629272)
[2025-02-04 03:07:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22719/23838 [30:13<06:44,  2.76it/s][2025-02-04 03:07:03][root][INFO] - Training Epoch: 2/2, step 22718/23838 completed (loss: 0.20262764394283295, acc: 0.9583333134651184)
[2025-02-04 03:07:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22720/23838 [30:14<06:39,  2.80it/s][2025-02-04 03:07:03][root][INFO] - Training Epoch: 2/2, step 22719/23838 completed (loss: 0.5230721831321716, acc: 0.875)
[2025-02-04 03:07:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22721/23838 [30:14<06:46,  2.75it/s][2025-02-04 03:07:04][root][INFO] - Training Epoch: 2/2, step 22720/23838 completed (loss: 0.4865938425064087, acc: 0.8709677457809448)
[2025-02-04 03:07:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22722/23838 [30:14<06:40,  2.79it/s][2025-02-04 03:07:04][root][INFO] - Training Epoch: 2/2, step 22721/23838 completed (loss: 0.21402910351753235, acc: 0.97826087474823)
[2025-02-04 03:07:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22723/23838 [30:15<06:39,  2.79it/s][2025-02-04 03:07:04][root][INFO] - Training Epoch: 2/2, step 22722/23838 completed (loss: 0.16056537628173828, acc: 0.8846153616905212)
[2025-02-04 03:07:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22724/23838 [30:15<06:33,  2.83it/s][2025-02-04 03:07:05][root][INFO] - Training Epoch: 2/2, step 22723/23838 completed (loss: 0.2237885445356369, acc: 0.978723406791687)
[2025-02-04 03:07:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22725/23838 [30:15<06:50,  2.71it/s][2025-02-04 03:07:05][root][INFO] - Training Epoch: 2/2, step 22724/23838 completed (loss: 0.8531019687652588, acc: 0.797468364238739)
[2025-02-04 03:07:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22726/23838 [30:16<06:54,  2.68it/s][2025-02-04 03:07:05][root][INFO] - Training Epoch: 2/2, step 22725/23838 completed (loss: 0.3714646100997925, acc: 0.868852436542511)
[2025-02-04 03:07:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22727/23838 [30:16<06:44,  2.75it/s][2025-02-04 03:07:06][root][INFO] - Training Epoch: 2/2, step 22726/23838 completed (loss: 0.45529279112815857, acc: 0.8571428656578064)
[2025-02-04 03:07:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22728/23838 [30:17<06:32,  2.83it/s][2025-02-04 03:07:06][root][INFO] - Training Epoch: 2/2, step 22727/23838 completed (loss: 0.094480961561203, acc: 0.9696969985961914)
[2025-02-04 03:07:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22729/23838 [30:17<06:32,  2.82it/s][2025-02-04 03:07:06][root][INFO] - Training Epoch: 2/2, step 22728/23838 completed (loss: 0.36456361413002014, acc: 0.939393937587738)
[2025-02-04 03:07:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22730/23838 [30:17<06:31,  2.83it/s][2025-02-04 03:07:07][root][INFO] - Training Epoch: 2/2, step 22729/23838 completed (loss: 0.23909637331962585, acc: 0.9019607901573181)
[2025-02-04 03:07:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22731/23838 [30:18<06:27,  2.86it/s][2025-02-04 03:07:07][root][INFO] - Training Epoch: 2/2, step 22730/23838 completed (loss: 0.5562335848808289, acc: 0.8676470518112183)
[2025-02-04 03:07:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22732/23838 [30:18<06:29,  2.84it/s][2025-02-04 03:07:08][root][INFO] - Training Epoch: 2/2, step 22731/23838 completed (loss: 0.6202964186668396, acc: 0.8409090638160706)
[2025-02-04 03:07:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22733/23838 [30:18<06:44,  2.73it/s][2025-02-04 03:07:08][root][INFO] - Training Epoch: 2/2, step 22732/23838 completed (loss: 0.28252190351486206, acc: 0.9428571462631226)
[2025-02-04 03:07:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22734/23838 [30:19<06:55,  2.66it/s][2025-02-04 03:07:08][root][INFO] - Training Epoch: 2/2, step 22733/23838 completed (loss: 0.15912215411663055, acc: 0.931034505367279)
[2025-02-04 03:07:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22735/23838 [30:19<07:05,  2.59it/s][2025-02-04 03:07:09][root][INFO] - Training Epoch: 2/2, step 22734/23838 completed (loss: 0.591997504234314, acc: 0.8307692408561707)
[2025-02-04 03:07:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22736/23838 [30:20<08:04,  2.27it/s][2025-02-04 03:07:09][root][INFO] - Training Epoch: 2/2, step 22735/23838 completed (loss: 0.39803779125213623, acc: 0.9137930870056152)
[2025-02-04 03:07:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22737/23838 [30:20<07:41,  2.38it/s][2025-02-04 03:07:10][root][INFO] - Training Epoch: 2/2, step 22736/23838 completed (loss: 0.338235080242157, acc: 0.949999988079071)
[2025-02-04 03:07:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22738/23838 [30:20<07:26,  2.46it/s][2025-02-04 03:07:10][root][INFO] - Training Epoch: 2/2, step 22737/23838 completed (loss: 0.28391095995903015, acc: 0.9487179517745972)
[2025-02-04 03:07:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22739/23838 [30:21<07:11,  2.55it/s][2025-02-04 03:07:10][root][INFO] - Training Epoch: 2/2, step 22738/23838 completed (loss: 0.1932229995727539, acc: 0.9444444179534912)
[2025-02-04 03:07:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22740/23838 [30:21<06:57,  2.63it/s][2025-02-04 03:07:11][root][INFO] - Training Epoch: 2/2, step 22739/23838 completed (loss: 0.6189720034599304, acc: 0.8611111044883728)
[2025-02-04 03:07:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22741/23838 [30:22<07:32,  2.43it/s][2025-02-04 03:07:11][root][INFO] - Training Epoch: 2/2, step 22740/23838 completed (loss: 0.6405555009841919, acc: 0.8360655903816223)
[2025-02-04 03:07:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22742/23838 [30:22<07:33,  2.42it/s][2025-02-04 03:07:12][root][INFO] - Training Epoch: 2/2, step 22741/23838 completed (loss: 0.3750973343849182, acc: 0.875)
[2025-02-04 03:07:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22743/23838 [30:22<07:10,  2.55it/s][2025-02-04 03:07:12][root][INFO] - Training Epoch: 2/2, step 22742/23838 completed (loss: 0.07868146896362305, acc: 1.0)
[2025-02-04 03:07:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22744/23838 [30:23<07:16,  2.51it/s][2025-02-04 03:07:12][root][INFO] - Training Epoch: 2/2, step 22743/23838 completed (loss: 0.7225967049598694, acc: 0.8070175647735596)
[2025-02-04 03:07:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22745/23838 [30:23<07:16,  2.50it/s][2025-02-04 03:07:13][root][INFO] - Training Epoch: 2/2, step 22744/23838 completed (loss: 0.9533448219299316, acc: 0.7222222089767456)
[2025-02-04 03:07:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22746/23838 [30:24<07:00,  2.60it/s][2025-02-04 03:07:13][root][INFO] - Training Epoch: 2/2, step 22745/23838 completed (loss: 0.4649704396724701, acc: 0.8703703880310059)
[2025-02-04 03:07:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22747/23838 [30:24<06:35,  2.76it/s][2025-02-04 03:07:13][root][INFO] - Training Epoch: 2/2, step 22746/23838 completed (loss: 0.08856132626533508, acc: 0.9772727489471436)
[2025-02-04 03:07:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22748/23838 [30:24<06:20,  2.86it/s][2025-02-04 03:07:14][root][INFO] - Training Epoch: 2/2, step 22747/23838 completed (loss: 0.4555036425590515, acc: 0.8620689511299133)
[2025-02-04 03:07:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22749/23838 [30:25<06:44,  2.70it/s][2025-02-04 03:07:14][root][INFO] - Training Epoch: 2/2, step 22748/23838 completed (loss: 0.5872489809989929, acc: 0.8416666388511658)
[2025-02-04 03:07:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22750/23838 [30:25<06:46,  2.68it/s][2025-02-04 03:07:15][root][INFO] - Training Epoch: 2/2, step 22749/23838 completed (loss: 0.931735634803772, acc: 0.7096773982048035)
[2025-02-04 03:07:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22751/23838 [30:25<06:37,  2.74it/s][2025-02-04 03:07:15][root][INFO] - Training Epoch: 2/2, step 22750/23838 completed (loss: 0.44160282611846924, acc: 0.8604651093482971)
[2025-02-04 03:07:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22752/23838 [30:26<07:05,  2.55it/s][2025-02-04 03:07:15][root][INFO] - Training Epoch: 2/2, step 22751/23838 completed (loss: 0.5068451762199402, acc: 0.8450704216957092)
[2025-02-04 03:07:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22753/23838 [30:26<06:44,  2.68it/s][2025-02-04 03:07:16][root][INFO] - Training Epoch: 2/2, step 22752/23838 completed (loss: 0.5261243581771851, acc: 0.8999999761581421)
[2025-02-04 03:07:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22754/23838 [30:27<06:41,  2.70it/s][2025-02-04 03:07:16][root][INFO] - Training Epoch: 2/2, step 22753/23838 completed (loss: 0.5566806197166443, acc: 0.8421052694320679)
[2025-02-04 03:07:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22755/23838 [30:27<06:43,  2.68it/s][2025-02-04 03:07:16][root][INFO] - Training Epoch: 2/2, step 22754/23838 completed (loss: 0.5976049304008484, acc: 0.8363636136054993)
[2025-02-04 03:07:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22756/23838 [30:27<06:59,  2.58it/s][2025-02-04 03:07:17][root][INFO] - Training Epoch: 2/2, step 22755/23838 completed (loss: 0.48402640223503113, acc: 0.8627451062202454)
[2025-02-04 03:07:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22757/23838 [30:28<07:54,  2.28it/s][2025-02-04 03:07:17][root][INFO] - Training Epoch: 2/2, step 22756/23838 completed (loss: 0.5595445036888123, acc: 0.8253968358039856)
[2025-02-04 03:07:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22758/23838 [30:28<07:15,  2.48it/s][2025-02-04 03:07:18][root][INFO] - Training Epoch: 2/2, step 22757/23838 completed (loss: 0.35998550057411194, acc: 0.9047619104385376)
[2025-02-04 03:07:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22759/23838 [30:29<07:18,  2.46it/s][2025-02-04 03:07:18][root][INFO] - Training Epoch: 2/2, step 22758/23838 completed (loss: 0.4848221242427826, acc: 0.8936170339584351)
[2025-02-04 03:07:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22760/23838 [30:29<07:15,  2.48it/s][2025-02-04 03:07:19][root][INFO] - Training Epoch: 2/2, step 22759/23838 completed (loss: 0.23343586921691895, acc: 0.936170220375061)
[2025-02-04 03:07:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22761/23838 [30:29<07:14,  2.48it/s][2025-02-04 03:07:19][root][INFO] - Training Epoch: 2/2, step 22760/23838 completed (loss: 0.40847253799438477, acc: 0.8888888955116272)
[2025-02-04 03:07:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22762/23838 [30:30<07:04,  2.54it/s][2025-02-04 03:07:19][root][INFO] - Training Epoch: 2/2, step 22761/23838 completed (loss: 0.6213890314102173, acc: 0.8191489577293396)
[2025-02-04 03:07:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22763/23838 [30:30<06:58,  2.57it/s][2025-02-04 03:07:20][root][INFO] - Training Epoch: 2/2, step 22762/23838 completed (loss: 0.23610416054725647, acc: 0.9473684430122375)
[2025-02-04 03:07:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22764/23838 [30:31<06:53,  2.60it/s][2025-02-04 03:07:20][root][INFO] - Training Epoch: 2/2, step 22763/23838 completed (loss: 0.8706271052360535, acc: 0.7555555701255798)
[2025-02-04 03:07:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  95%|[34m█████████▌[0m| 22765/23838 [30:31<07:09,  2.50it/s][2025-02-04 03:07:21][root][INFO] - Training Epoch: 2/2, step 22764/23838 completed (loss: 0.8397197723388672, acc: 0.7839506268501282)
[2025-02-04 03:07:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22766/23838 [30:31<07:11,  2.48it/s][2025-02-04 03:07:21][root][INFO] - Training Epoch: 2/2, step 22765/23838 completed (loss: 0.606216311454773, acc: 0.8320000171661377)
[2025-02-04 03:07:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22767/23838 [30:32<07:16,  2.45it/s][2025-02-04 03:07:21][root][INFO] - Training Epoch: 2/2, step 22766/23838 completed (loss: 0.22325627505779266, acc: 0.9242424368858337)
[2025-02-04 03:07:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22768/23838 [30:32<07:10,  2.48it/s][2025-02-04 03:07:22][root][INFO] - Training Epoch: 2/2, step 22767/23838 completed (loss: 0.8034183382987976, acc: 0.7209302186965942)
[2025-02-04 03:07:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22769/23838 [30:33<06:53,  2.59it/s][2025-02-04 03:07:22][root][INFO] - Training Epoch: 2/2, step 22768/23838 completed (loss: 0.4833396375179291, acc: 0.8205128312110901)
[2025-02-04 03:07:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22770/23838 [30:33<06:32,  2.72it/s][2025-02-04 03:07:22][root][INFO] - Training Epoch: 2/2, step 22769/23838 completed (loss: 0.5646191239356995, acc: 0.8392857313156128)
[2025-02-04 03:07:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22771/23838 [30:33<06:46,  2.63it/s][2025-02-04 03:07:23][root][INFO] - Training Epoch: 2/2, step 22770/23838 completed (loss: 0.8310133814811707, acc: 0.7560975551605225)
[2025-02-04 03:07:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22772/23838 [30:34<06:47,  2.61it/s][2025-02-04 03:07:23][root][INFO] - Training Epoch: 2/2, step 22771/23838 completed (loss: 0.5654181241989136, acc: 0.8571428656578064)
[2025-02-04 03:07:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22773/23838 [30:34<06:47,  2.61it/s][2025-02-04 03:07:24][root][INFO] - Training Epoch: 2/2, step 22772/23838 completed (loss: 0.36325278878211975, acc: 0.9047619104385376)
[2025-02-04 03:07:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22774/23838 [30:34<06:53,  2.57it/s][2025-02-04 03:07:24][root][INFO] - Training Epoch: 2/2, step 22773/23838 completed (loss: 0.997857928276062, acc: 0.7124999761581421)
[2025-02-04 03:07:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22775/23838 [30:35<06:48,  2.60it/s][2025-02-04 03:07:24][root][INFO] - Training Epoch: 2/2, step 22774/23838 completed (loss: 0.3896288573741913, acc: 0.9075630307197571)
[2025-02-04 03:07:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22776/23838 [30:35<06:52,  2.58it/s][2025-02-04 03:07:25][root][INFO] - Training Epoch: 2/2, step 22775/23838 completed (loss: 0.935330331325531, acc: 0.7790697813034058)
[2025-02-04 03:07:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22777/23838 [30:36<06:51,  2.58it/s][2025-02-04 03:07:25][root][INFO] - Training Epoch: 2/2, step 22776/23838 completed (loss: 0.3990277349948883, acc: 0.8815789222717285)
[2025-02-04 03:07:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22778/23838 [30:36<06:38,  2.66it/s][2025-02-04 03:07:26][root][INFO] - Training Epoch: 2/2, step 22777/23838 completed (loss: 0.43344545364379883, acc: 0.8842105269432068)
[2025-02-04 03:07:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22779/23838 [30:36<06:20,  2.78it/s][2025-02-04 03:07:26][root][INFO] - Training Epoch: 2/2, step 22778/23838 completed (loss: 0.7129815220832825, acc: 0.8536585569381714)
[2025-02-04 03:07:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22780/23838 [30:37<06:39,  2.65it/s][2025-02-04 03:07:26][root][INFO] - Training Epoch: 2/2, step 22779/23838 completed (loss: 0.7678722143173218, acc: 0.7213114500045776)
[2025-02-04 03:07:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22781/23838 [30:37<06:14,  2.82it/s][2025-02-04 03:07:27][root][INFO] - Training Epoch: 2/2, step 22780/23838 completed (loss: 0.4141729772090912, acc: 0.8918918967247009)
[2025-02-04 03:07:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22782/23838 [30:37<06:09,  2.86it/s][2025-02-04 03:07:27][root][INFO] - Training Epoch: 2/2, step 22781/23838 completed (loss: 0.4035727083683014, acc: 0.9137930870056152)
[2025-02-04 03:07:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22783/23838 [30:38<06:35,  2.67it/s][2025-02-04 03:07:27][root][INFO] - Training Epoch: 2/2, step 22782/23838 completed (loss: 0.6795619130134583, acc: 0.7850467562675476)
[2025-02-04 03:07:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22784/23838 [30:38<06:14,  2.82it/s][2025-02-04 03:07:28][root][INFO] - Training Epoch: 2/2, step 22783/23838 completed (loss: 0.2592470645904541, acc: 0.9230769276618958)
[2025-02-04 03:07:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22785/23838 [30:38<06:09,  2.85it/s][2025-02-04 03:07:28][root][INFO] - Training Epoch: 2/2, step 22784/23838 completed (loss: 0.5065041184425354, acc: 0.8244680762290955)
[2025-02-04 03:07:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22786/23838 [30:39<06:40,  2.63it/s][2025-02-04 03:07:28][root][INFO] - Training Epoch: 2/2, step 22785/23838 completed (loss: 0.39997097849845886, acc: 0.8620689511299133)
[2025-02-04 03:07:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22787/23838 [30:39<06:39,  2.63it/s][2025-02-04 03:07:29][root][INFO] - Training Epoch: 2/2, step 22786/23838 completed (loss: 0.34233492612838745, acc: 0.8834951519966125)
[2025-02-04 03:07:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22788/23838 [30:40<06:27,  2.71it/s][2025-02-04 03:07:29][root][INFO] - Training Epoch: 2/2, step 22787/23838 completed (loss: 0.27302709221839905, acc: 0.907216489315033)
[2025-02-04 03:07:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22789/23838 [30:40<06:16,  2.79it/s][2025-02-04 03:07:30][root][INFO] - Training Epoch: 2/2, step 22788/23838 completed (loss: 1.1633862257003784, acc: 0.6732673048973083)
[2025-02-04 03:07:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22790/23838 [30:40<06:19,  2.76it/s][2025-02-04 03:07:30][root][INFO] - Training Epoch: 2/2, step 22789/23838 completed (loss: 0.8511077761650085, acc: 0.7301587462425232)
[2025-02-04 03:07:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22791/23838 [30:41<06:13,  2.80it/s][2025-02-04 03:07:30][root][INFO] - Training Epoch: 2/2, step 22790/23838 completed (loss: 0.6442953944206238, acc: 0.8037382960319519)
[2025-02-04 03:07:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22792/23838 [30:41<06:06,  2.85it/s][2025-02-04 03:07:31][root][INFO] - Training Epoch: 2/2, step 22791/23838 completed (loss: 0.7480522990226746, acc: 0.8488371968269348)
[2025-02-04 03:07:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22793/23838 [30:41<06:06,  2.85it/s][2025-02-04 03:07:31][root][INFO] - Training Epoch: 2/2, step 22792/23838 completed (loss: 0.5584283471107483, acc: 0.8787878751754761)
[2025-02-04 03:07:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22794/23838 [30:42<05:56,  2.93it/s][2025-02-04 03:07:31][root][INFO] - Training Epoch: 2/2, step 22793/23838 completed (loss: 0.45087921619415283, acc: 0.8823529481887817)
[2025-02-04 03:07:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22795/23838 [30:42<06:11,  2.81it/s][2025-02-04 03:07:32][root][INFO] - Training Epoch: 2/2, step 22794/23838 completed (loss: 0.6497684121131897, acc: 0.8271604776382446)
[2025-02-04 03:07:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22796/23838 [30:42<06:22,  2.72it/s][2025-02-04 03:07:32][root][INFO] - Training Epoch: 2/2, step 22795/23838 completed (loss: 0.6016023755073547, acc: 0.8620689511299133)
[2025-02-04 03:07:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22797/23838 [30:43<06:17,  2.76it/s][2025-02-04 03:07:32][root][INFO] - Training Epoch: 2/2, step 22796/23838 completed (loss: 0.5089865922927856, acc: 0.8500000238418579)
[2025-02-04 03:07:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22798/23838 [30:43<06:23,  2.71it/s][2025-02-04 03:07:33][root][INFO] - Training Epoch: 2/2, step 22797/23838 completed (loss: 0.35059869289398193, acc: 0.9152542352676392)
[2025-02-04 03:07:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22799/23838 [30:44<06:13,  2.78it/s][2025-02-04 03:07:33][root][INFO] - Training Epoch: 2/2, step 22798/23838 completed (loss: 0.3401617705821991, acc: 0.8975903391838074)
[2025-02-04 03:07:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22800/23838 [30:44<06:13,  2.78it/s][2025-02-04 03:07:33][root][INFO] - Training Epoch: 2/2, step 22799/23838 completed (loss: 0.30984044075012207, acc: 0.9387755393981934)
[2025-02-04 03:07:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22801/23838 [30:44<06:04,  2.85it/s][2025-02-04 03:07:34][root][INFO] - Training Epoch: 2/2, step 22800/23838 completed (loss: 0.4530518651008606, acc: 0.8557692170143127)
[2025-02-04 03:07:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22802/23838 [30:45<06:02,  2.86it/s][2025-02-04 03:07:34][root][INFO] - Training Epoch: 2/2, step 22801/23838 completed (loss: 0.7304706573486328, acc: 0.8448275923728943)
[2025-02-04 03:07:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22803/23838 [30:45<05:59,  2.88it/s][2025-02-04 03:07:34][root][INFO] - Training Epoch: 2/2, step 22802/23838 completed (loss: 0.5575947761535645, acc: 0.8404255509376526)
[2025-02-04 03:07:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22804/23838 [30:45<06:09,  2.80it/s][2025-02-04 03:07:35][root][INFO] - Training Epoch: 2/2, step 22803/23838 completed (loss: 0.36278748512268066, acc: 0.9135802388191223)
[2025-02-04 03:07:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22805/23838 [30:46<06:04,  2.83it/s][2025-02-04 03:07:35][root][INFO] - Training Epoch: 2/2, step 22804/23838 completed (loss: 0.5041136741638184, acc: 0.8535031676292419)
[2025-02-04 03:07:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22806/23838 [30:46<05:52,  2.93it/s][2025-02-04 03:07:36][root][INFO] - Training Epoch: 2/2, step 22805/23838 completed (loss: 0.40826529264450073, acc: 0.8888888955116272)
[2025-02-04 03:07:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22807/23838 [30:46<05:50,  2.94it/s][2025-02-04 03:07:36][root][INFO] - Training Epoch: 2/2, step 22806/23838 completed (loss: 0.32286471128463745, acc: 0.9099099040031433)
[2025-02-04 03:07:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22808/23838 [30:47<06:09,  2.79it/s][2025-02-04 03:07:36][root][INFO] - Training Epoch: 2/2, step 22807/23838 completed (loss: 0.47240111231803894, acc: 0.8557692170143127)
[2025-02-04 03:07:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22809/23838 [30:47<06:36,  2.60it/s][2025-02-04 03:07:37][root][INFO] - Training Epoch: 2/2, step 22808/23838 completed (loss: 0.5465465188026428, acc: 0.8522727489471436)
[2025-02-04 03:07:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22810/23838 [30:47<06:25,  2.67it/s][2025-02-04 03:07:37][root][INFO] - Training Epoch: 2/2, step 22809/23838 completed (loss: 0.4816262722015381, acc: 0.8654970526695251)
[2025-02-04 03:07:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22811/23838 [30:48<06:17,  2.72it/s][2025-02-04 03:07:37][root][INFO] - Training Epoch: 2/2, step 22810/23838 completed (loss: 0.7427465915679932, acc: 0.7865168452262878)
[2025-02-04 03:07:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22812/23838 [30:48<06:44,  2.54it/s][2025-02-04 03:07:38][root][INFO] - Training Epoch: 2/2, step 22811/23838 completed (loss: 0.3841663897037506, acc: 0.8641975522041321)
[2025-02-04 03:07:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22813/23838 [30:49<06:38,  2.57it/s][2025-02-04 03:07:38][root][INFO] - Training Epoch: 2/2, step 22812/23838 completed (loss: 0.6456338167190552, acc: 0.8571428656578064)
[2025-02-04 03:07:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22814/23838 [30:49<06:24,  2.66it/s][2025-02-04 03:07:39][root][INFO] - Training Epoch: 2/2, step 22813/23838 completed (loss: 0.41601645946502686, acc: 0.8999999761581421)
[2025-02-04 03:07:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22815/23838 [30:49<06:11,  2.75it/s][2025-02-04 03:07:39][root][INFO] - Training Epoch: 2/2, step 22814/23838 completed (loss: 0.4809815585613251, acc: 0.8627451062202454)
[2025-02-04 03:07:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22816/23838 [30:50<05:58,  2.85it/s][2025-02-04 03:07:39][root][INFO] - Training Epoch: 2/2, step 22815/23838 completed (loss: 0.544775664806366, acc: 0.8301886916160583)
[2025-02-04 03:07:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22817/23838 [30:50<06:19,  2.69it/s][2025-02-04 03:07:40][root][INFO] - Training Epoch: 2/2, step 22816/23838 completed (loss: 0.9522139430046082, acc: 0.7014925479888916)
[2025-02-04 03:07:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22818/23838 [30:50<06:18,  2.70it/s][2025-02-04 03:07:40][root][INFO] - Training Epoch: 2/2, step 22817/23838 completed (loss: 0.43275755643844604, acc: 0.8382353186607361)
[2025-02-04 03:07:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22819/23838 [30:51<05:58,  2.85it/s][2025-02-04 03:07:40][root][INFO] - Training Epoch: 2/2, step 22818/23838 completed (loss: 0.3520139455795288, acc: 0.9242424368858337)
[2025-02-04 03:07:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22820/23838 [30:51<06:04,  2.79it/s][2025-02-04 03:07:41][root][INFO] - Training Epoch: 2/2, step 22819/23838 completed (loss: 0.5641022324562073, acc: 0.8731343150138855)
[2025-02-04 03:07:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22821/23838 [30:51<06:07,  2.77it/s][2025-02-04 03:07:41][root][INFO] - Training Epoch: 2/2, step 22820/23838 completed (loss: 0.7338273525238037, acc: 0.8235294222831726)
[2025-02-04 03:07:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22822/23838 [30:52<06:06,  2.77it/s][2025-02-04 03:07:41][root][INFO] - Training Epoch: 2/2, step 22821/23838 completed (loss: 0.9297309517860413, acc: 0.7066666483879089)
[2025-02-04 03:07:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22823/23838 [30:52<06:00,  2.82it/s][2025-02-04 03:07:42][root][INFO] - Training Epoch: 2/2, step 22822/23838 completed (loss: 0.796206533908844, acc: 0.7627118825912476)
[2025-02-04 03:07:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22824/23838 [30:53<06:07,  2.76it/s][2025-02-04 03:07:42][root][INFO] - Training Epoch: 2/2, step 22823/23838 completed (loss: 0.7724000215530396, acc: 0.7804877758026123)
[2025-02-04 03:07:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22825/23838 [30:53<06:06,  2.76it/s][2025-02-04 03:07:43][root][INFO] - Training Epoch: 2/2, step 22824/23838 completed (loss: 0.43460166454315186, acc: 0.8550724387168884)
[2025-02-04 03:07:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22826/23838 [30:53<06:27,  2.61it/s][2025-02-04 03:07:43][root][INFO] - Training Epoch: 2/2, step 22825/23838 completed (loss: 0.4439367949962616, acc: 0.8545454740524292)
[2025-02-04 03:07:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22827/23838 [30:54<06:31,  2.59it/s][2025-02-04 03:07:43][root][INFO] - Training Epoch: 2/2, step 22826/23838 completed (loss: 0.5601279139518738, acc: 0.8358209133148193)
[2025-02-04 03:07:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22828/23838 [30:54<06:19,  2.66it/s][2025-02-04 03:07:44][root][INFO] - Training Epoch: 2/2, step 22827/23838 completed (loss: 0.18224214017391205, acc: 0.9363057613372803)
[2025-02-04 03:07:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22829/23838 [30:54<06:07,  2.75it/s][2025-02-04 03:07:44][root][INFO] - Training Epoch: 2/2, step 22828/23838 completed (loss: 0.4502343237400055, acc: 0.8805969953536987)
[2025-02-04 03:07:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22830/23838 [30:55<06:10,  2.72it/s][2025-02-04 03:07:44][root][INFO] - Training Epoch: 2/2, step 22829/23838 completed (loss: 0.5209893584251404, acc: 0.8659793734550476)
[2025-02-04 03:07:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22831/23838 [30:55<06:02,  2.78it/s][2025-02-04 03:07:45][root][INFO] - Training Epoch: 2/2, step 22830/23838 completed (loss: 0.2864864766597748, acc: 0.9230769276618958)
[2025-02-04 03:07:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22832/23838 [30:56<06:01,  2.78it/s][2025-02-04 03:07:45][root][INFO] - Training Epoch: 2/2, step 22831/23838 completed (loss: 0.34945178031921387, acc: 0.939393937587738)
[2025-02-04 03:07:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22833/23838 [30:56<06:23,  2.62it/s][2025-02-04 03:07:46][root][INFO] - Training Epoch: 2/2, step 22832/23838 completed (loss: 0.22647570073604584, acc: 0.9245283007621765)
[2025-02-04 03:07:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22834/23838 [30:56<06:40,  2.51it/s][2025-02-04 03:07:46][root][INFO] - Training Epoch: 2/2, step 22833/23838 completed (loss: 0.3981696367263794, acc: 0.9012345671653748)
[2025-02-04 03:07:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22835/23838 [30:57<06:25,  2.60it/s][2025-02-04 03:07:46][root][INFO] - Training Epoch: 2/2, step 22834/23838 completed (loss: 0.5625836253166199, acc: 0.8604651093482971)
[2025-02-04 03:07:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22836/23838 [30:57<05:54,  2.82it/s][2025-02-04 03:07:47][root][INFO] - Training Epoch: 2/2, step 22835/23838 completed (loss: 0.5104286074638367, acc: 0.8529411554336548)
[2025-02-04 03:07:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22837/23838 [30:57<05:32,  3.01it/s][2025-02-04 03:07:47][root][INFO] - Training Epoch: 2/2, step 22836/23838 completed (loss: 0.22743096947669983, acc: 0.9343065619468689)
[2025-02-04 03:07:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22838/23838 [30:58<05:36,  2.97it/s][2025-02-04 03:07:47][root][INFO] - Training Epoch: 2/2, step 22837/23838 completed (loss: 0.24101407825946808, acc: 0.9370078444480896)
[2025-02-04 03:07:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22839/23838 [30:58<06:15,  2.66it/s][2025-02-04 03:07:48][root][INFO] - Training Epoch: 2/2, step 22838/23838 completed (loss: 0.32766714692115784, acc: 0.895652174949646)
[2025-02-04 03:07:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22840/23838 [30:58<06:11,  2.69it/s][2025-02-04 03:07:48][root][INFO] - Training Epoch: 2/2, step 22839/23838 completed (loss: 0.1542549431324005, acc: 0.9637681245803833)
[2025-02-04 03:07:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22841/23838 [30:59<06:16,  2.65it/s][2025-02-04 03:07:48][root][INFO] - Training Epoch: 2/2, step 22840/23838 completed (loss: 0.47793835401535034, acc: 0.8558558821678162)
[2025-02-04 03:07:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22842/23838 [30:59<06:10,  2.69it/s][2025-02-04 03:07:49][root][INFO] - Training Epoch: 2/2, step 22841/23838 completed (loss: 0.27296948432922363, acc: 0.9230769276618958)
[2025-02-04 03:07:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22843/23838 [31:00<06:01,  2.75it/s][2025-02-04 03:07:49][root][INFO] - Training Epoch: 2/2, step 22842/23838 completed (loss: 0.1496913582086563, acc: 0.931034505367279)
[2025-02-04 03:07:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22844/23838 [31:00<05:52,  2.82it/s][2025-02-04 03:07:49][root][INFO] - Training Epoch: 2/2, step 22843/23838 completed (loss: 0.31529828906059265, acc: 0.8965517282485962)
[2025-02-04 03:07:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22845/23838 [31:00<05:41,  2.91it/s][2025-02-04 03:07:50][root][INFO] - Training Epoch: 2/2, step 22844/23838 completed (loss: 0.31155434250831604, acc: 0.9152542352676392)
[2025-02-04 03:07:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22846/23838 [31:01<05:39,  2.92it/s][2025-02-04 03:07:50][root][INFO] - Training Epoch: 2/2, step 22845/23838 completed (loss: 0.3255120515823364, acc: 0.9027777910232544)
[2025-02-04 03:07:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22847/23838 [31:01<05:43,  2.88it/s][2025-02-04 03:07:51][root][INFO] - Training Epoch: 2/2, step 22846/23838 completed (loss: 0.26454126834869385, acc: 0.907975435256958)
[2025-02-04 03:07:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22848/23838 [31:01<05:39,  2.91it/s][2025-02-04 03:07:51][root][INFO] - Training Epoch: 2/2, step 22847/23838 completed (loss: 0.10357378423213959, acc: 0.9830508232116699)
[2025-02-04 03:07:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22849/23838 [31:02<05:35,  2.95it/s][2025-02-04 03:07:51][root][INFO] - Training Epoch: 2/2, step 22848/23838 completed (loss: 0.3515486717224121, acc: 0.9076923131942749)
[2025-02-04 03:07:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22850/23838 [31:02<05:45,  2.86it/s][2025-02-04 03:07:52][root][INFO] - Training Epoch: 2/2, step 22849/23838 completed (loss: 0.4511971175670624, acc: 0.8695651888847351)
[2025-02-04 03:07:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22851/23838 [31:02<05:50,  2.81it/s][2025-02-04 03:07:52][root][INFO] - Training Epoch: 2/2, step 22850/23838 completed (loss: 0.40583881735801697, acc: 0.8787878751754761)
[2025-02-04 03:07:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22852/23838 [31:03<05:44,  2.86it/s][2025-02-04 03:07:52][root][INFO] - Training Epoch: 2/2, step 22851/23838 completed (loss: 0.3730736970901489, acc: 0.9145299196243286)
[2025-02-04 03:07:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22853/23838 [31:03<05:57,  2.75it/s][2025-02-04 03:07:53][root][INFO] - Training Epoch: 2/2, step 22852/23838 completed (loss: 0.49724411964416504, acc: 0.8925619721412659)
[2025-02-04 03:07:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22854/23838 [31:03<06:07,  2.68it/s][2025-02-04 03:07:53][root][INFO] - Training Epoch: 2/2, step 22853/23838 completed (loss: 0.20847968757152557, acc: 0.9279279112815857)
[2025-02-04 03:07:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22855/23838 [31:04<06:31,  2.51it/s][2025-02-04 03:07:54][root][INFO] - Training Epoch: 2/2, step 22854/23838 completed (loss: 0.4986732602119446, acc: 0.8606557250022888)
[2025-02-04 03:07:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22856/23838 [31:04<06:25,  2.55it/s][2025-02-04 03:07:54][root][INFO] - Training Epoch: 2/2, step 22855/23838 completed (loss: 0.39824968576431274, acc: 0.8979591727256775)
[2025-02-04 03:07:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22857/23838 [31:05<06:21,  2.57it/s][2025-02-04 03:07:54][root][INFO] - Training Epoch: 2/2, step 22856/23838 completed (loss: 0.4277055859565735, acc: 0.9230769276618958)
[2025-02-04 03:07:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22858/23838 [31:05<06:14,  2.62it/s][2025-02-04 03:07:55][root][INFO] - Training Epoch: 2/2, step 22857/23838 completed (loss: 0.28035831451416016, acc: 0.9117646813392639)
[2025-02-04 03:07:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22859/23838 [31:05<05:55,  2.75it/s][2025-02-04 03:07:55][root][INFO] - Training Epoch: 2/2, step 22858/23838 completed (loss: 0.8320816159248352, acc: 0.8148148059844971)
[2025-02-04 03:07:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22860/23838 [31:06<05:48,  2.81it/s][2025-02-04 03:07:55][root][INFO] - Training Epoch: 2/2, step 22859/23838 completed (loss: 0.2980848252773285, acc: 0.8625954389572144)
[2025-02-04 03:07:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22861/23838 [31:06<05:50,  2.79it/s][2025-02-04 03:07:56][root][INFO] - Training Epoch: 2/2, step 22860/23838 completed (loss: 0.12391772866249084, acc: 0.9795918464660645)
[2025-02-04 03:07:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22862/23838 [31:06<05:44,  2.83it/s][2025-02-04 03:07:56][root][INFO] - Training Epoch: 2/2, step 22861/23838 completed (loss: 0.4164506196975708, acc: 0.8859649300575256)
[2025-02-04 03:07:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22863/23838 [31:07<05:40,  2.86it/s][2025-02-04 03:07:56][root][INFO] - Training Epoch: 2/2, step 22862/23838 completed (loss: 0.300455778837204, acc: 0.8981481194496155)
[2025-02-04 03:07:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22864/23838 [31:07<05:58,  2.71it/s][2025-02-04 03:07:57][root][INFO] - Training Epoch: 2/2, step 22863/23838 completed (loss: 0.4376182556152344, acc: 0.9142857193946838)
[2025-02-04 03:07:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22865/23838 [31:07<05:42,  2.84it/s][2025-02-04 03:07:57][root][INFO] - Training Epoch: 2/2, step 22864/23838 completed (loss: 0.16408859193325043, acc: 0.9576271176338196)
[2025-02-04 03:07:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22866/23838 [31:08<05:38,  2.87it/s][2025-02-04 03:07:57][root][INFO] - Training Epoch: 2/2, step 22865/23838 completed (loss: 0.2870609164237976, acc: 0.8913043737411499)
[2025-02-04 03:07:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22867/23838 [31:08<05:44,  2.82it/s][2025-02-04 03:07:58][root][INFO] - Training Epoch: 2/2, step 22866/23838 completed (loss: 0.20886069536209106, acc: 0.9545454382896423)
[2025-02-04 03:07:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22868/23838 [31:09<05:44,  2.81it/s][2025-02-04 03:07:58][root][INFO] - Training Epoch: 2/2, step 22867/23838 completed (loss: 0.16899456083774567, acc: 0.9545454382896423)
[2025-02-04 03:07:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22869/23838 [31:09<05:47,  2.79it/s][2025-02-04 03:07:58][root][INFO] - Training Epoch: 2/2, step 22868/23838 completed (loss: 0.2576455771923065, acc: 0.9494949579238892)
[2025-02-04 03:07:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22870/23838 [31:09<05:44,  2.81it/s][2025-02-04 03:07:59][root][INFO] - Training Epoch: 2/2, step 22869/23838 completed (loss: 0.13837039470672607, acc: 0.9642857313156128)
[2025-02-04 03:07:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22871/23838 [31:10<05:57,  2.70it/s][2025-02-04 03:07:59][root][INFO] - Training Epoch: 2/2, step 22870/23838 completed (loss: 0.3677537143230438, acc: 0.9147727489471436)
[2025-02-04 03:07:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22872/23838 [31:10<05:54,  2.72it/s][2025-02-04 03:08:00][root][INFO] - Training Epoch: 2/2, step 22871/23838 completed (loss: 0.08014180511236191, acc: 0.953125)
[2025-02-04 03:08:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22873/23838 [31:10<05:52,  2.74it/s][2025-02-04 03:08:00][root][INFO] - Training Epoch: 2/2, step 22872/23838 completed (loss: 0.46392613649368286, acc: 0.8382353186607361)
[2025-02-04 03:08:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22874/23838 [31:11<05:58,  2.69it/s][2025-02-04 03:08:00][root][INFO] - Training Epoch: 2/2, step 22873/23838 completed (loss: 0.365793913602829, acc: 0.8681318759918213)
[2025-02-04 03:08:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22875/23838 [31:11<05:43,  2.81it/s][2025-02-04 03:08:01][root][INFO] - Training Epoch: 2/2, step 22874/23838 completed (loss: 0.4249908924102783, acc: 0.875)
[2025-02-04 03:08:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22876/23838 [31:11<05:39,  2.84it/s][2025-02-04 03:08:01][root][INFO] - Training Epoch: 2/2, step 22875/23838 completed (loss: 0.44768887758255005, acc: 0.9259259104728699)
[2025-02-04 03:08:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22877/23838 [31:12<05:30,  2.90it/s][2025-02-04 03:08:01][root][INFO] - Training Epoch: 2/2, step 22876/23838 completed (loss: 0.4578842520713806, acc: 0.8928571343421936)
[2025-02-04 03:08:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22878/23838 [31:12<05:40,  2.82it/s][2025-02-04 03:08:02][root][INFO] - Training Epoch: 2/2, step 22877/23838 completed (loss: 0.8789852857589722, acc: 0.720588207244873)
[2025-02-04 03:08:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22879/23838 [31:13<05:43,  2.80it/s][2025-02-04 03:08:02][root][INFO] - Training Epoch: 2/2, step 22878/23838 completed (loss: 0.6314218640327454, acc: 0.800000011920929)
[2025-02-04 03:08:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22880/23838 [31:13<05:26,  2.94it/s][2025-02-04 03:08:02][root][INFO] - Training Epoch: 2/2, step 22879/23838 completed (loss: 0.327826589345932, acc: 0.859649121761322)
[2025-02-04 03:08:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22881/23838 [31:13<05:42,  2.79it/s][2025-02-04 03:08:03][root][INFO] - Training Epoch: 2/2, step 22880/23838 completed (loss: 0.20443817973136902, acc: 0.9253731369972229)
[2025-02-04 03:08:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22882/23838 [31:14<05:53,  2.70it/s][2025-02-04 03:08:03][root][INFO] - Training Epoch: 2/2, step 22881/23838 completed (loss: 0.27844321727752686, acc: 0.89552241563797)
[2025-02-04 03:08:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22883/23838 [31:14<05:31,  2.88it/s][2025-02-04 03:08:03][root][INFO] - Training Epoch: 2/2, step 22882/23838 completed (loss: 0.4921877980232239, acc: 0.8522727489471436)
[2025-02-04 03:08:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22884/23838 [31:14<05:35,  2.84it/s][2025-02-04 03:08:04][root][INFO] - Training Epoch: 2/2, step 22883/23838 completed (loss: 0.2508745789527893, acc: 0.9402984976768494)
[2025-02-04 03:08:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22885/23838 [31:15<05:43,  2.77it/s][2025-02-04 03:08:04][root][INFO] - Training Epoch: 2/2, step 22884/23838 completed (loss: 0.352752685546875, acc: 0.8782608509063721)
[2025-02-04 03:08:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22886/23838 [31:15<05:36,  2.83it/s][2025-02-04 03:08:05][root][INFO] - Training Epoch: 2/2, step 22885/23838 completed (loss: 0.34172433614730835, acc: 0.8947368264198303)
[2025-02-04 03:08:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22887/23838 [31:15<05:30,  2.87it/s][2025-02-04 03:08:05][root][INFO] - Training Epoch: 2/2, step 22886/23838 completed (loss: 0.46846455335617065, acc: 0.8771929740905762)
[2025-02-04 03:08:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22888/23838 [31:16<05:43,  2.76it/s][2025-02-04 03:08:05][root][INFO] - Training Epoch: 2/2, step 22887/23838 completed (loss: 0.7005752921104431, acc: 0.78125)
[2025-02-04 03:08:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22889/23838 [31:16<05:44,  2.76it/s][2025-02-04 03:08:06][root][INFO] - Training Epoch: 2/2, step 22888/23838 completed (loss: 0.7745746970176697, acc: 0.8444444537162781)
[2025-02-04 03:08:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22890/23838 [31:16<05:30,  2.87it/s][2025-02-04 03:08:06][root][INFO] - Training Epoch: 2/2, step 22889/23838 completed (loss: 0.4197236895561218, acc: 0.9069767594337463)
[2025-02-04 03:08:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22891/23838 [31:17<05:57,  2.65it/s][2025-02-04 03:08:06][root][INFO] - Training Epoch: 2/2, step 22890/23838 completed (loss: 0.39521753787994385, acc: 0.8813559412956238)
[2025-02-04 03:08:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22892/23838 [31:17<06:13,  2.53it/s][2025-02-04 03:08:07][root][INFO] - Training Epoch: 2/2, step 22891/23838 completed (loss: 0.513941764831543, acc: 0.9090909361839294)
[2025-02-04 03:08:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22893/23838 [31:18<06:47,  2.32it/s][2025-02-04 03:08:07][root][INFO] - Training Epoch: 2/2, step 22892/23838 completed (loss: 0.8234361410140991, acc: 0.8208954930305481)
[2025-02-04 03:08:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22894/23838 [31:18<06:35,  2.38it/s][2025-02-04 03:08:08][root][INFO] - Training Epoch: 2/2, step 22893/23838 completed (loss: 0.590225875377655, acc: 0.7733333110809326)
[2025-02-04 03:08:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22895/23838 [31:19<06:31,  2.41it/s][2025-02-04 03:08:08][root][INFO] - Training Epoch: 2/2, step 22894/23838 completed (loss: 0.27379676699638367, acc: 0.9193548560142517)
[2025-02-04 03:08:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22896/23838 [31:19<06:18,  2.49it/s][2025-02-04 03:08:09][root][INFO] - Training Epoch: 2/2, step 22895/23838 completed (loss: 0.20532825589179993, acc: 0.93388432264328)
[2025-02-04 03:08:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22897/23838 [31:19<06:01,  2.60it/s][2025-02-04 03:08:09][root][INFO] - Training Epoch: 2/2, step 22896/23838 completed (loss: 0.24779196083545685, acc: 0.9090909361839294)
[2025-02-04 03:08:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22898/23838 [31:20<05:53,  2.66it/s][2025-02-04 03:08:09][root][INFO] - Training Epoch: 2/2, step 22897/23838 completed (loss: 0.35701853036880493, acc: 0.9060402512550354)
[2025-02-04 03:08:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22899/23838 [31:20<06:01,  2.60it/s][2025-02-04 03:08:10][root][INFO] - Training Epoch: 2/2, step 22898/23838 completed (loss: 0.2825554311275482, acc: 0.9047619104385376)
[2025-02-04 03:08:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22900/23838 [31:20<05:54,  2.65it/s][2025-02-04 03:08:10][root][INFO] - Training Epoch: 2/2, step 22899/23838 completed (loss: 0.18139812350273132, acc: 0.939393937587738)
[2025-02-04 03:08:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22901/23838 [31:21<05:58,  2.61it/s][2025-02-04 03:08:10][root][INFO] - Training Epoch: 2/2, step 22900/23838 completed (loss: 0.5914191007614136, acc: 0.8352941274642944)
[2025-02-04 03:08:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22902/23838 [31:21<05:57,  2.62it/s][2025-02-04 03:08:11][root][INFO] - Training Epoch: 2/2, step 22901/23838 completed (loss: 0.08160847425460815, acc: 0.9677419066429138)
[2025-02-04 03:08:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22903/23838 [31:22<05:53,  2.65it/s][2025-02-04 03:08:11][root][INFO] - Training Epoch: 2/2, step 22902/23838 completed (loss: 0.2567189633846283, acc: 0.9264705777168274)
[2025-02-04 03:08:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22904/23838 [31:22<05:42,  2.73it/s][2025-02-04 03:08:11][root][INFO] - Training Epoch: 2/2, step 22903/23838 completed (loss: 0.40424785017967224, acc: 0.8878504633903503)
[2025-02-04 03:08:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22905/23838 [31:22<05:41,  2.73it/s][2025-02-04 03:08:12][root][INFO] - Training Epoch: 2/2, step 22904/23838 completed (loss: 0.7555238008499146, acc: 0.7848101258277893)
[2025-02-04 03:08:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22906/23838 [31:23<05:50,  2.66it/s][2025-02-04 03:08:12][root][INFO] - Training Epoch: 2/2, step 22905/23838 completed (loss: 0.4431408643722534, acc: 0.8648648858070374)
[2025-02-04 03:08:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22907/23838 [31:23<05:59,  2.59it/s][2025-02-04 03:08:13][root][INFO] - Training Epoch: 2/2, step 22906/23838 completed (loss: 0.47800278663635254, acc: 0.9024389982223511)
[2025-02-04 03:08:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22908/23838 [31:23<05:57,  2.60it/s][2025-02-04 03:08:13][root][INFO] - Training Epoch: 2/2, step 22907/23838 completed (loss: 0.27184659242630005, acc: 0.9189189076423645)
[2025-02-04 03:08:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22909/23838 [31:24<05:44,  2.70it/s][2025-02-04 03:08:13][root][INFO] - Training Epoch: 2/2, step 22908/23838 completed (loss: 0.4266452491283417, acc: 0.8645833134651184)
[2025-02-04 03:08:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22910/23838 [31:24<05:37,  2.75it/s][2025-02-04 03:08:14][root][INFO] - Training Epoch: 2/2, step 22909/23838 completed (loss: 0.3995719850063324, acc: 0.9124087691307068)
[2025-02-04 03:08:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22911/23838 [31:25<05:49,  2.65it/s][2025-02-04 03:08:14][root][INFO] - Training Epoch: 2/2, step 22910/23838 completed (loss: 0.41056469082832336, acc: 0.90625)
[2025-02-04 03:08:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22912/23838 [31:25<05:50,  2.64it/s][2025-02-04 03:08:15][root][INFO] - Training Epoch: 2/2, step 22911/23838 completed (loss: 0.3142685294151306, acc: 0.9151515364646912)
[2025-02-04 03:08:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22913/23838 [31:25<05:37,  2.74it/s][2025-02-04 03:08:15][root][INFO] - Training Epoch: 2/2, step 22912/23838 completed (loss: 0.5080272555351257, acc: 0.8627451062202454)
[2025-02-04 03:08:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22914/23838 [31:26<05:38,  2.73it/s][2025-02-04 03:08:15][root][INFO] - Training Epoch: 2/2, step 22913/23838 completed (loss: 0.17458009719848633, acc: 0.9741379022598267)
[2025-02-04 03:08:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22915/23838 [31:26<05:49,  2.64it/s][2025-02-04 03:08:16][root][INFO] - Training Epoch: 2/2, step 22914/23838 completed (loss: 0.3762281537055969, acc: 0.8965517282485962)
[2025-02-04 03:08:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22916/23838 [31:26<05:53,  2.61it/s][2025-02-04 03:08:16][root][INFO] - Training Epoch: 2/2, step 22915/23838 completed (loss: 0.2758079767227173, acc: 0.942307710647583)
[2025-02-04 03:08:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22917/23838 [31:27<05:43,  2.68it/s][2025-02-04 03:08:16][root][INFO] - Training Epoch: 2/2, step 22916/23838 completed (loss: 0.19941768050193787, acc: 0.9579831957817078)
[2025-02-04 03:08:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22918/23838 [31:27<05:27,  2.81it/s][2025-02-04 03:08:17][root][INFO] - Training Epoch: 2/2, step 22917/23838 completed (loss: 0.37821710109710693, acc: 0.8723404407501221)
[2025-02-04 03:08:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22919/23838 [31:27<05:14,  2.93it/s][2025-02-04 03:08:17][root][INFO] - Training Epoch: 2/2, step 22918/23838 completed (loss: 0.1497722864151001, acc: 0.9693877696990967)
[2025-02-04 03:08:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22920/23838 [31:28<05:14,  2.92it/s][2025-02-04 03:08:17][root][INFO] - Training Epoch: 2/2, step 22919/23838 completed (loss: 0.1804158091545105, acc: 0.9484536051750183)
[2025-02-04 03:08:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22921/23838 [31:28<05:03,  3.02it/s][2025-02-04 03:08:18][root][INFO] - Training Epoch: 2/2, step 22920/23838 completed (loss: 0.08798123151063919, acc: 0.9642857313156128)
[2025-02-04 03:08:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22922/23838 [31:28<05:08,  2.97it/s][2025-02-04 03:08:18][root][INFO] - Training Epoch: 2/2, step 22921/23838 completed (loss: 0.12550856173038483, acc: 0.9718309640884399)
[2025-02-04 03:08:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22923/23838 [31:29<05:31,  2.76it/s][2025-02-04 03:08:18][root][INFO] - Training Epoch: 2/2, step 22922/23838 completed (loss: 0.11548470705747604, acc: 0.9814814925193787)
[2025-02-04 03:08:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22924/23838 [31:29<05:43,  2.66it/s][2025-02-04 03:08:19][root][INFO] - Training Epoch: 2/2, step 22923/23838 completed (loss: 0.23257547616958618, acc: 0.9647058844566345)
[2025-02-04 03:08:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22925/23838 [31:30<05:33,  2.74it/s][2025-02-04 03:08:19][root][INFO] - Training Epoch: 2/2, step 22924/23838 completed (loss: 0.09726083278656006, acc: 0.9722222089767456)
[2025-02-04 03:08:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22926/23838 [31:30<05:24,  2.81it/s][2025-02-04 03:08:19][root][INFO] - Training Epoch: 2/2, step 22925/23838 completed (loss: 0.22691825032234192, acc: 0.9268292784690857)
[2025-02-04 03:08:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22927/23838 [31:30<05:07,  2.97it/s][2025-02-04 03:08:20][root][INFO] - Training Epoch: 2/2, step 22926/23838 completed (loss: 0.16190020740032196, acc: 0.9354838728904724)
[2025-02-04 03:08:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22928/23838 [31:31<05:21,  2.83it/s][2025-02-04 03:08:20][root][INFO] - Training Epoch: 2/2, step 22927/23838 completed (loss: 0.0694100484251976, acc: 0.9726027250289917)
[2025-02-04 03:08:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22929/23838 [31:31<05:25,  2.79it/s][2025-02-04 03:08:21][root][INFO] - Training Epoch: 2/2, step 22928/23838 completed (loss: 0.19478420913219452, acc: 0.9534883499145508)
[2025-02-04 03:08:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22930/23838 [31:31<05:08,  2.95it/s][2025-02-04 03:08:21][root][INFO] - Training Epoch: 2/2, step 22929/23838 completed (loss: 0.5852521657943726, acc: 0.8333333134651184)
[2025-02-04 03:08:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22931/23838 [31:32<04:59,  3.03it/s][2025-02-04 03:08:21][root][INFO] - Training Epoch: 2/2, step 22930/23838 completed (loss: 0.1612432301044464, acc: 0.9599999785423279)
[2025-02-04 03:08:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22932/23838 [31:32<04:59,  3.02it/s][2025-02-04 03:08:21][root][INFO] - Training Epoch: 2/2, step 22931/23838 completed (loss: 0.20824097096920013, acc: 0.930232584476471)
[2025-02-04 03:08:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22933/23838 [31:32<05:01,  3.00it/s][2025-02-04 03:08:22][root][INFO] - Training Epoch: 2/2, step 22932/23838 completed (loss: 0.5407209992408752, acc: 0.800000011920929)
[2025-02-04 03:08:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22934/23838 [31:33<04:51,  3.10it/s][2025-02-04 03:08:22][root][INFO] - Training Epoch: 2/2, step 22933/23838 completed (loss: 0.21732226014137268, acc: 0.9534883499145508)
[2025-02-04 03:08:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22935/23838 [31:33<04:53,  3.07it/s][2025-02-04 03:08:22][root][INFO] - Training Epoch: 2/2, step 22934/23838 completed (loss: 0.49506574869155884, acc: 0.8833333253860474)
[2025-02-04 03:08:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22936/23838 [31:33<05:00,  3.00it/s][2025-02-04 03:08:23][root][INFO] - Training Epoch: 2/2, step 22935/23838 completed (loss: 0.11673888564109802, acc: 0.9818181991577148)
[2025-02-04 03:08:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22937/23838 [31:34<04:54,  3.06it/s][2025-02-04 03:08:23][root][INFO] - Training Epoch: 2/2, step 22936/23838 completed (loss: 0.03782609850168228, acc: 1.0)
[2025-02-04 03:08:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22938/23838 [31:34<05:01,  2.99it/s][2025-02-04 03:08:23][root][INFO] - Training Epoch: 2/2, step 22937/23838 completed (loss: 0.445275217294693, acc: 0.848739504814148)
[2025-02-04 03:08:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22939/23838 [31:34<05:01,  2.98it/s][2025-02-04 03:08:24][root][INFO] - Training Epoch: 2/2, step 22938/23838 completed (loss: 0.49334102869033813, acc: 0.9032257795333862)
[2025-02-04 03:08:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22940/23838 [31:35<05:04,  2.95it/s][2025-02-04 03:08:24][root][INFO] - Training Epoch: 2/2, step 22939/23838 completed (loss: 0.2625250518321991, acc: 0.9207317233085632)
[2025-02-04 03:08:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22941/23838 [31:35<04:47,  3.12it/s][2025-02-04 03:08:24][root][INFO] - Training Epoch: 2/2, step 22940/23838 completed (loss: 0.2381940633058548, acc: 0.9555555582046509)
[2025-02-04 03:08:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22942/23838 [31:35<04:53,  3.05it/s][2025-02-04 03:08:25][root][INFO] - Training Epoch: 2/2, step 22941/23838 completed (loss: 0.17607618868350983, acc: 0.9594594836235046)
[2025-02-04 03:08:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22943/23838 [31:36<05:01,  2.97it/s][2025-02-04 03:08:25][root][INFO] - Training Epoch: 2/2, step 22942/23838 completed (loss: 0.3023786246776581, acc: 0.9285714030265808)
[2025-02-04 03:08:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▌[0m| 22944/23838 [31:36<05:06,  2.92it/s][2025-02-04 03:08:25][root][INFO] - Training Epoch: 2/2, step 22943/23838 completed (loss: 0.3547331690788269, acc: 0.9126983880996704)
[2025-02-04 03:08:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22945/23838 [31:36<05:08,  2.89it/s][2025-02-04 03:08:26][root][INFO] - Training Epoch: 2/2, step 22944/23838 completed (loss: 0.4899642765522003, acc: 0.9210526347160339)
[2025-02-04 03:08:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22946/23838 [31:37<05:06,  2.91it/s][2025-02-04 03:08:26][root][INFO] - Training Epoch: 2/2, step 22945/23838 completed (loss: 0.16402393579483032, acc: 0.9367088675498962)
[2025-02-04 03:08:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22947/23838 [31:37<05:04,  2.92it/s][2025-02-04 03:08:27][root][INFO] - Training Epoch: 2/2, step 22946/23838 completed (loss: 0.30144956707954407, acc: 0.8910890817642212)
[2025-02-04 03:08:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22948/23838 [31:37<04:58,  2.98it/s][2025-02-04 03:08:27][root][INFO] - Training Epoch: 2/2, step 22947/23838 completed (loss: 0.3527100086212158, acc: 0.8854166865348816)
[2025-02-04 03:08:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22949/23838 [31:38<05:08,  2.88it/s][2025-02-04 03:08:27][root][INFO] - Training Epoch: 2/2, step 22948/23838 completed (loss: 0.16472266614437103, acc: 0.9579831957817078)
[2025-02-04 03:08:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22950/23838 [31:38<05:10,  2.86it/s][2025-02-04 03:08:28][root][INFO] - Training Epoch: 2/2, step 22949/23838 completed (loss: 0.148281991481781, acc: 0.9428571462631226)
[2025-02-04 03:08:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22951/23838 [31:38<05:16,  2.80it/s][2025-02-04 03:08:28][root][INFO] - Training Epoch: 2/2, step 22950/23838 completed (loss: 0.18989165127277374, acc: 0.9514563083648682)
[2025-02-04 03:08:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22952/23838 [31:39<05:37,  2.63it/s][2025-02-04 03:08:28][root][INFO] - Training Epoch: 2/2, step 22951/23838 completed (loss: 0.3898914158344269, acc: 0.8773584961891174)
[2025-02-04 03:08:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22953/23838 [31:39<05:29,  2.69it/s][2025-02-04 03:08:29][root][INFO] - Training Epoch: 2/2, step 22952/23838 completed (loss: 0.0781838595867157, acc: 0.9861111044883728)
[2025-02-04 03:08:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22954/23838 [31:40<05:29,  2.68it/s][2025-02-04 03:08:29][root][INFO] - Training Epoch: 2/2, step 22953/23838 completed (loss: 0.08641547709703445, acc: 0.9892473220825195)
[2025-02-04 03:08:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22955/23838 [31:40<05:29,  2.68it/s][2025-02-04 03:08:29][root][INFO] - Training Epoch: 2/2, step 22954/23838 completed (loss: 0.08722390234470367, acc: 0.9746835231781006)
[2025-02-04 03:08:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22956/23838 [31:40<05:14,  2.80it/s][2025-02-04 03:08:30][root][INFO] - Training Epoch: 2/2, step 22955/23838 completed (loss: 0.633859395980835, acc: 0.8290598392486572)
[2025-02-04 03:08:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22957/23838 [31:41<05:19,  2.76it/s][2025-02-04 03:08:30][root][INFO] - Training Epoch: 2/2, step 22956/23838 completed (loss: 0.4655485153198242, acc: 0.8768116235733032)
[2025-02-04 03:08:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22958/23838 [31:41<05:13,  2.80it/s][2025-02-04 03:08:31][root][INFO] - Training Epoch: 2/2, step 22957/23838 completed (loss: 0.6741631627082825, acc: 0.7558139562606812)
[2025-02-04 03:08:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22959/23838 [31:41<05:11,  2.82it/s][2025-02-04 03:08:31][root][INFO] - Training Epoch: 2/2, step 22958/23838 completed (loss: 0.38508710265159607, acc: 0.875)
[2025-02-04 03:08:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22960/23838 [31:42<05:12,  2.81it/s][2025-02-04 03:08:31][root][INFO] - Training Epoch: 2/2, step 22959/23838 completed (loss: 0.3500632345676422, acc: 0.8823529481887817)
[2025-02-04 03:08:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22961/23838 [31:42<05:13,  2.79it/s][2025-02-04 03:08:32][root][INFO] - Training Epoch: 2/2, step 22960/23838 completed (loss: 0.5245063304901123, acc: 0.8301886916160583)
[2025-02-04 03:08:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22962/23838 [31:42<05:09,  2.83it/s][2025-02-04 03:08:32][root][INFO] - Training Epoch: 2/2, step 22961/23838 completed (loss: 0.631897509098053, acc: 0.8144329786300659)
[2025-02-04 03:08:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22963/23838 [31:43<05:10,  2.82it/s][2025-02-04 03:08:32][root][INFO] - Training Epoch: 2/2, step 22962/23838 completed (loss: 0.488890141248703, acc: 0.8571428656578064)
[2025-02-04 03:08:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22964/23838 [31:43<05:16,  2.76it/s][2025-02-04 03:08:33][root][INFO] - Training Epoch: 2/2, step 22963/23838 completed (loss: 0.8124410510063171, acc: 0.7765957713127136)
[2025-02-04 03:08:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22965/23838 [31:43<05:05,  2.86it/s][2025-02-04 03:08:33][root][INFO] - Training Epoch: 2/2, step 22964/23838 completed (loss: 0.5643724799156189, acc: 0.8409090638160706)
[2025-02-04 03:08:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22966/23838 [31:44<05:13,  2.78it/s][2025-02-04 03:08:33][root][INFO] - Training Epoch: 2/2, step 22965/23838 completed (loss: 0.7533802390098572, acc: 0.7822580933570862)
[2025-02-04 03:08:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22967/23838 [31:44<05:20,  2.72it/s][2025-02-04 03:08:34][root][INFO] - Training Epoch: 2/2, step 22966/23838 completed (loss: 0.6028038263320923, acc: 0.8557692170143127)
[2025-02-04 03:08:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22968/23838 [31:45<05:12,  2.79it/s][2025-02-04 03:08:34][root][INFO] - Training Epoch: 2/2, step 22967/23838 completed (loss: 0.4137185215950012, acc: 0.8928571343421936)
[2025-02-04 03:08:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22969/23838 [31:45<04:46,  3.03it/s][2025-02-04 03:08:34][root][INFO] - Training Epoch: 2/2, step 22968/23838 completed (loss: 0.7306671738624573, acc: 0.7638888955116272)
[2025-02-04 03:08:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22970/23838 [31:45<04:38,  3.12it/s][2025-02-04 03:08:35][root][INFO] - Training Epoch: 2/2, step 22969/23838 completed (loss: 0.6386151909828186, acc: 0.8529411554336548)
[2025-02-04 03:08:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22971/23838 [31:45<04:44,  3.05it/s][2025-02-04 03:08:35][root][INFO] - Training Epoch: 2/2, step 22970/23838 completed (loss: 0.32389822602272034, acc: 0.8873239159584045)
[2025-02-04 03:08:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22972/23838 [31:46<04:48,  3.00it/s][2025-02-04 03:08:35][root][INFO] - Training Epoch: 2/2, step 22971/23838 completed (loss: 0.42227011919021606, acc: 0.9082568883895874)
[2025-02-04 03:08:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22973/23838 [31:46<04:52,  2.96it/s][2025-02-04 03:08:36][root][INFO] - Training Epoch: 2/2, step 22972/23838 completed (loss: 0.25859206914901733, acc: 0.9090909361839294)
[2025-02-04 03:08:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22974/23838 [31:46<04:50,  2.97it/s][2025-02-04 03:08:36][root][INFO] - Training Epoch: 2/2, step 22973/23838 completed (loss: 0.11647296696901321, acc: 0.9714285731315613)
[2025-02-04 03:08:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22975/23838 [31:47<05:01,  2.86it/s][2025-02-04 03:08:36][root][INFO] - Training Epoch: 2/2, step 22974/23838 completed (loss: 0.3623439073562622, acc: 0.89552241563797)
[2025-02-04 03:08:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22976/23838 [31:47<04:55,  2.92it/s][2025-02-04 03:08:37][root][INFO] - Training Epoch: 2/2, step 22975/23838 completed (loss: 0.3812606930732727, acc: 0.9107142686843872)
[2025-02-04 03:08:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22977/23838 [31:48<04:57,  2.89it/s][2025-02-04 03:08:37][root][INFO] - Training Epoch: 2/2, step 22976/23838 completed (loss: 0.40104493498802185, acc: 0.89552241563797)
[2025-02-04 03:08:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22978/23838 [31:48<04:51,  2.95it/s][2025-02-04 03:08:37][root][INFO] - Training Epoch: 2/2, step 22977/23838 completed (loss: 0.414163202047348, acc: 0.90625)
[2025-02-04 03:08:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22979/23838 [31:48<04:59,  2.87it/s][2025-02-04 03:08:38][root][INFO] - Training Epoch: 2/2, step 22978/23838 completed (loss: 0.3041318953037262, acc: 0.9036144614219666)
[2025-02-04 03:08:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22980/23838 [31:49<05:05,  2.81it/s][2025-02-04 03:08:38][root][INFO] - Training Epoch: 2/2, step 22979/23838 completed (loss: 0.41338956356048584, acc: 0.8765432238578796)
[2025-02-04 03:08:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22981/23838 [31:49<05:07,  2.79it/s][2025-02-04 03:08:39][root][INFO] - Training Epoch: 2/2, step 22980/23838 completed (loss: 0.8537479639053345, acc: 0.752212405204773)
[2025-02-04 03:08:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22982/23838 [31:49<05:01,  2.84it/s][2025-02-04 03:08:39][root][INFO] - Training Epoch: 2/2, step 22981/23838 completed (loss: 0.44833874702453613, acc: 0.8842975497245789)
[2025-02-04 03:08:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22983/23838 [31:50<05:04,  2.80it/s][2025-02-04 03:08:39][root][INFO] - Training Epoch: 2/2, step 22982/23838 completed (loss: 0.3734615445137024, acc: 0.875)
[2025-02-04 03:08:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22984/23838 [31:50<05:04,  2.80it/s][2025-02-04 03:08:40][root][INFO] - Training Epoch: 2/2, step 22983/23838 completed (loss: 0.2330300509929657, acc: 0.9102563858032227)
[2025-02-04 03:08:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22985/23838 [31:50<05:03,  2.81it/s][2025-02-04 03:08:40][root][INFO] - Training Epoch: 2/2, step 22984/23838 completed (loss: 0.5630140900611877, acc: 0.8307692408561707)
[2025-02-04 03:08:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22986/23838 [31:51<05:04,  2.80it/s][2025-02-04 03:08:40][root][INFO] - Training Epoch: 2/2, step 22985/23838 completed (loss: 0.5591003894805908, acc: 0.8349514603614807)
[2025-02-04 03:08:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22987/23838 [31:51<05:34,  2.54it/s][2025-02-04 03:08:41][root][INFO] - Training Epoch: 2/2, step 22986/23838 completed (loss: 0.27479174733161926, acc: 0.9418604373931885)
[2025-02-04 03:08:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22988/23838 [31:52<05:25,  2.61it/s][2025-02-04 03:08:41][root][INFO] - Training Epoch: 2/2, step 22987/23838 completed (loss: 0.49991023540496826, acc: 0.8588235378265381)
[2025-02-04 03:08:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22989/23838 [31:52<05:17,  2.68it/s][2025-02-04 03:08:41][root][INFO] - Training Epoch: 2/2, step 22988/23838 completed (loss: 0.49713465571403503, acc: 0.8474576473236084)
[2025-02-04 03:08:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22990/23838 [31:52<05:23,  2.63it/s][2025-02-04 03:08:42][root][INFO] - Training Epoch: 2/2, step 22989/23838 completed (loss: 0.28075945377349854, acc: 0.9291338324546814)
[2025-02-04 03:08:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22991/23838 [31:53<05:26,  2.59it/s][2025-02-04 03:08:42][root][INFO] - Training Epoch: 2/2, step 22990/23838 completed (loss: 0.36751165986061096, acc: 0.8684210777282715)
[2025-02-04 03:08:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22992/23838 [31:53<05:16,  2.67it/s][2025-02-04 03:08:43][root][INFO] - Training Epoch: 2/2, step 22991/23838 completed (loss: 0.5038397312164307, acc: 0.8636363744735718)
[2025-02-04 03:08:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22993/23838 [31:53<05:35,  2.52it/s][2025-02-04 03:08:43][root][INFO] - Training Epoch: 2/2, step 22992/23838 completed (loss: 0.2949264347553253, acc: 0.9113923907279968)
[2025-02-04 03:08:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22994/23838 [31:54<05:23,  2.61it/s][2025-02-04 03:08:43][root][INFO] - Training Epoch: 2/2, step 22993/23838 completed (loss: 0.6027678847312927, acc: 0.853210985660553)
[2025-02-04 03:08:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22995/23838 [31:54<05:36,  2.51it/s][2025-02-04 03:08:44][root][INFO] - Training Epoch: 2/2, step 22994/23838 completed (loss: 0.8311124444007874, acc: 0.7586206793785095)
[2025-02-04 03:08:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22996/23838 [31:55<05:28,  2.57it/s][2025-02-04 03:08:44][root][INFO] - Training Epoch: 2/2, step 22995/23838 completed (loss: 0.4617719352245331, acc: 0.8695651888847351)
[2025-02-04 03:08:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22997/23838 [31:55<05:17,  2.65it/s][2025-02-04 03:08:45][root][INFO] - Training Epoch: 2/2, step 22996/23838 completed (loss: 0.22029563784599304, acc: 0.9599999785423279)
[2025-02-04 03:08:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22998/23838 [31:55<05:43,  2.45it/s][2025-02-04 03:08:45][root][INFO] - Training Epoch: 2/2, step 22997/23838 completed (loss: 0.36343374848365784, acc: 0.9084967374801636)
[2025-02-04 03:08:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 22999/23838 [31:56<05:43,  2.44it/s][2025-02-04 03:08:45][root][INFO] - Training Epoch: 2/2, step 22998/23838 completed (loss: 0.1167098879814148, acc: 0.9620253443717957)
[2025-02-04 03:08:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 23000/23838 [31:57<06:41,  2.09it/s][2025-02-04 03:08:46][root][INFO] - Training Epoch: 2/2, step 22999/23838 completed (loss: 0.3205835521221161, acc: 0.9214285612106323)
[2025-02-04 03:08:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 23001/23838 [31:57<06:35,  2.12it/s][2025-02-04 03:08:47][root][INFO] - Training Epoch: 2/2, step 23000/23838 completed (loss: 0.23475830256938934, acc: 0.9440000057220459)
[2025-02-04 03:08:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 23002/23838 [31:58<07:48,  1.78it/s][2025-02-04 03:08:47][root][INFO] - Training Epoch: 2/2, step 23001/23838 completed (loss: 0.4412604570388794, acc: 0.8790322542190552)
[2025-02-04 03:08:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  96%|[34m█████████▋[0m| 23003/23838 [31:58<07:17,  1.91it/s][2025-02-04 03:08:48][root][INFO] - Training Epoch: 2/2, step 23002/23838 completed (loss: 0.43160387873649597, acc: 0.8888888955116272)
[2025-02-04 03:08:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23004/23838 [31:59<06:40,  2.08it/s][2025-02-04 03:08:48][root][INFO] - Training Epoch: 2/2, step 23003/23838 completed (loss: 0.23449288308620453, acc: 0.9482758641242981)
[2025-02-04 03:08:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23005/23838 [31:59<06:13,  2.23it/s][2025-02-04 03:08:49][root][INFO] - Training Epoch: 2/2, step 23004/23838 completed (loss: 0.3564409613609314, acc: 0.9411764740943909)
[2025-02-04 03:08:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23006/23838 [31:59<06:16,  2.21it/s][2025-02-04 03:08:49][root][INFO] - Training Epoch: 2/2, step 23005/23838 completed (loss: 0.30541929602622986, acc: 0.9069767594337463)
[2025-02-04 03:08:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23007/23838 [32:00<05:41,  2.44it/s][2025-02-04 03:08:49][root][INFO] - Training Epoch: 2/2, step 23006/23838 completed (loss: 0.10042966157197952, acc: 0.984375)
[2025-02-04 03:08:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23008/23838 [32:00<05:22,  2.58it/s][2025-02-04 03:08:50][root][INFO] - Training Epoch: 2/2, step 23007/23838 completed (loss: 0.2271852195262909, acc: 0.9375)
[2025-02-04 03:08:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23009/23838 [32:01<05:43,  2.41it/s][2025-02-04 03:08:50][root][INFO] - Training Epoch: 2/2, step 23008/23838 completed (loss: 0.18794310092926025, acc: 0.9397590160369873)
[2025-02-04 03:08:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23010/23838 [32:01<06:25,  2.15it/s][2025-02-04 03:08:51][root][INFO] - Training Epoch: 2/2, step 23009/23838 completed (loss: 0.36589792370796204, acc: 0.9111111164093018)
[2025-02-04 03:08:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23011/23838 [32:02<06:11,  2.23it/s][2025-02-04 03:08:51][root][INFO] - Training Epoch: 2/2, step 23010/23838 completed (loss: 0.3182569146156311, acc: 0.9174311757087708)
[2025-02-04 03:08:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23012/23838 [32:02<05:54,  2.33it/s][2025-02-04 03:08:51][root][INFO] - Training Epoch: 2/2, step 23011/23838 completed (loss: 0.7001532912254333, acc: 0.7543859481811523)
[2025-02-04 03:08:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23013/23838 [32:02<05:41,  2.42it/s][2025-02-04 03:08:52][root][INFO] - Training Epoch: 2/2, step 23012/23838 completed (loss: 0.3028271794319153, acc: 0.9200000166893005)
[2025-02-04 03:08:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23014/23838 [32:03<06:10,  2.23it/s][2025-02-04 03:08:52][root][INFO] - Training Epoch: 2/2, step 23013/23838 completed (loss: 0.3949020504951477, acc: 0.8971962332725525)
[2025-02-04 03:08:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23015/23838 [32:03<07:02,  1.95it/s][2025-02-04 03:08:53][root][INFO] - Training Epoch: 2/2, step 23014/23838 completed (loss: 0.35023272037506104, acc: 0.8787878751754761)
[2025-02-04 03:08:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23016/23838 [32:04<08:06,  1.69it/s][2025-02-04 03:08:54][root][INFO] - Training Epoch: 2/2, step 23015/23838 completed (loss: 0.29019424319267273, acc: 0.9186992049217224)
[2025-02-04 03:08:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23017/23838 [32:05<08:23,  1.63it/s][2025-02-04 03:08:55][root][INFO] - Training Epoch: 2/2, step 23016/23838 completed (loss: 0.1799919605255127, acc: 0.961904764175415)
[2025-02-04 03:08:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23018/23838 [32:05<07:37,  1.79it/s][2025-02-04 03:08:55][root][INFO] - Training Epoch: 2/2, step 23017/23838 completed (loss: 0.6167532801628113, acc: 0.805084764957428)
[2025-02-04 03:08:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23019/23838 [32:06<06:48,  2.01it/s][2025-02-04 03:08:55][root][INFO] - Training Epoch: 2/2, step 23018/23838 completed (loss: 0.5095003247261047, acc: 0.89552241563797)
[2025-02-04 03:08:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23020/23838 [32:06<06:17,  2.16it/s][2025-02-04 03:08:56][root][INFO] - Training Epoch: 2/2, step 23019/23838 completed (loss: 0.36953768134117126, acc: 0.8695651888847351)
[2025-02-04 03:08:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23021/23838 [32:06<05:54,  2.31it/s][2025-02-04 03:08:56][root][INFO] - Training Epoch: 2/2, step 23020/23838 completed (loss: 0.14746153354644775, acc: 0.9550561904907227)
[2025-02-04 03:08:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23022/23838 [32:07<05:41,  2.39it/s][2025-02-04 03:08:56][root][INFO] - Training Epoch: 2/2, step 23021/23838 completed (loss: 0.2025415450334549, acc: 0.9375)
[2025-02-04 03:08:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23023/23838 [32:07<05:23,  2.52it/s][2025-02-04 03:08:57][root][INFO] - Training Epoch: 2/2, step 23022/23838 completed (loss: 0.19637562334537506, acc: 0.9545454382896423)
[2025-02-04 03:08:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23024/23838 [32:08<05:11,  2.61it/s][2025-02-04 03:08:57][root][INFO] - Training Epoch: 2/2, step 23023/23838 completed (loss: 0.7868711948394775, acc: 0.7272727489471436)
[2025-02-04 03:08:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23025/23838 [32:08<05:09,  2.63it/s][2025-02-04 03:08:57][root][INFO] - Training Epoch: 2/2, step 23024/23838 completed (loss: 0.14855946600437164, acc: 0.9491525292396545)
[2025-02-04 03:08:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23026/23838 [32:08<05:01,  2.69it/s][2025-02-04 03:08:58][root][INFO] - Training Epoch: 2/2, step 23025/23838 completed (loss: 0.015867678448557854, acc: 1.0)
[2025-02-04 03:08:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23027/23838 [32:09<04:57,  2.73it/s][2025-02-04 03:08:58][root][INFO] - Training Epoch: 2/2, step 23026/23838 completed (loss: 0.2140803188085556, acc: 0.9189189076423645)
[2025-02-04 03:08:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23028/23838 [32:09<04:52,  2.77it/s][2025-02-04 03:08:59][root][INFO] - Training Epoch: 2/2, step 23027/23838 completed (loss: 0.21009111404418945, acc: 0.9431818127632141)
[2025-02-04 03:08:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23029/23838 [32:09<04:50,  2.78it/s][2025-02-04 03:08:59][root][INFO] - Training Epoch: 2/2, step 23028/23838 completed (loss: 0.022887568920850754, acc: 1.0)
[2025-02-04 03:08:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23030/23838 [32:10<04:51,  2.78it/s][2025-02-04 03:08:59][root][INFO] - Training Epoch: 2/2, step 23029/23838 completed (loss: 0.09650584310293198, acc: 0.96875)
[2025-02-04 03:08:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23031/23838 [32:10<04:54,  2.74it/s][2025-02-04 03:09:00][root][INFO] - Training Epoch: 2/2, step 23030/23838 completed (loss: 0.08441199362277985, acc: 1.0)
[2025-02-04 03:09:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23032/23838 [32:10<04:54,  2.74it/s][2025-02-04 03:09:00][root][INFO] - Training Epoch: 2/2, step 23031/23838 completed (loss: 0.1456872969865799, acc: 0.9245283007621765)
[2025-02-04 03:09:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23033/23838 [32:11<04:52,  2.76it/s][2025-02-04 03:09:00][root][INFO] - Training Epoch: 2/2, step 23032/23838 completed (loss: 0.25134411454200745, acc: 0.8974359035491943)
[2025-02-04 03:09:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23034/23838 [32:11<04:50,  2.77it/s][2025-02-04 03:09:01][root][INFO] - Training Epoch: 2/2, step 23033/23838 completed (loss: 0.13532592356204987, acc: 0.970588207244873)
[2025-02-04 03:09:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23035/23838 [32:11<04:41,  2.85it/s][2025-02-04 03:09:01][root][INFO] - Training Epoch: 2/2, step 23034/23838 completed (loss: 0.1876779943704605, acc: 0.9259259104728699)
[2025-02-04 03:09:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23036/23838 [32:12<04:46,  2.80it/s][2025-02-04 03:09:01][root][INFO] - Training Epoch: 2/2, step 23035/23838 completed (loss: 0.2913021147251129, acc: 0.925000011920929)
[2025-02-04 03:09:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23037/23838 [32:12<04:50,  2.76it/s][2025-02-04 03:09:02][root][INFO] - Training Epoch: 2/2, step 23036/23838 completed (loss: 0.264642596244812, acc: 0.9354838728904724)
[2025-02-04 03:09:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23038/23838 [32:13<04:53,  2.73it/s][2025-02-04 03:09:02][root][INFO] - Training Epoch: 2/2, step 23037/23838 completed (loss: 0.04160156473517418, acc: 0.9821428656578064)
[2025-02-04 03:09:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23039/23838 [32:13<04:55,  2.71it/s][2025-02-04 03:09:03][root][INFO] - Training Epoch: 2/2, step 23038/23838 completed (loss: 0.344544917345047, acc: 0.8965517282485962)
[2025-02-04 03:09:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23040/23838 [32:13<04:50,  2.75it/s][2025-02-04 03:09:03][root][INFO] - Training Epoch: 2/2, step 23039/23838 completed (loss: 0.15545493364334106, acc: 0.9814814925193787)
[2025-02-04 03:09:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23041/23838 [32:14<04:30,  2.95it/s][2025-02-04 03:09:03][root][INFO] - Training Epoch: 2/2, step 23040/23838 completed (loss: 0.23571635782718658, acc: 0.9333333373069763)
[2025-02-04 03:09:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23042/23838 [32:14<04:22,  3.03it/s][2025-02-04 03:09:03][root][INFO] - Training Epoch: 2/2, step 23041/23838 completed (loss: 0.34154072403907776, acc: 0.9367088675498962)
[2025-02-04 03:09:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23043/23838 [32:14<04:18,  3.07it/s][2025-02-04 03:09:04][root][INFO] - Training Epoch: 2/2, step 23042/23838 completed (loss: 0.14463725686073303, acc: 0.9354838728904724)
[2025-02-04 03:09:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23044/23838 [32:15<04:13,  3.14it/s][2025-02-04 03:09:04][root][INFO] - Training Epoch: 2/2, step 23043/23838 completed (loss: 0.36876073479652405, acc: 0.9090909361839294)
[2025-02-04 03:09:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23045/23838 [32:15<04:25,  2.99it/s][2025-02-04 03:09:04][root][INFO] - Training Epoch: 2/2, step 23044/23838 completed (loss: 0.03271685168147087, acc: 1.0)
[2025-02-04 03:09:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23046/23838 [32:15<04:33,  2.89it/s][2025-02-04 03:09:05][root][INFO] - Training Epoch: 2/2, step 23045/23838 completed (loss: 0.5459005832672119, acc: 0.8426966071128845)
[2025-02-04 03:09:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23047/23838 [32:16<04:47,  2.75it/s][2025-02-04 03:09:05][root][INFO] - Training Epoch: 2/2, step 23046/23838 completed (loss: 0.4933564066886902, acc: 0.8275862336158752)
[2025-02-04 03:09:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23048/23838 [32:16<04:24,  2.99it/s][2025-02-04 03:09:06][root][INFO] - Training Epoch: 2/2, step 23047/23838 completed (loss: 0.0225444957613945, acc: 1.0)
[2025-02-04 03:09:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23049/23838 [32:16<04:17,  3.06it/s][2025-02-04 03:09:06][root][INFO] - Training Epoch: 2/2, step 23048/23838 completed (loss: 0.060365479439496994, acc: 1.0)
[2025-02-04 03:09:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23050/23838 [32:17<04:22,  3.01it/s][2025-02-04 03:09:06][root][INFO] - Training Epoch: 2/2, step 23049/23838 completed (loss: 0.4133542478084564, acc: 0.7692307829856873)
[2025-02-04 03:09:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23051/23838 [32:17<04:16,  3.07it/s][2025-02-04 03:09:06][root][INFO] - Training Epoch: 2/2, step 23050/23838 completed (loss: 0.5610029101371765, acc: 0.9200000166893005)
[2025-02-04 03:09:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23052/23838 [32:17<04:28,  2.92it/s][2025-02-04 03:09:07][root][INFO] - Training Epoch: 2/2, step 23051/23838 completed (loss: 0.39386865496635437, acc: 0.9178082346916199)
[2025-02-04 03:09:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23053/23838 [32:18<04:39,  2.81it/s][2025-02-04 03:09:07][root][INFO] - Training Epoch: 2/2, step 23052/23838 completed (loss: 0.24480895698070526, acc: 0.9487179517745972)
[2025-02-04 03:09:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23054/23838 [32:18<04:35,  2.84it/s][2025-02-04 03:09:08][root][INFO] - Training Epoch: 2/2, step 23053/23838 completed (loss: 0.42773327231407166, acc: 0.9223300814628601)
[2025-02-04 03:09:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23055/23838 [32:18<04:30,  2.89it/s][2025-02-04 03:09:08][root][INFO] - Training Epoch: 2/2, step 23054/23838 completed (loss: 0.10299033671617508, acc: 0.9682539701461792)
[2025-02-04 03:09:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23056/23838 [32:19<04:44,  2.75it/s][2025-02-04 03:09:08][root][INFO] - Training Epoch: 2/2, step 23055/23838 completed (loss: 0.2886742651462555, acc: 0.9137930870056152)
[2025-02-04 03:09:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23057/23838 [32:19<04:51,  2.68it/s][2025-02-04 03:09:09][root][INFO] - Training Epoch: 2/2, step 23056/23838 completed (loss: 0.12124297767877579, acc: 0.9555555582046509)
[2025-02-04 03:09:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23058/23838 [32:19<04:45,  2.73it/s][2025-02-04 03:09:09][root][INFO] - Training Epoch: 2/2, step 23057/23838 completed (loss: 0.12966082990169525, acc: 0.9824561476707458)
[2025-02-04 03:09:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23059/23838 [32:20<04:40,  2.78it/s][2025-02-04 03:09:09][root][INFO] - Training Epoch: 2/2, step 23058/23838 completed (loss: 0.15937384963035583, acc: 0.949999988079071)
[2025-02-04 03:09:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23060/23838 [32:20<04:33,  2.84it/s][2025-02-04 03:09:10][root][INFO] - Training Epoch: 2/2, step 23059/23838 completed (loss: 0.02702738530933857, acc: 1.0)
[2025-02-04 03:09:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23061/23838 [32:20<04:22,  2.96it/s][2025-02-04 03:09:10][root][INFO] - Training Epoch: 2/2, step 23060/23838 completed (loss: 0.20973820984363556, acc: 0.9210526347160339)
[2025-02-04 03:09:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23062/23838 [32:21<04:16,  3.02it/s][2025-02-04 03:09:10][root][INFO] - Training Epoch: 2/2, step 23061/23838 completed (loss: 0.2970774173736572, acc: 0.930232584476471)
[2025-02-04 03:09:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23063/23838 [32:21<04:18,  2.99it/s][2025-02-04 03:09:11][root][INFO] - Training Epoch: 2/2, step 23062/23838 completed (loss: 0.2780149579048157, acc: 0.9375)
[2025-02-04 03:09:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23064/23838 [32:21<04:17,  3.01it/s][2025-02-04 03:09:11][root][INFO] - Training Epoch: 2/2, step 23063/23838 completed (loss: 0.38801851868629456, acc: 0.8644067645072937)
[2025-02-04 03:09:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23065/23838 [32:22<04:17,  3.01it/s][2025-02-04 03:09:11][root][INFO] - Training Epoch: 2/2, step 23064/23838 completed (loss: 0.15936020016670227, acc: 0.953125)
[2025-02-04 03:09:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23066/23838 [32:22<04:11,  3.07it/s][2025-02-04 03:09:12][root][INFO] - Training Epoch: 2/2, step 23065/23838 completed (loss: 0.3417031466960907, acc: 0.8684210777282715)
[2025-02-04 03:09:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23067/23838 [32:22<04:16,  3.01it/s][2025-02-04 03:09:12][root][INFO] - Training Epoch: 2/2, step 23066/23838 completed (loss: 0.14140373468399048, acc: 0.9562841653823853)
[2025-02-04 03:09:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23068/23838 [32:23<04:19,  2.97it/s][2025-02-04 03:09:12][root][INFO] - Training Epoch: 2/2, step 23067/23838 completed (loss: 0.4366837739944458, acc: 0.9109588861465454)
[2025-02-04 03:09:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23069/23838 [32:23<04:41,  2.73it/s][2025-02-04 03:09:13][root][INFO] - Training Epoch: 2/2, step 23068/23838 completed (loss: 0.15944400429725647, acc: 0.9599999785423279)
[2025-02-04 03:09:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23070/23838 [32:24<04:36,  2.78it/s][2025-02-04 03:09:13][root][INFO] - Training Epoch: 2/2, step 23069/23838 completed (loss: 0.29513636231422424, acc: 0.9226190447807312)
[2025-02-04 03:09:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23071/23838 [32:24<04:30,  2.83it/s][2025-02-04 03:09:14][root][INFO] - Training Epoch: 2/2, step 23070/23838 completed (loss: 0.13755065202713013, acc: 0.9700000286102295)
[2025-02-04 03:09:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23072/23838 [32:24<04:34,  2.79it/s][2025-02-04 03:09:14][root][INFO] - Training Epoch: 2/2, step 23071/23838 completed (loss: 0.22052741050720215, acc: 0.9189189076423645)
[2025-02-04 03:09:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23073/23838 [32:25<04:31,  2.81it/s][2025-02-04 03:09:14][root][INFO] - Training Epoch: 2/2, step 23072/23838 completed (loss: 0.7616036534309387, acc: 0.8571428656578064)
[2025-02-04 03:09:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23074/23838 [32:25<04:30,  2.82it/s][2025-02-04 03:09:15][root][INFO] - Training Epoch: 2/2, step 23073/23838 completed (loss: 0.2812226116657257, acc: 0.9268292784690857)
[2025-02-04 03:09:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23075/23838 [32:25<04:32,  2.80it/s][2025-02-04 03:09:15][root][INFO] - Training Epoch: 2/2, step 23074/23838 completed (loss: 0.04681290313601494, acc: 0.9882352948188782)
[2025-02-04 03:09:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23076/23838 [32:26<04:28,  2.84it/s][2025-02-04 03:09:15][root][INFO] - Training Epoch: 2/2, step 23075/23838 completed (loss: 0.06562652438879013, acc: 0.9821428656578064)
[2025-02-04 03:09:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23077/23838 [32:26<04:39,  2.73it/s][2025-02-04 03:09:16][root][INFO] - Training Epoch: 2/2, step 23076/23838 completed (loss: 0.15787307918071747, acc: 0.949367105960846)
[2025-02-04 03:09:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23078/23838 [32:27<04:48,  2.64it/s][2025-02-04 03:09:16][root][INFO] - Training Epoch: 2/2, step 23077/23838 completed (loss: 0.5491122007369995, acc: 0.8727272748947144)
[2025-02-04 03:09:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23079/23838 [32:27<04:44,  2.67it/s][2025-02-04 03:09:16][root][INFO] - Training Epoch: 2/2, step 23078/23838 completed (loss: 0.1356724202632904, acc: 0.9739130139350891)
[2025-02-04 03:09:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23080/23838 [32:27<04:55,  2.57it/s][2025-02-04 03:09:17][root][INFO] - Training Epoch: 2/2, step 23079/23838 completed (loss: 0.38971370458602905, acc: 0.8813559412956238)
[2025-02-04 03:09:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23081/23838 [32:28<04:44,  2.66it/s][2025-02-04 03:09:17][root][INFO] - Training Epoch: 2/2, step 23080/23838 completed (loss: 0.07806513458490372, acc: 0.984375)
[2025-02-04 03:09:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23082/23838 [32:28<04:49,  2.61it/s][2025-02-04 03:09:18][root][INFO] - Training Epoch: 2/2, step 23081/23838 completed (loss: 0.3695528209209442, acc: 0.8181818127632141)
[2025-02-04 03:09:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23083/23838 [32:29<05:11,  2.43it/s][2025-02-04 03:09:18][root][INFO] - Training Epoch: 2/2, step 23082/23838 completed (loss: 0.630308210849762, acc: 0.8064516186714172)
[2025-02-04 03:09:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23084/23838 [32:29<05:03,  2.49it/s][2025-02-04 03:09:18][root][INFO] - Training Epoch: 2/2, step 23083/23838 completed (loss: 0.3549378216266632, acc: 0.9047619104385376)
[2025-02-04 03:09:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23085/23838 [32:29<05:14,  2.39it/s][2025-02-04 03:09:19][root][INFO] - Training Epoch: 2/2, step 23084/23838 completed (loss: 0.47143739461898804, acc: 0.8679245114326477)
[2025-02-04 03:09:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23086/23838 [32:30<05:00,  2.51it/s][2025-02-04 03:09:19][root][INFO] - Training Epoch: 2/2, step 23085/23838 completed (loss: 0.8391444087028503, acc: 0.75)
[2025-02-04 03:09:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23087/23838 [32:30<04:51,  2.58it/s][2025-02-04 03:09:20][root][INFO] - Training Epoch: 2/2, step 23086/23838 completed (loss: 0.4211685061454773, acc: 0.8970588445663452)
[2025-02-04 03:09:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23088/23838 [32:31<05:34,  2.24it/s][2025-02-04 03:09:20][root][INFO] - Training Epoch: 2/2, step 23087/23838 completed (loss: 0.8391357660293579, acc: 0.7586206793785095)
[2025-02-04 03:09:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23089/23838 [32:31<05:48,  2.15it/s][2025-02-04 03:09:21][root][INFO] - Training Epoch: 2/2, step 23088/23838 completed (loss: 0.5867583155632019, acc: 0.8641975522041321)
[2025-02-04 03:09:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23090/23838 [32:32<05:28,  2.27it/s][2025-02-04 03:09:21][root][INFO] - Training Epoch: 2/2, step 23089/23838 completed (loss: 1.3268065452575684, acc: 0.5609756112098694)
[2025-02-04 03:09:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23091/23838 [32:32<05:24,  2.30it/s][2025-02-04 03:09:22][root][INFO] - Training Epoch: 2/2, step 23090/23838 completed (loss: 0.5724802613258362, acc: 0.8684210777282715)
[2025-02-04 03:09:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23092/23838 [32:33<06:05,  2.04it/s][2025-02-04 03:09:22][root][INFO] - Training Epoch: 2/2, step 23091/23838 completed (loss: 0.6679787039756775, acc: 0.800000011920929)
[2025-02-04 03:09:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23093/23838 [32:33<05:55,  2.10it/s][2025-02-04 03:09:23][root][INFO] - Training Epoch: 2/2, step 23092/23838 completed (loss: 1.1378819942474365, acc: 0.644444465637207)
[2025-02-04 03:09:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23094/23838 [32:33<05:37,  2.21it/s][2025-02-04 03:09:23][root][INFO] - Training Epoch: 2/2, step 23093/23838 completed (loss: 0.7243042588233948, acc: 0.7868852615356445)
[2025-02-04 03:09:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23095/23838 [32:34<05:19,  2.32it/s][2025-02-04 03:09:23][root][INFO] - Training Epoch: 2/2, step 23094/23838 completed (loss: 0.8584545850753784, acc: 0.7580645084381104)
[2025-02-04 03:09:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23096/23838 [32:34<04:57,  2.49it/s][2025-02-04 03:09:24][root][INFO] - Training Epoch: 2/2, step 23095/23838 completed (loss: 0.8700161576271057, acc: 0.7349397540092468)
[2025-02-04 03:09:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23097/23838 [32:34<04:41,  2.63it/s][2025-02-04 03:09:24][root][INFO] - Training Epoch: 2/2, step 23096/23838 completed (loss: 0.7230292558670044, acc: 0.8048780560493469)
[2025-02-04 03:09:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23098/23838 [32:35<04:40,  2.64it/s][2025-02-04 03:09:24][root][INFO] - Training Epoch: 2/2, step 23097/23838 completed (loss: 0.8174356818199158, acc: 0.8235294222831726)
[2025-02-04 03:09:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23099/23838 [32:35<04:22,  2.81it/s][2025-02-04 03:09:25][root][INFO] - Training Epoch: 2/2, step 23098/23838 completed (loss: 0.8652393221855164, acc: 0.71875)
[2025-02-04 03:09:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23100/23838 [32:36<04:29,  2.74it/s][2025-02-04 03:09:25][root][INFO] - Training Epoch: 2/2, step 23099/23838 completed (loss: 0.7324711680412292, acc: 0.800000011920929)
[2025-02-04 03:09:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23101/23838 [32:36<04:23,  2.80it/s][2025-02-04 03:09:25][root][INFO] - Training Epoch: 2/2, step 23100/23838 completed (loss: 0.906181812286377, acc: 0.7843137383460999)
[2025-02-04 03:09:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23102/23838 [32:36<04:18,  2.84it/s][2025-02-04 03:09:26][root][INFO] - Training Epoch: 2/2, step 23101/23838 completed (loss: 1.0787370204925537, acc: 0.6792452931404114)
[2025-02-04 03:09:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23103/23838 [32:37<04:20,  2.82it/s][2025-02-04 03:09:26][root][INFO] - Training Epoch: 2/2, step 23102/23838 completed (loss: 0.9646926522254944, acc: 0.6666666865348816)
[2025-02-04 03:09:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23104/23838 [32:37<04:32,  2.70it/s][2025-02-04 03:09:27][root][INFO] - Training Epoch: 2/2, step 23103/23838 completed (loss: 1.2088356018066406, acc: 0.6000000238418579)
[2025-02-04 03:09:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23105/23838 [32:37<04:19,  2.83it/s][2025-02-04 03:09:27][root][INFO] - Training Epoch: 2/2, step 23104/23838 completed (loss: 0.9899349212646484, acc: 0.75)
[2025-02-04 03:09:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23106/23838 [32:38<04:15,  2.87it/s][2025-02-04 03:09:27][root][INFO] - Training Epoch: 2/2, step 23105/23838 completed (loss: 1.427650809288025, acc: 0.5263158082962036)
[2025-02-04 03:09:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23107/23838 [32:38<04:27,  2.73it/s][2025-02-04 03:09:28][root][INFO] - Training Epoch: 2/2, step 23106/23838 completed (loss: 0.879645049571991, acc: 0.75)
[2025-02-04 03:09:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23108/23838 [32:38<04:28,  2.72it/s][2025-02-04 03:09:28][root][INFO] - Training Epoch: 2/2, step 23107/23838 completed (loss: 0.9624006748199463, acc: 0.7037037014961243)
[2025-02-04 03:09:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23109/23838 [32:39<04:24,  2.75it/s][2025-02-04 03:09:28][root][INFO] - Training Epoch: 2/2, step 23108/23838 completed (loss: 0.4986092746257782, acc: 0.8651685118675232)
[2025-02-04 03:09:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23110/23838 [32:39<04:22,  2.77it/s][2025-02-04 03:09:29][root][INFO] - Training Epoch: 2/2, step 23109/23838 completed (loss: 0.5132245421409607, acc: 0.8695651888847351)
[2025-02-04 03:09:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23111/23838 [32:40<04:28,  2.71it/s][2025-02-04 03:09:29][root][INFO] - Training Epoch: 2/2, step 23110/23838 completed (loss: 1.6386345624923706, acc: 0.5681818127632141)
[2025-02-04 03:09:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23112/23838 [32:40<04:25,  2.74it/s][2025-02-04 03:09:29][root][INFO] - Training Epoch: 2/2, step 23111/23838 completed (loss: 1.1227309703826904, acc: 0.7027027010917664)
[2025-02-04 03:09:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23113/23838 [32:40<04:22,  2.76it/s][2025-02-04 03:09:30][root][INFO] - Training Epoch: 2/2, step 23112/23838 completed (loss: 1.1261307001113892, acc: 0.7105262875556946)
[2025-02-04 03:09:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23114/23838 [32:41<04:23,  2.75it/s][2025-02-04 03:09:30][root][INFO] - Training Epoch: 2/2, step 23113/23838 completed (loss: 0.7536947727203369, acc: 0.7592592835426331)
[2025-02-04 03:09:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23115/23838 [32:41<04:43,  2.55it/s][2025-02-04 03:09:31][root][INFO] - Training Epoch: 2/2, step 23114/23838 completed (loss: 0.9991652965545654, acc: 0.75)
[2025-02-04 03:09:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23116/23838 [32:41<04:55,  2.44it/s][2025-02-04 03:09:31][root][INFO] - Training Epoch: 2/2, step 23115/23838 completed (loss: 0.9101234078407288, acc: 0.7387387156486511)
[2025-02-04 03:09:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23117/23838 [32:42<04:45,  2.53it/s][2025-02-04 03:09:31][root][INFO] - Training Epoch: 2/2, step 23116/23838 completed (loss: 0.9917207956314087, acc: 0.7866666913032532)
[2025-02-04 03:09:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23118/23838 [32:42<04:36,  2.60it/s][2025-02-04 03:09:32][root][INFO] - Training Epoch: 2/2, step 23117/23838 completed (loss: 0.5853844881057739, acc: 0.8253968358039856)
[2025-02-04 03:09:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23119/23838 [32:43<04:41,  2.56it/s][2025-02-04 03:09:32][root][INFO] - Training Epoch: 2/2, step 23118/23838 completed (loss: 0.4710578918457031, acc: 0.8253968358039856)
[2025-02-04 03:09:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23120/23838 [32:43<04:34,  2.61it/s][2025-02-04 03:09:33][root][INFO] - Training Epoch: 2/2, step 23119/23838 completed (loss: 0.7198168039321899, acc: 0.7777777910232544)
[2025-02-04 03:09:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23121/23838 [32:43<04:32,  2.63it/s][2025-02-04 03:09:33][root][INFO] - Training Epoch: 2/2, step 23120/23838 completed (loss: 0.7054069638252258, acc: 0.8387096524238586)
[2025-02-04 03:09:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23122/23838 [32:44<04:35,  2.60it/s][2025-02-04 03:09:33][root][INFO] - Training Epoch: 2/2, step 23121/23838 completed (loss: 0.7832508087158203, acc: 0.7692307829856873)
[2025-02-04 03:09:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23123/23838 [32:44<04:35,  2.60it/s][2025-02-04 03:09:34][root][INFO] - Training Epoch: 2/2, step 23122/23838 completed (loss: 0.9573835134506226, acc: 0.6938775777816772)
[2025-02-04 03:09:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23124/23838 [32:45<04:37,  2.58it/s][2025-02-04 03:09:34][root][INFO] - Training Epoch: 2/2, step 23123/23838 completed (loss: 0.8277004361152649, acc: 0.7543859481811523)
[2025-02-04 03:09:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23125/23838 [32:45<04:26,  2.67it/s][2025-02-04 03:09:34][root][INFO] - Training Epoch: 2/2, step 23124/23838 completed (loss: 0.6764219999313354, acc: 0.875)
[2025-02-04 03:09:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23126/23838 [32:45<04:42,  2.52it/s][2025-02-04 03:09:35][root][INFO] - Training Epoch: 2/2, step 23125/23838 completed (loss: 1.0075711011886597, acc: 0.7096773982048035)
[2025-02-04 03:09:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23127/23838 [32:46<04:30,  2.63it/s][2025-02-04 03:09:35][root][INFO] - Training Epoch: 2/2, step 23126/23838 completed (loss: 0.547857403755188, acc: 0.7906976938247681)
[2025-02-04 03:09:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23128/23838 [32:46<04:25,  2.68it/s][2025-02-04 03:09:36][root][INFO] - Training Epoch: 2/2, step 23127/23838 completed (loss: 0.3418942391872406, acc: 0.9126213788986206)
[2025-02-04 03:09:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23129/23838 [32:46<04:18,  2.74it/s][2025-02-04 03:09:36][root][INFO] - Training Epoch: 2/2, step 23128/23838 completed (loss: 0.3786066174507141, acc: 0.8918918967247009)
[2025-02-04 03:09:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23130/23838 [32:47<04:16,  2.76it/s][2025-02-04 03:09:36][root][INFO] - Training Epoch: 2/2, step 23129/23838 completed (loss: 0.5853696465492249, acc: 0.8823529481887817)
[2025-02-04 03:09:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23131/23838 [32:47<04:21,  2.70it/s][2025-02-04 03:09:37][root][INFO] - Training Epoch: 2/2, step 23130/23838 completed (loss: 0.6605343818664551, acc: 0.8292682766914368)
[2025-02-04 03:09:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23132/23838 [32:47<04:15,  2.76it/s][2025-02-04 03:09:37][root][INFO] - Training Epoch: 2/2, step 23131/23838 completed (loss: 0.22818608582019806, acc: 0.949999988079071)
[2025-02-04 03:09:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23133/23838 [32:48<04:15,  2.76it/s][2025-02-04 03:09:37][root][INFO] - Training Epoch: 2/2, step 23132/23838 completed (loss: 0.11853969097137451, acc: 0.9636363387107849)
[2025-02-04 03:09:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23134/23838 [32:48<04:12,  2.79it/s][2025-02-04 03:09:38][root][INFO] - Training Epoch: 2/2, step 23133/23838 completed (loss: 0.16379667818546295, acc: 0.9602649211883545)
[2025-02-04 03:09:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23135/23838 [32:49<04:19,  2.71it/s][2025-02-04 03:09:38][root][INFO] - Training Epoch: 2/2, step 23134/23838 completed (loss: 0.4096706807613373, acc: 0.8965517282485962)
[2025-02-04 03:09:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23136/23838 [32:49<04:38,  2.52it/s][2025-02-04 03:09:39][root][INFO] - Training Epoch: 2/2, step 23135/23838 completed (loss: 0.2732698619365692, acc: 0.9090909361839294)
[2025-02-04 03:09:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23137/23838 [32:49<04:43,  2.47it/s][2025-02-04 03:09:39][root][INFO] - Training Epoch: 2/2, step 23136/23838 completed (loss: 0.40774503350257874, acc: 0.9178082346916199)
[2025-02-04 03:09:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23138/23838 [32:50<04:42,  2.48it/s][2025-02-04 03:09:39][root][INFO] - Training Epoch: 2/2, step 23137/23838 completed (loss: 0.13545823097229004, acc: 0.9444444179534912)
[2025-02-04 03:09:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23139/23838 [32:50<04:21,  2.67it/s][2025-02-04 03:09:40][root][INFO] - Training Epoch: 2/2, step 23138/23838 completed (loss: 0.37090983986854553, acc: 0.9139072895050049)
[2025-02-04 03:09:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23140/23838 [32:51<04:16,  2.73it/s][2025-02-04 03:09:40][root][INFO] - Training Epoch: 2/2, step 23139/23838 completed (loss: 0.31203994154930115, acc: 0.9166666865348816)
[2025-02-04 03:09:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23141/23838 [32:51<04:11,  2.77it/s][2025-02-04 03:09:40][root][INFO] - Training Epoch: 2/2, step 23140/23838 completed (loss: 0.3671267628669739, acc: 0.8602150678634644)
[2025-02-04 03:09:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23142/23838 [32:51<04:14,  2.73it/s][2025-02-04 03:09:41][root][INFO] - Training Epoch: 2/2, step 23141/23838 completed (loss: 0.35884860157966614, acc: 0.8780487775802612)
[2025-02-04 03:09:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23143/23838 [32:52<04:11,  2.77it/s][2025-02-04 03:09:41][root][INFO] - Training Epoch: 2/2, step 23142/23838 completed (loss: 0.18352973461151123, acc: 0.9529411792755127)
[2025-02-04 03:09:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23144/23838 [32:52<04:07,  2.81it/s][2025-02-04 03:09:42][root][INFO] - Training Epoch: 2/2, step 23143/23838 completed (loss: 0.1273040920495987, acc: 0.9677419066429138)
[2025-02-04 03:09:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23145/23838 [32:52<04:08,  2.79it/s][2025-02-04 03:09:42][root][INFO] - Training Epoch: 2/2, step 23144/23838 completed (loss: 0.24513794481754303, acc: 0.9453125)
[2025-02-04 03:09:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23146/23838 [32:53<04:08,  2.79it/s][2025-02-04 03:09:42][root][INFO] - Training Epoch: 2/2, step 23145/23838 completed (loss: 0.4836294949054718, acc: 0.8837209343910217)
[2025-02-04 03:09:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23147/23838 [32:53<04:04,  2.82it/s][2025-02-04 03:09:43][root][INFO] - Training Epoch: 2/2, step 23146/23838 completed (loss: 0.3590308129787445, acc: 0.893203854560852)
[2025-02-04 03:09:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23148/23838 [32:53<04:00,  2.87it/s][2025-02-04 03:09:43][root][INFO] - Training Epoch: 2/2, step 23147/23838 completed (loss: 0.4379886984825134, acc: 0.8976377844810486)
[2025-02-04 03:09:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23149/23838 [32:54<03:58,  2.89it/s][2025-02-04 03:09:43][root][INFO] - Training Epoch: 2/2, step 23148/23838 completed (loss: 0.45813000202178955, acc: 0.8720930218696594)
[2025-02-04 03:09:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23150/23838 [32:54<04:10,  2.75it/s][2025-02-04 03:09:44][root][INFO] - Training Epoch: 2/2, step 23149/23838 completed (loss: 0.4817250669002533, acc: 0.886904776096344)
[2025-02-04 03:09:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23151/23838 [32:54<04:13,  2.71it/s][2025-02-04 03:09:44][root][INFO] - Training Epoch: 2/2, step 23150/23838 completed (loss: 0.39813777804374695, acc: 0.9074074029922485)
[2025-02-04 03:09:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23152/23838 [32:55<04:26,  2.58it/s][2025-02-04 03:09:44][root][INFO] - Training Epoch: 2/2, step 23151/23838 completed (loss: 0.2310568392276764, acc: 0.9534883499145508)
[2025-02-04 03:09:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23153/23838 [32:55<04:26,  2.57it/s][2025-02-04 03:09:45][root][INFO] - Training Epoch: 2/2, step 23152/23838 completed (loss: 0.699027955532074, acc: 0.824999988079071)
[2025-02-04 03:09:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23154/23838 [32:56<04:11,  2.72it/s][2025-02-04 03:09:45][root][INFO] - Training Epoch: 2/2, step 23153/23838 completed (loss: 0.6387425661087036, acc: 0.8267716765403748)
[2025-02-04 03:09:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23155/23838 [32:56<04:00,  2.84it/s][2025-02-04 03:09:45][root][INFO] - Training Epoch: 2/2, step 23154/23838 completed (loss: 0.4533565640449524, acc: 0.8260869383811951)
[2025-02-04 03:09:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23156/23838 [32:56<03:50,  2.96it/s][2025-02-04 03:09:46][root][INFO] - Training Epoch: 2/2, step 23155/23838 completed (loss: 0.43624383211135864, acc: 0.8363636136054993)
[2025-02-04 03:09:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23157/23838 [32:57<03:52,  2.93it/s][2025-02-04 03:09:46][root][INFO] - Training Epoch: 2/2, step 23156/23838 completed (loss: 0.8037691712379456, acc: 0.761904776096344)
[2025-02-04 03:09:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23158/23838 [32:57<03:56,  2.87it/s][2025-02-04 03:09:47][root][INFO] - Training Epoch: 2/2, step 23157/23838 completed (loss: 0.4039572477340698, acc: 0.8817204236984253)
[2025-02-04 03:09:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23159/23838 [32:57<03:49,  2.96it/s][2025-02-04 03:09:47][root][INFO] - Training Epoch: 2/2, step 23158/23838 completed (loss: 0.4511244595050812, acc: 0.8857142925262451)
[2025-02-04 03:09:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23160/23838 [32:58<03:44,  3.02it/s][2025-02-04 03:09:47][root][INFO] - Training Epoch: 2/2, step 23159/23838 completed (loss: 0.23663978278636932, acc: 0.9482758641242981)
[2025-02-04 03:09:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23161/23838 [32:58<03:40,  3.07it/s][2025-02-04 03:09:47][root][INFO] - Training Epoch: 2/2, step 23160/23838 completed (loss: 0.152444526553154, acc: 0.9487179517745972)
[2025-02-04 03:09:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23162/23838 [32:58<03:38,  3.10it/s][2025-02-04 03:09:48][root][INFO] - Training Epoch: 2/2, step 23161/23838 completed (loss: 0.24116696417331696, acc: 0.931506872177124)
[2025-02-04 03:09:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23163/23838 [32:59<03:43,  3.02it/s][2025-02-04 03:09:48][root][INFO] - Training Epoch: 2/2, step 23162/23838 completed (loss: 0.22315023839473724, acc: 0.9595959782600403)
[2025-02-04 03:09:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23164/23838 [32:59<03:47,  2.97it/s][2025-02-04 03:09:48][root][INFO] - Training Epoch: 2/2, step 23163/23838 completed (loss: 0.35779711604118347, acc: 0.9298245906829834)
[2025-02-04 03:09:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23165/23838 [32:59<03:43,  3.02it/s][2025-02-04 03:09:49][root][INFO] - Training Epoch: 2/2, step 23164/23838 completed (loss: 0.41008415818214417, acc: 0.875)
[2025-02-04 03:09:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23166/23838 [33:00<03:53,  2.87it/s][2025-02-04 03:09:49][root][INFO] - Training Epoch: 2/2, step 23165/23838 completed (loss: 0.4326804578304291, acc: 0.868686854839325)
[2025-02-04 03:09:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23167/23838 [33:00<04:09,  2.69it/s][2025-02-04 03:09:50][root][INFO] - Training Epoch: 2/2, step 23166/23838 completed (loss: 0.10246433317661285, acc: 0.9871794581413269)
[2025-02-04 03:09:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23168/23838 [33:00<04:03,  2.75it/s][2025-02-04 03:09:50][root][INFO] - Training Epoch: 2/2, step 23167/23838 completed (loss: 0.6764024496078491, acc: 0.7865168452262878)
[2025-02-04 03:09:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23169/23838 [33:01<03:55,  2.84it/s][2025-02-04 03:09:50][root][INFO] - Training Epoch: 2/2, step 23168/23838 completed (loss: 0.26859134435653687, acc: 0.942307710647583)
[2025-02-04 03:09:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23170/23838 [33:01<03:56,  2.83it/s][2025-02-04 03:09:51][root][INFO] - Training Epoch: 2/2, step 23169/23838 completed (loss: 0.3536588251590729, acc: 0.8867924809455872)
[2025-02-04 03:09:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23171/23838 [33:01<03:50,  2.90it/s][2025-02-04 03:09:51][root][INFO] - Training Epoch: 2/2, step 23170/23838 completed (loss: 0.10034893453121185, acc: 0.9764705896377563)
[2025-02-04 03:09:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23172/23838 [33:02<04:10,  2.66it/s][2025-02-04 03:09:51][root][INFO] - Training Epoch: 2/2, step 23171/23838 completed (loss: 0.43284639716148376, acc: 0.8902438879013062)
[2025-02-04 03:09:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23173/23838 [33:02<04:04,  2.72it/s][2025-02-04 03:09:52][root][INFO] - Training Epoch: 2/2, step 23172/23838 completed (loss: 0.128254234790802, acc: 0.9596773982048035)
[2025-02-04 03:09:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23174/23838 [33:03<03:59,  2.77it/s][2025-02-04 03:09:52][root][INFO] - Training Epoch: 2/2, step 23173/23838 completed (loss: 0.2013014703989029, acc: 0.9459459185600281)
[2025-02-04 03:09:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23175/23838 [33:03<03:55,  2.81it/s][2025-02-04 03:09:52][root][INFO] - Training Epoch: 2/2, step 23174/23838 completed (loss: 0.12761740386486053, acc: 0.9569892287254333)
[2025-02-04 03:09:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23176/23838 [33:03<03:56,  2.79it/s][2025-02-04 03:09:53][root][INFO] - Training Epoch: 2/2, step 23175/23838 completed (loss: 0.09643913060426712, acc: 0.95652174949646)
[2025-02-04 03:09:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23177/23838 [33:04<03:52,  2.85it/s][2025-02-04 03:09:53][root][INFO] - Training Epoch: 2/2, step 23176/23838 completed (loss: 0.29604053497314453, acc: 0.90625)
[2025-02-04 03:09:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23178/23838 [33:04<03:53,  2.83it/s][2025-02-04 03:09:54][root][INFO] - Training Epoch: 2/2, step 23177/23838 completed (loss: 0.5508710145950317, acc: 0.8717948794364929)
[2025-02-04 03:09:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23179/23838 [33:04<03:47,  2.90it/s][2025-02-04 03:09:54][root][INFO] - Training Epoch: 2/2, step 23178/23838 completed (loss: 0.41185566782951355, acc: 0.849056601524353)
[2025-02-04 03:09:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23180/23838 [33:05<03:46,  2.90it/s][2025-02-04 03:09:54][root][INFO] - Training Epoch: 2/2, step 23179/23838 completed (loss: 0.22028350830078125, acc: 0.9296875)
[2025-02-04 03:09:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23181/23838 [33:05<03:55,  2.79it/s][2025-02-04 03:09:55][root][INFO] - Training Epoch: 2/2, step 23180/23838 completed (loss: 0.5554940104484558, acc: 0.824999988079071)
[2025-02-04 03:09:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23182/23838 [33:05<03:56,  2.77it/s][2025-02-04 03:09:55][root][INFO] - Training Epoch: 2/2, step 23181/23838 completed (loss: 0.5799885392189026, acc: 0.8571428656578064)
[2025-02-04 03:09:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23183/23838 [33:06<04:04,  2.68it/s][2025-02-04 03:09:55][root][INFO] - Training Epoch: 2/2, step 23182/23838 completed (loss: 0.33049413561820984, acc: 0.9364162087440491)
[2025-02-04 03:09:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23184/23838 [33:06<04:03,  2.69it/s][2025-02-04 03:09:56][root][INFO] - Training Epoch: 2/2, step 23183/23838 completed (loss: 0.2536718547344208, acc: 0.9275362491607666)
[2025-02-04 03:09:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23185/23838 [33:06<04:03,  2.68it/s][2025-02-04 03:09:56][root][INFO] - Training Epoch: 2/2, step 23184/23838 completed (loss: 0.4347633123397827, acc: 0.8759689927101135)
[2025-02-04 03:09:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23186/23838 [33:07<04:04,  2.66it/s][2025-02-04 03:09:56][root][INFO] - Training Epoch: 2/2, step 23185/23838 completed (loss: 0.23531299829483032, acc: 0.9319371581077576)
[2025-02-04 03:09:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23187/23838 [33:07<04:01,  2.70it/s][2025-02-04 03:09:57][root][INFO] - Training Epoch: 2/2, step 23186/23838 completed (loss: 0.1687660664319992, acc: 0.9583333134651184)
[2025-02-04 03:09:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23188/23838 [33:08<03:56,  2.75it/s][2025-02-04 03:09:57][root][INFO] - Training Epoch: 2/2, step 23187/23838 completed (loss: 0.2919160723686218, acc: 0.9214285612106323)
[2025-02-04 03:09:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23189/23838 [33:08<03:47,  2.85it/s][2025-02-04 03:09:57][root][INFO] - Training Epoch: 2/2, step 23188/23838 completed (loss: 0.15612556040287018, acc: 0.9561403393745422)
[2025-02-04 03:09:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23190/23838 [33:08<03:43,  2.90it/s][2025-02-04 03:09:58][root][INFO] - Training Epoch: 2/2, step 23189/23838 completed (loss: 0.31358852982521057, acc: 0.939393937587738)
[2025-02-04 03:09:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23191/23838 [33:09<03:41,  2.92it/s][2025-02-04 03:09:58][root][INFO] - Training Epoch: 2/2, step 23190/23838 completed (loss: 0.7088897228240967, acc: 0.8133333325386047)
[2025-02-04 03:09:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23192/23838 [33:09<03:55,  2.74it/s][2025-02-04 03:09:59][root][INFO] - Training Epoch: 2/2, step 23191/23838 completed (loss: 0.1865779161453247, acc: 0.9494949579238892)
[2025-02-04 03:09:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23193/23838 [33:09<03:57,  2.71it/s][2025-02-04 03:09:59][root][INFO] - Training Epoch: 2/2, step 23192/23838 completed (loss: 0.6343106031417847, acc: 0.800000011920929)
[2025-02-04 03:09:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23194/23838 [33:10<04:00,  2.67it/s][2025-02-04 03:09:59][root][INFO] - Training Epoch: 2/2, step 23193/23838 completed (loss: 0.7619110941886902, acc: 0.790123462677002)
[2025-02-04 03:09:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23195/23838 [33:10<04:01,  2.66it/s][2025-02-04 03:10:00][root][INFO] - Training Epoch: 2/2, step 23194/23838 completed (loss: 0.5950638055801392, acc: 0.8039215803146362)
[2025-02-04 03:10:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23196/23838 [33:11<04:11,  2.55it/s][2025-02-04 03:10:00][root][INFO] - Training Epoch: 2/2, step 23195/23838 completed (loss: 0.28982675075531006, acc: 0.9239130616188049)
[2025-02-04 03:10:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23197/23838 [33:11<04:24,  2.42it/s][2025-02-04 03:10:01][root][INFO] - Training Epoch: 2/2, step 23196/23838 completed (loss: 0.3425927758216858, acc: 0.8888888955116272)
[2025-02-04 03:10:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23198/23838 [33:11<04:19,  2.47it/s][2025-02-04 03:10:01][root][INFO] - Training Epoch: 2/2, step 23197/23838 completed (loss: 0.48945435881614685, acc: 0.8421052694320679)
[2025-02-04 03:10:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23199/23838 [33:12<04:23,  2.43it/s][2025-02-04 03:10:01][root][INFO] - Training Epoch: 2/2, step 23198/23838 completed (loss: 0.3730414807796478, acc: 0.8811880946159363)
[2025-02-04 03:10:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23200/23838 [33:12<04:13,  2.52it/s][2025-02-04 03:10:02][root][INFO] - Training Epoch: 2/2, step 23199/23838 completed (loss: 0.2089785486459732, acc: 0.9340659379959106)
[2025-02-04 03:10:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23201/23838 [33:12<03:50,  2.76it/s][2025-02-04 03:10:02][root][INFO] - Training Epoch: 2/2, step 23200/23838 completed (loss: 0.33586031198501587, acc: 0.9256198406219482)
[2025-02-04 03:10:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23202/23838 [33:13<03:40,  2.89it/s][2025-02-04 03:10:02][root][INFO] - Training Epoch: 2/2, step 23201/23838 completed (loss: 0.49424344301223755, acc: 0.8484848737716675)
[2025-02-04 03:10:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23203/23838 [33:13<03:50,  2.75it/s][2025-02-04 03:10:03][root][INFO] - Training Epoch: 2/2, step 23202/23838 completed (loss: 0.3475929796695709, acc: 0.902255654335022)
[2025-02-04 03:10:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23204/23838 [33:14<03:47,  2.78it/s][2025-02-04 03:10:03][root][INFO] - Training Epoch: 2/2, step 23203/23838 completed (loss: 0.7521239519119263, acc: 0.7818182110786438)
[2025-02-04 03:10:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23205/23838 [33:14<03:44,  2.81it/s][2025-02-04 03:10:03][root][INFO] - Training Epoch: 2/2, step 23204/23838 completed (loss: 0.7504114508628845, acc: 0.790123462677002)
[2025-02-04 03:10:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23206/23838 [33:14<03:32,  2.98it/s][2025-02-04 03:10:04][root][INFO] - Training Epoch: 2/2, step 23205/23838 completed (loss: 0.36666399240493774, acc: 0.8730158805847168)
[2025-02-04 03:10:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23207/23838 [33:15<03:51,  2.73it/s][2025-02-04 03:10:04][root][INFO] - Training Epoch: 2/2, step 23206/23838 completed (loss: 0.5853337049484253, acc: 0.8333333134651184)
[2025-02-04 03:10:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23208/23838 [33:15<03:54,  2.68it/s][2025-02-04 03:10:05][root][INFO] - Training Epoch: 2/2, step 23207/23838 completed (loss: 0.447133332490921, acc: 0.8873239159584045)
[2025-02-04 03:10:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23209/23838 [33:15<03:57,  2.65it/s][2025-02-04 03:10:05][root][INFO] - Training Epoch: 2/2, step 23208/23838 completed (loss: 0.5230046510696411, acc: 0.84375)
[2025-02-04 03:10:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23210/23838 [33:16<03:54,  2.67it/s][2025-02-04 03:10:05][root][INFO] - Training Epoch: 2/2, step 23209/23838 completed (loss: 0.3615190088748932, acc: 0.8666666746139526)
[2025-02-04 03:10:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23211/23838 [33:16<03:53,  2.68it/s][2025-02-04 03:10:06][root][INFO] - Training Epoch: 2/2, step 23210/23838 completed (loss: 0.0767330601811409, acc: 0.9837398529052734)
[2025-02-04 03:10:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23212/23838 [33:16<03:48,  2.74it/s][2025-02-04 03:10:06][root][INFO] - Training Epoch: 2/2, step 23211/23838 completed (loss: 0.5612996816635132, acc: 0.8428571224212646)
[2025-02-04 03:10:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23213/23838 [33:17<03:49,  2.73it/s][2025-02-04 03:10:06][root][INFO] - Training Epoch: 2/2, step 23212/23838 completed (loss: 0.5066317915916443, acc: 0.8636363744735718)
[2025-02-04 03:10:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23214/23838 [33:17<03:33,  2.93it/s][2025-02-04 03:10:07][root][INFO] - Training Epoch: 2/2, step 23213/23838 completed (loss: 0.6012759208679199, acc: 0.8243243098258972)
[2025-02-04 03:10:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23215/23838 [33:17<03:29,  2.98it/s][2025-02-04 03:10:07][root][INFO] - Training Epoch: 2/2, step 23214/23838 completed (loss: 0.15980719029903412, acc: 0.9230769276618958)
[2025-02-04 03:10:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23216/23838 [33:18<03:30,  2.96it/s][2025-02-04 03:10:07][root][INFO] - Training Epoch: 2/2, step 23215/23838 completed (loss: 0.5845494270324707, acc: 0.8181818127632141)
[2025-02-04 03:10:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23217/23838 [33:18<03:36,  2.87it/s][2025-02-04 03:10:08][root][INFO] - Training Epoch: 2/2, step 23216/23838 completed (loss: 0.41392359137535095, acc: 0.8728813529014587)
[2025-02-04 03:10:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23218/23838 [33:18<03:30,  2.95it/s][2025-02-04 03:10:08][root][INFO] - Training Epoch: 2/2, step 23217/23838 completed (loss: 0.1507938653230667, acc: 0.9532710313796997)
[2025-02-04 03:10:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23219/23838 [33:19<03:47,  2.72it/s][2025-02-04 03:10:08][root][INFO] - Training Epoch: 2/2, step 23218/23838 completed (loss: 0.3912009000778198, acc: 0.8760330677032471)
[2025-02-04 03:10:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23220/23838 [33:19<04:00,  2.57it/s][2025-02-04 03:10:09][root][INFO] - Training Epoch: 2/2, step 23219/23838 completed (loss: 0.5067257285118103, acc: 0.8363636136054993)
[2025-02-04 03:10:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23221/23838 [33:20<03:54,  2.63it/s][2025-02-04 03:10:09][root][INFO] - Training Epoch: 2/2, step 23220/23838 completed (loss: 0.394780695438385, acc: 0.9047619104385376)
[2025-02-04 03:10:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23222/23838 [33:20<03:56,  2.60it/s][2025-02-04 03:10:10][root][INFO] - Training Epoch: 2/2, step 23221/23838 completed (loss: 0.5234227180480957, acc: 0.8374999761581421)
[2025-02-04 03:10:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23223/23838 [33:20<03:57,  2.59it/s][2025-02-04 03:10:10][root][INFO] - Training Epoch: 2/2, step 23222/23838 completed (loss: 0.22458986937999725, acc: 0.9238095283508301)
[2025-02-04 03:10:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23224/23838 [33:21<04:07,  2.48it/s][2025-02-04 03:10:11][root][INFO] - Training Epoch: 2/2, step 23223/23838 completed (loss: 0.19006624817848206, acc: 0.9552238583564758)
[2025-02-04 03:10:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23225/23838 [33:21<04:19,  2.37it/s][2025-02-04 03:10:11][root][INFO] - Training Epoch: 2/2, step 23224/23838 completed (loss: 0.18323878943920135, acc: 0.930232584476471)
[2025-02-04 03:10:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23226/23838 [33:22<04:22,  2.33it/s][2025-02-04 03:10:11][root][INFO] - Training Epoch: 2/2, step 23225/23838 completed (loss: 0.5299482345581055, acc: 0.8285714387893677)
[2025-02-04 03:10:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23227/23838 [33:22<04:11,  2.43it/s][2025-02-04 03:10:12][root][INFO] - Training Epoch: 2/2, step 23226/23838 completed (loss: 0.6019763350486755, acc: 0.8260869383811951)
[2025-02-04 03:10:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23228/23838 [33:23<04:01,  2.53it/s][2025-02-04 03:10:12][root][INFO] - Training Epoch: 2/2, step 23227/23838 completed (loss: 0.41011160612106323, acc: 0.9137930870056152)
[2025-02-04 03:10:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23229/23838 [33:23<03:58,  2.55it/s][2025-02-04 03:10:13][root][INFO] - Training Epoch: 2/2, step 23228/23838 completed (loss: 0.4982415437698364, acc: 0.8620689511299133)
[2025-02-04 03:10:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23230/23838 [33:23<03:47,  2.67it/s][2025-02-04 03:10:13][root][INFO] - Training Epoch: 2/2, step 23229/23838 completed (loss: 0.2635822296142578, acc: 0.9255319237709045)
[2025-02-04 03:10:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23231/23838 [33:24<03:51,  2.62it/s][2025-02-04 03:10:13][root][INFO] - Training Epoch: 2/2, step 23230/23838 completed (loss: 0.3325534760951996, acc: 0.8818897604942322)
[2025-02-04 03:10:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23232/23838 [33:24<03:33,  2.84it/s][2025-02-04 03:10:14][root][INFO] - Training Epoch: 2/2, step 23231/23838 completed (loss: 0.7596614956855774, acc: 0.8159999847412109)
[2025-02-04 03:10:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23233/23838 [33:24<03:28,  2.90it/s][2025-02-04 03:10:14][root][INFO] - Training Epoch: 2/2, step 23232/23838 completed (loss: 0.6570043563842773, acc: 0.8181818127632141)
[2025-02-04 03:10:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23234/23838 [33:25<03:36,  2.79it/s][2025-02-04 03:10:14][root][INFO] - Training Epoch: 2/2, step 23233/23838 completed (loss: 0.05935031920671463, acc: 0.9914529919624329)
[2025-02-04 03:10:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23235/23838 [33:25<03:35,  2.79it/s][2025-02-04 03:10:15][root][INFO] - Training Epoch: 2/2, step 23234/23838 completed (loss: 0.3128872215747833, acc: 0.9009901285171509)
[2025-02-04 03:10:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23236/23838 [33:25<03:27,  2.90it/s][2025-02-04 03:10:15][root][INFO] - Training Epoch: 2/2, step 23235/23838 completed (loss: 0.2365065962076187, acc: 0.9390243887901306)
[2025-02-04 03:10:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23237/23838 [33:26<03:30,  2.85it/s][2025-02-04 03:10:15][root][INFO] - Training Epoch: 2/2, step 23236/23838 completed (loss: 0.3982658088207245, acc: 0.8636363744735718)
[2025-02-04 03:10:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23238/23838 [33:26<03:27,  2.89it/s][2025-02-04 03:10:16][root][INFO] - Training Epoch: 2/2, step 23237/23838 completed (loss: 0.5226660370826721, acc: 0.8449612259864807)
[2025-02-04 03:10:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23239/23838 [33:26<03:32,  2.82it/s][2025-02-04 03:10:16][root][INFO] - Training Epoch: 2/2, step 23238/23838 completed (loss: 0.6760959625244141, acc: 0.828125)
[2025-02-04 03:10:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23240/23838 [33:27<03:29,  2.85it/s][2025-02-04 03:10:16][root][INFO] - Training Epoch: 2/2, step 23239/23838 completed (loss: 0.7047346830368042, acc: 0.8503937125205994)
[2025-02-04 03:10:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23241/23838 [33:27<03:26,  2.90it/s][2025-02-04 03:10:17][root][INFO] - Training Epoch: 2/2, step 23240/23838 completed (loss: 0.4802601635456085, acc: 0.868852436542511)
[2025-02-04 03:10:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  97%|[34m█████████▋[0m| 23242/23838 [33:27<03:27,  2.88it/s][2025-02-04 03:10:17][root][INFO] - Training Epoch: 2/2, step 23241/23838 completed (loss: 0.16073574125766754, acc: 0.949999988079071)
[2025-02-04 03:10:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23243/23838 [33:28<03:37,  2.73it/s][2025-02-04 03:10:17][root][INFO] - Training Epoch: 2/2, step 23242/23838 completed (loss: 0.4793718755245209, acc: 0.8333333134651184)
[2025-02-04 03:10:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23244/23838 [33:28<03:36,  2.74it/s][2025-02-04 03:10:18][root][INFO] - Training Epoch: 2/2, step 23243/23838 completed (loss: 0.2713547646999359, acc: 0.9316239356994629)
[2025-02-04 03:10:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23245/23838 [33:29<03:36,  2.75it/s][2025-02-04 03:10:18][root][INFO] - Training Epoch: 2/2, step 23244/23838 completed (loss: 0.21271035075187683, acc: 0.960629940032959)
[2025-02-04 03:10:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23246/23838 [33:29<03:29,  2.83it/s][2025-02-04 03:10:19][root][INFO] - Training Epoch: 2/2, step 23245/23838 completed (loss: 0.21131476759910583, acc: 0.9197860956192017)
[2025-02-04 03:10:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23247/23838 [33:29<03:25,  2.88it/s][2025-02-04 03:10:19][root][INFO] - Training Epoch: 2/2, step 23246/23838 completed (loss: 0.23738251626491547, acc: 0.9328858852386475)
[2025-02-04 03:10:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23248/23838 [33:30<03:20,  2.94it/s][2025-02-04 03:10:19][root][INFO] - Training Epoch: 2/2, step 23247/23838 completed (loss: 0.23454488813877106, acc: 0.9572649598121643)
[2025-02-04 03:10:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23249/23838 [33:30<03:32,  2.77it/s][2025-02-04 03:10:20][root][INFO] - Training Epoch: 2/2, step 23248/23838 completed (loss: 0.45771488547325134, acc: 0.8679245114326477)
[2025-02-04 03:10:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23250/23838 [33:30<03:21,  2.91it/s][2025-02-04 03:10:20][root][INFO] - Training Epoch: 2/2, step 23249/23838 completed (loss: 0.46635496616363525, acc: 0.8793103694915771)
[2025-02-04 03:10:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23251/23838 [33:31<03:09,  3.09it/s][2025-02-04 03:10:20][root][INFO] - Training Epoch: 2/2, step 23250/23838 completed (loss: 0.19926956295967102, acc: 0.9279279112815857)
[2025-02-04 03:10:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23252/23838 [33:31<03:04,  3.17it/s][2025-02-04 03:10:20][root][INFO] - Training Epoch: 2/2, step 23251/23838 completed (loss: 0.4892822206020355, acc: 0.875)
[2025-02-04 03:10:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23253/23838 [33:31<03:04,  3.16it/s][2025-02-04 03:10:21][root][INFO] - Training Epoch: 2/2, step 23252/23838 completed (loss: 0.513034462928772, acc: 0.8602150678634644)
[2025-02-04 03:10:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23254/23838 [33:31<03:00,  3.24it/s][2025-02-04 03:10:21][root][INFO] - Training Epoch: 2/2, step 23253/23838 completed (loss: 0.259202778339386, acc: 0.8791208863258362)
[2025-02-04 03:10:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23255/23838 [33:32<03:09,  3.08it/s][2025-02-04 03:10:21][root][INFO] - Training Epoch: 2/2, step 23254/23838 completed (loss: 0.2668393552303314, acc: 0.9012345671653748)
[2025-02-04 03:10:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23256/23838 [33:32<03:13,  3.02it/s][2025-02-04 03:10:22][root][INFO] - Training Epoch: 2/2, step 23255/23838 completed (loss: 0.3419537842273712, acc: 0.903030276298523)
[2025-02-04 03:10:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23257/23838 [33:32<03:01,  3.20it/s][2025-02-04 03:10:22][root][INFO] - Training Epoch: 2/2, step 23256/23838 completed (loss: 0.7021193504333496, acc: 0.7536231875419617)
[2025-02-04 03:10:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23258/23838 [33:33<03:13,  2.99it/s][2025-02-04 03:10:22][root][INFO] - Training Epoch: 2/2, step 23257/23838 completed (loss: 0.7388714551925659, acc: 0.8166666626930237)
[2025-02-04 03:10:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23259/23838 [33:33<03:18,  2.91it/s][2025-02-04 03:10:23][root][INFO] - Training Epoch: 2/2, step 23258/23838 completed (loss: 0.5552924871444702, acc: 0.7840909361839294)
[2025-02-04 03:10:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23260/23838 [33:34<03:25,  2.81it/s][2025-02-04 03:10:23][root][INFO] - Training Epoch: 2/2, step 23259/23838 completed (loss: 0.43447786569595337, acc: 0.8653846383094788)
[2025-02-04 03:10:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23261/23838 [33:34<03:23,  2.84it/s][2025-02-04 03:10:24][root][INFO] - Training Epoch: 2/2, step 23260/23838 completed (loss: 0.39829733967781067, acc: 0.8709677457809448)
[2025-02-04 03:10:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23262/23838 [33:34<03:29,  2.74it/s][2025-02-04 03:10:24][root][INFO] - Training Epoch: 2/2, step 23261/23838 completed (loss: 0.320645272731781, acc: 0.8878504633903503)
[2025-02-04 03:10:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23263/23838 [33:35<03:35,  2.67it/s][2025-02-04 03:10:24][root][INFO] - Training Epoch: 2/2, step 23262/23838 completed (loss: 0.5361091494560242, acc: 0.8181818127632141)
[2025-02-04 03:10:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23264/23838 [33:35<03:32,  2.70it/s][2025-02-04 03:10:25][root][INFO] - Training Epoch: 2/2, step 23263/23838 completed (loss: 0.46356847882270813, acc: 0.8631578683853149)
[2025-02-04 03:10:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23265/23838 [33:35<03:28,  2.75it/s][2025-02-04 03:10:25][root][INFO] - Training Epoch: 2/2, step 23264/23838 completed (loss: 0.7609244585037231, acc: 0.8214285969734192)
[2025-02-04 03:10:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23266/23838 [33:36<03:25,  2.78it/s][2025-02-04 03:10:25][root][INFO] - Training Epoch: 2/2, step 23265/23838 completed (loss: 0.6928170323371887, acc: 0.767123281955719)
[2025-02-04 03:10:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23267/23838 [33:36<03:20,  2.85it/s][2025-02-04 03:10:26][root][INFO] - Training Epoch: 2/2, step 23266/23838 completed (loss: 0.4783448874950409, acc: 0.8604651093482971)
[2025-02-04 03:10:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23268/23838 [33:37<03:29,  2.71it/s][2025-02-04 03:10:26][root][INFO] - Training Epoch: 2/2, step 23267/23838 completed (loss: 0.7325578331947327, acc: 0.7684210538864136)
[2025-02-04 03:10:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23269/23838 [33:37<03:42,  2.56it/s][2025-02-04 03:10:27][root][INFO] - Training Epoch: 2/2, step 23268/23838 completed (loss: 0.5535315871238708, acc: 0.8999999761581421)
[2025-02-04 03:10:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23270/23838 [33:37<03:48,  2.49it/s][2025-02-04 03:10:27][root][INFO] - Training Epoch: 2/2, step 23269/23838 completed (loss: 0.4936227798461914, acc: 0.8472222089767456)
[2025-02-04 03:10:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23271/23838 [33:38<03:56,  2.39it/s][2025-02-04 03:10:27][root][INFO] - Training Epoch: 2/2, step 23270/23838 completed (loss: 0.22822150588035583, acc: 0.9320388436317444)
[2025-02-04 03:10:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23272/23838 [33:38<04:05,  2.30it/s][2025-02-04 03:10:28][root][INFO] - Training Epoch: 2/2, step 23271/23838 completed (loss: 0.5149019956588745, acc: 0.8292682766914368)
[2025-02-04 03:10:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23273/23838 [33:39<03:59,  2.36it/s][2025-02-04 03:10:28][root][INFO] - Training Epoch: 2/2, step 23272/23838 completed (loss: 0.7812197208404541, acc: 0.7857142686843872)
[2025-02-04 03:10:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23274/23838 [33:39<04:05,  2.29it/s][2025-02-04 03:10:29][root][INFO] - Training Epoch: 2/2, step 23273/23838 completed (loss: 0.5188360214233398, acc: 0.8350515365600586)
[2025-02-04 03:10:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23275/23838 [33:40<03:54,  2.40it/s][2025-02-04 03:10:29][root][INFO] - Training Epoch: 2/2, step 23274/23838 completed (loss: 0.7433140873908997, acc: 0.8275862336158752)
[2025-02-04 03:10:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23276/23838 [33:40<03:54,  2.40it/s][2025-02-04 03:10:30][root][INFO] - Training Epoch: 2/2, step 23275/23838 completed (loss: 0.5409176349639893, acc: 0.8857142925262451)
[2025-02-04 03:10:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23277/23838 [33:40<03:51,  2.42it/s][2025-02-04 03:10:30][root][INFO] - Training Epoch: 2/2, step 23276/23838 completed (loss: 0.5017455220222473, acc: 0.8541666865348816)
[2025-02-04 03:10:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23278/23838 [33:41<03:41,  2.53it/s][2025-02-04 03:10:30][root][INFO] - Training Epoch: 2/2, step 23277/23838 completed (loss: 0.7091137170791626, acc: 0.8275862336158752)
[2025-02-04 03:10:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23279/23838 [33:41<03:30,  2.65it/s][2025-02-04 03:10:31][root][INFO] - Training Epoch: 2/2, step 23278/23838 completed (loss: 0.4609359800815582, acc: 0.9041095972061157)
[2025-02-04 03:10:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23280/23838 [33:41<03:32,  2.62it/s][2025-02-04 03:10:31][root][INFO] - Training Epoch: 2/2, step 23279/23838 completed (loss: 0.9397090077400208, acc: 0.7575757503509521)
[2025-02-04 03:10:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23281/23838 [33:42<03:28,  2.67it/s][2025-02-04 03:10:31][root][INFO] - Training Epoch: 2/2, step 23280/23838 completed (loss: 0.5628798007965088, acc: 0.8720930218696594)
[2025-02-04 03:10:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23282/23838 [33:42<03:28,  2.67it/s][2025-02-04 03:10:32][root][INFO] - Training Epoch: 2/2, step 23281/23838 completed (loss: 0.6058898568153381, acc: 0.8095238208770752)
[2025-02-04 03:10:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23283/23838 [33:43<03:27,  2.67it/s][2025-02-04 03:10:32][root][INFO] - Training Epoch: 2/2, step 23282/23838 completed (loss: 0.40322089195251465, acc: 0.886956512928009)
[2025-02-04 03:10:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23284/23838 [33:43<03:28,  2.65it/s][2025-02-04 03:10:33][root][INFO] - Training Epoch: 2/2, step 23283/23838 completed (loss: 0.6248253583908081, acc: 0.8387096524238586)
[2025-02-04 03:10:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23285/23838 [33:43<03:18,  2.78it/s][2025-02-04 03:10:33][root][INFO] - Training Epoch: 2/2, step 23284/23838 completed (loss: 0.8022438883781433, acc: 0.7979797720909119)
[2025-02-04 03:10:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23286/23838 [33:44<03:14,  2.83it/s][2025-02-04 03:10:33][root][INFO] - Training Epoch: 2/2, step 23285/23838 completed (loss: 0.36959028244018555, acc: 0.9108911156654358)
[2025-02-04 03:10:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23287/23838 [33:44<03:10,  2.89it/s][2025-02-04 03:10:34][root][INFO] - Training Epoch: 2/2, step 23286/23838 completed (loss: 0.4160669445991516, acc: 0.8888888955116272)
[2025-02-04 03:10:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23288/23838 [33:44<03:22,  2.71it/s][2025-02-04 03:10:34][root][INFO] - Training Epoch: 2/2, step 23287/23838 completed (loss: 0.35520538687705994, acc: 0.8846153616905212)
[2025-02-04 03:10:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23289/23838 [33:45<03:14,  2.82it/s][2025-02-04 03:10:34][root][INFO] - Training Epoch: 2/2, step 23288/23838 completed (loss: 0.4122903645038605, acc: 0.8962963223457336)
[2025-02-04 03:10:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23290/23838 [33:45<03:11,  2.86it/s][2025-02-04 03:10:35][root][INFO] - Training Epoch: 2/2, step 23289/23838 completed (loss: 0.49175402522087097, acc: 0.8522727489471436)
[2025-02-04 03:10:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23291/23838 [33:45<03:21,  2.71it/s][2025-02-04 03:10:35][root][INFO] - Training Epoch: 2/2, step 23290/23838 completed (loss: 0.7761942148208618, acc: 0.84375)
[2025-02-04 03:10:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23292/23838 [33:46<03:21,  2.71it/s][2025-02-04 03:10:35][root][INFO] - Training Epoch: 2/2, step 23291/23838 completed (loss: 0.3058125078678131, acc: 0.907216489315033)
[2025-02-04 03:10:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23293/23838 [33:46<03:17,  2.76it/s][2025-02-04 03:10:36][root][INFO] - Training Epoch: 2/2, step 23292/23838 completed (loss: 0.634557843208313, acc: 0.8170731663703918)
[2025-02-04 03:10:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23294/23838 [33:46<03:11,  2.85it/s][2025-02-04 03:10:36][root][INFO] - Training Epoch: 2/2, step 23293/23838 completed (loss: 0.2878469228744507, acc: 0.930232584476471)
[2025-02-04 03:10:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23295/23838 [33:47<03:09,  2.86it/s][2025-02-04 03:10:36][root][INFO] - Training Epoch: 2/2, step 23294/23838 completed (loss: 0.36542797088623047, acc: 0.9065420627593994)
[2025-02-04 03:10:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23296/23838 [33:47<03:12,  2.82it/s][2025-02-04 03:10:37][root][INFO] - Training Epoch: 2/2, step 23295/23838 completed (loss: 0.32636868953704834, acc: 0.9142857193946838)
[2025-02-04 03:10:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23297/23838 [33:48<03:07,  2.89it/s][2025-02-04 03:10:37][root][INFO] - Training Epoch: 2/2, step 23296/23838 completed (loss: 0.7533252239227295, acc: 0.8421052694320679)
[2025-02-04 03:10:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23298/23838 [33:48<02:58,  3.02it/s][2025-02-04 03:10:37][root][INFO] - Training Epoch: 2/2, step 23297/23838 completed (loss: 0.3598172068595886, acc: 0.8918918967247009)
[2025-02-04 03:10:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23299/23838 [33:48<02:59,  3.00it/s][2025-02-04 03:10:38][root][INFO] - Training Epoch: 2/2, step 23298/23838 completed (loss: 0.1822604537010193, acc: 0.9386503100395203)
[2025-02-04 03:10:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23300/23838 [33:49<03:07,  2.87it/s][2025-02-04 03:10:38][root][INFO] - Training Epoch: 2/2, step 23299/23838 completed (loss: 0.2839329242706299, acc: 0.929347813129425)
[2025-02-04 03:10:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23301/23838 [33:49<03:16,  2.73it/s][2025-02-04 03:10:39][root][INFO] - Training Epoch: 2/2, step 23300/23838 completed (loss: 0.5250751972198486, acc: 0.8588235378265381)
[2025-02-04 03:10:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23302/23838 [33:49<03:21,  2.67it/s][2025-02-04 03:10:39][root][INFO] - Training Epoch: 2/2, step 23301/23838 completed (loss: 0.3317875564098358, acc: 0.9120000004768372)
[2025-02-04 03:10:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23303/23838 [33:50<03:20,  2.67it/s][2025-02-04 03:10:39][root][INFO] - Training Epoch: 2/2, step 23302/23838 completed (loss: 0.6652756333351135, acc: 0.7916666865348816)
[2025-02-04 03:10:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23304/23838 [33:50<03:31,  2.52it/s][2025-02-04 03:10:40][root][INFO] - Training Epoch: 2/2, step 23303/23838 completed (loss: 0.5073527097702026, acc: 0.8773584961891174)
[2025-02-04 03:10:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23305/23838 [33:50<03:22,  2.64it/s][2025-02-04 03:10:40][root][INFO] - Training Epoch: 2/2, step 23304/23838 completed (loss: 0.6158654093742371, acc: 0.841269850730896)
[2025-02-04 03:10:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23306/23838 [33:51<03:16,  2.70it/s][2025-02-04 03:10:40][root][INFO] - Training Epoch: 2/2, step 23305/23838 completed (loss: 0.4505143463611603, acc: 0.8736842274665833)
[2025-02-04 03:10:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23307/23838 [33:51<03:14,  2.73it/s][2025-02-04 03:10:41][root][INFO] - Training Epoch: 2/2, step 23306/23838 completed (loss: 0.41464224457740784, acc: 0.8809523582458496)
[2025-02-04 03:10:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23308/23838 [33:52<03:09,  2.80it/s][2025-02-04 03:10:41][root][INFO] - Training Epoch: 2/2, step 23307/23838 completed (loss: 0.35518544912338257, acc: 0.8846153616905212)
[2025-02-04 03:10:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23309/23838 [33:52<03:13,  2.73it/s][2025-02-04 03:10:42][root][INFO] - Training Epoch: 2/2, step 23308/23838 completed (loss: 0.3679109811782837, acc: 0.8952381014823914)
[2025-02-04 03:10:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23310/23838 [33:52<03:25,  2.57it/s][2025-02-04 03:10:42][root][INFO] - Training Epoch: 2/2, step 23309/23838 completed (loss: 0.14403153955936432, acc: 0.9682539701461792)
[2025-02-04 03:10:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23311/23838 [33:53<03:16,  2.68it/s][2025-02-04 03:10:42][root][INFO] - Training Epoch: 2/2, step 23310/23838 completed (loss: 0.4085533618927002, acc: 0.8695651888847351)
[2025-02-04 03:10:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23312/23838 [33:53<03:17,  2.66it/s][2025-02-04 03:10:43][root][INFO] - Training Epoch: 2/2, step 23311/23838 completed (loss: 0.41173163056373596, acc: 0.8928571343421936)
[2025-02-04 03:10:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23313/23838 [33:53<03:18,  2.64it/s][2025-02-04 03:10:43][root][INFO] - Training Epoch: 2/2, step 23312/23838 completed (loss: 0.680790901184082, acc: 0.8181818127632141)
[2025-02-04 03:10:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23314/23838 [33:54<03:19,  2.63it/s][2025-02-04 03:10:43][root][INFO] - Training Epoch: 2/2, step 23313/23838 completed (loss: 0.457686185836792, acc: 0.8965517282485962)
[2025-02-04 03:10:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23315/23838 [33:54<03:15,  2.67it/s][2025-02-04 03:10:44][root][INFO] - Training Epoch: 2/2, step 23314/23838 completed (loss: 0.3789510428905487, acc: 0.9032257795333862)
[2025-02-04 03:10:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23316/23838 [33:55<03:21,  2.59it/s][2025-02-04 03:10:44][root][INFO] - Training Epoch: 2/2, step 23315/23838 completed (loss: 0.40556854009628296, acc: 0.8684210777282715)
[2025-02-04 03:10:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23317/23838 [33:55<03:13,  2.70it/s][2025-02-04 03:10:45][root][INFO] - Training Epoch: 2/2, step 23316/23838 completed (loss: 0.25954630970954895, acc: 0.9439252614974976)
[2025-02-04 03:10:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23318/23838 [33:55<03:08,  2.76it/s][2025-02-04 03:10:45][root][INFO] - Training Epoch: 2/2, step 23317/23838 completed (loss: 0.7478387355804443, acc: 0.7849462628364563)
[2025-02-04 03:10:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23319/23838 [33:56<03:05,  2.79it/s][2025-02-04 03:10:45][root][INFO] - Training Epoch: 2/2, step 23318/23838 completed (loss: 0.6028494238853455, acc: 0.8440366983413696)
[2025-02-04 03:10:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23320/23838 [33:56<03:02,  2.83it/s][2025-02-04 03:10:46][root][INFO] - Training Epoch: 2/2, step 23319/23838 completed (loss: 0.3350803852081299, acc: 0.8870967626571655)
[2025-02-04 03:10:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23321/23838 [33:56<03:01,  2.85it/s][2025-02-04 03:10:46][root][INFO] - Training Epoch: 2/2, step 23320/23838 completed (loss: 0.4033315181732178, acc: 0.8846153616905212)
[2025-02-04 03:10:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23322/23838 [33:57<03:04,  2.80it/s][2025-02-04 03:10:46][root][INFO] - Training Epoch: 2/2, step 23321/23838 completed (loss: 0.37437546253204346, acc: 0.8983050584793091)
[2025-02-04 03:10:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23323/23838 [33:57<03:00,  2.85it/s][2025-02-04 03:10:47][root][INFO] - Training Epoch: 2/2, step 23322/23838 completed (loss: 0.18021497130393982, acc: 0.9452054500579834)
[2025-02-04 03:10:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23324/23838 [33:57<03:03,  2.80it/s][2025-02-04 03:10:47][root][INFO] - Training Epoch: 2/2, step 23323/23838 completed (loss: 0.5662144422531128, acc: 0.8039215803146362)
[2025-02-04 03:10:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23325/23838 [33:58<03:08,  2.72it/s][2025-02-04 03:10:47][root][INFO] - Training Epoch: 2/2, step 23324/23838 completed (loss: 0.3274787664413452, acc: 0.930232584476471)
[2025-02-04 03:10:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23326/23838 [33:58<03:06,  2.74it/s][2025-02-04 03:10:48][root][INFO] - Training Epoch: 2/2, step 23325/23838 completed (loss: 0.15220247209072113, acc: 0.9494949579238892)
[2025-02-04 03:10:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23327/23838 [33:59<03:21,  2.54it/s][2025-02-04 03:10:48][root][INFO] - Training Epoch: 2/2, step 23326/23838 completed (loss: 0.3008969724178314, acc: 0.9571428298950195)
[2025-02-04 03:10:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23328/23838 [33:59<03:18,  2.56it/s][2025-02-04 03:10:49][root][INFO] - Training Epoch: 2/2, step 23327/23838 completed (loss: 0.24208630621433258, acc: 0.9152542352676392)
[2025-02-04 03:10:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23329/23838 [33:59<03:24,  2.49it/s][2025-02-04 03:10:49][root][INFO] - Training Epoch: 2/2, step 23328/23838 completed (loss: 0.3974360525608063, acc: 0.8818897604942322)
[2025-02-04 03:10:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23330/23838 [34:00<03:31,  2.40it/s][2025-02-04 03:10:49][root][INFO] - Training Epoch: 2/2, step 23329/23838 completed (loss: 0.1734616905450821, acc: 0.9655172228813171)
[2025-02-04 03:10:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23331/23838 [34:00<03:22,  2.50it/s][2025-02-04 03:10:50][root][INFO] - Training Epoch: 2/2, step 23330/23838 completed (loss: 0.275374174118042, acc: 0.9417475461959839)
[2025-02-04 03:10:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23332/23838 [34:01<03:14,  2.60it/s][2025-02-04 03:10:50][root][INFO] - Training Epoch: 2/2, step 23331/23838 completed (loss: 0.2426842749118805, acc: 0.9496855139732361)
[2025-02-04 03:10:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23333/23838 [34:01<03:08,  2.69it/s][2025-02-04 03:10:51][root][INFO] - Training Epoch: 2/2, step 23332/23838 completed (loss: 0.5602452158927917, acc: 0.8709677457809448)
[2025-02-04 03:10:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23334/23838 [34:01<03:03,  2.74it/s][2025-02-04 03:10:51][root][INFO] - Training Epoch: 2/2, step 23333/23838 completed (loss: 0.7542471289634705, acc: 0.8442623019218445)
[2025-02-04 03:10:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23335/23838 [34:02<02:59,  2.81it/s][2025-02-04 03:10:51][root][INFO] - Training Epoch: 2/2, step 23334/23838 completed (loss: 0.531913161277771, acc: 0.887499988079071)
[2025-02-04 03:10:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23336/23838 [34:02<02:57,  2.83it/s][2025-02-04 03:10:52][root][INFO] - Training Epoch: 2/2, step 23335/23838 completed (loss: 0.12118194252252579, acc: 0.9801980257034302)
[2025-02-04 03:10:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23337/23838 [34:02<02:56,  2.84it/s][2025-02-04 03:10:52][root][INFO] - Training Epoch: 2/2, step 23336/23838 completed (loss: 0.5759415030479431, acc: 0.849056601524353)
[2025-02-04 03:10:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23338/23838 [34:03<02:56,  2.83it/s][2025-02-04 03:10:52][root][INFO] - Training Epoch: 2/2, step 23337/23838 completed (loss: 0.5278680920600891, acc: 0.8645833134651184)
[2025-02-04 03:10:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23339/23838 [34:03<02:54,  2.86it/s][2025-02-04 03:10:53][root][INFO] - Training Epoch: 2/2, step 23338/23838 completed (loss: 0.3440302908420563, acc: 0.8947368264198303)
[2025-02-04 03:10:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23340/23838 [34:03<02:50,  2.92it/s][2025-02-04 03:10:53][root][INFO] - Training Epoch: 2/2, step 23339/23838 completed (loss: 0.3005034029483795, acc: 0.890625)
[2025-02-04 03:10:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23341/23838 [34:04<02:50,  2.92it/s][2025-02-04 03:10:53][root][INFO] - Training Epoch: 2/2, step 23340/23838 completed (loss: 0.2615916430950165, acc: 0.9462365508079529)
[2025-02-04 03:10:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23342/23838 [34:04<03:02,  2.71it/s][2025-02-04 03:10:54][root][INFO] - Training Epoch: 2/2, step 23341/23838 completed (loss: 0.28885239362716675, acc: 0.8918918967247009)
[2025-02-04 03:10:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23343/23838 [34:04<03:03,  2.70it/s][2025-02-04 03:10:54][root][INFO] - Training Epoch: 2/2, step 23342/23838 completed (loss: 0.6661232709884644, acc: 0.8367347121238708)
[2025-02-04 03:10:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23344/23838 [34:05<02:59,  2.75it/s][2025-02-04 03:10:54][root][INFO] - Training Epoch: 2/2, step 23343/23838 completed (loss: 0.5355051755905151, acc: 0.8194444179534912)
[2025-02-04 03:10:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23345/23838 [34:05<02:56,  2.80it/s][2025-02-04 03:10:55][root][INFO] - Training Epoch: 2/2, step 23344/23838 completed (loss: 0.38394907116889954, acc: 0.9032257795333862)
[2025-02-04 03:10:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23346/23838 [34:06<02:49,  2.89it/s][2025-02-04 03:10:55][root][INFO] - Training Epoch: 2/2, step 23345/23838 completed (loss: 0.40836837887763977, acc: 0.8896551728248596)
[2025-02-04 03:10:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23347/23838 [34:06<02:52,  2.85it/s][2025-02-04 03:10:55][root][INFO] - Training Epoch: 2/2, step 23346/23838 completed (loss: 0.2679474353790283, acc: 0.9100000262260437)
[2025-02-04 03:10:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23348/23838 [34:06<02:58,  2.75it/s][2025-02-04 03:10:56][root][INFO] - Training Epoch: 2/2, step 23347/23838 completed (loss: 0.42334356904029846, acc: 0.8571428656578064)
[2025-02-04 03:10:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23349/23838 [34:07<02:57,  2.76it/s][2025-02-04 03:10:56][root][INFO] - Training Epoch: 2/2, step 23348/23838 completed (loss: 0.299015074968338, acc: 0.9173553586006165)
[2025-02-04 03:10:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23350/23838 [34:07<02:59,  2.72it/s][2025-02-04 03:10:57][root][INFO] - Training Epoch: 2/2, step 23349/23838 completed (loss: 0.6788603067398071, acc: 0.7903226017951965)
[2025-02-04 03:10:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23351/23838 [34:07<02:58,  2.72it/s][2025-02-04 03:10:57][root][INFO] - Training Epoch: 2/2, step 23350/23838 completed (loss: 0.37224164605140686, acc: 0.8834951519966125)
[2025-02-04 03:10:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23352/23838 [34:08<02:58,  2.73it/s][2025-02-04 03:10:57][root][INFO] - Training Epoch: 2/2, step 23351/23838 completed (loss: 0.306358277797699, acc: 0.9196428656578064)
[2025-02-04 03:10:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23353/23838 [34:08<03:04,  2.63it/s][2025-02-04 03:10:58][root][INFO] - Training Epoch: 2/2, step 23352/23838 completed (loss: 0.46650558710098267, acc: 0.8740741014480591)
[2025-02-04 03:10:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23354/23838 [34:08<02:56,  2.74it/s][2025-02-04 03:10:58][root][INFO] - Training Epoch: 2/2, step 23353/23838 completed (loss: 0.6738638877868652, acc: 0.8220338821411133)
[2025-02-04 03:10:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23355/23838 [34:09<02:42,  2.97it/s][2025-02-04 03:10:58][root][INFO] - Training Epoch: 2/2, step 23354/23838 completed (loss: 0.41076377034187317, acc: 0.8823529481887817)
[2025-02-04 03:10:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23356/23838 [34:09<02:37,  3.06it/s][2025-02-04 03:10:59][root][INFO] - Training Epoch: 2/2, step 23355/23838 completed (loss: 0.371175616979599, acc: 0.8970588445663452)
[2025-02-04 03:10:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23357/23838 [34:09<02:46,  2.88it/s][2025-02-04 03:10:59][root][INFO] - Training Epoch: 2/2, step 23356/23838 completed (loss: 0.10927313566207886, acc: 0.9622641801834106)
[2025-02-04 03:10:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23358/23838 [34:10<02:38,  3.03it/s][2025-02-04 03:10:59][root][INFO] - Training Epoch: 2/2, step 23357/23838 completed (loss: 0.37257716059684753, acc: 0.8764045238494873)
[2025-02-04 03:10:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23359/23838 [34:10<02:39,  3.01it/s][2025-02-04 03:11:00][root][INFO] - Training Epoch: 2/2, step 23358/23838 completed (loss: 0.1335817128419876, acc: 0.9649122953414917)
[2025-02-04 03:11:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23360/23838 [34:10<02:42,  2.94it/s][2025-02-04 03:11:00][root][INFO] - Training Epoch: 2/2, step 23359/23838 completed (loss: 0.16802160441875458, acc: 0.9415584206581116)
[2025-02-04 03:11:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23361/23838 [34:11<02:40,  2.98it/s][2025-02-04 03:11:00][root][INFO] - Training Epoch: 2/2, step 23360/23838 completed (loss: 0.2573891580104828, acc: 0.930232584476471)
[2025-02-04 03:11:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23362/23838 [34:11<02:44,  2.90it/s][2025-02-04 03:11:01][root][INFO] - Training Epoch: 2/2, step 23361/23838 completed (loss: 0.35904815793037415, acc: 0.8950276374816895)
[2025-02-04 03:11:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23363/23838 [34:11<02:46,  2.85it/s][2025-02-04 03:11:01][root][INFO] - Training Epoch: 2/2, step 23362/23838 completed (loss: 0.3368336260318756, acc: 0.8860759735107422)
[2025-02-04 03:11:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23364/23838 [34:12<02:55,  2.69it/s][2025-02-04 03:11:01][root][INFO] - Training Epoch: 2/2, step 23363/23838 completed (loss: 0.42714473605155945, acc: 0.8976377844810486)
[2025-02-04 03:11:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23365/23838 [34:12<02:54,  2.71it/s][2025-02-04 03:11:02][root][INFO] - Training Epoch: 2/2, step 23364/23838 completed (loss: 0.7804977297782898, acc: 0.7971014380455017)
[2025-02-04 03:11:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23366/23838 [34:13<02:54,  2.70it/s][2025-02-04 03:11:02][root][INFO] - Training Epoch: 2/2, step 23365/23838 completed (loss: 0.27292659878730774, acc: 0.9298245906829834)
[2025-02-04 03:11:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23367/23838 [34:13<02:43,  2.88it/s][2025-02-04 03:11:03][root][INFO] - Training Epoch: 2/2, step 23366/23838 completed (loss: 0.4789186418056488, acc: 0.8796296119689941)
[2025-02-04 03:11:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23368/23838 [34:13<02:45,  2.84it/s][2025-02-04 03:11:03][root][INFO] - Training Epoch: 2/2, step 23367/23838 completed (loss: 0.3882543444633484, acc: 0.9139072895050049)
[2025-02-04 03:11:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23369/23838 [34:14<02:43,  2.87it/s][2025-02-04 03:11:03][root][INFO] - Training Epoch: 2/2, step 23368/23838 completed (loss: 0.5956063866615295, acc: 0.7848101258277893)
[2025-02-04 03:11:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23370/23838 [34:14<02:41,  2.89it/s][2025-02-04 03:11:04][root][INFO] - Training Epoch: 2/2, step 23369/23838 completed (loss: 0.3274414837360382, acc: 0.8928571343421936)
[2025-02-04 03:11:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23371/23838 [34:14<02:44,  2.83it/s][2025-02-04 03:11:04][root][INFO] - Training Epoch: 2/2, step 23370/23838 completed (loss: 0.3091583251953125, acc: 0.9078947305679321)
[2025-02-04 03:11:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23372/23838 [34:15<02:48,  2.76it/s][2025-02-04 03:11:04][root][INFO] - Training Epoch: 2/2, step 23371/23838 completed (loss: 0.5458999276161194, acc: 0.875)
[2025-02-04 03:11:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23373/23838 [34:15<02:57,  2.62it/s][2025-02-04 03:11:05][root][INFO] - Training Epoch: 2/2, step 23372/23838 completed (loss: 0.4620438516139984, acc: 0.8533333539962769)
[2025-02-04 03:11:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23374/23838 [34:16<02:59,  2.59it/s][2025-02-04 03:11:05][root][INFO] - Training Epoch: 2/2, step 23373/23838 completed (loss: 0.10002953559160233, acc: 0.9824561476707458)
[2025-02-04 03:11:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23375/23838 [34:16<02:59,  2.58it/s][2025-02-04 03:11:06][root][INFO] - Training Epoch: 2/2, step 23374/23838 completed (loss: 0.13481564819812775, acc: 0.98591548204422)
[2025-02-04 03:11:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23376/23838 [34:16<02:55,  2.63it/s][2025-02-04 03:11:06][root][INFO] - Training Epoch: 2/2, step 23375/23838 completed (loss: 0.32875144481658936, acc: 0.8907563090324402)
[2025-02-04 03:11:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23377/23838 [34:17<02:56,  2.61it/s][2025-02-04 03:11:06][root][INFO] - Training Epoch: 2/2, step 23376/23838 completed (loss: 0.3637222647666931, acc: 0.9100000262260437)
[2025-02-04 03:11:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23378/23838 [34:17<02:53,  2.65it/s][2025-02-04 03:11:07][root][INFO] - Training Epoch: 2/2, step 23377/23838 completed (loss: 0.2769777476787567, acc: 0.9120000004768372)
[2025-02-04 03:11:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23379/23838 [34:17<02:55,  2.62it/s][2025-02-04 03:11:07][root][INFO] - Training Epoch: 2/2, step 23378/23838 completed (loss: 0.3676941990852356, acc: 0.8660714030265808)
[2025-02-04 03:11:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23380/23838 [34:18<02:49,  2.70it/s][2025-02-04 03:11:07][root][INFO] - Training Epoch: 2/2, step 23379/23838 completed (loss: 0.30885666608810425, acc: 0.918749988079071)
[2025-02-04 03:11:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23381/23838 [34:18<02:46,  2.74it/s][2025-02-04 03:11:08][root][INFO] - Training Epoch: 2/2, step 23380/23838 completed (loss: 0.22392620146274567, acc: 0.9142857193946838)
[2025-02-04 03:11:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23382/23838 [34:18<02:43,  2.78it/s][2025-02-04 03:11:08][root][INFO] - Training Epoch: 2/2, step 23381/23838 completed (loss: 0.11966739594936371, acc: 0.960629940032959)
[2025-02-04 03:11:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23383/23838 [34:19<02:51,  2.66it/s][2025-02-04 03:11:08][root][INFO] - Training Epoch: 2/2, step 23382/23838 completed (loss: 0.26741793751716614, acc: 0.9191176295280457)
[2025-02-04 03:11:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23384/23838 [34:19<02:49,  2.68it/s][2025-02-04 03:11:09][root][INFO] - Training Epoch: 2/2, step 23383/23838 completed (loss: 0.1732521653175354, acc: 0.9438202381134033)
[2025-02-04 03:11:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23385/23838 [34:20<02:40,  2.81it/s][2025-02-04 03:11:09][root][INFO] - Training Epoch: 2/2, step 23384/23838 completed (loss: 0.5528135299682617, acc: 0.8376068472862244)
[2025-02-04 03:11:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23386/23838 [34:20<02:34,  2.93it/s][2025-02-04 03:11:09][root][INFO] - Training Epoch: 2/2, step 23385/23838 completed (loss: 0.4067924916744232, acc: 0.868686854839325)
[2025-02-04 03:11:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23387/23838 [34:20<02:38,  2.84it/s][2025-02-04 03:11:10][root][INFO] - Training Epoch: 2/2, step 23386/23838 completed (loss: 0.46013033390045166, acc: 0.875)
[2025-02-04 03:11:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23388/23838 [34:21<02:35,  2.89it/s][2025-02-04 03:11:10][root][INFO] - Training Epoch: 2/2, step 23387/23838 completed (loss: 0.07896243780851364, acc: 0.9708737730979919)
[2025-02-04 03:11:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23389/23838 [34:21<02:30,  2.98it/s][2025-02-04 03:11:11][root][INFO] - Training Epoch: 2/2, step 23388/23838 completed (loss: 0.23926660418510437, acc: 0.9292035102844238)
[2025-02-04 03:11:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23390/23838 [34:21<02:31,  2.96it/s][2025-02-04 03:11:11][root][INFO] - Training Epoch: 2/2, step 23389/23838 completed (loss: 0.08141113072633743, acc: 0.9750000238418579)
[2025-02-04 03:11:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23391/23838 [34:22<02:30,  2.97it/s][2025-02-04 03:11:11][root][INFO] - Training Epoch: 2/2, step 23390/23838 completed (loss: 0.33069756627082825, acc: 0.8831169009208679)
[2025-02-04 03:11:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23392/23838 [34:22<02:33,  2.90it/s][2025-02-04 03:11:12][root][INFO] - Training Epoch: 2/2, step 23391/23838 completed (loss: 0.28908202052116394, acc: 0.9239130616188049)
[2025-02-04 03:11:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23393/23838 [34:22<02:32,  2.92it/s][2025-02-04 03:11:12][root][INFO] - Training Epoch: 2/2, step 23392/23838 completed (loss: 0.5614365339279175, acc: 0.800000011920929)
[2025-02-04 03:11:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23394/23838 [34:23<02:32,  2.91it/s][2025-02-04 03:11:12][root][INFO] - Training Epoch: 2/2, step 23393/23838 completed (loss: 0.5442652106285095, acc: 0.8130081295967102)
[2025-02-04 03:11:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23395/23838 [34:23<02:34,  2.86it/s][2025-02-04 03:11:13][root][INFO] - Training Epoch: 2/2, step 23394/23838 completed (loss: 0.779594361782074, acc: 0.7777777910232544)
[2025-02-04 03:11:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23396/23838 [34:23<02:36,  2.83it/s][2025-02-04 03:11:13][root][INFO] - Training Epoch: 2/2, step 23395/23838 completed (loss: 0.3838074803352356, acc: 0.890625)
[2025-02-04 03:11:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23397/23838 [34:24<02:37,  2.80it/s][2025-02-04 03:11:13][root][INFO] - Training Epoch: 2/2, step 23396/23838 completed (loss: 0.25919488072395325, acc: 0.9038461446762085)
[2025-02-04 03:11:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23398/23838 [34:24<02:36,  2.80it/s][2025-02-04 03:11:14][root][INFO] - Training Epoch: 2/2, step 23397/23838 completed (loss: 0.22269606590270996, acc: 0.9459459185600281)
[2025-02-04 03:11:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23399/23838 [34:24<02:37,  2.79it/s][2025-02-04 03:11:14][root][INFO] - Training Epoch: 2/2, step 23398/23838 completed (loss: 0.656380295753479, acc: 0.8142856955528259)
[2025-02-04 03:11:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23400/23838 [34:25<02:36,  2.80it/s][2025-02-04 03:11:14][root][INFO] - Training Epoch: 2/2, step 23399/23838 completed (loss: 0.4060749411582947, acc: 0.8857142925262451)
[2025-02-04 03:11:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23401/23838 [34:25<02:34,  2.82it/s][2025-02-04 03:11:15][root][INFO] - Training Epoch: 2/2, step 23400/23838 completed (loss: 0.1738443821668625, acc: 0.9586777091026306)
[2025-02-04 03:11:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23402/23838 [34:26<02:40,  2.72it/s][2025-02-04 03:11:15][root][INFO] - Training Epoch: 2/2, step 23401/23838 completed (loss: 0.4964234232902527, acc: 0.8644067645072937)
[2025-02-04 03:11:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23403/23838 [34:26<02:43,  2.66it/s][2025-02-04 03:11:16][root][INFO] - Training Epoch: 2/2, step 23402/23838 completed (loss: 0.22328254580497742, acc: 0.9230769276618958)
[2025-02-04 03:11:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23404/23838 [34:26<02:36,  2.77it/s][2025-02-04 03:11:16][root][INFO] - Training Epoch: 2/2, step 23403/23838 completed (loss: 0.3193519115447998, acc: 0.929411768913269)
[2025-02-04 03:11:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23405/23838 [34:27<02:36,  2.77it/s][2025-02-04 03:11:16][root][INFO] - Training Epoch: 2/2, step 23404/23838 completed (loss: 0.20027852058410645, acc: 0.9115044474601746)
[2025-02-04 03:11:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23406/23838 [34:27<02:35,  2.79it/s][2025-02-04 03:11:17][root][INFO] - Training Epoch: 2/2, step 23405/23838 completed (loss: 0.3393080234527588, acc: 0.8524590134620667)
[2025-02-04 03:11:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23407/23838 [34:27<02:29,  2.87it/s][2025-02-04 03:11:17][root][INFO] - Training Epoch: 2/2, step 23406/23838 completed (loss: 0.23497392237186432, acc: 0.9398496150970459)
[2025-02-04 03:11:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23408/23838 [34:28<02:34,  2.79it/s][2025-02-04 03:11:17][root][INFO] - Training Epoch: 2/2, step 23407/23838 completed (loss: 0.40522128343582153, acc: 0.8658536672592163)
[2025-02-04 03:11:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23409/23838 [34:28<02:38,  2.70it/s][2025-02-04 03:11:18][root][INFO] - Training Epoch: 2/2, step 23408/23838 completed (loss: 0.0619017593562603, acc: 1.0)
[2025-02-04 03:11:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23410/23838 [34:28<02:41,  2.65it/s][2025-02-04 03:11:18][root][INFO] - Training Epoch: 2/2, step 23409/23838 completed (loss: 0.3168560862541199, acc: 0.8852459192276001)
[2025-02-04 03:11:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23411/23838 [34:29<02:37,  2.71it/s][2025-02-04 03:11:18][root][INFO] - Training Epoch: 2/2, step 23410/23838 completed (loss: 0.17766709625720978, acc: 0.932584285736084)
[2025-02-04 03:11:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23412/23838 [34:29<02:35,  2.74it/s][2025-02-04 03:11:19][root][INFO] - Training Epoch: 2/2, step 23411/23838 completed (loss: 0.34990885853767395, acc: 0.8983050584793091)
[2025-02-04 03:11:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23413/23838 [34:30<02:30,  2.83it/s][2025-02-04 03:11:19][root][INFO] - Training Epoch: 2/2, step 23412/23838 completed (loss: 0.22911974787712097, acc: 0.9166666865348816)
[2025-02-04 03:11:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23414/23838 [34:30<02:26,  2.90it/s][2025-02-04 03:11:19][root][INFO] - Training Epoch: 2/2, step 23413/23838 completed (loss: 0.2617640197277069, acc: 0.9212598204612732)
[2025-02-04 03:11:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23415/23838 [34:30<02:23,  2.94it/s][2025-02-04 03:11:20][root][INFO] - Training Epoch: 2/2, step 23414/23838 completed (loss: 0.06930429488420486, acc: 0.9708737730979919)
[2025-02-04 03:11:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23416/23838 [34:30<02:15,  3.11it/s][2025-02-04 03:11:20][root][INFO] - Training Epoch: 2/2, step 23415/23838 completed (loss: 0.17077232897281647, acc: 0.9666666388511658)
[2025-02-04 03:11:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23417/23838 [34:31<02:14,  3.13it/s][2025-02-04 03:11:20][root][INFO] - Training Epoch: 2/2, step 23416/23838 completed (loss: 0.4723818600177765, acc: 0.8765432238578796)
[2025-02-04 03:11:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23418/23838 [34:31<02:17,  3.06it/s][2025-02-04 03:11:21][root][INFO] - Training Epoch: 2/2, step 23417/23838 completed (loss: 0.17708861827850342, acc: 0.9333333373069763)
[2025-02-04 03:11:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23419/23838 [34:31<02:14,  3.11it/s][2025-02-04 03:11:21][root][INFO] - Training Epoch: 2/2, step 23418/23838 completed (loss: 0.4936879873275757, acc: 0.8571428656578064)
[2025-02-04 03:11:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23420/23838 [34:32<02:20,  2.97it/s][2025-02-04 03:11:21][root][INFO] - Training Epoch: 2/2, step 23419/23838 completed (loss: 0.9718642830848694, acc: 0.6760563254356384)
[2025-02-04 03:11:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23421/23838 [34:32<02:21,  2.96it/s][2025-02-04 03:11:22][root][INFO] - Training Epoch: 2/2, step 23420/23838 completed (loss: 0.33029189705848694, acc: 0.9264705777168274)
[2025-02-04 03:11:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23422/23838 [34:32<02:21,  2.94it/s][2025-02-04 03:11:22][root][INFO] - Training Epoch: 2/2, step 23421/23838 completed (loss: 0.3426835834980011, acc: 0.9318181872367859)
[2025-02-04 03:11:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23423/23838 [34:33<02:24,  2.88it/s][2025-02-04 03:11:22][root][INFO] - Training Epoch: 2/2, step 23422/23838 completed (loss: 0.16976512968540192, acc: 0.9666666388511658)
[2025-02-04 03:11:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23424/23838 [34:33<02:24,  2.87it/s][2025-02-04 03:11:23][root][INFO] - Training Epoch: 2/2, step 23423/23838 completed (loss: 0.17431770265102386, acc: 0.9603960514068604)
[2025-02-04 03:11:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23425/23838 [34:34<02:24,  2.85it/s][2025-02-04 03:11:23][root][INFO] - Training Epoch: 2/2, step 23424/23838 completed (loss: 0.1861748844385147, acc: 0.9264705777168274)
[2025-02-04 03:11:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23426/23838 [34:34<02:29,  2.76it/s][2025-02-04 03:11:24][root][INFO] - Training Epoch: 2/2, step 23425/23838 completed (loss: 0.09211944788694382, acc: 0.9679144620895386)
[2025-02-04 03:11:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23427/23838 [34:34<02:25,  2.83it/s][2025-02-04 03:11:24][root][INFO] - Training Epoch: 2/2, step 23426/23838 completed (loss: 0.4463626742362976, acc: 0.8928571343421936)
[2025-02-04 03:11:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23428/23838 [34:35<02:25,  2.82it/s][2025-02-04 03:11:24][root][INFO] - Training Epoch: 2/2, step 23427/23838 completed (loss: 0.14000312983989716, acc: 0.9479166865348816)
[2025-02-04 03:11:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23429/23838 [34:35<02:33,  2.66it/s][2025-02-04 03:11:25][root][INFO] - Training Epoch: 2/2, step 23428/23838 completed (loss: 0.348903626203537, acc: 0.9051094651222229)
[2025-02-04 03:11:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23430/23838 [34:35<02:29,  2.73it/s][2025-02-04 03:11:25][root][INFO] - Training Epoch: 2/2, step 23429/23838 completed (loss: 0.22103548049926758, acc: 0.966292142868042)
[2025-02-04 03:11:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23431/23838 [34:36<02:27,  2.76it/s][2025-02-04 03:11:25][root][INFO] - Training Epoch: 2/2, step 23430/23838 completed (loss: 0.42037057876586914, acc: 0.8846153616905212)
[2025-02-04 03:11:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23432/23838 [34:36<02:26,  2.76it/s][2025-02-04 03:11:26][root][INFO] - Training Epoch: 2/2, step 23431/23838 completed (loss: 0.4545321464538574, acc: 0.8783783912658691)
[2025-02-04 03:11:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23433/23838 [34:36<02:26,  2.77it/s][2025-02-04 03:11:26][root][INFO] - Training Epoch: 2/2, step 23432/23838 completed (loss: 0.34380778670310974, acc: 0.875)
[2025-02-04 03:11:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23434/23838 [34:37<02:22,  2.84it/s][2025-02-04 03:11:26][root][INFO] - Training Epoch: 2/2, step 23433/23838 completed (loss: 0.2708309292793274, acc: 0.924369752407074)
[2025-02-04 03:11:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23435/23838 [34:37<02:19,  2.89it/s][2025-02-04 03:11:27][root][INFO] - Training Epoch: 2/2, step 23434/23838 completed (loss: 0.5415821075439453, acc: 0.8832116723060608)
[2025-02-04 03:11:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23436/23838 [34:37<02:15,  2.98it/s][2025-02-04 03:11:27][root][INFO] - Training Epoch: 2/2, step 23435/23838 completed (loss: 0.3780567944049835, acc: 0.8700000047683716)
[2025-02-04 03:11:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23437/23838 [34:38<02:20,  2.85it/s][2025-02-04 03:11:27][root][INFO] - Training Epoch: 2/2, step 23436/23838 completed (loss: 0.1964360773563385, acc: 0.945652186870575)
[2025-02-04 03:11:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23438/23838 [34:38<02:25,  2.76it/s][2025-02-04 03:11:28][root][INFO] - Training Epoch: 2/2, step 23437/23838 completed (loss: 0.18564686179161072, acc: 0.9247311949729919)
[2025-02-04 03:11:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23439/23838 [34:39<02:23,  2.78it/s][2025-02-04 03:11:28][root][INFO] - Training Epoch: 2/2, step 23438/23838 completed (loss: 0.7368367314338684, acc: 0.8103448152542114)
[2025-02-04 03:11:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23440/23838 [34:39<02:21,  2.82it/s][2025-02-04 03:11:29][root][INFO] - Training Epoch: 2/2, step 23439/23838 completed (loss: 0.22765207290649414, acc: 0.9090909361839294)
[2025-02-04 03:11:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23441/23838 [34:39<02:12,  2.99it/s][2025-02-04 03:11:29][root][INFO] - Training Epoch: 2/2, step 23440/23838 completed (loss: 0.2007700502872467, acc: 0.9534883499145508)
[2025-02-04 03:11:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23442/23838 [34:40<02:19,  2.84it/s][2025-02-04 03:11:29][root][INFO] - Training Epoch: 2/2, step 23441/23838 completed (loss: 0.2307821363210678, acc: 0.9153845906257629)
[2025-02-04 03:11:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23443/23838 [34:40<02:17,  2.87it/s][2025-02-04 03:11:30][root][INFO] - Training Epoch: 2/2, step 23442/23838 completed (loss: 0.5615457892417908, acc: 0.8409090638160706)
[2025-02-04 03:11:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23444/23838 [34:40<02:12,  2.97it/s][2025-02-04 03:11:30][root][INFO] - Training Epoch: 2/2, step 23443/23838 completed (loss: 0.07180611044168472, acc: 0.991304337978363)
[2025-02-04 03:11:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23445/23838 [34:41<02:13,  2.95it/s][2025-02-04 03:11:30][root][INFO] - Training Epoch: 2/2, step 23444/23838 completed (loss: 0.14876747131347656, acc: 0.9689922332763672)
[2025-02-04 03:11:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23446/23838 [34:41<02:20,  2.78it/s][2025-02-04 03:11:31][root][INFO] - Training Epoch: 2/2, step 23445/23838 completed (loss: 0.46561986207962036, acc: 0.875)
[2025-02-04 03:11:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23447/23838 [34:41<02:23,  2.72it/s][2025-02-04 03:11:31][root][INFO] - Training Epoch: 2/2, step 23446/23838 completed (loss: 0.666720449924469, acc: 0.8541666865348816)
[2025-02-04 03:11:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23448/23838 [34:42<02:19,  2.79it/s][2025-02-04 03:11:31][root][INFO] - Training Epoch: 2/2, step 23447/23838 completed (loss: 0.46332797408103943, acc: 0.8854166865348816)
[2025-02-04 03:11:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23449/23838 [34:42<02:13,  2.91it/s][2025-02-04 03:11:32][root][INFO] - Training Epoch: 2/2, step 23448/23838 completed (loss: 0.7162001132965088, acc: 0.8048780560493469)
[2025-02-04 03:11:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23450/23838 [34:42<02:11,  2.94it/s][2025-02-04 03:11:32][root][INFO] - Training Epoch: 2/2, step 23449/23838 completed (loss: 0.4539761245250702, acc: 0.8990825414657593)
[2025-02-04 03:11:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23451/23838 [34:43<02:15,  2.86it/s][2025-02-04 03:11:32][root][INFO] - Training Epoch: 2/2, step 23450/23838 completed (loss: 0.43588459491729736, acc: 0.8476190567016602)
[2025-02-04 03:11:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23452/23838 [34:43<02:12,  2.91it/s][2025-02-04 03:11:33][root][INFO] - Training Epoch: 2/2, step 23451/23838 completed (loss: 0.521661639213562, acc: 0.8225806355476379)
[2025-02-04 03:11:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23453/23838 [34:43<02:09,  2.98it/s][2025-02-04 03:11:33][root][INFO] - Training Epoch: 2/2, step 23452/23838 completed (loss: 0.29076290130615234, acc: 0.9411764740943909)
[2025-02-04 03:11:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23454/23838 [34:44<02:09,  2.96it/s][2025-02-04 03:11:33][root][INFO] - Training Epoch: 2/2, step 23453/23838 completed (loss: 0.48640263080596924, acc: 0.8476190567016602)
[2025-02-04 03:11:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23455/23838 [34:44<02:15,  2.83it/s][2025-02-04 03:11:34][root][INFO] - Training Epoch: 2/2, step 23454/23838 completed (loss: 0.9419783353805542, acc: 0.6896551847457886)
[2025-02-04 03:11:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23456/23838 [34:44<02:16,  2.81it/s][2025-02-04 03:11:34][root][INFO] - Training Epoch: 2/2, step 23455/23838 completed (loss: 0.1873287856578827, acc: 0.9529411792755127)
[2025-02-04 03:11:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23457/23838 [34:45<02:14,  2.84it/s][2025-02-04 03:11:34][root][INFO] - Training Epoch: 2/2, step 23456/23838 completed (loss: 0.46012914180755615, acc: 0.844660222530365)
[2025-02-04 03:11:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23458/23838 [34:45<02:18,  2.75it/s][2025-02-04 03:11:35][root][INFO] - Training Epoch: 2/2, step 23457/23838 completed (loss: 0.38526836037635803, acc: 0.9047619104385376)
[2025-02-04 03:11:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23459/23838 [34:46<02:19,  2.72it/s][2025-02-04 03:11:35][root][INFO] - Training Epoch: 2/2, step 23458/23838 completed (loss: 0.8896824717521667, acc: 0.7910447716712952)
[2025-02-04 03:11:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23460/23838 [34:46<02:16,  2.77it/s][2025-02-04 03:11:36][root][INFO] - Training Epoch: 2/2, step 23459/23838 completed (loss: 0.640958845615387, acc: 0.8103448152542114)
[2025-02-04 03:11:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23461/23838 [34:46<02:15,  2.79it/s][2025-02-04 03:11:36][root][INFO] - Training Epoch: 2/2, step 23460/23838 completed (loss: 0.5258800387382507, acc: 0.8421052694320679)
[2025-02-04 03:11:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23462/23838 [34:47<02:19,  2.69it/s][2025-02-04 03:11:36][root][INFO] - Training Epoch: 2/2, step 23461/23838 completed (loss: 0.3887975513935089, acc: 0.9173553586006165)
[2025-02-04 03:11:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23463/23838 [34:47<02:15,  2.76it/s][2025-02-04 03:11:37][root][INFO] - Training Epoch: 2/2, step 23462/23838 completed (loss: 0.4847307801246643, acc: 0.8689655065536499)
[2025-02-04 03:11:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23464/23838 [34:47<02:20,  2.67it/s][2025-02-04 03:11:37][root][INFO] - Training Epoch: 2/2, step 23463/23838 completed (loss: 0.4146232604980469, acc: 0.8961039185523987)
[2025-02-04 03:11:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23465/23838 [34:48<02:13,  2.80it/s][2025-02-04 03:11:37][root][INFO] - Training Epoch: 2/2, step 23464/23838 completed (loss: 0.3966960310935974, acc: 0.891566276550293)
[2025-02-04 03:11:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23466/23838 [34:48<02:12,  2.81it/s][2025-02-04 03:11:38][root][INFO] - Training Epoch: 2/2, step 23465/23838 completed (loss: 0.27222803235054016, acc: 0.9333333373069763)
[2025-02-04 03:11:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23467/23838 [34:48<02:11,  2.82it/s][2025-02-04 03:11:38][root][INFO] - Training Epoch: 2/2, step 23466/23838 completed (loss: 0.4125107228755951, acc: 0.8958333134651184)
[2025-02-04 03:11:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23468/23838 [34:49<02:07,  2.90it/s][2025-02-04 03:11:38][root][INFO] - Training Epoch: 2/2, step 23467/23838 completed (loss: 0.46675345301628113, acc: 0.8571428656578064)
[2025-02-04 03:11:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23469/23838 [34:49<02:10,  2.84it/s][2025-02-04 03:11:39][root][INFO] - Training Epoch: 2/2, step 23468/23838 completed (loss: 0.5582439303398132, acc: 0.8611111044883728)
[2025-02-04 03:11:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23470/23838 [34:49<02:08,  2.87it/s][2025-02-04 03:11:39][root][INFO] - Training Epoch: 2/2, step 23469/23838 completed (loss: 0.49067509174346924, acc: 0.8470588326454163)
[2025-02-04 03:11:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23471/23838 [34:50<02:03,  2.96it/s][2025-02-04 03:11:39][root][INFO] - Training Epoch: 2/2, step 23470/23838 completed (loss: 0.4645902216434479, acc: 0.8559321761131287)
[2025-02-04 03:11:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23472/23838 [34:50<02:04,  2.94it/s][2025-02-04 03:11:40][root][INFO] - Training Epoch: 2/2, step 23471/23838 completed (loss: 0.6292266845703125, acc: 0.7846153974533081)
[2025-02-04 03:11:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23473/23838 [34:50<02:02,  2.97it/s][2025-02-04 03:11:40][root][INFO] - Training Epoch: 2/2, step 23472/23838 completed (loss: 0.38061636686325073, acc: 0.8999999761581421)
[2025-02-04 03:11:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23474/23838 [34:51<02:03,  2.94it/s][2025-02-04 03:11:40][root][INFO] - Training Epoch: 2/2, step 23473/23838 completed (loss: 0.6026220321655273, acc: 0.7972972989082336)
[2025-02-04 03:11:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23475/23838 [34:51<02:08,  2.83it/s][2025-02-04 03:11:41][root][INFO] - Training Epoch: 2/2, step 23474/23838 completed (loss: 0.1585506647825241, acc: 0.9714285731315613)
[2025-02-04 03:11:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23476/23838 [34:52<02:20,  2.58it/s][2025-02-04 03:11:41][root][INFO] - Training Epoch: 2/2, step 23475/23838 completed (loss: 0.6692233085632324, acc: 0.8062499761581421)
[2025-02-04 03:11:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23477/23838 [34:52<02:21,  2.55it/s][2025-02-04 03:11:42][root][INFO] - Training Epoch: 2/2, step 23476/23838 completed (loss: 0.46270033717155457, acc: 0.8392857313156128)
[2025-02-04 03:11:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23478/23838 [34:52<02:23,  2.52it/s][2025-02-04 03:11:42][root][INFO] - Training Epoch: 2/2, step 23477/23838 completed (loss: 0.20570862293243408, acc: 0.9342105388641357)
[2025-02-04 03:11:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23479/23838 [34:53<02:13,  2.70it/s][2025-02-04 03:11:42][root][INFO] - Training Epoch: 2/2, step 23478/23838 completed (loss: 0.2062830924987793, acc: 0.949367105960846)
[2025-02-04 03:11:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  98%|[34m█████████▊[0m| 23480/23838 [34:53<02:08,  2.79it/s][2025-02-04 03:11:43][root][INFO] - Training Epoch: 2/2, step 23479/23838 completed (loss: 0.37759727239608765, acc: 0.8666666746139526)
[2025-02-04 03:11:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23481/23838 [34:53<02:07,  2.80it/s][2025-02-04 03:11:43][root][INFO] - Training Epoch: 2/2, step 23480/23838 completed (loss: 0.5843287706375122, acc: 0.7699999809265137)
[2025-02-04 03:11:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23482/23838 [34:54<02:12,  2.69it/s][2025-02-04 03:11:43][root][INFO] - Training Epoch: 2/2, step 23481/23838 completed (loss: 0.3559398949146271, acc: 0.8796296119689941)
[2025-02-04 03:11:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23483/23838 [34:54<02:12,  2.68it/s][2025-02-04 03:11:44][root][INFO] - Training Epoch: 2/2, step 23482/23838 completed (loss: 0.13730457425117493, acc: 0.9537037014961243)
[2025-02-04 03:11:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23484/23838 [34:55<02:09,  2.73it/s][2025-02-04 03:11:44][root][INFO] - Training Epoch: 2/2, step 23483/23838 completed (loss: 0.44976505637168884, acc: 0.8761904835700989)
[2025-02-04 03:11:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23485/23838 [34:55<02:16,  2.58it/s][2025-02-04 03:11:45][root][INFO] - Training Epoch: 2/2, step 23484/23838 completed (loss: 0.3950616419315338, acc: 0.9064748287200928)
[2025-02-04 03:11:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23486/23838 [34:55<02:14,  2.62it/s][2025-02-04 03:11:45][root][INFO] - Training Epoch: 2/2, step 23485/23838 completed (loss: 0.4380260705947876, acc: 0.8767123222351074)
[2025-02-04 03:11:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23487/23838 [34:56<02:08,  2.72it/s][2025-02-04 03:11:45][root][INFO] - Training Epoch: 2/2, step 23486/23838 completed (loss: 0.24476034939289093, acc: 0.940397322177887)
[2025-02-04 03:11:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23488/23838 [34:56<02:05,  2.79it/s][2025-02-04 03:11:46][root][INFO] - Training Epoch: 2/2, step 23487/23838 completed (loss: 0.23442097008228302, acc: 0.9280575513839722)
[2025-02-04 03:11:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23489/23838 [34:56<01:58,  2.93it/s][2025-02-04 03:11:46][root][INFO] - Training Epoch: 2/2, step 23488/23838 completed (loss: 0.14558950066566467, acc: 0.9415584206581116)
[2025-02-04 03:11:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23490/23838 [34:57<01:57,  2.96it/s][2025-02-04 03:11:46][root][INFO] - Training Epoch: 2/2, step 23489/23838 completed (loss: 0.5023176670074463, acc: 0.8518518805503845)
[2025-02-04 03:11:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23491/23838 [34:57<02:05,  2.77it/s][2025-02-04 03:11:47][root][INFO] - Training Epoch: 2/2, step 23490/23838 completed (loss: 0.3882255554199219, acc: 0.8476190567016602)
[2025-02-04 03:11:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23492/23838 [34:57<01:57,  2.95it/s][2025-02-04 03:11:47][root][INFO] - Training Epoch: 2/2, step 23491/23838 completed (loss: 0.629180371761322, acc: 0.8170731663703918)
[2025-02-04 03:11:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23493/23838 [34:58<01:59,  2.88it/s][2025-02-04 03:11:47][root][INFO] - Training Epoch: 2/2, step 23492/23838 completed (loss: 0.4792402684688568, acc: 0.8653846383094788)
[2025-02-04 03:11:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23494/23838 [34:58<01:57,  2.93it/s][2025-02-04 03:11:48][root][INFO] - Training Epoch: 2/2, step 23493/23838 completed (loss: 0.07163620740175247, acc: 0.9777777791023254)
[2025-02-04 03:11:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23495/23838 [34:58<01:54,  2.99it/s][2025-02-04 03:11:48][root][INFO] - Training Epoch: 2/2, step 23494/23838 completed (loss: 0.6643169522285461, acc: 0.7848101258277893)
[2025-02-04 03:11:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23496/23838 [34:59<01:52,  3.05it/s][2025-02-04 03:11:48][root][INFO] - Training Epoch: 2/2, step 23495/23838 completed (loss: 0.11033650487661362, acc: 0.9700000286102295)
[2025-02-04 03:11:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23497/23838 [34:59<01:56,  2.94it/s][2025-02-04 03:11:49][root][INFO] - Training Epoch: 2/2, step 23496/23838 completed (loss: 0.22874395549297333, acc: 0.9425287246704102)
[2025-02-04 03:11:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23498/23838 [35:00<02:07,  2.66it/s][2025-02-04 03:11:49][root][INFO] - Training Epoch: 2/2, step 23497/23838 completed (loss: 0.1789519339799881, acc: 0.9291338324546814)
[2025-02-04 03:11:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23499/23838 [35:00<02:02,  2.78it/s][2025-02-04 03:11:49][root][INFO] - Training Epoch: 2/2, step 23498/23838 completed (loss: 0.22178968787193298, acc: 0.9402984976768494)
[2025-02-04 03:11:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23500/23838 [35:00<02:04,  2.72it/s][2025-02-04 03:11:50][root][INFO] - Training Epoch: 2/2, step 23499/23838 completed (loss: 0.3692023456096649, acc: 0.8860759735107422)
[2025-02-04 03:11:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23501/23838 [35:01<02:01,  2.77it/s][2025-02-04 03:11:50][root][INFO] - Training Epoch: 2/2, step 23500/23838 completed (loss: 0.8418442010879517, acc: 0.7580645084381104)
[2025-02-04 03:11:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23502/23838 [35:01<02:05,  2.69it/s][2025-02-04 03:11:51][root][INFO] - Training Epoch: 2/2, step 23501/23838 completed (loss: 0.43734705448150635, acc: 0.8705882430076599)
[2025-02-04 03:11:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23503/23838 [35:01<02:03,  2.72it/s][2025-02-04 03:11:51][root][INFO] - Training Epoch: 2/2, step 23502/23838 completed (loss: 0.2413128912448883, acc: 0.9433962106704712)
[2025-02-04 03:11:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23504/23838 [35:02<02:01,  2.76it/s][2025-02-04 03:11:51][root][INFO] - Training Epoch: 2/2, step 23503/23838 completed (loss: 0.3706262409687042, acc: 0.8793103694915771)
[2025-02-04 03:11:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23505/23838 [35:02<02:05,  2.65it/s][2025-02-04 03:11:52][root][INFO] - Training Epoch: 2/2, step 23504/23838 completed (loss: 0.4983060657978058, acc: 0.8571428656578064)
[2025-02-04 03:11:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23506/23838 [35:03<02:07,  2.60it/s][2025-02-04 03:11:52][root][INFO] - Training Epoch: 2/2, step 23505/23838 completed (loss: 0.24567601084709167, acc: 0.9333333373069763)
[2025-02-04 03:11:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23507/23838 [35:03<02:07,  2.60it/s][2025-02-04 03:11:53][root][INFO] - Training Epoch: 2/2, step 23506/23838 completed (loss: 0.4927339255809784, acc: 0.8369565010070801)
[2025-02-04 03:11:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23508/23838 [35:03<02:04,  2.66it/s][2025-02-04 03:11:53][root][INFO] - Training Epoch: 2/2, step 23507/23838 completed (loss: 0.1766509860754013, acc: 0.942148745059967)
[2025-02-04 03:11:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23509/23838 [35:04<02:08,  2.56it/s][2025-02-04 03:11:53][root][INFO] - Training Epoch: 2/2, step 23508/23838 completed (loss: 0.21384210884571075, acc: 0.925000011920929)
[2025-02-04 03:11:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23510/23838 [35:04<02:02,  2.68it/s][2025-02-04 03:11:54][root][INFO] - Training Epoch: 2/2, step 23509/23838 completed (loss: 0.4782099723815918, acc: 0.8493150472640991)
[2025-02-04 03:11:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23511/23838 [35:04<02:05,  2.60it/s][2025-02-04 03:11:54][root][INFO] - Training Epoch: 2/2, step 23510/23838 completed (loss: 0.6941016912460327, acc: 0.7719298005104065)
[2025-02-04 03:11:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23512/23838 [35:05<02:05,  2.59it/s][2025-02-04 03:11:54][root][INFO] - Training Epoch: 2/2, step 23511/23838 completed (loss: 0.3703683912754059, acc: 0.920634925365448)
[2025-02-04 03:11:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23513/23838 [35:05<02:02,  2.65it/s][2025-02-04 03:11:55][root][INFO] - Training Epoch: 2/2, step 23512/23838 completed (loss: 0.19575530290603638, acc: 0.9379844665527344)
[2025-02-04 03:11:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23514/23838 [35:06<01:58,  2.74it/s][2025-02-04 03:11:55][root][INFO] - Training Epoch: 2/2, step 23513/23838 completed (loss: 0.5134931206703186, acc: 0.8780487775802612)
[2025-02-04 03:11:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23515/23838 [35:06<02:01,  2.66it/s][2025-02-04 03:11:56][root][INFO] - Training Epoch: 2/2, step 23514/23838 completed (loss: 0.9924150109291077, acc: 0.7164179086685181)
[2025-02-04 03:11:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23516/23838 [35:06<02:05,  2.57it/s][2025-02-04 03:11:56][root][INFO] - Training Epoch: 2/2, step 23515/23838 completed (loss: 0.31492725014686584, acc: 0.8866666555404663)
[2025-02-04 03:11:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23517/23838 [35:07<01:56,  2.76it/s][2025-02-04 03:11:56][root][INFO] - Training Epoch: 2/2, step 23516/23838 completed (loss: 0.29202476143836975, acc: 0.9150943160057068)
[2025-02-04 03:11:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23518/23838 [35:07<01:53,  2.81it/s][2025-02-04 03:11:57][root][INFO] - Training Epoch: 2/2, step 23517/23838 completed (loss: 0.3546474575996399, acc: 0.9047619104385376)
[2025-02-04 03:11:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23519/23838 [35:07<01:56,  2.75it/s][2025-02-04 03:11:57][root][INFO] - Training Epoch: 2/2, step 23518/23838 completed (loss: 0.45716702938079834, acc: 0.8644067645072937)
[2025-02-04 03:11:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23520/23838 [35:08<01:54,  2.77it/s][2025-02-04 03:11:57][root][INFO] - Training Epoch: 2/2, step 23519/23838 completed (loss: 0.39927318692207336, acc: 0.9101123809814453)
[2025-02-04 03:11:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23521/23838 [35:08<01:51,  2.85it/s][2025-02-04 03:11:58][root][INFO] - Training Epoch: 2/2, step 23520/23838 completed (loss: 0.4607578217983246, acc: 0.8571428656578064)
[2025-02-04 03:11:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23522/23838 [35:08<01:50,  2.86it/s][2025-02-04 03:11:58][root][INFO] - Training Epoch: 2/2, step 23521/23838 completed (loss: 0.335353285074234, acc: 0.9107142686843872)
[2025-02-04 03:11:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23523/23838 [35:09<01:50,  2.84it/s][2025-02-04 03:11:58][root][INFO] - Training Epoch: 2/2, step 23522/23838 completed (loss: 0.4334012567996979, acc: 0.875)
[2025-02-04 03:11:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23524/23838 [35:09<01:49,  2.87it/s][2025-02-04 03:11:59][root][INFO] - Training Epoch: 2/2, step 23523/23838 completed (loss: 0.5476410984992981, acc: 0.8208954930305481)
[2025-02-04 03:11:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23525/23838 [35:09<01:47,  2.91it/s][2025-02-04 03:11:59][root][INFO] - Training Epoch: 2/2, step 23524/23838 completed (loss: 0.5173856616020203, acc: 0.8289473652839661)
[2025-02-04 03:11:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23526/23838 [35:10<01:58,  2.64it/s][2025-02-04 03:11:59][root][INFO] - Training Epoch: 2/2, step 23525/23838 completed (loss: 0.44194427132606506, acc: 0.8849557638168335)
[2025-02-04 03:12:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23527/23838 [35:10<01:56,  2.67it/s][2025-02-04 03:12:00][root][INFO] - Training Epoch: 2/2, step 23526/23838 completed (loss: 0.16245098412036896, acc: 0.9428571462631226)
[2025-02-04 03:12:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23528/23838 [35:11<01:53,  2.73it/s][2025-02-04 03:12:00][root][INFO] - Training Epoch: 2/2, step 23527/23838 completed (loss: 0.45818665623664856, acc: 0.8399999737739563)
[2025-02-04 03:12:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23529/23838 [35:11<01:49,  2.82it/s][2025-02-04 03:12:01][root][INFO] - Training Epoch: 2/2, step 23528/23838 completed (loss: 0.3758876919746399, acc: 0.8870967626571655)
[2025-02-04 03:12:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23530/23838 [35:11<01:45,  2.92it/s][2025-02-04 03:12:01][root][INFO] - Training Epoch: 2/2, step 23529/23838 completed (loss: 0.16406488418579102, acc: 0.9405940771102905)
[2025-02-04 03:12:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23531/23838 [35:12<01:42,  2.98it/s][2025-02-04 03:12:01][root][INFO] - Training Epoch: 2/2, step 23530/23838 completed (loss: 0.22874552011489868, acc: 0.9156626462936401)
[2025-02-04 03:12:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23532/23838 [35:12<01:40,  3.06it/s][2025-02-04 03:12:01][root][INFO] - Training Epoch: 2/2, step 23531/23838 completed (loss: 0.5209091305732727, acc: 0.8684210777282715)
[2025-02-04 03:12:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23533/23838 [35:12<01:39,  3.07it/s][2025-02-04 03:12:02][root][INFO] - Training Epoch: 2/2, step 23532/23838 completed (loss: 0.3849460780620575, acc: 0.8823529481887817)
[2025-02-04 03:12:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23534/23838 [35:13<01:40,  3.02it/s][2025-02-04 03:12:02][root][INFO] - Training Epoch: 2/2, step 23533/23838 completed (loss: 0.5877776145935059, acc: 0.8045976758003235)
[2025-02-04 03:12:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23535/23838 [35:13<01:45,  2.87it/s][2025-02-04 03:12:03][root][INFO] - Training Epoch: 2/2, step 23534/23838 completed (loss: 0.5038629770278931, acc: 0.8620689511299133)
[2025-02-04 03:12:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23536/23838 [35:13<01:52,  2.69it/s][2025-02-04 03:12:03][root][INFO] - Training Epoch: 2/2, step 23535/23838 completed (loss: 0.22679278254508972, acc: 0.9375)
[2025-02-04 03:12:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23537/23838 [35:14<01:53,  2.65it/s][2025-02-04 03:12:03][root][INFO] - Training Epoch: 2/2, step 23536/23838 completed (loss: 0.24251142144203186, acc: 0.9186046719551086)
[2025-02-04 03:12:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23538/23838 [35:14<01:51,  2.68it/s][2025-02-04 03:12:04][root][INFO] - Training Epoch: 2/2, step 23537/23838 completed (loss: 0.07151906192302704, acc: 0.988095223903656)
[2025-02-04 03:12:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23539/23838 [35:14<01:52,  2.66it/s][2025-02-04 03:12:04][root][INFO] - Training Epoch: 2/2, step 23538/23838 completed (loss: 0.281584233045578, acc: 0.8999999761581421)
[2025-02-04 03:12:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▊[0m| 23540/23838 [35:15<01:56,  2.56it/s][2025-02-04 03:12:05][root][INFO] - Training Epoch: 2/2, step 23539/23838 completed (loss: 0.3285503685474396, acc: 0.913385808467865)
[2025-02-04 03:12:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23541/23838 [35:15<01:47,  2.77it/s][2025-02-04 03:12:05][root][INFO] - Training Epoch: 2/2, step 23540/23838 completed (loss: 0.26199015974998474, acc: 0.9367088675498962)
[2025-02-04 03:12:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23542/23838 [35:16<01:55,  2.55it/s][2025-02-04 03:12:05][root][INFO] - Training Epoch: 2/2, step 23541/23838 completed (loss: 0.215658500790596, acc: 0.9477611780166626)
[2025-02-04 03:12:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23543/23838 [35:16<01:57,  2.50it/s][2025-02-04 03:12:06][root][INFO] - Training Epoch: 2/2, step 23542/23838 completed (loss: 0.5228546261787415, acc: 0.8730158805847168)
[2025-02-04 03:12:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23544/23838 [35:16<01:54,  2.56it/s][2025-02-04 03:12:06][root][INFO] - Training Epoch: 2/2, step 23543/23838 completed (loss: 0.06659336388111115, acc: 1.0)
[2025-02-04 03:12:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23545/23838 [35:17<01:51,  2.62it/s][2025-02-04 03:12:06][root][INFO] - Training Epoch: 2/2, step 23544/23838 completed (loss: 0.26197925209999084, acc: 0.9324324131011963)
[2025-02-04 03:12:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23546/23838 [35:17<01:52,  2.60it/s][2025-02-04 03:12:07][root][INFO] - Training Epoch: 2/2, step 23545/23838 completed (loss: 0.79461270570755, acc: 0.7575757503509521)
[2025-02-04 03:12:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23547/23838 [35:18<01:47,  2.70it/s][2025-02-04 03:12:07][root][INFO] - Training Epoch: 2/2, step 23546/23838 completed (loss: 0.32480546832084656, acc: 0.875)
[2025-02-04 03:12:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23548/23838 [35:18<01:42,  2.82it/s][2025-02-04 03:12:07][root][INFO] - Training Epoch: 2/2, step 23547/23838 completed (loss: 0.3255036473274231, acc: 0.8928571343421936)
[2025-02-04 03:12:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23549/23838 [35:18<01:34,  3.05it/s][2025-02-04 03:12:08][root][INFO] - Training Epoch: 2/2, step 23548/23838 completed (loss: 0.42409709095954895, acc: 0.8691588640213013)
[2025-02-04 03:12:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23550/23838 [35:18<01:34,  3.04it/s][2025-02-04 03:12:08][root][INFO] - Training Epoch: 2/2, step 23549/23838 completed (loss: 0.3940867781639099, acc: 0.8787878751754761)
[2025-02-04 03:12:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23551/23838 [35:19<01:35,  3.02it/s][2025-02-04 03:12:08][root][INFO] - Training Epoch: 2/2, step 23550/23838 completed (loss: 0.3048359751701355, acc: 0.9142857193946838)
[2025-02-04 03:12:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23552/23838 [35:19<01:30,  3.16it/s][2025-02-04 03:12:09][root][INFO] - Training Epoch: 2/2, step 23551/23838 completed (loss: 0.15520916879177094, acc: 0.9672130942344666)
[2025-02-04 03:12:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23553/23838 [35:19<01:28,  3.23it/s][2025-02-04 03:12:09][root][INFO] - Training Epoch: 2/2, step 23552/23838 completed (loss: 0.2661585211753845, acc: 0.9305555820465088)
[2025-02-04 03:12:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23554/23838 [35:20<01:36,  2.93it/s][2025-02-04 03:12:09][root][INFO] - Training Epoch: 2/2, step 23553/23838 completed (loss: 0.19748564064502716, acc: 0.9447852969169617)
[2025-02-04 03:12:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23555/23838 [35:20<01:33,  3.03it/s][2025-02-04 03:12:10][root][INFO] - Training Epoch: 2/2, step 23554/23838 completed (loss: 0.4061509072780609, acc: 0.89552241563797)
[2025-02-04 03:12:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23556/23838 [35:20<01:28,  3.18it/s][2025-02-04 03:12:10][root][INFO] - Training Epoch: 2/2, step 23555/23838 completed (loss: 0.4525969922542572, acc: 0.9035087823867798)
[2025-02-04 03:12:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23557/23838 [35:21<01:30,  3.10it/s][2025-02-04 03:12:10][root][INFO] - Training Epoch: 2/2, step 23556/23838 completed (loss: 0.23175911605358124, acc: 0.9538461565971375)
[2025-02-04 03:12:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23558/23838 [35:21<01:32,  3.02it/s][2025-02-04 03:12:11][root][INFO] - Training Epoch: 2/2, step 23557/23838 completed (loss: 0.1275499016046524, acc: 0.9666666388511658)
[2025-02-04 03:12:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23559/23838 [35:21<01:28,  3.15it/s][2025-02-04 03:12:11][root][INFO] - Training Epoch: 2/2, step 23558/23838 completed (loss: 0.2275678962469101, acc: 0.9285714030265808)
[2025-02-04 03:12:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23560/23838 [35:22<01:32,  3.00it/s][2025-02-04 03:12:11][root][INFO] - Training Epoch: 2/2, step 23559/23838 completed (loss: 0.1198398619890213, acc: 0.9411764740943909)
[2025-02-04 03:12:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23561/23838 [35:22<01:33,  2.97it/s][2025-02-04 03:12:12][root][INFO] - Training Epoch: 2/2, step 23560/23838 completed (loss: 0.4017614424228668, acc: 0.8879310488700867)
[2025-02-04 03:12:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23562/23838 [35:22<01:32,  2.99it/s][2025-02-04 03:12:12][root][INFO] - Training Epoch: 2/2, step 23561/23838 completed (loss: 0.4436192810535431, acc: 0.8888888955116272)
[2025-02-04 03:12:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23563/23838 [35:23<01:31,  2.99it/s][2025-02-04 03:12:12][root][INFO] - Training Epoch: 2/2, step 23562/23838 completed (loss: 0.14341989159584045, acc: 0.9555555582046509)
[2025-02-04 03:12:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23564/23838 [35:23<01:32,  2.97it/s][2025-02-04 03:12:13][root][INFO] - Training Epoch: 2/2, step 23563/23838 completed (loss: 0.31761446595191956, acc: 0.9189189076423645)
[2025-02-04 03:12:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23565/23838 [35:23<01:31,  2.98it/s][2025-02-04 03:12:13][root][INFO] - Training Epoch: 2/2, step 23564/23838 completed (loss: 0.3257461190223694, acc: 0.9125000238418579)
[2025-02-04 03:12:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23566/23838 [35:24<01:28,  3.06it/s][2025-02-04 03:12:13][root][INFO] - Training Epoch: 2/2, step 23565/23838 completed (loss: 0.41763758659362793, acc: 0.8620689511299133)
[2025-02-04 03:12:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23567/23838 [35:24<01:28,  3.05it/s][2025-02-04 03:12:14][root][INFO] - Training Epoch: 2/2, step 23566/23838 completed (loss: 0.32104620337486267, acc: 0.9256198406219482)
[2025-02-04 03:12:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23568/23838 [35:24<01:33,  2.87it/s][2025-02-04 03:12:14][root][INFO] - Training Epoch: 2/2, step 23567/23838 completed (loss: 0.47629719972610474, acc: 0.8690476417541504)
[2025-02-04 03:12:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23569/23838 [35:25<01:34,  2.85it/s][2025-02-04 03:12:14][root][INFO] - Training Epoch: 2/2, step 23568/23838 completed (loss: 0.2080134153366089, acc: 0.9489796161651611)
[2025-02-04 03:12:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23570/23838 [35:25<01:33,  2.88it/s][2025-02-04 03:12:15][root][INFO] - Training Epoch: 2/2, step 23569/23838 completed (loss: 0.4426378309726715, acc: 0.874015748500824)
[2025-02-04 03:12:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23571/23838 [35:25<01:33,  2.86it/s][2025-02-04 03:12:15][root][INFO] - Training Epoch: 2/2, step 23570/23838 completed (loss: 0.527825653553009, acc: 0.8405796885490417)
[2025-02-04 03:12:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23572/23838 [35:26<01:32,  2.88it/s][2025-02-04 03:12:15][root][INFO] - Training Epoch: 2/2, step 23571/23838 completed (loss: 0.8138888478279114, acc: 0.7746478915214539)
[2025-02-04 03:12:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23573/23838 [35:26<01:30,  2.93it/s][2025-02-04 03:12:16][root][INFO] - Training Epoch: 2/2, step 23572/23838 completed (loss: 0.30410492420196533, acc: 0.9230769276618958)
[2025-02-04 03:12:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23574/23838 [35:27<01:32,  2.85it/s][2025-02-04 03:12:16][root][INFO] - Training Epoch: 2/2, step 23573/23838 completed (loss: 0.21460680663585663, acc: 0.9230769276618958)
[2025-02-04 03:12:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23575/23838 [35:27<01:33,  2.83it/s][2025-02-04 03:12:16][root][INFO] - Training Epoch: 2/2, step 23574/23838 completed (loss: 0.5352774262428284, acc: 0.8503937125205994)
[2025-02-04 03:12:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23576/23838 [35:27<01:30,  2.89it/s][2025-02-04 03:12:17][root][INFO] - Training Epoch: 2/2, step 23575/23838 completed (loss: 0.0959990844130516, acc: 0.9795918464660645)
[2025-02-04 03:12:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23577/23838 [35:28<01:28,  2.96it/s][2025-02-04 03:12:17][root][INFO] - Training Epoch: 2/2, step 23576/23838 completed (loss: 0.46532389521598816, acc: 0.8924731016159058)
[2025-02-04 03:12:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23578/23838 [35:28<01:28,  2.94it/s][2025-02-04 03:12:17][root][INFO] - Training Epoch: 2/2, step 23577/23838 completed (loss: 0.23721055686473846, acc: 0.9464285969734192)
[2025-02-04 03:12:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23579/23838 [35:28<01:27,  2.95it/s][2025-02-04 03:12:18][root][INFO] - Training Epoch: 2/2, step 23578/23838 completed (loss: 0.2754071056842804, acc: 0.90625)
[2025-02-04 03:12:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23580/23838 [35:29<01:30,  2.84it/s][2025-02-04 03:12:18][root][INFO] - Training Epoch: 2/2, step 23579/23838 completed (loss: 0.2829386591911316, acc: 0.9248554706573486)
[2025-02-04 03:12:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23581/23838 [35:29<01:30,  2.85it/s][2025-02-04 03:12:19][root][INFO] - Training Epoch: 2/2, step 23580/23838 completed (loss: 0.4091434180736542, acc: 0.8999999761581421)
[2025-02-04 03:12:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23582/23838 [35:29<01:30,  2.83it/s][2025-02-04 03:12:19][root][INFO] - Training Epoch: 2/2, step 23581/23838 completed (loss: 0.3422257900238037, acc: 0.9166666865348816)
[2025-02-04 03:12:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23583/23838 [35:30<01:34,  2.70it/s][2025-02-04 03:12:19][root][INFO] - Training Epoch: 2/2, step 23582/23838 completed (loss: 0.5721471905708313, acc: 0.8421052694320679)
[2025-02-04 03:12:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23584/23838 [35:30<01:34,  2.70it/s][2025-02-04 03:12:20][root][INFO] - Training Epoch: 2/2, step 23583/23838 completed (loss: 0.6133363246917725, acc: 0.8113207817077637)
[2025-02-04 03:12:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23585/23838 [35:30<01:31,  2.77it/s][2025-02-04 03:12:20][root][INFO] - Training Epoch: 2/2, step 23584/23838 completed (loss: 0.3790102005004883, acc: 0.9230769276618958)
[2025-02-04 03:12:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23586/23838 [35:31<01:30,  2.78it/s][2025-02-04 03:12:20][root][INFO] - Training Epoch: 2/2, step 23585/23838 completed (loss: 0.4313361644744873, acc: 0.9047619104385376)
[2025-02-04 03:12:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23587/23838 [35:31<01:28,  2.84it/s][2025-02-04 03:12:21][root][INFO] - Training Epoch: 2/2, step 23586/23838 completed (loss: 0.36396655440330505, acc: 0.8970588445663452)
[2025-02-04 03:12:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23588/23838 [35:32<01:32,  2.70it/s][2025-02-04 03:12:21][root][INFO] - Training Epoch: 2/2, step 23587/23838 completed (loss: 0.8937095403671265, acc: 0.8600000143051147)
[2025-02-04 03:12:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23589/23838 [35:32<01:36,  2.59it/s][2025-02-04 03:12:22][root][INFO] - Training Epoch: 2/2, step 23588/23838 completed (loss: 0.15493856370449066, acc: 0.95652174949646)
[2025-02-04 03:12:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23590/23838 [35:32<01:37,  2.55it/s][2025-02-04 03:12:22][root][INFO] - Training Epoch: 2/2, step 23589/23838 completed (loss: 0.3592369258403778, acc: 0.9135802388191223)
[2025-02-04 03:12:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23591/23838 [35:33<01:35,  2.58it/s][2025-02-04 03:12:22][root][INFO] - Training Epoch: 2/2, step 23590/23838 completed (loss: 0.3148195147514343, acc: 0.9300000071525574)
[2025-02-04 03:12:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23592/23838 [35:33<01:38,  2.49it/s][2025-02-04 03:12:23][root][INFO] - Training Epoch: 2/2, step 23591/23838 completed (loss: 0.24467185139656067, acc: 0.9385964870452881)
[2025-02-04 03:12:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23593/23838 [35:34<01:36,  2.55it/s][2025-02-04 03:12:23][root][INFO] - Training Epoch: 2/2, step 23592/23838 completed (loss: 0.42172303795814514, acc: 0.8854166865348816)
[2025-02-04 03:12:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23594/23838 [35:34<01:32,  2.63it/s][2025-02-04 03:12:23][root][INFO] - Training Epoch: 2/2, step 23593/23838 completed (loss: 0.1473616063594818, acc: 0.9700000286102295)
[2025-02-04 03:12:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23595/23838 [35:34<01:29,  2.72it/s][2025-02-04 03:12:24][root][INFO] - Training Epoch: 2/2, step 23594/23838 completed (loss: 0.3603624403476715, acc: 0.8924731016159058)
[2025-02-04 03:12:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23596/23838 [35:35<01:30,  2.69it/s][2025-02-04 03:12:24][root][INFO] - Training Epoch: 2/2, step 23595/23838 completed (loss: 0.12996500730514526, acc: 0.9444444179534912)
[2025-02-04 03:12:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23597/23838 [35:35<01:28,  2.73it/s][2025-02-04 03:12:25][root][INFO] - Training Epoch: 2/2, step 23596/23838 completed (loss: 0.41499122977256775, acc: 0.8813559412956238)
[2025-02-04 03:12:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23598/23838 [35:35<01:22,  2.90it/s][2025-02-04 03:12:25][root][INFO] - Training Epoch: 2/2, step 23597/23838 completed (loss: 0.40358418226242065, acc: 0.8545454740524292)
[2025-02-04 03:12:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23599/23838 [35:36<01:20,  2.97it/s][2025-02-04 03:12:25][root][INFO] - Training Epoch: 2/2, step 23598/23838 completed (loss: 0.5971086025238037, acc: 0.8586956262588501)
[2025-02-04 03:12:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23600/23838 [35:36<01:19,  3.01it/s][2025-02-04 03:12:25][root][INFO] - Training Epoch: 2/2, step 23599/23838 completed (loss: 0.33762863278388977, acc: 0.9195402264595032)
[2025-02-04 03:12:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23601/23838 [35:36<01:18,  3.01it/s][2025-02-04 03:12:26][root][INFO] - Training Epoch: 2/2, step 23600/23838 completed (loss: 0.19228678941726685, acc: 0.9390243887901306)
[2025-02-04 03:12:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23602/23838 [35:37<01:16,  3.10it/s][2025-02-04 03:12:26][root][INFO] - Training Epoch: 2/2, step 23601/23838 completed (loss: 0.2615623474121094, acc: 0.9351851940155029)
[2025-02-04 03:12:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23603/23838 [35:37<01:18,  2.99it/s][2025-02-04 03:12:26][root][INFO] - Training Epoch: 2/2, step 23602/23838 completed (loss: 0.5074228644371033, acc: 0.876288652420044)
[2025-02-04 03:12:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23604/23838 [35:37<01:19,  2.96it/s][2025-02-04 03:12:27][root][INFO] - Training Epoch: 2/2, step 23603/23838 completed (loss: 0.5609138011932373, acc: 0.8433734774589539)
[2025-02-04 03:12:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23605/23838 [35:38<01:17,  3.01it/s][2025-02-04 03:12:27][root][INFO] - Training Epoch: 2/2, step 23604/23838 completed (loss: 0.19450783729553223, acc: 0.9583333134651184)
[2025-02-04 03:12:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23606/23838 [35:38<01:18,  2.96it/s][2025-02-04 03:12:28][root][INFO] - Training Epoch: 2/2, step 23605/23838 completed (loss: 0.7745590209960938, acc: 0.7166666388511658)
[2025-02-04 03:12:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23607/23838 [35:38<01:20,  2.88it/s][2025-02-04 03:12:28][root][INFO] - Training Epoch: 2/2, step 23606/23838 completed (loss: 0.3479466438293457, acc: 0.8969072103500366)
[2025-02-04 03:12:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23608/23838 [35:39<01:18,  2.91it/s][2025-02-04 03:12:28][root][INFO] - Training Epoch: 2/2, step 23607/23838 completed (loss: 0.3749885857105255, acc: 0.8999999761581421)
[2025-02-04 03:12:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23609/23838 [35:39<01:14,  3.07it/s][2025-02-04 03:12:28][root][INFO] - Training Epoch: 2/2, step 23608/23838 completed (loss: 0.17481768131256104, acc: 0.9444444179534912)
[2025-02-04 03:12:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23610/23838 [35:39<01:13,  3.08it/s][2025-02-04 03:12:29][root][INFO] - Training Epoch: 2/2, step 23609/23838 completed (loss: 0.23990817368030548, acc: 0.938144326210022)
[2025-02-04 03:12:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23611/23838 [35:40<01:14,  3.04it/s][2025-02-04 03:12:29][root][INFO] - Training Epoch: 2/2, step 23610/23838 completed (loss: 0.17030535638332367, acc: 0.9487179517745972)
[2025-02-04 03:12:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23612/23838 [35:40<01:13,  3.06it/s][2025-02-04 03:12:29][root][INFO] - Training Epoch: 2/2, step 23611/23838 completed (loss: 0.44701388478279114, acc: 0.8936170339584351)
[2025-02-04 03:12:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23613/23838 [35:40<01:14,  3.01it/s][2025-02-04 03:12:30][root][INFO] - Training Epoch: 2/2, step 23612/23838 completed (loss: 0.2946712374687195, acc: 0.8857142925262451)
[2025-02-04 03:12:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23614/23838 [35:41<01:18,  2.85it/s][2025-02-04 03:12:30][root][INFO] - Training Epoch: 2/2, step 23613/23838 completed (loss: 0.43095988035202026, acc: 0.9101123809814453)
[2025-02-04 03:12:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23615/23838 [35:41<01:18,  2.85it/s][2025-02-04 03:12:31][root][INFO] - Training Epoch: 2/2, step 23614/23838 completed (loss: 0.1781424880027771, acc: 0.9264705777168274)
[2025-02-04 03:12:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23616/23838 [35:41<01:19,  2.79it/s][2025-02-04 03:12:31][root][INFO] - Training Epoch: 2/2, step 23615/23838 completed (loss: 0.2808283865451813, acc: 0.9130434989929199)
[2025-02-04 03:12:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23617/23838 [35:42<01:22,  2.67it/s][2025-02-04 03:12:31][root][INFO] - Training Epoch: 2/2, step 23616/23838 completed (loss: 0.1866900622844696, acc: 0.938144326210022)
[2025-02-04 03:12:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23618/23838 [35:42<01:22,  2.66it/s][2025-02-04 03:12:32][root][INFO] - Training Epoch: 2/2, step 23617/23838 completed (loss: 0.5098180174827576, acc: 0.8705882430076599)
[2025-02-04 03:12:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23619/23838 [35:42<01:20,  2.71it/s][2025-02-04 03:12:32][root][INFO] - Training Epoch: 2/2, step 23618/23838 completed (loss: 0.5355036854743958, acc: 0.8295454382896423)
[2025-02-04 03:12:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23620/23838 [35:43<01:18,  2.76it/s][2025-02-04 03:12:32][root][INFO] - Training Epoch: 2/2, step 23619/23838 completed (loss: 0.22072656452655792, acc: 0.931034505367279)
[2025-02-04 03:12:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23621/23838 [35:43<01:15,  2.86it/s][2025-02-04 03:12:33][root][INFO] - Training Epoch: 2/2, step 23620/23838 completed (loss: 0.5741885900497437, acc: 0.8484848737716675)
[2025-02-04 03:12:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23622/23838 [35:43<01:13,  2.95it/s][2025-02-04 03:12:33][root][INFO] - Training Epoch: 2/2, step 23621/23838 completed (loss: 0.2348509579896927, acc: 0.9166666865348816)
[2025-02-04 03:12:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23623/23838 [35:44<01:11,  3.00it/s][2025-02-04 03:12:33][root][INFO] - Training Epoch: 2/2, step 23622/23838 completed (loss: 0.22328044474124908, acc: 0.9264705777168274)
[2025-02-04 03:12:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23624/23838 [35:44<01:06,  3.22it/s][2025-02-04 03:12:34][root][INFO] - Training Epoch: 2/2, step 23623/23838 completed (loss: 0.5325478911399841, acc: 0.7848101258277893)
[2025-02-04 03:12:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23625/23838 [35:44<01:02,  3.39it/s][2025-02-04 03:12:34][root][INFO] - Training Epoch: 2/2, step 23624/23838 completed (loss: 0.17020274698734283, acc: 0.9615384340286255)
[2025-02-04 03:12:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23626/23838 [35:45<01:06,  3.20it/s][2025-02-04 03:12:34][root][INFO] - Training Epoch: 2/2, step 23625/23838 completed (loss: 0.1431419402360916, acc: 0.9553571343421936)
[2025-02-04 03:12:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23627/23838 [35:45<01:09,  3.02it/s][2025-02-04 03:12:35][root][INFO] - Training Epoch: 2/2, step 23626/23838 completed (loss: 0.3115270733833313, acc: 0.9450549483299255)
[2025-02-04 03:12:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23628/23838 [35:45<01:14,  2.84it/s][2025-02-04 03:12:35][root][INFO] - Training Epoch: 2/2, step 23627/23838 completed (loss: 0.1840870976448059, acc: 0.9279999732971191)
[2025-02-04 03:12:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23629/23838 [35:46<01:13,  2.83it/s][2025-02-04 03:12:35][root][INFO] - Training Epoch: 2/2, step 23628/23838 completed (loss: 0.29691168665885925, acc: 0.9466666579246521)
[2025-02-04 03:12:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23630/23838 [35:46<01:13,  2.85it/s][2025-02-04 03:12:36][root][INFO] - Training Epoch: 2/2, step 23629/23838 completed (loss: 0.24853207170963287, acc: 0.9259259104728699)
[2025-02-04 03:12:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23631/23838 [35:47<01:13,  2.82it/s][2025-02-04 03:12:36][root][INFO] - Training Epoch: 2/2, step 23630/23838 completed (loss: 0.21692723035812378, acc: 0.8947368264198303)
[2025-02-04 03:12:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23632/23838 [35:47<01:14,  2.75it/s][2025-02-04 03:12:36][root][INFO] - Training Epoch: 2/2, step 23631/23838 completed (loss: 0.21264399588108063, acc: 0.9577465057373047)
[2025-02-04 03:12:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23633/23838 [35:47<01:17,  2.64it/s][2025-02-04 03:12:37][root][INFO] - Training Epoch: 2/2, step 23632/23838 completed (loss: 0.1491890847682953, acc: 0.9512194991111755)
[2025-02-04 03:12:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23634/23838 [35:48<01:17,  2.65it/s][2025-02-04 03:12:37][root][INFO] - Training Epoch: 2/2, step 23633/23838 completed (loss: 0.33717989921569824, acc: 0.9078947305679321)
[2025-02-04 03:12:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23635/23838 [35:48<01:13,  2.75it/s][2025-02-04 03:12:38][root][INFO] - Training Epoch: 2/2, step 23634/23838 completed (loss: 0.42119258642196655, acc: 0.8082191944122314)
[2025-02-04 03:12:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23636/23838 [35:48<01:12,  2.78it/s][2025-02-04 03:12:38][root][INFO] - Training Epoch: 2/2, step 23635/23838 completed (loss: 0.3840982913970947, acc: 0.8840579986572266)
[2025-02-04 03:12:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23637/23838 [35:49<01:13,  2.75it/s][2025-02-04 03:12:38][root][INFO] - Training Epoch: 2/2, step 23636/23838 completed (loss: 0.12447302788496017, acc: 0.948051929473877)
[2025-02-04 03:12:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23638/23838 [35:49<01:16,  2.61it/s][2025-02-04 03:12:39][root][INFO] - Training Epoch: 2/2, step 23637/23838 completed (loss: 0.6137687563896179, acc: 0.808080792427063)
[2025-02-04 03:12:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23639/23838 [35:50<01:16,  2.61it/s][2025-02-04 03:12:39][root][INFO] - Training Epoch: 2/2, step 23638/23838 completed (loss: 0.1538206934928894, acc: 0.9550561904907227)
[2025-02-04 03:12:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23640/23838 [35:50<01:12,  2.75it/s][2025-02-04 03:12:39][root][INFO] - Training Epoch: 2/2, step 23639/23838 completed (loss: 0.19087237119674683, acc: 0.9578947424888611)
[2025-02-04 03:12:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23641/23838 [35:50<01:07,  2.90it/s][2025-02-04 03:12:40][root][INFO] - Training Epoch: 2/2, step 23640/23838 completed (loss: 0.6925726532936096, acc: 0.8153846263885498)
[2025-02-04 03:12:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23642/23838 [35:51<01:07,  2.89it/s][2025-02-04 03:12:40][root][INFO] - Training Epoch: 2/2, step 23641/23838 completed (loss: 0.18814446032047272, acc: 0.9399999976158142)
[2025-02-04 03:12:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23643/23838 [35:51<01:07,  2.91it/s][2025-02-04 03:12:40][root][INFO] - Training Epoch: 2/2, step 23642/23838 completed (loss: 0.3048342764377594, acc: 0.9220778942108154)
[2025-02-04 03:12:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23644/23838 [35:51<01:06,  2.90it/s][2025-02-04 03:12:41][root][INFO] - Training Epoch: 2/2, step 23643/23838 completed (loss: 0.27684032917022705, acc: 0.9166666865348816)
[2025-02-04 03:12:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23645/23838 [35:52<01:05,  2.96it/s][2025-02-04 03:12:41][root][INFO] - Training Epoch: 2/2, step 23644/23838 completed (loss: 0.6448013186454773, acc: 0.7638888955116272)
[2025-02-04 03:12:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23646/23838 [35:52<01:04,  2.99it/s][2025-02-04 03:12:41][root][INFO] - Training Epoch: 2/2, step 23645/23838 completed (loss: 0.0938863456249237, acc: 0.9666666388511658)
[2025-02-04 03:12:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23647/23838 [35:52<01:02,  3.07it/s][2025-02-04 03:12:42][root][INFO] - Training Epoch: 2/2, step 23646/23838 completed (loss: 0.42349156737327576, acc: 0.8645833134651184)
[2025-02-04 03:12:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23648/23838 [35:53<01:06,  2.84it/s][2025-02-04 03:12:42][root][INFO] - Training Epoch: 2/2, step 23647/23838 completed (loss: 0.2903703451156616, acc: 0.9246575236320496)
[2025-02-04 03:12:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23649/23838 [35:53<01:09,  2.72it/s][2025-02-04 03:12:43][root][INFO] - Training Epoch: 2/2, step 23648/23838 completed (loss: 0.2738216817378998, acc: 0.913294792175293)
[2025-02-04 03:12:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23650/23838 [35:53<01:10,  2.66it/s][2025-02-04 03:12:43][root][INFO] - Training Epoch: 2/2, step 23649/23838 completed (loss: 0.1887369006872177, acc: 0.9333333373069763)
[2025-02-04 03:12:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23651/23838 [35:54<01:09,  2.67it/s][2025-02-04 03:12:43][root][INFO] - Training Epoch: 2/2, step 23650/23838 completed (loss: 0.6083860397338867, acc: 0.828125)
[2025-02-04 03:12:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23652/23838 [35:54<01:07,  2.74it/s][2025-02-04 03:12:44][root][INFO] - Training Epoch: 2/2, step 23651/23838 completed (loss: 0.10498417168855667, acc: 0.9770992398262024)
[2025-02-04 03:12:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23653/23838 [35:54<01:07,  2.72it/s][2025-02-04 03:12:44][root][INFO] - Training Epoch: 2/2, step 23652/23838 completed (loss: 0.24938435852527618, acc: 0.9239130616188049)
[2025-02-04 03:12:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23654/23838 [35:55<01:06,  2.76it/s][2025-02-04 03:12:44][root][INFO] - Training Epoch: 2/2, step 23653/23838 completed (loss: 0.21532690525054932, acc: 0.9247311949729919)
[2025-02-04 03:12:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23655/23838 [35:55<01:05,  2.81it/s][2025-02-04 03:12:45][root][INFO] - Training Epoch: 2/2, step 23654/23838 completed (loss: 0.34082260727882385, acc: 0.8818181753158569)
[2025-02-04 03:12:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23656/23838 [35:56<01:04,  2.81it/s][2025-02-04 03:12:45][root][INFO] - Training Epoch: 2/2, step 23655/23838 completed (loss: 0.3987691104412079, acc: 0.8970588445663452)
[2025-02-04 03:12:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23657/23838 [35:56<01:03,  2.84it/s][2025-02-04 03:12:45][root][INFO] - Training Epoch: 2/2, step 23656/23838 completed (loss: 0.38917678594589233, acc: 0.9180327653884888)
[2025-02-04 03:12:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23658/23838 [35:56<01:03,  2.83it/s][2025-02-04 03:12:46][root][INFO] - Training Epoch: 2/2, step 23657/23838 completed (loss: 0.577838659286499, acc: 0.8474576473236084)
[2025-02-04 03:12:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23659/23838 [35:57<01:07,  2.65it/s][2025-02-04 03:12:46][root][INFO] - Training Epoch: 2/2, step 23658/23838 completed (loss: 0.2935512661933899, acc: 0.9107142686843872)
[2025-02-04 03:12:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23660/23838 [35:57<01:09,  2.56it/s][2025-02-04 03:12:47][root][INFO] - Training Epoch: 2/2, step 23659/23838 completed (loss: 0.464711457490921, acc: 0.89552241563797)
[2025-02-04 03:12:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23661/23838 [35:57<01:09,  2.54it/s][2025-02-04 03:12:47][root][INFO] - Training Epoch: 2/2, step 23660/23838 completed (loss: 0.19029337167739868, acc: 0.9324324131011963)
[2025-02-04 03:12:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23662/23838 [35:58<01:12,  2.43it/s][2025-02-04 03:12:47][root][INFO] - Training Epoch: 2/2, step 23661/23838 completed (loss: 0.22124972939491272, acc: 0.9666666388511658)
[2025-02-04 03:12:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23663/23838 [35:58<01:09,  2.51it/s][2025-02-04 03:12:48][root][INFO] - Training Epoch: 2/2, step 23662/23838 completed (loss: 0.24872982501983643, acc: 0.9462365508079529)
[2025-02-04 03:12:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23664/23838 [35:59<01:06,  2.63it/s][2025-02-04 03:12:48][root][INFO] - Training Epoch: 2/2, step 23663/23838 completed (loss: 0.4579642415046692, acc: 0.8850574493408203)
[2025-02-04 03:12:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23665/23838 [35:59<01:03,  2.74it/s][2025-02-04 03:12:49][root][INFO] - Training Epoch: 2/2, step 23664/23838 completed (loss: 0.13276712596416473, acc: 0.9624060392379761)
[2025-02-04 03:12:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23666/23838 [35:59<01:01,  2.79it/s][2025-02-04 03:12:49][root][INFO] - Training Epoch: 2/2, step 23665/23838 completed (loss: 0.1362154632806778, acc: 0.9541984796524048)
[2025-02-04 03:12:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23667/23838 [36:00<01:00,  2.84it/s][2025-02-04 03:12:49][root][INFO] - Training Epoch: 2/2, step 23666/23838 completed (loss: 0.18602018058300018, acc: 0.9659863710403442)
[2025-02-04 03:12:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23668/23838 [36:00<00:59,  2.86it/s][2025-02-04 03:12:50][root][INFO] - Training Epoch: 2/2, step 23667/23838 completed (loss: 0.27124646306037903, acc: 0.9337748289108276)
[2025-02-04 03:12:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23669/23838 [36:00<00:59,  2.84it/s][2025-02-04 03:12:50][root][INFO] - Training Epoch: 2/2, step 23668/23838 completed (loss: 0.23294797539710999, acc: 0.9266055226325989)
[2025-02-04 03:12:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23670/23838 [36:01<00:57,  2.92it/s][2025-02-04 03:12:50][root][INFO] - Training Epoch: 2/2, step 23669/23838 completed (loss: 0.32356569170951843, acc: 0.893750011920929)
[2025-02-04 03:12:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23671/23838 [36:01<00:55,  3.01it/s][2025-02-04 03:12:51][root][INFO] - Training Epoch: 2/2, step 23670/23838 completed (loss: 0.4682917296886444, acc: 0.8606557250022888)
[2025-02-04 03:12:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23672/23838 [36:01<00:54,  3.06it/s][2025-02-04 03:12:51][root][INFO] - Training Epoch: 2/2, step 23671/23838 completed (loss: 0.27853620052337646, acc: 0.936170220375061)
[2025-02-04 03:12:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23673/23838 [36:02<00:59,  2.80it/s][2025-02-04 03:12:51][root][INFO] - Training Epoch: 2/2, step 23672/23838 completed (loss: 0.45371657609939575, acc: 0.8617021441459656)
[2025-02-04 03:12:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23674/23838 [36:02<00:57,  2.87it/s][2025-02-04 03:12:52][root][INFO] - Training Epoch: 2/2, step 23673/23838 completed (loss: 0.4443359673023224, acc: 0.8640776872634888)
[2025-02-04 03:12:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23675/23838 [36:02<00:59,  2.75it/s][2025-02-04 03:12:52][root][INFO] - Training Epoch: 2/2, step 23674/23838 completed (loss: 0.18257637321949005, acc: 0.9479166865348816)
[2025-02-04 03:12:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23676/23838 [36:03<00:59,  2.72it/s][2025-02-04 03:12:52][root][INFO] - Training Epoch: 2/2, step 23675/23838 completed (loss: 0.33878225088119507, acc: 0.8897637724876404)
[2025-02-04 03:12:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23677/23838 [36:03<01:00,  2.65it/s][2025-02-04 03:12:53][root][INFO] - Training Epoch: 2/2, step 23676/23838 completed (loss: 0.2977241277694702, acc: 0.9014084339141846)
[2025-02-04 03:12:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23678/23838 [36:04<01:01,  2.58it/s][2025-02-04 03:12:53][root][INFO] - Training Epoch: 2/2, step 23677/23838 completed (loss: 0.2153729945421219, acc: 0.9279999732971191)
[2025-02-04 03:12:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23679/23838 [36:04<00:58,  2.73it/s][2025-02-04 03:12:54][root][INFO] - Training Epoch: 2/2, step 23678/23838 completed (loss: 0.43465161323547363, acc: 0.9052631855010986)
[2025-02-04 03:12:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23680/23838 [36:04<00:57,  2.77it/s][2025-02-04 03:12:54][root][INFO] - Training Epoch: 2/2, step 23679/23838 completed (loss: 0.12695664167404175, acc: 0.9599999785423279)
[2025-02-04 03:12:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23681/23838 [36:05<00:56,  2.77it/s][2025-02-04 03:12:54][root][INFO] - Training Epoch: 2/2, step 23680/23838 completed (loss: 0.33534035086631775, acc: 0.9166666865348816)
[2025-02-04 03:12:54][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23682/23838 [36:05<00:54,  2.86it/s][2025-02-04 03:12:55][root][INFO] - Training Epoch: 2/2, step 23681/23838 completed (loss: 0.31855493783950806, acc: 0.9024389982223511)
[2025-02-04 03:12:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23683/23838 [36:05<00:55,  2.80it/s][2025-02-04 03:12:55][root][INFO] - Training Epoch: 2/2, step 23682/23838 completed (loss: 0.41010546684265137, acc: 0.8585858345031738)
[2025-02-04 03:12:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23684/23838 [36:06<00:55,  2.80it/s][2025-02-04 03:12:55][root][INFO] - Training Epoch: 2/2, step 23683/23838 completed (loss: 0.37114417552948, acc: 0.8840579986572266)
[2025-02-04 03:12:55][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23685/23838 [36:06<00:54,  2.79it/s][2025-02-04 03:12:56][root][INFO] - Training Epoch: 2/2, step 23684/23838 completed (loss: 0.34954872727394104, acc: 0.931506872177124)
[2025-02-04 03:12:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23686/23838 [36:06<00:56,  2.69it/s][2025-02-04 03:12:56][root][INFO] - Training Epoch: 2/2, step 23685/23838 completed (loss: 0.35509610176086426, acc: 0.9215686321258545)
[2025-02-04 03:12:56][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23687/23838 [36:07<00:58,  2.58it/s][2025-02-04 03:12:56][root][INFO] - Training Epoch: 2/2, step 23686/23838 completed (loss: 0.1797030121088028, acc: 0.9463087320327759)
[2025-02-04 03:12:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23688/23838 [36:07<00:58,  2.58it/s][2025-02-04 03:12:57][root][INFO] - Training Epoch: 2/2, step 23687/23838 completed (loss: 0.19555428624153137, acc: 0.9417475461959839)
[2025-02-04 03:12:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23689/23838 [36:08<00:55,  2.69it/s][2025-02-04 03:12:57][root][INFO] - Training Epoch: 2/2, step 23688/23838 completed (loss: 0.5233139395713806, acc: 0.8548387289047241)
[2025-02-04 03:12:57][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23690/23838 [36:08<00:53,  2.76it/s][2025-02-04 03:12:58][root][INFO] - Training Epoch: 2/2, step 23689/23838 completed (loss: 0.4262748956680298, acc: 0.8653846383094788)
[2025-02-04 03:12:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23691/23838 [36:08<00:51,  2.88it/s][2025-02-04 03:12:58][root][INFO] - Training Epoch: 2/2, step 23690/23838 completed (loss: 0.3949638903141022, acc: 0.9113923907279968)
[2025-02-04 03:12:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23692/23838 [36:09<00:49,  2.93it/s][2025-02-04 03:12:58][root][INFO] - Training Epoch: 2/2, step 23691/23838 completed (loss: 0.33321380615234375, acc: 0.9122806787490845)
[2025-02-04 03:12:58][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23693/23838 [36:09<00:49,  2.90it/s][2025-02-04 03:12:59][root][INFO] - Training Epoch: 2/2, step 23692/23838 completed (loss: 0.6875269412994385, acc: 0.8539325594902039)
[2025-02-04 03:12:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23694/23838 [36:09<00:47,  3.01it/s][2025-02-04 03:12:59][root][INFO] - Training Epoch: 2/2, step 23693/23838 completed (loss: 0.12852676212787628, acc: 0.961240291595459)
[2025-02-04 03:12:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23695/23838 [36:10<00:45,  3.13it/s][2025-02-04 03:12:59][root][INFO] - Training Epoch: 2/2, step 23694/23838 completed (loss: 0.26374921202659607, acc: 0.931034505367279)
[2025-02-04 03:12:59][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23696/23838 [36:10<00:47,  3.00it/s][2025-02-04 03:12:59][root][INFO] - Training Epoch: 2/2, step 23695/23838 completed (loss: 0.24974435567855835, acc: 0.9134615659713745)
[2025-02-04 03:13:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23697/23838 [36:10<00:46,  3.04it/s][2025-02-04 03:13:00][root][INFO] - Training Epoch: 2/2, step 23696/23838 completed (loss: 0.2191426157951355, acc: 0.932584285736084)
[2025-02-04 03:13:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23698/23838 [36:11<00:45,  3.09it/s][2025-02-04 03:13:00][root][INFO] - Training Epoch: 2/2, step 23697/23838 completed (loss: 0.21444812417030334, acc: 0.9176470637321472)
[2025-02-04 03:13:00][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23699/23838 [36:11<00:44,  3.11it/s][2025-02-04 03:13:00][root][INFO] - Training Epoch: 2/2, step 23698/23838 completed (loss: 0.22094303369522095, acc: 0.9419354796409607)
[2025-02-04 03:13:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23700/23838 [36:11<00:46,  2.95it/s][2025-02-04 03:13:01][root][INFO] - Training Epoch: 2/2, step 23699/23838 completed (loss: 0.6917842030525208, acc: 0.8909090757369995)
[2025-02-04 03:13:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23701/23838 [36:12<00:45,  3.00it/s][2025-02-04 03:13:01][root][INFO] - Training Epoch: 2/2, step 23700/23838 completed (loss: 0.5090811252593994, acc: 0.8888888955116272)
[2025-02-04 03:13:01][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23702/23838 [36:12<00:44,  3.07it/s][2025-02-04 03:13:01][root][INFO] - Training Epoch: 2/2, step 23701/23838 completed (loss: 0.6669380068778992, acc: 0.8666666746139526)
[2025-02-04 03:13:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23703/23838 [36:12<00:45,  2.94it/s][2025-02-04 03:13:02][root][INFO] - Training Epoch: 2/2, step 23702/23838 completed (loss: 0.11590921133756638, acc: 1.0)
[2025-02-04 03:13:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23704/23838 [36:13<00:46,  2.90it/s][2025-02-04 03:13:02][root][INFO] - Training Epoch: 2/2, step 23703/23838 completed (loss: 0.3231308162212372, acc: 0.8846153616905212)
[2025-02-04 03:13:02][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23705/23838 [36:13<00:45,  2.90it/s][2025-02-04 03:13:03][root][INFO] - Training Epoch: 2/2, step 23704/23838 completed (loss: 0.665262758731842, acc: 0.8148148059844971)
[2025-02-04 03:13:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23706/23838 [36:13<00:45,  2.92it/s][2025-02-04 03:13:03][root][INFO] - Training Epoch: 2/2, step 23705/23838 completed (loss: 0.3021141588687897, acc: 0.9333333373069763)
[2025-02-04 03:13:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23707/23838 [36:14<00:44,  2.96it/s][2025-02-04 03:13:03][root][INFO] - Training Epoch: 2/2, step 23706/23838 completed (loss: 0.24457961320877075, acc: 0.9333333373069763)
[2025-02-04 03:13:03][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23708/23838 [36:14<00:44,  2.92it/s][2025-02-04 03:13:04][root][INFO] - Training Epoch: 2/2, step 23707/23838 completed (loss: 0.28084269165992737, acc: 0.9166666865348816)
[2025-02-04 03:13:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23709/23838 [36:14<00:44,  2.87it/s][2025-02-04 03:13:04][root][INFO] - Training Epoch: 2/2, step 23708/23838 completed (loss: 0.32332292199134827, acc: 0.9230769276618958)
[2025-02-04 03:13:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23710/23838 [36:15<00:46,  2.78it/s][2025-02-04 03:13:04][root][INFO] - Training Epoch: 2/2, step 23709/23838 completed (loss: 0.26393985748291016, acc: 0.9399999976158142)
[2025-02-04 03:13:04][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23711/23838 [36:15<00:45,  2.82it/s][2025-02-04 03:13:05][root][INFO] - Training Epoch: 2/2, step 23710/23838 completed (loss: 0.23599949479103088, acc: 0.9516128897666931)
[2025-02-04 03:13:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23712/23838 [36:15<00:45,  2.74it/s][2025-02-04 03:13:05][root][INFO] - Training Epoch: 2/2, step 23711/23838 completed (loss: 0.22916829586029053, acc: 0.9428571462631226)
[2025-02-04 03:13:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23713/23838 [36:16<00:45,  2.74it/s][2025-02-04 03:13:05][root][INFO] - Training Epoch: 2/2, step 23712/23838 completed (loss: 0.16652299463748932, acc: 0.9142857193946838)
[2025-02-04 03:13:05][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23714/23838 [36:16<00:43,  2.83it/s][2025-02-04 03:13:06][root][INFO] - Training Epoch: 2/2, step 23713/23838 completed (loss: 0.3305263817310333, acc: 0.9130434989929199)
[2025-02-04 03:13:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23715/23838 [36:16<00:44,  2.78it/s][2025-02-04 03:13:06][root][INFO] - Training Epoch: 2/2, step 23714/23838 completed (loss: 0.20349948108196259, acc: 0.9523809552192688)
[2025-02-04 03:13:06][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23716/23838 [36:17<00:46,  2.65it/s][2025-02-04 03:13:06][root][INFO] - Training Epoch: 2/2, step 23715/23838 completed (loss: 0.4246104955673218, acc: 0.859649121761322)
[2025-02-04 03:13:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23717/23838 [36:17<00:43,  2.75it/s][2025-02-04 03:13:07][root][INFO] - Training Epoch: 2/2, step 23716/23838 completed (loss: 0.4044983983039856, acc: 0.8947368264198303)
[2025-02-04 03:13:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2:  99%|[34m█████████▉[0m| 23718/23838 [36:18<00:42,  2.80it/s][2025-02-04 03:13:07][root][INFO] - Training Epoch: 2/2, step 23717/23838 completed (loss: 0.3393641710281372, acc: 0.920634925365448)
[2025-02-04 03:13:07][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23719/23838 [36:18<00:44,  2.67it/s][2025-02-04 03:13:08][root][INFO] - Training Epoch: 2/2, step 23718/23838 completed (loss: 0.2845114767551422, acc: 0.8529411554336548)
[2025-02-04 03:13:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23720/23838 [36:18<00:44,  2.64it/s][2025-02-04 03:13:08][root][INFO] - Training Epoch: 2/2, step 23719/23838 completed (loss: 0.08349605649709702, acc: 0.9756097793579102)
[2025-02-04 03:13:08][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23721/23838 [36:19<00:45,  2.55it/s][2025-02-04 03:13:08][root][INFO] - Training Epoch: 2/2, step 23720/23838 completed (loss: 0.884623646736145, acc: 0.75)
[2025-02-04 03:13:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23722/23838 [36:19<00:45,  2.55it/s][2025-02-04 03:13:09][root][INFO] - Training Epoch: 2/2, step 23721/23838 completed (loss: 0.14530836045742035, acc: 0.9583333134651184)
[2025-02-04 03:13:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23723/23838 [36:20<00:43,  2.63it/s][2025-02-04 03:13:09][root][INFO] - Training Epoch: 2/2, step 23722/23838 completed (loss: 0.21812240779399872, acc: 0.9448819160461426)
[2025-02-04 03:13:09][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23724/23838 [36:20<00:44,  2.59it/s][2025-02-04 03:13:10][root][INFO] - Training Epoch: 2/2, step 23723/23838 completed (loss: 0.30498263239860535, acc: 0.9545454382896423)
[2025-02-04 03:13:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23725/23838 [36:20<00:42,  2.67it/s][2025-02-04 03:13:10][root][INFO] - Training Epoch: 2/2, step 23724/23838 completed (loss: 0.579620897769928, acc: 0.8695651888847351)
[2025-02-04 03:13:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23726/23838 [36:21<00:42,  2.64it/s][2025-02-04 03:13:10][root][INFO] - Training Epoch: 2/2, step 23725/23838 completed (loss: 0.40971502661705017, acc: 0.8500000238418579)
[2025-02-04 03:13:10][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23727/23838 [36:21<00:41,  2.69it/s][2025-02-04 03:13:11][root][INFO] - Training Epoch: 2/2, step 23726/23838 completed (loss: 0.6824792623519897, acc: 0.9285714030265808)
[2025-02-04 03:13:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23728/23838 [36:21<00:41,  2.64it/s][2025-02-04 03:13:11][root][INFO] - Training Epoch: 2/2, step 23727/23838 completed (loss: 0.3991250693798065, acc: 0.8529411554336548)
[2025-02-04 03:13:11][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23729/23838 [36:22<00:40,  2.66it/s][2025-02-04 03:13:11][root][INFO] - Training Epoch: 2/2, step 23728/23838 completed (loss: 0.5367537140846252, acc: 0.8461538553237915)
[2025-02-04 03:13:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23730/23838 [36:22<00:42,  2.52it/s][2025-02-04 03:13:12][root][INFO] - Training Epoch: 2/2, step 23729/23838 completed (loss: 0.1509758085012436, acc: 0.9444444179534912)
[2025-02-04 03:13:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23731/23838 [36:23<00:42,  2.49it/s][2025-02-04 03:13:12][root][INFO] - Training Epoch: 2/2, step 23730/23838 completed (loss: 0.43457257747650146, acc: 0.8809523582458496)
[2025-02-04 03:13:12][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23732/23838 [36:23<00:41,  2.58it/s][2025-02-04 03:13:13][root][INFO] - Training Epoch: 2/2, step 23731/23838 completed (loss: 0.13803541660308838, acc: 0.9473684430122375)
[2025-02-04 03:13:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23733/23838 [36:23<00:40,  2.59it/s][2025-02-04 03:13:13][root][INFO] - Training Epoch: 2/2, step 23732/23838 completed (loss: 0.060966625809669495, acc: 0.9666666388511658)
[2025-02-04 03:13:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23734/23838 [36:24<00:40,  2.58it/s][2025-02-04 03:13:13][root][INFO] - Training Epoch: 2/2, step 23733/23838 completed (loss: 0.19493240118026733, acc: 0.9655172228813171)
[2025-02-04 03:13:13][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23735/23838 [36:24<00:38,  2.65it/s][2025-02-04 03:13:14][root][INFO] - Training Epoch: 2/2, step 23734/23838 completed (loss: 0.1864294856786728, acc: 0.9767441749572754)
[2025-02-04 03:13:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23736/23838 [36:25<00:37,  2.69it/s][2025-02-04 03:13:14][root][INFO] - Training Epoch: 2/2, step 23735/23838 completed (loss: 0.05959583446383476, acc: 0.9726027250289917)
[2025-02-04 03:13:14][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23737/23838 [36:25<00:36,  2.78it/s][2025-02-04 03:13:14][root][INFO] - Training Epoch: 2/2, step 23736/23838 completed (loss: 0.1166481077671051, acc: 0.96875)
[2025-02-04 03:13:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23738/23838 [36:25<00:36,  2.72it/s][2025-02-04 03:13:15][root][INFO] - Training Epoch: 2/2, step 23737/23838 completed (loss: 0.22957566380500793, acc: 0.9710144996643066)
[2025-02-04 03:13:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23739/23838 [36:26<00:37,  2.67it/s][2025-02-04 03:13:15][root][INFO] - Training Epoch: 2/2, step 23738/23838 completed (loss: 0.08483324199914932, acc: 0.9811320900917053)
[2025-02-04 03:13:15][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23740/23838 [36:26<00:36,  2.70it/s][2025-02-04 03:13:16][root][INFO] - Training Epoch: 2/2, step 23739/23838 completed (loss: 0.1369653046131134, acc: 0.9861111044883728)
[2025-02-04 03:13:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23741/23838 [36:26<00:35,  2.72it/s][2025-02-04 03:13:16][root][INFO] - Training Epoch: 2/2, step 23740/23838 completed (loss: 0.0711062029004097, acc: 1.0)
[2025-02-04 03:13:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23742/23838 [36:27<00:34,  2.77it/s][2025-02-04 03:13:16][root][INFO] - Training Epoch: 2/2, step 23741/23838 completed (loss: 0.10311119258403778, acc: 0.9743589758872986)
[2025-02-04 03:13:16][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23743/23838 [36:27<00:33,  2.84it/s][2025-02-04 03:13:17][root][INFO] - Training Epoch: 2/2, step 23742/23838 completed (loss: 0.08558133244514465, acc: 0.9795918464660645)
[2025-02-04 03:13:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23744/23838 [36:27<00:32,  2.88it/s][2025-02-04 03:13:17][root][INFO] - Training Epoch: 2/2, step 23743/23838 completed (loss: 0.7142632603645325, acc: 0.8809523582458496)
[2025-02-04 03:13:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23745/23838 [36:28<00:33,  2.79it/s][2025-02-04 03:13:17][root][INFO] - Training Epoch: 2/2, step 23744/23838 completed (loss: 0.30592262744903564, acc: 0.9189189076423645)
[2025-02-04 03:13:17][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23746/23838 [36:28<00:34,  2.66it/s][2025-02-04 03:13:18][root][INFO] - Training Epoch: 2/2, step 23745/23838 completed (loss: 0.879097044467926, acc: 0.761904776096344)
[2025-02-04 03:13:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23747/23838 [36:29<00:37,  2.44it/s][2025-02-04 03:13:18][root][INFO] - Training Epoch: 2/2, step 23746/23838 completed (loss: 0.24348586797714233, acc: 0.938144326210022)
[2025-02-04 03:13:18][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23748/23838 [36:29<00:33,  2.65it/s][2025-02-04 03:13:19][root][INFO] - Training Epoch: 2/2, step 23747/23838 completed (loss: 0.5745288133621216, acc: 0.8541666865348816)
[2025-02-04 03:13:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23749/23838 [36:29<00:34,  2.58it/s][2025-02-04 03:13:19][root][INFO] - Training Epoch: 2/2, step 23748/23838 completed (loss: 0.40341442823410034, acc: 0.8709677457809448)
[2025-02-04 03:13:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23750/23838 [36:30<00:33,  2.60it/s][2025-02-04 03:13:19][root][INFO] - Training Epoch: 2/2, step 23749/23838 completed (loss: 0.5062545537948608, acc: 0.925000011920929)
[2025-02-04 03:13:19][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23751/23838 [36:30<00:33,  2.63it/s][2025-02-04 03:13:20][root][INFO] - Training Epoch: 2/2, step 23750/23838 completed (loss: 0.05643606558442116, acc: 1.0)
[2025-02-04 03:13:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23752/23838 [36:30<00:31,  2.73it/s][2025-02-04 03:13:20][root][INFO] - Training Epoch: 2/2, step 23751/23838 completed (loss: 1.1463521718978882, acc: 0.6666666865348816)
[2025-02-04 03:13:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23753/23838 [36:31<00:30,  2.75it/s][2025-02-04 03:13:20][root][INFO] - Training Epoch: 2/2, step 23752/23838 completed (loss: 0.04883226379752159, acc: 1.0)
[2025-02-04 03:13:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23754/23838 [36:31<00:30,  2.79it/s][2025-02-04 03:13:21][root][INFO] - Training Epoch: 2/2, step 23753/23838 completed (loss: 0.0708126574754715, acc: 1.0)
[2025-02-04 03:13:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23755/23838 [36:32<00:30,  2.71it/s][2025-02-04 03:13:21][root][INFO] - Training Epoch: 2/2, step 23754/23838 completed (loss: 0.3943590521812439, acc: 0.8461538553237915)
[2025-02-04 03:13:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23756/23838 [36:32<00:29,  2.76it/s][2025-02-04 03:13:21][root][INFO] - Training Epoch: 2/2, step 23755/23838 completed (loss: 0.3097952604293823, acc: 0.918367326259613)
[2025-02-04 03:13:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23757/23838 [36:32<00:28,  2.88it/s][2025-02-04 03:13:22][root][INFO] - Training Epoch: 2/2, step 23756/23838 completed (loss: 0.1841188371181488, acc: 0.8999999761581421)
[2025-02-04 03:13:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23758/23838 [36:33<00:27,  2.91it/s][2025-02-04 03:13:22][root][INFO] - Training Epoch: 2/2, step 23757/23838 completed (loss: 0.2769300639629364, acc: 0.9230769276618958)
[2025-02-04 03:13:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23759/23838 [36:33<00:26,  2.94it/s][2025-02-04 03:13:22][root][INFO] - Training Epoch: 2/2, step 23758/23838 completed (loss: 0.29659172892570496, acc: 0.9090909361839294)
[2025-02-04 03:13:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23760/23838 [36:33<00:27,  2.81it/s][2025-02-04 03:13:23][root][INFO] - Training Epoch: 2/2, step 23759/23838 completed (loss: 0.09742379933595657, acc: 0.9599999785423279)
[2025-02-04 03:13:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23761/23838 [36:34<00:28,  2.70it/s][2025-02-04 03:13:23][root][INFO] - Training Epoch: 2/2, step 23760/23838 completed (loss: 0.8869035840034485, acc: 0.7976190447807312)
[2025-02-04 03:13:23][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23762/23838 [36:34<00:26,  2.85it/s][2025-02-04 03:13:24][root][INFO] - Training Epoch: 2/2, step 23761/23838 completed (loss: 0.5494328737258911, acc: 0.8275862336158752)
[2025-02-04 03:13:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23763/23838 [36:34<00:28,  2.62it/s][2025-02-04 03:13:24][root][INFO] - Training Epoch: 2/2, step 23762/23838 completed (loss: 0.9399703741073608, acc: 0.695652186870575)
[2025-02-04 03:13:24][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23764/23838 [36:35<00:29,  2.47it/s][2025-02-04 03:13:24][root][INFO] - Training Epoch: 2/2, step 23763/23838 completed (loss: 0.6532304286956787, acc: 0.8070175647735596)
[2025-02-04 03:13:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23765/23838 [36:35<00:28,  2.54it/s][2025-02-04 03:13:25][root][INFO] - Training Epoch: 2/2, step 23764/23838 completed (loss: 0.8525325059890747, acc: 0.7428571581840515)
[2025-02-04 03:13:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23766/23838 [36:36<00:30,  2.37it/s][2025-02-04 03:13:25][root][INFO] - Training Epoch: 2/2, step 23765/23838 completed (loss: 0.5095809102058411, acc: 0.8306451439857483)
[2025-02-04 03:13:25][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23767/23838 [36:36<00:28,  2.49it/s][2025-02-04 03:13:26][root][INFO] - Training Epoch: 2/2, step 23766/23838 completed (loss: 0.4482896327972412, acc: 0.8235294222831726)
[2025-02-04 03:13:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23768/23838 [36:37<00:31,  2.19it/s][2025-02-04 03:13:26][root][INFO] - Training Epoch: 2/2, step 23767/23838 completed (loss: 0.4302862882614136, acc: 0.8771929740905762)
[2025-02-04 03:13:26][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23769/23838 [36:37<00:29,  2.34it/s][2025-02-04 03:13:27][root][INFO] - Training Epoch: 2/2, step 23768/23838 completed (loss: 0.3826308250427246, acc: 0.8823529481887817)
[2025-02-04 03:13:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23770/23838 [36:37<00:28,  2.39it/s][2025-02-04 03:13:27][root][INFO] - Training Epoch: 2/2, step 23769/23838 completed (loss: 0.5163342952728271, acc: 0.8780487775802612)
[2025-02-04 03:13:27][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23771/23838 [36:38<00:31,  2.11it/s][2025-02-04 03:13:28][root][INFO] - Training Epoch: 2/2, step 23770/23838 completed (loss: 0.7121937870979309, acc: 0.7538461685180664)
[2025-02-04 03:13:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23772/23838 [36:38<00:28,  2.32it/s][2025-02-04 03:13:28][root][INFO] - Training Epoch: 2/2, step 23771/23838 completed (loss: 0.2745085656642914, acc: 0.918367326259613)
[2025-02-04 03:13:28][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23773/23838 [36:39<00:27,  2.38it/s][2025-02-04 03:13:28][root][INFO] - Training Epoch: 2/2, step 23772/23838 completed (loss: 0.2213415801525116, acc: 0.9397590160369873)
[2025-02-04 03:13:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23774/23838 [36:39<00:26,  2.38it/s][2025-02-04 03:13:29][root][INFO] - Training Epoch: 2/2, step 23773/23838 completed (loss: 0.08993591368198395, acc: 0.976190447807312)
[2025-02-04 03:13:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23775/23838 [36:40<00:25,  2.43it/s][2025-02-04 03:13:29][root][INFO] - Training Epoch: 2/2, step 23774/23838 completed (loss: 0.21041716635227203, acc: 0.9655172228813171)
[2025-02-04 03:13:29][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23776/23838 [36:40<00:24,  2.55it/s][2025-02-04 03:13:29][root][INFO] - Training Epoch: 2/2, step 23775/23838 completed (loss: 0.21332597732543945, acc: 0.9375)
[2025-02-04 03:13:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23777/23838 [36:40<00:23,  2.60it/s][2025-02-04 03:13:30][root][INFO] - Training Epoch: 2/2, step 23776/23838 completed (loss: 0.3136310577392578, acc: 0.925000011920929)
[2025-02-04 03:13:30][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23778/23838 [36:41<00:24,  2.44it/s][2025-02-04 03:13:30][root][INFO] - Training Epoch: 2/2, step 23777/23838 completed (loss: 0.07217101007699966, acc: 0.966292142868042)
[2025-02-04 03:13:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23779/23838 [36:41<00:24,  2.39it/s][2025-02-04 03:13:31][root][INFO] - Training Epoch: 2/2, step 23778/23838 completed (loss: 0.02712312527000904, acc: 1.0)
[2025-02-04 03:13:31][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23780/23838 [36:42<00:27,  2.12it/s][2025-02-04 03:13:31][root][INFO] - Training Epoch: 2/2, step 23779/23838 completed (loss: 0.16384634375572205, acc: 0.948051929473877)
[2025-02-04 03:13:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23781/23838 [36:42<00:26,  2.15it/s][2025-02-04 03:13:32][root][INFO] - Training Epoch: 2/2, step 23780/23838 completed (loss: 0.4449826180934906, acc: 0.8666666746139526)
[2025-02-04 03:13:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23782/23838 [36:43<00:23,  2.34it/s][2025-02-04 03:13:32][root][INFO] - Training Epoch: 2/2, step 23781/23838 completed (loss: 0.2025415450334549, acc: 0.9473684430122375)
[2025-02-04 03:13:32][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23783/23838 [36:43<00:22,  2.47it/s][2025-02-04 03:13:33][root][INFO] - Training Epoch: 2/2, step 23782/23838 completed (loss: 0.38538384437561035, acc: 0.800000011920929)
[2025-02-04 03:13:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23784/23838 [36:43<00:21,  2.49it/s][2025-02-04 03:13:33][root][INFO] - Training Epoch: 2/2, step 23783/23838 completed (loss: 0.771038830280304, acc: 0.7906976938247681)
[2025-02-04 03:13:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23785/23838 [36:44<00:20,  2.64it/s][2025-02-04 03:13:33][root][INFO] - Training Epoch: 2/2, step 23784/23838 completed (loss: 0.03703148663043976, acc: 1.0)
[2025-02-04 03:13:33][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23786/23838 [36:44<00:19,  2.67it/s][2025-02-04 03:13:34][root][INFO] - Training Epoch: 2/2, step 23785/23838 completed (loss: 0.20560722053050995, acc: 0.9599999785423279)
[2025-02-04 03:13:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23787/23838 [36:44<00:19,  2.58it/s][2025-02-04 03:13:34][root][INFO] - Training Epoch: 2/2, step 23786/23838 completed (loss: 0.04450808838009834, acc: 0.9841269850730896)
[2025-02-04 03:13:34][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23788/23838 [36:45<00:23,  2.17it/s][2025-02-04 03:13:35][root][INFO] - Training Epoch: 2/2, step 23787/23838 completed (loss: 0.06052318587899208, acc: 0.9852941036224365)
[2025-02-04 03:13:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23789/23838 [36:45<00:21,  2.27it/s][2025-02-04 03:13:35][root][INFO] - Training Epoch: 2/2, step 23788/23838 completed (loss: 0.277898907661438, acc: 0.9433962106704712)
[2025-02-04 03:13:35][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23790/23838 [36:46<00:20,  2.32it/s][2025-02-04 03:13:35][root][INFO] - Training Epoch: 2/2, step 23789/23838 completed (loss: 0.022835951298475266, acc: 0.9906542301177979)
[2025-02-04 03:13:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23791/23838 [36:46<00:18,  2.48it/s][2025-02-04 03:13:36][root][INFO] - Training Epoch: 2/2, step 23790/23838 completed (loss: 0.26333460211753845, acc: 0.918367326259613)
[2025-02-04 03:13:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23792/23838 [36:47<00:17,  2.59it/s][2025-02-04 03:13:36][root][INFO] - Training Epoch: 2/2, step 23791/23838 completed (loss: 0.17022259533405304, acc: 0.96875)
[2025-02-04 03:13:36][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23793/23838 [36:47<00:16,  2.66it/s][2025-02-04 03:13:36][root][INFO] - Training Epoch: 2/2, step 23792/23838 completed (loss: 0.03163158521056175, acc: 1.0)
[2025-02-04 03:13:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23794/23838 [36:47<00:17,  2.54it/s][2025-02-04 03:13:37][root][INFO] - Training Epoch: 2/2, step 23793/23838 completed (loss: 0.4734567105770111, acc: 0.9027777910232544)
[2025-02-04 03:13:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23795/23838 [36:48<00:16,  2.54it/s][2025-02-04 03:13:37][root][INFO] - Training Epoch: 2/2, step 23794/23838 completed (loss: 0.01751314476132393, acc: 1.0)
[2025-02-04 03:13:37][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23796/23838 [36:48<00:17,  2.47it/s][2025-02-04 03:13:38][root][INFO] - Training Epoch: 2/2, step 23795/23838 completed (loss: 0.12598170340061188, acc: 0.9879518151283264)
[2025-02-04 03:13:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23797/23838 [36:48<00:15,  2.58it/s][2025-02-04 03:13:38][root][INFO] - Training Epoch: 2/2, step 23796/23838 completed (loss: 0.17195852100849152, acc: 0.9756097793579102)
[2025-02-04 03:13:38][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23798/23838 [36:49<00:15,  2.60it/s][2025-02-04 03:13:38][root][INFO] - Training Epoch: 2/2, step 23797/23838 completed (loss: 0.005124995950609446, acc: 1.0)
[2025-02-04 03:13:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23799/23838 [36:49<00:14,  2.69it/s][2025-02-04 03:13:39][root][INFO] - Training Epoch: 2/2, step 23798/23838 completed (loss: 0.07481787353754044, acc: 1.0)
[2025-02-04 03:13:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23800/23838 [36:50<00:14,  2.62it/s][2025-02-04 03:13:39][root][INFO] - Training Epoch: 2/2, step 23799/23838 completed (loss: 0.16910846531391144, acc: 0.9583333134651184)
[2025-02-04 03:13:39][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23801/23838 [36:50<00:13,  2.70it/s][2025-02-04 03:13:40][root][INFO] - Training Epoch: 2/2, step 23800/23838 completed (loss: 0.15133658051490784, acc: 0.9433962106704712)
[2025-02-04 03:13:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23802/23838 [36:50<00:12,  2.79it/s][2025-02-04 03:13:40][root][INFO] - Training Epoch: 2/2, step 23801/23838 completed (loss: 0.1506909877061844, acc: 0.9444444179534912)
[2025-02-04 03:13:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23803/23838 [36:51<00:13,  2.61it/s][2025-02-04 03:13:40][root][INFO] - Training Epoch: 2/2, step 23802/23838 completed (loss: 0.7646993398666382, acc: 0.8307692408561707)
[2025-02-04 03:13:40][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23804/23838 [36:51<00:12,  2.62it/s][2025-02-04 03:13:41][root][INFO] - Training Epoch: 2/2, step 23803/23838 completed (loss: 0.22013741731643677, acc: 0.9090909361839294)
[2025-02-04 03:13:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23805/23838 [36:52<00:12,  2.58it/s][2025-02-04 03:13:41][root][INFO] - Training Epoch: 2/2, step 23804/23838 completed (loss: 0.38685038685798645, acc: 0.8999999761581421)
[2025-02-04 03:13:41][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23806/23838 [36:52<00:12,  2.49it/s][2025-02-04 03:13:42][root][INFO] - Training Epoch: 2/2, step 23805/23838 completed (loss: 0.05591391399502754, acc: 0.9873417615890503)
[2025-02-04 03:13:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23807/23838 [36:52<00:12,  2.42it/s][2025-02-04 03:13:42][root][INFO] - Training Epoch: 2/2, step 23806/23838 completed (loss: 0.2565363645553589, acc: 0.9175257682800293)
[2025-02-04 03:13:42][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23808/23838 [36:53<00:11,  2.53it/s][2025-02-04 03:13:42][root][INFO] - Training Epoch: 2/2, step 23807/23838 completed (loss: 0.23478354513645172, acc: 0.9210526347160339)
[2025-02-04 03:13:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23809/23838 [36:53<00:14,  2.03it/s][2025-02-04 03:13:43][root][INFO] - Training Epoch: 2/2, step 23808/23838 completed (loss: 0.11439499258995056, acc: 0.9431818127632141)
[2025-02-04 03:13:43][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23810/23838 [36:54<00:12,  2.20it/s][2025-02-04 03:13:43][root][INFO] - Training Epoch: 2/2, step 23809/23838 completed (loss: 0.2227286696434021, acc: 0.9365079402923584)
[2025-02-04 03:13:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23811/23838 [36:54<00:13,  2.08it/s][2025-02-04 03:13:44][root][INFO] - Training Epoch: 2/2, step 23810/23838 completed (loss: 0.3079838752746582, acc: 0.9295774698257446)
[2025-02-04 03:13:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23812/23838 [36:55<00:12,  2.14it/s][2025-02-04 03:13:44][root][INFO] - Training Epoch: 2/2, step 23811/23838 completed (loss: 0.43828335404396057, acc: 0.8888888955116272)
[2025-02-04 03:13:44][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23813/23838 [36:55<00:10,  2.31it/s][2025-02-04 03:13:45][root][INFO] - Training Epoch: 2/2, step 23812/23838 completed (loss: 0.2927398085594177, acc: 0.9189189076423645)
[2025-02-04 03:13:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23814/23838 [36:56<00:10,  2.34it/s][2025-02-04 03:13:45][root][INFO] - Training Epoch: 2/2, step 23813/23838 completed (loss: 0.02483493834733963, acc: 0.9888888597488403)
[2025-02-04 03:13:45][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23815/23838 [36:56<00:10,  2.13it/s][2025-02-04 03:13:46][root][INFO] - Training Epoch: 2/2, step 23814/23838 completed (loss: 0.2861271798610687, acc: 0.9207921028137207)
[2025-02-04 03:13:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23816/23838 [36:57<00:10,  2.18it/s][2025-02-04 03:13:46][root][INFO] - Training Epoch: 2/2, step 23815/23838 completed (loss: 0.15314419567584991, acc: 0.9534883499145508)
[2025-02-04 03:13:46][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23817/23838 [36:57<00:08,  2.34it/s][2025-02-04 03:13:47][root][INFO] - Training Epoch: 2/2, step 23816/23838 completed (loss: 0.680436909198761, acc: 0.8510638475418091)
[2025-02-04 03:13:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23818/23838 [36:57<00:08,  2.42it/s][2025-02-04 03:13:47][root][INFO] - Training Epoch: 2/2, step 23817/23838 completed (loss: 0.2153143584728241, acc: 0.9210526347160339)
[2025-02-04 03:13:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23819/23838 [36:58<00:07,  2.49it/s][2025-02-04 03:13:47][root][INFO] - Training Epoch: 2/2, step 23818/23838 completed (loss: 0.47346019744873047, acc: 0.8965517282485962)
[2025-02-04 03:13:47][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23820/23838 [36:58<00:07,  2.51it/s][2025-02-04 03:13:48][root][INFO] - Training Epoch: 2/2, step 23819/23838 completed (loss: 0.14939190447330475, acc: 0.9658119678497314)
[2025-02-04 03:13:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23821/23838 [36:58<00:06,  2.49it/s][2025-02-04 03:13:48][root][INFO] - Training Epoch: 2/2, step 23820/23838 completed (loss: 0.9585449695587158, acc: 0.7377049326896667)
[2025-02-04 03:13:48][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23822/23838 [36:59<00:06,  2.37it/s][2025-02-04 03:13:49][root][INFO] - Training Epoch: 2/2, step 23821/23838 completed (loss: 0.36254215240478516, acc: 0.8842105269432068)
[2025-02-04 03:13:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23823/23838 [36:59<00:06,  2.49it/s][2025-02-04 03:13:49][root][INFO] - Training Epoch: 2/2, step 23822/23838 completed (loss: 0.260703444480896, acc: 0.9365079402923584)
[2025-02-04 03:13:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23824/23838 [37:00<00:05,  2.54it/s][2025-02-04 03:13:49][root][INFO] - Training Epoch: 2/2, step 23823/23838 completed (loss: 0.526788592338562, acc: 0.8405796885490417)
[2025-02-04 03:13:49][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23825/23838 [37:00<00:05,  2.44it/s][2025-02-04 03:13:50][root][INFO] - Training Epoch: 2/2, step 23824/23838 completed (loss: 0.31848329305648804, acc: 0.8958333134651184)
[2025-02-04 03:13:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23826/23838 [37:01<00:04,  2.52it/s][2025-02-04 03:13:50][root][INFO] - Training Epoch: 2/2, step 23825/23838 completed (loss: 0.6093252301216125, acc: 0.8214285969734192)
[2025-02-04 03:13:50][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23827/23838 [37:01<00:04,  2.54it/s][2025-02-04 03:13:50][root][INFO] - Training Epoch: 2/2, step 23826/23838 completed (loss: 0.4252336919307709, acc: 0.8888888955116272)
[2025-02-04 03:13:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23828/23838 [37:01<00:03,  2.59it/s][2025-02-04 03:13:51][root][INFO] - Training Epoch: 2/2, step 23827/23838 completed (loss: 0.34208977222442627, acc: 0.9166666865348816)
[2025-02-04 03:13:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23829/23838 [37:02<00:03,  2.56it/s][2025-02-04 03:13:51][root][INFO] - Training Epoch: 2/2, step 23828/23838 completed (loss: 0.4495539665222168, acc: 0.8584070801734924)
[2025-02-04 03:13:51][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23830/23838 [37:02<00:03,  2.60it/s][2025-02-04 03:13:52][root][INFO] - Training Epoch: 2/2, step 23829/23838 completed (loss: 0.3431272804737091, acc: 0.9019607901573181)
[2025-02-04 03:13:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23831/23838 [37:02<00:02,  2.56it/s][2025-02-04 03:13:52][root][INFO] - Training Epoch: 2/2, step 23830/23838 completed (loss: 0.4842492640018463, acc: 0.8717948794364929)
[2025-02-04 03:13:52][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23832/23838 [37:03<00:02,  2.53it/s][2025-02-04 03:13:52][root][INFO] - Training Epoch: 2/2, step 23831/23838 completed (loss: 0.5241722464561462, acc: 0.8313252925872803)
[2025-02-04 03:13:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23833/23838 [37:03<00:01,  2.65it/s][2025-02-04 03:13:53][root][INFO] - Training Epoch: 2/2, step 23832/23838 completed (loss: 0.15421098470687866, acc: 0.966292142868042)
[2025-02-04 03:13:53][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23834/23838 [37:03<00:01,  2.79it/s][2025-02-04 03:13:53][root][INFO] - Training Epoch: 2/2, step 23833/23838 completed (loss: 0.3165785074234009, acc: 0.9450549483299255)

Evaluating Epoch:   0%|[32m          [0m| 0/3290 [00:00<?, ?it/s][A[2025-02-04 03:13:54][slam_llm.models.slam_model][INFO] - modality encoder

Evaluating Epoch:   0%|[32m          [0m| 1/3290 [00:01<57:20,  1.05s/it][A
step: 1/3290, eval_loss: 0.1651, eval_acc: 0.9802:   0%|[32m          [0m| 1/3290 [00:01<57:20,  1.05s/it][A[2025-02-04 03:13:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1/3290, eval_loss: 0.1651, eval_acc: 0.9802:   0%|[32m          [0m| 2/3290 [00:01<35:43,  1.53it/s][A
step: 2/3290, eval_loss: 0.1309, eval_acc: 0.9731:   0%|[32m          [0m| 2/3290 [00:01<35:43,  1.53it/s][A[2025-02-04 03:13:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2/3290, eval_loss: 0.1309, eval_acc: 0.9731:   0%|[32m          [0m| 3/3290 [00:01<29:11,  1.88it/s][A
step: 3/3290, eval_loss: 0.1875, eval_acc: 0.9585:   0%|[32m          [0m| 3/3290 [00:01<29:11,  1.88it/s][A[2025-02-04 03:13:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 3/3290, eval_loss: 0.1875, eval_acc: 0.9585:   0%|[32m          [0m| 4/3290 [00:02<23:05,  2.37it/s][A
step: 4/3290, eval_loss: 0.1890, eval_acc: 0.9537:   0%|[32m          [0m| 4/3290 [00:02<23:05,  2.37it/s][A[2025-02-04 03:13:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 4/3290, eval_loss: 0.1890, eval_acc: 0.9537:   0%|[32m          [0m| 5/3290 [00:02<19:55,  2.75it/s][A
step: 5/3290, eval_loss: 0.1792, eval_acc: 0.9534:   0%|[32m          [0m| 5/3290 [00:02<19:55,  2.75it/s][A[2025-02-04 03:13:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 5/3290, eval_loss: 0.1792, eval_acc: 0.9534:   0%|[32m          [0m| 6/3290 [00:02<19:50,  2.76it/s][A
step: 6/3290, eval_loss: 0.1762, eval_acc: 0.9557:   0%|[32m          [0m| 6/3290 [00:02<19:50,  2.76it/s][A[2025-02-04 03:13:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 6/3290, eval_loss: 0.1762, eval_acc: 0.9557:   0%|[32m          [0m| 7/3290 [00:03<20:53,  2.62it/s][A
step: 7/3290, eval_loss: 0.1724, eval_acc: 0.9557:   0%|[32m          [0m| 7/3290 [00:03<20:53,  2.62it/s][A[2025-02-04 03:13:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 7/3290, eval_loss: 0.1724, eval_acc: 0.9557:   0%|[32m          [0m| 8/3290 [00:03<20:58,  2.61it/s][A
step: 8/3290, eval_loss: 0.1560, eval_acc: 0.9603:   0%|[32m          [0m| 8/3290 [00:03<20:58,  2.61it/s][A[2025-02-04 03:13:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 8/3290, eval_loss: 0.1560, eval_acc: 0.9603:   0%|[32m          [0m| 9/3290 [00:03<20:01,  2.73it/s][A
step: 9/3290, eval_loss: 0.1401, eval_acc: 0.9647:   0%|[32m          [0m| 9/3290 [00:03<20:01,  2.73it/s][A[2025-02-04 03:13:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 9/3290, eval_loss: 0.1401, eval_acc: 0.9647:   0%|[32m          [0m| 10/3290 [00:04<24:13,  2.26it/s][A
step: 10/3290, eval_loss: 0.1429, eval_acc: 0.9641:   0%|[32m          [0m| 10/3290 [00:04<24:13,  2.26it/s][A[2025-02-04 03:13:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 10/3290, eval_loss: 0.1429, eval_acc: 0.9641:   0%|[32m          [0m| 11/3290 [00:04<23:23,  2.34it/s][A
step: 11/3290, eval_loss: 0.1317, eval_acc: 0.9674:   0%|[32m          [0m| 11/3290 [00:04<23:23,  2.34it/s][A[2025-02-04 03:13:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 11/3290, eval_loss: 0.1317, eval_acc: 0.9674:   0%|[32m          [0m| 12/3290 [00:05<28:13,  1.94it/s][A
step: 12/3290, eval_loss: 0.1512, eval_acc: 0.9603:   0%|[32m          [0m| 12/3290 [00:05<28:13,  1.94it/s][A[2025-02-04 03:13:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 12/3290, eval_loss: 0.1512, eval_acc: 0.9603:   0%|[32m          [0m| 13/3290 [00:05<25:15,  2.16it/s][A
step: 13/3290, eval_loss: 0.1424, eval_acc: 0.9634:   0%|[32m          [0m| 13/3290 [00:05<25:15,  2.16it/s][A[2025-02-04 03:14:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 13/3290, eval_loss: 0.1424, eval_acc: 0.9634:   0%|[32m          [0m| 14/3290 [00:06<26:12,  2.08it/s][A
step: 14/3290, eval_loss: 0.1597, eval_acc: 0.9590:   0%|[32m          [0m| 14/3290 [00:06<26:12,  2.08it/s][A[2025-02-04 03:14:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 14/3290, eval_loss: 0.1597, eval_acc: 0.9590:   0%|[32m          [0m| 15/3290 [00:06<24:28,  2.23it/s][A
step: 15/3290, eval_loss: 0.1559, eval_acc: 0.9605:   0%|[32m          [0m| 15/3290 [00:06<24:28,  2.23it/s][A[2025-02-04 03:14:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 15/3290, eval_loss: 0.1559, eval_acc: 0.9605:   0%|[32m          [0m| 16/3290 [00:07<24:00,  2.27it/s][A
step: 16/3290, eval_loss: 0.1495, eval_acc: 0.9624:   0%|[32m          [0m| 16/3290 [00:07<24:00,  2.27it/s][A[2025-02-04 03:14:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 16/3290, eval_loss: 0.1495, eval_acc: 0.9624:   1%|[32m          [0m| 17/3290 [00:07<23:34,  2.31it/s][A
step: 17/3290, eval_loss: 0.1644, eval_acc: 0.9593:   1%|[32m          [0m| 17/3290 [00:07<23:34,  2.31it/s][A[2025-02-04 03:14:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 17/3290, eval_loss: 0.1644, eval_acc: 0.9593:   1%|[32m          [0m| 18/3290 [00:08<24:28,  2.23it/s][A
step: 18/3290, eval_loss: 0.1676, eval_acc: 0.9583:   1%|[32m          [0m| 18/3290 [00:08<24:28,  2.23it/s][A[2025-02-04 03:14:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 18/3290, eval_loss: 0.1676, eval_acc: 0.9583:   1%|[32m          [0m| 19/3290 [00:08<22:17,  2.45it/s][A
step: 19/3290, eval_loss: 0.1669, eval_acc: 0.9577:   1%|[32m          [0m| 19/3290 [00:08<22:17,  2.45it/s][A[2025-02-04 03:14:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 19/3290, eval_loss: 0.1669, eval_acc: 0.9577:   1%|[32m          [0m| 20/3290 [00:08<21:35,  2.52it/s][A
step: 20/3290, eval_loss: 0.1677, eval_acc: 0.9573:   1%|[32m          [0m| 20/3290 [00:08<21:35,  2.52it/s][A[2025-02-04 03:14:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 20/3290, eval_loss: 0.1677, eval_acc: 0.9573:   1%|[32m          [0m| 21/3290 [00:09<20:59,  2.60it/s][A
step: 21/3290, eval_loss: 0.1672, eval_acc: 0.9578:   1%|[32m          [0m| 21/3290 [00:09<20:59,  2.60it/s][A[2025-02-04 03:14:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 21/3290, eval_loss: 0.1672, eval_acc: 0.9578:   1%|[32m          [0m| 22/3290 [00:09<22:06,  2.46it/s][A
step: 22/3290, eval_loss: 0.1637, eval_acc: 0.9589:   1%|[32m          [0m| 22/3290 [00:09<22:06,  2.46it/s][A[2025-02-04 03:14:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 22/3290, eval_loss: 0.1637, eval_acc: 0.9589:   1%|[32m          [0m| 23/3290 [00:10<22:43,  2.40it/s][A
step: 23/3290, eval_loss: 0.1608, eval_acc: 0.9597:   1%|[32m          [0m| 23/3290 [00:10<22:43,  2.40it/s][A[2025-02-04 03:14:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 23/3290, eval_loss: 0.1608, eval_acc: 0.9597:   1%|[32m          [0m| 24/3290 [00:10<22:02,  2.47it/s][A
step: 24/3290, eval_loss: 0.1555, eval_acc: 0.9611:   1%|[32m          [0m| 24/3290 [00:10<22:02,  2.47it/s][A[2025-02-04 03:14:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 24/3290, eval_loss: 0.1555, eval_acc: 0.9611:   1%|[32m          [0m| 25/3290 [00:10<23:45,  2.29it/s][A
step: 25/3290, eval_loss: 0.1498, eval_acc: 0.9626:   1%|[32m          [0m| 25/3290 [00:10<23:45,  2.29it/s][A[2025-02-04 03:14:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 25/3290, eval_loss: 0.1498, eval_acc: 0.9626:   1%|[32m          [0m| 26/3290 [00:11<23:16,  2.34it/s][A
step: 26/3290, eval_loss: 0.1502, eval_acc: 0.9619:   1%|[32m          [0m| 26/3290 [00:11<23:16,  2.34it/s][A[2025-02-04 03:14:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 26/3290, eval_loss: 0.1502, eval_acc: 0.9619:   1%|[32m          [0m| 27/3290 [00:11<20:54,  2.60it/s][A
step: 27/3290, eval_loss: 0.1517, eval_acc: 0.9612:   1%|[32m          [0m| 27/3290 [00:11<20:54,  2.60it/s][A[2025-02-04 03:14:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 27/3290, eval_loss: 0.1517, eval_acc: 0.9612:   1%|[32m          [0m| 28/3290 [00:11<19:44,  2.75it/s][A
step: 28/3290, eval_loss: 0.1488, eval_acc: 0.9618:   1%|[32m          [0m| 28/3290 [00:11<19:44,  2.75it/s][A[2025-02-04 03:14:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 28/3290, eval_loss: 0.1488, eval_acc: 0.9618:   1%|[32m          [0m| 29/3290 [00:12<20:56,  2.60it/s][A
step: 29/3290, eval_loss: 0.1475, eval_acc: 0.9623:   1%|[32m          [0m| 29/3290 [00:12<20:56,  2.60it/s][A[2025-02-04 03:14:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 29/3290, eval_loss: 0.1475, eval_acc: 0.9623:   1%|[32m          [0m| 30/3290 [00:12<20:38,  2.63it/s][A
step: 30/3290, eval_loss: 0.1442, eval_acc: 0.9626:   1%|[32m          [0m| 30/3290 [00:12<20:38,  2.63it/s][A[2025-02-04 03:14:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 30/3290, eval_loss: 0.1442, eval_acc: 0.9626:   1%|[32m          [0m| 31/3290 [00:13<21:16,  2.55it/s][A
step: 31/3290, eval_loss: 0.1466, eval_acc: 0.9623:   1%|[32m          [0m| 31/3290 [00:13<21:16,  2.55it/s][A[2025-02-04 03:14:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 31/3290, eval_loss: 0.1466, eval_acc: 0.9623:   1%|[32m          [0m| 32/3290 [00:13<21:05,  2.58it/s][A
step: 32/3290, eval_loss: 0.1446, eval_acc: 0.9628:   1%|[32m          [0m| 32/3290 [00:13<21:05,  2.58it/s][A[2025-02-04 03:14:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 32/3290, eval_loss: 0.1446, eval_acc: 0.9628:   1%|[32m          [0m| 33/3290 [00:13<20:30,  2.65it/s][A
step: 33/3290, eval_loss: 0.1500, eval_acc: 0.9616:   1%|[32m          [0m| 33/3290 [00:13<20:30,  2.65it/s][A[2025-02-04 03:14:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 33/3290, eval_loss: 0.1500, eval_acc: 0.9616:   1%|[32m          [0m| 34/3290 [00:14<20:33,  2.64it/s][A
step: 34/3290, eval_loss: 0.1520, eval_acc: 0.9612:   1%|[32m          [0m| 34/3290 [00:14<20:33,  2.64it/s][A[2025-02-04 03:14:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 34/3290, eval_loss: 0.1520, eval_acc: 0.9612:   1%|[32m          [0m| 35/3290 [00:14<21:53,  2.48it/s][A
step: 35/3290, eval_loss: 0.1530, eval_acc: 0.9609:   1%|[32m          [0m| 35/3290 [00:14<21:53,  2.48it/s][A[2025-02-04 03:14:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 35/3290, eval_loss: 0.1530, eval_acc: 0.9609:   1%|[32m          [0m| 36/3290 [00:15<22:42,  2.39it/s][A
step: 36/3290, eval_loss: 0.1541, eval_acc: 0.9599:   1%|[32m          [0m| 36/3290 [00:15<22:42,  2.39it/s][A[2025-02-04 03:14:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 36/3290, eval_loss: 0.1541, eval_acc: 0.9599:   1%|[32m          [0m| 37/3290 [00:15<21:03,  2.57it/s][A
step: 37/3290, eval_loss: 0.1570, eval_acc: 0.9590:   1%|[32m          [0m| 37/3290 [00:15<21:03,  2.57it/s][A[2025-02-04 03:14:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 37/3290, eval_loss: 0.1570, eval_acc: 0.9590:   1%|[32m          [0m| 38/3290 [00:15<20:51,  2.60it/s][A
step: 38/3290, eval_loss: 0.1536, eval_acc: 0.9597:   1%|[32m          [0m| 38/3290 [00:15<20:51,  2.60it/s][A[2025-02-04 03:14:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 38/3290, eval_loss: 0.1536, eval_acc: 0.9597:   1%|[32m          [0m| 39/3290 [00:16<21:02,  2.58it/s][A
step: 39/3290, eval_loss: 0.1545, eval_acc: 0.9594:   1%|[32m          [0m| 39/3290 [00:16<21:02,  2.58it/s][A[2025-02-04 03:14:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 39/3290, eval_loss: 0.1545, eval_acc: 0.9594:   1%|[32m          [0m| 40/3290 [00:16<20:17,  2.67it/s][A
step: 40/3290, eval_loss: 0.1730, eval_acc: 0.9554:   1%|[32m          [0m| 40/3290 [00:16<20:17,  2.67it/s][A[2025-02-04 03:14:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 40/3290, eval_loss: 0.1730, eval_acc: 0.9554:   1%|[32m          [0m| 41/3290 [00:17<20:20,  2.66it/s][A
step: 41/3290, eval_loss: 0.1730, eval_acc: 0.9554:   1%|[32m          [0m| 41/3290 [00:17<20:20,  2.66it/s][A[2025-02-04 03:14:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 41/3290, eval_loss: 0.1730, eval_acc: 0.9554:   1%|[32m▏         [0m| 42/3290 [00:17<19:56,  2.71it/s][A
step: 42/3290, eval_loss: 0.1705, eval_acc: 0.9558:   1%|[32m▏         [0m| 42/3290 [00:17<19:56,  2.71it/s][A[2025-02-04 03:14:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 42/3290, eval_loss: 0.1705, eval_acc: 0.9558:   1%|[32m▏         [0m| 43/3290 [00:17<19:55,  2.72it/s][A
step: 43/3290, eval_loss: 0.1669, eval_acc: 0.9568:   1%|[32m▏         [0m| 43/3290 [00:17<19:55,  2.72it/s][A[2025-02-04 03:14:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 43/3290, eval_loss: 0.1669, eval_acc: 0.9568:   1%|[32m▏         [0m| 44/3290 [00:18<21:29,  2.52it/s][A
step: 44/3290, eval_loss: 0.1657, eval_acc: 0.9570:   1%|[32m▏         [0m| 44/3290 [00:18<21:29,  2.52it/s][A[2025-02-04 03:14:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 44/3290, eval_loss: 0.1657, eval_acc: 0.9570:   1%|[32m▏         [0m| 45/3290 [00:18<21:04,  2.57it/s][A
step: 45/3290, eval_loss: 0.1681, eval_acc: 0.9563:   1%|[32m▏         [0m| 45/3290 [00:18<21:04,  2.57it/s][A[2025-02-04 03:14:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 45/3290, eval_loss: 0.1681, eval_acc: 0.9563:   1%|[32m▏         [0m| 46/3290 [00:18<20:10,  2.68it/s][A
step: 46/3290, eval_loss: 0.1715, eval_acc: 0.9547:   1%|[32m▏         [0m| 46/3290 [00:18<20:10,  2.68it/s][A[2025-02-04 03:14:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 46/3290, eval_loss: 0.1715, eval_acc: 0.9547:   1%|[32m▏         [0m| 47/3290 [00:19<21:59,  2.46it/s][A
step: 47/3290, eval_loss: 0.1730, eval_acc: 0.9544:   1%|[32m▏         [0m| 47/3290 [00:19<21:59,  2.46it/s][A[2025-02-04 03:14:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 47/3290, eval_loss: 0.1730, eval_acc: 0.9544:   1%|[32m▏         [0m| 48/3290 [00:19<21:02,  2.57it/s][A
step: 48/3290, eval_loss: 0.1749, eval_acc: 0.9537:   1%|[32m▏         [0m| 48/3290 [00:19<21:02,  2.57it/s][A[2025-02-04 03:14:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 48/3290, eval_loss: 0.1749, eval_acc: 0.9537:   1%|[32m▏         [0m| 49/3290 [00:20<20:25,  2.64it/s][A
step: 49/3290, eval_loss: 0.1726, eval_acc: 0.9543:   1%|[32m▏         [0m| 49/3290 [00:20<20:25,  2.64it/s][A[2025-02-04 03:14:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 49/3290, eval_loss: 0.1726, eval_acc: 0.9543:   2%|[32m▏         [0m| 50/3290 [00:20<19:34,  2.76it/s][A
step: 50/3290, eval_loss: 0.1742, eval_acc: 0.9538:   2%|[32m▏         [0m| 50/3290 [00:20<19:34,  2.76it/s][A[2025-02-04 03:14:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 50/3290, eval_loss: 0.1742, eval_acc: 0.9538:   2%|[32m▏         [0m| 51/3290 [00:20<20:39,  2.61it/s][A
step: 51/3290, eval_loss: 0.1783, eval_acc: 0.9526:   2%|[32m▏         [0m| 51/3290 [00:20<20:39,  2.61it/s][A[2025-02-04 03:14:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 51/3290, eval_loss: 0.1783, eval_acc: 0.9526:   2%|[32m▏         [0m| 52/3290 [00:21<19:24,  2.78it/s][A
step: 52/3290, eval_loss: 0.1806, eval_acc: 0.9524:   2%|[32m▏         [0m| 52/3290 [00:21<19:24,  2.78it/s][A[2025-02-04 03:14:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 52/3290, eval_loss: 0.1806, eval_acc: 0.9524:   2%|[32m▏         [0m| 53/3290 [00:21<18:19,  2.94it/s][A
step: 53/3290, eval_loss: 0.1824, eval_acc: 0.9522:   2%|[32m▏         [0m| 53/3290 [00:21<18:19,  2.94it/s][A[2025-02-04 03:14:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 53/3290, eval_loss: 0.1824, eval_acc: 0.9522:   2%|[32m▏         [0m| 54/3290 [00:21<18:39,  2.89it/s][A
step: 54/3290, eval_loss: 0.1838, eval_acc: 0.9521:   2%|[32m▏         [0m| 54/3290 [00:21<18:39,  2.89it/s][A[2025-02-04 03:14:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 54/3290, eval_loss: 0.1838, eval_acc: 0.9521:   2%|[32m▏         [0m| 55/3290 [00:22<19:46,  2.73it/s][A
step: 55/3290, eval_loss: 0.1882, eval_acc: 0.9509:   2%|[32m▏         [0m| 55/3290 [00:22<19:46,  2.73it/s][A[2025-02-04 03:14:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 55/3290, eval_loss: 0.1882, eval_acc: 0.9509:   2%|[32m▏         [0m| 56/3290 [00:22<19:07,  2.82it/s][A
step: 56/3290, eval_loss: 0.1979, eval_acc: 0.9479:   2%|[32m▏         [0m| 56/3290 [00:22<19:07,  2.82it/s][A[2025-02-04 03:14:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 56/3290, eval_loss: 0.1979, eval_acc: 0.9479:   2%|[32m▏         [0m| 57/3290 [00:22<19:36,  2.75it/s][A
step: 57/3290, eval_loss: 0.1996, eval_acc: 0.9470:   2%|[32m▏         [0m| 57/3290 [00:22<19:36,  2.75it/s][A[2025-02-04 03:14:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 57/3290, eval_loss: 0.1996, eval_acc: 0.9470:   2%|[32m▏         [0m| 58/3290 [00:23<20:15,  2.66it/s][A
step: 58/3290, eval_loss: 0.2008, eval_acc: 0.9471:   2%|[32m▏         [0m| 58/3290 [00:23<20:15,  2.66it/s][A[2025-02-04 03:14:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 58/3290, eval_loss: 0.2008, eval_acc: 0.9471:   2%|[32m▏         [0m| 59/3290 [00:23<20:18,  2.65it/s][A
step: 59/3290, eval_loss: 0.2088, eval_acc: 0.9456:   2%|[32m▏         [0m| 59/3290 [00:23<20:18,  2.65it/s][A[2025-02-04 03:14:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 59/3290, eval_loss: 0.2088, eval_acc: 0.9456:   2%|[32m▏         [0m| 60/3290 [00:23<18:50,  2.86it/s][A
step: 60/3290, eval_loss: 0.2080, eval_acc: 0.9459:   2%|[32m▏         [0m| 60/3290 [00:23<18:50,  2.86it/s][A[2025-02-04 03:14:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 60/3290, eval_loss: 0.2080, eval_acc: 0.9459:   2%|[32m▏         [0m| 61/3290 [00:24<20:18,  2.65it/s][A
step: 61/3290, eval_loss: 0.2207, eval_acc: 0.9415:   2%|[32m▏         [0m| 61/3290 [00:24<20:18,  2.65it/s][A[2025-02-04 03:14:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 61/3290, eval_loss: 0.2207, eval_acc: 0.9415:   2%|[32m▏         [0m| 62/3290 [00:24<21:10,  2.54it/s][A
step: 62/3290, eval_loss: 0.2251, eval_acc: 0.9404:   2%|[32m▏         [0m| 62/3290 [00:24<21:10,  2.54it/s][A[2025-02-04 03:14:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 62/3290, eval_loss: 0.2251, eval_acc: 0.9404:   2%|[32m▏         [0m| 63/3290 [00:25<19:38,  2.74it/s][A
step: 63/3290, eval_loss: 0.2263, eval_acc: 0.9394:   2%|[32m▏         [0m| 63/3290 [00:25<19:38,  2.74it/s][A[2025-02-04 03:14:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 63/3290, eval_loss: 0.2263, eval_acc: 0.9394:   2%|[32m▏         [0m| 64/3290 [00:25<20:12,  2.66it/s][A
step: 64/3290, eval_loss: 0.2294, eval_acc: 0.9385:   2%|[32m▏         [0m| 64/3290 [00:25<20:12,  2.66it/s][A[2025-02-04 03:14:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 64/3290, eval_loss: 0.2294, eval_acc: 0.9385:   2%|[32m▏         [0m| 65/3290 [00:25<18:31,  2.90it/s][A
step: 65/3290, eval_loss: 0.2305, eval_acc: 0.9383:   2%|[32m▏         [0m| 65/3290 [00:25<18:31,  2.90it/s][A[2025-02-04 03:14:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 65/3290, eval_loss: 0.2305, eval_acc: 0.9383:   2%|[32m▏         [0m| 66/3290 [00:26<19:21,  2.78it/s][A
step: 66/3290, eval_loss: 0.2344, eval_acc: 0.9372:   2%|[32m▏         [0m| 66/3290 [00:26<19:21,  2.78it/s][A[2025-02-04 03:14:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 66/3290, eval_loss: 0.2344, eval_acc: 0.9372:   2%|[32m▏         [0m| 67/3290 [00:26<19:35,  2.74it/s][A
step: 67/3290, eval_loss: 0.2345, eval_acc: 0.9374:   2%|[32m▏         [0m| 67/3290 [00:26<19:35,  2.74it/s][A[2025-02-04 03:14:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 67/3290, eval_loss: 0.2345, eval_acc: 0.9374:   2%|[32m▏         [0m| 68/3290 [00:26<18:53,  2.84it/s][A
step: 68/3290, eval_loss: 0.2351, eval_acc: 0.9377:   2%|[32m▏         [0m| 68/3290 [00:26<18:53,  2.84it/s][A[2025-02-04 03:14:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 68/3290, eval_loss: 0.2351, eval_acc: 0.9377:   2%|[32m▏         [0m| 69/3290 [00:27<19:31,  2.75it/s][A
step: 69/3290, eval_loss: 0.2337, eval_acc: 0.9381:   2%|[32m▏         [0m| 69/3290 [00:27<19:31,  2.75it/s][A[2025-02-04 03:14:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 69/3290, eval_loss: 0.2337, eval_acc: 0.9381:   2%|[32m▏         [0m| 70/3290 [00:27<20:50,  2.58it/s][A
step: 70/3290, eval_loss: 0.2347, eval_acc: 0.9383:   2%|[32m▏         [0m| 70/3290 [00:27<20:50,  2.58it/s][A[2025-02-04 03:14:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 70/3290, eval_loss: 0.2347, eval_acc: 0.9383:   2%|[32m▏         [0m| 71/3290 [00:28<19:28,  2.76it/s][A
step: 71/3290, eval_loss: 0.2364, eval_acc: 0.9379:   2%|[32m▏         [0m| 71/3290 [00:28<19:28,  2.76it/s][A[2025-02-04 03:14:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 71/3290, eval_loss: 0.2364, eval_acc: 0.9379:   2%|[32m▏         [0m| 72/3290 [00:28<17:55,  2.99it/s][A
step: 72/3290, eval_loss: 0.2403, eval_acc: 0.9368:   2%|[32m▏         [0m| 72/3290 [00:28<17:55,  2.99it/s][A[2025-02-04 03:14:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 72/3290, eval_loss: 0.2403, eval_acc: 0.9368:   2%|[32m▏         [0m| 73/3290 [00:28<19:01,  2.82it/s][A
step: 73/3290, eval_loss: 0.2418, eval_acc: 0.9365:   2%|[32m▏         [0m| 73/3290 [00:28<19:01,  2.82it/s][A[2025-02-04 03:14:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 73/3290, eval_loss: 0.2418, eval_acc: 0.9365:   2%|[32m▏         [0m| 74/3290 [00:29<17:29,  3.06it/s][A
step: 74/3290, eval_loss: 0.2409, eval_acc: 0.9366:   2%|[32m▏         [0m| 74/3290 [00:29<17:29,  3.06it/s][A[2025-02-04 03:14:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 74/3290, eval_loss: 0.2409, eval_acc: 0.9366:   2%|[32m▏         [0m| 75/3290 [00:29<17:20,  3.09it/s][A
step: 75/3290, eval_loss: 0.2413, eval_acc: 0.9365:   2%|[32m▏         [0m| 75/3290 [00:29<17:20,  3.09it/s][A[2025-02-04 03:14:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 75/3290, eval_loss: 0.2413, eval_acc: 0.9365:   2%|[32m▏         [0m| 76/3290 [00:29<17:24,  3.08it/s][A
step: 76/3290, eval_loss: 0.2424, eval_acc: 0.9362:   2%|[32m▏         [0m| 76/3290 [00:29<17:24,  3.08it/s][A[2025-02-04 03:14:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 76/3290, eval_loss: 0.2424, eval_acc: 0.9362:   2%|[32m▏         [0m| 77/3290 [00:29<16:41,  3.21it/s][A
step: 77/3290, eval_loss: 0.2433, eval_acc: 0.9360:   2%|[32m▏         [0m| 77/3290 [00:29<16:41,  3.21it/s][A[2025-02-04 03:14:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 77/3290, eval_loss: 0.2433, eval_acc: 0.9360:   2%|[32m▏         [0m| 78/3290 [00:30<17:18,  3.09it/s][A
step: 78/3290, eval_loss: 0.2452, eval_acc: 0.9354:   2%|[32m▏         [0m| 78/3290 [00:30<17:18,  3.09it/s][A[2025-02-04 03:14:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 78/3290, eval_loss: 0.2452, eval_acc: 0.9354:   2%|[32m▏         [0m| 79/3290 [00:30<17:47,  3.01it/s][A
step: 79/3290, eval_loss: 0.2443, eval_acc: 0.9354:   2%|[32m▏         [0m| 79/3290 [00:30<17:47,  3.01it/s][A[2025-02-04 03:14:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 79/3290, eval_loss: 0.2443, eval_acc: 0.9354:   2%|[32m▏         [0m| 80/3290 [00:30<17:06,  3.13it/s][A
step: 80/3290, eval_loss: 0.2538, eval_acc: 0.9345:   2%|[32m▏         [0m| 80/3290 [00:30<17:06,  3.13it/s][A[2025-02-04 03:14:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 80/3290, eval_loss: 0.2538, eval_acc: 0.9345:   2%|[32m▏         [0m| 81/3290 [00:31<16:59,  3.15it/s][A
step: 81/3290, eval_loss: 0.2596, eval_acc: 0.9332:   2%|[32m▏         [0m| 81/3290 [00:31<16:59,  3.15it/s][A[2025-02-04 03:14:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 81/3290, eval_loss: 0.2596, eval_acc: 0.9332:   2%|[32m▏         [0m| 82/3290 [00:31<17:52,  2.99it/s][A
step: 82/3290, eval_loss: 0.2588, eval_acc: 0.9334:   2%|[32m▏         [0m| 82/3290 [00:31<17:52,  2.99it/s][A[2025-02-04 03:14:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 82/3290, eval_loss: 0.2588, eval_acc: 0.9334:   3%|[32m▎         [0m| 83/3290 [00:31<17:17,  3.09it/s][A
step: 83/3290, eval_loss: 0.2634, eval_acc: 0.9323:   3%|[32m▎         [0m| 83/3290 [00:31<17:17,  3.09it/s][A[2025-02-04 03:14:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 83/3290, eval_loss: 0.2634, eval_acc: 0.9323:   3%|[32m▎         [0m| 84/3290 [00:32<17:56,  2.98it/s][A
step: 84/3290, eval_loss: 0.2696, eval_acc: 0.9302:   3%|[32m▎         [0m| 84/3290 [00:32<17:56,  2.98it/s][A[2025-02-04 03:14:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 84/3290, eval_loss: 0.2696, eval_acc: 0.9302:   3%|[32m▎         [0m| 85/3290 [00:32<17:03,  3.13it/s][A
step: 85/3290, eval_loss: 0.2814, eval_acc: 0.9282:   3%|[32m▎         [0m| 85/3290 [00:32<17:03,  3.13it/s][A[2025-02-04 03:14:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 85/3290, eval_loss: 0.2814, eval_acc: 0.9282:   3%|[32m▎         [0m| 86/3290 [00:32<18:41,  2.86it/s][A
step: 86/3290, eval_loss: 0.2794, eval_acc: 0.9285:   3%|[32m▎         [0m| 86/3290 [00:32<18:41,  2.86it/s][A[2025-02-04 03:14:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 86/3290, eval_loss: 0.2794, eval_acc: 0.9285:   3%|[32m▎         [0m| 87/3290 [00:33<19:10,  2.78it/s][A
step: 87/3290, eval_loss: 0.2872, eval_acc: 0.9263:   3%|[32m▎         [0m| 87/3290 [00:33<19:10,  2.78it/s][A[2025-02-04 03:14:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 87/3290, eval_loss: 0.2872, eval_acc: 0.9263:   3%|[32m▎         [0m| 88/3290 [00:33<20:14,  2.64it/s][A
step: 88/3290, eval_loss: 0.2921, eval_acc: 0.9250:   3%|[32m▎         [0m| 88/3290 [00:33<20:14,  2.64it/s][A[2025-02-04 03:14:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 88/3290, eval_loss: 0.2921, eval_acc: 0.9250:   3%|[32m▎         [0m| 89/3290 [00:34<19:31,  2.73it/s][A
step: 89/3290, eval_loss: 0.2960, eval_acc: 0.9240:   3%|[32m▎         [0m| 89/3290 [00:34<19:31,  2.73it/s][A[2025-02-04 03:14:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 89/3290, eval_loss: 0.2960, eval_acc: 0.9240:   3%|[32m▎         [0m| 90/3290 [00:34<19:36,  2.72it/s][A
step: 90/3290, eval_loss: 0.3000, eval_acc: 0.9229:   3%|[32m▎         [0m| 90/3290 [00:34<19:36,  2.72it/s][A[2025-02-04 03:14:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 90/3290, eval_loss: 0.3000, eval_acc: 0.9229:   3%|[32m▎         [0m| 91/3290 [00:34<20:25,  2.61it/s][A
step: 91/3290, eval_loss: 0.3011, eval_acc: 0.9223:   3%|[32m▎         [0m| 91/3290 [00:34<20:25,  2.61it/s][A[2025-02-04 03:14:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 91/3290, eval_loss: 0.3011, eval_acc: 0.9223:   3%|[32m▎         [0m| 92/3290 [00:35<19:09,  2.78it/s][A
step: 92/3290, eval_loss: 0.3008, eval_acc: 0.9220:   3%|[32m▎         [0m| 92/3290 [00:35<19:09,  2.78it/s][A[2025-02-04 03:14:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 92/3290, eval_loss: 0.3008, eval_acc: 0.9220:   3%|[32m▎         [0m| 93/3290 [00:35<19:35,  2.72it/s][A
step: 93/3290, eval_loss: 0.3047, eval_acc: 0.9207:   3%|[32m▎         [0m| 93/3290 [00:35<19:35,  2.72it/s][A[2025-02-04 03:14:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 93/3290, eval_loss: 0.3047, eval_acc: 0.9207:   3%|[32m▎         [0m| 94/3290 [00:35<17:46,  3.00it/s][A
step: 94/3290, eval_loss: 0.3076, eval_acc: 0.9205:   3%|[32m▎         [0m| 94/3290 [00:35<17:46,  3.00it/s][A[2025-02-04 03:14:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 94/3290, eval_loss: 0.3076, eval_acc: 0.9205:   3%|[32m▎         [0m| 95/3290 [00:36<17:33,  3.03it/s][A
step: 95/3290, eval_loss: 0.3112, eval_acc: 0.9194:   3%|[32m▎         [0m| 95/3290 [00:36<17:33,  3.03it/s][A[2025-02-04 03:14:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 95/3290, eval_loss: 0.3112, eval_acc: 0.9194:   3%|[32m▎         [0m| 96/3290 [00:36<17:32,  3.03it/s][A
step: 96/3290, eval_loss: 0.3123, eval_acc: 0.9199:   3%|[32m▎         [0m| 96/3290 [00:36<17:32,  3.03it/s][A[2025-02-04 03:14:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 96/3290, eval_loss: 0.3123, eval_acc: 0.9199:   3%|[32m▎         [0m| 97/3290 [00:36<19:46,  2.69it/s][A
step: 97/3290, eval_loss: 0.3099, eval_acc: 0.9206:   3%|[32m▎         [0m| 97/3290 [00:36<19:46,  2.69it/s][A[2025-02-04 03:14:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 97/3290, eval_loss: 0.3099, eval_acc: 0.9206:   3%|[32m▎         [0m| 98/3290 [00:37<20:28,  2.60it/s][A
step: 98/3290, eval_loss: 0.3095, eval_acc: 0.9208:   3%|[32m▎         [0m| 98/3290 [00:37<20:28,  2.60it/s][A[2025-02-04 03:14:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 98/3290, eval_loss: 0.3095, eval_acc: 0.9208:   3%|[32m▎         [0m| 99/3290 [00:37<21:27,  2.48it/s][A
step: 99/3290, eval_loss: 0.3121, eval_acc: 0.9202:   3%|[32m▎         [0m| 99/3290 [00:37<21:27,  2.48it/s][A[2025-02-04 03:14:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 99/3290, eval_loss: 0.3121, eval_acc: 0.9202:   3%|[32m▎         [0m| 100/3290 [00:38<22:16,  2.39it/s][A
step: 100/3290, eval_loss: 0.3101, eval_acc: 0.9204:   3%|[32m▎         [0m| 100/3290 [00:38<22:16,  2.39it/s][A[2025-02-04 03:14:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 100/3290, eval_loss: 0.3101, eval_acc: 0.9204:   3%|[32m▎         [0m| 101/3290 [00:38<21:16,  2.50it/s][A
step: 101/3290, eval_loss: 0.3095, eval_acc: 0.9205:   3%|[32m▎         [0m| 101/3290 [00:38<21:16,  2.50it/s][A[2025-02-04 03:14:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 101/3290, eval_loss: 0.3095, eval_acc: 0.9205:   3%|[32m▎         [0m| 102/3290 [00:38<19:00,  2.80it/s][A
step: 102/3290, eval_loss: 0.3094, eval_acc: 0.9207:   3%|[32m▎         [0m| 102/3290 [00:38<19:00,  2.80it/s][A[2025-02-04 03:14:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 102/3290, eval_loss: 0.3094, eval_acc: 0.9207:   3%|[32m▎         [0m| 103/3290 [00:39<19:34,  2.71it/s][A
step: 103/3290, eval_loss: 0.3086, eval_acc: 0.9209:   3%|[32m▎         [0m| 103/3290 [00:39<19:34,  2.71it/s][A[2025-02-04 03:14:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 103/3290, eval_loss: 0.3086, eval_acc: 0.9209:   3%|[32m▎         [0m| 104/3290 [00:39<17:23,  3.05it/s][A
step: 104/3290, eval_loss: 0.3091, eval_acc: 0.9207:   3%|[32m▎         [0m| 104/3290 [00:39<17:23,  3.05it/s][A[2025-02-04 03:14:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 104/3290, eval_loss: 0.3091, eval_acc: 0.9207:   3%|[32m▎         [0m| 105/3290 [00:39<18:49,  2.82it/s][A
step: 105/3290, eval_loss: 0.3120, eval_acc: 0.9204:   3%|[32m▎         [0m| 105/3290 [00:39<18:49,  2.82it/s][A[2025-02-04 03:14:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 105/3290, eval_loss: 0.3120, eval_acc: 0.9204:   3%|[32m▎         [0m| 106/3290 [00:40<17:37,  3.01it/s][A
step: 106/3290, eval_loss: 0.3131, eval_acc: 0.9202:   3%|[32m▎         [0m| 106/3290 [00:40<17:37,  3.01it/s][A[2025-02-04 03:14:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 106/3290, eval_loss: 0.3131, eval_acc: 0.9202:   3%|[32m▎         [0m| 107/3290 [00:40<17:13,  3.08it/s][A
step: 107/3290, eval_loss: 0.3155, eval_acc: 0.9198:   3%|[32m▎         [0m| 107/3290 [00:40<17:13,  3.08it/s][A[2025-02-04 03:14:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 107/3290, eval_loss: 0.3155, eval_acc: 0.9198:   3%|[32m▎         [0m| 108/3290 [00:40<16:28,  3.22it/s][A
step: 108/3290, eval_loss: 0.3134, eval_acc: 0.9204:   3%|[32m▎         [0m| 108/3290 [00:40<16:28,  3.22it/s][A[2025-02-04 03:14:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 108/3290, eval_loss: 0.3134, eval_acc: 0.9204:   3%|[32m▎         [0m| 109/3290 [00:41<17:05,  3.10it/s][A
step: 109/3290, eval_loss: 0.3130, eval_acc: 0.9206:   3%|[32m▎         [0m| 109/3290 [00:41<17:05,  3.10it/s][A[2025-02-04 03:14:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 109/3290, eval_loss: 0.3130, eval_acc: 0.9206:   3%|[32m▎         [0m| 110/3290 [00:41<17:36,  3.01it/s][A
step: 110/3290, eval_loss: 0.3137, eval_acc: 0.9203:   3%|[32m▎         [0m| 110/3290 [00:41<17:36,  3.01it/s][A[2025-02-04 03:14:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 110/3290, eval_loss: 0.3137, eval_acc: 0.9203:   3%|[32m▎         [0m| 111/3290 [00:41<17:56,  2.95it/s][A
step: 111/3290, eval_loss: 0.3152, eval_acc: 0.9199:   3%|[32m▎         [0m| 111/3290 [00:41<17:56,  2.95it/s][A[2025-02-04 03:14:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 111/3290, eval_loss: 0.3152, eval_acc: 0.9199:   3%|[32m▎         [0m| 112/3290 [00:42<17:58,  2.95it/s][A
step: 112/3290, eval_loss: 0.3152, eval_acc: 0.9200:   3%|[32m▎         [0m| 112/3290 [00:42<17:58,  2.95it/s][A[2025-02-04 03:14:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 112/3290, eval_loss: 0.3152, eval_acc: 0.9200:   3%|[32m▎         [0m| 113/3290 [00:42<16:57,  3.12it/s][A
step: 113/3290, eval_loss: 0.3168, eval_acc: 0.9196:   3%|[32m▎         [0m| 113/3290 [00:42<16:57,  3.12it/s][A[2025-02-04 03:14:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 113/3290, eval_loss: 0.3168, eval_acc: 0.9196:   3%|[32m▎         [0m| 114/3290 [00:42<16:59,  3.11it/s][A
step: 114/3290, eval_loss: 0.3255, eval_acc: 0.9180:   3%|[32m▎         [0m| 114/3290 [00:42<16:59,  3.11it/s][A[2025-02-04 03:14:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 114/3290, eval_loss: 0.3255, eval_acc: 0.9180:   3%|[32m▎         [0m| 115/3290 [00:43<17:05,  3.10it/s][A
step: 115/3290, eval_loss: 0.3305, eval_acc: 0.9172:   3%|[32m▎         [0m| 115/3290 [00:43<17:05,  3.10it/s][A[2025-02-04 03:14:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 115/3290, eval_loss: 0.3305, eval_acc: 0.9172:   4%|[32m▎         [0m| 116/3290 [00:43<17:19,  3.05it/s][A
step: 116/3290, eval_loss: 0.3284, eval_acc: 0.9177:   4%|[32m▎         [0m| 116/3290 [00:43<17:19,  3.05it/s][A[2025-02-04 03:14:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 116/3290, eval_loss: 0.3284, eval_acc: 0.9177:   4%|[32m▎         [0m| 117/3290 [00:43<19:02,  2.78it/s][A
step: 117/3290, eval_loss: 0.3267, eval_acc: 0.9180:   4%|[32m▎         [0m| 117/3290 [00:43<19:02,  2.78it/s][A[2025-02-04 03:14:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 117/3290, eval_loss: 0.3267, eval_acc: 0.9180:   4%|[32m▎         [0m| 118/3290 [00:44<21:39,  2.44it/s][A
step: 118/3290, eval_loss: 0.3322, eval_acc: 0.9169:   4%|[32m▎         [0m| 118/3290 [00:44<21:39,  2.44it/s][A[2025-02-04 03:14:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 118/3290, eval_loss: 0.3322, eval_acc: 0.9169:   4%|[32m▎         [0m| 119/3290 [00:44<21:12,  2.49it/s][A
step: 119/3290, eval_loss: 0.3316, eval_acc: 0.9173:   4%|[32m▎         [0m| 119/3290 [00:44<21:12,  2.49it/s][A[2025-02-04 03:14:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 119/3290, eval_loss: 0.3316, eval_acc: 0.9173:   4%|[32m▎         [0m| 120/3290 [00:45<20:28,  2.58it/s][A
step: 120/3290, eval_loss: 0.3376, eval_acc: 0.9163:   4%|[32m▎         [0m| 120/3290 [00:45<20:28,  2.58it/s][A[2025-02-04 03:14:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 120/3290, eval_loss: 0.3376, eval_acc: 0.9163:   4%|[32m▎         [0m| 121/3290 [00:45<21:02,  2.51it/s][A
step: 121/3290, eval_loss: 0.3366, eval_acc: 0.9164:   4%|[32m▎         [0m| 121/3290 [00:45<21:02,  2.51it/s][A[2025-02-04 03:14:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 121/3290, eval_loss: 0.3366, eval_acc: 0.9164:   4%|[32m▎         [0m| 122/3290 [00:45<19:44,  2.68it/s][A
step: 122/3290, eval_loss: 0.3354, eval_acc: 0.9165:   4%|[32m▎         [0m| 122/3290 [00:45<19:44,  2.68it/s][A[2025-02-04 03:14:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 122/3290, eval_loss: 0.3354, eval_acc: 0.9165:   4%|[32m▎         [0m| 123/3290 [00:46<18:59,  2.78it/s][A
step: 123/3290, eval_loss: 0.3358, eval_acc: 0.9161:   4%|[32m▎         [0m| 123/3290 [00:46<18:59,  2.78it/s][A[2025-02-04 03:14:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 123/3290, eval_loss: 0.3358, eval_acc: 0.9161:   4%|[32m▍         [0m| 124/3290 [00:46<20:49,  2.53it/s][A
step: 124/3290, eval_loss: 0.3360, eval_acc: 0.9159:   4%|[32m▍         [0m| 124/3290 [00:46<20:49,  2.53it/s][A[2025-02-04 03:14:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 124/3290, eval_loss: 0.3360, eval_acc: 0.9159:   4%|[32m▍         [0m| 125/3290 [00:47<20:13,  2.61it/s][A
step: 125/3290, eval_loss: 0.3387, eval_acc: 0.9158:   4%|[32m▍         [0m| 125/3290 [00:47<20:13,  2.61it/s][A[2025-02-04 03:14:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 125/3290, eval_loss: 0.3387, eval_acc: 0.9158:   4%|[32m▍         [0m| 126/3290 [00:47<19:39,  2.68it/s][A
step: 126/3290, eval_loss: 0.3400, eval_acc: 0.9154:   4%|[32m▍         [0m| 126/3290 [00:47<19:39,  2.68it/s][A[2025-02-04 03:14:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 126/3290, eval_loss: 0.3400, eval_acc: 0.9154:   4%|[32m▍         [0m| 127/3290 [00:47<19:02,  2.77it/s][A
step: 127/3290, eval_loss: 0.3419, eval_acc: 0.9147:   4%|[32m▍         [0m| 127/3290 [00:47<19:02,  2.77it/s][A[2025-02-04 03:14:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 127/3290, eval_loss: 0.3419, eval_acc: 0.9147:   4%|[32m▍         [0m| 128/3290 [00:48<19:33,  2.69it/s][A
step: 128/3290, eval_loss: 0.3420, eval_acc: 0.9143:   4%|[32m▍         [0m| 128/3290 [00:48<19:33,  2.69it/s][A[2025-02-04 03:14:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 128/3290, eval_loss: 0.3420, eval_acc: 0.9143:   4%|[32m▍         [0m| 129/3290 [00:48<19:06,  2.76it/s][A
step: 129/3290, eval_loss: 0.3417, eval_acc: 0.9144:   4%|[32m▍         [0m| 129/3290 [00:48<19:06,  2.76it/s][A[2025-02-04 03:14:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 129/3290, eval_loss: 0.3417, eval_acc: 0.9144:   4%|[32m▍         [0m| 130/3290 [00:48<18:54,  2.79it/s][A
step: 130/3290, eval_loss: 0.3417, eval_acc: 0.9143:   4%|[32m▍         [0m| 130/3290 [00:48<18:54,  2.79it/s][A[2025-02-04 03:14:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 130/3290, eval_loss: 0.3417, eval_acc: 0.9143:   4%|[32m▍         [0m| 131/3290 [00:49<19:54,  2.65it/s][A
step: 131/3290, eval_loss: 0.3406, eval_acc: 0.9145:   4%|[32m▍         [0m| 131/3290 [00:49<19:54,  2.65it/s][A[2025-02-04 03:14:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 131/3290, eval_loss: 0.3406, eval_acc: 0.9145:   4%|[32m▍         [0m| 132/3290 [00:49<21:28,  2.45it/s][A
step: 132/3290, eval_loss: 0.3398, eval_acc: 0.9146:   4%|[32m▍         [0m| 132/3290 [00:49<21:28,  2.45it/s][A[2025-02-04 03:14:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 132/3290, eval_loss: 0.3398, eval_acc: 0.9146:   4%|[32m▍         [0m| 133/3290 [00:50<20:26,  2.57it/s][A
step: 133/3290, eval_loss: 0.3398, eval_acc: 0.9147:   4%|[32m▍         [0m| 133/3290 [00:50<20:26,  2.57it/s][A[2025-02-04 03:14:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 133/3290, eval_loss: 0.3398, eval_acc: 0.9147:   4%|[32m▍         [0m| 134/3290 [00:50<19:52,  2.65it/s][A
step: 134/3290, eval_loss: 0.3393, eval_acc: 0.9147:   4%|[32m▍         [0m| 134/3290 [00:50<19:52,  2.65it/s][A[2025-02-04 03:14:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 134/3290, eval_loss: 0.3393, eval_acc: 0.9147:   4%|[32m▍         [0m| 135/3290 [00:50<17:58,  2.92it/s][A
step: 135/3290, eval_loss: 0.3374, eval_acc: 0.9151:   4%|[32m▍         [0m| 135/3290 [00:50<17:58,  2.92it/s][A[2025-02-04 03:14:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 135/3290, eval_loss: 0.3374, eval_acc: 0.9151:   4%|[32m▍         [0m| 136/3290 [00:51<18:40,  2.81it/s][A
step: 136/3290, eval_loss: 0.3358, eval_acc: 0.9153:   4%|[32m▍         [0m| 136/3290 [00:51<18:40,  2.81it/s][A[2025-02-04 03:14:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 136/3290, eval_loss: 0.3358, eval_acc: 0.9153:   4%|[32m▍         [0m| 137/3290 [00:51<19:45,  2.66it/s][A
step: 137/3290, eval_loss: 0.3366, eval_acc: 0.9149:   4%|[32m▍         [0m| 137/3290 [00:51<19:45,  2.66it/s][A[2025-02-04 03:14:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 137/3290, eval_loss: 0.3366, eval_acc: 0.9149:   4%|[32m▍         [0m| 138/3290 [00:51<19:42,  2.66it/s][A
step: 138/3290, eval_loss: 0.3352, eval_acc: 0.9154:   4%|[32m▍         [0m| 138/3290 [00:51<19:42,  2.66it/s][A[2025-02-04 03:14:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 138/3290, eval_loss: 0.3352, eval_acc: 0.9154:   4%|[32m▍         [0m| 139/3290 [00:52<20:33,  2.56it/s][A
step: 139/3290, eval_loss: 0.3350, eval_acc: 0.9153:   4%|[32m▍         [0m| 139/3290 [00:52<20:33,  2.56it/s][A[2025-02-04 03:14:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 139/3290, eval_loss: 0.3350, eval_acc: 0.9153:   4%|[32m▍         [0m| 140/3290 [00:52<20:35,  2.55it/s][A
step: 140/3290, eval_loss: 0.3350, eval_acc: 0.9153:   4%|[32m▍         [0m| 140/3290 [00:52<20:35,  2.55it/s][A[2025-02-04 03:14:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 140/3290, eval_loss: 0.3350, eval_acc: 0.9153:   4%|[32m▍         [0m| 141/3290 [00:53<20:53,  2.51it/s][A
step: 141/3290, eval_loss: 0.3341, eval_acc: 0.9154:   4%|[32m▍         [0m| 141/3290 [00:53<20:53,  2.51it/s][A[2025-02-04 03:14:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 141/3290, eval_loss: 0.3341, eval_acc: 0.9154:   4%|[32m▍         [0m| 142/3290 [00:53<20:22,  2.57it/s][A
step: 142/3290, eval_loss: 0.3344, eval_acc: 0.9154:   4%|[32m▍         [0m| 142/3290 [00:53<20:22,  2.57it/s][A[2025-02-04 03:14:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 142/3290, eval_loss: 0.3344, eval_acc: 0.9154:   4%|[32m▍         [0m| 143/3290 [00:53<20:46,  2.53it/s][A
step: 143/3290, eval_loss: 0.3363, eval_acc: 0.9148:   4%|[32m▍         [0m| 143/3290 [00:53<20:46,  2.53it/s][A[2025-02-04 03:14:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 143/3290, eval_loss: 0.3363, eval_acc: 0.9148:   4%|[32m▍         [0m| 144/3290 [00:54<20:22,  2.57it/s][A
step: 144/3290, eval_loss: 0.3379, eval_acc: 0.9146:   4%|[32m▍         [0m| 144/3290 [00:54<20:22,  2.57it/s][A[2025-02-04 03:14:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 144/3290, eval_loss: 0.3379, eval_acc: 0.9146:   4%|[32m▍         [0m| 145/3290 [00:54<21:15,  2.47it/s][A
step: 145/3290, eval_loss: 0.3386, eval_acc: 0.9145:   4%|[32m▍         [0m| 145/3290 [00:54<21:15,  2.47it/s][A[2025-02-04 03:14:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 145/3290, eval_loss: 0.3386, eval_acc: 0.9145:   4%|[32m▍         [0m| 146/3290 [00:55<21:37,  2.42it/s][A
step: 146/3290, eval_loss: 0.3388, eval_acc: 0.9143:   4%|[32m▍         [0m| 146/3290 [00:55<21:37,  2.42it/s][A[2025-02-04 03:14:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 146/3290, eval_loss: 0.3388, eval_acc: 0.9143:   4%|[32m▍         [0m| 147/3290 [00:55<21:45,  2.41it/s][A
step: 147/3290, eval_loss: 0.3419, eval_acc: 0.9135:   4%|[32m▍         [0m| 147/3290 [00:55<21:45,  2.41it/s][A[2025-02-04 03:14:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 147/3290, eval_loss: 0.3419, eval_acc: 0.9135:   4%|[32m▍         [0m| 148/3290 [00:56<22:21,  2.34it/s][A
step: 148/3290, eval_loss: 0.3410, eval_acc: 0.9135:   4%|[32m▍         [0m| 148/3290 [00:56<22:21,  2.34it/s][A[2025-02-04 03:14:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 148/3290, eval_loss: 0.3410, eval_acc: 0.9135:   5%|[32m▍         [0m| 149/3290 [00:56<21:25,  2.44it/s][A
step: 149/3290, eval_loss: 0.3399, eval_acc: 0.9138:   5%|[32m▍         [0m| 149/3290 [00:56<21:25,  2.44it/s][A[2025-02-04 03:14:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 149/3290, eval_loss: 0.3399, eval_acc: 0.9138:   5%|[32m▍         [0m| 150/3290 [00:56<20:57,  2.50it/s][A
step: 150/3290, eval_loss: 0.3379, eval_acc: 0.9144:   5%|[32m▍         [0m| 150/3290 [00:56<20:57,  2.50it/s][A[2025-02-04 03:14:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 150/3290, eval_loss: 0.3379, eval_acc: 0.9144:   5%|[32m▍         [0m| 151/3290 [00:57<20:01,  2.61it/s][A
step: 151/3290, eval_loss: 0.3365, eval_acc: 0.9147:   5%|[32m▍         [0m| 151/3290 [00:57<20:01,  2.61it/s][A[2025-02-04 03:14:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 151/3290, eval_loss: 0.3365, eval_acc: 0.9147:   5%|[32m▍         [0m| 152/3290 [00:57<20:09,  2.59it/s][A
step: 152/3290, eval_loss: 0.3371, eval_acc: 0.9147:   5%|[32m▍         [0m| 152/3290 [00:57<20:09,  2.59it/s][A[2025-02-04 03:14:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 152/3290, eval_loss: 0.3371, eval_acc: 0.9147:   5%|[32m▍         [0m| 153/3290 [00:57<20:11,  2.59it/s][A
step: 153/3290, eval_loss: 0.3374, eval_acc: 0.9146:   5%|[32m▍         [0m| 153/3290 [00:57<20:11,  2.59it/s][A[2025-02-04 03:14:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 153/3290, eval_loss: 0.3374, eval_acc: 0.9146:   5%|[32m▍         [0m| 154/3290 [00:58<19:04,  2.74it/s][A
step: 154/3290, eval_loss: 0.3367, eval_acc: 0.9148:   5%|[32m▍         [0m| 154/3290 [00:58<19:04,  2.74it/s][A[2025-02-04 03:14:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 154/3290, eval_loss: 0.3367, eval_acc: 0.9148:   5%|[32m▍         [0m| 155/3290 [00:58<19:11,  2.72it/s][A
step: 155/3290, eval_loss: 0.3353, eval_acc: 0.9153:   5%|[32m▍         [0m| 155/3290 [00:58<19:11,  2.72it/s][A[2025-02-04 03:14:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 155/3290, eval_loss: 0.3353, eval_acc: 0.9153:   5%|[32m▍         [0m| 156/3290 [00:58<17:57,  2.91it/s][A
step: 156/3290, eval_loss: 0.3377, eval_acc: 0.9144:   5%|[32m▍         [0m| 156/3290 [00:58<17:57,  2.91it/s][A[2025-02-04 03:14:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 156/3290, eval_loss: 0.3377, eval_acc: 0.9144:   5%|[32m▍         [0m| 157/3290 [00:59<18:26,  2.83it/s][A
step: 157/3290, eval_loss: 0.3374, eval_acc: 0.9143:   5%|[32m▍         [0m| 157/3290 [00:59<18:26,  2.83it/s][A[2025-02-04 03:14:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 157/3290, eval_loss: 0.3374, eval_acc: 0.9143:   5%|[32m▍         [0m| 158/3290 [00:59<16:59,  3.07it/s][A
step: 158/3290, eval_loss: 0.3358, eval_acc: 0.9148:   5%|[32m▍         [0m| 158/3290 [00:59<16:59,  3.07it/s][A[2025-02-04 03:14:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 158/3290, eval_loss: 0.3358, eval_acc: 0.9148:   5%|[32m▍         [0m| 159/3290 [00:59<16:45,  3.11it/s][A
step: 159/3290, eval_loss: 0.3342, eval_acc: 0.9151:   5%|[32m▍         [0m| 159/3290 [00:59<16:45,  3.11it/s][A[2025-02-04 03:14:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 159/3290, eval_loss: 0.3342, eval_acc: 0.9151:   5%|[32m▍         [0m| 160/3290 [01:00<17:43,  2.94it/s][A
step: 160/3290, eval_loss: 0.3327, eval_acc: 0.9154:   5%|[32m▍         [0m| 160/3290 [01:00<17:43,  2.94it/s][A[2025-02-04 03:14:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 160/3290, eval_loss: 0.3327, eval_acc: 0.9154:   5%|[32m▍         [0m| 161/3290 [01:00<17:31,  2.98it/s][A
step: 161/3290, eval_loss: 0.3340, eval_acc: 0.9152:   5%|[32m▍         [0m| 161/3290 [01:00<17:31,  2.98it/s][A[2025-02-04 03:14:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 161/3290, eval_loss: 0.3340, eval_acc: 0.9152:   5%|[32m▍         [0m| 162/3290 [01:00<17:38,  2.96it/s][A
step: 162/3290, eval_loss: 0.3364, eval_acc: 0.9147:   5%|[32m▍         [0m| 162/3290 [01:00<17:38,  2.96it/s][A[2025-02-04 03:14:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 162/3290, eval_loss: 0.3364, eval_acc: 0.9147:   5%|[32m▍         [0m| 163/3290 [01:01<16:56,  3.08it/s][A
step: 163/3290, eval_loss: 0.3378, eval_acc: 0.9145:   5%|[32m▍         [0m| 163/3290 [01:01<16:56,  3.08it/s][A[2025-02-04 03:14:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 163/3290, eval_loss: 0.3378, eval_acc: 0.9145:   5%|[32m▍         [0m| 164/3290 [01:01<17:12,  3.03it/s][A
step: 164/3290, eval_loss: 0.3384, eval_acc: 0.9143:   5%|[32m▍         [0m| 164/3290 [01:01<17:12,  3.03it/s][A[2025-02-04 03:14:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 164/3290, eval_loss: 0.3384, eval_acc: 0.9143:   5%|[32m▌         [0m| 165/3290 [01:01<17:25,  2.99it/s][A
step: 165/3290, eval_loss: 0.3379, eval_acc: 0.9145:   5%|[32m▌         [0m| 165/3290 [01:01<17:25,  2.99it/s][A[2025-02-04 03:14:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 165/3290, eval_loss: 0.3379, eval_acc: 0.9145:   5%|[32m▌         [0m| 166/3290 [01:02<17:16,  3.01it/s][A
step: 166/3290, eval_loss: 0.3370, eval_acc: 0.9147:   5%|[32m▌         [0m| 166/3290 [01:02<17:16,  3.01it/s][A[2025-02-04 03:14:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 166/3290, eval_loss: 0.3370, eval_acc: 0.9147:   5%|[32m▌         [0m| 167/3290 [01:02<17:22,  3.00it/s][A
step: 167/3290, eval_loss: 0.3362, eval_acc: 0.9148:   5%|[32m▌         [0m| 167/3290 [01:02<17:22,  3.00it/s][A[2025-02-04 03:14:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 167/3290, eval_loss: 0.3362, eval_acc: 0.9148:   5%|[32m▌         [0m| 168/3290 [01:02<18:10,  2.86it/s][A
step: 168/3290, eval_loss: 0.3354, eval_acc: 0.9148:   5%|[32m▌         [0m| 168/3290 [01:02<18:10,  2.86it/s][A[2025-02-04 03:14:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 168/3290, eval_loss: 0.3354, eval_acc: 0.9148:   5%|[32m▌         [0m| 169/3290 [01:03<18:35,  2.80it/s][A
step: 169/3290, eval_loss: 0.3353, eval_acc: 0.9145:   5%|[32m▌         [0m| 169/3290 [01:03<18:35,  2.80it/s][A[2025-02-04 03:14:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 169/3290, eval_loss: 0.3353, eval_acc: 0.9145:   5%|[32m▌         [0m| 170/3290 [01:03<17:55,  2.90it/s][A
step: 170/3290, eval_loss: 0.3346, eval_acc: 0.9147:   5%|[32m▌         [0m| 170/3290 [01:03<17:55,  2.90it/s][A[2025-02-04 03:14:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 170/3290, eval_loss: 0.3346, eval_acc: 0.9147:   5%|[32m▌         [0m| 171/3290 [01:03<18:28,  2.81it/s][A
step: 171/3290, eval_loss: 0.3356, eval_acc: 0.9145:   5%|[32m▌         [0m| 171/3290 [01:03<18:28,  2.81it/s][A[2025-02-04 03:14:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 171/3290, eval_loss: 0.3356, eval_acc: 0.9145:   5%|[32m▌         [0m| 172/3290 [01:04<18:24,  2.82it/s][A
step: 172/3290, eval_loss: 0.3344, eval_acc: 0.9149:   5%|[32m▌         [0m| 172/3290 [01:04<18:24,  2.82it/s][A[2025-02-04 03:14:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 172/3290, eval_loss: 0.3344, eval_acc: 0.9149:   5%|[32m▌         [0m| 173/3290 [01:04<18:52,  2.75it/s][A
step: 173/3290, eval_loss: 0.3359, eval_acc: 0.9145:   5%|[32m▌         [0m| 173/3290 [01:04<18:52,  2.75it/s][A[2025-02-04 03:14:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 173/3290, eval_loss: 0.3359, eval_acc: 0.9145:   5%|[32m▌         [0m| 174/3290 [01:05<20:25,  2.54it/s][A
step: 174/3290, eval_loss: 0.3351, eval_acc: 0.9146:   5%|[32m▌         [0m| 174/3290 [01:05<20:25,  2.54it/s][A[2025-02-04 03:14:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 174/3290, eval_loss: 0.3351, eval_acc: 0.9146:   5%|[32m▌         [0m| 175/3290 [01:05<19:56,  2.60it/s][A
step: 175/3290, eval_loss: 0.3359, eval_acc: 0.9142:   5%|[32m▌         [0m| 175/3290 [01:05<19:56,  2.60it/s][A[2025-02-04 03:14:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 175/3290, eval_loss: 0.3359, eval_acc: 0.9142:   5%|[32m▌         [0m| 176/3290 [01:05<20:47,  2.50it/s][A
step: 176/3290, eval_loss: 0.3345, eval_acc: 0.9145:   5%|[32m▌         [0m| 176/3290 [01:05<20:47,  2.50it/s][A[2025-02-04 03:15:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 176/3290, eval_loss: 0.3345, eval_acc: 0.9145:   5%|[32m▌         [0m| 177/3290 [01:06<20:03,  2.59it/s][A
step: 177/3290, eval_loss: 0.3373, eval_acc: 0.9139:   5%|[32m▌         [0m| 177/3290 [01:06<20:03,  2.59it/s][A[2025-02-04 03:15:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 177/3290, eval_loss: 0.3373, eval_acc: 0.9139:   5%|[32m▌         [0m| 178/3290 [01:06<20:09,  2.57it/s][A
step: 178/3290, eval_loss: 0.3375, eval_acc: 0.9138:   5%|[32m▌         [0m| 178/3290 [01:06<20:09,  2.57it/s][A[2025-02-04 03:15:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 178/3290, eval_loss: 0.3375, eval_acc: 0.9138:   5%|[32m▌         [0m| 179/3290 [01:07<22:35,  2.29it/s][A
step: 179/3290, eval_loss: 0.3365, eval_acc: 0.9141:   5%|[32m▌         [0m| 179/3290 [01:07<22:35,  2.29it/s][A[2025-02-04 03:15:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 179/3290, eval_loss: 0.3365, eval_acc: 0.9141:   5%|[32m▌         [0m| 180/3290 [01:07<23:31,  2.20it/s][A
step: 180/3290, eval_loss: 0.3352, eval_acc: 0.9144:   5%|[32m▌         [0m| 180/3290 [01:07<23:31,  2.20it/s][A[2025-02-04 03:15:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 180/3290, eval_loss: 0.3352, eval_acc: 0.9144:   6%|[32m▌         [0m| 181/3290 [01:08<23:29,  2.21it/s][A
step: 181/3290, eval_loss: 0.3348, eval_acc: 0.9144:   6%|[32m▌         [0m| 181/3290 [01:08<23:29,  2.21it/s][A[2025-02-04 03:15:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 181/3290, eval_loss: 0.3348, eval_acc: 0.9144:   6%|[32m▌         [0m| 182/3290 [01:08<21:11,  2.45it/s][A
step: 182/3290, eval_loss: 0.3353, eval_acc: 0.9142:   6%|[32m▌         [0m| 182/3290 [01:08<21:11,  2.45it/s][A[2025-02-04 03:15:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 182/3290, eval_loss: 0.3353, eval_acc: 0.9142:   6%|[32m▌         [0m| 183/3290 [01:08<19:15,  2.69it/s][A
step: 183/3290, eval_loss: 0.3356, eval_acc: 0.9141:   6%|[32m▌         [0m| 183/3290 [01:08<19:15,  2.69it/s][A[2025-02-04 03:15:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 183/3290, eval_loss: 0.3356, eval_acc: 0.9141:   6%|[32m▌         [0m| 184/3290 [01:09<18:06,  2.86it/s][A
step: 184/3290, eval_loss: 0.3345, eval_acc: 0.9144:   6%|[32m▌         [0m| 184/3290 [01:09<18:06,  2.86it/s][A[2025-02-04 03:15:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 184/3290, eval_loss: 0.3345, eval_acc: 0.9144:   6%|[32m▌         [0m| 185/3290 [01:09<19:39,  2.63it/s][A
step: 185/3290, eval_loss: 0.3354, eval_acc: 0.9139:   6%|[32m▌         [0m| 185/3290 [01:09<19:39,  2.63it/s][A[2025-02-04 03:15:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 185/3290, eval_loss: 0.3354, eval_acc: 0.9139:   6%|[32m▌         [0m| 186/3290 [01:09<19:48,  2.61it/s][A
step: 186/3290, eval_loss: 0.3354, eval_acc: 0.9140:   6%|[32m▌         [0m| 186/3290 [01:09<19:48,  2.61it/s][A[2025-02-04 03:15:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 186/3290, eval_loss: 0.3354, eval_acc: 0.9140:   6%|[32m▌         [0m| 187/3290 [01:10<20:04,  2.58it/s][A
step: 187/3290, eval_loss: 0.3352, eval_acc: 0.9138:   6%|[32m▌         [0m| 187/3290 [01:10<20:04,  2.58it/s][A[2025-02-04 03:15:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 187/3290, eval_loss: 0.3352, eval_acc: 0.9138:   6%|[32m▌         [0m| 188/3290 [01:10<20:53,  2.47it/s][A
step: 188/3290, eval_loss: 0.3349, eval_acc: 0.9139:   6%|[32m▌         [0m| 188/3290 [01:10<20:53,  2.47it/s][A[2025-02-04 03:15:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 188/3290, eval_loss: 0.3349, eval_acc: 0.9139:   6%|[32m▌         [0m| 189/3290 [01:11<20:32,  2.52it/s][A
step: 189/3290, eval_loss: 0.3353, eval_acc: 0.9138:   6%|[32m▌         [0m| 189/3290 [01:11<20:32,  2.52it/s][A[2025-02-04 03:15:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 189/3290, eval_loss: 0.3353, eval_acc: 0.9138:   6%|[32m▌         [0m| 190/3290 [01:11<18:58,  2.72it/s][A
step: 190/3290, eval_loss: 0.3356, eval_acc: 0.9137:   6%|[32m▌         [0m| 190/3290 [01:11<18:58,  2.72it/s][A[2025-02-04 03:15:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 190/3290, eval_loss: 0.3356, eval_acc: 0.9137:   6%|[32m▌         [0m| 191/3290 [01:11<19:37,  2.63it/s][A
step: 191/3290, eval_loss: 0.3361, eval_acc: 0.9134:   6%|[32m▌         [0m| 191/3290 [01:11<19:37,  2.63it/s][A[2025-02-04 03:15:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 191/3290, eval_loss: 0.3361, eval_acc: 0.9134:   6%|[32m▌         [0m| 192/3290 [01:12<18:42,  2.76it/s][A
step: 192/3290, eval_loss: 0.3392, eval_acc: 0.9124:   6%|[32m▌         [0m| 192/3290 [01:12<18:42,  2.76it/s][A[2025-02-04 03:15:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 192/3290, eval_loss: 0.3392, eval_acc: 0.9124:   6%|[32m▌         [0m| 193/3290 [01:12<18:29,  2.79it/s][A
step: 193/3290, eval_loss: 0.3378, eval_acc: 0.9127:   6%|[32m▌         [0m| 193/3290 [01:12<18:29,  2.79it/s][A[2025-02-04 03:15:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 193/3290, eval_loss: 0.3378, eval_acc: 0.9127:   6%|[32m▌         [0m| 194/3290 [01:12<17:34,  2.94it/s][A
step: 194/3290, eval_loss: 0.3375, eval_acc: 0.9127:   6%|[32m▌         [0m| 194/3290 [01:12<17:34,  2.94it/s][A[2025-02-04 03:15:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 194/3290, eval_loss: 0.3375, eval_acc: 0.9127:   6%|[32m▌         [0m| 195/3290 [01:13<16:36,  3.11it/s][A
step: 195/3290, eval_loss: 0.3380, eval_acc: 0.9127:   6%|[32m▌         [0m| 195/3290 [01:13<16:36,  3.11it/s][A[2025-02-04 03:15:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 195/3290, eval_loss: 0.3380, eval_acc: 0.9127:   6%|[32m▌         [0m| 196/3290 [01:13<16:08,  3.19it/s][A
step: 196/3290, eval_loss: 0.3383, eval_acc: 0.9124:   6%|[32m▌         [0m| 196/3290 [01:13<16:08,  3.19it/s][A[2025-02-04 03:15:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 196/3290, eval_loss: 0.3383, eval_acc: 0.9124:   6%|[32m▌         [0m| 197/3290 [01:13<16:33,  3.11it/s][A
step: 197/3290, eval_loss: 0.3379, eval_acc: 0.9124:   6%|[32m▌         [0m| 197/3290 [01:13<16:33,  3.11it/s][A[2025-02-04 03:15:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 197/3290, eval_loss: 0.3379, eval_acc: 0.9124:   6%|[32m▌         [0m| 198/3290 [01:14<15:45,  3.27it/s][A
step: 198/3290, eval_loss: 0.3379, eval_acc: 0.9125:   6%|[32m▌         [0m| 198/3290 [01:14<15:45,  3.27it/s][A[2025-02-04 03:15:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 198/3290, eval_loss: 0.3379, eval_acc: 0.9125:   6%|[32m▌         [0m| 199/3290 [01:14<15:35,  3.31it/s][A
step: 199/3290, eval_loss: 0.3376, eval_acc: 0.9126:   6%|[32m▌         [0m| 199/3290 [01:14<15:35,  3.31it/s][A[2025-02-04 03:15:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 199/3290, eval_loss: 0.3376, eval_acc: 0.9126:   6%|[32m▌         [0m| 200/3290 [01:14<16:09,  3.19it/s][A
step: 200/3290, eval_loss: 0.3382, eval_acc: 0.9125:   6%|[32m▌         [0m| 200/3290 [01:14<16:09,  3.19it/s][A[2025-02-04 03:15:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 200/3290, eval_loss: 0.3382, eval_acc: 0.9125:   6%|[32m▌         [0m| 201/3290 [01:14<16:27,  3.13it/s][A
step: 201/3290, eval_loss: 0.3382, eval_acc: 0.9125:   6%|[32m▌         [0m| 201/3290 [01:14<16:27,  3.13it/s][A[2025-02-04 03:15:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 201/3290, eval_loss: 0.3382, eval_acc: 0.9125:   6%|[32m▌         [0m| 202/3290 [01:15<16:58,  3.03it/s][A
step: 202/3290, eval_loss: 0.3387, eval_acc: 0.9125:   6%|[32m▌         [0m| 202/3290 [01:15<16:58,  3.03it/s][A[2025-02-04 03:15:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 202/3290, eval_loss: 0.3387, eval_acc: 0.9125:   6%|[32m▌         [0m| 203/3290 [01:15<16:23,  3.14it/s][A
step: 203/3290, eval_loss: 0.3379, eval_acc: 0.9126:   6%|[32m▌         [0m| 203/3290 [01:15<16:23,  3.14it/s][A[2025-02-04 03:15:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 203/3290, eval_loss: 0.3379, eval_acc: 0.9126:   6%|[32m▌         [0m| 204/3290 [01:15<16:16,  3.16it/s][A
step: 204/3290, eval_loss: 0.3402, eval_acc: 0.9124:   6%|[32m▌         [0m| 204/3290 [01:15<16:16,  3.16it/s][A[2025-02-04 03:15:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 204/3290, eval_loss: 0.3402, eval_acc: 0.9124:   6%|[32m▌         [0m| 205/3290 [01:16<15:54,  3.23it/s][A
step: 205/3290, eval_loss: 0.3402, eval_acc: 0.9121:   6%|[32m▌         [0m| 205/3290 [01:16<15:54,  3.23it/s][A[2025-02-04 03:15:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 205/3290, eval_loss: 0.3402, eval_acc: 0.9121:   6%|[32m▋         [0m| 206/3290 [01:16<17:12,  2.99it/s][A
step: 206/3290, eval_loss: 0.3400, eval_acc: 0.9122:   6%|[32m▋         [0m| 206/3290 [01:16<17:12,  2.99it/s][A[2025-02-04 03:15:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 206/3290, eval_loss: 0.3400, eval_acc: 0.9122:   6%|[32m▋         [0m| 207/3290 [01:17<18:24,  2.79it/s][A
step: 207/3290, eval_loss: 0.3401, eval_acc: 0.9121:   6%|[32m▋         [0m| 207/3290 [01:17<18:24,  2.79it/s][A[2025-02-04 03:15:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 207/3290, eval_loss: 0.3401, eval_acc: 0.9121:   6%|[32m▋         [0m| 208/3290 [01:17<20:01,  2.57it/s][A
step: 208/3290, eval_loss: 0.3395, eval_acc: 0.9123:   6%|[32m▋         [0m| 208/3290 [01:17<20:01,  2.57it/s][A[2025-02-04 03:15:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 208/3290, eval_loss: 0.3395, eval_acc: 0.9123:   6%|[32m▋         [0m| 209/3290 [01:17<19:17,  2.66it/s][A
step: 209/3290, eval_loss: 0.3391, eval_acc: 0.9123:   6%|[32m▋         [0m| 209/3290 [01:17<19:17,  2.66it/s][A[2025-02-04 03:15:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 209/3290, eval_loss: 0.3391, eval_acc: 0.9123:   6%|[32m▋         [0m| 210/3290 [01:18<19:59,  2.57it/s][A
step: 210/3290, eval_loss: 0.3396, eval_acc: 0.9123:   6%|[32m▋         [0m| 210/3290 [01:18<19:59,  2.57it/s][A[2025-02-04 03:15:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 210/3290, eval_loss: 0.3396, eval_acc: 0.9123:   6%|[32m▋         [0m| 211/3290 [01:18<19:16,  2.66it/s][A
step: 211/3290, eval_loss: 0.3391, eval_acc: 0.9121:   6%|[32m▋         [0m| 211/3290 [01:18<19:16,  2.66it/s][A[2025-02-04 03:15:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 211/3290, eval_loss: 0.3391, eval_acc: 0.9121:   6%|[32m▋         [0m| 212/3290 [01:18<18:27,  2.78it/s][A
step: 212/3290, eval_loss: 0.3395, eval_acc: 0.9121:   6%|[32m▋         [0m| 212/3290 [01:18<18:27,  2.78it/s][A[2025-02-04 03:15:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 212/3290, eval_loss: 0.3395, eval_acc: 0.9121:   6%|[32m▋         [0m| 213/3290 [01:19<18:42,  2.74it/s][A
step: 213/3290, eval_loss: 0.3399, eval_acc: 0.9119:   6%|[32m▋         [0m| 213/3290 [01:19<18:42,  2.74it/s][A[2025-02-04 03:15:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 213/3290, eval_loss: 0.3399, eval_acc: 0.9119:   7%|[32m▋         [0m| 214/3290 [01:19<18:21,  2.79it/s][A
step: 214/3290, eval_loss: 0.3390, eval_acc: 0.9122:   7%|[32m▋         [0m| 214/3290 [01:19<18:21,  2.79it/s][A[2025-02-04 03:15:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 214/3290, eval_loss: 0.3390, eval_acc: 0.9122:   7%|[32m▋         [0m| 215/3290 [01:19<17:09,  2.99it/s][A
step: 215/3290, eval_loss: 0.3389, eval_acc: 0.9122:   7%|[32m▋         [0m| 215/3290 [01:19<17:09,  2.99it/s][A[2025-02-04 03:15:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 215/3290, eval_loss: 0.3389, eval_acc: 0.9122:   7%|[32m▋         [0m| 216/3290 [01:20<18:42,  2.74it/s][A
step: 216/3290, eval_loss: 0.3383, eval_acc: 0.9124:   7%|[32m▋         [0m| 216/3290 [01:20<18:42,  2.74it/s][A[2025-02-04 03:15:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 216/3290, eval_loss: 0.3383, eval_acc: 0.9124:   7%|[32m▋         [0m| 217/3290 [01:20<19:03,  2.69it/s][A
step: 217/3290, eval_loss: 0.3380, eval_acc: 0.9124:   7%|[32m▋         [0m| 217/3290 [01:20<19:03,  2.69it/s][A[2025-02-04 03:15:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 217/3290, eval_loss: 0.3380, eval_acc: 0.9124:   7%|[32m▋         [0m| 218/3290 [01:21<17:35,  2.91it/s][A
step: 218/3290, eval_loss: 0.3389, eval_acc: 0.9121:   7%|[32m▋         [0m| 218/3290 [01:21<17:35,  2.91it/s][A[2025-02-04 03:15:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 218/3290, eval_loss: 0.3389, eval_acc: 0.9121:   7%|[32m▋         [0m| 219/3290 [01:21<18:03,  2.83it/s][A
step: 219/3290, eval_loss: 0.3390, eval_acc: 0.9121:   7%|[32m▋         [0m| 219/3290 [01:21<18:03,  2.83it/s][A[2025-02-04 03:15:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 219/3290, eval_loss: 0.3390, eval_acc: 0.9121:   7%|[32m▋         [0m| 220/3290 [01:21<18:51,  2.71it/s][A
step: 220/3290, eval_loss: 0.3411, eval_acc: 0.9117:   7%|[32m▋         [0m| 220/3290 [01:21<18:51,  2.71it/s][A[2025-02-04 03:15:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 220/3290, eval_loss: 0.3411, eval_acc: 0.9117:   7%|[32m▋         [0m| 221/3290 [01:22<19:05,  2.68it/s][A
step: 221/3290, eval_loss: 0.3419, eval_acc: 0.9116:   7%|[32m▋         [0m| 221/3290 [01:22<19:05,  2.68it/s][A[2025-02-04 03:15:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 221/3290, eval_loss: 0.3419, eval_acc: 0.9116:   7%|[32m▋         [0m| 222/3290 [01:22<18:13,  2.80it/s][A
step: 222/3290, eval_loss: 0.3413, eval_acc: 0.9118:   7%|[32m▋         [0m| 222/3290 [01:22<18:13,  2.80it/s][A[2025-02-04 03:15:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 222/3290, eval_loss: 0.3413, eval_acc: 0.9118:   7%|[32m▋         [0m| 223/3290 [01:22<17:55,  2.85it/s][A
step: 223/3290, eval_loss: 0.3402, eval_acc: 0.9120:   7%|[32m▋         [0m| 223/3290 [01:22<17:55,  2.85it/s][A[2025-02-04 03:15:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 223/3290, eval_loss: 0.3402, eval_acc: 0.9120:   7%|[32m▋         [0m| 224/3290 [01:23<17:21,  2.94it/s][A
step: 224/3290, eval_loss: 0.3395, eval_acc: 0.9122:   7%|[32m▋         [0m| 224/3290 [01:23<17:21,  2.94it/s][A[2025-02-04 03:15:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 224/3290, eval_loss: 0.3395, eval_acc: 0.9122:   7%|[32m▋         [0m| 225/3290 [01:23<16:16,  3.14it/s][A
step: 225/3290, eval_loss: 0.3391, eval_acc: 0.9123:   7%|[32m▋         [0m| 225/3290 [01:23<16:16,  3.14it/s][A[2025-02-04 03:15:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 225/3290, eval_loss: 0.3391, eval_acc: 0.9123:   7%|[32m▋         [0m| 226/3290 [01:23<15:28,  3.30it/s][A
step: 226/3290, eval_loss: 0.3420, eval_acc: 0.9114:   7%|[32m▋         [0m| 226/3290 [01:23<15:28,  3.30it/s][A[2025-02-04 03:15:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 226/3290, eval_loss: 0.3420, eval_acc: 0.9114:   7%|[32m▋         [0m| 227/3290 [01:23<15:16,  3.34it/s][A
step: 227/3290, eval_loss: 0.3414, eval_acc: 0.9114:   7%|[32m▋         [0m| 227/3290 [01:23<15:16,  3.34it/s][A[2025-02-04 03:15:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 227/3290, eval_loss: 0.3414, eval_acc: 0.9114:   7%|[32m▋         [0m| 228/3290 [01:24<14:27,  3.53it/s][A
step: 228/3290, eval_loss: 0.3408, eval_acc: 0.9115:   7%|[32m▋         [0m| 228/3290 [01:24<14:27,  3.53it/s][A[2025-02-04 03:15:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 228/3290, eval_loss: 0.3408, eval_acc: 0.9115:   7%|[32m▋         [0m| 229/3290 [01:24<16:07,  3.16it/s][A
step: 229/3290, eval_loss: 0.3412, eval_acc: 0.9114:   7%|[32m▋         [0m| 229/3290 [01:24<16:07,  3.16it/s][A[2025-02-04 03:15:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 229/3290, eval_loss: 0.3412, eval_acc: 0.9114:   7%|[32m▋         [0m| 230/3290 [01:25<18:23,  2.77it/s][A
step: 230/3290, eval_loss: 0.3407, eval_acc: 0.9114:   7%|[32m▋         [0m| 230/3290 [01:25<18:23,  2.77it/s][A[2025-02-04 03:15:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 230/3290, eval_loss: 0.3407, eval_acc: 0.9114:   7%|[32m▋         [0m| 231/3290 [01:25<17:05,  2.98it/s][A
step: 231/3290, eval_loss: 0.3402, eval_acc: 0.9114:   7%|[32m▋         [0m| 231/3290 [01:25<17:05,  2.98it/s][A[2025-02-04 03:15:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 231/3290, eval_loss: 0.3402, eval_acc: 0.9114:   7%|[32m▋         [0m| 232/3290 [01:25<18:09,  2.81it/s][A
step: 232/3290, eval_loss: 0.3401, eval_acc: 0.9112:   7%|[32m▋         [0m| 232/3290 [01:25<18:09,  2.81it/s][A[2025-02-04 03:15:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 232/3290, eval_loss: 0.3401, eval_acc: 0.9112:   7%|[32m▋         [0m| 233/3290 [01:26<19:01,  2.68it/s][A
step: 233/3290, eval_loss: 0.3396, eval_acc: 0.9114:   7%|[32m▋         [0m| 233/3290 [01:26<19:01,  2.68it/s][A[2025-02-04 03:15:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 233/3290, eval_loss: 0.3396, eval_acc: 0.9114:   7%|[32m▋         [0m| 234/3290 [01:26<19:08,  2.66it/s][A
step: 234/3290, eval_loss: 0.3387, eval_acc: 0.9116:   7%|[32m▋         [0m| 234/3290 [01:26<19:08,  2.66it/s][A[2025-02-04 03:15:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 234/3290, eval_loss: 0.3387, eval_acc: 0.9116:   7%|[32m▋         [0m| 235/3290 [01:26<19:40,  2.59it/s][A
step: 235/3290, eval_loss: 0.3377, eval_acc: 0.9118:   7%|[32m▋         [0m| 235/3290 [01:26<19:40,  2.59it/s][A[2025-02-04 03:15:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 235/3290, eval_loss: 0.3377, eval_acc: 0.9118:   7%|[32m▋         [0m| 236/3290 [01:27<19:19,  2.63it/s][A
step: 236/3290, eval_loss: 0.3371, eval_acc: 0.9120:   7%|[32m▋         [0m| 236/3290 [01:27<19:19,  2.63it/s][A[2025-02-04 03:15:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 236/3290, eval_loss: 0.3371, eval_acc: 0.9120:   7%|[32m▋         [0m| 237/3290 [01:27<17:42,  2.87it/s][A
step: 237/3290, eval_loss: 0.3369, eval_acc: 0.9121:   7%|[32m▋         [0m| 237/3290 [01:27<17:42,  2.87it/s][A[2025-02-04 03:15:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 237/3290, eval_loss: 0.3369, eval_acc: 0.9121:   7%|[32m▋         [0m| 238/3290 [01:28<19:04,  2.67it/s][A
step: 238/3290, eval_loss: 0.3380, eval_acc: 0.9118:   7%|[32m▋         [0m| 238/3290 [01:28<19:04,  2.67it/s][A[2025-02-04 03:15:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 238/3290, eval_loss: 0.3380, eval_acc: 0.9118:   7%|[32m▋         [0m| 239/3290 [01:28<18:06,  2.81it/s][A
step: 239/3290, eval_loss: 0.3385, eval_acc: 0.9118:   7%|[32m▋         [0m| 239/3290 [01:28<18:06,  2.81it/s][A[2025-02-04 03:15:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 239/3290, eval_loss: 0.3385, eval_acc: 0.9118:   7%|[32m▋         [0m| 240/3290 [01:28<17:35,  2.89it/s][A
step: 240/3290, eval_loss: 0.3391, eval_acc: 0.9117:   7%|[32m▋         [0m| 240/3290 [01:28<17:35,  2.89it/s][A[2025-02-04 03:15:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 240/3290, eval_loss: 0.3391, eval_acc: 0.9117:   7%|[32m▋         [0m| 241/3290 [01:29<18:59,  2.68it/s][A
step: 241/3290, eval_loss: 0.3404, eval_acc: 0.9114:   7%|[32m▋         [0m| 241/3290 [01:29<18:59,  2.68it/s][A[2025-02-04 03:15:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 241/3290, eval_loss: 0.3404, eval_acc: 0.9114:   7%|[32m▋         [0m| 242/3290 [01:29<18:54,  2.69it/s][A
step: 242/3290, eval_loss: 0.3394, eval_acc: 0.9116:   7%|[32m▋         [0m| 242/3290 [01:29<18:54,  2.69it/s][A[2025-02-04 03:15:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 242/3290, eval_loss: 0.3394, eval_acc: 0.9116:   7%|[32m▋         [0m| 243/3290 [01:29<17:33,  2.89it/s][A
step: 243/3290, eval_loss: 0.3393, eval_acc: 0.9117:   7%|[32m▋         [0m| 243/3290 [01:29<17:33,  2.89it/s][A[2025-02-04 03:15:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 243/3290, eval_loss: 0.3393, eval_acc: 0.9117:   7%|[32m▋         [0m| 244/3290 [01:30<18:35,  2.73it/s][A
step: 244/3290, eval_loss: 0.3395, eval_acc: 0.9116:   7%|[32m▋         [0m| 244/3290 [01:30<18:35,  2.73it/s][A[2025-02-04 03:15:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 244/3290, eval_loss: 0.3395, eval_acc: 0.9116:   7%|[32m▋         [0m| 245/3290 [01:30<19:52,  2.55it/s][A
step: 245/3290, eval_loss: 0.3408, eval_acc: 0.9114:   7%|[32m▋         [0m| 245/3290 [01:30<19:52,  2.55it/s][A[2025-02-04 03:15:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 245/3290, eval_loss: 0.3408, eval_acc: 0.9114:   7%|[32m▋         [0m| 246/3290 [01:31<20:49,  2.44it/s][A
step: 246/3290, eval_loss: 0.3401, eval_acc: 0.9116:   7%|[32m▋         [0m| 246/3290 [01:31<20:49,  2.44it/s][A[2025-02-04 03:15:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 246/3290, eval_loss: 0.3401, eval_acc: 0.9116:   8%|[32m▊         [0m| 247/3290 [01:31<21:12,  2.39it/s][A
step: 247/3290, eval_loss: 0.3400, eval_acc: 0.9116:   8%|[32m▊         [0m| 247/3290 [01:31<21:12,  2.39it/s][A[2025-02-04 03:15:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 247/3290, eval_loss: 0.3400, eval_acc: 0.9116:   8%|[32m▊         [0m| 248/3290 [01:32<21:45,  2.33it/s][A
step: 248/3290, eval_loss: 0.3395, eval_acc: 0.9117:   8%|[32m▊         [0m| 248/3290 [01:32<21:45,  2.33it/s][A[2025-02-04 03:15:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 248/3290, eval_loss: 0.3395, eval_acc: 0.9117:   8%|[32m▊         [0m| 249/3290 [01:32<20:27,  2.48it/s][A
step: 249/3290, eval_loss: 0.3403, eval_acc: 0.9113:   8%|[32m▊         [0m| 249/3290 [01:32<20:27,  2.48it/s][A[2025-02-04 03:15:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 249/3290, eval_loss: 0.3403, eval_acc: 0.9113:   8%|[32m▊         [0m| 250/3290 [01:32<20:11,  2.51it/s][A
step: 250/3290, eval_loss: 0.3397, eval_acc: 0.9115:   8%|[32m▊         [0m| 250/3290 [01:32<20:11,  2.51it/s][A[2025-02-04 03:15:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 250/3290, eval_loss: 0.3397, eval_acc: 0.9115:   8%|[32m▊         [0m| 251/3290 [01:33<19:58,  2.54it/s][A
step: 251/3290, eval_loss: 0.3388, eval_acc: 0.9118:   8%|[32m▊         [0m| 251/3290 [01:33<19:58,  2.54it/s][A[2025-02-04 03:15:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 251/3290, eval_loss: 0.3388, eval_acc: 0.9118:   8%|[32m▊         [0m| 252/3290 [01:33<18:14,  2.78it/s][A
step: 252/3290, eval_loss: 0.3384, eval_acc: 0.9119:   8%|[32m▊         [0m| 252/3290 [01:33<18:14,  2.78it/s][A[2025-02-04 03:15:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 252/3290, eval_loss: 0.3384, eval_acc: 0.9119:   8%|[32m▊         [0m| 253/3290 [01:33<18:55,  2.67it/s][A
step: 253/3290, eval_loss: 0.3383, eval_acc: 0.9121:   8%|[32m▊         [0m| 253/3290 [01:33<18:55,  2.67it/s][A[2025-02-04 03:15:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 253/3290, eval_loss: 0.3383, eval_acc: 0.9121:   8%|[32m▊         [0m| 254/3290 [01:34<18:23,  2.75it/s][A
step: 254/3290, eval_loss: 0.3386, eval_acc: 0.9119:   8%|[32m▊         [0m| 254/3290 [01:34<18:23,  2.75it/s][A[2025-02-04 03:15:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 254/3290, eval_loss: 0.3386, eval_acc: 0.9119:   8%|[32m▊         [0m| 255/3290 [01:34<19:32,  2.59it/s][A
step: 255/3290, eval_loss: 0.3382, eval_acc: 0.9121:   8%|[32m▊         [0m| 255/3290 [01:34<19:32,  2.59it/s][A[2025-02-04 03:15:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 255/3290, eval_loss: 0.3382, eval_acc: 0.9121:   8%|[32m▊         [0m| 256/3290 [01:34<19:31,  2.59it/s][A
step: 256/3290, eval_loss: 0.3370, eval_acc: 0.9124:   8%|[32m▊         [0m| 256/3290 [01:34<19:31,  2.59it/s][A[2025-02-04 03:15:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 256/3290, eval_loss: 0.3370, eval_acc: 0.9124:   8%|[32m▊         [0m| 257/3290 [01:35<18:15,  2.77it/s][A
step: 257/3290, eval_loss: 0.3364, eval_acc: 0.9126:   8%|[32m▊         [0m| 257/3290 [01:35<18:15,  2.77it/s][A[2025-02-04 03:15:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 257/3290, eval_loss: 0.3364, eval_acc: 0.9126:   8%|[32m▊         [0m| 258/3290 [01:35<17:02,  2.97it/s][A
step: 258/3290, eval_loss: 0.3366, eval_acc: 0.9125:   8%|[32m▊         [0m| 258/3290 [01:35<17:02,  2.97it/s][A[2025-02-04 03:15:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 258/3290, eval_loss: 0.3366, eval_acc: 0.9125:   8%|[32m▊         [0m| 259/3290 [01:35<17:26,  2.90it/s][A
step: 259/3290, eval_loss: 0.3365, eval_acc: 0.9126:   8%|[32m▊         [0m| 259/3290 [01:35<17:26,  2.90it/s][A[2025-02-04 03:15:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 259/3290, eval_loss: 0.3365, eval_acc: 0.9126:   8%|[32m▊         [0m| 260/3290 [01:36<17:32,  2.88it/s][A
step: 260/3290, eval_loss: 0.3356, eval_acc: 0.9128:   8%|[32m▊         [0m| 260/3290 [01:36<17:32,  2.88it/s][A[2025-02-04 03:15:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 260/3290, eval_loss: 0.3356, eval_acc: 0.9128:   8%|[32m▊         [0m| 261/3290 [01:36<17:17,  2.92it/s][A
step: 261/3290, eval_loss: 0.3351, eval_acc: 0.9129:   8%|[32m▊         [0m| 261/3290 [01:36<17:17,  2.92it/s][A[2025-02-04 03:15:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 261/3290, eval_loss: 0.3351, eval_acc: 0.9129:   8%|[32m▊         [0m| 262/3290 [01:36<17:18,  2.92it/s][A
step: 262/3290, eval_loss: 0.3347, eval_acc: 0.9130:   8%|[32m▊         [0m| 262/3290 [01:36<17:18,  2.92it/s][A[2025-02-04 03:15:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 262/3290, eval_loss: 0.3347, eval_acc: 0.9130:   8%|[32m▊         [0m| 263/3290 [01:37<17:46,  2.84it/s][A
step: 263/3290, eval_loss: 0.3336, eval_acc: 0.9133:   8%|[32m▊         [0m| 263/3290 [01:37<17:46,  2.84it/s][A[2025-02-04 03:15:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 263/3290, eval_loss: 0.3336, eval_acc: 0.9133:   8%|[32m▊         [0m| 264/3290 [01:37<18:27,  2.73it/s][A
step: 264/3290, eval_loss: 0.3345, eval_acc: 0.9129:   8%|[32m▊         [0m| 264/3290 [01:37<18:27,  2.73it/s][A[2025-02-04 03:15:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 264/3290, eval_loss: 0.3345, eval_acc: 0.9129:   8%|[32m▊         [0m| 265/3290 [01:38<17:53,  2.82it/s][A
step: 265/3290, eval_loss: 0.3357, eval_acc: 0.9127:   8%|[32m▊         [0m| 265/3290 [01:38<17:53,  2.82it/s][A[2025-02-04 03:15:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 265/3290, eval_loss: 0.3357, eval_acc: 0.9127:   8%|[32m▊         [0m| 266/3290 [01:38<16:27,  3.06it/s][A
step: 266/3290, eval_loss: 0.3392, eval_acc: 0.9121:   8%|[32m▊         [0m| 266/3290 [01:38<16:27,  3.06it/s][A[2025-02-04 03:15:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 266/3290, eval_loss: 0.3392, eval_acc: 0.9121:   8%|[32m▊         [0m| 267/3290 [01:38<17:05,  2.95it/s][A
step: 267/3290, eval_loss: 0.3416, eval_acc: 0.9112:   8%|[32m▊         [0m| 267/3290 [01:38<17:05,  2.95it/s][A[2025-02-04 03:15:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 267/3290, eval_loss: 0.3416, eval_acc: 0.9112:   8%|[32m▊         [0m| 268/3290 [01:38<16:11,  3.11it/s][A
step: 268/3290, eval_loss: 0.3443, eval_acc: 0.9103:   8%|[32m▊         [0m| 268/3290 [01:38<16:11,  3.11it/s][A[2025-02-04 03:15:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 268/3290, eval_loss: 0.3443, eval_acc: 0.9103:   8%|[32m▊         [0m| 269/3290 [01:39<16:02,  3.14it/s][A
step: 269/3290, eval_loss: 0.3452, eval_acc: 0.9101:   8%|[32m▊         [0m| 269/3290 [01:39<16:02,  3.14it/s][A[2025-02-04 03:15:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 269/3290, eval_loss: 0.3452, eval_acc: 0.9101:   8%|[32m▊         [0m| 270/3290 [01:39<16:07,  3.12it/s][A
step: 270/3290, eval_loss: 0.3454, eval_acc: 0.9100:   8%|[32m▊         [0m| 270/3290 [01:39<16:07,  3.12it/s][A[2025-02-04 03:15:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 270/3290, eval_loss: 0.3454, eval_acc: 0.9100:   8%|[32m▊         [0m| 271/3290 [01:39<17:12,  2.92it/s][A
step: 271/3290, eval_loss: 0.3462, eval_acc: 0.9097:   8%|[32m▊         [0m| 271/3290 [01:39<17:12,  2.92it/s][A[2025-02-04 03:15:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 271/3290, eval_loss: 0.3462, eval_acc: 0.9097:   8%|[32m▊         [0m| 272/3290 [01:40<16:34,  3.03it/s][A
step: 272/3290, eval_loss: 0.3477, eval_acc: 0.9093:   8%|[32m▊         [0m| 272/3290 [01:40<16:34,  3.03it/s][A[2025-02-04 03:15:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 272/3290, eval_loss: 0.3477, eval_acc: 0.9093:   8%|[32m▊         [0m| 273/3290 [01:40<16:47,  3.00it/s][A
step: 273/3290, eval_loss: 0.3509, eval_acc: 0.9085:   8%|[32m▊         [0m| 273/3290 [01:40<16:47,  3.00it/s][A[2025-02-04 03:15:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 273/3290, eval_loss: 0.3509, eval_acc: 0.9085:   8%|[32m▊         [0m| 274/3290 [01:40<15:38,  3.21it/s][A
step: 274/3290, eval_loss: 0.3524, eval_acc: 0.9078:   8%|[32m▊         [0m| 274/3290 [01:40<15:38,  3.21it/s][A[2025-02-04 03:15:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 274/3290, eval_loss: 0.3524, eval_acc: 0.9078:   8%|[32m▊         [0m| 275/3290 [01:41<14:49,  3.39it/s][A
step: 275/3290, eval_loss: 0.3544, eval_acc: 0.9072:   8%|[32m▊         [0m| 275/3290 [01:41<14:49,  3.39it/s][A[2025-02-04 03:15:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 275/3290, eval_loss: 0.3544, eval_acc: 0.9072:   8%|[32m▊         [0m| 276/3290 [01:41<16:53,  2.97it/s][A
step: 276/3290, eval_loss: 0.3555, eval_acc: 0.9069:   8%|[32m▊         [0m| 276/3290 [01:41<16:53,  2.97it/s][A[2025-02-04 03:15:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 276/3290, eval_loss: 0.3555, eval_acc: 0.9069:   8%|[32m▊         [0m| 277/3290 [01:41<16:58,  2.96it/s][A
step: 277/3290, eval_loss: 0.3576, eval_acc: 0.9063:   8%|[32m▊         [0m| 277/3290 [01:41<16:58,  2.96it/s][A[2025-02-04 03:15:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 277/3290, eval_loss: 0.3576, eval_acc: 0.9063:   8%|[32m▊         [0m| 278/3290 [01:42<16:27,  3.05it/s][A
step: 278/3290, eval_loss: 0.3576, eval_acc: 0.9061:   8%|[32m▊         [0m| 278/3290 [01:42<16:27,  3.05it/s][A[2025-02-04 03:15:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 278/3290, eval_loss: 0.3576, eval_acc: 0.9061:   8%|[32m▊         [0m| 279/3290 [01:42<15:51,  3.16it/s][A
step: 279/3290, eval_loss: 0.3583, eval_acc: 0.9059:   8%|[32m▊         [0m| 279/3290 [01:42<15:51,  3.16it/s][A[2025-02-04 03:15:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 279/3290, eval_loss: 0.3583, eval_acc: 0.9059:   9%|[32m▊         [0m| 280/3290 [01:42<17:50,  2.81it/s][A
step: 280/3290, eval_loss: 0.3597, eval_acc: 0.9056:   9%|[32m▊         [0m| 280/3290 [01:42<17:50,  2.81it/s][A[2025-02-04 03:15:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 280/3290, eval_loss: 0.3597, eval_acc: 0.9056:   9%|[32m▊         [0m| 281/3290 [01:43<19:05,  2.63it/s][A
step: 281/3290, eval_loss: 0.3616, eval_acc: 0.9050:   9%|[32m▊         [0m| 281/3290 [01:43<19:05,  2.63it/s][A[2025-02-04 03:15:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 281/3290, eval_loss: 0.3616, eval_acc: 0.9050:   9%|[32m▊         [0m| 282/3290 [01:43<18:08,  2.76it/s][A
step: 282/3290, eval_loss: 0.3623, eval_acc: 0.9048:   9%|[32m▊         [0m| 282/3290 [01:43<18:08,  2.76it/s][A[2025-02-04 03:15:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 282/3290, eval_loss: 0.3623, eval_acc: 0.9048:   9%|[32m▊         [0m| 283/3290 [01:44<19:32,  2.57it/s][A
step: 283/3290, eval_loss: 0.3649, eval_acc: 0.9042:   9%|[32m▊         [0m| 283/3290 [01:44<19:32,  2.57it/s][A[2025-02-04 03:15:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 283/3290, eval_loss: 0.3649, eval_acc: 0.9042:   9%|[32m▊         [0m| 284/3290 [01:44<19:29,  2.57it/s][A
step: 284/3290, eval_loss: 0.3659, eval_acc: 0.9039:   9%|[32m▊         [0m| 284/3290 [01:44<19:29,  2.57it/s][A[2025-02-04 03:15:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 284/3290, eval_loss: 0.3659, eval_acc: 0.9039:   9%|[32m▊         [0m| 285/3290 [01:44<17:54,  2.80it/s][A
step: 285/3290, eval_loss: 0.3675, eval_acc: 0.9036:   9%|[32m▊         [0m| 285/3290 [01:44<17:54,  2.80it/s][A[2025-02-04 03:15:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 285/3290, eval_loss: 0.3675, eval_acc: 0.9036:   9%|[32m▊         [0m| 286/3290 [01:45<18:07,  2.76it/s][A
step: 286/3290, eval_loss: 0.3692, eval_acc: 0.9032:   9%|[32m▊         [0m| 286/3290 [01:45<18:07,  2.76it/s][A[2025-02-04 03:15:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 286/3290, eval_loss: 0.3692, eval_acc: 0.9032:   9%|[32m▊         [0m| 287/3290 [01:45<16:59,  2.95it/s][A
step: 287/3290, eval_loss: 0.3697, eval_acc: 0.9031:   9%|[32m▊         [0m| 287/3290 [01:45<16:59,  2.95it/s][A[2025-02-04 03:15:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 287/3290, eval_loss: 0.3697, eval_acc: 0.9031:   9%|[32m▉         [0m| 288/3290 [01:45<18:42,  2.67it/s][A
step: 288/3290, eval_loss: 0.3733, eval_acc: 0.9019:   9%|[32m▉         [0m| 288/3290 [01:45<18:42,  2.67it/s][A[2025-02-04 03:15:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 288/3290, eval_loss: 0.3733, eval_acc: 0.9019:   9%|[32m▉         [0m| 289/3290 [01:46<17:40,  2.83it/s][A
step: 289/3290, eval_loss: 0.3737, eval_acc: 0.9018:   9%|[32m▉         [0m| 289/3290 [01:46<17:40,  2.83it/s][A[2025-02-04 03:15:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 289/3290, eval_loss: 0.3737, eval_acc: 0.9018:   9%|[32m▉         [0m| 290/3290 [01:46<16:37,  3.01it/s][A
step: 290/3290, eval_loss: 0.3756, eval_acc: 0.9014:   9%|[32m▉         [0m| 290/3290 [01:46<16:37,  3.01it/s][A[2025-02-04 03:15:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 290/3290, eval_loss: 0.3756, eval_acc: 0.9014:   9%|[32m▉         [0m| 291/3290 [01:46<16:30,  3.03it/s][A
step: 291/3290, eval_loss: 0.3780, eval_acc: 0.9006:   9%|[32m▉         [0m| 291/3290 [01:46<16:30,  3.03it/s][A[2025-02-04 03:15:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 291/3290, eval_loss: 0.3780, eval_acc: 0.9006:   9%|[32m▉         [0m| 292/3290 [01:47<17:46,  2.81it/s][A
step: 292/3290, eval_loss: 0.3776, eval_acc: 0.9007:   9%|[32m▉         [0m| 292/3290 [01:47<17:46,  2.81it/s][A[2025-02-04 03:15:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 292/3290, eval_loss: 0.3776, eval_acc: 0.9007:   9%|[32m▉         [0m| 293/3290 [01:47<17:21,  2.88it/s][A
step: 293/3290, eval_loss: 0.3776, eval_acc: 0.9006:   9%|[32m▉         [0m| 293/3290 [01:47<17:21,  2.88it/s][A[2025-02-04 03:15:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 293/3290, eval_loss: 0.3776, eval_acc: 0.9006:   9%|[32m▉         [0m| 294/3290 [01:48<18:23,  2.71it/s][A
step: 294/3290, eval_loss: 0.3776, eval_acc: 0.9006:   9%|[32m▉         [0m| 294/3290 [01:48<18:23,  2.71it/s][A[2025-02-04 03:15:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 294/3290, eval_loss: 0.3776, eval_acc: 0.9006:   9%|[32m▉         [0m| 295/3290 [01:48<20:39,  2.42it/s][A
step: 295/3290, eval_loss: 0.3809, eval_acc: 0.8996:   9%|[32m▉         [0m| 295/3290 [01:48<20:39,  2.42it/s][A[2025-02-04 03:15:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 295/3290, eval_loss: 0.3809, eval_acc: 0.8996:   9%|[32m▉         [0m| 296/3290 [01:49<21:34,  2.31it/s][A
step: 296/3290, eval_loss: 0.3829, eval_acc: 0.8989:   9%|[32m▉         [0m| 296/3290 [01:49<21:34,  2.31it/s][A[2025-02-04 03:15:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 296/3290, eval_loss: 0.3829, eval_acc: 0.8989:   9%|[32m▉         [0m| 297/3290 [01:49<20:25,  2.44it/s][A
step: 297/3290, eval_loss: 0.3850, eval_acc: 0.8983:   9%|[32m▉         [0m| 297/3290 [01:49<20:25,  2.44it/s][A[2025-02-04 03:15:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 297/3290, eval_loss: 0.3850, eval_acc: 0.8983:   9%|[32m▉         [0m| 298/3290 [01:49<21:34,  2.31it/s][A
step: 298/3290, eval_loss: 0.3867, eval_acc: 0.8981:   9%|[32m▉         [0m| 298/3290 [01:49<21:34,  2.31it/s][A[2025-02-04 03:15:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 298/3290, eval_loss: 0.3867, eval_acc: 0.8981:   9%|[32m▉         [0m| 299/3290 [01:50<20:20,  2.45it/s][A
step: 299/3290, eval_loss: 0.3870, eval_acc: 0.8976:   9%|[32m▉         [0m| 299/3290 [01:50<20:20,  2.45it/s][A[2025-02-04 03:15:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 299/3290, eval_loss: 0.3870, eval_acc: 0.8976:   9%|[32m▉         [0m| 300/3290 [01:50<19:30,  2.56it/s][A
step: 300/3290, eval_loss: 0.3877, eval_acc: 0.8973:   9%|[32m▉         [0m| 300/3290 [01:50<19:30,  2.56it/s][A[2025-02-04 03:15:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 300/3290, eval_loss: 0.3877, eval_acc: 0.8973:   9%|[32m▉         [0m| 301/3290 [01:50<18:37,  2.68it/s][A
step: 301/3290, eval_loss: 0.3884, eval_acc: 0.8972:   9%|[32m▉         [0m| 301/3290 [01:50<18:37,  2.68it/s][A[2025-02-04 03:15:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 301/3290, eval_loss: 0.3884, eval_acc: 0.8972:   9%|[32m▉         [0m| 302/3290 [01:51<18:32,  2.69it/s][A
step: 302/3290, eval_loss: 0.3891, eval_acc: 0.8970:   9%|[32m▉         [0m| 302/3290 [01:51<18:32,  2.69it/s][A[2025-02-04 03:15:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 302/3290, eval_loss: 0.3891, eval_acc: 0.8970:   9%|[32m▉         [0m| 303/3290 [01:51<17:23,  2.86it/s][A
step: 303/3290, eval_loss: 0.3901, eval_acc: 0.8968:   9%|[32m▉         [0m| 303/3290 [01:51<17:23,  2.86it/s][A[2025-02-04 03:15:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 303/3290, eval_loss: 0.3901, eval_acc: 0.8968:   9%|[32m▉         [0m| 304/3290 [01:52<18:57,  2.63it/s][A
step: 304/3290, eval_loss: 0.3917, eval_acc: 0.8963:   9%|[32m▉         [0m| 304/3290 [01:52<18:57,  2.63it/s][A[2025-02-04 03:15:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 304/3290, eval_loss: 0.3917, eval_acc: 0.8963:   9%|[32m▉         [0m| 305/3290 [01:52<17:46,  2.80it/s][A
step: 305/3290, eval_loss: 0.3941, eval_acc: 0.8954:   9%|[32m▉         [0m| 305/3290 [01:52<17:46,  2.80it/s][A[2025-02-04 03:15:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 305/3290, eval_loss: 0.3941, eval_acc: 0.8954:   9%|[32m▉         [0m| 306/3290 [01:52<16:32,  3.01it/s][A
step: 306/3290, eval_loss: 0.3958, eval_acc: 0.8951:   9%|[32m▉         [0m| 306/3290 [01:52<16:32,  3.01it/s][A[2025-02-04 03:15:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 306/3290, eval_loss: 0.3958, eval_acc: 0.8951:   9%|[32m▉         [0m| 307/3290 [01:52<15:06,  3.29it/s][A
step: 307/3290, eval_loss: 0.3968, eval_acc: 0.8949:   9%|[32m▉         [0m| 307/3290 [01:52<15:06,  3.29it/s][A[2025-02-04 03:15:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 307/3290, eval_loss: 0.3968, eval_acc: 0.8949:   9%|[32m▉         [0m| 308/3290 [01:53<14:58,  3.32it/s][A
step: 308/3290, eval_loss: 0.3986, eval_acc: 0.8945:   9%|[32m▉         [0m| 308/3290 [01:53<14:58,  3.32it/s][A[2025-02-04 03:15:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 308/3290, eval_loss: 0.3986, eval_acc: 0.8945:   9%|[32m▉         [0m| 309/3290 [01:53<16:22,  3.03it/s][A
step: 309/3290, eval_loss: 0.3998, eval_acc: 0.8942:   9%|[32m▉         [0m| 309/3290 [01:53<16:22,  3.03it/s][A[2025-02-04 03:15:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 309/3290, eval_loss: 0.3998, eval_acc: 0.8942:   9%|[32m▉         [0m| 310/3290 [01:53<16:33,  3.00it/s][A
step: 310/3290, eval_loss: 0.4017, eval_acc: 0.8940:   9%|[32m▉         [0m| 310/3290 [01:53<16:33,  3.00it/s][A[2025-02-04 03:15:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 310/3290, eval_loss: 0.4017, eval_acc: 0.8940:   9%|[32m▉         [0m| 311/3290 [01:54<16:27,  3.02it/s][A
step: 311/3290, eval_loss: 0.4021, eval_acc: 0.8938:   9%|[32m▉         [0m| 311/3290 [01:54<16:27,  3.02it/s][A[2025-02-04 03:15:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 311/3290, eval_loss: 0.4021, eval_acc: 0.8938:   9%|[32m▉         [0m| 312/3290 [01:54<17:38,  2.81it/s][A
step: 312/3290, eval_loss: 0.4043, eval_acc: 0.8934:   9%|[32m▉         [0m| 312/3290 [01:54<17:38,  2.81it/s][A[2025-02-04 03:15:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 312/3290, eval_loss: 0.4043, eval_acc: 0.8934:  10%|[32m▉         [0m| 313/3290 [01:54<17:23,  2.85it/s][A
step: 313/3290, eval_loss: 0.4054, eval_acc: 0.8931:  10%|[32m▉         [0m| 313/3290 [01:54<17:23,  2.85it/s][A[2025-02-04 03:15:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 313/3290, eval_loss: 0.4054, eval_acc: 0.8931:  10%|[32m▉         [0m| 314/3290 [01:55<16:55,  2.93it/s][A
step: 314/3290, eval_loss: 0.4060, eval_acc: 0.8929:  10%|[32m▉         [0m| 314/3290 [01:55<16:55,  2.93it/s][A[2025-02-04 03:15:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 314/3290, eval_loss: 0.4060, eval_acc: 0.8929:  10%|[32m▉         [0m| 315/3290 [01:55<16:03,  3.09it/s][A
step: 315/3290, eval_loss: 0.4065, eval_acc: 0.8926:  10%|[32m▉         [0m| 315/3290 [01:55<16:03,  3.09it/s][A[2025-02-04 03:15:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 315/3290, eval_loss: 0.4065, eval_acc: 0.8926:  10%|[32m▉         [0m| 316/3290 [01:55<14:53,  3.33it/s][A
step: 316/3290, eval_loss: 0.4092, eval_acc: 0.8918:  10%|[32m▉         [0m| 316/3290 [01:55<14:53,  3.33it/s][A[2025-02-04 03:15:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 316/3290, eval_loss: 0.4092, eval_acc: 0.8918:  10%|[32m▉         [0m| 317/3290 [01:56<14:42,  3.37it/s][A
step: 317/3290, eval_loss: 0.4102, eval_acc: 0.8913:  10%|[32m▉         [0m| 317/3290 [01:56<14:42,  3.37it/s][A[2025-02-04 03:15:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 317/3290, eval_loss: 0.4102, eval_acc: 0.8913:  10%|[32m▉         [0m| 318/3290 [01:56<14:41,  3.37it/s][A
step: 318/3290, eval_loss: 0.4127, eval_acc: 0.8903:  10%|[32m▉         [0m| 318/3290 [01:56<14:41,  3.37it/s][A[2025-02-04 03:15:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 318/3290, eval_loss: 0.4127, eval_acc: 0.8903:  10%|[32m▉         [0m| 319/3290 [01:56<14:33,  3.40it/s][A
step: 319/3290, eval_loss: 0.4146, eval_acc: 0.8897:  10%|[32m▉         [0m| 319/3290 [01:56<14:33,  3.40it/s][A[2025-02-04 03:15:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 319/3290, eval_loss: 0.4146, eval_acc: 0.8897:  10%|[32m▉         [0m| 320/3290 [01:56<13:51,  3.57it/s][A
step: 320/3290, eval_loss: 0.4171, eval_acc: 0.8890:  10%|[32m▉         [0m| 320/3290 [01:56<13:51,  3.57it/s][A[2025-02-04 03:15:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 320/3290, eval_loss: 0.4171, eval_acc: 0.8890:  10%|[32m▉         [0m| 321/3290 [01:57<13:46,  3.59it/s][A
step: 321/3290, eval_loss: 0.4193, eval_acc: 0.8886:  10%|[32m▉         [0m| 321/3290 [01:57<13:46,  3.59it/s][A[2025-02-04 03:15:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 321/3290, eval_loss: 0.4193, eval_acc: 0.8886:  10%|[32m▉         [0m| 322/3290 [01:57<13:30,  3.66it/s][A
step: 322/3290, eval_loss: 0.4194, eval_acc: 0.8886:  10%|[32m▉         [0m| 322/3290 [01:57<13:30,  3.66it/s][A[2025-02-04 03:15:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 322/3290, eval_loss: 0.4194, eval_acc: 0.8886:  10%|[32m▉         [0m| 323/3290 [01:57<13:34,  3.64it/s][A
step: 323/3290, eval_loss: 0.4197, eval_acc: 0.8883:  10%|[32m▉         [0m| 323/3290 [01:57<13:34,  3.64it/s][A[2025-02-04 03:15:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 323/3290, eval_loss: 0.4197, eval_acc: 0.8883:  10%|[32m▉         [0m| 324/3290 [01:58<13:40,  3.62it/s][A
step: 324/3290, eval_loss: 0.4206, eval_acc: 0.8877:  10%|[32m▉         [0m| 324/3290 [01:58<13:40,  3.62it/s][A[2025-02-04 03:15:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 324/3290, eval_loss: 0.4206, eval_acc: 0.8877:  10%|[32m▉         [0m| 325/3290 [01:58<15:05,  3.27it/s][A
step: 325/3290, eval_loss: 0.4216, eval_acc: 0.8872:  10%|[32m▉         [0m| 325/3290 [01:58<15:05,  3.27it/s][A[2025-02-04 03:15:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 325/3290, eval_loss: 0.4216, eval_acc: 0.8872:  10%|[32m▉         [0m| 326/3290 [01:58<16:58,  2.91it/s][A
step: 326/3290, eval_loss: 0.4222, eval_acc: 0.8868:  10%|[32m▉         [0m| 326/3290 [01:58<16:58,  2.91it/s][A[2025-02-04 03:15:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 326/3290, eval_loss: 0.4222, eval_acc: 0.8868:  10%|[32m▉         [0m| 327/3290 [01:59<16:53,  2.92it/s][A
step: 327/3290, eval_loss: 0.4235, eval_acc: 0.8864:  10%|[32m▉         [0m| 327/3290 [01:59<16:53,  2.92it/s][A[2025-02-04 03:15:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 327/3290, eval_loss: 0.4235, eval_acc: 0.8864:  10%|[32m▉         [0m| 328/3290 [01:59<18:52,  2.61it/s][A
step: 328/3290, eval_loss: 0.4299, eval_acc: 0.8855:  10%|[32m▉         [0m| 328/3290 [01:59<18:52,  2.61it/s][A[2025-02-04 03:15:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 328/3290, eval_loss: 0.4299, eval_acc: 0.8855:  10%|[32m█         [0m| 329/3290 [01:59<17:25,  2.83it/s][A
step: 329/3290, eval_loss: 0.4316, eval_acc: 0.8852:  10%|[32m█         [0m| 329/3290 [01:59<17:25,  2.83it/s][A[2025-02-04 03:15:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 329/3290, eval_loss: 0.4316, eval_acc: 0.8852:  10%|[32m█         [0m| 330/3290 [02:00<16:37,  2.97it/s][A
step: 330/3290, eval_loss: 0.4351, eval_acc: 0.8843:  10%|[32m█         [0m| 330/3290 [02:00<16:37,  2.97it/s][A[2025-02-04 03:15:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 330/3290, eval_loss: 0.4351, eval_acc: 0.8843:  10%|[32m█         [0m| 331/3290 [02:00<16:20,  3.02it/s][A
step: 331/3290, eval_loss: 0.4359, eval_acc: 0.8843:  10%|[32m█         [0m| 331/3290 [02:00<16:20,  3.02it/s][A[2025-02-04 03:15:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 331/3290, eval_loss: 0.4359, eval_acc: 0.8843:  10%|[32m█         [0m| 332/3290 [02:00<15:58,  3.09it/s][A
step: 332/3290, eval_loss: 0.4396, eval_acc: 0.8834:  10%|[32m█         [0m| 332/3290 [02:00<15:58,  3.09it/s][A[2025-02-04 03:15:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 332/3290, eval_loss: 0.4396, eval_acc: 0.8834:  10%|[32m█         [0m| 333/3290 [02:01<15:40,  3.15it/s][A
step: 333/3290, eval_loss: 0.4412, eval_acc: 0.8827:  10%|[32m█         [0m| 333/3290 [02:01<15:40,  3.15it/s][A[2025-02-04 03:15:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 333/3290, eval_loss: 0.4412, eval_acc: 0.8827:  10%|[32m█         [0m| 334/3290 [02:01<14:42,  3.35it/s][A
step: 334/3290, eval_loss: 0.4415, eval_acc: 0.8825:  10%|[32m█         [0m| 334/3290 [02:01<14:42,  3.35it/s][A[2025-02-04 03:15:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 334/3290, eval_loss: 0.4415, eval_acc: 0.8825:  10%|[32m█         [0m| 335/3290 [02:01<14:27,  3.41it/s][A
step: 335/3290, eval_loss: 0.4436, eval_acc: 0.8818:  10%|[32m█         [0m| 335/3290 [02:01<14:27,  3.41it/s][A[2025-02-04 03:15:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 335/3290, eval_loss: 0.4436, eval_acc: 0.8818:  10%|[32m█         [0m| 336/3290 [02:02<14:57,  3.29it/s][A
step: 336/3290, eval_loss: 0.4456, eval_acc: 0.8815:  10%|[32m█         [0m| 336/3290 [02:02<14:57,  3.29it/s][A[2025-02-04 03:15:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 336/3290, eval_loss: 0.4456, eval_acc: 0.8815:  10%|[32m█         [0m| 337/3290 [02:02<17:07,  2.87it/s][A
step: 337/3290, eval_loss: 0.4469, eval_acc: 0.8812:  10%|[32m█         [0m| 337/3290 [02:02<17:07,  2.87it/s][A[2025-02-04 03:15:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 337/3290, eval_loss: 0.4469, eval_acc: 0.8812:  10%|[32m█         [0m| 338/3290 [02:02<16:46,  2.93it/s][A
step: 338/3290, eval_loss: 0.4474, eval_acc: 0.8811:  10%|[32m█         [0m| 338/3290 [02:02<16:46,  2.93it/s][A[2025-02-04 03:15:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 338/3290, eval_loss: 0.4474, eval_acc: 0.8811:  10%|[32m█         [0m| 339/3290 [02:03<15:56,  3.08it/s][A
step: 339/3290, eval_loss: 0.4499, eval_acc: 0.8806:  10%|[32m█         [0m| 339/3290 [02:03<15:56,  3.08it/s][A[2025-02-04 03:15:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 339/3290, eval_loss: 0.4499, eval_acc: 0.8806:  10%|[32m█         [0m| 340/3290 [02:03<15:07,  3.25it/s][A
step: 340/3290, eval_loss: 0.4506, eval_acc: 0.8804:  10%|[32m█         [0m| 340/3290 [02:03<15:07,  3.25it/s][A[2025-02-04 03:15:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 340/3290, eval_loss: 0.4506, eval_acc: 0.8804:  10%|[32m█         [0m| 341/3290 [02:03<16:03,  3.06it/s][A
step: 341/3290, eval_loss: 0.4512, eval_acc: 0.8802:  10%|[32m█         [0m| 341/3290 [02:03<16:03,  3.06it/s][A[2025-02-04 03:15:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 341/3290, eval_loss: 0.4512, eval_acc: 0.8802:  10%|[32m█         [0m| 342/3290 [02:03<15:26,  3.18it/s][A
step: 342/3290, eval_loss: 0.4527, eval_acc: 0.8797:  10%|[32m█         [0m| 342/3290 [02:03<15:26,  3.18it/s][A[2025-02-04 03:15:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 342/3290, eval_loss: 0.4527, eval_acc: 0.8797:  10%|[32m█         [0m| 343/3290 [02:04<14:29,  3.39it/s][A
step: 343/3290, eval_loss: 0.4545, eval_acc: 0.8794:  10%|[32m█         [0m| 343/3290 [02:04<14:29,  3.39it/s][A[2025-02-04 03:15:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 343/3290, eval_loss: 0.4545, eval_acc: 0.8794:  10%|[32m█         [0m| 344/3290 [02:04<13:51,  3.54it/s][A
step: 344/3290, eval_loss: 0.4557, eval_acc: 0.8791:  10%|[32m█         [0m| 344/3290 [02:04<13:51,  3.54it/s][A[2025-02-04 03:15:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 344/3290, eval_loss: 0.4557, eval_acc: 0.8791:  10%|[32m█         [0m| 345/3290 [02:04<14:28,  3.39it/s][A
step: 345/3290, eval_loss: 0.4574, eval_acc: 0.8787:  10%|[32m█         [0m| 345/3290 [02:04<14:28,  3.39it/s][A[2025-02-04 03:15:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 345/3290, eval_loss: 0.4574, eval_acc: 0.8787:  11%|[32m█         [0m| 346/3290 [02:05<15:29,  3.17it/s][A
step: 346/3290, eval_loss: 0.4579, eval_acc: 0.8784:  11%|[32m█         [0m| 346/3290 [02:05<15:29,  3.17it/s][A[2025-02-04 03:15:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 346/3290, eval_loss: 0.4579, eval_acc: 0.8784:  11%|[32m█         [0m| 347/3290 [02:05<17:50,  2.75it/s][A
step: 347/3290, eval_loss: 0.4597, eval_acc: 0.8779:  11%|[32m█         [0m| 347/3290 [02:05<17:50,  2.75it/s][A[2025-02-04 03:15:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 347/3290, eval_loss: 0.4597, eval_acc: 0.8779:  11%|[32m█         [0m| 348/3290 [02:05<17:27,  2.81it/s][A
step: 348/3290, eval_loss: 0.4602, eval_acc: 0.8778:  11%|[32m█         [0m| 348/3290 [02:05<17:27,  2.81it/s][A[2025-02-04 03:16:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 348/3290, eval_loss: 0.4602, eval_acc: 0.8778:  11%|[32m█         [0m| 349/3290 [02:06<17:32,  2.80it/s][A
step: 349/3290, eval_loss: 0.4613, eval_acc: 0.8777:  11%|[32m█         [0m| 349/3290 [02:06<17:32,  2.80it/s][A[2025-02-04 03:16:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 349/3290, eval_loss: 0.4613, eval_acc: 0.8777:  11%|[32m█         [0m| 350/3290 [02:06<17:36,  2.78it/s][A
step: 350/3290, eval_loss: 0.4638, eval_acc: 0.8768:  11%|[32m█         [0m| 350/3290 [02:06<17:36,  2.78it/s][A[2025-02-04 03:16:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 350/3290, eval_loss: 0.4638, eval_acc: 0.8768:  11%|[32m█         [0m| 351/3290 [02:07<17:25,  2.81it/s][A
step: 351/3290, eval_loss: 0.4644, eval_acc: 0.8766:  11%|[32m█         [0m| 351/3290 [02:07<17:25,  2.81it/s][A[2025-02-04 03:16:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 351/3290, eval_loss: 0.4644, eval_acc: 0.8766:  11%|[32m█         [0m| 352/3290 [02:07<18:03,  2.71it/s][A
step: 352/3290, eval_loss: 0.4669, eval_acc: 0.8758:  11%|[32m█         [0m| 352/3290 [02:07<18:03,  2.71it/s][A[2025-02-04 03:16:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 352/3290, eval_loss: 0.4669, eval_acc: 0.8758:  11%|[32m█         [0m| 353/3290 [02:07<17:42,  2.76it/s][A
step: 353/3290, eval_loss: 0.4682, eval_acc: 0.8752:  11%|[32m█         [0m| 353/3290 [02:07<17:42,  2.76it/s][A[2025-02-04 03:16:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 353/3290, eval_loss: 0.4682, eval_acc: 0.8752:  11%|[32m█         [0m| 354/3290 [02:08<17:46,  2.75it/s][A
step: 354/3290, eval_loss: 0.4688, eval_acc: 0.8751:  11%|[32m█         [0m| 354/3290 [02:08<17:46,  2.75it/s][A[2025-02-04 03:16:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 354/3290, eval_loss: 0.4688, eval_acc: 0.8751:  11%|[32m█         [0m| 355/3290 [02:08<17:37,  2.78it/s][A
step: 355/3290, eval_loss: 0.4693, eval_acc: 0.8749:  11%|[32m█         [0m| 355/3290 [02:08<17:37,  2.78it/s][A[2025-02-04 03:16:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 355/3290, eval_loss: 0.4693, eval_acc: 0.8749:  11%|[32m█         [0m| 356/3290 [02:08<17:52,  2.73it/s][A
step: 356/3290, eval_loss: 0.4695, eval_acc: 0.8748:  11%|[32m█         [0m| 356/3290 [02:08<17:52,  2.73it/s][A[2025-02-04 03:16:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 356/3290, eval_loss: 0.4695, eval_acc: 0.8748:  11%|[32m█         [0m| 357/3290 [02:09<16:31,  2.96it/s][A
step: 357/3290, eval_loss: 0.4707, eval_acc: 0.8743:  11%|[32m█         [0m| 357/3290 [02:09<16:31,  2.96it/s][A[2025-02-04 03:16:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 357/3290, eval_loss: 0.4707, eval_acc: 0.8743:  11%|[32m█         [0m| 358/3290 [02:09<17:08,  2.85it/s][A
step: 358/3290, eval_loss: 0.4719, eval_acc: 0.8739:  11%|[32m█         [0m| 358/3290 [02:09<17:08,  2.85it/s][A[2025-02-04 03:16:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 358/3290, eval_loss: 0.4719, eval_acc: 0.8739:  11%|[32m█         [0m| 359/3290 [02:09<17:12,  2.84it/s][A
step: 359/3290, eval_loss: 0.4725, eval_acc: 0.8737:  11%|[32m█         [0m| 359/3290 [02:09<17:12,  2.84it/s][A[2025-02-04 03:16:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 359/3290, eval_loss: 0.4725, eval_acc: 0.8737:  11%|[32m█         [0m| 360/3290 [02:10<16:03,  3.04it/s][A
step: 360/3290, eval_loss: 0.4730, eval_acc: 0.8735:  11%|[32m█         [0m| 360/3290 [02:10<16:03,  3.04it/s][A[2025-02-04 03:16:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 360/3290, eval_loss: 0.4730, eval_acc: 0.8735:  11%|[32m█         [0m| 361/3290 [02:10<16:24,  2.97it/s][A
step: 361/3290, eval_loss: 0.4740, eval_acc: 0.8732:  11%|[32m█         [0m| 361/3290 [02:10<16:24,  2.97it/s][A[2025-02-04 03:16:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 361/3290, eval_loss: 0.4740, eval_acc: 0.8732:  11%|[32m█         [0m| 362/3290 [02:10<17:18,  2.82it/s][A
step: 362/3290, eval_loss: 0.4749, eval_acc: 0.8729:  11%|[32m█         [0m| 362/3290 [02:10<17:18,  2.82it/s][A[2025-02-04 03:16:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 362/3290, eval_loss: 0.4749, eval_acc: 0.8729:  11%|[32m█         [0m| 363/3290 [02:11<17:28,  2.79it/s][A
step: 363/3290, eval_loss: 0.4755, eval_acc: 0.8725:  11%|[32m█         [0m| 363/3290 [02:11<17:28,  2.79it/s][A[2025-02-04 03:16:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 363/3290, eval_loss: 0.4755, eval_acc: 0.8725:  11%|[32m█         [0m| 364/3290 [02:11<18:40,  2.61it/s][A
step: 364/3290, eval_loss: 0.4763, eval_acc: 0.8723:  11%|[32m█         [0m| 364/3290 [02:11<18:40,  2.61it/s][A[2025-02-04 03:16:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 364/3290, eval_loss: 0.4763, eval_acc: 0.8723:  11%|[32m█         [0m| 365/3290 [02:12<18:53,  2.58it/s][A
step: 365/3290, eval_loss: 0.4770, eval_acc: 0.8721:  11%|[32m█         [0m| 365/3290 [02:12<18:53,  2.58it/s][A[2025-02-04 03:16:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 365/3290, eval_loss: 0.4770, eval_acc: 0.8721:  11%|[32m█         [0m| 366/3290 [02:12<18:10,  2.68it/s][A
step: 366/3290, eval_loss: 0.4788, eval_acc: 0.8717:  11%|[32m█         [0m| 366/3290 [02:12<18:10,  2.68it/s][A[2025-02-04 03:16:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 366/3290, eval_loss: 0.4788, eval_acc: 0.8717:  11%|[32m█         [0m| 367/3290 [02:12<16:43,  2.91it/s][A
step: 367/3290, eval_loss: 0.4798, eval_acc: 0.8714:  11%|[32m█         [0m| 367/3290 [02:12<16:43,  2.91it/s][A[2025-02-04 03:16:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 367/3290, eval_loss: 0.4798, eval_acc: 0.8714:  11%|[32m█         [0m| 368/3290 [02:13<19:03,  2.55it/s][A
step: 368/3290, eval_loss: 0.4804, eval_acc: 0.8711:  11%|[32m█         [0m| 368/3290 [02:13<19:03,  2.55it/s][A[2025-02-04 03:16:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 368/3290, eval_loss: 0.4804, eval_acc: 0.8711:  11%|[32m█         [0m| 369/3290 [02:13<19:19,  2.52it/s][A
step: 369/3290, eval_loss: 0.4810, eval_acc: 0.8709:  11%|[32m█         [0m| 369/3290 [02:13<19:19,  2.52it/s][A[2025-02-04 03:16:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 369/3290, eval_loss: 0.4810, eval_acc: 0.8709:  11%|[32m█         [0m| 370/3290 [02:14<20:05,  2.42it/s][A
step: 370/3290, eval_loss: 0.4815, eval_acc: 0.8708:  11%|[32m█         [0m| 370/3290 [02:14<20:05,  2.42it/s][A[2025-02-04 03:16:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 370/3290, eval_loss: 0.4815, eval_acc: 0.8708:  11%|[32m█▏        [0m| 371/3290 [02:14<19:25,  2.50it/s][A
step: 371/3290, eval_loss: 0.4827, eval_acc: 0.8705:  11%|[32m█▏        [0m| 371/3290 [02:14<19:25,  2.50it/s][A[2025-02-04 03:16:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 371/3290, eval_loss: 0.4827, eval_acc: 0.8705:  11%|[32m█▏        [0m| 372/3290 [02:14<17:48,  2.73it/s][A
step: 372/3290, eval_loss: 0.4837, eval_acc: 0.8702:  11%|[32m█▏        [0m| 372/3290 [02:14<17:48,  2.73it/s][A[2025-02-04 03:16:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 372/3290, eval_loss: 0.4837, eval_acc: 0.8702:  11%|[32m█▏        [0m| 373/3290 [02:15<16:20,  2.98it/s][A
step: 373/3290, eval_loss: 0.4847, eval_acc: 0.8698:  11%|[32m█▏        [0m| 373/3290 [02:15<16:20,  2.98it/s][A[2025-02-04 03:16:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 373/3290, eval_loss: 0.4847, eval_acc: 0.8698:  11%|[32m█▏        [0m| 374/3290 [02:15<15:19,  3.17it/s][A
step: 374/3290, eval_loss: 0.4860, eval_acc: 0.8695:  11%|[32m█▏        [0m| 374/3290 [02:15<15:19,  3.17it/s][A[2025-02-04 03:16:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 374/3290, eval_loss: 0.4860, eval_acc: 0.8695:  11%|[32m█▏        [0m| 375/3290 [02:15<15:31,  3.13it/s][A
step: 375/3290, eval_loss: 0.4868, eval_acc: 0.8692:  11%|[32m█▏        [0m| 375/3290 [02:15<15:31,  3.13it/s][A[2025-02-04 03:16:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 375/3290, eval_loss: 0.4868, eval_acc: 0.8692:  11%|[32m█▏        [0m| 376/3290 [02:15<15:27,  3.14it/s][A
step: 376/3290, eval_loss: 0.4873, eval_acc: 0.8692:  11%|[32m█▏        [0m| 376/3290 [02:15<15:27,  3.14it/s][A[2025-02-04 03:16:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 376/3290, eval_loss: 0.4873, eval_acc: 0.8692:  11%|[32m█▏        [0m| 377/3290 [02:16<14:50,  3.27it/s][A
step: 377/3290, eval_loss: 0.4886, eval_acc: 0.8690:  11%|[32m█▏        [0m| 377/3290 [02:16<14:50,  3.27it/s][A[2025-02-04 03:16:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 377/3290, eval_loss: 0.4886, eval_acc: 0.8690:  11%|[32m█▏        [0m| 378/3290 [02:16<14:59,  3.24it/s][A
step: 378/3290, eval_loss: 0.4891, eval_acc: 0.8688:  11%|[32m█▏        [0m| 378/3290 [02:16<14:59,  3.24it/s][A[2025-02-04 03:16:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 378/3290, eval_loss: 0.4891, eval_acc: 0.8688:  12%|[32m█▏        [0m| 379/3290 [02:16<15:08,  3.20it/s][A
step: 379/3290, eval_loss: 0.4887, eval_acc: 0.8688:  12%|[32m█▏        [0m| 379/3290 [02:16<15:08,  3.20it/s][A[2025-02-04 03:16:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 379/3290, eval_loss: 0.4887, eval_acc: 0.8688:  12%|[32m█▏        [0m| 380/3290 [02:17<15:30,  3.13it/s][A
step: 380/3290, eval_loss: 0.4895, eval_acc: 0.8686:  12%|[32m█▏        [0m| 380/3290 [02:17<15:30,  3.13it/s][A[2025-02-04 03:16:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 380/3290, eval_loss: 0.4895, eval_acc: 0.8686:  12%|[32m█▏        [0m| 381/3290 [02:17<16:22,  2.96it/s][A
step: 381/3290, eval_loss: 0.4902, eval_acc: 0.8685:  12%|[32m█▏        [0m| 381/3290 [02:17<16:22,  2.96it/s][A[2025-02-04 03:16:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 381/3290, eval_loss: 0.4902, eval_acc: 0.8685:  12%|[32m█▏        [0m| 382/3290 [02:18<17:42,  2.74it/s][A
step: 382/3290, eval_loss: 0.4907, eval_acc: 0.8684:  12%|[32m█▏        [0m| 382/3290 [02:18<17:42,  2.74it/s][A[2025-02-04 03:16:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 382/3290, eval_loss: 0.4907, eval_acc: 0.8684:  12%|[32m█▏        [0m| 383/3290 [02:18<17:31,  2.76it/s][A
step: 383/3290, eval_loss: 0.4899, eval_acc: 0.8686:  12%|[32m█▏        [0m| 383/3290 [02:18<17:31,  2.76it/s][A[2025-02-04 03:16:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 383/3290, eval_loss: 0.4899, eval_acc: 0.8686:  12%|[32m█▏        [0m| 384/3290 [02:18<17:12,  2.81it/s][A
step: 384/3290, eval_loss: 0.4906, eval_acc: 0.8685:  12%|[32m█▏        [0m| 384/3290 [02:18<17:12,  2.81it/s][A[2025-02-04 03:16:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 384/3290, eval_loss: 0.4906, eval_acc: 0.8685:  12%|[32m█▏        [0m| 385/3290 [02:19<18:28,  2.62it/s][A
step: 385/3290, eval_loss: 0.4920, eval_acc: 0.8682:  12%|[32m█▏        [0m| 385/3290 [02:19<18:28,  2.62it/s][A[2025-02-04 03:16:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 385/3290, eval_loss: 0.4920, eval_acc: 0.8682:  12%|[32m█▏        [0m| 386/3290 [02:19<19:26,  2.49it/s][A
step: 386/3290, eval_loss: 0.4926, eval_acc: 0.8680:  12%|[32m█▏        [0m| 386/3290 [02:19<19:26,  2.49it/s][A[2025-02-04 03:16:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 386/3290, eval_loss: 0.4926, eval_acc: 0.8680:  12%|[32m█▏        [0m| 387/3290 [02:19<17:42,  2.73it/s][A
step: 387/3290, eval_loss: 0.4933, eval_acc: 0.8678:  12%|[32m█▏        [0m| 387/3290 [02:19<17:42,  2.73it/s][A[2025-02-04 03:16:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 387/3290, eval_loss: 0.4933, eval_acc: 0.8678:  12%|[32m█▏        [0m| 388/3290 [02:20<18:45,  2.58it/s][A
step: 388/3290, eval_loss: 0.4946, eval_acc: 0.8675:  12%|[32m█▏        [0m| 388/3290 [02:20<18:45,  2.58it/s][A[2025-02-04 03:16:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 388/3290, eval_loss: 0.4946, eval_acc: 0.8675:  12%|[32m█▏        [0m| 389/3290 [02:20<18:49,  2.57it/s][A
step: 389/3290, eval_loss: 0.4942, eval_acc: 0.8676:  12%|[32m█▏        [0m| 389/3290 [02:20<18:49,  2.57it/s][A[2025-02-04 03:16:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 389/3290, eval_loss: 0.4942, eval_acc: 0.8676:  12%|[32m█▏        [0m| 390/3290 [02:21<18:29,  2.61it/s][A
step: 390/3290, eval_loss: 0.4949, eval_acc: 0.8675:  12%|[32m█▏        [0m| 390/3290 [02:21<18:29,  2.61it/s][A[2025-02-04 03:16:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 390/3290, eval_loss: 0.4949, eval_acc: 0.8675:  12%|[32m█▏        [0m| 391/3290 [02:21<17:47,  2.72it/s][A
step: 391/3290, eval_loss: 0.4953, eval_acc: 0.8673:  12%|[32m█▏        [0m| 391/3290 [02:21<17:47,  2.72it/s][A[2025-02-04 03:16:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 391/3290, eval_loss: 0.4953, eval_acc: 0.8673:  12%|[32m█▏        [0m| 392/3290 [02:21<17:11,  2.81it/s][A
step: 392/3290, eval_loss: 0.4955, eval_acc: 0.8672:  12%|[32m█▏        [0m| 392/3290 [02:21<17:11,  2.81it/s][A[2025-02-04 03:16:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 392/3290, eval_loss: 0.4955, eval_acc: 0.8672:  12%|[32m█▏        [0m| 393/3290 [02:22<16:18,  2.96it/s][A
step: 393/3290, eval_loss: 0.4954, eval_acc: 0.8672:  12%|[32m█▏        [0m| 393/3290 [02:22<16:18,  2.96it/s][A[2025-02-04 03:16:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 393/3290, eval_loss: 0.4954, eval_acc: 0.8672:  12%|[32m█▏        [0m| 394/3290 [02:22<16:43,  2.89it/s][A
step: 394/3290, eval_loss: 0.4973, eval_acc: 0.8668:  12%|[32m█▏        [0m| 394/3290 [02:22<16:43,  2.89it/s][A[2025-02-04 03:16:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 394/3290, eval_loss: 0.4973, eval_acc: 0.8668:  12%|[32m█▏        [0m| 395/3290 [02:22<17:11,  2.81it/s][A
step: 395/3290, eval_loss: 0.5000, eval_acc: 0.8662:  12%|[32m█▏        [0m| 395/3290 [02:22<17:11,  2.81it/s][A[2025-02-04 03:16:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 395/3290, eval_loss: 0.5000, eval_acc: 0.8662:  12%|[32m█▏        [0m| 396/3290 [02:23<16:50,  2.86it/s][A
step: 396/3290, eval_loss: 0.5002, eval_acc: 0.8661:  12%|[32m█▏        [0m| 396/3290 [02:23<16:50,  2.86it/s][A[2025-02-04 03:16:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 396/3290, eval_loss: 0.5002, eval_acc: 0.8661:  12%|[32m█▏        [0m| 397/3290 [02:23<17:30,  2.75it/s][A
step: 397/3290, eval_loss: 0.5006, eval_acc: 0.8659:  12%|[32m█▏        [0m| 397/3290 [02:23<17:30,  2.75it/s][A[2025-02-04 03:16:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 397/3290, eval_loss: 0.5006, eval_acc: 0.8659:  12%|[32m█▏        [0m| 398/3290 [02:23<17:56,  2.69it/s][A
step: 398/3290, eval_loss: 0.4998, eval_acc: 0.8661:  12%|[32m█▏        [0m| 398/3290 [02:23<17:56,  2.69it/s][A[2025-02-04 03:16:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 398/3290, eval_loss: 0.4998, eval_acc: 0.8661:  12%|[32m█▏        [0m| 399/3290 [02:24<16:24,  2.94it/s][A
step: 399/3290, eval_loss: 0.4989, eval_acc: 0.8663:  12%|[32m█▏        [0m| 399/3290 [02:24<16:24,  2.94it/s][A[2025-02-04 03:16:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 399/3290, eval_loss: 0.4989, eval_acc: 0.8663:  12%|[32m█▏        [0m| 400/3290 [02:24<17:55,  2.69it/s][A
step: 400/3290, eval_loss: 0.4979, eval_acc: 0.8665:  12%|[32m█▏        [0m| 400/3290 [02:24<17:55,  2.69it/s][A[2025-02-04 03:16:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 400/3290, eval_loss: 0.4979, eval_acc: 0.8665:  12%|[32m█▏        [0m| 401/3290 [02:24<17:25,  2.76it/s][A
step: 401/3290, eval_loss: 0.4969, eval_acc: 0.8667:  12%|[32m█▏        [0m| 401/3290 [02:24<17:25,  2.76it/s][A[2025-02-04 03:16:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 401/3290, eval_loss: 0.4969, eval_acc: 0.8667:  12%|[32m█▏        [0m| 402/3290 [02:25<18:33,  2.59it/s][A
step: 402/3290, eval_loss: 0.4967, eval_acc: 0.8668:  12%|[32m█▏        [0m| 402/3290 [02:25<18:33,  2.59it/s][A[2025-02-04 03:16:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 402/3290, eval_loss: 0.4967, eval_acc: 0.8668:  12%|[32m█▏        [0m| 403/3290 [02:25<19:13,  2.50it/s][A
step: 403/3290, eval_loss: 0.4960, eval_acc: 0.8670:  12%|[32m█▏        [0m| 403/3290 [02:25<19:13,  2.50it/s][A[2025-02-04 03:16:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 403/3290, eval_loss: 0.4960, eval_acc: 0.8670:  12%|[32m█▏        [0m| 404/3290 [02:26<18:48,  2.56it/s][A
step: 404/3290, eval_loss: 0.4957, eval_acc: 0.8671:  12%|[32m█▏        [0m| 404/3290 [02:26<18:48,  2.56it/s][A[2025-02-04 03:16:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 404/3290, eval_loss: 0.4957, eval_acc: 0.8671:  12%|[32m█▏        [0m| 405/3290 [02:26<18:05,  2.66it/s][A
step: 405/3290, eval_loss: 0.4948, eval_acc: 0.8673:  12%|[32m█▏        [0m| 405/3290 [02:26<18:05,  2.66it/s][A[2025-02-04 03:16:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 405/3290, eval_loss: 0.4948, eval_acc: 0.8673:  12%|[32m█▏        [0m| 406/3290 [02:26<19:05,  2.52it/s][A
step: 406/3290, eval_loss: 0.4943, eval_acc: 0.8675:  12%|[32m█▏        [0m| 406/3290 [02:27<19:05,  2.52it/s][A[2025-02-04 03:16:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 406/3290, eval_loss: 0.4943, eval_acc: 0.8675:  12%|[32m█▏        [0m| 407/3290 [02:27<19:11,  2.50it/s][A
step: 407/3290, eval_loss: 0.4936, eval_acc: 0.8677:  12%|[32m█▏        [0m| 407/3290 [02:27<19:11,  2.50it/s][A[2025-02-04 03:16:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 407/3290, eval_loss: 0.4936, eval_acc: 0.8677:  12%|[32m█▏        [0m| 408/3290 [02:27<18:04,  2.66it/s][A
step: 408/3290, eval_loss: 0.4931, eval_acc: 0.8678:  12%|[32m█▏        [0m| 408/3290 [02:27<18:04,  2.66it/s][A[2025-02-04 03:16:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 408/3290, eval_loss: 0.4931, eval_acc: 0.8678:  12%|[32m█▏        [0m| 409/3290 [02:28<17:49,  2.69it/s][A
step: 409/3290, eval_loss: 0.4926, eval_acc: 0.8679:  12%|[32m█▏        [0m| 409/3290 [02:28<17:49,  2.69it/s][A[2025-02-04 03:16:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 409/3290, eval_loss: 0.4926, eval_acc: 0.8679:  12%|[32m█▏        [0m| 410/3290 [02:28<17:15,  2.78it/s][A
step: 410/3290, eval_loss: 0.4931, eval_acc: 0.8677:  12%|[32m█▏        [0m| 410/3290 [02:28<17:15,  2.78it/s][A[2025-02-04 03:16:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 410/3290, eval_loss: 0.4931, eval_acc: 0.8677:  12%|[32m█▏        [0m| 411/3290 [02:28<16:45,  2.86it/s][A
step: 411/3290, eval_loss: 0.4919, eval_acc: 0.8680:  12%|[32m█▏        [0m| 411/3290 [02:28<16:45,  2.86it/s][A[2025-02-04 03:16:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 411/3290, eval_loss: 0.4919, eval_acc: 0.8680:  13%|[32m█▎        [0m| 412/3290 [02:29<16:06,  2.98it/s][A
step: 412/3290, eval_loss: 0.4914, eval_acc: 0.8682:  13%|[32m█▎        [0m| 412/3290 [02:29<16:06,  2.98it/s][A[2025-02-04 03:16:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 412/3290, eval_loss: 0.4914, eval_acc: 0.8682:  13%|[32m█▎        [0m| 413/3290 [02:29<17:09,  2.80it/s][A
step: 413/3290, eval_loss: 0.4905, eval_acc: 0.8684:  13%|[32m█▎        [0m| 413/3290 [02:29<17:09,  2.80it/s][A[2025-02-04 03:16:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 413/3290, eval_loss: 0.4905, eval_acc: 0.8684:  13%|[32m█▎        [0m| 414/3290 [02:29<16:24,  2.92it/s][A
step: 414/3290, eval_loss: 0.4894, eval_acc: 0.8687:  13%|[32m█▎        [0m| 414/3290 [02:29<16:24,  2.92it/s][A[2025-02-04 03:16:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 414/3290, eval_loss: 0.4894, eval_acc: 0.8687:  13%|[32m█▎        [0m| 415/3290 [02:30<17:11,  2.79it/s][A
step: 415/3290, eval_loss: 0.4888, eval_acc: 0.8688:  13%|[32m█▎        [0m| 415/3290 [02:30<17:11,  2.79it/s][A[2025-02-04 03:16:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 415/3290, eval_loss: 0.4888, eval_acc: 0.8688:  13%|[32m█▎        [0m| 416/3290 [02:30<17:09,  2.79it/s][A
step: 416/3290, eval_loss: 0.4892, eval_acc: 0.8687:  13%|[32m█▎        [0m| 416/3290 [02:30<17:09,  2.79it/s][A[2025-02-04 03:16:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 416/3290, eval_loss: 0.4892, eval_acc: 0.8687:  13%|[32m█▎        [0m| 417/3290 [02:30<15:24,  3.11it/s][A
step: 417/3290, eval_loss: 0.4884, eval_acc: 0.8689:  13%|[32m█▎        [0m| 417/3290 [02:30<15:24,  3.11it/s][A[2025-02-04 03:16:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 417/3290, eval_loss: 0.4884, eval_acc: 0.8689:  13%|[32m█▎        [0m| 418/3290 [02:31<14:53,  3.22it/s][A
step: 418/3290, eval_loss: 0.4875, eval_acc: 0.8691:  13%|[32m█▎        [0m| 418/3290 [02:31<14:53,  3.22it/s][A[2025-02-04 03:16:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 418/3290, eval_loss: 0.4875, eval_acc: 0.8691:  13%|[32m█▎        [0m| 419/3290 [02:31<14:39,  3.26it/s][A
step: 419/3290, eval_loss: 0.4878, eval_acc: 0.8690:  13%|[32m█▎        [0m| 419/3290 [02:31<14:39,  3.26it/s][A[2025-02-04 03:16:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 419/3290, eval_loss: 0.4878, eval_acc: 0.8690:  13%|[32m█▎        [0m| 420/3290 [02:31<14:18,  3.34it/s][A
step: 420/3290, eval_loss: 0.4867, eval_acc: 0.8694:  13%|[32m█▎        [0m| 420/3290 [02:31<14:18,  3.34it/s][A[2025-02-04 03:16:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 420/3290, eval_loss: 0.4867, eval_acc: 0.8694:  13%|[32m█▎        [0m| 421/3290 [02:31<15:11,  3.15it/s][A
step: 421/3290, eval_loss: 0.4866, eval_acc: 0.8694:  13%|[32m█▎        [0m| 421/3290 [02:31<15:11,  3.15it/s][A[2025-02-04 03:16:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 421/3290, eval_loss: 0.4866, eval_acc: 0.8694:  13%|[32m█▎        [0m| 422/3290 [02:32<19:10,  2.49it/s][A
step: 422/3290, eval_loss: 0.4864, eval_acc: 0.8694:  13%|[32m█▎        [0m| 422/3290 [02:32<19:10,  2.49it/s][A[2025-02-04 03:16:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 422/3290, eval_loss: 0.4864, eval_acc: 0.8694:  13%|[32m█▎        [0m| 423/3290 [02:32<18:56,  2.52it/s][A
step: 423/3290, eval_loss: 0.4862, eval_acc: 0.8694:  13%|[32m█▎        [0m| 423/3290 [02:32<18:56,  2.52it/s][A[2025-02-04 03:16:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 423/3290, eval_loss: 0.4862, eval_acc: 0.8694:  13%|[32m█▎        [0m| 424/3290 [02:33<18:38,  2.56it/s][A
step: 424/3290, eval_loss: 0.4858, eval_acc: 0.8695:  13%|[32m█▎        [0m| 424/3290 [02:33<18:38,  2.56it/s][A[2025-02-04 03:16:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 424/3290, eval_loss: 0.4858, eval_acc: 0.8695:  13%|[32m█▎        [0m| 425/3290 [02:33<18:41,  2.56it/s][A
step: 425/3290, eval_loss: 0.4856, eval_acc: 0.8696:  13%|[32m█▎        [0m| 425/3290 [02:33<18:41,  2.56it/s][A[2025-02-04 03:16:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 425/3290, eval_loss: 0.4856, eval_acc: 0.8696:  13%|[32m█▎        [0m| 426/3290 [02:34<17:09,  2.78it/s][A
step: 426/3290, eval_loss: 0.4850, eval_acc: 0.8698:  13%|[32m█▎        [0m| 426/3290 [02:34<17:09,  2.78it/s][A[2025-02-04 03:16:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 426/3290, eval_loss: 0.4850, eval_acc: 0.8698:  13%|[32m█▎        [0m| 427/3290 [02:34<17:59,  2.65it/s][A
step: 427/3290, eval_loss: 0.4845, eval_acc: 0.8699:  13%|[32m█▎        [0m| 427/3290 [02:34<17:59,  2.65it/s][A[2025-02-04 03:16:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 427/3290, eval_loss: 0.4845, eval_acc: 0.8699:  13%|[32m█▎        [0m| 428/3290 [02:34<17:08,  2.78it/s][A
step: 428/3290, eval_loss: 0.4848, eval_acc: 0.8700:  13%|[32m█▎        [0m| 428/3290 [02:34<17:08,  2.78it/s][A[2025-02-04 03:16:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 428/3290, eval_loss: 0.4848, eval_acc: 0.8700:  13%|[32m█▎        [0m| 429/3290 [02:35<15:42,  3.04it/s][A
step: 429/3290, eval_loss: 0.4840, eval_acc: 0.8702:  13%|[32m█▎        [0m| 429/3290 [02:35<15:42,  3.04it/s][A[2025-02-04 03:16:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 429/3290, eval_loss: 0.4840, eval_acc: 0.8702:  13%|[32m█▎        [0m| 430/3290 [02:35<15:39,  3.04it/s][A
step: 430/3290, eval_loss: 0.4832, eval_acc: 0.8703:  13%|[32m█▎        [0m| 430/3290 [02:35<15:39,  3.04it/s][A[2025-02-04 03:16:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 430/3290, eval_loss: 0.4832, eval_acc: 0.8703:  13%|[32m█▎        [0m| 431/3290 [02:35<15:48,  3.01it/s][A
step: 431/3290, eval_loss: 0.4824, eval_acc: 0.8705:  13%|[32m█▎        [0m| 431/3290 [02:35<15:48,  3.01it/s][A[2025-02-04 03:16:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 431/3290, eval_loss: 0.4824, eval_acc: 0.8705:  13%|[32m█▎        [0m| 432/3290 [02:36<16:56,  2.81it/s][A
step: 432/3290, eval_loss: 0.4818, eval_acc: 0.8707:  13%|[32m█▎        [0m| 432/3290 [02:36<16:56,  2.81it/s][A[2025-02-04 03:16:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 432/3290, eval_loss: 0.4818, eval_acc: 0.8707:  13%|[32m█▎        [0m| 433/3290 [02:36<15:45,  3.02it/s][A
step: 433/3290, eval_loss: 0.4808, eval_acc: 0.8710:  13%|[32m█▎        [0m| 433/3290 [02:36<15:45,  3.02it/s][A[2025-02-04 03:16:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 433/3290, eval_loss: 0.4808, eval_acc: 0.8710:  13%|[32m█▎        [0m| 434/3290 [02:36<15:19,  3.11it/s][A
step: 434/3290, eval_loss: 0.4808, eval_acc: 0.8710:  13%|[32m█▎        [0m| 434/3290 [02:36<15:19,  3.11it/s][A[2025-02-04 03:16:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 434/3290, eval_loss: 0.4808, eval_acc: 0.8710:  13%|[32m█▎        [0m| 435/3290 [02:37<16:45,  2.84it/s][A
step: 435/3290, eval_loss: 0.4802, eval_acc: 0.8712:  13%|[32m█▎        [0m| 435/3290 [02:37<16:45,  2.84it/s][A[2025-02-04 03:16:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 435/3290, eval_loss: 0.4802, eval_acc: 0.8712:  13%|[32m█▎        [0m| 436/3290 [02:37<16:50,  2.83it/s][A
step: 436/3290, eval_loss: 0.4792, eval_acc: 0.8714:  13%|[32m█▎        [0m| 436/3290 [02:37<16:50,  2.83it/s][A[2025-02-04 03:16:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 436/3290, eval_loss: 0.4792, eval_acc: 0.8714:  13%|[32m█▎        [0m| 437/3290 [02:37<17:44,  2.68it/s][A
step: 437/3290, eval_loss: 0.4787, eval_acc: 0.8716:  13%|[32m█▎        [0m| 437/3290 [02:37<17:44,  2.68it/s][A[2025-02-04 03:16:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 437/3290, eval_loss: 0.4787, eval_acc: 0.8716:  13%|[32m█▎        [0m| 438/3290 [02:38<19:53,  2.39it/s][A
step: 438/3290, eval_loss: 0.4784, eval_acc: 0.8717:  13%|[32m█▎        [0m| 438/3290 [02:38<19:53,  2.39it/s][A[2025-02-04 03:16:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 438/3290, eval_loss: 0.4784, eval_acc: 0.8717:  13%|[32m█▎        [0m| 439/3290 [02:38<20:59,  2.26it/s][A
step: 439/3290, eval_loss: 0.4779, eval_acc: 0.8718:  13%|[32m█▎        [0m| 439/3290 [02:38<20:59,  2.26it/s][A[2025-02-04 03:16:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 439/3290, eval_loss: 0.4779, eval_acc: 0.8718:  13%|[32m█▎        [0m| 440/3290 [02:39<19:39,  2.42it/s][A
step: 440/3290, eval_loss: 0.4773, eval_acc: 0.8719:  13%|[32m█▎        [0m| 440/3290 [02:39<19:39,  2.42it/s][A[2025-02-04 03:16:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 440/3290, eval_loss: 0.4773, eval_acc: 0.8719:  13%|[32m█▎        [0m| 441/3290 [02:39<19:45,  2.40it/s][A
step: 441/3290, eval_loss: 0.4771, eval_acc: 0.8720:  13%|[32m█▎        [0m| 441/3290 [02:39<19:45,  2.40it/s][A[2025-02-04 03:16:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 441/3290, eval_loss: 0.4771, eval_acc: 0.8720:  13%|[32m█▎        [0m| 442/3290 [02:39<17:42,  2.68it/s][A
step: 442/3290, eval_loss: 0.4779, eval_acc: 0.8720:  13%|[32m█▎        [0m| 442/3290 [02:39<17:42,  2.68it/s][A[2025-02-04 03:16:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 442/3290, eval_loss: 0.4779, eval_acc: 0.8720:  13%|[32m█▎        [0m| 443/3290 [02:40<18:23,  2.58it/s][A
step: 443/3290, eval_loss: 0.4774, eval_acc: 0.8721:  13%|[32m█▎        [0m| 443/3290 [02:40<18:23,  2.58it/s][A[2025-02-04 03:16:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 443/3290, eval_loss: 0.4774, eval_acc: 0.8721:  13%|[32m█▎        [0m| 444/3290 [02:40<17:39,  2.68it/s][A
step: 444/3290, eval_loss: 0.4768, eval_acc: 0.8723:  13%|[32m█▎        [0m| 444/3290 [02:40<17:39,  2.68it/s][A[2025-02-04 03:16:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 444/3290, eval_loss: 0.4768, eval_acc: 0.8723:  14%|[32m█▎        [0m| 445/3290 [02:41<17:14,  2.75it/s][A
step: 445/3290, eval_loss: 0.4770, eval_acc: 0.8724:  14%|[32m█▎        [0m| 445/3290 [02:41<17:14,  2.75it/s][A[2025-02-04 03:16:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 445/3290, eval_loss: 0.4770, eval_acc: 0.8724:  14%|[32m█▎        [0m| 446/3290 [02:41<17:37,  2.69it/s][A
step: 446/3290, eval_loss: 0.4767, eval_acc: 0.8725:  14%|[32m█▎        [0m| 446/3290 [02:41<17:37,  2.69it/s][A[2025-02-04 03:16:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 446/3290, eval_loss: 0.4767, eval_acc: 0.8725:  14%|[32m█▎        [0m| 447/3290 [02:41<17:08,  2.77it/s][A
step: 447/3290, eval_loss: 0.4765, eval_acc: 0.8727:  14%|[32m█▎        [0m| 447/3290 [02:41<17:08,  2.77it/s][A[2025-02-04 03:16:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 447/3290, eval_loss: 0.4765, eval_acc: 0.8727:  14%|[32m█▎        [0m| 448/3290 [02:42<18:30,  2.56it/s][A
step: 448/3290, eval_loss: 0.4762, eval_acc: 0.8728:  14%|[32m█▎        [0m| 448/3290 [02:42<18:30,  2.56it/s][A[2025-02-04 03:16:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 448/3290, eval_loss: 0.4762, eval_acc: 0.8728:  14%|[32m█▎        [0m| 449/3290 [02:42<18:30,  2.56it/s][A
step: 449/3290, eval_loss: 0.4755, eval_acc: 0.8730:  14%|[32m█▎        [0m| 449/3290 [02:42<18:30,  2.56it/s][A[2025-02-04 03:16:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 449/3290, eval_loss: 0.4755, eval_acc: 0.8730:  14%|[32m█▎        [0m| 450/3290 [02:43<19:28,  2.43it/s][A
step: 450/3290, eval_loss: 0.4746, eval_acc: 0.8732:  14%|[32m█▎        [0m| 450/3290 [02:43<19:28,  2.43it/s][A[2025-02-04 03:16:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 450/3290, eval_loss: 0.4746, eval_acc: 0.8732:  14%|[32m█▎        [0m| 451/3290 [02:43<18:57,  2.50it/s][A
step: 451/3290, eval_loss: 0.4747, eval_acc: 0.8732:  14%|[32m█▎        [0m| 451/3290 [02:43<18:57,  2.50it/s][A[2025-02-04 03:16:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 451/3290, eval_loss: 0.4747, eval_acc: 0.8732:  14%|[32m█▎        [0m| 452/3290 [02:43<19:32,  2.42it/s][A
step: 452/3290, eval_loss: 0.4740, eval_acc: 0.8734:  14%|[32m█▎        [0m| 452/3290 [02:43<19:32,  2.42it/s][A[2025-02-04 03:16:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 452/3290, eval_loss: 0.4740, eval_acc: 0.8734:  14%|[32m█▍        [0m| 453/3290 [02:44<18:52,  2.50it/s][A
step: 453/3290, eval_loss: 0.4731, eval_acc: 0.8736:  14%|[32m█▍        [0m| 453/3290 [02:44<18:52,  2.50it/s][A[2025-02-04 03:16:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 453/3290, eval_loss: 0.4731, eval_acc: 0.8736:  14%|[32m█▍        [0m| 454/3290 [02:44<18:35,  2.54it/s][A
step: 454/3290, eval_loss: 0.4728, eval_acc: 0.8737:  14%|[32m█▍        [0m| 454/3290 [02:44<18:35,  2.54it/s][A[2025-02-04 03:16:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 454/3290, eval_loss: 0.4728, eval_acc: 0.8737:  14%|[32m█▍        [0m| 455/3290 [02:45<19:25,  2.43it/s][A
step: 455/3290, eval_loss: 0.4725, eval_acc: 0.8739:  14%|[32m█▍        [0m| 455/3290 [02:45<19:25,  2.43it/s][A[2025-02-04 03:16:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 455/3290, eval_loss: 0.4725, eval_acc: 0.8739:  14%|[32m█▍        [0m| 456/3290 [02:45<18:03,  2.62it/s][A
step: 456/3290, eval_loss: 0.4719, eval_acc: 0.8740:  14%|[32m█▍        [0m| 456/3290 [02:45<18:03,  2.62it/s][A[2025-02-04 03:16:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 456/3290, eval_loss: 0.4719, eval_acc: 0.8740:  14%|[32m█▍        [0m| 457/3290 [02:45<17:05,  2.76it/s][A
step: 457/3290, eval_loss: 0.4716, eval_acc: 0.8741:  14%|[32m█▍        [0m| 457/3290 [02:45<17:05,  2.76it/s][A[2025-02-04 03:16:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 457/3290, eval_loss: 0.4716, eval_acc: 0.8741:  14%|[32m█▍        [0m| 458/3290 [02:46<17:02,  2.77it/s][A
step: 458/3290, eval_loss: 0.4707, eval_acc: 0.8744:  14%|[32m█▍        [0m| 458/3290 [02:46<17:02,  2.77it/s][A[2025-02-04 03:16:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 458/3290, eval_loss: 0.4707, eval_acc: 0.8744:  14%|[32m█▍        [0m| 459/3290 [02:46<18:22,  2.57it/s][A
step: 459/3290, eval_loss: 0.4705, eval_acc: 0.8745:  14%|[32m█▍        [0m| 459/3290 [02:46<18:22,  2.57it/s][A[2025-02-04 03:16:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 459/3290, eval_loss: 0.4705, eval_acc: 0.8745:  14%|[32m█▍        [0m| 460/3290 [02:46<19:11,  2.46it/s][A
step: 460/3290, eval_loss: 0.4706, eval_acc: 0.8744:  14%|[32m█▍        [0m| 460/3290 [02:46<19:11,  2.46it/s][A[2025-02-04 03:16:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 460/3290, eval_loss: 0.4706, eval_acc: 0.8744:  14%|[32m█▍        [0m| 461/3290 [02:47<18:35,  2.54it/s][A
step: 461/3290, eval_loss: 0.4700, eval_acc: 0.8746:  14%|[32m█▍        [0m| 461/3290 [02:47<18:35,  2.54it/s][A[2025-02-04 03:16:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 461/3290, eval_loss: 0.4700, eval_acc: 0.8746:  14%|[32m█▍        [0m| 462/3290 [02:47<18:37,  2.53it/s][A
step: 462/3290, eval_loss: 0.4696, eval_acc: 0.8746:  14%|[32m█▍        [0m| 462/3290 [02:47<18:37,  2.53it/s][A[2025-02-04 03:16:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 462/3290, eval_loss: 0.4696, eval_acc: 0.8746:  14%|[32m█▍        [0m| 463/3290 [02:48<18:59,  2.48it/s][A
step: 463/3290, eval_loss: 0.4693, eval_acc: 0.8747:  14%|[32m█▍        [0m| 463/3290 [02:48<18:59,  2.48it/s][A[2025-02-04 03:16:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 463/3290, eval_loss: 0.4693, eval_acc: 0.8747:  14%|[32m█▍        [0m| 464/3290 [02:48<17:49,  2.64it/s][A
step: 464/3290, eval_loss: 0.4688, eval_acc: 0.8748:  14%|[32m█▍        [0m| 464/3290 [02:48<17:49,  2.64it/s][A[2025-02-04 03:16:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 464/3290, eval_loss: 0.4688, eval_acc: 0.8748:  14%|[32m█▍        [0m| 465/3290 [02:48<18:04,  2.60it/s][A
step: 465/3290, eval_loss: 0.4680, eval_acc: 0.8750:  14%|[32m█▍        [0m| 465/3290 [02:48<18:04,  2.60it/s][A[2025-02-04 03:16:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 465/3290, eval_loss: 0.4680, eval_acc: 0.8750:  14%|[32m█▍        [0m| 466/3290 [02:49<17:19,  2.72it/s][A
step: 466/3290, eval_loss: 0.4684, eval_acc: 0.8749:  14%|[32m█▍        [0m| 466/3290 [02:49<17:19,  2.72it/s][A[2025-02-04 03:16:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 466/3290, eval_loss: 0.4684, eval_acc: 0.8749:  14%|[32m█▍        [0m| 467/3290 [02:49<16:27,  2.86it/s][A
step: 467/3290, eval_loss: 0.4678, eval_acc: 0.8750:  14%|[32m█▍        [0m| 467/3290 [02:49<16:27,  2.86it/s][A[2025-02-04 03:16:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 467/3290, eval_loss: 0.4678, eval_acc: 0.8750:  14%|[32m█▍        [0m| 468/3290 [02:49<16:43,  2.81it/s][A
step: 468/3290, eval_loss: 0.4674, eval_acc: 0.8752:  14%|[32m█▍        [0m| 468/3290 [02:49<16:43,  2.81it/s][A[2025-02-04 03:16:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 468/3290, eval_loss: 0.4674, eval_acc: 0.8752:  14%|[32m█▍        [0m| 469/3290 [02:50<15:54,  2.95it/s][A
step: 469/3290, eval_loss: 0.4676, eval_acc: 0.8752:  14%|[32m█▍        [0m| 469/3290 [02:50<15:54,  2.95it/s][A[2025-02-04 03:16:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 469/3290, eval_loss: 0.4676, eval_acc: 0.8752:  14%|[32m█▍        [0m| 470/3290 [02:50<16:05,  2.92it/s][A
step: 470/3290, eval_loss: 0.4678, eval_acc: 0.8750:  14%|[32m█▍        [0m| 470/3290 [02:50<16:05,  2.92it/s][A[2025-02-04 03:16:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 470/3290, eval_loss: 0.4678, eval_acc: 0.8750:  14%|[32m█▍        [0m| 471/3290 [02:50<16:35,  2.83it/s][A
step: 471/3290, eval_loss: 0.4679, eval_acc: 0.8750:  14%|[32m█▍        [0m| 471/3290 [02:50<16:35,  2.83it/s][A[2025-02-04 03:16:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 471/3290, eval_loss: 0.4679, eval_acc: 0.8750:  14%|[32m█▍        [0m| 472/3290 [02:51<16:54,  2.78it/s][A
step: 472/3290, eval_loss: 0.4680, eval_acc: 0.8750:  14%|[32m█▍        [0m| 472/3290 [02:51<16:54,  2.78it/s][A[2025-02-04 03:16:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 472/3290, eval_loss: 0.4680, eval_acc: 0.8750:  14%|[32m█▍        [0m| 473/3290 [02:51<16:05,  2.92it/s][A
step: 473/3290, eval_loss: 0.4679, eval_acc: 0.8750:  14%|[32m█▍        [0m| 473/3290 [02:51<16:05,  2.92it/s][A[2025-02-04 03:16:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 473/3290, eval_loss: 0.4679, eval_acc: 0.8750:  14%|[32m█▍        [0m| 474/3290 [02:51<15:56,  2.94it/s][A
step: 474/3290, eval_loss: 0.4683, eval_acc: 0.8749:  14%|[32m█▍        [0m| 474/3290 [02:51<15:56,  2.94it/s][A[2025-02-04 03:16:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 474/3290, eval_loss: 0.4683, eval_acc: 0.8749:  14%|[32m█▍        [0m| 475/3290 [02:52<16:36,  2.82it/s][A
step: 475/3290, eval_loss: 0.4681, eval_acc: 0.8749:  14%|[32m█▍        [0m| 475/3290 [02:52<16:36,  2.82it/s][A[2025-02-04 03:16:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 475/3290, eval_loss: 0.4681, eval_acc: 0.8749:  14%|[32m█▍        [0m| 476/3290 [02:52<17:05,  2.75it/s][A
step: 476/3290, eval_loss: 0.4677, eval_acc: 0.8750:  14%|[32m█▍        [0m| 476/3290 [02:52<17:05,  2.75it/s][A[2025-02-04 03:16:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 476/3290, eval_loss: 0.4677, eval_acc: 0.8750:  14%|[32m█▍        [0m| 477/3290 [02:53<17:04,  2.74it/s][A
step: 477/3290, eval_loss: 0.4683, eval_acc: 0.8748:  14%|[32m█▍        [0m| 477/3290 [02:53<17:04,  2.74it/s][A[2025-02-04 03:16:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 477/3290, eval_loss: 0.4683, eval_acc: 0.8748:  15%|[32m█▍        [0m| 478/3290 [02:53<17:09,  2.73it/s][A
step: 478/3290, eval_loss: 0.4682, eval_acc: 0.8749:  15%|[32m█▍        [0m| 478/3290 [02:53<17:09,  2.73it/s][A[2025-02-04 03:16:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 478/3290, eval_loss: 0.4682, eval_acc: 0.8749:  15%|[32m█▍        [0m| 479/3290 [02:53<17:21,  2.70it/s][A
step: 479/3290, eval_loss: 0.4707, eval_acc: 0.8743:  15%|[32m█▍        [0m| 479/3290 [02:53<17:21,  2.70it/s][A[2025-02-04 03:16:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 479/3290, eval_loss: 0.4707, eval_acc: 0.8743:  15%|[32m█▍        [0m| 480/3290 [02:54<17:07,  2.74it/s][A
step: 480/3290, eval_loss: 0.4711, eval_acc: 0.8741:  15%|[32m█▍        [0m| 480/3290 [02:54<17:07,  2.74it/s][A[2025-02-04 03:16:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 480/3290, eval_loss: 0.4711, eval_acc: 0.8741:  15%|[32m█▍        [0m| 481/3290 [02:54<17:23,  2.69it/s][A
step: 481/3290, eval_loss: 0.4714, eval_acc: 0.8740:  15%|[32m█▍        [0m| 481/3290 [02:54<17:23,  2.69it/s][A[2025-02-04 03:16:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 481/3290, eval_loss: 0.4714, eval_acc: 0.8740:  15%|[32m█▍        [0m| 482/3290 [02:54<15:39,  2.99it/s][A
step: 482/3290, eval_loss: 0.4707, eval_acc: 0.8742:  15%|[32m█▍        [0m| 482/3290 [02:54<15:39,  2.99it/s][A[2025-02-04 03:16:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 482/3290, eval_loss: 0.4707, eval_acc: 0.8742:  15%|[32m█▍        [0m| 483/3290 [02:55<15:08,  3.09it/s][A
step: 483/3290, eval_loss: 0.4709, eval_acc: 0.8741:  15%|[32m█▍        [0m| 483/3290 [02:55<15:08,  3.09it/s][A[2025-02-04 03:16:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 483/3290, eval_loss: 0.4709, eval_acc: 0.8741:  15%|[32m█▍        [0m| 484/3290 [02:55<16:03,  2.91it/s][A
step: 484/3290, eval_loss: 0.4708, eval_acc: 0.8742:  15%|[32m█▍        [0m| 484/3290 [02:55<16:03,  2.91it/s][A[2025-02-04 03:16:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 484/3290, eval_loss: 0.4708, eval_acc: 0.8742:  15%|[32m█▍        [0m| 485/3290 [02:55<16:24,  2.85it/s][A
step: 485/3290, eval_loss: 0.4712, eval_acc: 0.8741:  15%|[32m█▍        [0m| 485/3290 [02:55<16:24,  2.85it/s][A[2025-02-04 03:16:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 485/3290, eval_loss: 0.4712, eval_acc: 0.8741:  15%|[32m█▍        [0m| 486/3290 [02:56<16:26,  2.84it/s][A
step: 486/3290, eval_loss: 0.4710, eval_acc: 0.8741:  15%|[32m█▍        [0m| 486/3290 [02:56<16:26,  2.84it/s][A[2025-02-04 03:16:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 486/3290, eval_loss: 0.4710, eval_acc: 0.8741:  15%|[32m█▍        [0m| 487/3290 [02:56<16:20,  2.86it/s][A
step: 487/3290, eval_loss: 0.4704, eval_acc: 0.8742:  15%|[32m█▍        [0m| 487/3290 [02:56<16:20,  2.86it/s][A[2025-02-04 03:16:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 487/3290, eval_loss: 0.4704, eval_acc: 0.8742:  15%|[32m█▍        [0m| 488/3290 [02:56<15:39,  2.98it/s][A
step: 488/3290, eval_loss: 0.4699, eval_acc: 0.8744:  15%|[32m█▍        [0m| 488/3290 [02:56<15:39,  2.98it/s][A[2025-02-04 03:16:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 488/3290, eval_loss: 0.4699, eval_acc: 0.8744:  15%|[32m█▍        [0m| 489/3290 [02:57<15:17,  3.05it/s][A
step: 489/3290, eval_loss: 0.4710, eval_acc: 0.8740:  15%|[32m█▍        [0m| 489/3290 [02:57<15:17,  3.05it/s][A[2025-02-04 03:16:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 489/3290, eval_loss: 0.4710, eval_acc: 0.8740:  15%|[32m█▍        [0m| 490/3290 [02:57<14:22,  3.25it/s][A
step: 490/3290, eval_loss: 0.4705, eval_acc: 0.8742:  15%|[32m█▍        [0m| 490/3290 [02:57<14:22,  3.25it/s][A[2025-02-04 03:16:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 490/3290, eval_loss: 0.4705, eval_acc: 0.8742:  15%|[32m█▍        [0m| 491/3290 [02:57<14:15,  3.27it/s][A
step: 491/3290, eval_loss: 0.4710, eval_acc: 0.8741:  15%|[32m█▍        [0m| 491/3290 [02:57<14:15,  3.27it/s][A[2025-02-04 03:16:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 491/3290, eval_loss: 0.4710, eval_acc: 0.8741:  15%|[32m█▍        [0m| 492/3290 [02:57<13:27,  3.46it/s][A
step: 492/3290, eval_loss: 0.4723, eval_acc: 0.8738:  15%|[32m█▍        [0m| 492/3290 [02:57<13:27,  3.46it/s][A[2025-02-04 03:16:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 492/3290, eval_loss: 0.4723, eval_acc: 0.8738:  15%|[32m█▍        [0m| 493/3290 [02:58<13:10,  3.54it/s][A
step: 493/3290, eval_loss: 0.4721, eval_acc: 0.8738:  15%|[32m█▍        [0m| 493/3290 [02:58<13:10,  3.54it/s][A[2025-02-04 03:16:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 493/3290, eval_loss: 0.4721, eval_acc: 0.8738:  15%|[32m█▌        [0m| 494/3290 [02:58<12:46,  3.65it/s][A
step: 494/3290, eval_loss: 0.4717, eval_acc: 0.8739:  15%|[32m█▌        [0m| 494/3290 [02:58<12:46,  3.65it/s][A[2025-02-04 03:16:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 494/3290, eval_loss: 0.4717, eval_acc: 0.8739:  15%|[32m█▌        [0m| 495/3290 [02:58<12:25,  3.75it/s][A
step: 495/3290, eval_loss: 0.4735, eval_acc: 0.8733:  15%|[32m█▌        [0m| 495/3290 [02:58<12:25,  3.75it/s][A[2025-02-04 03:16:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 495/3290, eval_loss: 0.4735, eval_acc: 0.8733:  15%|[32m█▌        [0m| 496/3290 [02:59<12:26,  3.74it/s][A
step: 496/3290, eval_loss: 0.4746, eval_acc: 0.8730:  15%|[32m█▌        [0m| 496/3290 [02:59<12:26,  3.74it/s][A[2025-02-04 03:16:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 496/3290, eval_loss: 0.4746, eval_acc: 0.8730:  15%|[32m█▌        [0m| 497/3290 [02:59<12:16,  3.79it/s][A
step: 497/3290, eval_loss: 0.4756, eval_acc: 0.8728:  15%|[32m█▌        [0m| 497/3290 [02:59<12:16,  3.79it/s][A[2025-02-04 03:16:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 497/3290, eval_loss: 0.4756, eval_acc: 0.8728:  15%|[32m█▌        [0m| 498/3290 [02:59<13:34,  3.43it/s][A
step: 498/3290, eval_loss: 0.4758, eval_acc: 0.8728:  15%|[32m█▌        [0m| 498/3290 [02:59<13:34,  3.43it/s][A[2025-02-04 03:16:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 498/3290, eval_loss: 0.4758, eval_acc: 0.8728:  15%|[32m█▌        [0m| 499/3290 [03:00<14:50,  3.13it/s][A
step: 499/3290, eval_loss: 0.4750, eval_acc: 0.8729:  15%|[32m█▌        [0m| 499/3290 [03:00<14:50,  3.13it/s][A[2025-02-04 03:16:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 499/3290, eval_loss: 0.4750, eval_acc: 0.8729:  15%|[32m█▌        [0m| 500/3290 [03:00<15:40,  2.97it/s][A
step: 500/3290, eval_loss: 0.4749, eval_acc: 0.8729:  15%|[32m█▌        [0m| 500/3290 [03:00<15:40,  2.97it/s][A[2025-02-04 03:16:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 500/3290, eval_loss: 0.4749, eval_acc: 0.8729:  15%|[32m█▌        [0m| 501/3290 [03:00<16:56,  2.74it/s][A
step: 501/3290, eval_loss: 0.4744, eval_acc: 0.8730:  15%|[32m█▌        [0m| 501/3290 [03:00<16:56,  2.74it/s][A[2025-02-04 03:16:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 501/3290, eval_loss: 0.4744, eval_acc: 0.8730:  15%|[32m█▌        [0m| 502/3290 [03:01<17:51,  2.60it/s][A
step: 502/3290, eval_loss: 0.4749, eval_acc: 0.8730:  15%|[32m█▌        [0m| 502/3290 [03:01<17:51,  2.60it/s][A[2025-02-04 03:16:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 502/3290, eval_loss: 0.4749, eval_acc: 0.8730:  15%|[32m█▌        [0m| 503/3290 [03:01<17:39,  2.63it/s][A
step: 503/3290, eval_loss: 0.4761, eval_acc: 0.8726:  15%|[32m█▌        [0m| 503/3290 [03:01<17:39,  2.63it/s][A[2025-02-04 03:16:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 503/3290, eval_loss: 0.4761, eval_acc: 0.8726:  15%|[32m█▌        [0m| 504/3290 [03:02<20:05,  2.31it/s][A
step: 504/3290, eval_loss: 0.4770, eval_acc: 0.8724:  15%|[32m█▌        [0m| 504/3290 [03:02<20:05,  2.31it/s][A[2025-02-04 03:16:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 504/3290, eval_loss: 0.4770, eval_acc: 0.8724:  15%|[32m█▌        [0m| 505/3290 [03:02<20:51,  2.23it/s][A
step: 505/3290, eval_loss: 0.4766, eval_acc: 0.8725:  15%|[32m█▌        [0m| 505/3290 [03:02<20:51,  2.23it/s][A[2025-02-04 03:16:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 505/3290, eval_loss: 0.4766, eval_acc: 0.8725:  15%|[32m█▌        [0m| 506/3290 [03:03<21:14,  2.18it/s][A
step: 506/3290, eval_loss: 0.4761, eval_acc: 0.8726:  15%|[32m█▌        [0m| 506/3290 [03:03<21:14,  2.18it/s][A[2025-02-04 03:16:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 506/3290, eval_loss: 0.4761, eval_acc: 0.8726:  15%|[32m█▌        [0m| 507/3290 [03:03<21:02,  2.20it/s][A
step: 507/3290, eval_loss: 0.4757, eval_acc: 0.8728:  15%|[32m█▌        [0m| 507/3290 [03:03<21:02,  2.20it/s][A[2025-02-04 03:16:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 507/3290, eval_loss: 0.4757, eval_acc: 0.8728:  15%|[32m█▌        [0m| 508/3290 [03:04<20:35,  2.25it/s][A
step: 508/3290, eval_loss: 0.4757, eval_acc: 0.8727:  15%|[32m█▌        [0m| 508/3290 [03:04<20:35,  2.25it/s][A[2025-02-04 03:16:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 508/3290, eval_loss: 0.4757, eval_acc: 0.8727:  15%|[32m█▌        [0m| 509/3290 [03:04<20:05,  2.31it/s][A
step: 509/3290, eval_loss: 0.4760, eval_acc: 0.8726:  15%|[32m█▌        [0m| 509/3290 [03:04<20:05,  2.31it/s][A[2025-02-04 03:16:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 509/3290, eval_loss: 0.4760, eval_acc: 0.8726:  16%|[32m█▌        [0m| 510/3290 [03:04<19:42,  2.35it/s][A
step: 510/3290, eval_loss: 0.4762, eval_acc: 0.8724:  16%|[32m█▌        [0m| 510/3290 [03:04<19:42,  2.35it/s][A[2025-02-04 03:16:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 510/3290, eval_loss: 0.4762, eval_acc: 0.8724:  16%|[32m█▌        [0m| 511/3290 [03:05<20:17,  2.28it/s][A
step: 511/3290, eval_loss: 0.4771, eval_acc: 0.8723:  16%|[32m█▌        [0m| 511/3290 [03:05<20:17,  2.28it/s][A[2025-02-04 03:16:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 511/3290, eval_loss: 0.4771, eval_acc: 0.8723:  16%|[32m█▌        [0m| 512/3290 [03:05<21:22,  2.17it/s][A
step: 512/3290, eval_loss: 0.4782, eval_acc: 0.8720:  16%|[32m█▌        [0m| 512/3290 [03:05<21:22,  2.17it/s][A[2025-02-04 03:16:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 512/3290, eval_loss: 0.4782, eval_acc: 0.8720:  16%|[32m█▌        [0m| 513/3290 [03:06<19:04,  2.43it/s][A
step: 513/3290, eval_loss: 0.4782, eval_acc: 0.8721:  16%|[32m█▌        [0m| 513/3290 [03:06<19:04,  2.43it/s][A[2025-02-04 03:17:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 513/3290, eval_loss: 0.4782, eval_acc: 0.8721:  16%|[32m█▌        [0m| 514/3290 [03:06<17:47,  2.60it/s][A
step: 514/3290, eval_loss: 0.4796, eval_acc: 0.8717:  16%|[32m█▌        [0m| 514/3290 [03:06<17:47,  2.60it/s][A[2025-02-04 03:17:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 514/3290, eval_loss: 0.4796, eval_acc: 0.8717:  16%|[32m█▌        [0m| 515/3290 [03:06<18:19,  2.52it/s][A
step: 515/3290, eval_loss: 0.4801, eval_acc: 0.8716:  16%|[32m█▌        [0m| 515/3290 [03:06<18:19,  2.52it/s][A[2025-02-04 03:17:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 515/3290, eval_loss: 0.4801, eval_acc: 0.8716:  16%|[32m█▌        [0m| 516/3290 [03:07<18:43,  2.47it/s][A
step: 516/3290, eval_loss: 0.4805, eval_acc: 0.8714:  16%|[32m█▌        [0m| 516/3290 [03:07<18:43,  2.47it/s][A[2025-02-04 03:17:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 516/3290, eval_loss: 0.4805, eval_acc: 0.8714:  16%|[32m█▌        [0m| 517/3290 [03:07<21:24,  2.16it/s][A
step: 517/3290, eval_loss: 0.4809, eval_acc: 0.8712:  16%|[32m█▌        [0m| 517/3290 [03:07<21:24,  2.16it/s][A[2025-02-04 03:17:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 517/3290, eval_loss: 0.4809, eval_acc: 0.8712:  16%|[32m█▌        [0m| 518/3290 [03:08<20:37,  2.24it/s][A
step: 518/3290, eval_loss: 0.4805, eval_acc: 0.8714:  16%|[32m█▌        [0m| 518/3290 [03:08<20:37,  2.24it/s][A[2025-02-04 03:17:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 518/3290, eval_loss: 0.4805, eval_acc: 0.8714:  16%|[32m█▌        [0m| 519/3290 [03:08<18:35,  2.48it/s][A
step: 519/3290, eval_loss: 0.4809, eval_acc: 0.8712:  16%|[32m█▌        [0m| 519/3290 [03:08<18:35,  2.48it/s][A[2025-02-04 03:17:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 519/3290, eval_loss: 0.4809, eval_acc: 0.8712:  16%|[32m█▌        [0m| 520/3290 [03:08<16:28,  2.80it/s][A
step: 520/3290, eval_loss: 0.4814, eval_acc: 0.8712:  16%|[32m█▌        [0m| 520/3290 [03:08<16:28,  2.80it/s][A[2025-02-04 03:17:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 520/3290, eval_loss: 0.4814, eval_acc: 0.8712:  16%|[32m█▌        [0m| 521/3290 [03:09<15:54,  2.90it/s][A
step: 521/3290, eval_loss: 0.4814, eval_acc: 0.8712:  16%|[32m█▌        [0m| 521/3290 [03:09<15:54,  2.90it/s][A[2025-02-04 03:17:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 521/3290, eval_loss: 0.4814, eval_acc: 0.8712:  16%|[32m█▌        [0m| 522/3290 [03:09<16:18,  2.83it/s][A
step: 522/3290, eval_loss: 0.4813, eval_acc: 0.8712:  16%|[32m█▌        [0m| 522/3290 [03:09<16:18,  2.83it/s][A[2025-02-04 03:17:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 522/3290, eval_loss: 0.4813, eval_acc: 0.8712:  16%|[32m█▌        [0m| 523/3290 [03:09<17:29,  2.64it/s][A
step: 523/3290, eval_loss: 0.4821, eval_acc: 0.8709:  16%|[32m█▌        [0m| 523/3290 [03:09<17:29,  2.64it/s][A[2025-02-04 03:17:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 523/3290, eval_loss: 0.4821, eval_acc: 0.8709:  16%|[32m█▌        [0m| 524/3290 [03:10<17:57,  2.57it/s][A
step: 524/3290, eval_loss: 0.4829, eval_acc: 0.8707:  16%|[32m█▌        [0m| 524/3290 [03:10<17:57,  2.57it/s][A[2025-02-04 03:17:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 524/3290, eval_loss: 0.4829, eval_acc: 0.8707:  16%|[32m█▌        [0m| 525/3290 [03:10<17:31,  2.63it/s][A
step: 525/3290, eval_loss: 0.4837, eval_acc: 0.8704:  16%|[32m█▌        [0m| 525/3290 [03:10<17:31,  2.63it/s][A[2025-02-04 03:17:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 525/3290, eval_loss: 0.4837, eval_acc: 0.8704:  16%|[32m█▌        [0m| 526/3290 [03:11<16:52,  2.73it/s][A
step: 526/3290, eval_loss: 0.4837, eval_acc: 0.8704:  16%|[32m█▌        [0m| 526/3290 [03:11<16:52,  2.73it/s][A[2025-02-04 03:17:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 526/3290, eval_loss: 0.4837, eval_acc: 0.8704:  16%|[32m█▌        [0m| 527/3290 [03:11<16:24,  2.81it/s][A
step: 527/3290, eval_loss: 0.4841, eval_acc: 0.8702:  16%|[32m█▌        [0m| 527/3290 [03:11<16:24,  2.81it/s][A[2025-02-04 03:17:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 527/3290, eval_loss: 0.4841, eval_acc: 0.8702:  16%|[32m█▌        [0m| 528/3290 [03:11<16:39,  2.76it/s][A
step: 528/3290, eval_loss: 0.4851, eval_acc: 0.8700:  16%|[32m█▌        [0m| 528/3290 [03:11<16:39,  2.76it/s][A[2025-02-04 03:17:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 528/3290, eval_loss: 0.4851, eval_acc: 0.8700:  16%|[32m█▌        [0m| 529/3290 [03:12<16:05,  2.86it/s][A
step: 529/3290, eval_loss: 0.4862, eval_acc: 0.8696:  16%|[32m█▌        [0m| 529/3290 [03:12<16:05,  2.86it/s][A[2025-02-04 03:17:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 529/3290, eval_loss: 0.4862, eval_acc: 0.8696:  16%|[32m█▌        [0m| 530/3290 [03:12<15:45,  2.92it/s][A
step: 530/3290, eval_loss: 0.4880, eval_acc: 0.8692:  16%|[32m█▌        [0m| 530/3290 [03:12<15:45,  2.92it/s][A[2025-02-04 03:17:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 530/3290, eval_loss: 0.4880, eval_acc: 0.8692:  16%|[32m█▌        [0m| 531/3290 [03:12<15:54,  2.89it/s][A
step: 531/3290, eval_loss: 0.4884, eval_acc: 0.8691:  16%|[32m█▌        [0m| 531/3290 [03:12<15:54,  2.89it/s][A[2025-02-04 03:17:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 531/3290, eval_loss: 0.4884, eval_acc: 0.8691:  16%|[32m█▌        [0m| 532/3290 [03:13<14:47,  3.11it/s][A
step: 532/3290, eval_loss: 0.4884, eval_acc: 0.8690:  16%|[32m█▌        [0m| 532/3290 [03:13<14:47,  3.11it/s][A[2025-02-04 03:17:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 532/3290, eval_loss: 0.4884, eval_acc: 0.8690:  16%|[32m█▌        [0m| 533/3290 [03:13<14:58,  3.07it/s][A
step: 533/3290, eval_loss: 0.4889, eval_acc: 0.8690:  16%|[32m█▌        [0m| 533/3290 [03:13<14:58,  3.07it/s][A[2025-02-04 03:17:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 533/3290, eval_loss: 0.4889, eval_acc: 0.8690:  16%|[32m█▌        [0m| 534/3290 [03:13<15:32,  2.95it/s][A
step: 534/3290, eval_loss: 0.4890, eval_acc: 0.8689:  16%|[32m█▌        [0m| 534/3290 [03:13<15:32,  2.95it/s][A[2025-02-04 03:17:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 534/3290, eval_loss: 0.4890, eval_acc: 0.8689:  16%|[32m█▋        [0m| 535/3290 [03:14<16:19,  2.81it/s][A
step: 535/3290, eval_loss: 0.4889, eval_acc: 0.8689:  16%|[32m█▋        [0m| 535/3290 [03:14<16:19,  2.81it/s][A[2025-02-04 03:17:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 535/3290, eval_loss: 0.4889, eval_acc: 0.8689:  16%|[32m█▋        [0m| 536/3290 [03:14<15:34,  2.95it/s][A
step: 536/3290, eval_loss: 0.4889, eval_acc: 0.8688:  16%|[32m█▋        [0m| 536/3290 [03:14<15:34,  2.95it/s][A[2025-02-04 03:17:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 536/3290, eval_loss: 0.4889, eval_acc: 0.8688:  16%|[32m█▋        [0m| 537/3290 [03:14<16:39,  2.75it/s][A
step: 537/3290, eval_loss: 0.4883, eval_acc: 0.8690:  16%|[32m█▋        [0m| 537/3290 [03:14<16:39,  2.75it/s][A[2025-02-04 03:17:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 537/3290, eval_loss: 0.4883, eval_acc: 0.8690:  16%|[32m█▋        [0m| 538/3290 [03:15<17:16,  2.66it/s][A
step: 538/3290, eval_loss: 0.4881, eval_acc: 0.8691:  16%|[32m█▋        [0m| 538/3290 [03:15<17:16,  2.66it/s][A[2025-02-04 03:17:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 538/3290, eval_loss: 0.4881, eval_acc: 0.8691:  16%|[32m█▋        [0m| 539/3290 [03:15<18:00,  2.55it/s][A
step: 539/3290, eval_loss: 0.4879, eval_acc: 0.8692:  16%|[32m█▋        [0m| 539/3290 [03:15<18:00,  2.55it/s][A[2025-02-04 03:17:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 539/3290, eval_loss: 0.4879, eval_acc: 0.8692:  16%|[32m█▋        [0m| 540/3290 [03:16<17:24,  2.63it/s][A
step: 540/3290, eval_loss: 0.4875, eval_acc: 0.8693:  16%|[32m█▋        [0m| 540/3290 [03:16<17:24,  2.63it/s][A[2025-02-04 03:17:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 540/3290, eval_loss: 0.4875, eval_acc: 0.8693:  16%|[32m█▋        [0m| 541/3290 [03:16<16:49,  2.72it/s][A
step: 541/3290, eval_loss: 0.4872, eval_acc: 0.8693:  16%|[32m█▋        [0m| 541/3290 [03:16<16:49,  2.72it/s][A[2025-02-04 03:17:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 541/3290, eval_loss: 0.4872, eval_acc: 0.8693:  16%|[32m█▋        [0m| 542/3290 [03:16<16:46,  2.73it/s][A
step: 542/3290, eval_loss: 0.4873, eval_acc: 0.8692:  16%|[32m█▋        [0m| 542/3290 [03:16<16:46,  2.73it/s][A[2025-02-04 03:17:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 542/3290, eval_loss: 0.4873, eval_acc: 0.8692:  17%|[32m█▋        [0m| 543/3290 [03:17<16:42,  2.74it/s][A
step: 543/3290, eval_loss: 0.4868, eval_acc: 0.8694:  17%|[32m█▋        [0m| 543/3290 [03:17<16:42,  2.74it/s][A[2025-02-04 03:17:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 543/3290, eval_loss: 0.4868, eval_acc: 0.8694:  17%|[32m█▋        [0m| 544/3290 [03:17<18:20,  2.50it/s][A
step: 544/3290, eval_loss: 0.4867, eval_acc: 0.8693:  17%|[32m█▋        [0m| 544/3290 [03:17<18:20,  2.50it/s][A[2025-02-04 03:17:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 544/3290, eval_loss: 0.4867, eval_acc: 0.8693:  17%|[32m█▋        [0m| 545/3290 [03:18<19:50,  2.31it/s][A
step: 545/3290, eval_loss: 0.4873, eval_acc: 0.8692:  17%|[32m█▋        [0m| 545/3290 [03:18<19:50,  2.31it/s][A[2025-02-04 03:17:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 545/3290, eval_loss: 0.4873, eval_acc: 0.8692:  17%|[32m█▋        [0m| 546/3290 [03:18<17:37,  2.59it/s][A
step: 546/3290, eval_loss: 0.4882, eval_acc: 0.8690:  17%|[32m█▋        [0m| 546/3290 [03:18<17:37,  2.59it/s][A[2025-02-04 03:17:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 546/3290, eval_loss: 0.4882, eval_acc: 0.8690:  17%|[32m█▋        [0m| 547/3290 [03:18<16:49,  2.72it/s][A
step: 547/3290, eval_loss: 0.4875, eval_acc: 0.8692:  17%|[32m█▋        [0m| 547/3290 [03:18<16:49,  2.72it/s][A[2025-02-04 03:17:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 547/3290, eval_loss: 0.4875, eval_acc: 0.8692:  17%|[32m█▋        [0m| 548/3290 [03:19<16:00,  2.86it/s][A
step: 548/3290, eval_loss: 0.4881, eval_acc: 0.8691:  17%|[32m█▋        [0m| 548/3290 [03:19<16:00,  2.86it/s][A[2025-02-04 03:17:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 548/3290, eval_loss: 0.4881, eval_acc: 0.8691:  17%|[32m█▋        [0m| 549/3290 [03:19<15:29,  2.95it/s][A
step: 549/3290, eval_loss: 0.4879, eval_acc: 0.8691:  17%|[32m█▋        [0m| 549/3290 [03:19<15:29,  2.95it/s][A[2025-02-04 03:17:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 549/3290, eval_loss: 0.4879, eval_acc: 0.8691:  17%|[32m█▋        [0m| 550/3290 [03:19<15:19,  2.98it/s][A
step: 550/3290, eval_loss: 0.4883, eval_acc: 0.8690:  17%|[32m█▋        [0m| 550/3290 [03:19<15:19,  2.98it/s][A[2025-02-04 03:17:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 550/3290, eval_loss: 0.4883, eval_acc: 0.8690:  17%|[32m█▋        [0m| 551/3290 [03:20<15:40,  2.91it/s][A
step: 551/3290, eval_loss: 0.4880, eval_acc: 0.8691:  17%|[32m█▋        [0m| 551/3290 [03:20<15:40,  2.91it/s][A[2025-02-04 03:17:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 551/3290, eval_loss: 0.4880, eval_acc: 0.8691:  17%|[32m█▋        [0m| 552/3290 [03:20<17:14,  2.65it/s][A
step: 552/3290, eval_loss: 0.4884, eval_acc: 0.8689:  17%|[32m█▋        [0m| 552/3290 [03:20<17:14,  2.65it/s][A[2025-02-04 03:17:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 552/3290, eval_loss: 0.4884, eval_acc: 0.8689:  17%|[32m█▋        [0m| 553/3290 [03:20<18:44,  2.43it/s][A
step: 553/3290, eval_loss: 0.4885, eval_acc: 0.8689:  17%|[32m█▋        [0m| 553/3290 [03:20<18:44,  2.43it/s][A[2025-02-04 03:17:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 553/3290, eval_loss: 0.4885, eval_acc: 0.8689:  17%|[32m█▋        [0m| 554/3290 [03:21<19:54,  2.29it/s][A
step: 554/3290, eval_loss: 0.4893, eval_acc: 0.8687:  17%|[32m█▋        [0m| 554/3290 [03:21<19:54,  2.29it/s][A[2025-02-04 03:17:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 554/3290, eval_loss: 0.4893, eval_acc: 0.8687:  17%|[32m█▋        [0m| 555/3290 [03:21<18:39,  2.44it/s][A
step: 555/3290, eval_loss: 0.4889, eval_acc: 0.8688:  17%|[32m█▋        [0m| 555/3290 [03:21<18:39,  2.44it/s][A[2025-02-04 03:17:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 555/3290, eval_loss: 0.4889, eval_acc: 0.8688:  17%|[32m█▋        [0m| 556/3290 [03:22<17:51,  2.55it/s][A
step: 556/3290, eval_loss: 0.4894, eval_acc: 0.8686:  17%|[32m█▋        [0m| 556/3290 [03:22<17:51,  2.55it/s][A[2025-02-04 03:17:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 556/3290, eval_loss: 0.4894, eval_acc: 0.8686:  17%|[32m█▋        [0m| 557/3290 [03:22<18:38,  2.44it/s][A
step: 557/3290, eval_loss: 0.4899, eval_acc: 0.8685:  17%|[32m█▋        [0m| 557/3290 [03:22<18:38,  2.44it/s][A[2025-02-04 03:17:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 557/3290, eval_loss: 0.4899, eval_acc: 0.8685:  17%|[32m█▋        [0m| 558/3290 [03:22<18:04,  2.52it/s][A
step: 558/3290, eval_loss: 0.4900, eval_acc: 0.8685:  17%|[32m█▋        [0m| 558/3290 [03:22<18:04,  2.52it/s][A[2025-02-04 03:17:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 558/3290, eval_loss: 0.4900, eval_acc: 0.8685:  17%|[32m█▋        [0m| 559/3290 [03:23<18:15,  2.49it/s][A
step: 559/3290, eval_loss: 0.4897, eval_acc: 0.8686:  17%|[32m█▋        [0m| 559/3290 [03:23<18:15,  2.49it/s][A[2025-02-04 03:17:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 559/3290, eval_loss: 0.4897, eval_acc: 0.8686:  17%|[32m█▋        [0m| 560/3290 [03:23<19:06,  2.38it/s][A
step: 560/3290, eval_loss: 0.4895, eval_acc: 0.8686:  17%|[32m█▋        [0m| 560/3290 [03:23<19:06,  2.38it/s][A[2025-02-04 03:17:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 560/3290, eval_loss: 0.4895, eval_acc: 0.8686:  17%|[32m█▋        [0m| 561/3290 [03:24<20:17,  2.24it/s][A
step: 561/3290, eval_loss: 0.4891, eval_acc: 0.8687:  17%|[32m█▋        [0m| 561/3290 [03:24<20:17,  2.24it/s][A[2025-02-04 03:17:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 561/3290, eval_loss: 0.4891, eval_acc: 0.8687:  17%|[32m█▋        [0m| 562/3290 [03:24<20:46,  2.19it/s][A
step: 562/3290, eval_loss: 0.4901, eval_acc: 0.8684:  17%|[32m█▋        [0m| 562/3290 [03:24<20:46,  2.19it/s][A[2025-02-04 03:17:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 562/3290, eval_loss: 0.4901, eval_acc: 0.8684:  17%|[32m█▋        [0m| 563/3290 [03:25<20:10,  2.25it/s][A
step: 563/3290, eval_loss: 0.4906, eval_acc: 0.8682:  17%|[32m█▋        [0m| 563/3290 [03:25<20:10,  2.25it/s][A[2025-02-04 03:17:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 563/3290, eval_loss: 0.4906, eval_acc: 0.8682:  17%|[32m█▋        [0m| 564/3290 [03:25<19:01,  2.39it/s][A
step: 564/3290, eval_loss: 0.4924, eval_acc: 0.8677:  17%|[32m█▋        [0m| 564/3290 [03:25<19:01,  2.39it/s][A[2025-02-04 03:17:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 564/3290, eval_loss: 0.4924, eval_acc: 0.8677:  17%|[32m█▋        [0m| 565/3290 [03:26<19:01,  2.39it/s][A
step: 565/3290, eval_loss: 0.4945, eval_acc: 0.8671:  17%|[32m█▋        [0m| 565/3290 [03:26<19:01,  2.39it/s][A[2025-02-04 03:17:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 565/3290, eval_loss: 0.4945, eval_acc: 0.8671:  17%|[32m█▋        [0m| 566/3290 [03:26<17:38,  2.57it/s][A
step: 566/3290, eval_loss: 0.4975, eval_acc: 0.8664:  17%|[32m█▋        [0m| 566/3290 [03:26<17:38,  2.57it/s][A[2025-02-04 03:17:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 566/3290, eval_loss: 0.4975, eval_acc: 0.8664:  17%|[32m█▋        [0m| 567/3290 [03:26<17:00,  2.67it/s][A
step: 567/3290, eval_loss: 0.4977, eval_acc: 0.8663:  17%|[32m█▋        [0m| 567/3290 [03:26<17:00,  2.67it/s][A[2025-02-04 03:17:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 567/3290, eval_loss: 0.4977, eval_acc: 0.8663:  17%|[32m█▋        [0m| 568/3290 [03:27<17:18,  2.62it/s][A
step: 568/3290, eval_loss: 0.4994, eval_acc: 0.8658:  17%|[32m█▋        [0m| 568/3290 [03:27<17:18,  2.62it/s][A[2025-02-04 03:17:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 568/3290, eval_loss: 0.4994, eval_acc: 0.8658:  17%|[32m█▋        [0m| 569/3290 [03:27<15:27,  2.94it/s][A
step: 569/3290, eval_loss: 0.5000, eval_acc: 0.8656:  17%|[32m█▋        [0m| 569/3290 [03:27<15:27,  2.94it/s][A[2025-02-04 03:17:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 569/3290, eval_loss: 0.5000, eval_acc: 0.8656:  17%|[32m█▋        [0m| 570/3290 [03:27<17:15,  2.63it/s][A
step: 570/3290, eval_loss: 0.5001, eval_acc: 0.8655:  17%|[32m█▋        [0m| 570/3290 [03:27<17:15,  2.63it/s][A[2025-02-04 03:17:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 570/3290, eval_loss: 0.5001, eval_acc: 0.8655:  17%|[32m█▋        [0m| 571/3290 [03:28<17:26,  2.60it/s][A
step: 571/3290, eval_loss: 0.5008, eval_acc: 0.8653:  17%|[32m█▋        [0m| 571/3290 [03:28<17:26,  2.60it/s][A[2025-02-04 03:17:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 571/3290, eval_loss: 0.5008, eval_acc: 0.8653:  17%|[32m█▋        [0m| 572/3290 [03:28<18:22,  2.47it/s][A
step: 572/3290, eval_loss: 0.5020, eval_acc: 0.8650:  17%|[32m█▋        [0m| 572/3290 [03:28<18:22,  2.47it/s][A[2025-02-04 03:17:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 572/3290, eval_loss: 0.5020, eval_acc: 0.8650:  17%|[32m█▋        [0m| 573/3290 [03:29<19:46,  2.29it/s][A
step: 573/3290, eval_loss: 0.5034, eval_acc: 0.8646:  17%|[32m█▋        [0m| 573/3290 [03:29<19:46,  2.29it/s][A[2025-02-04 03:17:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 573/3290, eval_loss: 0.5034, eval_acc: 0.8646:  17%|[32m█▋        [0m| 574/3290 [03:29<19:37,  2.31it/s][A
step: 574/3290, eval_loss: 0.5047, eval_acc: 0.8641:  17%|[32m█▋        [0m| 574/3290 [03:29<19:37,  2.31it/s][A[2025-02-04 03:17:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 574/3290, eval_loss: 0.5047, eval_acc: 0.8641:  17%|[32m█▋        [0m| 575/3290 [03:30<19:49,  2.28it/s][A
step: 575/3290, eval_loss: 0.5058, eval_acc: 0.8638:  17%|[32m█▋        [0m| 575/3290 [03:30<19:49,  2.28it/s][A[2025-02-04 03:17:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 575/3290, eval_loss: 0.5058, eval_acc: 0.8638:  18%|[32m█▊        [0m| 576/3290 [03:30<18:55,  2.39it/s][A
step: 576/3290, eval_loss: 0.5074, eval_acc: 0.8634:  18%|[32m█▊        [0m| 576/3290 [03:30<18:55,  2.39it/s][A[2025-02-04 03:17:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 576/3290, eval_loss: 0.5074, eval_acc: 0.8634:  18%|[32m█▊        [0m| 577/3290 [03:30<17:49,  2.54it/s][A
step: 577/3290, eval_loss: 0.5082, eval_acc: 0.8632:  18%|[32m█▊        [0m| 577/3290 [03:30<17:49,  2.54it/s][A[2025-02-04 03:17:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 577/3290, eval_loss: 0.5082, eval_acc: 0.8632:  18%|[32m█▊        [0m| 578/3290 [03:31<17:20,  2.61it/s][A
step: 578/3290, eval_loss: 0.5096, eval_acc: 0.8627:  18%|[32m█▊        [0m| 578/3290 [03:31<17:20,  2.61it/s][A[2025-02-04 03:17:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 578/3290, eval_loss: 0.5096, eval_acc: 0.8627:  18%|[32m█▊        [0m| 579/3290 [03:31<17:35,  2.57it/s][A
step: 579/3290, eval_loss: 0.5103, eval_acc: 0.8626:  18%|[32m█▊        [0m| 579/3290 [03:31<17:35,  2.57it/s][A[2025-02-04 03:17:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 579/3290, eval_loss: 0.5103, eval_acc: 0.8626:  18%|[32m█▊        [0m| 580/3290 [03:31<18:45,  2.41it/s][A
step: 580/3290, eval_loss: 0.5117, eval_acc: 0.8622:  18%|[32m█▊        [0m| 580/3290 [03:31<18:45,  2.41it/s][A[2025-02-04 03:17:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 580/3290, eval_loss: 0.5117, eval_acc: 0.8622:  18%|[32m█▊        [0m| 581/3290 [03:32<20:27,  2.21it/s][A
step: 581/3290, eval_loss: 0.5126, eval_acc: 0.8619:  18%|[32m█▊        [0m| 581/3290 [03:32<20:27,  2.21it/s][A[2025-02-04 03:17:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 581/3290, eval_loss: 0.5126, eval_acc: 0.8619:  18%|[32m█▊        [0m| 582/3290 [03:32<20:03,  2.25it/s][A
step: 582/3290, eval_loss: 0.5134, eval_acc: 0.8617:  18%|[32m█▊        [0m| 582/3290 [03:32<20:03,  2.25it/s][A[2025-02-04 03:17:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 582/3290, eval_loss: 0.5134, eval_acc: 0.8617:  18%|[32m█▊        [0m| 583/3290 [03:33<21:49,  2.07it/s][A
step: 583/3290, eval_loss: 0.5146, eval_acc: 0.8612:  18%|[32m█▊        [0m| 583/3290 [03:33<21:49,  2.07it/s][A[2025-02-04 03:17:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 583/3290, eval_loss: 0.5146, eval_acc: 0.8612:  18%|[32m█▊        [0m| 584/3290 [03:33<19:02,  2.37it/s][A
step: 584/3290, eval_loss: 0.5163, eval_acc: 0.8608:  18%|[32m█▊        [0m| 584/3290 [03:33<19:02,  2.37it/s][A[2025-02-04 03:17:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 584/3290, eval_loss: 0.5163, eval_acc: 0.8608:  18%|[32m█▊        [0m| 585/3290 [03:34<19:55,  2.26it/s][A
step: 585/3290, eval_loss: 0.5168, eval_acc: 0.8607:  18%|[32m█▊        [0m| 585/3290 [03:34<19:55,  2.26it/s][A[2025-02-04 03:17:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 585/3290, eval_loss: 0.5168, eval_acc: 0.8607:  18%|[32m█▊        [0m| 586/3290 [03:34<22:12,  2.03it/s][A
step: 586/3290, eval_loss: 0.5172, eval_acc: 0.8606:  18%|[32m█▊        [0m| 586/3290 [03:34<22:12,  2.03it/s][A[2025-02-04 03:17:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 586/3290, eval_loss: 0.5172, eval_acc: 0.8606:  18%|[32m█▊        [0m| 587/3290 [03:35<20:27,  2.20it/s][A
step: 587/3290, eval_loss: 0.5194, eval_acc: 0.8600:  18%|[32m█▊        [0m| 587/3290 [03:35<20:27,  2.20it/s][A[2025-02-04 03:17:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 587/3290, eval_loss: 0.5194, eval_acc: 0.8600:  18%|[32m█▊        [0m| 588/3290 [03:35<21:33,  2.09it/s][A
step: 588/3290, eval_loss: 0.5199, eval_acc: 0.8598:  18%|[32m█▊        [0m| 588/3290 [03:35<21:33,  2.09it/s][A[2025-02-04 03:17:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 588/3290, eval_loss: 0.5199, eval_acc: 0.8598:  18%|[32m█▊        [0m| 589/3290 [03:36<19:34,  2.30it/s][A
step: 589/3290, eval_loss: 0.5208, eval_acc: 0.8593:  18%|[32m█▊        [0m| 589/3290 [03:36<19:34,  2.30it/s][A[2025-02-04 03:17:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 589/3290, eval_loss: 0.5208, eval_acc: 0.8593:  18%|[32m█▊        [0m| 590/3290 [03:36<19:51,  2.27it/s][A
step: 590/3290, eval_loss: 0.5221, eval_acc: 0.8590:  18%|[32m█▊        [0m| 590/3290 [03:36<19:51,  2.27it/s][A[2025-02-04 03:17:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 590/3290, eval_loss: 0.5221, eval_acc: 0.8590:  18%|[32m█▊        [0m| 591/3290 [03:36<19:05,  2.36it/s][A
step: 591/3290, eval_loss: 0.5250, eval_acc: 0.8583:  18%|[32m█▊        [0m| 591/3290 [03:36<19:05,  2.36it/s][A[2025-02-04 03:17:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 591/3290, eval_loss: 0.5250, eval_acc: 0.8583:  18%|[32m█▊        [0m| 592/3290 [03:37<18:21,  2.45it/s][A
step: 592/3290, eval_loss: 0.5272, eval_acc: 0.8577:  18%|[32m█▊        [0m| 592/3290 [03:37<18:21,  2.45it/s][A[2025-02-04 03:17:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 592/3290, eval_loss: 0.5272, eval_acc: 0.8577:  18%|[32m█▊        [0m| 593/3290 [03:37<19:27,  2.31it/s][A
step: 593/3290, eval_loss: 0.5289, eval_acc: 0.8572:  18%|[32m█▊        [0m| 593/3290 [03:37<19:27,  2.31it/s][A[2025-02-04 03:17:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 593/3290, eval_loss: 0.5289, eval_acc: 0.8572:  18%|[32m█▊        [0m| 594/3290 [03:38<22:45,  1.98it/s][A
step: 594/3290, eval_loss: 0.5312, eval_acc: 0.8565:  18%|[32m█▊        [0m| 594/3290 [03:38<22:45,  1.98it/s][A[2025-02-04 03:17:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 594/3290, eval_loss: 0.5312, eval_acc: 0.8565:  18%|[32m█▊        [0m| 595/3290 [03:38<20:55,  2.15it/s][A
step: 595/3290, eval_loss: 0.5316, eval_acc: 0.8563:  18%|[32m█▊        [0m| 595/3290 [03:38<20:55,  2.15it/s][A[2025-02-04 03:17:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 595/3290, eval_loss: 0.5316, eval_acc: 0.8563:  18%|[32m█▊        [0m| 596/3290 [03:39<20:17,  2.21it/s][A
step: 596/3290, eval_loss: 0.5322, eval_acc: 0.8562:  18%|[32m█▊        [0m| 596/3290 [03:39<20:17,  2.21it/s][A[2025-02-04 03:17:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 596/3290, eval_loss: 0.5322, eval_acc: 0.8562:  18%|[32m█▊        [0m| 597/3290 [03:39<21:08,  2.12it/s][A
step: 597/3290, eval_loss: 0.5335, eval_acc: 0.8558:  18%|[32m█▊        [0m| 597/3290 [03:39<21:08,  2.12it/s][A[2025-02-04 03:17:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 597/3290, eval_loss: 0.5335, eval_acc: 0.8558:  18%|[32m█▊        [0m| 598/3290 [03:40<19:45,  2.27it/s][A
step: 598/3290, eval_loss: 0.5346, eval_acc: 0.8554:  18%|[32m█▊        [0m| 598/3290 [03:40<19:45,  2.27it/s][A[2025-02-04 03:17:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 598/3290, eval_loss: 0.5346, eval_acc: 0.8554:  18%|[32m█▊        [0m| 599/3290 [03:40<18:56,  2.37it/s][A
step: 599/3290, eval_loss: 0.5357, eval_acc: 0.8552:  18%|[32m█▊        [0m| 599/3290 [03:40<18:56,  2.37it/s][A[2025-02-04 03:17:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 599/3290, eval_loss: 0.5357, eval_acc: 0.8552:  18%|[32m█▊        [0m| 600/3290 [03:40<17:35,  2.55it/s][A
step: 600/3290, eval_loss: 0.5372, eval_acc: 0.8547:  18%|[32m█▊        [0m| 600/3290 [03:40<17:35,  2.55it/s][A[2025-02-04 03:17:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 600/3290, eval_loss: 0.5372, eval_acc: 0.8547:  18%|[32m█▊        [0m| 601/3290 [03:41<17:00,  2.64it/s][A
step: 601/3290, eval_loss: 0.5388, eval_acc: 0.8542:  18%|[32m█▊        [0m| 601/3290 [03:41<17:00,  2.64it/s][A[2025-02-04 03:17:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 601/3290, eval_loss: 0.5388, eval_acc: 0.8542:  18%|[32m█▊        [0m| 602/3290 [03:41<19:24,  2.31it/s][A
step: 602/3290, eval_loss: 0.5399, eval_acc: 0.8538:  18%|[32m█▊        [0m| 602/3290 [03:41<19:24,  2.31it/s][A[2025-02-04 03:17:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 602/3290, eval_loss: 0.5399, eval_acc: 0.8538:  18%|[32m█▊        [0m| 603/3290 [03:42<18:23,  2.43it/s][A
step: 603/3290, eval_loss: 0.5411, eval_acc: 0.8536:  18%|[32m█▊        [0m| 603/3290 [03:42<18:23,  2.43it/s][A[2025-02-04 03:17:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 603/3290, eval_loss: 0.5411, eval_acc: 0.8536:  18%|[32m█▊        [0m| 604/3290 [03:42<17:17,  2.59it/s][A
step: 604/3290, eval_loss: 0.5419, eval_acc: 0.8534:  18%|[32m█▊        [0m| 604/3290 [03:42<17:17,  2.59it/s][A[2025-02-04 03:17:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 604/3290, eval_loss: 0.5419, eval_acc: 0.8534:  18%|[32m█▊        [0m| 605/3290 [03:42<18:12,  2.46it/s][A
step: 605/3290, eval_loss: 0.5420, eval_acc: 0.8534:  18%|[32m█▊        [0m| 605/3290 [03:42<18:12,  2.46it/s][A[2025-02-04 03:17:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 605/3290, eval_loss: 0.5420, eval_acc: 0.8534:  18%|[32m█▊        [0m| 606/3290 [03:43<16:37,  2.69it/s][A
step: 606/3290, eval_loss: 0.5422, eval_acc: 0.8533:  18%|[32m█▊        [0m| 606/3290 [03:43<16:37,  2.69it/s][A[2025-02-04 03:17:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 606/3290, eval_loss: 0.5422, eval_acc: 0.8533:  18%|[32m█▊        [0m| 607/3290 [03:43<15:20,  2.91it/s][A
step: 607/3290, eval_loss: 0.5427, eval_acc: 0.8532:  18%|[32m█▊        [0m| 607/3290 [03:43<15:20,  2.91it/s][A[2025-02-04 03:17:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 607/3290, eval_loss: 0.5427, eval_acc: 0.8532:  18%|[32m█▊        [0m| 608/3290 [03:43<14:06,  3.17it/s][A
step: 608/3290, eval_loss: 0.5434, eval_acc: 0.8529:  18%|[32m█▊        [0m| 608/3290 [03:43<14:06,  3.17it/s][A[2025-02-04 03:17:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 608/3290, eval_loss: 0.5434, eval_acc: 0.8529:  19%|[32m█▊        [0m| 609/3290 [03:44<15:06,  2.96it/s][A
step: 609/3290, eval_loss: 0.5433, eval_acc: 0.8530:  19%|[32m█▊        [0m| 609/3290 [03:44<15:06,  2.96it/s][A[2025-02-04 03:17:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 609/3290, eval_loss: 0.5433, eval_acc: 0.8530:  19%|[32m█▊        [0m| 610/3290 [03:44<15:23,  2.90it/s][A
step: 610/3290, eval_loss: 0.5427, eval_acc: 0.8532:  19%|[32m█▊        [0m| 610/3290 [03:44<15:23,  2.90it/s][A[2025-02-04 03:17:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 610/3290, eval_loss: 0.5427, eval_acc: 0.8532:  19%|[32m█▊        [0m| 611/3290 [03:44<16:10,  2.76it/s][A
step: 611/3290, eval_loss: 0.5424, eval_acc: 0.8533:  19%|[32m█▊        [0m| 611/3290 [03:44<16:10,  2.76it/s][A[2025-02-04 03:17:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 611/3290, eval_loss: 0.5424, eval_acc: 0.8533:  19%|[32m█▊        [0m| 612/3290 [03:45<16:11,  2.76it/s][A
step: 612/3290, eval_loss: 0.5419, eval_acc: 0.8534:  19%|[32m█▊        [0m| 612/3290 [03:45<16:11,  2.76it/s][A[2025-02-04 03:17:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 612/3290, eval_loss: 0.5419, eval_acc: 0.8534:  19%|[32m█▊        [0m| 613/3290 [03:45<14:45,  3.02it/s][A
step: 613/3290, eval_loss: 0.5419, eval_acc: 0.8534:  19%|[32m█▊        [0m| 613/3290 [03:45<14:45,  3.02it/s][A[2025-02-04 03:17:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 613/3290, eval_loss: 0.5419, eval_acc: 0.8534:  19%|[32m█▊        [0m| 614/3290 [03:46<16:48,  2.65it/s][A
step: 614/3290, eval_loss: 0.5415, eval_acc: 0.8535:  19%|[32m█▊        [0m| 614/3290 [03:46<16:48,  2.65it/s][A[2025-02-04 03:17:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 614/3290, eval_loss: 0.5415, eval_acc: 0.8535:  19%|[32m█▊        [0m| 615/3290 [03:46<16:35,  2.69it/s][A
step: 615/3290, eval_loss: 0.5413, eval_acc: 0.8536:  19%|[32m█▊        [0m| 615/3290 [03:46<16:35,  2.69it/s][A[2025-02-04 03:17:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 615/3290, eval_loss: 0.5413, eval_acc: 0.8536:  19%|[32m█▊        [0m| 616/3290 [03:46<16:06,  2.77it/s][A
step: 616/3290, eval_loss: 0.5410, eval_acc: 0.8536:  19%|[32m█▊        [0m| 616/3290 [03:46<16:06,  2.77it/s][A[2025-02-04 03:17:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 616/3290, eval_loss: 0.5410, eval_acc: 0.8536:  19%|[32m█▉        [0m| 617/3290 [03:47<16:15,  2.74it/s][A
step: 617/3290, eval_loss: 0.5407, eval_acc: 0.8537:  19%|[32m█▉        [0m| 617/3290 [03:47<16:15,  2.74it/s][A[2025-02-04 03:17:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 617/3290, eval_loss: 0.5407, eval_acc: 0.8537:  19%|[32m█▉        [0m| 618/3290 [03:47<14:52,  2.99it/s][A
step: 618/3290, eval_loss: 0.5410, eval_acc: 0.8536:  19%|[32m█▉        [0m| 618/3290 [03:47<14:52,  2.99it/s][A[2025-02-04 03:17:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 618/3290, eval_loss: 0.5410, eval_acc: 0.8536:  19%|[32m█▉        [0m| 619/3290 [03:47<15:25,  2.89it/s][A
step: 619/3290, eval_loss: 0.5404, eval_acc: 0.8538:  19%|[32m█▉        [0m| 619/3290 [03:47<15:25,  2.89it/s][A[2025-02-04 03:17:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 619/3290, eval_loss: 0.5404, eval_acc: 0.8538:  19%|[32m█▉        [0m| 620/3290 [03:48<16:40,  2.67it/s][A
step: 620/3290, eval_loss: 0.5404, eval_acc: 0.8538:  19%|[32m█▉        [0m| 620/3290 [03:48<16:40,  2.67it/s][A[2025-02-04 03:17:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 620/3290, eval_loss: 0.5404, eval_acc: 0.8538:  19%|[32m█▉        [0m| 621/3290 [03:48<15:49,  2.81it/s][A
step: 621/3290, eval_loss: 0.5402, eval_acc: 0.8538:  19%|[32m█▉        [0m| 621/3290 [03:48<15:49,  2.81it/s][A[2025-02-04 03:17:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 621/3290, eval_loss: 0.5402, eval_acc: 0.8538:  19%|[32m█▉        [0m| 622/3290 [03:48<14:42,  3.02it/s][A
step: 622/3290, eval_loss: 0.5401, eval_acc: 0.8538:  19%|[32m█▉        [0m| 622/3290 [03:48<14:42,  3.02it/s][A[2025-02-04 03:17:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 622/3290, eval_loss: 0.5401, eval_acc: 0.8538:  19%|[32m█▉        [0m| 623/3290 [03:49<14:27,  3.07it/s][A
step: 623/3290, eval_loss: 0.5403, eval_acc: 0.8538:  19%|[32m█▉        [0m| 623/3290 [03:49<14:27,  3.07it/s][A[2025-02-04 03:17:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 623/3290, eval_loss: 0.5403, eval_acc: 0.8538:  19%|[32m█▉        [0m| 624/3290 [03:49<13:47,  3.22it/s][A
step: 624/3290, eval_loss: 0.5409, eval_acc: 0.8537:  19%|[32m█▉        [0m| 624/3290 [03:49<13:47,  3.22it/s][A[2025-02-04 03:17:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 624/3290, eval_loss: 0.5409, eval_acc: 0.8537:  19%|[32m█▉        [0m| 625/3290 [03:49<14:44,  3.01it/s][A
step: 625/3290, eval_loss: 0.5411, eval_acc: 0.8536:  19%|[32m█▉        [0m| 625/3290 [03:49<14:44,  3.01it/s][A[2025-02-04 03:17:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 625/3290, eval_loss: 0.5411, eval_acc: 0.8536:  19%|[32m█▉        [0m| 626/3290 [03:50<16:18,  2.72it/s][A
step: 626/3290, eval_loss: 0.5407, eval_acc: 0.8537:  19%|[32m█▉        [0m| 626/3290 [03:50<16:18,  2.72it/s][A[2025-02-04 03:17:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 626/3290, eval_loss: 0.5407, eval_acc: 0.8537:  19%|[32m█▉        [0m| 627/3290 [03:50<17:45,  2.50it/s][A
step: 627/3290, eval_loss: 0.5409, eval_acc: 0.8537:  19%|[32m█▉        [0m| 627/3290 [03:50<17:45,  2.50it/s][A[2025-02-04 03:17:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 627/3290, eval_loss: 0.5409, eval_acc: 0.8537:  19%|[32m█▉        [0m| 628/3290 [03:51<17:59,  2.47it/s][A
step: 628/3290, eval_loss: 0.5407, eval_acc: 0.8538:  19%|[32m█▉        [0m| 628/3290 [03:51<17:59,  2.47it/s][A[2025-02-04 03:17:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 628/3290, eval_loss: 0.5407, eval_acc: 0.8538:  19%|[32m█▉        [0m| 629/3290 [03:51<19:02,  2.33it/s][A
step: 629/3290, eval_loss: 0.5402, eval_acc: 0.8540:  19%|[32m█▉        [0m| 629/3290 [03:51<19:02,  2.33it/s][A[2025-02-04 03:17:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 629/3290, eval_loss: 0.5402, eval_acc: 0.8540:  19%|[32m█▉        [0m| 630/3290 [03:51<19:03,  2.33it/s][A
step: 630/3290, eval_loss: 0.5399, eval_acc: 0.8541:  19%|[32m█▉        [0m| 630/3290 [03:51<19:03,  2.33it/s][A[2025-02-04 03:17:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 630/3290, eval_loss: 0.5399, eval_acc: 0.8541:  19%|[32m█▉        [0m| 631/3290 [03:52<18:38,  2.38it/s][A
step: 631/3290, eval_loss: 0.5394, eval_acc: 0.8542:  19%|[32m█▉        [0m| 631/3290 [03:52<18:38,  2.38it/s][A[2025-02-04 03:17:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 631/3290, eval_loss: 0.5394, eval_acc: 0.8542:  19%|[32m█▉        [0m| 632/3290 [03:52<17:59,  2.46it/s][A
step: 632/3290, eval_loss: 0.5387, eval_acc: 0.8544:  19%|[32m█▉        [0m| 632/3290 [03:52<17:59,  2.46it/s][A[2025-02-04 03:17:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 632/3290, eval_loss: 0.5387, eval_acc: 0.8544:  19%|[32m█▉        [0m| 633/3290 [03:53<17:38,  2.51it/s][A
step: 633/3290, eval_loss: 0.5387, eval_acc: 0.8544:  19%|[32m█▉        [0m| 633/3290 [03:53<17:38,  2.51it/s][A[2025-02-04 03:17:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 633/3290, eval_loss: 0.5387, eval_acc: 0.8544:  19%|[32m█▉        [0m| 634/3290 [03:53<18:15,  2.43it/s][A
step: 634/3290, eval_loss: 0.5384, eval_acc: 0.8545:  19%|[32m█▉        [0m| 634/3290 [03:53<18:15,  2.43it/s][A[2025-02-04 03:17:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 634/3290, eval_loss: 0.5384, eval_acc: 0.8545:  19%|[32m█▉        [0m| 635/3290 [03:53<17:22,  2.55it/s][A
step: 635/3290, eval_loss: 0.5381, eval_acc: 0.8546:  19%|[32m█▉        [0m| 635/3290 [03:53<17:22,  2.55it/s][A[2025-02-04 03:17:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 635/3290, eval_loss: 0.5381, eval_acc: 0.8546:  19%|[32m█▉        [0m| 636/3290 [03:54<17:04,  2.59it/s][A
step: 636/3290, eval_loss: 0.5375, eval_acc: 0.8547:  19%|[32m█▉        [0m| 636/3290 [03:54<17:04,  2.59it/s][A[2025-02-04 03:17:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 636/3290, eval_loss: 0.5375, eval_acc: 0.8547:  19%|[32m█▉        [0m| 637/3290 [03:54<18:23,  2.40it/s][A
step: 637/3290, eval_loss: 0.5373, eval_acc: 0.8548:  19%|[32m█▉        [0m| 637/3290 [03:54<18:23,  2.40it/s][A[2025-02-04 03:17:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 637/3290, eval_loss: 0.5373, eval_acc: 0.8548:  19%|[32m█▉        [0m| 638/3290 [03:55<17:47,  2.48it/s][A
step: 638/3290, eval_loss: 0.5367, eval_acc: 0.8549:  19%|[32m█▉        [0m| 638/3290 [03:55<17:47,  2.48it/s][A[2025-02-04 03:17:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 638/3290, eval_loss: 0.5367, eval_acc: 0.8549:  19%|[32m█▉        [0m| 639/3290 [03:55<17:01,  2.60it/s][A
step: 639/3290, eval_loss: 0.5364, eval_acc: 0.8550:  19%|[32m█▉        [0m| 639/3290 [03:55<17:01,  2.60it/s][A[2025-02-04 03:17:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 639/3290, eval_loss: 0.5364, eval_acc: 0.8550:  19%|[32m█▉        [0m| 640/3290 [03:55<17:50,  2.47it/s][A
step: 640/3290, eval_loss: 0.5362, eval_acc: 0.8551:  19%|[32m█▉        [0m| 640/3290 [03:55<17:50,  2.47it/s][A[2025-02-04 03:17:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 640/3290, eval_loss: 0.5362, eval_acc: 0.8551:  19%|[32m█▉        [0m| 641/3290 [03:56<17:33,  2.51it/s][A
step: 641/3290, eval_loss: 0.5366, eval_acc: 0.8550:  19%|[32m█▉        [0m| 641/3290 [03:56<17:33,  2.51it/s][A[2025-02-04 03:17:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 641/3290, eval_loss: 0.5366, eval_acc: 0.8550:  20%|[32m█▉        [0m| 642/3290 [03:56<16:17,  2.71it/s][A
step: 642/3290, eval_loss: 0.5364, eval_acc: 0.8551:  20%|[32m█▉        [0m| 642/3290 [03:56<16:17,  2.71it/s][A[2025-02-04 03:17:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 642/3290, eval_loss: 0.5364, eval_acc: 0.8551:  20%|[32m█▉        [0m| 643/3290 [03:57<16:33,  2.66it/s][A
step: 643/3290, eval_loss: 0.5362, eval_acc: 0.8551:  20%|[32m█▉        [0m| 643/3290 [03:57<16:33,  2.66it/s][A[2025-02-04 03:17:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 643/3290, eval_loss: 0.5362, eval_acc: 0.8551:  20%|[32m█▉        [0m| 644/3290 [03:57<16:59,  2.60it/s][A
step: 644/3290, eval_loss: 0.5360, eval_acc: 0.8551:  20%|[32m█▉        [0m| 644/3290 [03:57<16:59,  2.60it/s][A[2025-02-04 03:17:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 644/3290, eval_loss: 0.5360, eval_acc: 0.8551:  20%|[32m█▉        [0m| 645/3290 [03:57<17:21,  2.54it/s][A
step: 645/3290, eval_loss: 0.5357, eval_acc: 0.8552:  20%|[32m█▉        [0m| 645/3290 [03:57<17:21,  2.54it/s][A[2025-02-04 03:17:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 645/3290, eval_loss: 0.5357, eval_acc: 0.8552:  20%|[32m█▉        [0m| 646/3290 [03:58<16:33,  2.66it/s][A
step: 646/3290, eval_loss: 0.5354, eval_acc: 0.8553:  20%|[32m█▉        [0m| 646/3290 [03:58<16:33,  2.66it/s][A[2025-02-04 03:17:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 646/3290, eval_loss: 0.5354, eval_acc: 0.8553:  20%|[32m█▉        [0m| 647/3290 [03:58<16:22,  2.69it/s][A
step: 647/3290, eval_loss: 0.5357, eval_acc: 0.8553:  20%|[32m█▉        [0m| 647/3290 [03:58<16:22,  2.69it/s][A[2025-02-04 03:17:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 647/3290, eval_loss: 0.5357, eval_acc: 0.8553:  20%|[32m█▉        [0m| 648/3290 [03:58<15:10,  2.90it/s][A
step: 648/3290, eval_loss: 0.5359, eval_acc: 0.8552:  20%|[32m█▉        [0m| 648/3290 [03:58<15:10,  2.90it/s][A[2025-02-04 03:17:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 648/3290, eval_loss: 0.5359, eval_acc: 0.8552:  20%|[32m█▉        [0m| 649/3290 [03:59<14:09,  3.11it/s][A
step: 649/3290, eval_loss: 0.5354, eval_acc: 0.8553:  20%|[32m█▉        [0m| 649/3290 [03:59<14:09,  3.11it/s][A[2025-02-04 03:17:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 649/3290, eval_loss: 0.5354, eval_acc: 0.8553:  20%|[32m█▉        [0m| 650/3290 [03:59<14:29,  3.04it/s][A
step: 650/3290, eval_loss: 0.5350, eval_acc: 0.8554:  20%|[32m█▉        [0m| 650/3290 [03:59<14:29,  3.04it/s][A[2025-02-04 03:17:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 650/3290, eval_loss: 0.5350, eval_acc: 0.8554:  20%|[32m█▉        [0m| 651/3290 [03:59<15:43,  2.80it/s][A
step: 651/3290, eval_loss: 0.5350, eval_acc: 0.8554:  20%|[32m█▉        [0m| 651/3290 [03:59<15:43,  2.80it/s][A[2025-02-04 03:17:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 651/3290, eval_loss: 0.5350, eval_acc: 0.8554:  20%|[32m█▉        [0m| 652/3290 [04:00<15:50,  2.78it/s][A
step: 652/3290, eval_loss: 0.5345, eval_acc: 0.8556:  20%|[32m█▉        [0m| 652/3290 [04:00<15:50,  2.78it/s][A[2025-02-04 03:17:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 652/3290, eval_loss: 0.5345, eval_acc: 0.8556:  20%|[32m█▉        [0m| 653/3290 [04:00<15:44,  2.79it/s][A
step: 653/3290, eval_loss: 0.5340, eval_acc: 0.8557:  20%|[32m█▉        [0m| 653/3290 [04:00<15:44,  2.79it/s][A[2025-02-04 03:17:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 653/3290, eval_loss: 0.5340, eval_acc: 0.8557:  20%|[32m█▉        [0m| 654/3290 [04:00<14:16,  3.08it/s][A
step: 654/3290, eval_loss: 0.5344, eval_acc: 0.8556:  20%|[32m█▉        [0m| 654/3290 [04:00<14:16,  3.08it/s][A[2025-02-04 03:17:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 654/3290, eval_loss: 0.5344, eval_acc: 0.8556:  20%|[32m█▉        [0m| 655/3290 [04:01<13:59,  3.14it/s][A
step: 655/3290, eval_loss: 0.5344, eval_acc: 0.8556:  20%|[32m█▉        [0m| 655/3290 [04:01<13:59,  3.14it/s][A[2025-02-04 03:17:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 655/3290, eval_loss: 0.5344, eval_acc: 0.8556:  20%|[32m█▉        [0m| 656/3290 [04:01<14:26,  3.04it/s][A
step: 656/3290, eval_loss: 0.5338, eval_acc: 0.8558:  20%|[32m█▉        [0m| 656/3290 [04:01<14:26,  3.04it/s][A[2025-02-04 03:17:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 656/3290, eval_loss: 0.5338, eval_acc: 0.8558:  20%|[32m█▉        [0m| 657/3290 [04:01<14:39,  2.99it/s][A
step: 657/3290, eval_loss: 0.5334, eval_acc: 0.8559:  20%|[32m█▉        [0m| 657/3290 [04:01<14:39,  2.99it/s][A[2025-02-04 03:17:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 657/3290, eval_loss: 0.5334, eval_acc: 0.8559:  20%|[32m██        [0m| 658/3290 [04:02<14:29,  3.03it/s][A
step: 658/3290, eval_loss: 0.5333, eval_acc: 0.8559:  20%|[32m██        [0m| 658/3290 [04:02<14:29,  3.03it/s][A[2025-02-04 03:17:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 658/3290, eval_loss: 0.5333, eval_acc: 0.8559:  20%|[32m██        [0m| 659/3290 [04:02<14:55,  2.94it/s][A
step: 659/3290, eval_loss: 0.5329, eval_acc: 0.8560:  20%|[32m██        [0m| 659/3290 [04:02<14:55,  2.94it/s][A[2025-02-04 03:17:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 659/3290, eval_loss: 0.5329, eval_acc: 0.8560:  20%|[32m██        [0m| 660/3290 [04:02<14:56,  2.93it/s][A
step: 660/3290, eval_loss: 0.5331, eval_acc: 0.8560:  20%|[32m██        [0m| 660/3290 [04:02<14:56,  2.93it/s][A[2025-02-04 03:17:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 660/3290, eval_loss: 0.5331, eval_acc: 0.8560:  20%|[32m██        [0m| 661/3290 [04:03<16:04,  2.73it/s][A
step: 661/3290, eval_loss: 0.5329, eval_acc: 0.8560:  20%|[32m██        [0m| 661/3290 [04:03<16:04,  2.73it/s][A[2025-02-04 03:17:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 661/3290, eval_loss: 0.5329, eval_acc: 0.8560:  20%|[32m██        [0m| 662/3290 [04:03<16:21,  2.68it/s][A
step: 662/3290, eval_loss: 0.5331, eval_acc: 0.8560:  20%|[32m██        [0m| 662/3290 [04:03<16:21,  2.68it/s][A[2025-02-04 03:17:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 662/3290, eval_loss: 0.5331, eval_acc: 0.8560:  20%|[32m██        [0m| 663/3290 [04:04<16:10,  2.71it/s][A
step: 663/3290, eval_loss: 0.5328, eval_acc: 0.8560:  20%|[32m██        [0m| 663/3290 [04:04<16:10,  2.71it/s][A[2025-02-04 03:17:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 663/3290, eval_loss: 0.5328, eval_acc: 0.8560:  20%|[32m██        [0m| 664/3290 [04:04<15:51,  2.76it/s][A
step: 664/3290, eval_loss: 0.5324, eval_acc: 0.8561:  20%|[32m██        [0m| 664/3290 [04:04<15:51,  2.76it/s][A[2025-02-04 03:17:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 664/3290, eval_loss: 0.5324, eval_acc: 0.8561:  20%|[32m██        [0m| 665/3290 [04:04<15:55,  2.75it/s][A
step: 665/3290, eval_loss: 0.5319, eval_acc: 0.8563:  20%|[32m██        [0m| 665/3290 [04:04<15:55,  2.75it/s][A[2025-02-04 03:17:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 665/3290, eval_loss: 0.5319, eval_acc: 0.8563:  20%|[32m██        [0m| 666/3290 [04:05<16:53,  2.59it/s][A
step: 666/3290, eval_loss: 0.5315, eval_acc: 0.8563:  20%|[32m██        [0m| 666/3290 [04:05<16:53,  2.59it/s][A[2025-02-04 03:17:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 666/3290, eval_loss: 0.5315, eval_acc: 0.8563:  20%|[32m██        [0m| 667/3290 [04:05<17:05,  2.56it/s][A
step: 667/3290, eval_loss: 0.5317, eval_acc: 0.8563:  20%|[32m██        [0m| 667/3290 [04:05<17:05,  2.56it/s][A[2025-02-04 03:17:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 667/3290, eval_loss: 0.5317, eval_acc: 0.8563:  20%|[32m██        [0m| 668/3290 [04:06<18:05,  2.42it/s][A
step: 668/3290, eval_loss: 0.5313, eval_acc: 0.8564:  20%|[32m██        [0m| 668/3290 [04:06<18:05,  2.42it/s][A[2025-02-04 03:18:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 668/3290, eval_loss: 0.5313, eval_acc: 0.8564:  20%|[32m██        [0m| 669/3290 [04:06<19:14,  2.27it/s][A
step: 669/3290, eval_loss: 0.5311, eval_acc: 0.8565:  20%|[32m██        [0m| 669/3290 [04:06<19:14,  2.27it/s][A[2025-02-04 03:18:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 669/3290, eval_loss: 0.5311, eval_acc: 0.8565:  20%|[32m██        [0m| 670/3290 [04:06<18:25,  2.37it/s][A
step: 670/3290, eval_loss: 0.5306, eval_acc: 0.8566:  20%|[32m██        [0m| 670/3290 [04:06<18:25,  2.37it/s][A[2025-02-04 03:18:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 670/3290, eval_loss: 0.5306, eval_acc: 0.8566:  20%|[32m██        [0m| 671/3290 [04:07<16:22,  2.66it/s][A
step: 671/3290, eval_loss: 0.5311, eval_acc: 0.8564:  20%|[32m██        [0m| 671/3290 [04:07<16:22,  2.66it/s][A[2025-02-04 03:18:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 671/3290, eval_loss: 0.5311, eval_acc: 0.8564:  20%|[32m██        [0m| 672/3290 [04:07<16:58,  2.57it/s][A
step: 672/3290, eval_loss: 0.5307, eval_acc: 0.8565:  20%|[32m██        [0m| 672/3290 [04:07<16:58,  2.57it/s][A[2025-02-04 03:18:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 672/3290, eval_loss: 0.5307, eval_acc: 0.8565:  20%|[32m██        [0m| 673/3290 [04:08<17:09,  2.54it/s][A
step: 673/3290, eval_loss: 0.5305, eval_acc: 0.8566:  20%|[32m██        [0m| 673/3290 [04:08<17:09,  2.54it/s][A[2025-02-04 03:18:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 673/3290, eval_loss: 0.5305, eval_acc: 0.8566:  20%|[32m██        [0m| 674/3290 [04:08<17:21,  2.51it/s][A
step: 674/3290, eval_loss: 0.5305, eval_acc: 0.8565:  20%|[32m██        [0m| 674/3290 [04:08<17:21,  2.51it/s][A[2025-02-04 03:18:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 674/3290, eval_loss: 0.5305, eval_acc: 0.8565:  21%|[32m██        [0m| 675/3290 [04:08<16:32,  2.63it/s][A
step: 675/3290, eval_loss: 0.5305, eval_acc: 0.8565:  21%|[32m██        [0m| 675/3290 [04:08<16:32,  2.63it/s][A[2025-02-04 03:18:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 675/3290, eval_loss: 0.5305, eval_acc: 0.8565:  21%|[32m██        [0m| 676/3290 [04:09<16:37,  2.62it/s][A
step: 676/3290, eval_loss: 0.5302, eval_acc: 0.8566:  21%|[32m██        [0m| 676/3290 [04:09<16:37,  2.62it/s][A[2025-02-04 03:18:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 676/3290, eval_loss: 0.5302, eval_acc: 0.8566:  21%|[32m██        [0m| 677/3290 [04:09<17:32,  2.48it/s][A
step: 677/3290, eval_loss: 0.5302, eval_acc: 0.8566:  21%|[32m██        [0m| 677/3290 [04:09<17:32,  2.48it/s][A[2025-02-04 03:18:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 677/3290, eval_loss: 0.5302, eval_acc: 0.8566:  21%|[32m██        [0m| 678/3290 [04:10<17:23,  2.50it/s][A
step: 678/3290, eval_loss: 0.5298, eval_acc: 0.8567:  21%|[32m██        [0m| 678/3290 [04:10<17:23,  2.50it/s][A[2025-02-04 03:18:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 678/3290, eval_loss: 0.5298, eval_acc: 0.8567:  21%|[32m██        [0m| 679/3290 [04:10<16:46,  2.59it/s][A
step: 679/3290, eval_loss: 0.5296, eval_acc: 0.8567:  21%|[32m██        [0m| 679/3290 [04:10<16:46,  2.59it/s][A[2025-02-04 03:18:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 679/3290, eval_loss: 0.5296, eval_acc: 0.8567:  21%|[32m██        [0m| 680/3290 [04:10<17:28,  2.49it/s][A
step: 680/3290, eval_loss: 0.5293, eval_acc: 0.8568:  21%|[32m██        [0m| 680/3290 [04:10<17:28,  2.49it/s][A[2025-02-04 03:18:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 680/3290, eval_loss: 0.5293, eval_acc: 0.8568:  21%|[32m██        [0m| 681/3290 [04:11<16:06,  2.70it/s][A
step: 681/3290, eval_loss: 0.5292, eval_acc: 0.8568:  21%|[32m██        [0m| 681/3290 [04:11<16:06,  2.70it/s][A[2025-02-04 03:18:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 681/3290, eval_loss: 0.5292, eval_acc: 0.8568:  21%|[32m██        [0m| 682/3290 [04:11<15:05,  2.88it/s][A
step: 682/3290, eval_loss: 0.5299, eval_acc: 0.8566:  21%|[32m██        [0m| 682/3290 [04:11<15:05,  2.88it/s][A[2025-02-04 03:18:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 682/3290, eval_loss: 0.5299, eval_acc: 0.8566:  21%|[32m██        [0m| 683/3290 [04:11<15:42,  2.77it/s][A
step: 683/3290, eval_loss: 0.5296, eval_acc: 0.8566:  21%|[32m██        [0m| 683/3290 [04:11<15:42,  2.77it/s][A[2025-02-04 03:18:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 683/3290, eval_loss: 0.5296, eval_acc: 0.8566:  21%|[32m██        [0m| 684/3290 [04:12<15:07,  2.87it/s][A
step: 684/3290, eval_loss: 0.5298, eval_acc: 0.8566:  21%|[32m██        [0m| 684/3290 [04:12<15:07,  2.87it/s][A[2025-02-04 03:18:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 684/3290, eval_loss: 0.5298, eval_acc: 0.8566:  21%|[32m██        [0m| 685/3290 [04:12<15:28,  2.81it/s][A
step: 685/3290, eval_loss: 0.5298, eval_acc: 0.8566:  21%|[32m██        [0m| 685/3290 [04:12<15:28,  2.81it/s][A[2025-02-04 03:18:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 685/3290, eval_loss: 0.5298, eval_acc: 0.8566:  21%|[32m██        [0m| 686/3290 [04:12<16:53,  2.57it/s][A
step: 686/3290, eval_loss: 0.5299, eval_acc: 0.8566:  21%|[32m██        [0m| 686/3290 [04:12<16:53,  2.57it/s][A[2025-02-04 03:18:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 686/3290, eval_loss: 0.5299, eval_acc: 0.8566:  21%|[32m██        [0m| 687/3290 [04:13<16:46,  2.59it/s][A
step: 687/3290, eval_loss: 0.5302, eval_acc: 0.8565:  21%|[32m██        [0m| 687/3290 [04:13<16:46,  2.59it/s][A[2025-02-04 03:18:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 687/3290, eval_loss: 0.5302, eval_acc: 0.8565:  21%|[32m██        [0m| 688/3290 [04:13<16:05,  2.69it/s][A
step: 688/3290, eval_loss: 0.5314, eval_acc: 0.8562:  21%|[32m██        [0m| 688/3290 [04:13<16:05,  2.69it/s][A[2025-02-04 03:18:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 688/3290, eval_loss: 0.5314, eval_acc: 0.8562:  21%|[32m██        [0m| 689/3290 [04:14<16:13,  2.67it/s][A
step: 689/3290, eval_loss: 0.5320, eval_acc: 0.8561:  21%|[32m██        [0m| 689/3290 [04:14<16:13,  2.67it/s][A[2025-02-04 03:18:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 689/3290, eval_loss: 0.5320, eval_acc: 0.8561:  21%|[32m██        [0m| 690/3290 [04:14<16:19,  2.66it/s][A
step: 690/3290, eval_loss: 0.5329, eval_acc: 0.8558:  21%|[32m██        [0m| 690/3290 [04:14<16:19,  2.66it/s][A[2025-02-04 03:18:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 690/3290, eval_loss: 0.5329, eval_acc: 0.8558:  21%|[32m██        [0m| 691/3290 [04:14<15:59,  2.71it/s][A
step: 691/3290, eval_loss: 0.5327, eval_acc: 0.8558:  21%|[32m██        [0m| 691/3290 [04:14<15:59,  2.71it/s][A[2025-02-04 03:18:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 691/3290, eval_loss: 0.5327, eval_acc: 0.8558:  21%|[32m██        [0m| 692/3290 [04:15<17:06,  2.53it/s][A
step: 692/3290, eval_loss: 0.5325, eval_acc: 0.8559:  21%|[32m██        [0m| 692/3290 [04:15<17:06,  2.53it/s][A[2025-02-04 03:18:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 692/3290, eval_loss: 0.5325, eval_acc: 0.8559:  21%|[32m██        [0m| 693/3290 [04:15<16:43,  2.59it/s][A
step: 693/3290, eval_loss: 0.5320, eval_acc: 0.8560:  21%|[32m██        [0m| 693/3290 [04:15<16:43,  2.59it/s][A[2025-02-04 03:18:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 693/3290, eval_loss: 0.5320, eval_acc: 0.8560:  21%|[32m██        [0m| 694/3290 [04:15<15:55,  2.72it/s][A
step: 694/3290, eval_loss: 0.5315, eval_acc: 0.8561:  21%|[32m██        [0m| 694/3290 [04:15<15:55,  2.72it/s][A[2025-02-04 03:18:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 694/3290, eval_loss: 0.5315, eval_acc: 0.8561:  21%|[32m██        [0m| 695/3290 [04:16<14:42,  2.94it/s][A
step: 695/3290, eval_loss: 0.5312, eval_acc: 0.8562:  21%|[32m██        [0m| 695/3290 [04:16<14:42,  2.94it/s][A[2025-02-04 03:18:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 695/3290, eval_loss: 0.5312, eval_acc: 0.8562:  21%|[32m██        [0m| 696/3290 [04:16<16:10,  2.67it/s][A
step: 696/3290, eval_loss: 0.5316, eval_acc: 0.8561:  21%|[32m██        [0m| 696/3290 [04:16<16:10,  2.67it/s][A[2025-02-04 03:18:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 696/3290, eval_loss: 0.5316, eval_acc: 0.8561:  21%|[32m██        [0m| 697/3290 [04:17<16:11,  2.67it/s][A
step: 697/3290, eval_loss: 0.5313, eval_acc: 0.8562:  21%|[32m██        [0m| 697/3290 [04:17<16:11,  2.67it/s][A[2025-02-04 03:18:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 697/3290, eval_loss: 0.5313, eval_acc: 0.8562:  21%|[32m██        [0m| 698/3290 [04:17<16:32,  2.61it/s][A
step: 698/3290, eval_loss: 0.5312, eval_acc: 0.8563:  21%|[32m██        [0m| 698/3290 [04:17<16:32,  2.61it/s][A[2025-02-04 03:18:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 698/3290, eval_loss: 0.5312, eval_acc: 0.8563:  21%|[32m██        [0m| 699/3290 [04:18<19:04,  2.26it/s][A
step: 699/3290, eval_loss: 0.5312, eval_acc: 0.8562:  21%|[32m██        [0m| 699/3290 [04:18<19:04,  2.26it/s][A[2025-02-04 03:18:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 699/3290, eval_loss: 0.5312, eval_acc: 0.8562:  21%|[32m██▏       [0m| 700/3290 [04:18<16:44,  2.58it/s][A
step: 700/3290, eval_loss: 0.5312, eval_acc: 0.8563:  21%|[32m██▏       [0m| 700/3290 [04:18<16:44,  2.58it/s][A[2025-02-04 03:18:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 700/3290, eval_loss: 0.5312, eval_acc: 0.8563:  21%|[32m██▏       [0m| 701/3290 [04:18<17:20,  2.49it/s][A
step: 701/3290, eval_loss: 0.5313, eval_acc: 0.8562:  21%|[32m██▏       [0m| 701/3290 [04:18<17:20,  2.49it/s][A[2025-02-04 03:18:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 701/3290, eval_loss: 0.5313, eval_acc: 0.8562:  21%|[32m██▏       [0m| 702/3290 [04:19<17:31,  2.46it/s][A
step: 702/3290, eval_loss: 0.5317, eval_acc: 0.8561:  21%|[32m██▏       [0m| 702/3290 [04:19<17:31,  2.46it/s][A[2025-02-04 03:18:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 702/3290, eval_loss: 0.5317, eval_acc: 0.8561:  21%|[32m██▏       [0m| 703/3290 [04:19<15:44,  2.74it/s][A
step: 703/3290, eval_loss: 0.5320, eval_acc: 0.8560:  21%|[32m██▏       [0m| 703/3290 [04:19<15:44,  2.74it/s][A[2025-02-04 03:18:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 703/3290, eval_loss: 0.5320, eval_acc: 0.8560:  21%|[32m██▏       [0m| 704/3290 [04:19<14:55,  2.89it/s][A
step: 704/3290, eval_loss: 0.5322, eval_acc: 0.8559:  21%|[32m██▏       [0m| 704/3290 [04:19<14:55,  2.89it/s][A[2025-02-04 03:18:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 704/3290, eval_loss: 0.5322, eval_acc: 0.8559:  21%|[32m██▏       [0m| 705/3290 [04:19<14:19,  3.01it/s][A
step: 705/3290, eval_loss: 0.5322, eval_acc: 0.8560:  21%|[32m██▏       [0m| 705/3290 [04:19<14:19,  3.01it/s][A[2025-02-04 03:18:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 705/3290, eval_loss: 0.5322, eval_acc: 0.8560:  21%|[32m██▏       [0m| 706/3290 [04:20<15:29,  2.78it/s][A
step: 706/3290, eval_loss: 0.5326, eval_acc: 0.8559:  21%|[32m██▏       [0m| 706/3290 [04:20<15:29,  2.78it/s][A[2025-02-04 03:18:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 706/3290, eval_loss: 0.5326, eval_acc: 0.8559:  21%|[32m██▏       [0m| 707/3290 [04:20<16:20,  2.63it/s][A
step: 707/3290, eval_loss: 0.5333, eval_acc: 0.8557:  21%|[32m██▏       [0m| 707/3290 [04:20<16:20,  2.63it/s][A[2025-02-04 03:18:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 707/3290, eval_loss: 0.5333, eval_acc: 0.8557:  22%|[32m██▏       [0m| 708/3290 [04:21<16:31,  2.60it/s][A
step: 708/3290, eval_loss: 0.5334, eval_acc: 0.8556:  22%|[32m██▏       [0m| 708/3290 [04:21<16:31,  2.60it/s][A[2025-02-04 03:18:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 708/3290, eval_loss: 0.5334, eval_acc: 0.8556:  22%|[32m██▏       [0m| 709/3290 [04:21<17:36,  2.44it/s][A
step: 709/3290, eval_loss: 0.5337, eval_acc: 0.8556:  22%|[32m██▏       [0m| 709/3290 [04:21<17:36,  2.44it/s][A[2025-02-04 03:18:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 709/3290, eval_loss: 0.5337, eval_acc: 0.8556:  22%|[32m██▏       [0m| 710/3290 [04:22<17:49,  2.41it/s][A
step: 710/3290, eval_loss: 0.5337, eval_acc: 0.8556:  22%|[32m██▏       [0m| 710/3290 [04:22<17:49,  2.41it/s][A[2025-02-04 03:18:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 710/3290, eval_loss: 0.5337, eval_acc: 0.8556:  22%|[32m██▏       [0m| 711/3290 [04:22<20:05,  2.14it/s][A
step: 711/3290, eval_loss: 0.5332, eval_acc: 0.8557:  22%|[32m██▏       [0m| 711/3290 [04:22<20:05,  2.14it/s][A[2025-02-04 03:18:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 711/3290, eval_loss: 0.5332, eval_acc: 0.8557:  22%|[32m██▏       [0m| 712/3290 [04:23<21:00,  2.05it/s][A
step: 712/3290, eval_loss: 0.5329, eval_acc: 0.8558:  22%|[32m██▏       [0m| 712/3290 [04:23<21:00,  2.05it/s][A[2025-02-04 03:18:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 712/3290, eval_loss: 0.5329, eval_acc: 0.8558:  22%|[32m██▏       [0m| 713/3290 [04:23<18:55,  2.27it/s][A
step: 713/3290, eval_loss: 0.5328, eval_acc: 0.8558:  22%|[32m██▏       [0m| 713/3290 [04:23<18:55,  2.27it/s][A[2025-02-04 03:18:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 713/3290, eval_loss: 0.5328, eval_acc: 0.8558:  22%|[32m██▏       [0m| 714/3290 [04:23<17:43,  2.42it/s][A
step: 714/3290, eval_loss: 0.5331, eval_acc: 0.8557:  22%|[32m██▏       [0m| 714/3290 [04:23<17:43,  2.42it/s][A[2025-02-04 03:18:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 714/3290, eval_loss: 0.5331, eval_acc: 0.8557:  22%|[32m██▏       [0m| 715/3290 [04:24<16:11,  2.65it/s][A
step: 715/3290, eval_loss: 0.5329, eval_acc: 0.8557:  22%|[32m██▏       [0m| 715/3290 [04:24<16:11,  2.65it/s][A[2025-02-04 03:18:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 715/3290, eval_loss: 0.5329, eval_acc: 0.8557:  22%|[32m██▏       [0m| 716/3290 [04:24<15:25,  2.78it/s][A
step: 716/3290, eval_loss: 0.5338, eval_acc: 0.8555:  22%|[32m██▏       [0m| 716/3290 [04:24<15:25,  2.78it/s][A[2025-02-04 03:18:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 716/3290, eval_loss: 0.5338, eval_acc: 0.8555:  22%|[32m██▏       [0m| 717/3290 [04:24<14:31,  2.95it/s][A
step: 717/3290, eval_loss: 0.5341, eval_acc: 0.8555:  22%|[32m██▏       [0m| 717/3290 [04:24<14:31,  2.95it/s][A[2025-02-04 03:18:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 717/3290, eval_loss: 0.5341, eval_acc: 0.8555:  22%|[32m██▏       [0m| 718/3290 [04:25<15:21,  2.79it/s][A
step: 718/3290, eval_loss: 0.5342, eval_acc: 0.8554:  22%|[32m██▏       [0m| 718/3290 [04:25<15:21,  2.79it/s][A[2025-02-04 03:18:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 718/3290, eval_loss: 0.5342, eval_acc: 0.8554:  22%|[32m██▏       [0m| 719/3290 [04:25<15:24,  2.78it/s][A
step: 719/3290, eval_loss: 0.5338, eval_acc: 0.8555:  22%|[32m██▏       [0m| 719/3290 [04:25<15:24,  2.78it/s][A[2025-02-04 03:18:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 719/3290, eval_loss: 0.5338, eval_acc: 0.8555:  22%|[32m██▏       [0m| 720/3290 [04:25<14:58,  2.86it/s][A
step: 720/3290, eval_loss: 0.5339, eval_acc: 0.8555:  22%|[32m██▏       [0m| 720/3290 [04:25<14:58,  2.86it/s][A[2025-02-04 03:18:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 720/3290, eval_loss: 0.5339, eval_acc: 0.8555:  22%|[32m██▏       [0m| 721/3290 [04:26<15:28,  2.77it/s][A
step: 721/3290, eval_loss: 0.5334, eval_acc: 0.8556:  22%|[32m██▏       [0m| 721/3290 [04:26<15:28,  2.77it/s][A[2025-02-04 03:18:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 721/3290, eval_loss: 0.5334, eval_acc: 0.8556:  22%|[32m██▏       [0m| 722/3290 [04:26<15:57,  2.68it/s][A
step: 722/3290, eval_loss: 0.5331, eval_acc: 0.8557:  22%|[32m██▏       [0m| 722/3290 [04:26<15:57,  2.68it/s][A[2025-02-04 03:18:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 722/3290, eval_loss: 0.5331, eval_acc: 0.8557:  22%|[32m██▏       [0m| 723/3290 [04:27<16:12,  2.64it/s][A
step: 723/3290, eval_loss: 0.5328, eval_acc: 0.8558:  22%|[32m██▏       [0m| 723/3290 [04:27<16:12,  2.64it/s][A[2025-02-04 03:18:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 723/3290, eval_loss: 0.5328, eval_acc: 0.8558:  22%|[32m██▏       [0m| 724/3290 [04:27<14:51,  2.88it/s][A
step: 724/3290, eval_loss: 0.5330, eval_acc: 0.8558:  22%|[32m██▏       [0m| 724/3290 [04:27<14:51,  2.88it/s][A[2025-02-04 03:18:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 724/3290, eval_loss: 0.5330, eval_acc: 0.8558:  22%|[32m██▏       [0m| 725/3290 [04:28<18:57,  2.26it/s][A
step: 725/3290, eval_loss: 0.5331, eval_acc: 0.8557:  22%|[32m██▏       [0m| 725/3290 [04:28<18:57,  2.26it/s][A[2025-02-04 03:18:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 725/3290, eval_loss: 0.5331, eval_acc: 0.8557:  22%|[32m██▏       [0m| 726/3290 [04:28<17:56,  2.38it/s][A
step: 726/3290, eval_loss: 0.5327, eval_acc: 0.8558:  22%|[32m██▏       [0m| 726/3290 [04:28<17:56,  2.38it/s][A[2025-02-04 03:18:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 726/3290, eval_loss: 0.5327, eval_acc: 0.8558:  22%|[32m██▏       [0m| 727/3290 [04:28<17:34,  2.43it/s][A
step: 727/3290, eval_loss: 0.5335, eval_acc: 0.8557:  22%|[32m██▏       [0m| 727/3290 [04:28<17:34,  2.43it/s][A[2025-02-04 03:18:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 727/3290, eval_loss: 0.5335, eval_acc: 0.8557:  22%|[32m██▏       [0m| 728/3290 [04:29<18:52,  2.26it/s][A
step: 728/3290, eval_loss: 0.5335, eval_acc: 0.8556:  22%|[32m██▏       [0m| 728/3290 [04:29<18:52,  2.26it/s][A[2025-02-04 03:18:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 728/3290, eval_loss: 0.5335, eval_acc: 0.8556:  22%|[32m██▏       [0m| 729/3290 [04:29<19:19,  2.21it/s][A
step: 729/3290, eval_loss: 0.5330, eval_acc: 0.8558:  22%|[32m██▏       [0m| 729/3290 [04:29<19:19,  2.21it/s][A[2025-02-04 03:18:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 729/3290, eval_loss: 0.5330, eval_acc: 0.8558:  22%|[32m██▏       [0m| 730/3290 [04:30<18:50,  2.26it/s][A
step: 730/3290, eval_loss: 0.5333, eval_acc: 0.8557:  22%|[32m██▏       [0m| 730/3290 [04:30<18:50,  2.26it/s][A[2025-02-04 03:18:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 730/3290, eval_loss: 0.5333, eval_acc: 0.8557:  22%|[32m██▏       [0m| 731/3290 [04:30<17:34,  2.43it/s][A
step: 731/3290, eval_loss: 0.5329, eval_acc: 0.8558:  22%|[32m██▏       [0m| 731/3290 [04:30<17:34,  2.43it/s][A[2025-02-04 03:18:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 731/3290, eval_loss: 0.5329, eval_acc: 0.8558:  22%|[32m██▏       [0m| 732/3290 [04:30<16:27,  2.59it/s][A
step: 732/3290, eval_loss: 0.5332, eval_acc: 0.8557:  22%|[32m██▏       [0m| 732/3290 [04:30<16:27,  2.59it/s][A[2025-02-04 03:18:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 732/3290, eval_loss: 0.5332, eval_acc: 0.8557:  22%|[32m██▏       [0m| 733/3290 [04:31<14:41,  2.90it/s][A
step: 733/3290, eval_loss: 0.5329, eval_acc: 0.8558:  22%|[32m██▏       [0m| 733/3290 [04:31<14:41,  2.90it/s][A[2025-02-04 03:18:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 733/3290, eval_loss: 0.5329, eval_acc: 0.8558:  22%|[32m██▏       [0m| 734/3290 [04:31<15:21,  2.77it/s][A
step: 734/3290, eval_loss: 0.5328, eval_acc: 0.8558:  22%|[32m██▏       [0m| 734/3290 [04:31<15:21,  2.77it/s][A[2025-02-04 03:18:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 734/3290, eval_loss: 0.5328, eval_acc: 0.8558:  22%|[32m██▏       [0m| 735/3290 [04:31<15:10,  2.81it/s][A
step: 735/3290, eval_loss: 0.5324, eval_acc: 0.8560:  22%|[32m██▏       [0m| 735/3290 [04:31<15:10,  2.81it/s][A[2025-02-04 03:18:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 735/3290, eval_loss: 0.5324, eval_acc: 0.8560:  22%|[32m██▏       [0m| 736/3290 [04:32<14:41,  2.90it/s][A
step: 736/3290, eval_loss: 0.5323, eval_acc: 0.8560:  22%|[32m██▏       [0m| 736/3290 [04:32<14:41,  2.90it/s][A[2025-02-04 03:18:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 736/3290, eval_loss: 0.5323, eval_acc: 0.8560:  22%|[32m██▏       [0m| 737/3290 [04:32<13:41,  3.11it/s][A
step: 737/3290, eval_loss: 0.5329, eval_acc: 0.8558:  22%|[32m██▏       [0m| 737/3290 [04:32<13:41,  3.11it/s][A[2025-02-04 03:18:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 737/3290, eval_loss: 0.5329, eval_acc: 0.8558:  22%|[32m██▏       [0m| 738/3290 [04:32<13:50,  3.07it/s][A
step: 738/3290, eval_loss: 0.5328, eval_acc: 0.8558:  22%|[32m██▏       [0m| 738/3290 [04:32<13:50,  3.07it/s][A[2025-02-04 03:18:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 738/3290, eval_loss: 0.5328, eval_acc: 0.8558:  22%|[32m██▏       [0m| 739/3290 [04:33<13:37,  3.12it/s][A
step: 739/3290, eval_loss: 0.5326, eval_acc: 0.8558:  22%|[32m██▏       [0m| 739/3290 [04:33<13:37,  3.12it/s][A[2025-02-04 03:18:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 739/3290, eval_loss: 0.5326, eval_acc: 0.8558:  22%|[32m██▏       [0m| 740/3290 [04:33<14:26,  2.94it/s][A
step: 740/3290, eval_loss: 0.5328, eval_acc: 0.8558:  22%|[32m██▏       [0m| 740/3290 [04:33<14:26,  2.94it/s][A[2025-02-04 03:18:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 740/3290, eval_loss: 0.5328, eval_acc: 0.8558:  23%|[32m██▎       [0m| 741/3290 [04:33<15:46,  2.69it/s][A
step: 741/3290, eval_loss: 0.5330, eval_acc: 0.8557:  23%|[32m██▎       [0m| 741/3290 [04:33<15:46,  2.69it/s][A[2025-02-04 03:18:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 741/3290, eval_loss: 0.5330, eval_acc: 0.8557:  23%|[32m██▎       [0m| 742/3290 [04:34<16:34,  2.56it/s][A
step: 742/3290, eval_loss: 0.5331, eval_acc: 0.8558:  23%|[32m██▎       [0m| 742/3290 [04:34<16:34,  2.56it/s][A[2025-02-04 03:18:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 742/3290, eval_loss: 0.5331, eval_acc: 0.8558:  23%|[32m██▎       [0m| 743/3290 [04:34<17:06,  2.48it/s][A
step: 743/3290, eval_loss: 0.5326, eval_acc: 0.8559:  23%|[32m██▎       [0m| 743/3290 [04:34<17:06,  2.48it/s][A[2025-02-04 03:18:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 743/3290, eval_loss: 0.5326, eval_acc: 0.8559:  23%|[32m██▎       [0m| 744/3290 [04:35<17:08,  2.47it/s][A
step: 744/3290, eval_loss: 0.5339, eval_acc: 0.8558:  23%|[32m██▎       [0m| 744/3290 [04:35<17:08,  2.47it/s][A[2025-02-04 03:18:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 744/3290, eval_loss: 0.5339, eval_acc: 0.8558:  23%|[32m██▎       [0m| 745/3290 [04:35<17:41,  2.40it/s][A
step: 745/3290, eval_loss: 0.5335, eval_acc: 0.8559:  23%|[32m██▎       [0m| 745/3290 [04:35<17:41,  2.40it/s][A[2025-02-04 03:18:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 745/3290, eval_loss: 0.5335, eval_acc: 0.8559:  23%|[32m██▎       [0m| 746/3290 [04:35<15:35,  2.72it/s][A
step: 746/3290, eval_loss: 0.5335, eval_acc: 0.8559:  23%|[32m██▎       [0m| 746/3290 [04:35<15:35,  2.72it/s][A[2025-02-04 03:18:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 746/3290, eval_loss: 0.5335, eval_acc: 0.8559:  23%|[32m██▎       [0m| 747/3290 [04:36<15:10,  2.79it/s][A
step: 747/3290, eval_loss: 0.5331, eval_acc: 0.8560:  23%|[32m██▎       [0m| 747/3290 [04:36<15:10,  2.79it/s][A[2025-02-04 03:18:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 747/3290, eval_loss: 0.5331, eval_acc: 0.8560:  23%|[32m██▎       [0m| 748/3290 [04:36<15:50,  2.67it/s][A
step: 748/3290, eval_loss: 0.5331, eval_acc: 0.8560:  23%|[32m██▎       [0m| 748/3290 [04:36<15:50,  2.67it/s][A[2025-02-04 03:18:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 748/3290, eval_loss: 0.5331, eval_acc: 0.8560:  23%|[32m██▎       [0m| 749/3290 [04:37<16:12,  2.61it/s][A
step: 749/3290, eval_loss: 0.5325, eval_acc: 0.8561:  23%|[32m██▎       [0m| 749/3290 [04:37<16:12,  2.61it/s][A[2025-02-04 03:18:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 749/3290, eval_loss: 0.5325, eval_acc: 0.8561:  23%|[32m██▎       [0m| 750/3290 [04:37<15:19,  2.76it/s][A
step: 750/3290, eval_loss: 0.5320, eval_acc: 0.8562:  23%|[32m██▎       [0m| 750/3290 [04:37<15:19,  2.76it/s][A[2025-02-04 03:18:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 750/3290, eval_loss: 0.5320, eval_acc: 0.8562:  23%|[32m██▎       [0m| 751/3290 [04:37<16:05,  2.63it/s][A
step: 751/3290, eval_loss: 0.5316, eval_acc: 0.8564:  23%|[32m██▎       [0m| 751/3290 [04:37<16:05,  2.63it/s][A[2025-02-04 03:18:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 751/3290, eval_loss: 0.5316, eval_acc: 0.8564:  23%|[32m██▎       [0m| 752/3290 [04:38<15:05,  2.80it/s][A
step: 752/3290, eval_loss: 0.5310, eval_acc: 0.8565:  23%|[32m██▎       [0m| 752/3290 [04:38<15:05,  2.80it/s][A[2025-02-04 03:18:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 752/3290, eval_loss: 0.5310, eval_acc: 0.8565:  23%|[32m██▎       [0m| 753/3290 [04:38<14:58,  2.83it/s][A
step: 753/3290, eval_loss: 0.5312, eval_acc: 0.8565:  23%|[32m██▎       [0m| 753/3290 [04:38<14:58,  2.83it/s][A[2025-02-04 03:18:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 753/3290, eval_loss: 0.5312, eval_acc: 0.8565:  23%|[32m██▎       [0m| 754/3290 [04:38<14:12,  2.97it/s][A
step: 754/3290, eval_loss: 0.5313, eval_acc: 0.8563:  23%|[32m██▎       [0m| 754/3290 [04:38<14:12,  2.97it/s][A[2025-02-04 03:18:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 754/3290, eval_loss: 0.5313, eval_acc: 0.8563:  23%|[32m██▎       [0m| 755/3290 [04:39<13:14,  3.19it/s][A
step: 755/3290, eval_loss: 0.5311, eval_acc: 0.8564:  23%|[32m██▎       [0m| 755/3290 [04:39<13:14,  3.19it/s][A[2025-02-04 03:18:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 755/3290, eval_loss: 0.5311, eval_acc: 0.8564:  23%|[32m██▎       [0m| 756/3290 [04:39<13:14,  3.19it/s][A
step: 756/3290, eval_loss: 0.5310, eval_acc: 0.8564:  23%|[32m██▎       [0m| 756/3290 [04:39<13:14,  3.19it/s][A[2025-02-04 03:18:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 756/3290, eval_loss: 0.5310, eval_acc: 0.8564:  23%|[32m██▎       [0m| 757/3290 [04:39<13:42,  3.08it/s][A
step: 757/3290, eval_loss: 0.5309, eval_acc: 0.8564:  23%|[32m██▎       [0m| 757/3290 [04:39<13:42,  3.08it/s][A[2025-02-04 03:18:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 757/3290, eval_loss: 0.5309, eval_acc: 0.8564:  23%|[32m██▎       [0m| 758/3290 [04:39<13:47,  3.06it/s][A
step: 758/3290, eval_loss: 0.5315, eval_acc: 0.8563:  23%|[32m██▎       [0m| 758/3290 [04:39<13:47,  3.06it/s][A[2025-02-04 03:18:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 758/3290, eval_loss: 0.5315, eval_acc: 0.8563:  23%|[32m██▎       [0m| 759/3290 [04:40<15:13,  2.77it/s][A
step: 759/3290, eval_loss: 0.5322, eval_acc: 0.8562:  23%|[32m██▎       [0m| 759/3290 [04:40<15:13,  2.77it/s][A[2025-02-04 03:18:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 759/3290, eval_loss: 0.5322, eval_acc: 0.8562:  23%|[32m██▎       [0m| 760/3290 [04:40<16:10,  2.61it/s][A
step: 760/3290, eval_loss: 0.5321, eval_acc: 0.8561:  23%|[32m██▎       [0m| 760/3290 [04:40<16:10,  2.61it/s][A[2025-02-04 03:18:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 760/3290, eval_loss: 0.5321, eval_acc: 0.8561:  23%|[32m██▎       [0m| 761/3290 [04:41<16:41,  2.53it/s][A
step: 761/3290, eval_loss: 0.5329, eval_acc: 0.8560:  23%|[32m██▎       [0m| 761/3290 [04:41<16:41,  2.53it/s][A[2025-02-04 03:18:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 761/3290, eval_loss: 0.5329, eval_acc: 0.8560:  23%|[32m██▎       [0m| 762/3290 [04:41<15:50,  2.66it/s][A
step: 762/3290, eval_loss: 0.5341, eval_acc: 0.8556:  23%|[32m██▎       [0m| 762/3290 [04:41<15:50,  2.66it/s][A[2025-02-04 03:18:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 762/3290, eval_loss: 0.5341, eval_acc: 0.8556:  23%|[32m██▎       [0m| 763/3290 [04:41<15:40,  2.69it/s][A
step: 763/3290, eval_loss: 0.5342, eval_acc: 0.8555:  23%|[32m██▎       [0m| 763/3290 [04:41<15:40,  2.69it/s][A[2025-02-04 03:18:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 763/3290, eval_loss: 0.5342, eval_acc: 0.8555:  23%|[32m██▎       [0m| 764/3290 [04:42<15:29,  2.72it/s][A
step: 764/3290, eval_loss: 0.5338, eval_acc: 0.8556:  23%|[32m██▎       [0m| 764/3290 [04:42<15:29,  2.72it/s][A[2025-02-04 03:18:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 764/3290, eval_loss: 0.5338, eval_acc: 0.8556:  23%|[32m██▎       [0m| 765/3290 [04:42<15:40,  2.69it/s][A
step: 765/3290, eval_loss: 0.5341, eval_acc: 0.8554:  23%|[32m██▎       [0m| 765/3290 [04:42<15:40,  2.69it/s][A[2025-02-04 03:18:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 765/3290, eval_loss: 0.5341, eval_acc: 0.8554:  23%|[32m██▎       [0m| 766/3290 [04:43<14:49,  2.84it/s][A
step: 766/3290, eval_loss: 0.5343, eval_acc: 0.8554:  23%|[32m██▎       [0m| 766/3290 [04:43<14:49,  2.84it/s][A[2025-02-04 03:18:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 766/3290, eval_loss: 0.5343, eval_acc: 0.8554:  23%|[32m██▎       [0m| 767/3290 [04:43<14:15,  2.95it/s][A
step: 767/3290, eval_loss: 0.5344, eval_acc: 0.8554:  23%|[32m██▎       [0m| 767/3290 [04:43<14:15,  2.95it/s][A[2025-02-04 03:18:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 767/3290, eval_loss: 0.5344, eval_acc: 0.8554:  23%|[32m██▎       [0m| 768/3290 [04:43<14:36,  2.88it/s][A
step: 768/3290, eval_loss: 0.5350, eval_acc: 0.8552:  23%|[32m██▎       [0m| 768/3290 [04:43<14:36,  2.88it/s][A[2025-02-04 03:18:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 768/3290, eval_loss: 0.5350, eval_acc: 0.8552:  23%|[32m██▎       [0m| 769/3290 [04:44<14:27,  2.91it/s][A
step: 769/3290, eval_loss: 0.5356, eval_acc: 0.8550:  23%|[32m██▎       [0m| 769/3290 [04:44<14:27,  2.91it/s][A[2025-02-04 03:18:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 769/3290, eval_loss: 0.5356, eval_acc: 0.8550:  23%|[32m██▎       [0m| 770/3290 [04:44<14:40,  2.86it/s][A
step: 770/3290, eval_loss: 0.5358, eval_acc: 0.8548:  23%|[32m██▎       [0m| 770/3290 [04:44<14:40,  2.86it/s][A[2025-02-04 03:18:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 770/3290, eval_loss: 0.5358, eval_acc: 0.8548:  23%|[32m██▎       [0m| 771/3290 [04:44<13:57,  3.01it/s][A
step: 771/3290, eval_loss: 0.5358, eval_acc: 0.8548:  23%|[32m██▎       [0m| 771/3290 [04:44<13:57,  3.01it/s][A[2025-02-04 03:18:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 771/3290, eval_loss: 0.5358, eval_acc: 0.8548:  23%|[32m██▎       [0m| 772/3290 [04:45<14:39,  2.86it/s][A
step: 772/3290, eval_loss: 0.5368, eval_acc: 0.8546:  23%|[32m██▎       [0m| 772/3290 [04:45<14:39,  2.86it/s][A[2025-02-04 03:18:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 772/3290, eval_loss: 0.5368, eval_acc: 0.8546:  23%|[32m██▎       [0m| 773/3290 [04:45<15:11,  2.76it/s][A
step: 773/3290, eval_loss: 0.5381, eval_acc: 0.8542:  23%|[32m██▎       [0m| 773/3290 [04:45<15:11,  2.76it/s][A[2025-02-04 03:18:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 773/3290, eval_loss: 0.5381, eval_acc: 0.8542:  24%|[32m██▎       [0m| 774/3290 [04:45<14:40,  2.86it/s][A
step: 774/3290, eval_loss: 0.5381, eval_acc: 0.8542:  24%|[32m██▎       [0m| 774/3290 [04:45<14:40,  2.86it/s][A[2025-02-04 03:18:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 774/3290, eval_loss: 0.5381, eval_acc: 0.8542:  24%|[32m██▎       [0m| 775/3290 [04:46<14:05,  2.97it/s][A
step: 775/3290, eval_loss: 0.5389, eval_acc: 0.8540:  24%|[32m██▎       [0m| 775/3290 [04:46<14:05,  2.97it/s][A[2025-02-04 03:18:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 775/3290, eval_loss: 0.5389, eval_acc: 0.8540:  24%|[32m██▎       [0m| 776/3290 [04:46<15:24,  2.72it/s][A
step: 776/3290, eval_loss: 0.5387, eval_acc: 0.8540:  24%|[32m██▎       [0m| 776/3290 [04:46<15:24,  2.72it/s][A[2025-02-04 03:18:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 776/3290, eval_loss: 0.5387, eval_acc: 0.8540:  24%|[32m██▎       [0m| 777/3290 [04:46<14:34,  2.87it/s][A
step: 777/3290, eval_loss: 0.5390, eval_acc: 0.8540:  24%|[32m██▎       [0m| 777/3290 [04:46<14:34,  2.87it/s][A[2025-02-04 03:18:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 777/3290, eval_loss: 0.5390, eval_acc: 0.8540:  24%|[32m██▎       [0m| 778/3290 [04:47<14:18,  2.93it/s][A
step: 778/3290, eval_loss: 0.5398, eval_acc: 0.8537:  24%|[32m██▎       [0m| 778/3290 [04:47<14:18,  2.93it/s][A[2025-02-04 03:18:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 778/3290, eval_loss: 0.5398, eval_acc: 0.8537:  24%|[32m██▎       [0m| 779/3290 [04:47<14:57,  2.80it/s][A
step: 779/3290, eval_loss: 0.5395, eval_acc: 0.8537:  24%|[32m██▎       [0m| 779/3290 [04:47<14:57,  2.80it/s][A[2025-02-04 03:18:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 779/3290, eval_loss: 0.5395, eval_acc: 0.8537:  24%|[32m██▎       [0m| 780/3290 [04:47<14:31,  2.88it/s][A
step: 780/3290, eval_loss: 0.5396, eval_acc: 0.8537:  24%|[32m██▎       [0m| 780/3290 [04:47<14:31,  2.88it/s][A[2025-02-04 03:18:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 780/3290, eval_loss: 0.5396, eval_acc: 0.8537:  24%|[32m██▎       [0m| 781/3290 [04:48<14:18,  2.92it/s][A
step: 781/3290, eval_loss: 0.5406, eval_acc: 0.8534:  24%|[32m██▎       [0m| 781/3290 [04:48<14:18,  2.92it/s][A[2025-02-04 03:18:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 781/3290, eval_loss: 0.5406, eval_acc: 0.8534:  24%|[32m██▍       [0m| 782/3290 [04:48<13:47,  3.03it/s][A
step: 782/3290, eval_loss: 0.5407, eval_acc: 0.8533:  24%|[32m██▍       [0m| 782/3290 [04:48<13:47,  3.03it/s][A[2025-02-04 03:18:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 782/3290, eval_loss: 0.5407, eval_acc: 0.8533:  24%|[32m██▍       [0m| 783/3290 [04:48<12:44,  3.28it/s][A
step: 783/3290, eval_loss: 0.5422, eval_acc: 0.8531:  24%|[32m██▍       [0m| 783/3290 [04:48<12:44,  3.28it/s][A[2025-02-04 03:18:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 783/3290, eval_loss: 0.5422, eval_acc: 0.8531:  24%|[32m██▍       [0m| 784/3290 [04:49<12:17,  3.40it/s][A
step: 784/3290, eval_loss: 0.5431, eval_acc: 0.8528:  24%|[32m██▍       [0m| 784/3290 [04:49<12:17,  3.40it/s][A[2025-02-04 03:18:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 784/3290, eval_loss: 0.5431, eval_acc: 0.8528:  24%|[32m██▍       [0m| 785/3290 [04:49<13:32,  3.08it/s][A
step: 785/3290, eval_loss: 0.5434, eval_acc: 0.8527:  24%|[32m██▍       [0m| 785/3290 [04:49<13:32,  3.08it/s][A[2025-02-04 03:18:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 785/3290, eval_loss: 0.5434, eval_acc: 0.8527:  24%|[32m██▍       [0m| 786/3290 [04:49<13:09,  3.17it/s][A
step: 786/3290, eval_loss: 0.5441, eval_acc: 0.8525:  24%|[32m██▍       [0m| 786/3290 [04:49<13:09,  3.17it/s][A[2025-02-04 03:18:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 786/3290, eval_loss: 0.5441, eval_acc: 0.8525:  24%|[32m██▍       [0m| 787/3290 [04:49<12:18,  3.39it/s][A
step: 787/3290, eval_loss: 0.5442, eval_acc: 0.8525:  24%|[32m██▍       [0m| 787/3290 [04:49<12:18,  3.39it/s][A[2025-02-04 03:18:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 787/3290, eval_loss: 0.5442, eval_acc: 0.8525:  24%|[32m██▍       [0m| 788/3290 [04:50<12:49,  3.25it/s][A
step: 788/3290, eval_loss: 0.5443, eval_acc: 0.8524:  24%|[32m██▍       [0m| 788/3290 [04:50<12:49,  3.25it/s][A[2025-02-04 03:18:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 788/3290, eval_loss: 0.5443, eval_acc: 0.8524:  24%|[32m██▍       [0m| 789/3290 [04:50<13:10,  3.16it/s][A
step: 789/3290, eval_loss: 0.5444, eval_acc: 0.8524:  24%|[32m██▍       [0m| 789/3290 [04:50<13:10,  3.16it/s][A[2025-02-04 03:18:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 789/3290, eval_loss: 0.5444, eval_acc: 0.8524:  24%|[32m██▍       [0m| 790/3290 [04:50<12:40,  3.29it/s][A
step: 790/3290, eval_loss: 0.5446, eval_acc: 0.8523:  24%|[32m██▍       [0m| 790/3290 [04:50<12:40,  3.29it/s][A[2025-02-04 03:18:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 790/3290, eval_loss: 0.5446, eval_acc: 0.8523:  24%|[32m██▍       [0m| 791/3290 [04:51<13:36,  3.06it/s][A
step: 791/3290, eval_loss: 0.5449, eval_acc: 0.8522:  24%|[32m██▍       [0m| 791/3290 [04:51<13:36,  3.06it/s][A[2025-02-04 03:18:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 791/3290, eval_loss: 0.5449, eval_acc: 0.8522:  24%|[32m██▍       [0m| 792/3290 [04:51<14:29,  2.87it/s][A
step: 792/3290, eval_loss: 0.5456, eval_acc: 0.8520:  24%|[32m██▍       [0m| 792/3290 [04:51<14:29,  2.87it/s][A[2025-02-04 03:18:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 792/3290, eval_loss: 0.5456, eval_acc: 0.8520:  24%|[32m██▍       [0m| 793/3290 [04:52<16:00,  2.60it/s][A
step: 793/3290, eval_loss: 0.5463, eval_acc: 0.8519:  24%|[32m██▍       [0m| 793/3290 [04:52<16:00,  2.60it/s][A[2025-02-04 03:18:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 793/3290, eval_loss: 0.5463, eval_acc: 0.8519:  24%|[32m██▍       [0m| 794/3290 [04:52<16:10,  2.57it/s][A
step: 794/3290, eval_loss: 0.5466, eval_acc: 0.8518:  24%|[32m██▍       [0m| 794/3290 [04:52<16:10,  2.57it/s][A[2025-02-04 03:18:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 794/3290, eval_loss: 0.5466, eval_acc: 0.8518:  24%|[32m██▍       [0m| 795/3290 [04:52<14:31,  2.86it/s][A
step: 795/3290, eval_loss: 0.5467, eval_acc: 0.8518:  24%|[32m██▍       [0m| 795/3290 [04:52<14:31,  2.86it/s][A[2025-02-04 03:18:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 795/3290, eval_loss: 0.5467, eval_acc: 0.8518:  24%|[32m██▍       [0m| 796/3290 [04:53<14:21,  2.90it/s][A
step: 796/3290, eval_loss: 0.5477, eval_acc: 0.8516:  24%|[32m██▍       [0m| 796/3290 [04:53<14:21,  2.90it/s][A[2025-02-04 03:18:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 796/3290, eval_loss: 0.5477, eval_acc: 0.8516:  24%|[32m██▍       [0m| 797/3290 [04:53<14:25,  2.88it/s][A
step: 797/3290, eval_loss: 0.5478, eval_acc: 0.8516:  24%|[32m██▍       [0m| 797/3290 [04:53<14:25,  2.88it/s][A[2025-02-04 03:18:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 797/3290, eval_loss: 0.5478, eval_acc: 0.8516:  24%|[32m██▍       [0m| 798/3290 [04:53<14:39,  2.83it/s][A
step: 798/3290, eval_loss: 0.5487, eval_acc: 0.8514:  24%|[32m██▍       [0m| 798/3290 [04:53<14:39,  2.83it/s][A[2025-02-04 03:18:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 798/3290, eval_loss: 0.5487, eval_acc: 0.8514:  24%|[32m██▍       [0m| 799/3290 [04:54<14:37,  2.84it/s][A
step: 799/3290, eval_loss: 0.5496, eval_acc: 0.8512:  24%|[32m██▍       [0m| 799/3290 [04:54<14:37,  2.84it/s][A[2025-02-04 03:18:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 799/3290, eval_loss: 0.5496, eval_acc: 0.8512:  24%|[32m██▍       [0m| 800/3290 [04:54<15:09,  2.74it/s][A
step: 800/3290, eval_loss: 0.5498, eval_acc: 0.8511:  24%|[32m██▍       [0m| 800/3290 [04:54<15:09,  2.74it/s][A[2025-02-04 03:18:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 800/3290, eval_loss: 0.5498, eval_acc: 0.8511:  24%|[32m██▍       [0m| 801/3290 [04:54<14:32,  2.85it/s][A
step: 801/3290, eval_loss: 0.5507, eval_acc: 0.8508:  24%|[32m██▍       [0m| 801/3290 [04:54<14:32,  2.85it/s][A[2025-02-04 03:18:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 801/3290, eval_loss: 0.5507, eval_acc: 0.8508:  24%|[32m██▍       [0m| 802/3290 [04:55<13:32,  3.06it/s][A
step: 802/3290, eval_loss: 0.5508, eval_acc: 0.8508:  24%|[32m██▍       [0m| 802/3290 [04:55<13:32,  3.06it/s][A[2025-02-04 03:18:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 802/3290, eval_loss: 0.5508, eval_acc: 0.8508:  24%|[32m██▍       [0m| 803/3290 [04:55<12:48,  3.24it/s][A
step: 803/3290, eval_loss: 0.5513, eval_acc: 0.8507:  24%|[32m██▍       [0m| 803/3290 [04:55<12:48,  3.24it/s][A[2025-02-04 03:18:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 803/3290, eval_loss: 0.5513, eval_acc: 0.8507:  24%|[32m██▍       [0m| 804/3290 [04:55<13:26,  3.08it/s][A
step: 804/3290, eval_loss: 0.5515, eval_acc: 0.8507:  24%|[32m██▍       [0m| 804/3290 [04:55<13:26,  3.08it/s][A[2025-02-04 03:18:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 804/3290, eval_loss: 0.5515, eval_acc: 0.8507:  24%|[32m██▍       [0m| 805/3290 [04:56<13:04,  3.17it/s][A
step: 805/3290, eval_loss: 0.5520, eval_acc: 0.8506:  24%|[32m██▍       [0m| 805/3290 [04:56<13:04,  3.17it/s][A[2025-02-04 03:18:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 805/3290, eval_loss: 0.5520, eval_acc: 0.8506:  24%|[32m██▍       [0m| 806/3290 [04:56<14:40,  2.82it/s][A
step: 806/3290, eval_loss: 0.5527, eval_acc: 0.8504:  24%|[32m██▍       [0m| 806/3290 [04:56<14:40,  2.82it/s][A[2025-02-04 03:18:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 806/3290, eval_loss: 0.5527, eval_acc: 0.8504:  25%|[32m██▍       [0m| 807/3290 [04:57<16:07,  2.57it/s][A
step: 807/3290, eval_loss: 0.5536, eval_acc: 0.8502:  25%|[32m██▍       [0m| 807/3290 [04:57<16:07,  2.57it/s][A[2025-02-04 03:18:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 807/3290, eval_loss: 0.5536, eval_acc: 0.8502:  25%|[32m██▍       [0m| 808/3290 [04:57<14:32,  2.85it/s][A
step: 808/3290, eval_loss: 0.5539, eval_acc: 0.8501:  25%|[32m██▍       [0m| 808/3290 [04:57<14:32,  2.85it/s][A[2025-02-04 03:18:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 808/3290, eval_loss: 0.5539, eval_acc: 0.8501:  25%|[32m██▍       [0m| 809/3290 [04:57<14:58,  2.76it/s][A
step: 809/3290, eval_loss: 0.5538, eval_acc: 0.8501:  25%|[32m██▍       [0m| 809/3290 [04:57<14:58,  2.76it/s][A[2025-02-04 03:18:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 809/3290, eval_loss: 0.5538, eval_acc: 0.8501:  25%|[32m██▍       [0m| 810/3290 [04:58<14:38,  2.82it/s][A
step: 810/3290, eval_loss: 0.5549, eval_acc: 0.8498:  25%|[32m██▍       [0m| 810/3290 [04:58<14:38,  2.82it/s][A[2025-02-04 03:18:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 810/3290, eval_loss: 0.5549, eval_acc: 0.8498:  25%|[32m██▍       [0m| 811/3290 [04:58<14:07,  2.93it/s][A
step: 811/3290, eval_loss: 0.5556, eval_acc: 0.8497:  25%|[32m██▍       [0m| 811/3290 [04:58<14:07,  2.93it/s][A[2025-02-04 03:18:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 811/3290, eval_loss: 0.5556, eval_acc: 0.8497:  25%|[32m██▍       [0m| 812/3290 [04:58<14:42,  2.81it/s][A
step: 812/3290, eval_loss: 0.5554, eval_acc: 0.8497:  25%|[32m██▍       [0m| 812/3290 [04:58<14:42,  2.81it/s][A[2025-02-04 03:18:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 812/3290, eval_loss: 0.5554, eval_acc: 0.8497:  25%|[32m██▍       [0m| 813/3290 [04:59<14:57,  2.76it/s][A
step: 813/3290, eval_loss: 0.5553, eval_acc: 0.8498:  25%|[32m██▍       [0m| 813/3290 [04:59<14:57,  2.76it/s][A[2025-02-04 03:18:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 813/3290, eval_loss: 0.5553, eval_acc: 0.8498:  25%|[32m██▍       [0m| 814/3290 [04:59<14:20,  2.88it/s][A
step: 814/3290, eval_loss: 0.5555, eval_acc: 0.8497:  25%|[32m██▍       [0m| 814/3290 [04:59<14:20,  2.88it/s][A[2025-02-04 03:18:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 814/3290, eval_loss: 0.5555, eval_acc: 0.8497:  25%|[32m██▍       [0m| 815/3290 [04:59<14:55,  2.76it/s][A
step: 815/3290, eval_loss: 0.5557, eval_acc: 0.8496:  25%|[32m██▍       [0m| 815/3290 [04:59<14:55,  2.76it/s][A[2025-02-04 03:18:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 815/3290, eval_loss: 0.5557, eval_acc: 0.8496:  25%|[32m██▍       [0m| 816/3290 [05:00<14:49,  2.78it/s][A
step: 816/3290, eval_loss: 0.5555, eval_acc: 0.8496:  25%|[32m██▍       [0m| 816/3290 [05:00<14:49,  2.78it/s][A[2025-02-04 03:18:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 816/3290, eval_loss: 0.5555, eval_acc: 0.8496:  25%|[32m██▍       [0m| 817/3290 [05:00<13:38,  3.02it/s][A
step: 817/3290, eval_loss: 0.5550, eval_acc: 0.8497:  25%|[32m██▍       [0m| 817/3290 [05:00<13:38,  3.02it/s][A[2025-02-04 03:18:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 817/3290, eval_loss: 0.5550, eval_acc: 0.8497:  25%|[32m██▍       [0m| 818/3290 [05:00<13:59,  2.95it/s][A
step: 818/3290, eval_loss: 0.5556, eval_acc: 0.8496:  25%|[32m██▍       [0m| 818/3290 [05:00<13:59,  2.95it/s][A[2025-02-04 03:18:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 818/3290, eval_loss: 0.5556, eval_acc: 0.8496:  25%|[32m██▍       [0m| 819/3290 [05:01<13:49,  2.98it/s][A
step: 819/3290, eval_loss: 0.5558, eval_acc: 0.8496:  25%|[32m██▍       [0m| 819/3290 [05:01<13:49,  2.98it/s][A[2025-02-04 03:18:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 819/3290, eval_loss: 0.5558, eval_acc: 0.8496:  25%|[32m██▍       [0m| 820/3290 [05:01<14:14,  2.89it/s][A
step: 820/3290, eval_loss: 0.5561, eval_acc: 0.8495:  25%|[32m██▍       [0m| 820/3290 [05:01<14:14,  2.89it/s][A[2025-02-04 03:18:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 820/3290, eval_loss: 0.5561, eval_acc: 0.8495:  25%|[32m██▍       [0m| 821/3290 [05:02<16:07,  2.55it/s][A
step: 821/3290, eval_loss: 0.5565, eval_acc: 0.8494:  25%|[32m██▍       [0m| 821/3290 [05:02<16:07,  2.55it/s][A[2025-02-04 03:18:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 821/3290, eval_loss: 0.5565, eval_acc: 0.8494:  25%|[32m██▍       [0m| 822/3290 [05:02<18:30,  2.22it/s][A
step: 822/3290, eval_loss: 0.5569, eval_acc: 0.8493:  25%|[32m██▍       [0m| 822/3290 [05:02<18:30,  2.22it/s][A[2025-02-04 03:18:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 822/3290, eval_loss: 0.5569, eval_acc: 0.8493:  25%|[32m██▌       [0m| 823/3290 [05:02<17:19,  2.37it/s][A
step: 823/3290, eval_loss: 0.5567, eval_acc: 0.8493:  25%|[32m██▌       [0m| 823/3290 [05:02<17:19,  2.37it/s][A[2025-02-04 03:18:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 823/3290, eval_loss: 0.5567, eval_acc: 0.8493:  25%|[32m██▌       [0m| 824/3290 [05:03<16:45,  2.45it/s][A
step: 824/3290, eval_loss: 0.5566, eval_acc: 0.8494:  25%|[32m██▌       [0m| 824/3290 [05:03<16:45,  2.45it/s][A[2025-02-04 03:18:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 824/3290, eval_loss: 0.5566, eval_acc: 0.8494:  25%|[32m██▌       [0m| 825/3290 [05:03<16:28,  2.49it/s][A
step: 825/3290, eval_loss: 0.5566, eval_acc: 0.8494:  25%|[32m██▌       [0m| 825/3290 [05:03<16:28,  2.49it/s][A[2025-02-04 03:18:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 825/3290, eval_loss: 0.5566, eval_acc: 0.8494:  25%|[32m██▌       [0m| 826/3290 [05:04<16:21,  2.51it/s][A
step: 826/3290, eval_loss: 0.5566, eval_acc: 0.8494:  25%|[32m██▌       [0m| 826/3290 [05:04<16:21,  2.51it/s][A[2025-02-04 03:18:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 826/3290, eval_loss: 0.5566, eval_acc: 0.8494:  25%|[32m██▌       [0m| 827/3290 [05:04<16:10,  2.54it/s][A
step: 827/3290, eval_loss: 0.5566, eval_acc: 0.8494:  25%|[32m██▌       [0m| 827/3290 [05:04<16:10,  2.54it/s][A[2025-02-04 03:18:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 827/3290, eval_loss: 0.5566, eval_acc: 0.8494:  25%|[32m██▌       [0m| 828/3290 [05:05<17:54,  2.29it/s][A
step: 828/3290, eval_loss: 0.5569, eval_acc: 0.8493:  25%|[32m██▌       [0m| 828/3290 [05:05<17:54,  2.29it/s][A[2025-02-04 03:18:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 828/3290, eval_loss: 0.5569, eval_acc: 0.8493:  25%|[32m██▌       [0m| 829/3290 [05:05<18:14,  2.25it/s][A
step: 829/3290, eval_loss: 0.5571, eval_acc: 0.8492:  25%|[32m██▌       [0m| 829/3290 [05:05<18:14,  2.25it/s][A[2025-02-04 03:18:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 829/3290, eval_loss: 0.5571, eval_acc: 0.8492:  25%|[32m██▌       [0m| 830/3290 [05:05<18:42,  2.19it/s][A
step: 830/3290, eval_loss: 0.5579, eval_acc: 0.8490:  25%|[32m██▌       [0m| 830/3290 [05:05<18:42,  2.19it/s][A[2025-02-04 03:19:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 830/3290, eval_loss: 0.5579, eval_acc: 0.8490:  25%|[32m██▌       [0m| 831/3290 [05:06<17:37,  2.33it/s][A
step: 831/3290, eval_loss: 0.5578, eval_acc: 0.8491:  25%|[32m██▌       [0m| 831/3290 [05:06<17:37,  2.33it/s][A[2025-02-04 03:19:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 831/3290, eval_loss: 0.5578, eval_acc: 0.8491:  25%|[32m██▌       [0m| 832/3290 [05:06<15:36,  2.62it/s][A
step: 832/3290, eval_loss: 0.5579, eval_acc: 0.8490:  25%|[32m██▌       [0m| 832/3290 [05:06<15:36,  2.62it/s][A[2025-02-04 03:19:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 832/3290, eval_loss: 0.5579, eval_acc: 0.8490:  25%|[32m██▌       [0m| 833/3290 [05:07<15:53,  2.58it/s][A
step: 833/3290, eval_loss: 0.5580, eval_acc: 0.8490:  25%|[32m██▌       [0m| 833/3290 [05:07<15:53,  2.58it/s][A[2025-02-04 03:19:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 833/3290, eval_loss: 0.5580, eval_acc: 0.8490:  25%|[32m██▌       [0m| 834/3290 [05:07<16:16,  2.51it/s][A
step: 834/3290, eval_loss: 0.5575, eval_acc: 0.8490:  25%|[32m██▌       [0m| 834/3290 [05:07<16:16,  2.51it/s][A[2025-02-04 03:19:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 834/3290, eval_loss: 0.5575, eval_acc: 0.8490:  25%|[32m██▌       [0m| 835/3290 [05:07<16:28,  2.48it/s][A
step: 835/3290, eval_loss: 0.5582, eval_acc: 0.8489:  25%|[32m██▌       [0m| 835/3290 [05:07<16:28,  2.48it/s][A[2025-02-04 03:19:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 835/3290, eval_loss: 0.5582, eval_acc: 0.8489:  25%|[32m██▌       [0m| 836/3290 [05:08<17:38,  2.32it/s][A
step: 836/3290, eval_loss: 0.5587, eval_acc: 0.8487:  25%|[32m██▌       [0m| 836/3290 [05:08<17:38,  2.32it/s][A[2025-02-04 03:19:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 836/3290, eval_loss: 0.5587, eval_acc: 0.8487:  25%|[32m██▌       [0m| 837/3290 [05:08<17:12,  2.38it/s][A
step: 837/3290, eval_loss: 0.5592, eval_acc: 0.8485:  25%|[32m██▌       [0m| 837/3290 [05:08<17:12,  2.38it/s][A[2025-02-04 03:19:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 837/3290, eval_loss: 0.5592, eval_acc: 0.8485:  25%|[32m██▌       [0m| 838/3290 [05:09<15:28,  2.64it/s][A
step: 838/3290, eval_loss: 0.5588, eval_acc: 0.8486:  25%|[32m██▌       [0m| 838/3290 [05:09<15:28,  2.64it/s][A[2025-02-04 03:19:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 838/3290, eval_loss: 0.5588, eval_acc: 0.8486:  26%|[32m██▌       [0m| 839/3290 [05:09<14:03,  2.91it/s][A
step: 839/3290, eval_loss: 0.5590, eval_acc: 0.8486:  26%|[32m██▌       [0m| 839/3290 [05:09<14:03,  2.91it/s][A[2025-02-04 03:19:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 839/3290, eval_loss: 0.5590, eval_acc: 0.8486:  26%|[32m██▌       [0m| 840/3290 [05:09<14:57,  2.73it/s][A
step: 840/3290, eval_loss: 0.5585, eval_acc: 0.8487:  26%|[32m██▌       [0m| 840/3290 [05:09<14:57,  2.73it/s][A[2025-02-04 03:19:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 840/3290, eval_loss: 0.5585, eval_acc: 0.8487:  26%|[32m██▌       [0m| 841/3290 [05:10<16:57,  2.41it/s][A
step: 841/3290, eval_loss: 0.5580, eval_acc: 0.8488:  26%|[32m██▌       [0m| 841/3290 [05:10<16:57,  2.41it/s][A[2025-02-04 03:19:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 841/3290, eval_loss: 0.5580, eval_acc: 0.8488:  26%|[32m██▌       [0m| 842/3290 [05:10<16:57,  2.41it/s][A
step: 842/3290, eval_loss: 0.5576, eval_acc: 0.8490:  26%|[32m██▌       [0m| 842/3290 [05:10<16:57,  2.41it/s][A[2025-02-04 03:19:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 842/3290, eval_loss: 0.5576, eval_acc: 0.8490:  26%|[32m██▌       [0m| 843/3290 [05:10<15:23,  2.65it/s][A
step: 843/3290, eval_loss: 0.5576, eval_acc: 0.8489:  26%|[32m██▌       [0m| 843/3290 [05:10<15:23,  2.65it/s][A[2025-02-04 03:19:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 843/3290, eval_loss: 0.5576, eval_acc: 0.8489:  26%|[32m██▌       [0m| 844/3290 [05:11<14:43,  2.77it/s][A
step: 844/3290, eval_loss: 0.5577, eval_acc: 0.8489:  26%|[32m██▌       [0m| 844/3290 [05:11<14:43,  2.77it/s][A[2025-02-04 03:19:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 844/3290, eval_loss: 0.5577, eval_acc: 0.8489:  26%|[32m██▌       [0m| 845/3290 [05:11<14:15,  2.86it/s][A
step: 845/3290, eval_loss: 0.5583, eval_acc: 0.8488:  26%|[32m██▌       [0m| 845/3290 [05:11<14:15,  2.86it/s][A[2025-02-04 03:19:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 845/3290, eval_loss: 0.5583, eval_acc: 0.8488:  26%|[32m██▌       [0m| 846/3290 [05:11<14:32,  2.80it/s][A
step: 846/3290, eval_loss: 0.5587, eval_acc: 0.8487:  26%|[32m██▌       [0m| 846/3290 [05:11<14:32,  2.80it/s][A[2025-02-04 03:19:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 846/3290, eval_loss: 0.5587, eval_acc: 0.8487:  26%|[32m██▌       [0m| 847/3290 [05:12<14:38,  2.78it/s][A
step: 847/3290, eval_loss: 0.5585, eval_acc: 0.8488:  26%|[32m██▌       [0m| 847/3290 [05:12<14:38,  2.78it/s][A[2025-02-04 03:19:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 847/3290, eval_loss: 0.5585, eval_acc: 0.8488:  26%|[32m██▌       [0m| 848/3290 [05:12<16:04,  2.53it/s][A
step: 848/3290, eval_loss: 0.5583, eval_acc: 0.8488:  26%|[32m██▌       [0m| 848/3290 [05:12<16:04,  2.53it/s][A[2025-02-04 03:19:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 848/3290, eval_loss: 0.5583, eval_acc: 0.8488:  26%|[32m██▌       [0m| 849/3290 [05:13<16:40,  2.44it/s][A
step: 849/3290, eval_loss: 0.5589, eval_acc: 0.8487:  26%|[32m██▌       [0m| 849/3290 [05:13<16:40,  2.44it/s][A[2025-02-04 03:19:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 849/3290, eval_loss: 0.5589, eval_acc: 0.8487:  26%|[32m██▌       [0m| 850/3290 [05:13<17:57,  2.26it/s][A
step: 850/3290, eval_loss: 0.5587, eval_acc: 0.8487:  26%|[32m██▌       [0m| 850/3290 [05:13<17:57,  2.26it/s][A[2025-02-04 03:19:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 850/3290, eval_loss: 0.5587, eval_acc: 0.8487:  26%|[32m██▌       [0m| 851/3290 [05:14<15:42,  2.59it/s][A
step: 851/3290, eval_loss: 0.5585, eval_acc: 0.8488:  26%|[32m██▌       [0m| 851/3290 [05:14<15:42,  2.59it/s][A[2025-02-04 03:19:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 851/3290, eval_loss: 0.5585, eval_acc: 0.8488:  26%|[32m██▌       [0m| 852/3290 [05:14<16:25,  2.47it/s][A
step: 852/3290, eval_loss: 0.5586, eval_acc: 0.8487:  26%|[32m██▌       [0m| 852/3290 [05:14<16:25,  2.47it/s][A[2025-02-04 03:19:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 852/3290, eval_loss: 0.5586, eval_acc: 0.8487:  26%|[32m██▌       [0m| 853/3290 [05:14<15:15,  2.66it/s][A
step: 853/3290, eval_loss: 0.5591, eval_acc: 0.8486:  26%|[32m██▌       [0m| 853/3290 [05:14<15:15,  2.66it/s][A[2025-02-04 03:19:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 853/3290, eval_loss: 0.5591, eval_acc: 0.8486:  26%|[32m██▌       [0m| 854/3290 [05:15<14:07,  2.87it/s][A
step: 854/3290, eval_loss: 0.5590, eval_acc: 0.8486:  26%|[32m██▌       [0m| 854/3290 [05:15<14:07,  2.87it/s][A[2025-02-04 03:19:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 854/3290, eval_loss: 0.5590, eval_acc: 0.8486:  26%|[32m██▌       [0m| 855/3290 [05:15<13:18,  3.05it/s][A
step: 855/3290, eval_loss: 0.5589, eval_acc: 0.8486:  26%|[32m██▌       [0m| 855/3290 [05:15<13:18,  3.05it/s][A[2025-02-04 03:19:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 855/3290, eval_loss: 0.5589, eval_acc: 0.8486:  26%|[32m██▌       [0m| 856/3290 [05:15<12:20,  3.29it/s][A
step: 856/3290, eval_loss: 0.5587, eval_acc: 0.8486:  26%|[32m██▌       [0m| 856/3290 [05:15<12:20,  3.29it/s][A[2025-02-04 03:19:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 856/3290, eval_loss: 0.5587, eval_acc: 0.8486:  26%|[32m██▌       [0m| 857/3290 [05:15<11:35,  3.50it/s][A
step: 857/3290, eval_loss: 0.5590, eval_acc: 0.8485:  26%|[32m██▌       [0m| 857/3290 [05:15<11:35,  3.50it/s][A[2025-02-04 03:19:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 857/3290, eval_loss: 0.5590, eval_acc: 0.8485:  26%|[32m██▌       [0m| 858/3290 [05:16<11:19,  3.58it/s][A
step: 858/3290, eval_loss: 0.5594, eval_acc: 0.8485:  26%|[32m██▌       [0m| 858/3290 [05:16<11:19,  3.58it/s][A[2025-02-04 03:19:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 858/3290, eval_loss: 0.5594, eval_acc: 0.8485:  26%|[32m██▌       [0m| 859/3290 [05:16<11:59,  3.38it/s][A
step: 859/3290, eval_loss: 0.5601, eval_acc: 0.8483:  26%|[32m██▌       [0m| 859/3290 [05:16<11:59,  3.38it/s][A[2025-02-04 03:19:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 859/3290, eval_loss: 0.5601, eval_acc: 0.8483:  26%|[32m██▌       [0m| 860/3290 [05:16<11:45,  3.44it/s][A
step: 860/3290, eval_loss: 0.5601, eval_acc: 0.8483:  26%|[32m██▌       [0m| 860/3290 [05:16<11:45,  3.44it/s][A[2025-02-04 03:19:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 860/3290, eval_loss: 0.5601, eval_acc: 0.8483:  26%|[32m██▌       [0m| 861/3290 [05:16<11:43,  3.45it/s][A
step: 861/3290, eval_loss: 0.5605, eval_acc: 0.8482:  26%|[32m██▌       [0m| 861/3290 [05:16<11:43,  3.45it/s][A[2025-02-04 03:19:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 861/3290, eval_loss: 0.5605, eval_acc: 0.8482:  26%|[32m██▌       [0m| 862/3290 [05:17<11:35,  3.49it/s][A
step: 862/3290, eval_loss: 0.5604, eval_acc: 0.8482:  26%|[32m██▌       [0m| 862/3290 [05:17<11:35,  3.49it/s][A[2025-02-04 03:19:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 862/3290, eval_loss: 0.5604, eval_acc: 0.8482:  26%|[32m██▌       [0m| 863/3290 [05:17<12:14,  3.31it/s][A
step: 863/3290, eval_loss: 0.5602, eval_acc: 0.8483:  26%|[32m██▌       [0m| 863/3290 [05:17<12:14,  3.31it/s][A[2025-02-04 03:19:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 863/3290, eval_loss: 0.5602, eval_acc: 0.8483:  26%|[32m██▋       [0m| 864/3290 [05:17<12:11,  3.32it/s][A
step: 864/3290, eval_loss: 0.5603, eval_acc: 0.8482:  26%|[32m██▋       [0m| 864/3290 [05:17<12:11,  3.32it/s][A[2025-02-04 03:19:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 864/3290, eval_loss: 0.5603, eval_acc: 0.8482:  26%|[32m██▋       [0m| 865/3290 [05:18<13:03,  3.10it/s][A
step: 865/3290, eval_loss: 0.5601, eval_acc: 0.8483:  26%|[32m██▋       [0m| 865/3290 [05:18<13:03,  3.10it/s][A[2025-02-04 03:19:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 865/3290, eval_loss: 0.5601, eval_acc: 0.8483:  26%|[32m██▋       [0m| 866/3290 [05:18<13:32,  2.98it/s][A
step: 866/3290, eval_loss: 0.5601, eval_acc: 0.8483:  26%|[32m██▋       [0m| 866/3290 [05:18<13:32,  2.98it/s][A[2025-02-04 03:19:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 866/3290, eval_loss: 0.5601, eval_acc: 0.8483:  26%|[32m██▋       [0m| 867/3290 [05:19<14:30,  2.78it/s][A
step: 867/3290, eval_loss: 0.5600, eval_acc: 0.8483:  26%|[32m██▋       [0m| 867/3290 [05:19<14:30,  2.78it/s][A[2025-02-04 03:19:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 867/3290, eval_loss: 0.5600, eval_acc: 0.8483:  26%|[32m██▋       [0m| 868/3290 [05:19<16:52,  2.39it/s][A
step: 868/3290, eval_loss: 0.5598, eval_acc: 0.8483:  26%|[32m██▋       [0m| 868/3290 [05:19<16:52,  2.39it/s][A[2025-02-04 03:19:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 868/3290, eval_loss: 0.5598, eval_acc: 0.8483:  26%|[32m██▋       [0m| 869/3290 [05:20<17:12,  2.34it/s][A
step: 869/3290, eval_loss: 0.5599, eval_acc: 0.8483:  26%|[32m██▋       [0m| 869/3290 [05:20<17:12,  2.34it/s][A[2025-02-04 03:19:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 869/3290, eval_loss: 0.5599, eval_acc: 0.8483:  26%|[32m██▋       [0m| 870/3290 [05:20<16:33,  2.44it/s][A
step: 870/3290, eval_loss: 0.5608, eval_acc: 0.8481:  26%|[32m██▋       [0m| 870/3290 [05:20<16:33,  2.44it/s][A[2025-02-04 03:19:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 870/3290, eval_loss: 0.5608, eval_acc: 0.8481:  26%|[32m██▋       [0m| 871/3290 [05:20<14:31,  2.78it/s][A
step: 871/3290, eval_loss: 0.5611, eval_acc: 0.8480:  26%|[32m██▋       [0m| 871/3290 [05:20<14:31,  2.78it/s][A[2025-02-04 03:19:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 871/3290, eval_loss: 0.5611, eval_acc: 0.8480:  27%|[32m██▋       [0m| 872/3290 [05:21<15:14,  2.64it/s][A
step: 872/3290, eval_loss: 0.5611, eval_acc: 0.8481:  27%|[32m██▋       [0m| 872/3290 [05:21<15:14,  2.64it/s][A[2025-02-04 03:19:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 872/3290, eval_loss: 0.5611, eval_acc: 0.8481:  27%|[32m██▋       [0m| 873/3290 [05:21<16:14,  2.48it/s][A
step: 873/3290, eval_loss: 0.5614, eval_acc: 0.8480:  27%|[32m██▋       [0m| 873/3290 [05:21<16:14,  2.48it/s][A[2025-02-04 03:19:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 873/3290, eval_loss: 0.5614, eval_acc: 0.8480:  27%|[32m██▋       [0m| 874/3290 [05:21<16:15,  2.48it/s][A
step: 874/3290, eval_loss: 0.5610, eval_acc: 0.8481:  27%|[32m██▋       [0m| 874/3290 [05:21<16:15,  2.48it/s][A[2025-02-04 03:19:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 874/3290, eval_loss: 0.5610, eval_acc: 0.8481:  27%|[32m██▋       [0m| 875/3290 [05:22<16:01,  2.51it/s][A
step: 875/3290, eval_loss: 0.5614, eval_acc: 0.8480:  27%|[32m██▋       [0m| 875/3290 [05:22<16:01,  2.51it/s][A[2025-02-04 03:19:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 875/3290, eval_loss: 0.5614, eval_acc: 0.8480:  27%|[32m██▋       [0m| 876/3290 [05:22<16:19,  2.46it/s][A
step: 876/3290, eval_loss: 0.5621, eval_acc: 0.8479:  27%|[32m██▋       [0m| 876/3290 [05:22<16:19,  2.46it/s][A[2025-02-04 03:19:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 876/3290, eval_loss: 0.5621, eval_acc: 0.8479:  27%|[32m██▋       [0m| 877/3290 [05:23<15:32,  2.59it/s][A
step: 877/3290, eval_loss: 0.5624, eval_acc: 0.8478:  27%|[32m██▋       [0m| 877/3290 [05:23<15:32,  2.59it/s][A[2025-02-04 03:19:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 877/3290, eval_loss: 0.5624, eval_acc: 0.8478:  27%|[32m██▋       [0m| 878/3290 [05:23<14:54,  2.70it/s][A
step: 878/3290, eval_loss: 0.5623, eval_acc: 0.8478:  27%|[32m██▋       [0m| 878/3290 [05:23<14:54,  2.70it/s][A[2025-02-04 03:19:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 878/3290, eval_loss: 0.5623, eval_acc: 0.8478:  27%|[32m██▋       [0m| 879/3290 [05:23<14:54,  2.70it/s][A
step: 879/3290, eval_loss: 0.5624, eval_acc: 0.8477:  27%|[32m██▋       [0m| 879/3290 [05:23<14:54,  2.70it/s][A[2025-02-04 03:19:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 879/3290, eval_loss: 0.5624, eval_acc: 0.8477:  27%|[32m██▋       [0m| 880/3290 [05:24<13:46,  2.92it/s][A
step: 880/3290, eval_loss: 0.5625, eval_acc: 0.8477:  27%|[32m██▋       [0m| 880/3290 [05:24<13:46,  2.92it/s][A[2025-02-04 03:19:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 880/3290, eval_loss: 0.5625, eval_acc: 0.8477:  27%|[32m██▋       [0m| 881/3290 [05:24<13:26,  2.99it/s][A
step: 881/3290, eval_loss: 0.5638, eval_acc: 0.8475:  27%|[32m██▋       [0m| 881/3290 [05:24<13:26,  2.99it/s][A[2025-02-04 03:19:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 881/3290, eval_loss: 0.5638, eval_acc: 0.8475:  27%|[32m██▋       [0m| 882/3290 [05:24<13:25,  2.99it/s][A
step: 882/3290, eval_loss: 0.5640, eval_acc: 0.8474:  27%|[32m██▋       [0m| 882/3290 [05:24<13:25,  2.99it/s][A[2025-02-04 03:19:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 882/3290, eval_loss: 0.5640, eval_acc: 0.8474:  27%|[32m██▋       [0m| 883/3290 [05:25<13:31,  2.97it/s][A
step: 883/3290, eval_loss: 0.5642, eval_acc: 0.8474:  27%|[32m██▋       [0m| 883/3290 [05:25<13:31,  2.97it/s][A[2025-02-04 03:19:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 883/3290, eval_loss: 0.5642, eval_acc: 0.8474:  27%|[32m██▋       [0m| 884/3290 [05:25<13:46,  2.91it/s][A
step: 884/3290, eval_loss: 0.5641, eval_acc: 0.8474:  27%|[32m██▋       [0m| 884/3290 [05:25<13:46,  2.91it/s][A[2025-02-04 03:19:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 884/3290, eval_loss: 0.5641, eval_acc: 0.8474:  27%|[32m██▋       [0m| 885/3290 [05:25<13:03,  3.07it/s][A
step: 885/3290, eval_loss: 0.5647, eval_acc: 0.8472:  27%|[32m██▋       [0m| 885/3290 [05:25<13:03,  3.07it/s][A[2025-02-04 03:19:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 885/3290, eval_loss: 0.5647, eval_acc: 0.8472:  27%|[32m██▋       [0m| 886/3290 [05:26<13:31,  2.96it/s][A
step: 886/3290, eval_loss: 0.5648, eval_acc: 0.8471:  27%|[32m██▋       [0m| 886/3290 [05:26<13:31,  2.96it/s][A[2025-02-04 03:19:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 886/3290, eval_loss: 0.5648, eval_acc: 0.8471:  27%|[32m██▋       [0m| 887/3290 [05:26<13:42,  2.92it/s][A
step: 887/3290, eval_loss: 0.5653, eval_acc: 0.8470:  27%|[32m██▋       [0m| 887/3290 [05:26<13:42,  2.92it/s][A[2025-02-04 03:19:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 887/3290, eval_loss: 0.5653, eval_acc: 0.8470:  27%|[32m██▋       [0m| 888/3290 [05:26<13:58,  2.87it/s][A
step: 888/3290, eval_loss: 0.5651, eval_acc: 0.8470:  27%|[32m██▋       [0m| 888/3290 [05:26<13:58,  2.87it/s][A[2025-02-04 03:19:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 888/3290, eval_loss: 0.5651, eval_acc: 0.8470:  27%|[32m██▋       [0m| 889/3290 [05:27<14:38,  2.73it/s][A
step: 889/3290, eval_loss: 0.5654, eval_acc: 0.8469:  27%|[32m██▋       [0m| 889/3290 [05:27<14:38,  2.73it/s][A[2025-02-04 03:19:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 889/3290, eval_loss: 0.5654, eval_acc: 0.8469:  27%|[32m██▋       [0m| 890/3290 [05:27<15:14,  2.62it/s][A
step: 890/3290, eval_loss: 0.5654, eval_acc: 0.8469:  27%|[32m██▋       [0m| 890/3290 [05:27<15:14,  2.62it/s][A[2025-02-04 03:19:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 890/3290, eval_loss: 0.5654, eval_acc: 0.8469:  27%|[32m██▋       [0m| 891/3290 [05:27<14:30,  2.75it/s][A
step: 891/3290, eval_loss: 0.5652, eval_acc: 0.8469:  27%|[32m██▋       [0m| 891/3290 [05:27<14:30,  2.75it/s][A[2025-02-04 03:19:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 891/3290, eval_loss: 0.5652, eval_acc: 0.8469:  27%|[32m██▋       [0m| 892/3290 [05:28<14:36,  2.74it/s][A
step: 892/3290, eval_loss: 0.5655, eval_acc: 0.8468:  27%|[32m██▋       [0m| 892/3290 [05:28<14:36,  2.74it/s][A[2025-02-04 03:19:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 892/3290, eval_loss: 0.5655, eval_acc: 0.8468:  27%|[32m██▋       [0m| 893/3290 [05:28<13:21,  2.99it/s][A
step: 893/3290, eval_loss: 0.5656, eval_acc: 0.8468:  27%|[32m██▋       [0m| 893/3290 [05:28<13:21,  2.99it/s][A[2025-02-04 03:19:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 893/3290, eval_loss: 0.5656, eval_acc: 0.8468:  27%|[32m██▋       [0m| 894/3290 [05:28<13:52,  2.88it/s][A
step: 894/3290, eval_loss: 0.5656, eval_acc: 0.8468:  27%|[32m██▋       [0m| 894/3290 [05:28<13:52,  2.88it/s][A[2025-02-04 03:19:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 894/3290, eval_loss: 0.5656, eval_acc: 0.8468:  27%|[32m██▋       [0m| 895/3290 [05:29<13:20,  2.99it/s][A
step: 895/3290, eval_loss: 0.5655, eval_acc: 0.8469:  27%|[32m██▋       [0m| 895/3290 [05:29<13:20,  2.99it/s][A[2025-02-04 03:19:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 895/3290, eval_loss: 0.5655, eval_acc: 0.8469:  27%|[32m██▋       [0m| 896/3290 [05:29<13:09,  3.03it/s][A
step: 896/3290, eval_loss: 0.5654, eval_acc: 0.8469:  27%|[32m██▋       [0m| 896/3290 [05:29<13:09,  3.03it/s][A[2025-02-04 03:19:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 896/3290, eval_loss: 0.5654, eval_acc: 0.8469:  27%|[32m██▋       [0m| 897/3290 [05:29<13:02,  3.06it/s][A
step: 897/3290, eval_loss: 0.5655, eval_acc: 0.8469:  27%|[32m██▋       [0m| 897/3290 [05:29<13:02,  3.06it/s][A[2025-02-04 03:19:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 897/3290, eval_loss: 0.5655, eval_acc: 0.8469:  27%|[32m██▋       [0m| 898/3290 [05:30<12:58,  3.07it/s][A
step: 898/3290, eval_loss: 0.5654, eval_acc: 0.8470:  27%|[32m██▋       [0m| 898/3290 [05:30<12:58,  3.07it/s][A[2025-02-04 03:19:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 898/3290, eval_loss: 0.5654, eval_acc: 0.8470:  27%|[32m██▋       [0m| 899/3290 [05:30<13:08,  3.03it/s][A
step: 899/3290, eval_loss: 0.5654, eval_acc: 0.8469:  27%|[32m██▋       [0m| 899/3290 [05:30<13:08,  3.03it/s][A[2025-02-04 03:19:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 899/3290, eval_loss: 0.5654, eval_acc: 0.8469:  27%|[32m██▋       [0m| 900/3290 [05:30<12:37,  3.15it/s][A
step: 900/3290, eval_loss: 0.5664, eval_acc: 0.8467:  27%|[32m██▋       [0m| 900/3290 [05:30<12:37,  3.15it/s][A[2025-02-04 03:19:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 900/3290, eval_loss: 0.5664, eval_acc: 0.8467:  27%|[32m██▋       [0m| 901/3290 [05:31<13:11,  3.02it/s][A
step: 901/3290, eval_loss: 0.5669, eval_acc: 0.8465:  27%|[32m██▋       [0m| 901/3290 [05:31<13:11,  3.02it/s][A[2025-02-04 03:19:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 901/3290, eval_loss: 0.5669, eval_acc: 0.8465:  27%|[32m██▋       [0m| 902/3290 [05:31<13:30,  2.94it/s][A
step: 902/3290, eval_loss: 0.5673, eval_acc: 0.8464:  27%|[32m██▋       [0m| 902/3290 [05:31<13:30,  2.94it/s][A[2025-02-04 03:19:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 902/3290, eval_loss: 0.5673, eval_acc: 0.8464:  27%|[32m██▋       [0m| 903/3290 [05:31<13:47,  2.89it/s][A
step: 903/3290, eval_loss: 0.5679, eval_acc: 0.8463:  27%|[32m██▋       [0m| 903/3290 [05:31<13:47,  2.89it/s][A[2025-02-04 03:19:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 903/3290, eval_loss: 0.5679, eval_acc: 0.8463:  27%|[32m██▋       [0m| 904/3290 [05:32<13:35,  2.93it/s][A
step: 904/3290, eval_loss: 0.5681, eval_acc: 0.8462:  27%|[32m██▋       [0m| 904/3290 [05:32<13:35,  2.93it/s][A[2025-02-04 03:19:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 904/3290, eval_loss: 0.5681, eval_acc: 0.8462:  28%|[32m██▊       [0m| 905/3290 [05:32<13:40,  2.91it/s][A
step: 905/3290, eval_loss: 0.5681, eval_acc: 0.8462:  28%|[32m██▊       [0m| 905/3290 [05:32<13:40,  2.91it/s][A[2025-02-04 03:19:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 905/3290, eval_loss: 0.5681, eval_acc: 0.8462:  28%|[32m██▊       [0m| 906/3290 [05:32<13:02,  3.05it/s][A
step: 906/3290, eval_loss: 0.5684, eval_acc: 0.8461:  28%|[32m██▊       [0m| 906/3290 [05:32<13:02,  3.05it/s][A[2025-02-04 03:19:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 906/3290, eval_loss: 0.5684, eval_acc: 0.8461:  28%|[32m██▊       [0m| 907/3290 [05:33<14:15,  2.79it/s][A
step: 907/3290, eval_loss: 0.5688, eval_acc: 0.8460:  28%|[32m██▊       [0m| 907/3290 [05:33<14:15,  2.79it/s][A[2025-02-04 03:19:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 907/3290, eval_loss: 0.5688, eval_acc: 0.8460:  28%|[32m██▊       [0m| 908/3290 [05:33<13:05,  3.03it/s][A
step: 908/3290, eval_loss: 0.5697, eval_acc: 0.8457:  28%|[32m██▊       [0m| 908/3290 [05:33<13:05,  3.03it/s][A[2025-02-04 03:19:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 908/3290, eval_loss: 0.5697, eval_acc: 0.8457:  28%|[32m██▊       [0m| 909/3290 [05:33<12:50,  3.09it/s][A
step: 909/3290, eval_loss: 0.5693, eval_acc: 0.8459:  28%|[32m██▊       [0m| 909/3290 [05:33<12:50,  3.09it/s][A[2025-02-04 03:19:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 909/3290, eval_loss: 0.5693, eval_acc: 0.8459:  28%|[32m██▊       [0m| 910/3290 [05:34<13:15,  2.99it/s][A
step: 910/3290, eval_loss: 0.5697, eval_acc: 0.8458:  28%|[32m██▊       [0m| 910/3290 [05:34<13:15,  2.99it/s][A[2025-02-04 03:19:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 910/3290, eval_loss: 0.5697, eval_acc: 0.8458:  28%|[32m██▊       [0m| 911/3290 [05:34<12:22,  3.20it/s][A
step: 911/3290, eval_loss: 0.5698, eval_acc: 0.8457:  28%|[32m██▊       [0m| 911/3290 [05:34<12:22,  3.20it/s][A[2025-02-04 03:19:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 911/3290, eval_loss: 0.5698, eval_acc: 0.8457:  28%|[32m██▊       [0m| 912/3290 [05:34<12:36,  3.14it/s][A
step: 912/3290, eval_loss: 0.5700, eval_acc: 0.8456:  28%|[32m██▊       [0m| 912/3290 [05:34<12:36,  3.14it/s][A[2025-02-04 03:19:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 912/3290, eval_loss: 0.5700, eval_acc: 0.8456:  28%|[32m██▊       [0m| 913/3290 [05:35<13:01,  3.04it/s][A
step: 913/3290, eval_loss: 0.5700, eval_acc: 0.8456:  28%|[32m██▊       [0m| 913/3290 [05:35<13:01,  3.04it/s][A[2025-02-04 03:19:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 913/3290, eval_loss: 0.5700, eval_acc: 0.8456:  28%|[32m██▊       [0m| 914/3290 [05:35<13:27,  2.94it/s][A
step: 914/3290, eval_loss: 0.5702, eval_acc: 0.8456:  28%|[32m██▊       [0m| 914/3290 [05:35<13:27,  2.94it/s][A[2025-02-04 03:19:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 914/3290, eval_loss: 0.5702, eval_acc: 0.8456:  28%|[32m██▊       [0m| 915/3290 [05:35<14:02,  2.82it/s][A
step: 915/3290, eval_loss: 0.5705, eval_acc: 0.8456:  28%|[32m██▊       [0m| 915/3290 [05:35<14:02,  2.82it/s][A[2025-02-04 03:19:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 915/3290, eval_loss: 0.5705, eval_acc: 0.8456:  28%|[32m██▊       [0m| 916/3290 [05:36<15:50,  2.50it/s][A
step: 916/3290, eval_loss: 0.5709, eval_acc: 0.8455:  28%|[32m██▊       [0m| 916/3290 [05:36<15:50,  2.50it/s][A[2025-02-04 03:19:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 916/3290, eval_loss: 0.5709, eval_acc: 0.8455:  28%|[32m██▊       [0m| 917/3290 [05:36<15:43,  2.52it/s][A
step: 917/3290, eval_loss: 0.5713, eval_acc: 0.8454:  28%|[32m██▊       [0m| 917/3290 [05:36<15:43,  2.52it/s][A[2025-02-04 03:19:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 917/3290, eval_loss: 0.5713, eval_acc: 0.8454:  28%|[32m██▊       [0m| 918/3290 [05:37<14:37,  2.70it/s][A
step: 918/3290, eval_loss: 0.5719, eval_acc: 0.8453:  28%|[32m██▊       [0m| 918/3290 [05:37<14:37,  2.70it/s][A[2025-02-04 03:19:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 918/3290, eval_loss: 0.5719, eval_acc: 0.8453:  28%|[32m██▊       [0m| 919/3290 [05:37<14:21,  2.75it/s][A
step: 919/3290, eval_loss: 0.5722, eval_acc: 0.8451:  28%|[32m██▊       [0m| 919/3290 [05:37<14:21,  2.75it/s][A[2025-02-04 03:19:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 919/3290, eval_loss: 0.5722, eval_acc: 0.8451:  28%|[32m██▊       [0m| 920/3290 [05:37<13:52,  2.85it/s][A
step: 920/3290, eval_loss: 0.5724, eval_acc: 0.8450:  28%|[32m██▊       [0m| 920/3290 [05:37<13:52,  2.85it/s][A[2025-02-04 03:19:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 920/3290, eval_loss: 0.5724, eval_acc: 0.8450:  28%|[32m██▊       [0m| 921/3290 [05:38<13:22,  2.95it/s][A
step: 921/3290, eval_loss: 0.5727, eval_acc: 0.8449:  28%|[32m██▊       [0m| 921/3290 [05:38<13:22,  2.95it/s][A[2025-02-04 03:19:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 921/3290, eval_loss: 0.5727, eval_acc: 0.8449:  28%|[32m██▊       [0m| 922/3290 [05:38<12:13,  3.23it/s][A
step: 922/3290, eval_loss: 0.5733, eval_acc: 0.8448:  28%|[32m██▊       [0m| 922/3290 [05:38<12:13,  3.23it/s][A[2025-02-04 03:19:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 922/3290, eval_loss: 0.5733, eval_acc: 0.8448:  28%|[32m██▊       [0m| 923/3290 [05:38<11:47,  3.35it/s][A
step: 923/3290, eval_loss: 0.5734, eval_acc: 0.8448:  28%|[32m██▊       [0m| 923/3290 [05:38<11:47,  3.35it/s][A[2025-02-04 03:19:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 923/3290, eval_loss: 0.5734, eval_acc: 0.8448:  28%|[32m██▊       [0m| 924/3290 [05:38<11:19,  3.48it/s][A
step: 924/3290, eval_loss: 0.5734, eval_acc: 0.8447:  28%|[32m██▊       [0m| 924/3290 [05:38<11:19,  3.48it/s][A[2025-02-04 03:19:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 924/3290, eval_loss: 0.5734, eval_acc: 0.8447:  28%|[32m██▊       [0m| 925/3290 [05:39<13:23,  2.94it/s][A
step: 925/3290, eval_loss: 0.5736, eval_acc: 0.8447:  28%|[32m██▊       [0m| 925/3290 [05:39<13:23,  2.94it/s][A[2025-02-04 03:19:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 925/3290, eval_loss: 0.5736, eval_acc: 0.8447:  28%|[32m██▊       [0m| 926/3290 [05:39<13:13,  2.98it/s][A
step: 926/3290, eval_loss: 0.5745, eval_acc: 0.8445:  28%|[32m██▊       [0m| 926/3290 [05:39<13:13,  2.98it/s][A[2025-02-04 03:19:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 926/3290, eval_loss: 0.5745, eval_acc: 0.8445:  28%|[32m██▊       [0m| 927/3290 [05:40<13:52,  2.84it/s][A
step: 927/3290, eval_loss: 0.5751, eval_acc: 0.8443:  28%|[32m██▊       [0m| 927/3290 [05:40<13:52,  2.84it/s][A[2025-02-04 03:19:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 927/3290, eval_loss: 0.5751, eval_acc: 0.8443:  28%|[32m██▊       [0m| 928/3290 [05:40<14:43,  2.67it/s][A
step: 928/3290, eval_loss: 0.5749, eval_acc: 0.8444:  28%|[32m██▊       [0m| 928/3290 [05:40<14:43,  2.67it/s][A[2025-02-04 03:19:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 928/3290, eval_loss: 0.5749, eval_acc: 0.8444:  28%|[32m██▊       [0m| 929/3290 [05:40<14:21,  2.74it/s][A
step: 929/3290, eval_loss: 0.5744, eval_acc: 0.8446:  28%|[32m██▊       [0m| 929/3290 [05:40<14:21,  2.74it/s][A[2025-02-04 03:19:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 929/3290, eval_loss: 0.5744, eval_acc: 0.8446:  28%|[32m██▊       [0m| 930/3290 [05:41<13:56,  2.82it/s][A
step: 930/3290, eval_loss: 0.5741, eval_acc: 0.8446:  28%|[32m██▊       [0m| 930/3290 [05:41<13:56,  2.82it/s][A[2025-02-04 03:19:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 930/3290, eval_loss: 0.5741, eval_acc: 0.8446:  28%|[32m██▊       [0m| 931/3290 [05:41<15:11,  2.59it/s][A
step: 931/3290, eval_loss: 0.5739, eval_acc: 0.8447:  28%|[32m██▊       [0m| 931/3290 [05:41<15:11,  2.59it/s][A[2025-02-04 03:19:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 931/3290, eval_loss: 0.5739, eval_acc: 0.8447:  28%|[32m██▊       [0m| 932/3290 [05:42<15:50,  2.48it/s][A
step: 932/3290, eval_loss: 0.5735, eval_acc: 0.8448:  28%|[32m██▊       [0m| 932/3290 [05:42<15:50,  2.48it/s][A[2025-02-04 03:19:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 932/3290, eval_loss: 0.5735, eval_acc: 0.8448:  28%|[32m██▊       [0m| 933/3290 [05:42<14:57,  2.62it/s][A
step: 933/3290, eval_loss: 0.5729, eval_acc: 0.8450:  28%|[32m██▊       [0m| 933/3290 [05:42<14:57,  2.62it/s][A[2025-02-04 03:19:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 933/3290, eval_loss: 0.5729, eval_acc: 0.8450:  28%|[32m██▊       [0m| 934/3290 [05:42<15:06,  2.60it/s][A
step: 934/3290, eval_loss: 0.5724, eval_acc: 0.8451:  28%|[32m██▊       [0m| 934/3290 [05:42<15:06,  2.60it/s][A[2025-02-04 03:19:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 934/3290, eval_loss: 0.5724, eval_acc: 0.8451:  28%|[32m██▊       [0m| 935/3290 [05:43<15:38,  2.51it/s][A
step: 935/3290, eval_loss: 0.5719, eval_acc: 0.8452:  28%|[32m██▊       [0m| 935/3290 [05:43<15:38,  2.51it/s][A[2025-02-04 03:19:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 935/3290, eval_loss: 0.5719, eval_acc: 0.8452:  28%|[32m██▊       [0m| 936/3290 [05:43<15:14,  2.57it/s][A
step: 936/3290, eval_loss: 0.5717, eval_acc: 0.8453:  28%|[32m██▊       [0m| 936/3290 [05:43<15:14,  2.57it/s][A[2025-02-04 03:19:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 936/3290, eval_loss: 0.5717, eval_acc: 0.8453:  28%|[32m██▊       [0m| 937/3290 [05:43<13:46,  2.85it/s][A
step: 937/3290, eval_loss: 0.5718, eval_acc: 0.8453:  28%|[32m██▊       [0m| 937/3290 [05:43<13:46,  2.85it/s][A[2025-02-04 03:19:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 937/3290, eval_loss: 0.5718, eval_acc: 0.8453:  29%|[32m██▊       [0m| 938/3290 [05:44<13:30,  2.90it/s][A
step: 938/3290, eval_loss: 0.5714, eval_acc: 0.8454:  29%|[32m██▊       [0m| 938/3290 [05:44<13:30,  2.90it/s][A[2025-02-04 03:19:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 938/3290, eval_loss: 0.5714, eval_acc: 0.8454:  29%|[32m██▊       [0m| 939/3290 [05:44<12:55,  3.03it/s][A
step: 939/3290, eval_loss: 0.5709, eval_acc: 0.8455:  29%|[32m██▊       [0m| 939/3290 [05:44<12:55,  3.03it/s][A[2025-02-04 03:19:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 939/3290, eval_loss: 0.5709, eval_acc: 0.8455:  29%|[32m██▊       [0m| 940/3290 [05:44<12:49,  3.05it/s][A
step: 940/3290, eval_loss: 0.5706, eval_acc: 0.8457:  29%|[32m██▊       [0m| 940/3290 [05:44<12:49,  3.05it/s][A[2025-02-04 03:19:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 940/3290, eval_loss: 0.5706, eval_acc: 0.8457:  29%|[32m██▊       [0m| 941/3290 [05:45<12:32,  3.12it/s][A
step: 941/3290, eval_loss: 0.5701, eval_acc: 0.8458:  29%|[32m██▊       [0m| 941/3290 [05:45<12:32,  3.12it/s][A[2025-02-04 03:19:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 941/3290, eval_loss: 0.5701, eval_acc: 0.8458:  29%|[32m██▊       [0m| 942/3290 [05:45<13:23,  2.92it/s][A
step: 942/3290, eval_loss: 0.5697, eval_acc: 0.8459:  29%|[32m██▊       [0m| 942/3290 [05:45<13:23,  2.92it/s][A[2025-02-04 03:19:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 942/3290, eval_loss: 0.5697, eval_acc: 0.8459:  29%|[32m██▊       [0m| 943/3290 [05:45<12:41,  3.08it/s][A
step: 943/3290, eval_loss: 0.5693, eval_acc: 0.8460:  29%|[32m██▊       [0m| 943/3290 [05:45<12:41,  3.08it/s][A[2025-02-04 03:19:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 943/3290, eval_loss: 0.5693, eval_acc: 0.8460:  29%|[32m██▊       [0m| 944/3290 [05:46<12:07,  3.23it/s][A
step: 944/3290, eval_loss: 0.5693, eval_acc: 0.8460:  29%|[32m██▊       [0m| 944/3290 [05:46<12:07,  3.23it/s][A[2025-02-04 03:19:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 944/3290, eval_loss: 0.5693, eval_acc: 0.8460:  29%|[32m██▊       [0m| 945/3290 [05:46<13:06,  2.98it/s][A
step: 945/3290, eval_loss: 0.5687, eval_acc: 0.8462:  29%|[32m██▊       [0m| 945/3290 [05:46<13:06,  2.98it/s][A[2025-02-04 03:19:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 945/3290, eval_loss: 0.5687, eval_acc: 0.8462:  29%|[32m██▉       [0m| 946/3290 [05:46<13:24,  2.91it/s][A
step: 946/3290, eval_loss: 0.5685, eval_acc: 0.8462:  29%|[32m██▉       [0m| 946/3290 [05:46<13:24,  2.91it/s][A[2025-02-04 03:19:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 946/3290, eval_loss: 0.5685, eval_acc: 0.8462:  29%|[32m██▉       [0m| 947/3290 [05:47<14:12,  2.75it/s][A
step: 947/3290, eval_loss: 0.5683, eval_acc: 0.8463:  29%|[32m██▉       [0m| 947/3290 [05:47<14:12,  2.75it/s][A[2025-02-04 03:19:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 947/3290, eval_loss: 0.5683, eval_acc: 0.8463:  29%|[32m██▉       [0m| 948/3290 [05:47<14:48,  2.64it/s][A
step: 948/3290, eval_loss: 0.5679, eval_acc: 0.8464:  29%|[32m██▉       [0m| 948/3290 [05:47<14:48,  2.64it/s][A[2025-02-04 03:19:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 948/3290, eval_loss: 0.5679, eval_acc: 0.8464:  29%|[32m██▉       [0m| 949/3290 [05:48<15:23,  2.53it/s][A
step: 949/3290, eval_loss: 0.5676, eval_acc: 0.8465:  29%|[32m██▉       [0m| 949/3290 [05:48<15:23,  2.53it/s][A[2025-02-04 03:19:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 949/3290, eval_loss: 0.5676, eval_acc: 0.8465:  29%|[32m██▉       [0m| 950/3290 [05:48<15:09,  2.57it/s][A
step: 950/3290, eval_loss: 0.5675, eval_acc: 0.8465:  29%|[32m██▉       [0m| 950/3290 [05:48<15:09,  2.57it/s][A[2025-02-04 03:19:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 950/3290, eval_loss: 0.5675, eval_acc: 0.8465:  29%|[32m██▉       [0m| 951/3290 [05:48<15:34,  2.50it/s][A
step: 951/3290, eval_loss: 0.5670, eval_acc: 0.8466:  29%|[32m██▉       [0m| 951/3290 [05:48<15:34,  2.50it/s][A[2025-02-04 03:19:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 951/3290, eval_loss: 0.5670, eval_acc: 0.8466:  29%|[32m██▉       [0m| 952/3290 [05:49<16:08,  2.41it/s][A
step: 952/3290, eval_loss: 0.5665, eval_acc: 0.8467:  29%|[32m██▉       [0m| 952/3290 [05:49<16:08,  2.41it/s][A[2025-02-04 03:19:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 952/3290, eval_loss: 0.5665, eval_acc: 0.8467:  29%|[32m██▉       [0m| 953/3290 [05:49<16:30,  2.36it/s][A
step: 953/3290, eval_loss: 0.5662, eval_acc: 0.8468:  29%|[32m██▉       [0m| 953/3290 [05:49<16:30,  2.36it/s][A[2025-02-04 03:19:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 953/3290, eval_loss: 0.5662, eval_acc: 0.8468:  29%|[32m██▉       [0m| 954/3290 [05:50<15:20,  2.54it/s][A
step: 954/3290, eval_loss: 0.5662, eval_acc: 0.8468:  29%|[32m██▉       [0m| 954/3290 [05:50<15:20,  2.54it/s][A[2025-02-04 03:19:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 954/3290, eval_loss: 0.5662, eval_acc: 0.8468:  29%|[32m██▉       [0m| 955/3290 [05:50<15:44,  2.47it/s][A
step: 955/3290, eval_loss: 0.5657, eval_acc: 0.8469:  29%|[32m██▉       [0m| 955/3290 [05:50<15:44,  2.47it/s][A[2025-02-04 03:19:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 955/3290, eval_loss: 0.5657, eval_acc: 0.8469:  29%|[32m██▉       [0m| 956/3290 [05:50<15:31,  2.51it/s][A
step: 956/3290, eval_loss: 0.5658, eval_acc: 0.8469:  29%|[32m██▉       [0m| 956/3290 [05:50<15:31,  2.51it/s][A[2025-02-04 03:19:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 956/3290, eval_loss: 0.5658, eval_acc: 0.8469:  29%|[32m██▉       [0m| 957/3290 [05:51<16:15,  2.39it/s][A
step: 957/3290, eval_loss: 0.5654, eval_acc: 0.8471:  29%|[32m██▉       [0m| 957/3290 [05:51<16:15,  2.39it/s][A[2025-02-04 03:19:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 957/3290, eval_loss: 0.5654, eval_acc: 0.8471:  29%|[32m██▉       [0m| 958/3290 [05:51<15:02,  2.58it/s][A
step: 958/3290, eval_loss: 0.5648, eval_acc: 0.8472:  29%|[32m██▉       [0m| 958/3290 [05:51<15:02,  2.58it/s][A[2025-02-04 03:19:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 958/3290, eval_loss: 0.5648, eval_acc: 0.8472:  29%|[32m██▉       [0m| 959/3290 [05:52<14:27,  2.69it/s][A
step: 959/3290, eval_loss: 0.5648, eval_acc: 0.8472:  29%|[32m██▉       [0m| 959/3290 [05:52<14:27,  2.69it/s][A[2025-02-04 03:19:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 959/3290, eval_loss: 0.5648, eval_acc: 0.8472:  29%|[32m██▉       [0m| 960/3290 [05:52<15:23,  2.52it/s][A
step: 960/3290, eval_loss: 0.5645, eval_acc: 0.8473:  29%|[32m██▉       [0m| 960/3290 [05:52<15:23,  2.52it/s][A[2025-02-04 03:19:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 960/3290, eval_loss: 0.5645, eval_acc: 0.8473:  29%|[32m██▉       [0m| 961/3290 [05:52<15:23,  2.52it/s][A
step: 961/3290, eval_loss: 0.5640, eval_acc: 0.8475:  29%|[32m██▉       [0m| 961/3290 [05:52<15:23,  2.52it/s][A[2025-02-04 03:19:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 961/3290, eval_loss: 0.5640, eval_acc: 0.8475:  29%|[32m██▉       [0m| 962/3290 [05:53<15:02,  2.58it/s][A
step: 962/3290, eval_loss: 0.5636, eval_acc: 0.8476:  29%|[32m██▉       [0m| 962/3290 [05:53<15:02,  2.58it/s][A[2025-02-04 03:19:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 962/3290, eval_loss: 0.5636, eval_acc: 0.8476:  29%|[32m██▉       [0m| 963/3290 [05:53<14:01,  2.76it/s][A
step: 963/3290, eval_loss: 0.5634, eval_acc: 0.8476:  29%|[32m██▉       [0m| 963/3290 [05:53<14:01,  2.76it/s][A[2025-02-04 03:19:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 963/3290, eval_loss: 0.5634, eval_acc: 0.8476:  29%|[32m██▉       [0m| 964/3290 [05:53<14:07,  2.74it/s][A
step: 964/3290, eval_loss: 0.5633, eval_acc: 0.8476:  29%|[32m██▉       [0m| 964/3290 [05:53<14:07,  2.74it/s][A[2025-02-04 03:19:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 964/3290, eval_loss: 0.5633, eval_acc: 0.8476:  29%|[32m██▉       [0m| 965/3290 [05:54<14:29,  2.67it/s][A
step: 965/3290, eval_loss: 0.5631, eval_acc: 0.8476:  29%|[32m██▉       [0m| 965/3290 [05:54<14:29,  2.67it/s][A[2025-02-04 03:19:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 965/3290, eval_loss: 0.5631, eval_acc: 0.8476:  29%|[32m██▉       [0m| 966/3290 [05:54<13:37,  2.84it/s][A
step: 966/3290, eval_loss: 0.5627, eval_acc: 0.8477:  29%|[32m██▉       [0m| 966/3290 [05:54<13:37,  2.84it/s][A[2025-02-04 03:19:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 966/3290, eval_loss: 0.5627, eval_acc: 0.8477:  29%|[32m██▉       [0m| 967/3290 [05:55<13:47,  2.81it/s][A
step: 967/3290, eval_loss: 0.5623, eval_acc: 0.8478:  29%|[32m██▉       [0m| 967/3290 [05:55<13:47,  2.81it/s][A[2025-02-04 03:19:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 967/3290, eval_loss: 0.5623, eval_acc: 0.8478:  29%|[32m██▉       [0m| 968/3290 [05:55<13:34,  2.85it/s][A
step: 968/3290, eval_loss: 0.5620, eval_acc: 0.8479:  29%|[32m██▉       [0m| 968/3290 [05:55<13:34,  2.85it/s][A[2025-02-04 03:19:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 968/3290, eval_loss: 0.5620, eval_acc: 0.8479:  29%|[32m██▉       [0m| 969/3290 [05:55<14:47,  2.62it/s][A
step: 969/3290, eval_loss: 0.5625, eval_acc: 0.8479:  29%|[32m██▉       [0m| 969/3290 [05:55<14:47,  2.62it/s][A[2025-02-04 03:19:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 969/3290, eval_loss: 0.5625, eval_acc: 0.8479:  29%|[32m██▉       [0m| 970/3290 [05:56<14:29,  2.67it/s][A
step: 970/3290, eval_loss: 0.5625, eval_acc: 0.8479:  29%|[32m██▉       [0m| 970/3290 [05:56<14:29,  2.67it/s][A[2025-02-04 03:19:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 970/3290, eval_loss: 0.5625, eval_acc: 0.8479:  30%|[32m██▉       [0m| 971/3290 [05:56<13:10,  2.93it/s][A
step: 971/3290, eval_loss: 0.5620, eval_acc: 0.8480:  30%|[32m██▉       [0m| 971/3290 [05:56<13:10,  2.93it/s][A[2025-02-04 03:19:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 971/3290, eval_loss: 0.5620, eval_acc: 0.8480:  30%|[32m██▉       [0m| 972/3290 [05:56<12:13,  3.16it/s][A
step: 972/3290, eval_loss: 0.5616, eval_acc: 0.8481:  30%|[32m██▉       [0m| 972/3290 [05:56<12:13,  3.16it/s][A[2025-02-04 03:19:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 972/3290, eval_loss: 0.5616, eval_acc: 0.8481:  30%|[32m██▉       [0m| 973/3290 [05:56<12:01,  3.21it/s][A
step: 973/3290, eval_loss: 0.5613, eval_acc: 0.8481:  30%|[32m██▉       [0m| 973/3290 [05:56<12:01,  3.21it/s][A[2025-02-04 03:19:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 973/3290, eval_loss: 0.5613, eval_acc: 0.8481:  30%|[32m██▉       [0m| 974/3290 [05:57<11:42,  3.30it/s][A
step: 974/3290, eval_loss: 0.5608, eval_acc: 0.8482:  30%|[32m██▉       [0m| 974/3290 [05:57<11:42,  3.30it/s][A[2025-02-04 03:19:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 974/3290, eval_loss: 0.5608, eval_acc: 0.8482:  30%|[32m██▉       [0m| 975/3290 [05:57<12:08,  3.18it/s][A
step: 975/3290, eval_loss: 0.5612, eval_acc: 0.8481:  30%|[32m██▉       [0m| 975/3290 [05:57<12:08,  3.18it/s][A[2025-02-04 03:19:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 975/3290, eval_loss: 0.5612, eval_acc: 0.8481:  30%|[32m██▉       [0m| 976/3290 [05:58<13:26,  2.87it/s][A
step: 976/3290, eval_loss: 0.5612, eval_acc: 0.8481:  30%|[32m██▉       [0m| 976/3290 [05:58<13:26,  2.87it/s][A[2025-02-04 03:19:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 976/3290, eval_loss: 0.5612, eval_acc: 0.8481:  30%|[32m██▉       [0m| 977/3290 [05:58<14:47,  2.61it/s][A
step: 977/3290, eval_loss: 0.5615, eval_acc: 0.8480:  30%|[32m██▉       [0m| 977/3290 [05:58<14:47,  2.61it/s][A[2025-02-04 03:19:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 977/3290, eval_loss: 0.5615, eval_acc: 0.8480:  30%|[32m██▉       [0m| 978/3290 [05:58<13:55,  2.77it/s][A
step: 978/3290, eval_loss: 0.5615, eval_acc: 0.8480:  30%|[32m██▉       [0m| 978/3290 [05:58<13:55,  2.77it/s][A[2025-02-04 03:19:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 978/3290, eval_loss: 0.5615, eval_acc: 0.8480:  30%|[32m██▉       [0m| 979/3290 [05:59<12:41,  3.03it/s][A
step: 979/3290, eval_loss: 0.5619, eval_acc: 0.8479:  30%|[32m██▉       [0m| 979/3290 [05:59<12:41,  3.03it/s][A[2025-02-04 03:19:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 979/3290, eval_loss: 0.5619, eval_acc: 0.8479:  30%|[32m██▉       [0m| 980/3290 [05:59<12:39,  3.04it/s][A
step: 980/3290, eval_loss: 0.5618, eval_acc: 0.8479:  30%|[32m██▉       [0m| 980/3290 [05:59<12:39,  3.04it/s][A[2025-02-04 03:19:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 980/3290, eval_loss: 0.5618, eval_acc: 0.8479:  30%|[32m██▉       [0m| 981/3290 [05:59<13:51,  2.78it/s][A
step: 981/3290, eval_loss: 0.5612, eval_acc: 0.8481:  30%|[32m██▉       [0m| 981/3290 [05:59<13:51,  2.78it/s][A[2025-02-04 03:19:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 981/3290, eval_loss: 0.5612, eval_acc: 0.8481:  30%|[32m██▉       [0m| 982/3290 [06:00<13:34,  2.83it/s][A
step: 982/3290, eval_loss: 0.5614, eval_acc: 0.8480:  30%|[32m██▉       [0m| 982/3290 [06:00<13:34,  2.83it/s][A[2025-02-04 03:19:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 982/3290, eval_loss: 0.5614, eval_acc: 0.8480:  30%|[32m██▉       [0m| 983/3290 [06:00<12:57,  2.97it/s][A
step: 983/3290, eval_loss: 0.5610, eval_acc: 0.8481:  30%|[32m██▉       [0m| 983/3290 [06:00<12:57,  2.97it/s][A[2025-02-04 03:19:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 983/3290, eval_loss: 0.5610, eval_acc: 0.8481:  30%|[32m██▉       [0m| 984/3290 [06:00<13:06,  2.93it/s][A
step: 984/3290, eval_loss: 0.5612, eval_acc: 0.8482:  30%|[32m██▉       [0m| 984/3290 [06:00<13:06,  2.93it/s][A[2025-02-04 03:19:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 984/3290, eval_loss: 0.5612, eval_acc: 0.8482:  30%|[32m██▉       [0m| 985/3290 [06:01<12:50,  2.99it/s][A
step: 985/3290, eval_loss: 0.5608, eval_acc: 0.8483:  30%|[32m██▉       [0m| 985/3290 [06:01<12:50,  2.99it/s][A[2025-02-04 03:19:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 985/3290, eval_loss: 0.5608, eval_acc: 0.8483:  30%|[32m██▉       [0m| 986/3290 [06:01<13:30,  2.84it/s][A
step: 986/3290, eval_loss: 0.5605, eval_acc: 0.8484:  30%|[32m██▉       [0m| 986/3290 [06:01<13:30,  2.84it/s][A[2025-02-04 03:19:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 986/3290, eval_loss: 0.5605, eval_acc: 0.8484:  30%|[32m███       [0m| 987/3290 [06:01<14:37,  2.62it/s][A
step: 987/3290, eval_loss: 0.5604, eval_acc: 0.8484:  30%|[32m███       [0m| 987/3290 [06:01<14:37,  2.62it/s][A[2025-02-04 03:19:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 987/3290, eval_loss: 0.5604, eval_acc: 0.8484:  30%|[32m███       [0m| 988/3290 [06:02<13:24,  2.86it/s][A
step: 988/3290, eval_loss: 0.5600, eval_acc: 0.8485:  30%|[32m███       [0m| 988/3290 [06:02<13:24,  2.86it/s][A[2025-02-04 03:19:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 988/3290, eval_loss: 0.5600, eval_acc: 0.8485:  30%|[32m███       [0m| 989/3290 [06:02<13:16,  2.89it/s][A
step: 989/3290, eval_loss: 0.5596, eval_acc: 0.8486:  30%|[32m███       [0m| 989/3290 [06:02<13:16,  2.89it/s][A[2025-02-04 03:19:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 989/3290, eval_loss: 0.5596, eval_acc: 0.8486:  30%|[32m███       [0m| 990/3290 [06:02<13:14,  2.90it/s][A
step: 990/3290, eval_loss: 0.5591, eval_acc: 0.8487:  30%|[32m███       [0m| 990/3290 [06:02<13:14,  2.90it/s][A[2025-02-04 03:19:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 990/3290, eval_loss: 0.5591, eval_acc: 0.8487:  30%|[32m███       [0m| 991/3290 [06:03<15:02,  2.55it/s][A
step: 991/3290, eval_loss: 0.5589, eval_acc: 0.8487:  30%|[32m███       [0m| 991/3290 [06:03<15:02,  2.55it/s][A[2025-02-04 03:19:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 991/3290, eval_loss: 0.5589, eval_acc: 0.8487:  30%|[32m███       [0m| 992/3290 [06:03<15:33,  2.46it/s][A
step: 992/3290, eval_loss: 0.5585, eval_acc: 0.8488:  30%|[32m███       [0m| 992/3290 [06:03<15:33,  2.46it/s][A[2025-02-04 03:19:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 992/3290, eval_loss: 0.5585, eval_acc: 0.8488:  30%|[32m███       [0m| 993/3290 [06:04<15:18,  2.50it/s][A
step: 993/3290, eval_loss: 0.5585, eval_acc: 0.8489:  30%|[32m███       [0m| 993/3290 [06:04<15:18,  2.50it/s][A[2025-02-04 03:19:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 993/3290, eval_loss: 0.5585, eval_acc: 0.8489:  30%|[32m███       [0m| 994/3290 [06:04<15:44,  2.43it/s][A
step: 994/3290, eval_loss: 0.5580, eval_acc: 0.8490:  30%|[32m███       [0m| 994/3290 [06:04<15:44,  2.43it/s][A[2025-02-04 03:19:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 994/3290, eval_loss: 0.5580, eval_acc: 0.8490:  30%|[32m███       [0m| 995/3290 [06:05<16:36,  2.30it/s][A
step: 995/3290, eval_loss: 0.5579, eval_acc: 0.8491:  30%|[32m███       [0m| 995/3290 [06:05<16:36,  2.30it/s][A[2025-02-04 03:19:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 995/3290, eval_loss: 0.5579, eval_acc: 0.8491:  30%|[32m███       [0m| 996/3290 [06:05<14:41,  2.60it/s][A
step: 996/3290, eval_loss: 0.5574, eval_acc: 0.8492:  30%|[32m███       [0m| 996/3290 [06:05<14:41,  2.60it/s][A[2025-02-04 03:19:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 996/3290, eval_loss: 0.5574, eval_acc: 0.8492:  30%|[32m███       [0m| 997/3290 [06:05<14:36,  2.62it/s][A
step: 997/3290, eval_loss: 0.5570, eval_acc: 0.8493:  30%|[32m███       [0m| 997/3290 [06:05<14:36,  2.62it/s][A[2025-02-04 03:19:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 997/3290, eval_loss: 0.5570, eval_acc: 0.8493:  30%|[32m███       [0m| 998/3290 [06:06<13:10,  2.90it/s][A
step: 998/3290, eval_loss: 0.5566, eval_acc: 0.8494:  30%|[32m███       [0m| 998/3290 [06:06<13:10,  2.90it/s][A[2025-02-04 03:20:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 998/3290, eval_loss: 0.5566, eval_acc: 0.8494:  30%|[32m███       [0m| 999/3290 [06:06<12:10,  3.14it/s][A
step: 999/3290, eval_loss: 0.5567, eval_acc: 0.8494:  30%|[32m███       [0m| 999/3290 [06:06<12:10,  3.14it/s][A[2025-02-04 03:20:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 999/3290, eval_loss: 0.5567, eval_acc: 0.8494:  30%|[32m███       [0m| 1000/3290 [06:06<11:38,  3.28it/s][A
step: 1000/3290, eval_loss: 0.5569, eval_acc: 0.8493:  30%|[32m███       [0m| 1000/3290 [06:06<11:38,  3.28it/s][A[2025-02-04 03:20:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1000/3290, eval_loss: 0.5569, eval_acc: 0.8493:  30%|[32m███       [0m| 1001/3290 [06:06<11:24,  3.34it/s][A
step: 1001/3290, eval_loss: 0.5566, eval_acc: 0.8494:  30%|[32m███       [0m| 1001/3290 [06:06<11:24,  3.34it/s][A[2025-02-04 03:20:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1001/3290, eval_loss: 0.5566, eval_acc: 0.8494:  30%|[32m███       [0m| 1002/3290 [06:07<11:12,  3.40it/s][A
step: 1002/3290, eval_loss: 0.5561, eval_acc: 0.8495:  30%|[32m███       [0m| 1002/3290 [06:07<11:12,  3.40it/s][A[2025-02-04 03:20:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1002/3290, eval_loss: 0.5561, eval_acc: 0.8495:  30%|[32m███       [0m| 1003/3290 [06:07<11:12,  3.40it/s][A
step: 1003/3290, eval_loss: 0.5557, eval_acc: 0.8496:  30%|[32m███       [0m| 1003/3290 [06:07<11:12,  3.40it/s][A[2025-02-04 03:20:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1003/3290, eval_loss: 0.5557, eval_acc: 0.8496:  31%|[32m███       [0m| 1004/3290 [06:07<12:08,  3.14it/s][A
step: 1004/3290, eval_loss: 0.5552, eval_acc: 0.8497:  31%|[32m███       [0m| 1004/3290 [06:07<12:08,  3.14it/s][A[2025-02-04 03:20:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1004/3290, eval_loss: 0.5552, eval_acc: 0.8497:  31%|[32m███       [0m| 1005/3290 [06:08<12:16,  3.10it/s][A
step: 1005/3290, eval_loss: 0.5553, eval_acc: 0.8496:  31%|[32m███       [0m| 1005/3290 [06:08<12:16,  3.10it/s][A[2025-02-04 03:20:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1005/3290, eval_loss: 0.5553, eval_acc: 0.8496:  31%|[32m███       [0m| 1006/3290 [06:08<12:22,  3.08it/s][A
step: 1006/3290, eval_loss: 0.5550, eval_acc: 0.8497:  31%|[32m███       [0m| 1006/3290 [06:08<12:22,  3.08it/s][A[2025-02-04 03:20:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1006/3290, eval_loss: 0.5550, eval_acc: 0.8497:  31%|[32m███       [0m| 1007/3290 [06:08<13:42,  2.77it/s][A
step: 1007/3290, eval_loss: 0.5555, eval_acc: 0.8496:  31%|[32m███       [0m| 1007/3290 [06:08<13:42,  2.77it/s][A[2025-02-04 03:20:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1007/3290, eval_loss: 0.5555, eval_acc: 0.8496:  31%|[32m███       [0m| 1008/3290 [06:09<14:10,  2.68it/s][A
step: 1008/3290, eval_loss: 0.5555, eval_acc: 0.8496:  31%|[32m███       [0m| 1008/3290 [06:09<14:10,  2.68it/s][A[2025-02-04 03:20:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1008/3290, eval_loss: 0.5555, eval_acc: 0.8496:  31%|[32m███       [0m| 1009/3290 [06:09<14:28,  2.63it/s][A
step: 1009/3290, eval_loss: 0.5559, eval_acc: 0.8495:  31%|[32m███       [0m| 1009/3290 [06:09<14:28,  2.63it/s][A[2025-02-04 03:20:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1009/3290, eval_loss: 0.5559, eval_acc: 0.8495:  31%|[32m███       [0m| 1010/3290 [06:10<14:13,  2.67it/s][A
step: 1010/3290, eval_loss: 0.5556, eval_acc: 0.8496:  31%|[32m███       [0m| 1010/3290 [06:10<14:13,  2.67it/s][A[2025-02-04 03:20:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1010/3290, eval_loss: 0.5556, eval_acc: 0.8496:  31%|[32m███       [0m| 1011/3290 [06:10<15:17,  2.48it/s][A
step: 1011/3290, eval_loss: 0.5558, eval_acc: 0.8496:  31%|[32m███       [0m| 1011/3290 [06:10<15:17,  2.48it/s][A[2025-02-04 03:20:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1011/3290, eval_loss: 0.5558, eval_acc: 0.8496:  31%|[32m███       [0m| 1012/3290 [06:11<17:13,  2.20it/s][A
step: 1012/3290, eval_loss: 0.5558, eval_acc: 0.8496:  31%|[32m███       [0m| 1012/3290 [06:11<17:13,  2.20it/s][A[2025-02-04 03:20:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1012/3290, eval_loss: 0.5558, eval_acc: 0.8496:  31%|[32m███       [0m| 1013/3290 [06:11<18:08,  2.09it/s][A
step: 1013/3290, eval_loss: 0.5556, eval_acc: 0.8496:  31%|[32m███       [0m| 1013/3290 [06:11<18:08,  2.09it/s][A[2025-02-04 03:20:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1013/3290, eval_loss: 0.5556, eval_acc: 0.8496:  31%|[32m███       [0m| 1014/3290 [06:12<17:04,  2.22it/s][A
step: 1014/3290, eval_loss: 0.5553, eval_acc: 0.8497:  31%|[32m███       [0m| 1014/3290 [06:12<17:04,  2.22it/s][A[2025-02-04 03:20:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1014/3290, eval_loss: 0.5553, eval_acc: 0.8497:  31%|[32m███       [0m| 1015/3290 [06:12<16:17,  2.33it/s][A
step: 1015/3290, eval_loss: 0.5561, eval_acc: 0.8496:  31%|[32m███       [0m| 1015/3290 [06:12<16:17,  2.33it/s][A[2025-02-04 03:20:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1015/3290, eval_loss: 0.5561, eval_acc: 0.8496:  31%|[32m███       [0m| 1016/3290 [06:12<16:38,  2.28it/s][A
step: 1016/3290, eval_loss: 0.5558, eval_acc: 0.8496:  31%|[32m███       [0m| 1016/3290 [06:12<16:38,  2.28it/s][A[2025-02-04 03:20:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1016/3290, eval_loss: 0.5558, eval_acc: 0.8496:  31%|[32m███       [0m| 1017/3290 [06:13<16:57,  2.23it/s][A
step: 1017/3290, eval_loss: 0.5558, eval_acc: 0.8496:  31%|[32m███       [0m| 1017/3290 [06:13<16:57,  2.23it/s][A[2025-02-04 03:20:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1017/3290, eval_loss: 0.5558, eval_acc: 0.8496:  31%|[32m███       [0m| 1018/3290 [06:13<16:59,  2.23it/s][A
step: 1018/3290, eval_loss: 0.5556, eval_acc: 0.8497:  31%|[32m███       [0m| 1018/3290 [06:13<16:59,  2.23it/s][A[2025-02-04 03:20:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1018/3290, eval_loss: 0.5556, eval_acc: 0.8497:  31%|[32m███       [0m| 1019/3290 [06:14<15:54,  2.38it/s][A
step: 1019/3290, eval_loss: 0.5553, eval_acc: 0.8498:  31%|[32m███       [0m| 1019/3290 [06:14<15:54,  2.38it/s][A[2025-02-04 03:20:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1019/3290, eval_loss: 0.5553, eval_acc: 0.8498:  31%|[32m███       [0m| 1020/3290 [06:14<15:28,  2.44it/s][A
step: 1020/3290, eval_loss: 0.5552, eval_acc: 0.8499:  31%|[32m███       [0m| 1020/3290 [06:14<15:28,  2.44it/s][A[2025-02-04 03:20:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1020/3290, eval_loss: 0.5552, eval_acc: 0.8499:  31%|[32m███       [0m| 1021/3290 [06:15<15:35,  2.43it/s][A
step: 1021/3290, eval_loss: 0.5548, eval_acc: 0.8500:  31%|[32m███       [0m| 1021/3290 [06:15<15:35,  2.43it/s][A[2025-02-04 03:20:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1021/3290, eval_loss: 0.5548, eval_acc: 0.8500:  31%|[32m███       [0m| 1022/3290 [06:15<14:37,  2.59it/s][A
step: 1022/3290, eval_loss: 0.5544, eval_acc: 0.8501:  31%|[32m███       [0m| 1022/3290 [06:15<14:37,  2.59it/s][A[2025-02-04 03:20:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1022/3290, eval_loss: 0.5544, eval_acc: 0.8501:  31%|[32m███       [0m| 1023/3290 [06:15<16:16,  2.32it/s][A
step: 1023/3290, eval_loss: 0.5540, eval_acc: 0.8502:  31%|[32m███       [0m| 1023/3290 [06:15<16:16,  2.32it/s][A[2025-02-04 03:20:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1023/3290, eval_loss: 0.5540, eval_acc: 0.8502:  31%|[32m███       [0m| 1024/3290 [06:16<15:03,  2.51it/s][A
step: 1024/3290, eval_loss: 0.5536, eval_acc: 0.8503:  31%|[32m███       [0m| 1024/3290 [06:16<15:03,  2.51it/s][A[2025-02-04 03:20:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1024/3290, eval_loss: 0.5536, eval_acc: 0.8503:  31%|[32m███       [0m| 1025/3290 [06:16<13:39,  2.76it/s][A
step: 1025/3290, eval_loss: 0.5533, eval_acc: 0.8504:  31%|[32m███       [0m| 1025/3290 [06:16<13:39,  2.76it/s][A[2025-02-04 03:20:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1025/3290, eval_loss: 0.5533, eval_acc: 0.8504:  31%|[32m███       [0m| 1026/3290 [06:16<12:30,  3.02it/s][A
step: 1026/3290, eval_loss: 0.5529, eval_acc: 0.8505:  31%|[32m███       [0m| 1026/3290 [06:16<12:30,  3.02it/s][A[2025-02-04 03:20:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1026/3290, eval_loss: 0.5529, eval_acc: 0.8505:  31%|[32m███       [0m| 1027/3290 [06:17<11:55,  3.16it/s][A
step: 1027/3290, eval_loss: 0.5529, eval_acc: 0.8505:  31%|[32m███       [0m| 1027/3290 [06:17<11:55,  3.16it/s][A[2025-02-04 03:20:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1027/3290, eval_loss: 0.5529, eval_acc: 0.8505:  31%|[32m███       [0m| 1028/3290 [06:17<12:17,  3.07it/s][A
step: 1028/3290, eval_loss: 0.5531, eval_acc: 0.8504:  31%|[32m███       [0m| 1028/3290 [06:17<12:17,  3.07it/s][A[2025-02-04 03:20:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1028/3290, eval_loss: 0.5531, eval_acc: 0.8504:  31%|[32m███▏      [0m| 1029/3290 [06:17<13:19,  2.83it/s][A
step: 1029/3290, eval_loss: 0.5529, eval_acc: 0.8504:  31%|[32m███▏      [0m| 1029/3290 [06:17<13:19,  2.83it/s][A[2025-02-04 03:20:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1029/3290, eval_loss: 0.5529, eval_acc: 0.8504:  31%|[32m███▏      [0m| 1030/3290 [06:18<14:19,  2.63it/s][A
step: 1030/3290, eval_loss: 0.5531, eval_acc: 0.8504:  31%|[32m███▏      [0m| 1030/3290 [06:18<14:19,  2.63it/s][A[2025-02-04 03:20:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1030/3290, eval_loss: 0.5531, eval_acc: 0.8504:  31%|[32m███▏      [0m| 1031/3290 [06:18<14:57,  2.52it/s][A
step: 1031/3290, eval_loss: 0.5529, eval_acc: 0.8505:  31%|[32m███▏      [0m| 1031/3290 [06:18<14:57,  2.52it/s][A[2025-02-04 03:20:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1031/3290, eval_loss: 0.5529, eval_acc: 0.8505:  31%|[32m███▏      [0m| 1032/3290 [06:18<13:18,  2.83it/s][A
step: 1032/3290, eval_loss: 0.5530, eval_acc: 0.8505:  31%|[32m███▏      [0m| 1032/3290 [06:18<13:18,  2.83it/s][A[2025-02-04 03:20:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1032/3290, eval_loss: 0.5530, eval_acc: 0.8505:  31%|[32m███▏      [0m| 1033/3290 [06:19<14:07,  2.66it/s][A
step: 1033/3290, eval_loss: 0.5527, eval_acc: 0.8506:  31%|[32m███▏      [0m| 1033/3290 [06:19<14:07,  2.66it/s][A[2025-02-04 03:20:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1033/3290, eval_loss: 0.5527, eval_acc: 0.8506:  31%|[32m███▏      [0m| 1034/3290 [06:19<13:19,  2.82it/s][A
step: 1034/3290, eval_loss: 0.5522, eval_acc: 0.8507:  31%|[32m███▏      [0m| 1034/3290 [06:19<13:19,  2.82it/s][A[2025-02-04 03:20:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1034/3290, eval_loss: 0.5522, eval_acc: 0.8507:  31%|[32m███▏      [0m| 1035/3290 [06:20<13:34,  2.77it/s][A
step: 1035/3290, eval_loss: 0.5521, eval_acc: 0.8507:  31%|[32m███▏      [0m| 1035/3290 [06:20<13:34,  2.77it/s][A[2025-02-04 03:20:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1035/3290, eval_loss: 0.5521, eval_acc: 0.8507:  31%|[32m███▏      [0m| 1036/3290 [06:20<14:03,  2.67it/s][A
step: 1036/3290, eval_loss: 0.5517, eval_acc: 0.8508:  31%|[32m███▏      [0m| 1036/3290 [06:20<14:03,  2.67it/s][A[2025-02-04 03:20:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1036/3290, eval_loss: 0.5517, eval_acc: 0.8508:  32%|[32m███▏      [0m| 1037/3290 [06:20<15:54,  2.36it/s][A
step: 1037/3290, eval_loss: 0.5513, eval_acc: 0.8509:  32%|[32m███▏      [0m| 1037/3290 [06:20<15:54,  2.36it/s][A[2025-02-04 03:20:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1037/3290, eval_loss: 0.5513, eval_acc: 0.8509:  32%|[32m███▏      [0m| 1038/3290 [06:21<15:01,  2.50it/s][A
step: 1038/3290, eval_loss: 0.5509, eval_acc: 0.8510:  32%|[32m███▏      [0m| 1038/3290 [06:21<15:01,  2.50it/s][A[2025-02-04 03:20:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1038/3290, eval_loss: 0.5509, eval_acc: 0.8510:  32%|[32m███▏      [0m| 1039/3290 [06:21<14:48,  2.53it/s][A
step: 1039/3290, eval_loss: 0.5504, eval_acc: 0.8511:  32%|[32m███▏      [0m| 1039/3290 [06:21<14:48,  2.53it/s][A[2025-02-04 03:20:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1039/3290, eval_loss: 0.5504, eval_acc: 0.8511:  32%|[32m███▏      [0m| 1040/3290 [06:22<15:52,  2.36it/s][A
step: 1040/3290, eval_loss: 0.5500, eval_acc: 0.8512:  32%|[32m███▏      [0m| 1040/3290 [06:22<15:52,  2.36it/s][A[2025-02-04 03:20:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1040/3290, eval_loss: 0.5500, eval_acc: 0.8512:  32%|[32m███▏      [0m| 1041/3290 [06:22<15:02,  2.49it/s][A
step: 1041/3290, eval_loss: 0.5496, eval_acc: 0.8514:  32%|[32m███▏      [0m| 1041/3290 [06:22<15:02,  2.49it/s][A[2025-02-04 03:20:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1041/3290, eval_loss: 0.5496, eval_acc: 0.8514:  32%|[32m███▏      [0m| 1042/3290 [06:22<15:30,  2.41it/s][A
step: 1042/3290, eval_loss: 0.5493, eval_acc: 0.8514:  32%|[32m███▏      [0m| 1042/3290 [06:22<15:30,  2.41it/s][A[2025-02-04 03:20:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1042/3290, eval_loss: 0.5493, eval_acc: 0.8514:  32%|[32m███▏      [0m| 1043/3290 [06:23<15:21,  2.44it/s][A
step: 1043/3290, eval_loss: 0.5492, eval_acc: 0.8515:  32%|[32m███▏      [0m| 1043/3290 [06:23<15:21,  2.44it/s][A[2025-02-04 03:20:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1043/3290, eval_loss: 0.5492, eval_acc: 0.8515:  32%|[32m███▏      [0m| 1044/3290 [06:23<14:06,  2.65it/s][A
step: 1044/3290, eval_loss: 0.5490, eval_acc: 0.8515:  32%|[32m███▏      [0m| 1044/3290 [06:23<14:06,  2.65it/s][A[2025-02-04 03:20:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1044/3290, eval_loss: 0.5490, eval_acc: 0.8515:  32%|[32m███▏      [0m| 1045/3290 [06:24<14:34,  2.57it/s][A
step: 1045/3290, eval_loss: 0.5490, eval_acc: 0.8515:  32%|[32m███▏      [0m| 1045/3290 [06:24<14:34,  2.57it/s][A[2025-02-04 03:20:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1045/3290, eval_loss: 0.5490, eval_acc: 0.8515:  32%|[32m███▏      [0m| 1046/3290 [06:24<13:24,  2.79it/s][A
step: 1046/3290, eval_loss: 0.5489, eval_acc: 0.8516:  32%|[32m███▏      [0m| 1046/3290 [06:24<13:24,  2.79it/s][A[2025-02-04 03:20:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1046/3290, eval_loss: 0.5489, eval_acc: 0.8516:  32%|[32m███▏      [0m| 1047/3290 [06:24<13:18,  2.81it/s][A
step: 1047/3290, eval_loss: 0.5485, eval_acc: 0.8517:  32%|[32m███▏      [0m| 1047/3290 [06:24<13:18,  2.81it/s][A[2025-02-04 03:20:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1047/3290, eval_loss: 0.5485, eval_acc: 0.8517:  32%|[32m███▏      [0m| 1048/3290 [06:25<13:02,  2.87it/s][A
step: 1048/3290, eval_loss: 0.5480, eval_acc: 0.8518:  32%|[32m███▏      [0m| 1048/3290 [06:25<13:02,  2.87it/s][A[2025-02-04 03:20:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1048/3290, eval_loss: 0.5480, eval_acc: 0.8518:  32%|[32m███▏      [0m| 1049/3290 [06:25<12:17,  3.04it/s][A
step: 1049/3290, eval_loss: 0.5476, eval_acc: 0.8519:  32%|[32m███▏      [0m| 1049/3290 [06:25<12:17,  3.04it/s][A[2025-02-04 03:20:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1049/3290, eval_loss: 0.5476, eval_acc: 0.8519:  32%|[32m███▏      [0m| 1050/3290 [06:25<12:52,  2.90it/s][A
step: 1050/3290, eval_loss: 0.5473, eval_acc: 0.8520:  32%|[32m███▏      [0m| 1050/3290 [06:25<12:52,  2.90it/s][A[2025-02-04 03:20:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1050/3290, eval_loss: 0.5473, eval_acc: 0.8520:  32%|[32m███▏      [0m| 1051/3290 [06:26<12:47,  2.92it/s][A
step: 1051/3290, eval_loss: 0.5470, eval_acc: 0.8521:  32%|[32m███▏      [0m| 1051/3290 [06:26<12:47,  2.92it/s][A[2025-02-04 03:20:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1051/3290, eval_loss: 0.5470, eval_acc: 0.8521:  32%|[32m███▏      [0m| 1052/3290 [06:26<12:44,  2.93it/s][A
step: 1052/3290, eval_loss: 0.5470, eval_acc: 0.8521:  32%|[32m███▏      [0m| 1052/3290 [06:26<12:44,  2.93it/s][A[2025-02-04 03:20:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1052/3290, eval_loss: 0.5470, eval_acc: 0.8521:  32%|[32m███▏      [0m| 1053/3290 [06:26<12:44,  2.93it/s][A
step: 1053/3290, eval_loss: 0.5465, eval_acc: 0.8523:  32%|[32m███▏      [0m| 1053/3290 [06:26<12:44,  2.93it/s][A[2025-02-04 03:20:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1053/3290, eval_loss: 0.5465, eval_acc: 0.8523:  32%|[32m███▏      [0m| 1054/3290 [06:27<12:55,  2.88it/s][A
step: 1054/3290, eval_loss: 0.5464, eval_acc: 0.8523:  32%|[32m███▏      [0m| 1054/3290 [06:27<12:55,  2.88it/s][A[2025-02-04 03:20:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1054/3290, eval_loss: 0.5464, eval_acc: 0.8523:  32%|[32m███▏      [0m| 1055/3290 [06:27<13:32,  2.75it/s][A
step: 1055/3290, eval_loss: 0.5464, eval_acc: 0.8523:  32%|[32m███▏      [0m| 1055/3290 [06:27<13:32,  2.75it/s][A[2025-02-04 03:20:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1055/3290, eval_loss: 0.5464, eval_acc: 0.8523:  32%|[32m███▏      [0m| 1056/3290 [06:27<14:12,  2.62it/s][A
step: 1056/3290, eval_loss: 0.5460, eval_acc: 0.8524:  32%|[32m███▏      [0m| 1056/3290 [06:27<14:12,  2.62it/s][A[2025-02-04 03:20:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1056/3290, eval_loss: 0.5460, eval_acc: 0.8524:  32%|[32m███▏      [0m| 1057/3290 [06:28<14:58,  2.49it/s][A
step: 1057/3290, eval_loss: 0.5456, eval_acc: 0.8525:  32%|[32m███▏      [0m| 1057/3290 [06:28<14:58,  2.49it/s][A[2025-02-04 03:20:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1057/3290, eval_loss: 0.5456, eval_acc: 0.8525:  32%|[32m███▏      [0m| 1058/3290 [06:28<15:17,  2.43it/s][A
step: 1058/3290, eval_loss: 0.5454, eval_acc: 0.8525:  32%|[32m███▏      [0m| 1058/3290 [06:28<15:17,  2.43it/s][A[2025-02-04 03:20:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1058/3290, eval_loss: 0.5454, eval_acc: 0.8525:  32%|[32m███▏      [0m| 1059/3290 [06:29<15:03,  2.47it/s][A
step: 1059/3290, eval_loss: 0.5452, eval_acc: 0.8526:  32%|[32m███▏      [0m| 1059/3290 [06:29<15:03,  2.47it/s][A[2025-02-04 03:20:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1059/3290, eval_loss: 0.5452, eval_acc: 0.8526:  32%|[32m███▏      [0m| 1060/3290 [06:29<14:27,  2.57it/s][A
step: 1060/3290, eval_loss: 0.5451, eval_acc: 0.8527:  32%|[32m███▏      [0m| 1060/3290 [06:29<14:27,  2.57it/s][A[2025-02-04 03:20:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1060/3290, eval_loss: 0.5451, eval_acc: 0.8527:  32%|[32m███▏      [0m| 1061/3290 [06:29<14:47,  2.51it/s][A
step: 1061/3290, eval_loss: 0.5449, eval_acc: 0.8527:  32%|[32m███▏      [0m| 1061/3290 [06:29<14:47,  2.51it/s][A[2025-02-04 03:20:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1061/3290, eval_loss: 0.5449, eval_acc: 0.8527:  32%|[32m███▏      [0m| 1062/3290 [06:30<13:31,  2.75it/s][A
step: 1062/3290, eval_loss: 0.5448, eval_acc: 0.8527:  32%|[32m███▏      [0m| 1062/3290 [06:30<13:31,  2.75it/s][A[2025-02-04 03:20:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1062/3290, eval_loss: 0.5448, eval_acc: 0.8527:  32%|[32m███▏      [0m| 1063/3290 [06:30<12:14,  3.03it/s][A
step: 1063/3290, eval_loss: 0.5445, eval_acc: 0.8528:  32%|[32m███▏      [0m| 1063/3290 [06:30<12:14,  3.03it/s][A[2025-02-04 03:20:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1063/3290, eval_loss: 0.5445, eval_acc: 0.8528:  32%|[32m███▏      [0m| 1064/3290 [06:30<11:18,  3.28it/s][A
step: 1064/3290, eval_loss: 0.5443, eval_acc: 0.8528:  32%|[32m███▏      [0m| 1064/3290 [06:30<11:18,  3.28it/s][A[2025-02-04 03:20:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1064/3290, eval_loss: 0.5443, eval_acc: 0.8528:  32%|[32m███▏      [0m| 1065/3290 [06:31<12:47,  2.90it/s][A
step: 1065/3290, eval_loss: 0.5438, eval_acc: 0.8529:  32%|[32m███▏      [0m| 1065/3290 [06:31<12:47,  2.90it/s][A[2025-02-04 03:20:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1065/3290, eval_loss: 0.5438, eval_acc: 0.8529:  32%|[32m███▏      [0m| 1066/3290 [06:31<13:18,  2.79it/s][A
step: 1066/3290, eval_loss: 0.5433, eval_acc: 0.8531:  32%|[32m███▏      [0m| 1066/3290 [06:31<13:18,  2.79it/s][A[2025-02-04 03:20:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1066/3290, eval_loss: 0.5433, eval_acc: 0.8531:  32%|[32m███▏      [0m| 1067/3290 [06:31<13:09,  2.81it/s][A
step: 1067/3290, eval_loss: 0.5434, eval_acc: 0.8531:  32%|[32m███▏      [0m| 1067/3290 [06:31<13:09,  2.81it/s][A[2025-02-04 03:20:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1067/3290, eval_loss: 0.5434, eval_acc: 0.8531:  32%|[32m███▏      [0m| 1068/3290 [06:32<13:00,  2.85it/s][A
step: 1068/3290, eval_loss: 0.5434, eval_acc: 0.8531:  32%|[32m███▏      [0m| 1068/3290 [06:32<13:00,  2.85it/s][A[2025-02-04 03:20:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1068/3290, eval_loss: 0.5434, eval_acc: 0.8531:  32%|[32m███▏      [0m| 1069/3290 [06:32<13:55,  2.66it/s][A
step: 1069/3290, eval_loss: 0.5430, eval_acc: 0.8532:  32%|[32m███▏      [0m| 1069/3290 [06:32<13:55,  2.66it/s][A[2025-02-04 03:20:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1069/3290, eval_loss: 0.5430, eval_acc: 0.8532:  33%|[32m███▎      [0m| 1070/3290 [06:33<13:13,  2.80it/s][A
step: 1070/3290, eval_loss: 0.5434, eval_acc: 0.8531:  33%|[32m███▎      [0m| 1070/3290 [06:33<13:13,  2.80it/s][A[2025-02-04 03:20:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1070/3290, eval_loss: 0.5434, eval_acc: 0.8531:  33%|[32m███▎      [0m| 1071/3290 [06:33<12:36,  2.93it/s][A
step: 1071/3290, eval_loss: 0.5434, eval_acc: 0.8531:  33%|[32m███▎      [0m| 1071/3290 [06:33<12:36,  2.93it/s][A[2025-02-04 03:20:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1071/3290, eval_loss: 0.5434, eval_acc: 0.8531:  33%|[32m███▎      [0m| 1072/3290 [06:33<13:09,  2.81it/s][A
step: 1072/3290, eval_loss: 0.5432, eval_acc: 0.8532:  33%|[32m███▎      [0m| 1072/3290 [06:33<13:09,  2.81it/s][A[2025-02-04 03:20:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1072/3290, eval_loss: 0.5432, eval_acc: 0.8532:  33%|[32m███▎      [0m| 1073/3290 [06:34<13:12,  2.80it/s][A
step: 1073/3290, eval_loss: 0.5433, eval_acc: 0.8532:  33%|[32m███▎      [0m| 1073/3290 [06:34<13:12,  2.80it/s][A[2025-02-04 03:20:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1073/3290, eval_loss: 0.5433, eval_acc: 0.8532:  33%|[32m███▎      [0m| 1074/3290 [06:34<12:59,  2.84it/s][A
step: 1074/3290, eval_loss: 0.5437, eval_acc: 0.8531:  33%|[32m███▎      [0m| 1074/3290 [06:34<12:59,  2.84it/s][A[2025-02-04 03:20:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1074/3290, eval_loss: 0.5437, eval_acc: 0.8531:  33%|[32m███▎      [0m| 1075/3290 [06:34<12:49,  2.88it/s][A
step: 1075/3290, eval_loss: 0.5443, eval_acc: 0.8531:  33%|[32m███▎      [0m| 1075/3290 [06:34<12:49,  2.88it/s][A[2025-02-04 03:20:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1075/3290, eval_loss: 0.5443, eval_acc: 0.8531:  33%|[32m███▎      [0m| 1076/3290 [06:35<13:26,  2.75it/s][A
step: 1076/3290, eval_loss: 0.5445, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1076/3290 [06:35<13:26,  2.75it/s][A[2025-02-04 03:20:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1076/3290, eval_loss: 0.5445, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1077/3290 [06:35<13:10,  2.80it/s][A
step: 1077/3290, eval_loss: 0.5445, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1077/3290 [06:35<13:10,  2.80it/s][A[2025-02-04 03:20:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1077/3290, eval_loss: 0.5445, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1078/3290 [06:35<13:24,  2.75it/s][A
step: 1078/3290, eval_loss: 0.5447, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1078/3290 [06:35<13:24,  2.75it/s][A[2025-02-04 03:20:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1078/3290, eval_loss: 0.5447, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1079/3290 [06:36<13:30,  2.73it/s][A
step: 1079/3290, eval_loss: 0.5448, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1079/3290 [06:36<13:30,  2.73it/s][A[2025-02-04 03:20:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1079/3290, eval_loss: 0.5448, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1080/3290 [06:36<12:49,  2.87it/s][A
step: 1080/3290, eval_loss: 0.5450, eval_acc: 0.8529:  33%|[32m███▎      [0m| 1080/3290 [06:36<12:49,  2.87it/s][A[2025-02-04 03:20:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1080/3290, eval_loss: 0.5450, eval_acc: 0.8529:  33%|[32m███▎      [0m| 1081/3290 [06:36<12:44,  2.89it/s][A
step: 1081/3290, eval_loss: 0.5451, eval_acc: 0.8529:  33%|[32m███▎      [0m| 1081/3290 [06:36<12:44,  2.89it/s][A[2025-02-04 03:20:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1081/3290, eval_loss: 0.5451, eval_acc: 0.8529:  33%|[32m███▎      [0m| 1082/3290 [06:37<15:13,  2.42it/s][A
step: 1082/3290, eval_loss: 0.5447, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1082/3290 [06:37<15:13,  2.42it/s][A[2025-02-04 03:20:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1082/3290, eval_loss: 0.5447, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1083/3290 [06:37<13:33,  2.71it/s][A
step: 1083/3290, eval_loss: 0.5449, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1083/3290 [06:37<13:33,  2.71it/s][A[2025-02-04 03:20:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1083/3290, eval_loss: 0.5449, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1084/3290 [06:38<13:45,  2.67it/s][A
step: 1084/3290, eval_loss: 0.5447, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1084/3290 [06:38<13:45,  2.67it/s][A[2025-02-04 03:20:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1084/3290, eval_loss: 0.5447, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1085/3290 [06:38<13:21,  2.75it/s][A
step: 1085/3290, eval_loss: 0.5449, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1085/3290 [06:38<13:21,  2.75it/s][A[2025-02-04 03:20:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1085/3290, eval_loss: 0.5449, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1086/3290 [06:38<14:28,  2.54it/s][A
step: 1086/3290, eval_loss: 0.5448, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1086/3290 [06:38<14:28,  2.54it/s][A[2025-02-04 03:20:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1086/3290, eval_loss: 0.5448, eval_acc: 0.8530:  33%|[32m███▎      [0m| 1087/3290 [06:39<14:50,  2.47it/s][A
step: 1087/3290, eval_loss: 0.5454, eval_acc: 0.8529:  33%|[32m███▎      [0m| 1087/3290 [06:39<14:50,  2.47it/s][A[2025-02-04 03:20:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1087/3290, eval_loss: 0.5454, eval_acc: 0.8529:  33%|[32m███▎      [0m| 1088/3290 [06:39<14:26,  2.54it/s][A
step: 1088/3290, eval_loss: 0.5454, eval_acc: 0.8529:  33%|[32m███▎      [0m| 1088/3290 [06:39<14:26,  2.54it/s][A[2025-02-04 03:20:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1088/3290, eval_loss: 0.5454, eval_acc: 0.8529:  33%|[32m███▎      [0m| 1089/3290 [06:40<14:01,  2.62it/s][A
step: 1089/3290, eval_loss: 0.5456, eval_acc: 0.8528:  33%|[32m███▎      [0m| 1089/3290 [06:40<14:01,  2.62it/s][A[2025-02-04 03:20:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1089/3290, eval_loss: 0.5456, eval_acc: 0.8528:  33%|[32m███▎      [0m| 1090/3290 [06:40<14:16,  2.57it/s][A
step: 1090/3290, eval_loss: 0.5457, eval_acc: 0.8528:  33%|[32m███▎      [0m| 1090/3290 [06:40<14:16,  2.57it/s][A[2025-02-04 03:20:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1090/3290, eval_loss: 0.5457, eval_acc: 0.8528:  33%|[32m███▎      [0m| 1091/3290 [06:40<13:33,  2.70it/s][A
step: 1091/3290, eval_loss: 0.5460, eval_acc: 0.8528:  33%|[32m███▎      [0m| 1091/3290 [06:40<13:33,  2.70it/s][A[2025-02-04 03:20:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1091/3290, eval_loss: 0.5460, eval_acc: 0.8528:  33%|[32m███▎      [0m| 1092/3290 [06:41<13:04,  2.80it/s][A
step: 1092/3290, eval_loss: 0.5460, eval_acc: 0.8528:  33%|[32m███▎      [0m| 1092/3290 [06:41<13:04,  2.80it/s][A[2025-02-04 03:20:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1092/3290, eval_loss: 0.5460, eval_acc: 0.8528:  33%|[32m███▎      [0m| 1093/3290 [06:41<13:48,  2.65it/s][A
step: 1093/3290, eval_loss: 0.5467, eval_acc: 0.8527:  33%|[32m███▎      [0m| 1093/3290 [06:41<13:48,  2.65it/s][A[2025-02-04 03:20:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1093/3290, eval_loss: 0.5467, eval_acc: 0.8527:  33%|[32m███▎      [0m| 1094/3290 [06:41<14:16,  2.56it/s][A
step: 1094/3290, eval_loss: 0.5470, eval_acc: 0.8526:  33%|[32m███▎      [0m| 1094/3290 [06:41<14:16,  2.56it/s][A[2025-02-04 03:20:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1094/3290, eval_loss: 0.5470, eval_acc: 0.8526:  33%|[32m███▎      [0m| 1095/3290 [06:42<14:50,  2.46it/s][A
step: 1095/3290, eval_loss: 0.5471, eval_acc: 0.8526:  33%|[32m███▎      [0m| 1095/3290 [06:42<14:50,  2.46it/s][A[2025-02-04 03:20:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1095/3290, eval_loss: 0.5471, eval_acc: 0.8526:  33%|[32m███▎      [0m| 1096/3290 [06:42<13:22,  2.73it/s][A
step: 1096/3290, eval_loss: 0.5468, eval_acc: 0.8527:  33%|[32m███▎      [0m| 1096/3290 [06:42<13:22,  2.73it/s][A[2025-02-04 03:20:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1096/3290, eval_loss: 0.5468, eval_acc: 0.8527:  33%|[32m███▎      [0m| 1097/3290 [06:43<12:59,  2.81it/s][A
step: 1097/3290, eval_loss: 0.5467, eval_acc: 0.8527:  33%|[32m███▎      [0m| 1097/3290 [06:43<12:59,  2.81it/s][A[2025-02-04 03:20:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1097/3290, eval_loss: 0.5467, eval_acc: 0.8527:  33%|[32m███▎      [0m| 1098/3290 [06:43<13:20,  2.74it/s][A
step: 1098/3290, eval_loss: 0.5470, eval_acc: 0.8527:  33%|[32m███▎      [0m| 1098/3290 [06:43<13:20,  2.74it/s][A[2025-02-04 03:20:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1098/3290, eval_loss: 0.5470, eval_acc: 0.8527:  33%|[32m███▎      [0m| 1099/3290 [06:43<13:31,  2.70it/s][A
step: 1099/3290, eval_loss: 0.5471, eval_acc: 0.8527:  33%|[32m███▎      [0m| 1099/3290 [06:43<13:31,  2.70it/s][A[2025-02-04 03:20:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1099/3290, eval_loss: 0.5471, eval_acc: 0.8527:  33%|[32m███▎      [0m| 1100/3290 [06:44<13:38,  2.68it/s][A
step: 1100/3290, eval_loss: 0.5471, eval_acc: 0.8527:  33%|[32m███▎      [0m| 1100/3290 [06:44<13:38,  2.68it/s][A[2025-02-04 03:20:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1100/3290, eval_loss: 0.5471, eval_acc: 0.8527:  33%|[32m███▎      [0m| 1101/3290 [06:44<13:06,  2.78it/s][A
step: 1101/3290, eval_loss: 0.5477, eval_acc: 0.8525:  33%|[32m███▎      [0m| 1101/3290 [06:44<13:06,  2.78it/s][A[2025-02-04 03:20:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1101/3290, eval_loss: 0.5477, eval_acc: 0.8525:  33%|[32m███▎      [0m| 1102/3290 [06:44<14:18,  2.55it/s][A
step: 1102/3290, eval_loss: 0.5479, eval_acc: 0.8525:  33%|[32m███▎      [0m| 1102/3290 [06:44<14:18,  2.55it/s][A[2025-02-04 03:20:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1102/3290, eval_loss: 0.5479, eval_acc: 0.8525:  34%|[32m███▎      [0m| 1103/3290 [06:45<13:22,  2.72it/s][A
step: 1103/3290, eval_loss: 0.5479, eval_acc: 0.8526:  34%|[32m███▎      [0m| 1103/3290 [06:45<13:22,  2.72it/s][A[2025-02-04 03:20:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1103/3290, eval_loss: 0.5479, eval_acc: 0.8526:  34%|[32m███▎      [0m| 1104/3290 [06:45<13:07,  2.77it/s][A
step: 1104/3290, eval_loss: 0.5482, eval_acc: 0.8525:  34%|[32m███▎      [0m| 1104/3290 [06:45<13:07,  2.77it/s][A[2025-02-04 03:20:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1104/3290, eval_loss: 0.5482, eval_acc: 0.8525:  34%|[32m███▎      [0m| 1105/3290 [06:46<13:36,  2.68it/s][A
step: 1105/3290, eval_loss: 0.5483, eval_acc: 0.8525:  34%|[32m███▎      [0m| 1105/3290 [06:46<13:36,  2.68it/s][A[2025-02-04 03:20:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1105/3290, eval_loss: 0.5483, eval_acc: 0.8525:  34%|[32m███▎      [0m| 1106/3290 [06:46<13:09,  2.77it/s][A
step: 1106/3290, eval_loss: 0.5482, eval_acc: 0.8525:  34%|[32m███▎      [0m| 1106/3290 [06:46<13:09,  2.77it/s][A[2025-02-04 03:20:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1106/3290, eval_loss: 0.5482, eval_acc: 0.8525:  34%|[32m███▎      [0m| 1107/3290 [06:46<13:39,  2.66it/s][A
step: 1107/3290, eval_loss: 0.5480, eval_acc: 0.8526:  34%|[32m███▎      [0m| 1107/3290 [06:46<13:39,  2.66it/s][A[2025-02-04 03:20:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1107/3290, eval_loss: 0.5480, eval_acc: 0.8526:  34%|[32m███▎      [0m| 1108/3290 [06:47<13:21,  2.72it/s][A
step: 1108/3290, eval_loss: 0.5484, eval_acc: 0.8525:  34%|[32m███▎      [0m| 1108/3290 [06:47<13:21,  2.72it/s][A[2025-02-04 03:20:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1108/3290, eval_loss: 0.5484, eval_acc: 0.8525:  34%|[32m███▎      [0m| 1109/3290 [06:47<13:23,  2.71it/s][A
step: 1109/3290, eval_loss: 0.5486, eval_acc: 0.8525:  34%|[32m███▎      [0m| 1109/3290 [06:47<13:23,  2.71it/s][A[2025-02-04 03:20:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1109/3290, eval_loss: 0.5486, eval_acc: 0.8525:  34%|[32m███▎      [0m| 1110/3290 [06:47<13:30,  2.69it/s][A
step: 1110/3290, eval_loss: 0.5486, eval_acc: 0.8525:  34%|[32m███▎      [0m| 1110/3290 [06:47<13:30,  2.69it/s][A[2025-02-04 03:20:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1110/3290, eval_loss: 0.5486, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1111/3290 [06:48<13:46,  2.64it/s][A
step: 1111/3290, eval_loss: 0.5485, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1111/3290 [06:48<13:46,  2.64it/s][A[2025-02-04 03:20:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1111/3290, eval_loss: 0.5485, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1112/3290 [06:48<13:57,  2.60it/s][A
step: 1112/3290, eval_loss: 0.5484, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1112/3290 [06:48<13:57,  2.60it/s][A[2025-02-04 03:20:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1112/3290, eval_loss: 0.5484, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1113/3290 [06:48<13:16,  2.73it/s][A
step: 1113/3290, eval_loss: 0.5485, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1113/3290 [06:48<13:16,  2.73it/s][A[2025-02-04 03:20:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1113/3290, eval_loss: 0.5485, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1114/3290 [06:49<13:11,  2.75it/s][A
step: 1114/3290, eval_loss: 0.5486, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1114/3290 [06:49<13:11,  2.75it/s][A[2025-02-04 03:20:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1114/3290, eval_loss: 0.5486, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1115/3290 [06:49<12:17,  2.95it/s][A
step: 1115/3290, eval_loss: 0.5487, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1115/3290 [06:49<12:17,  2.95it/s][A[2025-02-04 03:20:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1115/3290, eval_loss: 0.5487, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1116/3290 [06:49<11:50,  3.06it/s][A
step: 1116/3290, eval_loss: 0.5484, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1116/3290 [06:49<11:50,  3.06it/s][A[2025-02-04 03:20:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1116/3290, eval_loss: 0.5484, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1117/3290 [06:50<11:15,  3.22it/s][A
step: 1117/3290, eval_loss: 0.5487, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1117/3290 [06:50<11:15,  3.22it/s][A[2025-02-04 03:20:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1117/3290, eval_loss: 0.5487, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1118/3290 [06:50<10:44,  3.37it/s][A
step: 1118/3290, eval_loss: 0.5488, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1118/3290 [06:50<10:44,  3.37it/s][A[2025-02-04 03:20:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1118/3290, eval_loss: 0.5488, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1119/3290 [06:50<10:47,  3.35it/s][A
step: 1119/3290, eval_loss: 0.5489, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1119/3290 [06:50<10:47,  3.35it/s][A[2025-02-04 03:20:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1119/3290, eval_loss: 0.5489, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1120/3290 [06:51<11:56,  3.03it/s][A
step: 1120/3290, eval_loss: 0.5496, eval_acc: 0.8523:  34%|[32m███▍      [0m| 1120/3290 [06:51<11:56,  3.03it/s][A[2025-02-04 03:20:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1120/3290, eval_loss: 0.5496, eval_acc: 0.8523:  34%|[32m███▍      [0m| 1121/3290 [06:51<12:50,  2.82it/s][A
step: 1121/3290, eval_loss: 0.5496, eval_acc: 0.8523:  34%|[32m███▍      [0m| 1121/3290 [06:51<12:50,  2.82it/s][A[2025-02-04 03:20:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1121/3290, eval_loss: 0.5496, eval_acc: 0.8523:  34%|[32m███▍      [0m| 1122/3290 [06:51<13:14,  2.73it/s][A
step: 1122/3290, eval_loss: 0.5496, eval_acc: 0.8523:  34%|[32m███▍      [0m| 1122/3290 [06:51<13:14,  2.73it/s][A[2025-02-04 03:20:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1122/3290, eval_loss: 0.5496, eval_acc: 0.8523:  34%|[32m███▍      [0m| 1123/3290 [06:52<12:27,  2.90it/s][A
step: 1123/3290, eval_loss: 0.5496, eval_acc: 0.8523:  34%|[32m███▍      [0m| 1123/3290 [06:52<12:27,  2.90it/s][A[2025-02-04 03:20:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1123/3290, eval_loss: 0.5496, eval_acc: 0.8523:  34%|[32m███▍      [0m| 1124/3290 [06:52<11:50,  3.05it/s][A
step: 1124/3290, eval_loss: 0.5496, eval_acc: 0.8523:  34%|[32m███▍      [0m| 1124/3290 [06:52<11:50,  3.05it/s][A[2025-02-04 03:20:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1124/3290, eval_loss: 0.5496, eval_acc: 0.8523:  34%|[32m███▍      [0m| 1125/3290 [06:52<11:28,  3.15it/s][A
step: 1125/3290, eval_loss: 0.5493, eval_acc: 0.8524:  34%|[32m███▍      [0m| 1125/3290 [06:52<11:28,  3.15it/s][A[2025-02-04 03:20:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1125/3290, eval_loss: 0.5493, eval_acc: 0.8524:  34%|[32m███▍      [0m| 1126/3290 [06:53<14:21,  2.51it/s][A
step: 1126/3290, eval_loss: 0.5493, eval_acc: 0.8524:  34%|[32m███▍      [0m| 1126/3290 [06:53<14:21,  2.51it/s][A[2025-02-04 03:20:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1126/3290, eval_loss: 0.5493, eval_acc: 0.8524:  34%|[32m███▍      [0m| 1127/3290 [06:53<13:53,  2.60it/s][A
step: 1127/3290, eval_loss: 0.5489, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1127/3290 [06:53<13:53,  2.60it/s][A[2025-02-04 03:20:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1127/3290, eval_loss: 0.5489, eval_acc: 0.8525:  34%|[32m███▍      [0m| 1128/3290 [06:54<13:59,  2.57it/s][A
step: 1128/3290, eval_loss: 0.5485, eval_acc: 0.8526:  34%|[32m███▍      [0m| 1128/3290 [06:54<13:59,  2.57it/s][A[2025-02-04 03:20:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1128/3290, eval_loss: 0.5485, eval_acc: 0.8526:  34%|[32m███▍      [0m| 1129/3290 [06:54<13:41,  2.63it/s][A
step: 1129/3290, eval_loss: 0.5482, eval_acc: 0.8527:  34%|[32m███▍      [0m| 1129/3290 [06:54<13:41,  2.63it/s][A[2025-02-04 03:20:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1129/3290, eval_loss: 0.5482, eval_acc: 0.8527:  34%|[32m███▍      [0m| 1130/3290 [06:54<13:20,  2.70it/s][A
step: 1130/3290, eval_loss: 0.5480, eval_acc: 0.8527:  34%|[32m███▍      [0m| 1130/3290 [06:54<13:20,  2.70it/s][A[2025-02-04 03:20:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1130/3290, eval_loss: 0.5480, eval_acc: 0.8527:  34%|[32m███▍      [0m| 1131/3290 [06:55<12:35,  2.86it/s][A
step: 1131/3290, eval_loss: 0.5478, eval_acc: 0.8528:  34%|[32m███▍      [0m| 1131/3290 [06:55<12:35,  2.86it/s][A[2025-02-04 03:20:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1131/3290, eval_loss: 0.5478, eval_acc: 0.8528:  34%|[32m███▍      [0m| 1132/3290 [06:55<13:13,  2.72it/s][A
step: 1132/3290, eval_loss: 0.5475, eval_acc: 0.8529:  34%|[32m███▍      [0m| 1132/3290 [06:55<13:13,  2.72it/s][A[2025-02-04 03:20:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1132/3290, eval_loss: 0.5475, eval_acc: 0.8529:  34%|[32m███▍      [0m| 1133/3290 [06:55<13:15,  2.71it/s][A
step: 1133/3290, eval_loss: 0.5470, eval_acc: 0.8530:  34%|[32m███▍      [0m| 1133/3290 [06:55<13:15,  2.71it/s][A[2025-02-04 03:20:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1133/3290, eval_loss: 0.5470, eval_acc: 0.8530:  34%|[32m███▍      [0m| 1134/3290 [06:56<13:42,  2.62it/s][A
step: 1134/3290, eval_loss: 0.5469, eval_acc: 0.8530:  34%|[32m███▍      [0m| 1134/3290 [06:56<13:42,  2.62it/s][A[2025-02-04 03:20:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1134/3290, eval_loss: 0.5469, eval_acc: 0.8530:  34%|[32m███▍      [0m| 1135/3290 [06:56<13:35,  2.64it/s][A
step: 1135/3290, eval_loss: 0.5465, eval_acc: 0.8531:  34%|[32m███▍      [0m| 1135/3290 [06:56<13:35,  2.64it/s][A[2025-02-04 03:20:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1135/3290, eval_loss: 0.5465, eval_acc: 0.8531:  35%|[32m███▍      [0m| 1136/3290 [06:57<14:14,  2.52it/s][A
step: 1136/3290, eval_loss: 0.5461, eval_acc: 0.8532:  35%|[32m███▍      [0m| 1136/3290 [06:57<14:14,  2.52it/s][A[2025-02-04 03:20:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1136/3290, eval_loss: 0.5461, eval_acc: 0.8532:  35%|[32m███▍      [0m| 1137/3290 [06:57<14:21,  2.50it/s][A
step: 1137/3290, eval_loss: 0.5457, eval_acc: 0.8533:  35%|[32m███▍      [0m| 1137/3290 [06:57<14:21,  2.50it/s][A[2025-02-04 03:20:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1137/3290, eval_loss: 0.5457, eval_acc: 0.8533:  35%|[32m███▍      [0m| 1138/3290 [06:57<13:42,  2.62it/s][A
step: 1138/3290, eval_loss: 0.5455, eval_acc: 0.8534:  35%|[32m███▍      [0m| 1138/3290 [06:57<13:42,  2.62it/s][A[2025-02-04 03:20:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1138/3290, eval_loss: 0.5455, eval_acc: 0.8534:  35%|[32m███▍      [0m| 1139/3290 [06:58<13:45,  2.60it/s][A
step: 1139/3290, eval_loss: 0.5452, eval_acc: 0.8535:  35%|[32m███▍      [0m| 1139/3290 [06:58<13:45,  2.60it/s][A[2025-02-04 03:20:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1139/3290, eval_loss: 0.5452, eval_acc: 0.8535:  35%|[32m███▍      [0m| 1140/3290 [06:58<13:39,  2.62it/s][A
step: 1140/3290, eval_loss: 0.5448, eval_acc: 0.8536:  35%|[32m███▍      [0m| 1140/3290 [06:58<13:39,  2.62it/s][A[2025-02-04 03:20:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1140/3290, eval_loss: 0.5448, eval_acc: 0.8536:  35%|[32m███▍      [0m| 1141/3290 [06:59<15:00,  2.39it/s][A
step: 1141/3290, eval_loss: 0.5446, eval_acc: 0.8536:  35%|[32m███▍      [0m| 1141/3290 [06:59<15:00,  2.39it/s][A[2025-02-04 03:20:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1141/3290, eval_loss: 0.5446, eval_acc: 0.8536:  35%|[32m███▍      [0m| 1142/3290 [06:59<14:23,  2.49it/s][A
step: 1142/3290, eval_loss: 0.5442, eval_acc: 0.8537:  35%|[32m███▍      [0m| 1142/3290 [06:59<14:23,  2.49it/s][A[2025-02-04 03:20:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1142/3290, eval_loss: 0.5442, eval_acc: 0.8537:  35%|[32m███▍      [0m| 1143/3290 [06:59<14:33,  2.46it/s][A
step: 1143/3290, eval_loss: 0.5438, eval_acc: 0.8538:  35%|[32m███▍      [0m| 1143/3290 [07:00<14:33,  2.46it/s][A[2025-02-04 03:20:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1143/3290, eval_loss: 0.5438, eval_acc: 0.8538:  35%|[32m███▍      [0m| 1144/3290 [07:00<13:56,  2.57it/s][A
step: 1144/3290, eval_loss: 0.5436, eval_acc: 0.8539:  35%|[32m███▍      [0m| 1144/3290 [07:00<13:56,  2.57it/s][A[2025-02-04 03:20:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1144/3290, eval_loss: 0.5436, eval_acc: 0.8539:  35%|[32m███▍      [0m| 1145/3290 [07:00<13:33,  2.64it/s][A
step: 1145/3290, eval_loss: 0.5432, eval_acc: 0.8540:  35%|[32m███▍      [0m| 1145/3290 [07:00<13:33,  2.64it/s][A[2025-02-04 03:20:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1145/3290, eval_loss: 0.5432, eval_acc: 0.8540:  35%|[32m███▍      [0m| 1146/3290 [07:01<13:20,  2.68it/s][A
step: 1146/3290, eval_loss: 0.5429, eval_acc: 0.8541:  35%|[32m███▍      [0m| 1146/3290 [07:01<13:20,  2.68it/s][A[2025-02-04 03:20:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1146/3290, eval_loss: 0.5429, eval_acc: 0.8541:  35%|[32m███▍      [0m| 1147/3290 [07:01<12:40,  2.82it/s][A
step: 1147/3290, eval_loss: 0.5425, eval_acc: 0.8542:  35%|[32m███▍      [0m| 1147/3290 [07:01<12:40,  2.82it/s][A[2025-02-04 03:20:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1147/3290, eval_loss: 0.5425, eval_acc: 0.8542:  35%|[32m███▍      [0m| 1148/3290 [07:01<12:08,  2.94it/s][A
step: 1148/3290, eval_loss: 0.5422, eval_acc: 0.8543:  35%|[32m███▍      [0m| 1148/3290 [07:01<12:08,  2.94it/s][A[2025-02-04 03:20:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1148/3290, eval_loss: 0.5422, eval_acc: 0.8543:  35%|[32m███▍      [0m| 1149/3290 [07:02<13:20,  2.68it/s][A
step: 1149/3290, eval_loss: 0.5419, eval_acc: 0.8544:  35%|[32m███▍      [0m| 1149/3290 [07:02<13:20,  2.68it/s][A[2025-02-04 03:20:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1149/3290, eval_loss: 0.5419, eval_acc: 0.8544:  35%|[32m███▍      [0m| 1150/3290 [07:02<12:26,  2.87it/s][A
step: 1150/3290, eval_loss: 0.5420, eval_acc: 0.8543:  35%|[32m███▍      [0m| 1150/3290 [07:02<12:26,  2.87it/s][A[2025-02-04 03:20:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1150/3290, eval_loss: 0.5420, eval_acc: 0.8543:  35%|[32m███▍      [0m| 1151/3290 [07:02<13:14,  2.69it/s][A
step: 1151/3290, eval_loss: 0.5419, eval_acc: 0.8543:  35%|[32m███▍      [0m| 1151/3290 [07:02<13:14,  2.69it/s][A[2025-02-04 03:20:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1151/3290, eval_loss: 0.5419, eval_acc: 0.8543:  35%|[32m███▌      [0m| 1152/3290 [07:03<12:44,  2.80it/s][A
step: 1152/3290, eval_loss: 0.5417, eval_acc: 0.8544:  35%|[32m███▌      [0m| 1152/3290 [07:03<12:44,  2.80it/s][A[2025-02-04 03:20:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1152/3290, eval_loss: 0.5417, eval_acc: 0.8544:  35%|[32m███▌      [0m| 1153/3290 [07:03<12:45,  2.79it/s][A
step: 1153/3290, eval_loss: 0.5415, eval_acc: 0.8544:  35%|[32m███▌      [0m| 1153/3290 [07:03<12:45,  2.79it/s][A[2025-02-04 03:20:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1153/3290, eval_loss: 0.5415, eval_acc: 0.8544:  35%|[32m███▌      [0m| 1154/3290 [07:03<13:08,  2.71it/s][A
step: 1154/3290, eval_loss: 0.5416, eval_acc: 0.8544:  35%|[32m███▌      [0m| 1154/3290 [07:03<13:08,  2.71it/s][A[2025-02-04 03:20:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1154/3290, eval_loss: 0.5416, eval_acc: 0.8544:  35%|[32m███▌      [0m| 1155/3290 [07:04<13:18,  2.67it/s][A
step: 1155/3290, eval_loss: 0.5415, eval_acc: 0.8544:  35%|[32m███▌      [0m| 1155/3290 [07:04<13:18,  2.67it/s][A[2025-02-04 03:20:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1155/3290, eval_loss: 0.5415, eval_acc: 0.8544:  35%|[32m███▌      [0m| 1156/3290 [07:04<13:11,  2.70it/s][A
step: 1156/3290, eval_loss: 0.5411, eval_acc: 0.8545:  35%|[32m███▌      [0m| 1156/3290 [07:04<13:11,  2.70it/s][A[2025-02-04 03:20:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1156/3290, eval_loss: 0.5411, eval_acc: 0.8545:  35%|[32m███▌      [0m| 1157/3290 [07:04<12:17,  2.89it/s][A
step: 1157/3290, eval_loss: 0.5407, eval_acc: 0.8546:  35%|[32m███▌      [0m| 1157/3290 [07:04<12:17,  2.89it/s][A[2025-02-04 03:20:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1157/3290, eval_loss: 0.5407, eval_acc: 0.8546:  35%|[32m███▌      [0m| 1158/3290 [07:05<12:09,  2.92it/s][A
step: 1158/3290, eval_loss: 0.5404, eval_acc: 0.8547:  35%|[32m███▌      [0m| 1158/3290 [07:05<12:09,  2.92it/s][A[2025-02-04 03:20:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1158/3290, eval_loss: 0.5404, eval_acc: 0.8547:  35%|[32m███▌      [0m| 1159/3290 [07:05<11:13,  3.16it/s][A
step: 1159/3290, eval_loss: 0.5403, eval_acc: 0.8547:  35%|[32m███▌      [0m| 1159/3290 [07:05<11:13,  3.16it/s][A[2025-02-04 03:20:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1159/3290, eval_loss: 0.5403, eval_acc: 0.8547:  35%|[32m███▌      [0m| 1160/3290 [07:05<10:52,  3.26it/s][A
step: 1160/3290, eval_loss: 0.5407, eval_acc: 0.8547:  35%|[32m███▌      [0m| 1160/3290 [07:05<10:52,  3.26it/s][A[2025-02-04 03:20:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1160/3290, eval_loss: 0.5407, eval_acc: 0.8547:  35%|[32m███▌      [0m| 1161/3290 [07:06<11:24,  3.11it/s][A
step: 1161/3290, eval_loss: 0.5403, eval_acc: 0.8548:  35%|[32m███▌      [0m| 1161/3290 [07:06<11:24,  3.11it/s][A[2025-02-04 03:21:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1161/3290, eval_loss: 0.5403, eval_acc: 0.8548:  35%|[32m███▌      [0m| 1162/3290 [07:06<11:30,  3.08it/s][A
step: 1162/3290, eval_loss: 0.5402, eval_acc: 0.8548:  35%|[32m███▌      [0m| 1162/3290 [07:06<11:30,  3.08it/s][A[2025-02-04 03:21:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1162/3290, eval_loss: 0.5402, eval_acc: 0.8548:  35%|[32m███▌      [0m| 1163/3290 [07:06<11:20,  3.12it/s][A
step: 1163/3290, eval_loss: 0.5400, eval_acc: 0.8549:  35%|[32m███▌      [0m| 1163/3290 [07:06<11:20,  3.12it/s][A[2025-02-04 03:21:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1163/3290, eval_loss: 0.5400, eval_acc: 0.8549:  35%|[32m███▌      [0m| 1164/3290 [07:07<12:40,  2.80it/s][A
step: 1164/3290, eval_loss: 0.5401, eval_acc: 0.8549:  35%|[32m███▌      [0m| 1164/3290 [07:07<12:40,  2.80it/s][A[2025-02-04 03:21:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1164/3290, eval_loss: 0.5401, eval_acc: 0.8549:  35%|[32m███▌      [0m| 1165/3290 [07:07<12:27,  2.84it/s][A
step: 1165/3290, eval_loss: 0.5398, eval_acc: 0.8550:  35%|[32m███▌      [0m| 1165/3290 [07:07<12:27,  2.84it/s][A[2025-02-04 03:21:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1165/3290, eval_loss: 0.5398, eval_acc: 0.8550:  35%|[32m███▌      [0m| 1166/3290 [07:07<11:54,  2.97it/s][A
step: 1166/3290, eval_loss: 0.5396, eval_acc: 0.8550:  35%|[32m███▌      [0m| 1166/3290 [07:07<11:54,  2.97it/s][A[2025-02-04 03:21:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1166/3290, eval_loss: 0.5396, eval_acc: 0.8550:  35%|[32m███▌      [0m| 1167/3290 [07:08<11:42,  3.02it/s][A
step: 1167/3290, eval_loss: 0.5398, eval_acc: 0.8550:  35%|[32m███▌      [0m| 1167/3290 [07:08<11:42,  3.02it/s][A[2025-02-04 03:21:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1167/3290, eval_loss: 0.5398, eval_acc: 0.8550:  36%|[32m███▌      [0m| 1168/3290 [07:08<12:15,  2.89it/s][A
step: 1168/3290, eval_loss: 0.5395, eval_acc: 0.8551:  36%|[32m███▌      [0m| 1168/3290 [07:08<12:15,  2.89it/s][A[2025-02-04 03:21:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1168/3290, eval_loss: 0.5395, eval_acc: 0.8551:  36%|[32m███▌      [0m| 1169/3290 [07:08<12:34,  2.81it/s][A
step: 1169/3290, eval_loss: 0.5392, eval_acc: 0.8552:  36%|[32m███▌      [0m| 1169/3290 [07:08<12:34,  2.81it/s][A[2025-02-04 03:21:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1169/3290, eval_loss: 0.5392, eval_acc: 0.8552:  36%|[32m███▌      [0m| 1170/3290 [07:09<13:20,  2.65it/s][A
step: 1170/3290, eval_loss: 0.5391, eval_acc: 0.8552:  36%|[32m███▌      [0m| 1170/3290 [07:09<13:20,  2.65it/s][A[2025-02-04 03:21:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1170/3290, eval_loss: 0.5391, eval_acc: 0.8552:  36%|[32m███▌      [0m| 1171/3290 [07:09<13:20,  2.65it/s][A
step: 1171/3290, eval_loss: 0.5388, eval_acc: 0.8553:  36%|[32m███▌      [0m| 1171/3290 [07:09<13:20,  2.65it/s][A[2025-02-04 03:21:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1171/3290, eval_loss: 0.5388, eval_acc: 0.8553:  36%|[32m███▌      [0m| 1172/3290 [07:10<13:42,  2.58it/s][A
step: 1172/3290, eval_loss: 0.5386, eval_acc: 0.8553:  36%|[32m███▌      [0m| 1172/3290 [07:10<13:42,  2.58it/s][A[2025-02-04 03:21:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1172/3290, eval_loss: 0.5386, eval_acc: 0.8553:  36%|[32m███▌      [0m| 1173/3290 [07:10<13:49,  2.55it/s][A
step: 1173/3290, eval_loss: 0.5384, eval_acc: 0.8554:  36%|[32m███▌      [0m| 1173/3290 [07:10<13:49,  2.55it/s][A[2025-02-04 03:21:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1173/3290, eval_loss: 0.5384, eval_acc: 0.8554:  36%|[32m███▌      [0m| 1174/3290 [07:10<13:19,  2.65it/s][A
step: 1174/3290, eval_loss: 0.5385, eval_acc: 0.8553:  36%|[32m███▌      [0m| 1174/3290 [07:10<13:19,  2.65it/s][A[2025-02-04 03:21:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1174/3290, eval_loss: 0.5385, eval_acc: 0.8553:  36%|[32m███▌      [0m| 1175/3290 [07:11<11:57,  2.95it/s][A
step: 1175/3290, eval_loss: 0.5383, eval_acc: 0.8554:  36%|[32m███▌      [0m| 1175/3290 [07:11<11:57,  2.95it/s][A[2025-02-04 03:21:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1175/3290, eval_loss: 0.5383, eval_acc: 0.8554:  36%|[32m███▌      [0m| 1176/3290 [07:11<11:41,  3.01it/s][A
step: 1176/3290, eval_loss: 0.5384, eval_acc: 0.8554:  36%|[32m███▌      [0m| 1176/3290 [07:11<11:41,  3.01it/s][A[2025-02-04 03:21:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1176/3290, eval_loss: 0.5384, eval_acc: 0.8554:  36%|[32m███▌      [0m| 1177/3290 [07:11<11:06,  3.17it/s][A
step: 1177/3290, eval_loss: 0.5384, eval_acc: 0.8554:  36%|[32m███▌      [0m| 1177/3290 [07:11<11:06,  3.17it/s][A[2025-02-04 03:21:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1177/3290, eval_loss: 0.5384, eval_acc: 0.8554:  36%|[32m███▌      [0m| 1178/3290 [07:12<11:13,  3.13it/s][A
step: 1178/3290, eval_loss: 0.5382, eval_acc: 0.8555:  36%|[32m███▌      [0m| 1178/3290 [07:12<11:13,  3.13it/s][A[2025-02-04 03:21:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1178/3290, eval_loss: 0.5382, eval_acc: 0.8555:  36%|[32m███▌      [0m| 1179/3290 [07:12<10:20,  3.40it/s][A
step: 1179/3290, eval_loss: 0.5382, eval_acc: 0.8555:  36%|[32m███▌      [0m| 1179/3290 [07:12<10:20,  3.40it/s][A[2025-02-04 03:21:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1179/3290, eval_loss: 0.5382, eval_acc: 0.8555:  36%|[32m███▌      [0m| 1180/3290 [07:12<11:32,  3.04it/s][A
step: 1180/3290, eval_loss: 0.5379, eval_acc: 0.8556:  36%|[32m███▌      [0m| 1180/3290 [07:12<11:32,  3.04it/s][A[2025-02-04 03:21:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1180/3290, eval_loss: 0.5379, eval_acc: 0.8556:  36%|[32m███▌      [0m| 1181/3290 [07:13<11:05,  3.17it/s][A
step: 1181/3290, eval_loss: 0.5376, eval_acc: 0.8557:  36%|[32m███▌      [0m| 1181/3290 [07:13<11:05,  3.17it/s][A[2025-02-04 03:21:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1181/3290, eval_loss: 0.5376, eval_acc: 0.8557:  36%|[32m███▌      [0m| 1182/3290 [07:13<10:41,  3.28it/s][A
step: 1182/3290, eval_loss: 0.5372, eval_acc: 0.8558:  36%|[32m███▌      [0m| 1182/3290 [07:13<10:41,  3.28it/s][A[2025-02-04 03:21:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1182/3290, eval_loss: 0.5372, eval_acc: 0.8558:  36%|[32m███▌      [0m| 1183/3290 [07:13<11:22,  3.09it/s][A
step: 1183/3290, eval_loss: 0.5368, eval_acc: 0.8559:  36%|[32m███▌      [0m| 1183/3290 [07:13<11:22,  3.09it/s][A[2025-02-04 03:21:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1183/3290, eval_loss: 0.5368, eval_acc: 0.8559:  36%|[32m███▌      [0m| 1184/3290 [07:14<11:13,  3.13it/s][A
step: 1184/3290, eval_loss: 0.5368, eval_acc: 0.8559:  36%|[32m███▌      [0m| 1184/3290 [07:14<11:13,  3.13it/s][A[2025-02-04 03:21:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1184/3290, eval_loss: 0.5368, eval_acc: 0.8559:  36%|[32m███▌      [0m| 1185/3290 [07:14<11:44,  2.99it/s][A
step: 1185/3290, eval_loss: 0.5364, eval_acc: 0.8560:  36%|[32m███▌      [0m| 1185/3290 [07:14<11:44,  2.99it/s][A[2025-02-04 03:21:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1185/3290, eval_loss: 0.5364, eval_acc: 0.8560:  36%|[32m███▌      [0m| 1186/3290 [07:14<11:51,  2.96it/s][A
step: 1186/3290, eval_loss: 0.5361, eval_acc: 0.8561:  36%|[32m███▌      [0m| 1186/3290 [07:14<11:51,  2.96it/s][A[2025-02-04 03:21:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1186/3290, eval_loss: 0.5361, eval_acc: 0.8561:  36%|[32m███▌      [0m| 1187/3290 [07:15<11:52,  2.95it/s][A
step: 1187/3290, eval_loss: 0.5358, eval_acc: 0.8562:  36%|[32m███▌      [0m| 1187/3290 [07:15<11:52,  2.95it/s][A[2025-02-04 03:21:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1187/3290, eval_loss: 0.5358, eval_acc: 0.8562:  36%|[32m███▌      [0m| 1188/3290 [07:15<12:08,  2.88it/s][A
step: 1188/3290, eval_loss: 0.5354, eval_acc: 0.8563:  36%|[32m███▌      [0m| 1188/3290 [07:15<12:08,  2.88it/s][A[2025-02-04 03:21:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1188/3290, eval_loss: 0.5354, eval_acc: 0.8563:  36%|[32m███▌      [0m| 1189/3290 [07:15<12:22,  2.83it/s][A
step: 1189/3290, eval_loss: 0.5352, eval_acc: 0.8563:  36%|[32m███▌      [0m| 1189/3290 [07:15<12:22,  2.83it/s][A[2025-02-04 03:21:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1189/3290, eval_loss: 0.5352, eval_acc: 0.8563:  36%|[32m███▌      [0m| 1190/3290 [07:16<11:44,  2.98it/s][A
step: 1190/3290, eval_loss: 0.5348, eval_acc: 0.8564:  36%|[32m███▌      [0m| 1190/3290 [07:16<11:44,  2.98it/s][A[2025-02-04 03:21:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1190/3290, eval_loss: 0.5348, eval_acc: 0.8564:  36%|[32m███▌      [0m| 1191/3290 [07:16<10:45,  3.25it/s][A
step: 1191/3290, eval_loss: 0.5344, eval_acc: 0.8565:  36%|[32m███▌      [0m| 1191/3290 [07:16<10:45,  3.25it/s][A[2025-02-04 03:21:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1191/3290, eval_loss: 0.5344, eval_acc: 0.8565:  36%|[32m███▌      [0m| 1192/3290 [07:16<11:45,  2.97it/s][A
step: 1192/3290, eval_loss: 0.5341, eval_acc: 0.8566:  36%|[32m███▌      [0m| 1192/3290 [07:16<11:45,  2.97it/s][A[2025-02-04 03:21:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1192/3290, eval_loss: 0.5341, eval_acc: 0.8566:  36%|[32m███▋      [0m| 1193/3290 [07:17<11:52,  2.94it/s][A
step: 1193/3290, eval_loss: 0.5337, eval_acc: 0.8567:  36%|[32m███▋      [0m| 1193/3290 [07:17<11:52,  2.94it/s][A[2025-02-04 03:21:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1193/3290, eval_loss: 0.5337, eval_acc: 0.8567:  36%|[32m███▋      [0m| 1194/3290 [07:17<11:30,  3.04it/s][A
step: 1194/3290, eval_loss: 0.5334, eval_acc: 0.8568:  36%|[32m███▋      [0m| 1194/3290 [07:17<11:30,  3.04it/s][A[2025-02-04 03:21:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1194/3290, eval_loss: 0.5334, eval_acc: 0.8568:  36%|[32m███▋      [0m| 1195/3290 [07:17<12:01,  2.90it/s][A
step: 1195/3290, eval_loss: 0.5330, eval_acc: 0.8569:  36%|[32m███▋      [0m| 1195/3290 [07:17<12:01,  2.90it/s][A[2025-02-04 03:21:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1195/3290, eval_loss: 0.5330, eval_acc: 0.8569:  36%|[32m███▋      [0m| 1196/3290 [07:18<11:53,  2.93it/s][A
step: 1196/3290, eval_loss: 0.5327, eval_acc: 0.8570:  36%|[32m███▋      [0m| 1196/3290 [07:18<11:53,  2.93it/s][A[2025-02-04 03:21:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1196/3290, eval_loss: 0.5327, eval_acc: 0.8570:  36%|[32m███▋      [0m| 1197/3290 [07:18<11:45,  2.97it/s][A
step: 1197/3290, eval_loss: 0.5323, eval_acc: 0.8571:  36%|[32m███▋      [0m| 1197/3290 [07:18<11:45,  2.97it/s][A[2025-02-04 03:21:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1197/3290, eval_loss: 0.5323, eval_acc: 0.8571:  36%|[32m███▋      [0m| 1198/3290 [07:18<11:45,  2.97it/s][A
step: 1198/3290, eval_loss: 0.5322, eval_acc: 0.8572:  36%|[32m███▋      [0m| 1198/3290 [07:18<11:45,  2.97it/s][A[2025-02-04 03:21:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1198/3290, eval_loss: 0.5322, eval_acc: 0.8572:  36%|[32m███▋      [0m| 1199/3290 [07:19<11:17,  3.08it/s][A
step: 1199/3290, eval_loss: 0.5319, eval_acc: 0.8572:  36%|[32m███▋      [0m| 1199/3290 [07:19<11:17,  3.08it/s][A[2025-02-04 03:21:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1199/3290, eval_loss: 0.5319, eval_acc: 0.8572:  36%|[32m███▋      [0m| 1200/3290 [07:19<11:15,  3.09it/s][A
step: 1200/3290, eval_loss: 0.5315, eval_acc: 0.8573:  36%|[32m███▋      [0m| 1200/3290 [07:19<11:15,  3.09it/s][A[2025-02-04 03:21:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1200/3290, eval_loss: 0.5315, eval_acc: 0.8573:  37%|[32m███▋      [0m| 1201/3290 [07:19<10:43,  3.25it/s][A
step: 1201/3290, eval_loss: 0.5311, eval_acc: 0.8574:  37%|[32m███▋      [0m| 1201/3290 [07:19<10:43,  3.25it/s][A[2025-02-04 03:21:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1201/3290, eval_loss: 0.5311, eval_acc: 0.8574:  37%|[32m███▋      [0m| 1202/3290 [07:20<11:37,  2.99it/s][A
step: 1202/3290, eval_loss: 0.5308, eval_acc: 0.8575:  37%|[32m███▋      [0m| 1202/3290 [07:20<11:37,  2.99it/s][A[2025-02-04 03:21:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1202/3290, eval_loss: 0.5308, eval_acc: 0.8575:  37%|[32m███▋      [0m| 1203/3290 [07:20<11:20,  3.07it/s][A
step: 1203/3290, eval_loss: 0.5303, eval_acc: 0.8576:  37%|[32m███▋      [0m| 1203/3290 [07:20<11:20,  3.07it/s][A[2025-02-04 03:21:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1203/3290, eval_loss: 0.5303, eval_acc: 0.8576:  37%|[32m███▋      [0m| 1204/3290 [07:20<11:52,  2.93it/s][A
step: 1204/3290, eval_loss: 0.5302, eval_acc: 0.8577:  37%|[32m███▋      [0m| 1204/3290 [07:20<11:52,  2.93it/s][A[2025-02-04 03:21:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1204/3290, eval_loss: 0.5302, eval_acc: 0.8577:  37%|[32m███▋      [0m| 1205/3290 [07:21<12:29,  2.78it/s][A
step: 1205/3290, eval_loss: 0.5298, eval_acc: 0.8578:  37%|[32m███▋      [0m| 1205/3290 [07:21<12:29,  2.78it/s][A[2025-02-04 03:21:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1205/3290, eval_loss: 0.5298, eval_acc: 0.8578:  37%|[32m███▋      [0m| 1206/3290 [07:21<12:44,  2.72it/s][A
step: 1206/3290, eval_loss: 0.5295, eval_acc: 0.8579:  37%|[32m███▋      [0m| 1206/3290 [07:21<12:44,  2.72it/s][A[2025-02-04 03:21:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1206/3290, eval_loss: 0.5295, eval_acc: 0.8579:  37%|[32m███▋      [0m| 1207/3290 [07:21<12:59,  2.67it/s][A
step: 1207/3290, eval_loss: 0.5291, eval_acc: 0.8580:  37%|[32m███▋      [0m| 1207/3290 [07:21<12:59,  2.67it/s][A[2025-02-04 03:21:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1207/3290, eval_loss: 0.5291, eval_acc: 0.8580:  37%|[32m███▋      [0m| 1208/3290 [07:22<14:25,  2.40it/s][A
step: 1208/3290, eval_loss: 0.5289, eval_acc: 0.8581:  37%|[32m███▋      [0m| 1208/3290 [07:22<14:25,  2.40it/s][A[2025-02-04 03:21:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1208/3290, eval_loss: 0.5289, eval_acc: 0.8581:  37%|[32m███▋      [0m| 1209/3290 [07:22<13:37,  2.55it/s][A
step: 1209/3290, eval_loss: 0.5286, eval_acc: 0.8581:  37%|[32m███▋      [0m| 1209/3290 [07:22<13:37,  2.55it/s][A[2025-02-04 03:21:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1209/3290, eval_loss: 0.5286, eval_acc: 0.8581:  37%|[32m███▋      [0m| 1210/3290 [07:23<13:37,  2.54it/s][A
step: 1210/3290, eval_loss: 0.5283, eval_acc: 0.8582:  37%|[32m███▋      [0m| 1210/3290 [07:23<13:37,  2.54it/s][A[2025-02-04 03:21:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1210/3290, eval_loss: 0.5283, eval_acc: 0.8582:  37%|[32m███▋      [0m| 1211/3290 [07:23<13:43,  2.52it/s][A
step: 1211/3290, eval_loss: 0.5280, eval_acc: 0.8583:  37%|[32m███▋      [0m| 1211/3290 [07:23<13:43,  2.52it/s][A[2025-02-04 03:21:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1211/3290, eval_loss: 0.5280, eval_acc: 0.8583:  37%|[32m███▋      [0m| 1212/3290 [07:23<13:05,  2.65it/s][A
step: 1212/3290, eval_loss: 0.5277, eval_acc: 0.8584:  37%|[32m███▋      [0m| 1212/3290 [07:23<13:05,  2.65it/s][A[2025-02-04 03:21:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1212/3290, eval_loss: 0.5277, eval_acc: 0.8584:  37%|[32m███▋      [0m| 1213/3290 [07:24<13:43,  2.52it/s][A
step: 1213/3290, eval_loss: 0.5275, eval_acc: 0.8584:  37%|[32m███▋      [0m| 1213/3290 [07:24<13:43,  2.52it/s][A[2025-02-04 03:21:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1213/3290, eval_loss: 0.5275, eval_acc: 0.8584:  37%|[32m███▋      [0m| 1214/3290 [07:24<14:13,  2.43it/s][A
step: 1214/3290, eval_loss: 0.5271, eval_acc: 0.8585:  37%|[32m███▋      [0m| 1214/3290 [07:24<14:13,  2.43it/s][A[2025-02-04 03:21:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1214/3290, eval_loss: 0.5271, eval_acc: 0.8585:  37%|[32m███▋      [0m| 1215/3290 [07:25<13:27,  2.57it/s][A
step: 1215/3290, eval_loss: 0.5269, eval_acc: 0.8586:  37%|[32m███▋      [0m| 1215/3290 [07:25<13:27,  2.57it/s][A[2025-02-04 03:21:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1215/3290, eval_loss: 0.5269, eval_acc: 0.8586:  37%|[32m███▋      [0m| 1216/3290 [07:25<12:38,  2.73it/s][A
step: 1216/3290, eval_loss: 0.5265, eval_acc: 0.8587:  37%|[32m███▋      [0m| 1216/3290 [07:25<12:38,  2.73it/s][A[2025-02-04 03:21:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1216/3290, eval_loss: 0.5265, eval_acc: 0.8587:  37%|[32m███▋      [0m| 1217/3290 [07:25<12:29,  2.76it/s][A
step: 1217/3290, eval_loss: 0.5261, eval_acc: 0.8588:  37%|[32m███▋      [0m| 1217/3290 [07:25<12:29,  2.76it/s][A[2025-02-04 03:21:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1217/3290, eval_loss: 0.5261, eval_acc: 0.8588:  37%|[32m███▋      [0m| 1218/3290 [07:26<11:37,  2.97it/s][A
step: 1218/3290, eval_loss: 0.5259, eval_acc: 0.8589:  37%|[32m███▋      [0m| 1218/3290 [07:26<11:37,  2.97it/s][A[2025-02-04 03:21:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1218/3290, eval_loss: 0.5259, eval_acc: 0.8589:  37%|[32m███▋      [0m| 1219/3290 [07:26<12:14,  2.82it/s][A
step: 1219/3290, eval_loss: 0.5255, eval_acc: 0.8590:  37%|[32m███▋      [0m| 1219/3290 [07:26<12:14,  2.82it/s][A[2025-02-04 03:21:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1219/3290, eval_loss: 0.5255, eval_acc: 0.8590:  37%|[32m███▋      [0m| 1220/3290 [07:26<12:03,  2.86it/s][A
step: 1220/3290, eval_loss: 0.5252, eval_acc: 0.8590:  37%|[32m███▋      [0m| 1220/3290 [07:26<12:03,  2.86it/s][A[2025-02-04 03:21:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1220/3290, eval_loss: 0.5252, eval_acc: 0.8590:  37%|[32m███▋      [0m| 1221/3290 [07:27<10:59,  3.14it/s][A
step: 1221/3290, eval_loss: 0.5248, eval_acc: 0.8592:  37%|[32m███▋      [0m| 1221/3290 [07:27<10:59,  3.14it/s][A[2025-02-04 03:21:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1221/3290, eval_loss: 0.5248, eval_acc: 0.8592:  37%|[32m███▋      [0m| 1222/3290 [07:27<10:10,  3.39it/s][A
step: 1222/3290, eval_loss: 0.5245, eval_acc: 0.8592:  37%|[32m███▋      [0m| 1222/3290 [07:27<10:10,  3.39it/s][A[2025-02-04 03:21:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1222/3290, eval_loss: 0.5245, eval_acc: 0.8592:  37%|[32m███▋      [0m| 1223/3290 [07:27<09:55,  3.47it/s][A
step: 1223/3290, eval_loss: 0.5242, eval_acc: 0.8593:  37%|[32m███▋      [0m| 1223/3290 [07:27<09:55,  3.47it/s][A[2025-02-04 03:21:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1223/3290, eval_loss: 0.5242, eval_acc: 0.8593:  37%|[32m███▋      [0m| 1224/3290 [07:27<11:01,  3.12it/s][A
step: 1224/3290, eval_loss: 0.5238, eval_acc: 0.8594:  37%|[32m███▋      [0m| 1224/3290 [07:27<11:01,  3.12it/s][A[2025-02-04 03:21:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1224/3290, eval_loss: 0.5238, eval_acc: 0.8594:  37%|[32m███▋      [0m| 1225/3290 [07:28<11:55,  2.89it/s][A
step: 1225/3290, eval_loss: 0.5235, eval_acc: 0.8595:  37%|[32m███▋      [0m| 1225/3290 [07:28<11:55,  2.89it/s][A[2025-02-04 03:21:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1225/3290, eval_loss: 0.5235, eval_acc: 0.8595:  37%|[32m███▋      [0m| 1226/3290 [07:28<11:54,  2.89it/s][A
step: 1226/3290, eval_loss: 0.5232, eval_acc: 0.8596:  37%|[32m███▋      [0m| 1226/3290 [07:28<11:54,  2.89it/s][A[2025-02-04 03:21:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1226/3290, eval_loss: 0.5232, eval_acc: 0.8596:  37%|[32m███▋      [0m| 1227/3290 [07:29<11:22,  3.02it/s][A
step: 1227/3290, eval_loss: 0.5230, eval_acc: 0.8596:  37%|[32m███▋      [0m| 1227/3290 [07:29<11:22,  3.02it/s][A[2025-02-04 03:21:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1227/3290, eval_loss: 0.5230, eval_acc: 0.8596:  37%|[32m███▋      [0m| 1228/3290 [07:29<10:38,  3.23it/s][A
step: 1228/3290, eval_loss: 0.5227, eval_acc: 0.8597:  37%|[32m███▋      [0m| 1228/3290 [07:29<10:38,  3.23it/s][A[2025-02-04 03:21:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1228/3290, eval_loss: 0.5227, eval_acc: 0.8597:  37%|[32m███▋      [0m| 1229/3290 [07:29<11:52,  2.89it/s][A
step: 1229/3290, eval_loss: 0.5225, eval_acc: 0.8597:  37%|[32m███▋      [0m| 1229/3290 [07:29<11:52,  2.89it/s][A[2025-02-04 03:21:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1229/3290, eval_loss: 0.5225, eval_acc: 0.8597:  37%|[32m███▋      [0m| 1230/3290 [07:30<11:29,  2.99it/s][A
step: 1230/3290, eval_loss: 0.5224, eval_acc: 0.8598:  37%|[32m███▋      [0m| 1230/3290 [07:30<11:29,  2.99it/s][A[2025-02-04 03:21:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1230/3290, eval_loss: 0.5224, eval_acc: 0.8598:  37%|[32m███▋      [0m| 1231/3290 [07:30<10:54,  3.15it/s][A
step: 1231/3290, eval_loss: 0.5221, eval_acc: 0.8599:  37%|[32m███▋      [0m| 1231/3290 [07:30<10:54,  3.15it/s][A[2025-02-04 03:21:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1231/3290, eval_loss: 0.5221, eval_acc: 0.8599:  37%|[32m███▋      [0m| 1232/3290 [07:30<12:14,  2.80it/s][A
step: 1232/3290, eval_loss: 0.5217, eval_acc: 0.8599:  37%|[32m███▋      [0m| 1232/3290 [07:30<12:14,  2.80it/s][A[2025-02-04 03:21:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1232/3290, eval_loss: 0.5217, eval_acc: 0.8599:  37%|[32m███▋      [0m| 1233/3290 [07:31<13:28,  2.55it/s][A
step: 1233/3290, eval_loss: 0.5214, eval_acc: 0.8600:  37%|[32m███▋      [0m| 1233/3290 [07:31<13:28,  2.55it/s][A[2025-02-04 03:21:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1233/3290, eval_loss: 0.5214, eval_acc: 0.8600:  38%|[32m███▊      [0m| 1234/3290 [07:31<12:58,  2.64it/s][A
step: 1234/3290, eval_loss: 0.5211, eval_acc: 0.8601:  38%|[32m███▊      [0m| 1234/3290 [07:31<12:58,  2.64it/s][A[2025-02-04 03:21:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1234/3290, eval_loss: 0.5211, eval_acc: 0.8601:  38%|[32m███▊      [0m| 1235/3290 [07:31<12:44,  2.69it/s][A
step: 1235/3290, eval_loss: 0.5210, eval_acc: 0.8601:  38%|[32m███▊      [0m| 1235/3290 [07:31<12:44,  2.69it/s][A[2025-02-04 03:21:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1235/3290, eval_loss: 0.5210, eval_acc: 0.8601:  38%|[32m███▊      [0m| 1236/3290 [07:32<12:16,  2.79it/s][A
step: 1236/3290, eval_loss: 0.5208, eval_acc: 0.8602:  38%|[32m███▊      [0m| 1236/3290 [07:32<12:16,  2.79it/s][A[2025-02-04 03:21:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1236/3290, eval_loss: 0.5208, eval_acc: 0.8602:  38%|[32m███▊      [0m| 1237/3290 [07:32<12:28,  2.74it/s][A
step: 1237/3290, eval_loss: 0.5205, eval_acc: 0.8603:  38%|[32m███▊      [0m| 1237/3290 [07:32<12:28,  2.74it/s][A[2025-02-04 03:21:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1237/3290, eval_loss: 0.5205, eval_acc: 0.8603:  38%|[32m███▊      [0m| 1238/3290 [07:32<11:47,  2.90it/s][A
step: 1238/3290, eval_loss: 0.5201, eval_acc: 0.8604:  38%|[32m███▊      [0m| 1238/3290 [07:32<11:47,  2.90it/s][A[2025-02-04 03:21:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1238/3290, eval_loss: 0.5201, eval_acc: 0.8604:  38%|[32m███▊      [0m| 1239/3290 [07:33<10:58,  3.11it/s][A
step: 1239/3290, eval_loss: 0.5198, eval_acc: 0.8605:  38%|[32m███▊      [0m| 1239/3290 [07:33<10:58,  3.11it/s][A[2025-02-04 03:21:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1239/3290, eval_loss: 0.5198, eval_acc: 0.8605:  38%|[32m███▊      [0m| 1240/3290 [07:33<10:30,  3.25it/s][A
step: 1240/3290, eval_loss: 0.5195, eval_acc: 0.8605:  38%|[32m███▊      [0m| 1240/3290 [07:33<10:30,  3.25it/s][A[2025-02-04 03:21:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1240/3290, eval_loss: 0.5195, eval_acc: 0.8605:  38%|[32m███▊      [0m| 1241/3290 [07:33<10:09,  3.36it/s][A
step: 1241/3290, eval_loss: 0.5194, eval_acc: 0.8606:  38%|[32m███▊      [0m| 1241/3290 [07:33<10:09,  3.36it/s][A[2025-02-04 03:21:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1241/3290, eval_loss: 0.5194, eval_acc: 0.8606:  38%|[32m███▊      [0m| 1242/3290 [07:34<09:55,  3.44it/s][A
step: 1242/3290, eval_loss: 0.5193, eval_acc: 0.8606:  38%|[32m███▊      [0m| 1242/3290 [07:34<09:55,  3.44it/s][A[2025-02-04 03:21:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1242/3290, eval_loss: 0.5193, eval_acc: 0.8606:  38%|[32m███▊      [0m| 1243/3290 [07:34<09:14,  3.69it/s][A
step: 1243/3290, eval_loss: 0.5192, eval_acc: 0.8606:  38%|[32m███▊      [0m| 1243/3290 [07:34<09:14,  3.69it/s][A[2025-02-04 03:21:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1243/3290, eval_loss: 0.5192, eval_acc: 0.8606:  38%|[32m███▊      [0m| 1244/3290 [07:34<08:59,  3.79it/s][A
step: 1244/3290, eval_loss: 0.5191, eval_acc: 0.8606:  38%|[32m███▊      [0m| 1244/3290 [07:34<08:59,  3.79it/s][A[2025-02-04 03:21:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1244/3290, eval_loss: 0.5191, eval_acc: 0.8606:  38%|[32m███▊      [0m| 1245/3290 [07:34<08:53,  3.83it/s][A
step: 1245/3290, eval_loss: 0.5189, eval_acc: 0.8606:  38%|[32m███▊      [0m| 1245/3290 [07:34<08:53,  3.83it/s][A[2025-02-04 03:21:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1245/3290, eval_loss: 0.5189, eval_acc: 0.8606:  38%|[32m███▊      [0m| 1246/3290 [07:35<09:30,  3.59it/s][A
step: 1246/3290, eval_loss: 0.5188, eval_acc: 0.8607:  38%|[32m███▊      [0m| 1246/3290 [07:35<09:30,  3.59it/s][A[2025-02-04 03:21:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1246/3290, eval_loss: 0.5188, eval_acc: 0.8607:  38%|[32m███▊      [0m| 1247/3290 [07:35<09:15,  3.68it/s][A
step: 1247/3290, eval_loss: 0.5186, eval_acc: 0.8607:  38%|[32m███▊      [0m| 1247/3290 [07:35<09:15,  3.68it/s][A[2025-02-04 03:21:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1247/3290, eval_loss: 0.5186, eval_acc: 0.8607:  38%|[32m███▊      [0m| 1248/3290 [07:35<10:53,  3.13it/s][A
step: 1248/3290, eval_loss: 0.5187, eval_acc: 0.8607:  38%|[32m███▊      [0m| 1248/3290 [07:35<10:53,  3.13it/s][A[2025-02-04 03:21:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1248/3290, eval_loss: 0.5187, eval_acc: 0.8607:  38%|[32m███▊      [0m| 1249/3290 [07:36<11:35,  2.93it/s][A
step: 1249/3290, eval_loss: 0.5187, eval_acc: 0.8607:  38%|[32m███▊      [0m| 1249/3290 [07:36<11:35,  2.93it/s][A[2025-02-04 03:21:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1249/3290, eval_loss: 0.5187, eval_acc: 0.8607:  38%|[32m███▊      [0m| 1250/3290 [07:36<12:09,  2.80it/s][A
step: 1250/3290, eval_loss: 0.5186, eval_acc: 0.8608:  38%|[32m███▊      [0m| 1250/3290 [07:36<12:09,  2.80it/s][A[2025-02-04 03:21:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1250/3290, eval_loss: 0.5186, eval_acc: 0.8608:  38%|[32m███▊      [0m| 1251/3290 [07:36<11:54,  2.85it/s][A
step: 1251/3290, eval_loss: 0.5183, eval_acc: 0.8608:  38%|[32m███▊      [0m| 1251/3290 [07:36<11:54,  2.85it/s][A[2025-02-04 03:21:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1251/3290, eval_loss: 0.5183, eval_acc: 0.8608:  38%|[32m███▊      [0m| 1252/3290 [07:37<12:25,  2.73it/s][A
step: 1252/3290, eval_loss: 0.5181, eval_acc: 0.8608:  38%|[32m███▊      [0m| 1252/3290 [07:37<12:25,  2.73it/s][A[2025-02-04 03:21:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1252/3290, eval_loss: 0.5181, eval_acc: 0.8608:  38%|[32m███▊      [0m| 1253/3290 [07:37<15:01,  2.26it/s][A
step: 1253/3290, eval_loss: 0.5179, eval_acc: 0.8609:  38%|[32m███▊      [0m| 1253/3290 [07:37<15:01,  2.26it/s][A[2025-02-04 03:21:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1253/3290, eval_loss: 0.5179, eval_acc: 0.8609:  38%|[32m███▊      [0m| 1254/3290 [07:38<14:52,  2.28it/s][A
step: 1254/3290, eval_loss: 0.5176, eval_acc: 0.8610:  38%|[32m███▊      [0m| 1254/3290 [07:38<14:52,  2.28it/s][A[2025-02-04 03:21:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1254/3290, eval_loss: 0.5176, eval_acc: 0.8610:  38%|[32m███▊      [0m| 1255/3290 [07:38<14:40,  2.31it/s][A
step: 1255/3290, eval_loss: 0.5175, eval_acc: 0.8610:  38%|[32m███▊      [0m| 1255/3290 [07:38<14:40,  2.31it/s][A[2025-02-04 03:21:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1255/3290, eval_loss: 0.5175, eval_acc: 0.8610:  38%|[32m███▊      [0m| 1256/3290 [07:39<15:09,  2.24it/s][A
step: 1256/3290, eval_loss: 0.5173, eval_acc: 0.8610:  38%|[32m███▊      [0m| 1256/3290 [07:39<15:09,  2.24it/s][A[2025-02-04 03:21:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1256/3290, eval_loss: 0.5173, eval_acc: 0.8610:  38%|[32m███▊      [0m| 1257/3290 [07:39<15:45,  2.15it/s][A
step: 1257/3290, eval_loss: 0.5172, eval_acc: 0.8611:  38%|[32m███▊      [0m| 1257/3290 [07:39<15:45,  2.15it/s][A[2025-02-04 03:21:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1257/3290, eval_loss: 0.5172, eval_acc: 0.8611:  38%|[32m███▊      [0m| 1258/3290 [07:40<15:54,  2.13it/s][A
step: 1258/3290, eval_loss: 0.5171, eval_acc: 0.8611:  38%|[32m███▊      [0m| 1258/3290 [07:40<15:54,  2.13it/s][A[2025-02-04 03:21:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1258/3290, eval_loss: 0.5171, eval_acc: 0.8611:  38%|[32m███▊      [0m| 1259/3290 [07:40<15:40,  2.16it/s][A
step: 1259/3290, eval_loss: 0.5174, eval_acc: 0.8610:  38%|[32m███▊      [0m| 1259/3290 [07:40<15:40,  2.16it/s][A[2025-02-04 03:21:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1259/3290, eval_loss: 0.5174, eval_acc: 0.8610:  38%|[32m███▊      [0m| 1260/3290 [07:41<14:33,  2.32it/s][A
step: 1260/3290, eval_loss: 0.5174, eval_acc: 0.8610:  38%|[32m███▊      [0m| 1260/3290 [07:41<14:33,  2.32it/s][A[2025-02-04 03:21:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1260/3290, eval_loss: 0.5174, eval_acc: 0.8610:  38%|[32m███▊      [0m| 1261/3290 [07:41<15:05,  2.24it/s][A
step: 1261/3290, eval_loss: 0.5171, eval_acc: 0.8611:  38%|[32m███▊      [0m| 1261/3290 [07:41<15:05,  2.24it/s][A[2025-02-04 03:21:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1261/3290, eval_loss: 0.5171, eval_acc: 0.8611:  38%|[32m███▊      [0m| 1262/3290 [07:41<14:03,  2.40it/s][A
step: 1262/3290, eval_loss: 0.5172, eval_acc: 0.8610:  38%|[32m███▊      [0m| 1262/3290 [07:41<14:03,  2.40it/s][A[2025-02-04 03:21:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1262/3290, eval_loss: 0.5172, eval_acc: 0.8610:  38%|[32m███▊      [0m| 1263/3290 [07:42<13:54,  2.43it/s][A
step: 1263/3290, eval_loss: 0.5171, eval_acc: 0.8611:  38%|[32m███▊      [0m| 1263/3290 [07:42<13:54,  2.43it/s][A[2025-02-04 03:21:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1263/3290, eval_loss: 0.5171, eval_acc: 0.8611:  38%|[32m███▊      [0m| 1264/3290 [07:42<13:27,  2.51it/s][A
step: 1264/3290, eval_loss: 0.5170, eval_acc: 0.8611:  38%|[32m███▊      [0m| 1264/3290 [07:42<13:27,  2.51it/s][A[2025-02-04 03:21:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1264/3290, eval_loss: 0.5170, eval_acc: 0.8611:  38%|[32m███▊      [0m| 1265/3290 [07:42<12:41,  2.66it/s][A
step: 1265/3290, eval_loss: 0.5167, eval_acc: 0.8612:  38%|[32m███▊      [0m| 1265/3290 [07:42<12:41,  2.66it/s][A[2025-02-04 03:21:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1265/3290, eval_loss: 0.5167, eval_acc: 0.8612:  38%|[32m███▊      [0m| 1266/3290 [07:43<12:12,  2.76it/s][A
step: 1266/3290, eval_loss: 0.5166, eval_acc: 0.8612:  38%|[32m███▊      [0m| 1266/3290 [07:43<12:12,  2.76it/s][A[2025-02-04 03:21:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1266/3290, eval_loss: 0.5166, eval_acc: 0.8612:  39%|[32m███▊      [0m| 1267/3290 [07:43<11:43,  2.87it/s][A
step: 1267/3290, eval_loss: 0.5163, eval_acc: 0.8613:  39%|[32m███▊      [0m| 1267/3290 [07:43<11:43,  2.87it/s][A[2025-02-04 03:21:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1267/3290, eval_loss: 0.5163, eval_acc: 0.8613:  39%|[32m███▊      [0m| 1268/3290 [07:44<12:42,  2.65it/s][A
step: 1268/3290, eval_loss: 0.5160, eval_acc: 0.8614:  39%|[32m███▊      [0m| 1268/3290 [07:44<12:42,  2.65it/s][A[2025-02-04 03:21:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1268/3290, eval_loss: 0.5160, eval_acc: 0.8614:  39%|[32m███▊      [0m| 1269/3290 [07:44<13:16,  2.54it/s][A
step: 1269/3290, eval_loss: 0.5160, eval_acc: 0.8614:  39%|[32m███▊      [0m| 1269/3290 [07:44<13:16,  2.54it/s][A[2025-02-04 03:21:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1269/3290, eval_loss: 0.5160, eval_acc: 0.8614:  39%|[32m███▊      [0m| 1270/3290 [07:44<12:02,  2.80it/s][A
step: 1270/3290, eval_loss: 0.5158, eval_acc: 0.8615:  39%|[32m███▊      [0m| 1270/3290 [07:44<12:02,  2.80it/s][A[2025-02-04 03:21:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1270/3290, eval_loss: 0.5158, eval_acc: 0.8615:  39%|[32m███▊      [0m| 1271/3290 [07:45<11:43,  2.87it/s][A
step: 1271/3290, eval_loss: 0.5156, eval_acc: 0.8615:  39%|[32m███▊      [0m| 1271/3290 [07:45<11:43,  2.87it/s][A[2025-02-04 03:21:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1271/3290, eval_loss: 0.5156, eval_acc: 0.8615:  39%|[32m███▊      [0m| 1272/3290 [07:45<12:41,  2.65it/s][A
step: 1272/3290, eval_loss: 0.5153, eval_acc: 0.8616:  39%|[32m███▊      [0m| 1272/3290 [07:45<12:41,  2.65it/s][A[2025-02-04 03:21:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1272/3290, eval_loss: 0.5153, eval_acc: 0.8616:  39%|[32m███▊      [0m| 1273/3290 [07:45<11:53,  2.82it/s][A
step: 1273/3290, eval_loss: 0.5151, eval_acc: 0.8616:  39%|[32m███▊      [0m| 1273/3290 [07:45<11:53,  2.82it/s][A[2025-02-04 03:21:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1273/3290, eval_loss: 0.5151, eval_acc: 0.8616:  39%|[32m███▊      [0m| 1274/3290 [07:46<12:29,  2.69it/s][A
step: 1274/3290, eval_loss: 0.5151, eval_acc: 0.8616:  39%|[32m███▊      [0m| 1274/3290 [07:46<12:29,  2.69it/s][A[2025-02-04 03:21:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1274/3290, eval_loss: 0.5151, eval_acc: 0.8616:  39%|[32m███▉      [0m| 1275/3290 [07:46<12:38,  2.66it/s][A
step: 1275/3290, eval_loss: 0.5151, eval_acc: 0.8616:  39%|[32m███▉      [0m| 1275/3290 [07:46<12:38,  2.66it/s][A[2025-02-04 03:21:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1275/3290, eval_loss: 0.5151, eval_acc: 0.8616:  39%|[32m███▉      [0m| 1276/3290 [07:47<13:20,  2.52it/s][A
step: 1276/3290, eval_loss: 0.5148, eval_acc: 0.8617:  39%|[32m███▉      [0m| 1276/3290 [07:47<13:20,  2.52it/s][A[2025-02-04 03:21:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1276/3290, eval_loss: 0.5148, eval_acc: 0.8617:  39%|[32m███▉      [0m| 1277/3290 [07:47<12:10,  2.76it/s][A
step: 1277/3290, eval_loss: 0.5146, eval_acc: 0.8618:  39%|[32m███▉      [0m| 1277/3290 [07:47<12:10,  2.76it/s][A[2025-02-04 03:21:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1277/3290, eval_loss: 0.5146, eval_acc: 0.8618:  39%|[32m███▉      [0m| 1278/3290 [07:47<11:58,  2.80it/s][A
step: 1278/3290, eval_loss: 0.5144, eval_acc: 0.8618:  39%|[32m███▉      [0m| 1278/3290 [07:47<11:58,  2.80it/s][A[2025-02-04 03:21:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1278/3290, eval_loss: 0.5144, eval_acc: 0.8618:  39%|[32m███▉      [0m| 1279/3290 [07:48<12:40,  2.64it/s][A
step: 1279/3290, eval_loss: 0.5142, eval_acc: 0.8619:  39%|[32m███▉      [0m| 1279/3290 [07:48<12:40,  2.64it/s][A[2025-02-04 03:21:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1279/3290, eval_loss: 0.5142, eval_acc: 0.8619:  39%|[32m███▉      [0m| 1280/3290 [07:48<12:47,  2.62it/s][A
step: 1280/3290, eval_loss: 0.5140, eval_acc: 0.8619:  39%|[32m███▉      [0m| 1280/3290 [07:48<12:47,  2.62it/s][A[2025-02-04 03:21:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1280/3290, eval_loss: 0.5140, eval_acc: 0.8619:  39%|[32m███▉      [0m| 1281/3290 [07:48<13:06,  2.55it/s][A
step: 1281/3290, eval_loss: 0.5138, eval_acc: 0.8620:  39%|[32m███▉      [0m| 1281/3290 [07:48<13:06,  2.55it/s][A[2025-02-04 03:21:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1281/3290, eval_loss: 0.5138, eval_acc: 0.8620:  39%|[32m███▉      [0m| 1282/3290 [07:49<12:50,  2.61it/s][A
step: 1282/3290, eval_loss: 0.5136, eval_acc: 0.8620:  39%|[32m███▉      [0m| 1282/3290 [07:49<12:50,  2.61it/s][A[2025-02-04 03:21:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1282/3290, eval_loss: 0.5136, eval_acc: 0.8620:  39%|[32m███▉      [0m| 1283/3290 [07:49<14:04,  2.38it/s][A
step: 1283/3290, eval_loss: 0.5136, eval_acc: 0.8620:  39%|[32m███▉      [0m| 1283/3290 [07:49<14:04,  2.38it/s][A[2025-02-04 03:21:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1283/3290, eval_loss: 0.5136, eval_acc: 0.8620:  39%|[32m███▉      [0m| 1284/3290 [07:50<14:36,  2.29it/s][A
step: 1284/3290, eval_loss: 0.5135, eval_acc: 0.8621:  39%|[32m███▉      [0m| 1284/3290 [07:50<14:36,  2.29it/s][A[2025-02-04 03:21:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1284/3290, eval_loss: 0.5135, eval_acc: 0.8621:  39%|[32m███▉      [0m| 1285/3290 [07:50<12:53,  2.59it/s][A
step: 1285/3290, eval_loss: 0.5132, eval_acc: 0.8621:  39%|[32m███▉      [0m| 1285/3290 [07:50<12:53,  2.59it/s][A[2025-02-04 03:21:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1285/3290, eval_loss: 0.5132, eval_acc: 0.8621:  39%|[32m███▉      [0m| 1286/3290 [07:50<12:32,  2.66it/s][A
step: 1286/3290, eval_loss: 0.5130, eval_acc: 0.8622:  39%|[32m███▉      [0m| 1286/3290 [07:50<12:32,  2.66it/s][A[2025-02-04 03:21:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1286/3290, eval_loss: 0.5130, eval_acc: 0.8622:  39%|[32m███▉      [0m| 1287/3290 [07:51<12:22,  2.70it/s][A
step: 1287/3290, eval_loss: 0.5128, eval_acc: 0.8622:  39%|[32m███▉      [0m| 1287/3290 [07:51<12:22,  2.70it/s][A[2025-02-04 03:21:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1287/3290, eval_loss: 0.5128, eval_acc: 0.8622:  39%|[32m███▉      [0m| 1288/3290 [07:51<12:15,  2.72it/s][A
step: 1288/3290, eval_loss: 0.5129, eval_acc: 0.8622:  39%|[32m███▉      [0m| 1288/3290 [07:51<12:15,  2.72it/s][A[2025-02-04 03:21:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1288/3290, eval_loss: 0.5129, eval_acc: 0.8622:  39%|[32m███▉      [0m| 1289/3290 [07:51<12:25,  2.68it/s][A
step: 1289/3290, eval_loss: 0.5129, eval_acc: 0.8622:  39%|[32m███▉      [0m| 1289/3290 [07:51<12:25,  2.68it/s][A[2025-02-04 03:21:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1289/3290, eval_loss: 0.5129, eval_acc: 0.8622:  39%|[32m███▉      [0m| 1290/3290 [07:52<13:03,  2.55it/s][A
step: 1290/3290, eval_loss: 0.5128, eval_acc: 0.8622:  39%|[32m███▉      [0m| 1290/3290 [07:52<13:03,  2.55it/s][A[2025-02-04 03:21:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1290/3290, eval_loss: 0.5128, eval_acc: 0.8622:  39%|[32m███▉      [0m| 1291/3290 [07:52<13:27,  2.48it/s][A
step: 1291/3290, eval_loss: 0.5128, eval_acc: 0.8622:  39%|[32m███▉      [0m| 1291/3290 [07:52<13:27,  2.48it/s][A[2025-02-04 03:21:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1291/3290, eval_loss: 0.5128, eval_acc: 0.8622:  39%|[32m███▉      [0m| 1292/3290 [07:53<13:40,  2.43it/s][A
step: 1292/3290, eval_loss: 0.5127, eval_acc: 0.8623:  39%|[32m███▉      [0m| 1292/3290 [07:53<13:40,  2.43it/s][A[2025-02-04 03:21:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1292/3290, eval_loss: 0.5127, eval_acc: 0.8623:  39%|[32m███▉      [0m| 1293/3290 [07:53<12:56,  2.57it/s][A
step: 1293/3290, eval_loss: 0.5125, eval_acc: 0.8623:  39%|[32m███▉      [0m| 1293/3290 [07:53<12:56,  2.57it/s][A[2025-02-04 03:21:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1293/3290, eval_loss: 0.5125, eval_acc: 0.8623:  39%|[32m███▉      [0m| 1294/3290 [07:54<14:45,  2.25it/s][A
step: 1294/3290, eval_loss: 0.5124, eval_acc: 0.8623:  39%|[32m███▉      [0m| 1294/3290 [07:54<14:45,  2.25it/s][A[2025-02-04 03:21:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1294/3290, eval_loss: 0.5124, eval_acc: 0.8623:  39%|[32m███▉      [0m| 1295/3290 [07:54<14:34,  2.28it/s][A
step: 1295/3290, eval_loss: 0.5122, eval_acc: 0.8623:  39%|[32m███▉      [0m| 1295/3290 [07:54<14:34,  2.28it/s][A[2025-02-04 03:21:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1295/3290, eval_loss: 0.5122, eval_acc: 0.8623:  39%|[32m███▉      [0m| 1296/3290 [07:54<14:12,  2.34it/s][A
step: 1296/3290, eval_loss: 0.5121, eval_acc: 0.8624:  39%|[32m███▉      [0m| 1296/3290 [07:55<14:12,  2.34it/s][A[2025-02-04 03:21:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1296/3290, eval_loss: 0.5121, eval_acc: 0.8624:  39%|[32m███▉      [0m| 1297/3290 [07:55<13:51,  2.40it/s][A
step: 1297/3290, eval_loss: 0.5118, eval_acc: 0.8624:  39%|[32m███▉      [0m| 1297/3290 [07:55<13:51,  2.40it/s][A[2025-02-04 03:21:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1297/3290, eval_loss: 0.5118, eval_acc: 0.8624:  39%|[32m███▉      [0m| 1298/3290 [07:55<14:40,  2.26it/s][A
step: 1298/3290, eval_loss: 0.5116, eval_acc: 0.8625:  39%|[32m███▉      [0m| 1298/3290 [07:55<14:40,  2.26it/s][A[2025-02-04 03:21:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1298/3290, eval_loss: 0.5116, eval_acc: 0.8625:  39%|[32m███▉      [0m| 1299/3290 [07:56<15:08,  2.19it/s][A
step: 1299/3290, eval_loss: 0.5114, eval_acc: 0.8625:  39%|[32m███▉      [0m| 1299/3290 [07:56<15:08,  2.19it/s][A[2025-02-04 03:21:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1299/3290, eval_loss: 0.5114, eval_acc: 0.8625:  40%|[32m███▉      [0m| 1300/3290 [07:56<16:41,  1.99it/s][A
step: 1300/3290, eval_loss: 0.5112, eval_acc: 0.8626:  40%|[32m███▉      [0m| 1300/3290 [07:56<16:41,  1.99it/s][A[2025-02-04 03:21:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1300/3290, eval_loss: 0.5112, eval_acc: 0.8626:  40%|[32m███▉      [0m| 1301/3290 [07:57<15:53,  2.09it/s][A
step: 1301/3290, eval_loss: 0.5111, eval_acc: 0.8627:  40%|[32m███▉      [0m| 1301/3290 [07:57<15:53,  2.09it/s][A[2025-02-04 03:21:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1301/3290, eval_loss: 0.5111, eval_acc: 0.8627:  40%|[32m███▉      [0m| 1302/3290 [07:57<14:15,  2.32it/s][A
step: 1302/3290, eval_loss: 0.5108, eval_acc: 0.8627:  40%|[32m███▉      [0m| 1302/3290 [07:57<14:15,  2.32it/s][A[2025-02-04 03:21:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1302/3290, eval_loss: 0.5108, eval_acc: 0.8627:  40%|[32m███▉      [0m| 1303/3290 [07:58<13:04,  2.53it/s][A
step: 1303/3290, eval_loss: 0.5107, eval_acc: 0.8628:  40%|[32m███▉      [0m| 1303/3290 [07:58<13:04,  2.53it/s][A[2025-02-04 03:21:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1303/3290, eval_loss: 0.5107, eval_acc: 0.8628:  40%|[32m███▉      [0m| 1304/3290 [07:58<12:05,  2.74it/s][A
step: 1304/3290, eval_loss: 0.5106, eval_acc: 0.8628:  40%|[32m███▉      [0m| 1304/3290 [07:58<12:05,  2.74it/s][A[2025-02-04 03:21:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1304/3290, eval_loss: 0.5106, eval_acc: 0.8628:  40%|[32m███▉      [0m| 1305/3290 [07:58<11:48,  2.80it/s][A
step: 1305/3290, eval_loss: 0.5107, eval_acc: 0.8628:  40%|[32m███▉      [0m| 1305/3290 [07:58<11:48,  2.80it/s][A[2025-02-04 03:21:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1305/3290, eval_loss: 0.5107, eval_acc: 0.8628:  40%|[32m███▉      [0m| 1306/3290 [07:58<11:20,  2.92it/s][A
step: 1306/3290, eval_loss: 0.5106, eval_acc: 0.8628:  40%|[32m███▉      [0m| 1306/3290 [07:58<11:20,  2.92it/s][A[2025-02-04 03:21:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1306/3290, eval_loss: 0.5106, eval_acc: 0.8628:  40%|[32m███▉      [0m| 1307/3290 [07:59<13:47,  2.40it/s][A
step: 1307/3290, eval_loss: 0.5105, eval_acc: 0.8629:  40%|[32m███▉      [0m| 1307/3290 [07:59<13:47,  2.40it/s][A[2025-02-04 03:21:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1307/3290, eval_loss: 0.5105, eval_acc: 0.8629:  40%|[32m███▉      [0m| 1308/3290 [07:59<12:48,  2.58it/s][A
step: 1308/3290, eval_loss: 0.5102, eval_acc: 0.8629:  40%|[32m███▉      [0m| 1308/3290 [07:59<12:48,  2.58it/s][A[2025-02-04 03:21:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1308/3290, eval_loss: 0.5102, eval_acc: 0.8629:  40%|[32m███▉      [0m| 1309/3290 [08:00<12:32,  2.63it/s][A
step: 1309/3290, eval_loss: 0.5099, eval_acc: 0.8630:  40%|[32m███▉      [0m| 1309/3290 [08:00<12:32,  2.63it/s][A[2025-02-04 03:21:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1309/3290, eval_loss: 0.5099, eval_acc: 0.8630:  40%|[32m███▉      [0m| 1310/3290 [08:00<12:50,  2.57it/s][A
step: 1310/3290, eval_loss: 0.5098, eval_acc: 0.8631:  40%|[32m███▉      [0m| 1310/3290 [08:00<12:50,  2.57it/s][A[2025-02-04 03:21:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1310/3290, eval_loss: 0.5098, eval_acc: 0.8631:  40%|[32m███▉      [0m| 1311/3290 [08:01<12:20,  2.67it/s][A
step: 1311/3290, eval_loss: 0.5097, eval_acc: 0.8631:  40%|[32m███▉      [0m| 1311/3290 [08:01<12:20,  2.67it/s][A[2025-02-04 03:21:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1311/3290, eval_loss: 0.5097, eval_acc: 0.8631:  40%|[32m███▉      [0m| 1312/3290 [08:01<14:38,  2.25it/s][A
step: 1312/3290, eval_loss: 0.5097, eval_acc: 0.8631:  40%|[32m███▉      [0m| 1312/3290 [08:01<14:38,  2.25it/s][A[2025-02-04 03:21:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1312/3290, eval_loss: 0.5097, eval_acc: 0.8631:  40%|[32m███▉      [0m| 1313/3290 [08:01<13:12,  2.49it/s][A
step: 1313/3290, eval_loss: 0.5096, eval_acc: 0.8631:  40%|[32m███▉      [0m| 1313/3290 [08:01<13:12,  2.49it/s][A[2025-02-04 03:21:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1313/3290, eval_loss: 0.5096, eval_acc: 0.8631:  40%|[32m███▉      [0m| 1314/3290 [08:02<12:07,  2.72it/s][A
step: 1314/3290, eval_loss: 0.5095, eval_acc: 0.8631:  40%|[32m███▉      [0m| 1314/3290 [08:02<12:07,  2.72it/s][A[2025-02-04 03:21:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1314/3290, eval_loss: 0.5095, eval_acc: 0.8631:  40%|[32m███▉      [0m| 1315/3290 [08:02<12:23,  2.66it/s][A
step: 1315/3290, eval_loss: 0.5094, eval_acc: 0.8632:  40%|[32m███▉      [0m| 1315/3290 [08:02<12:23,  2.66it/s][A[2025-02-04 03:21:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1315/3290, eval_loss: 0.5094, eval_acc: 0.8632:  40%|[32m████      [0m| 1316/3290 [08:03<13:34,  2.42it/s][A
step: 1316/3290, eval_loss: 0.5092, eval_acc: 0.8632:  40%|[32m████      [0m| 1316/3290 [08:03<13:34,  2.42it/s][A[2025-02-04 03:21:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1316/3290, eval_loss: 0.5092, eval_acc: 0.8632:  40%|[32m████      [0m| 1317/3290 [08:03<13:38,  2.41it/s][A
step: 1317/3290, eval_loss: 0.5092, eval_acc: 0.8633:  40%|[32m████      [0m| 1317/3290 [08:03<13:38,  2.41it/s][A[2025-02-04 03:21:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1317/3290, eval_loss: 0.5092, eval_acc: 0.8633:  40%|[32m████      [0m| 1318/3290 [08:03<13:30,  2.43it/s][A
step: 1318/3290, eval_loss: 0.5091, eval_acc: 0.8633:  40%|[32m████      [0m| 1318/3290 [08:03<13:30,  2.43it/s][A[2025-02-04 03:21:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1318/3290, eval_loss: 0.5091, eval_acc: 0.8633:  40%|[32m████      [0m| 1319/3290 [08:04<12:41,  2.59it/s][A
step: 1319/3290, eval_loss: 0.5090, eval_acc: 0.8633:  40%|[32m████      [0m| 1319/3290 [08:04<12:41,  2.59it/s][A[2025-02-04 03:21:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1319/3290, eval_loss: 0.5090, eval_acc: 0.8633:  40%|[32m████      [0m| 1320/3290 [08:04<12:44,  2.58it/s][A
step: 1320/3290, eval_loss: 0.5089, eval_acc: 0.8633:  40%|[32m████      [0m| 1320/3290 [08:04<12:44,  2.58it/s][A[2025-02-04 03:21:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1320/3290, eval_loss: 0.5089, eval_acc: 0.8633:  40%|[32m████      [0m| 1321/3290 [08:05<12:50,  2.55it/s][A
step: 1321/3290, eval_loss: 0.5089, eval_acc: 0.8633:  40%|[32m████      [0m| 1321/3290 [08:05<12:50,  2.55it/s][A[2025-02-04 03:21:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1321/3290, eval_loss: 0.5089, eval_acc: 0.8633:  40%|[32m████      [0m| 1322/3290 [08:05<13:20,  2.46it/s][A
step: 1322/3290, eval_loss: 0.5089, eval_acc: 0.8633:  40%|[32m████      [0m| 1322/3290 [08:05<13:20,  2.46it/s][A[2025-02-04 03:21:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1322/3290, eval_loss: 0.5089, eval_acc: 0.8633:  40%|[32m████      [0m| 1323/3290 [08:05<13:31,  2.42it/s][A
step: 1323/3290, eval_loss: 0.5087, eval_acc: 0.8634:  40%|[32m████      [0m| 1323/3290 [08:05<13:31,  2.42it/s][A[2025-02-04 03:22:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1323/3290, eval_loss: 0.5087, eval_acc: 0.8634:  40%|[32m████      [0m| 1324/3290 [08:06<13:33,  2.42it/s][A
step: 1324/3290, eval_loss: 0.5086, eval_acc: 0.8634:  40%|[32m████      [0m| 1324/3290 [08:06<13:33,  2.42it/s][A[2025-02-04 03:22:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1324/3290, eval_loss: 0.5086, eval_acc: 0.8634:  40%|[32m████      [0m| 1325/3290 [08:06<13:14,  2.47it/s][A
step: 1325/3290, eval_loss: 0.5084, eval_acc: 0.8634:  40%|[32m████      [0m| 1325/3290 [08:06<13:14,  2.47it/s][A[2025-02-04 03:22:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1325/3290, eval_loss: 0.5084, eval_acc: 0.8634:  40%|[32m████      [0m| 1326/3290 [08:07<12:29,  2.62it/s][A
step: 1326/3290, eval_loss: 0.5084, eval_acc: 0.8634:  40%|[32m████      [0m| 1326/3290 [08:07<12:29,  2.62it/s][A[2025-02-04 03:22:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1326/3290, eval_loss: 0.5084, eval_acc: 0.8634:  40%|[32m████      [0m| 1327/3290 [08:07<12:38,  2.59it/s][A
step: 1327/3290, eval_loss: 0.5083, eval_acc: 0.8635:  40%|[32m████      [0m| 1327/3290 [08:07<12:38,  2.59it/s][A[2025-02-04 03:22:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1327/3290, eval_loss: 0.5083, eval_acc: 0.8635:  40%|[32m████      [0m| 1328/3290 [08:07<12:16,  2.67it/s][A
step: 1328/3290, eval_loss: 0.5080, eval_acc: 0.8635:  40%|[32m████      [0m| 1328/3290 [08:07<12:16,  2.67it/s][A[2025-02-04 03:22:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1328/3290, eval_loss: 0.5080, eval_acc: 0.8635:  40%|[32m████      [0m| 1329/3290 [08:08<11:42,  2.79it/s][A
step: 1329/3290, eval_loss: 0.5080, eval_acc: 0.8636:  40%|[32m████      [0m| 1329/3290 [08:08<11:42,  2.79it/s][A[2025-02-04 03:22:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1329/3290, eval_loss: 0.5080, eval_acc: 0.8636:  40%|[32m████      [0m| 1330/3290 [08:08<11:43,  2.79it/s][A
step: 1330/3290, eval_loss: 0.5080, eval_acc: 0.8636:  40%|[32m████      [0m| 1330/3290 [08:08<11:43,  2.79it/s][A[2025-02-04 03:22:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1330/3290, eval_loss: 0.5080, eval_acc: 0.8636:  40%|[32m████      [0m| 1331/3290 [08:08<12:05,  2.70it/s][A
step: 1331/3290, eval_loss: 0.5077, eval_acc: 0.8637:  40%|[32m████      [0m| 1331/3290 [08:08<12:05,  2.70it/s][A[2025-02-04 03:22:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1331/3290, eval_loss: 0.5077, eval_acc: 0.8637:  40%|[32m████      [0m| 1332/3290 [08:09<12:51,  2.54it/s][A
step: 1332/3290, eval_loss: 0.5075, eval_acc: 0.8637:  40%|[32m████      [0m| 1332/3290 [08:09<12:51,  2.54it/s][A[2025-02-04 03:22:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1332/3290, eval_loss: 0.5075, eval_acc: 0.8637:  41%|[32m████      [0m| 1333/3290 [08:09<13:04,  2.49it/s][A
step: 1333/3290, eval_loss: 0.5072, eval_acc: 0.8638:  41%|[32m████      [0m| 1333/3290 [08:09<13:04,  2.49it/s][A[2025-02-04 03:22:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1333/3290, eval_loss: 0.5072, eval_acc: 0.8638:  41%|[32m████      [0m| 1334/3290 [08:10<12:40,  2.57it/s][A
step: 1334/3290, eval_loss: 0.5073, eval_acc: 0.8638:  41%|[32m████      [0m| 1334/3290 [08:10<12:40,  2.57it/s][A[2025-02-04 03:22:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1334/3290, eval_loss: 0.5073, eval_acc: 0.8638:  41%|[32m████      [0m| 1335/3290 [08:10<12:38,  2.58it/s][A
step: 1335/3290, eval_loss: 0.5071, eval_acc: 0.8638:  41%|[32m████      [0m| 1335/3290 [08:10<12:38,  2.58it/s][A[2025-02-04 03:22:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1335/3290, eval_loss: 0.5071, eval_acc: 0.8638:  41%|[32m████      [0m| 1336/3290 [08:10<13:09,  2.48it/s][A
step: 1336/3290, eval_loss: 0.5069, eval_acc: 0.8639:  41%|[32m████      [0m| 1336/3290 [08:10<13:09,  2.48it/s][A[2025-02-04 03:22:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1336/3290, eval_loss: 0.5069, eval_acc: 0.8639:  41%|[32m████      [0m| 1337/3290 [08:11<12:02,  2.70it/s][A
step: 1337/3290, eval_loss: 0.5067, eval_acc: 0.8639:  41%|[32m████      [0m| 1337/3290 [08:11<12:02,  2.70it/s][A[2025-02-04 03:22:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1337/3290, eval_loss: 0.5067, eval_acc: 0.8639:  41%|[32m████      [0m| 1338/3290 [08:11<12:04,  2.70it/s][A
step: 1338/3290, eval_loss: 0.5067, eval_acc: 0.8639:  41%|[32m████      [0m| 1338/3290 [08:11<12:04,  2.70it/s][A[2025-02-04 03:22:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1338/3290, eval_loss: 0.5067, eval_acc: 0.8639:  41%|[32m████      [0m| 1339/3290 [08:12<13:10,  2.47it/s][A
step: 1339/3290, eval_loss: 0.5065, eval_acc: 0.8640:  41%|[32m████      [0m| 1339/3290 [08:12<13:10,  2.47it/s][A[2025-02-04 03:22:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1339/3290, eval_loss: 0.5065, eval_acc: 0.8640:  41%|[32m████      [0m| 1340/3290 [08:12<12:50,  2.53it/s][A
step: 1340/3290, eval_loss: 0.5068, eval_acc: 0.8639:  41%|[32m████      [0m| 1340/3290 [08:12<12:50,  2.53it/s][A[2025-02-04 03:22:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1340/3290, eval_loss: 0.5068, eval_acc: 0.8639:  41%|[32m████      [0m| 1341/3290 [08:12<12:26,  2.61it/s][A
step: 1341/3290, eval_loss: 0.5065, eval_acc: 0.8640:  41%|[32m████      [0m| 1341/3290 [08:12<12:26,  2.61it/s][A[2025-02-04 03:22:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1341/3290, eval_loss: 0.5065, eval_acc: 0.8640:  41%|[32m████      [0m| 1342/3290 [08:13<12:13,  2.65it/s][A
step: 1342/3290, eval_loss: 0.5066, eval_acc: 0.8640:  41%|[32m████      [0m| 1342/3290 [08:13<12:13,  2.65it/s][A[2025-02-04 03:22:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1342/3290, eval_loss: 0.5066, eval_acc: 0.8640:  41%|[32m████      [0m| 1343/3290 [08:13<12:17,  2.64it/s][A
step: 1343/3290, eval_loss: 0.5064, eval_acc: 0.8641:  41%|[32m████      [0m| 1343/3290 [08:13<12:17,  2.64it/s][A[2025-02-04 03:22:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1343/3290, eval_loss: 0.5064, eval_acc: 0.8641:  41%|[32m████      [0m| 1344/3290 [08:13<12:33,  2.58it/s][A
step: 1344/3290, eval_loss: 0.5064, eval_acc: 0.8641:  41%|[32m████      [0m| 1344/3290 [08:13<12:33,  2.58it/s][A[2025-02-04 03:22:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1344/3290, eval_loss: 0.5064, eval_acc: 0.8641:  41%|[32m████      [0m| 1345/3290 [08:14<12:16,  2.64it/s][A
step: 1345/3290, eval_loss: 0.5062, eval_acc: 0.8641:  41%|[32m████      [0m| 1345/3290 [08:14<12:16,  2.64it/s][A[2025-02-04 03:22:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1345/3290, eval_loss: 0.5062, eval_acc: 0.8641:  41%|[32m████      [0m| 1346/3290 [08:14<11:48,  2.74it/s][A
step: 1346/3290, eval_loss: 0.5063, eval_acc: 0.8641:  41%|[32m████      [0m| 1346/3290 [08:14<11:48,  2.74it/s][A[2025-02-04 03:22:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1346/3290, eval_loss: 0.5063, eval_acc: 0.8641:  41%|[32m████      [0m| 1347/3290 [08:15<12:57,  2.50it/s][A
step: 1347/3290, eval_loss: 0.5061, eval_acc: 0.8642:  41%|[32m████      [0m| 1347/3290 [08:15<12:57,  2.50it/s][A[2025-02-04 03:22:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1347/3290, eval_loss: 0.5061, eval_acc: 0.8642:  41%|[32m████      [0m| 1348/3290 [08:15<13:16,  2.44it/s][A
step: 1348/3290, eval_loss: 0.5059, eval_acc: 0.8642:  41%|[32m████      [0m| 1348/3290 [08:15<13:16,  2.44it/s][A[2025-02-04 03:22:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1348/3290, eval_loss: 0.5059, eval_acc: 0.8642:  41%|[32m████      [0m| 1349/3290 [08:15<12:35,  2.57it/s][A
step: 1349/3290, eval_loss: 0.5057, eval_acc: 0.8643:  41%|[32m████      [0m| 1349/3290 [08:15<12:35,  2.57it/s][A[2025-02-04 03:22:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1349/3290, eval_loss: 0.5057, eval_acc: 0.8643:  41%|[32m████      [0m| 1350/3290 [08:16<15:01,  2.15it/s][A
step: 1350/3290, eval_loss: 0.5057, eval_acc: 0.8643:  41%|[32m████      [0m| 1350/3290 [08:16<15:01,  2.15it/s][A[2025-02-04 03:22:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1350/3290, eval_loss: 0.5057, eval_acc: 0.8643:  41%|[32m████      [0m| 1351/3290 [08:16<13:15,  2.44it/s][A
step: 1351/3290, eval_loss: 0.5057, eval_acc: 0.8643:  41%|[32m████      [0m| 1351/3290 [08:16<13:15,  2.44it/s][A[2025-02-04 03:22:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1351/3290, eval_loss: 0.5057, eval_acc: 0.8643:  41%|[32m████      [0m| 1352/3290 [08:17<13:16,  2.43it/s][A
step: 1352/3290, eval_loss: 0.5056, eval_acc: 0.8643:  41%|[32m████      [0m| 1352/3290 [08:17<13:16,  2.43it/s][A[2025-02-04 03:22:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1352/3290, eval_loss: 0.5056, eval_acc: 0.8643:  41%|[32m████      [0m| 1353/3290 [08:17<13:25,  2.40it/s][A
step: 1353/3290, eval_loss: 0.5056, eval_acc: 0.8643:  41%|[32m████      [0m| 1353/3290 [08:17<13:25,  2.40it/s][A[2025-02-04 03:22:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1353/3290, eval_loss: 0.5056, eval_acc: 0.8643:  41%|[32m████      [0m| 1354/3290 [08:18<13:37,  2.37it/s][A
step: 1354/3290, eval_loss: 0.5058, eval_acc: 0.8642:  41%|[32m████      [0m| 1354/3290 [08:18<13:37,  2.37it/s][A[2025-02-04 03:22:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1354/3290, eval_loss: 0.5058, eval_acc: 0.8642:  41%|[32m████      [0m| 1355/3290 [08:18<12:59,  2.48it/s][A
step: 1355/3290, eval_loss: 0.5057, eval_acc: 0.8642:  41%|[32m████      [0m| 1355/3290 [08:18<12:59,  2.48it/s][A[2025-02-04 03:22:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1355/3290, eval_loss: 0.5057, eval_acc: 0.8642:  41%|[32m████      [0m| 1356/3290 [08:19<14:57,  2.15it/s][A
step: 1356/3290, eval_loss: 0.5057, eval_acc: 0.8643:  41%|[32m████      [0m| 1356/3290 [08:19<14:57,  2.15it/s][A[2025-02-04 03:22:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1356/3290, eval_loss: 0.5057, eval_acc: 0.8643:  41%|[32m████      [0m| 1357/3290 [08:19<15:42,  2.05it/s][A
step: 1357/3290, eval_loss: 0.5056, eval_acc: 0.8643:  41%|[32m████      [0m| 1357/3290 [08:19<15:42,  2.05it/s][A[2025-02-04 03:22:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1357/3290, eval_loss: 0.5056, eval_acc: 0.8643:  41%|[32m████▏     [0m| 1358/3290 [08:19<14:10,  2.27it/s][A
step: 1358/3290, eval_loss: 0.5054, eval_acc: 0.8643:  41%|[32m████▏     [0m| 1358/3290 [08:19<14:10,  2.27it/s][A[2025-02-04 03:22:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1358/3290, eval_loss: 0.5054, eval_acc: 0.8643:  41%|[32m████▏     [0m| 1359/3290 [08:20<13:18,  2.42it/s][A
step: 1359/3290, eval_loss: 0.5053, eval_acc: 0.8644:  41%|[32m████▏     [0m| 1359/3290 [08:20<13:18,  2.42it/s][A[2025-02-04 03:22:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1359/3290, eval_loss: 0.5053, eval_acc: 0.8644:  41%|[32m████▏     [0m| 1360/3290 [08:20<13:52,  2.32it/s][A
step: 1360/3290, eval_loss: 0.5051, eval_acc: 0.8644:  41%|[32m████▏     [0m| 1360/3290 [08:20<13:52,  2.32it/s][A[2025-02-04 03:22:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1360/3290, eval_loss: 0.5051, eval_acc: 0.8644:  41%|[32m████▏     [0m| 1361/3290 [08:21<14:19,  2.25it/s][A
step: 1361/3290, eval_loss: 0.5049, eval_acc: 0.8645:  41%|[32m████▏     [0m| 1361/3290 [08:21<14:19,  2.25it/s][A[2025-02-04 03:22:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1361/3290, eval_loss: 0.5049, eval_acc: 0.8645:  41%|[32m████▏     [0m| 1362/3290 [08:21<13:09,  2.44it/s][A
step: 1362/3290, eval_loss: 0.5047, eval_acc: 0.8645:  41%|[32m████▏     [0m| 1362/3290 [08:21<13:09,  2.44it/s][A[2025-02-04 03:22:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1362/3290, eval_loss: 0.5047, eval_acc: 0.8645:  41%|[32m████▏     [0m| 1363/3290 [08:21<12:49,  2.51it/s][A
step: 1363/3290, eval_loss: 0.5044, eval_acc: 0.8646:  41%|[32m████▏     [0m| 1363/3290 [08:21<12:49,  2.51it/s][A[2025-02-04 03:22:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1363/3290, eval_loss: 0.5044, eval_acc: 0.8646:  41%|[32m████▏     [0m| 1364/3290 [08:22<11:45,  2.73it/s][A
step: 1364/3290, eval_loss: 0.5044, eval_acc: 0.8646:  41%|[32m████▏     [0m| 1364/3290 [08:22<11:45,  2.73it/s][A[2025-02-04 03:22:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1364/3290, eval_loss: 0.5044, eval_acc: 0.8646:  41%|[32m████▏     [0m| 1365/3290 [08:22<10:57,  2.93it/s][A
step: 1365/3290, eval_loss: 0.5044, eval_acc: 0.8646:  41%|[32m████▏     [0m| 1365/3290 [08:22<10:57,  2.93it/s][A[2025-02-04 03:22:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1365/3290, eval_loss: 0.5044, eval_acc: 0.8646:  42%|[32m████▏     [0m| 1366/3290 [08:22<10:49,  2.96it/s][A
step: 1366/3290, eval_loss: 0.5043, eval_acc: 0.8646:  42%|[32m████▏     [0m| 1366/3290 [08:22<10:49,  2.96it/s][A[2025-02-04 03:22:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1366/3290, eval_loss: 0.5043, eval_acc: 0.8646:  42%|[32m████▏     [0m| 1367/3290 [08:23<12:20,  2.60it/s][A
step: 1367/3290, eval_loss: 0.5044, eval_acc: 0.8646:  42%|[32m████▏     [0m| 1367/3290 [08:23<12:20,  2.60it/s][A[2025-02-04 03:22:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1367/3290, eval_loss: 0.5044, eval_acc: 0.8646:  42%|[32m████▏     [0m| 1368/3290 [08:23<13:01,  2.46it/s][A
step: 1368/3290, eval_loss: 0.5042, eval_acc: 0.8647:  42%|[32m████▏     [0m| 1368/3290 [08:23<13:01,  2.46it/s][A[2025-02-04 03:22:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1368/3290, eval_loss: 0.5042, eval_acc: 0.8647:  42%|[32m████▏     [0m| 1369/3290 [08:24<12:06,  2.64it/s][A
step: 1369/3290, eval_loss: 0.5039, eval_acc: 0.8647:  42%|[32m████▏     [0m| 1369/3290 [08:24<12:06,  2.64it/s][A[2025-02-04 03:22:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1369/3290, eval_loss: 0.5039, eval_acc: 0.8647:  42%|[32m████▏     [0m| 1370/3290 [08:24<12:24,  2.58it/s][A
step: 1370/3290, eval_loss: 0.5038, eval_acc: 0.8648:  42%|[32m████▏     [0m| 1370/3290 [08:24<12:24,  2.58it/s][A[2025-02-04 03:22:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1370/3290, eval_loss: 0.5038, eval_acc: 0.8648:  42%|[32m████▏     [0m| 1371/3290 [08:24<11:48,  2.71it/s][A
step: 1371/3290, eval_loss: 0.5039, eval_acc: 0.8648:  42%|[32m████▏     [0m| 1371/3290 [08:24<11:48,  2.71it/s][A[2025-02-04 03:22:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1371/3290, eval_loss: 0.5039, eval_acc: 0.8648:  42%|[32m████▏     [0m| 1372/3290 [08:25<12:48,  2.50it/s][A
step: 1372/3290, eval_loss: 0.5037, eval_acc: 0.8648:  42%|[32m████▏     [0m| 1372/3290 [08:25<12:48,  2.50it/s][A[2025-02-04 03:22:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1372/3290, eval_loss: 0.5037, eval_acc: 0.8648:  42%|[32m████▏     [0m| 1373/3290 [08:25<13:46,  2.32it/s][A
step: 1373/3290, eval_loss: 0.5036, eval_acc: 0.8649:  42%|[32m████▏     [0m| 1373/3290 [08:25<13:46,  2.32it/s][A[2025-02-04 03:22:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1373/3290, eval_loss: 0.5036, eval_acc: 0.8649:  42%|[32m████▏     [0m| 1374/3290 [08:26<13:25,  2.38it/s][A
step: 1374/3290, eval_loss: 0.5036, eval_acc: 0.8649:  42%|[32m████▏     [0m| 1374/3290 [08:26<13:25,  2.38it/s][A[2025-02-04 03:22:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1374/3290, eval_loss: 0.5036, eval_acc: 0.8649:  42%|[32m████▏     [0m| 1375/3290 [08:26<13:04,  2.44it/s][A
step: 1375/3290, eval_loss: 0.5034, eval_acc: 0.8649:  42%|[32m████▏     [0m| 1375/3290 [08:26<13:04,  2.44it/s][A[2025-02-04 03:22:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1375/3290, eval_loss: 0.5034, eval_acc: 0.8649:  42%|[32m████▏     [0m| 1376/3290 [08:26<12:42,  2.51it/s][A
step: 1376/3290, eval_loss: 0.5031, eval_acc: 0.8650:  42%|[32m████▏     [0m| 1376/3290 [08:26<12:42,  2.51it/s][A[2025-02-04 03:22:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1376/3290, eval_loss: 0.5031, eval_acc: 0.8650:  42%|[32m████▏     [0m| 1377/3290 [08:27<13:36,  2.34it/s][A
step: 1377/3290, eval_loss: 0.5030, eval_acc: 0.8650:  42%|[32m████▏     [0m| 1377/3290 [08:27<13:36,  2.34it/s][A[2025-02-04 03:22:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1377/3290, eval_loss: 0.5030, eval_acc: 0.8650:  42%|[32m████▏     [0m| 1378/3290 [08:27<13:10,  2.42it/s][A
step: 1378/3290, eval_loss: 0.5029, eval_acc: 0.8651:  42%|[32m████▏     [0m| 1378/3290 [08:27<13:10,  2.42it/s][A[2025-02-04 03:22:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1378/3290, eval_loss: 0.5029, eval_acc: 0.8651:  42%|[32m████▏     [0m| 1379/3290 [08:28<13:02,  2.44it/s][A
step: 1379/3290, eval_loss: 0.5029, eval_acc: 0.8651:  42%|[32m████▏     [0m| 1379/3290 [08:28<13:02,  2.44it/s][A[2025-02-04 03:22:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1379/3290, eval_loss: 0.5029, eval_acc: 0.8651:  42%|[32m████▏     [0m| 1380/3290 [08:28<12:52,  2.47it/s][A
step: 1380/3290, eval_loss: 0.5028, eval_acc: 0.8651:  42%|[32m████▏     [0m| 1380/3290 [08:28<12:52,  2.47it/s][A[2025-02-04 03:22:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1380/3290, eval_loss: 0.5028, eval_acc: 0.8651:  42%|[32m████▏     [0m| 1381/3290 [08:29<13:41,  2.32it/s][A
step: 1381/3290, eval_loss: 0.5029, eval_acc: 0.8651:  42%|[32m████▏     [0m| 1381/3290 [08:29<13:41,  2.32it/s][A[2025-02-04 03:22:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1381/3290, eval_loss: 0.5029, eval_acc: 0.8651:  42%|[32m████▏     [0m| 1382/3290 [08:29<13:59,  2.27it/s][A
step: 1382/3290, eval_loss: 0.5027, eval_acc: 0.8652:  42%|[32m████▏     [0m| 1382/3290 [08:29<13:59,  2.27it/s][A[2025-02-04 03:22:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1382/3290, eval_loss: 0.5027, eval_acc: 0.8652:  42%|[32m████▏     [0m| 1383/3290 [08:30<13:52,  2.29it/s][A
step: 1383/3290, eval_loss: 0.5024, eval_acc: 0.8652:  42%|[32m████▏     [0m| 1383/3290 [08:30<13:52,  2.29it/s][A[2025-02-04 03:22:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1383/3290, eval_loss: 0.5024, eval_acc: 0.8652:  42%|[32m████▏     [0m| 1384/3290 [08:30<12:50,  2.47it/s][A
step: 1384/3290, eval_loss: 0.5023, eval_acc: 0.8653:  42%|[32m████▏     [0m| 1384/3290 [08:30<12:50,  2.47it/s][A[2025-02-04 03:22:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1384/3290, eval_loss: 0.5023, eval_acc: 0.8653:  42%|[32m████▏     [0m| 1385/3290 [08:30<12:02,  2.64it/s][A
step: 1385/3290, eval_loss: 0.5025, eval_acc: 0.8652:  42%|[32m████▏     [0m| 1385/3290 [08:30<12:02,  2.64it/s][A[2025-02-04 03:22:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1385/3290, eval_loss: 0.5025, eval_acc: 0.8652:  42%|[32m████▏     [0m| 1386/3290 [08:31<12:53,  2.46it/s][A
step: 1386/3290, eval_loss: 0.5023, eval_acc: 0.8653:  42%|[32m████▏     [0m| 1386/3290 [08:31<12:53,  2.46it/s][A[2025-02-04 03:22:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1386/3290, eval_loss: 0.5023, eval_acc: 0.8653:  42%|[32m████▏     [0m| 1387/3290 [08:31<14:53,  2.13it/s][A
step: 1387/3290, eval_loss: 0.5023, eval_acc: 0.8653:  42%|[32m████▏     [0m| 1387/3290 [08:31<14:53,  2.13it/s][A[2025-02-04 03:22:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1387/3290, eval_loss: 0.5023, eval_acc: 0.8653:  42%|[32m████▏     [0m| 1388/3290 [08:32<13:38,  2.32it/s][A
step: 1388/3290, eval_loss: 0.5022, eval_acc: 0.8653:  42%|[32m████▏     [0m| 1388/3290 [08:32<13:38,  2.32it/s][A[2025-02-04 03:22:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1388/3290, eval_loss: 0.5022, eval_acc: 0.8653:  42%|[32m████▏     [0m| 1389/3290 [08:32<14:08,  2.24it/s][A
step: 1389/3290, eval_loss: 0.5019, eval_acc: 0.8654:  42%|[32m████▏     [0m| 1389/3290 [08:32<14:08,  2.24it/s][A[2025-02-04 03:22:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1389/3290, eval_loss: 0.5019, eval_acc: 0.8654:  42%|[32m████▏     [0m| 1390/3290 [08:32<13:32,  2.34it/s][A
step: 1390/3290, eval_loss: 0.5018, eval_acc: 0.8655:  42%|[32m████▏     [0m| 1390/3290 [08:32<13:32,  2.34it/s][A[2025-02-04 03:22:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1390/3290, eval_loss: 0.5018, eval_acc: 0.8655:  42%|[32m████▏     [0m| 1391/3290 [08:33<12:05,  2.62it/s][A
step: 1391/3290, eval_loss: 0.5018, eval_acc: 0.8655:  42%|[32m████▏     [0m| 1391/3290 [08:33<12:05,  2.62it/s][A[2025-02-04 03:22:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1391/3290, eval_loss: 0.5018, eval_acc: 0.8655:  42%|[32m████▏     [0m| 1392/3290 [08:33<11:18,  2.80it/s][A
step: 1392/3290, eval_loss: 0.5017, eval_acc: 0.8655:  42%|[32m████▏     [0m| 1392/3290 [08:33<11:18,  2.80it/s][A[2025-02-04 03:22:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1392/3290, eval_loss: 0.5017, eval_acc: 0.8655:  42%|[32m████▏     [0m| 1393/3290 [08:33<10:17,  3.07it/s][A
step: 1393/3290, eval_loss: 0.5015, eval_acc: 0.8655:  42%|[32m████▏     [0m| 1393/3290 [08:33<10:17,  3.07it/s][A[2025-02-04 03:22:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1393/3290, eval_loss: 0.5015, eval_acc: 0.8655:  42%|[32m████▏     [0m| 1394/3290 [08:34<10:51,  2.91it/s][A
step: 1394/3290, eval_loss: 0.5015, eval_acc: 0.8656:  42%|[32m████▏     [0m| 1394/3290 [08:34<10:51,  2.91it/s][A[2025-02-04 03:22:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1394/3290, eval_loss: 0.5015, eval_acc: 0.8656:  42%|[32m████▏     [0m| 1395/3290 [08:34<10:06,  3.12it/s][A
step: 1395/3290, eval_loss: 0.5012, eval_acc: 0.8656:  42%|[32m████▏     [0m| 1395/3290 [08:34<10:06,  3.12it/s][A[2025-02-04 03:22:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1395/3290, eval_loss: 0.5012, eval_acc: 0.8656:  42%|[32m████▏     [0m| 1396/3290 [08:34<10:20,  3.05it/s][A
step: 1396/3290, eval_loss: 0.5010, eval_acc: 0.8657:  42%|[32m████▏     [0m| 1396/3290 [08:34<10:20,  3.05it/s][A[2025-02-04 03:22:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1396/3290, eval_loss: 0.5010, eval_acc: 0.8657:  42%|[32m████▏     [0m| 1397/3290 [08:35<11:20,  2.78it/s][A
step: 1397/3290, eval_loss: 0.5009, eval_acc: 0.8657:  42%|[32m████▏     [0m| 1397/3290 [08:35<11:20,  2.78it/s][A[2025-02-04 03:22:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1397/3290, eval_loss: 0.5009, eval_acc: 0.8657:  42%|[32m████▏     [0m| 1398/3290 [08:35<11:53,  2.65it/s][A
step: 1398/3290, eval_loss: 0.5008, eval_acc: 0.8657:  42%|[32m████▏     [0m| 1398/3290 [08:35<11:53,  2.65it/s][A[2025-02-04 03:22:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1398/3290, eval_loss: 0.5008, eval_acc: 0.8657:  43%|[32m████▎     [0m| 1399/3290 [08:35<10:58,  2.87it/s][A
step: 1399/3290, eval_loss: 0.5008, eval_acc: 0.8657:  43%|[32m████▎     [0m| 1399/3290 [08:35<10:58,  2.87it/s][A[2025-02-04 03:22:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1399/3290, eval_loss: 0.5008, eval_acc: 0.8657:  43%|[32m████▎     [0m| 1400/3290 [08:36<11:28,  2.75it/s][A
step: 1400/3290, eval_loss: 0.5006, eval_acc: 0.8658:  43%|[32m████▎     [0m| 1400/3290 [08:36<11:28,  2.75it/s][A[2025-02-04 03:22:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1400/3290, eval_loss: 0.5006, eval_acc: 0.8658:  43%|[32m████▎     [0m| 1401/3290 [08:36<12:36,  2.50it/s][A
step: 1401/3290, eval_loss: 0.5004, eval_acc: 0.8658:  43%|[32m████▎     [0m| 1401/3290 [08:36<12:36,  2.50it/s][A[2025-02-04 03:22:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1401/3290, eval_loss: 0.5004, eval_acc: 0.8658:  43%|[32m████▎     [0m| 1402/3290 [08:37<13:04,  2.41it/s][A
step: 1402/3290, eval_loss: 0.5001, eval_acc: 0.8659:  43%|[32m████▎     [0m| 1402/3290 [08:37<13:04,  2.41it/s][A[2025-02-04 03:22:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1402/3290, eval_loss: 0.5001, eval_acc: 0.8659:  43%|[32m████▎     [0m| 1403/3290 [08:37<13:19,  2.36it/s][A
step: 1403/3290, eval_loss: 0.4999, eval_acc: 0.8659:  43%|[32m████▎     [0m| 1403/3290 [08:37<13:19,  2.36it/s][A[2025-02-04 03:22:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1403/3290, eval_loss: 0.4999, eval_acc: 0.8659:  43%|[32m████▎     [0m| 1404/3290 [08:38<12:37,  2.49it/s][A
step: 1404/3290, eval_loss: 0.4999, eval_acc: 0.8659:  43%|[32m████▎     [0m| 1404/3290 [08:38<12:37,  2.49it/s][A[2025-02-04 03:22:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1404/3290, eval_loss: 0.4999, eval_acc: 0.8659:  43%|[32m████▎     [0m| 1405/3290 [08:38<11:52,  2.65it/s][A
step: 1405/3290, eval_loss: 0.4999, eval_acc: 0.8659:  43%|[32m████▎     [0m| 1405/3290 [08:38<11:52,  2.65it/s][A[2025-02-04 03:22:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1405/3290, eval_loss: 0.4999, eval_acc: 0.8659:  43%|[32m████▎     [0m| 1406/3290 [08:38<12:03,  2.60it/s][A
step: 1406/3290, eval_loss: 0.4998, eval_acc: 0.8659:  43%|[32m████▎     [0m| 1406/3290 [08:38<12:03,  2.60it/s][A[2025-02-04 03:22:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1406/3290, eval_loss: 0.4998, eval_acc: 0.8659:  43%|[32m████▎     [0m| 1407/3290 [08:39<12:13,  2.57it/s][A
step: 1407/3290, eval_loss: 0.4996, eval_acc: 0.8660:  43%|[32m████▎     [0m| 1407/3290 [08:39<12:13,  2.57it/s][A[2025-02-04 03:22:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1407/3290, eval_loss: 0.4996, eval_acc: 0.8660:  43%|[32m████▎     [0m| 1408/3290 [08:39<12:02,  2.61it/s][A
step: 1408/3290, eval_loss: 0.4996, eval_acc: 0.8660:  43%|[32m████▎     [0m| 1408/3290 [08:39<12:02,  2.61it/s][A[2025-02-04 03:22:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1408/3290, eval_loss: 0.4996, eval_acc: 0.8660:  43%|[32m████▎     [0m| 1409/3290 [08:39<11:17,  2.78it/s][A
step: 1409/3290, eval_loss: 0.4995, eval_acc: 0.8661:  43%|[32m████▎     [0m| 1409/3290 [08:39<11:17,  2.78it/s][A[2025-02-04 03:22:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1409/3290, eval_loss: 0.4995, eval_acc: 0.8661:  43%|[32m████▎     [0m| 1410/3290 [08:40<11:33,  2.71it/s][A
step: 1410/3290, eval_loss: 0.4993, eval_acc: 0.8661:  43%|[32m████▎     [0m| 1410/3290 [08:40<11:33,  2.71it/s][A[2025-02-04 03:22:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1410/3290, eval_loss: 0.4993, eval_acc: 0.8661:  43%|[32m████▎     [0m| 1411/3290 [08:40<12:13,  2.56it/s][A
step: 1411/3290, eval_loss: 0.4991, eval_acc: 0.8662:  43%|[32m████▎     [0m| 1411/3290 [08:40<12:13,  2.56it/s][A[2025-02-04 03:22:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1411/3290, eval_loss: 0.4991, eval_acc: 0.8662:  43%|[32m████▎     [0m| 1412/3290 [08:41<11:42,  2.67it/s][A
step: 1412/3290, eval_loss: 0.4991, eval_acc: 0.8662:  43%|[32m████▎     [0m| 1412/3290 [08:41<11:42,  2.67it/s][A[2025-02-04 03:22:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1412/3290, eval_loss: 0.4991, eval_acc: 0.8662:  43%|[32m████▎     [0m| 1413/3290 [08:41<11:50,  2.64it/s][A
step: 1413/3290, eval_loss: 0.4989, eval_acc: 0.8662:  43%|[32m████▎     [0m| 1413/3290 [08:41<11:50,  2.64it/s][A[2025-02-04 03:22:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1413/3290, eval_loss: 0.4989, eval_acc: 0.8662:  43%|[32m████▎     [0m| 1414/3290 [08:41<12:43,  2.46it/s][A
step: 1414/3290, eval_loss: 0.4987, eval_acc: 0.8663:  43%|[32m████▎     [0m| 1414/3290 [08:41<12:43,  2.46it/s][A[2025-02-04 03:22:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1414/3290, eval_loss: 0.4987, eval_acc: 0.8663:  43%|[32m████▎     [0m| 1415/3290 [08:42<11:29,  2.72it/s][A
step: 1415/3290, eval_loss: 0.4986, eval_acc: 0.8663:  43%|[32m████▎     [0m| 1415/3290 [08:42<11:29,  2.72it/s][A[2025-02-04 03:22:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1415/3290, eval_loss: 0.4986, eval_acc: 0.8663:  43%|[32m████▎     [0m| 1416/3290 [08:42<11:59,  2.60it/s][A
step: 1416/3290, eval_loss: 0.4984, eval_acc: 0.8663:  43%|[32m████▎     [0m| 1416/3290 [08:42<11:59,  2.60it/s][A[2025-02-04 03:22:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1416/3290, eval_loss: 0.4984, eval_acc: 0.8663:  43%|[32m████▎     [0m| 1417/3290 [08:42<11:55,  2.62it/s][A
step: 1417/3290, eval_loss: 0.4982, eval_acc: 0.8664:  43%|[32m████▎     [0m| 1417/3290 [08:42<11:55,  2.62it/s][A[2025-02-04 03:22:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1417/3290, eval_loss: 0.4982, eval_acc: 0.8664:  43%|[32m████▎     [0m| 1418/3290 [08:43<11:30,  2.71it/s][A
step: 1418/3290, eval_loss: 0.4981, eval_acc: 0.8664:  43%|[32m████▎     [0m| 1418/3290 [08:43<11:30,  2.71it/s][A[2025-02-04 03:22:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1418/3290, eval_loss: 0.4981, eval_acc: 0.8664:  43%|[32m████▎     [0m| 1419/3290 [08:43<11:22,  2.74it/s][A
step: 1419/3290, eval_loss: 0.4980, eval_acc: 0.8665:  43%|[32m████▎     [0m| 1419/3290 [08:43<11:22,  2.74it/s][A[2025-02-04 03:22:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1419/3290, eval_loss: 0.4980, eval_acc: 0.8665:  43%|[32m████▎     [0m| 1420/3290 [08:44<11:48,  2.64it/s][A
step: 1420/3290, eval_loss: 0.4978, eval_acc: 0.8665:  43%|[32m████▎     [0m| 1420/3290 [08:44<11:48,  2.64it/s][A[2025-02-04 03:22:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1420/3290, eval_loss: 0.4978, eval_acc: 0.8665:  43%|[32m████▎     [0m| 1421/3290 [08:44<12:26,  2.51it/s][A
step: 1421/3290, eval_loss: 0.4977, eval_acc: 0.8665:  43%|[32m████▎     [0m| 1421/3290 [08:44<12:26,  2.51it/s][A[2025-02-04 03:22:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1421/3290, eval_loss: 0.4977, eval_acc: 0.8665:  43%|[32m████▎     [0m| 1422/3290 [08:44<11:33,  2.70it/s][A
step: 1422/3290, eval_loss: 0.4974, eval_acc: 0.8666:  43%|[32m████▎     [0m| 1422/3290 [08:44<11:33,  2.70it/s][A[2025-02-04 03:22:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1422/3290, eval_loss: 0.4974, eval_acc: 0.8666:  43%|[32m████▎     [0m| 1423/3290 [08:45<11:27,  2.71it/s][A
step: 1423/3290, eval_loss: 0.4974, eval_acc: 0.8666:  43%|[32m████▎     [0m| 1423/3290 [08:45<11:27,  2.71it/s][A[2025-02-04 03:22:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1423/3290, eval_loss: 0.4974, eval_acc: 0.8666:  43%|[32m████▎     [0m| 1424/3290 [08:45<12:16,  2.53it/s][A
step: 1424/3290, eval_loss: 0.4974, eval_acc: 0.8666:  43%|[32m████▎     [0m| 1424/3290 [08:45<12:16,  2.53it/s][A[2025-02-04 03:22:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1424/3290, eval_loss: 0.4974, eval_acc: 0.8666:  43%|[32m████▎     [0m| 1425/3290 [08:46<12:21,  2.51it/s][A
step: 1425/3290, eval_loss: 0.4973, eval_acc: 0.8666:  43%|[32m████▎     [0m| 1425/3290 [08:46<12:21,  2.51it/s][A[2025-02-04 03:22:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1425/3290, eval_loss: 0.4973, eval_acc: 0.8666:  43%|[32m████▎     [0m| 1426/3290 [08:46<12:09,  2.56it/s][A
step: 1426/3290, eval_loss: 0.4973, eval_acc: 0.8666:  43%|[32m████▎     [0m| 1426/3290 [08:46<12:09,  2.56it/s][A[2025-02-04 03:22:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1426/3290, eval_loss: 0.4973, eval_acc: 0.8666:  43%|[32m████▎     [0m| 1427/3290 [08:46<12:39,  2.45it/s][A
step: 1427/3290, eval_loss: 0.4972, eval_acc: 0.8667:  43%|[32m████▎     [0m| 1427/3290 [08:46<12:39,  2.45it/s][A[2025-02-04 03:22:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1427/3290, eval_loss: 0.4972, eval_acc: 0.8667:  43%|[32m████▎     [0m| 1428/3290 [08:47<12:14,  2.53it/s][A
step: 1428/3290, eval_loss: 0.4972, eval_acc: 0.8667:  43%|[32m████▎     [0m| 1428/3290 [08:47<12:14,  2.53it/s][A[2025-02-04 03:22:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1428/3290, eval_loss: 0.4972, eval_acc: 0.8667:  43%|[32m████▎     [0m| 1429/3290 [08:47<11:42,  2.65it/s][A
step: 1429/3290, eval_loss: 0.4970, eval_acc: 0.8667:  43%|[32m████▎     [0m| 1429/3290 [08:47<11:42,  2.65it/s][A[2025-02-04 03:22:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1429/3290, eval_loss: 0.4970, eval_acc: 0.8667:  43%|[32m████▎     [0m| 1430/3290 [08:47<11:05,  2.80it/s][A
step: 1430/3290, eval_loss: 0.4967, eval_acc: 0.8668:  43%|[32m████▎     [0m| 1430/3290 [08:47<11:05,  2.80it/s][A[2025-02-04 03:22:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1430/3290, eval_loss: 0.4967, eval_acc: 0.8668:  43%|[32m████▎     [0m| 1431/3290 [08:48<11:42,  2.64it/s][A
step: 1431/3290, eval_loss: 0.4965, eval_acc: 0.8669:  43%|[32m████▎     [0m| 1431/3290 [08:48<11:42,  2.64it/s][A[2025-02-04 03:22:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1431/3290, eval_loss: 0.4965, eval_acc: 0.8669:  44%|[32m████▎     [0m| 1432/3290 [08:48<12:59,  2.38it/s][A
step: 1432/3290, eval_loss: 0.4963, eval_acc: 0.8669:  44%|[32m████▎     [0m| 1432/3290 [08:48<12:59,  2.38it/s][A[2025-02-04 03:22:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1432/3290, eval_loss: 0.4963, eval_acc: 0.8669:  44%|[32m████▎     [0m| 1433/3290 [08:49<13:22,  2.31it/s][A
step: 1433/3290, eval_loss: 0.4961, eval_acc: 0.8670:  44%|[32m████▎     [0m| 1433/3290 [08:49<13:22,  2.31it/s][A[2025-02-04 03:22:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1433/3290, eval_loss: 0.4961, eval_acc: 0.8670:  44%|[32m████▎     [0m| 1434/3290 [08:49<12:24,  2.49it/s][A
step: 1434/3290, eval_loss: 0.4958, eval_acc: 0.8670:  44%|[32m████▎     [0m| 1434/3290 [08:49<12:24,  2.49it/s][A[2025-02-04 03:22:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1434/3290, eval_loss: 0.4958, eval_acc: 0.8670:  44%|[32m████▎     [0m| 1435/3290 [08:49<11:49,  2.61it/s][A
step: 1435/3290, eval_loss: 0.4958, eval_acc: 0.8670:  44%|[32m████▎     [0m| 1435/3290 [08:49<11:49,  2.61it/s][A[2025-02-04 03:22:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1435/3290, eval_loss: 0.4958, eval_acc: 0.8670:  44%|[32m████▎     [0m| 1436/3290 [08:50<10:57,  2.82it/s][A
step: 1436/3290, eval_loss: 0.4955, eval_acc: 0.8671:  44%|[32m████▎     [0m| 1436/3290 [08:50<10:57,  2.82it/s][A[2025-02-04 03:22:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1436/3290, eval_loss: 0.4955, eval_acc: 0.8671:  44%|[32m████▎     [0m| 1437/3290 [08:50<11:45,  2.63it/s][A
step: 1437/3290, eval_loss: 0.4953, eval_acc: 0.8672:  44%|[32m████▎     [0m| 1437/3290 [08:50<11:45,  2.63it/s][A[2025-02-04 03:22:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1437/3290, eval_loss: 0.4953, eval_acc: 0.8672:  44%|[32m████▎     [0m| 1438/3290 [08:51<11:44,  2.63it/s][A
step: 1438/3290, eval_loss: 0.4954, eval_acc: 0.8672:  44%|[32m████▎     [0m| 1438/3290 [08:51<11:44,  2.63it/s][A[2025-02-04 03:22:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1438/3290, eval_loss: 0.4954, eval_acc: 0.8672:  44%|[32m████▎     [0m| 1439/3290 [08:51<11:55,  2.59it/s][A
step: 1439/3290, eval_loss: 0.4953, eval_acc: 0.8672:  44%|[32m████▎     [0m| 1439/3290 [08:51<11:55,  2.59it/s][A[2025-02-04 03:22:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1439/3290, eval_loss: 0.4953, eval_acc: 0.8672:  44%|[32m████▍     [0m| 1440/3290 [08:51<12:05,  2.55it/s][A
step: 1440/3290, eval_loss: 0.4950, eval_acc: 0.8673:  44%|[32m████▍     [0m| 1440/3290 [08:51<12:05,  2.55it/s][A[2025-02-04 03:22:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1440/3290, eval_loss: 0.4950, eval_acc: 0.8673:  44%|[32m████▍     [0m| 1441/3290 [08:52<11:26,  2.69it/s][A
step: 1441/3290, eval_loss: 0.4951, eval_acc: 0.8672:  44%|[32m████▍     [0m| 1441/3290 [08:52<11:26,  2.69it/s][A[2025-02-04 03:22:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1441/3290, eval_loss: 0.4951, eval_acc: 0.8672:  44%|[32m████▍     [0m| 1442/3290 [08:52<10:48,  2.85it/s][A
step: 1442/3290, eval_loss: 0.4952, eval_acc: 0.8672:  44%|[32m████▍     [0m| 1442/3290 [08:52<10:48,  2.85it/s][A[2025-02-04 03:22:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1442/3290, eval_loss: 0.4952, eval_acc: 0.8672:  44%|[32m████▍     [0m| 1443/3290 [08:52<11:51,  2.60it/s][A
step: 1443/3290, eval_loss: 0.4951, eval_acc: 0.8673:  44%|[32m████▍     [0m| 1443/3290 [08:52<11:51,  2.60it/s][A[2025-02-04 03:22:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1443/3290, eval_loss: 0.4951, eval_acc: 0.8673:  44%|[32m████▍     [0m| 1444/3290 [08:53<12:03,  2.55it/s][A
step: 1444/3290, eval_loss: 0.4953, eval_acc: 0.8672:  44%|[32m████▍     [0m| 1444/3290 [08:53<12:03,  2.55it/s][A[2025-02-04 03:22:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1444/3290, eval_loss: 0.4953, eval_acc: 0.8672:  44%|[32m████▍     [0m| 1445/3290 [08:53<12:12,  2.52it/s][A
step: 1445/3290, eval_loss: 0.4951, eval_acc: 0.8672:  44%|[32m████▍     [0m| 1445/3290 [08:53<12:12,  2.52it/s][A[2025-02-04 03:22:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1445/3290, eval_loss: 0.4951, eval_acc: 0.8672:  44%|[32m████▍     [0m| 1446/3290 [08:54<12:29,  2.46it/s][A
step: 1446/3290, eval_loss: 0.4948, eval_acc: 0.8673:  44%|[32m████▍     [0m| 1446/3290 [08:54<12:29,  2.46it/s][A[2025-02-04 03:22:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1446/3290, eval_loss: 0.4948, eval_acc: 0.8673:  44%|[32m████▍     [0m| 1447/3290 [08:54<12:18,  2.49it/s][A
step: 1447/3290, eval_loss: 0.4949, eval_acc: 0.8673:  44%|[32m████▍     [0m| 1447/3290 [08:54<12:18,  2.49it/s][A[2025-02-04 03:22:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1447/3290, eval_loss: 0.4949, eval_acc: 0.8673:  44%|[32m████▍     [0m| 1448/3290 [08:54<11:27,  2.68it/s][A
step: 1448/3290, eval_loss: 0.4946, eval_acc: 0.8674:  44%|[32m████▍     [0m| 1448/3290 [08:54<11:27,  2.68it/s][A[2025-02-04 03:22:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1448/3290, eval_loss: 0.4946, eval_acc: 0.8674:  44%|[32m████▍     [0m| 1449/3290 [08:55<10:25,  2.94it/s][A
step: 1449/3290, eval_loss: 0.4945, eval_acc: 0.8674:  44%|[32m████▍     [0m| 1449/3290 [08:55<10:25,  2.94it/s][A[2025-02-04 03:22:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1449/3290, eval_loss: 0.4945, eval_acc: 0.8674:  44%|[32m████▍     [0m| 1450/3290 [08:55<09:36,  3.19it/s][A
step: 1450/3290, eval_loss: 0.4943, eval_acc: 0.8674:  44%|[32m████▍     [0m| 1450/3290 [08:55<09:36,  3.19it/s][A[2025-02-04 03:22:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1450/3290, eval_loss: 0.4943, eval_acc: 0.8674:  44%|[32m████▍     [0m| 1451/3290 [08:55<10:35,  2.89it/s][A
step: 1451/3290, eval_loss: 0.4941, eval_acc: 0.8675:  44%|[32m████▍     [0m| 1451/3290 [08:55<10:35,  2.89it/s][A[2025-02-04 03:22:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1451/3290, eval_loss: 0.4941, eval_acc: 0.8675:  44%|[32m████▍     [0m| 1452/3290 [08:56<10:14,  2.99it/s][A
step: 1452/3290, eval_loss: 0.4940, eval_acc: 0.8675:  44%|[32m████▍     [0m| 1452/3290 [08:56<10:14,  2.99it/s][A[2025-02-04 03:22:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1452/3290, eval_loss: 0.4940, eval_acc: 0.8675:  44%|[32m████▍     [0m| 1453/3290 [08:56<10:25,  2.94it/s][A
step: 1453/3290, eval_loss: 0.4939, eval_acc: 0.8675:  44%|[32m████▍     [0m| 1453/3290 [08:56<10:25,  2.94it/s][A[2025-02-04 03:22:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1453/3290, eval_loss: 0.4939, eval_acc: 0.8675:  44%|[32m████▍     [0m| 1454/3290 [08:56<10:34,  2.90it/s][A
step: 1454/3290, eval_loss: 0.4937, eval_acc: 0.8676:  44%|[32m████▍     [0m| 1454/3290 [08:56<10:34,  2.90it/s][A[2025-02-04 03:22:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1454/3290, eval_loss: 0.4937, eval_acc: 0.8676:  44%|[32m████▍     [0m| 1455/3290 [08:57<11:08,  2.74it/s][A
step: 1455/3290, eval_loss: 0.4935, eval_acc: 0.8676:  44%|[32m████▍     [0m| 1455/3290 [08:57<11:08,  2.74it/s][A[2025-02-04 03:22:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1455/3290, eval_loss: 0.4935, eval_acc: 0.8676:  44%|[32m████▍     [0m| 1456/3290 [08:57<11:13,  2.72it/s][A
step: 1456/3290, eval_loss: 0.4932, eval_acc: 0.8677:  44%|[32m████▍     [0m| 1456/3290 [08:57<11:13,  2.72it/s][A[2025-02-04 03:22:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1456/3290, eval_loss: 0.4932, eval_acc: 0.8677:  44%|[32m████▍     [0m| 1457/3290 [08:57<11:17,  2.70it/s][A
step: 1457/3290, eval_loss: 0.4930, eval_acc: 0.8678:  44%|[32m████▍     [0m| 1457/3290 [08:57<11:17,  2.70it/s][A[2025-02-04 03:22:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1457/3290, eval_loss: 0.4930, eval_acc: 0.8678:  44%|[32m████▍     [0m| 1458/3290 [08:58<11:22,  2.68it/s][A
step: 1458/3290, eval_loss: 0.4929, eval_acc: 0.8678:  44%|[32m████▍     [0m| 1458/3290 [08:58<11:22,  2.68it/s][A[2025-02-04 03:22:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1458/3290, eval_loss: 0.4929, eval_acc: 0.8678:  44%|[32m████▍     [0m| 1459/3290 [08:58<12:25,  2.46it/s][A
step: 1459/3290, eval_loss: 0.4928, eval_acc: 0.8679:  44%|[32m████▍     [0m| 1459/3290 [08:58<12:25,  2.46it/s][A[2025-02-04 03:22:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1459/3290, eval_loss: 0.4928, eval_acc: 0.8679:  44%|[32m████▍     [0m| 1460/3290 [08:59<13:17,  2.29it/s][A
step: 1460/3290, eval_loss: 0.4926, eval_acc: 0.8679:  44%|[32m████▍     [0m| 1460/3290 [08:59<13:17,  2.29it/s][A[2025-02-04 03:22:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1460/3290, eval_loss: 0.4926, eval_acc: 0.8679:  44%|[32m████▍     [0m| 1461/3290 [08:59<13:13,  2.31it/s][A
step: 1461/3290, eval_loss: 0.4925, eval_acc: 0.8679:  44%|[32m████▍     [0m| 1461/3290 [08:59<13:13,  2.31it/s][A[2025-02-04 03:22:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1461/3290, eval_loss: 0.4925, eval_acc: 0.8679:  44%|[32m████▍     [0m| 1462/3290 [09:00<12:03,  2.53it/s][A
step: 1462/3290, eval_loss: 0.4922, eval_acc: 0.8680:  44%|[32m████▍     [0m| 1462/3290 [09:00<12:03,  2.53it/s][A[2025-02-04 03:22:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1462/3290, eval_loss: 0.4922, eval_acc: 0.8680:  44%|[32m████▍     [0m| 1463/3290 [09:00<11:47,  2.58it/s][A
step: 1463/3290, eval_loss: 0.4923, eval_acc: 0.8680:  44%|[32m████▍     [0m| 1463/3290 [09:00<11:47,  2.58it/s][A[2025-02-04 03:22:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1463/3290, eval_loss: 0.4923, eval_acc: 0.8680:  44%|[32m████▍     [0m| 1464/3290 [09:00<12:15,  2.48it/s][A
step: 1464/3290, eval_loss: 0.4924, eval_acc: 0.8680:  44%|[32m████▍     [0m| 1464/3290 [09:00<12:15,  2.48it/s][A[2025-02-04 03:22:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1464/3290, eval_loss: 0.4924, eval_acc: 0.8680:  45%|[32m████▍     [0m| 1465/3290 [09:01<12:14,  2.48it/s][A
step: 1465/3290, eval_loss: 0.4922, eval_acc: 0.8680:  45%|[32m████▍     [0m| 1465/3290 [09:01<12:14,  2.48it/s][A[2025-02-04 03:22:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1465/3290, eval_loss: 0.4922, eval_acc: 0.8680:  45%|[32m████▍     [0m| 1466/3290 [09:01<12:13,  2.49it/s][A
step: 1466/3290, eval_loss: 0.4919, eval_acc: 0.8681:  45%|[32m████▍     [0m| 1466/3290 [09:01<12:13,  2.49it/s][A[2025-02-04 03:22:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1466/3290, eval_loss: 0.4919, eval_acc: 0.8681:  45%|[32m████▍     [0m| 1467/3290 [09:02<13:02,  2.33it/s][A
step: 1467/3290, eval_loss: 0.4919, eval_acc: 0.8681:  45%|[32m████▍     [0m| 1467/3290 [09:02<13:02,  2.33it/s][A[2025-02-04 03:22:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1467/3290, eval_loss: 0.4919, eval_acc: 0.8681:  45%|[32m████▍     [0m| 1468/3290 [09:02<13:20,  2.28it/s][A
step: 1468/3290, eval_loss: 0.4916, eval_acc: 0.8682:  45%|[32m████▍     [0m| 1468/3290 [09:02<13:20,  2.28it/s][A[2025-02-04 03:22:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1468/3290, eval_loss: 0.4916, eval_acc: 0.8682:  45%|[32m████▍     [0m| 1469/3290 [09:03<13:26,  2.26it/s][A
step: 1469/3290, eval_loss: 0.4915, eval_acc: 0.8683:  45%|[32m████▍     [0m| 1469/3290 [09:03<13:26,  2.26it/s][A[2025-02-04 03:22:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1469/3290, eval_loss: 0.4915, eval_acc: 0.8683:  45%|[32m████▍     [0m| 1470/3290 [09:03<13:11,  2.30it/s][A
step: 1470/3290, eval_loss: 0.4913, eval_acc: 0.8683:  45%|[32m████▍     [0m| 1470/3290 [09:03<13:11,  2.30it/s][A[2025-02-04 03:22:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1470/3290, eval_loss: 0.4913, eval_acc: 0.8683:  45%|[32m████▍     [0m| 1471/3290 [09:03<13:03,  2.32it/s][A
step: 1471/3290, eval_loss: 0.4911, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1471/3290 [09:03<13:03,  2.32it/s][A[2025-02-04 03:22:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1471/3290, eval_loss: 0.4911, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1472/3290 [09:04<12:54,  2.35it/s][A
step: 1472/3290, eval_loss: 0.4910, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1472/3290 [09:04<12:54,  2.35it/s][A[2025-02-04 03:22:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1472/3290, eval_loss: 0.4910, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1473/3290 [09:04<12:08,  2.49it/s][A
step: 1473/3290, eval_loss: 0.4910, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1473/3290 [09:04<12:08,  2.49it/s][A[2025-02-04 03:22:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1473/3290, eval_loss: 0.4910, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1474/3290 [09:05<11:46,  2.57it/s][A
step: 1474/3290, eval_loss: 0.4908, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1474/3290 [09:05<11:46,  2.57it/s][A[2025-02-04 03:22:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1474/3290, eval_loss: 0.4908, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1475/3290 [09:05<12:22,  2.44it/s][A
step: 1475/3290, eval_loss: 0.4907, eval_acc: 0.8685:  45%|[32m████▍     [0m| 1475/3290 [09:05<12:22,  2.44it/s][A[2025-02-04 03:22:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1475/3290, eval_loss: 0.4907, eval_acc: 0.8685:  45%|[32m████▍     [0m| 1476/3290 [09:05<12:01,  2.52it/s][A
step: 1476/3290, eval_loss: 0.4910, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1476/3290 [09:05<12:01,  2.52it/s][A[2025-02-04 03:23:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1476/3290, eval_loss: 0.4910, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1477/3290 [09:06<13:47,  2.19it/s][A
step: 1477/3290, eval_loss: 0.4911, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1477/3290 [09:06<13:47,  2.19it/s][A[2025-02-04 03:23:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1477/3290, eval_loss: 0.4911, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1478/3290 [09:06<13:33,  2.23it/s][A
step: 1478/3290, eval_loss: 0.4912, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1478/3290 [09:06<13:33,  2.23it/s][A[2025-02-04 03:23:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1478/3290, eval_loss: 0.4912, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1479/3290 [09:07<13:48,  2.19it/s][A
step: 1479/3290, eval_loss: 0.4911, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1479/3290 [09:07<13:48,  2.19it/s][A[2025-02-04 03:23:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1479/3290, eval_loss: 0.4911, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1480/3290 [09:07<13:45,  2.19it/s][A
step: 1480/3290, eval_loss: 0.4911, eval_acc: 0.8684:  45%|[32m████▍     [0m| 1480/3290 [09:07<13:45,  2.19it/s][A[2025-02-04 03:23:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1480/3290, eval_loss: 0.4911, eval_acc: 0.8684:  45%|[32m████▌     [0m| 1481/3290 [09:08<13:04,  2.31it/s][A
step: 1481/3290, eval_loss: 0.4910, eval_acc: 0.8684:  45%|[32m████▌     [0m| 1481/3290 [09:08<13:04,  2.31it/s][A[2025-02-04 03:23:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1481/3290, eval_loss: 0.4910, eval_acc: 0.8684:  45%|[32m████▌     [0m| 1482/3290 [09:08<12:17,  2.45it/s][A
step: 1482/3290, eval_loss: 0.4910, eval_acc: 0.8684:  45%|[32m████▌     [0m| 1482/3290 [09:08<12:17,  2.45it/s][A[2025-02-04 03:23:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1482/3290, eval_loss: 0.4910, eval_acc: 0.8684:  45%|[32m████▌     [0m| 1483/3290 [09:09<13:35,  2.22it/s][A
step: 1483/3290, eval_loss: 0.4908, eval_acc: 0.8685:  45%|[32m████▌     [0m| 1483/3290 [09:09<13:35,  2.22it/s][A[2025-02-04 03:23:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1483/3290, eval_loss: 0.4908, eval_acc: 0.8685:  45%|[32m████▌     [0m| 1484/3290 [09:09<12:45,  2.36it/s][A
step: 1484/3290, eval_loss: 0.4906, eval_acc: 0.8685:  45%|[32m████▌     [0m| 1484/3290 [09:09<12:45,  2.36it/s][A[2025-02-04 03:23:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1484/3290, eval_loss: 0.4906, eval_acc: 0.8685:  45%|[32m████▌     [0m| 1485/3290 [09:09<13:12,  2.28it/s][A
step: 1485/3290, eval_loss: 0.4906, eval_acc: 0.8685:  45%|[32m████▌     [0m| 1485/3290 [09:09<13:12,  2.28it/s][A[2025-02-04 03:23:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1485/3290, eval_loss: 0.4906, eval_acc: 0.8685:  45%|[32m████▌     [0m| 1486/3290 [09:10<13:59,  2.15it/s][A
step: 1486/3290, eval_loss: 0.4905, eval_acc: 0.8685:  45%|[32m████▌     [0m| 1486/3290 [09:10<13:59,  2.15it/s][A[2025-02-04 03:23:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1486/3290, eval_loss: 0.4905, eval_acc: 0.8685:  45%|[32m████▌     [0m| 1487/3290 [09:10<13:28,  2.23it/s][A
step: 1487/3290, eval_loss: 0.4903, eval_acc: 0.8686:  45%|[32m████▌     [0m| 1487/3290 [09:10<13:28,  2.23it/s][A[2025-02-04 03:23:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1487/3290, eval_loss: 0.4903, eval_acc: 0.8686:  45%|[32m████▌     [0m| 1488/3290 [09:11<13:39,  2.20it/s][A
step: 1488/3290, eval_loss: 0.4902, eval_acc: 0.8686:  45%|[32m████▌     [0m| 1488/3290 [09:11<13:39,  2.20it/s][A[2025-02-04 03:23:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1488/3290, eval_loss: 0.4902, eval_acc: 0.8686:  45%|[32m████▌     [0m| 1489/3290 [09:11<13:28,  2.23it/s][A
step: 1489/3290, eval_loss: 0.4900, eval_acc: 0.8686:  45%|[32m████▌     [0m| 1489/3290 [09:11<13:28,  2.23it/s][A[2025-02-04 03:23:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1489/3290, eval_loss: 0.4900, eval_acc: 0.8686:  45%|[32m████▌     [0m| 1490/3290 [09:12<13:16,  2.26it/s][A
step: 1490/3290, eval_loss: 0.4900, eval_acc: 0.8686:  45%|[32m████▌     [0m| 1490/3290 [09:12<13:16,  2.26it/s][A[2025-02-04 03:23:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1490/3290, eval_loss: 0.4900, eval_acc: 0.8686:  45%|[32m████▌     [0m| 1491/3290 [09:12<12:46,  2.35it/s][A
step: 1491/3290, eval_loss: 0.4900, eval_acc: 0.8686:  45%|[32m████▌     [0m| 1491/3290 [09:12<12:46,  2.35it/s][A[2025-02-04 03:23:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1491/3290, eval_loss: 0.4900, eval_acc: 0.8686:  45%|[32m████▌     [0m| 1492/3290 [09:12<11:46,  2.55it/s][A
step: 1492/3290, eval_loss: 0.4898, eval_acc: 0.8687:  45%|[32m████▌     [0m| 1492/3290 [09:12<11:46,  2.55it/s][A[2025-02-04 03:23:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1492/3290, eval_loss: 0.4898, eval_acc: 0.8687:  45%|[32m████▌     [0m| 1493/3290 [09:13<11:42,  2.56it/s][A
step: 1493/3290, eval_loss: 0.4896, eval_acc: 0.8687:  45%|[32m████▌     [0m| 1493/3290 [09:13<11:42,  2.56it/s][A[2025-02-04 03:23:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1493/3290, eval_loss: 0.4896, eval_acc: 0.8687:  45%|[32m████▌     [0m| 1494/3290 [09:13<11:46,  2.54it/s][A
step: 1494/3290, eval_loss: 0.4897, eval_acc: 0.8687:  45%|[32m████▌     [0m| 1494/3290 [09:13<11:46,  2.54it/s][A[2025-02-04 03:23:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1494/3290, eval_loss: 0.4897, eval_acc: 0.8687:  45%|[32m████▌     [0m| 1495/3290 [09:14<11:48,  2.53it/s][A
step: 1495/3290, eval_loss: 0.4895, eval_acc: 0.8688:  45%|[32m████▌     [0m| 1495/3290 [09:14<11:48,  2.53it/s][A[2025-02-04 03:23:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1495/3290, eval_loss: 0.4895, eval_acc: 0.8688:  45%|[32m████▌     [0m| 1496/3290 [09:14<11:55,  2.51it/s][A
step: 1496/3290, eval_loss: 0.4894, eval_acc: 0.8688:  45%|[32m████▌     [0m| 1496/3290 [09:14<11:55,  2.51it/s][A[2025-02-04 03:23:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1496/3290, eval_loss: 0.4894, eval_acc: 0.8688:  46%|[32m████▌     [0m| 1497/3290 [09:14<11:42,  2.55it/s][A
step: 1497/3290, eval_loss: 0.4892, eval_acc: 0.8688:  46%|[32m████▌     [0m| 1497/3290 [09:14<11:42,  2.55it/s][A[2025-02-04 03:23:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1497/3290, eval_loss: 0.4892, eval_acc: 0.8688:  46%|[32m████▌     [0m| 1498/3290 [09:15<11:45,  2.54it/s][A
step: 1498/3290, eval_loss: 0.4891, eval_acc: 0.8689:  46%|[32m████▌     [0m| 1498/3290 [09:15<11:45,  2.54it/s][A[2025-02-04 03:23:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1498/3290, eval_loss: 0.4891, eval_acc: 0.8689:  46%|[32m████▌     [0m| 1499/3290 [09:15<11:17,  2.64it/s][A
step: 1499/3290, eval_loss: 0.4892, eval_acc: 0.8689:  46%|[32m████▌     [0m| 1499/3290 [09:15<11:17,  2.64it/s][A[2025-02-04 03:23:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1499/3290, eval_loss: 0.4892, eval_acc: 0.8689:  46%|[32m████▌     [0m| 1500/3290 [09:16<13:08,  2.27it/s][A
step: 1500/3290, eval_loss: 0.4890, eval_acc: 0.8689:  46%|[32m████▌     [0m| 1500/3290 [09:16<13:08,  2.27it/s][A[2025-02-04 03:23:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1500/3290, eval_loss: 0.4890, eval_acc: 0.8689:  46%|[32m████▌     [0m| 1501/3290 [09:16<12:13,  2.44it/s][A
step: 1501/3290, eval_loss: 0.4889, eval_acc: 0.8689:  46%|[32m████▌     [0m| 1501/3290 [09:16<12:13,  2.44it/s][A[2025-02-04 03:23:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1501/3290, eval_loss: 0.4889, eval_acc: 0.8689:  46%|[32m████▌     [0m| 1502/3290 [09:16<11:31,  2.59it/s][A
step: 1502/3290, eval_loss: 0.4888, eval_acc: 0.8690:  46%|[32m████▌     [0m| 1502/3290 [09:16<11:31,  2.59it/s][A[2025-02-04 03:23:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1502/3290, eval_loss: 0.4888, eval_acc: 0.8690:  46%|[32m████▌     [0m| 1503/3290 [09:17<10:44,  2.77it/s][A
step: 1503/3290, eval_loss: 0.4886, eval_acc: 0.8690:  46%|[32m████▌     [0m| 1503/3290 [09:17<10:44,  2.77it/s][A[2025-02-04 03:23:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1503/3290, eval_loss: 0.4886, eval_acc: 0.8690:  46%|[32m████▌     [0m| 1504/3290 [09:17<10:13,  2.91it/s][A
step: 1504/3290, eval_loss: 0.4886, eval_acc: 0.8690:  46%|[32m████▌     [0m| 1504/3290 [09:17<10:13,  2.91it/s][A[2025-02-04 03:23:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1504/3290, eval_loss: 0.4886, eval_acc: 0.8690:  46%|[32m████▌     [0m| 1505/3290 [09:17<09:55,  3.00it/s][A
step: 1505/3290, eval_loss: 0.4885, eval_acc: 0.8691:  46%|[32m████▌     [0m| 1505/3290 [09:17<09:55,  3.00it/s][A[2025-02-04 03:23:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1505/3290, eval_loss: 0.4885, eval_acc: 0.8691:  46%|[32m████▌     [0m| 1506/3290 [09:18<10:37,  2.80it/s][A
step: 1506/3290, eval_loss: 0.4885, eval_acc: 0.8690:  46%|[32m████▌     [0m| 1506/3290 [09:18<10:37,  2.80it/s][A[2025-02-04 03:23:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1506/3290, eval_loss: 0.4885, eval_acc: 0.8690:  46%|[32m████▌     [0m| 1507/3290 [09:18<10:43,  2.77it/s][A
step: 1507/3290, eval_loss: 0.4884, eval_acc: 0.8691:  46%|[32m████▌     [0m| 1507/3290 [09:18<10:43,  2.77it/s][A[2025-02-04 03:23:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1507/3290, eval_loss: 0.4884, eval_acc: 0.8691:  46%|[32m████▌     [0m| 1508/3290 [09:18<10:20,  2.87it/s][A
step: 1508/3290, eval_loss: 0.4885, eval_acc: 0.8691:  46%|[32m████▌     [0m| 1508/3290 [09:18<10:20,  2.87it/s][A[2025-02-04 03:23:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1508/3290, eval_loss: 0.4885, eval_acc: 0.8691:  46%|[32m████▌     [0m| 1509/3290 [09:19<10:34,  2.81it/s][A
step: 1509/3290, eval_loss: 0.4886, eval_acc: 0.8691:  46%|[32m████▌     [0m| 1509/3290 [09:19<10:34,  2.81it/s][A[2025-02-04 03:23:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1509/3290, eval_loss: 0.4886, eval_acc: 0.8691:  46%|[32m████▌     [0m| 1510/3290 [09:19<09:58,  2.98it/s][A
step: 1510/3290, eval_loss: 0.4884, eval_acc: 0.8691:  46%|[32m████▌     [0m| 1510/3290 [09:19<09:58,  2.98it/s][A[2025-02-04 03:23:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1510/3290, eval_loss: 0.4884, eval_acc: 0.8691:  46%|[32m████▌     [0m| 1511/3290 [09:19<10:26,  2.84it/s][A
step: 1511/3290, eval_loss: 0.4882, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1511/3290 [09:19<10:26,  2.84it/s][A[2025-02-04 03:23:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1511/3290, eval_loss: 0.4882, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1512/3290 [09:20<10:20,  2.87it/s][A
step: 1512/3290, eval_loss: 0.4879, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1512/3290 [09:20<10:20,  2.87it/s][A[2025-02-04 03:23:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1512/3290, eval_loss: 0.4879, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1513/3290 [09:20<10:45,  2.75it/s][A
step: 1513/3290, eval_loss: 0.4879, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1513/3290 [09:20<10:45,  2.75it/s][A[2025-02-04 03:23:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1513/3290, eval_loss: 0.4879, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1514/3290 [09:21<10:51,  2.73it/s][A
step: 1514/3290, eval_loss: 0.4880, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1514/3290 [09:21<10:51,  2.73it/s][A[2025-02-04 03:23:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1514/3290, eval_loss: 0.4880, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1515/3290 [09:21<12:36,  2.35it/s][A
step: 1515/3290, eval_loss: 0.4881, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1515/3290 [09:21<12:36,  2.35it/s][A[2025-02-04 03:23:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1515/3290, eval_loss: 0.4881, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1516/3290 [09:22<12:28,  2.37it/s][A
step: 1516/3290, eval_loss: 0.4879, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1516/3290 [09:22<12:28,  2.37it/s][A[2025-02-04 03:23:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1516/3290, eval_loss: 0.4879, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1517/3290 [09:22<13:08,  2.25it/s][A
step: 1517/3290, eval_loss: 0.4878, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1517/3290 [09:22<13:08,  2.25it/s][A[2025-02-04 03:23:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1517/3290, eval_loss: 0.4878, eval_acc: 0.8692:  46%|[32m████▌     [0m| 1518/3290 [09:23<13:07,  2.25it/s][A
step: 1518/3290, eval_loss: 0.4876, eval_acc: 0.8693:  46%|[32m████▌     [0m| 1518/3290 [09:23<13:07,  2.25it/s][A[2025-02-04 03:23:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1518/3290, eval_loss: 0.4876, eval_acc: 0.8693:  46%|[32m████▌     [0m| 1519/3290 [09:23<12:55,  2.28it/s][A
step: 1519/3290, eval_loss: 0.4875, eval_acc: 0.8693:  46%|[32m████▌     [0m| 1519/3290 [09:23<12:55,  2.28it/s][A[2025-02-04 03:23:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1519/3290, eval_loss: 0.4875, eval_acc: 0.8693:  46%|[32m████▌     [0m| 1520/3290 [09:23<12:27,  2.37it/s][A
step: 1520/3290, eval_loss: 0.4874, eval_acc: 0.8694:  46%|[32m████▌     [0m| 1520/3290 [09:23<12:27,  2.37it/s][A[2025-02-04 03:23:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1520/3290, eval_loss: 0.4874, eval_acc: 0.8694:  46%|[32m████▌     [0m| 1521/3290 [09:24<11:59,  2.46it/s][A
step: 1521/3290, eval_loss: 0.4872, eval_acc: 0.8694:  46%|[32m████▌     [0m| 1521/3290 [09:24<11:59,  2.46it/s][A[2025-02-04 03:23:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1521/3290, eval_loss: 0.4872, eval_acc: 0.8694:  46%|[32m████▋     [0m| 1522/3290 [09:24<12:39,  2.33it/s][A
step: 1522/3290, eval_loss: 0.4871, eval_acc: 0.8695:  46%|[32m████▋     [0m| 1522/3290 [09:24<12:39,  2.33it/s][A[2025-02-04 03:23:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1522/3290, eval_loss: 0.4871, eval_acc: 0.8695:  46%|[32m████▋     [0m| 1523/3290 [09:25<15:07,  1.95it/s][A
step: 1523/3290, eval_loss: 0.4870, eval_acc: 0.8695:  46%|[32m████▋     [0m| 1523/3290 [09:25<15:07,  1.95it/s][A[2025-02-04 03:23:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1523/3290, eval_loss: 0.4870, eval_acc: 0.8695:  46%|[32m████▋     [0m| 1524/3290 [09:25<14:23,  2.05it/s][A
step: 1524/3290, eval_loss: 0.4869, eval_acc: 0.8695:  46%|[32m████▋     [0m| 1524/3290 [09:25<14:23,  2.05it/s][A[2025-02-04 03:23:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1524/3290, eval_loss: 0.4869, eval_acc: 0.8695:  46%|[32m████▋     [0m| 1525/3290 [09:26<13:31,  2.18it/s][A
step: 1525/3290, eval_loss: 0.4870, eval_acc: 0.8695:  46%|[32m████▋     [0m| 1525/3290 [09:26<13:31,  2.18it/s][A[2025-02-04 03:23:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1525/3290, eval_loss: 0.4870, eval_acc: 0.8695:  46%|[32m████▋     [0m| 1526/3290 [09:26<12:15,  2.40it/s][A
step: 1526/3290, eval_loss: 0.4870, eval_acc: 0.8695:  46%|[32m████▋     [0m| 1526/3290 [09:26<12:15,  2.40it/s][A[2025-02-04 03:23:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1526/3290, eval_loss: 0.4870, eval_acc: 0.8695:  46%|[32m████▋     [0m| 1527/3290 [09:27<13:37,  2.16it/s][A
step: 1527/3290, eval_loss: 0.4869, eval_acc: 0.8695:  46%|[32m████▋     [0m| 1527/3290 [09:27<13:37,  2.16it/s][A[2025-02-04 03:23:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1527/3290, eval_loss: 0.4869, eval_acc: 0.8695:  46%|[32m████▋     [0m| 1528/3290 [09:27<14:05,  2.08it/s][A
step: 1528/3290, eval_loss: 0.4868, eval_acc: 0.8696:  46%|[32m████▋     [0m| 1528/3290 [09:27<14:05,  2.08it/s][A[2025-02-04 03:23:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1528/3290, eval_loss: 0.4868, eval_acc: 0.8696:  46%|[32m████▋     [0m| 1529/3290 [09:28<14:00,  2.09it/s][A
step: 1529/3290, eval_loss: 0.4867, eval_acc: 0.8696:  46%|[32m████▋     [0m| 1529/3290 [09:28<14:00,  2.09it/s][A[2025-02-04 03:23:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1529/3290, eval_loss: 0.4867, eval_acc: 0.8696:  47%|[32m████▋     [0m| 1530/3290 [09:28<14:14,  2.06it/s][A
step: 1530/3290, eval_loss: 0.4867, eval_acc: 0.8696:  47%|[32m████▋     [0m| 1530/3290 [09:28<14:14,  2.06it/s][A[2025-02-04 03:23:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1530/3290, eval_loss: 0.4867, eval_acc: 0.8696:  47%|[32m████▋     [0m| 1531/3290 [09:28<13:11,  2.22it/s][A
step: 1531/3290, eval_loss: 0.4868, eval_acc: 0.8696:  47%|[32m████▋     [0m| 1531/3290 [09:28<13:11,  2.22it/s][A[2025-02-04 03:23:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1531/3290, eval_loss: 0.4868, eval_acc: 0.8696:  47%|[32m████▋     [0m| 1532/3290 [09:29<12:10,  2.41it/s][A
step: 1532/3290, eval_loss: 0.4867, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1532/3290 [09:29<12:10,  2.41it/s][A[2025-02-04 03:23:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1532/3290, eval_loss: 0.4867, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1533/3290 [09:29<12:17,  2.38it/s][A
step: 1533/3290, eval_loss: 0.4866, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1533/3290 [09:29<12:17,  2.38it/s][A[2025-02-04 03:23:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1533/3290, eval_loss: 0.4866, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1534/3290 [09:30<11:38,  2.51it/s][A
step: 1534/3290, eval_loss: 0.4867, eval_acc: 0.8696:  47%|[32m████▋     [0m| 1534/3290 [09:30<11:38,  2.51it/s][A[2025-02-04 03:23:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1534/3290, eval_loss: 0.4867, eval_acc: 0.8696:  47%|[32m████▋     [0m| 1535/3290 [09:30<11:25,  2.56it/s][A
step: 1535/3290, eval_loss: 0.4867, eval_acc: 0.8696:  47%|[32m████▋     [0m| 1535/3290 [09:30<11:25,  2.56it/s][A[2025-02-04 03:23:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1535/3290, eval_loss: 0.4867, eval_acc: 0.8696:  47%|[32m████▋     [0m| 1536/3290 [09:30<11:00,  2.66it/s][A
step: 1536/3290, eval_loss: 0.4865, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1536/3290 [09:30<11:00,  2.66it/s][A[2025-02-04 03:23:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1536/3290, eval_loss: 0.4865, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1537/3290 [09:31<11:20,  2.57it/s][A
step: 1537/3290, eval_loss: 0.4864, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1537/3290 [09:31<11:20,  2.57it/s][A[2025-02-04 03:23:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1537/3290, eval_loss: 0.4864, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1538/3290 [09:31<10:32,  2.77it/s][A
step: 1538/3290, eval_loss: 0.4862, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1538/3290 [09:31<10:32,  2.77it/s][A[2025-02-04 03:23:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1538/3290, eval_loss: 0.4862, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1539/3290 [09:31<11:42,  2.49it/s][A
step: 1539/3290, eval_loss: 0.4861, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1539/3290 [09:31<11:42,  2.49it/s][A[2025-02-04 03:23:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1539/3290, eval_loss: 0.4861, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1540/3290 [09:32<11:41,  2.50it/s][A
step: 1540/3290, eval_loss: 0.4862, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1540/3290 [09:32<11:41,  2.50it/s][A[2025-02-04 03:23:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1540/3290, eval_loss: 0.4862, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1541/3290 [09:32<11:41,  2.49it/s][A
step: 1541/3290, eval_loss: 0.4861, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1541/3290 [09:32<11:41,  2.49it/s][A[2025-02-04 03:23:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1541/3290, eval_loss: 0.4861, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1542/3290 [09:33<11:32,  2.53it/s][A
step: 1542/3290, eval_loss: 0.4861, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1542/3290 [09:33<11:32,  2.53it/s][A[2025-02-04 03:23:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1542/3290, eval_loss: 0.4861, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1543/3290 [09:33<10:53,  2.67it/s][A
step: 1543/3290, eval_loss: 0.4863, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1543/3290 [09:33<10:53,  2.67it/s][A[2025-02-04 03:23:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1543/3290, eval_loss: 0.4863, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1544/3290 [09:33<10:33,  2.75it/s][A
step: 1544/3290, eval_loss: 0.4864, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1544/3290 [09:33<10:33,  2.75it/s][A[2025-02-04 03:23:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1544/3290, eval_loss: 0.4864, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1545/3290 [09:34<10:36,  2.74it/s][A
step: 1545/3290, eval_loss: 0.4865, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1545/3290 [09:34<10:36,  2.74it/s][A[2025-02-04 03:23:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1545/3290, eval_loss: 0.4865, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1546/3290 [09:34<11:15,  2.58it/s][A
step: 1546/3290, eval_loss: 0.4868, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1546/3290 [09:34<11:15,  2.58it/s][A[2025-02-04 03:23:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1546/3290, eval_loss: 0.4868, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1547/3290 [09:35<11:56,  2.43it/s][A
step: 1547/3290, eval_loss: 0.4869, eval_acc: 0.8696:  47%|[32m████▋     [0m| 1547/3290 [09:35<11:56,  2.43it/s][A[2025-02-04 03:23:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1547/3290, eval_loss: 0.4869, eval_acc: 0.8696:  47%|[32m████▋     [0m| 1548/3290 [09:35<10:47,  2.69it/s][A
step: 1548/3290, eval_loss: 0.4868, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1548/3290 [09:35<10:47,  2.69it/s][A[2025-02-04 03:23:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1548/3290, eval_loss: 0.4868, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1549/3290 [09:35<12:20,  2.35it/s][A
step: 1549/3290, eval_loss: 0.4867, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1549/3290 [09:35<12:20,  2.35it/s][A[2025-02-04 03:23:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1549/3290, eval_loss: 0.4867, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1550/3290 [09:36<12:21,  2.35it/s][A
step: 1550/3290, eval_loss: 0.4866, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1550/3290 [09:36<12:21,  2.35it/s][A[2025-02-04 03:23:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1550/3290, eval_loss: 0.4866, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1551/3290 [09:36<12:05,  2.40it/s][A
step: 1551/3290, eval_loss: 0.4867, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1551/3290 [09:36<12:05,  2.40it/s][A[2025-02-04 03:23:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1551/3290, eval_loss: 0.4867, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1552/3290 [09:37<13:01,  2.22it/s][A
step: 1552/3290, eval_loss: 0.4866, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1552/3290 [09:37<13:01,  2.22it/s][A[2025-02-04 03:23:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1552/3290, eval_loss: 0.4866, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1553/3290 [09:37<12:38,  2.29it/s][A
step: 1553/3290, eval_loss: 0.4867, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1553/3290 [09:37<12:38,  2.29it/s][A[2025-02-04 03:23:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1553/3290, eval_loss: 0.4867, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1554/3290 [09:38<12:21,  2.34it/s][A
step: 1554/3290, eval_loss: 0.4866, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1554/3290 [09:38<12:21,  2.34it/s][A[2025-02-04 03:23:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1554/3290, eval_loss: 0.4866, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1555/3290 [09:38<11:58,  2.41it/s][A
step: 1555/3290, eval_loss: 0.4867, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1555/3290 [09:38<11:58,  2.41it/s][A[2025-02-04 03:23:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1555/3290, eval_loss: 0.4867, eval_acc: 0.8698:  47%|[32m████▋     [0m| 1556/3290 [09:38<12:46,  2.26it/s][A
step: 1556/3290, eval_loss: 0.4867, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1556/3290 [09:38<12:46,  2.26it/s][A[2025-02-04 03:23:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1556/3290, eval_loss: 0.4867, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1557/3290 [09:39<11:57,  2.42it/s][A
step: 1557/3290, eval_loss: 0.4866, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1557/3290 [09:39<11:57,  2.42it/s][A[2025-02-04 03:23:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1557/3290, eval_loss: 0.4866, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1558/3290 [09:39<11:20,  2.55it/s][A
step: 1558/3290, eval_loss: 0.4866, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1558/3290 [09:39<11:20,  2.55it/s][A[2025-02-04 03:23:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1558/3290, eval_loss: 0.4866, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1559/3290 [09:40<10:54,  2.65it/s][A
step: 1559/3290, eval_loss: 0.4865, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1559/3290 [09:40<10:54,  2.65it/s][A[2025-02-04 03:23:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1559/3290, eval_loss: 0.4865, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1560/3290 [09:40<10:13,  2.82it/s][A
step: 1560/3290, eval_loss: 0.4868, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1560/3290 [09:40<10:13,  2.82it/s][A[2025-02-04 03:23:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1560/3290, eval_loss: 0.4868, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1561/3290 [09:40<10:09,  2.84it/s][A
step: 1561/3290, eval_loss: 0.4867, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1561/3290 [09:40<10:09,  2.84it/s][A[2025-02-04 03:23:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1561/3290, eval_loss: 0.4867, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1562/3290 [09:40<09:51,  2.92it/s][A
step: 1562/3290, eval_loss: 0.4866, eval_acc: 0.8697:  47%|[32m████▋     [0m| 1562/3290 [09:40<09:51,  2.92it/s][A[2025-02-04 03:23:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1562/3290, eval_loss: 0.4866, eval_acc: 0.8697:  48%|[32m████▊     [0m| 1563/3290 [09:41<10:53,  2.64it/s][A
step: 1563/3290, eval_loss: 0.4865, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1563/3290 [09:41<10:53,  2.64it/s][A[2025-02-04 03:23:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1563/3290, eval_loss: 0.4865, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1564/3290 [09:41<10:50,  2.65it/s][A
step: 1564/3290, eval_loss: 0.4862, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1564/3290 [09:41<10:50,  2.65it/s][A[2025-02-04 03:23:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1564/3290, eval_loss: 0.4862, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1565/3290 [09:42<09:59,  2.88it/s][A
step: 1565/3290, eval_loss: 0.4862, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1565/3290 [09:42<09:59,  2.88it/s][A[2025-02-04 03:23:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1565/3290, eval_loss: 0.4862, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1566/3290 [09:42<09:30,  3.02it/s][A
step: 1566/3290, eval_loss: 0.4863, eval_acc: 0.8697:  48%|[32m████▊     [0m| 1566/3290 [09:42<09:30,  3.02it/s][A[2025-02-04 03:23:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1566/3290, eval_loss: 0.4863, eval_acc: 0.8697:  48%|[32m████▊     [0m| 1567/3290 [09:42<09:04,  3.16it/s][A
step: 1567/3290, eval_loss: 0.4861, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1567/3290 [09:42<09:04,  3.16it/s][A[2025-02-04 03:23:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1567/3290, eval_loss: 0.4861, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1568/3290 [09:42<08:54,  3.22it/s][A
step: 1568/3290, eval_loss: 0.4861, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1568/3290 [09:42<08:54,  3.22it/s][A[2025-02-04 03:23:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1568/3290, eval_loss: 0.4861, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1569/3290 [09:43<09:36,  2.99it/s][A
step: 1569/3290, eval_loss: 0.4859, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1569/3290 [09:43<09:36,  2.99it/s][A[2025-02-04 03:23:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1569/3290, eval_loss: 0.4859, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1570/3290 [09:43<09:33,  3.00it/s][A
step: 1570/3290, eval_loss: 0.4858, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1570/3290 [09:43<09:33,  3.00it/s][A[2025-02-04 03:23:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1570/3290, eval_loss: 0.4858, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1571/3290 [09:44<09:17,  3.08it/s][A
step: 1571/3290, eval_loss: 0.4858, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1571/3290 [09:44<09:17,  3.08it/s][A[2025-02-04 03:23:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1571/3290, eval_loss: 0.4858, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1572/3290 [09:44<10:18,  2.78it/s][A
step: 1572/3290, eval_loss: 0.4858, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1572/3290 [09:44<10:18,  2.78it/s][A[2025-02-04 03:23:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1572/3290, eval_loss: 0.4858, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1573/3290 [09:44<10:25,  2.75it/s][A
step: 1573/3290, eval_loss: 0.4857, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1573/3290 [09:44<10:25,  2.75it/s][A[2025-02-04 03:23:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1573/3290, eval_loss: 0.4857, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1574/3290 [09:45<10:43,  2.67it/s][A
step: 1574/3290, eval_loss: 0.4858, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1574/3290 [09:45<10:43,  2.67it/s][A[2025-02-04 03:23:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1574/3290, eval_loss: 0.4858, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1575/3290 [09:45<09:38,  2.96it/s][A
step: 1575/3290, eval_loss: 0.4858, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1575/3290 [09:45<09:38,  2.96it/s][A[2025-02-04 03:23:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1575/3290, eval_loss: 0.4858, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1576/3290 [09:45<10:18,  2.77it/s][A
step: 1576/3290, eval_loss: 0.4857, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1576/3290 [09:45<10:18,  2.77it/s][A[2025-02-04 03:23:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1576/3290, eval_loss: 0.4857, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1577/3290 [09:46<10:23,  2.75it/s][A
step: 1577/3290, eval_loss: 0.4856, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1577/3290 [09:46<10:23,  2.75it/s][A[2025-02-04 03:23:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1577/3290, eval_loss: 0.4856, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1578/3290 [09:46<10:53,  2.62it/s][A
step: 1578/3290, eval_loss: 0.4859, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1578/3290 [09:46<10:53,  2.62it/s][A[2025-02-04 03:23:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1578/3290, eval_loss: 0.4859, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1579/3290 [09:47<10:39,  2.67it/s][A
step: 1579/3290, eval_loss: 0.4858, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1579/3290 [09:47<10:39,  2.67it/s][A[2025-02-04 03:23:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1579/3290, eval_loss: 0.4858, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1580/3290 [09:47<11:00,  2.59it/s][A
step: 1580/3290, eval_loss: 0.4862, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1580/3290 [09:47<11:00,  2.59it/s][A[2025-02-04 03:23:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1580/3290, eval_loss: 0.4862, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1581/3290 [09:47<11:06,  2.57it/s][A
step: 1581/3290, eval_loss: 0.4863, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1581/3290 [09:47<11:06,  2.57it/s][A[2025-02-04 03:23:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1581/3290, eval_loss: 0.4863, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1582/3290 [09:48<11:35,  2.46it/s][A
step: 1582/3290, eval_loss: 0.4860, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1582/3290 [09:48<11:35,  2.46it/s][A[2025-02-04 03:23:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1582/3290, eval_loss: 0.4860, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1583/3290 [09:48<11:09,  2.55it/s][A
step: 1583/3290, eval_loss: 0.4860, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1583/3290 [09:48<11:09,  2.55it/s][A[2025-02-04 03:23:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1583/3290, eval_loss: 0.4860, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1584/3290 [09:49<10:54,  2.61it/s][A
step: 1584/3290, eval_loss: 0.4861, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1584/3290 [09:49<10:54,  2.61it/s][A[2025-02-04 03:23:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1584/3290, eval_loss: 0.4861, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1585/3290 [09:49<10:35,  2.68it/s][A
step: 1585/3290, eval_loss: 0.4859, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1585/3290 [09:49<10:35,  2.68it/s][A[2025-02-04 03:23:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1585/3290, eval_loss: 0.4859, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1586/3290 [09:49<09:55,  2.86it/s][A
step: 1586/3290, eval_loss: 0.4863, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1586/3290 [09:49<09:55,  2.86it/s][A[2025-02-04 03:23:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1586/3290, eval_loss: 0.4863, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1587/3290 [09:49<09:46,  2.90it/s][A
step: 1587/3290, eval_loss: 0.4862, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1587/3290 [09:49<09:46,  2.90it/s][A[2025-02-04 03:23:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1587/3290, eval_loss: 0.4862, eval_acc: 0.8698:  48%|[32m████▊     [0m| 1588/3290 [09:50<09:59,  2.84it/s][A
step: 1588/3290, eval_loss: 0.4860, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1588/3290 [09:50<09:59,  2.84it/s][A[2025-02-04 03:23:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1588/3290, eval_loss: 0.4860, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1589/3290 [09:50<11:05,  2.56it/s][A
step: 1589/3290, eval_loss: 0.4859, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1589/3290 [09:50<11:05,  2.56it/s][A[2025-02-04 03:23:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1589/3290, eval_loss: 0.4859, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1590/3290 [09:51<11:40,  2.43it/s][A
step: 1590/3290, eval_loss: 0.4857, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1590/3290 [09:51<11:40,  2.43it/s][A[2025-02-04 03:23:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1590/3290, eval_loss: 0.4857, eval_acc: 0.8699:  48%|[32m████▊     [0m| 1591/3290 [09:51<13:25,  2.11it/s][A
step: 1591/3290, eval_loss: 0.4855, eval_acc: 0.8700:  48%|[32m████▊     [0m| 1591/3290 [09:51<13:25,  2.11it/s][A[2025-02-04 03:23:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1591/3290, eval_loss: 0.4855, eval_acc: 0.8700:  48%|[32m████▊     [0m| 1592/3290 [09:52<12:34,  2.25it/s][A
step: 1592/3290, eval_loss: 0.4854, eval_acc: 0.8701:  48%|[32m████▊     [0m| 1592/3290 [09:52<12:34,  2.25it/s][A[2025-02-04 03:23:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1592/3290, eval_loss: 0.4854, eval_acc: 0.8701:  48%|[32m████▊     [0m| 1593/3290 [09:52<12:14,  2.31it/s][A
step: 1593/3290, eval_loss: 0.4854, eval_acc: 0.8701:  48%|[32m████▊     [0m| 1593/3290 [09:52<12:14,  2.31it/s][A[2025-02-04 03:23:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1593/3290, eval_loss: 0.4854, eval_acc: 0.8701:  48%|[32m████▊     [0m| 1594/3290 [09:53<11:04,  2.55it/s][A
step: 1594/3290, eval_loss: 0.4859, eval_acc: 0.8700:  48%|[32m████▊     [0m| 1594/3290 [09:53<11:04,  2.55it/s][A[2025-02-04 03:23:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1594/3290, eval_loss: 0.4859, eval_acc: 0.8700:  48%|[32m████▊     [0m| 1595/3290 [09:53<10:47,  2.62it/s][A
step: 1595/3290, eval_loss: 0.4858, eval_acc: 0.8700:  48%|[32m████▊     [0m| 1595/3290 [09:53<10:47,  2.62it/s][A[2025-02-04 03:23:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1595/3290, eval_loss: 0.4858, eval_acc: 0.8700:  49%|[32m████▊     [0m| 1596/3290 [09:53<09:39,  2.92it/s][A
step: 1596/3290, eval_loss: 0.4857, eval_acc: 0.8700:  49%|[32m████▊     [0m| 1596/3290 [09:53<09:39,  2.92it/s][A[2025-02-04 03:23:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1596/3290, eval_loss: 0.4857, eval_acc: 0.8700:  49%|[32m████▊     [0m| 1597/3290 [09:53<08:59,  3.14it/s][A
step: 1597/3290, eval_loss: 0.4860, eval_acc: 0.8700:  49%|[32m████▊     [0m| 1597/3290 [09:53<08:59,  3.14it/s][A[2025-02-04 03:23:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1597/3290, eval_loss: 0.4860, eval_acc: 0.8700:  49%|[32m████▊     [0m| 1598/3290 [09:54<08:32,  3.30it/s][A
step: 1598/3290, eval_loss: 0.4860, eval_acc: 0.8700:  49%|[32m████▊     [0m| 1598/3290 [09:54<08:32,  3.30it/s][A[2025-02-04 03:23:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1598/3290, eval_loss: 0.4860, eval_acc: 0.8700:  49%|[32m████▊     [0m| 1599/3290 [09:54<09:23,  3.00it/s][A
step: 1599/3290, eval_loss: 0.4859, eval_acc: 0.8700:  49%|[32m████▊     [0m| 1599/3290 [09:54<09:23,  3.00it/s][A[2025-02-04 03:23:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1599/3290, eval_loss: 0.4859, eval_acc: 0.8700:  49%|[32m████▊     [0m| 1600/3290 [09:54<08:50,  3.19it/s][A
step: 1600/3290, eval_loss: 0.4860, eval_acc: 0.8700:  49%|[32m████▊     [0m| 1600/3290 [09:54<08:50,  3.19it/s][A[2025-02-04 03:23:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1600/3290, eval_loss: 0.4860, eval_acc: 0.8700:  49%|[32m████▊     [0m| 1601/3290 [09:55<09:40,  2.91it/s][A
step: 1601/3290, eval_loss: 0.4857, eval_acc: 0.8701:  49%|[32m████▊     [0m| 1601/3290 [09:55<09:40,  2.91it/s][A[2025-02-04 03:23:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1601/3290, eval_loss: 0.4857, eval_acc: 0.8701:  49%|[32m████▊     [0m| 1602/3290 [09:55<09:50,  2.86it/s][A
step: 1602/3290, eval_loss: 0.4857, eval_acc: 0.8701:  49%|[32m████▊     [0m| 1602/3290 [09:55<09:50,  2.86it/s][A[2025-02-04 03:23:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1602/3290, eval_loss: 0.4857, eval_acc: 0.8701:  49%|[32m████▊     [0m| 1603/3290 [09:55<09:37,  2.92it/s][A
step: 1603/3290, eval_loss: 0.4855, eval_acc: 0.8702:  49%|[32m████▊     [0m| 1603/3290 [09:55<09:37,  2.92it/s][A[2025-02-04 03:23:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1603/3290, eval_loss: 0.4855, eval_acc: 0.8702:  49%|[32m████▉     [0m| 1604/3290 [09:56<09:40,  2.91it/s][A
step: 1604/3290, eval_loss: 0.4853, eval_acc: 0.8702:  49%|[32m████▉     [0m| 1604/3290 [09:56<09:40,  2.91it/s][A[2025-02-04 03:23:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1604/3290, eval_loss: 0.4853, eval_acc: 0.8702:  49%|[32m████▉     [0m| 1605/3290 [09:56<09:51,  2.85it/s][A
step: 1605/3290, eval_loss: 0.4853, eval_acc: 0.8702:  49%|[32m████▉     [0m| 1605/3290 [09:56<09:51,  2.85it/s][A[2025-02-04 03:23:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1605/3290, eval_loss: 0.4853, eval_acc: 0.8702:  49%|[32m████▉     [0m| 1606/3290 [09:56<09:29,  2.96it/s][A
step: 1606/3290, eval_loss: 0.4852, eval_acc: 0.8702:  49%|[32m████▉     [0m| 1606/3290 [09:56<09:29,  2.96it/s][A[2025-02-04 03:23:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1606/3290, eval_loss: 0.4852, eval_acc: 0.8702:  49%|[32m████▉     [0m| 1607/3290 [09:57<09:15,  3.03it/s][A
step: 1607/3290, eval_loss: 0.4852, eval_acc: 0.8702:  49%|[32m████▉     [0m| 1607/3290 [09:57<09:15,  3.03it/s][A[2025-02-04 03:23:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1607/3290, eval_loss: 0.4852, eval_acc: 0.8702:  49%|[32m████▉     [0m| 1608/3290 [09:57<08:59,  3.12it/s][A
step: 1608/3290, eval_loss: 0.4849, eval_acc: 0.8703:  49%|[32m████▉     [0m| 1608/3290 [09:57<08:59,  3.12it/s][A[2025-02-04 03:23:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1608/3290, eval_loss: 0.4849, eval_acc: 0.8703:  49%|[32m████▉     [0m| 1609/3290 [09:58<10:19,  2.71it/s][A
step: 1609/3290, eval_loss: 0.4848, eval_acc: 0.8703:  49%|[32m████▉     [0m| 1609/3290 [09:58<10:19,  2.71it/s][A[2025-02-04 03:23:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1609/3290, eval_loss: 0.4848, eval_acc: 0.8703:  49%|[32m████▉     [0m| 1610/3290 [09:58<11:26,  2.45it/s][A
step: 1610/3290, eval_loss: 0.4845, eval_acc: 0.8704:  49%|[32m████▉     [0m| 1610/3290 [09:58<11:26,  2.45it/s][A[2025-02-04 03:23:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1610/3290, eval_loss: 0.4845, eval_acc: 0.8704:  49%|[32m████▉     [0m| 1611/3290 [09:58<11:40,  2.40it/s][A
step: 1611/3290, eval_loss: 0.4843, eval_acc: 0.8704:  49%|[32m████▉     [0m| 1611/3290 [09:58<11:40,  2.40it/s][A[2025-02-04 03:23:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1611/3290, eval_loss: 0.4843, eval_acc: 0.8704:  49%|[32m████▉     [0m| 1612/3290 [09:59<11:30,  2.43it/s][A
step: 1612/3290, eval_loss: 0.4841, eval_acc: 0.8705:  49%|[32m████▉     [0m| 1612/3290 [09:59<11:30,  2.43it/s][A[2025-02-04 03:23:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1612/3290, eval_loss: 0.4841, eval_acc: 0.8705:  49%|[32m████▉     [0m| 1613/3290 [09:59<11:37,  2.40it/s][A
step: 1613/3290, eval_loss: 0.4840, eval_acc: 0.8705:  49%|[32m████▉     [0m| 1613/3290 [09:59<11:37,  2.40it/s][A[2025-02-04 03:23:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1613/3290, eval_loss: 0.4840, eval_acc: 0.8705:  49%|[32m████▉     [0m| 1614/3290 [10:00<11:35,  2.41it/s][A
step: 1614/3290, eval_loss: 0.4839, eval_acc: 0.8706:  49%|[32m████▉     [0m| 1614/3290 [10:00<11:35,  2.41it/s][A[2025-02-04 03:23:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1614/3290, eval_loss: 0.4839, eval_acc: 0.8706:  49%|[32m████▉     [0m| 1615/3290 [10:00<12:29,  2.23it/s][A
step: 1615/3290, eval_loss: 0.4838, eval_acc: 0.8706:  49%|[32m████▉     [0m| 1615/3290 [10:00<12:29,  2.23it/s][A[2025-02-04 03:23:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1615/3290, eval_loss: 0.4838, eval_acc: 0.8706:  49%|[32m████▉     [0m| 1616/3290 [10:01<13:04,  2.13it/s][A
step: 1616/3290, eval_loss: 0.4837, eval_acc: 0.8706:  49%|[32m████▉     [0m| 1616/3290 [10:01<13:04,  2.13it/s][A[2025-02-04 03:23:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1616/3290, eval_loss: 0.4837, eval_acc: 0.8706:  49%|[32m████▉     [0m| 1617/3290 [10:01<12:14,  2.28it/s][A
step: 1617/3290, eval_loss: 0.4835, eval_acc: 0.8707:  49%|[32m████▉     [0m| 1617/3290 [10:01<12:14,  2.28it/s][A[2025-02-04 03:23:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1617/3290, eval_loss: 0.4835, eval_acc: 0.8707:  49%|[32m████▉     [0m| 1618/3290 [10:01<11:29,  2.42it/s][A
step: 1618/3290, eval_loss: 0.4834, eval_acc: 0.8707:  49%|[32m████▉     [0m| 1618/3290 [10:01<11:29,  2.42it/s][A[2025-02-04 03:23:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1618/3290, eval_loss: 0.4834, eval_acc: 0.8707:  49%|[32m████▉     [0m| 1619/3290 [10:02<10:53,  2.56it/s][A
step: 1619/3290, eval_loss: 0.4833, eval_acc: 0.8707:  49%|[32m████▉     [0m| 1619/3290 [10:02<10:53,  2.56it/s][A[2025-02-04 03:23:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1619/3290, eval_loss: 0.4833, eval_acc: 0.8707:  49%|[32m████▉     [0m| 1620/3290 [10:02<10:30,  2.65it/s][A
step: 1620/3290, eval_loss: 0.4833, eval_acc: 0.8707:  49%|[32m████▉     [0m| 1620/3290 [10:02<10:30,  2.65it/s][A[2025-02-04 03:23:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1620/3290, eval_loss: 0.4833, eval_acc: 0.8707:  49%|[32m████▉     [0m| 1621/3290 [10:02<10:04,  2.76it/s][A
step: 1621/3290, eval_loss: 0.4834, eval_acc: 0.8707:  49%|[32m████▉     [0m| 1621/3290 [10:02<10:04,  2.76it/s][A[2025-02-04 03:23:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1621/3290, eval_loss: 0.4834, eval_acc: 0.8707:  49%|[32m████▉     [0m| 1622/3290 [10:03<11:02,  2.52it/s][A
step: 1622/3290, eval_loss: 0.4833, eval_acc: 0.8707:  49%|[32m████▉     [0m| 1622/3290 [10:03<11:02,  2.52it/s][A[2025-02-04 03:23:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1622/3290, eval_loss: 0.4833, eval_acc: 0.8707:  49%|[32m████▉     [0m| 1623/3290 [10:03<10:00,  2.78it/s][A
step: 1623/3290, eval_loss: 0.4830, eval_acc: 0.8708:  49%|[32m████▉     [0m| 1623/3290 [10:03<10:00,  2.78it/s][A[2025-02-04 03:23:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1623/3290, eval_loss: 0.4830, eval_acc: 0.8708:  49%|[32m████▉     [0m| 1624/3290 [10:04<10:06,  2.75it/s][A
step: 1624/3290, eval_loss: 0.4829, eval_acc: 0.8708:  49%|[32m████▉     [0m| 1624/3290 [10:04<10:06,  2.75it/s][A[2025-02-04 03:23:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1624/3290, eval_loss: 0.4829, eval_acc: 0.8708:  49%|[32m████▉     [0m| 1625/3290 [10:04<12:04,  2.30it/s][A
step: 1625/3290, eval_loss: 0.4828, eval_acc: 0.8709:  49%|[32m████▉     [0m| 1625/3290 [10:04<12:04,  2.30it/s][A[2025-02-04 03:23:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1625/3290, eval_loss: 0.4828, eval_acc: 0.8709:  49%|[32m████▉     [0m| 1626/3290 [10:05<11:17,  2.46it/s][A
step: 1626/3290, eval_loss: 0.4826, eval_acc: 0.8709:  49%|[32m████▉     [0m| 1626/3290 [10:05<11:17,  2.46it/s][A[2025-02-04 03:23:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1626/3290, eval_loss: 0.4826, eval_acc: 0.8709:  49%|[32m████▉     [0m| 1627/3290 [10:05<11:00,  2.52it/s][A
step: 1627/3290, eval_loss: 0.4824, eval_acc: 0.8710:  49%|[32m████▉     [0m| 1627/3290 [10:05<11:00,  2.52it/s][A[2025-02-04 03:23:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1627/3290, eval_loss: 0.4824, eval_acc: 0.8710:  49%|[32m████▉     [0m| 1628/3290 [10:05<10:22,  2.67it/s][A
step: 1628/3290, eval_loss: 0.4822, eval_acc: 0.8710:  49%|[32m████▉     [0m| 1628/3290 [10:05<10:22,  2.67it/s][A[2025-02-04 03:23:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1628/3290, eval_loss: 0.4822, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1629/3290 [10:06<09:47,  2.83it/s][A
step: 1629/3290, eval_loss: 0.4821, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1629/3290 [10:06<09:47,  2.83it/s][A[2025-02-04 03:24:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1629/3290, eval_loss: 0.4821, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1630/3290 [10:06<09:11,  3.01it/s][A
step: 1630/3290, eval_loss: 0.4820, eval_acc: 0.8711:  50%|[32m████▉     [0m| 1630/3290 [10:06<09:11,  3.01it/s][A[2025-02-04 03:24:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1630/3290, eval_loss: 0.4820, eval_acc: 0.8711:  50%|[32m████▉     [0m| 1631/3290 [10:06<08:49,  3.13it/s][A
step: 1631/3290, eval_loss: 0.4821, eval_acc: 0.8711:  50%|[32m████▉     [0m| 1631/3290 [10:06<08:49,  3.13it/s][A[2025-02-04 03:24:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1631/3290, eval_loss: 0.4821, eval_acc: 0.8711:  50%|[32m████▉     [0m| 1632/3290 [10:07<10:03,  2.75it/s][A
step: 1632/3290, eval_loss: 0.4821, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1632/3290 [10:07<10:03,  2.75it/s][A[2025-02-04 03:24:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1632/3290, eval_loss: 0.4821, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1633/3290 [10:07<10:09,  2.72it/s][A
step: 1633/3290, eval_loss: 0.4819, eval_acc: 0.8711:  50%|[32m████▉     [0m| 1633/3290 [10:07<10:09,  2.72it/s][A[2025-02-04 03:24:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1633/3290, eval_loss: 0.4819, eval_acc: 0.8711:  50%|[32m████▉     [0m| 1634/3290 [10:07<10:31,  2.62it/s][A
step: 1634/3290, eval_loss: 0.4820, eval_acc: 0.8711:  50%|[32m████▉     [0m| 1634/3290 [10:07<10:31,  2.62it/s][A[2025-02-04 03:24:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1634/3290, eval_loss: 0.4820, eval_acc: 0.8711:  50%|[32m████▉     [0m| 1635/3290 [10:08<10:27,  2.64it/s][A
step: 1635/3290, eval_loss: 0.4819, eval_acc: 0.8711:  50%|[32m████▉     [0m| 1635/3290 [10:08<10:27,  2.64it/s][A[2025-02-04 03:24:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1635/3290, eval_loss: 0.4819, eval_acc: 0.8711:  50%|[32m████▉     [0m| 1636/3290 [10:08<10:15,  2.69it/s][A
step: 1636/3290, eval_loss: 0.4822, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1636/3290 [10:08<10:15,  2.69it/s][A[2025-02-04 03:24:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1636/3290, eval_loss: 0.4822, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1637/3290 [10:08<10:05,  2.73it/s][A
step: 1637/3290, eval_loss: 0.4824, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1637/3290 [10:08<10:05,  2.73it/s][A[2025-02-04 03:24:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1637/3290, eval_loss: 0.4824, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1638/3290 [10:09<09:27,  2.91it/s][A
step: 1638/3290, eval_loss: 0.4824, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1638/3290 [10:09<09:27,  2.91it/s][A[2025-02-04 03:24:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1638/3290, eval_loss: 0.4824, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1639/3290 [10:09<08:48,  3.12it/s][A
step: 1639/3290, eval_loss: 0.4822, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1639/3290 [10:09<08:48,  3.12it/s][A[2025-02-04 03:24:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1639/3290, eval_loss: 0.4822, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1640/3290 [10:09<08:49,  3.11it/s][A
step: 1640/3290, eval_loss: 0.4822, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1640/3290 [10:09<08:49,  3.11it/s][A[2025-02-04 03:24:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1640/3290, eval_loss: 0.4822, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1641/3290 [10:10<08:55,  3.08it/s][A
step: 1641/3290, eval_loss: 0.4824, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1641/3290 [10:10<08:55,  3.08it/s][A[2025-02-04 03:24:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1641/3290, eval_loss: 0.4824, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1642/3290 [10:10<09:01,  3.04it/s][A
step: 1642/3290, eval_loss: 0.4822, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1642/3290 [10:10<09:01,  3.04it/s][A[2025-02-04 03:24:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1642/3290, eval_loss: 0.4822, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1643/3290 [10:10<09:30,  2.89it/s][A
step: 1643/3290, eval_loss: 0.4823, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1643/3290 [10:10<09:30,  2.89it/s][A[2025-02-04 03:24:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1643/3290, eval_loss: 0.4823, eval_acc: 0.8710:  50%|[32m████▉     [0m| 1644/3290 [10:11<10:45,  2.55it/s][A
step: 1644/3290, eval_loss: 0.4822, eval_acc: 0.8711:  50%|[32m████▉     [0m| 1644/3290 [10:11<10:45,  2.55it/s][A[2025-02-04 03:24:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1644/3290, eval_loss: 0.4822, eval_acc: 0.8711:  50%|[32m█████     [0m| 1645/3290 [10:11<09:50,  2.79it/s][A
step: 1645/3290, eval_loss: 0.4821, eval_acc: 0.8711:  50%|[32m█████     [0m| 1645/3290 [10:11<09:50,  2.79it/s][A[2025-02-04 03:24:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1645/3290, eval_loss: 0.4821, eval_acc: 0.8711:  50%|[32m█████     [0m| 1646/3290 [10:12<10:29,  2.61it/s][A
step: 1646/3290, eval_loss: 0.4820, eval_acc: 0.8712:  50%|[32m█████     [0m| 1646/3290 [10:12<10:29,  2.61it/s][A[2025-02-04 03:24:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1646/3290, eval_loss: 0.4820, eval_acc: 0.8712:  50%|[32m█████     [0m| 1647/3290 [10:12<09:52,  2.77it/s][A
step: 1647/3290, eval_loss: 0.4820, eval_acc: 0.8712:  50%|[32m█████     [0m| 1647/3290 [10:12<09:52,  2.77it/s][A[2025-02-04 03:24:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1647/3290, eval_loss: 0.4820, eval_acc: 0.8712:  50%|[32m█████     [0m| 1648/3290 [10:12<09:29,  2.88it/s][A
step: 1648/3290, eval_loss: 0.4820, eval_acc: 0.8712:  50%|[32m█████     [0m| 1648/3290 [10:12<09:29,  2.88it/s][A[2025-02-04 03:24:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1648/3290, eval_loss: 0.4820, eval_acc: 0.8712:  50%|[32m█████     [0m| 1649/3290 [10:13<09:08,  2.99it/s][A
step: 1649/3290, eval_loss: 0.4820, eval_acc: 0.8712:  50%|[32m█████     [0m| 1649/3290 [10:13<09:08,  2.99it/s][A[2025-02-04 03:24:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1649/3290, eval_loss: 0.4820, eval_acc: 0.8712:  50%|[32m█████     [0m| 1650/3290 [10:13<08:44,  3.13it/s][A
step: 1650/3290, eval_loss: 0.4818, eval_acc: 0.8712:  50%|[32m█████     [0m| 1650/3290 [10:13<08:44,  3.13it/s][A[2025-02-04 03:24:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1650/3290, eval_loss: 0.4818, eval_acc: 0.8712:  50%|[32m█████     [0m| 1651/3290 [10:13<08:38,  3.16it/s][A
step: 1651/3290, eval_loss: 0.4819, eval_acc: 0.8712:  50%|[32m█████     [0m| 1651/3290 [10:13<08:38,  3.16it/s][A[2025-02-04 03:24:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1651/3290, eval_loss: 0.4819, eval_acc: 0.8712:  50%|[32m█████     [0m| 1652/3290 [10:13<08:47,  3.11it/s][A
step: 1652/3290, eval_loss: 0.4819, eval_acc: 0.8712:  50%|[32m█████     [0m| 1652/3290 [10:13<08:47,  3.11it/s][A[2025-02-04 03:24:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1652/3290, eval_loss: 0.4819, eval_acc: 0.8712:  50%|[32m█████     [0m| 1653/3290 [10:14<08:48,  3.10it/s][A
step: 1653/3290, eval_loss: 0.4819, eval_acc: 0.8712:  50%|[32m█████     [0m| 1653/3290 [10:14<08:48,  3.10it/s][A[2025-02-04 03:24:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1653/3290, eval_loss: 0.4819, eval_acc: 0.8712:  50%|[32m█████     [0m| 1654/3290 [10:14<08:53,  3.07it/s][A
step: 1654/3290, eval_loss: 0.4818, eval_acc: 0.8712:  50%|[32m█████     [0m| 1654/3290 [10:14<08:53,  3.07it/s][A[2025-02-04 03:24:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1654/3290, eval_loss: 0.4818, eval_acc: 0.8712:  50%|[32m█████     [0m| 1655/3290 [10:15<09:25,  2.89it/s][A
step: 1655/3290, eval_loss: 0.4818, eval_acc: 0.8712:  50%|[32m█████     [0m| 1655/3290 [10:15<09:25,  2.89it/s][A[2025-02-04 03:24:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1655/3290, eval_loss: 0.4818, eval_acc: 0.8712:  50%|[32m█████     [0m| 1656/3290 [10:15<09:26,  2.88it/s][A
step: 1656/3290, eval_loss: 0.4817, eval_acc: 0.8713:  50%|[32m█████     [0m| 1656/3290 [10:15<09:26,  2.88it/s][A[2025-02-04 03:24:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1656/3290, eval_loss: 0.4817, eval_acc: 0.8713:  50%|[32m█████     [0m| 1657/3290 [10:15<09:19,  2.92it/s][A
step: 1657/3290, eval_loss: 0.4817, eval_acc: 0.8713:  50%|[32m█████     [0m| 1657/3290 [10:15<09:19,  2.92it/s][A[2025-02-04 03:24:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1657/3290, eval_loss: 0.4817, eval_acc: 0.8713:  50%|[32m█████     [0m| 1658/3290 [10:16<09:05,  2.99it/s][A
step: 1658/3290, eval_loss: 0.4819, eval_acc: 0.8712:  50%|[32m█████     [0m| 1658/3290 [10:16<09:05,  2.99it/s][A[2025-02-04 03:24:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1658/3290, eval_loss: 0.4819, eval_acc: 0.8712:  50%|[32m█████     [0m| 1659/3290 [10:16<09:05,  2.99it/s][A
step: 1659/3290, eval_loss: 0.4820, eval_acc: 0.8712:  50%|[32m█████     [0m| 1659/3290 [10:16<09:05,  2.99it/s][A[2025-02-04 03:24:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1659/3290, eval_loss: 0.4820, eval_acc: 0.8712:  50%|[32m█████     [0m| 1660/3290 [10:16<09:15,  2.94it/s][A
step: 1660/3290, eval_loss: 0.4820, eval_acc: 0.8712:  50%|[32m█████     [0m| 1660/3290 [10:16<09:15,  2.94it/s][A[2025-02-04 03:24:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1660/3290, eval_loss: 0.4820, eval_acc: 0.8712:  50%|[32m█████     [0m| 1661/3290 [10:17<09:15,  2.93it/s][A
step: 1661/3290, eval_loss: 0.4823, eval_acc: 0.8711:  50%|[32m█████     [0m| 1661/3290 [10:17<09:15,  2.93it/s][A[2025-02-04 03:24:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1661/3290, eval_loss: 0.4823, eval_acc: 0.8711:  51%|[32m█████     [0m| 1662/3290 [10:17<09:29,  2.86it/s][A
step: 1662/3290, eval_loss: 0.4823, eval_acc: 0.8711:  51%|[32m█████     [0m| 1662/3290 [10:17<09:29,  2.86it/s][A[2025-02-04 03:24:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1662/3290, eval_loss: 0.4823, eval_acc: 0.8711:  51%|[32m█████     [0m| 1663/3290 [10:17<09:14,  2.93it/s][A
step: 1663/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1663/3290 [10:17<09:14,  2.93it/s][A[2025-02-04 03:24:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1663/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1664/3290 [10:18<10:17,  2.63it/s][A
step: 1664/3290, eval_loss: 0.4827, eval_acc: 0.8711:  51%|[32m█████     [0m| 1664/3290 [10:18<10:17,  2.63it/s][A[2025-02-04 03:24:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1664/3290, eval_loss: 0.4827, eval_acc: 0.8711:  51%|[32m█████     [0m| 1665/3290 [10:18<10:21,  2.61it/s][A
step: 1665/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1665/3290 [10:18<10:21,  2.61it/s][A[2025-02-04 03:24:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1665/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1666/3290 [10:18<10:04,  2.69it/s][A
step: 1666/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1666/3290 [10:18<10:04,  2.69it/s][A[2025-02-04 03:24:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1666/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1667/3290 [10:19<09:36,  2.81it/s][A
step: 1667/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1667/3290 [10:19<09:36,  2.81it/s][A[2025-02-04 03:24:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1667/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1668/3290 [10:19<09:09,  2.95it/s][A
step: 1668/3290, eval_loss: 0.4827, eval_acc: 0.8711:  51%|[32m█████     [0m| 1668/3290 [10:19<09:09,  2.95it/s][A[2025-02-04 03:24:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1668/3290, eval_loss: 0.4827, eval_acc: 0.8711:  51%|[32m█████     [0m| 1669/3290 [10:19<08:54,  3.03it/s][A
step: 1669/3290, eval_loss: 0.4825, eval_acc: 0.8711:  51%|[32m█████     [0m| 1669/3290 [10:19<08:54,  3.03it/s][A[2025-02-04 03:24:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1669/3290, eval_loss: 0.4825, eval_acc: 0.8711:  51%|[32m█████     [0m| 1670/3290 [10:20<08:55,  3.03it/s][A
step: 1670/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1670/3290 [10:20<08:55,  3.03it/s][A[2025-02-04 03:24:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1670/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1671/3290 [10:20<10:07,  2.67it/s][A
step: 1671/3290, eval_loss: 0.4825, eval_acc: 0.8711:  51%|[32m█████     [0m| 1671/3290 [10:20<10:07,  2.67it/s][A[2025-02-04 03:24:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1671/3290, eval_loss: 0.4825, eval_acc: 0.8711:  51%|[32m█████     [0m| 1672/3290 [10:21<10:08,  2.66it/s][A
step: 1672/3290, eval_loss: 0.4828, eval_acc: 0.8711:  51%|[32m█████     [0m| 1672/3290 [10:21<10:08,  2.66it/s][A[2025-02-04 03:24:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1672/3290, eval_loss: 0.4828, eval_acc: 0.8711:  51%|[32m█████     [0m| 1673/3290 [10:21<10:57,  2.46it/s][A
step: 1673/3290, eval_loss: 0.4828, eval_acc: 0.8711:  51%|[32m█████     [0m| 1673/3290 [10:21<10:57,  2.46it/s][A[2025-02-04 03:24:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1673/3290, eval_loss: 0.4828, eval_acc: 0.8711:  51%|[32m█████     [0m| 1674/3290 [10:22<11:34,  2.33it/s][A
step: 1674/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1674/3290 [10:22<11:34,  2.33it/s][A[2025-02-04 03:24:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1674/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1675/3290 [10:22<12:18,  2.19it/s][A
step: 1675/3290, eval_loss: 0.4825, eval_acc: 0.8711:  51%|[32m█████     [0m| 1675/3290 [10:22<12:18,  2.19it/s][A[2025-02-04 03:24:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1675/3290, eval_loss: 0.4825, eval_acc: 0.8711:  51%|[32m█████     [0m| 1676/3290 [10:22<11:57,  2.25it/s][A
step: 1676/3290, eval_loss: 0.4824, eval_acc: 0.8712:  51%|[32m█████     [0m| 1676/3290 [10:22<11:57,  2.25it/s][A[2025-02-04 03:24:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1676/3290, eval_loss: 0.4824, eval_acc: 0.8712:  51%|[32m█████     [0m| 1677/3290 [10:23<11:29,  2.34it/s][A
step: 1677/3290, eval_loss: 0.4825, eval_acc: 0.8711:  51%|[32m█████     [0m| 1677/3290 [10:23<11:29,  2.34it/s][A[2025-02-04 03:24:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1677/3290, eval_loss: 0.4825, eval_acc: 0.8711:  51%|[32m█████     [0m| 1678/3290 [10:23<11:58,  2.24it/s][A
step: 1678/3290, eval_loss: 0.4824, eval_acc: 0.8712:  51%|[32m█████     [0m| 1678/3290 [10:23<11:58,  2.24it/s][A[2025-02-04 03:24:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1678/3290, eval_loss: 0.4824, eval_acc: 0.8712:  51%|[32m█████     [0m| 1679/3290 [10:24<11:36,  2.31it/s][A
step: 1679/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1679/3290 [10:24<11:36,  2.31it/s][A[2025-02-04 03:24:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1679/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1680/3290 [10:24<10:39,  2.52it/s][A
step: 1680/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1680/3290 [10:24<10:39,  2.52it/s][A[2025-02-04 03:24:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1680/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1681/3290 [10:24<10:40,  2.51it/s][A
step: 1681/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1681/3290 [10:24<10:40,  2.51it/s][A[2025-02-04 03:24:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1681/3290, eval_loss: 0.4826, eval_acc: 0.8711:  51%|[32m█████     [0m| 1682/3290 [10:25<10:34,  2.54it/s][A
step: 1682/3290, eval_loss: 0.4829, eval_acc: 0.8711:  51%|[32m█████     [0m| 1682/3290 [10:25<10:34,  2.54it/s][A[2025-02-04 03:24:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1682/3290, eval_loss: 0.4829, eval_acc: 0.8711:  51%|[32m█████     [0m| 1683/3290 [10:25<10:29,  2.55it/s][A
step: 1683/3290, eval_loss: 0.4827, eval_acc: 0.8711:  51%|[32m█████     [0m| 1683/3290 [10:25<10:29,  2.55it/s][A[2025-02-04 03:24:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1683/3290, eval_loss: 0.4827, eval_acc: 0.8711:  51%|[32m█████     [0m| 1684/3290 [10:26<10:10,  2.63it/s][A
step: 1684/3290, eval_loss: 0.4828, eval_acc: 0.8711:  51%|[32m█████     [0m| 1684/3290 [10:26<10:10,  2.63it/s][A[2025-02-04 03:24:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1684/3290, eval_loss: 0.4828, eval_acc: 0.8711:  51%|[32m█████     [0m| 1685/3290 [10:26<10:26,  2.56it/s][A
step: 1685/3290, eval_loss: 0.4829, eval_acc: 0.8711:  51%|[32m█████     [0m| 1685/3290 [10:26<10:26,  2.56it/s][A[2025-02-04 03:24:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1685/3290, eval_loss: 0.4829, eval_acc: 0.8711:  51%|[32m█████     [0m| 1686/3290 [10:27<11:33,  2.31it/s][A
step: 1686/3290, eval_loss: 0.4828, eval_acc: 0.8711:  51%|[32m█████     [0m| 1686/3290 [10:27<11:33,  2.31it/s][A[2025-02-04 03:24:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1686/3290, eval_loss: 0.4828, eval_acc: 0.8711:  51%|[32m█████▏    [0m| 1687/3290 [10:27<12:07,  2.20it/s][A
step: 1687/3290, eval_loss: 0.4827, eval_acc: 0.8711:  51%|[32m█████▏    [0m| 1687/3290 [10:27<12:07,  2.20it/s][A[2025-02-04 03:24:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1687/3290, eval_loss: 0.4827, eval_acc: 0.8711:  51%|[32m█████▏    [0m| 1688/3290 [10:28<12:41,  2.10it/s][A
step: 1688/3290, eval_loss: 0.4826, eval_acc: 0.8712:  51%|[32m█████▏    [0m| 1688/3290 [10:28<12:41,  2.10it/s][A[2025-02-04 03:24:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1688/3290, eval_loss: 0.4826, eval_acc: 0.8712:  51%|[32m█████▏    [0m| 1689/3290 [10:28<11:40,  2.29it/s][A
step: 1689/3290, eval_loss: 0.4825, eval_acc: 0.8712:  51%|[32m█████▏    [0m| 1689/3290 [10:28<11:40,  2.29it/s][A[2025-02-04 03:24:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1689/3290, eval_loss: 0.4825, eval_acc: 0.8712:  51%|[32m█████▏    [0m| 1690/3290 [10:28<10:41,  2.49it/s][A
step: 1690/3290, eval_loss: 0.4823, eval_acc: 0.8712:  51%|[32m█████▏    [0m| 1690/3290 [10:28<10:41,  2.49it/s][A[2025-02-04 03:24:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1690/3290, eval_loss: 0.4823, eval_acc: 0.8712:  51%|[32m█████▏    [0m| 1691/3290 [10:29<09:46,  2.72it/s][A
step: 1691/3290, eval_loss: 0.4822, eval_acc: 0.8713:  51%|[32m█████▏    [0m| 1691/3290 [10:29<09:46,  2.72it/s][A[2025-02-04 03:24:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1691/3290, eval_loss: 0.4822, eval_acc: 0.8713:  51%|[32m█████▏    [0m| 1692/3290 [10:29<09:55,  2.68it/s][A
step: 1692/3290, eval_loss: 0.4823, eval_acc: 0.8713:  51%|[32m█████▏    [0m| 1692/3290 [10:29<09:55,  2.68it/s][A[2025-02-04 03:24:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1692/3290, eval_loss: 0.4823, eval_acc: 0.8713:  51%|[32m█████▏    [0m| 1693/3290 [10:29<09:57,  2.67it/s][A
step: 1693/3290, eval_loss: 0.4821, eval_acc: 0.8713:  51%|[32m█████▏    [0m| 1693/3290 [10:29<09:57,  2.67it/s][A[2025-02-04 03:24:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1693/3290, eval_loss: 0.4821, eval_acc: 0.8713:  51%|[32m█████▏    [0m| 1694/3290 [10:30<11:01,  2.41it/s][A
step: 1694/3290, eval_loss: 0.4820, eval_acc: 0.8713:  51%|[32m█████▏    [0m| 1694/3290 [10:30<11:01,  2.41it/s][A[2025-02-04 03:24:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1694/3290, eval_loss: 0.4820, eval_acc: 0.8713:  52%|[32m█████▏    [0m| 1695/3290 [10:30<11:14,  2.36it/s][A
step: 1695/3290, eval_loss: 0.4818, eval_acc: 0.8714:  52%|[32m█████▏    [0m| 1695/3290 [10:30<11:14,  2.36it/s][A[2025-02-04 03:24:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1695/3290, eval_loss: 0.4818, eval_acc: 0.8714:  52%|[32m█████▏    [0m| 1696/3290 [10:31<11:08,  2.38it/s][A
step: 1696/3290, eval_loss: 0.4816, eval_acc: 0.8714:  52%|[32m█████▏    [0m| 1696/3290 [10:31<11:08,  2.38it/s][A[2025-02-04 03:24:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1696/3290, eval_loss: 0.4816, eval_acc: 0.8714:  52%|[32m█████▏    [0m| 1697/3290 [10:31<10:32,  2.52it/s][A
step: 1697/3290, eval_loss: 0.4817, eval_acc: 0.8714:  52%|[32m█████▏    [0m| 1697/3290 [10:31<10:32,  2.52it/s][A[2025-02-04 03:24:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1697/3290, eval_loss: 0.4817, eval_acc: 0.8714:  52%|[32m█████▏    [0m| 1698/3290 [10:31<10:14,  2.59it/s][A
step: 1698/3290, eval_loss: 0.4816, eval_acc: 0.8715:  52%|[32m█████▏    [0m| 1698/3290 [10:31<10:14,  2.59it/s][A[2025-02-04 03:24:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1698/3290, eval_loss: 0.4816, eval_acc: 0.8715:  52%|[32m█████▏    [0m| 1699/3290 [10:32<09:40,  2.74it/s][A
step: 1699/3290, eval_loss: 0.4815, eval_acc: 0.8715:  52%|[32m█████▏    [0m| 1699/3290 [10:32<09:40,  2.74it/s][A[2025-02-04 03:24:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1699/3290, eval_loss: 0.4815, eval_acc: 0.8715:  52%|[32m█████▏    [0m| 1700/3290 [10:32<10:27,  2.53it/s][A
step: 1700/3290, eval_loss: 0.4814, eval_acc: 0.8715:  52%|[32m█████▏    [0m| 1700/3290 [10:32<10:27,  2.53it/s][A[2025-02-04 03:24:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1700/3290, eval_loss: 0.4814, eval_acc: 0.8715:  52%|[32m█████▏    [0m| 1701/3290 [10:32<10:05,  2.62it/s][A
step: 1701/3290, eval_loss: 0.4812, eval_acc: 0.8716:  52%|[32m█████▏    [0m| 1701/3290 [10:32<10:05,  2.62it/s][A[2025-02-04 03:24:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1701/3290, eval_loss: 0.4812, eval_acc: 0.8716:  52%|[32m█████▏    [0m| 1702/3290 [10:33<10:01,  2.64it/s][A
step: 1702/3290, eval_loss: 0.4813, eval_acc: 0.8715:  52%|[32m█████▏    [0m| 1702/3290 [10:33<10:01,  2.64it/s][A[2025-02-04 03:24:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1702/3290, eval_loss: 0.4813, eval_acc: 0.8715:  52%|[32m█████▏    [0m| 1703/3290 [10:33<10:06,  2.62it/s][A
step: 1703/3290, eval_loss: 0.4811, eval_acc: 0.8716:  52%|[32m█████▏    [0m| 1703/3290 [10:33<10:06,  2.62it/s][A[2025-02-04 03:24:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1703/3290, eval_loss: 0.4811, eval_acc: 0.8716:  52%|[32m█████▏    [0m| 1704/3290 [10:34<09:21,  2.83it/s][A
step: 1704/3290, eval_loss: 0.4812, eval_acc: 0.8716:  52%|[32m█████▏    [0m| 1704/3290 [10:34<09:21,  2.83it/s][A[2025-02-04 03:24:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1704/3290, eval_loss: 0.4812, eval_acc: 0.8716:  52%|[32m█████▏    [0m| 1705/3290 [10:34<09:44,  2.71it/s][A
step: 1705/3290, eval_loss: 0.4811, eval_acc: 0.8716:  52%|[32m█████▏    [0m| 1705/3290 [10:34<09:44,  2.71it/s][A[2025-02-04 03:24:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1705/3290, eval_loss: 0.4811, eval_acc: 0.8716:  52%|[32m█████▏    [0m| 1706/3290 [10:34<10:02,  2.63it/s][A
step: 1706/3290, eval_loss: 0.4810, eval_acc: 0.8716:  52%|[32m█████▏    [0m| 1706/3290 [10:34<10:02,  2.63it/s][A[2025-02-04 03:24:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1706/3290, eval_loss: 0.4810, eval_acc: 0.8716:  52%|[32m█████▏    [0m| 1707/3290 [10:35<09:25,  2.80it/s][A
step: 1707/3290, eval_loss: 0.4808, eval_acc: 0.8717:  52%|[32m█████▏    [0m| 1707/3290 [10:35<09:25,  2.80it/s][A[2025-02-04 03:24:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1707/3290, eval_loss: 0.4808, eval_acc: 0.8717:  52%|[32m█████▏    [0m| 1708/3290 [10:35<09:12,  2.86it/s][A
step: 1708/3290, eval_loss: 0.4806, eval_acc: 0.8717:  52%|[32m█████▏    [0m| 1708/3290 [10:35<09:12,  2.86it/s][A[2025-02-04 03:24:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1708/3290, eval_loss: 0.4806, eval_acc: 0.8717:  52%|[32m█████▏    [0m| 1709/3290 [10:35<09:42,  2.72it/s][A
step: 1709/3290, eval_loss: 0.4805, eval_acc: 0.8718:  52%|[32m█████▏    [0m| 1709/3290 [10:35<09:42,  2.72it/s][A[2025-02-04 03:24:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1709/3290, eval_loss: 0.4805, eval_acc: 0.8718:  52%|[32m█████▏    [0m| 1710/3290 [10:36<10:08,  2.60it/s][A
step: 1710/3290, eval_loss: 0.4804, eval_acc: 0.8718:  52%|[32m█████▏    [0m| 1710/3290 [10:36<10:08,  2.60it/s][A[2025-02-04 03:24:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1710/3290, eval_loss: 0.4804, eval_acc: 0.8718:  52%|[32m█████▏    [0m| 1711/3290 [10:36<11:24,  2.31it/s][A
step: 1711/3290, eval_loss: 0.4803, eval_acc: 0.8718:  52%|[32m█████▏    [0m| 1711/3290 [10:36<11:24,  2.31it/s][A[2025-02-04 03:24:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1711/3290, eval_loss: 0.4803, eval_acc: 0.8718:  52%|[32m█████▏    [0m| 1712/3290 [10:37<11:44,  2.24it/s][A
step: 1712/3290, eval_loss: 0.4803, eval_acc: 0.8718:  52%|[32m█████▏    [0m| 1712/3290 [10:37<11:44,  2.24it/s][A[2025-02-04 03:24:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1712/3290, eval_loss: 0.4803, eval_acc: 0.8718:  52%|[32m█████▏    [0m| 1713/3290 [10:37<12:02,  2.18it/s][A
step: 1713/3290, eval_loss: 0.4803, eval_acc: 0.8718:  52%|[32m█████▏    [0m| 1713/3290 [10:37<12:02,  2.18it/s][A[2025-02-04 03:24:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1713/3290, eval_loss: 0.4803, eval_acc: 0.8718:  52%|[32m█████▏    [0m| 1714/3290 [10:38<11:22,  2.31it/s][A
step: 1714/3290, eval_loss: 0.4802, eval_acc: 0.8718:  52%|[32m█████▏    [0m| 1714/3290 [10:38<11:22,  2.31it/s][A[2025-02-04 03:24:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1714/3290, eval_loss: 0.4802, eval_acc: 0.8718:  52%|[32m█████▏    [0m| 1715/3290 [10:38<11:30,  2.28it/s][A
step: 1715/3290, eval_loss: 0.4801, eval_acc: 0.8719:  52%|[32m█████▏    [0m| 1715/3290 [10:38<11:30,  2.28it/s][A[2025-02-04 03:24:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1715/3290, eval_loss: 0.4801, eval_acc: 0.8719:  52%|[32m█████▏    [0m| 1716/3290 [10:38<10:46,  2.44it/s][A
step: 1716/3290, eval_loss: 0.4802, eval_acc: 0.8719:  52%|[32m█████▏    [0m| 1716/3290 [10:38<10:46,  2.44it/s][A[2025-02-04 03:24:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1716/3290, eval_loss: 0.4802, eval_acc: 0.8719:  52%|[32m█████▏    [0m| 1717/3290 [10:39<11:09,  2.35it/s][A
step: 1717/3290, eval_loss: 0.4800, eval_acc: 0.8719:  52%|[32m█████▏    [0m| 1717/3290 [10:39<11:09,  2.35it/s][A[2025-02-04 03:24:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1717/3290, eval_loss: 0.4800, eval_acc: 0.8719:  52%|[32m█████▏    [0m| 1718/3290 [10:39<10:42,  2.45it/s][A
step: 1718/3290, eval_loss: 0.4799, eval_acc: 0.8719:  52%|[32m█████▏    [0m| 1718/3290 [10:39<10:42,  2.45it/s][A[2025-02-04 03:24:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1718/3290, eval_loss: 0.4799, eval_acc: 0.8719:  52%|[32m█████▏    [0m| 1719/3290 [10:40<12:31,  2.09it/s][A
step: 1719/3290, eval_loss: 0.4798, eval_acc: 0.8720:  52%|[32m█████▏    [0m| 1719/3290 [10:40<12:31,  2.09it/s][A[2025-02-04 03:24:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1719/3290, eval_loss: 0.4798, eval_acc: 0.8720:  52%|[32m█████▏    [0m| 1720/3290 [10:40<12:44,  2.05it/s][A
step: 1720/3290, eval_loss: 0.4796, eval_acc: 0.8720:  52%|[32m█████▏    [0m| 1720/3290 [10:40<12:44,  2.05it/s][A[2025-02-04 03:24:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1720/3290, eval_loss: 0.4796, eval_acc: 0.8720:  52%|[32m█████▏    [0m| 1721/3290 [10:41<11:08,  2.35it/s][A
step: 1721/3290, eval_loss: 0.4795, eval_acc: 0.8720:  52%|[32m█████▏    [0m| 1721/3290 [10:41<11:08,  2.35it/s][A[2025-02-04 03:24:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1721/3290, eval_loss: 0.4795, eval_acc: 0.8720:  52%|[32m█████▏    [0m| 1722/3290 [10:41<10:21,  2.52it/s][A
step: 1722/3290, eval_loss: 0.4795, eval_acc: 0.8721:  52%|[32m█████▏    [0m| 1722/3290 [10:41<10:21,  2.52it/s][A[2025-02-04 03:24:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1722/3290, eval_loss: 0.4795, eval_acc: 0.8721:  52%|[32m█████▏    [0m| 1723/3290 [10:41<09:22,  2.78it/s][A
step: 1723/3290, eval_loss: 0.4793, eval_acc: 0.8721:  52%|[32m█████▏    [0m| 1723/3290 [10:41<09:22,  2.78it/s][A[2025-02-04 03:24:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1723/3290, eval_loss: 0.4793, eval_acc: 0.8721:  52%|[32m█████▏    [0m| 1724/3290 [10:42<09:48,  2.66it/s][A
step: 1724/3290, eval_loss: 0.4792, eval_acc: 0.8721:  52%|[32m█████▏    [0m| 1724/3290 [10:42<09:48,  2.66it/s][A[2025-02-04 03:24:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1724/3290, eval_loss: 0.4792, eval_acc: 0.8721:  52%|[32m█████▏    [0m| 1725/3290 [10:42<09:22,  2.78it/s][A
step: 1725/3290, eval_loss: 0.4791, eval_acc: 0.8722:  52%|[32m█████▏    [0m| 1725/3290 [10:42<09:22,  2.78it/s][A[2025-02-04 03:24:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1725/3290, eval_loss: 0.4791, eval_acc: 0.8722:  52%|[32m█████▏    [0m| 1726/3290 [10:42<09:10,  2.84it/s][A
step: 1726/3290, eval_loss: 0.4790, eval_acc: 0.8722:  52%|[32m█████▏    [0m| 1726/3290 [10:42<09:10,  2.84it/s][A[2025-02-04 03:24:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1726/3290, eval_loss: 0.4790, eval_acc: 0.8722:  52%|[32m█████▏    [0m| 1727/3290 [10:43<09:38,  2.70it/s][A
step: 1727/3290, eval_loss: 0.4790, eval_acc: 0.8722:  52%|[32m█████▏    [0m| 1727/3290 [10:43<09:38,  2.70it/s][A[2025-02-04 03:24:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1727/3290, eval_loss: 0.4790, eval_acc: 0.8722:  53%|[32m█████▎    [0m| 1728/3290 [10:43<09:09,  2.84it/s][A
step: 1728/3290, eval_loss: 0.4789, eval_acc: 0.8722:  53%|[32m█████▎    [0m| 1728/3290 [10:43<09:09,  2.84it/s][A[2025-02-04 03:24:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1728/3290, eval_loss: 0.4789, eval_acc: 0.8722:  53%|[32m█████▎    [0m| 1729/3290 [10:44<10:12,  2.55it/s][A
step: 1729/3290, eval_loss: 0.4788, eval_acc: 0.8723:  53%|[32m█████▎    [0m| 1729/3290 [10:44<10:12,  2.55it/s][A[2025-02-04 03:24:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1729/3290, eval_loss: 0.4788, eval_acc: 0.8723:  53%|[32m█████▎    [0m| 1730/3290 [10:44<10:59,  2.37it/s][A
step: 1730/3290, eval_loss: 0.4786, eval_acc: 0.8723:  53%|[32m█████▎    [0m| 1730/3290 [10:44<10:59,  2.37it/s][A[2025-02-04 03:24:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1730/3290, eval_loss: 0.4786, eval_acc: 0.8723:  53%|[32m█████▎    [0m| 1731/3290 [10:44<10:20,  2.51it/s][A
step: 1731/3290, eval_loss: 0.4785, eval_acc: 0.8723:  53%|[32m█████▎    [0m| 1731/3290 [10:44<10:20,  2.51it/s][A[2025-02-04 03:24:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1731/3290, eval_loss: 0.4785, eval_acc: 0.8723:  53%|[32m█████▎    [0m| 1732/3290 [10:45<10:33,  2.46it/s][A
step: 1732/3290, eval_loss: 0.4783, eval_acc: 0.8724:  53%|[32m█████▎    [0m| 1732/3290 [10:45<10:33,  2.46it/s][A[2025-02-04 03:24:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1732/3290, eval_loss: 0.4783, eval_acc: 0.8724:  53%|[32m█████▎    [0m| 1733/3290 [10:45<11:01,  2.35it/s][A
step: 1733/3290, eval_loss: 0.4783, eval_acc: 0.8724:  53%|[32m█████▎    [0m| 1733/3290 [10:45<11:01,  2.35it/s][A[2025-02-04 03:24:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1733/3290, eval_loss: 0.4783, eval_acc: 0.8724:  53%|[32m█████▎    [0m| 1734/3290 [10:46<10:23,  2.49it/s][A
step: 1734/3290, eval_loss: 0.4782, eval_acc: 0.8724:  53%|[32m█████▎    [0m| 1734/3290 [10:46<10:23,  2.49it/s][A[2025-02-04 03:24:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1734/3290, eval_loss: 0.4782, eval_acc: 0.8724:  53%|[32m█████▎    [0m| 1735/3290 [10:46<10:05,  2.57it/s][A
step: 1735/3290, eval_loss: 0.4783, eval_acc: 0.8724:  53%|[32m█████▎    [0m| 1735/3290 [10:46<10:05,  2.57it/s][A[2025-02-04 03:24:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1735/3290, eval_loss: 0.4783, eval_acc: 0.8724:  53%|[32m█████▎    [0m| 1736/3290 [10:46<09:45,  2.65it/s][A
step: 1736/3290, eval_loss: 0.4782, eval_acc: 0.8724:  53%|[32m█████▎    [0m| 1736/3290 [10:46<09:45,  2.65it/s][A[2025-02-04 03:24:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1736/3290, eval_loss: 0.4782, eval_acc: 0.8724:  53%|[32m█████▎    [0m| 1737/3290 [10:47<10:25,  2.48it/s][A
step: 1737/3290, eval_loss: 0.4780, eval_acc: 0.8724:  53%|[32m█████▎    [0m| 1737/3290 [10:47<10:25,  2.48it/s][A[2025-02-04 03:24:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1737/3290, eval_loss: 0.4780, eval_acc: 0.8724:  53%|[32m█████▎    [0m| 1738/3290 [10:47<09:30,  2.72it/s][A
step: 1738/3290, eval_loss: 0.4778, eval_acc: 0.8725:  53%|[32m█████▎    [0m| 1738/3290 [10:47<09:30,  2.72it/s][A[2025-02-04 03:24:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1738/3290, eval_loss: 0.4778, eval_acc: 0.8725:  53%|[32m█████▎    [0m| 1739/3290 [10:47<09:07,  2.84it/s][A
step: 1739/3290, eval_loss: 0.4776, eval_acc: 0.8725:  53%|[32m█████▎    [0m| 1739/3290 [10:47<09:07,  2.84it/s][A[2025-02-04 03:24:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1739/3290, eval_loss: 0.4776, eval_acc: 0.8725:  53%|[32m█████▎    [0m| 1740/3290 [10:48<09:37,  2.68it/s][A
step: 1740/3290, eval_loss: 0.4775, eval_acc: 0.8726:  53%|[32m█████▎    [0m| 1740/3290 [10:48<09:37,  2.68it/s][A[2025-02-04 03:24:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1740/3290, eval_loss: 0.4775, eval_acc: 0.8726:  53%|[32m█████▎    [0m| 1741/3290 [10:48<10:21,  2.49it/s][A
step: 1741/3290, eval_loss: 0.4773, eval_acc: 0.8726:  53%|[32m█████▎    [0m| 1741/3290 [10:48<10:21,  2.49it/s][A[2025-02-04 03:24:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1741/3290, eval_loss: 0.4773, eval_acc: 0.8726:  53%|[32m█████▎    [0m| 1742/3290 [10:49<09:47,  2.64it/s][A
step: 1742/3290, eval_loss: 0.4771, eval_acc: 0.8727:  53%|[32m█████▎    [0m| 1742/3290 [10:49<09:47,  2.64it/s][A[2025-02-04 03:24:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1742/3290, eval_loss: 0.4771, eval_acc: 0.8727:  53%|[32m█████▎    [0m| 1743/3290 [10:49<09:07,  2.83it/s][A
step: 1743/3290, eval_loss: 0.4770, eval_acc: 0.8727:  53%|[32m█████▎    [0m| 1743/3290 [10:49<09:07,  2.83it/s][A[2025-02-04 03:24:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1743/3290, eval_loss: 0.4770, eval_acc: 0.8727:  53%|[32m█████▎    [0m| 1744/3290 [10:49<09:24,  2.74it/s][A
step: 1744/3290, eval_loss: 0.4768, eval_acc: 0.8728:  53%|[32m█████▎    [0m| 1744/3290 [10:49<09:24,  2.74it/s][A[2025-02-04 03:24:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1744/3290, eval_loss: 0.4768, eval_acc: 0.8728:  53%|[32m█████▎    [0m| 1745/3290 [10:50<09:26,  2.73it/s][A
step: 1745/3290, eval_loss: 0.4766, eval_acc: 0.8729:  53%|[32m█████▎    [0m| 1745/3290 [10:50<09:26,  2.73it/s][A[2025-02-04 03:24:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1745/3290, eval_loss: 0.4766, eval_acc: 0.8729:  53%|[32m█████▎    [0m| 1746/3290 [10:50<10:05,  2.55it/s][A
step: 1746/3290, eval_loss: 0.4764, eval_acc: 0.8729:  53%|[32m█████▎    [0m| 1746/3290 [10:50<10:05,  2.55it/s][A[2025-02-04 03:24:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1746/3290, eval_loss: 0.4764, eval_acc: 0.8729:  53%|[32m█████▎    [0m| 1747/3290 [10:51<11:07,  2.31it/s][A
step: 1747/3290, eval_loss: 0.4763, eval_acc: 0.8729:  53%|[32m█████▎    [0m| 1747/3290 [10:51<11:07,  2.31it/s][A[2025-02-04 03:24:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1747/3290, eval_loss: 0.4763, eval_acc: 0.8729:  53%|[32m█████▎    [0m| 1748/3290 [10:51<10:26,  2.46it/s][A
step: 1748/3290, eval_loss: 0.4761, eval_acc: 0.8729:  53%|[32m█████▎    [0m| 1748/3290 [10:51<10:26,  2.46it/s][A[2025-02-04 03:24:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1748/3290, eval_loss: 0.4761, eval_acc: 0.8729:  53%|[32m█████▎    [0m| 1749/3290 [10:51<10:25,  2.46it/s][A
step: 1749/3290, eval_loss: 0.4759, eval_acc: 0.8730:  53%|[32m█████▎    [0m| 1749/3290 [10:51<10:25,  2.46it/s][A[2025-02-04 03:24:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1749/3290, eval_loss: 0.4759, eval_acc: 0.8730:  53%|[32m█████▎    [0m| 1750/3290 [10:52<10:24,  2.46it/s][A
step: 1750/3290, eval_loss: 0.4757, eval_acc: 0.8730:  53%|[32m█████▎    [0m| 1750/3290 [10:52<10:24,  2.46it/s][A[2025-02-04 03:24:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1750/3290, eval_loss: 0.4757, eval_acc: 0.8730:  53%|[32m█████▎    [0m| 1751/3290 [10:52<09:57,  2.58it/s][A
step: 1751/3290, eval_loss: 0.4755, eval_acc: 0.8731:  53%|[32m█████▎    [0m| 1751/3290 [10:52<09:57,  2.58it/s][A[2025-02-04 03:24:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1751/3290, eval_loss: 0.4755, eval_acc: 0.8731:  53%|[32m█████▎    [0m| 1752/3290 [10:53<09:21,  2.74it/s][A
step: 1752/3290, eval_loss: 0.4753, eval_acc: 0.8732:  53%|[32m█████▎    [0m| 1752/3290 [10:53<09:21,  2.74it/s][A[2025-02-04 03:24:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1752/3290, eval_loss: 0.4753, eval_acc: 0.8732:  53%|[32m█████▎    [0m| 1753/3290 [10:53<09:51,  2.60it/s][A
step: 1753/3290, eval_loss: 0.4754, eval_acc: 0.8731:  53%|[32m█████▎    [0m| 1753/3290 [10:53<09:51,  2.60it/s][A[2025-02-04 03:24:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1753/3290, eval_loss: 0.4754, eval_acc: 0.8731:  53%|[32m█████▎    [0m| 1754/3290 [10:53<10:04,  2.54it/s][A
step: 1754/3290, eval_loss: 0.4753, eval_acc: 0.8731:  53%|[32m█████▎    [0m| 1754/3290 [10:53<10:04,  2.54it/s][A[2025-02-04 03:24:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1754/3290, eval_loss: 0.4753, eval_acc: 0.8731:  53%|[32m█████▎    [0m| 1755/3290 [10:54<10:40,  2.40it/s][A
step: 1755/3290, eval_loss: 0.4753, eval_acc: 0.8731:  53%|[32m█████▎    [0m| 1755/3290 [10:54<10:40,  2.40it/s][A[2025-02-04 03:24:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1755/3290, eval_loss: 0.4753, eval_acc: 0.8731:  53%|[32m█████▎    [0m| 1756/3290 [10:54<10:24,  2.46it/s][A
step: 1756/3290, eval_loss: 0.4751, eval_acc: 0.8732:  53%|[32m█████▎    [0m| 1756/3290 [10:54<10:24,  2.46it/s][A[2025-02-04 03:24:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1756/3290, eval_loss: 0.4751, eval_acc: 0.8732:  53%|[32m█████▎    [0m| 1757/3290 [10:55<10:37,  2.40it/s][A
step: 1757/3290, eval_loss: 0.4748, eval_acc: 0.8732:  53%|[32m█████▎    [0m| 1757/3290 [10:55<10:37,  2.40it/s][A[2025-02-04 03:24:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1757/3290, eval_loss: 0.4748, eval_acc: 0.8732:  53%|[32m█████▎    [0m| 1758/3290 [10:55<10:27,  2.44it/s][A
step: 1758/3290, eval_loss: 0.4746, eval_acc: 0.8733:  53%|[32m█████▎    [0m| 1758/3290 [10:55<10:27,  2.44it/s][A[2025-02-04 03:24:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1758/3290, eval_loss: 0.4746, eval_acc: 0.8733:  53%|[32m█████▎    [0m| 1759/3290 [10:55<10:01,  2.55it/s][A
step: 1759/3290, eval_loss: 0.4747, eval_acc: 0.8733:  53%|[32m█████▎    [0m| 1759/3290 [10:55<10:01,  2.55it/s][A[2025-02-04 03:24:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1759/3290, eval_loss: 0.4747, eval_acc: 0.8733:  53%|[32m█████▎    [0m| 1760/3290 [10:56<10:07,  2.52it/s][A
step: 1760/3290, eval_loss: 0.4747, eval_acc: 0.8733:  53%|[32m█████▎    [0m| 1760/3290 [10:56<10:07,  2.52it/s][A[2025-02-04 03:24:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1760/3290, eval_loss: 0.4747, eval_acc: 0.8733:  54%|[32m█████▎    [0m| 1761/3290 [10:56<10:29,  2.43it/s][A
step: 1761/3290, eval_loss: 0.4745, eval_acc: 0.8733:  54%|[32m█████▎    [0m| 1761/3290 [10:56<10:29,  2.43it/s][A[2025-02-04 03:24:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1761/3290, eval_loss: 0.4745, eval_acc: 0.8733:  54%|[32m█████▎    [0m| 1762/3290 [10:57<10:45,  2.37it/s][A
step: 1762/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1762/3290 [10:57<10:45,  2.37it/s][A[2025-02-04 03:24:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1762/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1763/3290 [10:57<11:38,  2.19it/s][A
step: 1763/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1763/3290 [10:57<11:38,  2.19it/s][A[2025-02-04 03:24:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1763/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1764/3290 [10:58<11:06,  2.29it/s][A
step: 1764/3290, eval_loss: 0.4745, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1764/3290 [10:58<11:06,  2.29it/s][A[2025-02-04 03:24:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1764/3290, eval_loss: 0.4745, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1765/3290 [10:58<10:32,  2.41it/s][A
step: 1765/3290, eval_loss: 0.4745, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1765/3290 [10:58<10:32,  2.41it/s][A[2025-02-04 03:24:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1765/3290, eval_loss: 0.4745, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1766/3290 [10:58<10:09,  2.50it/s][A
step: 1766/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1766/3290 [10:58<10:09,  2.50it/s][A[2025-02-04 03:24:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1766/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1767/3290 [10:59<10:07,  2.51it/s][A
step: 1767/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1767/3290 [10:59<10:07,  2.51it/s][A[2025-02-04 03:24:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1767/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1768/3290 [10:59<09:26,  2.68it/s][A
step: 1768/3290, eval_loss: 0.4743, eval_acc: 0.8734:  54%|[32m█████▎    [0m| 1768/3290 [10:59<09:26,  2.68it/s][A[2025-02-04 03:24:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1768/3290, eval_loss: 0.4743, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1769/3290 [10:59<09:15,  2.74it/s][A
step: 1769/3290, eval_loss: 0.4742, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1769/3290 [10:59<09:15,  2.74it/s][A[2025-02-04 03:24:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1769/3290, eval_loss: 0.4742, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1770/3290 [11:00<09:52,  2.56it/s][A
step: 1770/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1770/3290 [11:00<09:52,  2.56it/s][A[2025-02-04 03:24:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1770/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1771/3290 [11:00<09:49,  2.57it/s][A
step: 1771/3290, eval_loss: 0.4745, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1771/3290 [11:00<09:49,  2.57it/s][A[2025-02-04 03:24:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1771/3290, eval_loss: 0.4745, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1772/3290 [11:01<10:26,  2.42it/s][A
step: 1772/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1772/3290 [11:01<10:26,  2.42it/s][A[2025-02-04 03:24:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1772/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1773/3290 [11:01<11:42,  2.16it/s][A
step: 1773/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1773/3290 [11:01<11:42,  2.16it/s][A[2025-02-04 03:24:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1773/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1774/3290 [11:02<10:18,  2.45it/s][A
step: 1774/3290, eval_loss: 0.4743, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1774/3290 [11:02<10:18,  2.45it/s][A[2025-02-04 03:24:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1774/3290, eval_loss: 0.4743, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1775/3290 [11:02<09:27,  2.67it/s][A
step: 1775/3290, eval_loss: 0.4742, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1775/3290 [11:02<09:27,  2.67it/s][A[2025-02-04 03:24:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1775/3290, eval_loss: 0.4742, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1776/3290 [11:02<09:01,  2.79it/s][A
step: 1776/3290, eval_loss: 0.4743, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1776/3290 [11:02<09:01,  2.79it/s][A[2025-02-04 03:24:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1776/3290, eval_loss: 0.4743, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1777/3290 [11:03<08:43,  2.89it/s][A
step: 1777/3290, eval_loss: 0.4743, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1777/3290 [11:03<08:43,  2.89it/s][A[2025-02-04 03:24:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1777/3290, eval_loss: 0.4743, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1778/3290 [11:03<09:10,  2.75it/s][A
step: 1778/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1778/3290 [11:03<09:10,  2.75it/s][A[2025-02-04 03:24:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1778/3290, eval_loss: 0.4744, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1779/3290 [11:03<09:26,  2.67it/s][A
step: 1779/3290, eval_loss: 0.4743, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1779/3290 [11:03<09:26,  2.67it/s][A[2025-02-04 03:24:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1779/3290, eval_loss: 0.4743, eval_acc: 0.8734:  54%|[32m█████▍    [0m| 1780/3290 [11:04<09:40,  2.60it/s][A
step: 1780/3290, eval_loss: 0.4742, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1780/3290 [11:04<09:40,  2.60it/s][A[2025-02-04 03:24:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1780/3290, eval_loss: 0.4742, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1781/3290 [11:04<08:59,  2.80it/s][A
step: 1781/3290, eval_loss: 0.4741, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1781/3290 [11:04<08:59,  2.80it/s][A[2025-02-04 03:24:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1781/3290, eval_loss: 0.4741, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1782/3290 [11:04<08:41,  2.89it/s][A
step: 1782/3290, eval_loss: 0.4742, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1782/3290 [11:04<08:41,  2.89it/s][A[2025-02-04 03:24:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1782/3290, eval_loss: 0.4742, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1783/3290 [11:05<08:00,  3.13it/s][A
step: 1783/3290, eval_loss: 0.4741, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1783/3290 [11:05<08:00,  3.13it/s][A[2025-02-04 03:24:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1783/3290, eval_loss: 0.4741, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1784/3290 [11:05<07:36,  3.30it/s][A
step: 1784/3290, eval_loss: 0.4740, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1784/3290 [11:05<07:36,  3.30it/s][A[2025-02-04 03:24:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1784/3290, eval_loss: 0.4740, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1785/3290 [11:05<07:29,  3.34it/s][A
step: 1785/3290, eval_loss: 0.4739, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1785/3290 [11:05<07:29,  3.34it/s][A[2025-02-04 03:24:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1785/3290, eval_loss: 0.4739, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1786/3290 [11:05<07:13,  3.47it/s][A
step: 1786/3290, eval_loss: 0.4740, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1786/3290 [11:05<07:13,  3.47it/s][A[2025-02-04 03:25:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1786/3290, eval_loss: 0.4740, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1787/3290 [11:06<07:11,  3.48it/s][A
step: 1787/3290, eval_loss: 0.4740, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1787/3290 [11:06<07:11,  3.48it/s][A[2025-02-04 03:25:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1787/3290, eval_loss: 0.4740, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1788/3290 [11:06<07:15,  3.45it/s][A
step: 1788/3290, eval_loss: 0.4738, eval_acc: 0.8736:  54%|[32m█████▍    [0m| 1788/3290 [11:06<07:15,  3.45it/s][A[2025-02-04 03:25:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1788/3290, eval_loss: 0.4738, eval_acc: 0.8736:  54%|[32m█████▍    [0m| 1789/3290 [11:06<07:05,  3.53it/s][A
step: 1789/3290, eval_loss: 0.4738, eval_acc: 0.8736:  54%|[32m█████▍    [0m| 1789/3290 [11:06<07:05,  3.53it/s][A[2025-02-04 03:25:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1789/3290, eval_loss: 0.4738, eval_acc: 0.8736:  54%|[32m█████▍    [0m| 1790/3290 [11:07<07:05,  3.52it/s][A
step: 1790/3290, eval_loss: 0.4740, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1790/3290 [11:07<07:05,  3.52it/s][A[2025-02-04 03:25:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1790/3290, eval_loss: 0.4740, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1791/3290 [11:07<07:04,  3.53it/s][A
step: 1791/3290, eval_loss: 0.4738, eval_acc: 0.8736:  54%|[32m█████▍    [0m| 1791/3290 [11:07<07:04,  3.53it/s][A[2025-02-04 03:25:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1791/3290, eval_loss: 0.4738, eval_acc: 0.8736:  54%|[32m█████▍    [0m| 1792/3290 [11:07<06:47,  3.67it/s][A
step: 1792/3290, eval_loss: 0.4739, eval_acc: 0.8736:  54%|[32m█████▍    [0m| 1792/3290 [11:07<06:47,  3.67it/s][A[2025-02-04 03:25:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1792/3290, eval_loss: 0.4739, eval_acc: 0.8736:  54%|[32m█████▍    [0m| 1793/3290 [11:07<07:06,  3.51it/s][A
step: 1793/3290, eval_loss: 0.4739, eval_acc: 0.8735:  54%|[32m█████▍    [0m| 1793/3290 [11:07<07:06,  3.51it/s][A[2025-02-04 03:25:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1793/3290, eval_loss: 0.4739, eval_acc: 0.8735:  55%|[32m█████▍    [0m| 1794/3290 [11:08<07:08,  3.49it/s][A
step: 1794/3290, eval_loss: 0.4740, eval_acc: 0.8735:  55%|[32m█████▍    [0m| 1794/3290 [11:08<07:08,  3.49it/s][A[2025-02-04 03:25:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1794/3290, eval_loss: 0.4740, eval_acc: 0.8735:  55%|[32m█████▍    [0m| 1795/3290 [11:08<06:58,  3.57it/s][A
step: 1795/3290, eval_loss: 0.4739, eval_acc: 0.8735:  55%|[32m█████▍    [0m| 1795/3290 [11:08<06:58,  3.57it/s][A[2025-02-04 03:25:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1795/3290, eval_loss: 0.4739, eval_acc: 0.8735:  55%|[32m█████▍    [0m| 1796/3290 [11:08<07:41,  3.24it/s][A
step: 1796/3290, eval_loss: 0.4737, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1796/3290 [11:08<07:41,  3.24it/s][A[2025-02-04 03:25:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1796/3290, eval_loss: 0.4737, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1797/3290 [11:09<07:41,  3.24it/s][A
step: 1797/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1797/3290 [11:09<07:41,  3.24it/s][A[2025-02-04 03:25:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1797/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1798/3290 [11:09<07:51,  3.16it/s][A
step: 1798/3290, eval_loss: 0.4737, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1798/3290 [11:09<07:51,  3.16it/s][A[2025-02-04 03:25:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1798/3290, eval_loss: 0.4737, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1799/3290 [11:09<08:14,  3.01it/s][A
step: 1799/3290, eval_loss: 0.4737, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1799/3290 [11:09<08:14,  3.01it/s][A[2025-02-04 03:25:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1799/3290, eval_loss: 0.4737, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1800/3290 [11:10<08:23,  2.96it/s][A
step: 1800/3290, eval_loss: 0.4736, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1800/3290 [11:10<08:23,  2.96it/s][A[2025-02-04 03:25:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1800/3290, eval_loss: 0.4736, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1801/3290 [11:10<08:39,  2.87it/s][A
step: 1801/3290, eval_loss: 0.4737, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1801/3290 [11:10<08:39,  2.87it/s][A[2025-02-04 03:25:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1801/3290, eval_loss: 0.4737, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1802/3290 [11:10<08:21,  2.97it/s][A
step: 1802/3290, eval_loss: 0.4737, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1802/3290 [11:10<08:21,  2.97it/s][A[2025-02-04 03:25:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1802/3290, eval_loss: 0.4737, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1803/3290 [11:11<08:59,  2.76it/s][A
step: 1803/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1803/3290 [11:11<08:59,  2.76it/s][A[2025-02-04 03:25:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1803/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1804/3290 [11:11<09:12,  2.69it/s][A
step: 1804/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1804/3290 [11:11<09:12,  2.69it/s][A[2025-02-04 03:25:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1804/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1805/3290 [11:12<09:00,  2.75it/s][A
step: 1805/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1805/3290 [11:12<09:00,  2.75it/s][A[2025-02-04 03:25:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1805/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1806/3290 [11:12<09:01,  2.74it/s][A
step: 1806/3290, eval_loss: 0.4739, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1806/3290 [11:12<09:01,  2.74it/s][A[2025-02-04 03:25:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1806/3290, eval_loss: 0.4739, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1807/3290 [11:12<08:04,  3.06it/s][A
step: 1807/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1807/3290 [11:12<08:04,  3.06it/s][A[2025-02-04 03:25:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1807/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▍    [0m| 1808/3290 [11:12<07:24,  3.33it/s][A
step: 1808/3290, eval_loss: 0.4739, eval_acc: 0.8735:  55%|[32m█████▍    [0m| 1808/3290 [11:12<07:24,  3.33it/s][A[2025-02-04 03:25:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1808/3290, eval_loss: 0.4739, eval_acc: 0.8735:  55%|[32m█████▍    [0m| 1809/3290 [11:13<07:03,  3.49it/s][A
step: 1809/3290, eval_loss: 0.4738, eval_acc: 0.8735:  55%|[32m█████▍    [0m| 1809/3290 [11:13<07:03,  3.49it/s][A[2025-02-04 03:25:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1809/3290, eval_loss: 0.4738, eval_acc: 0.8735:  55%|[32m█████▌    [0m| 1810/3290 [11:13<06:58,  3.54it/s][A
step: 1810/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1810/3290 [11:13<06:58,  3.54it/s][A[2025-02-04 03:25:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1810/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1811/3290 [11:13<06:44,  3.65it/s][A
step: 1811/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1811/3290 [11:13<06:44,  3.65it/s][A[2025-02-04 03:25:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1811/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1812/3290 [11:14<08:04,  3.05it/s][A
step: 1812/3290, eval_loss: 0.4739, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1812/3290 [11:14<08:04,  3.05it/s][A[2025-02-04 03:25:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1812/3290, eval_loss: 0.4739, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1813/3290 [11:14<09:34,  2.57it/s][A
step: 1813/3290, eval_loss: 0.4739, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1813/3290 [11:14<09:34,  2.57it/s][A[2025-02-04 03:25:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1813/3290, eval_loss: 0.4739, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1814/3290 [11:14<09:00,  2.73it/s][A
step: 1814/3290, eval_loss: 0.4740, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1814/3290 [11:14<09:00,  2.73it/s][A[2025-02-04 03:25:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1814/3290, eval_loss: 0.4740, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1815/3290 [11:15<08:09,  3.02it/s][A
step: 1815/3290, eval_loss: 0.4740, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1815/3290 [11:15<08:09,  3.02it/s][A[2025-02-04 03:25:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1815/3290, eval_loss: 0.4740, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1816/3290 [11:15<08:06,  3.03it/s][A
step: 1816/3290, eval_loss: 0.4739, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1816/3290 [11:15<08:06,  3.03it/s][A[2025-02-04 03:25:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1816/3290, eval_loss: 0.4739, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1817/3290 [11:15<08:45,  2.80it/s][A
step: 1817/3290, eval_loss: 0.4741, eval_acc: 0.8735:  55%|[32m█████▌    [0m| 1817/3290 [11:15<08:45,  2.80it/s][A[2025-02-04 03:25:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1817/3290, eval_loss: 0.4741, eval_acc: 0.8735:  55%|[32m█████▌    [0m| 1818/3290 [11:16<09:15,  2.65it/s][A
step: 1818/3290, eval_loss: 0.4740, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1818/3290 [11:16<09:15,  2.65it/s][A[2025-02-04 03:25:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1818/3290, eval_loss: 0.4740, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1819/3290 [11:16<09:11,  2.67it/s][A
step: 1819/3290, eval_loss: 0.4739, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1819/3290 [11:16<09:11,  2.67it/s][A[2025-02-04 03:25:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1819/3290, eval_loss: 0.4739, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1820/3290 [11:17<08:58,  2.73it/s][A
step: 1820/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1820/3290 [11:17<08:58,  2.73it/s][A[2025-02-04 03:25:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1820/3290, eval_loss: 0.4738, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1821/3290 [11:17<10:39,  2.30it/s][A
step: 1821/3290, eval_loss: 0.4739, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1821/3290 [11:17<10:39,  2.30it/s][A[2025-02-04 03:25:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1821/3290, eval_loss: 0.4739, eval_acc: 0.8736:  55%|[32m█████▌    [0m| 1822/3290 [11:18<10:43,  2.28it/s][A
step: 1822/3290, eval_loss: 0.4739, eval_acc: 0.8735:  55%|[32m█████▌    [0m| 1822/3290 [11:18<10:43,  2.28it/s][A[2025-02-04 03:25:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1822/3290, eval_loss: 0.4739, eval_acc: 0.8735:  55%|[32m█████▌    [0m| 1823/3290 [11:18<09:44,  2.51it/s][A
step: 1823/3290, eval_loss: 0.4739, eval_acc: 0.8735:  55%|[32m█████▌    [0m| 1823/3290 [11:18<09:44,  2.51it/s][A[2025-02-04 03:25:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1823/3290, eval_loss: 0.4739, eval_acc: 0.8735:  55%|[32m█████▌    [0m| 1824/3290 [11:18<09:15,  2.64it/s][A
step: 1824/3290, eval_loss: 0.4738, eval_acc: 0.8735:  55%|[32m█████▌    [0m| 1824/3290 [11:18<09:15,  2.64it/s][A[2025-02-04 03:25:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1824/3290, eval_loss: 0.4738, eval_acc: 0.8735:  55%|[32m█████▌    [0m| 1825/3290 [11:19<09:42,  2.51it/s][A
step: 1825/3290, eval_loss: 0.4738, eval_acc: 0.8735:  55%|[32m█████▌    [0m| 1825/3290 [11:19<09:42,  2.51it/s][A[2025-02-04 03:25:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1825/3290, eval_loss: 0.4738, eval_acc: 0.8735:  56%|[32m█████▌    [0m| 1826/3290 [11:19<09:39,  2.53it/s][A
step: 1826/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1826/3290 [11:19<09:39,  2.53it/s][A[2025-02-04 03:25:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1826/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1827/3290 [11:20<09:48,  2.49it/s][A
step: 1827/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1827/3290 [11:20<09:48,  2.49it/s][A[2025-02-04 03:25:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1827/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1828/3290 [11:20<10:05,  2.41it/s][A
step: 1828/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1828/3290 [11:20<10:05,  2.41it/s][A[2025-02-04 03:25:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1828/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1829/3290 [11:20<10:12,  2.38it/s][A
step: 1829/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1829/3290 [11:20<10:12,  2.38it/s][A[2025-02-04 03:25:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1829/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1830/3290 [11:21<09:56,  2.45it/s][A
step: 1830/3290, eval_loss: 0.4740, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1830/3290 [11:21<09:56,  2.45it/s][A[2025-02-04 03:25:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1830/3290, eval_loss: 0.4740, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1831/3290 [11:21<09:23,  2.59it/s][A
step: 1831/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1831/3290 [11:21<09:23,  2.59it/s][A[2025-02-04 03:25:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1831/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1832/3290 [11:22<09:20,  2.60it/s][A
step: 1832/3290, eval_loss: 0.4742, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1832/3290 [11:22<09:20,  2.60it/s][A[2025-02-04 03:25:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1832/3290, eval_loss: 0.4742, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1833/3290 [11:22<09:30,  2.56it/s][A
step: 1833/3290, eval_loss: 0.4742, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1833/3290 [11:22<09:30,  2.56it/s][A[2025-02-04 03:25:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1833/3290, eval_loss: 0.4742, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1834/3290 [11:22<09:05,  2.67it/s][A
step: 1834/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1834/3290 [11:22<09:05,  2.67it/s][A[2025-02-04 03:25:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1834/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1835/3290 [11:23<08:40,  2.80it/s][A
step: 1835/3290, eval_loss: 0.4742, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1835/3290 [11:23<08:40,  2.80it/s][A[2025-02-04 03:25:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1835/3290, eval_loss: 0.4742, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1836/3290 [11:23<08:07,  2.99it/s][A
step: 1836/3290, eval_loss: 0.4742, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1836/3290 [11:23<08:07,  2.99it/s][A[2025-02-04 03:25:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1836/3290, eval_loss: 0.4742, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1837/3290 [11:23<09:01,  2.68it/s][A
step: 1837/3290, eval_loss: 0.4742, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1837/3290 [11:23<09:01,  2.68it/s][A[2025-02-04 03:25:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1837/3290, eval_loss: 0.4742, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1838/3290 [11:24<10:00,  2.42it/s][A
step: 1838/3290, eval_loss: 0.4746, eval_acc: 0.8732:  56%|[32m█████▌    [0m| 1838/3290 [11:24<10:00,  2.42it/s][A[2025-02-04 03:25:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1838/3290, eval_loss: 0.4746, eval_acc: 0.8732:  56%|[32m█████▌    [0m| 1839/3290 [11:24<09:48,  2.47it/s][A
step: 1839/3290, eval_loss: 0.4745, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1839/3290 [11:24<09:48,  2.47it/s][A[2025-02-04 03:25:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 1839/3290, eval_loss: 0.4745, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1840/3290 [11:25<09:34,  2.53it/s][A
step: 1840/3290, eval_loss: 0.4744, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1840/3290 [11:25<09:34,  2.53it/s][A[2025-02-04 03:25:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1840/3290, eval_loss: 0.4744, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1841/3290 [11:25<09:46,  2.47it/s][A
step: 1841/3290, eval_loss: 0.4745, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1841/3290 [11:25<09:46,  2.47it/s][A[2025-02-04 03:25:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 1841/3290, eval_loss: 0.4745, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1842/3290 [11:26<10:27,  2.31it/s][A
step: 1842/3290, eval_loss: 0.4743, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1842/3290 [11:26<10:27,  2.31it/s][A[2025-02-04 03:25:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1842/3290, eval_loss: 0.4743, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1843/3290 [11:26<10:40,  2.26it/s][A
step: 1843/3290, eval_loss: 0.4743, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1843/3290 [11:26<10:40,  2.26it/s][A[2025-02-04 03:25:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 1843/3290, eval_loss: 0.4743, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1844/3290 [11:26<11:13,  2.15it/s][A
step: 1844/3290, eval_loss: 0.4743, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1844/3290 [11:26<11:13,  2.15it/s][A[2025-02-04 03:25:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1844/3290, eval_loss: 0.4743, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1845/3290 [11:27<11:06,  2.17it/s][A
step: 1845/3290, eval_loss: 0.4742, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1845/3290 [11:27<11:06,  2.17it/s][A[2025-02-04 03:25:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1845/3290, eval_loss: 0.4742, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1846/3290 [11:27<09:46,  2.46it/s][A
step: 1846/3290, eval_loss: 0.4745, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1846/3290 [11:27<09:46,  2.46it/s][A[2025-02-04 03:25:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 1846/3290, eval_loss: 0.4745, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1847/3290 [11:28<09:33,  2.52it/s][A
step: 1847/3290, eval_loss: 0.4744, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1847/3290 [11:28<09:33,  2.52it/s][A[2025-02-04 03:25:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1847/3290, eval_loss: 0.4744, eval_acc: 0.8733:  56%|[32m█████▌    [0m| 1848/3290 [11:28<09:23,  2.56it/s][A
step: 1848/3290, eval_loss: 0.4743, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1848/3290 [11:28<09:23,  2.56it/s][A[2025-02-04 03:25:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1848/3290, eval_loss: 0.4743, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1849/3290 [11:28<08:54,  2.69it/s][A
step: 1849/3290, eval_loss: 0.4742, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1849/3290 [11:28<08:54,  2.69it/s][A[2025-02-04 03:25:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 1849/3290, eval_loss: 0.4742, eval_acc: 0.8734:  56%|[32m█████▌    [0m| 1850/3290 [11:29<08:16,  2.90it/s][A
step: 1850/3290, eval_loss: 0.4740, eval_acc: 0.8735:  56%|[32m█████▌    [0m| 1850/3290 [11:29<08:16,  2.90it/s][A[2025-02-04 03:25:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1850/3290, eval_loss: 0.4740, eval_acc: 0.8735:  56%|[32m█████▋    [0m| 1851/3290 [11:29<08:22,  2.87it/s][A
step: 1851/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▋    [0m| 1851/3290 [11:29<08:22,  2.87it/s][A[2025-02-04 03:25:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 1851/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▋    [0m| 1852/3290 [11:29<08:39,  2.77it/s][A
step: 1852/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▋    [0m| 1852/3290 [11:29<08:39,  2.77it/s][A[2025-02-04 03:25:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1852/3290, eval_loss: 0.4741, eval_acc: 0.8734:  56%|[32m█████▋    [0m| 1853/3290 [11:30<08:34,  2.79it/s][A
step: 1853/3290, eval_loss: 0.4744, eval_acc: 0.8733:  56%|[32m█████▋    [0m| 1853/3290 [11:30<08:34,  2.79it/s][A[2025-02-04 03:25:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1853/3290, eval_loss: 0.4744, eval_acc: 0.8733:  56%|[32m█████▋    [0m| 1854/3290 [11:30<08:24,  2.85it/s][A
step: 1854/3290, eval_loss: 0.4745, eval_acc: 0.8733:  56%|[32m█████▋    [0m| 1854/3290 [11:30<08:24,  2.85it/s][A[2025-02-04 03:25:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1854/3290, eval_loss: 0.4745, eval_acc: 0.8733:  56%|[32m█████▋    [0m| 1855/3290 [11:30<07:47,  3.07it/s][A
step: 1855/3290, eval_loss: 0.4744, eval_acc: 0.8733:  56%|[32m█████▋    [0m| 1855/3290 [11:30<07:47,  3.07it/s][A[2025-02-04 03:25:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 1855/3290, eval_loss: 0.4744, eval_acc: 0.8733:  56%|[32m█████▋    [0m| 1856/3290 [11:31<07:28,  3.20it/s][A
step: 1856/3290, eval_loss: 0.4743, eval_acc: 0.8733:  56%|[32m█████▋    [0m| 1856/3290 [11:31<07:28,  3.20it/s][A[2025-02-04 03:25:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1856/3290, eval_loss: 0.4743, eval_acc: 0.8733:  56%|[32m█████▋    [0m| 1857/3290 [11:31<07:54,  3.02it/s][A
step: 1857/3290, eval_loss: 0.4743, eval_acc: 0.8733:  56%|[32m█████▋    [0m| 1857/3290 [11:31<07:54,  3.02it/s][A[2025-02-04 03:25:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 1857/3290, eval_loss: 0.4743, eval_acc: 0.8733:  56%|[32m█████▋    [0m| 1858/3290 [11:31<08:19,  2.87it/s][A
step: 1858/3290, eval_loss: 0.4745, eval_acc: 0.8733:  56%|[32m█████▋    [0m| 1858/3290 [11:31<08:19,  2.87it/s][A[2025-02-04 03:25:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1858/3290, eval_loss: 0.4745, eval_acc: 0.8733:  57%|[32m█████▋    [0m| 1859/3290 [11:32<09:22,  2.54it/s][A
step: 1859/3290, eval_loss: 0.4749, eval_acc: 0.8732:  57%|[32m█████▋    [0m| 1859/3290 [11:32<09:22,  2.54it/s][A[2025-02-04 03:25:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 1859/3290, eval_loss: 0.4749, eval_acc: 0.8732:  57%|[32m█████▋    [0m| 1860/3290 [11:32<09:51,  2.42it/s][A
step: 1860/3290, eval_loss: 0.4750, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1860/3290 [11:32<09:51,  2.42it/s][A[2025-02-04 03:25:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1860/3290, eval_loss: 0.4750, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1861/3290 [11:33<10:46,  2.21it/s][A
step: 1861/3290, eval_loss: 0.4751, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1861/3290 [11:33<10:46,  2.21it/s][A[2025-02-04 03:25:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1861/3290, eval_loss: 0.4751, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1862/3290 [11:33<11:03,  2.15it/s][A
step: 1862/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1862/3290 [11:33<11:03,  2.15it/s][A[2025-02-04 03:25:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 1862/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1863/3290 [11:34<10:23,  2.29it/s][A
step: 1863/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1863/3290 [11:34<10:23,  2.29it/s][A[2025-02-04 03:25:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1863/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1864/3290 [11:34<09:23,  2.53it/s][A
step: 1864/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1864/3290 [11:34<09:23,  2.53it/s][A[2025-02-04 03:25:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1864/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1865/3290 [11:34<08:19,  2.85it/s][A
step: 1865/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1865/3290 [11:34<08:19,  2.85it/s][A[2025-02-04 03:25:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 1865/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1866/3290 [11:35<08:43,  2.72it/s][A
step: 1866/3290, eval_loss: 0.4752, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1866/3290 [11:35<08:43,  2.72it/s][A[2025-02-04 03:25:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1866/3290, eval_loss: 0.4752, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1867/3290 [11:35<08:44,  2.72it/s][A
step: 1867/3290, eval_loss: 0.4751, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1867/3290 [11:35<08:44,  2.72it/s][A[2025-02-04 03:25:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 1867/3290, eval_loss: 0.4751, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1868/3290 [11:35<08:32,  2.78it/s][A
step: 1868/3290, eval_loss: 0.4750, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1868/3290 [11:35<08:32,  2.78it/s][A[2025-02-04 03:25:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1868/3290, eval_loss: 0.4750, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1869/3290 [11:36<08:31,  2.78it/s][A
step: 1869/3290, eval_loss: 0.4749, eval_acc: 0.8732:  57%|[32m█████▋    [0m| 1869/3290 [11:36<08:31,  2.78it/s][A[2025-02-04 03:25:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1869/3290, eval_loss: 0.4749, eval_acc: 0.8732:  57%|[32m█████▋    [0m| 1870/3290 [11:36<08:38,  2.74it/s][A
step: 1870/3290, eval_loss: 0.4750, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1870/3290 [11:36<08:38,  2.74it/s][A[2025-02-04 03:25:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 1870/3290, eval_loss: 0.4750, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1871/3290 [11:36<08:35,  2.75it/s][A
step: 1871/3290, eval_loss: 0.4750, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1871/3290 [11:36<08:35,  2.75it/s][A[2025-02-04 03:25:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1871/3290, eval_loss: 0.4750, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1872/3290 [11:37<08:03,  2.93it/s][A
step: 1872/3290, eval_loss: 0.4750, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1872/3290 [11:37<08:03,  2.93it/s][A[2025-02-04 03:25:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1872/3290, eval_loss: 0.4750, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1873/3290 [11:37<08:39,  2.73it/s][A
step: 1873/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1873/3290 [11:37<08:39,  2.73it/s][A[2025-02-04 03:25:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 1873/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1874/3290 [11:37<08:11,  2.88it/s][A
step: 1874/3290, eval_loss: 0.4752, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1874/3290 [11:37<08:11,  2.88it/s][A[2025-02-04 03:25:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1874/3290, eval_loss: 0.4752, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1875/3290 [11:38<08:18,  2.84it/s][A
step: 1875/3290, eval_loss: 0.4750, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1875/3290 [11:38<08:18,  2.84it/s][A[2025-02-04 03:25:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1875/3290, eval_loss: 0.4750, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1876/3290 [11:38<08:11,  2.88it/s][A
step: 1876/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1876/3290 [11:38<08:11,  2.88it/s][A[2025-02-04 03:25:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 1876/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1877/3290 [11:39<08:42,  2.71it/s][A
step: 1877/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1877/3290 [11:39<08:42,  2.71it/s][A[2025-02-04 03:25:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1877/3290, eval_loss: 0.4753, eval_acc: 0.8731:  57%|[32m█████▋    [0m| 1878/3290 [11:39<09:22,  2.51it/s][A
step: 1878/3290, eval_loss: 0.4755, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1878/3290 [11:39<09:22,  2.51it/s][A[2025-02-04 03:25:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 1878/3290, eval_loss: 0.4755, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1879/3290 [11:39<08:35,  2.74it/s][A
step: 1879/3290, eval_loss: 0.4756, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1879/3290 [11:39<08:35,  2.74it/s][A[2025-02-04 03:25:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1879/3290, eval_loss: 0.4756, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1880/3290 [11:40<09:21,  2.51it/s][A
step: 1880/3290, eval_loss: 0.4755, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1880/3290 [11:40<09:21,  2.51it/s][A[2025-02-04 03:25:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 1880/3290, eval_loss: 0.4755, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1881/3290 [11:40<09:44,  2.41it/s][A
step: 1881/3290, eval_loss: 0.4756, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1881/3290 [11:40<09:44,  2.41it/s][A[2025-02-04 03:25:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1881/3290, eval_loss: 0.4756, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1882/3290 [11:41<09:54,  2.37it/s][A
step: 1882/3290, eval_loss: 0.4754, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1882/3290 [11:41<09:54,  2.37it/s][A[2025-02-04 03:25:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1882/3290, eval_loss: 0.4754, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1883/3290 [11:41<09:43,  2.41it/s][A
step: 1883/3290, eval_loss: 0.4756, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1883/3290 [11:41<09:43,  2.41it/s][A[2025-02-04 03:25:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 1883/3290, eval_loss: 0.4756, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1884/3290 [11:42<09:41,  2.42it/s][A
step: 1884/3290, eval_loss: 0.4756, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1884/3290 [11:42<09:41,  2.42it/s][A[2025-02-04 03:25:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1884/3290, eval_loss: 0.4756, eval_acc: 0.8730:  57%|[32m█████▋    [0m| 1885/3290 [11:42<09:30,  2.46it/s][A
step: 1885/3290, eval_loss: 0.4758, eval_acc: 0.8729:  57%|[32m█████▋    [0m| 1885/3290 [11:42<09:30,  2.46it/s][A[2025-02-04 03:25:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1885/3290, eval_loss: 0.4758, eval_acc: 0.8729:  57%|[32m█████▋    [0m| 1886/3290 [11:42<09:04,  2.58it/s][A
step: 1886/3290, eval_loss: 0.4760, eval_acc: 0.8728:  57%|[32m█████▋    [0m| 1886/3290 [11:42<09:04,  2.58it/s][A[2025-02-04 03:25:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 1886/3290, eval_loss: 0.4760, eval_acc: 0.8728:  57%|[32m█████▋    [0m| 1887/3290 [11:43<08:26,  2.77it/s][A
step: 1887/3290, eval_loss: 0.4761, eval_acc: 0.8728:  57%|[32m█████▋    [0m| 1887/3290 [11:43<08:26,  2.77it/s][A[2025-02-04 03:25:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1887/3290, eval_loss: 0.4761, eval_acc: 0.8728:  57%|[32m█████▋    [0m| 1888/3290 [11:43<07:43,  3.03it/s][A
step: 1888/3290, eval_loss: 0.4760, eval_acc: 0.8728:  57%|[32m█████▋    [0m| 1888/3290 [11:43<07:43,  3.03it/s][A[2025-02-04 03:25:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 1888/3290, eval_loss: 0.4760, eval_acc: 0.8728:  57%|[32m█████▋    [0m| 1889/3290 [11:43<09:00,  2.59it/s][A
step: 1889/3290, eval_loss: 0.4762, eval_acc: 0.8728:  57%|[32m█████▋    [0m| 1889/3290 [11:43<09:00,  2.59it/s][A[2025-02-04 03:25:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1889/3290, eval_loss: 0.4762, eval_acc: 0.8728:  57%|[32m█████▋    [0m| 1890/3290 [11:44<09:54,  2.35it/s][A
step: 1890/3290, eval_loss: 0.4764, eval_acc: 0.8728:  57%|[32m█████▋    [0m| 1890/3290 [11:44<09:54,  2.35it/s][A[2025-02-04 03:25:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 1890/3290, eval_loss: 0.4764, eval_acc: 0.8728:  57%|[32m█████▋    [0m| 1891/3290 [11:44<09:46,  2.38it/s][A
step: 1891/3290, eval_loss: 0.4764, eval_acc: 0.8728:  57%|[32m█████▋    [0m| 1891/3290 [11:44<09:46,  2.38it/s][A[2025-02-04 03:25:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1891/3290, eval_loss: 0.4764, eval_acc: 0.8728:  58%|[32m█████▊    [0m| 1892/3290 [11:45<10:16,  2.27it/s][A
step: 1892/3290, eval_loss: 0.4766, eval_acc: 0.8727:  58%|[32m█████▊    [0m| 1892/3290 [11:45<10:16,  2.27it/s][A[2025-02-04 03:25:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1892/3290, eval_loss: 0.4766, eval_acc: 0.8727:  58%|[32m█████▊    [0m| 1893/3290 [11:45<10:22,  2.24it/s][A
step: 1893/3290, eval_loss: 0.4767, eval_acc: 0.8727:  58%|[32m█████▊    [0m| 1893/3290 [11:45<10:22,  2.24it/s][A[2025-02-04 03:25:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 1893/3290, eval_loss: 0.4767, eval_acc: 0.8727:  58%|[32m█████▊    [0m| 1894/3290 [11:46<09:31,  2.44it/s][A
step: 1894/3290, eval_loss: 0.4765, eval_acc: 0.8727:  58%|[32m█████▊    [0m| 1894/3290 [11:46<09:31,  2.44it/s][A[2025-02-04 03:25:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1894/3290, eval_loss: 0.4765, eval_acc: 0.8727:  58%|[32m█████▊    [0m| 1895/3290 [11:46<09:42,  2.40it/s][A
step: 1895/3290, eval_loss: 0.4764, eval_acc: 0.8727:  58%|[32m█████▊    [0m| 1895/3290 [11:46<09:42,  2.40it/s][A[2025-02-04 03:25:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 1895/3290, eval_loss: 0.4764, eval_acc: 0.8727:  58%|[32m█████▊    [0m| 1896/3290 [11:46<08:56,  2.60it/s][A
step: 1896/3290, eval_loss: 0.4763, eval_acc: 0.8728:  58%|[32m█████▊    [0m| 1896/3290 [11:46<08:56,  2.60it/s][A[2025-02-04 03:25:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1896/3290, eval_loss: 0.4763, eval_acc: 0.8728:  58%|[32m█████▊    [0m| 1897/3290 [11:47<09:30,  2.44it/s][A
step: 1897/3290, eval_loss: 0.4766, eval_acc: 0.8727:  58%|[32m█████▊    [0m| 1897/3290 [11:47<09:30,  2.44it/s][A[2025-02-04 03:25:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1897/3290, eval_loss: 0.4766, eval_acc: 0.8727:  58%|[32m█████▊    [0m| 1898/3290 [11:47<08:52,  2.62it/s][A
step: 1898/3290, eval_loss: 0.4768, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1898/3290 [11:47<08:52,  2.62it/s][A[2025-02-04 03:25:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 1898/3290, eval_loss: 0.4768, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1899/3290 [11:47<08:56,  2.59it/s][A
step: 1899/3290, eval_loss: 0.4767, eval_acc: 0.8727:  58%|[32m█████▊    [0m| 1899/3290 [11:47<08:56,  2.59it/s][A[2025-02-04 03:25:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1899/3290, eval_loss: 0.4767, eval_acc: 0.8727:  58%|[32m█████▊    [0m| 1900/3290 [11:48<08:43,  2.65it/s][A
step: 1900/3290, eval_loss: 0.4769, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1900/3290 [11:48<08:43,  2.65it/s][A[2025-02-04 03:25:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 1900/3290, eval_loss: 0.4769, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1901/3290 [11:48<10:35,  2.19it/s][A
step: 1901/3290, eval_loss: 0.4770, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1901/3290 [11:48<10:35,  2.19it/s][A[2025-02-04 03:25:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1901/3290, eval_loss: 0.4770, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1902/3290 [11:49<09:25,  2.45it/s][A
step: 1902/3290, eval_loss: 0.4770, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1902/3290 [11:49<09:25,  2.45it/s][A[2025-02-04 03:25:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1902/3290, eval_loss: 0.4770, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1903/3290 [11:49<08:11,  2.82it/s][A
step: 1903/3290, eval_loss: 0.4769, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1903/3290 [11:49<08:11,  2.82it/s][A[2025-02-04 03:25:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1903/3290, eval_loss: 0.4769, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1904/3290 [11:49<07:28,  3.09it/s][A
step: 1904/3290, eval_loss: 0.4769, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1904/3290 [11:49<07:28,  3.09it/s][A[2025-02-04 03:25:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 1904/3290, eval_loss: 0.4769, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1905/3290 [11:50<07:27,  3.09it/s][A
step: 1905/3290, eval_loss: 0.4768, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1905/3290 [11:50<07:27,  3.09it/s][A[2025-02-04 03:25:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1905/3290, eval_loss: 0.4768, eval_acc: 0.8726:  58%|[32m█████▊    [0m| 1906/3290 [11:50<07:12,  3.20it/s][A
step: 1906/3290, eval_loss: 0.4773, eval_acc: 0.8725:  58%|[32m█████▊    [0m| 1906/3290 [11:50<07:12,  3.20it/s][A[2025-02-04 03:25:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1906/3290, eval_loss: 0.4773, eval_acc: 0.8725:  58%|[32m█████▊    [0m| 1907/3290 [11:50<06:51,  3.36it/s][A
step: 1907/3290, eval_loss: 0.4776, eval_acc: 0.8724:  58%|[32m█████▊    [0m| 1907/3290 [11:50<06:51,  3.36it/s][A[2025-02-04 03:25:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 1907/3290, eval_loss: 0.4776, eval_acc: 0.8724:  58%|[32m█████▊    [0m| 1908/3290 [11:50<06:46,  3.40it/s][A
step: 1908/3290, eval_loss: 0.4777, eval_acc: 0.8724:  58%|[32m█████▊    [0m| 1908/3290 [11:50<06:46,  3.40it/s][A[2025-02-04 03:25:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1908/3290, eval_loss: 0.4777, eval_acc: 0.8724:  58%|[32m█████▊    [0m| 1909/3290 [11:51<06:41,  3.44it/s][A
step: 1909/3290, eval_loss: 0.4775, eval_acc: 0.8724:  58%|[32m█████▊    [0m| 1909/3290 [11:51<06:41,  3.44it/s][A[2025-02-04 03:25:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1909/3290, eval_loss: 0.4775, eval_acc: 0.8724:  58%|[32m█████▊    [0m| 1910/3290 [11:51<07:06,  3.23it/s][A
step: 1910/3290, eval_loss: 0.4777, eval_acc: 0.8724:  58%|[32m█████▊    [0m| 1910/3290 [11:51<07:06,  3.23it/s][A[2025-02-04 03:25:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 1910/3290, eval_loss: 0.4777, eval_acc: 0.8724:  58%|[32m█████▊    [0m| 1911/3290 [11:51<07:56,  2.89it/s][A
step: 1911/3290, eval_loss: 0.4781, eval_acc: 0.8723:  58%|[32m█████▊    [0m| 1911/3290 [11:51<07:56,  2.89it/s][A[2025-02-04 03:25:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1911/3290, eval_loss: 0.4781, eval_acc: 0.8723:  58%|[32m█████▊    [0m| 1912/3290 [11:52<07:49,  2.93it/s][A
step: 1912/3290, eval_loss: 0.4781, eval_acc: 0.8723:  58%|[32m█████▊    [0m| 1912/3290 [11:52<07:49,  2.93it/s][A[2025-02-04 03:25:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1912/3290, eval_loss: 0.4781, eval_acc: 0.8723:  58%|[32m█████▊    [0m| 1913/3290 [11:52<08:18,  2.76it/s][A
step: 1913/3290, eval_loss: 0.4785, eval_acc: 0.8723:  58%|[32m█████▊    [0m| 1913/3290 [11:52<08:18,  2.76it/s][A[2025-02-04 03:25:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 1913/3290, eval_loss: 0.4785, eval_acc: 0.8723:  58%|[32m█████▊    [0m| 1914/3290 [11:52<07:55,  2.90it/s][A
step: 1914/3290, eval_loss: 0.4785, eval_acc: 0.8723:  58%|[32m█████▊    [0m| 1914/3290 [11:52<07:55,  2.90it/s][A[2025-02-04 03:25:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1914/3290, eval_loss: 0.4785, eval_acc: 0.8723:  58%|[32m█████▊    [0m| 1915/3290 [11:53<07:22,  3.11it/s][A
step: 1915/3290, eval_loss: 0.4787, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1915/3290 [11:53<07:22,  3.11it/s][A[2025-02-04 03:25:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1915/3290, eval_loss: 0.4787, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1916/3290 [11:53<07:20,  3.12it/s][A
step: 1916/3290, eval_loss: 0.4785, eval_acc: 0.8723:  58%|[32m█████▊    [0m| 1916/3290 [11:53<07:20,  3.12it/s][A[2025-02-04 03:25:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 1916/3290, eval_loss: 0.4785, eval_acc: 0.8723:  58%|[32m█████▊    [0m| 1917/3290 [11:53<07:31,  3.04it/s][A
step: 1917/3290, eval_loss: 0.4785, eval_acc: 0.8723:  58%|[32m█████▊    [0m| 1917/3290 [11:53<07:31,  3.04it/s][A[2025-02-04 03:25:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1917/3290, eval_loss: 0.4785, eval_acc: 0.8723:  58%|[32m█████▊    [0m| 1918/3290 [11:54<07:24,  3.09it/s][A
step: 1918/3290, eval_loss: 0.4785, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1918/3290 [11:54<07:24,  3.09it/s][A[2025-02-04 03:25:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1918/3290, eval_loss: 0.4785, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1919/3290 [11:54<07:13,  3.16it/s][A
step: 1919/3290, eval_loss: 0.4788, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1919/3290 [11:54<07:13,  3.16it/s][A[2025-02-04 03:25:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 1919/3290, eval_loss: 0.4788, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1920/3290 [11:54<07:29,  3.05it/s][A
step: 1920/3290, eval_loss: 0.4789, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1920/3290 [11:54<07:29,  3.05it/s][A[2025-02-04 03:25:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1920/3290, eval_loss: 0.4789, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1921/3290 [11:55<07:49,  2.92it/s][A
step: 1921/3290, eval_loss: 0.4791, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1921/3290 [11:55<07:49,  2.92it/s][A[2025-02-04 03:25:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1921/3290, eval_loss: 0.4791, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1922/3290 [11:55<07:39,  2.98it/s][A
step: 1922/3290, eval_loss: 0.4791, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1922/3290 [11:55<07:39,  2.98it/s][A[2025-02-04 03:25:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 1922/3290, eval_loss: 0.4791, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1923/3290 [11:55<07:32,  3.02it/s][A
step: 1923/3290, eval_loss: 0.4790, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1923/3290 [11:55<07:32,  3.02it/s][A[2025-02-04 03:25:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1923/3290, eval_loss: 0.4790, eval_acc: 0.8722:  58%|[32m█████▊    [0m| 1924/3290 [11:56<07:52,  2.89it/s][A
step: 1924/3290, eval_loss: 0.4792, eval_acc: 0.8721:  58%|[32m█████▊    [0m| 1924/3290 [11:56<07:52,  2.89it/s][A[2025-02-04 03:25:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1924/3290, eval_loss: 0.4792, eval_acc: 0.8721:  59%|[32m█████▊    [0m| 1925/3290 [11:56<07:43,  2.95it/s][A
step: 1925/3290, eval_loss: 0.4791, eval_acc: 0.8721:  59%|[32m█████▊    [0m| 1925/3290 [11:56<07:43,  2.95it/s][A[2025-02-04 03:25:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 1925/3290, eval_loss: 0.4791, eval_acc: 0.8721:  59%|[32m█████▊    [0m| 1926/3290 [11:56<07:29,  3.04it/s][A
step: 1926/3290, eval_loss: 0.4790, eval_acc: 0.8722:  59%|[32m█████▊    [0m| 1926/3290 [11:56<07:29,  3.04it/s][A[2025-02-04 03:25:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1926/3290, eval_loss: 0.4790, eval_acc: 0.8722:  59%|[32m█████▊    [0m| 1927/3290 [11:57<07:12,  3.15it/s][A
step: 1927/3290, eval_loss: 0.4788, eval_acc: 0.8722:  59%|[32m█████▊    [0m| 1927/3290 [11:57<07:12,  3.15it/s][A[2025-02-04 03:25:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1927/3290, eval_loss: 0.4788, eval_acc: 0.8722:  59%|[32m█████▊    [0m| 1928/3290 [11:57<08:53,  2.55it/s][A
step: 1928/3290, eval_loss: 0.4792, eval_acc: 0.8721:  59%|[32m█████▊    [0m| 1928/3290 [11:57<08:53,  2.55it/s][A[2025-02-04 03:25:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 1928/3290, eval_loss: 0.4792, eval_acc: 0.8721:  59%|[32m█████▊    [0m| 1929/3290 [11:58<08:25,  2.69it/s][A
step: 1929/3290, eval_loss: 0.4791, eval_acc: 0.8721:  59%|[32m█████▊    [0m| 1929/3290 [11:58<08:25,  2.69it/s][A[2025-02-04 03:25:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1929/3290, eval_loss: 0.4791, eval_acc: 0.8721:  59%|[32m█████▊    [0m| 1930/3290 [11:58<08:20,  2.72it/s][A
step: 1930/3290, eval_loss: 0.4790, eval_acc: 0.8721:  59%|[32m█████▊    [0m| 1930/3290 [11:58<08:20,  2.72it/s][A[2025-02-04 03:25:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1930/3290, eval_loss: 0.4790, eval_acc: 0.8721:  59%|[32m█████▊    [0m| 1931/3290 [11:58<08:00,  2.83it/s][A
step: 1931/3290, eval_loss: 0.4790, eval_acc: 0.8722:  59%|[32m█████▊    [0m| 1931/3290 [11:58<08:00,  2.83it/s][A[2025-02-04 03:25:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 1931/3290, eval_loss: 0.4790, eval_acc: 0.8722:  59%|[32m█████▊    [0m| 1932/3290 [11:59<08:19,  2.72it/s][A
step: 1932/3290, eval_loss: 0.4789, eval_acc: 0.8722:  59%|[32m█████▊    [0m| 1932/3290 [11:59<08:19,  2.72it/s][A[2025-02-04 03:25:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1932/3290, eval_loss: 0.4789, eval_acc: 0.8722:  59%|[32m█████▉    [0m| 1933/3290 [11:59<07:58,  2.84it/s][A
step: 1933/3290, eval_loss: 0.4787, eval_acc: 0.8722:  59%|[32m█████▉    [0m| 1933/3290 [11:59<07:58,  2.84it/s][A[2025-02-04 03:25:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1933/3290, eval_loss: 0.4787, eval_acc: 0.8722:  59%|[32m█████▉    [0m| 1934/3290 [11:59<07:23,  3.06it/s][A
step: 1934/3290, eval_loss: 0.4786, eval_acc: 0.8722:  59%|[32m█████▉    [0m| 1934/3290 [11:59<07:23,  3.06it/s][A[2025-02-04 03:25:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 1934/3290, eval_loss: 0.4786, eval_acc: 0.8722:  59%|[32m█████▉    [0m| 1935/3290 [12:00<07:31,  3.00it/s][A
step: 1935/3290, eval_loss: 0.4786, eval_acc: 0.8722:  59%|[32m█████▉    [0m| 1935/3290 [12:00<07:31,  3.00it/s][A[2025-02-04 03:25:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1935/3290, eval_loss: 0.4786, eval_acc: 0.8722:  59%|[32m█████▉    [0m| 1936/3290 [12:00<06:57,  3.24it/s][A
step: 1936/3290, eval_loss: 0.4784, eval_acc: 0.8723:  59%|[32m█████▉    [0m| 1936/3290 [12:00<06:57,  3.24it/s][A[2025-02-04 03:25:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1936/3290, eval_loss: 0.4784, eval_acc: 0.8723:  59%|[32m█████▉    [0m| 1937/3290 [12:00<07:29,  3.01it/s][A
step: 1937/3290, eval_loss: 0.4785, eval_acc: 0.8723:  59%|[32m█████▉    [0m| 1937/3290 [12:00<07:29,  3.01it/s][A[2025-02-04 03:25:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 1937/3290, eval_loss: 0.4785, eval_acc: 0.8723:  59%|[32m█████▉    [0m| 1938/3290 [12:01<07:22,  3.05it/s][A
step: 1938/3290, eval_loss: 0.4785, eval_acc: 0.8722:  59%|[32m█████▉    [0m| 1938/3290 [12:01<07:22,  3.05it/s][A[2025-02-04 03:25:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1938/3290, eval_loss: 0.4785, eval_acc: 0.8722:  59%|[32m█████▉    [0m| 1939/3290 [12:01<07:15,  3.10it/s][A
step: 1939/3290, eval_loss: 0.4784, eval_acc: 0.8723:  59%|[32m█████▉    [0m| 1939/3290 [12:01<07:15,  3.10it/s][A[2025-02-04 03:25:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1939/3290, eval_loss: 0.4784, eval_acc: 0.8723:  59%|[32m█████▉    [0m| 1940/3290 [12:01<07:46,  2.89it/s][A
step: 1940/3290, eval_loss: 0.4783, eval_acc: 0.8723:  59%|[32m█████▉    [0m| 1940/3290 [12:01<07:46,  2.89it/s][A[2025-02-04 03:25:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 1940/3290, eval_loss: 0.4783, eval_acc: 0.8723:  59%|[32m█████▉    [0m| 1941/3290 [12:02<08:16,  2.72it/s][A
step: 1941/3290, eval_loss: 0.4781, eval_acc: 0.8723:  59%|[32m█████▉    [0m| 1941/3290 [12:02<08:16,  2.72it/s][A[2025-02-04 03:25:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1941/3290, eval_loss: 0.4781, eval_acc: 0.8723:  59%|[32m█████▉    [0m| 1942/3290 [12:02<08:36,  2.61it/s][A
step: 1942/3290, eval_loss: 0.4782, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1942/3290 [12:02<08:36,  2.61it/s][A[2025-02-04 03:25:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 1942/3290, eval_loss: 0.4782, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1943/3290 [12:03<08:50,  2.54it/s][A
step: 1943/3290, eval_loss: 0.4782, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1943/3290 [12:03<08:50,  2.54it/s][A[2025-02-04 03:25:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1943/3290, eval_loss: 0.4782, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1944/3290 [12:03<09:17,  2.41it/s][A
step: 1944/3290, eval_loss: 0.4780, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1944/3290 [12:03<09:17,  2.41it/s][A[2025-02-04 03:25:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 1944/3290, eval_loss: 0.4780, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1945/3290 [12:03<09:07,  2.46it/s][A
step: 1945/3290, eval_loss: 0.4780, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1945/3290 [12:03<09:07,  2.46it/s][A[2025-02-04 03:25:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1945/3290, eval_loss: 0.4780, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1946/3290 [12:04<08:39,  2.59it/s][A
step: 1946/3290, eval_loss: 0.4779, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1946/3290 [12:04<08:39,  2.59it/s][A[2025-02-04 03:25:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1946/3290, eval_loss: 0.4779, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1947/3290 [12:04<09:11,  2.44it/s][A
step: 1947/3290, eval_loss: 0.4779, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1947/3290 [12:04<09:11,  2.44it/s][A[2025-02-04 03:25:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 1947/3290, eval_loss: 0.4779, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1948/3290 [12:05<08:50,  2.53it/s][A
step: 1948/3290, eval_loss: 0.4778, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1948/3290 [12:05<08:50,  2.53it/s][A[2025-02-04 03:25:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1948/3290, eval_loss: 0.4778, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1949/3290 [12:05<08:15,  2.71it/s][A
step: 1949/3290, eval_loss: 0.4779, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1949/3290 [12:05<08:15,  2.71it/s][A[2025-02-04 03:25:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1949/3290, eval_loss: 0.4779, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1950/3290 [12:05<08:29,  2.63it/s][A
step: 1950/3290, eval_loss: 0.4777, eval_acc: 0.8725:  59%|[32m█████▉    [0m| 1950/3290 [12:05<08:29,  2.63it/s][A[2025-02-04 03:25:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 1950/3290, eval_loss: 0.4777, eval_acc: 0.8725:  59%|[32m█████▉    [0m| 1951/3290 [12:06<08:34,  2.60it/s][A
step: 1951/3290, eval_loss: 0.4778, eval_acc: 0.8725:  59%|[32m█████▉    [0m| 1951/3290 [12:06<08:34,  2.60it/s][A[2025-02-04 03:26:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1951/3290, eval_loss: 0.4778, eval_acc: 0.8725:  59%|[32m█████▉    [0m| 1952/3290 [12:06<08:17,  2.69it/s][A
step: 1952/3290, eval_loss: 0.4777, eval_acc: 0.8725:  59%|[32m█████▉    [0m| 1952/3290 [12:06<08:17,  2.69it/s][A[2025-02-04 03:26:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 1952/3290, eval_loss: 0.4777, eval_acc: 0.8725:  59%|[32m█████▉    [0m| 1953/3290 [12:06<08:05,  2.75it/s][A
step: 1953/3290, eval_loss: 0.4775, eval_acc: 0.8725:  59%|[32m█████▉    [0m| 1953/3290 [12:06<08:05,  2.75it/s][A[2025-02-04 03:26:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1953/3290, eval_loss: 0.4775, eval_acc: 0.8725:  59%|[32m█████▉    [0m| 1954/3290 [12:07<08:01,  2.77it/s][A
step: 1954/3290, eval_loss: 0.4776, eval_acc: 0.8725:  59%|[32m█████▉    [0m| 1954/3290 [12:07<08:01,  2.77it/s][A[2025-02-04 03:26:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1954/3290, eval_loss: 0.4776, eval_acc: 0.8725:  59%|[32m█████▉    [0m| 1955/3290 [12:07<07:31,  2.95it/s][A
step: 1955/3290, eval_loss: 0.4776, eval_acc: 0.8725:  59%|[32m█████▉    [0m| 1955/3290 [12:07<07:31,  2.95it/s][A[2025-02-04 03:26:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1955/3290, eval_loss: 0.4776, eval_acc: 0.8725:  59%|[32m█████▉    [0m| 1956/3290 [12:07<07:14,  3.07it/s][A
step: 1956/3290, eval_loss: 0.4778, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1956/3290 [12:07<07:14,  3.07it/s][A[2025-02-04 03:26:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 1956/3290, eval_loss: 0.4778, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1957/3290 [12:08<07:12,  3.08it/s][A
step: 1957/3290, eval_loss: 0.4777, eval_acc: 0.8724:  59%|[32m█████▉    [0m| 1957/3290 [12:08<07:12,  3.08it/s][A[2025-02-04 03:26:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1957/3290, eval_loss: 0.4777, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1958/3290 [12:08<08:01,  2.77it/s][A
step: 1958/3290, eval_loss: 0.4779, eval_acc: 0.8723:  60%|[32m█████▉    [0m| 1958/3290 [12:08<08:01,  2.77it/s][A[2025-02-04 03:26:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1958/3290, eval_loss: 0.4779, eval_acc: 0.8723:  60%|[32m█████▉    [0m| 1959/3290 [12:08<07:31,  2.95it/s][A
step: 1959/3290, eval_loss: 0.4777, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1959/3290 [12:08<07:31,  2.95it/s][A[2025-02-04 03:26:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 1959/3290, eval_loss: 0.4777, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1960/3290 [12:09<06:55,  3.20it/s][A
step: 1960/3290, eval_loss: 0.4777, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1960/3290 [12:09<06:55,  3.20it/s][A[2025-02-04 03:26:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1960/3290, eval_loss: 0.4777, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1961/3290 [12:09<06:23,  3.46it/s][A
step: 1961/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1961/3290 [12:09<06:23,  3.46it/s][A[2025-02-04 03:26:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1961/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1962/3290 [12:09<06:31,  3.39it/s][A
step: 1962/3290, eval_loss: 0.4775, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1962/3290 [12:09<06:31,  3.39it/s][A[2025-02-04 03:26:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 1962/3290, eval_loss: 0.4775, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1963/3290 [12:09<06:51,  3.23it/s][A
step: 1963/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1963/3290 [12:09<06:51,  3.23it/s][A[2025-02-04 03:26:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1963/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1964/3290 [12:10<07:04,  3.12it/s][A
step: 1964/3290, eval_loss: 0.4777, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1964/3290 [12:10<07:04,  3.12it/s][A[2025-02-04 03:26:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1964/3290, eval_loss: 0.4777, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1965/3290 [12:10<07:36,  2.90it/s][A
step: 1965/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1965/3290 [12:10<07:36,  2.90it/s][A[2025-02-04 03:26:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 1965/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1966/3290 [12:10<07:05,  3.11it/s][A
step: 1966/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1966/3290 [12:10<07:05,  3.11it/s][A[2025-02-04 03:26:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1966/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1967/3290 [12:11<07:05,  3.11it/s][A
step: 1967/3290, eval_loss: 0.4775, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1967/3290 [12:11<07:05,  3.11it/s][A[2025-02-04 03:26:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1967/3290, eval_loss: 0.4775, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1968/3290 [12:11<07:04,  3.12it/s][A
step: 1968/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1968/3290 [12:11<07:04,  3.12it/s][A[2025-02-04 03:26:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 1968/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1969/3290 [12:11<07:13,  3.05it/s][A
step: 1969/3290, eval_loss: 0.4775, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1969/3290 [12:11<07:13,  3.05it/s][A[2025-02-04 03:26:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1969/3290, eval_loss: 0.4775, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1970/3290 [12:12<07:12,  3.05it/s][A
step: 1970/3290, eval_loss: 0.4777, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1970/3290 [12:12<07:12,  3.05it/s][A[2025-02-04 03:26:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1970/3290, eval_loss: 0.4777, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1971/3290 [12:12<07:06,  3.09it/s][A
step: 1971/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1971/3290 [12:12<07:06,  3.09it/s][A[2025-02-04 03:26:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 1971/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1972/3290 [12:12<06:40,  3.29it/s][A
step: 1972/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1972/3290 [12:12<06:40,  3.29it/s][A[2025-02-04 03:26:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1972/3290, eval_loss: 0.4776, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1973/3290 [12:13<07:36,  2.89it/s][A
step: 1973/3290, eval_loss: 0.4774, eval_acc: 0.8724:  60%|[32m█████▉    [0m| 1973/3290 [12:13<07:36,  2.89it/s][A[2025-02-04 03:26:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1973/3290, eval_loss: 0.4774, eval_acc: 0.8724:  60%|[32m██████    [0m| 1974/3290 [12:13<08:08,  2.69it/s][A
step: 1974/3290, eval_loss: 0.4773, eval_acc: 0.8725:  60%|[32m██████    [0m| 1974/3290 [12:13<08:08,  2.69it/s][A[2025-02-04 03:26:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 1974/3290, eval_loss: 0.4773, eval_acc: 0.8725:  60%|[32m██████    [0m| 1975/3290 [12:14<08:23,  2.61it/s][A
step: 1975/3290, eval_loss: 0.4774, eval_acc: 0.8725:  60%|[32m██████    [0m| 1975/3290 [12:14<08:23,  2.61it/s][A[2025-02-04 03:26:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1975/3290, eval_loss: 0.4774, eval_acc: 0.8725:  60%|[32m██████    [0m| 1976/3290 [12:14<08:41,  2.52it/s][A
step: 1976/3290, eval_loss: 0.4773, eval_acc: 0.8725:  60%|[32m██████    [0m| 1976/3290 [12:14<08:41,  2.52it/s][A[2025-02-04 03:26:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 1976/3290, eval_loss: 0.4773, eval_acc: 0.8725:  60%|[32m██████    [0m| 1977/3290 [12:15<08:50,  2.47it/s][A
step: 1977/3290, eval_loss: 0.4772, eval_acc: 0.8725:  60%|[32m██████    [0m| 1977/3290 [12:15<08:50,  2.47it/s][A[2025-02-04 03:26:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1977/3290, eval_loss: 0.4772, eval_acc: 0.8725:  60%|[32m██████    [0m| 1978/3290 [12:15<08:58,  2.43it/s][A
step: 1978/3290, eval_loss: 0.4773, eval_acc: 0.8725:  60%|[32m██████    [0m| 1978/3290 [12:15<08:58,  2.43it/s][A[2025-02-04 03:26:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1978/3290, eval_loss: 0.4773, eval_acc: 0.8725:  60%|[32m██████    [0m| 1979/3290 [12:15<08:40,  2.52it/s][A
step: 1979/3290, eval_loss: 0.4773, eval_acc: 0.8725:  60%|[32m██████    [0m| 1979/3290 [12:15<08:40,  2.52it/s][A[2025-02-04 03:26:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 1979/3290, eval_loss: 0.4773, eval_acc: 0.8725:  60%|[32m██████    [0m| 1980/3290 [12:16<08:20,  2.62it/s][A
step: 1980/3290, eval_loss: 0.4773, eval_acc: 0.8725:  60%|[32m██████    [0m| 1980/3290 [12:16<08:20,  2.62it/s][A[2025-02-04 03:26:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1980/3290, eval_loss: 0.4773, eval_acc: 0.8725:  60%|[32m██████    [0m| 1981/3290 [12:16<08:38,  2.53it/s][A
step: 1981/3290, eval_loss: 0.4772, eval_acc: 0.8725:  60%|[32m██████    [0m| 1981/3290 [12:16<08:38,  2.53it/s][A[2025-02-04 03:26:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 1981/3290, eval_loss: 0.4772, eval_acc: 0.8725:  60%|[32m██████    [0m| 1982/3290 [12:16<08:01,  2.72it/s][A
step: 1982/3290, eval_loss: 0.4771, eval_acc: 0.8725:  60%|[32m██████    [0m| 1982/3290 [12:16<08:01,  2.72it/s][A[2025-02-04 03:26:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1982/3290, eval_loss: 0.4771, eval_acc: 0.8725:  60%|[32m██████    [0m| 1983/3290 [12:17<07:29,  2.91it/s][A
step: 1983/3290, eval_loss: 0.4770, eval_acc: 0.8726:  60%|[32m██████    [0m| 1983/3290 [12:17<07:29,  2.91it/s][A[2025-02-04 03:26:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1983/3290, eval_loss: 0.4770, eval_acc: 0.8726:  60%|[32m██████    [0m| 1984/3290 [12:17<07:22,  2.95it/s][A
step: 1984/3290, eval_loss: 0.4769, eval_acc: 0.8726:  60%|[32m██████    [0m| 1984/3290 [12:17<07:22,  2.95it/s][A[2025-02-04 03:26:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 1984/3290, eval_loss: 0.4769, eval_acc: 0.8726:  60%|[32m██████    [0m| 1985/3290 [12:17<07:41,  2.83it/s][A
step: 1985/3290, eval_loss: 0.4768, eval_acc: 0.8726:  60%|[32m██████    [0m| 1985/3290 [12:17<07:41,  2.83it/s][A[2025-02-04 03:26:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1985/3290, eval_loss: 0.4768, eval_acc: 0.8726:  60%|[32m██████    [0m| 1986/3290 [12:18<07:11,  3.02it/s][A
step: 1986/3290, eval_loss: 0.4766, eval_acc: 0.8726:  60%|[32m██████    [0m| 1986/3290 [12:18<07:11,  3.02it/s][A[2025-02-04 03:26:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1986/3290, eval_loss: 0.4766, eval_acc: 0.8726:  60%|[32m██████    [0m| 1987/3290 [12:18<07:15,  2.99it/s][A
step: 1987/3290, eval_loss: 0.4766, eval_acc: 0.8726:  60%|[32m██████    [0m| 1987/3290 [12:18<07:15,  2.99it/s][A[2025-02-04 03:26:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1987/3290, eval_loss: 0.4766, eval_acc: 0.8726:  60%|[32m██████    [0m| 1988/3290 [12:18<07:07,  3.05it/s][A
step: 1988/3290, eval_loss: 0.4766, eval_acc: 0.8726:  60%|[32m██████    [0m| 1988/3290 [12:18<07:07,  3.05it/s][A[2025-02-04 03:26:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 1988/3290, eval_loss: 0.4766, eval_acc: 0.8726:  60%|[32m██████    [0m| 1989/3290 [12:19<07:18,  2.97it/s][A
step: 1989/3290, eval_loss: 0.4765, eval_acc: 0.8726:  60%|[32m██████    [0m| 1989/3290 [12:19<07:18,  2.97it/s][A[2025-02-04 03:26:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1989/3290, eval_loss: 0.4765, eval_acc: 0.8726:  60%|[32m██████    [0m| 1990/3290 [12:19<08:02,  2.69it/s][A
step: 1990/3290, eval_loss: 0.4764, eval_acc: 0.8726:  60%|[32m██████    [0m| 1990/3290 [12:19<08:02,  2.69it/s][A[2025-02-04 03:26:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 1990/3290, eval_loss: 0.4764, eval_acc: 0.8726:  61%|[32m██████    [0m| 1991/3290 [12:20<08:10,  2.65it/s][A
step: 1991/3290, eval_loss: 0.4763, eval_acc: 0.8727:  61%|[32m██████    [0m| 1991/3290 [12:20<08:10,  2.65it/s][A[2025-02-04 03:26:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1991/3290, eval_loss: 0.4763, eval_acc: 0.8727:  61%|[32m██████    [0m| 1992/3290 [12:20<08:17,  2.61it/s][A
step: 1992/3290, eval_loss: 0.4763, eval_acc: 0.8727:  61%|[32m██████    [0m| 1992/3290 [12:20<08:17,  2.61it/s][A[2025-02-04 03:26:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1992/3290, eval_loss: 0.4763, eval_acc: 0.8727:  61%|[32m██████    [0m| 1993/3290 [12:20<08:00,  2.70it/s][A
step: 1993/3290, eval_loss: 0.4764, eval_acc: 0.8727:  61%|[32m██████    [0m| 1993/3290 [12:20<08:00,  2.70it/s][A[2025-02-04 03:26:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 1993/3290, eval_loss: 0.4764, eval_acc: 0.8727:  61%|[32m██████    [0m| 1994/3290 [12:21<08:19,  2.59it/s][A
step: 1994/3290, eval_loss: 0.4764, eval_acc: 0.8727:  61%|[32m██████    [0m| 1994/3290 [12:21<08:19,  2.59it/s][A[2025-02-04 03:26:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1994/3290, eval_loss: 0.4764, eval_acc: 0.8727:  61%|[32m██████    [0m| 1995/3290 [12:21<08:31,  2.53it/s][A
step: 1995/3290, eval_loss: 0.4764, eval_acc: 0.8727:  61%|[32m██████    [0m| 1995/3290 [12:21<08:31,  2.53it/s][A[2025-02-04 03:26:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 1995/3290, eval_loss: 0.4764, eval_acc: 0.8727:  61%|[32m██████    [0m| 1996/3290 [12:21<08:11,  2.63it/s][A
step: 1996/3290, eval_loss: 0.4765, eval_acc: 0.8727:  61%|[32m██████    [0m| 1996/3290 [12:21<08:11,  2.63it/s][A[2025-02-04 03:26:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1996/3290, eval_loss: 0.4765, eval_acc: 0.8727:  61%|[32m██████    [0m| 1997/3290 [12:22<08:03,  2.68it/s][A
step: 1997/3290, eval_loss: 0.4763, eval_acc: 0.8727:  61%|[32m██████    [0m| 1997/3290 [12:22<08:03,  2.68it/s][A[2025-02-04 03:26:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1997/3290, eval_loss: 0.4763, eval_acc: 0.8727:  61%|[32m██████    [0m| 1998/3290 [12:22<07:36,  2.83it/s][A
step: 1998/3290, eval_loss: 0.4762, eval_acc: 0.8728:  61%|[32m██████    [0m| 1998/3290 [12:22<07:36,  2.83it/s][A[2025-02-04 03:26:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 1998/3290, eval_loss: 0.4762, eval_acc: 0.8728:  61%|[32m██████    [0m| 1999/3290 [12:22<07:24,  2.91it/s][A
step: 1999/3290, eval_loss: 0.4761, eval_acc: 0.8728:  61%|[32m██████    [0m| 1999/3290 [12:22<07:24,  2.91it/s][A[2025-02-04 03:26:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 1999/3290, eval_loss: 0.4761, eval_acc: 0.8728:  61%|[32m██████    [0m| 2000/3290 [12:23<07:47,  2.76it/s][A
step: 2000/3290, eval_loss: 0.4760, eval_acc: 0.8728:  61%|[32m██████    [0m| 2000/3290 [12:23<07:47,  2.76it/s][A[2025-02-04 03:26:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2000/3290, eval_loss: 0.4760, eval_acc: 0.8728:  61%|[32m██████    [0m| 2001/3290 [12:23<07:27,  2.88it/s][A
step: 2001/3290, eval_loss: 0.4759, eval_acc: 0.8729:  61%|[32m██████    [0m| 2001/3290 [12:23<07:27,  2.88it/s][A[2025-02-04 03:26:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2001/3290, eval_loss: 0.4759, eval_acc: 0.8729:  61%|[32m██████    [0m| 2002/3290 [12:24<07:29,  2.86it/s][A
step: 2002/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████    [0m| 2002/3290 [12:24<07:29,  2.86it/s][A[2025-02-04 03:26:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2002/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████    [0m| 2003/3290 [12:24<07:16,  2.95it/s][A
step: 2003/3290, eval_loss: 0.4758, eval_acc: 0.8729:  61%|[32m██████    [0m| 2003/3290 [12:24<07:16,  2.95it/s][A[2025-02-04 03:26:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2003/3290, eval_loss: 0.4758, eval_acc: 0.8729:  61%|[32m██████    [0m| 2004/3290 [12:24<07:42,  2.78it/s][A
step: 2004/3290, eval_loss: 0.4756, eval_acc: 0.8730:  61%|[32m██████    [0m| 2004/3290 [12:24<07:42,  2.78it/s][A[2025-02-04 03:26:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2004/3290, eval_loss: 0.4756, eval_acc: 0.8730:  61%|[32m██████    [0m| 2005/3290 [12:25<07:58,  2.69it/s][A
step: 2005/3290, eval_loss: 0.4758, eval_acc: 0.8729:  61%|[32m██████    [0m| 2005/3290 [12:25<07:58,  2.69it/s][A[2025-02-04 03:26:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2005/3290, eval_loss: 0.4758, eval_acc: 0.8729:  61%|[32m██████    [0m| 2006/3290 [12:25<08:44,  2.45it/s][A
step: 2006/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████    [0m| 2006/3290 [12:25<08:44,  2.45it/s][A[2025-02-04 03:26:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2006/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████    [0m| 2007/3290 [12:25<08:09,  2.62it/s][A
step: 2007/3290, eval_loss: 0.4756, eval_acc: 0.8729:  61%|[32m██████    [0m| 2007/3290 [12:25<08:09,  2.62it/s][A[2025-02-04 03:26:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2007/3290, eval_loss: 0.4756, eval_acc: 0.8729:  61%|[32m██████    [0m| 2008/3290 [12:26<07:38,  2.79it/s][A
step: 2008/3290, eval_loss: 0.4756, eval_acc: 0.8729:  61%|[32m██████    [0m| 2008/3290 [12:26<07:38,  2.79it/s][A[2025-02-04 03:26:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2008/3290, eval_loss: 0.4756, eval_acc: 0.8729:  61%|[32m██████    [0m| 2009/3290 [12:26<08:11,  2.60it/s][A
step: 2009/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████    [0m| 2009/3290 [12:26<08:11,  2.60it/s][A[2025-02-04 03:26:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2009/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████    [0m| 2010/3290 [12:27<07:48,  2.73it/s][A
step: 2010/3290, eval_loss: 0.4758, eval_acc: 0.8729:  61%|[32m██████    [0m| 2010/3290 [12:27<07:48,  2.73it/s][A[2025-02-04 03:26:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2010/3290, eval_loss: 0.4758, eval_acc: 0.8729:  61%|[32m██████    [0m| 2011/3290 [12:27<08:09,  2.62it/s][A
step: 2011/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████    [0m| 2011/3290 [12:27<08:09,  2.62it/s][A[2025-02-04 03:26:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2011/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████    [0m| 2012/3290 [12:27<08:05,  2.63it/s][A
step: 2012/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████    [0m| 2012/3290 [12:27<08:05,  2.63it/s][A[2025-02-04 03:26:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2012/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████    [0m| 2013/3290 [12:28<08:04,  2.63it/s][A
step: 2013/3290, eval_loss: 0.4755, eval_acc: 0.8729:  61%|[32m██████    [0m| 2013/3290 [12:28<08:04,  2.63it/s][A[2025-02-04 03:26:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2013/3290, eval_loss: 0.4755, eval_acc: 0.8729:  61%|[32m██████    [0m| 2014/3290 [12:28<08:17,  2.57it/s][A
step: 2014/3290, eval_loss: 0.4756, eval_acc: 0.8729:  61%|[32m██████    [0m| 2014/3290 [12:28<08:17,  2.57it/s][A[2025-02-04 03:26:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2014/3290, eval_loss: 0.4756, eval_acc: 0.8729:  61%|[32m██████    [0m| 2015/3290 [12:28<08:19,  2.55it/s][A
step: 2015/3290, eval_loss: 0.4754, eval_acc: 0.8729:  61%|[32m██████    [0m| 2015/3290 [12:28<08:19,  2.55it/s][A[2025-02-04 03:26:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2015/3290, eval_loss: 0.4754, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2016/3290 [12:29<08:04,  2.63it/s][A
step: 2016/3290, eval_loss: 0.4755, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2016/3290 [12:29<08:04,  2.63it/s][A[2025-02-04 03:26:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2016/3290, eval_loss: 0.4755, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2017/3290 [12:29<08:12,  2.58it/s][A
step: 2017/3290, eval_loss: 0.4755, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2017/3290 [12:29<08:12,  2.58it/s][A[2025-02-04 03:26:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2017/3290, eval_loss: 0.4755, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2018/3290 [12:30<08:54,  2.38it/s][A
step: 2018/3290, eval_loss: 0.4756, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2018/3290 [12:30<08:54,  2.38it/s][A[2025-02-04 03:26:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2018/3290, eval_loss: 0.4756, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2019/3290 [12:30<08:16,  2.56it/s][A
step: 2019/3290, eval_loss: 0.4755, eval_acc: 0.8730:  61%|[32m██████▏   [0m| 2019/3290 [12:30<08:16,  2.56it/s][A[2025-02-04 03:26:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2019/3290, eval_loss: 0.4755, eval_acc: 0.8730:  61%|[32m██████▏   [0m| 2020/3290 [12:30<07:29,  2.82it/s][A
step: 2020/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2020/3290 [12:30<07:29,  2.82it/s][A[2025-02-04 03:26:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2020/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2021/3290 [12:31<07:20,  2.88it/s][A
step: 2021/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2021/3290 [12:31<07:20,  2.88it/s][A[2025-02-04 03:26:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2021/3290, eval_loss: 0.4757, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2022/3290 [12:31<07:03,  2.99it/s][A
step: 2022/3290, eval_loss: 0.4756, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2022/3290 [12:31<07:03,  2.99it/s][A[2025-02-04 03:26:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2022/3290, eval_loss: 0.4756, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2023/3290 [12:31<07:32,  2.80it/s][A
step: 2023/3290, eval_loss: 0.4759, eval_acc: 0.8729:  61%|[32m██████▏   [0m| 2023/3290 [12:31<07:32,  2.80it/s][A[2025-02-04 03:26:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2023/3290, eval_loss: 0.4759, eval_acc: 0.8729:  62%|[32m██████▏   [0m| 2024/3290 [12:32<07:44,  2.72it/s][A
step: 2024/3290, eval_loss: 0.4760, eval_acc: 0.8729:  62%|[32m██████▏   [0m| 2024/3290 [12:32<07:44,  2.72it/s][A[2025-02-04 03:26:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2024/3290, eval_loss: 0.4760, eval_acc: 0.8729:  62%|[32m██████▏   [0m| 2025/3290 [12:32<08:02,  2.62it/s][A
step: 2025/3290, eval_loss: 0.4758, eval_acc: 0.8729:  62%|[32m██████▏   [0m| 2025/3290 [12:32<08:02,  2.62it/s][A[2025-02-04 03:26:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2025/3290, eval_loss: 0.4758, eval_acc: 0.8729:  62%|[32m██████▏   [0m| 2026/3290 [12:33<07:38,  2.76it/s][A
step: 2026/3290, eval_loss: 0.4757, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2026/3290 [12:33<07:38,  2.76it/s][A[2025-02-04 03:26:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2026/3290, eval_loss: 0.4757, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2027/3290 [12:33<06:54,  3.05it/s][A
step: 2027/3290, eval_loss: 0.4756, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2027/3290 [12:33<06:54,  3.05it/s][A[2025-02-04 03:26:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2027/3290, eval_loss: 0.4756, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2028/3290 [12:33<07:11,  2.92it/s][A
step: 2028/3290, eval_loss: 0.4755, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2028/3290 [12:33<07:11,  2.92it/s][A[2025-02-04 03:26:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2028/3290, eval_loss: 0.4755, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2029/3290 [12:34<07:25,  2.83it/s][A
step: 2029/3290, eval_loss: 0.4758, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2029/3290 [12:34<07:25,  2.83it/s][A[2025-02-04 03:26:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2029/3290, eval_loss: 0.4758, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2030/3290 [12:34<07:48,  2.69it/s][A
step: 2030/3290, eval_loss: 0.4758, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2030/3290 [12:34<07:48,  2.69it/s][A[2025-02-04 03:26:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2030/3290, eval_loss: 0.4758, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2031/3290 [12:34<07:25,  2.83it/s][A
step: 2031/3290, eval_loss: 0.4756, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2031/3290 [12:34<07:25,  2.83it/s][A[2025-02-04 03:26:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2031/3290, eval_loss: 0.4756, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2032/3290 [12:35<08:17,  2.53it/s][A
step: 2032/3290, eval_loss: 0.4756, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2032/3290 [12:35<08:17,  2.53it/s][A[2025-02-04 03:26:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2032/3290, eval_loss: 0.4756, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2033/3290 [12:35<08:16,  2.53it/s][A
step: 2033/3290, eval_loss: 0.4756, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2033/3290 [12:35<08:16,  2.53it/s][A[2025-02-04 03:26:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2033/3290, eval_loss: 0.4756, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2034/3290 [12:35<07:52,  2.66it/s][A
step: 2034/3290, eval_loss: 0.4756, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2034/3290 [12:35<07:52,  2.66it/s][A[2025-02-04 03:26:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2034/3290, eval_loss: 0.4756, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2035/3290 [12:36<07:34,  2.76it/s][A
step: 2035/3290, eval_loss: 0.4754, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2035/3290 [12:36<07:34,  2.76it/s][A[2025-02-04 03:26:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2035/3290, eval_loss: 0.4754, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2036/3290 [12:36<07:10,  2.91it/s][A
step: 2036/3290, eval_loss: 0.4753, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2036/3290 [12:36<07:10,  2.91it/s][A[2025-02-04 03:26:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2036/3290, eval_loss: 0.4753, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2037/3290 [12:36<07:35,  2.75it/s][A
step: 2037/3290, eval_loss: 0.4757, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2037/3290 [12:36<07:35,  2.75it/s][A[2025-02-04 03:26:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2037/3290, eval_loss: 0.4757, eval_acc: 0.8730:  62%|[32m██████▏   [0m| 2038/3290 [12:37<07:47,  2.68it/s][A
step: 2038/3290, eval_loss: 0.4755, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2038/3290 [12:37<07:47,  2.68it/s][A[2025-02-04 03:26:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2038/3290, eval_loss: 0.4755, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2039/3290 [12:37<07:29,  2.78it/s][A
step: 2039/3290, eval_loss: 0.4754, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2039/3290 [12:37<07:29,  2.78it/s][A[2025-02-04 03:26:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2039/3290, eval_loss: 0.4754, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2040/3290 [12:38<08:18,  2.51it/s][A
step: 2040/3290, eval_loss: 0.4753, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2040/3290 [12:38<08:18,  2.51it/s][A[2025-02-04 03:26:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2040/3290, eval_loss: 0.4753, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2041/3290 [12:38<08:12,  2.53it/s][A
step: 2041/3290, eval_loss: 0.4751, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2041/3290 [12:38<08:12,  2.53it/s][A[2025-02-04 03:26:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2041/3290, eval_loss: 0.4751, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2042/3290 [12:38<07:48,  2.66it/s][A
step: 2042/3290, eval_loss: 0.4749, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2042/3290 [12:38<07:48,  2.66it/s][A[2025-02-04 03:26:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2042/3290, eval_loss: 0.4749, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2043/3290 [12:39<07:38,  2.72it/s][A
step: 2043/3290, eval_loss: 0.4749, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2043/3290 [12:39<07:38,  2.72it/s][A[2025-02-04 03:26:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2043/3290, eval_loss: 0.4749, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2044/3290 [12:39<07:51,  2.64it/s][A
step: 2044/3290, eval_loss: 0.4751, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2044/3290 [12:39<07:51,  2.64it/s][A[2025-02-04 03:26:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2044/3290, eval_loss: 0.4751, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2045/3290 [12:40<07:51,  2.64it/s][A
step: 2045/3290, eval_loss: 0.4749, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2045/3290 [12:40<07:51,  2.64it/s][A[2025-02-04 03:26:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2045/3290, eval_loss: 0.4749, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2046/3290 [12:40<07:56,  2.61it/s][A
step: 2046/3290, eval_loss: 0.4748, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2046/3290 [12:40<07:56,  2.61it/s][A[2025-02-04 03:26:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2046/3290, eval_loss: 0.4748, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2047/3290 [12:40<07:51,  2.64it/s][A
step: 2047/3290, eval_loss: 0.4747, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2047/3290 [12:40<07:51,  2.64it/s][A[2025-02-04 03:26:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2047/3290, eval_loss: 0.4747, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2048/3290 [12:41<07:43,  2.68it/s][A
step: 2048/3290, eval_loss: 0.4746, eval_acc: 0.8733:  62%|[32m██████▏   [0m| 2048/3290 [12:41<07:43,  2.68it/s][A[2025-02-04 03:26:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2048/3290, eval_loss: 0.4746, eval_acc: 0.8733:  62%|[32m██████▏   [0m| 2049/3290 [12:41<08:10,  2.53it/s][A
step: 2049/3290, eval_loss: 0.4745, eval_acc: 0.8733:  62%|[32m██████▏   [0m| 2049/3290 [12:41<08:10,  2.53it/s][A[2025-02-04 03:26:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2049/3290, eval_loss: 0.4745, eval_acc: 0.8733:  62%|[32m██████▏   [0m| 2050/3290 [12:41<07:44,  2.67it/s][A
step: 2050/3290, eval_loss: 0.4746, eval_acc: 0.8733:  62%|[32m██████▏   [0m| 2050/3290 [12:41<07:44,  2.67it/s][A[2025-02-04 03:26:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2050/3290, eval_loss: 0.4746, eval_acc: 0.8733:  62%|[32m██████▏   [0m| 2051/3290 [12:42<07:51,  2.63it/s][A
step: 2051/3290, eval_loss: 0.4745, eval_acc: 0.8733:  62%|[32m██████▏   [0m| 2051/3290 [12:42<07:51,  2.63it/s][A[2025-02-04 03:26:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2051/3290, eval_loss: 0.4745, eval_acc: 0.8733:  62%|[32m██████▏   [0m| 2052/3290 [12:42<07:45,  2.66it/s][A
step: 2052/3290, eval_loss: 0.4749, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2052/3290 [12:42<07:45,  2.66it/s][A[2025-02-04 03:26:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2052/3290, eval_loss: 0.4749, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2053/3290 [12:43<07:48,  2.64it/s][A
step: 2053/3290, eval_loss: 0.4751, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2053/3290 [12:43<07:48,  2.64it/s][A[2025-02-04 03:26:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2053/3290, eval_loss: 0.4751, eval_acc: 0.8731:  62%|[32m██████▏   [0m| 2054/3290 [12:43<07:46,  2.65it/s][A
step: 2054/3290, eval_loss: 0.4749, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2054/3290 [12:43<07:46,  2.65it/s][A[2025-02-04 03:26:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2054/3290, eval_loss: 0.4749, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2055/3290 [12:43<07:34,  2.72it/s][A
step: 2055/3290, eval_loss: 0.4748, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2055/3290 [12:43<07:34,  2.72it/s][A[2025-02-04 03:26:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2055/3290, eval_loss: 0.4748, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2056/3290 [12:44<07:46,  2.65it/s][A
step: 2056/3290, eval_loss: 0.4749, eval_acc: 0.8732:  62%|[32m██████▏   [0m| 2056/3290 [12:44<07:46,  2.65it/s][A[2025-02-04 03:26:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2056/3290, eval_loss: 0.4749, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2057/3290 [12:44<08:04,  2.54it/s][A
step: 2057/3290, eval_loss: 0.4749, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2057/3290 [12:44<08:04,  2.54it/s][A[2025-02-04 03:26:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2057/3290, eval_loss: 0.4749, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2058/3290 [12:44<07:37,  2.70it/s][A
step: 2058/3290, eval_loss: 0.4752, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2058/3290 [12:44<07:37,  2.70it/s][A[2025-02-04 03:26:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2058/3290, eval_loss: 0.4752, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2059/3290 [12:45<08:02,  2.55it/s][A
step: 2059/3290, eval_loss: 0.4752, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2059/3290 [12:45<08:02,  2.55it/s][A[2025-02-04 03:26:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2059/3290, eval_loss: 0.4752, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2060/3290 [12:45<08:07,  2.52it/s][A
step: 2060/3290, eval_loss: 0.4752, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2060/3290 [12:45<08:07,  2.52it/s][A[2025-02-04 03:26:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2060/3290, eval_loss: 0.4752, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2061/3290 [12:46<08:02,  2.55it/s][A
step: 2061/3290, eval_loss: 0.4751, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2061/3290 [12:46<08:02,  2.55it/s][A[2025-02-04 03:26:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2061/3290, eval_loss: 0.4751, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2062/3290 [12:46<07:56,  2.58it/s][A
step: 2062/3290, eval_loss: 0.4751, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2062/3290 [12:46<07:56,  2.58it/s][A[2025-02-04 03:26:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2062/3290, eval_loss: 0.4751, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2063/3290 [12:46<07:43,  2.65it/s][A
step: 2063/3290, eval_loss: 0.4752, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2063/3290 [12:46<07:43,  2.65it/s][A[2025-02-04 03:26:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2063/3290, eval_loss: 0.4752, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2064/3290 [12:47<07:37,  2.68it/s][A
step: 2064/3290, eval_loss: 0.4752, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2064/3290 [12:47<07:37,  2.68it/s][A[2025-02-04 03:26:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2064/3290, eval_loss: 0.4752, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2065/3290 [12:47<08:28,  2.41it/s][A
step: 2065/3290, eval_loss: 0.4750, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2065/3290 [12:47<08:28,  2.41it/s][A[2025-02-04 03:26:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2065/3290, eval_loss: 0.4750, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2066/3290 [12:48<07:52,  2.59it/s][A
step: 2066/3290, eval_loss: 0.4754, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2066/3290 [12:48<07:52,  2.59it/s][A[2025-02-04 03:26:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2066/3290, eval_loss: 0.4754, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2067/3290 [12:48<07:29,  2.72it/s][A
step: 2067/3290, eval_loss: 0.4753, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2067/3290 [12:48<07:29,  2.72it/s][A[2025-02-04 03:26:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2067/3290, eval_loss: 0.4753, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2068/3290 [12:48<07:46,  2.62it/s][A
step: 2068/3290, eval_loss: 0.4751, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2068/3290 [12:48<07:46,  2.62it/s][A[2025-02-04 03:26:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2068/3290, eval_loss: 0.4751, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2069/3290 [12:49<08:33,  2.38it/s][A
step: 2069/3290, eval_loss: 0.4750, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2069/3290 [12:49<08:33,  2.38it/s][A[2025-02-04 03:26:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2069/3290, eval_loss: 0.4750, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2070/3290 [12:49<08:17,  2.45it/s][A
step: 2070/3290, eval_loss: 0.4749, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2070/3290 [12:49<08:17,  2.45it/s][A[2025-02-04 03:26:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2070/3290, eval_loss: 0.4749, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2071/3290 [12:50<07:59,  2.54it/s][A
step: 2071/3290, eval_loss: 0.4752, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2071/3290 [12:50<07:59,  2.54it/s][A[2025-02-04 03:26:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2071/3290, eval_loss: 0.4752, eval_acc: 0.8731:  63%|[32m██████▎   [0m| 2072/3290 [12:50<08:16,  2.45it/s][A
step: 2072/3290, eval_loss: 0.4750, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2072/3290 [12:50<08:16,  2.45it/s][A[2025-02-04 03:26:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2072/3290, eval_loss: 0.4750, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2073/3290 [12:51<09:21,  2.17it/s][A
step: 2073/3290, eval_loss: 0.4749, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2073/3290 [12:51<09:21,  2.17it/s][A[2025-02-04 03:26:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2073/3290, eval_loss: 0.4749, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2074/3290 [12:51<08:43,  2.32it/s][A
step: 2074/3290, eval_loss: 0.4748, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2074/3290 [12:51<08:43,  2.32it/s][A[2025-02-04 03:26:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2074/3290, eval_loss: 0.4748, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2075/3290 [12:51<08:41,  2.33it/s][A
step: 2075/3290, eval_loss: 0.4747, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2075/3290 [12:51<08:41,  2.33it/s][A[2025-02-04 03:26:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2075/3290, eval_loss: 0.4747, eval_acc: 0.8732:  63%|[32m██████▎   [0m| 2076/3290 [12:52<08:56,  2.26it/s][A
step: 2076/3290, eval_loss: 0.4745, eval_acc: 0.8733:  63%|[32m██████▎   [0m| 2076/3290 [12:52<08:56,  2.26it/s][A[2025-02-04 03:26:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2076/3290, eval_loss: 0.4745, eval_acc: 0.8733:  63%|[32m██████▎   [0m| 2077/3290 [12:52<08:18,  2.43it/s][A
step: 2077/3290, eval_loss: 0.4744, eval_acc: 0.8733:  63%|[32m██████▎   [0m| 2077/3290 [12:52<08:18,  2.43it/s][A[2025-02-04 03:26:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2077/3290, eval_loss: 0.4744, eval_acc: 0.8733:  63%|[32m██████▎   [0m| 2078/3290 [12:53<07:44,  2.61it/s][A
step: 2078/3290, eval_loss: 0.4743, eval_acc: 0.8733:  63%|[32m██████▎   [0m| 2078/3290 [12:53<07:44,  2.61it/s][A[2025-02-04 03:26:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2078/3290, eval_loss: 0.4743, eval_acc: 0.8733:  63%|[32m██████▎   [0m| 2079/3290 [12:53<07:39,  2.64it/s][A
step: 2079/3290, eval_loss: 0.4742, eval_acc: 0.8733:  63%|[32m██████▎   [0m| 2079/3290 [12:53<07:39,  2.64it/s][A[2025-02-04 03:26:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2079/3290, eval_loss: 0.4742, eval_acc: 0.8733:  63%|[32m██████▎   [0m| 2080/3290 [12:53<07:28,  2.70it/s][A
step: 2080/3290, eval_loss: 0.4741, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2080/3290 [12:53<07:28,  2.70it/s][A[2025-02-04 03:26:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2080/3290, eval_loss: 0.4741, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2081/3290 [12:54<08:23,  2.40it/s][A
step: 2081/3290, eval_loss: 0.4740, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2081/3290 [12:54<08:23,  2.40it/s][A[2025-02-04 03:26:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2081/3290, eval_loss: 0.4740, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2082/3290 [12:54<07:52,  2.56it/s][A
step: 2082/3290, eval_loss: 0.4739, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2082/3290 [12:54<07:52,  2.56it/s][A[2025-02-04 03:26:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2082/3290, eval_loss: 0.4739, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2083/3290 [12:54<07:34,  2.66it/s][A
step: 2083/3290, eval_loss: 0.4739, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2083/3290 [12:54<07:34,  2.66it/s][A[2025-02-04 03:26:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2083/3290, eval_loss: 0.4739, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2084/3290 [12:55<06:56,  2.89it/s][A
step: 2084/3290, eval_loss: 0.4737, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2084/3290 [12:55<06:56,  2.89it/s][A[2025-02-04 03:26:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2084/3290, eval_loss: 0.4737, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2085/3290 [12:55<07:39,  2.62it/s][A
step: 2085/3290, eval_loss: 0.4738, eval_acc: 0.8735:  63%|[32m██████▎   [0m| 2085/3290 [12:55<07:39,  2.62it/s][A[2025-02-04 03:26:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2085/3290, eval_loss: 0.4738, eval_acc: 0.8735:  63%|[32m██████▎   [0m| 2086/3290 [12:56<07:53,  2.54it/s][A
step: 2086/3290, eval_loss: 0.4738, eval_acc: 0.8735:  63%|[32m██████▎   [0m| 2086/3290 [12:56<07:53,  2.54it/s][A[2025-02-04 03:26:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2086/3290, eval_loss: 0.4738, eval_acc: 0.8735:  63%|[32m██████▎   [0m| 2087/3290 [12:56<08:09,  2.46it/s][A
step: 2087/3290, eval_loss: 0.4740, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2087/3290 [12:56<08:09,  2.46it/s][A[2025-02-04 03:26:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2087/3290, eval_loss: 0.4740, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2088/3290 [12:56<07:53,  2.54it/s][A
step: 2088/3290, eval_loss: 0.4739, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2088/3290 [12:56<07:53,  2.54it/s][A[2025-02-04 03:26:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2088/3290, eval_loss: 0.4739, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2089/3290 [12:57<07:40,  2.61it/s][A
step: 2089/3290, eval_loss: 0.4741, eval_acc: 0.8734:  63%|[32m██████▎   [0m| 2089/3290 [12:57<07:40,  2.61it/s][A[2025-02-04 03:26:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2089/3290, eval_loss: 0.4741, eval_acc: 0.8734:  64%|[32m██████▎   [0m| 2090/3290 [12:57<07:29,  2.67it/s][A
step: 2090/3290, eval_loss: 0.4742, eval_acc: 0.8734:  64%|[32m██████▎   [0m| 2090/3290 [12:57<07:29,  2.67it/s][A[2025-02-04 03:26:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2090/3290, eval_loss: 0.4742, eval_acc: 0.8734:  64%|[32m██████▎   [0m| 2091/3290 [12:58<08:03,  2.48it/s][A
step: 2091/3290, eval_loss: 0.4741, eval_acc: 0.8734:  64%|[32m██████▎   [0m| 2091/3290 [12:58<08:03,  2.48it/s][A[2025-02-04 03:26:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2091/3290, eval_loss: 0.4741, eval_acc: 0.8734:  64%|[32m██████▎   [0m| 2092/3290 [12:58<07:21,  2.71it/s][A
step: 2092/3290, eval_loss: 0.4741, eval_acc: 0.8734:  64%|[32m██████▎   [0m| 2092/3290 [12:58<07:21,  2.71it/s][A[2025-02-04 03:26:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2092/3290, eval_loss: 0.4741, eval_acc: 0.8734:  64%|[32m██████▎   [0m| 2093/3290 [12:58<07:52,  2.53it/s][A
step: 2093/3290, eval_loss: 0.4742, eval_acc: 0.8733:  64%|[32m██████▎   [0m| 2093/3290 [12:58<07:52,  2.53it/s][A[2025-02-04 03:26:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2093/3290, eval_loss: 0.4742, eval_acc: 0.8733:  64%|[32m██████▎   [0m| 2094/3290 [12:59<07:26,  2.68it/s][A
step: 2094/3290, eval_loss: 0.4741, eval_acc: 0.8734:  64%|[32m██████▎   [0m| 2094/3290 [12:59<07:26,  2.68it/s][A[2025-02-04 03:26:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2094/3290, eval_loss: 0.4741, eval_acc: 0.8734:  64%|[32m██████▎   [0m| 2095/3290 [12:59<07:11,  2.77it/s][A
step: 2095/3290, eval_loss: 0.4742, eval_acc: 0.8733:  64%|[32m██████▎   [0m| 2095/3290 [12:59<07:11,  2.77it/s][A[2025-02-04 03:26:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2095/3290, eval_loss: 0.4742, eval_acc: 0.8733:  64%|[32m██████▎   [0m| 2096/3290 [12:59<07:14,  2.75it/s][A
step: 2096/3290, eval_loss: 0.4742, eval_acc: 0.8733:  64%|[32m██████▎   [0m| 2096/3290 [12:59<07:14,  2.75it/s][A[2025-02-04 03:26:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2096/3290, eval_loss: 0.4742, eval_acc: 0.8733:  64%|[32m██████▎   [0m| 2097/3290 [13:00<06:58,  2.85it/s][A
step: 2097/3290, eval_loss: 0.4742, eval_acc: 0.8733:  64%|[32m██████▎   [0m| 2097/3290 [13:00<06:58,  2.85it/s][A[2025-02-04 03:26:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2097/3290, eval_loss: 0.4742, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2098/3290 [13:00<06:38,  2.99it/s][A
step: 2098/3290, eval_loss: 0.4740, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2098/3290 [13:00<06:38,  2.99it/s][A[2025-02-04 03:26:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2098/3290, eval_loss: 0.4740, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2099/3290 [13:00<07:12,  2.75it/s][A
step: 2099/3290, eval_loss: 0.4741, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2099/3290 [13:00<07:12,  2.75it/s][A[2025-02-04 03:26:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2099/3290, eval_loss: 0.4741, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2100/3290 [13:01<07:27,  2.66it/s][A
step: 2100/3290, eval_loss: 0.4740, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2100/3290 [13:01<07:27,  2.66it/s][A[2025-02-04 03:26:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2100/3290, eval_loss: 0.4740, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2101/3290 [13:01<07:31,  2.63it/s][A
step: 2101/3290, eval_loss: 0.4741, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2101/3290 [13:01<07:31,  2.63it/s][A[2025-02-04 03:26:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2101/3290, eval_loss: 0.4741, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2102/3290 [13:02<07:07,  2.78it/s][A
step: 2102/3290, eval_loss: 0.4739, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2102/3290 [13:02<07:07,  2.78it/s][A[2025-02-04 03:26:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2102/3290, eval_loss: 0.4739, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2103/3290 [13:02<07:36,  2.60it/s][A
step: 2103/3290, eval_loss: 0.4740, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2103/3290 [13:02<07:36,  2.60it/s][A[2025-02-04 03:26:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2103/3290, eval_loss: 0.4740, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2104/3290 [13:02<08:01,  2.46it/s][A
step: 2104/3290, eval_loss: 0.4739, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2104/3290 [13:02<08:01,  2.46it/s][A[2025-02-04 03:26:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2104/3290, eval_loss: 0.4739, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2105/3290 [13:03<07:54,  2.50it/s][A
step: 2105/3290, eval_loss: 0.4740, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2105/3290 [13:03<07:54,  2.50it/s][A[2025-02-04 03:26:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2105/3290, eval_loss: 0.4740, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2106/3290 [13:03<07:39,  2.58it/s][A
step: 2106/3290, eval_loss: 0.4738, eval_acc: 0.8734:  64%|[32m██████▍   [0m| 2106/3290 [13:03<07:39,  2.58it/s][A[2025-02-04 03:26:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2106/3290, eval_loss: 0.4738, eval_acc: 0.8734:  64%|[32m██████▍   [0m| 2107/3290 [13:04<07:37,  2.59it/s][A
step: 2107/3290, eval_loss: 0.4741, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2107/3290 [13:04<07:37,  2.59it/s][A[2025-02-04 03:26:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2107/3290, eval_loss: 0.4741, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2108/3290 [13:04<08:17,  2.38it/s][A
step: 2108/3290, eval_loss: 0.4741, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2108/3290 [13:04<08:17,  2.38it/s][A[2025-02-04 03:26:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2108/3290, eval_loss: 0.4741, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2109/3290 [13:04<07:57,  2.47it/s][A
step: 2109/3290, eval_loss: 0.4739, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2109/3290 [13:04<07:57,  2.47it/s][A[2025-02-04 03:26:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2109/3290, eval_loss: 0.4739, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2110/3290 [13:05<07:29,  2.63it/s][A
step: 2110/3290, eval_loss: 0.4738, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2110/3290 [13:05<07:29,  2.63it/s][A[2025-02-04 03:26:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2110/3290, eval_loss: 0.4738, eval_acc: 0.8733:  64%|[32m██████▍   [0m| 2111/3290 [13:05<07:31,  2.61it/s][A
step: 2111/3290, eval_loss: 0.4736, eval_acc: 0.8734:  64%|[32m██████▍   [0m| 2111/3290 [13:05<07:31,  2.61it/s][A[2025-02-04 03:26:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2111/3290, eval_loss: 0.4736, eval_acc: 0.8734:  64%|[32m██████▍   [0m| 2112/3290 [13:05<06:56,  2.83it/s][A
step: 2112/3290, eval_loss: 0.4735, eval_acc: 0.8734:  64%|[32m██████▍   [0m| 2112/3290 [13:05<06:56,  2.83it/s][A[2025-02-04 03:27:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2112/3290, eval_loss: 0.4735, eval_acc: 0.8734:  64%|[32m██████▍   [0m| 2113/3290 [13:06<06:34,  2.99it/s][A
step: 2113/3290, eval_loss: 0.4734, eval_acc: 0.8734:  64%|[32m██████▍   [0m| 2113/3290 [13:06<06:34,  2.99it/s][A[2025-02-04 03:27:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2113/3290, eval_loss: 0.4734, eval_acc: 0.8734:  64%|[32m██████▍   [0m| 2114/3290 [13:06<06:54,  2.84it/s][A
step: 2114/3290, eval_loss: 0.4732, eval_acc: 0.8735:  64%|[32m██████▍   [0m| 2114/3290 [13:06<06:54,  2.84it/s][A[2025-02-04 03:27:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2114/3290, eval_loss: 0.4732, eval_acc: 0.8735:  64%|[32m██████▍   [0m| 2115/3290 [13:06<06:50,  2.86it/s][A
step: 2115/3290, eval_loss: 0.4731, eval_acc: 0.8735:  64%|[32m██████▍   [0m| 2115/3290 [13:06<06:50,  2.86it/s][A[2025-02-04 03:27:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2115/3290, eval_loss: 0.4731, eval_acc: 0.8735:  64%|[32m██████▍   [0m| 2116/3290 [13:07<06:58,  2.80it/s][A
step: 2116/3290, eval_loss: 0.4732, eval_acc: 0.8735:  64%|[32m██████▍   [0m| 2116/3290 [13:07<06:58,  2.80it/s][A[2025-02-04 03:27:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2116/3290, eval_loss: 0.4732, eval_acc: 0.8735:  64%|[32m██████▍   [0m| 2117/3290 [13:07<06:48,  2.87it/s][A
step: 2117/3290, eval_loss: 0.4731, eval_acc: 0.8736:  64%|[32m██████▍   [0m| 2117/3290 [13:07<06:48,  2.87it/s][A[2025-02-04 03:27:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2117/3290, eval_loss: 0.4731, eval_acc: 0.8736:  64%|[32m██████▍   [0m| 2118/3290 [13:08<06:52,  2.84it/s][A
step: 2118/3290, eval_loss: 0.4731, eval_acc: 0.8735:  64%|[32m██████▍   [0m| 2118/3290 [13:08<06:52,  2.84it/s][A[2025-02-04 03:27:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2118/3290, eval_loss: 0.4731, eval_acc: 0.8735:  64%|[32m██████▍   [0m| 2119/3290 [13:08<06:21,  3.07it/s][A
step: 2119/3290, eval_loss: 0.4729, eval_acc: 0.8736:  64%|[32m██████▍   [0m| 2119/3290 [13:08<06:21,  3.07it/s][A[2025-02-04 03:27:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2119/3290, eval_loss: 0.4729, eval_acc: 0.8736:  64%|[32m██████▍   [0m| 2120/3290 [13:08<06:38,  2.94it/s][A
step: 2120/3290, eval_loss: 0.4729, eval_acc: 0.8735:  64%|[32m██████▍   [0m| 2120/3290 [13:08<06:38,  2.94it/s][A[2025-02-04 03:27:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2120/3290, eval_loss: 0.4729, eval_acc: 0.8735:  64%|[32m██████▍   [0m| 2121/3290 [13:09<06:48,  2.86it/s][A
step: 2121/3290, eval_loss: 0.4727, eval_acc: 0.8736:  64%|[32m██████▍   [0m| 2121/3290 [13:09<06:48,  2.86it/s][A[2025-02-04 03:27:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2121/3290, eval_loss: 0.4727, eval_acc: 0.8736:  64%|[32m██████▍   [0m| 2122/3290 [13:09<07:18,  2.66it/s][A
step: 2122/3290, eval_loss: 0.4728, eval_acc: 0.8736:  64%|[32m██████▍   [0m| 2122/3290 [13:09<07:18,  2.66it/s][A[2025-02-04 03:27:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2122/3290, eval_loss: 0.4728, eval_acc: 0.8736:  65%|[32m██████▍   [0m| 2123/3290 [13:09<06:57,  2.80it/s][A
step: 2123/3290, eval_loss: 0.4726, eval_acc: 0.8736:  65%|[32m██████▍   [0m| 2123/3290 [13:09<06:57,  2.80it/s][A[2025-02-04 03:27:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2123/3290, eval_loss: 0.4726, eval_acc: 0.8736:  65%|[32m██████▍   [0m| 2124/3290 [13:10<06:43,  2.89it/s][A
step: 2124/3290, eval_loss: 0.4725, eval_acc: 0.8736:  65%|[32m██████▍   [0m| 2124/3290 [13:10<06:43,  2.89it/s][A[2025-02-04 03:27:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2124/3290, eval_loss: 0.4725, eval_acc: 0.8736:  65%|[32m██████▍   [0m| 2125/3290 [13:10<06:49,  2.84it/s][A
step: 2125/3290, eval_loss: 0.4724, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2125/3290 [13:10<06:49,  2.84it/s][A[2025-02-04 03:27:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2125/3290, eval_loss: 0.4724, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2126/3290 [13:10<06:55,  2.80it/s][A
step: 2126/3290, eval_loss: 0.4722, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2126/3290 [13:10<06:55,  2.80it/s][A[2025-02-04 03:27:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2126/3290, eval_loss: 0.4722, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2127/3290 [13:11<06:54,  2.80it/s][A
step: 2127/3290, eval_loss: 0.4723, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2127/3290 [13:11<06:54,  2.80it/s][A[2025-02-04 03:27:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2127/3290, eval_loss: 0.4723, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2128/3290 [13:11<07:38,  2.53it/s][A
step: 2128/3290, eval_loss: 0.4723, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2128/3290 [13:11<07:38,  2.53it/s][A[2025-02-04 03:27:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2128/3290, eval_loss: 0.4723, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2129/3290 [13:12<07:30,  2.58it/s][A
step: 2129/3290, eval_loss: 0.4723, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2129/3290 [13:12<07:30,  2.58it/s][A[2025-02-04 03:27:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2129/3290, eval_loss: 0.4723, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2130/3290 [13:12<07:15,  2.66it/s][A
step: 2130/3290, eval_loss: 0.4724, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2130/3290 [13:12<07:15,  2.66it/s][A[2025-02-04 03:27:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2130/3290, eval_loss: 0.4724, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2131/3290 [13:12<07:25,  2.60it/s][A
step: 2131/3290, eval_loss: 0.4725, eval_acc: 0.8736:  65%|[32m██████▍   [0m| 2131/3290 [13:12<07:25,  2.60it/s][A[2025-02-04 03:27:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2131/3290, eval_loss: 0.4725, eval_acc: 0.8736:  65%|[32m██████▍   [0m| 2132/3290 [13:13<07:13,  2.67it/s][A
step: 2132/3290, eval_loss: 0.4723, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2132/3290 [13:13<07:13,  2.67it/s][A[2025-02-04 03:27:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2132/3290, eval_loss: 0.4723, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2133/3290 [13:13<07:29,  2.57it/s][A
step: 2133/3290, eval_loss: 0.4722, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2133/3290 [13:13<07:29,  2.57it/s][A[2025-02-04 03:27:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2133/3290, eval_loss: 0.4722, eval_acc: 0.8737:  65%|[32m██████▍   [0m| 2134/3290 [13:13<07:06,  2.71it/s][A
step: 2134/3290, eval_loss: 0.4722, eval_acc: 0.8738:  65%|[32m██████▍   [0m| 2134/3290 [13:13<07:06,  2.71it/s][A[2025-02-04 03:27:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2134/3290, eval_loss: 0.4722, eval_acc: 0.8738:  65%|[32m██████▍   [0m| 2135/3290 [13:14<06:18,  3.05it/s][A
step: 2135/3290, eval_loss: 0.4720, eval_acc: 0.8738:  65%|[32m██████▍   [0m| 2135/3290 [13:14<06:18,  3.05it/s][A[2025-02-04 03:27:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2135/3290, eval_loss: 0.4720, eval_acc: 0.8738:  65%|[32m██████▍   [0m| 2136/3290 [13:14<06:33,  2.93it/s][A
step: 2136/3290, eval_loss: 0.4720, eval_acc: 0.8738:  65%|[32m██████▍   [0m| 2136/3290 [13:14<06:33,  2.93it/s][A[2025-02-04 03:27:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2136/3290, eval_loss: 0.4720, eval_acc: 0.8738:  65%|[32m██████▍   [0m| 2137/3290 [13:14<06:25,  2.99it/s][A
step: 2137/3290, eval_loss: 0.4719, eval_acc: 0.8738:  65%|[32m██████▍   [0m| 2137/3290 [13:14<06:25,  2.99it/s][A[2025-02-04 03:27:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2137/3290, eval_loss: 0.4719, eval_acc: 0.8738:  65%|[32m██████▍   [0m| 2138/3290 [13:15<06:12,  3.09it/s][A
step: 2138/3290, eval_loss: 0.4718, eval_acc: 0.8739:  65%|[32m██████▍   [0m| 2138/3290 [13:15<06:12,  3.09it/s][A[2025-02-04 03:27:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2138/3290, eval_loss: 0.4718, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2139/3290 [13:15<06:49,  2.81it/s][A
step: 2139/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2139/3290 [13:15<06:49,  2.81it/s][A[2025-02-04 03:27:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2139/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2140/3290 [13:15<06:47,  2.82it/s][A
step: 2140/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2140/3290 [13:15<06:47,  2.82it/s][A[2025-02-04 03:27:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2140/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2141/3290 [13:16<06:28,  2.96it/s][A
step: 2141/3290, eval_loss: 0.4715, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2141/3290 [13:16<06:28,  2.96it/s][A[2025-02-04 03:27:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2141/3290, eval_loss: 0.4715, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2142/3290 [13:16<06:24,  2.99it/s][A
step: 2142/3290, eval_loss: 0.4715, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2142/3290 [13:16<06:24,  2.99it/s][A[2025-02-04 03:27:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2142/3290, eval_loss: 0.4715, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2143/3290 [13:16<05:59,  3.19it/s][A
step: 2143/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2143/3290 [13:16<05:59,  3.19it/s][A[2025-02-04 03:27:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2143/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2144/3290 [13:17<06:17,  3.04it/s][A
step: 2144/3290, eval_loss: 0.4718, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2144/3290 [13:17<06:17,  3.04it/s][A[2025-02-04 03:27:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2144/3290, eval_loss: 0.4718, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2145/3290 [13:17<06:25,  2.97it/s][A
step: 2145/3290, eval_loss: 0.4719, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2145/3290 [13:17<06:25,  2.97it/s][A[2025-02-04 03:27:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2145/3290, eval_loss: 0.4719, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2146/3290 [13:17<06:29,  2.93it/s][A
step: 2146/3290, eval_loss: 0.4718, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2146/3290 [13:17<06:29,  2.93it/s][A[2025-02-04 03:27:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2146/3290, eval_loss: 0.4718, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2147/3290 [13:18<06:32,  2.91it/s][A
step: 2147/3290, eval_loss: 0.4716, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2147/3290 [13:18<06:32,  2.91it/s][A[2025-02-04 03:27:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2147/3290, eval_loss: 0.4716, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2148/3290 [13:18<07:03,  2.70it/s][A
step: 2148/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2148/3290 [13:18<07:03,  2.70it/s][A[2025-02-04 03:27:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2148/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2149/3290 [13:18<06:39,  2.86it/s][A
step: 2149/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2149/3290 [13:18<06:39,  2.86it/s][A[2025-02-04 03:27:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2149/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2150/3290 [13:19<07:01,  2.71it/s][A
step: 2150/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2150/3290 [13:19<07:01,  2.71it/s][A[2025-02-04 03:27:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2150/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2151/3290 [13:19<07:48,  2.43it/s][A
step: 2151/3290, eval_loss: 0.4716, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2151/3290 [13:19<07:48,  2.43it/s][A[2025-02-04 03:27:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2151/3290, eval_loss: 0.4716, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2152/3290 [13:20<07:35,  2.50it/s][A
step: 2152/3290, eval_loss: 0.4716, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2152/3290 [13:20<07:35,  2.50it/s][A[2025-02-04 03:27:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2152/3290, eval_loss: 0.4716, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2153/3290 [13:20<07:17,  2.60it/s][A
step: 2153/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2153/3290 [13:20<07:17,  2.60it/s][A[2025-02-04 03:27:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2153/3290, eval_loss: 0.4717, eval_acc: 0.8739:  65%|[32m██████▌   [0m| 2154/3290 [13:20<06:51,  2.76it/s][A
step: 2154/3290, eval_loss: 0.4716, eval_acc: 0.8740:  65%|[32m██████▌   [0m| 2154/3290 [13:20<06:51,  2.76it/s][A[2025-02-04 03:27:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2154/3290, eval_loss: 0.4716, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2155/3290 [13:21<07:11,  2.63it/s][A
step: 2155/3290, eval_loss: 0.4714, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2155/3290 [13:21<07:11,  2.63it/s][A[2025-02-04 03:27:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2155/3290, eval_loss: 0.4714, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2156/3290 [13:21<07:18,  2.59it/s][A
step: 2156/3290, eval_loss: 0.4714, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2156/3290 [13:21<07:18,  2.59it/s][A[2025-02-04 03:27:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2156/3290, eval_loss: 0.4714, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2157/3290 [13:22<07:34,  2.49it/s][A
step: 2157/3290, eval_loss: 0.4717, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2157/3290 [13:22<07:34,  2.49it/s][A[2025-02-04 03:27:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2157/3290, eval_loss: 0.4717, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2158/3290 [13:22<07:20,  2.57it/s][A
step: 2158/3290, eval_loss: 0.4717, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2158/3290 [13:22<07:20,  2.57it/s][A[2025-02-04 03:27:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2158/3290, eval_loss: 0.4717, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2159/3290 [13:22<07:10,  2.63it/s][A
step: 2159/3290, eval_loss: 0.4716, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2159/3290 [13:22<07:10,  2.63it/s][A[2025-02-04 03:27:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2159/3290, eval_loss: 0.4716, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2160/3290 [13:23<07:13,  2.61it/s][A
step: 2160/3290, eval_loss: 0.4716, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2160/3290 [13:23<07:13,  2.61it/s][A[2025-02-04 03:27:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2160/3290, eval_loss: 0.4716, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2161/3290 [13:23<07:02,  2.67it/s][A
step: 2161/3290, eval_loss: 0.4714, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2161/3290 [13:23<07:02,  2.67it/s][A[2025-02-04 03:27:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2161/3290, eval_loss: 0.4714, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2162/3290 [13:24<07:05,  2.65it/s][A
step: 2162/3290, eval_loss: 0.4715, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2162/3290 [13:24<07:05,  2.65it/s][A[2025-02-04 03:27:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2162/3290, eval_loss: 0.4715, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2163/3290 [13:24<07:22,  2.55it/s][A
step: 2163/3290, eval_loss: 0.4715, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2163/3290 [13:24<07:22,  2.55it/s][A[2025-02-04 03:27:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2163/3290, eval_loss: 0.4715, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2164/3290 [13:24<07:28,  2.51it/s][A
step: 2164/3290, eval_loss: 0.4715, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2164/3290 [13:24<07:28,  2.51it/s][A[2025-02-04 03:27:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2164/3290, eval_loss: 0.4715, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2165/3290 [13:25<07:43,  2.43it/s][A
step: 2165/3290, eval_loss: 0.4715, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2165/3290 [13:25<07:43,  2.43it/s][A[2025-02-04 03:27:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2165/3290, eval_loss: 0.4715, eval_acc: 0.8739:  66%|[32m██████▌   [0m| 2166/3290 [13:25<09:00,  2.08it/s][A
step: 2166/3290, eval_loss: 0.4714, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2166/3290 [13:25<09:00,  2.08it/s][A[2025-02-04 03:27:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2166/3290, eval_loss: 0.4714, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2167/3290 [13:26<08:56,  2.09it/s][A
step: 2167/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2167/3290 [13:26<08:56,  2.09it/s][A[2025-02-04 03:27:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2167/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2168/3290 [13:26<08:42,  2.15it/s][A
step: 2168/3290, eval_loss: 0.4711, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2168/3290 [13:26<08:42,  2.15it/s][A[2025-02-04 03:27:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2168/3290, eval_loss: 0.4711, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2169/3290 [13:27<08:30,  2.20it/s][A
step: 2169/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2169/3290 [13:27<08:30,  2.20it/s][A[2025-02-04 03:27:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2169/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2170/3290 [13:27<07:49,  2.39it/s][A
step: 2170/3290, eval_loss: 0.4711, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2170/3290 [13:27<07:49,  2.39it/s][A[2025-02-04 03:27:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2170/3290, eval_loss: 0.4711, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2171/3290 [13:27<07:37,  2.44it/s][A
step: 2171/3290, eval_loss: 0.4710, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2171/3290 [13:27<07:37,  2.44it/s][A[2025-02-04 03:27:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2171/3290, eval_loss: 0.4710, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2172/3290 [13:28<07:18,  2.55it/s][A
step: 2172/3290, eval_loss: 0.4711, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2172/3290 [13:28<07:18,  2.55it/s][A[2025-02-04 03:27:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2172/3290, eval_loss: 0.4711, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2173/3290 [13:28<07:39,  2.43it/s][A
step: 2173/3290, eval_loss: 0.4710, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2173/3290 [13:28<07:39,  2.43it/s][A[2025-02-04 03:27:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2173/3290, eval_loss: 0.4710, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2174/3290 [13:29<07:10,  2.59it/s][A
step: 2174/3290, eval_loss: 0.4709, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2174/3290 [13:29<07:10,  2.59it/s][A[2025-02-04 03:27:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2174/3290, eval_loss: 0.4709, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2175/3290 [13:29<06:30,  2.86it/s][A
step: 2175/3290, eval_loss: 0.4709, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2175/3290 [13:29<06:30,  2.86it/s][A[2025-02-04 03:27:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2175/3290, eval_loss: 0.4709, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2176/3290 [13:29<06:48,  2.73it/s][A
step: 2176/3290, eval_loss: 0.4710, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2176/3290 [13:29<06:48,  2.73it/s][A[2025-02-04 03:27:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2176/3290, eval_loss: 0.4710, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2177/3290 [13:30<07:06,  2.61it/s][A
step: 2177/3290, eval_loss: 0.4711, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2177/3290 [13:30<07:06,  2.61it/s][A[2025-02-04 03:27:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2177/3290, eval_loss: 0.4711, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2178/3290 [13:30<07:20,  2.52it/s][A
step: 2178/3290, eval_loss: 0.4712, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2178/3290 [13:30<07:20,  2.52it/s][A[2025-02-04 03:27:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2178/3290, eval_loss: 0.4712, eval_acc: 0.8741:  66%|[32m██████▌   [0m| 2179/3290 [13:31<07:29,  2.47it/s][A
step: 2179/3290, eval_loss: 0.4713, eval_acc: 0.8740:  66%|[32m██████▌   [0m| 2179/3290 [13:31<07:29,  2.47it/s][A[2025-02-04 03:27:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2179/3290, eval_loss: 0.4713, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2180/3290 [13:31<07:56,  2.33it/s][A
step: 2180/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2180/3290 [13:31<07:56,  2.33it/s][A[2025-02-04 03:27:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2180/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2181/3290 [13:31<07:24,  2.50it/s][A
step: 2181/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2181/3290 [13:31<07:24,  2.50it/s][A[2025-02-04 03:27:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2181/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2182/3290 [13:32<07:25,  2.49it/s][A
step: 2182/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2182/3290 [13:32<07:25,  2.49it/s][A[2025-02-04 03:27:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2182/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2183/3290 [13:32<07:11,  2.57it/s][A
step: 2183/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2183/3290 [13:32<07:11,  2.57it/s][A[2025-02-04 03:27:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2183/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2184/3290 [13:33<07:05,  2.60it/s][A
step: 2184/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2184/3290 [13:33<07:05,  2.60it/s][A[2025-02-04 03:27:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2184/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2185/3290 [13:33<07:23,  2.49it/s][A
step: 2185/3290, eval_loss: 0.4713, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2185/3290 [13:33<07:23,  2.49it/s][A[2025-02-04 03:27:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2185/3290, eval_loss: 0.4713, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2186/3290 [13:33<07:05,  2.59it/s][A
step: 2186/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2186/3290 [13:33<07:05,  2.59it/s][A[2025-02-04 03:27:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2186/3290, eval_loss: 0.4712, eval_acc: 0.8740:  66%|[32m██████▋   [0m| 2187/3290 [13:34<08:26,  2.18it/s][A
step: 2187/3290, eval_loss: 0.4710, eval_acc: 0.8741:  66%|[32m██████▋   [0m| 2187/3290 [13:34<08:26,  2.18it/s][A[2025-02-04 03:27:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2187/3290, eval_loss: 0.4710, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2188/3290 [13:34<08:20,  2.20it/s][A
step: 2188/3290, eval_loss: 0.4710, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2188/3290 [13:34<08:20,  2.20it/s][A[2025-02-04 03:27:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2188/3290, eval_loss: 0.4710, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2189/3290 [13:35<08:05,  2.27it/s][A
step: 2189/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2189/3290 [13:35<08:05,  2.27it/s][A[2025-02-04 03:27:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2189/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2190/3290 [13:35<08:13,  2.23it/s][A
step: 2190/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2190/3290 [13:35<08:13,  2.23it/s][A[2025-02-04 03:27:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2190/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2191/3290 [13:36<07:16,  2.52it/s][A
step: 2191/3290, eval_loss: 0.4707, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2191/3290 [13:36<07:16,  2.52it/s][A[2025-02-04 03:27:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2191/3290, eval_loss: 0.4707, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2192/3290 [13:36<07:31,  2.43it/s][A
step: 2192/3290, eval_loss: 0.4707, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2192/3290 [13:36<07:31,  2.43it/s][A[2025-02-04 03:27:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2192/3290, eval_loss: 0.4707, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2193/3290 [13:37<08:14,  2.22it/s][A
step: 2193/3290, eval_loss: 0.4707, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2193/3290 [13:37<08:14,  2.22it/s][A[2025-02-04 03:27:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2193/3290, eval_loss: 0.4707, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2194/3290 [13:37<07:49,  2.34it/s][A
step: 2194/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2194/3290 [13:37<07:49,  2.34it/s][A[2025-02-04 03:27:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2194/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2195/3290 [13:37<07:35,  2.40it/s][A
step: 2195/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2195/3290 [13:37<07:35,  2.40it/s][A[2025-02-04 03:27:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2195/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2196/3290 [13:38<07:45,  2.35it/s][A
step: 2196/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2196/3290 [13:38<07:45,  2.35it/s][A[2025-02-04 03:27:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2196/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2197/3290 [13:38<08:17,  2.20it/s][A
step: 2197/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2197/3290 [13:38<08:17,  2.20it/s][A[2025-02-04 03:27:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2197/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2198/3290 [13:39<08:32,  2.13it/s][A
step: 2198/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2198/3290 [13:39<08:32,  2.13it/s][A[2025-02-04 03:27:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2198/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2199/3290 [13:39<08:50,  2.06it/s][A
step: 2199/3290, eval_loss: 0.4707, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2199/3290 [13:39<08:50,  2.06it/s][A[2025-02-04 03:27:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2199/3290, eval_loss: 0.4707, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2200/3290 [13:40<08:54,  2.04it/s][A
step: 2200/3290, eval_loss: 0.4707, eval_acc: 0.8742:  67%|[32m██████▋   [0m| 2200/3290 [13:40<08:54,  2.04it/s][A[2025-02-04 03:27:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2200/3290, eval_loss: 0.4707, eval_acc: 0.8742:  67%|[32m██████▋   [0m| 2201/3290 [13:40<08:37,  2.11it/s][A
step: 2201/3290, eval_loss: 0.4707, eval_acc: 0.8742:  67%|[32m██████▋   [0m| 2201/3290 [13:40<08:37,  2.11it/s][A[2025-02-04 03:27:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2201/3290, eval_loss: 0.4707, eval_acc: 0.8742:  67%|[32m██████▋   [0m| 2202/3290 [13:41<08:13,  2.21it/s][A
step: 2202/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2202/3290 [13:41<08:13,  2.21it/s][A[2025-02-04 03:27:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2202/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2203/3290 [13:41<07:53,  2.30it/s][A
step: 2203/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2203/3290 [13:41<07:53,  2.30it/s][A[2025-02-04 03:27:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2203/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2204/3290 [13:41<07:53,  2.29it/s][A
step: 2204/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2204/3290 [13:41<07:53,  2.29it/s][A[2025-02-04 03:27:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2204/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2205/3290 [13:42<07:11,  2.51it/s][A
step: 2205/3290, eval_loss: 0.4707, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2205/3290 [13:42<07:11,  2.51it/s][A[2025-02-04 03:27:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2205/3290, eval_loss: 0.4707, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2206/3290 [13:42<07:18,  2.47it/s][A
step: 2206/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2206/3290 [13:42<07:18,  2.47it/s][A[2025-02-04 03:27:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2206/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2207/3290 [13:43<07:14,  2.49it/s][A
step: 2207/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2207/3290 [13:43<07:14,  2.49it/s][A[2025-02-04 03:27:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2207/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2208/3290 [13:43<06:58,  2.59it/s][A
step: 2208/3290, eval_loss: 0.4706, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2208/3290 [13:43<06:58,  2.59it/s][A[2025-02-04 03:27:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2208/3290, eval_loss: 0.4706, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2209/3290 [13:43<06:39,  2.71it/s][A
step: 2209/3290, eval_loss: 0.4707, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2209/3290 [13:43<06:39,  2.71it/s][A[2025-02-04 03:27:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2209/3290, eval_loss: 0.4707, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2210/3290 [13:44<06:57,  2.59it/s][A
step: 2210/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2210/3290 [13:44<06:57,  2.59it/s][A[2025-02-04 03:27:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2210/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2211/3290 [13:44<06:43,  2.68it/s][A
step: 2211/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2211/3290 [13:44<06:43,  2.68it/s][A[2025-02-04 03:27:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2211/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2212/3290 [13:44<06:43,  2.67it/s][A
step: 2212/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2212/3290 [13:44<06:43,  2.67it/s][A[2025-02-04 03:27:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2212/3290, eval_loss: 0.4709, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2213/3290 [13:45<06:29,  2.77it/s][A
step: 2213/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2213/3290 [13:45<06:29,  2.77it/s][A[2025-02-04 03:27:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2213/3290, eval_loss: 0.4708, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2214/3290 [13:45<05:57,  3.01it/s][A
step: 2214/3290, eval_loss: 0.4711, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2214/3290 [13:45<05:57,  3.01it/s][A[2025-02-04 03:27:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2214/3290, eval_loss: 0.4711, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2215/3290 [13:45<06:15,  2.86it/s][A
step: 2215/3290, eval_loss: 0.4711, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2215/3290 [13:45<06:15,  2.86it/s][A[2025-02-04 03:27:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2215/3290, eval_loss: 0.4711, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2216/3290 [13:46<06:21,  2.82it/s][A
step: 2216/3290, eval_loss: 0.4710, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2216/3290 [13:46<06:21,  2.82it/s][A[2025-02-04 03:27:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2216/3290, eval_loss: 0.4710, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2217/3290 [13:46<06:53,  2.59it/s][A
step: 2217/3290, eval_loss: 0.4712, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2217/3290 [13:46<06:53,  2.59it/s][A[2025-02-04 03:27:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2217/3290, eval_loss: 0.4712, eval_acc: 0.8741:  67%|[32m██████▋   [0m| 2218/3290 [13:47<06:38,  2.69it/s][A
step: 2218/3290, eval_loss: 0.4715, eval_acc: 0.8740:  67%|[32m██████▋   [0m| 2218/3290 [13:47<06:38,  2.69it/s][A[2025-02-04 03:27:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2218/3290, eval_loss: 0.4715, eval_acc: 0.8740:  67%|[32m██████▋   [0m| 2219/3290 [13:47<06:20,  2.82it/s][A
step: 2219/3290, eval_loss: 0.4716, eval_acc: 0.8740:  67%|[32m██████▋   [0m| 2219/3290 [13:47<06:20,  2.82it/s][A[2025-02-04 03:27:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2219/3290, eval_loss: 0.4716, eval_acc: 0.8740:  67%|[32m██████▋   [0m| 2220/3290 [13:47<06:30,  2.74it/s][A
step: 2220/3290, eval_loss: 0.4715, eval_acc: 0.8740:  67%|[32m██████▋   [0m| 2220/3290 [13:47<06:30,  2.74it/s][A[2025-02-04 03:27:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2220/3290, eval_loss: 0.4715, eval_acc: 0.8740:  68%|[32m██████▊   [0m| 2221/3290 [13:48<06:44,  2.64it/s][A
step: 2221/3290, eval_loss: 0.4715, eval_acc: 0.8740:  68%|[32m██████▊   [0m| 2221/3290 [13:48<06:44,  2.64it/s][A[2025-02-04 03:27:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2221/3290, eval_loss: 0.4715, eval_acc: 0.8740:  68%|[32m██████▊   [0m| 2222/3290 [13:48<07:09,  2.48it/s][A
step: 2222/3290, eval_loss: 0.4715, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2222/3290 [13:48<07:09,  2.48it/s][A[2025-02-04 03:27:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2222/3290, eval_loss: 0.4715, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2223/3290 [13:49<06:53,  2.58it/s][A
step: 2223/3290, eval_loss: 0.4715, eval_acc: 0.8740:  68%|[32m██████▊   [0m| 2223/3290 [13:49<06:53,  2.58it/s][A[2025-02-04 03:27:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2223/3290, eval_loss: 0.4715, eval_acc: 0.8740:  68%|[32m██████▊   [0m| 2224/3290 [13:49<06:58,  2.55it/s][A
step: 2224/3290, eval_loss: 0.4717, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2224/3290 [13:49<06:58,  2.55it/s][A[2025-02-04 03:27:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2224/3290, eval_loss: 0.4717, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2225/3290 [13:49<06:37,  2.68it/s][A
step: 2225/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2225/3290 [13:49<06:37,  2.68it/s][A[2025-02-04 03:27:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2225/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2226/3290 [13:50<06:51,  2.58it/s][A
step: 2226/3290, eval_loss: 0.4719, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2226/3290 [13:50<06:51,  2.58it/s][A[2025-02-04 03:27:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2226/3290, eval_loss: 0.4719, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2227/3290 [13:50<06:45,  2.62it/s][A
step: 2227/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2227/3290 [13:50<06:45,  2.62it/s][A[2025-02-04 03:27:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2227/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2228/3290 [13:50<06:58,  2.54it/s][A
step: 2228/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2228/3290 [13:50<06:58,  2.54it/s][A[2025-02-04 03:27:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2228/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2229/3290 [13:51<08:23,  2.11it/s][A
step: 2229/3290, eval_loss: 0.4719, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2229/3290 [13:51<08:23,  2.11it/s][A[2025-02-04 03:27:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2229/3290, eval_loss: 0.4719, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2230/3290 [13:52<09:05,  1.94it/s][A
step: 2230/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2230/3290 [13:52<09:05,  1.94it/s][A[2025-02-04 03:27:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2230/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2231/3290 [13:52<08:09,  2.16it/s][A
step: 2231/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2231/3290 [13:52<08:09,  2.16it/s][A[2025-02-04 03:27:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2231/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2232/3290 [13:53<08:46,  2.01it/s][A
step: 2232/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2232/3290 [13:53<08:46,  2.01it/s][A[2025-02-04 03:27:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2232/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2233/3290 [13:53<08:13,  2.14it/s][A
step: 2233/3290, eval_loss: 0.4720, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2233/3290 [13:53<08:13,  2.14it/s][A[2025-02-04 03:27:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2233/3290, eval_loss: 0.4720, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2234/3290 [13:54<08:27,  2.08it/s][A
step: 2234/3290, eval_loss: 0.4719, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2234/3290 [13:54<08:27,  2.08it/s][A[2025-02-04 03:27:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2234/3290, eval_loss: 0.4719, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2235/3290 [13:54<08:18,  2.12it/s][A
step: 2235/3290, eval_loss: 0.4719, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2235/3290 [13:54<08:18,  2.12it/s][A[2025-02-04 03:27:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2235/3290, eval_loss: 0.4719, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2236/3290 [13:54<07:49,  2.24it/s][A
step: 2236/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2236/3290 [13:54<07:49,  2.24it/s][A[2025-02-04 03:27:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2236/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2237/3290 [13:55<07:46,  2.26it/s][A
step: 2237/3290, eval_loss: 0.4720, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2237/3290 [13:55<07:46,  2.26it/s][A[2025-02-04 03:27:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2237/3290, eval_loss: 0.4720, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2238/3290 [13:55<07:22,  2.38it/s][A
step: 2238/3290, eval_loss: 0.4721, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2238/3290 [13:55<07:22,  2.38it/s][A[2025-02-04 03:27:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2238/3290, eval_loss: 0.4721, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2239/3290 [13:56<07:39,  2.29it/s][A
step: 2239/3290, eval_loss: 0.4720, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2239/3290 [13:56<07:39,  2.29it/s][A[2025-02-04 03:27:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2239/3290, eval_loss: 0.4720, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2240/3290 [13:56<07:34,  2.31it/s][A
step: 2240/3290, eval_loss: 0.4720, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2240/3290 [13:56<07:34,  2.31it/s][A[2025-02-04 03:27:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2240/3290, eval_loss: 0.4720, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2241/3290 [13:56<07:19,  2.39it/s][A
step: 2241/3290, eval_loss: 0.4719, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2241/3290 [13:56<07:19,  2.39it/s][A[2025-02-04 03:27:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2241/3290, eval_loss: 0.4719, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2242/3290 [13:57<08:24,  2.08it/s][A
step: 2242/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2242/3290 [13:57<08:24,  2.08it/s][A[2025-02-04 03:27:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2242/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2243/3290 [13:57<07:32,  2.31it/s][A
step: 2243/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2243/3290 [13:57<07:32,  2.31it/s][A[2025-02-04 03:27:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2243/3290, eval_loss: 0.4718, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2244/3290 [13:58<06:56,  2.51it/s][A
step: 2244/3290, eval_loss: 0.4717, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2244/3290 [13:58<06:56,  2.51it/s][A[2025-02-04 03:27:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2244/3290, eval_loss: 0.4717, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2245/3290 [13:58<06:25,  2.71it/s][A
step: 2245/3290, eval_loss: 0.4719, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2245/3290 [13:58<06:25,  2.71it/s][A[2025-02-04 03:27:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2245/3290, eval_loss: 0.4719, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2246/3290 [13:58<06:23,  2.72it/s][A
step: 2246/3290, eval_loss: 0.4719, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2246/3290 [13:58<06:23,  2.72it/s][A[2025-02-04 03:27:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2246/3290, eval_loss: 0.4719, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2247/3290 [13:59<07:06,  2.45it/s][A
step: 2247/3290, eval_loss: 0.4719, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2247/3290 [13:59<07:06,  2.45it/s][A[2025-02-04 03:27:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2247/3290, eval_loss: 0.4719, eval_acc: 0.8739:  68%|[32m██████▊   [0m| 2248/3290 [13:59<06:24,  2.71it/s][A
step: 2248/3290, eval_loss: 0.4720, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2248/3290 [13:59<06:24,  2.71it/s][A[2025-02-04 03:27:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2248/3290, eval_loss: 0.4720, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2249/3290 [14:00<07:12,  2.41it/s][A
step: 2249/3290, eval_loss: 0.4720, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2249/3290 [14:00<07:12,  2.41it/s][A[2025-02-04 03:27:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2249/3290, eval_loss: 0.4720, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2250/3290 [14:00<07:48,  2.22it/s][A
step: 2250/3290, eval_loss: 0.4720, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2250/3290 [14:00<07:48,  2.22it/s][A[2025-02-04 03:27:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2250/3290, eval_loss: 0.4720, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2251/3290 [14:01<08:10,  2.12it/s][A
step: 2251/3290, eval_loss: 0.4719, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2251/3290 [14:01<08:10,  2.12it/s][A[2025-02-04 03:27:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2251/3290, eval_loss: 0.4719, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2252/3290 [14:01<07:40,  2.26it/s][A
step: 2252/3290, eval_loss: 0.4719, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2252/3290 [14:01<07:40,  2.26it/s][A[2025-02-04 03:27:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2252/3290, eval_loss: 0.4719, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2253/3290 [14:02<07:59,  2.16it/s][A
step: 2253/3290, eval_loss: 0.4720, eval_acc: 0.8738:  68%|[32m██████▊   [0m| 2253/3290 [14:02<07:59,  2.16it/s][A[2025-02-04 03:27:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2253/3290, eval_loss: 0.4720, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2254/3290 [14:02<07:58,  2.16it/s][A
step: 2254/3290, eval_loss: 0.4719, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2254/3290 [14:02<07:58,  2.16it/s][A[2025-02-04 03:27:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2254/3290, eval_loss: 0.4719, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2255/3290 [14:03<08:08,  2.12it/s][A
step: 2255/3290, eval_loss: 0.4719, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2255/3290 [14:03<08:08,  2.12it/s][A[2025-02-04 03:27:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2255/3290, eval_loss: 0.4719, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2256/3290 [14:03<07:50,  2.20it/s][A
step: 2256/3290, eval_loss: 0.4719, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2256/3290 [14:03<07:50,  2.20it/s][A[2025-02-04 03:27:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2256/3290, eval_loss: 0.4719, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2257/3290 [14:03<07:43,  2.23it/s][A
step: 2257/3290, eval_loss: 0.4718, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2257/3290 [14:03<07:43,  2.23it/s][A[2025-02-04 03:27:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2257/3290, eval_loss: 0.4718, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2258/3290 [14:04<07:05,  2.42it/s][A
step: 2258/3290, eval_loss: 0.4719, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2258/3290 [14:04<07:05,  2.42it/s][A[2025-02-04 03:27:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2258/3290, eval_loss: 0.4719, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2259/3290 [14:04<06:52,  2.50it/s][A
step: 2259/3290, eval_loss: 0.4720, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2259/3290 [14:04<06:52,  2.50it/s][A[2025-02-04 03:27:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2259/3290, eval_loss: 0.4720, eval_acc: 0.8738:  69%|[32m██████▊   [0m| 2260/3290 [14:05<06:51,  2.50it/s][A
step: 2260/3290, eval_loss: 0.4721, eval_acc: 0.8737:  69%|[32m██████▊   [0m| 2260/3290 [14:05<06:51,  2.50it/s][A[2025-02-04 03:27:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2260/3290, eval_loss: 0.4721, eval_acc: 0.8737:  69%|[32m██████▊   [0m| 2261/3290 [14:05<06:45,  2.54it/s][A
step: 2261/3290, eval_loss: 0.4722, eval_acc: 0.8737:  69%|[32m██████▊   [0m| 2261/3290 [14:05<06:45,  2.54it/s][A[2025-02-04 03:27:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2261/3290, eval_loss: 0.4722, eval_acc: 0.8737:  69%|[32m██████▉   [0m| 2262/3290 [14:05<06:31,  2.62it/s][A
step: 2262/3290, eval_loss: 0.4721, eval_acc: 0.8738:  69%|[32m██████▉   [0m| 2262/3290 [14:05<06:31,  2.62it/s][A[2025-02-04 03:28:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2262/3290, eval_loss: 0.4721, eval_acc: 0.8738:  69%|[32m██████▉   [0m| 2263/3290 [14:06<06:44,  2.54it/s][A
step: 2263/3290, eval_loss: 0.4720, eval_acc: 0.8738:  69%|[32m██████▉   [0m| 2263/3290 [14:06<06:44,  2.54it/s][A[2025-02-04 03:28:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2263/3290, eval_loss: 0.4720, eval_acc: 0.8738:  69%|[32m██████▉   [0m| 2264/3290 [14:06<07:09,  2.39it/s][A
step: 2264/3290, eval_loss: 0.4719, eval_acc: 0.8739:  69%|[32m██████▉   [0m| 2264/3290 [14:06<07:09,  2.39it/s][A[2025-02-04 03:28:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2264/3290, eval_loss: 0.4719, eval_acc: 0.8739:  69%|[32m██████▉   [0m| 2265/3290 [14:07<06:47,  2.52it/s][A
step: 2265/3290, eval_loss: 0.4717, eval_acc: 0.8739:  69%|[32m██████▉   [0m| 2265/3290 [14:07<06:47,  2.52it/s][A[2025-02-04 03:28:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2265/3290, eval_loss: 0.4717, eval_acc: 0.8739:  69%|[32m██████▉   [0m| 2266/3290 [14:07<06:38,  2.57it/s][A
step: 2266/3290, eval_loss: 0.4715, eval_acc: 0.8739:  69%|[32m██████▉   [0m| 2266/3290 [14:07<06:38,  2.57it/s][A[2025-02-04 03:28:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2266/3290, eval_loss: 0.4715, eval_acc: 0.8739:  69%|[32m██████▉   [0m| 2267/3290 [14:07<06:27,  2.64it/s][A
step: 2267/3290, eval_loss: 0.4715, eval_acc: 0.8739:  69%|[32m██████▉   [0m| 2267/3290 [14:07<06:27,  2.64it/s][A[2025-02-04 03:28:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2267/3290, eval_loss: 0.4715, eval_acc: 0.8739:  69%|[32m██████▉   [0m| 2268/3290 [14:08<06:23,  2.67it/s][A
step: 2268/3290, eval_loss: 0.4713, eval_acc: 0.8740:  69%|[32m██████▉   [0m| 2268/3290 [14:08<06:23,  2.67it/s][A[2025-02-04 03:28:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2268/3290, eval_loss: 0.4713, eval_acc: 0.8740:  69%|[32m██████▉   [0m| 2269/3290 [14:08<06:06,  2.78it/s][A
step: 2269/3290, eval_loss: 0.4713, eval_acc: 0.8740:  69%|[32m██████▉   [0m| 2269/3290 [14:08<06:06,  2.78it/s][A[2025-02-04 03:28:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2269/3290, eval_loss: 0.4713, eval_acc: 0.8740:  69%|[32m██████▉   [0m| 2270/3290 [14:08<06:27,  2.63it/s][A
step: 2270/3290, eval_loss: 0.4711, eval_acc: 0.8740:  69%|[32m██████▉   [0m| 2270/3290 [14:08<06:27,  2.63it/s][A[2025-02-04 03:28:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2270/3290, eval_loss: 0.4711, eval_acc: 0.8740:  69%|[32m██████▉   [0m| 2271/3290 [14:09<06:30,  2.61it/s][A
step: 2271/3290, eval_loss: 0.4711, eval_acc: 0.8741:  69%|[32m██████▉   [0m| 2271/3290 [14:09<06:30,  2.61it/s][A[2025-02-04 03:28:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2271/3290, eval_loss: 0.4711, eval_acc: 0.8741:  69%|[32m██████▉   [0m| 2272/3290 [14:09<06:39,  2.55it/s][A
step: 2272/3290, eval_loss: 0.4709, eval_acc: 0.8741:  69%|[32m██████▉   [0m| 2272/3290 [14:09<06:39,  2.55it/s][A[2025-02-04 03:28:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2272/3290, eval_loss: 0.4709, eval_acc: 0.8741:  69%|[32m██████▉   [0m| 2273/3290 [14:09<06:06,  2.78it/s][A
step: 2273/3290, eval_loss: 0.4707, eval_acc: 0.8742:  69%|[32m██████▉   [0m| 2273/3290 [14:09<06:06,  2.78it/s][A[2025-02-04 03:28:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2273/3290, eval_loss: 0.4707, eval_acc: 0.8742:  69%|[32m██████▉   [0m| 2274/3290 [14:10<06:25,  2.64it/s][A
step: 2274/3290, eval_loss: 0.4707, eval_acc: 0.8742:  69%|[32m██████▉   [0m| 2274/3290 [14:10<06:25,  2.64it/s][A[2025-02-04 03:28:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2274/3290, eval_loss: 0.4707, eval_acc: 0.8742:  69%|[32m██████▉   [0m| 2275/3290 [14:10<06:47,  2.49it/s][A
step: 2275/3290, eval_loss: 0.4705, eval_acc: 0.8742:  69%|[32m██████▉   [0m| 2275/3290 [14:10<06:47,  2.49it/s][A[2025-02-04 03:28:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2275/3290, eval_loss: 0.4705, eval_acc: 0.8742:  69%|[32m██████▉   [0m| 2276/3290 [14:11<06:26,  2.62it/s][A
step: 2276/3290, eval_loss: 0.4704, eval_acc: 0.8743:  69%|[32m██████▉   [0m| 2276/3290 [14:11<06:26,  2.62it/s][A[2025-02-04 03:28:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2276/3290, eval_loss: 0.4704, eval_acc: 0.8743:  69%|[32m██████▉   [0m| 2277/3290 [14:11<07:04,  2.38it/s][A
step: 2277/3290, eval_loss: 0.4702, eval_acc: 0.8743:  69%|[32m██████▉   [0m| 2277/3290 [14:11<07:04,  2.38it/s][A[2025-02-04 03:28:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2277/3290, eval_loss: 0.4702, eval_acc: 0.8743:  69%|[32m██████▉   [0m| 2278/3290 [14:12<06:35,  2.56it/s][A
step: 2278/3290, eval_loss: 0.4700, eval_acc: 0.8743:  69%|[32m██████▉   [0m| 2278/3290 [14:12<06:35,  2.56it/s][A[2025-02-04 03:28:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2278/3290, eval_loss: 0.4700, eval_acc: 0.8743:  69%|[32m██████▉   [0m| 2279/3290 [14:12<05:53,  2.86it/s][A
step: 2279/3290, eval_loss: 0.4699, eval_acc: 0.8744:  69%|[32m██████▉   [0m| 2279/3290 [14:12<05:53,  2.86it/s][A[2025-02-04 03:28:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2279/3290, eval_loss: 0.4699, eval_acc: 0.8744:  69%|[32m██████▉   [0m| 2280/3290 [14:12<05:24,  3.12it/s][A
step: 2280/3290, eval_loss: 0.4698, eval_acc: 0.8744:  69%|[32m██████▉   [0m| 2280/3290 [14:12<05:24,  3.12it/s][A[2025-02-04 03:28:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2280/3290, eval_loss: 0.4698, eval_acc: 0.8744:  69%|[32m██████▉   [0m| 2281/3290 [14:13<06:22,  2.64it/s][A
step: 2281/3290, eval_loss: 0.4698, eval_acc: 0.8744:  69%|[32m██████▉   [0m| 2281/3290 [14:13<06:22,  2.64it/s][A[2025-02-04 03:28:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2281/3290, eval_loss: 0.4698, eval_acc: 0.8744:  69%|[32m██████▉   [0m| 2282/3290 [14:13<07:01,  2.39it/s][A
step: 2282/3290, eval_loss: 0.4697, eval_acc: 0.8744:  69%|[32m██████▉   [0m| 2282/3290 [14:13<07:01,  2.39it/s][A[2025-02-04 03:28:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2282/3290, eval_loss: 0.4697, eval_acc: 0.8744:  69%|[32m██████▉   [0m| 2283/3290 [14:14<07:33,  2.22it/s][A
step: 2283/3290, eval_loss: 0.4695, eval_acc: 0.8745:  69%|[32m██████▉   [0m| 2283/3290 [14:14<07:33,  2.22it/s][A[2025-02-04 03:28:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2283/3290, eval_loss: 0.4695, eval_acc: 0.8745:  69%|[32m██████▉   [0m| 2284/3290 [14:14<07:20,  2.28it/s][A
step: 2284/3290, eval_loss: 0.4693, eval_acc: 0.8745:  69%|[32m██████▉   [0m| 2284/3290 [14:14<07:20,  2.28it/s][A[2025-02-04 03:28:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2284/3290, eval_loss: 0.4693, eval_acc: 0.8745:  69%|[32m██████▉   [0m| 2285/3290 [14:14<06:29,  2.58it/s][A
step: 2285/3290, eval_loss: 0.4692, eval_acc: 0.8746:  69%|[32m██████▉   [0m| 2285/3290 [14:14<06:29,  2.58it/s][A[2025-02-04 03:28:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2285/3290, eval_loss: 0.4692, eval_acc: 0.8746:  69%|[32m██████▉   [0m| 2286/3290 [14:15<06:13,  2.69it/s][A
step: 2286/3290, eval_loss: 0.4691, eval_acc: 0.8746:  69%|[32m██████▉   [0m| 2286/3290 [14:15<06:13,  2.69it/s][A[2025-02-04 03:28:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2286/3290, eval_loss: 0.4691, eval_acc: 0.8746:  70%|[32m██████▉   [0m| 2287/3290 [14:15<05:58,  2.79it/s][A
step: 2287/3290, eval_loss: 0.4690, eval_acc: 0.8747:  70%|[32m██████▉   [0m| 2287/3290 [14:15<05:58,  2.79it/s][A[2025-02-04 03:28:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2287/3290, eval_loss: 0.4690, eval_acc: 0.8747:  70%|[32m██████▉   [0m| 2288/3290 [14:15<05:30,  3.03it/s][A
step: 2288/3290, eval_loss: 0.4688, eval_acc: 0.8747:  70%|[32m██████▉   [0m| 2288/3290 [14:15<05:30,  3.03it/s][A[2025-02-04 03:28:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2288/3290, eval_loss: 0.4688, eval_acc: 0.8747:  70%|[32m██████▉   [0m| 2289/3290 [14:15<05:27,  3.05it/s][A
step: 2289/3290, eval_loss: 0.4686, eval_acc: 0.8748:  70%|[32m██████▉   [0m| 2289/3290 [14:15<05:27,  3.05it/s][A[2025-02-04 03:28:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2289/3290, eval_loss: 0.4686, eval_acc: 0.8748:  70%|[32m██████▉   [0m| 2290/3290 [14:16<05:36,  2.97it/s][A
step: 2290/3290, eval_loss: 0.4685, eval_acc: 0.8748:  70%|[32m██████▉   [0m| 2290/3290 [14:16<05:36,  2.97it/s][A[2025-02-04 03:28:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2290/3290, eval_loss: 0.4685, eval_acc: 0.8748:  70%|[32m██████▉   [0m| 2291/3290 [14:16<05:58,  2.79it/s][A
step: 2291/3290, eval_loss: 0.4692, eval_acc: 0.8746:  70%|[32m██████▉   [0m| 2291/3290 [14:16<05:58,  2.79it/s][A[2025-02-04 03:28:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2291/3290, eval_loss: 0.4692, eval_acc: 0.8746:  70%|[32m██████▉   [0m| 2292/3290 [14:17<06:23,  2.60it/s][A
step: 2292/3290, eval_loss: 0.4698, eval_acc: 0.8745:  70%|[32m██████▉   [0m| 2292/3290 [14:17<06:23,  2.60it/s][A[2025-02-04 03:28:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2292/3290, eval_loss: 0.4698, eval_acc: 0.8745:  70%|[32m██████▉   [0m| 2293/3290 [14:17<06:21,  2.61it/s][A
step: 2293/3290, eval_loss: 0.4701, eval_acc: 0.8744:  70%|[32m██████▉   [0m| 2293/3290 [14:17<06:21,  2.61it/s][A[2025-02-04 03:28:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2293/3290, eval_loss: 0.4701, eval_acc: 0.8744:  70%|[32m██████▉   [0m| 2294/3290 [14:17<06:01,  2.76it/s][A
step: 2294/3290, eval_loss: 0.4702, eval_acc: 0.8744:  70%|[32m██████▉   [0m| 2294/3290 [14:17<06:01,  2.76it/s][A[2025-02-04 03:28:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2294/3290, eval_loss: 0.4702, eval_acc: 0.8744:  70%|[32m██████▉   [0m| 2295/3290 [14:18<05:55,  2.80it/s][A
step: 2295/3290, eval_loss: 0.4709, eval_acc: 0.8742:  70%|[32m██████▉   [0m| 2295/3290 [14:18<05:55,  2.80it/s][A[2025-02-04 03:28:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2295/3290, eval_loss: 0.4709, eval_acc: 0.8742:  70%|[32m██████▉   [0m| 2296/3290 [14:18<06:19,  2.62it/s][A
step: 2296/3290, eval_loss: 0.4707, eval_acc: 0.8743:  70%|[32m██████▉   [0m| 2296/3290 [14:18<06:19,  2.62it/s][A[2025-02-04 03:28:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2296/3290, eval_loss: 0.4707, eval_acc: 0.8743:  70%|[32m██████▉   [0m| 2297/3290 [14:19<06:33,  2.53it/s][A
step: 2297/3290, eval_loss: 0.4707, eval_acc: 0.8743:  70%|[32m██████▉   [0m| 2297/3290 [14:19<06:33,  2.53it/s][A[2025-02-04 03:28:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2297/3290, eval_loss: 0.4707, eval_acc: 0.8743:  70%|[32m██████▉   [0m| 2298/3290 [14:19<06:09,  2.68it/s][A
step: 2298/3290, eval_loss: 0.4708, eval_acc: 0.8743:  70%|[32m██████▉   [0m| 2298/3290 [14:19<06:09,  2.68it/s][A[2025-02-04 03:28:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2298/3290, eval_loss: 0.4708, eval_acc: 0.8743:  70%|[32m██████▉   [0m| 2299/3290 [14:19<06:27,  2.56it/s][A
step: 2299/3290, eval_loss: 0.4711, eval_acc: 0.8743:  70%|[32m██████▉   [0m| 2299/3290 [14:19<06:27,  2.56it/s][A[2025-02-04 03:28:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2299/3290, eval_loss: 0.4711, eval_acc: 0.8743:  70%|[32m██████▉   [0m| 2300/3290 [14:20<06:44,  2.45it/s][A
step: 2300/3290, eval_loss: 0.4709, eval_acc: 0.8743:  70%|[32m██████▉   [0m| 2300/3290 [14:20<06:44,  2.45it/s][A[2025-02-04 03:28:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2300/3290, eval_loss: 0.4709, eval_acc: 0.8743:  70%|[32m██████▉   [0m| 2301/3290 [14:20<06:46,  2.43it/s][A
step: 2301/3290, eval_loss: 0.4708, eval_acc: 0.8744:  70%|[32m██████▉   [0m| 2301/3290 [14:20<06:46,  2.43it/s][A[2025-02-04 03:28:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2301/3290, eval_loss: 0.4708, eval_acc: 0.8744:  70%|[32m██████▉   [0m| 2302/3290 [14:20<06:03,  2.72it/s][A
step: 2302/3290, eval_loss: 0.4707, eval_acc: 0.8744:  70%|[32m██████▉   [0m| 2302/3290 [14:20<06:03,  2.72it/s][A[2025-02-04 03:28:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2302/3290, eval_loss: 0.4707, eval_acc: 0.8744:  70%|[32m███████   [0m| 2303/3290 [14:21<05:40,  2.90it/s][A
step: 2303/3290, eval_loss: 0.4705, eval_acc: 0.8744:  70%|[32m███████   [0m| 2303/3290 [14:21<05:40,  2.90it/s][A[2025-02-04 03:28:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2303/3290, eval_loss: 0.4705, eval_acc: 0.8744:  70%|[32m███████   [0m| 2304/3290 [14:21<05:40,  2.89it/s][A
step: 2304/3290, eval_loss: 0.4703, eval_acc: 0.8745:  70%|[32m███████   [0m| 2304/3290 [14:21<05:40,  2.89it/s][A[2025-02-04 03:28:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2304/3290, eval_loss: 0.4703, eval_acc: 0.8745:  70%|[32m███████   [0m| 2305/3290 [14:22<06:41,  2.46it/s][A
step: 2305/3290, eval_loss: 0.4703, eval_acc: 0.8745:  70%|[32m███████   [0m| 2305/3290 [14:22<06:41,  2.46it/s][A[2025-02-04 03:28:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2305/3290, eval_loss: 0.4703, eval_acc: 0.8745:  70%|[32m███████   [0m| 2306/3290 [14:22<06:33,  2.50it/s][A
step: 2306/3290, eval_loss: 0.4703, eval_acc: 0.8745:  70%|[32m███████   [0m| 2306/3290 [14:22<06:33,  2.50it/s][A[2025-02-04 03:28:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2306/3290, eval_loss: 0.4703, eval_acc: 0.8745:  70%|[32m███████   [0m| 2307/3290 [14:22<06:15,  2.62it/s][A
step: 2307/3290, eval_loss: 0.4702, eval_acc: 0.8745:  70%|[32m███████   [0m| 2307/3290 [14:22<06:15,  2.62it/s][A[2025-02-04 03:28:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2307/3290, eval_loss: 0.4702, eval_acc: 0.8745:  70%|[32m███████   [0m| 2308/3290 [14:23<07:11,  2.28it/s][A
step: 2308/3290, eval_loss: 0.4702, eval_acc: 0.8745:  70%|[32m███████   [0m| 2308/3290 [14:23<07:11,  2.28it/s][A[2025-02-04 03:28:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2308/3290, eval_loss: 0.4702, eval_acc: 0.8745:  70%|[32m███████   [0m| 2309/3290 [14:23<07:20,  2.23it/s][A
step: 2309/3290, eval_loss: 0.4701, eval_acc: 0.8745:  70%|[32m███████   [0m| 2309/3290 [14:23<07:20,  2.23it/s][A[2025-02-04 03:28:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2309/3290, eval_loss: 0.4701, eval_acc: 0.8745:  70%|[32m███████   [0m| 2310/3290 [14:24<07:17,  2.24it/s][A
step: 2310/3290, eval_loss: 0.4702, eval_acc: 0.8745:  70%|[32m███████   [0m| 2310/3290 [14:24<07:17,  2.24it/s][A[2025-02-04 03:28:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2310/3290, eval_loss: 0.4702, eval_acc: 0.8745:  70%|[32m███████   [0m| 2311/3290 [14:24<06:58,  2.34it/s][A
step: 2311/3290, eval_loss: 0.4704, eval_acc: 0.8745:  70%|[32m███████   [0m| 2311/3290 [14:24<06:58,  2.34it/s][A[2025-02-04 03:28:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2311/3290, eval_loss: 0.4704, eval_acc: 0.8745:  70%|[32m███████   [0m| 2312/3290 [14:25<06:46,  2.41it/s][A
step: 2312/3290, eval_loss: 0.4703, eval_acc: 0.8745:  70%|[32m███████   [0m| 2312/3290 [14:25<06:46,  2.41it/s][A[2025-02-04 03:28:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2312/3290, eval_loss: 0.4703, eval_acc: 0.8745:  70%|[32m███████   [0m| 2313/3290 [14:25<06:06,  2.66it/s][A
step: 2313/3290, eval_loss: 0.4702, eval_acc: 0.8745:  70%|[32m███████   [0m| 2313/3290 [14:25<06:06,  2.66it/s][A[2025-02-04 03:28:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2313/3290, eval_loss: 0.4702, eval_acc: 0.8745:  70%|[32m███████   [0m| 2314/3290 [14:25<06:19,  2.57it/s][A
step: 2314/3290, eval_loss: 0.4702, eval_acc: 0.8745:  70%|[32m███████   [0m| 2314/3290 [14:25<06:19,  2.57it/s][A[2025-02-04 03:28:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2314/3290, eval_loss: 0.4702, eval_acc: 0.8745:  70%|[32m███████   [0m| 2315/3290 [14:26<06:03,  2.68it/s][A
step: 2315/3290, eval_loss: 0.4701, eval_acc: 0.8745:  70%|[32m███████   [0m| 2315/3290 [14:26<06:03,  2.68it/s][A[2025-02-04 03:28:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2315/3290, eval_loss: 0.4701, eval_acc: 0.8745:  70%|[32m███████   [0m| 2316/3290 [14:26<05:44,  2.83it/s][A
step: 2316/3290, eval_loss: 0.4701, eval_acc: 0.8745:  70%|[32m███████   [0m| 2316/3290 [14:26<05:44,  2.83it/s][A[2025-02-04 03:28:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2316/3290, eval_loss: 0.4701, eval_acc: 0.8745:  70%|[32m███████   [0m| 2317/3290 [14:26<05:56,  2.73it/s][A
step: 2317/3290, eval_loss: 0.4701, eval_acc: 0.8745:  70%|[32m███████   [0m| 2317/3290 [14:26<05:56,  2.73it/s][A[2025-02-04 03:28:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2317/3290, eval_loss: 0.4701, eval_acc: 0.8745:  70%|[32m███████   [0m| 2318/3290 [14:27<06:15,  2.59it/s][A
step: 2318/3290, eval_loss: 0.4700, eval_acc: 0.8745:  70%|[32m███████   [0m| 2318/3290 [14:27<06:15,  2.59it/s][A[2025-02-04 03:28:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2318/3290, eval_loss: 0.4700, eval_acc: 0.8745:  70%|[32m███████   [0m| 2319/3290 [14:27<05:54,  2.74it/s][A
step: 2319/3290, eval_loss: 0.4701, eval_acc: 0.8745:  70%|[32m███████   [0m| 2319/3290 [14:27<05:54,  2.74it/s][A[2025-02-04 03:28:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2319/3290, eval_loss: 0.4701, eval_acc: 0.8745:  71%|[32m███████   [0m| 2320/3290 [14:27<05:42,  2.83it/s][A
step: 2320/3290, eval_loss: 0.4700, eval_acc: 0.8745:  71%|[32m███████   [0m| 2320/3290 [14:27<05:42,  2.83it/s][A[2025-02-04 03:28:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2320/3290, eval_loss: 0.4700, eval_acc: 0.8745:  71%|[32m███████   [0m| 2321/3290 [14:28<05:33,  2.90it/s][A
step: 2321/3290, eval_loss: 0.4701, eval_acc: 0.8745:  71%|[32m███████   [0m| 2321/3290 [14:28<05:33,  2.90it/s][A[2025-02-04 03:28:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2321/3290, eval_loss: 0.4701, eval_acc: 0.8745:  71%|[32m███████   [0m| 2322/3290 [14:28<05:46,  2.79it/s][A
step: 2322/3290, eval_loss: 0.4700, eval_acc: 0.8745:  71%|[32m███████   [0m| 2322/3290 [14:28<05:46,  2.79it/s][A[2025-02-04 03:28:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2322/3290, eval_loss: 0.4700, eval_acc: 0.8745:  71%|[32m███████   [0m| 2323/3290 [14:28<05:27,  2.96it/s][A
step: 2323/3290, eval_loss: 0.4700, eval_acc: 0.8745:  71%|[32m███████   [0m| 2323/3290 [14:28<05:27,  2.96it/s][A[2025-02-04 03:28:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2323/3290, eval_loss: 0.4700, eval_acc: 0.8745:  71%|[32m███████   [0m| 2324/3290 [14:29<05:41,  2.83it/s][A
step: 2324/3290, eval_loss: 0.4698, eval_acc: 0.8746:  71%|[32m███████   [0m| 2324/3290 [14:29<05:41,  2.83it/s][A[2025-02-04 03:28:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2324/3290, eval_loss: 0.4698, eval_acc: 0.8746:  71%|[32m███████   [0m| 2325/3290 [14:29<05:33,  2.90it/s][A
step: 2325/3290, eval_loss: 0.4696, eval_acc: 0.8746:  71%|[32m███████   [0m| 2325/3290 [14:29<05:33,  2.90it/s][A[2025-02-04 03:28:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2325/3290, eval_loss: 0.4696, eval_acc: 0.8746:  71%|[32m███████   [0m| 2326/3290 [14:29<04:59,  3.22it/s][A
step: 2326/3290, eval_loss: 0.4698, eval_acc: 0.8746:  71%|[32m███████   [0m| 2326/3290 [14:29<04:59,  3.22it/s][A[2025-02-04 03:28:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2326/3290, eval_loss: 0.4698, eval_acc: 0.8746:  71%|[32m███████   [0m| 2327/3290 [14:30<04:34,  3.50it/s][A
step: 2327/3290, eval_loss: 0.4697, eval_acc: 0.8747:  71%|[32m███████   [0m| 2327/3290 [14:30<04:34,  3.50it/s][A[2025-02-04 03:28:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2327/3290, eval_loss: 0.4697, eval_acc: 0.8747:  71%|[32m███████   [0m| 2328/3290 [14:30<04:15,  3.76it/s][A
step: 2328/3290, eval_loss: 0.4695, eval_acc: 0.8747:  71%|[32m███████   [0m| 2328/3290 [14:30<04:15,  3.76it/s][A[2025-02-04 03:28:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2328/3290, eval_loss: 0.4695, eval_acc: 0.8747:  71%|[32m███████   [0m| 2329/3290 [14:30<04:03,  3.95it/s][A
step: 2329/3290, eval_loss: 0.4694, eval_acc: 0.8747:  71%|[32m███████   [0m| 2329/3290 [14:30<04:03,  3.95it/s][A[2025-02-04 03:28:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2329/3290, eval_loss: 0.4694, eval_acc: 0.8747:  71%|[32m███████   [0m| 2330/3290 [14:30<04:00,  4.00it/s][A
step: 2330/3290, eval_loss: 0.4692, eval_acc: 0.8748:  71%|[32m███████   [0m| 2330/3290 [14:30<04:00,  4.00it/s][A[2025-02-04 03:28:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2330/3290, eval_loss: 0.4692, eval_acc: 0.8748:  71%|[32m███████   [0m| 2331/3290 [14:31<04:38,  3.45it/s][A
step: 2331/3290, eval_loss: 0.4691, eval_acc: 0.8748:  71%|[32m███████   [0m| 2331/3290 [14:31<04:38,  3.45it/s][A[2025-02-04 03:28:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2331/3290, eval_loss: 0.4691, eval_acc: 0.8748:  71%|[32m███████   [0m| 2332/3290 [14:31<05:12,  3.07it/s][A
step: 2332/3290, eval_loss: 0.4690, eval_acc: 0.8749:  71%|[32m███████   [0m| 2332/3290 [14:31<05:12,  3.07it/s][A[2025-02-04 03:28:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2332/3290, eval_loss: 0.4690, eval_acc: 0.8749:  71%|[32m███████   [0m| 2333/3290 [14:31<05:00,  3.18it/s][A
step: 2333/3290, eval_loss: 0.4688, eval_acc: 0.8749:  71%|[32m███████   [0m| 2333/3290 [14:31<05:00,  3.18it/s][A[2025-02-04 03:28:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2333/3290, eval_loss: 0.4688, eval_acc: 0.8749:  71%|[32m███████   [0m| 2334/3290 [14:32<05:00,  3.18it/s][A
step: 2334/3290, eval_loss: 0.4687, eval_acc: 0.8749:  71%|[32m███████   [0m| 2334/3290 [14:32<05:00,  3.18it/s][A[2025-02-04 03:28:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2334/3290, eval_loss: 0.4687, eval_acc: 0.8749:  71%|[32m███████   [0m| 2335/3290 [14:32<05:27,  2.91it/s][A
step: 2335/3290, eval_loss: 0.4686, eval_acc: 0.8750:  71%|[32m███████   [0m| 2335/3290 [14:32<05:27,  2.91it/s][A[2025-02-04 03:28:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2335/3290, eval_loss: 0.4686, eval_acc: 0.8750:  71%|[32m███████   [0m| 2336/3290 [14:32<05:25,  2.93it/s][A
step: 2336/3290, eval_loss: 0.4684, eval_acc: 0.8750:  71%|[32m███████   [0m| 2336/3290 [14:32<05:25,  2.93it/s][A[2025-02-04 03:28:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2336/3290, eval_loss: 0.4684, eval_acc: 0.8750:  71%|[32m███████   [0m| 2337/3290 [14:33<05:17,  3.00it/s][A
step: 2337/3290, eval_loss: 0.4683, eval_acc: 0.8750:  71%|[32m███████   [0m| 2337/3290 [14:33<05:17,  3.00it/s][A[2025-02-04 03:28:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2337/3290, eval_loss: 0.4683, eval_acc: 0.8750:  71%|[32m███████   [0m| 2338/3290 [14:33<05:24,  2.93it/s][A
step: 2338/3290, eval_loss: 0.4682, eval_acc: 0.8751:  71%|[32m███████   [0m| 2338/3290 [14:33<05:24,  2.93it/s][A[2025-02-04 03:28:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2338/3290, eval_loss: 0.4682, eval_acc: 0.8751:  71%|[32m███████   [0m| 2339/3290 [14:33<05:18,  2.99it/s][A
step: 2339/3290, eval_loss: 0.4682, eval_acc: 0.8751:  71%|[32m███████   [0m| 2339/3290 [14:33<05:18,  2.99it/s][A[2025-02-04 03:28:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2339/3290, eval_loss: 0.4682, eval_acc: 0.8751:  71%|[32m███████   [0m| 2340/3290 [14:34<05:04,  3.12it/s][A
step: 2340/3290, eval_loss: 0.4681, eval_acc: 0.8751:  71%|[32m███████   [0m| 2340/3290 [14:34<05:04,  3.12it/s][A[2025-02-04 03:28:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2340/3290, eval_loss: 0.4681, eval_acc: 0.8751:  71%|[32m███████   [0m| 2341/3290 [14:34<04:58,  3.18it/s][A
step: 2341/3290, eval_loss: 0.4682, eval_acc: 0.8751:  71%|[32m███████   [0m| 2341/3290 [14:34<04:58,  3.18it/s][A[2025-02-04 03:28:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2341/3290, eval_loss: 0.4682, eval_acc: 0.8751:  71%|[32m███████   [0m| 2342/3290 [14:34<05:05,  3.10it/s][A
step: 2342/3290, eval_loss: 0.4681, eval_acc: 0.8751:  71%|[32m███████   [0m| 2342/3290 [14:34<05:05,  3.10it/s][A[2025-02-04 03:28:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2342/3290, eval_loss: 0.4681, eval_acc: 0.8751:  71%|[32m███████   [0m| 2343/3290 [14:35<04:59,  3.16it/s][A
step: 2343/3290, eval_loss: 0.4680, eval_acc: 0.8751:  71%|[32m███████   [0m| 2343/3290 [14:35<04:59,  3.16it/s][A[2025-02-04 03:28:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2343/3290, eval_loss: 0.4680, eval_acc: 0.8751:  71%|[32m███████   [0m| 2344/3290 [14:35<05:19,  2.96it/s][A
step: 2344/3290, eval_loss: 0.4678, eval_acc: 0.8752:  71%|[32m███████   [0m| 2344/3290 [14:35<05:19,  2.96it/s][A[2025-02-04 03:28:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2344/3290, eval_loss: 0.4678, eval_acc: 0.8752:  71%|[32m███████▏  [0m| 2345/3290 [14:35<05:30,  2.86it/s][A
step: 2345/3290, eval_loss: 0.4677, eval_acc: 0.8752:  71%|[32m███████▏  [0m| 2345/3290 [14:35<05:30,  2.86it/s][A[2025-02-04 03:28:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2345/3290, eval_loss: 0.4677, eval_acc: 0.8752:  71%|[32m███████▏  [0m| 2346/3290 [14:36<05:28,  2.87it/s][A
step: 2346/3290, eval_loss: 0.4676, eval_acc: 0.8752:  71%|[32m███████▏  [0m| 2346/3290 [14:36<05:28,  2.87it/s][A[2025-02-04 03:28:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2346/3290, eval_loss: 0.4676, eval_acc: 0.8752:  71%|[32m███████▏  [0m| 2347/3290 [14:36<05:00,  3.14it/s][A
step: 2347/3290, eval_loss: 0.4675, eval_acc: 0.8753:  71%|[32m███████▏  [0m| 2347/3290 [14:36<05:00,  3.14it/s][A[2025-02-04 03:28:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2347/3290, eval_loss: 0.4675, eval_acc: 0.8753:  71%|[32m███████▏  [0m| 2348/3290 [14:36<05:08,  3.05it/s][A
step: 2348/3290, eval_loss: 0.4674, eval_acc: 0.8753:  71%|[32m███████▏  [0m| 2348/3290 [14:36<05:08,  3.05it/s][A[2025-02-04 03:28:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2348/3290, eval_loss: 0.4674, eval_acc: 0.8753:  71%|[32m███████▏  [0m| 2349/3290 [14:37<05:08,  3.05it/s][A
step: 2349/3290, eval_loss: 0.4673, eval_acc: 0.8753:  71%|[32m███████▏  [0m| 2349/3290 [14:37<05:08,  3.05it/s][A[2025-02-04 03:28:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2349/3290, eval_loss: 0.4673, eval_acc: 0.8753:  71%|[32m███████▏  [0m| 2350/3290 [14:37<05:39,  2.77it/s][A
step: 2350/3290, eval_loss: 0.4673, eval_acc: 0.8754:  71%|[32m███████▏  [0m| 2350/3290 [14:37<05:39,  2.77it/s][A[2025-02-04 03:28:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2350/3290, eval_loss: 0.4673, eval_acc: 0.8754:  71%|[32m███████▏  [0m| 2351/3290 [14:38<05:31,  2.83it/s][A
step: 2351/3290, eval_loss: 0.4671, eval_acc: 0.8754:  71%|[32m███████▏  [0m| 2351/3290 [14:38<05:31,  2.83it/s][A[2025-02-04 03:28:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2351/3290, eval_loss: 0.4671, eval_acc: 0.8754:  71%|[32m███████▏  [0m| 2352/3290 [14:38<05:52,  2.66it/s][A
step: 2352/3290, eval_loss: 0.4672, eval_acc: 0.8754:  71%|[32m███████▏  [0m| 2352/3290 [14:38<05:52,  2.66it/s][A[2025-02-04 03:28:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2352/3290, eval_loss: 0.4672, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2353/3290 [14:38<05:44,  2.72it/s][A
step: 2353/3290, eval_loss: 0.4670, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2353/3290 [14:38<05:44,  2.72it/s][A[2025-02-04 03:28:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2353/3290, eval_loss: 0.4670, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2354/3290 [14:39<05:30,  2.83it/s][A
step: 2354/3290, eval_loss: 0.4670, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2354/3290 [14:39<05:30,  2.83it/s][A[2025-02-04 03:28:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2354/3290, eval_loss: 0.4670, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2355/3290 [14:39<05:17,  2.95it/s][A
step: 2355/3290, eval_loss: 0.4669, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2355/3290 [14:39<05:17,  2.95it/s][A[2025-02-04 03:28:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2355/3290, eval_loss: 0.4669, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2356/3290 [14:40<06:24,  2.43it/s][A
step: 2356/3290, eval_loss: 0.4668, eval_acc: 0.8755:  72%|[32m███████▏  [0m| 2356/3290 [14:40<06:24,  2.43it/s][A[2025-02-04 03:28:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2356/3290, eval_loss: 0.4668, eval_acc: 0.8755:  72%|[32m███████▏  [0m| 2357/3290 [14:40<06:10,  2.52it/s][A
step: 2357/3290, eval_loss: 0.4667, eval_acc: 0.8755:  72%|[32m███████▏  [0m| 2357/3290 [14:40<06:10,  2.52it/s][A[2025-02-04 03:28:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2357/3290, eval_loss: 0.4667, eval_acc: 0.8755:  72%|[32m███████▏  [0m| 2358/3290 [14:40<05:30,  2.82it/s][A
step: 2358/3290, eval_loss: 0.4666, eval_acc: 0.8755:  72%|[32m███████▏  [0m| 2358/3290 [14:40<05:30,  2.82it/s][A[2025-02-04 03:28:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2358/3290, eval_loss: 0.4666, eval_acc: 0.8755:  72%|[32m███████▏  [0m| 2359/3290 [14:41<05:55,  2.62it/s][A
step: 2359/3290, eval_loss: 0.4664, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2359/3290 [14:41<05:55,  2.62it/s][A[2025-02-04 03:28:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2359/3290, eval_loss: 0.4664, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2360/3290 [14:41<06:53,  2.25it/s][A
step: 2360/3290, eval_loss: 0.4663, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2360/3290 [14:41<06:53,  2.25it/s][A[2025-02-04 03:28:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2360/3290, eval_loss: 0.4663, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2361/3290 [14:42<06:36,  2.34it/s][A
step: 2361/3290, eval_loss: 0.4662, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2361/3290 [14:42<06:36,  2.34it/s][A[2025-02-04 03:28:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2361/3290, eval_loss: 0.4662, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2362/3290 [14:42<05:59,  2.58it/s][A
step: 2362/3290, eval_loss: 0.4662, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2362/3290 [14:42<05:59,  2.58it/s][A[2025-02-04 03:28:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2362/3290, eval_loss: 0.4662, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2363/3290 [14:42<05:48,  2.66it/s][A
step: 2363/3290, eval_loss: 0.4661, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2363/3290 [14:42<05:48,  2.66it/s][A[2025-02-04 03:28:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2363/3290, eval_loss: 0.4661, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2364/3290 [14:43<05:31,  2.79it/s][A
step: 2364/3290, eval_loss: 0.4659, eval_acc: 0.8757:  72%|[32m███████▏  [0m| 2364/3290 [14:43<05:31,  2.79it/s][A[2025-02-04 03:28:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2364/3290, eval_loss: 0.4659, eval_acc: 0.8757:  72%|[32m███████▏  [0m| 2365/3290 [14:43<05:17,  2.91it/s][A
step: 2365/3290, eval_loss: 0.4659, eval_acc: 0.8757:  72%|[32m███████▏  [0m| 2365/3290 [14:43<05:17,  2.91it/s][A[2025-02-04 03:28:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2365/3290, eval_loss: 0.4659, eval_acc: 0.8757:  72%|[32m███████▏  [0m| 2366/3290 [14:43<04:54,  3.13it/s][A
step: 2366/3290, eval_loss: 0.4660, eval_acc: 0.8757:  72%|[32m███████▏  [0m| 2366/3290 [14:43<04:54,  3.13it/s][A[2025-02-04 03:28:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2366/3290, eval_loss: 0.4660, eval_acc: 0.8757:  72%|[32m███████▏  [0m| 2367/3290 [14:43<05:20,  2.88it/s][A
step: 2367/3290, eval_loss: 0.4661, eval_acc: 0.8757:  72%|[32m███████▏  [0m| 2367/3290 [14:43<05:20,  2.88it/s][A[2025-02-04 03:28:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2367/3290, eval_loss: 0.4661, eval_acc: 0.8757:  72%|[32m███████▏  [0m| 2368/3290 [14:44<05:53,  2.61it/s][A
step: 2368/3290, eval_loss: 0.4662, eval_acc: 0.8757:  72%|[32m███████▏  [0m| 2368/3290 [14:44<05:53,  2.61it/s][A[2025-02-04 03:28:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2368/3290, eval_loss: 0.4662, eval_acc: 0.8757:  72%|[32m███████▏  [0m| 2369/3290 [14:44<06:10,  2.49it/s][A
step: 2369/3290, eval_loss: 0.4662, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2369/3290 [14:44<06:10,  2.49it/s][A[2025-02-04 03:28:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2369/3290, eval_loss: 0.4662, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2370/3290 [14:45<05:55,  2.59it/s][A
step: 2370/3290, eval_loss: 0.4663, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2370/3290 [14:45<05:55,  2.59it/s][A[2025-02-04 03:28:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2370/3290, eval_loss: 0.4663, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2371/3290 [14:45<06:02,  2.54it/s][A
step: 2371/3290, eval_loss: 0.4664, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2371/3290 [14:45<06:02,  2.54it/s][A[2025-02-04 03:28:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2371/3290, eval_loss: 0.4664, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2372/3290 [14:46<05:55,  2.58it/s][A
step: 2372/3290, eval_loss: 0.4664, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2372/3290 [14:46<05:55,  2.58it/s][A[2025-02-04 03:28:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2372/3290, eval_loss: 0.4664, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2373/3290 [14:46<05:21,  2.86it/s][A
step: 2373/3290, eval_loss: 0.4665, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2373/3290 [14:46<05:21,  2.86it/s][A[2025-02-04 03:28:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2373/3290, eval_loss: 0.4665, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2374/3290 [14:46<04:54,  3.11it/s][A
step: 2374/3290, eval_loss: 0.4666, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2374/3290 [14:46<04:54,  3.11it/s][A[2025-02-04 03:28:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2374/3290, eval_loss: 0.4666, eval_acc: 0.8756:  72%|[32m███████▏  [0m| 2375/3290 [14:46<04:48,  3.17it/s][A
step: 2375/3290, eval_loss: 0.4670, eval_acc: 0.8755:  72%|[32m███████▏  [0m| 2375/3290 [14:46<04:48,  3.17it/s][A[2025-02-04 03:28:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2375/3290, eval_loss: 0.4670, eval_acc: 0.8755:  72%|[32m███████▏  [0m| 2376/3290 [14:47<04:51,  3.13it/s][A
step: 2376/3290, eval_loss: 0.4671, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2376/3290 [14:47<04:51,  3.13it/s][A[2025-02-04 03:28:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2376/3290, eval_loss: 0.4671, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2377/3290 [14:47<05:12,  2.92it/s][A
step: 2377/3290, eval_loss: 0.4671, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2377/3290 [14:47<05:12,  2.92it/s][A[2025-02-04 03:28:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2377/3290, eval_loss: 0.4671, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2378/3290 [14:47<05:09,  2.95it/s][A
step: 2378/3290, eval_loss: 0.4670, eval_acc: 0.8755:  72%|[32m███████▏  [0m| 2378/3290 [14:47<05:09,  2.95it/s][A[2025-02-04 03:28:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2378/3290, eval_loss: 0.4670, eval_acc: 0.8755:  72%|[32m███████▏  [0m| 2379/3290 [14:48<05:03,  3.01it/s][A
step: 2379/3290, eval_loss: 0.4671, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2379/3290 [14:48<05:03,  3.01it/s][A[2025-02-04 03:28:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2379/3290, eval_loss: 0.4671, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2380/3290 [14:48<04:42,  3.22it/s][A
step: 2380/3290, eval_loss: 0.4670, eval_acc: 0.8755:  72%|[32m███████▏  [0m| 2380/3290 [14:48<04:42,  3.22it/s][A[2025-02-04 03:28:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2380/3290, eval_loss: 0.4670, eval_acc: 0.8755:  72%|[32m███████▏  [0m| 2381/3290 [14:48<05:04,  2.98it/s][A
step: 2381/3290, eval_loss: 0.4672, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2381/3290 [14:48<05:04,  2.98it/s][A[2025-02-04 03:28:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2381/3290, eval_loss: 0.4672, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2382/3290 [14:49<05:00,  3.02it/s][A
step: 2382/3290, eval_loss: 0.4672, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2382/3290 [14:49<05:00,  3.02it/s][A[2025-02-04 03:28:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2382/3290, eval_loss: 0.4672, eval_acc: 0.8754:  72%|[32m███████▏  [0m| 2383/3290 [14:49<04:58,  3.03it/s][A
step: 2383/3290, eval_loss: 0.4674, eval_acc: 0.8753:  72%|[32m███████▏  [0m| 2383/3290 [14:49<04:58,  3.03it/s][A[2025-02-04 03:28:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2383/3290, eval_loss: 0.4674, eval_acc: 0.8753:  72%|[32m███████▏  [0m| 2384/3290 [14:49<05:19,  2.83it/s][A
step: 2384/3290, eval_loss: 0.4676, eval_acc: 0.8753:  72%|[32m███████▏  [0m| 2384/3290 [14:49<05:19,  2.83it/s][A[2025-02-04 03:28:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2384/3290, eval_loss: 0.4676, eval_acc: 0.8753:  72%|[32m███████▏  [0m| 2385/3290 [14:50<06:02,  2.50it/s][A
step: 2385/3290, eval_loss: 0.4676, eval_acc: 0.8753:  72%|[32m███████▏  [0m| 2385/3290 [14:50<06:02,  2.50it/s][A[2025-02-04 03:28:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2385/3290, eval_loss: 0.4676, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2386/3290 [14:50<06:06,  2.47it/s][A
step: 2386/3290, eval_loss: 0.4676, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2386/3290 [14:50<06:06,  2.47it/s][A[2025-02-04 03:28:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2386/3290, eval_loss: 0.4676, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2387/3290 [14:51<06:04,  2.47it/s][A
step: 2387/3290, eval_loss: 0.4676, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2387/3290 [14:51<06:04,  2.47it/s][A[2025-02-04 03:28:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2387/3290, eval_loss: 0.4676, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2388/3290 [14:51<06:01,  2.50it/s][A
step: 2388/3290, eval_loss: 0.4677, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2388/3290 [14:51<06:01,  2.50it/s][A[2025-02-04 03:28:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2388/3290, eval_loss: 0.4677, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2389/3290 [14:52<05:48,  2.59it/s][A
step: 2389/3290, eval_loss: 0.4679, eval_acc: 0.8752:  73%|[32m███████▎  [0m| 2389/3290 [14:52<05:48,  2.59it/s][A[2025-02-04 03:28:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2389/3290, eval_loss: 0.4679, eval_acc: 0.8752:  73%|[32m███████▎  [0m| 2390/3290 [14:52<05:41,  2.64it/s][A
step: 2390/3290, eval_loss: 0.4678, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2390/3290 [14:52<05:41,  2.64it/s][A[2025-02-04 03:28:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2390/3290, eval_loss: 0.4678, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2391/3290 [14:52<05:35,  2.68it/s][A
step: 2391/3290, eval_loss: 0.4678, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2391/3290 [14:52<05:35,  2.68it/s][A[2025-02-04 03:28:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2391/3290, eval_loss: 0.4678, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2392/3290 [14:53<05:22,  2.79it/s][A
step: 2392/3290, eval_loss: 0.4678, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2392/3290 [14:53<05:22,  2.79it/s][A[2025-02-04 03:28:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2392/3290, eval_loss: 0.4678, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2393/3290 [14:53<05:20,  2.80it/s][A
step: 2393/3290, eval_loss: 0.4678, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2393/3290 [14:53<05:20,  2.80it/s][A[2025-02-04 03:28:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2393/3290, eval_loss: 0.4678, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2394/3290 [14:53<05:45,  2.59it/s][A
step: 2394/3290, eval_loss: 0.4678, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2394/3290 [14:53<05:45,  2.59it/s][A[2025-02-04 03:28:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2394/3290, eval_loss: 0.4678, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2395/3290 [14:54<06:06,  2.44it/s][A
step: 2395/3290, eval_loss: 0.4679, eval_acc: 0.8752:  73%|[32m███████▎  [0m| 2395/3290 [14:54<06:06,  2.44it/s][A[2025-02-04 03:28:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2395/3290, eval_loss: 0.4679, eval_acc: 0.8752:  73%|[32m███████▎  [0m| 2396/3290 [14:54<06:24,  2.33it/s][A
step: 2396/3290, eval_loss: 0.4677, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2396/3290 [14:54<06:24,  2.33it/s][A[2025-02-04 03:28:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2396/3290, eval_loss: 0.4677, eval_acc: 0.8753:  73%|[32m███████▎  [0m| 2397/3290 [14:55<06:12,  2.40it/s][A
step: 2397/3290, eval_loss: 0.4679, eval_acc: 0.8752:  73%|[32m███████▎  [0m| 2397/3290 [14:55<06:12,  2.40it/s][A[2025-02-04 03:28:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2397/3290, eval_loss: 0.4679, eval_acc: 0.8752:  73%|[32m███████▎  [0m| 2398/3290 [14:55<05:32,  2.68it/s][A
step: 2398/3290, eval_loss: 0.4683, eval_acc: 0.8751:  73%|[32m███████▎  [0m| 2398/3290 [14:55<05:32,  2.68it/s][A[2025-02-04 03:28:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2398/3290, eval_loss: 0.4683, eval_acc: 0.8751:  73%|[32m███████▎  [0m| 2399/3290 [14:55<04:56,  3.01it/s][A
step: 2399/3290, eval_loss: 0.4685, eval_acc: 0.8751:  73%|[32m███████▎  [0m| 2399/3290 [14:55<04:56,  3.01it/s][A[2025-02-04 03:28:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2399/3290, eval_loss: 0.4685, eval_acc: 0.8751:  73%|[32m███████▎  [0m| 2400/3290 [14:55<04:40,  3.17it/s][A
step: 2400/3290, eval_loss: 0.4688, eval_acc: 0.8750:  73%|[32m███████▎  [0m| 2400/3290 [14:55<04:40,  3.17it/s][A[2025-02-04 03:28:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2400/3290, eval_loss: 0.4688, eval_acc: 0.8750:  73%|[32m███████▎  [0m| 2401/3290 [14:56<05:15,  2.81it/s][A
step: 2401/3290, eval_loss: 0.4690, eval_acc: 0.8749:  73%|[32m███████▎  [0m| 2401/3290 [14:56<05:15,  2.81it/s][A[2025-02-04 03:28:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2401/3290, eval_loss: 0.4690, eval_acc: 0.8749:  73%|[32m███████▎  [0m| 2402/3290 [14:56<05:16,  2.81it/s][A
step: 2402/3290, eval_loss: 0.4689, eval_acc: 0.8749:  73%|[32m███████▎  [0m| 2402/3290 [14:56<05:16,  2.81it/s][A[2025-02-04 03:28:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2402/3290, eval_loss: 0.4689, eval_acc: 0.8749:  73%|[32m███████▎  [0m| 2403/3290 [14:57<05:04,  2.91it/s][A
step: 2403/3290, eval_loss: 0.4691, eval_acc: 0.8749:  73%|[32m███████▎  [0m| 2403/3290 [14:57<05:04,  2.91it/s][A[2025-02-04 03:28:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2403/3290, eval_loss: 0.4691, eval_acc: 0.8749:  73%|[32m███████▎  [0m| 2404/3290 [14:57<05:18,  2.78it/s][A
step: 2404/3290, eval_loss: 0.4692, eval_acc: 0.8749:  73%|[32m███████▎  [0m| 2404/3290 [14:57<05:18,  2.78it/s][A[2025-02-04 03:28:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2404/3290, eval_loss: 0.4692, eval_acc: 0.8749:  73%|[32m███████▎  [0m| 2405/3290 [14:57<04:53,  3.01it/s][A
step: 2405/3290, eval_loss: 0.4697, eval_acc: 0.8748:  73%|[32m███████▎  [0m| 2405/3290 [14:57<04:53,  3.01it/s][A[2025-02-04 03:28:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2405/3290, eval_loss: 0.4697, eval_acc: 0.8748:  73%|[32m███████▎  [0m| 2406/3290 [14:58<05:31,  2.67it/s][A
step: 2406/3290, eval_loss: 0.4697, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2406/3290 [14:58<05:31,  2.67it/s][A[2025-02-04 03:28:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2406/3290, eval_loss: 0.4697, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2407/3290 [14:58<05:56,  2.48it/s][A
step: 2407/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2407/3290 [14:58<05:56,  2.48it/s][A[2025-02-04 03:28:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2407/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2408/3290 [14:59<05:38,  2.60it/s][A
step: 2408/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2408/3290 [14:59<05:38,  2.60it/s][A[2025-02-04 03:28:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2408/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2409/3290 [14:59<05:56,  2.47it/s][A
step: 2409/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2409/3290 [14:59<05:56,  2.47it/s][A[2025-02-04 03:28:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2409/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2410/3290 [15:00<07:02,  2.08it/s][A
step: 2410/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2410/3290 [15:00<07:02,  2.08it/s][A[2025-02-04 03:28:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2410/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2411/3290 [15:00<07:01,  2.08it/s][A
step: 2411/3290, eval_loss: 0.4698, eval_acc: 0.8748:  73%|[32m███████▎  [0m| 2411/3290 [15:00<07:01,  2.08it/s][A[2025-02-04 03:28:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2411/3290, eval_loss: 0.4698, eval_acc: 0.8748:  73%|[32m███████▎  [0m| 2412/3290 [15:01<07:18,  2.00it/s][A
step: 2412/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2412/3290 [15:01<07:18,  2.00it/s][A[2025-02-04 03:28:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2412/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2413/3290 [15:01<06:34,  2.22it/s][A
step: 2413/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2413/3290 [15:01<06:34,  2.22it/s][A[2025-02-04 03:28:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2413/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2414/3290 [15:01<05:57,  2.45it/s][A
step: 2414/3290, eval_loss: 0.4697, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2414/3290 [15:01<05:57,  2.45it/s][A[2025-02-04 03:28:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2414/3290, eval_loss: 0.4697, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2415/3290 [15:02<05:44,  2.54it/s][A
step: 2415/3290, eval_loss: 0.4696, eval_acc: 0.8748:  73%|[32m███████▎  [0m| 2415/3290 [15:02<05:44,  2.54it/s][A[2025-02-04 03:28:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2415/3290, eval_loss: 0.4696, eval_acc: 0.8748:  73%|[32m███████▎  [0m| 2416/3290 [15:02<06:26,  2.26it/s][A
step: 2416/3290, eval_loss: 0.4696, eval_acc: 0.8748:  73%|[32m███████▎  [0m| 2416/3290 [15:02<06:26,  2.26it/s][A[2025-02-04 03:28:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2416/3290, eval_loss: 0.4696, eval_acc: 0.8748:  73%|[32m███████▎  [0m| 2417/3290 [15:03<06:50,  2.13it/s][A
step: 2417/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2417/3290 [15:03<06:50,  2.13it/s][A[2025-02-04 03:28:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2417/3290, eval_loss: 0.4698, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2418/3290 [15:03<07:10,  2.02it/s][A
step: 2418/3290, eval_loss: 0.4699, eval_acc: 0.8747:  73%|[32m███████▎  [0m| 2418/3290 [15:03<07:10,  2.02it/s][A[2025-02-04 03:28:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2418/3290, eval_loss: 0.4699, eval_acc: 0.8747:  74%|[32m███████▎  [0m| 2419/3290 [15:04<06:46,  2.14it/s][A
step: 2419/3290, eval_loss: 0.4699, eval_acc: 0.8747:  74%|[32m███████▎  [0m| 2419/3290 [15:04<06:46,  2.14it/s][A[2025-02-04 03:28:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2419/3290, eval_loss: 0.4699, eval_acc: 0.8747:  74%|[32m███████▎  [0m| 2420/3290 [15:04<07:11,  2.02it/s][A
step: 2420/3290, eval_loss: 0.4702, eval_acc: 0.8746:  74%|[32m███████▎  [0m| 2420/3290 [15:04<07:11,  2.02it/s][A[2025-02-04 03:28:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2420/3290, eval_loss: 0.4702, eval_acc: 0.8746:  74%|[32m███████▎  [0m| 2421/3290 [15:05<07:28,  1.94it/s][A
step: 2421/3290, eval_loss: 0.4702, eval_acc: 0.8746:  74%|[32m███████▎  [0m| 2421/3290 [15:05<07:28,  1.94it/s][A[2025-02-04 03:28:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2421/3290, eval_loss: 0.4702, eval_acc: 0.8746:  74%|[32m███████▎  [0m| 2422/3290 [15:05<07:08,  2.02it/s][A
step: 2422/3290, eval_loss: 0.4705, eval_acc: 0.8745:  74%|[32m███████▎  [0m| 2422/3290 [15:05<07:08,  2.02it/s][A[2025-02-04 03:28:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2422/3290, eval_loss: 0.4705, eval_acc: 0.8745:  74%|[32m███████▎  [0m| 2423/3290 [15:06<06:37,  2.18it/s][A
step: 2423/3290, eval_loss: 0.4706, eval_acc: 0.8745:  74%|[32m███████▎  [0m| 2423/3290 [15:06<06:37,  2.18it/s][A[2025-02-04 03:29:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2423/3290, eval_loss: 0.4706, eval_acc: 0.8745:  74%|[32m███████▎  [0m| 2424/3290 [15:06<05:47,  2.49it/s][A
step: 2424/3290, eval_loss: 0.4708, eval_acc: 0.8745:  74%|[32m███████▎  [0m| 2424/3290 [15:06<05:47,  2.49it/s][A[2025-02-04 03:29:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2424/3290, eval_loss: 0.4708, eval_acc: 0.8745:  74%|[32m███████▎  [0m| 2425/3290 [15:06<04:59,  2.89it/s][A
step: 2425/3290, eval_loss: 0.4708, eval_acc: 0.8745:  74%|[32m███████▎  [0m| 2425/3290 [15:06<04:59,  2.89it/s][A[2025-02-04 03:29:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2425/3290, eval_loss: 0.4708, eval_acc: 0.8745:  74%|[32m███████▎  [0m| 2426/3290 [15:06<04:35,  3.14it/s][A
step: 2426/3290, eval_loss: 0.4708, eval_acc: 0.8745:  74%|[32m███████▎  [0m| 2426/3290 [15:06<04:35,  3.14it/s][A[2025-02-04 03:29:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2426/3290, eval_loss: 0.4708, eval_acc: 0.8745:  74%|[32m███████▍  [0m| 2427/3290 [15:07<04:15,  3.38it/s][A
step: 2427/3290, eval_loss: 0.4709, eval_acc: 0.8745:  74%|[32m███████▍  [0m| 2427/3290 [15:07<04:15,  3.38it/s][A[2025-02-04 03:29:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2427/3290, eval_loss: 0.4709, eval_acc: 0.8745:  74%|[32m███████▍  [0m| 2428/3290 [15:07<04:07,  3.48it/s][A
step: 2428/3290, eval_loss: 0.4710, eval_acc: 0.8744:  74%|[32m███████▍  [0m| 2428/3290 [15:07<04:07,  3.48it/s][A[2025-02-04 03:29:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2428/3290, eval_loss: 0.4710, eval_acc: 0.8744:  74%|[32m███████▍  [0m| 2429/3290 [15:07<04:05,  3.51it/s][A
step: 2429/3290, eval_loss: 0.4714, eval_acc: 0.8743:  74%|[32m███████▍  [0m| 2429/3290 [15:07<04:05,  3.51it/s][A[2025-02-04 03:29:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2429/3290, eval_loss: 0.4714, eval_acc: 0.8743:  74%|[32m███████▍  [0m| 2430/3290 [15:07<04:05,  3.50it/s][A
step: 2430/3290, eval_loss: 0.4716, eval_acc: 0.8743:  74%|[32m███████▍  [0m| 2430/3290 [15:07<04:05,  3.50it/s][A[2025-02-04 03:29:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2430/3290, eval_loss: 0.4716, eval_acc: 0.8743:  74%|[32m███████▍  [0m| 2431/3290 [15:08<03:51,  3.71it/s][A
step: 2431/3290, eval_loss: 0.4718, eval_acc: 0.8743:  74%|[32m███████▍  [0m| 2431/3290 [15:08<03:51,  3.71it/s][A[2025-02-04 03:29:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2431/3290, eval_loss: 0.4718, eval_acc: 0.8743:  74%|[32m███████▍  [0m| 2432/3290 [15:08<04:33,  3.14it/s][A
step: 2432/3290, eval_loss: 0.4719, eval_acc: 0.8742:  74%|[32m███████▍  [0m| 2432/3290 [15:08<04:33,  3.14it/s][A[2025-02-04 03:29:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2432/3290, eval_loss: 0.4719, eval_acc: 0.8742:  74%|[32m███████▍  [0m| 2433/3290 [15:09<04:41,  3.05it/s][A
step: 2433/3290, eval_loss: 0.4721, eval_acc: 0.8742:  74%|[32m███████▍  [0m| 2433/3290 [15:09<04:41,  3.05it/s][A[2025-02-04 03:29:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2433/3290, eval_loss: 0.4721, eval_acc: 0.8742:  74%|[32m███████▍  [0m| 2434/3290 [15:09<04:38,  3.07it/s][A
step: 2434/3290, eval_loss: 0.4722, eval_acc: 0.8741:  74%|[32m███████▍  [0m| 2434/3290 [15:09<04:38,  3.07it/s][A[2025-02-04 03:29:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2434/3290, eval_loss: 0.4722, eval_acc: 0.8741:  74%|[32m███████▍  [0m| 2435/3290 [15:09<04:23,  3.25it/s][A
step: 2435/3290, eval_loss: 0.4723, eval_acc: 0.8741:  74%|[32m███████▍  [0m| 2435/3290 [15:09<04:23,  3.25it/s][A[2025-02-04 03:29:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2435/3290, eval_loss: 0.4723, eval_acc: 0.8741:  74%|[32m███████▍  [0m| 2436/3290 [15:09<04:10,  3.41it/s][A
step: 2436/3290, eval_loss: 0.4726, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2436/3290 [15:09<04:10,  3.41it/s][A[2025-02-04 03:29:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2436/3290, eval_loss: 0.4726, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2437/3290 [15:10<04:09,  3.42it/s][A
step: 2437/3290, eval_loss: 0.4726, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2437/3290 [15:10<04:09,  3.42it/s][A[2025-02-04 03:29:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2437/3290, eval_loss: 0.4726, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2438/3290 [15:10<04:07,  3.44it/s][A
step: 2438/3290, eval_loss: 0.4726, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2438/3290 [15:10<04:07,  3.44it/s][A[2025-02-04 03:29:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2438/3290, eval_loss: 0.4726, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2439/3290 [15:10<04:01,  3.52it/s][A
step: 2439/3290, eval_loss: 0.4727, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2439/3290 [15:10<04:01,  3.52it/s][A[2025-02-04 03:29:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2439/3290, eval_loss: 0.4727, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2440/3290 [15:11<04:07,  3.44it/s][A
step: 2440/3290, eval_loss: 0.4727, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2440/3290 [15:11<04:07,  3.44it/s][A[2025-02-04 03:29:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2440/3290, eval_loss: 0.4727, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2441/3290 [15:11<04:12,  3.36it/s][A
step: 2441/3290, eval_loss: 0.4726, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2441/3290 [15:11<04:12,  3.36it/s][A[2025-02-04 03:29:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2441/3290, eval_loss: 0.4726, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2442/3290 [15:11<04:49,  2.93it/s][A
step: 2442/3290, eval_loss: 0.4725, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2442/3290 [15:11<04:49,  2.93it/s][A[2025-02-04 03:29:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2442/3290, eval_loss: 0.4725, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2443/3290 [15:12<04:51,  2.91it/s][A
step: 2443/3290, eval_loss: 0.4726, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2443/3290 [15:12<04:51,  2.91it/s][A[2025-02-04 03:29:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2443/3290, eval_loss: 0.4726, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2444/3290 [15:12<04:30,  3.13it/s][A
step: 2444/3290, eval_loss: 0.4727, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2444/3290 [15:12<04:30,  3.13it/s][A[2025-02-04 03:29:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2444/3290, eval_loss: 0.4727, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2445/3290 [15:12<04:59,  2.82it/s][A
step: 2445/3290, eval_loss: 0.4727, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2445/3290 [15:12<04:59,  2.82it/s][A[2025-02-04 03:29:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2445/3290, eval_loss: 0.4727, eval_acc: 0.8740:  74%|[32m███████▍  [0m| 2446/3290 [15:13<04:52,  2.89it/s][A
step: 2446/3290, eval_loss: 0.4728, eval_acc: 0.8739:  74%|[32m███████▍  [0m| 2446/3290 [15:13<04:52,  2.89it/s][A[2025-02-04 03:29:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2446/3290, eval_loss: 0.4728, eval_acc: 0.8739:  74%|[32m███████▍  [0m| 2447/3290 [15:13<05:02,  2.78it/s][A
step: 2447/3290, eval_loss: 0.4728, eval_acc: 0.8739:  74%|[32m███████▍  [0m| 2447/3290 [15:13<05:02,  2.78it/s][A[2025-02-04 03:29:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2447/3290, eval_loss: 0.4728, eval_acc: 0.8739:  74%|[32m███████▍  [0m| 2448/3290 [15:13<05:16,  2.66it/s][A
step: 2448/3290, eval_loss: 0.4728, eval_acc: 0.8739:  74%|[32m███████▍  [0m| 2448/3290 [15:13<05:16,  2.66it/s][A[2025-02-04 03:29:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2448/3290, eval_loss: 0.4728, eval_acc: 0.8739:  74%|[32m███████▍  [0m| 2449/3290 [15:14<05:22,  2.61it/s][A
step: 2449/3290, eval_loss: 0.4729, eval_acc: 0.8739:  74%|[32m███████▍  [0m| 2449/3290 [15:14<05:22,  2.61it/s][A[2025-02-04 03:29:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2449/3290, eval_loss: 0.4729, eval_acc: 0.8739:  74%|[32m███████▍  [0m| 2450/3290 [15:14<05:13,  2.68it/s][A
step: 2450/3290, eval_loss: 0.4730, eval_acc: 0.8739:  74%|[32m███████▍  [0m| 2450/3290 [15:14<05:13,  2.68it/s][A[2025-02-04 03:29:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2450/3290, eval_loss: 0.4730, eval_acc: 0.8739:  74%|[32m███████▍  [0m| 2451/3290 [15:14<04:55,  2.84it/s][A
step: 2451/3290, eval_loss: 0.4732, eval_acc: 0.8738:  74%|[32m███████▍  [0m| 2451/3290 [15:14<04:55,  2.84it/s][A[2025-02-04 03:29:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2451/3290, eval_loss: 0.4732, eval_acc: 0.8738:  75%|[32m███████▍  [0m| 2452/3290 [15:15<04:48,  2.91it/s][A
step: 2452/3290, eval_loss: 0.4735, eval_acc: 0.8737:  75%|[32m███████▍  [0m| 2452/3290 [15:15<04:48,  2.91it/s][A[2025-02-04 03:29:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2452/3290, eval_loss: 0.4735, eval_acc: 0.8737:  75%|[32m███████▍  [0m| 2453/3290 [15:15<04:36,  3.03it/s][A
step: 2453/3290, eval_loss: 0.4735, eval_acc: 0.8737:  75%|[32m███████▍  [0m| 2453/3290 [15:15<04:36,  3.03it/s][A[2025-02-04 03:29:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2453/3290, eval_loss: 0.4735, eval_acc: 0.8737:  75%|[32m███████▍  [0m| 2454/3290 [15:15<04:45,  2.93it/s][A
step: 2454/3290, eval_loss: 0.4737, eval_acc: 0.8737:  75%|[32m███████▍  [0m| 2454/3290 [15:15<04:45,  2.93it/s][A[2025-02-04 03:29:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2454/3290, eval_loss: 0.4737, eval_acc: 0.8737:  75%|[32m███████▍  [0m| 2455/3290 [15:16<05:05,  2.73it/s][A
step: 2455/3290, eval_loss: 0.4738, eval_acc: 0.8736:  75%|[32m███████▍  [0m| 2455/3290 [15:16<05:05,  2.73it/s][A[2025-02-04 03:29:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2455/3290, eval_loss: 0.4738, eval_acc: 0.8736:  75%|[32m███████▍  [0m| 2456/3290 [15:16<05:07,  2.72it/s][A
step: 2456/3290, eval_loss: 0.4743, eval_acc: 0.8735:  75%|[32m███████▍  [0m| 2456/3290 [15:16<05:07,  2.72it/s][A[2025-02-04 03:29:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2456/3290, eval_loss: 0.4743, eval_acc: 0.8735:  75%|[32m███████▍  [0m| 2457/3290 [15:17<05:22,  2.58it/s][A
step: 2457/3290, eval_loss: 0.4748, eval_acc: 0.8734:  75%|[32m███████▍  [0m| 2457/3290 [15:17<05:22,  2.58it/s][A[2025-02-04 03:29:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2457/3290, eval_loss: 0.4748, eval_acc: 0.8734:  75%|[32m███████▍  [0m| 2458/3290 [15:17<05:14,  2.65it/s][A
step: 2458/3290, eval_loss: 0.4751, eval_acc: 0.8733:  75%|[32m███████▍  [0m| 2458/3290 [15:17<05:14,  2.65it/s][A[2025-02-04 03:29:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2458/3290, eval_loss: 0.4751, eval_acc: 0.8733:  75%|[32m███████▍  [0m| 2459/3290 [15:17<05:16,  2.62it/s][A
step: 2459/3290, eval_loss: 0.4751, eval_acc: 0.8733:  75%|[32m███████▍  [0m| 2459/3290 [15:17<05:16,  2.62it/s][A[2025-02-04 03:29:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2459/3290, eval_loss: 0.4751, eval_acc: 0.8733:  75%|[32m███████▍  [0m| 2460/3290 [15:18<05:14,  2.64it/s][A
step: 2460/3290, eval_loss: 0.4753, eval_acc: 0.8733:  75%|[32m███████▍  [0m| 2460/3290 [15:18<05:14,  2.64it/s][A[2025-02-04 03:29:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2460/3290, eval_loss: 0.4753, eval_acc: 0.8733:  75%|[32m███████▍  [0m| 2461/3290 [15:18<05:15,  2.63it/s][A
step: 2461/3290, eval_loss: 0.4755, eval_acc: 0.8732:  75%|[32m███████▍  [0m| 2461/3290 [15:18<05:15,  2.63it/s][A[2025-02-04 03:29:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2461/3290, eval_loss: 0.4755, eval_acc: 0.8732:  75%|[32m███████▍  [0m| 2462/3290 [15:19<04:51,  2.84it/s][A
step: 2462/3290, eval_loss: 0.4757, eval_acc: 0.8732:  75%|[32m███████▍  [0m| 2462/3290 [15:19<04:51,  2.84it/s][A[2025-02-04 03:29:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2462/3290, eval_loss: 0.4757, eval_acc: 0.8732:  75%|[32m███████▍  [0m| 2463/3290 [15:19<04:37,  2.98it/s][A
step: 2463/3290, eval_loss: 0.4758, eval_acc: 0.8731:  75%|[32m███████▍  [0m| 2463/3290 [15:19<04:37,  2.98it/s][A[2025-02-04 03:29:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2463/3290, eval_loss: 0.4758, eval_acc: 0.8731:  75%|[32m███████▍  [0m| 2464/3290 [15:19<04:16,  3.22it/s][A
step: 2464/3290, eval_loss: 0.4760, eval_acc: 0.8730:  75%|[32m███████▍  [0m| 2464/3290 [15:19<04:16,  3.22it/s][A[2025-02-04 03:29:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2464/3290, eval_loss: 0.4760, eval_acc: 0.8730:  75%|[32m███████▍  [0m| 2465/3290 [15:19<04:24,  3.12it/s][A
step: 2465/3290, eval_loss: 0.4760, eval_acc: 0.8730:  75%|[32m███████▍  [0m| 2465/3290 [15:19<04:24,  3.12it/s][A[2025-02-04 03:29:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2465/3290, eval_loss: 0.4760, eval_acc: 0.8730:  75%|[32m███████▍  [0m| 2466/3290 [15:20<04:45,  2.89it/s][A
step: 2466/3290, eval_loss: 0.4763, eval_acc: 0.8730:  75%|[32m███████▍  [0m| 2466/3290 [15:20<04:45,  2.89it/s][A[2025-02-04 03:29:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2466/3290, eval_loss: 0.4763, eval_acc: 0.8730:  75%|[32m███████▍  [0m| 2467/3290 [15:20<04:40,  2.93it/s][A
step: 2467/3290, eval_loss: 0.4765, eval_acc: 0.8729:  75%|[32m███████▍  [0m| 2467/3290 [15:20<04:40,  2.93it/s][A[2025-02-04 03:29:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2467/3290, eval_loss: 0.4765, eval_acc: 0.8729:  75%|[32m███████▌  [0m| 2468/3290 [15:20<04:45,  2.88it/s][A
step: 2468/3290, eval_loss: 0.4766, eval_acc: 0.8728:  75%|[32m███████▌  [0m| 2468/3290 [15:20<04:45,  2.88it/s][A[2025-02-04 03:29:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2468/3290, eval_loss: 0.4766, eval_acc: 0.8728:  75%|[32m███████▌  [0m| 2469/3290 [15:21<05:14,  2.61it/s][A
step: 2469/3290, eval_loss: 0.4767, eval_acc: 0.8728:  75%|[32m███████▌  [0m| 2469/3290 [15:21<05:14,  2.61it/s][A[2025-02-04 03:29:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2469/3290, eval_loss: 0.4767, eval_acc: 0.8728:  75%|[32m███████▌  [0m| 2470/3290 [15:21<05:08,  2.65it/s][A
step: 2470/3290, eval_loss: 0.4765, eval_acc: 0.8729:  75%|[32m███████▌  [0m| 2470/3290 [15:21<05:08,  2.65it/s][A[2025-02-04 03:29:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2470/3290, eval_loss: 0.4765, eval_acc: 0.8729:  75%|[32m███████▌  [0m| 2471/3290 [15:22<05:09,  2.65it/s][A
step: 2471/3290, eval_loss: 0.4763, eval_acc: 0.8729:  75%|[32m███████▌  [0m| 2471/3290 [15:22<05:09,  2.65it/s][A[2025-02-04 03:29:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2471/3290, eval_loss: 0.4763, eval_acc: 0.8729:  75%|[32m███████▌  [0m| 2472/3290 [15:22<04:51,  2.81it/s][A
step: 2472/3290, eval_loss: 0.4765, eval_acc: 0.8729:  75%|[32m███████▌  [0m| 2472/3290 [15:22<04:51,  2.81it/s][A[2025-02-04 03:29:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2472/3290, eval_loss: 0.4765, eval_acc: 0.8729:  75%|[32m███████▌  [0m| 2473/3290 [15:22<05:03,  2.69it/s][A
step: 2473/3290, eval_loss: 0.4766, eval_acc: 0.8728:  75%|[32m███████▌  [0m| 2473/3290 [15:22<05:03,  2.69it/s][A[2025-02-04 03:29:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2473/3290, eval_loss: 0.4766, eval_acc: 0.8728:  75%|[32m███████▌  [0m| 2474/3290 [15:23<05:17,  2.57it/s][A
step: 2474/3290, eval_loss: 0.4769, eval_acc: 0.8728:  75%|[32m███████▌  [0m| 2474/3290 [15:23<05:17,  2.57it/s][A[2025-02-04 03:29:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2474/3290, eval_loss: 0.4769, eval_acc: 0.8728:  75%|[32m███████▌  [0m| 2475/3290 [15:23<05:11,  2.62it/s][A
step: 2475/3290, eval_loss: 0.4769, eval_acc: 0.8728:  75%|[32m███████▌  [0m| 2475/3290 [15:23<05:11,  2.62it/s][A[2025-02-04 03:29:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2475/3290, eval_loss: 0.4769, eval_acc: 0.8728:  75%|[32m███████▌  [0m| 2476/3290 [15:24<05:08,  2.64it/s][A
step: 2476/3290, eval_loss: 0.4769, eval_acc: 0.8728:  75%|[32m███████▌  [0m| 2476/3290 [15:24<05:08,  2.64it/s][A[2025-02-04 03:29:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2476/3290, eval_loss: 0.4769, eval_acc: 0.8728:  75%|[32m███████▌  [0m| 2477/3290 [15:24<05:07,  2.64it/s][A
step: 2477/3290, eval_loss: 0.4771, eval_acc: 0.8727:  75%|[32m███████▌  [0m| 2477/3290 [15:24<05:07,  2.64it/s][A[2025-02-04 03:29:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2477/3290, eval_loss: 0.4771, eval_acc: 0.8727:  75%|[32m███████▌  [0m| 2478/3290 [15:24<05:02,  2.69it/s][A
step: 2478/3290, eval_loss: 0.4773, eval_acc: 0.8726:  75%|[32m███████▌  [0m| 2478/3290 [15:24<05:02,  2.69it/s][A[2025-02-04 03:29:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2478/3290, eval_loss: 0.4773, eval_acc: 0.8726:  75%|[32m███████▌  [0m| 2479/3290 [15:25<05:00,  2.70it/s][A
step: 2479/3290, eval_loss: 0.4776, eval_acc: 0.8725:  75%|[32m███████▌  [0m| 2479/3290 [15:25<05:00,  2.70it/s][A[2025-02-04 03:29:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2479/3290, eval_loss: 0.4776, eval_acc: 0.8725:  75%|[32m███████▌  [0m| 2480/3290 [15:25<04:31,  2.99it/s][A
step: 2480/3290, eval_loss: 0.4779, eval_acc: 0.8725:  75%|[32m███████▌  [0m| 2480/3290 [15:25<04:31,  2.99it/s][A[2025-02-04 03:29:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2480/3290, eval_loss: 0.4779, eval_acc: 0.8725:  75%|[32m███████▌  [0m| 2481/3290 [15:25<04:35,  2.94it/s][A
step: 2481/3290, eval_loss: 0.4782, eval_acc: 0.8724:  75%|[32m███████▌  [0m| 2481/3290 [15:25<04:35,  2.94it/s][A[2025-02-04 03:29:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2481/3290, eval_loss: 0.4782, eval_acc: 0.8724:  75%|[32m███████▌  [0m| 2482/3290 [15:26<04:59,  2.70it/s][A
step: 2482/3290, eval_loss: 0.4783, eval_acc: 0.8724:  75%|[32m███████▌  [0m| 2482/3290 [15:26<04:59,  2.70it/s][A[2025-02-04 03:29:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2482/3290, eval_loss: 0.4783, eval_acc: 0.8724:  75%|[32m███████▌  [0m| 2483/3290 [15:26<04:42,  2.86it/s][A
step: 2483/3290, eval_loss: 0.4783, eval_acc: 0.8724:  75%|[32m███████▌  [0m| 2483/3290 [15:26<04:42,  2.86it/s][A[2025-02-04 03:29:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2483/3290, eval_loss: 0.4783, eval_acc: 0.8724:  76%|[32m███████▌  [0m| 2484/3290 [15:26<04:52,  2.75it/s][A
step: 2484/3290, eval_loss: 0.4784, eval_acc: 0.8724:  76%|[32m███████▌  [0m| 2484/3290 [15:26<04:52,  2.75it/s][A[2025-02-04 03:29:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2484/3290, eval_loss: 0.4784, eval_acc: 0.8724:  76%|[32m███████▌  [0m| 2485/3290 [15:27<04:34,  2.93it/s][A
step: 2485/3290, eval_loss: 0.4784, eval_acc: 0.8724:  76%|[32m███████▌  [0m| 2485/3290 [15:27<04:34,  2.93it/s][A[2025-02-04 03:29:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2485/3290, eval_loss: 0.4784, eval_acc: 0.8724:  76%|[32m███████▌  [0m| 2486/3290 [15:27<04:19,  3.09it/s][A
step: 2486/3290, eval_loss: 0.4791, eval_acc: 0.8722:  76%|[32m███████▌  [0m| 2486/3290 [15:27<04:19,  3.09it/s][A[2025-02-04 03:29:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2486/3290, eval_loss: 0.4791, eval_acc: 0.8722:  76%|[32m███████▌  [0m| 2487/3290 [15:27<04:18,  3.11it/s][A
step: 2487/3290, eval_loss: 0.4791, eval_acc: 0.8722:  76%|[32m███████▌  [0m| 2487/3290 [15:27<04:18,  3.11it/s][A[2025-02-04 03:29:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2487/3290, eval_loss: 0.4791, eval_acc: 0.8722:  76%|[32m███████▌  [0m| 2488/3290 [15:28<04:34,  2.92it/s][A
step: 2488/3290, eval_loss: 0.4792, eval_acc: 0.8722:  76%|[32m███████▌  [0m| 2488/3290 [15:28<04:34,  2.92it/s][A[2025-02-04 03:29:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2488/3290, eval_loss: 0.4792, eval_acc: 0.8722:  76%|[32m███████▌  [0m| 2489/3290 [15:28<04:31,  2.95it/s][A
step: 2489/3290, eval_loss: 0.4793, eval_acc: 0.8721:  76%|[32m███████▌  [0m| 2489/3290 [15:28<04:31,  2.95it/s][A[2025-02-04 03:29:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2489/3290, eval_loss: 0.4793, eval_acc: 0.8721:  76%|[32m███████▌  [0m| 2490/3290 [15:28<04:38,  2.87it/s][A
step: 2490/3290, eval_loss: 0.4793, eval_acc: 0.8721:  76%|[32m███████▌  [0m| 2490/3290 [15:28<04:38,  2.87it/s][A[2025-02-04 03:29:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2490/3290, eval_loss: 0.4793, eval_acc: 0.8721:  76%|[32m███████▌  [0m| 2491/3290 [15:29<05:07,  2.60it/s][A
step: 2491/3290, eval_loss: 0.4794, eval_acc: 0.8721:  76%|[32m███████▌  [0m| 2491/3290 [15:29<05:07,  2.60it/s][A[2025-02-04 03:29:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2491/3290, eval_loss: 0.4794, eval_acc: 0.8721:  76%|[32m███████▌  [0m| 2492/3290 [15:29<04:48,  2.77it/s][A
step: 2492/3290, eval_loss: 0.4794, eval_acc: 0.8721:  76%|[32m███████▌  [0m| 2492/3290 [15:29<04:48,  2.77it/s][A[2025-02-04 03:29:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2492/3290, eval_loss: 0.4794, eval_acc: 0.8721:  76%|[32m███████▌  [0m| 2493/3290 [15:29<04:31,  2.94it/s][A
step: 2493/3290, eval_loss: 0.4794, eval_acc: 0.8721:  76%|[32m███████▌  [0m| 2493/3290 [15:29<04:31,  2.94it/s][A[2025-02-04 03:29:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2493/3290, eval_loss: 0.4794, eval_acc: 0.8721:  76%|[32m███████▌  [0m| 2494/3290 [15:30<04:56,  2.68it/s][A
step: 2494/3290, eval_loss: 0.4795, eval_acc: 0.8721:  76%|[32m███████▌  [0m| 2494/3290 [15:30<04:56,  2.68it/s][A[2025-02-04 03:29:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2494/3290, eval_loss: 0.4795, eval_acc: 0.8721:  76%|[32m███████▌  [0m| 2495/3290 [15:30<05:06,  2.59it/s][A
step: 2495/3290, eval_loss: 0.4797, eval_acc: 0.8720:  76%|[32m███████▌  [0m| 2495/3290 [15:30<05:06,  2.59it/s][A[2025-02-04 03:29:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2495/3290, eval_loss: 0.4797, eval_acc: 0.8720:  76%|[32m███████▌  [0m| 2496/3290 [15:31<05:06,  2.59it/s][A
step: 2496/3290, eval_loss: 0.4799, eval_acc: 0.8720:  76%|[32m███████▌  [0m| 2496/3290 [15:31<05:06,  2.59it/s][A[2025-02-04 03:29:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2496/3290, eval_loss: 0.4799, eval_acc: 0.8720:  76%|[32m███████▌  [0m| 2497/3290 [15:31<05:20,  2.47it/s][A
step: 2497/3290, eval_loss: 0.4800, eval_acc: 0.8720:  76%|[32m███████▌  [0m| 2497/3290 [15:31<05:20,  2.47it/s][A[2025-02-04 03:29:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2497/3290, eval_loss: 0.4800, eval_acc: 0.8720:  76%|[32m███████▌  [0m| 2498/3290 [15:32<05:18,  2.49it/s][A
step: 2498/3290, eval_loss: 0.4801, eval_acc: 0.8719:  76%|[32m███████▌  [0m| 2498/3290 [15:32<05:18,  2.49it/s][A[2025-02-04 03:29:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2498/3290, eval_loss: 0.4801, eval_acc: 0.8719:  76%|[32m███████▌  [0m| 2499/3290 [15:32<05:08,  2.56it/s][A
step: 2499/3290, eval_loss: 0.4805, eval_acc: 0.8718:  76%|[32m███████▌  [0m| 2499/3290 [15:32<05:08,  2.56it/s][A[2025-02-04 03:29:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2499/3290, eval_loss: 0.4805, eval_acc: 0.8718:  76%|[32m███████▌  [0m| 2500/3290 [15:32<05:15,  2.50it/s][A
step: 2500/3290, eval_loss: 0.4806, eval_acc: 0.8717:  76%|[32m███████▌  [0m| 2500/3290 [15:32<05:15,  2.50it/s][A[2025-02-04 03:29:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2500/3290, eval_loss: 0.4806, eval_acc: 0.8717:  76%|[32m███████▌  [0m| 2501/3290 [15:33<04:57,  2.65it/s][A
step: 2501/3290, eval_loss: 0.4806, eval_acc: 0.8717:  76%|[32m███████▌  [0m| 2501/3290 [15:33<04:57,  2.65it/s][A[2025-02-04 03:29:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2501/3290, eval_loss: 0.4806, eval_acc: 0.8717:  76%|[32m███████▌  [0m| 2502/3290 [15:33<05:06,  2.57it/s][A
step: 2502/3290, eval_loss: 0.4808, eval_acc: 0.8717:  76%|[32m███████▌  [0m| 2502/3290 [15:33<05:06,  2.57it/s][A[2025-02-04 03:29:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2502/3290, eval_loss: 0.4808, eval_acc: 0.8717:  76%|[32m███████▌  [0m| 2503/3290 [15:33<04:48,  2.72it/s][A
step: 2503/3290, eval_loss: 0.4809, eval_acc: 0.8716:  76%|[32m███████▌  [0m| 2503/3290 [15:33<04:48,  2.72it/s][A[2025-02-04 03:29:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2503/3290, eval_loss: 0.4809, eval_acc: 0.8716:  76%|[32m███████▌  [0m| 2504/3290 [15:34<05:05,  2.58it/s][A
step: 2504/3290, eval_loss: 0.4809, eval_acc: 0.8717:  76%|[32m███████▌  [0m| 2504/3290 [15:34<05:05,  2.58it/s][A[2025-02-04 03:29:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2504/3290, eval_loss: 0.4809, eval_acc: 0.8717:  76%|[32m███████▌  [0m| 2505/3290 [15:34<04:54,  2.67it/s][A
step: 2505/3290, eval_loss: 0.4810, eval_acc: 0.8716:  76%|[32m███████▌  [0m| 2505/3290 [15:34<04:54,  2.67it/s][A[2025-02-04 03:29:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2505/3290, eval_loss: 0.4810, eval_acc: 0.8716:  76%|[32m███████▌  [0m| 2506/3290 [15:35<04:58,  2.63it/s][A
step: 2506/3290, eval_loss: 0.4810, eval_acc: 0.8716:  76%|[32m███████▌  [0m| 2506/3290 [15:35<04:58,  2.63it/s][A[2025-02-04 03:29:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2506/3290, eval_loss: 0.4810, eval_acc: 0.8716:  76%|[32m███████▌  [0m| 2507/3290 [15:35<04:43,  2.76it/s][A
step: 2507/3290, eval_loss: 0.4810, eval_acc: 0.8716:  76%|[32m███████▌  [0m| 2507/3290 [15:35<04:43,  2.76it/s][A[2025-02-04 03:29:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2507/3290, eval_loss: 0.4810, eval_acc: 0.8716:  76%|[32m███████▌  [0m| 2508/3290 [15:35<04:35,  2.83it/s][A
step: 2508/3290, eval_loss: 0.4811, eval_acc: 0.8716:  76%|[32m███████▌  [0m| 2508/3290 [15:35<04:35,  2.83it/s][A[2025-02-04 03:29:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2508/3290, eval_loss: 0.4811, eval_acc: 0.8716:  76%|[32m███████▋  [0m| 2509/3290 [15:36<04:30,  2.89it/s][A
step: 2509/3290, eval_loss: 0.4811, eval_acc: 0.8716:  76%|[32m███████▋  [0m| 2509/3290 [15:36<04:30,  2.89it/s][A[2025-02-04 03:29:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2509/3290, eval_loss: 0.4811, eval_acc: 0.8716:  76%|[32m███████▋  [0m| 2510/3290 [15:36<04:30,  2.88it/s][A
step: 2510/3290, eval_loss: 0.4811, eval_acc: 0.8716:  76%|[32m███████▋  [0m| 2510/3290 [15:36<04:30,  2.88it/s][A[2025-02-04 03:29:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2510/3290, eval_loss: 0.4811, eval_acc: 0.8716:  76%|[32m███████▋  [0m| 2511/3290 [15:36<04:25,  2.93it/s][A
step: 2511/3290, eval_loss: 0.4812, eval_acc: 0.8716:  76%|[32m███████▋  [0m| 2511/3290 [15:36<04:25,  2.93it/s][A[2025-02-04 03:29:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2511/3290, eval_loss: 0.4812, eval_acc: 0.8716:  76%|[32m███████▋  [0m| 2512/3290 [15:37<04:16,  3.03it/s][A
step: 2512/3290, eval_loss: 0.4813, eval_acc: 0.8715:  76%|[32m███████▋  [0m| 2512/3290 [15:37<04:16,  3.03it/s][A[2025-02-04 03:29:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2512/3290, eval_loss: 0.4813, eval_acc: 0.8715:  76%|[32m███████▋  [0m| 2513/3290 [15:37<04:03,  3.19it/s][A
step: 2513/3290, eval_loss: 0.4814, eval_acc: 0.8715:  76%|[32m███████▋  [0m| 2513/3290 [15:37<04:03,  3.19it/s][A[2025-02-04 03:29:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2513/3290, eval_loss: 0.4814, eval_acc: 0.8715:  76%|[32m███████▋  [0m| 2514/3290 [15:37<03:53,  3.33it/s][A
step: 2514/3290, eval_loss: 0.4814, eval_acc: 0.8715:  76%|[32m███████▋  [0m| 2514/3290 [15:37<03:53,  3.33it/s][A[2025-02-04 03:29:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2514/3290, eval_loss: 0.4814, eval_acc: 0.8715:  76%|[32m███████▋  [0m| 2515/3290 [15:37<03:54,  3.31it/s][A
step: 2515/3290, eval_loss: 0.4813, eval_acc: 0.8715:  76%|[32m███████▋  [0m| 2515/3290 [15:37<03:54,  3.31it/s][A[2025-02-04 03:29:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2515/3290, eval_loss: 0.4813, eval_acc: 0.8715:  76%|[32m███████▋  [0m| 2516/3290 [15:38<03:48,  3.39it/s][A
step: 2516/3290, eval_loss: 0.4814, eval_acc: 0.8715:  76%|[32m███████▋  [0m| 2516/3290 [15:38<03:48,  3.39it/s][A[2025-02-04 03:29:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2516/3290, eval_loss: 0.4814, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2517/3290 [15:38<03:57,  3.25it/s][A
step: 2517/3290, eval_loss: 0.4818, eval_acc: 0.8714:  77%|[32m███████▋  [0m| 2517/3290 [15:38<03:57,  3.25it/s][A[2025-02-04 03:29:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2517/3290, eval_loss: 0.4818, eval_acc: 0.8714:  77%|[32m███████▋  [0m| 2518/3290 [15:38<04:31,  2.84it/s][A
step: 2518/3290, eval_loss: 0.4817, eval_acc: 0.8714:  77%|[32m███████▋  [0m| 2518/3290 [15:38<04:31,  2.84it/s][A[2025-02-04 03:29:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2518/3290, eval_loss: 0.4817, eval_acc: 0.8714:  77%|[32m███████▋  [0m| 2519/3290 [15:39<04:53,  2.62it/s][A
step: 2519/3290, eval_loss: 0.4816, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2519/3290 [15:39<04:53,  2.62it/s][A[2025-02-04 03:29:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2519/3290, eval_loss: 0.4816, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2520/3290 [15:39<04:36,  2.79it/s][A
step: 2520/3290, eval_loss: 0.4816, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2520/3290 [15:39<04:36,  2.79it/s][A[2025-02-04 03:29:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2520/3290, eval_loss: 0.4816, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2521/3290 [15:40<04:29,  2.85it/s][A
step: 2521/3290, eval_loss: 0.4815, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2521/3290 [15:40<04:29,  2.85it/s][A[2025-02-04 03:29:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2521/3290, eval_loss: 0.4815, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2522/3290 [15:40<04:39,  2.75it/s][A
step: 2522/3290, eval_loss: 0.4814, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2522/3290 [15:40<04:39,  2.75it/s][A[2025-02-04 03:29:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2522/3290, eval_loss: 0.4814, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2523/3290 [15:40<04:53,  2.61it/s][A
step: 2523/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2523/3290 [15:40<04:53,  2.61it/s][A[2025-02-04 03:29:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2523/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2524/3290 [15:41<05:16,  2.42it/s][A
step: 2524/3290, eval_loss: 0.4812, eval_acc: 0.8716:  77%|[32m███████▋  [0m| 2524/3290 [15:41<05:16,  2.42it/s][A[2025-02-04 03:29:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2524/3290, eval_loss: 0.4812, eval_acc: 0.8716:  77%|[32m███████▋  [0m| 2525/3290 [15:41<05:15,  2.42it/s][A
step: 2525/3290, eval_loss: 0.4812, eval_acc: 0.8716:  77%|[32m███████▋  [0m| 2525/3290 [15:41<05:15,  2.42it/s][A[2025-02-04 03:29:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2525/3290, eval_loss: 0.4812, eval_acc: 0.8716:  77%|[32m███████▋  [0m| 2526/3290 [15:42<04:57,  2.57it/s][A
step: 2526/3290, eval_loss: 0.4812, eval_acc: 0.8716:  77%|[32m███████▋  [0m| 2526/3290 [15:42<04:57,  2.57it/s][A[2025-02-04 03:29:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2526/3290, eval_loss: 0.4812, eval_acc: 0.8716:  77%|[32m███████▋  [0m| 2527/3290 [15:42<05:09,  2.47it/s][A
step: 2527/3290, eval_loss: 0.4812, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2527/3290 [15:42<05:09,  2.47it/s][A[2025-02-04 03:29:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2527/3290, eval_loss: 0.4812, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2528/3290 [15:42<04:39,  2.72it/s][A
step: 2528/3290, eval_loss: 0.4812, eval_acc: 0.8716:  77%|[32m███████▋  [0m| 2528/3290 [15:42<04:39,  2.72it/s][A[2025-02-04 03:29:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2528/3290, eval_loss: 0.4812, eval_acc: 0.8716:  77%|[32m███████▋  [0m| 2529/3290 [15:43<05:05,  2.49it/s][A
step: 2529/3290, eval_loss: 0.4812, eval_acc: 0.8716:  77%|[32m███████▋  [0m| 2529/3290 [15:43<05:05,  2.49it/s][A[2025-02-04 03:29:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2529/3290, eval_loss: 0.4812, eval_acc: 0.8716:  77%|[32m███████▋  [0m| 2530/3290 [15:43<05:14,  2.41it/s][A
step: 2530/3290, eval_loss: 0.4812, eval_acc: 0.8716:  77%|[32m███████▋  [0m| 2530/3290 [15:43<05:14,  2.41it/s][A[2025-02-04 03:29:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2530/3290, eval_loss: 0.4812, eval_acc: 0.8716:  77%|[32m███████▋  [0m| 2531/3290 [15:44<05:09,  2.45it/s][A
step: 2531/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2531/3290 [15:44<05:09,  2.45it/s][A[2025-02-04 03:29:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2531/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2532/3290 [15:44<04:58,  2.54it/s][A
step: 2532/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2532/3290 [15:44<04:58,  2.54it/s][A[2025-02-04 03:29:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2532/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2533/3290 [15:44<04:44,  2.66it/s][A
step: 2533/3290, eval_loss: 0.4814, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2533/3290 [15:44<04:44,  2.66it/s][A[2025-02-04 03:29:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2533/3290, eval_loss: 0.4814, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2534/3290 [15:45<04:36,  2.73it/s][A
step: 2534/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2534/3290 [15:45<04:36,  2.73it/s][A[2025-02-04 03:29:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2534/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2535/3290 [15:45<04:25,  2.84it/s][A
step: 2535/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2535/3290 [15:45<04:25,  2.84it/s][A[2025-02-04 03:29:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2535/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2536/3290 [15:45<04:02,  3.11it/s][A
step: 2536/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2536/3290 [15:45<04:02,  3.11it/s][A[2025-02-04 03:29:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2536/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2537/3290 [15:46<04:18,  2.91it/s][A
step: 2537/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2537/3290 [15:46<04:18,  2.91it/s][A[2025-02-04 03:29:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2537/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2538/3290 [15:46<04:18,  2.90it/s][A
step: 2538/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2538/3290 [15:46<04:18,  2.90it/s][A[2025-02-04 03:29:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2538/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2539/3290 [15:46<04:03,  3.09it/s][A
step: 2539/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2539/3290 [15:46<04:03,  3.09it/s][A[2025-02-04 03:29:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2539/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2540/3290 [15:47<03:48,  3.28it/s][A
step: 2540/3290, eval_loss: 0.4814, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2540/3290 [15:47<03:48,  3.28it/s][A[2025-02-04 03:29:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2540/3290, eval_loss: 0.4814, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2541/3290 [15:47<03:53,  3.21it/s][A
step: 2541/3290, eval_loss: 0.4814, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2541/3290 [15:47<03:53,  3.21it/s][A[2025-02-04 03:29:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2541/3290, eval_loss: 0.4814, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2542/3290 [15:47<04:25,  2.81it/s][A
step: 2542/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2542/3290 [15:47<04:25,  2.81it/s][A[2025-02-04 03:29:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2542/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2543/3290 [15:48<04:48,  2.59it/s][A
step: 2543/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2543/3290 [15:48<04:48,  2.59it/s][A[2025-02-04 03:29:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2543/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2544/3290 [15:48<05:00,  2.48it/s][A
step: 2544/3290, eval_loss: 0.4812, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2544/3290 [15:48<05:00,  2.48it/s][A[2025-02-04 03:29:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2544/3290, eval_loss: 0.4812, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2545/3290 [15:49<05:19,  2.33it/s][A
step: 2545/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2545/3290 [15:49<05:19,  2.33it/s][A[2025-02-04 03:29:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2545/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2546/3290 [15:49<05:33,  2.23it/s][A
step: 2546/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2546/3290 [15:49<05:33,  2.23it/s][A[2025-02-04 03:29:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2546/3290, eval_loss: 0.4813, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2547/3290 [15:50<05:40,  2.18it/s][A
step: 2547/3290, eval_loss: 0.4815, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2547/3290 [15:50<05:40,  2.18it/s][A[2025-02-04 03:29:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2547/3290, eval_loss: 0.4815, eval_acc: 0.8715:  77%|[32m███████▋  [0m| 2548/3290 [15:50<05:15,  2.35it/s][A
step: 2548/3290, eval_loss: 0.4815, eval_acc: 0.8714:  77%|[32m███████▋  [0m| 2548/3290 [15:50<05:15,  2.35it/s][A[2025-02-04 03:29:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2548/3290, eval_loss: 0.4815, eval_acc: 0.8714:  77%|[32m███████▋  [0m| 2549/3290 [15:50<05:16,  2.34it/s][A
step: 2549/3290, eval_loss: 0.4819, eval_acc: 0.8713:  77%|[32m███████▋  [0m| 2549/3290 [15:50<05:16,  2.34it/s][A[2025-02-04 03:29:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2549/3290, eval_loss: 0.4819, eval_acc: 0.8713:  78%|[32m███████▊  [0m| 2550/3290 [15:51<04:55,  2.51it/s][A
step: 2550/3290, eval_loss: 0.4823, eval_acc: 0.8713:  78%|[32m███████▊  [0m| 2550/3290 [15:51<04:55,  2.51it/s][A[2025-02-04 03:29:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2550/3290, eval_loss: 0.4823, eval_acc: 0.8713:  78%|[32m███████▊  [0m| 2551/3290 [15:51<04:35,  2.68it/s][A
step: 2551/3290, eval_loss: 0.4827, eval_acc: 0.8711:  78%|[32m███████▊  [0m| 2551/3290 [15:51<04:35,  2.68it/s][A[2025-02-04 03:29:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2551/3290, eval_loss: 0.4827, eval_acc: 0.8711:  78%|[32m███████▊  [0m| 2552/3290 [15:51<04:16,  2.88it/s][A
step: 2552/3290, eval_loss: 0.4826, eval_acc: 0.8712:  78%|[32m███████▊  [0m| 2552/3290 [15:51<04:16,  2.88it/s][A[2025-02-04 03:29:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2552/3290, eval_loss: 0.4826, eval_acc: 0.8712:  78%|[32m███████▊  [0m| 2553/3290 [15:52<04:12,  2.92it/s][A
step: 2553/3290, eval_loss: 0.4827, eval_acc: 0.8712:  78%|[32m███████▊  [0m| 2553/3290 [15:52<04:12,  2.92it/s][A[2025-02-04 03:29:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2553/3290, eval_loss: 0.4827, eval_acc: 0.8712:  78%|[32m███████▊  [0m| 2554/3290 [15:52<04:17,  2.85it/s][A
step: 2554/3290, eval_loss: 0.4827, eval_acc: 0.8711:  78%|[32m███████▊  [0m| 2554/3290 [15:52<04:17,  2.85it/s][A[2025-02-04 03:29:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2554/3290, eval_loss: 0.4827, eval_acc: 0.8711:  78%|[32m███████▊  [0m| 2555/3290 [15:52<04:17,  2.85it/s][A
step: 2555/3290, eval_loss: 0.4827, eval_acc: 0.8711:  78%|[32m███████▊  [0m| 2555/3290 [15:52<04:17,  2.85it/s][A[2025-02-04 03:29:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2555/3290, eval_loss: 0.4827, eval_acc: 0.8711:  78%|[32m███████▊  [0m| 2556/3290 [15:53<04:41,  2.61it/s][A
step: 2556/3290, eval_loss: 0.4826, eval_acc: 0.8711:  78%|[32m███████▊  [0m| 2556/3290 [15:53<04:41,  2.61it/s][A[2025-02-04 03:29:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2556/3290, eval_loss: 0.4826, eval_acc: 0.8711:  78%|[32m███████▊  [0m| 2557/3290 [15:53<04:23,  2.78it/s][A
step: 2557/3290, eval_loss: 0.4828, eval_acc: 0.8711:  78%|[32m███████▊  [0m| 2557/3290 [15:53<04:23,  2.78it/s][A[2025-02-04 03:29:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2557/3290, eval_loss: 0.4828, eval_acc: 0.8711:  78%|[32m███████▊  [0m| 2558/3290 [15:54<04:17,  2.84it/s][A
step: 2558/3290, eval_loss: 0.4833, eval_acc: 0.8709:  78%|[32m███████▊  [0m| 2558/3290 [15:54<04:17,  2.84it/s][A[2025-02-04 03:29:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2558/3290, eval_loss: 0.4833, eval_acc: 0.8709:  78%|[32m███████▊  [0m| 2559/3290 [15:54<04:23,  2.78it/s][A
step: 2559/3290, eval_loss: 0.4838, eval_acc: 0.8708:  78%|[32m███████▊  [0m| 2559/3290 [15:54<04:23,  2.78it/s][A[2025-02-04 03:29:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2559/3290, eval_loss: 0.4838, eval_acc: 0.8708:  78%|[32m███████▊  [0m| 2560/3290 [15:54<04:34,  2.66it/s][A
step: 2560/3290, eval_loss: 0.4844, eval_acc: 0.8707:  78%|[32m███████▊  [0m| 2560/3290 [15:54<04:34,  2.66it/s][A[2025-02-04 03:29:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2560/3290, eval_loss: 0.4844, eval_acc: 0.8707:  78%|[32m███████▊  [0m| 2561/3290 [15:55<04:16,  2.85it/s][A
step: 2561/3290, eval_loss: 0.4844, eval_acc: 0.8706:  78%|[32m███████▊  [0m| 2561/3290 [15:55<04:16,  2.85it/s][A[2025-02-04 03:29:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2561/3290, eval_loss: 0.4844, eval_acc: 0.8706:  78%|[32m███████▊  [0m| 2562/3290 [15:55<04:36,  2.63it/s][A
step: 2562/3290, eval_loss: 0.4845, eval_acc: 0.8706:  78%|[32m███████▊  [0m| 2562/3290 [15:55<04:36,  2.63it/s][A[2025-02-04 03:29:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2562/3290, eval_loss: 0.4845, eval_acc: 0.8706:  78%|[32m███████▊  [0m| 2563/3290 [15:55<04:41,  2.58it/s][A
step: 2563/3290, eval_loss: 0.4849, eval_acc: 0.8705:  78%|[32m███████▊  [0m| 2563/3290 [15:55<04:41,  2.58it/s][A[2025-02-04 03:29:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2563/3290, eval_loss: 0.4849, eval_acc: 0.8705:  78%|[32m███████▊  [0m| 2564/3290 [15:56<04:48,  2.51it/s][A
step: 2564/3290, eval_loss: 0.4852, eval_acc: 0.8704:  78%|[32m███████▊  [0m| 2564/3290 [15:56<04:48,  2.51it/s][A[2025-02-04 03:29:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2564/3290, eval_loss: 0.4852, eval_acc: 0.8704:  78%|[32m███████▊  [0m| 2565/3290 [15:56<04:39,  2.59it/s][A
step: 2565/3290, eval_loss: 0.4855, eval_acc: 0.8704:  78%|[32m███████▊  [0m| 2565/3290 [15:56<04:39,  2.59it/s][A[2025-02-04 03:29:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2565/3290, eval_loss: 0.4855, eval_acc: 0.8704:  78%|[32m███████▊  [0m| 2566/3290 [15:57<04:52,  2.48it/s][A
step: 2566/3290, eval_loss: 0.4857, eval_acc: 0.8703:  78%|[32m███████▊  [0m| 2566/3290 [15:57<04:52,  2.48it/s][A[2025-02-04 03:29:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2566/3290, eval_loss: 0.4857, eval_acc: 0.8703:  78%|[32m███████▊  [0m| 2567/3290 [15:57<04:40,  2.58it/s][A
step: 2567/3290, eval_loss: 0.4858, eval_acc: 0.8703:  78%|[32m███████▊  [0m| 2567/3290 [15:57<04:40,  2.58it/s][A[2025-02-04 03:29:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2567/3290, eval_loss: 0.4858, eval_acc: 0.8703:  78%|[32m███████▊  [0m| 2568/3290 [15:57<04:14,  2.83it/s][A
step: 2568/3290, eval_loss: 0.4859, eval_acc: 0.8702:  78%|[32m███████▊  [0m| 2568/3290 [15:57<04:14,  2.83it/s][A[2025-02-04 03:29:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2568/3290, eval_loss: 0.4859, eval_acc: 0.8702:  78%|[32m███████▊  [0m| 2569/3290 [15:58<04:11,  2.87it/s][A
step: 2569/3290, eval_loss: 0.4858, eval_acc: 0.8703:  78%|[32m███████▊  [0m| 2569/3290 [15:58<04:11,  2.87it/s][A[2025-02-04 03:29:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2569/3290, eval_loss: 0.4858, eval_acc: 0.8703:  78%|[32m███████▊  [0m| 2570/3290 [15:58<04:05,  2.93it/s][A
step: 2570/3290, eval_loss: 0.4862, eval_acc: 0.8702:  78%|[32m███████▊  [0m| 2570/3290 [15:58<04:05,  2.93it/s][A[2025-02-04 03:29:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2570/3290, eval_loss: 0.4862, eval_acc: 0.8702:  78%|[32m███████▊  [0m| 2571/3290 [15:58<04:18,  2.78it/s][A
step: 2571/3290, eval_loss: 0.4865, eval_acc: 0.8701:  78%|[32m███████▊  [0m| 2571/3290 [15:58<04:18,  2.78it/s][A[2025-02-04 03:29:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2571/3290, eval_loss: 0.4865, eval_acc: 0.8701:  78%|[32m███████▊  [0m| 2572/3290 [15:59<04:15,  2.81it/s][A
step: 2572/3290, eval_loss: 0.4869, eval_acc: 0.8699:  78%|[32m███████▊  [0m| 2572/3290 [15:59<04:15,  2.81it/s][A[2025-02-04 03:29:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2572/3290, eval_loss: 0.4869, eval_acc: 0.8699:  78%|[32m███████▊  [0m| 2573/3290 [15:59<04:23,  2.72it/s][A
step: 2573/3290, eval_loss: 0.4871, eval_acc: 0.8698:  78%|[32m███████▊  [0m| 2573/3290 [15:59<04:23,  2.72it/s][A[2025-02-04 03:29:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2573/3290, eval_loss: 0.4871, eval_acc: 0.8698:  78%|[32m███████▊  [0m| 2574/3290 [15:59<04:22,  2.73it/s][A
step: 2574/3290, eval_loss: 0.4874, eval_acc: 0.8697:  78%|[32m███████▊  [0m| 2574/3290 [16:00<04:22,  2.73it/s][A[2025-02-04 03:29:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2574/3290, eval_loss: 0.4874, eval_acc: 0.8697:  78%|[32m███████▊  [0m| 2575/3290 [16:00<04:20,  2.75it/s][A
step: 2575/3290, eval_loss: 0.4878, eval_acc: 0.8695:  78%|[32m███████▊  [0m| 2575/3290 [16:00<04:20,  2.75it/s][A[2025-02-04 03:29:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2575/3290, eval_loss: 0.4878, eval_acc: 0.8695:  78%|[32m███████▊  [0m| 2576/3290 [16:00<04:13,  2.82it/s][A
step: 2576/3290, eval_loss: 0.4880, eval_acc: 0.8695:  78%|[32m███████▊  [0m| 2576/3290 [16:00<04:13,  2.82it/s][A[2025-02-04 03:29:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2576/3290, eval_loss: 0.4880, eval_acc: 0.8695:  78%|[32m███████▊  [0m| 2577/3290 [16:01<04:19,  2.74it/s][A
step: 2577/3290, eval_loss: 0.4879, eval_acc: 0.8695:  78%|[32m███████▊  [0m| 2577/3290 [16:01<04:19,  2.74it/s][A[2025-02-04 03:29:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2577/3290, eval_loss: 0.4879, eval_acc: 0.8695:  78%|[32m███████▊  [0m| 2578/3290 [16:01<04:33,  2.60it/s][A
step: 2578/3290, eval_loss: 0.4878, eval_acc: 0.8696:  78%|[32m███████▊  [0m| 2578/3290 [16:01<04:33,  2.60it/s][A[2025-02-04 03:29:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2578/3290, eval_loss: 0.4878, eval_acc: 0.8696:  78%|[32m███████▊  [0m| 2579/3290 [16:01<04:17,  2.76it/s][A
step: 2579/3290, eval_loss: 0.4876, eval_acc: 0.8696:  78%|[32m███████▊  [0m| 2579/3290 [16:01<04:17,  2.76it/s][A[2025-02-04 03:29:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2579/3290, eval_loss: 0.4876, eval_acc: 0.8696:  78%|[32m███████▊  [0m| 2580/3290 [16:02<04:15,  2.78it/s][A
step: 2580/3290, eval_loss: 0.4877, eval_acc: 0.8696:  78%|[32m███████▊  [0m| 2580/3290 [16:02<04:15,  2.78it/s][A[2025-02-04 03:29:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2580/3290, eval_loss: 0.4877, eval_acc: 0.8696:  78%|[32m███████▊  [0m| 2581/3290 [16:02<04:15,  2.77it/s][A
step: 2581/3290, eval_loss: 0.4877, eval_acc: 0.8696:  78%|[32m███████▊  [0m| 2581/3290 [16:02<04:15,  2.77it/s][A[2025-02-04 03:29:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2581/3290, eval_loss: 0.4877, eval_acc: 0.8696:  78%|[32m███████▊  [0m| 2582/3290 [16:02<04:30,  2.62it/s][A
step: 2582/3290, eval_loss: 0.4879, eval_acc: 0.8695:  78%|[32m███████▊  [0m| 2582/3290 [16:02<04:30,  2.62it/s][A[2025-02-04 03:29:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2582/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▊  [0m| 2583/3290 [16:03<04:18,  2.74it/s][A
step: 2583/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▊  [0m| 2583/3290 [16:03<04:18,  2.74it/s][A[2025-02-04 03:29:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2583/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▊  [0m| 2584/3290 [16:03<04:12,  2.80it/s][A
step: 2584/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▊  [0m| 2584/3290 [16:03<04:12,  2.80it/s][A[2025-02-04 03:29:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2584/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▊  [0m| 2585/3290 [16:04<04:37,  2.54it/s][A
step: 2585/3290, eval_loss: 0.4878, eval_acc: 0.8695:  79%|[32m███████▊  [0m| 2585/3290 [16:04<04:37,  2.54it/s][A[2025-02-04 03:29:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2585/3290, eval_loss: 0.4878, eval_acc: 0.8695:  79%|[32m███████▊  [0m| 2586/3290 [16:04<04:42,  2.50it/s][A
step: 2586/3290, eval_loss: 0.4878, eval_acc: 0.8696:  79%|[32m███████▊  [0m| 2586/3290 [16:04<04:42,  2.50it/s][A[2025-02-04 03:29:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2586/3290, eval_loss: 0.4878, eval_acc: 0.8696:  79%|[32m███████▊  [0m| 2587/3290 [16:04<04:30,  2.60it/s][A
step: 2587/3290, eval_loss: 0.4877, eval_acc: 0.8696:  79%|[32m███████▊  [0m| 2587/3290 [16:04<04:30,  2.60it/s][A[2025-02-04 03:29:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2587/3290, eval_loss: 0.4877, eval_acc: 0.8696:  79%|[32m███████▊  [0m| 2588/3290 [16:05<04:45,  2.46it/s][A
step: 2588/3290, eval_loss: 0.4877, eval_acc: 0.8696:  79%|[32m███████▊  [0m| 2588/3290 [16:05<04:45,  2.46it/s][A[2025-02-04 03:29:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2588/3290, eval_loss: 0.4877, eval_acc: 0.8696:  79%|[32m███████▊  [0m| 2589/3290 [16:05<04:37,  2.53it/s][A
step: 2589/3290, eval_loss: 0.4877, eval_acc: 0.8696:  79%|[32m███████▊  [0m| 2589/3290 [16:05<04:37,  2.53it/s][A[2025-02-04 03:29:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2589/3290, eval_loss: 0.4877, eval_acc: 0.8696:  79%|[32m███████▊  [0m| 2590/3290 [16:06<04:46,  2.45it/s][A
step: 2590/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▊  [0m| 2590/3290 [16:06<04:46,  2.45it/s][A[2025-02-04 03:30:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2590/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2591/3290 [16:06<04:59,  2.33it/s][A
step: 2591/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2591/3290 [16:06<04:59,  2.33it/s][A[2025-02-04 03:30:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2591/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2592/3290 [16:06<04:28,  2.60it/s][A
step: 2592/3290, eval_loss: 0.4878, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2592/3290 [16:06<04:28,  2.60it/s][A[2025-02-04 03:30:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2592/3290, eval_loss: 0.4878, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2593/3290 [16:07<04:22,  2.65it/s][A
step: 2593/3290, eval_loss: 0.4878, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2593/3290 [16:07<04:22,  2.65it/s][A[2025-02-04 03:30:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2593/3290, eval_loss: 0.4878, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2594/3290 [16:07<04:34,  2.53it/s][A
step: 2594/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2594/3290 [16:07<04:34,  2.53it/s][A[2025-02-04 03:30:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2594/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2595/3290 [16:08<04:38,  2.50it/s][A
step: 2595/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2595/3290 [16:08<04:38,  2.50it/s][A[2025-02-04 03:30:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2595/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2596/3290 [16:08<05:02,  2.29it/s][A
step: 2596/3290, eval_loss: 0.4880, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2596/3290 [16:08<05:02,  2.29it/s][A[2025-02-04 03:30:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2596/3290, eval_loss: 0.4880, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2597/3290 [16:08<04:36,  2.51it/s][A
step: 2597/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2597/3290 [16:08<04:36,  2.51it/s][A[2025-02-04 03:30:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2597/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2598/3290 [16:09<04:32,  2.54it/s][A
step: 2598/3290, eval_loss: 0.4880, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2598/3290 [16:09<04:32,  2.54it/s][A[2025-02-04 03:30:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2598/3290, eval_loss: 0.4880, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2599/3290 [16:09<04:43,  2.44it/s][A
step: 2599/3290, eval_loss: 0.4880, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2599/3290 [16:09<04:43,  2.44it/s][A[2025-02-04 03:30:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2599/3290, eval_loss: 0.4880, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2600/3290 [16:10<04:52,  2.36it/s][A
step: 2600/3290, eval_loss: 0.4880, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2600/3290 [16:10<04:52,  2.36it/s][A[2025-02-04 03:30:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2600/3290, eval_loss: 0.4880, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2601/3290 [16:10<04:44,  2.42it/s][A
step: 2601/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2601/3290 [16:10<04:44,  2.42it/s][A[2025-02-04 03:30:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2601/3290, eval_loss: 0.4879, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2602/3290 [16:10<04:19,  2.65it/s][A
step: 2602/3290, eval_loss: 0.4878, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2602/3290 [16:10<04:19,  2.65it/s][A[2025-02-04 03:30:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2602/3290, eval_loss: 0.4878, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2603/3290 [16:11<04:10,  2.74it/s][A
step: 2603/3290, eval_loss: 0.4877, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2603/3290 [16:11<04:10,  2.74it/s][A[2025-02-04 03:30:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2603/3290, eval_loss: 0.4877, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2604/3290 [16:11<04:18,  2.65it/s][A
step: 2604/3290, eval_loss: 0.4878, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2604/3290 [16:11<04:18,  2.65it/s][A[2025-02-04 03:30:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2604/3290, eval_loss: 0.4878, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2605/3290 [16:11<04:06,  2.78it/s][A
step: 2605/3290, eval_loss: 0.4877, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2605/3290 [16:11<04:06,  2.78it/s][A[2025-02-04 03:30:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2605/3290, eval_loss: 0.4877, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2606/3290 [16:12<04:06,  2.78it/s][A
step: 2606/3290, eval_loss: 0.4877, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2606/3290 [16:12<04:06,  2.78it/s][A[2025-02-04 03:30:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2606/3290, eval_loss: 0.4877, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2607/3290 [16:12<03:50,  2.96it/s][A
step: 2607/3290, eval_loss: 0.4877, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2607/3290 [16:12<03:50,  2.96it/s][A[2025-02-04 03:30:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2607/3290, eval_loss: 0.4877, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2608/3290 [16:13<04:09,  2.74it/s][A
step: 2608/3290, eval_loss: 0.4878, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2608/3290 [16:13<04:09,  2.74it/s][A[2025-02-04 03:30:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2608/3290, eval_loss: 0.4878, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2609/3290 [16:13<04:23,  2.59it/s][A
step: 2609/3290, eval_loss: 0.4877, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2609/3290 [16:13<04:23,  2.59it/s][A[2025-02-04 03:30:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2609/3290, eval_loss: 0.4877, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2610/3290 [16:13<04:17,  2.64it/s][A
step: 2610/3290, eval_loss: 0.4876, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2610/3290 [16:13<04:17,  2.64it/s][A[2025-02-04 03:30:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2610/3290, eval_loss: 0.4876, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2611/3290 [16:14<04:21,  2.60it/s][A
step: 2611/3290, eval_loss: 0.4875, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2611/3290 [16:14<04:21,  2.60it/s][A[2025-02-04 03:30:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2611/3290, eval_loss: 0.4875, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2612/3290 [16:14<04:23,  2.57it/s][A
step: 2612/3290, eval_loss: 0.4875, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2612/3290 [16:14<04:23,  2.57it/s][A[2025-02-04 03:30:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2612/3290, eval_loss: 0.4875, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2613/3290 [16:15<04:36,  2.44it/s][A
step: 2613/3290, eval_loss: 0.4875, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2613/3290 [16:15<04:36,  2.44it/s][A[2025-02-04 03:30:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2613/3290, eval_loss: 0.4875, eval_acc: 0.8695:  79%|[32m███████▉  [0m| 2614/3290 [16:15<04:28,  2.52it/s][A
step: 2614/3290, eval_loss: 0.4875, eval_acc: 0.8696:  79%|[32m███████▉  [0m| 2614/3290 [16:15<04:28,  2.52it/s][A[2025-02-04 03:30:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2614/3290, eval_loss: 0.4875, eval_acc: 0.8696:  79%|[32m███████▉  [0m| 2615/3290 [16:15<04:37,  2.43it/s][A
step: 2615/3290, eval_loss: 0.4875, eval_acc: 0.8696:  79%|[32m███████▉  [0m| 2615/3290 [16:15<04:37,  2.43it/s][A[2025-02-04 03:30:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2615/3290, eval_loss: 0.4875, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2616/3290 [16:16<04:31,  2.49it/s][A
step: 2616/3290, eval_loss: 0.4874, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2616/3290 [16:16<04:31,  2.49it/s][A[2025-02-04 03:30:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2616/3290, eval_loss: 0.4874, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2617/3290 [16:16<04:38,  2.42it/s][A
step: 2617/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2617/3290 [16:16<04:38,  2.42it/s][A[2025-02-04 03:30:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2617/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2618/3290 [16:17<04:09,  2.69it/s][A
step: 2618/3290, eval_loss: 0.4874, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2618/3290 [16:17<04:09,  2.69it/s][A[2025-02-04 03:30:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2618/3290, eval_loss: 0.4874, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2619/3290 [16:17<04:13,  2.65it/s][A
step: 2619/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2619/3290 [16:17<04:13,  2.65it/s][A[2025-02-04 03:30:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2619/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2620/3290 [16:17<03:58,  2.81it/s][A
step: 2620/3290, eval_loss: 0.4872, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2620/3290 [16:17<03:58,  2.81it/s][A[2025-02-04 03:30:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2620/3290, eval_loss: 0.4872, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2621/3290 [16:18<04:00,  2.78it/s][A
step: 2621/3290, eval_loss: 0.4874, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2621/3290 [16:18<04:00,  2.78it/s][A[2025-02-04 03:30:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2621/3290, eval_loss: 0.4874, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2622/3290 [16:18<04:06,  2.71it/s][A
step: 2622/3290, eval_loss: 0.4874, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2622/3290 [16:18<04:06,  2.71it/s][A[2025-02-04 03:30:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2622/3290, eval_loss: 0.4874, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2623/3290 [16:18<04:06,  2.70it/s][A
step: 2623/3290, eval_loss: 0.4874, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2623/3290 [16:18<04:06,  2.70it/s][A[2025-02-04 03:30:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2623/3290, eval_loss: 0.4874, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2624/3290 [16:19<04:22,  2.54it/s][A
step: 2624/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2624/3290 [16:19<04:22,  2.54it/s][A[2025-02-04 03:30:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2624/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2625/3290 [16:19<04:16,  2.59it/s][A
step: 2625/3290, eval_loss: 0.4872, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2625/3290 [16:19<04:16,  2.59it/s][A[2025-02-04 03:30:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2625/3290, eval_loss: 0.4872, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2626/3290 [16:20<04:21,  2.54it/s][A
step: 2626/3290, eval_loss: 0.4872, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2626/3290 [16:20<04:21,  2.54it/s][A[2025-02-04 03:30:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2626/3290, eval_loss: 0.4872, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2627/3290 [16:20<05:14,  2.11it/s][A
step: 2627/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2627/3290 [16:20<05:14,  2.11it/s][A[2025-02-04 03:30:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2627/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2628/3290 [16:21<05:11,  2.13it/s][A
step: 2628/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2628/3290 [16:21<05:11,  2.13it/s][A[2025-02-04 03:30:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2628/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2629/3290 [16:21<05:03,  2.18it/s][A
step: 2629/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2629/3290 [16:21<05:03,  2.18it/s][A[2025-02-04 03:30:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2629/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2630/3290 [16:22<04:53,  2.25it/s][A
step: 2630/3290, eval_loss: 0.4874, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2630/3290 [16:22<04:53,  2.25it/s][A[2025-02-04 03:30:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2630/3290, eval_loss: 0.4874, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2631/3290 [16:22<04:56,  2.22it/s][A
step: 2631/3290, eval_loss: 0.4872, eval_acc: 0.8696:  80%|[32m███████▉  [0m| 2631/3290 [16:22<04:56,  2.22it/s][A[2025-02-04 03:30:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2631/3290, eval_loss: 0.4872, eval_acc: 0.8696:  80%|[32m████████  [0m| 2632/3290 [16:22<04:22,  2.51it/s][A
step: 2632/3290, eval_loss: 0.4872, eval_acc: 0.8696:  80%|[32m████████  [0m| 2632/3290 [16:22<04:22,  2.51it/s][A[2025-02-04 03:30:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2632/3290, eval_loss: 0.4872, eval_acc: 0.8696:  80%|[32m████████  [0m| 2633/3290 [16:23<04:42,  2.33it/s][A
step: 2633/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m████████  [0m| 2633/3290 [16:23<04:42,  2.33it/s][A[2025-02-04 03:30:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2633/3290, eval_loss: 0.4873, eval_acc: 0.8696:  80%|[32m████████  [0m| 2634/3290 [16:23<04:56,  2.21it/s][A
step: 2634/3290, eval_loss: 0.4873, eval_acc: 0.8695:  80%|[32m████████  [0m| 2634/3290 [16:23<04:56,  2.21it/s][A[2025-02-04 03:30:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2634/3290, eval_loss: 0.4873, eval_acc: 0.8695:  80%|[32m████████  [0m| 2635/3290 [16:24<04:53,  2.23it/s][A
step: 2635/3290, eval_loss: 0.4874, eval_acc: 0.8695:  80%|[32m████████  [0m| 2635/3290 [16:24<04:53,  2.23it/s][A[2025-02-04 03:30:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2635/3290, eval_loss: 0.4874, eval_acc: 0.8695:  80%|[32m████████  [0m| 2636/3290 [16:24<04:43,  2.30it/s][A
step: 2636/3290, eval_loss: 0.4877, eval_acc: 0.8695:  80%|[32m████████  [0m| 2636/3290 [16:24<04:43,  2.30it/s][A[2025-02-04 03:30:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2636/3290, eval_loss: 0.4877, eval_acc: 0.8695:  80%|[32m████████  [0m| 2637/3290 [16:24<04:29,  2.42it/s][A
step: 2637/3290, eval_loss: 0.4876, eval_acc: 0.8695:  80%|[32m████████  [0m| 2637/3290 [16:24<04:29,  2.42it/s][A[2025-02-04 03:30:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2637/3290, eval_loss: 0.4876, eval_acc: 0.8695:  80%|[32m████████  [0m| 2638/3290 [16:25<04:08,  2.62it/s][A
step: 2638/3290, eval_loss: 0.4874, eval_acc: 0.8695:  80%|[32m████████  [0m| 2638/3290 [16:25<04:08,  2.62it/s][A[2025-02-04 03:30:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2638/3290, eval_loss: 0.4874, eval_acc: 0.8695:  80%|[32m████████  [0m| 2639/3290 [16:25<03:57,  2.75it/s][A
step: 2639/3290, eval_loss: 0.4874, eval_acc: 0.8695:  80%|[32m████████  [0m| 2639/3290 [16:25<03:57,  2.75it/s][A[2025-02-04 03:30:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2639/3290, eval_loss: 0.4874, eval_acc: 0.8695:  80%|[32m████████  [0m| 2640/3290 [16:25<03:38,  2.98it/s][A
step: 2640/3290, eval_loss: 0.4876, eval_acc: 0.8695:  80%|[32m████████  [0m| 2640/3290 [16:25<03:38,  2.98it/s][A[2025-02-04 03:30:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2640/3290, eval_loss: 0.4876, eval_acc: 0.8695:  80%|[32m████████  [0m| 2641/3290 [16:26<04:37,  2.34it/s][A
step: 2641/3290, eval_loss: 0.4875, eval_acc: 0.8695:  80%|[32m████████  [0m| 2641/3290 [16:26<04:37,  2.34it/s][A[2025-02-04 03:30:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2641/3290, eval_loss: 0.4875, eval_acc: 0.8695:  80%|[32m████████  [0m| 2642/3290 [16:26<04:45,  2.27it/s][A
step: 2642/3290, eval_loss: 0.4875, eval_acc: 0.8695:  80%|[32m████████  [0m| 2642/3290 [16:26<04:45,  2.27it/s][A[2025-02-04 03:30:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2642/3290, eval_loss: 0.4875, eval_acc: 0.8695:  80%|[32m████████  [0m| 2643/3290 [16:27<05:14,  2.06it/s][A
step: 2643/3290, eval_loss: 0.4875, eval_acc: 0.8695:  80%|[32m████████  [0m| 2643/3290 [16:27<05:14,  2.06it/s][A[2025-02-04 03:30:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2643/3290, eval_loss: 0.4875, eval_acc: 0.8695:  80%|[32m████████  [0m| 2644/3290 [16:28<05:07,  2.10it/s][A
step: 2644/3290, eval_loss: 0.4875, eval_acc: 0.8695:  80%|[32m████████  [0m| 2644/3290 [16:28<05:07,  2.10it/s][A[2025-02-04 03:30:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2644/3290, eval_loss: 0.4875, eval_acc: 0.8695:  80%|[32m████████  [0m| 2645/3290 [16:28<04:50,  2.22it/s][A
step: 2645/3290, eval_loss: 0.4875, eval_acc: 0.8695:  80%|[32m████████  [0m| 2645/3290 [16:28<04:50,  2.22it/s][A[2025-02-04 03:30:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2645/3290, eval_loss: 0.4875, eval_acc: 0.8695:  80%|[32m████████  [0m| 2646/3290 [16:28<04:23,  2.44it/s][A
step: 2646/3290, eval_loss: 0.4875, eval_acc: 0.8695:  80%|[32m████████  [0m| 2646/3290 [16:28<04:23,  2.44it/s][A[2025-02-04 03:30:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2646/3290, eval_loss: 0.4875, eval_acc: 0.8695:  80%|[32m████████  [0m| 2647/3290 [16:29<04:19,  2.48it/s][A
step: 2647/3290, eval_loss: 0.4876, eval_acc: 0.8695:  80%|[32m████████  [0m| 2647/3290 [16:29<04:19,  2.48it/s][A[2025-02-04 03:30:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2647/3290, eval_loss: 0.4876, eval_acc: 0.8695:  80%|[32m████████  [0m| 2648/3290 [16:29<04:02,  2.65it/s][A
step: 2648/3290, eval_loss: 0.4877, eval_acc: 0.8694:  80%|[32m████████  [0m| 2648/3290 [16:29<04:02,  2.65it/s][A[2025-02-04 03:30:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2648/3290, eval_loss: 0.4877, eval_acc: 0.8694:  81%|[32m████████  [0m| 2649/3290 [16:29<03:45,  2.84it/s][A
step: 2649/3290, eval_loss: 0.4878, eval_acc: 0.8694:  81%|[32m████████  [0m| 2649/3290 [16:29<03:45,  2.84it/s][A[2025-02-04 03:30:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2649/3290, eval_loss: 0.4878, eval_acc: 0.8694:  81%|[32m████████  [0m| 2650/3290 [16:30<03:35,  2.98it/s][A
step: 2650/3290, eval_loss: 0.4880, eval_acc: 0.8693:  81%|[32m████████  [0m| 2650/3290 [16:30<03:35,  2.98it/s][A[2025-02-04 03:30:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2650/3290, eval_loss: 0.4880, eval_acc: 0.8693:  81%|[32m████████  [0m| 2651/3290 [16:30<03:30,  3.04it/s][A
step: 2651/3290, eval_loss: 0.4881, eval_acc: 0.8693:  81%|[32m████████  [0m| 2651/3290 [16:30<03:30,  3.04it/s][A[2025-02-04 03:30:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2651/3290, eval_loss: 0.4881, eval_acc: 0.8693:  81%|[32m████████  [0m| 2652/3290 [16:30<03:37,  2.93it/s][A
step: 2652/3290, eval_loss: 0.4882, eval_acc: 0.8693:  81%|[32m████████  [0m| 2652/3290 [16:30<03:37,  2.93it/s][A[2025-02-04 03:30:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2652/3290, eval_loss: 0.4882, eval_acc: 0.8693:  81%|[32m████████  [0m| 2653/3290 [16:31<03:43,  2.85it/s][A
step: 2653/3290, eval_loss: 0.4882, eval_acc: 0.8693:  81%|[32m████████  [0m| 2653/3290 [16:31<03:43,  2.85it/s][A[2025-02-04 03:30:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2653/3290, eval_loss: 0.4882, eval_acc: 0.8693:  81%|[32m████████  [0m| 2654/3290 [16:31<03:59,  2.65it/s][A
step: 2654/3290, eval_loss: 0.4883, eval_acc: 0.8692:  81%|[32m████████  [0m| 2654/3290 [16:31<03:59,  2.65it/s][A[2025-02-04 03:30:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2654/3290, eval_loss: 0.4883, eval_acc: 0.8692:  81%|[32m████████  [0m| 2655/3290 [16:31<03:57,  2.68it/s][A
step: 2655/3290, eval_loss: 0.4882, eval_acc: 0.8693:  81%|[32m████████  [0m| 2655/3290 [16:31<03:57,  2.68it/s][A[2025-02-04 03:30:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2655/3290, eval_loss: 0.4882, eval_acc: 0.8693:  81%|[32m████████  [0m| 2656/3290 [16:32<03:43,  2.83it/s][A
step: 2656/3290, eval_loss: 0.4882, eval_acc: 0.8692:  81%|[32m████████  [0m| 2656/3290 [16:32<03:43,  2.83it/s][A[2025-02-04 03:30:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2656/3290, eval_loss: 0.4882, eval_acc: 0.8692:  81%|[32m████████  [0m| 2657/3290 [16:32<04:01,  2.62it/s][A
step: 2657/3290, eval_loss: 0.4883, eval_acc: 0.8692:  81%|[32m████████  [0m| 2657/3290 [16:32<04:01,  2.62it/s][A[2025-02-04 03:30:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2657/3290, eval_loss: 0.4883, eval_acc: 0.8692:  81%|[32m████████  [0m| 2658/3290 [16:33<04:13,  2.49it/s][A
step: 2658/3290, eval_loss: 0.4887, eval_acc: 0.8691:  81%|[32m████████  [0m| 2658/3290 [16:33<04:13,  2.49it/s][A[2025-02-04 03:30:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2658/3290, eval_loss: 0.4887, eval_acc: 0.8691:  81%|[32m████████  [0m| 2659/3290 [16:33<04:23,  2.40it/s][A
step: 2659/3290, eval_loss: 0.4888, eval_acc: 0.8691:  81%|[32m████████  [0m| 2659/3290 [16:33<04:23,  2.40it/s][A[2025-02-04 03:30:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2659/3290, eval_loss: 0.4888, eval_acc: 0.8691:  81%|[32m████████  [0m| 2660/3290 [16:33<04:12,  2.49it/s][A
step: 2660/3290, eval_loss: 0.4890, eval_acc: 0.8690:  81%|[32m████████  [0m| 2660/3290 [16:33<04:12,  2.49it/s][A[2025-02-04 03:30:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2660/3290, eval_loss: 0.4890, eval_acc: 0.8690:  81%|[32m████████  [0m| 2661/3290 [16:34<04:27,  2.35it/s][A
step: 2661/3290, eval_loss: 0.4891, eval_acc: 0.8689:  81%|[32m████████  [0m| 2661/3290 [16:34<04:27,  2.35it/s][A[2025-02-04 03:30:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2661/3290, eval_loss: 0.4891, eval_acc: 0.8689:  81%|[32m████████  [0m| 2662/3290 [16:34<04:25,  2.37it/s][A
step: 2662/3290, eval_loss: 0.4894, eval_acc: 0.8688:  81%|[32m████████  [0m| 2662/3290 [16:34<04:25,  2.37it/s][A[2025-02-04 03:30:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2662/3290, eval_loss: 0.4894, eval_acc: 0.8688:  81%|[32m████████  [0m| 2663/3290 [16:35<04:08,  2.52it/s][A
step: 2663/3290, eval_loss: 0.4895, eval_acc: 0.8688:  81%|[32m████████  [0m| 2663/3290 [16:35<04:08,  2.52it/s][A[2025-02-04 03:30:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2663/3290, eval_loss: 0.4895, eval_acc: 0.8688:  81%|[32m████████  [0m| 2664/3290 [16:35<03:40,  2.84it/s][A
step: 2664/3290, eval_loss: 0.4895, eval_acc: 0.8688:  81%|[32m████████  [0m| 2664/3290 [16:35<03:40,  2.84it/s][A[2025-02-04 03:30:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2664/3290, eval_loss: 0.4895, eval_acc: 0.8688:  81%|[32m████████  [0m| 2665/3290 [16:35<03:36,  2.89it/s][A
step: 2665/3290, eval_loss: 0.4894, eval_acc: 0.8688:  81%|[32m████████  [0m| 2665/3290 [16:35<03:36,  2.89it/s][A[2025-02-04 03:30:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2665/3290, eval_loss: 0.4894, eval_acc: 0.8688:  81%|[32m████████  [0m| 2666/3290 [16:36<03:42,  2.80it/s][A
step: 2666/3290, eval_loss: 0.4894, eval_acc: 0.8688:  81%|[32m████████  [0m| 2666/3290 [16:36<03:42,  2.80it/s][A[2025-02-04 03:30:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2666/3290, eval_loss: 0.4894, eval_acc: 0.8688:  81%|[32m████████  [0m| 2667/3290 [16:36<03:41,  2.81it/s][A
step: 2667/3290, eval_loss: 0.4893, eval_acc: 0.8688:  81%|[32m████████  [0m| 2667/3290 [16:36<03:41,  2.81it/s][A[2025-02-04 03:30:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2667/3290, eval_loss: 0.4893, eval_acc: 0.8688:  81%|[32m████████  [0m| 2668/3290 [16:36<03:36,  2.88it/s][A
step: 2668/3290, eval_loss: 0.4895, eval_acc: 0.8688:  81%|[32m████████  [0m| 2668/3290 [16:36<03:36,  2.88it/s][A[2025-02-04 03:30:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2668/3290, eval_loss: 0.4895, eval_acc: 0.8688:  81%|[32m████████  [0m| 2669/3290 [16:37<03:20,  3.09it/s][A
step: 2669/3290, eval_loss: 0.4896, eval_acc: 0.8688:  81%|[32m████████  [0m| 2669/3290 [16:37<03:20,  3.09it/s][A[2025-02-04 03:30:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2669/3290, eval_loss: 0.4896, eval_acc: 0.8688:  81%|[32m████████  [0m| 2670/3290 [16:37<03:23,  3.05it/s][A
step: 2670/3290, eval_loss: 0.4897, eval_acc: 0.8687:  81%|[32m████████  [0m| 2670/3290 [16:37<03:23,  3.05it/s][A[2025-02-04 03:30:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2670/3290, eval_loss: 0.4897, eval_acc: 0.8687:  81%|[32m████████  [0m| 2671/3290 [16:37<03:21,  3.07it/s][A
step: 2671/3290, eval_loss: 0.4897, eval_acc: 0.8687:  81%|[32m████████  [0m| 2671/3290 [16:37<03:21,  3.07it/s][A[2025-02-04 03:30:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2671/3290, eval_loss: 0.4897, eval_acc: 0.8687:  81%|[32m████████  [0m| 2672/3290 [16:38<03:30,  2.94it/s][A
step: 2672/3290, eval_loss: 0.4908, eval_acc: 0.8685:  81%|[32m████████  [0m| 2672/3290 [16:38<03:30,  2.94it/s][A[2025-02-04 03:30:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2672/3290, eval_loss: 0.4908, eval_acc: 0.8685:  81%|[32m████████  [0m| 2673/3290 [16:38<03:27,  2.97it/s][A
step: 2673/3290, eval_loss: 0.4912, eval_acc: 0.8684:  81%|[32m████████  [0m| 2673/3290 [16:38<03:27,  2.97it/s][A[2025-02-04 03:30:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2673/3290, eval_loss: 0.4912, eval_acc: 0.8684:  81%|[32m████████▏ [0m| 2674/3290 [16:38<03:25,  3.00it/s][A
step: 2674/3290, eval_loss: 0.4926, eval_acc: 0.8682:  81%|[32m████████▏ [0m| 2674/3290 [16:38<03:25,  3.00it/s][A[2025-02-04 03:30:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2674/3290, eval_loss: 0.4926, eval_acc: 0.8682:  81%|[32m████████▏ [0m| 2675/3290 [16:39<03:19,  3.08it/s][A
step: 2675/3290, eval_loss: 0.4930, eval_acc: 0.8681:  81%|[32m████████▏ [0m| 2675/3290 [16:39<03:19,  3.08it/s][A[2025-02-04 03:30:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2675/3290, eval_loss: 0.4930, eval_acc: 0.8681:  81%|[32m████████▏ [0m| 2676/3290 [16:39<03:39,  2.80it/s][A
step: 2676/3290, eval_loss: 0.4935, eval_acc: 0.8680:  81%|[32m████████▏ [0m| 2676/3290 [16:39<03:39,  2.80it/s][A[2025-02-04 03:30:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2676/3290, eval_loss: 0.4935, eval_acc: 0.8680:  81%|[32m████████▏ [0m| 2677/3290 [16:39<03:41,  2.76it/s][A
step: 2677/3290, eval_loss: 0.4935, eval_acc: 0.8679:  81%|[32m████████▏ [0m| 2677/3290 [16:39<03:41,  2.76it/s][A[2025-02-04 03:30:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2677/3290, eval_loss: 0.4935, eval_acc: 0.8679:  81%|[32m████████▏ [0m| 2678/3290 [16:40<03:41,  2.76it/s][A
step: 2678/3290, eval_loss: 0.4938, eval_acc: 0.8678:  81%|[32m████████▏ [0m| 2678/3290 [16:40<03:41,  2.76it/s][A[2025-02-04 03:30:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2678/3290, eval_loss: 0.4938, eval_acc: 0.8678:  81%|[32m████████▏ [0m| 2679/3290 [16:40<03:50,  2.65it/s][A
step: 2679/3290, eval_loss: 0.4939, eval_acc: 0.8678:  81%|[32m████████▏ [0m| 2679/3290 [16:40<03:50,  2.65it/s][A[2025-02-04 03:30:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2679/3290, eval_loss: 0.4939, eval_acc: 0.8678:  81%|[32m████████▏ [0m| 2680/3290 [16:41<04:03,  2.51it/s][A
step: 2680/3290, eval_loss: 0.4939, eval_acc: 0.8678:  81%|[32m████████▏ [0m| 2680/3290 [16:41<04:03,  2.51it/s][A[2025-02-04 03:30:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2680/3290, eval_loss: 0.4939, eval_acc: 0.8678:  81%|[32m████████▏ [0m| 2681/3290 [16:41<04:07,  2.46it/s][A
step: 2681/3290, eval_loss: 0.4941, eval_acc: 0.8677:  81%|[32m████████▏ [0m| 2681/3290 [16:41<04:07,  2.46it/s][A[2025-02-04 03:30:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2681/3290, eval_loss: 0.4941, eval_acc: 0.8677:  82%|[32m████████▏ [0m| 2682/3290 [16:41<04:02,  2.51it/s][A
step: 2682/3290, eval_loss: 0.4941, eval_acc: 0.8677:  82%|[32m████████▏ [0m| 2682/3290 [16:41<04:02,  2.51it/s][A[2025-02-04 03:30:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2682/3290, eval_loss: 0.4941, eval_acc: 0.8677:  82%|[32m████████▏ [0m| 2683/3290 [16:42<03:55,  2.58it/s][A
step: 2683/3290, eval_loss: 0.4942, eval_acc: 0.8676:  82%|[32m████████▏ [0m| 2683/3290 [16:42<03:55,  2.58it/s][A[2025-02-04 03:30:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2683/3290, eval_loss: 0.4942, eval_acc: 0.8676:  82%|[32m████████▏ [0m| 2684/3290 [16:42<03:30,  2.87it/s][A
step: 2684/3290, eval_loss: 0.4946, eval_acc: 0.8675:  82%|[32m████████▏ [0m| 2684/3290 [16:42<03:30,  2.87it/s][A[2025-02-04 03:30:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2684/3290, eval_loss: 0.4946, eval_acc: 0.8675:  82%|[32m████████▏ [0m| 2685/3290 [16:42<03:23,  2.98it/s][A
step: 2685/3290, eval_loss: 0.4947, eval_acc: 0.8675:  82%|[32m████████▏ [0m| 2685/3290 [16:42<03:23,  2.98it/s][A[2025-02-04 03:30:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2685/3290, eval_loss: 0.4947, eval_acc: 0.8675:  82%|[32m████████▏ [0m| 2686/3290 [16:43<03:14,  3.10it/s][A
step: 2686/3290, eval_loss: 0.4947, eval_acc: 0.8675:  82%|[32m████████▏ [0m| 2686/3290 [16:43<03:14,  3.10it/s][A[2025-02-04 03:30:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2686/3290, eval_loss: 0.4947, eval_acc: 0.8675:  82%|[32m████████▏ [0m| 2687/3290 [16:43<03:02,  3.30it/s][A
step: 2687/3290, eval_loss: 0.4947, eval_acc: 0.8675:  82%|[32m████████▏ [0m| 2687/3290 [16:43<03:02,  3.30it/s][A[2025-02-04 03:30:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2687/3290, eval_loss: 0.4947, eval_acc: 0.8675:  82%|[32m████████▏ [0m| 2688/3290 [16:43<02:56,  3.41it/s][A
step: 2688/3290, eval_loss: 0.4950, eval_acc: 0.8674:  82%|[32m████████▏ [0m| 2688/3290 [16:43<02:56,  3.41it/s][A[2025-02-04 03:30:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2688/3290, eval_loss: 0.4950, eval_acc: 0.8674:  82%|[32m████████▏ [0m| 2689/3290 [16:43<02:53,  3.46it/s][A
step: 2689/3290, eval_loss: 0.4952, eval_acc: 0.8674:  82%|[32m████████▏ [0m| 2689/3290 [16:43<02:53,  3.46it/s][A[2025-02-04 03:30:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2689/3290, eval_loss: 0.4952, eval_acc: 0.8674:  82%|[32m████████▏ [0m| 2690/3290 [16:44<02:48,  3.57it/s][A
step: 2690/3290, eval_loss: 0.4953, eval_acc: 0.8674:  82%|[32m████████▏ [0m| 2690/3290 [16:44<02:48,  3.57it/s][A[2025-02-04 03:30:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2690/3290, eval_loss: 0.4953, eval_acc: 0.8674:  82%|[32m████████▏ [0m| 2691/3290 [16:44<02:44,  3.65it/s][A
step: 2691/3290, eval_loss: 0.4957, eval_acc: 0.8673:  82%|[32m████████▏ [0m| 2691/3290 [16:44<02:44,  3.65it/s][A[2025-02-04 03:30:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2691/3290, eval_loss: 0.4957, eval_acc: 0.8673:  82%|[32m████████▏ [0m| 2692/3290 [16:44<02:40,  3.73it/s][A
step: 2692/3290, eval_loss: 0.4957, eval_acc: 0.8672:  82%|[32m████████▏ [0m| 2692/3290 [16:44<02:40,  3.73it/s][A[2025-02-04 03:30:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2692/3290, eval_loss: 0.4957, eval_acc: 0.8672:  82%|[32m████████▏ [0m| 2693/3290 [16:45<03:00,  3.31it/s][A
step: 2693/3290, eval_loss: 0.4957, eval_acc: 0.8672:  82%|[32m████████▏ [0m| 2693/3290 [16:45<03:00,  3.31it/s][A[2025-02-04 03:30:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2693/3290, eval_loss: 0.4957, eval_acc: 0.8672:  82%|[32m████████▏ [0m| 2694/3290 [16:45<03:03,  3.25it/s][A
step: 2694/3290, eval_loss: 0.4960, eval_acc: 0.8672:  82%|[32m████████▏ [0m| 2694/3290 [16:45<03:03,  3.25it/s][A[2025-02-04 03:30:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2694/3290, eval_loss: 0.4960, eval_acc: 0.8672:  82%|[32m████████▏ [0m| 2695/3290 [16:45<02:55,  3.39it/s][A
step: 2695/3290, eval_loss: 0.4962, eval_acc: 0.8671:  82%|[32m████████▏ [0m| 2695/3290 [16:45<02:55,  3.39it/s][A[2025-02-04 03:30:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2695/3290, eval_loss: 0.4962, eval_acc: 0.8671:  82%|[32m████████▏ [0m| 2696/3290 [16:46<03:17,  3.01it/s][A
step: 2696/3290, eval_loss: 0.4965, eval_acc: 0.8670:  82%|[32m████████▏ [0m| 2696/3290 [16:46<03:17,  3.01it/s][A[2025-02-04 03:30:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2696/3290, eval_loss: 0.4965, eval_acc: 0.8670:  82%|[32m████████▏ [0m| 2697/3290 [16:46<03:33,  2.78it/s][A
step: 2697/3290, eval_loss: 0.4966, eval_acc: 0.8670:  82%|[32m████████▏ [0m| 2697/3290 [16:46<03:33,  2.78it/s][A[2025-02-04 03:30:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2697/3290, eval_loss: 0.4966, eval_acc: 0.8670:  82%|[32m████████▏ [0m| 2698/3290 [16:46<03:23,  2.91it/s][A
step: 2698/3290, eval_loss: 0.4964, eval_acc: 0.8670:  82%|[32m████████▏ [0m| 2698/3290 [16:46<03:23,  2.91it/s][A[2025-02-04 03:30:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2698/3290, eval_loss: 0.4964, eval_acc: 0.8670:  82%|[32m████████▏ [0m| 2699/3290 [16:47<03:26,  2.86it/s][A
step: 2699/3290, eval_loss: 0.4964, eval_acc: 0.8670:  82%|[32m████████▏ [0m| 2699/3290 [16:47<03:26,  2.86it/s][A[2025-02-04 03:30:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2699/3290, eval_loss: 0.4964, eval_acc: 0.8670:  82%|[32m████████▏ [0m| 2700/3290 [16:47<03:26,  2.85it/s][A
step: 2700/3290, eval_loss: 0.4967, eval_acc: 0.8669:  82%|[32m████████▏ [0m| 2700/3290 [16:47<03:26,  2.85it/s][A[2025-02-04 03:30:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2700/3290, eval_loss: 0.4967, eval_acc: 0.8669:  82%|[32m████████▏ [0m| 2701/3290 [16:47<03:34,  2.75it/s][A
step: 2701/3290, eval_loss: 0.4969, eval_acc: 0.8668:  82%|[32m████████▏ [0m| 2701/3290 [16:47<03:34,  2.75it/s][A[2025-02-04 03:30:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2701/3290, eval_loss: 0.4969, eval_acc: 0.8668:  82%|[32m████████▏ [0m| 2702/3290 [16:48<03:24,  2.87it/s][A
step: 2702/3290, eval_loss: 0.4971, eval_acc: 0.8668:  82%|[32m████████▏ [0m| 2702/3290 [16:48<03:24,  2.87it/s][A[2025-02-04 03:30:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2702/3290, eval_loss: 0.4971, eval_acc: 0.8668:  82%|[32m████████▏ [0m| 2703/3290 [16:48<03:26,  2.84it/s][A
step: 2703/3290, eval_loss: 0.4975, eval_acc: 0.8666:  82%|[32m████████▏ [0m| 2703/3290 [16:48<03:26,  2.84it/s][A[2025-02-04 03:30:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2703/3290, eval_loss: 0.4975, eval_acc: 0.8666:  82%|[32m████████▏ [0m| 2704/3290 [16:48<03:19,  2.93it/s][A
step: 2704/3290, eval_loss: 0.4978, eval_acc: 0.8665:  82%|[32m████████▏ [0m| 2704/3290 [16:48<03:19,  2.93it/s][A[2025-02-04 03:30:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2704/3290, eval_loss: 0.4978, eval_acc: 0.8665:  82%|[32m████████▏ [0m| 2705/3290 [16:49<03:28,  2.80it/s][A
step: 2705/3290, eval_loss: 0.4982, eval_acc: 0.8665:  82%|[32m████████▏ [0m| 2705/3290 [16:49<03:28,  2.80it/s][A[2025-02-04 03:30:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2705/3290, eval_loss: 0.4982, eval_acc: 0.8665:  82%|[32m████████▏ [0m| 2706/3290 [16:49<03:45,  2.59it/s][A
step: 2706/3290, eval_loss: 0.4984, eval_acc: 0.8664:  82%|[32m████████▏ [0m| 2706/3290 [16:49<03:45,  2.59it/s][A[2025-02-04 03:30:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2706/3290, eval_loss: 0.4984, eval_acc: 0.8664:  82%|[32m████████▏ [0m| 2707/3290 [16:50<03:42,  2.62it/s][A
step: 2707/3290, eval_loss: 0.4984, eval_acc: 0.8664:  82%|[32m████████▏ [0m| 2707/3290 [16:50<03:42,  2.62it/s][A[2025-02-04 03:30:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2707/3290, eval_loss: 0.4984, eval_acc: 0.8664:  82%|[32m████████▏ [0m| 2708/3290 [16:50<03:37,  2.68it/s][A
step: 2708/3290, eval_loss: 0.4985, eval_acc: 0.8663:  82%|[32m████████▏ [0m| 2708/3290 [16:50<03:37,  2.68it/s][A[2025-02-04 03:30:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2708/3290, eval_loss: 0.4985, eval_acc: 0.8663:  82%|[32m████████▏ [0m| 2709/3290 [16:50<03:52,  2.50it/s][A
step: 2709/3290, eval_loss: 0.4986, eval_acc: 0.8663:  82%|[32m████████▏ [0m| 2709/3290 [16:50<03:52,  2.50it/s][A[2025-02-04 03:30:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2709/3290, eval_loss: 0.4986, eval_acc: 0.8663:  82%|[32m████████▏ [0m| 2710/3290 [16:51<03:41,  2.62it/s][A
step: 2710/3290, eval_loss: 0.4986, eval_acc: 0.8663:  82%|[32m████████▏ [0m| 2710/3290 [16:51<03:41,  2.62it/s][A[2025-02-04 03:30:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2710/3290, eval_loss: 0.4986, eval_acc: 0.8663:  82%|[32m████████▏ [0m| 2711/3290 [16:51<03:46,  2.55it/s][A
step: 2711/3290, eval_loss: 0.4987, eval_acc: 0.8663:  82%|[32m████████▏ [0m| 2711/3290 [16:51<03:46,  2.55it/s][A[2025-02-04 03:30:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2711/3290, eval_loss: 0.4987, eval_acc: 0.8663:  82%|[32m████████▏ [0m| 2712/3290 [16:52<03:33,  2.70it/s][A
step: 2712/3290, eval_loss: 0.4989, eval_acc: 0.8663:  82%|[32m████████▏ [0m| 2712/3290 [16:52<03:33,  2.70it/s][A[2025-02-04 03:30:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2712/3290, eval_loss: 0.4989, eval_acc: 0.8663:  82%|[32m████████▏ [0m| 2713/3290 [16:52<03:29,  2.75it/s][A
step: 2713/3290, eval_loss: 0.4990, eval_acc: 0.8662:  82%|[32m████████▏ [0m| 2713/3290 [16:52<03:29,  2.75it/s][A[2025-02-04 03:30:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2713/3290, eval_loss: 0.4990, eval_acc: 0.8662:  82%|[32m████████▏ [0m| 2714/3290 [16:52<03:26,  2.79it/s][A
step: 2714/3290, eval_loss: 0.4991, eval_acc: 0.8662:  82%|[32m████████▏ [0m| 2714/3290 [16:52<03:26,  2.79it/s][A[2025-02-04 03:30:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2714/3290, eval_loss: 0.4991, eval_acc: 0.8662:  83%|[32m████████▎ [0m| 2715/3290 [16:53<03:28,  2.76it/s][A
step: 2715/3290, eval_loss: 0.4990, eval_acc: 0.8663:  83%|[32m████████▎ [0m| 2715/3290 [16:53<03:28,  2.76it/s][A[2025-02-04 03:30:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2715/3290, eval_loss: 0.4990, eval_acc: 0.8663:  83%|[32m████████▎ [0m| 2716/3290 [16:53<03:08,  3.04it/s][A
step: 2716/3290, eval_loss: 0.4991, eval_acc: 0.8662:  83%|[32m████████▎ [0m| 2716/3290 [16:53<03:08,  3.04it/s][A[2025-02-04 03:30:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2716/3290, eval_loss: 0.4991, eval_acc: 0.8662:  83%|[32m████████▎ [0m| 2717/3290 [16:53<03:31,  2.71it/s][A
step: 2717/3290, eval_loss: 0.4994, eval_acc: 0.8661:  83%|[32m████████▎ [0m| 2717/3290 [16:53<03:31,  2.71it/s][A[2025-02-04 03:30:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2717/3290, eval_loss: 0.4994, eval_acc: 0.8661:  83%|[32m████████▎ [0m| 2718/3290 [16:54<03:22,  2.83it/s][A
step: 2718/3290, eval_loss: 0.4996, eval_acc: 0.8661:  83%|[32m████████▎ [0m| 2718/3290 [16:54<03:22,  2.83it/s][A[2025-02-04 03:30:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2718/3290, eval_loss: 0.4996, eval_acc: 0.8661:  83%|[32m████████▎ [0m| 2719/3290 [16:54<03:28,  2.74it/s][A
step: 2719/3290, eval_loss: 0.4997, eval_acc: 0.8660:  83%|[32m████████▎ [0m| 2719/3290 [16:54<03:28,  2.74it/s][A[2025-02-04 03:30:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2719/3290, eval_loss: 0.4997, eval_acc: 0.8660:  83%|[32m████████▎ [0m| 2720/3290 [16:54<03:28,  2.73it/s][A
step: 2720/3290, eval_loss: 0.4998, eval_acc: 0.8660:  83%|[32m████████▎ [0m| 2720/3290 [16:54<03:28,  2.73it/s][A[2025-02-04 03:30:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2720/3290, eval_loss: 0.4998, eval_acc: 0.8660:  83%|[32m████████▎ [0m| 2721/3290 [16:55<03:23,  2.79it/s][A
step: 2721/3290, eval_loss: 0.4998, eval_acc: 0.8660:  83%|[32m████████▎ [0m| 2721/3290 [16:55<03:23,  2.79it/s][A[2025-02-04 03:30:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2721/3290, eval_loss: 0.4998, eval_acc: 0.8660:  83%|[32m████████▎ [0m| 2722/3290 [16:55<03:12,  2.94it/s][A
step: 2722/3290, eval_loss: 0.4998, eval_acc: 0.8660:  83%|[32m████████▎ [0m| 2722/3290 [16:55<03:12,  2.94it/s][A[2025-02-04 03:30:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2722/3290, eval_loss: 0.4998, eval_acc: 0.8660:  83%|[32m████████▎ [0m| 2723/3290 [16:55<02:55,  3.24it/s][A
step: 2723/3290, eval_loss: 0.4998, eval_acc: 0.8660:  83%|[32m████████▎ [0m| 2723/3290 [16:55<02:55,  3.24it/s][A[2025-02-04 03:30:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2723/3290, eval_loss: 0.4998, eval_acc: 0.8660:  83%|[32m████████▎ [0m| 2724/3290 [16:56<03:20,  2.83it/s][A
step: 2724/3290, eval_loss: 0.4999, eval_acc: 0.8659:  83%|[32m████████▎ [0m| 2724/3290 [16:56<03:20,  2.83it/s][A[2025-02-04 03:30:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2724/3290, eval_loss: 0.4999, eval_acc: 0.8659:  83%|[32m████████▎ [0m| 2725/3290 [16:56<03:35,  2.62it/s][A
step: 2725/3290, eval_loss: 0.5000, eval_acc: 0.8659:  83%|[32m████████▎ [0m| 2725/3290 [16:56<03:35,  2.62it/s][A[2025-02-04 03:30:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2725/3290, eval_loss: 0.5000, eval_acc: 0.8659:  83%|[32m████████▎ [0m| 2726/3290 [16:57<03:51,  2.43it/s][A
step: 2726/3290, eval_loss: 0.5001, eval_acc: 0.8659:  83%|[32m████████▎ [0m| 2726/3290 [16:57<03:51,  2.43it/s][A[2025-02-04 03:30:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2726/3290, eval_loss: 0.5001, eval_acc: 0.8659:  83%|[32m████████▎ [0m| 2727/3290 [16:57<03:49,  2.45it/s][A
step: 2727/3290, eval_loss: 0.5002, eval_acc: 0.8658:  83%|[32m████████▎ [0m| 2727/3290 [16:57<03:49,  2.45it/s][A[2025-02-04 03:30:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2727/3290, eval_loss: 0.5002, eval_acc: 0.8658:  83%|[32m████████▎ [0m| 2728/3290 [16:57<03:35,  2.61it/s][A
step: 2728/3290, eval_loss: 0.5006, eval_acc: 0.8658:  83%|[32m████████▎ [0m| 2728/3290 [16:57<03:35,  2.61it/s][A[2025-02-04 03:30:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2728/3290, eval_loss: 0.5006, eval_acc: 0.8658:  83%|[32m████████▎ [0m| 2729/3290 [16:58<03:32,  2.64it/s][A
step: 2729/3290, eval_loss: 0.5006, eval_acc: 0.8657:  83%|[32m████████▎ [0m| 2729/3290 [16:58<03:32,  2.64it/s][A[2025-02-04 03:30:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2729/3290, eval_loss: 0.5006, eval_acc: 0.8657:  83%|[32m████████▎ [0m| 2730/3290 [16:58<03:13,  2.89it/s][A
step: 2730/3290, eval_loss: 0.5009, eval_acc: 0.8656:  83%|[32m████████▎ [0m| 2730/3290 [16:58<03:13,  2.89it/s][A[2025-02-04 03:30:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2730/3290, eval_loss: 0.5009, eval_acc: 0.8656:  83%|[32m████████▎ [0m| 2731/3290 [16:58<03:09,  2.94it/s][A
step: 2731/3290, eval_loss: 0.5009, eval_acc: 0.8656:  83%|[32m████████▎ [0m| 2731/3290 [16:58<03:09,  2.94it/s][A[2025-02-04 03:30:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2731/3290, eval_loss: 0.5009, eval_acc: 0.8656:  83%|[32m████████▎ [0m| 2732/3290 [16:59<03:13,  2.88it/s][A
step: 2732/3290, eval_loss: 0.5009, eval_acc: 0.8657:  83%|[32m████████▎ [0m| 2732/3290 [16:59<03:13,  2.88it/s][A[2025-02-04 03:30:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2732/3290, eval_loss: 0.5009, eval_acc: 0.8657:  83%|[32m████████▎ [0m| 2733/3290 [16:59<03:01,  3.07it/s][A
step: 2733/3290, eval_loss: 0.5011, eval_acc: 0.8656:  83%|[32m████████▎ [0m| 2733/3290 [16:59<03:01,  3.07it/s][A[2025-02-04 03:30:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2733/3290, eval_loss: 0.5011, eval_acc: 0.8656:  83%|[32m████████▎ [0m| 2734/3290 [16:59<02:45,  3.35it/s][A
step: 2734/3290, eval_loss: 0.5013, eval_acc: 0.8655:  83%|[32m████████▎ [0m| 2734/3290 [16:59<02:45,  3.35it/s][A[2025-02-04 03:30:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2734/3290, eval_loss: 0.5013, eval_acc: 0.8655:  83%|[32m████████▎ [0m| 2735/3290 [17:00<02:46,  3.33it/s][A
step: 2735/3290, eval_loss: 0.5016, eval_acc: 0.8655:  83%|[32m████████▎ [0m| 2735/3290 [17:00<02:46,  3.33it/s][A[2025-02-04 03:30:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2735/3290, eval_loss: 0.5016, eval_acc: 0.8655:  83%|[32m████████▎ [0m| 2736/3290 [17:00<02:45,  3.34it/s][A
step: 2736/3290, eval_loss: 0.5018, eval_acc: 0.8654:  83%|[32m████████▎ [0m| 2736/3290 [17:00<02:45,  3.34it/s][A[2025-02-04 03:30:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2736/3290, eval_loss: 0.5018, eval_acc: 0.8654:  83%|[32m████████▎ [0m| 2737/3290 [17:00<02:59,  3.08it/s][A
step: 2737/3290, eval_loss: 0.5017, eval_acc: 0.8654:  83%|[32m████████▎ [0m| 2737/3290 [17:00<02:59,  3.08it/s][A[2025-02-04 03:30:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2737/3290, eval_loss: 0.5017, eval_acc: 0.8654:  83%|[32m████████▎ [0m| 2738/3290 [17:01<03:23,  2.72it/s][A
step: 2738/3290, eval_loss: 0.5019, eval_acc: 0.8653:  83%|[32m████████▎ [0m| 2738/3290 [17:01<03:23,  2.72it/s][A[2025-02-04 03:30:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2738/3290, eval_loss: 0.5019, eval_acc: 0.8653:  83%|[32m████████▎ [0m| 2739/3290 [17:01<03:34,  2.57it/s][A
step: 2739/3290, eval_loss: 0.5021, eval_acc: 0.8653:  83%|[32m████████▎ [0m| 2739/3290 [17:01<03:34,  2.57it/s][A[2025-02-04 03:30:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2739/3290, eval_loss: 0.5021, eval_acc: 0.8653:  83%|[32m████████▎ [0m| 2740/3290 [17:01<03:30,  2.61it/s][A
step: 2740/3290, eval_loss: 0.5021, eval_acc: 0.8653:  83%|[32m████████▎ [0m| 2740/3290 [17:01<03:30,  2.61it/s][A[2025-02-04 03:30:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2740/3290, eval_loss: 0.5021, eval_acc: 0.8653:  83%|[32m████████▎ [0m| 2741/3290 [17:02<03:25,  2.68it/s][A
step: 2741/3290, eval_loss: 0.5022, eval_acc: 0.8653:  83%|[32m████████▎ [0m| 2741/3290 [17:02<03:25,  2.68it/s][A[2025-02-04 03:30:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2741/3290, eval_loss: 0.5022, eval_acc: 0.8653:  83%|[32m████████▎ [0m| 2742/3290 [17:02<03:31,  2.59it/s][A
step: 2742/3290, eval_loss: 0.5023, eval_acc: 0.8653:  83%|[32m████████▎ [0m| 2742/3290 [17:02<03:31,  2.59it/s][A[2025-02-04 03:30:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2742/3290, eval_loss: 0.5023, eval_acc: 0.8653:  83%|[32m████████▎ [0m| 2743/3290 [17:03<03:15,  2.79it/s][A
step: 2743/3290, eval_loss: 0.5023, eval_acc: 0.8653:  83%|[32m████████▎ [0m| 2743/3290 [17:03<03:15,  2.79it/s][A[2025-02-04 03:30:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2743/3290, eval_loss: 0.5023, eval_acc: 0.8653:  83%|[32m████████▎ [0m| 2744/3290 [17:03<03:13,  2.82it/s][A
step: 2744/3290, eval_loss: 0.5025, eval_acc: 0.8652:  83%|[32m████████▎ [0m| 2744/3290 [17:03<03:13,  2.82it/s][A[2025-02-04 03:30:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2744/3290, eval_loss: 0.5025, eval_acc: 0.8652:  83%|[32m████████▎ [0m| 2745/3290 [17:03<02:59,  3.03it/s][A
step: 2745/3290, eval_loss: 0.5026, eval_acc: 0.8652:  83%|[32m████████▎ [0m| 2745/3290 [17:03<02:59,  3.03it/s][A[2025-02-04 03:30:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2745/3290, eval_loss: 0.5026, eval_acc: 0.8652:  83%|[32m████████▎ [0m| 2746/3290 [17:03<03:02,  2.97it/s][A
step: 2746/3290, eval_loss: 0.5028, eval_acc: 0.8651:  83%|[32m████████▎ [0m| 2746/3290 [17:03<03:02,  2.97it/s][A[2025-02-04 03:30:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2746/3290, eval_loss: 0.5028, eval_acc: 0.8651:  83%|[32m████████▎ [0m| 2747/3290 [17:04<02:48,  3.22it/s][A
step: 2747/3290, eval_loss: 0.5028, eval_acc: 0.8651:  83%|[32m████████▎ [0m| 2747/3290 [17:04<02:48,  3.22it/s][A[2025-02-04 03:30:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2747/3290, eval_loss: 0.5028, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2748/3290 [17:04<02:42,  3.34it/s][A
step: 2748/3290, eval_loss: 0.5027, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2748/3290 [17:04<02:42,  3.34it/s][A[2025-02-04 03:30:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2748/3290, eval_loss: 0.5027, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2749/3290 [17:04<02:36,  3.45it/s][A
step: 2749/3290, eval_loss: 0.5029, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2749/3290 [17:04<02:36,  3.45it/s][A[2025-02-04 03:30:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2749/3290, eval_loss: 0.5029, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2750/3290 [17:05<02:54,  3.10it/s][A
step: 2750/3290, eval_loss: 0.5029, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2750/3290 [17:05<02:54,  3.10it/s][A[2025-02-04 03:30:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2750/3290, eval_loss: 0.5029, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2751/3290 [17:05<02:55,  3.08it/s][A
step: 2751/3290, eval_loss: 0.5029, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2751/3290 [17:05<02:55,  3.08it/s][A[2025-02-04 03:30:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2751/3290, eval_loss: 0.5029, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2752/3290 [17:05<03:08,  2.86it/s][A
step: 2752/3290, eval_loss: 0.5028, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2752/3290 [17:05<03:08,  2.86it/s][A[2025-02-04 03:31:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2752/3290, eval_loss: 0.5028, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2753/3290 [17:06<02:59,  2.98it/s][A
step: 2753/3290, eval_loss: 0.5029, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2753/3290 [17:06<02:59,  2.98it/s][A[2025-02-04 03:31:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2753/3290, eval_loss: 0.5029, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2754/3290 [17:06<03:16,  2.72it/s][A
step: 2754/3290, eval_loss: 0.5029, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2754/3290 [17:06<03:16,  2.72it/s][A[2025-02-04 03:31:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2754/3290, eval_loss: 0.5029, eval_acc: 0.8651:  84%|[32m████████▎ [0m| 2755/3290 [17:07<03:39,  2.44it/s][A
step: 2755/3290, eval_loss: 0.5031, eval_acc: 0.8650:  84%|[32m████████▎ [0m| 2755/3290 [17:07<03:39,  2.44it/s][A[2025-02-04 03:31:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2755/3290, eval_loss: 0.5031, eval_acc: 0.8650:  84%|[32m████████▍ [0m| 2756/3290 [17:07<03:20,  2.66it/s][A
step: 2756/3290, eval_loss: 0.5031, eval_acc: 0.8650:  84%|[32m████████▍ [0m| 2756/3290 [17:07<03:20,  2.66it/s][A[2025-02-04 03:31:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2756/3290, eval_loss: 0.5031, eval_acc: 0.8650:  84%|[32m████████▍ [0m| 2757/3290 [17:07<03:02,  2.92it/s][A
step: 2757/3290, eval_loss: 0.5032, eval_acc: 0.8649:  84%|[32m████████▍ [0m| 2757/3290 [17:07<03:02,  2.92it/s][A[2025-02-04 03:31:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2757/3290, eval_loss: 0.5032, eval_acc: 0.8649:  84%|[32m████████▍ [0m| 2758/3290 [17:08<02:55,  3.03it/s][A
step: 2758/3290, eval_loss: 0.5034, eval_acc: 0.8649:  84%|[32m████████▍ [0m| 2758/3290 [17:08<02:55,  3.03it/s][A[2025-02-04 03:31:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2758/3290, eval_loss: 0.5034, eval_acc: 0.8649:  84%|[32m████████▍ [0m| 2759/3290 [17:08<03:04,  2.88it/s][A
step: 2759/3290, eval_loss: 0.5036, eval_acc: 0.8648:  84%|[32m████████▍ [0m| 2759/3290 [17:08<03:04,  2.88it/s][A[2025-02-04 03:31:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2759/3290, eval_loss: 0.5036, eval_acc: 0.8648:  84%|[32m████████▍ [0m| 2760/3290 [17:08<03:02,  2.91it/s][A
step: 2760/3290, eval_loss: 0.5039, eval_acc: 0.8647:  84%|[32m████████▍ [0m| 2760/3290 [17:08<03:02,  2.91it/s][A[2025-02-04 03:31:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2760/3290, eval_loss: 0.5039, eval_acc: 0.8647:  84%|[32m████████▍ [0m| 2761/3290 [17:09<03:01,  2.91it/s][A
step: 2761/3290, eval_loss: 0.5041, eval_acc: 0.8647:  84%|[32m████████▍ [0m| 2761/3290 [17:09<03:01,  2.91it/s][A[2025-02-04 03:31:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2761/3290, eval_loss: 0.5041, eval_acc: 0.8647:  84%|[32m████████▍ [0m| 2762/3290 [17:09<02:48,  3.13it/s][A
step: 2762/3290, eval_loss: 0.5043, eval_acc: 0.8646:  84%|[32m████████▍ [0m| 2762/3290 [17:09<02:48,  3.13it/s][A[2025-02-04 03:31:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2762/3290, eval_loss: 0.5043, eval_acc: 0.8646:  84%|[32m████████▍ [0m| 2763/3290 [17:09<02:56,  2.99it/s][A
step: 2763/3290, eval_loss: 0.5043, eval_acc: 0.8646:  84%|[32m████████▍ [0m| 2763/3290 [17:09<02:56,  2.99it/s][A[2025-02-04 03:31:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2763/3290, eval_loss: 0.5043, eval_acc: 0.8646:  84%|[32m████████▍ [0m| 2764/3290 [17:10<03:16,  2.67it/s][A
step: 2764/3290, eval_loss: 0.5045, eval_acc: 0.8645:  84%|[32m████████▍ [0m| 2764/3290 [17:10<03:16,  2.67it/s][A[2025-02-04 03:31:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2764/3290, eval_loss: 0.5045, eval_acc: 0.8645:  84%|[32m████████▍ [0m| 2765/3290 [17:10<03:34,  2.45it/s][A
step: 2765/3290, eval_loss: 0.5044, eval_acc: 0.8646:  84%|[32m████████▍ [0m| 2765/3290 [17:10<03:34,  2.45it/s][A[2025-02-04 03:31:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2765/3290, eval_loss: 0.5044, eval_acc: 0.8646:  84%|[32m████████▍ [0m| 2766/3290 [17:11<03:38,  2.40it/s][A
step: 2766/3290, eval_loss: 0.5045, eval_acc: 0.8645:  84%|[32m████████▍ [0m| 2766/3290 [17:11<03:38,  2.40it/s][A[2025-02-04 03:31:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2766/3290, eval_loss: 0.5045, eval_acc: 0.8645:  84%|[32m████████▍ [0m| 2767/3290 [17:11<03:30,  2.49it/s][A
step: 2767/3290, eval_loss: 0.5045, eval_acc: 0.8645:  84%|[32m████████▍ [0m| 2767/3290 [17:11<03:30,  2.49it/s][A[2025-02-04 03:31:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2767/3290, eval_loss: 0.5045, eval_acc: 0.8645:  84%|[32m████████▍ [0m| 2768/3290 [17:11<03:22,  2.58it/s][A
step: 2768/3290, eval_loss: 0.5046, eval_acc: 0.8645:  84%|[32m████████▍ [0m| 2768/3290 [17:11<03:22,  2.58it/s][A[2025-02-04 03:31:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2768/3290, eval_loss: 0.5046, eval_acc: 0.8645:  84%|[32m████████▍ [0m| 2769/3290 [17:12<03:22,  2.57it/s][A
step: 2769/3290, eval_loss: 0.5045, eval_acc: 0.8645:  84%|[32m████████▍ [0m| 2769/3290 [17:12<03:22,  2.57it/s][A[2025-02-04 03:31:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2769/3290, eval_loss: 0.5045, eval_acc: 0.8645:  84%|[32m████████▍ [0m| 2770/3290 [17:12<03:10,  2.73it/s][A
step: 2770/3290, eval_loss: 0.5047, eval_acc: 0.8645:  84%|[32m████████▍ [0m| 2770/3290 [17:12<03:10,  2.73it/s][A[2025-02-04 03:31:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2770/3290, eval_loss: 0.5047, eval_acc: 0.8645:  84%|[32m████████▍ [0m| 2771/3290 [17:12<03:09,  2.74it/s][A
step: 2771/3290, eval_loss: 0.5048, eval_acc: 0.8644:  84%|[32m████████▍ [0m| 2771/3290 [17:12<03:09,  2.74it/s][A[2025-02-04 03:31:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2771/3290, eval_loss: 0.5048, eval_acc: 0.8644:  84%|[32m████████▍ [0m| 2772/3290 [17:13<02:52,  3.00it/s][A
step: 2772/3290, eval_loss: 0.5050, eval_acc: 0.8644:  84%|[32m████████▍ [0m| 2772/3290 [17:13<02:52,  3.00it/s][A[2025-02-04 03:31:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2772/3290, eval_loss: 0.5050, eval_acc: 0.8644:  84%|[32m████████▍ [0m| 2773/3290 [17:13<03:07,  2.75it/s][A
step: 2773/3290, eval_loss: 0.5051, eval_acc: 0.8644:  84%|[32m████████▍ [0m| 2773/3290 [17:13<03:07,  2.75it/s][A[2025-02-04 03:31:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2773/3290, eval_loss: 0.5051, eval_acc: 0.8644:  84%|[32m████████▍ [0m| 2774/3290 [17:14<03:28,  2.48it/s][A
step: 2774/3290, eval_loss: 0.5052, eval_acc: 0.8643:  84%|[32m████████▍ [0m| 2774/3290 [17:14<03:28,  2.48it/s][A[2025-02-04 03:31:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2774/3290, eval_loss: 0.5052, eval_acc: 0.8643:  84%|[32m████████▍ [0m| 2775/3290 [17:14<03:20,  2.57it/s][A
step: 2775/3290, eval_loss: 0.5055, eval_acc: 0.8643:  84%|[32m████████▍ [0m| 2775/3290 [17:14<03:20,  2.57it/s][A[2025-02-04 03:31:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2775/3290, eval_loss: 0.5055, eval_acc: 0.8643:  84%|[32m████████▍ [0m| 2776/3290 [17:14<03:11,  2.69it/s][A
step: 2776/3290, eval_loss: 0.5055, eval_acc: 0.8643:  84%|[32m████████▍ [0m| 2776/3290 [17:14<03:11,  2.69it/s][A[2025-02-04 03:31:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2776/3290, eval_loss: 0.5055, eval_acc: 0.8643:  84%|[32m████████▍ [0m| 2777/3290 [17:15<03:18,  2.58it/s][A
step: 2777/3290, eval_loss: 0.5055, eval_acc: 0.8643:  84%|[32m████████▍ [0m| 2777/3290 [17:15<03:18,  2.58it/s][A[2025-02-04 03:31:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2777/3290, eval_loss: 0.5055, eval_acc: 0.8643:  84%|[32m████████▍ [0m| 2778/3290 [17:15<03:21,  2.54it/s][A
step: 2778/3290, eval_loss: 0.5055, eval_acc: 0.8643:  84%|[32m████████▍ [0m| 2778/3290 [17:15<03:21,  2.54it/s][A[2025-02-04 03:31:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2778/3290, eval_loss: 0.5055, eval_acc: 0.8643:  84%|[32m████████▍ [0m| 2779/3290 [17:15<02:59,  2.84it/s][A
step: 2779/3290, eval_loss: 0.5057, eval_acc: 0.8642:  84%|[32m████████▍ [0m| 2779/3290 [17:15<02:59,  2.84it/s][A[2025-02-04 03:31:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2779/3290, eval_loss: 0.5057, eval_acc: 0.8642:  84%|[32m████████▍ [0m| 2780/3290 [17:16<03:03,  2.77it/s][A
step: 2780/3290, eval_loss: 0.5056, eval_acc: 0.8642:  84%|[32m████████▍ [0m| 2780/3290 [17:16<03:03,  2.77it/s][A[2025-02-04 03:31:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2780/3290, eval_loss: 0.5056, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2781/3290 [17:16<02:59,  2.84it/s][A
step: 2781/3290, eval_loss: 0.5057, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2781/3290 [17:16<02:59,  2.84it/s][A[2025-02-04 03:31:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2781/3290, eval_loss: 0.5057, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2782/3290 [17:16<02:48,  3.01it/s][A
step: 2782/3290, eval_loss: 0.5058, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2782/3290 [17:16<02:48,  3.01it/s][A[2025-02-04 03:31:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2782/3290, eval_loss: 0.5058, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2783/3290 [17:17<02:50,  2.98it/s][A
step: 2783/3290, eval_loss: 0.5058, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2783/3290 [17:17<02:50,  2.98it/s][A[2025-02-04 03:31:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2783/3290, eval_loss: 0.5058, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2784/3290 [17:17<03:10,  2.66it/s][A
step: 2784/3290, eval_loss: 0.5058, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2784/3290 [17:17<03:10,  2.66it/s][A[2025-02-04 03:31:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2784/3290, eval_loss: 0.5058, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2785/3290 [17:17<02:58,  2.82it/s][A
step: 2785/3290, eval_loss: 0.5056, eval_acc: 0.8643:  85%|[32m████████▍ [0m| 2785/3290 [17:17<02:58,  2.82it/s][A[2025-02-04 03:31:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2785/3290, eval_loss: 0.5056, eval_acc: 0.8643:  85%|[32m████████▍ [0m| 2786/3290 [17:18<02:48,  3.00it/s][A
step: 2786/3290, eval_loss: 0.5059, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2786/3290 [17:18<02:48,  3.00it/s][A[2025-02-04 03:31:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2786/3290, eval_loss: 0.5059, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2787/3290 [17:18<02:47,  3.01it/s][A
step: 2787/3290, eval_loss: 0.5060, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2787/3290 [17:18<02:47,  3.01it/s][A[2025-02-04 03:31:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2787/3290, eval_loss: 0.5060, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2788/3290 [17:18<02:46,  3.01it/s][A
step: 2788/3290, eval_loss: 0.5061, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2788/3290 [17:18<02:46,  3.01it/s][A[2025-02-04 03:31:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2788/3290, eval_loss: 0.5061, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2789/3290 [17:19<03:05,  2.71it/s][A
step: 2789/3290, eval_loss: 0.5063, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2789/3290 [17:19<03:05,  2.71it/s][A[2025-02-04 03:31:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2789/3290, eval_loss: 0.5063, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2790/3290 [17:19<03:03,  2.72it/s][A
step: 2790/3290, eval_loss: 0.5062, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2790/3290 [17:19<03:03,  2.72it/s][A[2025-02-04 03:31:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2790/3290, eval_loss: 0.5062, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2791/3290 [17:20<03:02,  2.73it/s][A
step: 2791/3290, eval_loss: 0.5062, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2791/3290 [17:20<03:02,  2.73it/s][A[2025-02-04 03:31:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2791/3290, eval_loss: 0.5062, eval_acc: 0.8642:  85%|[32m████████▍ [0m| 2792/3290 [17:20<03:00,  2.75it/s][A
step: 2792/3290, eval_loss: 0.5066, eval_acc: 0.8641:  85%|[32m████████▍ [0m| 2792/3290 [17:20<03:00,  2.75it/s][A[2025-02-04 03:31:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2792/3290, eval_loss: 0.5066, eval_acc: 0.8641:  85%|[32m████████▍ [0m| 2793/3290 [17:20<03:06,  2.67it/s][A
step: 2793/3290, eval_loss: 0.5067, eval_acc: 0.8641:  85%|[32m████████▍ [0m| 2793/3290 [17:20<03:06,  2.67it/s][A[2025-02-04 03:31:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2793/3290, eval_loss: 0.5067, eval_acc: 0.8641:  85%|[32m████████▍ [0m| 2794/3290 [17:21<02:55,  2.83it/s][A
step: 2794/3290, eval_loss: 0.5069, eval_acc: 0.8640:  85%|[32m████████▍ [0m| 2794/3290 [17:21<02:55,  2.83it/s][A[2025-02-04 03:31:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2794/3290, eval_loss: 0.5069, eval_acc: 0.8640:  85%|[32m████████▍ [0m| 2795/3290 [17:21<03:02,  2.72it/s][A
step: 2795/3290, eval_loss: 0.5069, eval_acc: 0.8640:  85%|[32m████████▍ [0m| 2795/3290 [17:21<03:02,  2.72it/s][A[2025-02-04 03:31:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2795/3290, eval_loss: 0.5069, eval_acc: 0.8640:  85%|[32m████████▍ [0m| 2796/3290 [17:21<03:04,  2.68it/s][A
step: 2796/3290, eval_loss: 0.5069, eval_acc: 0.8640:  85%|[32m████████▍ [0m| 2796/3290 [17:21<03:04,  2.68it/s][A[2025-02-04 03:31:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2796/3290, eval_loss: 0.5069, eval_acc: 0.8640:  85%|[32m████████▌ [0m| 2797/3290 [17:22<02:57,  2.78it/s][A
step: 2797/3290, eval_loss: 0.5071, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2797/3290 [17:22<02:57,  2.78it/s][A[2025-02-04 03:31:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2797/3290, eval_loss: 0.5071, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2798/3290 [17:22<02:54,  2.81it/s][A
step: 2798/3290, eval_loss: 0.5071, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2798/3290 [17:22<02:54,  2.81it/s][A[2025-02-04 03:31:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2798/3290, eval_loss: 0.5071, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2799/3290 [17:23<03:03,  2.67it/s][A
step: 2799/3290, eval_loss: 0.5070, eval_acc: 0.8640:  85%|[32m████████▌ [0m| 2799/3290 [17:23<03:03,  2.67it/s][A[2025-02-04 03:31:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2799/3290, eval_loss: 0.5070, eval_acc: 0.8640:  85%|[32m████████▌ [0m| 2800/3290 [17:23<02:59,  2.73it/s][A
step: 2800/3290, eval_loss: 0.5069, eval_acc: 0.8640:  85%|[32m████████▌ [0m| 2800/3290 [17:23<02:59,  2.73it/s][A[2025-02-04 03:31:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2800/3290, eval_loss: 0.5069, eval_acc: 0.8640:  85%|[32m████████▌ [0m| 2801/3290 [17:23<02:55,  2.79it/s][A
step: 2801/3290, eval_loss: 0.5068, eval_acc: 0.8640:  85%|[32m████████▌ [0m| 2801/3290 [17:23<02:55,  2.79it/s][A[2025-02-04 03:31:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2801/3290, eval_loss: 0.5068, eval_acc: 0.8640:  85%|[32m████████▌ [0m| 2802/3290 [17:24<03:11,  2.55it/s][A
step: 2802/3290, eval_loss: 0.5070, eval_acc: 0.8640:  85%|[32m████████▌ [0m| 2802/3290 [17:24<03:11,  2.55it/s][A[2025-02-04 03:31:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2802/3290, eval_loss: 0.5070, eval_acc: 0.8640:  85%|[32m████████▌ [0m| 2803/3290 [17:24<03:03,  2.66it/s][A
step: 2803/3290, eval_loss: 0.5072, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2803/3290 [17:24<03:03,  2.66it/s][A[2025-02-04 03:31:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2803/3290, eval_loss: 0.5072, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2804/3290 [17:25<03:22,  2.40it/s][A
step: 2804/3290, eval_loss: 0.5073, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2804/3290 [17:25<03:22,  2.40it/s][A[2025-02-04 03:31:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2804/3290, eval_loss: 0.5073, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2805/3290 [17:25<03:00,  2.69it/s][A
step: 2805/3290, eval_loss: 0.5073, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2805/3290 [17:25<03:00,  2.69it/s][A[2025-02-04 03:31:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2805/3290, eval_loss: 0.5073, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2806/3290 [17:25<02:55,  2.76it/s][A
step: 2806/3290, eval_loss: 0.5073, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2806/3290 [17:25<02:55,  2.76it/s][A[2025-02-04 03:31:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2806/3290, eval_loss: 0.5073, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2807/3290 [17:25<02:49,  2.84it/s][A
step: 2807/3290, eval_loss: 0.5073, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2807/3290 [17:25<02:49,  2.84it/s][A[2025-02-04 03:31:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2807/3290, eval_loss: 0.5073, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2808/3290 [17:26<02:59,  2.69it/s][A
step: 2808/3290, eval_loss: 0.5074, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2808/3290 [17:26<02:59,  2.69it/s][A[2025-02-04 03:31:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2808/3290, eval_loss: 0.5074, eval_acc: 0.8639:  85%|[32m████████▌ [0m| 2809/3290 [17:26<02:58,  2.70it/s][A
step: 2809/3290, eval_loss: 0.5076, eval_acc: 0.8638:  85%|[32m████████▌ [0m| 2809/3290 [17:26<02:58,  2.70it/s][A[2025-02-04 03:31:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2809/3290, eval_loss: 0.5076, eval_acc: 0.8638:  85%|[32m████████▌ [0m| 2810/3290 [17:27<02:40,  2.99it/s][A
step: 2810/3290, eval_loss: 0.5076, eval_acc: 0.8638:  85%|[32m████████▌ [0m| 2810/3290 [17:27<02:40,  2.99it/s][A[2025-02-04 03:31:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2810/3290, eval_loss: 0.5076, eval_acc: 0.8638:  85%|[32m████████▌ [0m| 2811/3290 [17:27<02:48,  2.84it/s][A
step: 2811/3290, eval_loss: 0.5076, eval_acc: 0.8638:  85%|[32m████████▌ [0m| 2811/3290 [17:27<02:48,  2.84it/s][A[2025-02-04 03:31:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2811/3290, eval_loss: 0.5076, eval_acc: 0.8638:  85%|[32m████████▌ [0m| 2812/3290 [17:27<02:42,  2.94it/s][A
step: 2812/3290, eval_loss: 0.5076, eval_acc: 0.8638:  85%|[32m████████▌ [0m| 2812/3290 [17:27<02:42,  2.94it/s][A[2025-02-04 03:31:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2812/3290, eval_loss: 0.5076, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2813/3290 [17:28<02:31,  3.15it/s][A
step: 2813/3290, eval_loss: 0.5076, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2813/3290 [17:28<02:31,  3.15it/s][A[2025-02-04 03:31:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2813/3290, eval_loss: 0.5076, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2814/3290 [17:28<02:21,  3.37it/s][A
step: 2814/3290, eval_loss: 0.5075, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2814/3290 [17:28<02:21,  3.37it/s][A[2025-02-04 03:31:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2814/3290, eval_loss: 0.5075, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2815/3290 [17:28<02:28,  3.20it/s][A
step: 2815/3290, eval_loss: 0.5075, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2815/3290 [17:28<02:28,  3.20it/s][A[2025-02-04 03:31:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2815/3290, eval_loss: 0.5075, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2816/3290 [17:28<02:26,  3.24it/s][A
step: 2816/3290, eval_loss: 0.5075, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2816/3290 [17:28<02:26,  3.24it/s][A[2025-02-04 03:31:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2816/3290, eval_loss: 0.5075, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2817/3290 [17:29<02:24,  3.26it/s][A
step: 2817/3290, eval_loss: 0.5074, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2817/3290 [17:29<02:24,  3.26it/s][A[2025-02-04 03:31:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2817/3290, eval_loss: 0.5074, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2818/3290 [17:29<02:20,  3.36it/s][A
step: 2818/3290, eval_loss: 0.5073, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2818/3290 [17:29<02:20,  3.36it/s][A[2025-02-04 03:31:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2818/3290, eval_loss: 0.5073, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2819/3290 [17:29<02:27,  3.19it/s][A
step: 2819/3290, eval_loss: 0.5073, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2819/3290 [17:29<02:27,  3.19it/s][A[2025-02-04 03:31:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2819/3290, eval_loss: 0.5073, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2820/3290 [17:30<02:41,  2.91it/s][A
step: 2820/3290, eval_loss: 0.5073, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2820/3290 [17:30<02:41,  2.91it/s][A[2025-02-04 03:31:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2820/3290, eval_loss: 0.5073, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2821/3290 [17:30<02:33,  3.06it/s][A
step: 2821/3290, eval_loss: 0.5072, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2821/3290 [17:30<02:33,  3.06it/s][A[2025-02-04 03:31:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2821/3290, eval_loss: 0.5072, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2822/3290 [17:30<02:21,  3.31it/s][A
step: 2822/3290, eval_loss: 0.5076, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2822/3290 [17:30<02:21,  3.31it/s][A[2025-02-04 03:31:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2822/3290, eval_loss: 0.5076, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2823/3290 [17:31<02:43,  2.86it/s][A
step: 2823/3290, eval_loss: 0.5076, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2823/3290 [17:31<02:43,  2.86it/s][A[2025-02-04 03:31:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2823/3290, eval_loss: 0.5076, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2824/3290 [17:31<03:10,  2.45it/s][A
step: 2824/3290, eval_loss: 0.5075, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2824/3290 [17:31<03:10,  2.45it/s][A[2025-02-04 03:31:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2824/3290, eval_loss: 0.5075, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2825/3290 [17:32<03:15,  2.38it/s][A
step: 2825/3290, eval_loss: 0.5075, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2825/3290 [17:32<03:15,  2.38it/s][A[2025-02-04 03:31:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2825/3290, eval_loss: 0.5075, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2826/3290 [17:32<03:05,  2.50it/s][A
step: 2826/3290, eval_loss: 0.5074, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2826/3290 [17:32<03:05,  2.50it/s][A[2025-02-04 03:31:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2826/3290, eval_loss: 0.5074, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2827/3290 [17:32<02:51,  2.69it/s][A
step: 2827/3290, eval_loss: 0.5075, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2827/3290 [17:32<02:51,  2.69it/s][A[2025-02-04 03:31:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2827/3290, eval_loss: 0.5075, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2828/3290 [17:33<02:40,  2.88it/s][A
step: 2828/3290, eval_loss: 0.5076, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2828/3290 [17:33<02:40,  2.88it/s][A[2025-02-04 03:31:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2828/3290, eval_loss: 0.5076, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2829/3290 [17:33<02:38,  2.91it/s][A
step: 2829/3290, eval_loss: 0.5076, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2829/3290 [17:33<02:38,  2.91it/s][A[2025-02-04 03:31:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2829/3290, eval_loss: 0.5076, eval_acc: 0.8639:  86%|[32m████████▌ [0m| 2830/3290 [17:33<02:30,  3.06it/s][A
step: 2830/3290, eval_loss: 0.5078, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2830/3290 [17:33<02:30,  3.06it/s][A[2025-02-04 03:31:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2830/3290, eval_loss: 0.5078, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2831/3290 [17:34<02:25,  3.15it/s][A
step: 2831/3290, eval_loss: 0.5078, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2831/3290 [17:34<02:25,  3.15it/s][A[2025-02-04 03:31:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2831/3290, eval_loss: 0.5078, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2832/3290 [17:34<02:26,  3.12it/s][A
step: 2832/3290, eval_loss: 0.5081, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2832/3290 [17:34<02:26,  3.12it/s][A[2025-02-04 03:31:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2832/3290, eval_loss: 0.5081, eval_acc: 0.8638:  86%|[32m████████▌ [0m| 2833/3290 [17:34<02:37,  2.91it/s][A
step: 2833/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▌ [0m| 2833/3290 [17:34<02:37,  2.91it/s][A[2025-02-04 03:31:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2833/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▌ [0m| 2834/3290 [17:35<02:58,  2.55it/s][A
step: 2834/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▌ [0m| 2834/3290 [17:35<02:58,  2.55it/s][A[2025-02-04 03:31:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2834/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▌ [0m| 2835/3290 [17:35<03:05,  2.45it/s][A
step: 2835/3290, eval_loss: 0.5082, eval_acc: 0.8637:  86%|[32m████████▌ [0m| 2835/3290 [17:35<03:05,  2.45it/s][A[2025-02-04 03:31:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2835/3290, eval_loss: 0.5082, eval_acc: 0.8637:  86%|[32m████████▌ [0m| 2836/3290 [17:36<03:09,  2.40it/s][A
step: 2836/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▌ [0m| 2836/3290 [17:36<03:09,  2.40it/s][A[2025-02-04 03:31:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2836/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▌ [0m| 2837/3290 [17:36<03:13,  2.34it/s][A
step: 2837/3290, eval_loss: 0.5082, eval_acc: 0.8637:  86%|[32m████████▌ [0m| 2837/3290 [17:36<03:13,  2.34it/s][A[2025-02-04 03:31:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2837/3290, eval_loss: 0.5082, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2838/3290 [17:37<03:18,  2.28it/s][A
step: 2838/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2838/3290 [17:37<03:18,  2.28it/s][A[2025-02-04 03:31:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2838/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2839/3290 [17:37<02:54,  2.58it/s][A
step: 2839/3290, eval_loss: 0.5082, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2839/3290 [17:37<02:54,  2.58it/s][A[2025-02-04 03:31:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2839/3290, eval_loss: 0.5082, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2840/3290 [17:37<02:34,  2.90it/s][A
step: 2840/3290, eval_loss: 0.5081, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2840/3290 [17:37<02:34,  2.90it/s][A[2025-02-04 03:31:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2840/3290, eval_loss: 0.5081, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2841/3290 [17:37<02:24,  3.10it/s][A
step: 2841/3290, eval_loss: 0.5082, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2841/3290 [17:37<02:24,  3.10it/s][A[2025-02-04 03:31:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2841/3290, eval_loss: 0.5082, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2842/3290 [17:38<02:21,  3.17it/s][A
step: 2842/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2842/3290 [17:38<02:21,  3.17it/s][A[2025-02-04 03:31:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2842/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2843/3290 [17:38<02:19,  3.21it/s][A
step: 2843/3290, eval_loss: 0.5084, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2843/3290 [17:38<02:19,  3.21it/s][A[2025-02-04 03:31:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2843/3290, eval_loss: 0.5084, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2844/3290 [17:38<02:17,  3.25it/s][A
step: 2844/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2844/3290 [17:38<02:17,  3.25it/s][A[2025-02-04 03:31:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2844/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2845/3290 [17:39<02:15,  3.29it/s][A
step: 2845/3290, eval_loss: 0.5083, eval_acc: 0.8637:  86%|[32m████████▋ [0m| 2845/3290 [17:39<02:15,  3.29it/s][A[2025-02-04 03:31:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2845/3290, eval_loss: 0.5083, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2846/3290 [17:39<02:21,  3.15it/s][A
step: 2846/3290, eval_loss: 0.5082, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2846/3290 [17:39<02:21,  3.15it/s][A[2025-02-04 03:31:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2846/3290, eval_loss: 0.5082, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2847/3290 [17:39<02:27,  3.01it/s][A
step: 2847/3290, eval_loss: 0.5082, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2847/3290 [17:39<02:27,  3.01it/s][A[2025-02-04 03:31:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 2847/3290, eval_loss: 0.5082, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2848/3290 [17:40<02:35,  2.85it/s][A
step: 2848/3290, eval_loss: 0.5082, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2848/3290 [17:40<02:35,  2.85it/s][A[2025-02-04 03:31:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2848/3290, eval_loss: 0.5082, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2849/3290 [17:40<02:36,  2.82it/s][A
step: 2849/3290, eval_loss: 0.5083, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2849/3290 [17:40<02:36,  2.82it/s][A[2025-02-04 03:31:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 2849/3290, eval_loss: 0.5083, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2850/3290 [17:40<02:24,  3.04it/s][A
step: 2850/3290, eval_loss: 0.5082, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2850/3290 [17:40<02:24,  3.04it/s][A[2025-02-04 03:31:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2850/3290, eval_loss: 0.5082, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2851/3290 [17:41<02:32,  2.87it/s][A
step: 2851/3290, eval_loss: 0.5083, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2851/3290 [17:41<02:32,  2.87it/s][A[2025-02-04 03:31:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2851/3290, eval_loss: 0.5083, eval_acc: 0.8637:  87%|[32m████████▋ [0m| 2852/3290 [17:41<02:25,  3.01it/s][A
step: 2852/3290, eval_loss: 0.5083, eval_acc: 0.8638:  87%|[32m████████▋ [0m| 2852/3290 [17:41<02:25,  3.01it/s][A[2025-02-04 03:31:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 2852/3290, eval_loss: 0.5083, eval_acc: 0.8638:  87%|[32m████████▋ [0m| 2853/3290 [17:41<02:27,  2.97it/s][A
step: 2853/3290, eval_loss: 0.5083, eval_acc: 0.8638:  87%|[32m████████▋ [0m| 2853/3290 [17:41<02:27,  2.97it/s][A[2025-02-04 03:31:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2853/3290, eval_loss: 0.5083, eval_acc: 0.8638:  87%|[32m████████▋ [0m| 2854/3290 [17:42<02:40,  2.71it/s][A
step: 2854/3290, eval_loss: 0.5082, eval_acc: 0.8638:  87%|[32m████████▋ [0m| 2854/3290 [17:42<02:40,  2.71it/s][A[2025-02-04 03:31:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2854/3290, eval_loss: 0.5082, eval_acc: 0.8638:  87%|[32m████████▋ [0m| 2855/3290 [17:42<02:33,  2.83it/s][A
step: 2855/3290, eval_loss: 0.5081, eval_acc: 0.8638:  87%|[32m████████▋ [0m| 2855/3290 [17:42<02:33,  2.83it/s][A[2025-02-04 03:31:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 2855/3290, eval_loss: 0.5081, eval_acc: 0.8638:  87%|[32m████████▋ [0m| 2856/3290 [17:42<02:23,  3.02it/s][A
step: 2856/3290, eval_loss: 0.5081, eval_acc: 0.8638:  87%|[32m████████▋ [0m| 2856/3290 [17:42<02:23,  3.02it/s][A[2025-02-04 03:31:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2856/3290, eval_loss: 0.5081, eval_acc: 0.8638:  87%|[32m████████▋ [0m| 2857/3290 [17:43<02:11,  3.29it/s][A
step: 2857/3290, eval_loss: 0.5080, eval_acc: 0.8638:  87%|[32m████████▋ [0m| 2857/3290 [17:43<02:11,  3.29it/s][A[2025-02-04 03:31:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2857/3290, eval_loss: 0.5080, eval_acc: 0.8638:  87%|[32m████████▋ [0m| 2858/3290 [17:43<02:08,  3.37it/s][A
step: 2858/3290, eval_loss: 0.5080, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2858/3290 [17:43<02:08,  3.37it/s][A[2025-02-04 03:31:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 2858/3290, eval_loss: 0.5080, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2859/3290 [17:43<02:17,  3.14it/s][A
step: 2859/3290, eval_loss: 0.5079, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2859/3290 [17:43<02:17,  3.14it/s][A[2025-02-04 03:31:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2859/3290, eval_loss: 0.5079, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2860/3290 [17:44<02:31,  2.85it/s][A
step: 2860/3290, eval_loss: 0.5078, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2860/3290 [17:44<02:31,  2.85it/s][A[2025-02-04 03:31:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2860/3290, eval_loss: 0.5078, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2861/3290 [17:44<02:22,  3.01it/s][A
step: 2861/3290, eval_loss: 0.5077, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2861/3290 [17:44<02:22,  3.01it/s][A[2025-02-04 03:31:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 2861/3290, eval_loss: 0.5077, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2862/3290 [17:44<02:25,  2.95it/s][A
step: 2862/3290, eval_loss: 0.5075, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2862/3290 [17:44<02:25,  2.95it/s][A[2025-02-04 03:31:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2862/3290, eval_loss: 0.5075, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2863/3290 [17:45<02:19,  3.06it/s][A
step: 2863/3290, eval_loss: 0.5076, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2863/3290 [17:45<02:19,  3.06it/s][A[2025-02-04 03:31:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2863/3290, eval_loss: 0.5076, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2864/3290 [17:45<02:24,  2.95it/s][A
step: 2864/3290, eval_loss: 0.5075, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2864/3290 [17:45<02:24,  2.95it/s][A[2025-02-04 03:31:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 2864/3290, eval_loss: 0.5075, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2865/3290 [17:46<02:39,  2.66it/s][A
step: 2865/3290, eval_loss: 0.5073, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2865/3290 [17:46<02:39,  2.66it/s][A[2025-02-04 03:31:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2865/3290, eval_loss: 0.5073, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2866/3290 [17:46<02:43,  2.59it/s][A
step: 2866/3290, eval_loss: 0.5073, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2866/3290 [17:46<02:43,  2.59it/s][A[2025-02-04 03:31:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 2866/3290, eval_loss: 0.5073, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2867/3290 [17:46<02:41,  2.61it/s][A
step: 2867/3290, eval_loss: 0.5075, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2867/3290 [17:46<02:41,  2.61it/s][A[2025-02-04 03:31:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2867/3290, eval_loss: 0.5075, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2868/3290 [17:47<02:42,  2.60it/s][A
step: 2868/3290, eval_loss: 0.5075, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2868/3290 [17:47<02:42,  2.60it/s][A[2025-02-04 03:31:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2868/3290, eval_loss: 0.5075, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2869/3290 [17:47<02:41,  2.61it/s][A
step: 2869/3290, eval_loss: 0.5076, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2869/3290 [17:47<02:41,  2.61it/s][A[2025-02-04 03:31:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 2869/3290, eval_loss: 0.5076, eval_acc: 0.8639:  87%|[32m████████▋ [0m| 2870/3290 [17:47<02:39,  2.63it/s][A
step: 2870/3290, eval_loss: 0.5075, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2870/3290 [17:47<02:39,  2.63it/s][A[2025-02-04 03:31:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2870/3290, eval_loss: 0.5075, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2871/3290 [17:48<02:30,  2.78it/s][A
step: 2871/3290, eval_loss: 0.5074, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2871/3290 [17:48<02:30,  2.78it/s][A[2025-02-04 03:31:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2871/3290, eval_loss: 0.5074, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2872/3290 [17:48<02:27,  2.84it/s][A
step: 2872/3290, eval_loss: 0.5073, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2872/3290 [17:48<02:27,  2.84it/s][A[2025-02-04 03:31:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 2872/3290, eval_loss: 0.5073, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2873/3290 [17:49<02:36,  2.67it/s][A
step: 2873/3290, eval_loss: 0.5072, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2873/3290 [17:49<02:36,  2.67it/s][A[2025-02-04 03:31:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2873/3290, eval_loss: 0.5072, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2874/3290 [17:49<02:31,  2.75it/s][A
step: 2874/3290, eval_loss: 0.5072, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2874/3290 [17:49<02:31,  2.75it/s][A[2025-02-04 03:31:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 2874/3290, eval_loss: 0.5072, eval_acc: 0.8640:  87%|[32m████████▋ [0m| 2875/3290 [17:49<02:32,  2.72it/s][A
step: 2875/3290, eval_loss: 0.5071, eval_acc: 0.8641:  87%|[32m████████▋ [0m| 2875/3290 [17:49<02:32,  2.72it/s][A[2025-02-04 03:31:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2875/3290, eval_loss: 0.5071, eval_acc: 0.8641:  87%|[32m████████▋ [0m| 2876/3290 [17:50<02:42,  2.55it/s][A
step: 2876/3290, eval_loss: 0.5071, eval_acc: 0.8641:  87%|[32m████████▋ [0m| 2876/3290 [17:50<02:42,  2.55it/s][A[2025-02-04 03:31:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2876/3290, eval_loss: 0.5071, eval_acc: 0.8641:  87%|[32m████████▋ [0m| 2877/3290 [17:50<02:29,  2.75it/s][A
step: 2877/3290, eval_loss: 0.5069, eval_acc: 0.8641:  87%|[32m████████▋ [0m| 2877/3290 [17:50<02:29,  2.75it/s][A[2025-02-04 03:31:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2877/3290, eval_loss: 0.5069, eval_acc: 0.8641:  87%|[32m████████▋ [0m| 2878/3290 [17:50<02:21,  2.91it/s][A
step: 2878/3290, eval_loss: 0.5069, eval_acc: 0.8641:  87%|[32m████████▋ [0m| 2878/3290 [17:50<02:21,  2.91it/s][A[2025-02-04 03:31:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 2878/3290, eval_loss: 0.5069, eval_acc: 0.8641:  88%|[32m████████▊ [0m| 2879/3290 [17:51<02:11,  3.13it/s][A
step: 2879/3290, eval_loss: 0.5068, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2879/3290 [17:51<02:11,  3.13it/s][A[2025-02-04 03:31:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2879/3290, eval_loss: 0.5068, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2880/3290 [17:51<02:03,  3.31it/s][A
step: 2880/3290, eval_loss: 0.5068, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2880/3290 [17:51<02:03,  3.31it/s][A[2025-02-04 03:31:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2880/3290, eval_loss: 0.5068, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2881/3290 [17:51<02:08,  3.19it/s][A
step: 2881/3290, eval_loss: 0.5069, eval_acc: 0.8641:  88%|[32m████████▊ [0m| 2881/3290 [17:51<02:08,  3.19it/s][A[2025-02-04 03:31:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 2881/3290, eval_loss: 0.5069, eval_acc: 0.8641:  88%|[32m████████▊ [0m| 2882/3290 [17:52<02:20,  2.91it/s][A
step: 2882/3290, eval_loss: 0.5068, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2882/3290 [17:52<02:20,  2.91it/s][A[2025-02-04 03:31:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2882/3290, eval_loss: 0.5068, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2883/3290 [17:52<02:22,  2.85it/s][A
step: 2883/3290, eval_loss: 0.5068, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2883/3290 [17:52<02:22,  2.85it/s][A[2025-02-04 03:31:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2883/3290, eval_loss: 0.5068, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2884/3290 [17:52<02:15,  3.01it/s][A
step: 2884/3290, eval_loss: 0.5067, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2884/3290 [17:52<02:15,  3.01it/s][A[2025-02-04 03:31:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 2884/3290, eval_loss: 0.5067, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2885/3290 [17:53<02:19,  2.90it/s][A
step: 2885/3290, eval_loss: 0.5066, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2885/3290 [17:53<02:19,  2.90it/s][A[2025-02-04 03:31:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2885/3290, eval_loss: 0.5066, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2886/3290 [17:53<02:21,  2.86it/s][A
step: 2886/3290, eval_loss: 0.5065, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2886/3290 [17:53<02:21,  2.86it/s][A[2025-02-04 03:31:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 2886/3290, eval_loss: 0.5065, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2887/3290 [17:53<02:19,  2.88it/s][A
step: 2887/3290, eval_loss: 0.5066, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2887/3290 [17:53<02:19,  2.88it/s][A[2025-02-04 03:31:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2887/3290, eval_loss: 0.5066, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2888/3290 [17:54<02:44,  2.45it/s][A
step: 2888/3290, eval_loss: 0.5065, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2888/3290 [17:54<02:44,  2.45it/s][A[2025-02-04 03:31:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2888/3290, eval_loss: 0.5065, eval_acc: 0.8642:  88%|[32m████████▊ [0m| 2889/3290 [17:54<02:51,  2.34it/s][A
step: 2889/3290, eval_loss: 0.5064, eval_acc: 0.8643:  88%|[32m████████▊ [0m| 2889/3290 [17:54<02:51,  2.34it/s][A[2025-02-04 03:31:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 2889/3290, eval_loss: 0.5064, eval_acc: 0.8643:  88%|[32m████████▊ [0m| 2890/3290 [17:55<02:37,  2.54it/s][A
step: 2890/3290, eval_loss: 0.5064, eval_acc: 0.8643:  88%|[32m████████▊ [0m| 2890/3290 [17:55<02:37,  2.54it/s][A[2025-02-04 03:31:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2890/3290, eval_loss: 0.5064, eval_acc: 0.8643:  88%|[32m████████▊ [0m| 2891/3290 [17:55<02:38,  2.52it/s][A
step: 2891/3290, eval_loss: 0.5063, eval_acc: 0.8643:  88%|[32m████████▊ [0m| 2891/3290 [17:55<02:38,  2.52it/s][A[2025-02-04 03:31:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 2891/3290, eval_loss: 0.5063, eval_acc: 0.8643:  88%|[32m████████▊ [0m| 2892/3290 [17:55<02:39,  2.50it/s][A
step: 2892/3290, eval_loss: 0.5062, eval_acc: 0.8643:  88%|[32m████████▊ [0m| 2892/3290 [17:55<02:39,  2.50it/s][A[2025-02-04 03:31:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2892/3290, eval_loss: 0.5062, eval_acc: 0.8643:  88%|[32m████████▊ [0m| 2893/3290 [17:56<02:47,  2.37it/s][A
step: 2893/3290, eval_loss: 0.5062, eval_acc: 0.8643:  88%|[32m████████▊ [0m| 2893/3290 [17:56<02:47,  2.37it/s][A[2025-02-04 03:31:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 2893/3290, eval_loss: 0.5062, eval_acc: 0.8643:  88%|[32m████████▊ [0m| 2894/3290 [17:56<02:44,  2.41it/s][A
step: 2894/3290, eval_loss: 0.5061, eval_acc: 0.8644:  88%|[32m████████▊ [0m| 2894/3290 [17:56<02:44,  2.41it/s][A[2025-02-04 03:31:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2894/3290, eval_loss: 0.5061, eval_acc: 0.8644:  88%|[32m████████▊ [0m| 2895/3290 [17:57<02:54,  2.26it/s][A
step: 2895/3290, eval_loss: 0.5061, eval_acc: 0.8644:  88%|[32m████████▊ [0m| 2895/3290 [17:57<02:54,  2.26it/s][A[2025-02-04 03:31:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2895/3290, eval_loss: 0.5061, eval_acc: 0.8644:  88%|[32m████████▊ [0m| 2896/3290 [17:57<02:36,  2.52it/s][A
step: 2896/3290, eval_loss: 0.5060, eval_acc: 0.8644:  88%|[32m████████▊ [0m| 2896/3290 [17:57<02:36,  2.52it/s][A[2025-02-04 03:31:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 2896/3290, eval_loss: 0.5060, eval_acc: 0.8644:  88%|[32m████████▊ [0m| 2897/3290 [17:57<02:23,  2.75it/s][A
step: 2897/3290, eval_loss: 0.5059, eval_acc: 0.8644:  88%|[32m████████▊ [0m| 2897/3290 [17:57<02:23,  2.75it/s][A[2025-02-04 03:31:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2897/3290, eval_loss: 0.5059, eval_acc: 0.8644:  88%|[32m████████▊ [0m| 2898/3290 [17:58<02:19,  2.82it/s][A
step: 2898/3290, eval_loss: 0.5058, eval_acc: 0.8644:  88%|[32m████████▊ [0m| 2898/3290 [17:58<02:19,  2.82it/s][A[2025-02-04 03:31:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2898/3290, eval_loss: 0.5058, eval_acc: 0.8644:  88%|[32m████████▊ [0m| 2899/3290 [17:58<02:22,  2.75it/s][A
step: 2899/3290, eval_loss: 0.5057, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2899/3290 [17:58<02:22,  2.75it/s][A[2025-02-04 03:31:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 2899/3290, eval_loss: 0.5057, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2900/3290 [17:59<02:26,  2.66it/s][A
step: 2900/3290, eval_loss: 0.5057, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2900/3290 [17:59<02:26,  2.66it/s][A[2025-02-04 03:31:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2900/3290, eval_loss: 0.5057, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2901/3290 [17:59<02:20,  2.77it/s][A
step: 2901/3290, eval_loss: 0.5057, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2901/3290 [17:59<02:20,  2.77it/s][A[2025-02-04 03:31:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 2901/3290, eval_loss: 0.5057, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2902/3290 [17:59<02:40,  2.42it/s][A
step: 2902/3290, eval_loss: 0.5056, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2902/3290 [17:59<02:40,  2.42it/s][A[2025-02-04 03:31:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2902/3290, eval_loss: 0.5056, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2903/3290 [18:00<02:32,  2.53it/s][A
step: 2903/3290, eval_loss: 0.5055, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2903/3290 [18:00<02:32,  2.53it/s][A[2025-02-04 03:31:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2903/3290, eval_loss: 0.5055, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2904/3290 [18:00<02:17,  2.81it/s][A
step: 2904/3290, eval_loss: 0.5054, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2904/3290 [18:00<02:17,  2.81it/s][A[2025-02-04 03:31:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2904/3290, eval_loss: 0.5054, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2905/3290 [18:00<02:07,  3.02it/s][A
step: 2905/3290, eval_loss: 0.5054, eval_acc: 0.8646:  88%|[32m████████▊ [0m| 2905/3290 [18:00<02:07,  3.02it/s][A[2025-02-04 03:31:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 2905/3290, eval_loss: 0.5054, eval_acc: 0.8646:  88%|[32m████████▊ [0m| 2906/3290 [18:01<02:08,  2.99it/s][A
step: 2906/3290, eval_loss: 0.5053, eval_acc: 0.8646:  88%|[32m████████▊ [0m| 2906/3290 [18:01<02:08,  2.99it/s][A[2025-02-04 03:31:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2906/3290, eval_loss: 0.5053, eval_acc: 0.8646:  88%|[32m████████▊ [0m| 2907/3290 [18:01<02:08,  2.97it/s][A
step: 2907/3290, eval_loss: 0.5053, eval_acc: 0.8646:  88%|[32m████████▊ [0m| 2907/3290 [18:01<02:08,  2.97it/s][A[2025-02-04 03:31:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2907/3290, eval_loss: 0.5053, eval_acc: 0.8646:  88%|[32m████████▊ [0m| 2908/3290 [18:01<02:17,  2.78it/s][A
step: 2908/3290, eval_loss: 0.5053, eval_acc: 0.8646:  88%|[32m████████▊ [0m| 2908/3290 [18:01<02:17,  2.78it/s][A[2025-02-04 03:31:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 2908/3290, eval_loss: 0.5053, eval_acc: 0.8646:  88%|[32m████████▊ [0m| 2909/3290 [18:02<02:08,  2.97it/s][A
step: 2909/3290, eval_loss: 0.5053, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2909/3290 [18:02<02:08,  2.97it/s][A[2025-02-04 03:31:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2909/3290, eval_loss: 0.5053, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2910/3290 [18:02<02:05,  3.03it/s][A
step: 2910/3290, eval_loss: 0.5054, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2910/3290 [18:02<02:05,  3.03it/s][A[2025-02-04 03:31:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2910/3290, eval_loss: 0.5054, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2911/3290 [18:02<01:58,  3.19it/s][A
step: 2911/3290, eval_loss: 0.5055, eval_acc: 0.8645:  88%|[32m████████▊ [0m| 2911/3290 [18:02<01:58,  3.19it/s][A[2025-02-04 03:31:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 2911/3290, eval_loss: 0.5055, eval_acc: 0.8645:  89%|[32m████████▊ [0m| 2912/3290 [18:03<02:11,  2.86it/s][A
step: 2912/3290, eval_loss: 0.5054, eval_acc: 0.8645:  89%|[32m████████▊ [0m| 2912/3290 [18:03<02:11,  2.86it/s][A[2025-02-04 03:31:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2912/3290, eval_loss: 0.5054, eval_acc: 0.8645:  89%|[32m████████▊ [0m| 2913/3290 [18:03<02:19,  2.71it/s][A
step: 2913/3290, eval_loss: 0.5055, eval_acc: 0.8645:  89%|[32m████████▊ [0m| 2913/3290 [18:03<02:19,  2.71it/s][A[2025-02-04 03:31:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 2913/3290, eval_loss: 0.5055, eval_acc: 0.8645:  89%|[32m████████▊ [0m| 2914/3290 [18:03<02:20,  2.68it/s][A
step: 2914/3290, eval_loss: 0.5054, eval_acc: 0.8646:  89%|[32m████████▊ [0m| 2914/3290 [18:03<02:20,  2.68it/s][A[2025-02-04 03:31:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2914/3290, eval_loss: 0.5054, eval_acc: 0.8646:  89%|[32m████████▊ [0m| 2915/3290 [18:04<02:13,  2.81it/s][A
step: 2915/3290, eval_loss: 0.5053, eval_acc: 0.8646:  89%|[32m████████▊ [0m| 2915/3290 [18:04<02:13,  2.81it/s][A[2025-02-04 03:31:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2915/3290, eval_loss: 0.5053, eval_acc: 0.8646:  89%|[32m████████▊ [0m| 2916/3290 [18:04<02:04,  3.00it/s][A
step: 2916/3290, eval_loss: 0.5053, eval_acc: 0.8646:  89%|[32m████████▊ [0m| 2916/3290 [18:04<02:04,  3.00it/s][A[2025-02-04 03:31:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2916/3290, eval_loss: 0.5053, eval_acc: 0.8646:  89%|[32m████████▊ [0m| 2917/3290 [18:04<01:57,  3.17it/s][A
step: 2917/3290, eval_loss: 0.5053, eval_acc: 0.8646:  89%|[32m████████▊ [0m| 2917/3290 [18:04<01:57,  3.17it/s][A[2025-02-04 03:31:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 2917/3290, eval_loss: 0.5053, eval_acc: 0.8646:  89%|[32m████████▊ [0m| 2918/3290 [18:05<01:57,  3.16it/s][A
step: 2918/3290, eval_loss: 0.5052, eval_acc: 0.8646:  89%|[32m████████▊ [0m| 2918/3290 [18:05<01:57,  3.16it/s][A[2025-02-04 03:31:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2918/3290, eval_loss: 0.5052, eval_acc: 0.8646:  89%|[32m████████▊ [0m| 2919/3290 [18:05<02:03,  3.00it/s][A
step: 2919/3290, eval_loss: 0.5050, eval_acc: 0.8647:  89%|[32m████████▊ [0m| 2919/3290 [18:05<02:03,  3.00it/s][A[2025-02-04 03:31:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 2919/3290, eval_loss: 0.5050, eval_acc: 0.8647:  89%|[32m████████▉ [0m| 2920/3290 [18:05<02:05,  2.94it/s][A
step: 2920/3290, eval_loss: 0.5051, eval_acc: 0.8647:  89%|[32m████████▉ [0m| 2920/3290 [18:05<02:05,  2.94it/s][A[2025-02-04 03:32:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2920/3290, eval_loss: 0.5051, eval_acc: 0.8647:  89%|[32m████████▉ [0m| 2921/3290 [18:06<02:13,  2.77it/s][A
step: 2921/3290, eval_loss: 0.5051, eval_acc: 0.8647:  89%|[32m████████▉ [0m| 2921/3290 [18:06<02:13,  2.77it/s][A[2025-02-04 03:32:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2921/3290, eval_loss: 0.5051, eval_acc: 0.8647:  89%|[32m████████▉ [0m| 2922/3290 [18:06<02:25,  2.53it/s][A
step: 2922/3290, eval_loss: 0.5050, eval_acc: 0.8647:  89%|[32m████████▉ [0m| 2922/3290 [18:06<02:25,  2.53it/s][A[2025-02-04 03:32:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 2922/3290, eval_loss: 0.5050, eval_acc: 0.8647:  89%|[32m████████▉ [0m| 2923/3290 [18:07<02:32,  2.40it/s][A
step: 2923/3290, eval_loss: 0.5051, eval_acc: 0.8647:  89%|[32m████████▉ [0m| 2923/3290 [18:07<02:32,  2.40it/s][A[2025-02-04 03:32:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2923/3290, eval_loss: 0.5051, eval_acc: 0.8647:  89%|[32m████████▉ [0m| 2924/3290 [18:07<02:28,  2.47it/s][A
step: 2924/3290, eval_loss: 0.5049, eval_acc: 0.8648:  89%|[32m████████▉ [0m| 2924/3290 [18:07<02:28,  2.47it/s][A[2025-02-04 03:32:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 2924/3290, eval_loss: 0.5049, eval_acc: 0.8648:  89%|[32m████████▉ [0m| 2925/3290 [18:07<02:23,  2.55it/s][A
step: 2925/3290, eval_loss: 0.5048, eval_acc: 0.8648:  89%|[32m████████▉ [0m| 2925/3290 [18:07<02:23,  2.55it/s][A[2025-02-04 03:32:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2925/3290, eval_loss: 0.5048, eval_acc: 0.8648:  89%|[32m████████▉ [0m| 2926/3290 [18:08<02:46,  2.19it/s][A
step: 2926/3290, eval_loss: 0.5047, eval_acc: 0.8648:  89%|[32m████████▉ [0m| 2926/3290 [18:08<02:46,  2.19it/s][A[2025-02-04 03:32:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 2926/3290, eval_loss: 0.5047, eval_acc: 0.8648:  89%|[32m████████▉ [0m| 2927/3290 [18:08<02:39,  2.27it/s][A
step: 2927/3290, eval_loss: 0.5047, eval_acc: 0.8648:  89%|[32m████████▉ [0m| 2927/3290 [18:08<02:39,  2.27it/s][A[2025-02-04 03:32:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2927/3290, eval_loss: 0.5047, eval_acc: 0.8648:  89%|[32m████████▉ [0m| 2928/3290 [18:09<02:35,  2.33it/s][A
step: 2928/3290, eval_loss: 0.5046, eval_acc: 0.8648:  89%|[32m████████▉ [0m| 2928/3290 [18:09<02:35,  2.33it/s][A[2025-02-04 03:32:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 2928/3290, eval_loss: 0.5046, eval_acc: 0.8648:  89%|[32m████████▉ [0m| 2929/3290 [18:09<02:43,  2.20it/s][A
step: 2929/3290, eval_loss: 0.5045, eval_acc: 0.8649:  89%|[32m████████▉ [0m| 2929/3290 [18:09<02:43,  2.20it/s][A[2025-02-04 03:32:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2929/3290, eval_loss: 0.5045, eval_acc: 0.8649:  89%|[32m████████▉ [0m| 2930/3290 [18:10<02:45,  2.18it/s][A
step: 2930/3290, eval_loss: 0.5044, eval_acc: 0.8649:  89%|[32m████████▉ [0m| 2930/3290 [18:10<02:45,  2.18it/s][A[2025-02-04 03:32:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 2930/3290, eval_loss: 0.5044, eval_acc: 0.8649:  89%|[32m████████▉ [0m| 2931/3290 [18:10<02:45,  2.17it/s][A
step: 2931/3290, eval_loss: 0.5043, eval_acc: 0.8649:  89%|[32m████████▉ [0m| 2931/3290 [18:10<02:45,  2.17it/s][A[2025-02-04 03:32:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2931/3290, eval_loss: 0.5043, eval_acc: 0.8649:  89%|[32m████████▉ [0m| 2932/3290 [18:11<02:36,  2.29it/s][A
step: 2932/3290, eval_loss: 0.5041, eval_acc: 0.8650:  89%|[32m████████▉ [0m| 2932/3290 [18:11<02:36,  2.29it/s][A[2025-02-04 03:32:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2932/3290, eval_loss: 0.5041, eval_acc: 0.8650:  89%|[32m████████▉ [0m| 2933/3290 [18:11<02:31,  2.35it/s][A
step: 2933/3290, eval_loss: 0.5040, eval_acc: 0.8650:  89%|[32m████████▉ [0m| 2933/3290 [18:11<02:31,  2.35it/s][A[2025-02-04 03:32:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 2933/3290, eval_loss: 0.5040, eval_acc: 0.8650:  89%|[32m████████▉ [0m| 2934/3290 [18:12<02:46,  2.13it/s][A
step: 2934/3290, eval_loss: 0.5040, eval_acc: 0.8650:  89%|[32m████████▉ [0m| 2934/3290 [18:12<02:46,  2.13it/s][A[2025-02-04 03:32:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2934/3290, eval_loss: 0.5040, eval_acc: 0.8650:  89%|[32m████████▉ [0m| 2935/3290 [18:12<02:43,  2.18it/s][A
step: 2935/3290, eval_loss: 0.5038, eval_acc: 0.8650:  89%|[32m████████▉ [0m| 2935/3290 [18:12<02:43,  2.18it/s][A[2025-02-04 03:32:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 2935/3290, eval_loss: 0.5038, eval_acc: 0.8650:  89%|[32m████████▉ [0m| 2936/3290 [18:13<02:46,  2.13it/s][A
step: 2936/3290, eval_loss: 0.5037, eval_acc: 0.8651:  89%|[32m████████▉ [0m| 2936/3290 [18:13<02:46,  2.13it/s][A[2025-02-04 03:32:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2936/3290, eval_loss: 0.5037, eval_acc: 0.8651:  89%|[32m████████▉ [0m| 2937/3290 [18:13<02:27,  2.40it/s][A
step: 2937/3290, eval_loss: 0.5036, eval_acc: 0.8651:  89%|[32m████████▉ [0m| 2937/3290 [18:13<02:27,  2.40it/s][A[2025-02-04 03:32:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 2937/3290, eval_loss: 0.5036, eval_acc: 0.8651:  89%|[32m████████▉ [0m| 2938/3290 [18:13<02:28,  2.37it/s][A
step: 2938/3290, eval_loss: 0.5035, eval_acc: 0.8651:  89%|[32m████████▉ [0m| 2938/3290 [18:13<02:28,  2.37it/s][A[2025-02-04 03:32:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2938/3290, eval_loss: 0.5035, eval_acc: 0.8651:  89%|[32m████████▉ [0m| 2939/3290 [18:14<02:47,  2.10it/s][A
step: 2939/3290, eval_loss: 0.5034, eval_acc: 0.8652:  89%|[32m████████▉ [0m| 2939/3290 [18:14<02:47,  2.10it/s][A[2025-02-04 03:32:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2939/3290, eval_loss: 0.5034, eval_acc: 0.8652:  89%|[32m████████▉ [0m| 2940/3290 [18:14<02:23,  2.44it/s][A
step: 2940/3290, eval_loss: 0.5033, eval_acc: 0.8652:  89%|[32m████████▉ [0m| 2940/3290 [18:14<02:23,  2.44it/s][A[2025-02-04 03:32:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 2940/3290, eval_loss: 0.5033, eval_acc: 0.8652:  89%|[32m████████▉ [0m| 2941/3290 [18:15<02:23,  2.43it/s][A
step: 2941/3290, eval_loss: 0.5032, eval_acc: 0.8652:  89%|[32m████████▉ [0m| 2941/3290 [18:15<02:23,  2.43it/s][A[2025-02-04 03:32:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2941/3290, eval_loss: 0.5032, eval_acc: 0.8652:  89%|[32m████████▉ [0m| 2942/3290 [18:15<02:42,  2.15it/s][A
step: 2942/3290, eval_loss: 0.5031, eval_acc: 0.8652:  89%|[32m████████▉ [0m| 2942/3290 [18:15<02:42,  2.15it/s][A[2025-02-04 03:32:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 2942/3290, eval_loss: 0.5031, eval_acc: 0.8652:  89%|[32m████████▉ [0m| 2943/3290 [18:16<02:34,  2.24it/s][A
step: 2943/3290, eval_loss: 0.5031, eval_acc: 0.8652:  89%|[32m████████▉ [0m| 2943/3290 [18:16<02:34,  2.24it/s][A[2025-02-04 03:32:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2943/3290, eval_loss: 0.5031, eval_acc: 0.8652:  89%|[32m████████▉ [0m| 2944/3290 [18:16<02:33,  2.26it/s][A
step: 2944/3290, eval_loss: 0.5031, eval_acc: 0.8652:  89%|[32m████████▉ [0m| 2944/3290 [18:16<02:33,  2.26it/s][A[2025-02-04 03:32:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 2944/3290, eval_loss: 0.5031, eval_acc: 0.8652:  90%|[32m████████▉ [0m| 2945/3290 [18:16<02:25,  2.37it/s][A
step: 2945/3290, eval_loss: 0.5031, eval_acc: 0.8652:  90%|[32m████████▉ [0m| 2945/3290 [18:16<02:25,  2.37it/s][A[2025-02-04 03:32:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2945/3290, eval_loss: 0.5031, eval_acc: 0.8652:  90%|[32m████████▉ [0m| 2946/3290 [18:17<02:20,  2.45it/s][A
step: 2946/3290, eval_loss: 0.5029, eval_acc: 0.8652:  90%|[32m████████▉ [0m| 2946/3290 [18:17<02:20,  2.45it/s][A[2025-02-04 03:32:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2946/3290, eval_loss: 0.5029, eval_acc: 0.8652:  90%|[32m████████▉ [0m| 2947/3290 [18:17<02:13,  2.57it/s][A
step: 2947/3290, eval_loss: 0.5029, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2947/3290 [18:17<02:13,  2.57it/s][A[2025-02-04 03:32:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 2947/3290, eval_loss: 0.5029, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2948/3290 [18:17<02:06,  2.71it/s][A
step: 2948/3290, eval_loss: 0.5028, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2948/3290 [18:17<02:06,  2.71it/s][A[2025-02-04 03:32:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2948/3290, eval_loss: 0.5028, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2949/3290 [18:18<02:02,  2.78it/s][A
step: 2949/3290, eval_loss: 0.5027, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2949/3290 [18:18<02:02,  2.78it/s][A[2025-02-04 03:32:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2949/3290, eval_loss: 0.5027, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2950/3290 [18:18<01:53,  3.00it/s][A
step: 2950/3290, eval_loss: 0.5027, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2950/3290 [18:18<01:53,  3.00it/s][A[2025-02-04 03:32:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 2950/3290, eval_loss: 0.5027, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2951/3290 [18:19<02:06,  2.67it/s][A
step: 2951/3290, eval_loss: 0.5026, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2951/3290 [18:19<02:06,  2.67it/s][A[2025-02-04 03:32:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2951/3290, eval_loss: 0.5026, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2952/3290 [18:19<02:03,  2.74it/s][A
step: 2952/3290, eval_loss: 0.5027, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2952/3290 [18:19<02:03,  2.74it/s][A[2025-02-04 03:32:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2952/3290, eval_loss: 0.5027, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2953/3290 [18:19<02:04,  2.70it/s][A
step: 2953/3290, eval_loss: 0.5027, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2953/3290 [18:19<02:04,  2.70it/s][A[2025-02-04 03:32:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 2953/3290, eval_loss: 0.5027, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2954/3290 [18:20<02:03,  2.73it/s][A
step: 2954/3290, eval_loss: 0.5027, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2954/3290 [18:20<02:03,  2.73it/s][A[2025-02-04 03:32:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2954/3290, eval_loss: 0.5027, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2955/3290 [18:20<02:03,  2.71it/s][A
step: 2955/3290, eval_loss: 0.5027, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2955/3290 [18:20<02:03,  2.71it/s][A[2025-02-04 03:32:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2955/3290, eval_loss: 0.5027, eval_acc: 0.8653:  90%|[32m████████▉ [0m| 2956/3290 [18:20<01:59,  2.79it/s][A
step: 2956/3290, eval_loss: 0.5026, eval_acc: 0.8654:  90%|[32m████████▉ [0m| 2956/3290 [18:20<01:59,  2.79it/s][A[2025-02-04 03:32:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 2956/3290, eval_loss: 0.5026, eval_acc: 0.8654:  90%|[32m████████▉ [0m| 2957/3290 [18:21<01:55,  2.89it/s][A
step: 2957/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m████████▉ [0m| 2957/3290 [18:21<01:55,  2.89it/s][A[2025-02-04 03:32:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2957/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m████████▉ [0m| 2958/3290 [18:21<01:52,  2.95it/s][A
step: 2958/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m████████▉ [0m| 2958/3290 [18:21<01:52,  2.95it/s][A[2025-02-04 03:32:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 2958/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m████████▉ [0m| 2959/3290 [18:21<01:58,  2.79it/s][A
step: 2959/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m████████▉ [0m| 2959/3290 [18:21<01:58,  2.79it/s][A[2025-02-04 03:32:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2959/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m████████▉ [0m| 2960/3290 [18:22<02:07,  2.58it/s][A
step: 2960/3290, eval_loss: 0.5024, eval_acc: 0.8654:  90%|[32m████████▉ [0m| 2960/3290 [18:22<02:07,  2.58it/s][A[2025-02-04 03:32:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 2960/3290, eval_loss: 0.5024, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2961/3290 [18:22<02:09,  2.54it/s][A
step: 2961/3290, eval_loss: 0.5024, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2961/3290 [18:22<02:09,  2.54it/s][A[2025-02-04 03:32:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2961/3290, eval_loss: 0.5024, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2962/3290 [18:23<02:18,  2.37it/s][A
step: 2962/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2962/3290 [18:23<02:18,  2.37it/s][A[2025-02-04 03:32:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2962/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2963/3290 [18:23<02:25,  2.25it/s][A
step: 2963/3290, eval_loss: 0.5024, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2963/3290 [18:23<02:25,  2.25it/s][A[2025-02-04 03:32:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 2963/3290, eval_loss: 0.5024, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2964/3290 [18:24<02:15,  2.40it/s][A
step: 2964/3290, eval_loss: 0.5024, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2964/3290 [18:24<02:15,  2.40it/s][A[2025-02-04 03:32:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2964/3290, eval_loss: 0.5024, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2965/3290 [18:24<02:11,  2.47it/s][A
step: 2965/3290, eval_loss: 0.5024, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2965/3290 [18:24<02:11,  2.47it/s][A[2025-02-04 03:32:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 2965/3290, eval_loss: 0.5024, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2966/3290 [18:24<02:10,  2.47it/s][A
step: 2966/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2966/3290 [18:24<02:10,  2.47it/s][A[2025-02-04 03:32:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2966/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2967/3290 [18:25<02:02,  2.64it/s][A
step: 2967/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2967/3290 [18:25<02:02,  2.64it/s][A[2025-02-04 03:32:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2967/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2968/3290 [18:25<02:03,  2.60it/s][A
step: 2968/3290, eval_loss: 0.5024, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2968/3290 [18:25<02:03,  2.60it/s][A[2025-02-04 03:32:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 2968/3290, eval_loss: 0.5024, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2969/3290 [18:25<01:54,  2.80it/s][A
step: 2969/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2969/3290 [18:25<01:54,  2.80it/s][A[2025-02-04 03:32:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2969/3290, eval_loss: 0.5025, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2970/3290 [18:26<01:50,  2.88it/s][A
step: 2970/3290, eval_loss: 0.5024, eval_acc: 0.8655:  90%|[32m█████████ [0m| 2970/3290 [18:26<01:50,  2.88it/s][A[2025-02-04 03:32:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2970/3290, eval_loss: 0.5024, eval_acc: 0.8655:  90%|[32m█████████ [0m| 2971/3290 [18:26<02:02,  2.61it/s][A
step: 2971/3290, eval_loss: 0.5023, eval_acc: 0.8655:  90%|[32m█████████ [0m| 2971/3290 [18:26<02:02,  2.61it/s][A[2025-02-04 03:32:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 2971/3290, eval_loss: 0.5023, eval_acc: 0.8655:  90%|[32m█████████ [0m| 2972/3290 [18:27<02:05,  2.54it/s][A
step: 2972/3290, eval_loss: 0.5025, eval_acc: 0.8655:  90%|[32m█████████ [0m| 2972/3290 [18:27<02:05,  2.54it/s][A[2025-02-04 03:32:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2972/3290, eval_loss: 0.5025, eval_acc: 0.8655:  90%|[32m█████████ [0m| 2973/3290 [18:27<02:20,  2.26it/s][A
step: 2973/3290, eval_loss: 0.5025, eval_acc: 0.8655:  90%|[32m█████████ [0m| 2973/3290 [18:27<02:20,  2.26it/s][A[2025-02-04 03:32:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 2973/3290, eval_loss: 0.5025, eval_acc: 0.8655:  90%|[32m█████████ [0m| 2974/3290 [18:28<02:34,  2.05it/s][A
step: 2974/3290, eval_loss: 0.5026, eval_acc: 0.8655:  90%|[32m█████████ [0m| 2974/3290 [18:28<02:34,  2.05it/s][A[2025-02-04 03:32:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2974/3290, eval_loss: 0.5026, eval_acc: 0.8655:  90%|[32m█████████ [0m| 2975/3290 [18:28<02:27,  2.14it/s][A
step: 2975/3290, eval_loss: 0.5026, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2975/3290 [18:28<02:27,  2.14it/s][A[2025-02-04 03:32:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 2975/3290, eval_loss: 0.5026, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2976/3290 [18:28<02:14,  2.33it/s][A
step: 2976/3290, eval_loss: 0.5026, eval_acc: 0.8655:  90%|[32m█████████ [0m| 2976/3290 [18:28<02:14,  2.33it/s][A[2025-02-04 03:32:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2976/3290, eval_loss: 0.5026, eval_acc: 0.8655:  90%|[32m█████████ [0m| 2977/3290 [18:29<02:31,  2.07it/s][A
step: 2977/3290, eval_loss: 0.5027, eval_acc: 0.8654:  90%|[32m█████████ [0m| 2977/3290 [18:29<02:31,  2.07it/s][A[2025-02-04 03:32:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 2977/3290, eval_loss: 0.5027, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2978/3290 [18:29<02:15,  2.30it/s][A
step: 2978/3290, eval_loss: 0.5028, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2978/3290 [18:29<02:15,  2.30it/s][A[2025-02-04 03:32:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2978/3290, eval_loss: 0.5028, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2979/3290 [18:30<02:05,  2.48it/s][A
step: 2979/3290, eval_loss: 0.5029, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2979/3290 [18:30<02:05,  2.48it/s][A[2025-02-04 03:32:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2979/3290, eval_loss: 0.5029, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2980/3290 [18:30<01:59,  2.60it/s][A
step: 2980/3290, eval_loss: 0.5028, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2980/3290 [18:30<01:59,  2.60it/s][A[2025-02-04 03:32:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 2980/3290, eval_loss: 0.5028, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2981/3290 [18:31<02:08,  2.41it/s][A
step: 2981/3290, eval_loss: 0.5027, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2981/3290 [18:31<02:08,  2.41it/s][A[2025-02-04 03:32:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2981/3290, eval_loss: 0.5027, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2982/3290 [18:31<02:22,  2.16it/s][A
step: 2982/3290, eval_loss: 0.5027, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2982/3290 [18:31<02:22,  2.16it/s][A[2025-02-04 03:32:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 2982/3290, eval_loss: 0.5027, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2983/3290 [18:32<02:12,  2.31it/s][A
step: 2983/3290, eval_loss: 0.5027, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2983/3290 [18:32<02:12,  2.31it/s][A[2025-02-04 03:32:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2983/3290, eval_loss: 0.5027, eval_acc: 0.8654:  91%|[32m█████████ [0m| 2984/3290 [18:32<01:55,  2.64it/s][A
step: 2984/3290, eval_loss: 0.5026, eval_acc: 0.8655:  91%|[32m█████████ [0m| 2984/3290 [18:32<01:55,  2.64it/s][A[2025-02-04 03:32:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2984/3290, eval_loss: 0.5026, eval_acc: 0.8655:  91%|[32m█████████ [0m| 2985/3290 [18:32<01:52,  2.70it/s][A
step: 2985/3290, eval_loss: 0.5026, eval_acc: 0.8655:  91%|[32m█████████ [0m| 2985/3290 [18:32<01:52,  2.70it/s][A[2025-02-04 03:32:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 2985/3290, eval_loss: 0.5026, eval_acc: 0.8655:  91%|[32m█████████ [0m| 2986/3290 [18:32<01:51,  2.73it/s][A
step: 2986/3290, eval_loss: 0.5026, eval_acc: 0.8655:  91%|[32m█████████ [0m| 2986/3290 [18:32<01:51,  2.73it/s][A[2025-02-04 03:32:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2986/3290, eval_loss: 0.5026, eval_acc: 0.8655:  91%|[32m█████████ [0m| 2987/3290 [18:33<01:46,  2.84it/s][A
step: 2987/3290, eval_loss: 0.5025, eval_acc: 0.8655:  91%|[32m█████████ [0m| 2987/3290 [18:33<01:46,  2.84it/s][A[2025-02-04 03:32:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2987/3290, eval_loss: 0.5025, eval_acc: 0.8655:  91%|[32m█████████ [0m| 2988/3290 [18:33<01:52,  2.68it/s][A
step: 2988/3290, eval_loss: 0.5024, eval_acc: 0.8655:  91%|[32m█████████ [0m| 2988/3290 [18:33<01:52,  2.68it/s][A[2025-02-04 03:32:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 2988/3290, eval_loss: 0.5024, eval_acc: 0.8655:  91%|[32m█████████ [0m| 2989/3290 [18:34<01:49,  2.74it/s][A
step: 2989/3290, eval_loss: 0.5023, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2989/3290 [18:34<01:49,  2.74it/s][A[2025-02-04 03:32:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2989/3290, eval_loss: 0.5023, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2990/3290 [18:34<02:00,  2.48it/s][A
step: 2990/3290, eval_loss: 0.5022, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2990/3290 [18:34<02:00,  2.48it/s][A[2025-02-04 03:32:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 2990/3290, eval_loss: 0.5022, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2991/3290 [18:35<02:05,  2.38it/s][A
step: 2991/3290, eval_loss: 0.5022, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2991/3290 [18:35<02:05,  2.38it/s][A[2025-02-04 03:32:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2991/3290, eval_loss: 0.5022, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2992/3290 [18:35<02:05,  2.38it/s][A
step: 2992/3290, eval_loss: 0.5021, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2992/3290 [18:35<02:05,  2.38it/s][A[2025-02-04 03:32:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 2992/3290, eval_loss: 0.5021, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2993/3290 [18:35<02:11,  2.25it/s][A
step: 2993/3290, eval_loss: 0.5020, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2993/3290 [18:35<02:11,  2.25it/s][A[2025-02-04 03:32:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2993/3290, eval_loss: 0.5020, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2994/3290 [18:36<02:06,  2.33it/s][A
step: 2994/3290, eval_loss: 0.5021, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2994/3290 [18:36<02:06,  2.33it/s][A[2025-02-04 03:32:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2994/3290, eval_loss: 0.5021, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2995/3290 [18:36<01:56,  2.52it/s][A
step: 2995/3290, eval_loss: 0.5021, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2995/3290 [18:36<01:56,  2.52it/s][A[2025-02-04 03:32:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 2995/3290, eval_loss: 0.5021, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2996/3290 [18:37<02:05,  2.34it/s][A
step: 2996/3290, eval_loss: 0.5021, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2996/3290 [18:37<02:05,  2.34it/s][A[2025-02-04 03:32:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2996/3290, eval_loss: 0.5021, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2997/3290 [18:37<01:59,  2.45it/s][A
step: 2997/3290, eval_loss: 0.5021, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2997/3290 [18:37<01:59,  2.45it/s][A[2025-02-04 03:32:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 2997/3290, eval_loss: 0.5021, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2998/3290 [18:37<01:56,  2.51it/s][A
step: 2998/3290, eval_loss: 0.5020, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2998/3290 [18:37<01:56,  2.51it/s][A[2025-02-04 03:32:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2998/3290, eval_loss: 0.5020, eval_acc: 0.8656:  91%|[32m█████████ [0m| 2999/3290 [18:38<01:54,  2.54it/s][A
step: 2999/3290, eval_loss: 0.5019, eval_acc: 0.8657:  91%|[32m█████████ [0m| 2999/3290 [18:38<01:54,  2.54it/s][A[2025-02-04 03:32:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 2999/3290, eval_loss: 0.5019, eval_acc: 0.8657:  91%|[32m█████████ [0m| 3000/3290 [18:38<01:51,  2.59it/s][A
step: 3000/3290, eval_loss: 0.5022, eval_acc: 0.8656:  91%|[32m█████████ [0m| 3000/3290 [18:38<01:51,  2.59it/s][A[2025-02-04 03:32:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 3000/3290, eval_loss: 0.5022, eval_acc: 0.8656:  91%|[32m█████████ [0m| 3001/3290 [18:38<01:42,  2.81it/s][A
step: 3001/3290, eval_loss: 0.5023, eval_acc: 0.8656:  91%|[32m█████████ [0m| 3001/3290 [18:38<01:42,  2.81it/s][A[2025-02-04 03:32:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 3001/3290, eval_loss: 0.5023, eval_acc: 0.8656:  91%|[32m█████████ [0m| 3002/3290 [18:39<01:45,  2.72it/s][A
step: 3002/3290, eval_loss: 0.5023, eval_acc: 0.8656:  91%|[32m█████████ [0m| 3002/3290 [18:39<01:45,  2.72it/s][A[2025-02-04 03:32:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 3002/3290, eval_loss: 0.5023, eval_acc: 0.8656:  91%|[32m█████████▏[0m| 3003/3290 [18:39<01:47,  2.66it/s][A
step: 3003/3290, eval_loss: 0.5026, eval_acc: 0.8655:  91%|[32m█████████▏[0m| 3003/3290 [18:39<01:47,  2.66it/s][A[2025-02-04 03:32:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 3003/3290, eval_loss: 0.5026, eval_acc: 0.8655:  91%|[32m█████████▏[0m| 3004/3290 [18:40<01:41,  2.83it/s][A
step: 3004/3290, eval_loss: 0.5027, eval_acc: 0.8655:  91%|[32m█████████▏[0m| 3004/3290 [18:40<01:41,  2.83it/s][A[2025-02-04 03:32:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 3004/3290, eval_loss: 0.5027, eval_acc: 0.8655:  91%|[32m█████████▏[0m| 3005/3290 [18:40<01:44,  2.73it/s][A
step: 3005/3290, eval_loss: 0.5028, eval_acc: 0.8655:  91%|[32m█████████▏[0m| 3005/3290 [18:40<01:44,  2.73it/s][A[2025-02-04 03:32:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 3005/3290, eval_loss: 0.5028, eval_acc: 0.8655:  91%|[32m█████████▏[0m| 3006/3290 [18:40<01:50,  2.58it/s][A
step: 3006/3290, eval_loss: 0.5030, eval_acc: 0.8655:  91%|[32m█████████▏[0m| 3006/3290 [18:40<01:50,  2.58it/s][A[2025-02-04 03:32:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 3006/3290, eval_loss: 0.5030, eval_acc: 0.8655:  91%|[32m█████████▏[0m| 3007/3290 [18:41<01:49,  2.59it/s][A
step: 3007/3290, eval_loss: 0.5032, eval_acc: 0.8654:  91%|[32m█████████▏[0m| 3007/3290 [18:41<01:49,  2.59it/s][A[2025-02-04 03:32:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 3007/3290, eval_loss: 0.5032, eval_acc: 0.8654:  91%|[32m█████████▏[0m| 3008/3290 [18:41<01:48,  2.59it/s][A
step: 3008/3290, eval_loss: 0.5032, eval_acc: 0.8654:  91%|[32m█████████▏[0m| 3008/3290 [18:41<01:48,  2.59it/s][A[2025-02-04 03:32:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 3008/3290, eval_loss: 0.5032, eval_acc: 0.8654:  91%|[32m█████████▏[0m| 3009/3290 [18:41<01:46,  2.64it/s][A
step: 3009/3290, eval_loss: 0.5035, eval_acc: 0.8653:  91%|[32m█████████▏[0m| 3009/3290 [18:41<01:46,  2.64it/s][A[2025-02-04 03:32:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 3009/3290, eval_loss: 0.5035, eval_acc: 0.8653:  91%|[32m█████████▏[0m| 3010/3290 [18:42<01:55,  2.41it/s][A
step: 3010/3290, eval_loss: 0.5034, eval_acc: 0.8654:  91%|[32m█████████▏[0m| 3010/3290 [18:42<01:55,  2.41it/s][A[2025-02-04 03:32:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 3010/3290, eval_loss: 0.5034, eval_acc: 0.8654:  92%|[32m█████████▏[0m| 3011/3290 [18:42<01:45,  2.64it/s][A
step: 3011/3290, eval_loss: 0.5035, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3011/3290 [18:42<01:45,  2.64it/s][A[2025-02-04 03:32:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 3011/3290, eval_loss: 0.5035, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3012/3290 [18:43<01:42,  2.71it/s][A
step: 3012/3290, eval_loss: 0.5039, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3012/3290 [18:43<01:42,  2.71it/s][A[2025-02-04 03:32:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 3012/3290, eval_loss: 0.5039, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3013/3290 [18:43<01:51,  2.49it/s][A
step: 3013/3290, eval_loss: 0.5038, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3013/3290 [18:43<01:51,  2.49it/s][A[2025-02-04 03:32:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 3013/3290, eval_loss: 0.5038, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3014/3290 [18:44<01:51,  2.49it/s][A
step: 3014/3290, eval_loss: 0.5039, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3014/3290 [18:44<01:51,  2.49it/s][A[2025-02-04 03:32:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 3014/3290, eval_loss: 0.5039, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3015/3290 [18:44<01:50,  2.49it/s][A
step: 3015/3290, eval_loss: 0.5039, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3015/3290 [18:44<01:50,  2.49it/s][A[2025-02-04 03:32:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 3015/3290, eval_loss: 0.5039, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3016/3290 [18:44<01:51,  2.46it/s][A
step: 3016/3290, eval_loss: 0.5040, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3016/3290 [18:44<01:51,  2.46it/s][A[2025-02-04 03:32:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 3016/3290, eval_loss: 0.5040, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3017/3290 [18:45<01:46,  2.55it/s][A
step: 3017/3290, eval_loss: 0.5038, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3017/3290 [18:45<01:46,  2.55it/s][A[2025-02-04 03:32:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 3017/3290, eval_loss: 0.5038, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3018/3290 [18:45<01:49,  2.49it/s][A
step: 3018/3290, eval_loss: 0.5038, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3018/3290 [18:45<01:49,  2.49it/s][A[2025-02-04 03:32:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 3018/3290, eval_loss: 0.5038, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3019/3290 [18:45<01:47,  2.51it/s][A
step: 3019/3290, eval_loss: 0.5039, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3019/3290 [18:45<01:47,  2.51it/s][A[2025-02-04 03:32:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 3019/3290, eval_loss: 0.5039, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3020/3290 [18:46<01:41,  2.65it/s][A
step: 3020/3290, eval_loss: 0.5038, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3020/3290 [18:46<01:41,  2.65it/s][A[2025-02-04 03:32:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 3020/3290, eval_loss: 0.5038, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3021/3290 [18:46<01:37,  2.76it/s][A
step: 3021/3290, eval_loss: 0.5038, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3021/3290 [18:46<01:37,  2.76it/s][A[2025-02-04 03:32:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 3021/3290, eval_loss: 0.5038, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3022/3290 [18:47<01:38,  2.73it/s][A
step: 3022/3290, eval_loss: 0.5039, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3022/3290 [18:47<01:38,  2.73it/s][A[2025-02-04 03:32:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 3022/3290, eval_loss: 0.5039, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3023/3290 [18:47<01:36,  2.75it/s][A
step: 3023/3290, eval_loss: 0.5038, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3023/3290 [18:47<01:36,  2.75it/s][A[2025-02-04 03:32:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 3023/3290, eval_loss: 0.5038, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3024/3290 [18:47<01:29,  2.96it/s][A
step: 3024/3290, eval_loss: 0.5040, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3024/3290 [18:47<01:29,  2.96it/s][A[2025-02-04 03:32:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 3024/3290, eval_loss: 0.5040, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3025/3290 [18:47<01:27,  3.03it/s][A
step: 3025/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3025/3290 [18:47<01:27,  3.03it/s][A[2025-02-04 03:32:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 3025/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3026/3290 [18:48<01:34,  2.81it/s][A
step: 3026/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3026/3290 [18:48<01:34,  2.81it/s][A[2025-02-04 03:32:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 3026/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3027/3290 [18:48<01:33,  2.81it/s][A
step: 3027/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3027/3290 [18:48<01:33,  2.81it/s][A[2025-02-04 03:32:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 3027/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3028/3290 [18:49<01:34,  2.78it/s][A
step: 3028/3290, eval_loss: 0.5040, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3028/3290 [18:49<01:34,  2.78it/s][A[2025-02-04 03:32:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 3028/3290, eval_loss: 0.5040, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3029/3290 [18:49<01:28,  2.96it/s][A
step: 3029/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3029/3290 [18:49<01:28,  2.96it/s][A[2025-02-04 03:32:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 3029/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3030/3290 [18:49<01:25,  3.04it/s][A
step: 3030/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3030/3290 [18:49<01:25,  3.04it/s][A[2025-02-04 03:32:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 3030/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3031/3290 [18:50<01:23,  3.11it/s][A
step: 3031/3290, eval_loss: 0.5040, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3031/3290 [18:50<01:23,  3.11it/s][A[2025-02-04 03:32:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 3031/3290, eval_loss: 0.5040, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3032/3290 [18:50<01:28,  2.93it/s][A
step: 3032/3290, eval_loss: 0.5040, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3032/3290 [18:50<01:28,  2.93it/s][A[2025-02-04 03:32:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 3032/3290, eval_loss: 0.5040, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3033/3290 [18:50<01:22,  3.13it/s][A
step: 3033/3290, eval_loss: 0.5041, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3033/3290 [18:50<01:22,  3.13it/s][A[2025-02-04 03:32:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 3033/3290, eval_loss: 0.5041, eval_acc: 0.8653:  92%|[32m█████████▏[0m| 3034/3290 [18:50<01:18,  3.27it/s][A
step: 3034/3290, eval_loss: 0.5042, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3034/3290 [18:50<01:18,  3.27it/s][A[2025-02-04 03:32:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 3034/3290, eval_loss: 0.5042, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3035/3290 [18:51<01:16,  3.33it/s][A
step: 3035/3290, eval_loss: 0.5043, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3035/3290 [18:51<01:16,  3.33it/s][A[2025-02-04 03:32:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 3035/3290, eval_loss: 0.5043, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3036/3290 [18:51<01:26,  2.94it/s][A
step: 3036/3290, eval_loss: 0.5044, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3036/3290 [18:51<01:26,  2.94it/s][A[2025-02-04 03:32:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 3036/3290, eval_loss: 0.5044, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3037/3290 [18:51<01:23,  3.02it/s][A
step: 3037/3290, eval_loss: 0.5043, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3037/3290 [18:51<01:23,  3.02it/s][A[2025-02-04 03:32:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 3037/3290, eval_loss: 0.5043, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3038/3290 [18:52<01:27,  2.87it/s][A
step: 3038/3290, eval_loss: 0.5043, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3038/3290 [18:52<01:27,  2.87it/s][A[2025-02-04 03:32:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 3038/3290, eval_loss: 0.5043, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3039/3290 [18:52<01:29,  2.80it/s][A
step: 3039/3290, eval_loss: 0.5042, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3039/3290 [18:52<01:29,  2.80it/s][A[2025-02-04 03:32:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 3039/3290, eval_loss: 0.5042, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3040/3290 [18:53<01:39,  2.52it/s][A
step: 3040/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3040/3290 [18:53<01:39,  2.52it/s][A[2025-02-04 03:32:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 3040/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3041/3290 [18:53<01:28,  2.80it/s][A
step: 3041/3290, eval_loss: 0.5042, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3041/3290 [18:53<01:28,  2.80it/s][A[2025-02-04 03:32:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 3041/3290, eval_loss: 0.5042, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3042/3290 [18:53<01:32,  2.68it/s][A
step: 3042/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3042/3290 [18:53<01:32,  2.68it/s][A[2025-02-04 03:32:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 3042/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3043/3290 [18:54<01:32,  2.66it/s][A
step: 3043/3290, eval_loss: 0.5041, eval_acc: 0.8652:  92%|[32m█████████▏[0m| 3043/3290 [18:54<01:32,  2.66it/s][A[2025-02-04 03:32:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 3043/3290, eval_loss: 0.5041, eval_acc: 0.8652:  93%|[32m█████████▎[0m| 3044/3290 [18:54<01:26,  2.85it/s][A
step: 3044/3290, eval_loss: 0.5042, eval_acc: 0.8652:  93%|[32m█████████▎[0m| 3044/3290 [18:54<01:26,  2.85it/s][A[2025-02-04 03:32:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 3044/3290, eval_loss: 0.5042, eval_acc: 0.8652:  93%|[32m█████████▎[0m| 3045/3290 [18:54<01:28,  2.77it/s][A
step: 3045/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3045/3290 [18:54<01:28,  2.77it/s][A[2025-02-04 03:32:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 3045/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3046/3290 [18:55<01:33,  2.60it/s][A
step: 3046/3290, eval_loss: 0.5041, eval_acc: 0.8652:  93%|[32m█████████▎[0m| 3046/3290 [18:55<01:33,  2.60it/s][A[2025-02-04 03:32:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 3046/3290, eval_loss: 0.5041, eval_acc: 0.8652:  93%|[32m█████████▎[0m| 3047/3290 [18:55<01:28,  2.76it/s][A
step: 3047/3290, eval_loss: 0.5040, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3047/3290 [18:55<01:28,  2.76it/s][A[2025-02-04 03:32:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 3047/3290, eval_loss: 0.5040, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3048/3290 [18:56<01:27,  2.75it/s][A
step: 3048/3290, eval_loss: 0.5039, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3048/3290 [18:56<01:27,  2.75it/s][A[2025-02-04 03:32:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 3048/3290, eval_loss: 0.5039, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3049/3290 [18:56<01:26,  2.79it/s][A
step: 3049/3290, eval_loss: 0.5038, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3049/3290 [18:56<01:26,  2.79it/s][A[2025-02-04 03:32:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 3049/3290, eval_loss: 0.5038, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3050/3290 [18:56<01:28,  2.72it/s][A
step: 3050/3290, eval_loss: 0.5038, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3050/3290 [18:56<01:28,  2.72it/s][A[2025-02-04 03:32:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 3050/3290, eval_loss: 0.5038, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3051/3290 [18:57<01:28,  2.69it/s][A
step: 3051/3290, eval_loss: 0.5040, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3051/3290 [18:57<01:28,  2.69it/s][A[2025-02-04 03:32:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 3051/3290, eval_loss: 0.5040, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3052/3290 [18:57<01:22,  2.90it/s][A
step: 3052/3290, eval_loss: 0.5042, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3052/3290 [18:57<01:22,  2.90it/s][A[2025-02-04 03:32:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 3052/3290, eval_loss: 0.5042, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3053/3290 [18:57<01:23,  2.83it/s][A
step: 3053/3290, eval_loss: 0.5042, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3053/3290 [18:57<01:23,  2.83it/s][A[2025-02-04 03:32:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 3053/3290, eval_loss: 0.5042, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3054/3290 [18:58<01:26,  2.72it/s][A
step: 3054/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3054/3290 [18:58<01:26,  2.72it/s][A[2025-02-04 03:32:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 3054/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3055/3290 [18:58<01:29,  2.62it/s][A
step: 3055/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3055/3290 [18:58<01:29,  2.62it/s][A[2025-02-04 03:32:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 3055/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3056/3290 [18:59<01:27,  2.66it/s][A
step: 3056/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3056/3290 [18:59<01:27,  2.66it/s][A[2025-02-04 03:32:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 3056/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3057/3290 [18:59<01:22,  2.83it/s][A
step: 3057/3290, eval_loss: 0.5040, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3057/3290 [18:59<01:22,  2.83it/s][A[2025-02-04 03:32:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 3057/3290, eval_loss: 0.5040, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3058/3290 [18:59<01:29,  2.60it/s][A
step: 3058/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3058/3290 [18:59<01:29,  2.60it/s][A[2025-02-04 03:32:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 3058/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3059/3290 [19:00<01:29,  2.59it/s][A
step: 3059/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3059/3290 [19:00<01:29,  2.59it/s][A[2025-02-04 03:32:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 3059/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3060/3290 [19:00<01:21,  2.81it/s][A
step: 3060/3290, eval_loss: 0.5042, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3060/3290 [19:00<01:21,  2.81it/s][A[2025-02-04 03:32:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 3060/3290, eval_loss: 0.5042, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3061/3290 [19:00<01:23,  2.74it/s][A
step: 3061/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3061/3290 [19:00<01:23,  2.74it/s][A[2025-02-04 03:32:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 3061/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3062/3290 [19:01<01:24,  2.71it/s][A
step: 3062/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3062/3290 [19:01<01:24,  2.71it/s][A[2025-02-04 03:32:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 3062/3290, eval_loss: 0.5041, eval_acc: 0.8653:  93%|[32m█████████▎[0m| 3063/3290 [19:01<01:23,  2.70it/s][A
step: 3063/3290, eval_loss: 0.5040, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3063/3290 [19:01<01:23,  2.70it/s][A[2025-02-04 03:32:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 3063/3290, eval_loss: 0.5040, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3064/3290 [19:01<01:17,  2.92it/s][A
step: 3064/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3064/3290 [19:01<01:17,  2.92it/s][A[2025-02-04 03:32:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 3064/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3065/3290 [19:02<01:15,  2.99it/s][A
step: 3065/3290, eval_loss: 0.5037, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3065/3290 [19:02<01:15,  2.99it/s][A[2025-02-04 03:32:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 3065/3290, eval_loss: 0.5037, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3066/3290 [19:02<01:13,  3.04it/s][A
step: 3066/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3066/3290 [19:02<01:13,  3.04it/s][A[2025-02-04 03:32:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 3066/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3067/3290 [19:02<01:12,  3.09it/s][A
step: 3067/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3067/3290 [19:02<01:12,  3.09it/s][A[2025-02-04 03:32:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 3067/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3068/3290 [19:03<01:14,  2.98it/s][A
step: 3068/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3068/3290 [19:03<01:14,  2.98it/s][A[2025-02-04 03:32:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 3068/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3069/3290 [19:03<01:14,  2.96it/s][A
step: 3069/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3069/3290 [19:03<01:14,  2.96it/s][A[2025-02-04 03:32:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 3069/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3070/3290 [19:03<01:11,  3.08it/s][A
step: 3070/3290, eval_loss: 0.5040, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3070/3290 [19:03<01:11,  3.08it/s][A[2025-02-04 03:32:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 3070/3290, eval_loss: 0.5040, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3071/3290 [19:04<01:17,  2.84it/s][A
step: 3071/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3071/3290 [19:04<01:17,  2.84it/s][A[2025-02-04 03:32:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 3071/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3072/3290 [19:04<01:17,  2.82it/s][A
step: 3072/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3072/3290 [19:04<01:17,  2.82it/s][A[2025-02-04 03:32:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 3072/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3073/3290 [19:04<01:14,  2.91it/s][A
step: 3073/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3073/3290 [19:04<01:14,  2.91it/s][A[2025-02-04 03:32:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 3073/3290, eval_loss: 0.5039, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3074/3290 [19:05<01:14,  2.90it/s][A
step: 3074/3290, eval_loss: 0.5040, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3074/3290 [19:05<01:14,  2.90it/s][A[2025-02-04 03:32:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 3074/3290, eval_loss: 0.5040, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3075/3290 [19:05<01:18,  2.73it/s][A
step: 3075/3290, eval_loss: 0.5041, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3075/3290 [19:05<01:18,  2.73it/s][A[2025-02-04 03:32:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 3075/3290, eval_loss: 0.5041, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3076/3290 [19:06<01:23,  2.55it/s][A
step: 3076/3290, eval_loss: 0.5041, eval_acc: 0.8654:  93%|[32m█████████▎[0m| 3076/3290 [19:06<01:23,  2.55it/s][A[2025-02-04 03:33:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 3076/3290, eval_loss: 0.5041, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3077/3290 [19:06<01:24,  2.53it/s][A
step: 3077/3290, eval_loss: 0.5041, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3077/3290 [19:06<01:24,  2.53it/s][A[2025-02-04 03:33:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 3077/3290, eval_loss: 0.5041, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3078/3290 [19:06<01:15,  2.81it/s][A
step: 3078/3290, eval_loss: 0.5041, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3078/3290 [19:06<01:15,  2.81it/s][A[2025-02-04 03:33:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 3078/3290, eval_loss: 0.5041, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3079/3290 [19:07<01:12,  2.92it/s][A
step: 3079/3290, eval_loss: 0.5041, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3079/3290 [19:07<01:12,  2.92it/s][A[2025-02-04 03:33:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 3079/3290, eval_loss: 0.5041, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3080/3290 [19:07<01:09,  3.02it/s][A
step: 3080/3290, eval_loss: 0.5041, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3080/3290 [19:07<01:09,  3.02it/s][A[2025-02-04 03:33:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 3080/3290, eval_loss: 0.5041, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3081/3290 [19:07<01:11,  2.92it/s][A
step: 3081/3290, eval_loss: 0.5041, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3081/3290 [19:07<01:11,  2.92it/s][A[2025-02-04 03:33:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 3081/3290, eval_loss: 0.5041, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3082/3290 [19:08<01:09,  3.01it/s][A
step: 3082/3290, eval_loss: 0.5040, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3082/3290 [19:08<01:09,  3.01it/s][A[2025-02-04 03:33:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 3082/3290, eval_loss: 0.5040, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3083/3290 [19:08<01:11,  2.89it/s][A
step: 3083/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3083/3290 [19:08<01:11,  2.89it/s][A[2025-02-04 03:33:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 3083/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3084/3290 [19:08<01:12,  2.83it/s][A
step: 3084/3290, eval_loss: 0.5040, eval_acc: 0.8654:  94%|[32m█████████▎[0m| 3084/3290 [19:08<01:12,  2.83it/s][A[2025-02-04 03:33:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 3084/3290, eval_loss: 0.5040, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3085/3290 [19:09<01:12,  2.83it/s][A
step: 3085/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3085/3290 [19:09<01:12,  2.83it/s][A[2025-02-04 03:33:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 3085/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3086/3290 [19:09<01:08,  3.00it/s][A
step: 3086/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3086/3290 [19:09<01:08,  3.00it/s][A[2025-02-04 03:33:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 3086/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3087/3290 [19:09<01:15,  2.67it/s][A
step: 3087/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3087/3290 [19:09<01:15,  2.67it/s][A[2025-02-04 03:33:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 3087/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3088/3290 [19:10<01:11,  2.82it/s][A
step: 3088/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3088/3290 [19:10<01:11,  2.82it/s][A[2025-02-04 03:33:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 3088/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3089/3290 [19:10<01:13,  2.72it/s][A
step: 3089/3290, eval_loss: 0.5037, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3089/3290 [19:10<01:13,  2.72it/s][A[2025-02-04 03:33:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 3089/3290, eval_loss: 0.5037, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3090/3290 [19:11<01:13,  2.71it/s][A
step: 3090/3290, eval_loss: 0.5038, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3090/3290 [19:11<01:13,  2.71it/s][A[2025-02-04 03:33:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 3090/3290, eval_loss: 0.5038, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3091/3290 [19:11<01:13,  2.72it/s][A
step: 3091/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3091/3290 [19:11<01:13,  2.72it/s][A[2025-02-04 03:33:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 3091/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3092/3290 [19:11<01:13,  2.69it/s][A
step: 3092/3290, eval_loss: 0.5040, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3092/3290 [19:11<01:13,  2.69it/s][A[2025-02-04 03:33:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 3092/3290, eval_loss: 0.5040, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3093/3290 [19:12<01:15,  2.61it/s][A
step: 3093/3290, eval_loss: 0.5040, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3093/3290 [19:12<01:15,  2.61it/s][A[2025-02-04 03:33:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 3093/3290, eval_loss: 0.5040, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3094/3290 [19:12<01:12,  2.70it/s][A
step: 3094/3290, eval_loss: 0.5042, eval_acc: 0.8653:  94%|[32m█████████▍[0m| 3094/3290 [19:12<01:12,  2.70it/s][A[2025-02-04 03:33:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 3094/3290, eval_loss: 0.5042, eval_acc: 0.8653:  94%|[32m█████████▍[0m| 3095/3290 [19:12<01:07,  2.90it/s][A
step: 3095/3290, eval_loss: 0.5042, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3095/3290 [19:12<01:07,  2.90it/s][A[2025-02-04 03:33:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 3095/3290, eval_loss: 0.5042, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3096/3290 [19:13<01:07,  2.89it/s][A
step: 3096/3290, eval_loss: 0.5042, eval_acc: 0.8653:  94%|[32m█████████▍[0m| 3096/3290 [19:13<01:07,  2.89it/s][A[2025-02-04 03:33:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 3096/3290, eval_loss: 0.5042, eval_acc: 0.8653:  94%|[32m█████████▍[0m| 3097/3290 [19:13<01:04,  2.99it/s][A
step: 3097/3290, eval_loss: 0.5041, eval_acc: 0.8653:  94%|[32m█████████▍[0m| 3097/3290 [19:13<01:04,  2.99it/s][A[2025-02-04 03:33:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 3097/3290, eval_loss: 0.5041, eval_acc: 0.8653:  94%|[32m█████████▍[0m| 3098/3290 [19:13<01:10,  2.72it/s][A
step: 3098/3290, eval_loss: 0.5040, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3098/3290 [19:13<01:10,  2.72it/s][A[2025-02-04 03:33:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 3098/3290, eval_loss: 0.5040, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3099/3290 [19:14<01:11,  2.68it/s][A
step: 3099/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3099/3290 [19:14<01:11,  2.68it/s][A[2025-02-04 03:33:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 3099/3290, eval_loss: 0.5039, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3100/3290 [19:14<01:03,  2.99it/s][A
step: 3100/3290, eval_loss: 0.5037, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3100/3290 [19:14<01:03,  2.99it/s][A[2025-02-04 03:33:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 3100/3290, eval_loss: 0.5037, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3101/3290 [19:14<01:05,  2.88it/s][A
step: 3101/3290, eval_loss: 0.5038, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3101/3290 [19:14<01:05,  2.88it/s][A[2025-02-04 03:33:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 3101/3290, eval_loss: 0.5038, eval_acc: 0.8654:  94%|[32m█████████▍[0m| 3102/3290 [19:15<01:14,  2.54it/s][A
step: 3102/3290, eval_loss: 0.5037, eval_acc: 0.8655:  94%|[32m█████████▍[0m| 3102/3290 [19:15<01:14,  2.54it/s][A[2025-02-04 03:33:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 3102/3290, eval_loss: 0.5037, eval_acc: 0.8655:  94%|[32m█████████▍[0m| 3103/3290 [19:15<01:11,  2.60it/s][A
step: 3103/3290, eval_loss: 0.5036, eval_acc: 0.8655:  94%|[32m█████████▍[0m| 3103/3290 [19:15<01:11,  2.60it/s][A[2025-02-04 03:33:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 3103/3290, eval_loss: 0.5036, eval_acc: 0.8655:  94%|[32m█████████▍[0m| 3104/3290 [19:16<01:12,  2.58it/s][A
step: 3104/3290, eval_loss: 0.5035, eval_acc: 0.8655:  94%|[32m█████████▍[0m| 3104/3290 [19:16<01:12,  2.58it/s][A[2025-02-04 03:33:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 3104/3290, eval_loss: 0.5035, eval_acc: 0.8655:  94%|[32m█████████▍[0m| 3105/3290 [19:16<01:11,  2.60it/s][A
step: 3105/3290, eval_loss: 0.5034, eval_acc: 0.8655:  94%|[32m█████████▍[0m| 3105/3290 [19:16<01:11,  2.60it/s][A[2025-02-04 03:33:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 3105/3290, eval_loss: 0.5034, eval_acc: 0.8655:  94%|[32m█████████▍[0m| 3106/3290 [19:16<01:09,  2.64it/s][A
step: 3106/3290, eval_loss: 0.5032, eval_acc: 0.8656:  94%|[32m█████████▍[0m| 3106/3290 [19:16<01:09,  2.64it/s][A[2025-02-04 03:33:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 3106/3290, eval_loss: 0.5032, eval_acc: 0.8656:  94%|[32m█████████▍[0m| 3107/3290 [19:17<01:06,  2.77it/s][A
step: 3107/3290, eval_loss: 0.5032, eval_acc: 0.8656:  94%|[32m█████████▍[0m| 3107/3290 [19:17<01:06,  2.77it/s][A[2025-02-04 03:33:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 3107/3290, eval_loss: 0.5032, eval_acc: 0.8656:  94%|[32m█████████▍[0m| 3108/3290 [19:17<01:08,  2.64it/s][A
step: 3108/3290, eval_loss: 0.5032, eval_acc: 0.8656:  94%|[32m█████████▍[0m| 3108/3290 [19:17<01:08,  2.64it/s][A[2025-02-04 03:33:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 3108/3290, eval_loss: 0.5032, eval_acc: 0.8656:  94%|[32m█████████▍[0m| 3109/3290 [19:18<01:19,  2.28it/s][A
step: 3109/3290, eval_loss: 0.5031, eval_acc: 0.8656:  94%|[32m█████████▍[0m| 3109/3290 [19:18<01:19,  2.28it/s][A[2025-02-04 03:33:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 3109/3290, eval_loss: 0.5031, eval_acc: 0.8656:  95%|[32m█████████▍[0m| 3110/3290 [19:18<01:17,  2.32it/s][A
step: 3110/3290, eval_loss: 0.5032, eval_acc: 0.8656:  95%|[32m█████████▍[0m| 3110/3290 [19:18<01:17,  2.32it/s][A[2025-02-04 03:33:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 3110/3290, eval_loss: 0.5032, eval_acc: 0.8656:  95%|[32m█████████▍[0m| 3111/3290 [19:18<01:12,  2.47it/s][A
step: 3111/3290, eval_loss: 0.5031, eval_acc: 0.8656:  95%|[32m█████████▍[0m| 3111/3290 [19:18<01:12,  2.47it/s][A[2025-02-04 03:33:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 3111/3290, eval_loss: 0.5031, eval_acc: 0.8656:  95%|[32m█████████▍[0m| 3112/3290 [19:19<01:17,  2.31it/s][A
step: 3112/3290, eval_loss: 0.5030, eval_acc: 0.8657:  95%|[32m█████████▍[0m| 3112/3290 [19:19<01:17,  2.31it/s][A[2025-02-04 03:33:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 3112/3290, eval_loss: 0.5030, eval_acc: 0.8657:  95%|[32m█████████▍[0m| 3113/3290 [19:19<01:19,  2.22it/s][A
step: 3113/3290, eval_loss: 0.5029, eval_acc: 0.8657:  95%|[32m█████████▍[0m| 3113/3290 [19:19<01:19,  2.22it/s][A[2025-02-04 03:33:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 3113/3290, eval_loss: 0.5029, eval_acc: 0.8657:  95%|[32m█████████▍[0m| 3114/3290 [19:20<01:20,  2.19it/s][A
step: 3114/3290, eval_loss: 0.5028, eval_acc: 0.8657:  95%|[32m█████████▍[0m| 3114/3290 [19:20<01:20,  2.19it/s][A[2025-02-04 03:33:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 3114/3290, eval_loss: 0.5028, eval_acc: 0.8657:  95%|[32m█████████▍[0m| 3115/3290 [19:20<01:12,  2.40it/s][A
step: 3115/3290, eval_loss: 0.5027, eval_acc: 0.8657:  95%|[32m█████████▍[0m| 3115/3290 [19:20<01:12,  2.40it/s][A[2025-02-04 03:33:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 3115/3290, eval_loss: 0.5027, eval_acc: 0.8657:  95%|[32m█████████▍[0m| 3116/3290 [19:21<01:12,  2.39it/s][A
step: 3116/3290, eval_loss: 0.5027, eval_acc: 0.8658:  95%|[32m█████████▍[0m| 3116/3290 [19:21<01:12,  2.39it/s][A[2025-02-04 03:33:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 3116/3290, eval_loss: 0.5027, eval_acc: 0.8658:  95%|[32m█████████▍[0m| 3117/3290 [19:21<01:07,  2.56it/s][A
step: 3117/3290, eval_loss: 0.5026, eval_acc: 0.8658:  95%|[32m█████████▍[0m| 3117/3290 [19:21<01:07,  2.56it/s][A[2025-02-04 03:33:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 3117/3290, eval_loss: 0.5026, eval_acc: 0.8658:  95%|[32m█████████▍[0m| 3118/3290 [19:21<01:01,  2.80it/s][A
step: 3118/3290, eval_loss: 0.5025, eval_acc: 0.8658:  95%|[32m█████████▍[0m| 3118/3290 [19:21<01:01,  2.80it/s][A[2025-02-04 03:33:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 3118/3290, eval_loss: 0.5025, eval_acc: 0.8658:  95%|[32m█████████▍[0m| 3119/3290 [19:22<00:59,  2.88it/s][A
step: 3119/3290, eval_loss: 0.5024, eval_acc: 0.8658:  95%|[32m█████████▍[0m| 3119/3290 [19:22<00:59,  2.88it/s][A[2025-02-04 03:33:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 3119/3290, eval_loss: 0.5024, eval_acc: 0.8658:  95%|[32m█████████▍[0m| 3120/3290 [19:22<01:02,  2.72it/s][A
step: 3120/3290, eval_loss: 0.5022, eval_acc: 0.8659:  95%|[32m█████████▍[0m| 3120/3290 [19:22<01:02,  2.72it/s][A[2025-02-04 03:33:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 3120/3290, eval_loss: 0.5022, eval_acc: 0.8659:  95%|[32m█████████▍[0m| 3121/3290 [19:22<01:01,  2.75it/s][A
step: 3121/3290, eval_loss: 0.5022, eval_acc: 0.8659:  95%|[32m█████████▍[0m| 3121/3290 [19:22<01:01,  2.75it/s][A[2025-02-04 03:33:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 3121/3290, eval_loss: 0.5022, eval_acc: 0.8659:  95%|[32m█████████▍[0m| 3122/3290 [19:23<01:07,  2.49it/s][A
step: 3122/3290, eval_loss: 0.5021, eval_acc: 0.8659:  95%|[32m█████████▍[0m| 3122/3290 [19:23<01:07,  2.49it/s][A[2025-02-04 03:33:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 3122/3290, eval_loss: 0.5021, eval_acc: 0.8659:  95%|[32m█████████▍[0m| 3123/3290 [19:23<01:04,  2.58it/s][A
step: 3123/3290, eval_loss: 0.5021, eval_acc: 0.8659:  95%|[32m█████████▍[0m| 3123/3290 [19:23<01:04,  2.58it/s][A[2025-02-04 03:33:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 3123/3290, eval_loss: 0.5021, eval_acc: 0.8659:  95%|[32m█████████▍[0m| 3124/3290 [19:24<01:05,  2.55it/s][A
step: 3124/3290, eval_loss: 0.5020, eval_acc: 0.8659:  95%|[32m█████████▍[0m| 3124/3290 [19:24<01:05,  2.55it/s][A[2025-02-04 03:33:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 3124/3290, eval_loss: 0.5020, eval_acc: 0.8659:  95%|[32m█████████▍[0m| 3125/3290 [19:24<01:05,  2.51it/s][A
step: 3125/3290, eval_loss: 0.5019, eval_acc: 0.8660:  95%|[32m█████████▍[0m| 3125/3290 [19:24<01:05,  2.51it/s][A[2025-02-04 03:33:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 3125/3290, eval_loss: 0.5019, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3126/3290 [19:24<01:05,  2.49it/s][A
step: 3126/3290, eval_loss: 0.5019, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3126/3290 [19:24<01:05,  2.49it/s][A[2025-02-04 03:33:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 3126/3290, eval_loss: 0.5019, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3127/3290 [19:25<01:06,  2.46it/s][A
step: 3127/3290, eval_loss: 0.5020, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3127/3290 [19:25<01:06,  2.46it/s][A[2025-02-04 03:33:19][slam_llm.models.slam_model][INFO] - modality encoder

step: 3127/3290, eval_loss: 0.5020, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3128/3290 [19:25<01:02,  2.60it/s][A
step: 3128/3290, eval_loss: 0.5019, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3128/3290 [19:25<01:02,  2.60it/s][A[2025-02-04 03:33:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 3128/3290, eval_loss: 0.5019, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3129/3290 [19:26<01:04,  2.50it/s][A
step: 3129/3290, eval_loss: 0.5019, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3129/3290 [19:26<01:04,  2.50it/s][A[2025-02-04 03:33:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 3129/3290, eval_loss: 0.5019, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3130/3290 [19:26<01:01,  2.60it/s][A
step: 3130/3290, eval_loss: 0.5018, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3130/3290 [19:26<01:01,  2.60it/s][A[2025-02-04 03:33:20][slam_llm.models.slam_model][INFO] - modality encoder

step: 3130/3290, eval_loss: 0.5018, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3131/3290 [19:26<01:00,  2.64it/s][A
step: 3131/3290, eval_loss: 0.5018, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3131/3290 [19:26<01:00,  2.64it/s][A[2025-02-04 03:33:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 3131/3290, eval_loss: 0.5018, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3132/3290 [19:27<01:06,  2.37it/s][A
step: 3132/3290, eval_loss: 0.5017, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3132/3290 [19:27<01:06,  2.37it/s][A[2025-02-04 03:33:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 3132/3290, eval_loss: 0.5017, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3133/3290 [19:27<01:04,  2.44it/s][A
step: 3133/3290, eval_loss: 0.5017, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3133/3290 [19:27<01:04,  2.44it/s][A[2025-02-04 03:33:21][slam_llm.models.slam_model][INFO] - modality encoder

step: 3133/3290, eval_loss: 0.5017, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3134/3290 [19:28<01:01,  2.54it/s][A
step: 3134/3290, eval_loss: 0.5016, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3134/3290 [19:28<01:01,  2.54it/s][A[2025-02-04 03:33:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 3134/3290, eval_loss: 0.5016, eval_acc: 0.8660:  95%|[32m█████████▌[0m| 3135/3290 [19:28<00:59,  2.62it/s][A
step: 3135/3290, eval_loss: 0.5015, eval_acc: 0.8661:  95%|[32m█████████▌[0m| 3135/3290 [19:28<00:59,  2.62it/s][A[2025-02-04 03:33:22][slam_llm.models.slam_model][INFO] - modality encoder

step: 3135/3290, eval_loss: 0.5015, eval_acc: 0.8661:  95%|[32m█████████▌[0m| 3136/3290 [19:28<01:00,  2.53it/s][A
step: 3136/3290, eval_loss: 0.5014, eval_acc: 0.8661:  95%|[32m█████████▌[0m| 3136/3290 [19:28<01:00,  2.53it/s][A[2025-02-04 03:33:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 3136/3290, eval_loss: 0.5014, eval_acc: 0.8661:  95%|[32m█████████▌[0m| 3137/3290 [19:29<00:57,  2.65it/s][A
step: 3137/3290, eval_loss: 0.5013, eval_acc: 0.8661:  95%|[32m█████████▌[0m| 3137/3290 [19:29<00:57,  2.65it/s][A[2025-02-04 03:33:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 3137/3290, eval_loss: 0.5013, eval_acc: 0.8661:  95%|[32m█████████▌[0m| 3138/3290 [19:29<00:52,  2.89it/s][A
step: 3138/3290, eval_loss: 0.5011, eval_acc: 0.8662:  95%|[32m█████████▌[0m| 3138/3290 [19:29<00:52,  2.89it/s][A[2025-02-04 03:33:23][slam_llm.models.slam_model][INFO] - modality encoder

step: 3138/3290, eval_loss: 0.5011, eval_acc: 0.8662:  95%|[32m█████████▌[0m| 3139/3290 [19:29<00:53,  2.82it/s][A
step: 3139/3290, eval_loss: 0.5010, eval_acc: 0.8662:  95%|[32m█████████▌[0m| 3139/3290 [19:29<00:53,  2.82it/s][A[2025-02-04 03:33:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 3139/3290, eval_loss: 0.5010, eval_acc: 0.8662:  95%|[32m█████████▌[0m| 3140/3290 [19:30<00:58,  2.58it/s][A
step: 3140/3290, eval_loss: 0.5009, eval_acc: 0.8662:  95%|[32m█████████▌[0m| 3140/3290 [19:30<00:58,  2.58it/s][A[2025-02-04 03:33:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 3140/3290, eval_loss: 0.5009, eval_acc: 0.8662:  95%|[32m█████████▌[0m| 3141/3290 [19:30<00:57,  2.59it/s][A
step: 3141/3290, eval_loss: 0.5008, eval_acc: 0.8662:  95%|[32m█████████▌[0m| 3141/3290 [19:30<00:57,  2.59it/s][A[2025-02-04 03:33:24][slam_llm.models.slam_model][INFO] - modality encoder

step: 3141/3290, eval_loss: 0.5008, eval_acc: 0.8662:  96%|[32m█████████▌[0m| 3142/3290 [19:31<00:55,  2.67it/s][A
step: 3142/3290, eval_loss: 0.5007, eval_acc: 0.8663:  96%|[32m█████████▌[0m| 3142/3290 [19:31<00:55,  2.67it/s][A[2025-02-04 03:33:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 3142/3290, eval_loss: 0.5007, eval_acc: 0.8663:  96%|[32m█████████▌[0m| 3143/3290 [19:31<00:57,  2.56it/s][A
step: 3143/3290, eval_loss: 0.5007, eval_acc: 0.8663:  96%|[32m█████████▌[0m| 3143/3290 [19:31<00:57,  2.56it/s][A[2025-02-04 03:33:25][slam_llm.models.slam_model][INFO] - modality encoder

step: 3143/3290, eval_loss: 0.5007, eval_acc: 0.8663:  96%|[32m█████████▌[0m| 3144/3290 [19:31<00:55,  2.63it/s][A
step: 3144/3290, eval_loss: 0.5005, eval_acc: 0.8663:  96%|[32m█████████▌[0m| 3144/3290 [19:31<00:55,  2.63it/s][A[2025-02-04 03:33:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 3144/3290, eval_loss: 0.5005, eval_acc: 0.8663:  96%|[32m█████████▌[0m| 3145/3290 [19:32<00:51,  2.81it/s][A
step: 3145/3290, eval_loss: 0.5004, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3145/3290 [19:32<00:51,  2.81it/s][A[2025-02-04 03:33:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 3145/3290, eval_loss: 0.5004, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3146/3290 [19:32<00:51,  2.78it/s][A
step: 3146/3290, eval_loss: 0.5003, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3146/3290 [19:32<00:51,  2.78it/s][A[2025-02-04 03:33:26][slam_llm.models.slam_model][INFO] - modality encoder

step: 3146/3290, eval_loss: 0.5003, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3147/3290 [19:32<00:52,  2.70it/s][A
step: 3147/3290, eval_loss: 0.5002, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3147/3290 [19:32<00:52,  2.70it/s][A[2025-02-04 03:33:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 3147/3290, eval_loss: 0.5002, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3148/3290 [19:33<00:51,  2.76it/s][A
step: 3148/3290, eval_loss: 0.5002, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3148/3290 [19:33<00:51,  2.76it/s][A[2025-02-04 03:33:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 3148/3290, eval_loss: 0.5002, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3149/3290 [19:33<00:48,  2.92it/s][A
step: 3149/3290, eval_loss: 0.5001, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3149/3290 [19:33<00:48,  2.92it/s][A[2025-02-04 03:33:27][slam_llm.models.slam_model][INFO] - modality encoder

step: 3149/3290, eval_loss: 0.5001, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3150/3290 [19:33<00:46,  3.04it/s][A
step: 3150/3290, eval_loss: 0.5000, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3150/3290 [19:33<00:46,  3.04it/s][A[2025-02-04 03:33:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 3150/3290, eval_loss: 0.5000, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3151/3290 [19:34<00:46,  2.97it/s][A
step: 3151/3290, eval_loss: 0.5000, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3151/3290 [19:34<00:46,  2.97it/s][A[2025-02-04 03:33:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 3151/3290, eval_loss: 0.5000, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3152/3290 [19:34<00:47,  2.88it/s][A
step: 3152/3290, eval_loss: 0.5000, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3152/3290 [19:34<00:47,  2.88it/s][A[2025-02-04 03:33:28][slam_llm.models.slam_model][INFO] - modality encoder

step: 3152/3290, eval_loss: 0.5000, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3153/3290 [19:35<00:53,  2.58it/s][A
step: 3153/3290, eval_loss: 0.5000, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3153/3290 [19:35<00:53,  2.58it/s][A[2025-02-04 03:33:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 3153/3290, eval_loss: 0.5000, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3154/3290 [19:35<00:50,  2.71it/s][A
step: 3154/3290, eval_loss: 0.5000, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3154/3290 [19:35<00:50,  2.71it/s][A[2025-02-04 03:33:29][slam_llm.models.slam_model][INFO] - modality encoder

step: 3154/3290, eval_loss: 0.5000, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3155/3290 [19:35<00:50,  2.68it/s][A
step: 3155/3290, eval_loss: 0.5002, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3155/3290 [19:35<00:50,  2.68it/s][A[2025-02-04 03:33:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 3155/3290, eval_loss: 0.5002, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3156/3290 [19:36<00:51,  2.59it/s][A
step: 3156/3290, eval_loss: 0.5002, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3156/3290 [19:36<00:51,  2.59it/s][A[2025-02-04 03:33:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 3156/3290, eval_loss: 0.5002, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3157/3290 [19:36<00:56,  2.34it/s][A
step: 3157/3290, eval_loss: 0.5003, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3157/3290 [19:36<00:56,  2.34it/s][A[2025-02-04 03:33:30][slam_llm.models.slam_model][INFO] - modality encoder

step: 3157/3290, eval_loss: 0.5003, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3158/3290 [19:37<00:53,  2.48it/s][A
step: 3158/3290, eval_loss: 0.5003, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3158/3290 [19:37<00:53,  2.48it/s][A[2025-02-04 03:33:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 3158/3290, eval_loss: 0.5003, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3159/3290 [19:37<00:50,  2.58it/s][A
step: 3159/3290, eval_loss: 0.5002, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3159/3290 [19:37<00:50,  2.58it/s][A[2025-02-04 03:33:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 3159/3290, eval_loss: 0.5002, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3160/3290 [19:37<00:45,  2.87it/s][A
step: 3160/3290, eval_loss: 0.5001, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3160/3290 [19:37<00:45,  2.87it/s][A[2025-02-04 03:33:31][slam_llm.models.slam_model][INFO] - modality encoder

step: 3160/3290, eval_loss: 0.5001, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3161/3290 [19:38<00:46,  2.80it/s][A
step: 3161/3290, eval_loss: 0.5002, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3161/3290 [19:38<00:46,  2.80it/s][A[2025-02-04 03:33:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 3161/3290, eval_loss: 0.5002, eval_acc: 0.8664:  96%|[32m█████████▌[0m| 3162/3290 [19:38<00:44,  2.85it/s][A
step: 3162/3290, eval_loss: 0.5001, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3162/3290 [19:38<00:44,  2.85it/s][A[2025-02-04 03:33:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 3162/3290, eval_loss: 0.5001, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3163/3290 [19:38<00:46,  2.74it/s][A
step: 3163/3290, eval_loss: 0.5000, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3163/3290 [19:38<00:46,  2.74it/s][A[2025-02-04 03:33:32][slam_llm.models.slam_model][INFO] - modality encoder

step: 3163/3290, eval_loss: 0.5000, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3164/3290 [19:39<00:45,  2.76it/s][A
step: 3164/3290, eval_loss: 0.4998, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3164/3290 [19:39<00:45,  2.76it/s][A[2025-02-04 03:33:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 3164/3290, eval_loss: 0.4998, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3165/3290 [19:39<00:45,  2.75it/s][A
step: 3165/3290, eval_loss: 0.4997, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3165/3290 [19:39<00:45,  2.75it/s][A[2025-02-04 03:33:33][slam_llm.models.slam_model][INFO] - modality encoder

step: 3165/3290, eval_loss: 0.4997, eval_acc: 0.8665:  96%|[32m█████████▌[0m| 3166/3290 [19:39<00:44,  2.79it/s][A
step: 3166/3290, eval_loss: 0.4996, eval_acc: 0.8666:  96%|[32m█████████▌[0m| 3166/3290 [19:39<00:44,  2.79it/s][A[2025-02-04 03:33:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 3166/3290, eval_loss: 0.4996, eval_acc: 0.8666:  96%|[32m█████████▋[0m| 3167/3290 [19:40<00:43,  2.86it/s][A
step: 3167/3290, eval_loss: 0.4995, eval_acc: 0.8666:  96%|[32m█████████▋[0m| 3167/3290 [19:40<00:43,  2.86it/s][A[2025-02-04 03:33:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 3167/3290, eval_loss: 0.4995, eval_acc: 0.8666:  96%|[32m█████████▋[0m| 3168/3290 [19:40<00:43,  2.79it/s][A
step: 3168/3290, eval_loss: 0.4994, eval_acc: 0.8666:  96%|[32m█████████▋[0m| 3168/3290 [19:40<00:43,  2.79it/s][A[2025-02-04 03:33:34][slam_llm.models.slam_model][INFO] - modality encoder

step: 3168/3290, eval_loss: 0.4994, eval_acc: 0.8666:  96%|[32m█████████▋[0m| 3169/3290 [19:40<00:42,  2.85it/s][A
step: 3169/3290, eval_loss: 0.4993, eval_acc: 0.8667:  96%|[32m█████████▋[0m| 3169/3290 [19:40<00:42,  2.85it/s][A[2025-02-04 03:33:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 3169/3290, eval_loss: 0.4993, eval_acc: 0.8667:  96%|[32m█████████▋[0m| 3170/3290 [19:41<00:40,  2.96it/s][A
step: 3170/3290, eval_loss: 0.4992, eval_acc: 0.8667:  96%|[32m█████████▋[0m| 3170/3290 [19:41<00:40,  2.96it/s][A[2025-02-04 03:33:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 3170/3290, eval_loss: 0.4992, eval_acc: 0.8667:  96%|[32m█████████▋[0m| 3171/3290 [19:41<00:40,  2.96it/s][A
step: 3171/3290, eval_loss: 0.4991, eval_acc: 0.8667:  96%|[32m█████████▋[0m| 3171/3290 [19:41<00:40,  2.96it/s][A[2025-02-04 03:33:35][slam_llm.models.slam_model][INFO] - modality encoder

step: 3171/3290, eval_loss: 0.4991, eval_acc: 0.8667:  96%|[32m█████████▋[0m| 3172/3290 [19:41<00:41,  2.86it/s][A
step: 3172/3290, eval_loss: 0.4990, eval_acc: 0.8668:  96%|[32m█████████▋[0m| 3172/3290 [19:41<00:41,  2.86it/s][A[2025-02-04 03:33:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 3172/3290, eval_loss: 0.4990, eval_acc: 0.8668:  96%|[32m█████████▋[0m| 3173/3290 [19:42<00:41,  2.82it/s][A
step: 3173/3290, eval_loss: 0.4991, eval_acc: 0.8667:  96%|[32m█████████▋[0m| 3173/3290 [19:42<00:41,  2.82it/s][A[2025-02-04 03:33:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 3173/3290, eval_loss: 0.4991, eval_acc: 0.8667:  96%|[32m█████████▋[0m| 3174/3290 [19:42<00:41,  2.82it/s][A
step: 3174/3290, eval_loss: 0.4990, eval_acc: 0.8668:  96%|[32m█████████▋[0m| 3174/3290 [19:42<00:41,  2.82it/s][A[2025-02-04 03:33:36][slam_llm.models.slam_model][INFO] - modality encoder

step: 3174/3290, eval_loss: 0.4990, eval_acc: 0.8668:  97%|[32m█████████▋[0m| 3175/3290 [19:43<00:42,  2.68it/s][A
step: 3175/3290, eval_loss: 0.4989, eval_acc: 0.8668:  97%|[32m█████████▋[0m| 3175/3290 [19:43<00:42,  2.68it/s][A[2025-02-04 03:33:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 3175/3290, eval_loss: 0.4989, eval_acc: 0.8668:  97%|[32m█████████▋[0m| 3176/3290 [19:43<00:44,  2.59it/s][A
step: 3176/3290, eval_loss: 0.4989, eval_acc: 0.8668:  97%|[32m█████████▋[0m| 3176/3290 [19:43<00:44,  2.59it/s][A[2025-02-04 03:33:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 3176/3290, eval_loss: 0.4989, eval_acc: 0.8668:  97%|[32m█████████▋[0m| 3177/3290 [19:43<00:40,  2.80it/s][A
step: 3177/3290, eval_loss: 0.4988, eval_acc: 0.8668:  97%|[32m█████████▋[0m| 3177/3290 [19:43<00:40,  2.80it/s][A[2025-02-04 03:33:37][slam_llm.models.slam_model][INFO] - modality encoder

step: 3177/3290, eval_loss: 0.4988, eval_acc: 0.8668:  97%|[32m█████████▋[0m| 3178/3290 [19:44<00:38,  2.92it/s][A
step: 3178/3290, eval_loss: 0.4987, eval_acc: 0.8669:  97%|[32m█████████▋[0m| 3178/3290 [19:44<00:38,  2.92it/s][A[2025-02-04 03:33:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 3178/3290, eval_loss: 0.4987, eval_acc: 0.8669:  97%|[32m█████████▋[0m| 3179/3290 [19:44<00:40,  2.77it/s][A
step: 3179/3290, eval_loss: 0.4986, eval_acc: 0.8669:  97%|[32m█████████▋[0m| 3179/3290 [19:44<00:40,  2.77it/s][A[2025-02-04 03:33:38][slam_llm.models.slam_model][INFO] - modality encoder

step: 3179/3290, eval_loss: 0.4986, eval_acc: 0.8669:  97%|[32m█████████▋[0m| 3180/3290 [19:44<00:41,  2.68it/s][A
step: 3180/3290, eval_loss: 0.4985, eval_acc: 0.8669:  97%|[32m█████████▋[0m| 3180/3290 [19:44<00:41,  2.68it/s][A[2025-02-04 03:33:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 3180/3290, eval_loss: 0.4985, eval_acc: 0.8669:  97%|[32m█████████▋[0m| 3181/3290 [19:45<00:40,  2.69it/s][A
step: 3181/3290, eval_loss: 0.4985, eval_acc: 0.8669:  97%|[32m█████████▋[0m| 3181/3290 [19:45<00:40,  2.69it/s][A[2025-02-04 03:33:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 3181/3290, eval_loss: 0.4985, eval_acc: 0.8669:  97%|[32m█████████▋[0m| 3182/3290 [19:45<00:39,  2.76it/s][A
step: 3182/3290, eval_loss: 0.4984, eval_acc: 0.8669:  97%|[32m█████████▋[0m| 3182/3290 [19:45<00:39,  2.76it/s][A[2025-02-04 03:33:39][slam_llm.models.slam_model][INFO] - modality encoder

step: 3182/3290, eval_loss: 0.4984, eval_acc: 0.8669:  97%|[32m█████████▋[0m| 3183/3290 [19:45<00:37,  2.82it/s][A
step: 3183/3290, eval_loss: 0.4983, eval_acc: 0.8669:  97%|[32m█████████▋[0m| 3183/3290 [19:45<00:37,  2.82it/s][A[2025-02-04 03:33:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 3183/3290, eval_loss: 0.4983, eval_acc: 0.8669:  97%|[32m█████████▋[0m| 3184/3290 [19:46<00:35,  3.00it/s][A
step: 3184/3290, eval_loss: 0.4983, eval_acc: 0.8670:  97%|[32m█████████▋[0m| 3184/3290 [19:46<00:35,  3.00it/s][A[2025-02-04 03:33:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 3184/3290, eval_loss: 0.4983, eval_acc: 0.8670:  97%|[32m█████████▋[0m| 3185/3290 [19:46<00:34,  3.07it/s][A
step: 3185/3290, eval_loss: 0.4982, eval_acc: 0.8670:  97%|[32m█████████▋[0m| 3185/3290 [19:46<00:34,  3.07it/s][A[2025-02-04 03:33:40][slam_llm.models.slam_model][INFO] - modality encoder

step: 3185/3290, eval_loss: 0.4982, eval_acc: 0.8670:  97%|[32m█████████▋[0m| 3186/3290 [19:46<00:34,  3.01it/s][A
step: 3186/3290, eval_loss: 0.4981, eval_acc: 0.8670:  97%|[32m█████████▋[0m| 3186/3290 [19:46<00:34,  3.01it/s][A[2025-02-04 03:33:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 3186/3290, eval_loss: 0.4981, eval_acc: 0.8670:  97%|[32m█████████▋[0m| 3187/3290 [19:47<00:34,  3.03it/s][A
step: 3187/3290, eval_loss: 0.4981, eval_acc: 0.8670:  97%|[32m█████████▋[0m| 3187/3290 [19:47<00:34,  3.03it/s][A[2025-02-04 03:33:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 3187/3290, eval_loss: 0.4981, eval_acc: 0.8670:  97%|[32m█████████▋[0m| 3188/3290 [19:47<00:37,  2.73it/s][A
step: 3188/3290, eval_loss: 0.4980, eval_acc: 0.8670:  97%|[32m█████████▋[0m| 3188/3290 [19:47<00:37,  2.73it/s][A[2025-02-04 03:33:41][slam_llm.models.slam_model][INFO] - modality encoder

step: 3188/3290, eval_loss: 0.4980, eval_acc: 0.8670:  97%|[32m█████████▋[0m| 3189/3290 [19:48<00:38,  2.63it/s][A
step: 3189/3290, eval_loss: 0.4980, eval_acc: 0.8671:  97%|[32m█████████▋[0m| 3189/3290 [19:48<00:38,  2.63it/s][A[2025-02-04 03:33:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 3189/3290, eval_loss: 0.4980, eval_acc: 0.8671:  97%|[32m█████████▋[0m| 3190/3290 [19:48<00:36,  2.73it/s][A
step: 3190/3290, eval_loss: 0.4980, eval_acc: 0.8671:  97%|[32m█████████▋[0m| 3190/3290 [19:48<00:36,  2.73it/s][A[2025-02-04 03:33:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 3190/3290, eval_loss: 0.4980, eval_acc: 0.8671:  97%|[32m█████████▋[0m| 3191/3290 [19:48<00:37,  2.62it/s][A
step: 3191/3290, eval_loss: 0.4980, eval_acc: 0.8671:  97%|[32m█████████▋[0m| 3191/3290 [19:48<00:37,  2.62it/s][A[2025-02-04 03:33:42][slam_llm.models.slam_model][INFO] - modality encoder

step: 3191/3290, eval_loss: 0.4980, eval_acc: 0.8671:  97%|[32m█████████▋[0m| 3192/3290 [19:49<00:37,  2.63it/s][A
step: 3192/3290, eval_loss: 0.4979, eval_acc: 0.8671:  97%|[32m█████████▋[0m| 3192/3290 [19:49<00:37,  2.63it/s][A[2025-02-04 03:33:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 3192/3290, eval_loss: 0.4979, eval_acc: 0.8671:  97%|[32m█████████▋[0m| 3193/3290 [19:49<00:37,  2.57it/s][A
step: 3193/3290, eval_loss: 0.4978, eval_acc: 0.8671:  97%|[32m█████████▋[0m| 3193/3290 [19:49<00:37,  2.57it/s][A[2025-02-04 03:33:43][slam_llm.models.slam_model][INFO] - modality encoder

step: 3193/3290, eval_loss: 0.4978, eval_acc: 0.8671:  97%|[32m█████████▋[0m| 3194/3290 [19:49<00:35,  2.67it/s][A
step: 3194/3290, eval_loss: 0.4978, eval_acc: 0.8671:  97%|[32m█████████▋[0m| 3194/3290 [19:49<00:35,  2.67it/s][A[2025-02-04 03:33:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 3194/3290, eval_loss: 0.4978, eval_acc: 0.8671:  97%|[32m█████████▋[0m| 3195/3290 [19:50<00:34,  2.74it/s][A
step: 3195/3290, eval_loss: 0.4976, eval_acc: 0.8672:  97%|[32m█████████▋[0m| 3195/3290 [19:50<00:34,  2.74it/s][A[2025-02-04 03:33:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 3195/3290, eval_loss: 0.4976, eval_acc: 0.8672:  97%|[32m█████████▋[0m| 3196/3290 [19:50<00:33,  2.84it/s][A
step: 3196/3290, eval_loss: 0.4976, eval_acc: 0.8672:  97%|[32m█████████▋[0m| 3196/3290 [19:50<00:33,  2.84it/s][A[2025-02-04 03:33:44][slam_llm.models.slam_model][INFO] - modality encoder

step: 3196/3290, eval_loss: 0.4976, eval_acc: 0.8672:  97%|[32m█████████▋[0m| 3197/3290 [19:51<00:35,  2.66it/s][A
step: 3197/3290, eval_loss: 0.4975, eval_acc: 0.8672:  97%|[32m█████████▋[0m| 3197/3290 [19:51<00:35,  2.66it/s][A[2025-02-04 03:33:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 3197/3290, eval_loss: 0.4975, eval_acc: 0.8672:  97%|[32m█████████▋[0m| 3198/3290 [19:51<00:35,  2.61it/s][A
step: 3198/3290, eval_loss: 0.4974, eval_acc: 0.8672:  97%|[32m█████████▋[0m| 3198/3290 [19:51<00:35,  2.61it/s][A[2025-02-04 03:33:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 3198/3290, eval_loss: 0.4974, eval_acc: 0.8672:  97%|[32m█████████▋[0m| 3199/3290 [19:51<00:32,  2.78it/s][A
step: 3199/3290, eval_loss: 0.4974, eval_acc: 0.8672:  97%|[32m█████████▋[0m| 3199/3290 [19:51<00:32,  2.78it/s][A[2025-02-04 03:33:45][slam_llm.models.slam_model][INFO] - modality encoder

step: 3199/3290, eval_loss: 0.4974, eval_acc: 0.8672:  97%|[32m█████████▋[0m| 3200/3290 [19:52<00:30,  2.97it/s][A
step: 3200/3290, eval_loss: 0.4973, eval_acc: 0.8672:  97%|[32m█████████▋[0m| 3200/3290 [19:52<00:30,  2.97it/s][A[2025-02-04 03:33:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 3200/3290, eval_loss: 0.4973, eval_acc: 0.8672:  97%|[32m█████████▋[0m| 3201/3290 [19:52<00:29,  3.03it/s][A
step: 3201/3290, eval_loss: 0.4973, eval_acc: 0.8673:  97%|[32m█████████▋[0m| 3201/3290 [19:52<00:29,  3.03it/s][A[2025-02-04 03:33:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 3201/3290, eval_loss: 0.4973, eval_acc: 0.8673:  97%|[32m█████████▋[0m| 3202/3290 [19:52<00:30,  2.90it/s][A
step: 3202/3290, eval_loss: 0.4972, eval_acc: 0.8673:  97%|[32m█████████▋[0m| 3202/3290 [19:52<00:30,  2.90it/s][A[2025-02-04 03:33:46][slam_llm.models.slam_model][INFO] - modality encoder

step: 3202/3290, eval_loss: 0.4972, eval_acc: 0.8673:  97%|[32m█████████▋[0m| 3203/3290 [19:53<00:32,  2.67it/s][A
step: 3203/3290, eval_loss: 0.4970, eval_acc: 0.8673:  97%|[32m█████████▋[0m| 3203/3290 [19:53<00:32,  2.67it/s][A[2025-02-04 03:33:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 3203/3290, eval_loss: 0.4970, eval_acc: 0.8673:  97%|[32m█████████▋[0m| 3204/3290 [19:53<00:31,  2.76it/s][A
step: 3204/3290, eval_loss: 0.4969, eval_acc: 0.8673:  97%|[32m█████████▋[0m| 3204/3290 [19:53<00:31,  2.76it/s][A[2025-02-04 03:33:47][slam_llm.models.slam_model][INFO] - modality encoder

step: 3204/3290, eval_loss: 0.4969, eval_acc: 0.8673:  97%|[32m█████████▋[0m| 3205/3290 [19:53<00:30,  2.79it/s][A
step: 3205/3290, eval_loss: 0.4969, eval_acc: 0.8674:  97%|[32m█████████▋[0m| 3205/3290 [19:53<00:30,  2.79it/s][A[2025-02-04 03:33:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 3205/3290, eval_loss: 0.4969, eval_acc: 0.8674:  97%|[32m█████████▋[0m| 3206/3290 [19:54<00:31,  2.71it/s][A
step: 3206/3290, eval_loss: 0.4968, eval_acc: 0.8674:  97%|[32m█████████▋[0m| 3206/3290 [19:54<00:31,  2.71it/s][A[2025-02-04 03:33:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 3206/3290, eval_loss: 0.4968, eval_acc: 0.8674:  97%|[32m█████████▋[0m| 3207/3290 [19:54<00:30,  2.68it/s][A
step: 3207/3290, eval_loss: 0.4967, eval_acc: 0.8674:  97%|[32m█████████▋[0m| 3207/3290 [19:54<00:30,  2.68it/s][A[2025-02-04 03:33:48][slam_llm.models.slam_model][INFO] - modality encoder

step: 3207/3290, eval_loss: 0.4967, eval_acc: 0.8674:  98%|[32m█████████▊[0m| 3208/3290 [19:55<00:31,  2.64it/s][A
step: 3208/3290, eval_loss: 0.4965, eval_acc: 0.8674:  98%|[32m█████████▊[0m| 3208/3290 [19:55<00:31,  2.64it/s][A[2025-02-04 03:33:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 3208/3290, eval_loss: 0.4965, eval_acc: 0.8674:  98%|[32m█████████▊[0m| 3209/3290 [19:55<00:32,  2.47it/s][A
step: 3209/3290, eval_loss: 0.4965, eval_acc: 0.8675:  98%|[32m█████████▊[0m| 3209/3290 [19:55<00:32,  2.47it/s][A[2025-02-04 03:33:49][slam_llm.models.slam_model][INFO] - modality encoder

step: 3209/3290, eval_loss: 0.4965, eval_acc: 0.8675:  98%|[32m█████████▊[0m| 3210/3290 [19:55<00:31,  2.58it/s][A
step: 3210/3290, eval_loss: 0.4964, eval_acc: 0.8675:  98%|[32m█████████▊[0m| 3210/3290 [19:55<00:31,  2.58it/s][A[2025-02-04 03:33:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 3210/3290, eval_loss: 0.4964, eval_acc: 0.8675:  98%|[32m█████████▊[0m| 3211/3290 [19:56<00:34,  2.30it/s][A
step: 3211/3290, eval_loss: 0.4963, eval_acc: 0.8675:  98%|[32m█████████▊[0m| 3211/3290 [19:56<00:34,  2.30it/s][A[2025-02-04 03:33:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 3211/3290, eval_loss: 0.4963, eval_acc: 0.8675:  98%|[32m█████████▊[0m| 3212/3290 [19:56<00:31,  2.51it/s][A
step: 3212/3290, eval_loss: 0.4962, eval_acc: 0.8676:  98%|[32m█████████▊[0m| 3212/3290 [19:56<00:31,  2.51it/s][A[2025-02-04 03:33:50][slam_llm.models.slam_model][INFO] - modality encoder

step: 3212/3290, eval_loss: 0.4962, eval_acc: 0.8676:  98%|[32m█████████▊[0m| 3213/3290 [19:56<00:27,  2.79it/s][A
step: 3213/3290, eval_loss: 0.4961, eval_acc: 0.8676:  98%|[32m█████████▊[0m| 3213/3290 [19:56<00:27,  2.79it/s][A[2025-02-04 03:33:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 3213/3290, eval_loss: 0.4961, eval_acc: 0.8676:  98%|[32m█████████▊[0m| 3214/3290 [19:57<00:28,  2.64it/s][A
step: 3214/3290, eval_loss: 0.4960, eval_acc: 0.8676:  98%|[32m█████████▊[0m| 3214/3290 [19:57<00:28,  2.64it/s][A[2025-02-04 03:33:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 3214/3290, eval_loss: 0.4960, eval_acc: 0.8676:  98%|[32m█████████▊[0m| 3215/3290 [19:57<00:27,  2.71it/s][A
step: 3215/3290, eval_loss: 0.4960, eval_acc: 0.8676:  98%|[32m█████████▊[0m| 3215/3290 [19:57<00:27,  2.71it/s][A[2025-02-04 03:33:51][slam_llm.models.slam_model][INFO] - modality encoder

step: 3215/3290, eval_loss: 0.4960, eval_acc: 0.8676:  98%|[32m█████████▊[0m| 3216/3290 [19:58<00:28,  2.63it/s][A
step: 3216/3290, eval_loss: 0.4959, eval_acc: 0.8676:  98%|[32m█████████▊[0m| 3216/3290 [19:58<00:28,  2.63it/s][A[2025-02-04 03:33:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 3216/3290, eval_loss: 0.4959, eval_acc: 0.8676:  98%|[32m█████████▊[0m| 3217/3290 [19:58<00:29,  2.48it/s][A
step: 3217/3290, eval_loss: 0.4957, eval_acc: 0.8677:  98%|[32m█████████▊[0m| 3217/3290 [19:58<00:29,  2.48it/s][A[2025-02-04 03:33:52][slam_llm.models.slam_model][INFO] - modality encoder

step: 3217/3290, eval_loss: 0.4957, eval_acc: 0.8677:  98%|[32m█████████▊[0m| 3218/3290 [19:59<00:29,  2.46it/s][A
step: 3218/3290, eval_loss: 0.4957, eval_acc: 0.8677:  98%|[32m█████████▊[0m| 3218/3290 [19:59<00:29,  2.46it/s][A[2025-02-04 03:33:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 3218/3290, eval_loss: 0.4957, eval_acc: 0.8677:  98%|[32m█████████▊[0m| 3219/3290 [19:59<00:28,  2.47it/s][A
step: 3219/3290, eval_loss: 0.4955, eval_acc: 0.8677:  98%|[32m█████████▊[0m| 3219/3290 [19:59<00:28,  2.47it/s][A[2025-02-04 03:33:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 3219/3290, eval_loss: 0.4955, eval_acc: 0.8677:  98%|[32m█████████▊[0m| 3220/3290 [19:59<00:26,  2.63it/s][A
step: 3220/3290, eval_loss: 0.4954, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3220/3290 [19:59<00:26,  2.63it/s][A[2025-02-04 03:33:53][slam_llm.models.slam_model][INFO] - modality encoder

step: 3220/3290, eval_loss: 0.4954, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3221/3290 [20:00<00:25,  2.68it/s][A
step: 3221/3290, eval_loss: 0.4953, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3221/3290 [20:00<00:25,  2.68it/s][A[2025-02-04 03:33:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 3221/3290, eval_loss: 0.4953, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3222/3290 [20:00<00:25,  2.71it/s][A
step: 3222/3290, eval_loss: 0.4953, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3222/3290 [20:00<00:25,  2.71it/s][A[2025-02-04 03:33:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 3222/3290, eval_loss: 0.4953, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3223/3290 [20:00<00:25,  2.62it/s][A
step: 3223/3290, eval_loss: 0.4952, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3223/3290 [20:00<00:25,  2.62it/s][A[2025-02-04 03:33:54][slam_llm.models.slam_model][INFO] - modality encoder

step: 3223/3290, eval_loss: 0.4952, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3224/3290 [20:01<00:23,  2.83it/s][A
step: 3224/3290, eval_loss: 0.4952, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3224/3290 [20:01<00:23,  2.83it/s][A[2025-02-04 03:33:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 3224/3290, eval_loss: 0.4952, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3225/3290 [20:01<00:24,  2.67it/s][A
step: 3225/3290, eval_loss: 0.4952, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3225/3290 [20:01<00:24,  2.67it/s][A[2025-02-04 03:33:55][slam_llm.models.slam_model][INFO] - modality encoder

step: 3225/3290, eval_loss: 0.4952, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3226/3290 [20:01<00:23,  2.77it/s][A
step: 3226/3290, eval_loss: 0.4951, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3226/3290 [20:01<00:23,  2.77it/s][A[2025-02-04 03:33:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 3226/3290, eval_loss: 0.4951, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3227/3290 [20:02<00:21,  2.88it/s][A
step: 3227/3290, eval_loss: 0.4951, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3227/3290 [20:02<00:21,  2.88it/s][A[2025-02-04 03:33:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 3227/3290, eval_loss: 0.4951, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3228/3290 [20:02<00:20,  3.07it/s][A
step: 3228/3290, eval_loss: 0.4952, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3228/3290 [20:02<00:20,  3.07it/s][A[2025-02-04 03:33:56][slam_llm.models.slam_model][INFO] - modality encoder

step: 3228/3290, eval_loss: 0.4952, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3229/3290 [20:02<00:20,  2.92it/s][A
step: 3229/3290, eval_loss: 0.4951, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3229/3290 [20:02<00:20,  2.92it/s][A[2025-02-04 03:33:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 3229/3290, eval_loss: 0.4951, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3230/3290 [20:03<00:20,  2.92it/s][A
step: 3230/3290, eval_loss: 0.4951, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3230/3290 [20:03<00:20,  2.92it/s][A[2025-02-04 03:33:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 3230/3290, eval_loss: 0.4951, eval_acc: 0.8678:  98%|[32m█████████▊[0m| 3231/3290 [20:03<00:19,  2.96it/s][A
step: 3231/3290, eval_loss: 0.4951, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3231/3290 [20:03<00:19,  2.96it/s][A[2025-02-04 03:33:57][slam_llm.models.slam_model][INFO] - modality encoder

step: 3231/3290, eval_loss: 0.4951, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3232/3290 [20:03<00:20,  2.89it/s][A
step: 3232/3290, eval_loss: 0.4951, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3232/3290 [20:03<00:20,  2.89it/s][A[2025-02-04 03:33:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 3232/3290, eval_loss: 0.4951, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3233/3290 [20:04<00:18,  3.06it/s][A
step: 3233/3290, eval_loss: 0.4950, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3233/3290 [20:04<00:18,  3.06it/s][A[2025-02-04 03:33:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 3233/3290, eval_loss: 0.4950, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3234/3290 [20:04<00:17,  3.15it/s][A
step: 3234/3290, eval_loss: 0.4951, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3234/3290 [20:04<00:17,  3.15it/s][A[2025-02-04 03:33:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 3234/3290, eval_loss: 0.4951, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3235/3290 [20:04<00:17,  3.15it/s][A
step: 3235/3290, eval_loss: 0.4950, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3235/3290 [20:04<00:17,  3.15it/s][A[2025-02-04 03:33:58][slam_llm.models.slam_model][INFO] - modality encoder

step: 3235/3290, eval_loss: 0.4950, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3236/3290 [20:05<00:16,  3.21it/s][A
step: 3236/3290, eval_loss: 0.4950, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3236/3290 [20:05<00:16,  3.21it/s][A[2025-02-04 03:33:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 3236/3290, eval_loss: 0.4950, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3237/3290 [20:05<00:17,  3.04it/s][A
step: 3237/3290, eval_loss: 0.4950, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3237/3290 [20:05<00:17,  3.04it/s][A[2025-02-04 03:33:59][slam_llm.models.slam_model][INFO] - modality encoder

step: 3237/3290, eval_loss: 0.4950, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3238/3290 [20:05<00:17,  2.97it/s][A
step: 3238/3290, eval_loss: 0.4950, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3238/3290 [20:05<00:17,  2.97it/s][A[2025-02-04 03:34:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 3238/3290, eval_loss: 0.4950, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3239/3290 [20:06<00:18,  2.74it/s][A
step: 3239/3290, eval_loss: 0.4950, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3239/3290 [20:06<00:18,  2.74it/s][A[2025-02-04 03:34:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 3239/3290, eval_loss: 0.4950, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3240/3290 [20:06<00:19,  2.55it/s][A
step: 3240/3290, eval_loss: 0.4951, eval_acc: 0.8679:  98%|[32m█████████▊[0m| 3240/3290 [20:06<00:19,  2.55it/s][A[2025-02-04 03:34:00][slam_llm.models.slam_model][INFO] - modality encoder

step: 3240/3290, eval_loss: 0.4951, eval_acc: 0.8679:  99%|[32m█████████▊[0m| 3241/3290 [20:07<00:20,  2.43it/s][A
step: 3241/3290, eval_loss: 0.4950, eval_acc: 0.8679:  99%|[32m█████████▊[0m| 3241/3290 [20:07<00:20,  2.43it/s][A[2025-02-04 03:34:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 3241/3290, eval_loss: 0.4950, eval_acc: 0.8679:  99%|[32m█████████▊[0m| 3242/3290 [20:07<00:18,  2.66it/s][A
step: 3242/3290, eval_loss: 0.4950, eval_acc: 0.8679:  99%|[32m█████████▊[0m| 3242/3290 [20:07<00:18,  2.66it/s][A[2025-02-04 03:34:01][slam_llm.models.slam_model][INFO] - modality encoder

step: 3242/3290, eval_loss: 0.4950, eval_acc: 0.8679:  99%|[32m█████████▊[0m| 3243/3290 [20:07<00:18,  2.48it/s][A
step: 3243/3290, eval_loss: 0.4949, eval_acc: 0.8679:  99%|[32m█████████▊[0m| 3243/3290 [20:07<00:18,  2.48it/s][A[2025-02-04 03:34:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 3243/3290, eval_loss: 0.4949, eval_acc: 0.8679:  99%|[32m█████████▊[0m| 3244/3290 [20:08<00:18,  2.44it/s][A
step: 3244/3290, eval_loss: 0.4949, eval_acc: 0.8680:  99%|[32m█████████▊[0m| 3244/3290 [20:08<00:18,  2.44it/s][A[2025-02-04 03:34:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 3244/3290, eval_loss: 0.4949, eval_acc: 0.8680:  99%|[32m█████████▊[0m| 3245/3290 [20:08<00:18,  2.47it/s][A
step: 3245/3290, eval_loss: 0.4948, eval_acc: 0.8679:  99%|[32m█████████▊[0m| 3245/3290 [20:08<00:18,  2.47it/s][A[2025-02-04 03:34:02][slam_llm.models.slam_model][INFO] - modality encoder

step: 3245/3290, eval_loss: 0.4948, eval_acc: 0.8679:  99%|[32m█████████▊[0m| 3246/3290 [20:09<00:17,  2.51it/s][A
step: 3246/3290, eval_loss: 0.4948, eval_acc: 0.8680:  99%|[32m█████████▊[0m| 3246/3290 [20:09<00:17,  2.51it/s][A[2025-02-04 03:34:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 3246/3290, eval_loss: 0.4948, eval_acc: 0.8680:  99%|[32m█████████▊[0m| 3247/3290 [20:09<00:16,  2.57it/s][A
step: 3247/3290, eval_loss: 0.4947, eval_acc: 0.8680:  99%|[32m█████████▊[0m| 3247/3290 [20:09<00:16,  2.57it/s][A[2025-02-04 03:34:03][slam_llm.models.slam_model][INFO] - modality encoder

step: 3247/3290, eval_loss: 0.4947, eval_acc: 0.8680:  99%|[32m█████████▊[0m| 3248/3290 [20:09<00:15,  2.70it/s][A
step: 3248/3290, eval_loss: 0.4947, eval_acc: 0.8680:  99%|[32m█████████▊[0m| 3248/3290 [20:09<00:15,  2.70it/s][A[2025-02-04 03:34:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 3248/3290, eval_loss: 0.4947, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3249/3290 [20:10<00:15,  2.63it/s][A
step: 3249/3290, eval_loss: 0.4947, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3249/3290 [20:10<00:15,  2.63it/s][A[2025-02-04 03:34:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 3249/3290, eval_loss: 0.4947, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3250/3290 [20:10<00:14,  2.70it/s][A
step: 3250/3290, eval_loss: 0.4947, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3250/3290 [20:10<00:14,  2.70it/s][A[2025-02-04 03:34:04][slam_llm.models.slam_model][INFO] - modality encoder

step: 3250/3290, eval_loss: 0.4947, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3251/3290 [20:10<00:13,  2.80it/s][A
step: 3251/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3251/3290 [20:10<00:13,  2.80it/s][A[2025-02-04 03:34:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 3251/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3252/3290 [20:11<00:13,  2.89it/s][A
step: 3252/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3252/3290 [20:11<00:13,  2.89it/s][A[2025-02-04 03:34:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 3252/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3253/3290 [20:11<00:12,  3.01it/s][A
step: 3253/3290, eval_loss: 0.4947, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3253/3290 [20:11<00:12,  3.01it/s][A[2025-02-04 03:34:05][slam_llm.models.slam_model][INFO] - modality encoder

step: 3253/3290, eval_loss: 0.4947, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3254/3290 [20:11<00:12,  2.87it/s][A
step: 3254/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3254/3290 [20:11<00:12,  2.87it/s][A[2025-02-04 03:34:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 3254/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3255/3290 [20:12<00:11,  2.96it/s][A
step: 3255/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3255/3290 [20:12<00:11,  2.96it/s][A[2025-02-04 03:34:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 3255/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3256/3290 [20:12<00:11,  2.97it/s][A
step: 3256/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3256/3290 [20:12<00:11,  2.97it/s][A[2025-02-04 03:34:06][slam_llm.models.slam_model][INFO] - modality encoder

step: 3256/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3257/3290 [20:12<00:10,  3.13it/s][A
step: 3257/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3257/3290 [20:12<00:10,  3.13it/s][A[2025-02-04 03:34:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 3257/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3258/3290 [20:13<00:10,  2.93it/s][A
step: 3258/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3258/3290 [20:13<00:10,  2.93it/s][A[2025-02-04 03:34:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 3258/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3259/3290 [20:13<00:11,  2.64it/s][A
step: 3259/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3259/3290 [20:13<00:11,  2.64it/s][A[2025-02-04 03:34:07][slam_llm.models.slam_model][INFO] - modality encoder

step: 3259/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3260/3290 [20:14<00:11,  2.60it/s][A
step: 3260/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3260/3290 [20:14<00:11,  2.60it/s][A[2025-02-04 03:34:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 3260/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3261/3290 [20:14<00:11,  2.51it/s][A
step: 3261/3290, eval_loss: 0.4945, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3261/3290 [20:14<00:11,  2.51it/s][A[2025-02-04 03:34:08][slam_llm.models.slam_model][INFO] - modality encoder

step: 3261/3290, eval_loss: 0.4945, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3262/3290 [20:14<00:11,  2.46it/s][A
step: 3262/3290, eval_loss: 0.4944, eval_acc: 0.8681:  99%|[32m█████████▉[0m| 3262/3290 [20:14<00:11,  2.46it/s][A[2025-02-04 03:34:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 3262/3290, eval_loss: 0.4944, eval_acc: 0.8681:  99%|[32m█████████▉[0m| 3263/3290 [20:15<00:10,  2.48it/s][A
step: 3263/3290, eval_loss: 0.4944, eval_acc: 0.8681:  99%|[32m█████████▉[0m| 3263/3290 [20:15<00:10,  2.48it/s][A[2025-02-04 03:34:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 3263/3290, eval_loss: 0.4944, eval_acc: 0.8681:  99%|[32m█████████▉[0m| 3264/3290 [20:15<00:10,  2.55it/s][A
step: 3264/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3264/3290 [20:15<00:10,  2.55it/s][A[2025-02-04 03:34:09][slam_llm.models.slam_model][INFO] - modality encoder

step: 3264/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3265/3290 [20:16<00:09,  2.60it/s][A
step: 3265/3290, eval_loss: 0.4944, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3265/3290 [20:16<00:09,  2.60it/s][A[2025-02-04 03:34:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 3265/3290, eval_loss: 0.4944, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3266/3290 [20:16<00:08,  2.84it/s][A
step: 3266/3290, eval_loss: 0.4945, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3266/3290 [20:16<00:08,  2.84it/s][A[2025-02-04 03:34:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 3266/3290, eval_loss: 0.4945, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3267/3290 [20:16<00:07,  2.90it/s][A
step: 3267/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3267/3290 [20:16<00:07,  2.90it/s][A[2025-02-04 03:34:10][slam_llm.models.slam_model][INFO] - modality encoder

step: 3267/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3268/3290 [20:17<00:08,  2.66it/s][A
step: 3268/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3268/3290 [20:17<00:08,  2.66it/s][A[2025-02-04 03:34:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 3268/3290, eval_loss: 0.4946, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3269/3290 [20:17<00:07,  2.78it/s][A
step: 3269/3290, eval_loss: 0.4945, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3269/3290 [20:17<00:07,  2.78it/s][A[2025-02-04 03:34:11][slam_llm.models.slam_model][INFO] - modality encoder

step: 3269/3290, eval_loss: 0.4945, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3270/3290 [20:17<00:07,  2.85it/s][A
step: 3270/3290, eval_loss: 0.4945, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3270/3290 [20:17<00:07,  2.85it/s][A[2025-02-04 03:34:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 3270/3290, eval_loss: 0.4945, eval_acc: 0.8680:  99%|[32m█████████▉[0m| 3271/3290 [20:18<00:08,  2.37it/s][A
step: 3271/3290, eval_loss: 0.4944, eval_acc: 0.8681:  99%|[32m█████████▉[0m| 3271/3290 [20:18<00:08,  2.37it/s][A[2025-02-04 03:34:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 3271/3290, eval_loss: 0.4944, eval_acc: 0.8681:  99%|[32m█████████▉[0m| 3272/3290 [20:18<00:07,  2.45it/s][A
step: 3272/3290, eval_loss: 0.4943, eval_acc: 0.8681:  99%|[32m█████████▉[0m| 3272/3290 [20:18<00:07,  2.45it/s][A[2025-02-04 03:34:12][slam_llm.models.slam_model][INFO] - modality encoder

step: 3272/3290, eval_loss: 0.4943, eval_acc: 0.8681:  99%|[32m█████████▉[0m| 3273/3290 [20:19<00:06,  2.43it/s][A
step: 3273/3290, eval_loss: 0.4942, eval_acc: 0.8681:  99%|[32m█████████▉[0m| 3273/3290 [20:19<00:06,  2.43it/s][A[2025-02-04 03:34:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 3273/3290, eval_loss: 0.4942, eval_acc: 0.8681: 100%|[32m█████████▉[0m| 3274/3290 [20:19<00:06,  2.67it/s][A
step: 3274/3290, eval_loss: 0.4942, eval_acc: 0.8681: 100%|[32m█████████▉[0m| 3274/3290 [20:19<00:06,  2.67it/s][A[2025-02-04 03:34:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 3274/3290, eval_loss: 0.4942, eval_acc: 0.8681: 100%|[32m█████████▉[0m| 3275/3290 [20:19<00:05,  2.71it/s][A
step: 3275/3290, eval_loss: 0.4941, eval_acc: 0.8681: 100%|[32m█████████▉[0m| 3275/3290 [20:19<00:05,  2.71it/s][A[2025-02-04 03:34:13][slam_llm.models.slam_model][INFO] - modality encoder

step: 3275/3290, eval_loss: 0.4941, eval_acc: 0.8681: 100%|[32m█████████▉[0m| 3276/3290 [20:20<00:05,  2.68it/s][A
step: 3276/3290, eval_loss: 0.4940, eval_acc: 0.8681: 100%|[32m█████████▉[0m| 3276/3290 [20:20<00:05,  2.68it/s][A[2025-02-04 03:34:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 3276/3290, eval_loss: 0.4940, eval_acc: 0.8681: 100%|[32m█████████▉[0m| 3277/3290 [20:20<00:05,  2.44it/s][A
step: 3277/3290, eval_loss: 0.4940, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3277/3290 [20:20<00:05,  2.44it/s][A[2025-02-04 03:34:14][slam_llm.models.slam_model][INFO] - modality encoder

step: 3277/3290, eval_loss: 0.4940, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3278/3290 [20:21<00:04,  2.47it/s][A
step: 3278/3290, eval_loss: 0.4939, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3278/3290 [20:21<00:04,  2.47it/s][A[2025-02-04 03:34:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 3278/3290, eval_loss: 0.4939, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3279/3290 [20:21<00:04,  2.51it/s][A
step: 3279/3290, eval_loss: 0.4939, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3279/3290 [20:21<00:04,  2.51it/s][A[2025-02-04 03:34:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 3279/3290, eval_loss: 0.4939, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3280/3290 [20:21<00:03,  2.65it/s][A
step: 3280/3290, eval_loss: 0.4940, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3280/3290 [20:21<00:03,  2.65it/s][A[2025-02-04 03:34:15][slam_llm.models.slam_model][INFO] - modality encoder

step: 3280/3290, eval_loss: 0.4940, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3281/3290 [20:22<00:03,  2.78it/s][A
step: 3281/3290, eval_loss: 0.4940, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3281/3290 [20:22<00:03,  2.78it/s][A[2025-02-04 03:34:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 3281/3290, eval_loss: 0.4940, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3282/3290 [20:22<00:02,  2.95it/s][A
step: 3282/3290, eval_loss: 0.4939, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3282/3290 [20:22<00:02,  2.95it/s][A[2025-02-04 03:34:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 3282/3290, eval_loss: 0.4939, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3283/3290 [20:22<00:02,  2.82it/s][A
step: 3283/3290, eval_loss: 0.4939, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3283/3290 [20:22<00:02,  2.82it/s][A[2025-02-04 03:34:16][slam_llm.models.slam_model][INFO] - modality encoder

step: 3283/3290, eval_loss: 0.4939, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3284/3290 [20:23<00:02,  2.87it/s][A
step: 3284/3290, eval_loss: 0.4939, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3284/3290 [20:23<00:02,  2.87it/s][A[2025-02-04 03:34:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 3284/3290, eval_loss: 0.4939, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3285/3290 [20:23<00:01,  2.94it/s][A
step: 3285/3290, eval_loss: 0.4940, eval_acc: 0.8681: 100%|[32m█████████▉[0m| 3285/3290 [20:23<00:01,  2.94it/s][A[2025-02-04 03:34:17][slam_llm.models.slam_model][INFO] - modality encoder

step: 3285/3290, eval_loss: 0.4940, eval_acc: 0.8681: 100%|[32m█████████▉[0m| 3286/3290 [20:23<00:01,  2.79it/s][A
step: 3286/3290, eval_loss: 0.4939, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3286/3290 [20:23<00:01,  2.79it/s][A[2025-02-04 03:34:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 3286/3290, eval_loss: 0.4939, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3287/3290 [20:24<00:01,  2.87it/s][A
step: 3287/3290, eval_loss: 0.4938, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3287/3290 [20:24<00:01,  2.87it/s][A[2025-02-04 03:34:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 3287/3290, eval_loss: 0.4938, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3288/3290 [20:24<00:00,  3.11it/s][A
step: 3288/3290, eval_loss: 0.4938, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3288/3290 [20:24<00:00,  3.11it/s][A[2025-02-04 03:34:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 3288/3290, eval_loss: 0.4938, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3289/3290 [20:24<00:00,  3.06it/s][A
step: 3289/3290, eval_loss: 0.4938, eval_acc: 0.8682: 100%|[32m█████████▉[0m| 3289/3290 [20:24<00:00,  3.06it/s][A[2025-02-04 03:34:18][slam_llm.models.slam_model][INFO] - modality encoder

step: 3289/3290, eval_loss: 0.4938, eval_acc: 0.8682: 100%|[32m██████████[0m| 3290/3290 [20:25<00:00,  3.20it/s][A
step: 3290/3290, eval_loss: 0.4937, eval_acc: 0.8682: 100%|[32m██████████[0m| 3290/3290 [20:25<00:00,  3.20it/s][A[2025-02-04 03:34:19][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.6383, device='cuda:0') eval_epoch_loss=tensor(0.4937, device='cuda:0') eval_epoch_acc=tensor(0.8682, device='cuda:0')
step: 3290/3290, eval_loss: 0.4937, eval_acc: 0.8682: 100%|[32m██████████[0m| 3290/3290 [20:25<00:00,  2.68it/s]
[2025-02-04 03:34:19][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2025-02-04 03:34:19][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2025-02-04 03:34:20][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6/asr_epoch_2_step_23834_loss_0.4936819076538086/model.pt
[2025-02-04 03:34:20][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6 directory
[2025-02-04 03:34:20][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.4936819076538086
[2025-02-04 03:34:20][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.8682200312614441
[2025-02-04 03:34:20][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23835/23838 [57:31<18:25, 368.46s/it][2025-02-04 03:34:20][root][INFO] - Training Epoch: 2/2, step 23834/23838 completed (loss: 0.6664869785308838, acc: 0.8611111044883728)
[2025-02-04 03:34:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23836/23838 [57:31<08:36, 258.03s/it][2025-02-04 03:34:21][root][INFO] - Training Epoch: 2/2, step 23835/23838 completed (loss: 0.6046512126922607, acc: 0.824999988079071)
[2025-02-04 03:34:21][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m█████████▉[0m| 23837/23838 [57:32<03:00, 180.73s/it][2025-02-04 03:34:21][root][INFO] - Training Epoch: 2/2, step 23836/23838 completed (loss: 0.39868423342704773, acc: 0.8796296119689941)
[2025-02-04 03:34:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 100%|[34m██████████[0m| 23838/23838 [57:32<00:00, 126.74s/it][2025-02-04 03:34:22][root][INFO] - Training Epoch: 2/2, step 23837/23838 completed (loss: 0.14072369039058685, acc: 0.9411764740943909)
[2025-02-04 03:34:22][slam_llm.models.slam_model][INFO] - modality encoder
Training Epoch: 2: 23839it [57:33, 88.88s/it]                            [2025-02-04 03:34:22][root][INFO] - Training Epoch: 2/2, step 23838/23838 completed (loss: 0.20347607135772705, acc: 0.9468085169792175)
Training Epoch: 2: 23839it [57:33,  1.73it/s]
[2025-02-04 03:34:23][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=1.1025, train_epoch_loss=0.0976, epoch time 3454.4292911477387s
[2025-02-04 03:34:23][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 15 GB
[2025-02-04 03:34:23][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 20 GB
[2025-02-04 03:34:23][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 15 GB
[2025-02-04 03:34:23][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2025-02-04 03:34:23][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2025-02-04 03:34:23][root][INFO] - Key: avg_train_prep, Value: 1.102508306503296
[2025-02-04 03:34:23][root][INFO] - Key: avg_train_loss, Value: 0.09758790582418442
[2025-02-04 03:34:23][root][INFO] - Key: avg_train_acc, Value: 0.22279098629951477
[2025-02-04 03:34:23][root][INFO] - Key: avg_eval_prep, Value: 1.638337254524231
[2025-02-04 03:34:23][root][INFO] - Key: avg_eval_loss, Value: 0.4936819076538086
[2025-02-04 03:34:23][root][INFO] - Key: avg_eval_acc, Value: 0.8682200312614441
[2025-02-04 03:34:23][root][INFO] - Key: avg_epoch_time, Value: 3454.4292911477387
[2025-02-04 03:34:23][root][INFO] - Key: avg_checkpoint_time, Value: 0.400391798466444
wandb: - 0.007 MB of 0.007 MB uploadedwandb: \ 0.007 MB of 1.497 MB uploadedwandb: | 0.007 MB of 1.497 MB uploadedwandb: / 1.498 MB of 1.498 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:            train/train_epoch_acc ▁
wandb:           train/train_epoch_loss ▁
wandb:           train/train_perplexity ▁
wandb:                   train_inner/lr ▁▂▃▄▅▆██████████████████████████████████
wandb: train_inner/train_inner_accuracy ▃█▃▄▇█▆▄▇▅▃▆▇▆▅▄▃▅▄▇▆▇▆█▇▇▆▁▆▅▃▆▅▆▅▆▅▄▅▆
wandb:     train_inner/train_inner_loss ▆▂▆▅▁▁▄▆▂▄▆▂▂▃▄▇▄▆▄▁▄▃▃▁▂▁▃▇▂▃█▄▄▃▄▄▄▄▃▃
wandb:              valid/best_val_loss ▁
wandb:               valid/val_accuracy ▁
wandb:          valid/val_best_accuracy ▁
wandb:             valid/val_epoch_loss ▁
wandb:             valid/val_perplexity ▁
wandb: 
wandb: Run summary:
wandb:            train/train_epoch_acc 0.22279
wandb:           train/train_epoch_loss 0.09759
wandb:           train/train_perplexity 1.10251
wandb:                   train_inner/lr 9e-05
wandb: train_inner/train_inner_accuracy 0.825
wandb:     train_inner/train_inner_loss 0.60465
wandb:              valid/best_val_loss 0.49368
wandb:               valid/val_accuracy 0.86822
wandb:          valid/val_best_accuracy 0.86822
wandb:             valid/val_epoch_loss 0.49368
wandb:             valid/val_perplexity 1.63834
wandb: 
wandb: 🚀 View run aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6 at: https://wandb.ai/jindaz-work/SLAM-LLM/runs/wo8qxoi0
wandb: ⭐️ View project at: https://wandb.ai/jindaz-work/SLAM-LLM
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./out/log/wandb_log/wandb/run-20250204_023609-wo8qxoi0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Selected lowest loss checkpoint: asr_epoch_2_step_17875_loss_0.4531655013561249
Checkpoint file: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6/asr_epoch_2_step_17875_loss_0.4531655013561249/model.pt
ckpt_folder /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6/asr_epoch_2_step_17875_loss_0.4531655013561249
[2025-02-04 03:34:57][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False, 'save_embedding': False}
[2025-02-04 03:34:57][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2025-02-04 03:34:57][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 6, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': '', 'identifier': 'aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6'}
[2025-02-04 03:34:59][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.
  warnings.warn("torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.")
[2025-02-04 03:35:04][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-04 03:35:04][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2025-02-04 03:35:04][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2025-02-04 03:35:04][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2025-02-04 03:35:11][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-04 03:35:11][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2025-02-04 03:35:11][slam_llm.models.slam_model][INFO] - setup peft...
trainable params: 5,636,096 || all params: 1,241,450,496 || trainable%: 0.4539928106807088
[2025-02-04 03:35:11][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2025-02-04 03:35:11][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2025-02-04 03:35:11][slam_llm.utils.train_utils][INFO] - --> Module linear
[2025-02-04 03:35:11][slam_llm.utils.train_utils][INFO] - --> linear has 16.781312 Million params

[2025-02-04 03:35:11][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6/asr_epoch_2_step_17875_loss_0.4531655013561249/model.pt
[2025-02-04 03:35:11][slam_llm.utils.train_utils][INFO] - --> Model asr
[2025-02-04 03:35:11][slam_llm.utils.train_utils][INFO] - --> asr has 22.417408 Million params

[2025-02-04 03:35:13][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/aphasia_phoneme/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2025-02-04 03:35:15][root][INFO] - --> Training Set Length = 12232
[2025-02-04 03:35:15][root][INFO] - =====================================
Loaded LLM Config Path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/examples/asr_librispeech/scripts/llm_config/test_config.json
Loaded LLM Config: {'max_new_tokens': 200, 'num_beams': 4, 'do_sample': False, 'min_length': 1, 'top_p': 1.0, 'repetition_penalty': 2.0, 'length_penalty': 1.0, 'temperature': 1.0, 'no_repeat_ngram_size': 1}
  0%|          | 0/3058 [00:00<?, ?it/s]/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
[2025-02-04 03:35:17][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 1/3058 [00:03<2:35:10,  3.05s/it][2025-02-04 03:35:19][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 2/3058 [00:04<1:37:58,  1.92s/it][2025-02-04 03:35:20][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 3/3058 [00:05<1:18:11,  1.54s/it][2025-02-04 03:35:21][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 4/3058 [00:06<1:05:58,  1.30s/it][2025-02-04 03:35:22][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 5/3058 [00:07<58:16,  1.15s/it]  [2025-02-04 03:35:23][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 6/3058 [00:07<50:18,  1.01it/s][2025-02-04 03:35:23][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 7/3058 [00:08<52:53,  1.04s/it][2025-02-04 03:35:24][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 8/3058 [00:09<46:37,  1.09it/s][2025-02-04 03:35:25][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 9/3058 [00:10<49:12,  1.03it/s][2025-02-04 03:35:26][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 10/3058 [00:11<53:57,  1.06s/it][2025-02-04 03:35:28][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 11/3058 [00:13<59:49,  1.18s/it][2025-02-04 03:35:29][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 12/3058 [00:14<1:03:13,  1.25s/it][2025-02-04 03:35:31][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 13/3058 [00:15<1:02:48,  1.24s/it][2025-02-04 03:35:32][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 14/3058 [00:17<1:11:43,  1.41s/it][2025-02-04 03:35:34][slam_llm.models.slam_model][INFO] - modality encoder
  0%|          | 15/3058 [00:19<1:13:36,  1.45s/it][2025-02-04 03:35:35][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 16/3058 [00:20<1:16:08,  1.50s/it][2025-02-04 03:35:37][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 17/3058 [00:22<1:22:39,  1.63s/it][2025-02-04 03:35:39][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 18/3058 [00:24<1:19:15,  1.56s/it][2025-02-04 03:35:40][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 19/3058 [00:25<1:08:21,  1.35s/it][2025-02-04 03:35:41][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 20/3058 [00:26<1:11:05,  1.40s/it][2025-02-04 03:35:42][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 21/3058 [00:27<1:06:22,  1.31s/it][2025-02-04 03:35:43][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 22/3058 [00:29<1:09:04,  1.36s/it][2025-02-04 03:35:45][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 23/3058 [00:30<1:08:07,  1.35s/it][2025-02-04 03:35:46][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 24/3058 [00:32<1:09:43,  1.38s/it][2025-02-04 03:35:48][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 25/3058 [00:33<1:08:14,  1.35s/it][2025-02-04 03:35:49][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 26/3058 [00:35<1:15:33,  1.50s/it][2025-02-04 03:35:51][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 27/3058 [00:36<1:13:04,  1.45s/it][2025-02-04 03:35:52][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 28/3058 [00:37<1:05:13,  1.29s/it][2025-02-04 03:35:53][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 29/3058 [00:38<1:08:40,  1.36s/it][2025-02-04 03:35:55][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 30/3058 [00:40<1:12:17,  1.43s/it][2025-02-04 03:35:56][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 31/3058 [00:47<2:35:00,  3.07s/it][2025-02-04 03:36:03][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 32/3058 [00:48<2:07:55,  2.54s/it][2025-02-04 03:36:04][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 33/3058 [00:49<1:47:00,  2.12s/it][2025-02-04 03:36:05][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 34/3058 [00:51<1:41:28,  2.01s/it][2025-02-04 03:36:07][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 35/3058 [00:52<1:27:06,  1.73s/it][2025-02-04 03:36:08][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 36/3058 [00:53<1:19:45,  1.58s/it][2025-02-04 03:36:10][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 37/3058 [00:55<1:23:45,  1.66s/it][2025-02-04 03:36:11][slam_llm.models.slam_model][INFO] - modality encoder
  1%|          | 38/3058 [00:57<1:23:52,  1.67s/it][2025-02-04 03:36:13][slam_llm.models.slam_model][INFO] - modality encoder
  1%|▏         | 39/3058 [00:58<1:20:47,  1.61s/it][2025-02-04 03:36:15][slam_llm.models.slam_model][INFO] - modality encoder
  1%|▏         | 40/3058 [01:00<1:18:08,  1.55s/it][2025-02-04 03:36:16][slam_llm.models.slam_model][INFO] - modality encoder
  1%|▏         | 41/3058 [01:01<1:05:36,  1.30s/it][2025-02-04 03:36:17][slam_llm.models.slam_model][INFO] - modality encoder
  1%|▏         | 42/3058 [01:02<1:07:10,  1.34s/it][2025-02-04 03:36:18][slam_llm.models.slam_model][INFO] - modality encoder
  1%|▏         | 43/3058 [01:03<55:48,  1.11s/it]  [2025-02-04 03:36:19][slam_llm.models.slam_model][INFO] - modality encoder
  1%|▏         | 44/3058 [01:03<51:57,  1.03s/it][2025-02-04 03:36:20][slam_llm.models.slam_model][INFO] - modality encoder
  1%|▏         | 45/3058 [01:05<53:48,  1.07s/it][2025-02-04 03:36:21][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 46/3058 [01:07<1:07:53,  1.35s/it][2025-02-04 03:36:23][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 47/3058 [01:08<1:02:31,  1.25s/it][2025-02-04 03:36:24][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 48/3058 [01:08<51:22,  1.02s/it]  [2025-02-04 03:36:24][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 49/3058 [01:09<52:36,  1.05s/it][2025-02-04 03:36:25][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 50/3058 [01:10<50:05,  1.00it/s][2025-02-04 03:36:26][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 51/3058 [01:11<49:40,  1.01it/s][2025-02-04 03:36:27][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 52/3058 [01:12<56:24,  1.13s/it][2025-02-04 03:36:29][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 53/3058 [01:14<59:15,  1.18s/it][2025-02-04 03:36:30][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 54/3058 [01:14<50:46,  1.01s/it][2025-02-04 03:36:31][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 55/3058 [01:15<49:04,  1.02it/s][2025-02-04 03:36:32][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 56/3058 [01:16<49:47,  1.00it/s][2025-02-04 03:36:32][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 57/3058 [01:17<46:23,  1.08it/s][2025-02-04 03:36:33][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 58/3058 [01:18<40:14,  1.24it/s][2025-02-04 03:36:34][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 59/3058 [01:19<41:10,  1.21it/s][2025-02-04 03:36:35][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 60/3058 [01:19<36:54,  1.35it/s][2025-02-04 03:36:35][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 61/3058 [01:20<46:55,  1.06it/s][2025-02-04 03:36:37][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 62/3058 [01:21<45:22,  1.10it/s][2025-02-04 03:36:37][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 63/3058 [01:22<42:16,  1.18it/s][2025-02-04 03:36:38][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 64/3058 [01:23<41:23,  1.21it/s][2025-02-04 03:36:39][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 65/3058 [01:23<38:43,  1.29it/s][2025-02-04 03:36:40][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 66/3058 [01:24<36:22,  1.37it/s][2025-02-04 03:36:40][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 67/3058 [01:25<38:57,  1.28it/s][2025-02-04 03:36:41][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 68/3058 [01:26<38:33,  1.29it/s][2025-02-04 03:36:42][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 69/3058 [01:27<43:34,  1.14it/s][2025-02-04 03:36:43][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 70/3058 [01:28<41:56,  1.19it/s][2025-02-04 03:36:44][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 71/3058 [01:29<45:58,  1.08it/s][2025-02-04 03:36:45][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 72/3058 [01:29<40:28,  1.23it/s][2025-02-04 03:36:45][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 73/3058 [01:30<39:14,  1.27it/s][2025-02-04 03:36:46][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 74/3058 [01:31<37:25,  1.33it/s][2025-02-04 03:36:47][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 75/3058 [01:31<36:35,  1.36it/s][2025-02-04 03:36:47][slam_llm.models.slam_model][INFO] - modality encoder
  2%|▏         | 76/3058 [01:32<36:04,  1.38it/s][2025-02-04 03:36:48][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 77/3058 [01:33<44:54,  1.11it/s][2025-02-04 03:36:50][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 78/3058 [01:35<58:38,  1.18s/it][2025-02-04 03:36:51][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 79/3058 [01:36<54:09,  1.09s/it][2025-02-04 03:36:52][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 80/3058 [01:38<1:03:39,  1.28s/it][2025-02-04 03:36:54][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 81/3058 [01:39<1:08:08,  1.37s/it][2025-02-04 03:36:56][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 82/3058 [01:42<1:18:53,  1.59s/it][2025-02-04 03:36:58][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 83/3058 [01:43<1:22:10,  1.66s/it][2025-02-04 03:37:00][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 84/3058 [01:45<1:23:31,  1.69s/it][2025-02-04 03:37:01][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 85/3058 [01:46<1:19:15,  1.60s/it][2025-02-04 03:37:03][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 86/3058 [01:49<1:28:38,  1.79s/it][2025-02-04 03:37:05][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 87/3058 [01:50<1:25:42,  1.73s/it][2025-02-04 03:37:06][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 88/3058 [01:51<1:12:37,  1.47s/it][2025-02-04 03:37:07][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 89/3058 [01:53<1:14:40,  1.51s/it][2025-02-04 03:37:09][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 90/3058 [01:54<1:15:13,  1.52s/it][2025-02-04 03:37:10][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 91/3058 [01:56<1:17:03,  1.56s/it][2025-02-04 03:37:12][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 92/3058 [01:57<1:13:41,  1.49s/it][2025-02-04 03:37:13][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 93/3058 [01:59<1:15:47,  1.53s/it][2025-02-04 03:37:15][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 94/3058 [02:00<1:14:55,  1.52s/it][2025-02-04 03:37:17][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 95/3058 [02:02<1:12:05,  1.46s/it][2025-02-04 03:37:18][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 96/3058 [02:05<1:33:10,  1.89s/it][2025-02-04 03:37:21][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 97/3058 [02:08<1:55:13,  2.33s/it][2025-02-04 03:37:24][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 98/3058 [02:11<2:03:20,  2.50s/it][2025-02-04 03:37:27][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 99/3058 [02:13<1:52:32,  2.28s/it][2025-02-04 03:37:29][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 100/3058 [02:15<1:57:15,  2.38s/it][2025-02-04 03:37:31][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 101/3058 [02:16<1:34:40,  1.92s/it][2025-02-04 03:37:32][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 102/3058 [02:18<1:39:05,  2.01s/it][2025-02-04 03:37:35][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 103/3058 [02:21<1:47:02,  2.17s/it][2025-02-04 03:37:37][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 104/3058 [02:23<1:44:22,  2.12s/it][2025-02-04 03:37:39][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 105/3058 [02:24<1:34:10,  1.91s/it][2025-02-04 03:37:41][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 106/3058 [02:27<1:50:22,  2.24s/it][2025-02-04 03:37:44][slam_llm.models.slam_model][INFO] - modality encoder
  3%|▎         | 107/3058 [02:30<1:53:22,  2.31s/it][2025-02-04 03:37:46][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▎         | 108/3058 [02:31<1:42:47,  2.09s/it][2025-02-04 03:37:48][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▎         | 109/3058 [02:33<1:38:16,  2.00s/it][2025-02-04 03:37:49][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▎         | 110/3058 [02:34<1:26:30,  1.76s/it][2025-02-04 03:37:51][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▎         | 111/3058 [02:37<1:35:41,  1.95s/it][2025-02-04 03:37:53][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▎         | 112/3058 [02:38<1:31:30,  1.86s/it][2025-02-04 03:37:55][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▎         | 113/3058 [02:40<1:24:19,  1.72s/it][2025-02-04 03:37:56][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▎         | 114/3058 [02:41<1:09:55,  1.43s/it][2025-02-04 03:37:57][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 115/3058 [02:41<1:01:08,  1.25s/it][2025-02-04 03:37:57][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 116/3058 [02:42<50:40,  1.03s/it]  [2025-02-04 03:37:58][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 117/3058 [02:43<47:08,  1.04it/s][2025-02-04 03:37:59][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 118/3058 [02:43<41:59,  1.17it/s][2025-02-04 03:38:00][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 119/3058 [02:45<56:33,  1.15s/it][2025-02-04 03:38:01][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 120/3058 [02:46<51:27,  1.05s/it][2025-02-04 03:38:02][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 121/3058 [02:47<56:42,  1.16s/it][2025-02-04 03:38:03][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 122/3058 [02:49<1:05:26,  1.34s/it][2025-02-04 03:38:05][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 123/3058 [02:50<1:04:42,  1.32s/it][2025-02-04 03:38:07][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 124/3058 [02:53<1:18:24,  1.60s/it][2025-02-04 03:38:09][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 125/3058 [02:54<1:11:56,  1.47s/it][2025-02-04 03:38:10][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 126/3058 [02:55<1:09:40,  1.43s/it][2025-02-04 03:38:11][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 127/3058 [02:57<1:09:16,  1.42s/it][2025-02-04 03:38:13][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 128/3058 [02:58<1:14:31,  1.53s/it][2025-02-04 03:38:15][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 129/3058 [03:05<2:34:06,  3.16s/it][2025-02-04 03:38:22][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 130/3058 [03:07<2:05:47,  2.58s/it][2025-02-04 03:38:23][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 131/3058 [03:08<1:50:50,  2.27s/it][2025-02-04 03:38:24][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 132/3058 [03:10<1:40:09,  2.05s/it][2025-02-04 03:38:26][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 133/3058 [03:11<1:33:27,  1.92s/it][2025-02-04 03:38:28][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 134/3058 [03:13<1:26:21,  1.77s/it][2025-02-04 03:38:29][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 135/3058 [03:14<1:25:59,  1.77s/it][2025-02-04 03:38:31][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 136/3058 [03:17<1:33:10,  1.91s/it][2025-02-04 03:38:33][slam_llm.models.slam_model][INFO] - modality encoder
  4%|▍         | 137/3058 [03:18<1:18:32,  1.61s/it][2025-02-04 03:38:34][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 138/3058 [03:19<1:21:28,  1.67s/it][2025-02-04 03:38:36][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 139/3058 [03:21<1:18:52,  1.62s/it][2025-02-04 03:38:37][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 140/3058 [03:23<1:25:42,  1.76s/it][2025-02-04 03:38:39][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 141/3058 [03:24<1:18:33,  1.62s/it][2025-02-04 03:38:41][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 142/3058 [03:26<1:16:30,  1.57s/it][2025-02-04 03:38:42][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 143/3058 [03:27<1:15:25,  1.55s/it][2025-02-04 03:38:44][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 144/3058 [03:29<1:21:34,  1.68s/it][2025-02-04 03:38:45][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 145/3058 [03:31<1:16:37,  1.58s/it][2025-02-04 03:38:47][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 146/3058 [03:33<1:25:30,  1.76s/it][2025-02-04 03:38:49][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 147/3058 [03:34<1:24:08,  1.73s/it][2025-02-04 03:38:51][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 148/3058 [03:36<1:22:09,  1.69s/it][2025-02-04 03:38:52][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 149/3058 [03:38<1:20:56,  1.67s/it][2025-02-04 03:38:54][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 150/3058 [03:39<1:21:31,  1.68s/it][2025-02-04 03:38:56][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 151/3058 [03:41<1:23:18,  1.72s/it][2025-02-04 03:38:58][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▍         | 152/3058 [03:44<1:35:55,  1.98s/it][2025-02-04 03:39:00][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 153/3058 [03:46<1:42:56,  2.13s/it][2025-02-04 03:39:02][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 154/3058 [03:47<1:27:18,  1.80s/it][2025-02-04 03:39:04][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 155/3058 [03:49<1:25:50,  1.77s/it][2025-02-04 03:39:05][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 156/3058 [03:52<1:38:16,  2.03s/it][2025-02-04 03:39:08][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 157/3058 [03:52<1:20:52,  1.67s/it][2025-02-04 03:39:09][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 158/3058 [03:53<1:06:37,  1.38s/it][2025-02-04 03:39:09][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 159/3058 [03:54<54:05,  1.12s/it]  [2025-02-04 03:39:10][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 160/3058 [03:54<44:28,  1.09it/s][2025-02-04 03:39:10][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 161/3058 [03:55<40:27,  1.19it/s][2025-02-04 03:39:11][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 162/3058 [03:55<38:11,  1.26it/s][2025-02-04 03:39:12][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 163/3058 [03:57<51:44,  1.07s/it][2025-02-04 03:39:13][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 164/3058 [03:58<49:16,  1.02s/it][2025-02-04 03:39:14][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 165/3058 [04:00<1:04:29,  1.34s/it][2025-02-04 03:39:16][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 166/3058 [04:01<1:00:37,  1.26s/it][2025-02-04 03:39:17][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 167/3058 [04:02<1:01:09,  1.27s/it][2025-02-04 03:39:19][slam_llm.models.slam_model][INFO] - modality encoder
  5%|▌         | 168/3058 [04:04<1:06:28,  1.38s/it][2025-02-04 03:39:20][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 169/3058 [04:05<1:06:07,  1.37s/it][2025-02-04 03:39:22][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 170/3058 [04:07<1:02:59,  1.31s/it][2025-02-04 03:39:23][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 171/3058 [04:08<1:03:59,  1.33s/it][2025-02-04 03:39:24][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 172/3058 [04:09<1:03:02,  1.31s/it][2025-02-04 03:39:25][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 173/3058 [04:11<1:08:11,  1.42s/it][2025-02-04 03:39:27][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 174/3058 [04:12<1:08:32,  1.43s/it][2025-02-04 03:39:28][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 175/3058 [04:13<1:00:27,  1.26s/it][2025-02-04 03:39:29][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 176/3058 [04:15<1:05:01,  1.35s/it][2025-02-04 03:39:31][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 177/3058 [04:16<1:08:34,  1.43s/it][2025-02-04 03:39:33][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 178/3058 [04:18<1:04:57,  1.35s/it][2025-02-04 03:39:34][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 179/3058 [04:19<1:01:40,  1.29s/it][2025-02-04 03:39:35][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 180/3058 [04:20<1:02:35,  1.30s/it][2025-02-04 03:39:36][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 181/3058 [04:21<51:37,  1.08s/it]  [2025-02-04 03:39:37][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 182/3058 [04:22<58:32,  1.22s/it][2025-02-04 03:39:38][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 183/3058 [04:24<1:05:09,  1.36s/it][2025-02-04 03:39:40][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 184/3058 [04:26<1:12:30,  1.51s/it][2025-02-04 03:39:42][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 185/3058 [04:27<1:03:14,  1.32s/it][2025-02-04 03:39:43][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 186/3058 [04:29<1:15:37,  1.58s/it][2025-02-04 03:39:45][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 187/3058 [04:31<1:19:43,  1.67s/it][2025-02-04 03:39:47][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 188/3058 [04:32<1:16:18,  1.60s/it][2025-02-04 03:39:48][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 189/3058 [04:33<1:04:52,  1.36s/it][2025-02-04 03:39:49][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 190/3058 [04:34<1:06:58,  1.40s/it][2025-02-04 03:39:50][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▌         | 191/3058 [04:36<1:02:40,  1.31s/it][2025-02-04 03:39:52][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▋         | 192/3058 [04:36<56:33,  1.18s/it]  [2025-02-04 03:39:53][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▋         | 193/3058 [04:38<1:06:50,  1.40s/it][2025-02-04 03:39:54][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▋         | 194/3058 [04:41<1:18:35,  1.65s/it][2025-02-04 03:39:57][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▋         | 195/3058 [04:41<1:06:01,  1.38s/it][2025-02-04 03:39:57][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▋         | 196/3058 [04:43<1:17:01,  1.61s/it][2025-02-04 03:40:00][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▋         | 197/3058 [04:45<1:17:47,  1.63s/it][2025-02-04 03:40:01][slam_llm.models.slam_model][INFO] - modality encoder
  6%|▋         | 198/3058 [04:46<1:05:36,  1.38s/it][2025-02-04 03:40:02][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 199/3058 [04:47<1:01:12,  1.28s/it][2025-02-04 03:40:03][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 200/3058 [04:48<58:42,  1.23s/it]  [2025-02-04 03:40:04][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 201/3058 [04:49<59:46,  1.26s/it][2025-02-04 03:40:06][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 202/3058 [04:51<1:02:50,  1.32s/it][2025-02-04 03:40:07][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 203/3058 [04:53<1:07:50,  1.43s/it][2025-02-04 03:40:09][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 204/3058 [04:53<55:43,  1.17s/it]  [2025-02-04 03:40:09][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 205/3058 [04:54<54:00,  1.14s/it][2025-02-04 03:40:10][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 206/3058 [04:56<1:04:22,  1.35s/it][2025-02-04 03:40:12][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 207/3058 [04:58<1:10:07,  1.48s/it][2025-02-04 03:40:14][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 208/3058 [04:59<1:07:35,  1.42s/it][2025-02-04 03:40:15][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 209/3058 [05:01<1:13:55,  1.56s/it][2025-02-04 03:40:17][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 210/3058 [05:02<1:13:06,  1.54s/it][2025-02-04 03:40:19][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 211/3058 [05:03<1:04:02,  1.35s/it][2025-02-04 03:40:19][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 212/3058 [05:05<1:13:26,  1.55s/it][2025-02-04 03:40:21][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 213/3058 [05:06<1:04:41,  1.36s/it][2025-02-04 03:40:23][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 214/3058 [05:09<1:24:15,  1.78s/it][2025-02-04 03:40:25][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 215/3058 [05:10<1:19:32,  1.68s/it][2025-02-04 03:40:27][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 216/3058 [05:12<1:15:47,  1.60s/it][2025-02-04 03:40:28][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 217/3058 [05:13<1:11:49,  1.52s/it][2025-02-04 03:40:29][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 218/3058 [05:15<1:13:32,  1.55s/it][2025-02-04 03:40:31][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 219/3058 [05:17<1:22:25,  1.74s/it][2025-02-04 03:40:33][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 220/3058 [05:19<1:26:11,  1.82s/it][2025-02-04 03:40:35][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 221/3058 [05:22<1:36:33,  2.04s/it][2025-02-04 03:40:38][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 222/3058 [05:23<1:30:01,  1.90s/it][2025-02-04 03:40:39][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 223/3058 [05:26<1:37:08,  2.06s/it][2025-02-04 03:40:42][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 224/3058 [05:28<1:35:20,  2.02s/it][2025-02-04 03:40:44][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 225/3058 [05:29<1:22:17,  1.74s/it][2025-02-04 03:40:45][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 226/3058 [05:30<1:16:46,  1.63s/it][2025-02-04 03:40:46][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 227/3058 [05:31<1:11:27,  1.51s/it][2025-02-04 03:40:47][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 228/3058 [05:33<1:08:19,  1.45s/it][2025-02-04 03:40:49][slam_llm.models.slam_model][INFO] - modality encoder
  7%|▋         | 229/3058 [05:34<1:08:43,  1.46s/it][2025-02-04 03:40:50][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 230/3058 [05:35<1:07:14,  1.43s/it][2025-02-04 03:40:51][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 231/3058 [05:36<1:00:20,  1.28s/it][2025-02-04 03:40:52][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 232/3058 [05:39<1:14:17,  1.58s/it][2025-02-04 03:40:55][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 233/3058 [05:40<1:13:30,  1.56s/it][2025-02-04 03:40:56][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 234/3058 [05:41<1:09:34,  1.48s/it][2025-02-04 03:40:57][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 235/3058 [05:43<1:11:16,  1.51s/it][2025-02-04 03:40:59][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 236/3058 [05:44<1:09:10,  1.47s/it][2025-02-04 03:41:00][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 237/3058 [05:46<1:11:12,  1.51s/it][2025-02-04 03:41:02][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 238/3058 [05:47<1:05:40,  1.40s/it][2025-02-04 03:41:03][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 239/3058 [05:50<1:28:00,  1.87s/it][2025-02-04 03:41:06][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 240/3058 [05:53<1:44:40,  2.23s/it][2025-02-04 03:41:09][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 241/3058 [05:56<1:49:46,  2.34s/it][2025-02-04 03:41:12][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 242/3058 [05:58<1:43:59,  2.22s/it][2025-02-04 03:41:14][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 243/3058 [06:00<1:43:39,  2.21s/it][2025-02-04 03:41:16][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 244/3058 [06:02<1:38:53,  2.11s/it][2025-02-04 03:41:18][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 245/3058 [06:03<1:31:08,  1.94s/it][2025-02-04 03:41:19][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 246/3058 [06:05<1:21:10,  1.73s/it][2025-02-04 03:41:21][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 247/3058 [06:06<1:11:44,  1.53s/it][2025-02-04 03:41:22][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 248/3058 [06:07<1:06:45,  1.43s/it][2025-02-04 03:41:23][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 249/3058 [06:08<1:00:34,  1.29s/it][2025-02-04 03:41:24][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 250/3058 [06:09<52:57,  1.13s/it]  [2025-02-04 03:41:25][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 251/3058 [06:09<48:33,  1.04s/it][2025-02-04 03:41:25][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 252/3058 [06:10<48:34,  1.04s/it][2025-02-04 03:41:26][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 253/3058 [06:11<44:55,  1.04it/s][2025-02-04 03:41:27][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 254/3058 [06:12<38:52,  1.20it/s][2025-02-04 03:41:28][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 255/3058 [06:13<39:50,  1.17it/s][2025-02-04 03:41:29][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 256/3058 [06:13<33:01,  1.41it/s][2025-02-04 03:41:29][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 257/3058 [06:14<31:28,  1.48it/s][2025-02-04 03:41:30][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 258/3058 [06:14<32:01,  1.46it/s][2025-02-04 03:41:30][slam_llm.models.slam_model][INFO] - modality encoder
  8%|▊         | 259/3058 [06:15<37:08,  1.26it/s][2025-02-04 03:41:32][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▊         | 260/3058 [06:16<39:08,  1.19it/s][2025-02-04 03:41:32][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▊         | 261/3058 [06:18<57:41,  1.24s/it][2025-02-04 03:41:35][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▊         | 262/3058 [06:21<1:19:33,  1.71s/it][2025-02-04 03:41:37][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▊         | 263/3058 [06:23<1:15:35,  1.62s/it][2025-02-04 03:41:39][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▊         | 264/3058 [06:25<1:27:57,  1.89s/it][2025-02-04 03:41:41][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▊         | 265/3058 [06:26<1:16:31,  1.64s/it][2025-02-04 03:41:43][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▊         | 266/3058 [06:30<1:50:35,  2.38s/it][2025-02-04 03:41:46][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▊         | 267/3058 [06:32<1:38:56,  2.13s/it][2025-02-04 03:41:48][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 268/3058 [06:35<1:53:52,  2.45s/it][2025-02-04 03:41:51][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 269/3058 [06:38<1:57:07,  2.52s/it][2025-02-04 03:41:54][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 270/3058 [06:40<1:46:26,  2.29s/it][2025-02-04 03:41:56][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 271/3058 [06:43<1:56:37,  2.51s/it][2025-02-04 03:41:59][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 272/3058 [06:44<1:41:17,  2.18s/it][2025-02-04 03:42:00][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 273/3058 [06:47<1:50:28,  2.38s/it][2025-02-04 03:42:03][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 274/3058 [06:49<1:47:38,  2.32s/it][2025-02-04 03:42:05][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 275/3058 [06:52<1:54:12,  2.46s/it][2025-02-04 03:42:08][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 276/3058 [06:54<1:46:26,  2.30s/it][2025-02-04 03:42:10][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 277/3058 [06:56<1:41:15,  2.18s/it][2025-02-04 03:42:12][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 278/3058 [06:58<1:38:58,  2.14s/it][2025-02-04 03:42:14][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 279/3058 [07:00<1:36:28,  2.08s/it][2025-02-04 03:42:16][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 280/3058 [07:01<1:28:48,  1.92s/it][2025-02-04 03:42:17][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 281/3058 [07:03<1:34:09,  2.03s/it][2025-02-04 03:42:20][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 282/3058 [07:06<1:39:05,  2.14s/it][2025-02-04 03:42:22][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 283/3058 [07:09<1:57:05,  2.53s/it][2025-02-04 03:42:26][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 284/3058 [07:12<2:04:10,  2.69s/it][2025-02-04 03:42:28][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 285/3058 [07:13<1:41:42,  2.20s/it][2025-02-04 03:42:30][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 286/3058 [07:16<1:42:26,  2.22s/it][2025-02-04 03:42:32][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 287/3058 [07:17<1:36:31,  2.09s/it][2025-02-04 03:42:34][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 288/3058 [07:19<1:31:02,  1.97s/it][2025-02-04 03:42:35][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 289/3058 [07:21<1:30:28,  1.96s/it][2025-02-04 03:42:37][slam_llm.models.slam_model][INFO] - modality encoder
  9%|▉         | 290/3058 [07:22<1:22:30,  1.79s/it][2025-02-04 03:42:39][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 291/3058 [07:25<1:27:53,  1.91s/it][2025-02-04 03:42:41][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 292/3058 [07:26<1:15:06,  1.63s/it][2025-02-04 03:42:42][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 293/3058 [07:27<1:15:51,  1.65s/it][2025-02-04 03:42:43][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 294/3058 [07:29<1:10:07,  1.52s/it][2025-02-04 03:42:45][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 295/3058 [07:29<1:01:02,  1.33s/it][2025-02-04 03:42:46][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 296/3058 [07:30<56:02,  1.22s/it]  [2025-02-04 03:42:46][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 297/3058 [07:32<1:04:25,  1.40s/it][2025-02-04 03:42:48][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 298/3058 [07:33<58:29,  1.27s/it]  [2025-02-04 03:42:49][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 299/3058 [07:34<55:04,  1.20s/it][2025-02-04 03:42:50][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 300/3058 [07:35<55:32,  1.21s/it][2025-02-04 03:42:52][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 301/3058 [07:38<1:15:24,  1.64s/it][2025-02-04 03:42:54][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 302/3058 [07:39<1:08:55,  1.50s/it][2025-02-04 03:42:56][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 303/3058 [07:43<1:44:51,  2.28s/it][2025-02-04 03:42:59][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 304/3058 [07:45<1:36:00,  2.09s/it][2025-02-04 03:43:01][slam_llm.models.slam_model][INFO] - modality encoder
 10%|▉         | 305/3058 [07:47<1:31:26,  1.99s/it][2025-02-04 03:43:03][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 306/3058 [07:48<1:25:16,  1.86s/it][2025-02-04 03:43:04][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 307/3058 [07:50<1:28:22,  1.93s/it][2025-02-04 03:43:06][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 308/3058 [07:52<1:23:33,  1.82s/it][2025-02-04 03:43:08][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 309/3058 [07:54<1:25:48,  1.87s/it][2025-02-04 03:43:10][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 310/3058 [07:55<1:20:16,  1.75s/it][2025-02-04 03:43:11][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 311/3058 [07:57<1:16:25,  1.67s/it][2025-02-04 03:43:13][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 312/3058 [07:59<1:20:33,  1.76s/it][2025-02-04 03:43:15][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 313/3058 [08:01<1:21:38,  1.78s/it][2025-02-04 03:43:17][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 314/3058 [08:02<1:14:12,  1.62s/it][2025-02-04 03:43:18][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 315/3058 [08:05<1:37:48,  2.14s/it][2025-02-04 03:43:22][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 316/3058 [08:09<2:00:52,  2.65s/it][2025-02-04 03:43:25][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 317/3058 [08:11<1:50:27,  2.42s/it][2025-02-04 03:43:27][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 318/3058 [08:13<1:49:58,  2.41s/it][2025-02-04 03:43:30][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 319/3058 [08:15<1:42:29,  2.25s/it][2025-02-04 03:43:32][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 320/3058 [08:19<2:02:33,  2.69s/it][2025-02-04 03:43:35][slam_llm.models.slam_model][INFO] - modality encoder
 10%|█         | 321/3058 [08:23<2:21:55,  3.11s/it][2025-02-04 03:43:39][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 322/3058 [08:26<2:20:16,  3.08s/it][2025-02-04 03:43:43][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 323/3058 [08:30<2:27:46,  3.24s/it][2025-02-04 03:43:46][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 324/3058 [08:31<1:55:02,  2.52s/it][2025-02-04 03:43:47][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 325/3058 [08:31<1:32:47,  2.04s/it][2025-02-04 03:43:48][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 326/3058 [08:33<1:21:18,  1.79s/it][2025-02-04 03:43:49][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 327/3058 [08:35<1:30:01,  1.98s/it][2025-02-04 03:43:51][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 328/3058 [08:38<1:39:05,  2.18s/it][2025-02-04 03:43:54][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 329/3058 [08:40<1:36:51,  2.13s/it][2025-02-04 03:43:56][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 330/3058 [08:42<1:44:53,  2.31s/it][2025-02-04 03:43:59][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 331/3058 [08:44<1:32:03,  2.03s/it][2025-02-04 03:44:00][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 332/3058 [08:45<1:22:46,  1.82s/it][2025-02-04 03:44:01][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 333/3058 [08:47<1:17:05,  1.70s/it][2025-02-04 03:44:03][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 334/3058 [08:48<1:18:27,  1.73s/it][2025-02-04 03:44:05][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 335/3058 [08:50<1:12:32,  1.60s/it][2025-02-04 03:44:06][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 336/3058 [08:51<1:10:30,  1.55s/it][2025-02-04 03:44:08][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 337/3058 [08:53<1:18:37,  1.73s/it][2025-02-04 03:44:10][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 338/3058 [08:55<1:16:08,  1.68s/it][2025-02-04 03:44:11][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 339/3058 [08:56<1:05:41,  1.45s/it][2025-02-04 03:44:12][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 340/3058 [08:57<1:01:02,  1.35s/it][2025-02-04 03:44:13][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 341/3058 [08:58<1:00:59,  1.35s/it][2025-02-04 03:44:15][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 342/3058 [09:00<1:03:33,  1.40s/it][2025-02-04 03:44:16][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 343/3058 [09:01<59:54,  1.32s/it]  [2025-02-04 03:44:17][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█         | 344/3058 [09:02<1:03:28,  1.40s/it][2025-02-04 03:44:19][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█▏        | 345/3058 [09:03<55:43,  1.23s/it]  [2025-02-04 03:44:20][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█▏        | 346/3058 [09:05<1:05:08,  1.44s/it][2025-02-04 03:44:22][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█▏        | 347/3058 [09:08<1:18:31,  1.74s/it][2025-02-04 03:44:24][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█▏        | 348/3058 [09:09<1:09:56,  1.55s/it][2025-02-04 03:44:25][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█▏        | 349/3058 [09:10<1:04:37,  1.43s/it][2025-02-04 03:44:26][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█▏        | 350/3058 [09:11<57:57,  1.28s/it]  [2025-02-04 03:44:27][slam_llm.models.slam_model][INFO] - modality encoder
 11%|█▏        | 351/3058 [09:12<53:44,  1.19s/it][2025-02-04 03:44:28][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 352/3058 [09:14<1:04:12,  1.42s/it][2025-02-04 03:44:30][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 353/3058 [09:15<1:01:25,  1.36s/it][2025-02-04 03:44:31][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 354/3058 [09:18<1:28:50,  1.97s/it][2025-02-04 03:44:35][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 355/3058 [09:20<1:26:56,  1.93s/it][2025-02-04 03:44:36][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 356/3058 [09:22<1:25:11,  1.89s/it][2025-02-04 03:44:38][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 357/3058 [09:24<1:23:42,  1.86s/it][2025-02-04 03:44:40][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 358/3058 [09:26<1:23:35,  1.86s/it][2025-02-04 03:44:42][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 359/3058 [09:27<1:17:25,  1.72s/it][2025-02-04 03:44:43][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 360/3058 [09:29<1:14:19,  1.65s/it][2025-02-04 03:44:45][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 361/3058 [09:31<1:23:29,  1.86s/it][2025-02-04 03:44:47][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 362/3058 [09:32<1:16:27,  1.70s/it][2025-02-04 03:44:48][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 363/3058 [09:33<1:05:27,  1.46s/it][2025-02-04 03:44:49][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 364/3058 [09:34<1:00:29,  1.35s/it][2025-02-04 03:44:51][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 365/3058 [09:36<1:11:30,  1.59s/it][2025-02-04 03:44:53][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 366/3058 [09:38<1:06:24,  1.48s/it][2025-02-04 03:44:54][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 367/3058 [09:39<1:02:51,  1.40s/it][2025-02-04 03:44:55][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 368/3058 [09:41<1:07:03,  1.50s/it][2025-02-04 03:44:57][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 369/3058 [09:42<1:10:39,  1.58s/it][2025-02-04 03:44:59][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 370/3058 [09:45<1:26:34,  1.93s/it][2025-02-04 03:45:01][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 371/3058 [09:47<1:28:25,  1.97s/it][2025-02-04 03:45:03][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 372/3058 [09:49<1:31:33,  2.05s/it][2025-02-04 03:45:06][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 373/3058 [09:51<1:31:02,  2.03s/it][2025-02-04 03:45:08][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 374/3058 [09:53<1:21:45,  1.83s/it][2025-02-04 03:45:09][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 375/3058 [09:55<1:34:29,  2.11s/it][2025-02-04 03:45:12][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 376/3058 [09:56<1:18:59,  1.77s/it][2025-02-04 03:45:13][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 377/3058 [09:58<1:17:24,  1.73s/it][2025-02-04 03:45:14][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 378/3058 [09:59<1:12:15,  1.62s/it][2025-02-04 03:45:16][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 379/3058 [10:00<1:02:00,  1.39s/it][2025-02-04 03:45:16][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 380/3058 [10:03<1:17:51,  1.74s/it][2025-02-04 03:45:19][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 381/3058 [10:04<1:09:21,  1.55s/it][2025-02-04 03:45:20][slam_llm.models.slam_model][INFO] - modality encoder
 12%|█▏        | 382/3058 [10:07<1:31:46,  2.06s/it][2025-02-04 03:45:23][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 383/3058 [10:09<1:32:54,  2.08s/it][2025-02-04 03:45:26][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 384/3058 [10:12<1:38:54,  2.22s/it][2025-02-04 03:45:28][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 385/3058 [10:14<1:33:36,  2.10s/it][2025-02-04 03:45:30][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 386/3058 [10:15<1:19:23,  1.78s/it][2025-02-04 03:45:31][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 387/3058 [10:16<1:09:56,  1.57s/it][2025-02-04 03:45:32][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 388/3058 [10:17<1:10:15,  1.58s/it][2025-02-04 03:45:34][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 389/3058 [10:19<1:06:07,  1.49s/it][2025-02-04 03:45:35][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 390/3058 [10:21<1:10:25,  1.58s/it][2025-02-04 03:45:37][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 391/3058 [10:22<1:11:53,  1.62s/it][2025-02-04 03:45:38][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 392/3058 [10:24<1:12:41,  1.64s/it][2025-02-04 03:45:40][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 393/3058 [10:27<1:36:12,  2.17s/it][2025-02-04 03:45:44][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 394/3058 [10:31<1:50:10,  2.48s/it][2025-02-04 03:45:47][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 395/3058 [10:32<1:43:03,  2.32s/it][2025-02-04 03:45:49][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 396/3058 [10:34<1:32:41,  2.09s/it][2025-02-04 03:45:50][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 397/3058 [10:36<1:33:38,  2.11s/it][2025-02-04 03:45:52][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 398/3058 [10:38<1:28:07,  1.99s/it][2025-02-04 03:45:54][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 399/3058 [10:40<1:23:41,  1.89s/it][2025-02-04 03:45:56][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 400/3058 [10:42<1:28:15,  1.99s/it][2025-02-04 03:45:58][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 401/3058 [10:45<1:39:03,  2.24s/it][2025-02-04 03:46:01][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 402/3058 [10:46<1:33:53,  2.12s/it][2025-02-04 03:46:03][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 403/3058 [10:48<1:24:19,  1.91s/it][2025-02-04 03:46:04][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 404/3058 [10:50<1:30:31,  2.05s/it][2025-02-04 03:46:06][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 405/3058 [10:51<1:17:02,  1.74s/it][2025-02-04 03:46:07][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 406/3058 [10:53<1:13:12,  1.66s/it][2025-02-04 03:46:09][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 407/3058 [10:55<1:16:52,  1.74s/it][2025-02-04 03:46:11][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 408/3058 [10:55<1:04:53,  1.47s/it][2025-02-04 03:46:12][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 409/3058 [10:57<1:05:53,  1.49s/it][2025-02-04 03:46:13][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 410/3058 [10:58<1:01:02,  1.38s/it][2025-02-04 03:46:14][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 411/3058 [11:00<1:09:23,  1.57s/it][2025-02-04 03:46:16][slam_llm.models.slam_model][INFO] - modality encoder
 13%|█▎        | 412/3058 [11:03<1:21:36,  1.85s/it][2025-02-04 03:46:19][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▎        | 413/3058 [11:06<1:41:52,  2.31s/it][2025-02-04 03:46:22][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▎        | 414/3058 [11:08<1:32:02,  2.09s/it][2025-02-04 03:46:24][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▎        | 415/3058 [11:09<1:24:09,  1.91s/it][2025-02-04 03:46:25][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▎        | 416/3058 [11:11<1:20:12,  1.82s/it][2025-02-04 03:46:27][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▎        | 417/3058 [11:14<1:35:02,  2.16s/it][2025-02-04 03:46:30][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▎        | 418/3058 [11:16<1:43:42,  2.36s/it][2025-02-04 03:46:33][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▎        | 419/3058 [11:21<2:08:45,  2.93s/it][2025-02-04 03:46:37][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▎        | 420/3058 [11:23<1:58:39,  2.70s/it][2025-02-04 03:46:39][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 421/3058 [11:24<1:36:23,  2.19s/it][2025-02-04 03:46:40][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 422/3058 [11:25<1:21:57,  1.87s/it][2025-02-04 03:46:41][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 423/3058 [11:27<1:22:08,  1.87s/it][2025-02-04 03:46:43][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 424/3058 [11:29<1:30:48,  2.07s/it][2025-02-04 03:46:46][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 425/3058 [11:32<1:32:30,  2.11s/it][2025-02-04 03:46:48][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 426/3058 [11:35<1:51:57,  2.55s/it][2025-02-04 03:46:51][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 427/3058 [11:37<1:45:15,  2.40s/it][2025-02-04 03:46:53][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 428/3058 [11:39<1:38:03,  2.24s/it][2025-02-04 03:46:55][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 429/3058 [11:41<1:36:54,  2.21s/it][2025-02-04 03:46:57][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 430/3058 [11:44<1:37:27,  2.23s/it][2025-02-04 03:47:00][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 431/3058 [11:45<1:27:11,  1.99s/it][2025-02-04 03:47:01][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 432/3058 [11:46<1:14:40,  1.71s/it][2025-02-04 03:47:02][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 433/3058 [11:48<1:12:32,  1.66s/it][2025-02-04 03:47:04][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 434/3058 [11:50<1:16:04,  1.74s/it][2025-02-04 03:47:06][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 435/3058 [11:52<1:30:58,  2.08s/it][2025-02-04 03:47:09][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 436/3058 [11:55<1:36:32,  2.21s/it][2025-02-04 03:47:11][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 437/3058 [11:56<1:26:02,  1.97s/it][2025-02-04 03:47:12][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 438/3058 [11:59<1:32:32,  2.12s/it][2025-02-04 03:47:15][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 439/3058 [12:00<1:26:45,  1.99s/it][2025-02-04 03:47:17][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 440/3058 [12:02<1:22:53,  1.90s/it][2025-02-04 03:47:18][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 441/3058 [12:04<1:18:32,  1.80s/it][2025-02-04 03:47:20][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 442/3058 [12:05<1:15:21,  1.73s/it][2025-02-04 03:47:21][slam_llm.models.slam_model][INFO] - modality encoder
 14%|█▍        | 443/3058 [12:07<1:15:27,  1.73s/it][2025-02-04 03:47:23][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 444/3058 [12:09<1:20:12,  1.84s/it][2025-02-04 03:47:25][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 445/3058 [12:11<1:16:56,  1.77s/it][2025-02-04 03:47:27][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 446/3058 [12:13<1:25:39,  1.97s/it][2025-02-04 03:47:29][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 447/3058 [12:15<1:21:39,  1.88s/it][2025-02-04 03:47:31][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 448/3058 [12:18<1:40:42,  2.32s/it][2025-02-04 03:47:34][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 449/3058 [12:21<1:43:32,  2.38s/it][2025-02-04 03:47:37][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 450/3058 [12:23<1:39:50,  2.30s/it][2025-02-04 03:47:39][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 451/3058 [12:24<1:31:35,  2.11s/it][2025-02-04 03:47:41][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 452/3058 [12:28<1:53:39,  2.62s/it][2025-02-04 03:47:44][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 453/3058 [12:29<1:34:33,  2.18s/it][2025-02-04 03:47:46][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 454/3058 [12:31<1:31:30,  2.11s/it][2025-02-04 03:47:47][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 455/3058 [12:33<1:27:24,  2.01s/it][2025-02-04 03:47:49][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 456/3058 [12:34<1:13:41,  1.70s/it][2025-02-04 03:47:50][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 457/3058 [12:36<1:14:20,  1.71s/it][2025-02-04 03:47:52][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▍        | 458/3058 [12:38<1:15:09,  1.73s/it][2025-02-04 03:47:54][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 459/3058 [12:39<1:15:44,  1.75s/it][2025-02-04 03:47:56][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 460/3058 [12:42<1:21:13,  1.88s/it][2025-02-04 03:47:58][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 461/3058 [12:44<1:28:40,  2.05s/it][2025-02-04 03:48:00][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 462/3058 [12:46<1:22:33,  1.91s/it][2025-02-04 03:48:02][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 463/3058 [12:48<1:33:48,  2.17s/it][2025-02-04 03:48:05][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 464/3058 [12:50<1:21:44,  1.89s/it][2025-02-04 03:48:06][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 465/3058 [12:52<1:26:59,  2.01s/it][2025-02-04 03:48:08][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 466/3058 [12:54<1:23:48,  1.94s/it][2025-02-04 03:48:10][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 467/3058 [12:56<1:29:34,  2.07s/it][2025-02-04 03:48:12][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 468/3058 [12:58<1:27:00,  2.02s/it][2025-02-04 03:48:14][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 469/3058 [13:00<1:29:22,  2.07s/it][2025-02-04 03:48:16][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 470/3058 [13:02<1:27:48,  2.04s/it][2025-02-04 03:48:18][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 471/3058 [13:04<1:23:52,  1.95s/it][2025-02-04 03:48:20][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 472/3058 [13:07<1:38:52,  2.29s/it][2025-02-04 03:48:23][slam_llm.models.slam_model][INFO] - modality encoder
 15%|█▌        | 473/3058 [13:08<1:23:19,  1.93s/it][2025-02-04 03:48:24][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 474/3058 [13:09<1:14:34,  1.73s/it][2025-02-04 03:48:25][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 475/3058 [13:10<1:06:42,  1.55s/it][2025-02-04 03:48:27][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 476/3058 [13:12<1:13:03,  1.70s/it][2025-02-04 03:48:29][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 477/3058 [13:14<1:09:11,  1.61s/it][2025-02-04 03:48:30][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 478/3058 [13:15<58:19,  1.36s/it]  [2025-02-04 03:48:31][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 479/3058 [13:16<59:52,  1.39s/it][2025-02-04 03:48:32][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 480/3058 [13:18<1:07:43,  1.58s/it][2025-02-04 03:48:34][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 481/3058 [13:19<1:00:28,  1.41s/it][2025-02-04 03:48:35][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 482/3058 [13:21<1:02:01,  1.44s/it][2025-02-04 03:48:37][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 483/3058 [13:23<1:14:24,  1.73s/it][2025-02-04 03:48:39][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 484/3058 [13:24<58:27,  1.36s/it]  [2025-02-04 03:48:40][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 485/3058 [13:26<1:08:31,  1.60s/it][2025-02-04 03:48:42][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 486/3058 [13:28<1:16:04,  1.77s/it][2025-02-04 03:48:44][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 487/3058 [13:31<1:34:40,  2.21s/it][2025-02-04 03:48:47][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 488/3058 [13:34<1:37:04,  2.27s/it][2025-02-04 03:48:50][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 489/3058 [13:35<1:26:51,  2.03s/it][2025-02-04 03:48:51][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 490/3058 [13:36<1:17:23,  1.81s/it][2025-02-04 03:48:52][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 491/3058 [13:39<1:27:31,  2.05s/it][2025-02-04 03:48:55][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 492/3058 [13:42<1:39:04,  2.32s/it][2025-02-04 03:48:58][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 493/3058 [13:43<1:21:04,  1.90s/it][2025-02-04 03:48:59][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 494/3058 [13:46<1:39:36,  2.33s/it][2025-02-04 03:49:03][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 495/3058 [13:49<1:51:11,  2.60s/it][2025-02-04 03:49:06][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▌        | 496/3058 [13:51<1:35:41,  2.24s/it][2025-02-04 03:49:07][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▋        | 497/3058 [13:52<1:21:40,  1.91s/it][2025-02-04 03:49:09][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▋        | 498/3058 [13:54<1:25:55,  2.01s/it][2025-02-04 03:49:11][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▋        | 499/3058 [13:57<1:33:02,  2.18s/it][2025-02-04 03:49:13][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▋        | 500/3058 [14:00<1:42:09,  2.40s/it][2025-02-04 03:49:16][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▋        | 501/3058 [14:02<1:45:33,  2.48s/it][2025-02-04 03:49:19][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▋        | 502/3058 [14:04<1:30:29,  2.12s/it][2025-02-04 03:49:20][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▋        | 503/3058 [14:06<1:38:42,  2.32s/it][2025-02-04 03:49:23][slam_llm.models.slam_model][INFO] - modality encoder
 16%|█▋        | 504/3058 [14:09<1:37:51,  2.30s/it][2025-02-04 03:49:25][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 505/3058 [14:11<1:40:26,  2.36s/it][2025-02-04 03:49:27][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 506/3058 [14:12<1:24:21,  1.98s/it][2025-02-04 03:49:29][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 507/3058 [14:14<1:17:51,  1.83s/it][2025-02-04 03:49:30][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 508/3058 [14:15<1:14:03,  1.74s/it][2025-02-04 03:49:31][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 509/3058 [14:16<1:06:59,  1.58s/it][2025-02-04 03:49:33][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 510/3058 [14:18<1:03:06,  1.49s/it][2025-02-04 03:49:34][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 511/3058 [14:19<1:03:20,  1.49s/it][2025-02-04 03:49:35][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 512/3058 [14:20<59:15,  1.40s/it]  [2025-02-04 03:49:37][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 513/3058 [14:23<1:09:51,  1.65s/it][2025-02-04 03:49:39][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 514/3058 [14:25<1:13:32,  1.73s/it][2025-02-04 03:49:41][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 515/3058 [14:26<1:11:39,  1.69s/it][2025-02-04 03:49:43][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 516/3058 [14:28<1:16:43,  1.81s/it][2025-02-04 03:49:45][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 517/3058 [14:30<1:19:35,  1.88s/it][2025-02-04 03:49:47][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 518/3058 [14:33<1:25:36,  2.02s/it][2025-02-04 03:49:49][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 519/3058 [14:35<1:31:32,  2.16s/it][2025-02-04 03:49:51][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 520/3058 [14:38<1:36:44,  2.29s/it][2025-02-04 03:49:54][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 521/3058 [14:39<1:25:56,  2.03s/it][2025-02-04 03:49:55][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 522/3058 [14:41<1:20:23,  1.90s/it][2025-02-04 03:49:57][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 523/3058 [14:43<1:20:34,  1.91s/it][2025-02-04 03:49:59][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 524/3058 [14:44<1:07:40,  1.60s/it][2025-02-04 03:50:00][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 525/3058 [14:45<1:11:41,  1.70s/it][2025-02-04 03:50:02][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 526/3058 [14:48<1:19:45,  1.89s/it][2025-02-04 03:50:04][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 527/3058 [14:50<1:19:01,  1.87s/it][2025-02-04 03:50:06][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 528/3058 [14:51<1:18:24,  1.86s/it][2025-02-04 03:50:08][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 529/3058 [14:53<1:08:57,  1.64s/it][2025-02-04 03:50:09][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 530/3058 [14:55<1:21:18,  1.93s/it][2025-02-04 03:50:12][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 531/3058 [14:58<1:36:19,  2.29s/it][2025-02-04 03:50:15][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 532/3058 [15:00<1:28:14,  2.10s/it][2025-02-04 03:50:16][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 533/3058 [15:02<1:24:00,  2.00s/it][2025-02-04 03:50:18][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 534/3058 [15:05<1:33:59,  2.23s/it][2025-02-04 03:50:21][slam_llm.models.slam_model][INFO] - modality encoder
 17%|█▋        | 535/3058 [15:07<1:32:48,  2.21s/it][2025-02-04 03:50:23][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 536/3058 [15:09<1:35:05,  2.26s/it][2025-02-04 03:50:26][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 537/3058 [15:12<1:44:33,  2.49s/it][2025-02-04 03:50:28][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 538/3058 [15:13<1:28:41,  2.11s/it][2025-02-04 03:50:30][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 539/3058 [15:15<1:23:08,  1.98s/it][2025-02-04 03:50:31][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 540/3058 [15:16<1:13:39,  1.76s/it][2025-02-04 03:50:32][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 541/3058 [15:17<1:05:32,  1.56s/it][2025-02-04 03:50:34][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 542/3058 [15:18<58:19,  1.39s/it]  [2025-02-04 03:50:34][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 543/3058 [15:19<47:20,  1.13s/it][2025-02-04 03:50:35][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 544/3058 [15:20<47:20,  1.13s/it][2025-02-04 03:50:36][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 545/3058 [15:21<49:42,  1.19s/it][2025-02-04 03:50:38][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 546/3058 [15:23<57:12,  1.37s/it][2025-02-04 03:50:39][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 547/3058 [15:24<54:20,  1.30s/it][2025-02-04 03:50:40][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 548/3058 [15:26<57:38,  1.38s/it][2025-02-04 03:50:42][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 549/3058 [15:26<45:58,  1.10s/it][2025-02-04 03:50:43][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 550/3058 [15:28<51:14,  1.23s/it][2025-02-04 03:50:44][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 551/3058 [15:30<59:22,  1.42s/it][2025-02-04 03:50:46][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 552/3058 [15:31<57:11,  1.37s/it][2025-02-04 03:50:47][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 553/3058 [15:32<54:58,  1.32s/it][2025-02-04 03:50:48][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 554/3058 [15:33<48:33,  1.16s/it][2025-02-04 03:50:49][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 555/3058 [15:34<42:15,  1.01s/it][2025-02-04 03:50:50][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 556/3058 [15:35<44:04,  1.06s/it][2025-02-04 03:50:51][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 557/3058 [15:36<45:22,  1.09s/it][2025-02-04 03:50:52][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 558/3058 [15:37<50:47,  1.22s/it][2025-02-04 03:50:54][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 559/3058 [15:39<50:17,  1.21s/it][2025-02-04 03:50:55][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 560/3058 [15:40<53:27,  1.28s/it][2025-02-04 03:50:56][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 561/3058 [15:42<55:55,  1.34s/it][2025-02-04 03:50:58][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 562/3058 [15:44<1:08:10,  1.64s/it][2025-02-04 03:51:00][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 563/3058 [15:45<1:04:47,  1.56s/it][2025-02-04 03:51:02][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 564/3058 [15:47<1:04:29,  1.55s/it][2025-02-04 03:51:03][slam_llm.models.slam_model][INFO] - modality encoder
 18%|█▊        | 565/3058 [15:48<56:53,  1.37s/it]  [2025-02-04 03:51:04][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▊        | 566/3058 [15:49<52:27,  1.26s/it][2025-02-04 03:51:05][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▊        | 567/3058 [15:51<1:01:05,  1.47s/it][2025-02-04 03:51:07][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▊        | 568/3058 [15:53<1:07:17,  1.62s/it][2025-02-04 03:51:09][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▊        | 569/3058 [15:54<1:04:18,  1.55s/it][2025-02-04 03:51:10][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▊        | 570/3058 [15:55<1:00:57,  1.47s/it][2025-02-04 03:51:11][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▊        | 571/3058 [15:57<1:00:13,  1.45s/it][2025-02-04 03:51:13][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▊        | 572/3058 [15:58<1:01:48,  1.49s/it][2025-02-04 03:51:15][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▊        | 573/3058 [16:01<1:20:38,  1.95s/it][2025-02-04 03:51:18][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 574/3058 [16:04<1:33:30,  2.26s/it][2025-02-04 03:51:21][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 575/3058 [16:07<1:35:28,  2.31s/it][2025-02-04 03:51:23][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 576/3058 [16:09<1:30:47,  2.19s/it][2025-02-04 03:51:25][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 577/3058 [16:10<1:21:04,  1.96s/it][2025-02-04 03:51:26][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 578/3058 [16:12<1:24:26,  2.04s/it][2025-02-04 03:51:28][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 579/3058 [16:13<1:07:32,  1.63s/it][2025-02-04 03:51:29][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 580/3058 [16:14<59:07,  1.43s/it]  [2025-02-04 03:51:30][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 581/3058 [16:15<1:00:40,  1.47s/it][2025-02-04 03:51:32][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 582/3058 [16:17<56:57,  1.38s/it]  [2025-02-04 03:51:33][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 583/3058 [16:19<1:07:53,  1.65s/it][2025-02-04 03:51:36][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 584/3058 [16:22<1:22:06,  1.99s/it][2025-02-04 03:51:38][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 585/3058 [16:24<1:26:36,  2.10s/it][2025-02-04 03:51:40][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 586/3058 [16:25<1:10:01,  1.70s/it][2025-02-04 03:51:41][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 587/3058 [16:27<1:17:06,  1.87s/it][2025-02-04 03:51:43][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 588/3058 [16:28<1:10:56,  1.72s/it][2025-02-04 03:51:45][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 589/3058 [16:30<1:06:18,  1.61s/it][2025-02-04 03:51:46][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 590/3058 [16:32<1:11:30,  1.74s/it][2025-02-04 03:51:48][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 591/3058 [16:32<57:35,  1.40s/it]  [2025-02-04 03:51:49][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 592/3058 [16:34<52:57,  1.29s/it][2025-02-04 03:51:50][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 593/3058 [16:35<50:15,  1.22s/it][2025-02-04 03:51:51][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 594/3058 [16:36<49:05,  1.20s/it][2025-02-04 03:51:52][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 595/3058 [16:37<51:50,  1.26s/it][2025-02-04 03:51:53][slam_llm.models.slam_model][INFO] - modality encoder
 19%|█▉        | 596/3058 [16:38<46:10,  1.13s/it][2025-02-04 03:51:54][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 597/3058 [16:39<50:47,  1.24s/it][2025-02-04 03:51:56][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 598/3058 [16:40<46:46,  1.14s/it][2025-02-04 03:51:57][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 599/3058 [16:42<50:06,  1.22s/it][2025-02-04 03:51:58][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 600/3058 [16:43<45:06,  1.10s/it][2025-02-04 03:51:59][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 601/3058 [16:44<43:53,  1.07s/it][2025-02-04 03:52:00][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 602/3058 [16:45<52:15,  1.28s/it][2025-02-04 03:52:02][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 603/3058 [16:47<52:51,  1.29s/it][2025-02-04 03:52:03][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 604/3058 [16:49<1:06:20,  1.62s/it][2025-02-04 03:52:05][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 605/3058 [16:51<1:12:07,  1.76s/it][2025-02-04 03:52:07][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 606/3058 [16:52<1:04:51,  1.59s/it][2025-02-04 03:52:09][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 607/3058 [16:54<1:04:23,  1.58s/it][2025-02-04 03:52:10][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 608/3058 [16:55<1:03:03,  1.54s/it][2025-02-04 03:52:12][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 609/3058 [16:57<59:35,  1.46s/it]  [2025-02-04 03:52:13][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 610/3058 [16:58<55:05,  1.35s/it][2025-02-04 03:52:14][slam_llm.models.slam_model][INFO] - modality encoder
 20%|█▉        | 611/3058 [16:59<50:12,  1.23s/it][2025-02-04 03:52:15][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 612/3058 [17:00<46:33,  1.14s/it][2025-02-04 03:52:16][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 613/3058 [17:01<53:22,  1.31s/it][2025-02-04 03:52:17][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 614/3058 [17:03<53:00,  1.30s/it][2025-02-04 03:52:19][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 615/3058 [17:04<58:17,  1.43s/it][2025-02-04 03:52:20][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 616/3058 [17:06<1:06:54,  1.64s/it][2025-02-04 03:52:23][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 617/3058 [17:08<1:00:40,  1.49s/it][2025-02-04 03:52:24][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 618/3058 [17:09<1:04:55,  1.60s/it][2025-02-04 03:52:26][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 619/3058 [17:11<1:01:18,  1.51s/it][2025-02-04 03:52:27][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 620/3058 [17:12<1:01:27,  1.51s/it][2025-02-04 03:52:28][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 621/3058 [17:14<1:07:46,  1.67s/it][2025-02-04 03:52:30][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 622/3058 [17:17<1:24:57,  2.09s/it][2025-02-04 03:52:34][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 623/3058 [17:19<1:15:21,  1.86s/it][2025-02-04 03:52:35][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 624/3058 [17:20<1:06:55,  1.65s/it][2025-02-04 03:52:36][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 625/3058 [17:21<1:05:42,  1.62s/it][2025-02-04 03:52:38][slam_llm.models.slam_model][INFO] - modality encoder
 20%|██        | 626/3058 [17:24<1:12:21,  1.79s/it][2025-02-04 03:52:40][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 627/3058 [17:26<1:18:01,  1.93s/it][2025-02-04 03:52:42][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 628/3058 [17:28<1:23:38,  2.07s/it][2025-02-04 03:52:44][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 629/3058 [17:30<1:17:29,  1.91s/it][2025-02-04 03:52:46][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 630/3058 [17:31<1:05:01,  1.61s/it][2025-02-04 03:52:47][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 631/3058 [17:32<59:23,  1.47s/it]  [2025-02-04 03:52:48][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 632/3058 [17:33<56:36,  1.40s/it][2025-02-04 03:52:49][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 633/3058 [17:34<57:02,  1.41s/it][2025-02-04 03:52:51][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 634/3058 [17:36<1:02:24,  1.54s/it][2025-02-04 03:52:53][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 635/3058 [17:38<1:06:11,  1.64s/it][2025-02-04 03:52:54][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 636/3058 [17:39<1:01:08,  1.51s/it][2025-02-04 03:52:56][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 637/3058 [17:41<1:07:12,  1.67s/it][2025-02-04 03:52:58][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 638/3058 [17:43<1:09:55,  1.73s/it][2025-02-04 03:53:00][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 639/3058 [17:46<1:19:51,  1.98s/it][2025-02-04 03:53:02][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 640/3058 [17:48<1:25:40,  2.13s/it][2025-02-04 03:53:04][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 641/3058 [17:49<1:10:00,  1.74s/it][2025-02-04 03:53:05][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 642/3058 [17:50<1:03:34,  1.58s/it][2025-02-04 03:53:06][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 643/3058 [17:51<52:30,  1.30s/it]  [2025-02-04 03:53:07][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 644/3058 [17:52<49:43,  1.24s/it][2025-02-04 03:53:08][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 645/3058 [17:53<45:45,  1.14s/it][2025-02-04 03:53:09][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 646/3058 [17:55<56:25,  1.40s/it][2025-02-04 03:53:11][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 647/3058 [17:57<1:08:03,  1.69s/it][2025-02-04 03:53:14][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 648/3058 [17:59<1:04:44,  1.61s/it][2025-02-04 03:53:15][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██        | 649/3058 [18:00<1:01:44,  1.54s/it][2025-02-04 03:53:16][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██▏       | 650/3058 [18:01<55:55,  1.39s/it]  [2025-02-04 03:53:17][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██▏       | 651/3058 [18:02<50:50,  1.27s/it][2025-02-04 03:53:18][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██▏       | 652/3058 [18:03<45:02,  1.12s/it][2025-02-04 03:53:19][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██▏       | 653/3058 [18:04<44:49,  1.12s/it][2025-02-04 03:53:20][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██▏       | 654/3058 [18:05<44:48,  1.12s/it][2025-02-04 03:53:21][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██▏       | 655/3058 [18:07<53:10,  1.33s/it][2025-02-04 03:53:23][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██▏       | 656/3058 [18:08<53:54,  1.35s/it][2025-02-04 03:53:25][slam_llm.models.slam_model][INFO] - modality encoder
 21%|██▏       | 657/3058 [18:10<55:05,  1.38s/it][2025-02-04 03:53:26][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 658/3058 [18:12<1:00:58,  1.52s/it][2025-02-04 03:53:28][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 659/3058 [18:13<56:14,  1.41s/it]  [2025-02-04 03:53:29][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 660/3058 [18:16<1:13:31,  1.84s/it][2025-02-04 03:53:32][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 661/3058 [18:18<1:15:30,  1.89s/it][2025-02-04 03:53:34][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 662/3058 [18:19<1:07:06,  1.68s/it][2025-02-04 03:53:35][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 663/3058 [18:20<1:04:37,  1.62s/it][2025-02-04 03:53:37][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 664/3058 [18:22<1:01:40,  1.55s/it][2025-02-04 03:53:38][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 665/3058 [18:23<57:34,  1.44s/it]  [2025-02-04 03:53:39][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 666/3058 [18:25<1:03:42,  1.60s/it][2025-02-04 03:53:41][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 667/3058 [18:26<1:01:10,  1.54s/it][2025-02-04 03:53:42][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 668/3058 [18:27<53:09,  1.33s/it]  [2025-02-04 03:53:43][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 669/3058 [18:29<52:55,  1.33s/it][2025-02-04 03:53:45][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 670/3058 [18:30<56:01,  1.41s/it][2025-02-04 03:53:46][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 671/3058 [18:32<1:07:13,  1.69s/it][2025-02-04 03:53:49][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 672/3058 [18:35<1:17:23,  1.95s/it][2025-02-04 03:53:51][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 673/3058 [18:37<1:13:08,  1.84s/it][2025-02-04 03:53:53][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 674/3058 [18:38<1:08:34,  1.73s/it][2025-02-04 03:53:54][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 675/3058 [18:40<1:05:12,  1.64s/it][2025-02-04 03:53:56][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 676/3058 [18:41<1:01:11,  1.54s/it][2025-02-04 03:53:57][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 677/3058 [18:42<54:59,  1.39s/it]  [2025-02-04 03:53:58][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 678/3058 [18:43<55:39,  1.40s/it][2025-02-04 03:53:59][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 679/3058 [18:44<49:50,  1.26s/it][2025-02-04 03:54:00][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 680/3058 [18:46<50:54,  1.28s/it][2025-02-04 03:54:02][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 681/3058 [18:47<46:44,  1.18s/it][2025-02-04 03:54:03][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 682/3058 [18:48<52:24,  1.32s/it][2025-02-04 03:54:04][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 683/3058 [18:49<47:52,  1.21s/it][2025-02-04 03:54:05][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 684/3058 [18:50<44:24,  1.12s/it][2025-02-04 03:54:06][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 685/3058 [18:51<44:04,  1.11s/it][2025-02-04 03:54:07][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 686/3058 [18:52<44:44,  1.13s/it][2025-02-04 03:54:09][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 687/3058 [18:54<54:26,  1.38s/it][2025-02-04 03:54:10][slam_llm.models.slam_model][INFO] - modality encoder
 22%|██▏       | 688/3058 [18:55<48:23,  1.23s/it][2025-02-04 03:54:11][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 689/3058 [18:56<46:52,  1.19s/it][2025-02-04 03:54:12][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 690/3058 [18:57<46:20,  1.17s/it][2025-02-04 03:54:14][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 691/3058 [18:59<54:25,  1.38s/it][2025-02-04 03:54:15][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 692/3058 [19:00<49:33,  1.26s/it][2025-02-04 03:54:16][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 693/3058 [19:01<43:32,  1.10s/it][2025-02-04 03:54:17][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 694/3058 [19:02<39:34,  1.00s/it][2025-02-04 03:54:18][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 695/3058 [19:02<33:58,  1.16it/s][2025-02-04 03:54:18][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 696/3058 [19:04<43:28,  1.10s/it][2025-02-04 03:54:20][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 697/3058 [19:06<51:55,  1.32s/it][2025-02-04 03:54:22][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 698/3058 [19:07<52:48,  1.34s/it][2025-02-04 03:54:23][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 699/3058 [19:08<43:54,  1.12s/it][2025-02-04 03:54:24][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 700/3058 [19:10<59:55,  1.52s/it][2025-02-04 03:54:26][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 701/3058 [19:11<55:02,  1.40s/it][2025-02-04 03:54:27][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 702/3058 [19:13<55:23,  1.41s/it][2025-02-04 03:54:29][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 703/3058 [19:15<1:07:43,  1.73s/it][2025-02-04 03:54:31][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 704/3058 [19:16<54:57,  1.40s/it]  [2025-02-04 03:54:32][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 705/3058 [19:17<48:45,  1.24s/it][2025-02-04 03:54:33][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 706/3058 [19:18<50:05,  1.28s/it][2025-02-04 03:54:34][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 707/3058 [19:19<47:15,  1.21s/it][2025-02-04 03:54:35][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 708/3058 [19:21<55:08,  1.41s/it][2025-02-04 03:54:37][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 709/3058 [19:22<48:40,  1.24s/it][2025-02-04 03:54:38][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 710/3058 [19:23<45:17,  1.16s/it][2025-02-04 03:54:39][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 711/3058 [19:24<40:48,  1.04s/it][2025-02-04 03:54:40][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 712/3058 [19:25<43:49,  1.12s/it][2025-02-04 03:54:41][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 713/3058 [19:26<42:47,  1.09s/it][2025-02-04 03:54:42][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 714/3058 [19:27<38:31,  1.01it/s][2025-02-04 03:54:43][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 715/3058 [19:28<40:43,  1.04s/it][2025-02-04 03:54:44][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 716/3058 [19:29<37:36,  1.04it/s][2025-02-04 03:54:45][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 717/3058 [19:30<40:39,  1.04s/it][2025-02-04 03:54:46][slam_llm.models.slam_model][INFO] - modality encoder
 23%|██▎       | 718/3058 [19:31<46:46,  1.20s/it][2025-02-04 03:54:48][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▎       | 719/3058 [19:32<45:26,  1.17s/it][2025-02-04 03:54:49][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▎       | 720/3058 [19:33<40:55,  1.05s/it][2025-02-04 03:54:49][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▎       | 721/3058 [19:34<36:51,  1.06it/s][2025-02-04 03:54:50][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▎       | 722/3058 [19:35<33:55,  1.15it/s][2025-02-04 03:54:51][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▎       | 723/3058 [19:36<37:41,  1.03it/s][2025-02-04 03:54:52][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▎       | 724/3058 [19:36<33:20,  1.17it/s][2025-02-04 03:54:53][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▎       | 725/3058 [19:38<36:16,  1.07it/s][2025-02-04 03:54:54][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▎       | 726/3058 [19:38<36:03,  1.08it/s][2025-02-04 03:54:55][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 727/3058 [19:39<34:20,  1.13it/s][2025-02-04 03:54:55][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 728/3058 [19:40<37:12,  1.04it/s][2025-02-04 03:54:57][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 729/3058 [19:42<39:21,  1.01s/it][2025-02-04 03:54:58][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 730/3058 [19:42<34:31,  1.12it/s][2025-02-04 03:54:58][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 731/3058 [19:43<38:09,  1.02it/s][2025-02-04 03:54:59][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 732/3058 [19:44<33:11,  1.17it/s][2025-02-04 03:55:00][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 733/3058 [19:45<39:14,  1.01s/it][2025-02-04 03:55:01][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 734/3058 [19:46<39:34,  1.02s/it][2025-02-04 03:55:03][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 735/3058 [19:48<47:49,  1.24s/it][2025-02-04 03:55:04][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 736/3058 [19:49<45:45,  1.18s/it][2025-02-04 03:55:05][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 737/3058 [19:51<54:03,  1.40s/it][2025-02-04 03:55:07][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 738/3058 [19:52<50:47,  1.31s/it][2025-02-04 03:55:08][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 739/3058 [19:54<52:52,  1.37s/it][2025-02-04 03:55:10][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 740/3058 [19:55<53:23,  1.38s/it][2025-02-04 03:55:11][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 741/3058 [19:56<46:26,  1.20s/it][2025-02-04 03:55:12][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 742/3058 [19:57<48:44,  1.26s/it][2025-02-04 03:55:13][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 743/3058 [19:58<44:01,  1.14s/it][2025-02-04 03:55:14][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 744/3058 [19:59<42:11,  1.09s/it][2025-02-04 03:55:15][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 745/3058 [20:00<38:49,  1.01s/it][2025-02-04 03:55:16][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 746/3058 [20:00<33:18,  1.16it/s][2025-02-04 03:55:17][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 747/3058 [20:02<37:52,  1.02it/s][2025-02-04 03:55:18][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 748/3058 [20:02<35:16,  1.09it/s][2025-02-04 03:55:19][slam_llm.models.slam_model][INFO] - modality encoder
 24%|██▍       | 749/3058 [20:03<36:04,  1.07it/s][2025-02-04 03:55:20][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 750/3058 [20:04<35:55,  1.07it/s][2025-02-04 03:55:20][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 751/3058 [20:05<37:50,  1.02it/s][2025-02-04 03:55:22][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 752/3058 [20:07<40:45,  1.06s/it][2025-02-04 03:55:23][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 753/3058 [20:07<34:29,  1.11it/s][2025-02-04 03:55:23][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 754/3058 [20:08<35:17,  1.09it/s][2025-02-04 03:55:25][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 755/3058 [20:10<40:50,  1.06s/it][2025-02-04 03:55:26][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 756/3058 [20:12<51:38,  1.35s/it][2025-02-04 03:55:28][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 757/3058 [20:13<52:26,  1.37s/it][2025-02-04 03:55:30][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 758/3058 [20:16<1:06:08,  1.73s/it][2025-02-04 03:55:32][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 759/3058 [20:17<1:06:36,  1.74s/it][2025-02-04 03:55:34][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 760/3058 [20:19<1:08:26,  1.79s/it][2025-02-04 03:55:35][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 761/3058 [20:21<1:05:34,  1.71s/it][2025-02-04 03:55:37][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 762/3058 [20:22<1:00:14,  1.57s/it][2025-02-04 03:55:38][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 763/3058 [20:24<1:01:13,  1.60s/it][2025-02-04 03:55:40][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▍       | 764/3058 [20:26<1:05:45,  1.72s/it][2025-02-04 03:55:42][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 765/3058 [20:28<1:16:58,  2.01s/it][2025-02-04 03:55:45][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 766/3058 [20:31<1:26:49,  2.27s/it][2025-02-04 03:55:48][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 767/3058 [20:33<1:22:16,  2.15s/it][2025-02-04 03:55:50][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 768/3058 [20:35<1:22:04,  2.15s/it][2025-02-04 03:55:52][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 769/3058 [20:37<1:17:29,  2.03s/it][2025-02-04 03:55:53][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 770/3058 [20:39<1:15:14,  1.97s/it][2025-02-04 03:55:55][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 771/3058 [20:40<1:08:39,  1.80s/it][2025-02-04 03:55:57][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 772/3058 [20:43<1:15:53,  1.99s/it][2025-02-04 03:55:59][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 773/3058 [20:46<1:30:27,  2.38s/it][2025-02-04 03:56:03][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 774/3058 [20:48<1:29:15,  2.34s/it][2025-02-04 03:56:05][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 775/3058 [20:51<1:29:01,  2.34s/it][2025-02-04 03:56:07][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 776/3058 [20:53<1:31:11,  2.40s/it][2025-02-04 03:56:10][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 777/3058 [20:55<1:26:00,  2.26s/it][2025-02-04 03:56:12][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 778/3058 [20:57<1:19:16,  2.09s/it][2025-02-04 03:56:13][slam_llm.models.slam_model][INFO] - modality encoder
 25%|██▌       | 779/3058 [20:59<1:18:55,  2.08s/it][2025-02-04 03:56:15][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 780/3058 [21:01<1:16:03,  2.00s/it][2025-02-04 03:56:17][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 781/3058 [21:03<1:18:56,  2.08s/it][2025-02-04 03:56:19][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 782/3058 [21:05<1:23:28,  2.20s/it][2025-02-04 03:56:22][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 783/3058 [21:07<1:17:23,  2.04s/it][2025-02-04 03:56:24][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 784/3058 [21:10<1:26:17,  2.28s/it][2025-02-04 03:56:27][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 785/3058 [21:12<1:28:01,  2.32s/it][2025-02-04 03:56:28][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 786/3058 [21:14<1:18:39,  2.08s/it][2025-02-04 03:56:30][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 787/3058 [21:15<1:07:31,  1.78s/it][2025-02-04 03:56:31][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 788/3058 [21:16<59:59,  1.59s/it]  [2025-02-04 03:56:32][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 789/3058 [21:18<1:04:46,  1.71s/it][2025-02-04 03:56:35][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 790/3058 [21:21<1:15:35,  2.00s/it][2025-02-04 03:56:37][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 791/3058 [21:23<1:16:35,  2.03s/it][2025-02-04 03:56:39][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 792/3058 [21:24<1:13:01,  1.93s/it][2025-02-04 03:56:41][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 793/3058 [21:26<1:06:24,  1.76s/it][2025-02-04 03:56:42][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 794/3058 [21:28<1:06:51,  1.77s/it][2025-02-04 03:56:44][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 795/3058 [21:29<1:03:09,  1.67s/it][2025-02-04 03:56:45][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 796/3058 [21:31<1:04:26,  1.71s/it][2025-02-04 03:56:47][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 797/3058 [21:33<1:05:39,  1.74s/it][2025-02-04 03:56:49][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 798/3058 [21:34<57:45,  1.53s/it]  [2025-02-04 03:56:50][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 799/3058 [21:36<1:01:34,  1.64s/it][2025-02-04 03:56:52][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 800/3058 [21:36<51:17,  1.36s/it]  [2025-02-04 03:56:53][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 801/3058 [21:38<54:34,  1.45s/it][2025-02-04 03:56:54][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▌       | 802/3058 [21:39<54:09,  1.44s/it][2025-02-04 03:56:56][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▋       | 803/3058 [21:41<53:10,  1.41s/it][2025-02-04 03:56:57][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▋       | 804/3058 [21:44<1:17:16,  2.06s/it][2025-02-04 03:57:01][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▋       | 805/3058 [21:46<1:15:04,  2.00s/it][2025-02-04 03:57:02][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▋       | 806/3058 [21:48<1:10:07,  1.87s/it][2025-02-04 03:57:04][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▋       | 807/3058 [21:49<1:08:03,  1.81s/it][2025-02-04 03:57:06][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▋       | 808/3058 [21:52<1:15:30,  2.01s/it][2025-02-04 03:57:08][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▋       | 809/3058 [21:54<1:15:39,  2.02s/it][2025-02-04 03:57:10][slam_llm.models.slam_model][INFO] - modality encoder
 26%|██▋       | 810/3058 [21:56<1:17:20,  2.06s/it][2025-02-04 03:57:12][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 811/3058 [21:58<1:16:51,  2.05s/it][2025-02-04 03:57:14][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 812/3058 [21:59<1:06:51,  1.79s/it][2025-02-04 03:57:15][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 813/3058 [22:01<1:05:43,  1.76s/it][2025-02-04 03:57:17][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 814/3058 [22:03<1:04:44,  1.73s/it][2025-02-04 03:57:19][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 815/3058 [22:05<1:15:14,  2.01s/it][2025-02-04 03:57:22][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 816/3058 [22:07<1:13:34,  1.97s/it][2025-02-04 03:57:23][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 817/3058 [22:09<1:12:14,  1.93s/it][2025-02-04 03:57:25][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 818/3058 [22:11<1:11:18,  1.91s/it][2025-02-04 03:57:27][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 819/3058 [22:13<1:15:54,  2.03s/it][2025-02-04 03:57:29][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 820/3058 [22:15<1:09:45,  1.87s/it][2025-02-04 03:57:31][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 821/3058 [22:17<1:12:37,  1.95s/it][2025-02-04 03:57:34][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 822/3058 [22:20<1:25:42,  2.30s/it][2025-02-04 03:57:36][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 823/3058 [22:23<1:28:26,  2.37s/it][2025-02-04 03:57:39][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 824/3058 [22:25<1:27:43,  2.36s/it][2025-02-04 03:57:41][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 825/3058 [22:26<1:14:40,  2.01s/it][2025-02-04 03:57:42][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 826/3058 [22:30<1:31:03,  2.45s/it][2025-02-04 03:57:46][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 827/3058 [22:31<1:24:57,  2.28s/it][2025-02-04 03:57:48][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 828/3058 [22:33<1:11:48,  1.93s/it][2025-02-04 03:57:49][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 829/3058 [22:33<1:00:04,  1.62s/it][2025-02-04 03:57:50][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 830/3058 [22:35<1:02:03,  1.67s/it][2025-02-04 03:57:51][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 831/3058 [22:36<49:47,  1.34s/it]  [2025-02-04 03:57:52][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 832/3058 [22:38<57:52,  1.56s/it][2025-02-04 03:57:54][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 833/3058 [22:39<57:32,  1.55s/it][2025-02-04 03:57:55][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 834/3058 [22:40<52:27,  1.42s/it][2025-02-04 03:57:57][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 835/3058 [22:42<54:16,  1.47s/it][2025-02-04 03:57:58][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 836/3058 [22:43<47:34,  1.28s/it][2025-02-04 03:57:59][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 837/3058 [22:44<44:28,  1.20s/it][2025-02-04 03:58:00][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 838/3058 [22:46<49:13,  1.33s/it][2025-02-04 03:58:02][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 839/3058 [22:47<48:54,  1.32s/it][2025-02-04 03:58:03][slam_llm.models.slam_model][INFO] - modality encoder
 27%|██▋       | 840/3058 [22:49<55:38,  1.51s/it][2025-02-04 03:58:05][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 841/3058 [22:50<48:17,  1.31s/it][2025-02-04 03:58:06][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 842/3058 [22:56<1:42:44,  2.78s/it][2025-02-04 03:58:12][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 843/3058 [22:58<1:30:49,  2.46s/it][2025-02-04 03:58:14][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 844/3058 [22:59<1:21:35,  2.21s/it][2025-02-04 03:58:15][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 845/3058 [23:01<1:12:49,  1.97s/it][2025-02-04 03:58:17][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 846/3058 [23:02<1:06:36,  1.81s/it][2025-02-04 03:58:18][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 847/3058 [23:03<57:50,  1.57s/it]  [2025-02-04 03:58:19][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 848/3058 [23:06<1:10:00,  1.90s/it][2025-02-04 03:58:22][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 849/3058 [23:07<1:00:43,  1.65s/it][2025-02-04 03:58:23][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 850/3058 [23:09<1:05:47,  1.79s/it][2025-02-04 03:58:25][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 851/3058 [23:10<58:48,  1.60s/it]  [2025-02-04 03:58:26][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 852/3058 [23:11<56:27,  1.54s/it][2025-02-04 03:58:28][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 853/3058 [23:14<1:04:03,  1.74s/it][2025-02-04 03:58:30][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 854/3058 [23:15<56:49,  1.55s/it]  [2025-02-04 03:58:31][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 855/3058 [23:17<1:03:05,  1.72s/it][2025-02-04 03:58:33][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 856/3058 [23:19<1:04:42,  1.76s/it][2025-02-04 03:58:35][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 857/3058 [23:20<59:48,  1.63s/it]  [2025-02-04 03:58:36][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 858/3058 [23:22<1:08:10,  1.86s/it][2025-02-04 03:58:39][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 859/3058 [23:25<1:13:59,  2.02s/it][2025-02-04 03:58:41][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 860/3058 [23:26<1:00:09,  1.64s/it][2025-02-04 03:58:42][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 861/3058 [23:27<57:52,  1.58s/it]  [2025-02-04 03:58:43][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 862/3058 [23:29<1:05:45,  1.80s/it][2025-02-04 03:58:46][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 863/3058 [23:31<59:49,  1.64s/it]  [2025-02-04 03:58:47][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 864/3058 [23:32<57:14,  1.57s/it][2025-02-04 03:58:48][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 865/3058 [23:33<51:35,  1.41s/it][2025-02-04 03:58:49][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 866/3058 [23:35<56:39,  1.55s/it][2025-02-04 03:58:51][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 867/3058 [23:37<1:01:23,  1.68s/it][2025-02-04 03:58:53][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 868/3058 [23:38<55:48,  1.53s/it]  [2025-02-04 03:58:54][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 869/3058 [23:40<1:02:45,  1.72s/it][2025-02-04 03:58:56][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 870/3058 [23:42<1:00:50,  1.67s/it][2025-02-04 03:58:58][slam_llm.models.slam_model][INFO] - modality encoder
 28%|██▊       | 871/3058 [23:43<59:47,  1.64s/it]  [2025-02-04 03:59:00][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▊       | 872/3058 [23:45<58:33,  1.61s/it][2025-02-04 03:59:01][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▊       | 873/3058 [23:46<52:30,  1.44s/it][2025-02-04 03:59:02][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▊       | 874/3058 [23:47<45:12,  1.24s/it][2025-02-04 03:59:03][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▊       | 875/3058 [23:48<47:58,  1.32s/it][2025-02-04 03:59:04][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▊       | 876/3058 [23:50<47:59,  1.32s/it][2025-02-04 03:59:06][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▊       | 877/3058 [23:53<1:08:16,  1.88s/it][2025-02-04 03:59:09][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▊       | 878/3058 [23:55<1:12:06,  1.98s/it][2025-02-04 03:59:11][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▊       | 879/3058 [23:57<1:07:12,  1.85s/it][2025-02-04 03:59:13][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 880/3058 [23:58<57:31,  1.58s/it]  [2025-02-04 03:59:14][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 881/3058 [23:59<56:42,  1.56s/it][2025-02-04 03:59:15][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 882/3058 [24:02<1:06:46,  1.84s/it][2025-02-04 03:59:18][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 883/3058 [24:04<1:13:09,  2.02s/it][2025-02-04 03:59:20][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 884/3058 [24:07<1:22:49,  2.29s/it][2025-02-04 03:59:23][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 885/3058 [24:10<1:33:17,  2.58s/it][2025-02-04 03:59:26][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 886/3058 [24:13<1:34:02,  2.60s/it][2025-02-04 03:59:29][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 887/3058 [24:15<1:28:46,  2.45s/it][2025-02-04 03:59:31][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 888/3058 [24:17<1:22:56,  2.29s/it][2025-02-04 03:59:33][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 889/3058 [24:19<1:24:55,  2.35s/it][2025-02-04 03:59:35][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 890/3058 [24:21<1:21:13,  2.25s/it][2025-02-04 03:59:38][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 891/3058 [24:23<1:18:08,  2.16s/it][2025-02-04 03:59:39][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 892/3058 [24:25<1:13:10,  2.03s/it][2025-02-04 03:59:41][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 893/3058 [24:27<1:11:26,  1.98s/it][2025-02-04 03:59:43][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 894/3058 [24:28<1:07:42,  1.88s/it][2025-02-04 03:59:45][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 895/3058 [24:30<1:01:33,  1.71s/it][2025-02-04 03:59:46][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 896/3058 [24:33<1:13:14,  2.03s/it][2025-02-04 03:59:49][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 897/3058 [24:35<1:12:56,  2.03s/it][2025-02-04 03:59:51][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 898/3058 [24:37<1:16:25,  2.12s/it][2025-02-04 03:59:53][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 899/3058 [24:40<1:28:09,  2.45s/it][2025-02-04 03:59:56][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 900/3058 [24:42<1:16:53,  2.14s/it][2025-02-04 03:59:58][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 901/3058 [24:45<1:26:37,  2.41s/it][2025-02-04 04:00:01][slam_llm.models.slam_model][INFO] - modality encoder
 29%|██▉       | 902/3058 [24:46<1:17:40,  2.16s/it][2025-02-04 04:00:02][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 903/3058 [24:47<1:02:43,  1.75s/it][2025-02-04 04:00:03][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 904/3058 [24:48<56:45,  1.58s/it]  [2025-02-04 04:00:04][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 905/3058 [24:50<1:00:04,  1.67s/it][2025-02-04 04:00:06][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 906/3058 [24:52<1:04:58,  1.81s/it][2025-02-04 04:00:08][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 907/3058 [24:54<1:00:40,  1.69s/it][2025-02-04 04:00:10][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 908/3058 [24:55<55:06,  1.54s/it]  [2025-02-04 04:00:11][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 909/3058 [24:57<1:06:27,  1.86s/it][2025-02-04 04:00:14][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 910/3058 [24:59<1:06:47,  1.87s/it][2025-02-04 04:00:16][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 911/3058 [25:01<1:10:51,  1.98s/it][2025-02-04 04:00:18][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 912/3058 [25:03<1:02:08,  1.74s/it][2025-02-04 04:00:19][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 913/3058 [25:09<1:50:07,  3.08s/it][2025-02-04 04:00:25][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 914/3058 [25:12<1:54:25,  3.20s/it][2025-02-04 04:00:29][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 915/3058 [25:14<1:33:57,  2.63s/it][2025-02-04 04:00:30][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 916/3058 [25:17<1:40:32,  2.82s/it][2025-02-04 04:00:33][slam_llm.models.slam_model][INFO] - modality encoder
 30%|██▉       | 917/3058 [25:20<1:42:49,  2.88s/it][2025-02-04 04:00:36][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 918/3058 [25:25<2:10:33,  3.66s/it][2025-02-04 04:00:42][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 919/3058 [25:29<2:11:33,  3.69s/it][2025-02-04 04:00:45][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 920/3058 [25:32<2:01:32,  3.41s/it][2025-02-04 04:00:48][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 921/3058 [25:33<1:40:36,  2.82s/it][2025-02-04 04:00:49][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 922/3058 [25:34<1:21:46,  2.30s/it][2025-02-04 04:00:51][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 923/3058 [25:36<1:16:48,  2.16s/it][2025-02-04 04:00:52][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 924/3058 [25:39<1:20:13,  2.26s/it][2025-02-04 04:00:55][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 925/3058 [25:41<1:21:29,  2.29s/it][2025-02-04 04:00:57][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 926/3058 [25:43<1:18:47,  2.22s/it][2025-02-04 04:00:59][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 927/3058 [25:45<1:17:26,  2.18s/it][2025-02-04 04:01:01][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 928/3058 [25:47<1:10:10,  1.98s/it][2025-02-04 04:01:03][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 929/3058 [25:49<1:09:48,  1.97s/it][2025-02-04 04:01:05][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 930/3058 [25:53<1:29:03,  2.51s/it][2025-02-04 04:01:09][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 931/3058 [25:55<1:29:04,  2.51s/it][2025-02-04 04:01:11][slam_llm.models.slam_model][INFO] - modality encoder
 30%|███       | 932/3058 [25:56<1:17:51,  2.20s/it][2025-02-04 04:01:13][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 933/3058 [25:58<1:14:22,  2.10s/it][2025-02-04 04:01:14][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 934/3058 [26:00<1:07:38,  1.91s/it][2025-02-04 04:01:16][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 935/3058 [26:01<1:03:35,  1.80s/it][2025-02-04 04:01:18][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 936/3058 [26:05<1:21:14,  2.30s/it][2025-02-04 04:01:21][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 937/3058 [26:07<1:15:09,  2.13s/it][2025-02-04 04:01:23][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 938/3058 [26:08<1:09:55,  1.98s/it][2025-02-04 04:01:24][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 939/3058 [26:10<1:02:42,  1.78s/it][2025-02-04 04:01:26][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 940/3058 [26:11<1:01:24,  1.74s/it][2025-02-04 04:01:27][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 941/3058 [26:13<58:25,  1.66s/it]  [2025-02-04 04:01:29][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 942/3058 [26:14<55:43,  1.58s/it][2025-02-04 04:01:30][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 943/3058 [26:15<50:59,  1.45s/it][2025-02-04 04:01:31][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 944/3058 [26:16<43:06,  1.22s/it][2025-02-04 04:01:32][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 945/3058 [26:17<43:31,  1.24s/it][2025-02-04 04:01:33][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 946/3058 [26:19<53:46,  1.53s/it][2025-02-04 04:01:35][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 947/3058 [26:21<54:50,  1.56s/it][2025-02-04 04:01:37][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 948/3058 [26:23<59:43,  1.70s/it][2025-02-04 04:01:39][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 949/3058 [26:25<1:03:00,  1.79s/it][2025-02-04 04:01:41][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 950/3058 [26:26<53:58,  1.54s/it]  [2025-02-04 04:01:42][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 951/3058 [26:27<51:32,  1.47s/it][2025-02-04 04:01:43][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 952/3058 [26:28<47:07,  1.34s/it][2025-02-04 04:01:44][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 953/3058 [26:29<44:55,  1.28s/it][2025-02-04 04:01:46][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 954/3058 [26:31<48:15,  1.38s/it][2025-02-04 04:01:47][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███       | 955/3058 [26:32<41:11,  1.18s/it][2025-02-04 04:01:48][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███▏      | 956/3058 [26:33<40:37,  1.16s/it][2025-02-04 04:01:49][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███▏      | 957/3058 [26:35<50:53,  1.45s/it][2025-02-04 04:01:51][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███▏      | 958/3058 [26:36<47:20,  1.35s/it][2025-02-04 04:01:52][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███▏      | 959/3058 [26:37<42:44,  1.22s/it][2025-02-04 04:01:53][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███▏      | 960/3058 [26:38<37:10,  1.06s/it][2025-02-04 04:01:54][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███▏      | 961/3058 [26:39<36:41,  1.05s/it][2025-02-04 04:01:55][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███▏      | 962/3058 [26:40<40:53,  1.17s/it][2025-02-04 04:01:56][slam_llm.models.slam_model][INFO] - modality encoder
 31%|███▏      | 963/3058 [26:42<48:57,  1.40s/it][2025-02-04 04:01:58][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 964/3058 [26:44<53:22,  1.53s/it][2025-02-04 04:02:00][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 965/3058 [26:47<1:05:24,  1.88s/it][2025-02-04 04:02:03][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 966/3058 [26:50<1:17:57,  2.24s/it][2025-02-04 04:02:06][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 967/3058 [26:53<1:24:51,  2.43s/it][2025-02-04 04:02:09][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 968/3058 [26:54<1:09:10,  1.99s/it][2025-02-04 04:02:10][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 969/3058 [26:55<1:03:21,  1.82s/it][2025-02-04 04:02:11][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 970/3058 [27:00<1:36:43,  2.78s/it][2025-02-04 04:02:16][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 971/3058 [27:02<1:25:16,  2.45s/it][2025-02-04 04:02:18][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 972/3058 [27:03<1:13:36,  2.12s/it][2025-02-04 04:02:19][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 973/3058 [27:08<1:38:48,  2.84s/it][2025-02-04 04:02:24][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 974/3058 [27:09<1:24:17,  2.43s/it][2025-02-04 04:02:25][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 975/3058 [27:12<1:27:02,  2.51s/it][2025-02-04 04:02:28][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 976/3058 [27:13<1:09:00,  1.99s/it][2025-02-04 04:02:29][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 977/3058 [27:14<1:04:59,  1.87s/it][2025-02-04 04:02:30][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 978/3058 [27:16<1:08:42,  1.98s/it][2025-02-04 04:02:33][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 979/3058 [27:22<1:42:36,  2.96s/it][2025-02-04 04:02:38][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 980/3058 [27:24<1:39:13,  2.87s/it][2025-02-04 04:02:40][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 981/3058 [27:26<1:29:46,  2.59s/it][2025-02-04 04:02:42][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 982/3058 [27:27<1:15:59,  2.20s/it][2025-02-04 04:02:44][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 983/3058 [27:30<1:21:52,  2.37s/it][2025-02-04 04:02:46][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 984/3058 [27:32<1:12:52,  2.11s/it][2025-02-04 04:02:48][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 985/3058 [27:32<58:52,  1.70s/it]  [2025-02-04 04:02:49][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 986/3058 [27:34<52:37,  1.52s/it][2025-02-04 04:02:50][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 987/3058 [27:35<48:54,  1.42s/it][2025-02-04 04:02:51][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 988/3058 [27:37<54:19,  1.57s/it][2025-02-04 04:02:53][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 989/3058 [27:38<51:04,  1.48s/it][2025-02-04 04:02:54][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 990/3058 [27:43<1:28:47,  2.58s/it][2025-02-04 04:02:59][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 991/3058 [27:46<1:34:09,  2.73s/it][2025-02-04 04:03:02][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 992/3058 [27:48<1:27:02,  2.53s/it][2025-02-04 04:03:04][slam_llm.models.slam_model][INFO] - modality encoder
 32%|███▏      | 993/3058 [27:52<1:35:26,  2.77s/it][2025-02-04 04:03:08][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 994/3058 [27:53<1:22:51,  2.41s/it][2025-02-04 04:03:09][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 995/3058 [27:56<1:23:54,  2.44s/it][2025-02-04 04:03:12][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 996/3058 [27:57<1:13:07,  2.13s/it][2025-02-04 04:03:13][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 997/3058 [28:00<1:19:58,  2.33s/it][2025-02-04 04:03:16][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 998/3058 [28:02<1:16:07,  2.22s/it][2025-02-04 04:03:18][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 999/3058 [28:04<1:13:04,  2.13s/it][2025-02-04 04:03:20][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1000/3058 [28:06<1:17:34,  2.26s/it][2025-02-04 04:03:23][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1001/3058 [28:08<1:12:35,  2.12s/it][2025-02-04 04:03:24][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1002/3058 [28:12<1:31:03,  2.66s/it][2025-02-04 04:03:28][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1003/3058 [28:14<1:29:00,  2.60s/it][2025-02-04 04:03:31][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1004/3058 [28:18<1:37:45,  2.86s/it][2025-02-04 04:03:34][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1005/3058 [28:21<1:36:29,  2.82s/it][2025-02-04 04:03:37][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1006/3058 [28:24<1:36:36,  2.82s/it][2025-02-04 04:03:40][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1007/3058 [28:25<1:28:03,  2.58s/it][2025-02-04 04:03:42][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1008/3058 [28:31<2:00:13,  3.52s/it][2025-02-04 04:03:47][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1009/3058 [28:32<1:37:11,  2.85s/it][2025-02-04 04:03:49][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1010/3058 [28:34<1:28:30,  2.59s/it][2025-02-04 04:03:51][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1011/3058 [28:36<1:13:27,  2.15s/it][2025-02-04 04:03:52][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1012/3058 [28:37<1:03:26,  1.86s/it][2025-02-04 04:03:53][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1013/3058 [28:38<54:39,  1.60s/it]  [2025-02-04 04:03:54][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1014/3058 [28:39<49:50,  1.46s/it][2025-02-04 04:03:55][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1015/3058 [28:41<57:06,  1.68s/it][2025-02-04 04:03:57][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1016/3058 [28:42<49:57,  1.47s/it][2025-02-04 04:03:58][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1017/3058 [28:46<1:12:31,  2.13s/it][2025-02-04 04:04:02][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1018/3058 [28:49<1:28:03,  2.59s/it][2025-02-04 04:04:06][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1019/3058 [28:52<1:25:50,  2.53s/it][2025-02-04 04:04:08][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1020/3058 [28:56<1:40:57,  2.97s/it][2025-02-04 04:04:12][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1021/3058 [28:59<1:40:26,  2.96s/it][2025-02-04 04:04:15][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1022/3058 [29:03<1:56:21,  3.43s/it][2025-02-04 04:04:19][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1023/3058 [29:04<1:32:42,  2.73s/it][2025-02-04 04:04:21][slam_llm.models.slam_model][INFO] - modality encoder
 33%|███▎      | 1024/3058 [29:07<1:33:33,  2.76s/it][2025-02-04 04:04:23][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▎      | 1025/3058 [29:09<1:26:04,  2.54s/it][2025-02-04 04:04:25][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▎      | 1026/3058 [29:12<1:23:16,  2.46s/it][2025-02-04 04:04:28][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▎      | 1027/3058 [29:15<1:38:14,  2.90s/it][2025-02-04 04:04:32][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▎      | 1028/3058 [29:18<1:39:34,  2.94s/it][2025-02-04 04:04:35][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▎      | 1029/3058 [29:23<1:50:28,  3.27s/it][2025-02-04 04:04:39][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▎      | 1030/3058 [29:27<2:01:09,  3.58s/it][2025-02-04 04:04:43][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▎      | 1031/3058 [29:28<1:39:06,  2.93s/it][2025-02-04 04:04:45][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▎      | 1032/3058 [29:32<1:47:34,  3.19s/it][2025-02-04 04:04:48][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1033/3058 [29:35<1:49:25,  3.24s/it][2025-02-04 04:04:52][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1034/3058 [29:38<1:38:38,  2.92s/it][2025-02-04 04:04:54][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1035/3058 [29:40<1:31:48,  2.72s/it][2025-02-04 04:04:56][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1036/3058 [29:41<1:16:43,  2.28s/it][2025-02-04 04:04:57][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1037/3058 [29:43<1:14:26,  2.21s/it][2025-02-04 04:04:59][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1038/3058 [29:44<1:03:05,  1.87s/it][2025-02-04 04:05:00][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1039/3058 [29:48<1:17:40,  2.31s/it][2025-02-04 04:05:04][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1040/3058 [29:49<1:14:04,  2.20s/it][2025-02-04 04:05:06][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1041/3058 [29:53<1:27:54,  2.61s/it][2025-02-04 04:05:09][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1042/3058 [29:55<1:22:11,  2.45s/it][2025-02-04 04:05:11][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1043/3058 [29:57<1:17:50,  2.32s/it][2025-02-04 04:05:13][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1044/3058 [30:01<1:32:25,  2.75s/it][2025-02-04 04:05:17][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1045/3058 [30:02<1:17:14,  2.30s/it][2025-02-04 04:05:18][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1046/3058 [30:03<1:04:23,  1.92s/it][2025-02-04 04:05:19][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1047/3058 [30:06<1:13:49,  2.20s/it][2025-02-04 04:05:22][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1048/3058 [30:07<58:25,  1.74s/it]  [2025-02-04 04:05:23][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1049/3058 [30:09<59:21,  1.77s/it][2025-02-04 04:05:25][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1050/3058 [30:10<55:42,  1.66s/it][2025-02-04 04:05:26][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1051/3058 [30:12<56:03,  1.68s/it][2025-02-04 04:05:28][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1052/3058 [30:13<52:36,  1.57s/it][2025-02-04 04:05:29][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1053/3058 [30:15<59:08,  1.77s/it][2025-02-04 04:05:32][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1054/3058 [30:20<1:32:49,  2.78s/it][2025-02-04 04:05:37][slam_llm.models.slam_model][INFO] - modality encoder
 34%|███▍      | 1055/3058 [30:24<1:39:02,  2.97s/it][2025-02-04 04:05:40][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1056/3058 [30:26<1:35:44,  2.87s/it][2025-02-04 04:05:42][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1057/3058 [30:28<1:18:09,  2.34s/it][2025-02-04 04:05:44][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1058/3058 [30:29<1:13:12,  2.20s/it][2025-02-04 04:05:46][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1059/3058 [30:31<1:08:42,  2.06s/it][2025-02-04 04:05:47][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1060/3058 [30:33<1:06:32,  2.00s/it][2025-02-04 04:05:49][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1061/3058 [30:35<1:08:24,  2.06s/it][2025-02-04 04:05:52][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1062/3058 [30:40<1:32:48,  2.79s/it][2025-02-04 04:05:56][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1063/3058 [30:44<1:50:35,  3.33s/it][2025-02-04 04:06:00][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1064/3058 [30:47<1:47:23,  3.23s/it][2025-02-04 04:06:03][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1065/3058 [30:49<1:29:19,  2.69s/it][2025-02-04 04:06:05][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1066/3058 [30:50<1:20:27,  2.42s/it][2025-02-04 04:06:07][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1067/3058 [30:52<1:11:41,  2.16s/it][2025-02-04 04:06:08][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1068/3058 [30:55<1:15:13,  2.27s/it][2025-02-04 04:06:11][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1069/3058 [30:57<1:21:12,  2.45s/it][2025-02-04 04:06:14][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▍      | 1070/3058 [31:00<1:17:43,  2.35s/it][2025-02-04 04:06:16][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1071/3058 [31:01<1:04:30,  1.95s/it][2025-02-04 04:06:17][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1072/3058 [31:04<1:23:03,  2.51s/it][2025-02-04 04:06:21][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1073/3058 [31:08<1:34:29,  2.86s/it][2025-02-04 04:06:24][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1074/3058 [31:10<1:22:24,  2.49s/it][2025-02-04 04:06:26][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1075/3058 [31:14<1:36:58,  2.93s/it][2025-02-04 04:06:30][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1076/3058 [31:17<1:38:12,  2.97s/it][2025-02-04 04:06:33][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1077/3058 [31:18<1:23:42,  2.54s/it][2025-02-04 04:06:34][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1078/3058 [31:20<1:14:51,  2.27s/it][2025-02-04 04:06:36][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1079/3058 [31:22<1:10:42,  2.14s/it][2025-02-04 04:06:38][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1080/3058 [31:24<1:08:40,  2.08s/it][2025-02-04 04:06:40][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1081/3058 [31:25<58:51,  1.79s/it]  [2025-02-04 04:06:41][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1082/3058 [31:29<1:20:25,  2.44s/it][2025-02-04 04:06:45][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1083/3058 [31:30<1:08:26,  2.08s/it][2025-02-04 04:06:46][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1084/3058 [31:33<1:21:52,  2.49s/it][2025-02-04 04:06:50][slam_llm.models.slam_model][INFO] - modality encoder
 35%|███▌      | 1085/3058 [31:35<1:10:18,  2.14s/it][2025-02-04 04:06:51][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1086/3058 [31:37<1:08:17,  2.08s/it][2025-02-04 04:06:53][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1087/3058 [31:39<1:07:34,  2.06s/it][2025-02-04 04:06:55][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1088/3058 [31:40<1:00:54,  1.86s/it][2025-02-04 04:06:56][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1089/3058 [31:42<58:34,  1.78s/it]  [2025-02-04 04:06:58][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1090/3058 [31:44<1:00:30,  1.84s/it][2025-02-04 04:07:00][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1091/3058 [31:47<1:19:45,  2.43s/it][2025-02-04 04:07:04][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1092/3058 [31:49<1:06:40,  2.03s/it][2025-02-04 04:07:05][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1093/3058 [31:50<58:24,  1.78s/it]  [2025-02-04 04:07:06][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1094/3058 [31:52<58:28,  1.79s/it][2025-02-04 04:07:08][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1095/3058 [31:53<53:58,  1.65s/it][2025-02-04 04:07:09][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1096/3058 [31:54<49:51,  1.52s/it][2025-02-04 04:07:10][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1097/3058 [31:55<41:50,  1.28s/it][2025-02-04 04:07:11][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1098/3058 [31:56<37:31,  1.15s/it][2025-02-04 04:07:12][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1099/3058 [31:58<45:54,  1.41s/it][2025-02-04 04:07:14][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1100/3058 [31:59<43:29,  1.33s/it][2025-02-04 04:07:15][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1101/3058 [32:01<52:58,  1.62s/it][2025-02-04 04:07:18][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1102/3058 [32:05<1:14:55,  2.30s/it][2025-02-04 04:07:21][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1103/3058 [32:09<1:35:42,  2.94s/it][2025-02-04 04:07:26][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1104/3058 [32:14<1:51:53,  3.44s/it][2025-02-04 04:07:30][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1105/3058 [32:18<1:53:16,  3.48s/it][2025-02-04 04:07:34][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1106/3058 [32:20<1:40:02,  3.08s/it][2025-02-04 04:07:36][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1107/3058 [32:22<1:33:05,  2.86s/it][2025-02-04 04:07:38][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▌      | 1108/3058 [32:25<1:32:11,  2.84s/it][2025-02-04 04:07:41][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▋      | 1109/3058 [32:27<1:24:16,  2.59s/it][2025-02-04 04:07:43][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▋      | 1110/3058 [32:28<1:11:28,  2.20s/it][2025-02-04 04:07:44][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▋      | 1111/3058 [32:29<1:01:36,  1.90s/it][2025-02-04 04:07:45][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▋      | 1112/3058 [32:30<51:57,  1.60s/it]  [2025-02-04 04:07:46][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▋      | 1113/3058 [32:33<1:05:15,  2.01s/it][2025-02-04 04:07:50][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▋      | 1114/3058 [32:36<1:13:37,  2.27s/it][2025-02-04 04:07:52][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▋      | 1115/3058 [32:38<1:12:02,  2.22s/it][2025-02-04 04:07:54][slam_llm.models.slam_model][INFO] - modality encoder
 36%|███▋      | 1116/3058 [32:40<1:04:02,  1.98s/it][2025-02-04 04:07:56][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1117/3058 [32:41<59:32,  1.84s/it]  [2025-02-04 04:07:57][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1118/3058 [32:43<59:11,  1.83s/it][2025-02-04 04:07:59][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1119/3058 [32:47<1:22:41,  2.56s/it][2025-02-04 04:08:03][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1120/3058 [32:49<1:14:56,  2.32s/it][2025-02-04 04:08:05][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1121/3058 [32:53<1:31:32,  2.84s/it][2025-02-04 04:08:09][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1122/3058 [32:56<1:31:03,  2.82s/it][2025-02-04 04:08:12][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1123/3058 [32:59<1:34:23,  2.93s/it][2025-02-04 04:08:15][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1124/3058 [33:01<1:25:12,  2.64s/it][2025-02-04 04:08:17][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1125/3058 [33:03<1:14:42,  2.32s/it][2025-02-04 04:08:19][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1126/3058 [33:06<1:29:26,  2.78s/it][2025-02-04 04:08:23][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1127/3058 [33:08<1:13:30,  2.28s/it][2025-02-04 04:08:24][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1128/3058 [33:09<1:06:42,  2.07s/it][2025-02-04 04:08:25][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1129/3058 [33:11<1:02:00,  1.93s/it][2025-02-04 04:08:27][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1130/3058 [33:15<1:21:01,  2.52s/it][2025-02-04 04:08:31][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1131/3058 [33:17<1:24:12,  2.62s/it][2025-02-04 04:08:34][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1132/3058 [33:21<1:36:07,  2.99s/it][2025-02-04 04:08:38][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1133/3058 [33:24<1:33:43,  2.92s/it][2025-02-04 04:08:40][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1134/3058 [33:27<1:33:00,  2.90s/it][2025-02-04 04:08:43][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1135/3058 [33:28<1:18:11,  2.44s/it][2025-02-04 04:08:44][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1136/3058 [33:30<1:13:33,  2.30s/it][2025-02-04 04:08:46][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1137/3058 [33:33<1:14:05,  2.31s/it][2025-02-04 04:08:49][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1138/3058 [33:34<1:05:46,  2.06s/it][2025-02-04 04:08:50][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1139/3058 [33:35<57:36,  1.80s/it]  [2025-02-04 04:08:51][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1140/3058 [33:36<48:18,  1.51s/it][2025-02-04 04:08:52][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1141/3058 [33:38<54:35,  1.71s/it][2025-02-04 04:08:54][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1142/3058 [33:40<52:44,  1.65s/it][2025-02-04 04:08:56][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1143/3058 [33:45<1:26:15,  2.70s/it][2025-02-04 04:09:01][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1144/3058 [33:47<1:17:00,  2.41s/it][2025-02-04 04:09:03][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1145/3058 [33:47<59:20,  1.86s/it]  [2025-02-04 04:09:03][slam_llm.models.slam_model][INFO] - modality encoder
 37%|███▋      | 1146/3058 [33:48<50:26,  1.58s/it][2025-02-04 04:09:05][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1147/3058 [33:52<1:15:26,  2.37s/it][2025-02-04 04:09:09][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1148/3058 [33:56<1:23:12,  2.61s/it][2025-02-04 04:09:12][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1149/3058 [33:57<1:13:35,  2.31s/it][2025-02-04 04:09:13][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1150/3058 [34:01<1:26:00,  2.70s/it][2025-02-04 04:09:17][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1151/3058 [34:03<1:17:37,  2.44s/it][2025-02-04 04:09:19][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1152/3058 [34:04<1:08:23,  2.15s/it][2025-02-04 04:09:21][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1153/3058 [34:09<1:29:59,  2.83s/it][2025-02-04 04:09:25][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1154/3058 [34:13<1:43:59,  3.28s/it][2025-02-04 04:09:29][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1155/3058 [34:16<1:43:01,  3.25s/it][2025-02-04 04:09:32][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1156/3058 [34:21<1:54:58,  3.63s/it][2025-02-04 04:09:37][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1157/3058 [34:24<1:55:13,  3.64s/it][2025-02-04 04:09:40][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1158/3058 [34:27<1:50:45,  3.50s/it][2025-02-04 04:09:44][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1159/3058 [34:31<1:52:27,  3.55s/it][2025-02-04 04:09:47][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1160/3058 [34:34<1:49:24,  3.46s/it][2025-02-04 04:09:50][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1161/3058 [34:36<1:34:19,  2.98s/it][2025-02-04 04:09:52][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1162/3058 [34:38<1:22:37,  2.61s/it][2025-02-04 04:09:54][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1163/3058 [34:41<1:31:18,  2.89s/it][2025-02-04 04:09:58][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1164/3058 [34:43<1:15:38,  2.40s/it][2025-02-04 04:09:59][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1165/3058 [34:44<1:02:01,  1.97s/it][2025-02-04 04:10:00][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1166/3058 [34:46<1:04:45,  2.05s/it][2025-02-04 04:10:02][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1167/3058 [34:49<1:13:23,  2.33s/it][2025-02-04 04:10:05][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1168/3058 [34:51<1:10:48,  2.25s/it][2025-02-04 04:10:07][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1169/3058 [34:55<1:26:29,  2.75s/it][2025-02-04 04:10:11][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1170/3058 [34:56<1:13:21,  2.33s/it][2025-02-04 04:10:12][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1171/3058 [34:57<1:00:04,  1.91s/it][2025-02-04 04:10:13][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1172/3058 [34:58<53:43,  1.71s/it]  [2025-02-04 04:10:15][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1173/3058 [35:00<49:23,  1.57s/it][2025-02-04 04:10:16][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1174/3058 [35:02<51:55,  1.65s/it][2025-02-04 04:10:18][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1175/3058 [35:06<1:21:22,  2.59s/it][2025-02-04 04:10:22][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1176/3058 [35:10<1:29:17,  2.85s/it][2025-02-04 04:10:26][slam_llm.models.slam_model][INFO] - modality encoder
 38%|███▊      | 1177/3058 [35:11<1:17:18,  2.47s/it][2025-02-04 04:10:27][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▊      | 1178/3058 [35:13<1:08:52,  2.20s/it][2025-02-04 04:10:29][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▊      | 1179/3058 [35:14<59:01,  1.88s/it]  [2025-02-04 04:10:30][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▊      | 1180/3058 [35:15<54:45,  1.75s/it][2025-02-04 04:10:32][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▊      | 1181/3058 [35:17<54:38,  1.75s/it][2025-02-04 04:10:33][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▊      | 1182/3058 [35:19<57:45,  1.85s/it][2025-02-04 04:10:36][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▊      | 1183/3058 [35:24<1:23:06,  2.66s/it][2025-02-04 04:10:40][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▊      | 1184/3058 [35:26<1:16:35,  2.45s/it][2025-02-04 04:10:42][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1185/3058 [35:28<1:14:40,  2.39s/it][2025-02-04 04:10:44][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1186/3058 [35:29<1:05:04,  2.09s/it][2025-02-04 04:10:46][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1187/3058 [35:31<59:30,  1.91s/it]  [2025-02-04 04:10:47][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1188/3058 [35:32<51:19,  1.65s/it][2025-02-04 04:10:48][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1189/3058 [35:34<51:07,  1.64s/it][2025-02-04 04:10:50][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1190/3058 [35:38<1:14:12,  2.38s/it][2025-02-04 04:10:54][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1191/3058 [35:41<1:19:52,  2.57s/it][2025-02-04 04:10:57][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1192/3058 [35:43<1:17:27,  2.49s/it][2025-02-04 04:10:59][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1193/3058 [35:45<1:16:12,  2.45s/it][2025-02-04 04:11:02][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1194/3058 [35:48<1:16:31,  2.46s/it][2025-02-04 04:11:04][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1195/3058 [35:52<1:27:40,  2.82s/it][2025-02-04 04:11:08][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1196/3058 [35:55<1:33:17,  3.01s/it][2025-02-04 04:11:11][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1197/3058 [36:00<1:53:37,  3.66s/it][2025-02-04 04:11:17][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1198/3058 [36:04<1:54:14,  3.68s/it][2025-02-04 04:11:20][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1199/3058 [36:05<1:28:52,  2.87s/it][2025-02-04 04:11:21][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1200/3058 [36:06<1:09:50,  2.26s/it][2025-02-04 04:11:22][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1201/3058 [36:07<57:57,  1.87s/it]  [2025-02-04 04:11:23][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1202/3058 [36:08<53:29,  1.73s/it][2025-02-04 04:11:24][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1203/3058 [36:10<52:59,  1.71s/it][2025-02-04 04:11:26][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1204/3058 [36:11<48:32,  1.57s/it][2025-02-04 04:11:27][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1205/3058 [36:12<42:56,  1.39s/it][2025-02-04 04:11:28][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1206/3058 [36:13<40:06,  1.30s/it][2025-02-04 04:11:29][slam_llm.models.slam_model][INFO] - modality encoder
 39%|███▉      | 1207/3058 [36:16<53:07,  1.72s/it][2025-02-04 04:11:32][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1208/3058 [36:18<54:46,  1.78s/it][2025-02-04 04:11:34][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1209/3058 [36:20<1:00:57,  1.98s/it][2025-02-04 04:11:36][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1210/3058 [36:22<1:04:22,  2.09s/it][2025-02-04 04:11:39][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1211/3058 [36:26<1:14:48,  2.43s/it][2025-02-04 04:11:42][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1212/3058 [36:28<1:09:06,  2.25s/it][2025-02-04 04:11:44][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1213/3058 [36:32<1:26:11,  2.80s/it][2025-02-04 04:11:48][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1214/3058 [36:34<1:25:02,  2.77s/it][2025-02-04 04:11:51][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1215/3058 [36:38<1:31:06,  2.97s/it][2025-02-04 04:11:54][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1216/3058 [36:42<1:40:30,  3.27s/it][2025-02-04 04:11:58][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1217/3058 [36:43<1:26:35,  2.82s/it][2025-02-04 04:12:00][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1218/3058 [36:45<1:12:58,  2.38s/it][2025-02-04 04:12:01][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1219/3058 [36:50<1:38:11,  3.20s/it][2025-02-04 04:12:06][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1220/3058 [36:53<1:38:42,  3.22s/it][2025-02-04 04:12:09][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1221/3058 [36:55<1:26:44,  2.83s/it][2025-02-04 04:12:11][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1222/3058 [36:58<1:29:55,  2.94s/it][2025-02-04 04:12:15][slam_llm.models.slam_model][INFO] - modality encoder
 40%|███▉      | 1223/3058 [37:01<1:31:30,  2.99s/it][2025-02-04 04:12:18][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1224/3058 [37:06<1:47:04,  3.50s/it][2025-02-04 04:12:22][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1225/3058 [37:09<1:43:44,  3.40s/it][2025-02-04 04:12:26][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1226/3058 [37:14<1:55:39,  3.79s/it][2025-02-04 04:12:30][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1227/3058 [37:16<1:43:43,  3.40s/it][2025-02-04 04:12:33][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1228/3058 [37:19<1:36:49,  3.17s/it][2025-02-04 04:12:35][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1229/3058 [37:23<1:42:53,  3.38s/it][2025-02-04 04:12:39][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1230/3058 [37:25<1:26:31,  2.84s/it][2025-02-04 04:12:41][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1231/3058 [37:28<1:30:59,  2.99s/it][2025-02-04 04:12:44][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1232/3058 [37:31<1:28:19,  2.90s/it][2025-02-04 04:12:47][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1233/3058 [37:35<1:39:56,  3.29s/it][2025-02-04 04:12:51][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1234/3058 [37:36<1:23:58,  2.76s/it][2025-02-04 04:12:53][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1235/3058 [37:40<1:30:53,  2.99s/it][2025-02-04 04:12:56][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1236/3058 [37:44<1:40:15,  3.30s/it][2025-02-04 04:13:00][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1237/3058 [37:46<1:29:36,  2.95s/it][2025-02-04 04:13:02][slam_llm.models.slam_model][INFO] - modality encoder
 40%|████      | 1238/3058 [37:49<1:30:05,  2.97s/it][2025-02-04 04:13:05][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1239/3058 [37:53<1:37:03,  3.20s/it][2025-02-04 04:13:09][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1240/3058 [37:58<1:53:03,  3.73s/it][2025-02-04 04:13:14][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1241/3058 [38:01<1:49:10,  3.60s/it][2025-02-04 04:13:17][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1242/3058 [38:03<1:30:37,  2.99s/it][2025-02-04 04:13:19][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1243/3058 [38:04<1:11:30,  2.36s/it][2025-02-04 04:13:20][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1244/3058 [38:05<1:00:11,  1.99s/it][2025-02-04 04:13:21][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1245/3058 [38:06<58:26,  1.93s/it]  [2025-02-04 04:13:23][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1246/3058 [38:09<1:01:18,  2.03s/it][2025-02-04 04:13:25][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1247/3058 [38:11<1:08:15,  2.26s/it][2025-02-04 04:13:28][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1248/3058 [38:14<1:06:41,  2.21s/it][2025-02-04 04:13:30][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1249/3058 [38:14<52:56,  1.76s/it]  [2025-02-04 04:13:30][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1250/3058 [38:15<47:58,  1.59s/it][2025-02-04 04:13:32][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1251/3058 [38:17<50:24,  1.67s/it][2025-02-04 04:13:34][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1252/3058 [38:19<54:12,  1.80s/it][2025-02-04 04:13:36][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1253/3058 [38:22<1:01:54,  2.06s/it][2025-02-04 04:13:38][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1254/3058 [38:23<53:05,  1.77s/it]  [2025-02-04 04:13:39][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1255/3058 [38:26<1:02:07,  2.07s/it][2025-02-04 04:13:42][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1256/3058 [38:28<1:00:46,  2.02s/it][2025-02-04 04:13:44][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1257/3058 [38:29<53:56,  1.80s/it]  [2025-02-04 04:13:45][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1258/3058 [38:32<1:02:01,  2.07s/it][2025-02-04 04:13:48][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1259/3058 [38:34<1:03:21,  2.11s/it][2025-02-04 04:13:50][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1260/3058 [38:36<1:02:27,  2.08s/it][2025-02-04 04:13:52][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████      | 1261/3058 [38:38<1:04:15,  2.15s/it][2025-02-04 04:13:54][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████▏     | 1262/3058 [38:39<55:01,  1.84s/it]  [2025-02-04 04:13:56][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████▏     | 1263/3058 [38:41<47:41,  1.59s/it][2025-02-04 04:13:57][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████▏     | 1264/3058 [38:41<42:06,  1.41s/it][2025-02-04 04:13:58][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████▏     | 1265/3058 [38:43<43:20,  1.45s/it][2025-02-04 04:14:00][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████▏     | 1266/3058 [38:48<1:15:32,  2.53s/it][2025-02-04 04:14:04][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████▏     | 1267/3058 [38:51<1:20:49,  2.71s/it][2025-02-04 04:14:07][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████▏     | 1268/3058 [38:54<1:23:25,  2.80s/it][2025-02-04 04:14:10][slam_llm.models.slam_model][INFO] - modality encoder
 41%|████▏     | 1269/3058 [38:56<1:17:32,  2.60s/it][2025-02-04 04:14:12][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1270/3058 [38:57<1:02:04,  2.08s/it][2025-02-04 04:14:13][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1271/3058 [39:00<1:11:17,  2.39s/it][2025-02-04 04:14:16][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1272/3058 [39:01<57:30,  1.93s/it]  [2025-02-04 04:14:17][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1273/3058 [39:03<1:00:28,  2.03s/it][2025-02-04 04:14:20][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1274/3058 [39:05<56:38,  1.90s/it]  [2025-02-04 04:14:21][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1275/3058 [39:08<1:08:38,  2.31s/it][2025-02-04 04:14:24][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1276/3058 [39:09<57:40,  1.94s/it]  [2025-02-04 04:14:25][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1277/3058 [39:10<49:20,  1.66s/it][2025-02-04 04:14:27][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1278/3058 [39:12<47:14,  1.59s/it][2025-02-04 04:14:28][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1279/3058 [39:15<56:55,  1.92s/it][2025-02-04 04:14:31][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1280/3058 [39:19<1:21:49,  2.76s/it][2025-02-04 04:14:35][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1281/3058 [39:22<1:19:58,  2.70s/it][2025-02-04 04:14:38][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1282/3058 [39:25<1:20:46,  2.73s/it][2025-02-04 04:14:41][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1283/3058 [39:26<1:12:43,  2.46s/it][2025-02-04 04:14:43][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1284/3058 [39:30<1:23:08,  2.81s/it][2025-02-04 04:14:46][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1285/3058 [39:31<1:10:08,  2.37s/it][2025-02-04 04:14:48][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1286/3058 [39:34<1:07:35,  2.29s/it][2025-02-04 04:14:50][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1287/3058 [39:37<1:20:02,  2.71s/it][2025-02-04 04:14:53][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1288/3058 [39:41<1:25:04,  2.88s/it][2025-02-04 04:14:57][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1289/3058 [39:43<1:22:35,  2.80s/it][2025-02-04 04:14:59][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1290/3058 [39:47<1:34:26,  3.21s/it][2025-02-04 04:15:03][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1291/3058 [39:49<1:21:48,  2.78s/it][2025-02-04 04:15:05][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1292/3058 [39:51<1:16:35,  2.60s/it][2025-02-04 04:15:07][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1293/3058 [39:54<1:18:29,  2.67s/it][2025-02-04 04:15:10][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1294/3058 [39:58<1:29:26,  3.04s/it][2025-02-04 04:15:14][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1295/3058 [40:00<1:22:36,  2.81s/it][2025-02-04 04:15:16][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1296/3058 [40:02<1:11:23,  2.43s/it][2025-02-04 04:15:18][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1297/3058 [40:05<1:17:35,  2.64s/it][2025-02-04 04:15:21][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1298/3058 [40:09<1:26:54,  2.96s/it][2025-02-04 04:15:25][slam_llm.models.slam_model][INFO] - modality encoder
 42%|████▏     | 1299/3058 [40:11<1:18:52,  2.69s/it][2025-02-04 04:15:27][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1300/3058 [40:14<1:23:28,  2.85s/it][2025-02-04 04:15:30][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1301/3058 [40:17<1:29:27,  3.06s/it][2025-02-04 04:15:34][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1302/3058 [40:21<1:29:51,  3.07s/it][2025-02-04 04:15:37][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1303/3058 [40:22<1:14:56,  2.56s/it][2025-02-04 04:15:38][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1304/3058 [40:24<1:13:15,  2.51s/it][2025-02-04 04:15:40][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1305/3058 [40:27<1:12:59,  2.50s/it][2025-02-04 04:15:43][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1306/3058 [40:30<1:16:13,  2.61s/it][2025-02-04 04:15:46][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1307/3058 [40:31<1:09:09,  2.37s/it][2025-02-04 04:15:48][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1308/3058 [40:33<1:03:13,  2.17s/it][2025-02-04 04:15:49][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1309/3058 [40:34<54:00,  1.85s/it]  [2025-02-04 04:15:51][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1310/3058 [40:39<1:17:14,  2.65s/it][2025-02-04 04:15:55][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1311/3058 [40:40<1:03:07,  2.17s/it][2025-02-04 04:15:56][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1312/3058 [40:42<1:01:16,  2.11s/it][2025-02-04 04:15:58][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1313/3058 [40:46<1:21:23,  2.80s/it][2025-02-04 04:16:02][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1314/3058 [40:50<1:29:50,  3.09s/it][2025-02-04 04:16:06][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1315/3058 [40:52<1:23:30,  2.87s/it][2025-02-04 04:16:08][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1316/3058 [40:55<1:20:02,  2.76s/it][2025-02-04 04:16:11][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1317/3058 [40:57<1:10:36,  2.43s/it][2025-02-04 04:16:13][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1318/3058 [40:58<59:01,  2.04s/it]  [2025-02-04 04:16:14][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1319/3058 [41:00<58:30,  2.02s/it][2025-02-04 04:16:16][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1320/3058 [41:01<50:30,  1.74s/it][2025-02-04 04:16:17][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1321/3058 [41:02<48:21,  1.67s/it][2025-02-04 04:16:18][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1322/3058 [41:03<42:07,  1.46s/it][2025-02-04 04:16:19][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1323/3058 [41:05<42:19,  1.46s/it][2025-02-04 04:16:21][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1324/3058 [41:06<39:30,  1.37s/it][2025-02-04 04:16:22][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1325/3058 [41:08<44:15,  1.53s/it][2025-02-04 04:16:24][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1326/3058 [41:10<47:09,  1.63s/it][2025-02-04 04:16:26][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1327/3058 [41:13<1:02:05,  2.15s/it][2025-02-04 04:16:29][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1328/3058 [41:14<55:21,  1.92s/it]  [2025-02-04 04:16:30][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1329/3058 [41:16<51:29,  1.79s/it][2025-02-04 04:16:32][slam_llm.models.slam_model][INFO] - modality encoder
 43%|████▎     | 1330/3058 [41:17<48:27,  1.68s/it][2025-02-04 04:16:33][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▎     | 1331/3058 [41:20<56:27,  1.96s/it][2025-02-04 04:16:36][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▎     | 1332/3058 [41:22<54:25,  1.89s/it][2025-02-04 04:16:38][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▎     | 1333/3058 [41:24<1:02:11,  2.16s/it][2025-02-04 04:16:40][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▎     | 1334/3058 [41:26<54:12,  1.89s/it]  [2025-02-04 04:16:42][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▎     | 1335/3058 [41:27<47:04,  1.64s/it][2025-02-04 04:16:43][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▎     | 1336/3058 [41:28<45:05,  1.57s/it][2025-02-04 04:16:44][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▎     | 1337/3058 [41:30<47:31,  1.66s/it][2025-02-04 04:16:46][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1338/3058 [41:31<45:41,  1.59s/it][2025-02-04 04:16:48][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1339/3058 [41:34<52:23,  1.83s/it][2025-02-04 04:16:50][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1340/3058 [41:37<1:04:20,  2.25s/it][2025-02-04 04:16:53][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1341/3058 [41:38<55:25,  1.94s/it]  [2025-02-04 04:16:54][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1342/3058 [41:40<57:29,  2.01s/it][2025-02-04 04:16:56][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1343/3058 [41:42<53:32,  1.87s/it][2025-02-04 04:16:58][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1344/3058 [41:44<56:49,  1.99s/it][2025-02-04 04:17:00][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1345/3058 [41:46<52:30,  1.84s/it][2025-02-04 04:17:02][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1346/3058 [41:49<1:05:05,  2.28s/it][2025-02-04 04:17:05][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1347/3058 [41:51<1:06:23,  2.33s/it][2025-02-04 04:17:08][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1348/3058 [41:54<1:09:27,  2.44s/it][2025-02-04 04:17:10][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1349/3058 [41:56<1:03:52,  2.24s/it][2025-02-04 04:17:12][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1350/3058 [41:57<56:46,  1.99s/it]  [2025-02-04 04:17:13][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1351/3058 [41:59<56:36,  1.99s/it][2025-02-04 04:17:15][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1352/3058 [42:01<50:59,  1.79s/it][2025-02-04 04:17:17][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1353/3058 [42:02<48:38,  1.71s/it][2025-02-04 04:17:19][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1354/3058 [42:07<1:15:56,  2.67s/it][2025-02-04 04:17:23][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1355/3058 [42:09<1:05:56,  2.32s/it][2025-02-04 04:17:25][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1356/3058 [42:09<53:51,  1.90s/it]  [2025-02-04 04:17:26][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1357/3058 [42:11<48:00,  1.69s/it][2025-02-04 04:17:27][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1358/3058 [42:12<42:56,  1.52s/it][2025-02-04 04:17:28][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1359/3058 [42:13<38:53,  1.37s/it][2025-02-04 04:17:29][slam_llm.models.slam_model][INFO] - modality encoder
 44%|████▍     | 1360/3058 [42:14<36:24,  1.29s/it][2025-02-04 04:17:30][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1361/3058 [42:16<43:06,  1.52s/it][2025-02-04 04:17:32][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1362/3058 [42:18<42:52,  1.52s/it][2025-02-04 04:17:34][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1363/3058 [42:19<43:06,  1.53s/it][2025-02-04 04:17:35][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1364/3058 [42:21<43:37,  1.55s/it][2025-02-04 04:17:37][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1365/3058 [42:23<53:39,  1.90s/it][2025-02-04 04:17:39][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1366/3058 [42:25<52:57,  1.88s/it][2025-02-04 04:17:41][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1367/3058 [42:26<47:05,  1.67s/it][2025-02-04 04:17:42][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1368/3058 [42:28<45:06,  1.60s/it][2025-02-04 04:17:44][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1369/3058 [42:30<47:02,  1.67s/it][2025-02-04 04:17:46][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1370/3058 [42:31<45:52,  1.63s/it][2025-02-04 04:17:47][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1371/3058 [42:34<58:04,  2.07s/it][2025-02-04 04:17:50][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1372/3058 [42:36<53:54,  1.92s/it][2025-02-04 04:17:52][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1373/3058 [42:38<53:03,  1.89s/it][2025-02-04 04:17:54][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1374/3058 [42:38<43:21,  1.54s/it][2025-02-04 04:17:55][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1375/3058 [42:40<43:36,  1.55s/it][2025-02-04 04:17:56][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▍     | 1376/3058 [42:41<38:47,  1.38s/it][2025-02-04 04:17:57][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1377/3058 [42:42<38:33,  1.38s/it][2025-02-04 04:17:58][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1378/3058 [42:44<38:56,  1.39s/it][2025-02-04 04:18:00][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1379/3058 [42:47<54:03,  1.93s/it][2025-02-04 04:18:03][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1380/3058 [42:48<48:06,  1.72s/it][2025-02-04 04:18:04][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1381/3058 [42:50<44:43,  1.60s/it][2025-02-04 04:18:06][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1382/3058 [42:51<41:51,  1.50s/it][2025-02-04 04:18:07][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1383/3058 [42:54<58:01,  2.08s/it][2025-02-04 04:18:10][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1384/3058 [42:55<50:07,  1.80s/it][2025-02-04 04:18:11][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1385/3058 [42:57<49:58,  1.79s/it][2025-02-04 04:18:13][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1386/3058 [42:59<49:42,  1.78s/it][2025-02-04 04:18:15][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1387/3058 [43:01<52:57,  1.90s/it][2025-02-04 04:18:17][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1388/3058 [43:04<58:18,  2.09s/it][2025-02-04 04:18:20][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1389/3058 [43:06<1:04:00,  2.30s/it][2025-02-04 04:18:23][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1390/3058 [43:08<1:00:47,  2.19s/it][2025-02-04 04:18:24][slam_llm.models.slam_model][INFO] - modality encoder
 45%|████▌     | 1391/3058 [43:09<51:59,  1.87s/it]  [2025-02-04 04:18:26][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1392/3058 [43:13<1:08:29,  2.47s/it][2025-02-04 04:18:29][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1393/3058 [43:16<1:09:08,  2.49s/it][2025-02-04 04:18:32][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1394/3058 [43:17<56:31,  2.04s/it]  [2025-02-04 04:18:33][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1395/3058 [43:19<55:27,  2.00s/it][2025-02-04 04:18:35][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1396/3058 [43:22<1:05:04,  2.35s/it][2025-02-04 04:18:38][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1397/3058 [43:24<1:00:02,  2.17s/it][2025-02-04 04:18:40][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1398/3058 [43:26<1:02:53,  2.27s/it][2025-02-04 04:18:42][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1399/3058 [43:27<54:15,  1.96s/it]  [2025-02-04 04:18:43][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1400/3058 [43:28<43:55,  1.59s/it][2025-02-04 04:18:44][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1401/3058 [43:30<45:17,  1.64s/it][2025-02-04 04:18:46][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1402/3058 [43:31<38:55,  1.41s/it][2025-02-04 04:18:47][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1403/3058 [43:32<36:08,  1.31s/it][2025-02-04 04:18:48][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1404/3058 [43:35<50:16,  1.82s/it][2025-02-04 04:18:51][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1405/3058 [43:36<42:24,  1.54s/it][2025-02-04 04:18:52][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1406/3058 [43:39<57:49,  2.10s/it][2025-02-04 04:18:55][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1407/3058 [43:43<1:13:12,  2.66s/it][2025-02-04 04:18:59][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1408/3058 [43:45<1:08:47,  2.50s/it][2025-02-04 04:19:01][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1409/3058 [43:47<1:00:54,  2.22s/it][2025-02-04 04:19:03][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1410/3058 [43:48<52:36,  1.92s/it]  [2025-02-04 04:19:05][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1411/3058 [43:53<1:21:17,  2.96s/it][2025-02-04 04:19:10][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1412/3058 [43:57<1:25:51,  3.13s/it][2025-02-04 04:19:13][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1413/3058 [43:59<1:15:43,  2.76s/it][2025-02-04 04:19:15][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▌     | 1414/3058 [44:01<1:08:33,  2.50s/it][2025-02-04 04:19:17][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▋     | 1415/3058 [44:03<1:10:09,  2.56s/it][2025-02-04 04:19:20][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▋     | 1416/3058 [44:06<1:13:53,  2.70s/it][2025-02-04 04:19:23][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▋     | 1417/3058 [44:09<1:09:17,  2.53s/it][2025-02-04 04:19:25][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▋     | 1418/3058 [44:10<59:03,  2.16s/it]  [2025-02-04 04:19:26][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▋     | 1419/3058 [44:11<54:04,  1.98s/it][2025-02-04 04:19:28][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▋     | 1420/3058 [44:15<1:05:09,  2.39s/it][2025-02-04 04:19:31][slam_llm.models.slam_model][INFO] - modality encoder
 46%|████▋     | 1421/3058 [44:17<1:03:05,  2.31s/it][2025-02-04 04:19:33][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1422/3058 [44:18<50:06,  1.84s/it]  [2025-02-04 04:19:34][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1423/3058 [44:20<56:54,  2.09s/it][2025-02-04 04:19:36][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1424/3058 [44:23<1:04:52,  2.38s/it][2025-02-04 04:19:40][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1425/3058 [44:27<1:15:19,  2.77s/it][2025-02-04 04:19:43][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1426/3058 [44:29<1:11:53,  2.64s/it][2025-02-04 04:19:46][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1427/3058 [44:31<1:02:01,  2.28s/it][2025-02-04 04:19:47][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1428/3058 [44:32<55:33,  2.04s/it]  [2025-02-04 04:19:48][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1429/3058 [44:34<50:07,  1.85s/it][2025-02-04 04:19:50][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1430/3058 [44:37<1:00:20,  2.22s/it][2025-02-04 04:19:53][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1431/3058 [44:39<1:01:28,  2.27s/it][2025-02-04 04:19:55][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1432/3058 [44:41<1:00:51,  2.25s/it][2025-02-04 04:19:58][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1433/3058 [44:43<55:36,  2.05s/it]  [2025-02-04 04:19:59][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1434/3058 [44:45<54:55,  2.03s/it][2025-02-04 04:20:01][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1435/3058 [44:47<54:31,  2.02s/it][2025-02-04 04:20:03][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1436/3058 [44:48<47:14,  1.75s/it][2025-02-04 04:20:05][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1437/3058 [44:51<56:51,  2.10s/it][2025-02-04 04:20:07][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1438/3058 [44:53<51:52,  1.92s/it][2025-02-04 04:20:09][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1439/3058 [44:55<54:15,  2.01s/it][2025-02-04 04:20:11][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1440/3058 [44:56<51:23,  1.91s/it][2025-02-04 04:20:12][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1441/3058 [44:58<48:13,  1.79s/it][2025-02-04 04:20:14][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1442/3058 [45:01<57:21,  2.13s/it][2025-02-04 04:20:17][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1443/3058 [45:02<49:47,  1.85s/it][2025-02-04 04:20:18][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1444/3058 [45:04<54:38,  2.03s/it][2025-02-04 04:20:21][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1445/3058 [45:07<1:00:52,  2.26s/it][2025-02-04 04:20:24][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1446/3058 [45:11<1:11:11,  2.65s/it][2025-02-04 04:20:27][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1447/3058 [45:13<1:03:56,  2.38s/it][2025-02-04 04:20:29][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1448/3058 [45:16<1:09:01,  2.57s/it][2025-02-04 04:20:32][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1449/3058 [45:19<1:12:11,  2.69s/it][2025-02-04 04:20:35][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1450/3058 [45:20<1:03:37,  2.37s/it][2025-02-04 04:20:36][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1451/3058 [45:22<57:11,  2.14s/it]  [2025-02-04 04:20:38][slam_llm.models.slam_model][INFO] - modality encoder
 47%|████▋     | 1452/3058 [45:25<1:07:46,  2.53s/it][2025-02-04 04:20:41][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1453/3058 [45:28<1:11:38,  2.68s/it][2025-02-04 04:20:44][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1454/3058 [45:30<1:05:41,  2.46s/it][2025-02-04 04:20:46][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1455/3058 [45:33<1:04:53,  2.43s/it][2025-02-04 04:20:49][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1456/3058 [45:34<59:13,  2.22s/it]  [2025-02-04 04:20:50][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1457/3058 [45:37<1:03:56,  2.40s/it][2025-02-04 04:20:53][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1458/3058 [45:39<59:10,  2.22s/it]  [2025-02-04 04:20:55][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1459/3058 [45:41<58:39,  2.20s/it][2025-02-04 04:20:57][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1460/3058 [45:43<55:07,  2.07s/it][2025-02-04 04:20:59][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1461/3058 [45:45<53:37,  2.01s/it][2025-02-04 04:21:01][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1462/3058 [45:49<1:14:44,  2.81s/it][2025-02-04 04:21:06][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1463/3058 [45:52<1:10:48,  2.66s/it][2025-02-04 04:21:08][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1464/3058 [45:54<1:07:11,  2.53s/it][2025-02-04 04:21:10][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1465/3058 [45:56<1:07:11,  2.53s/it][2025-02-04 04:21:13][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1466/3058 [45:59<1:10:13,  2.65s/it][2025-02-04 04:21:15][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1467/3058 [46:01<59:06,  2.23s/it]  [2025-02-04 04:21:17][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1468/3058 [46:05<1:17:10,  2.91s/it][2025-02-04 04:21:22][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1469/3058 [46:12<1:49:17,  4.13s/it][2025-02-04 04:21:28][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1470/3058 [46:17<1:52:35,  4.25s/it][2025-02-04 04:21:33][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1471/3058 [46:20<1:48:33,  4.10s/it][2025-02-04 04:21:37][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1472/3058 [46:22<1:30:22,  3.42s/it][2025-02-04 04:21:38][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1473/3058 [46:25<1:26:40,  3.28s/it][2025-02-04 04:21:42][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1474/3058 [46:29<1:28:47,  3.36s/it][2025-02-04 04:21:45][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1475/3058 [46:32<1:24:28,  3.20s/it][2025-02-04 04:21:48][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1476/3058 [46:34<1:14:40,  2.83s/it][2025-02-04 04:21:50][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1477/3058 [46:39<1:36:46,  3.67s/it][2025-02-04 04:21:55][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1478/3058 [46:41<1:22:29,  3.13s/it][2025-02-04 04:21:57][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1479/3058 [46:44<1:18:42,  2.99s/it][2025-02-04 04:22:00][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1480/3058 [46:46<1:10:54,  2.70s/it][2025-02-04 04:22:02][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1481/3058 [46:48<1:11:17,  2.71s/it][2025-02-04 04:22:05][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1482/3058 [46:50<1:04:50,  2.47s/it][2025-02-04 04:22:06][slam_llm.models.slam_model][INFO] - modality encoder
 48%|████▊     | 1483/3058 [46:52<57:44,  2.20s/it]  [2025-02-04 04:22:08][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▊     | 1484/3058 [46:57<1:17:57,  2.97s/it][2025-02-04 04:22:13][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▊     | 1485/3058 [46:58<1:05:51,  2.51s/it][2025-02-04 04:22:14][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▊     | 1486/3058 [47:00<58:54,  2.25s/it]  [2025-02-04 04:22:16][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▊     | 1487/3058 [47:02<1:00:31,  2.31s/it][2025-02-04 04:22:18][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▊     | 1488/3058 [47:04<54:26,  2.08s/it]  [2025-02-04 04:22:20][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▊     | 1489/3058 [47:07<1:02:01,  2.37s/it][2025-02-04 04:22:23][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▊     | 1490/3058 [47:09<57:15,  2.19s/it]  [2025-02-04 04:22:25][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1491/3058 [47:13<1:10:36,  2.70s/it][2025-02-04 04:22:29][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1492/3058 [47:15<1:08:14,  2.61s/it][2025-02-04 04:22:31][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1493/3058 [47:19<1:15:52,  2.91s/it][2025-02-04 04:22:35][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1494/3058 [47:21<1:10:11,  2.69s/it][2025-02-04 04:22:37][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1495/3058 [47:24<1:16:14,  2.93s/it][2025-02-04 04:22:40][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1496/3058 [47:27<1:12:01,  2.77s/it][2025-02-04 04:22:43][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1497/3058 [47:29<1:07:40,  2.60s/it][2025-02-04 04:22:45][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1498/3058 [47:32<1:15:35,  2.91s/it][2025-02-04 04:22:49][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1499/3058 [47:37<1:30:53,  3.50s/it][2025-02-04 04:22:53][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1500/3058 [47:38<1:10:33,  2.72s/it][2025-02-04 04:22:54][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1501/3058 [47:40<1:07:12,  2.59s/it][2025-02-04 04:22:57][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1502/3058 [47:42<1:02:01,  2.39s/it][2025-02-04 04:22:59][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1503/3058 [47:46<1:08:13,  2.63s/it][2025-02-04 04:23:02][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1504/3058 [47:50<1:18:07,  3.02s/it][2025-02-04 04:23:06][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1505/3058 [47:52<1:12:22,  2.80s/it][2025-02-04 04:23:08][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1506/3058 [47:53<1:00:52,  2.35s/it][2025-02-04 04:23:09][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1507/3058 [47:56<1:04:52,  2.51s/it][2025-02-04 04:23:12][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1508/3058 [47:57<56:56,  2.20s/it]  [2025-02-04 04:23:14][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1509/3058 [48:00<57:59,  2.25s/it][2025-02-04 04:23:16][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1510/3058 [48:02<1:00:21,  2.34s/it][2025-02-04 04:23:19][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1511/3058 [48:06<1:06:59,  2.60s/it][2025-02-04 04:23:22][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1512/3058 [48:08<1:02:34,  2.43s/it][2025-02-04 04:23:24][slam_llm.models.slam_model][INFO] - modality encoder
 49%|████▉     | 1513/3058 [48:10<1:04:17,  2.50s/it][2025-02-04 04:23:26][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1514/3058 [48:13<1:06:07,  2.57s/it][2025-02-04 04:23:29][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1515/3058 [48:15<1:00:01,  2.33s/it][2025-02-04 04:23:31][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1516/3058 [48:18<1:07:00,  2.61s/it][2025-02-04 04:23:34][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1517/3058 [48:20<1:01:05,  2.38s/it][2025-02-04 04:23:36][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1518/3058 [48:23<1:06:50,  2.60s/it][2025-02-04 04:23:39][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1519/3058 [48:25<58:29,  2.28s/it]  [2025-02-04 04:23:41][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1520/3058 [48:28<1:05:32,  2.56s/it][2025-02-04 04:23:44][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1521/3058 [48:30<1:03:47,  2.49s/it][2025-02-04 04:23:46][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1522/3058 [48:31<54:55,  2.15s/it]  [2025-02-04 04:23:48][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1523/3058 [48:34<58:36,  2.29s/it][2025-02-04 04:23:50][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1524/3058 [48:36<55:46,  2.18s/it][2025-02-04 04:23:52][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1525/3058 [48:40<1:09:27,  2.72s/it][2025-02-04 04:23:56][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1526/3058 [48:42<1:01:45,  2.42s/it][2025-02-04 04:23:58][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1527/3058 [48:46<1:17:20,  3.03s/it][2025-02-04 04:24:02][slam_llm.models.slam_model][INFO] - modality encoder
 50%|████▉     | 1528/3058 [48:47<1:03:56,  2.51s/it][2025-02-04 04:24:04][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1529/3058 [48:52<1:17:42,  3.05s/it][2025-02-04 04:24:08][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1530/3058 [48:54<1:08:38,  2.70s/it][2025-02-04 04:24:10][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1531/3058 [48:55<1:01:15,  2.41s/it][2025-02-04 04:24:11][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1532/3058 [48:57<59:02,  2.32s/it]  [2025-02-04 04:24:14][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1533/3058 [48:59<52:22,  2.06s/it][2025-02-04 04:24:15][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1534/3058 [49:01<53:14,  2.10s/it][2025-02-04 04:24:17][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1535/3058 [49:04<1:03:20,  2.50s/it][2025-02-04 04:24:21][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1536/3058 [49:06<55:23,  2.18s/it]  [2025-02-04 04:24:22][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1537/3058 [49:08<53:07,  2.10s/it][2025-02-04 04:24:24][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1538/3058 [49:10<51:42,  2.04s/it][2025-02-04 04:24:26][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1539/3058 [49:12<52:09,  2.06s/it][2025-02-04 04:24:28][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1540/3058 [49:13<47:06,  1.86s/it][2025-02-04 04:24:30][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1541/3058 [49:18<1:06:02,  2.61s/it][2025-02-04 04:24:34][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1542/3058 [49:21<1:11:22,  2.82s/it][2025-02-04 04:24:37][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1543/3058 [49:25<1:17:31,  3.07s/it][2025-02-04 04:24:41][slam_llm.models.slam_model][INFO] - modality encoder
 50%|█████     | 1544/3058 [49:27<1:10:56,  2.81s/it][2025-02-04 04:24:43][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1545/3058 [49:28<59:22,  2.35s/it]  [2025-02-04 04:24:44][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1546/3058 [49:31<59:51,  2.38s/it][2025-02-04 04:24:47][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1547/3058 [49:32<49:58,  1.98s/it][2025-02-04 04:24:48][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1548/3058 [49:35<59:53,  2.38s/it][2025-02-04 04:24:51][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1549/3058 [49:37<54:12,  2.16s/it][2025-02-04 04:24:53][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1550/3058 [49:38<46:34,  1.85s/it][2025-02-04 04:24:54][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1551/3058 [49:39<41:04,  1.64s/it][2025-02-04 04:24:55][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1552/3058 [49:43<58:47,  2.34s/it][2025-02-04 04:24:59][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1553/3058 [49:44<50:12,  2.00s/it][2025-02-04 04:25:00][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1554/3058 [49:46<52:20,  2.09s/it][2025-02-04 04:25:02][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1555/3058 [49:49<56:39,  2.26s/it][2025-02-04 04:25:05][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1556/3058 [49:51<51:26,  2.06s/it][2025-02-04 04:25:07][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1557/3058 [49:53<52:22,  2.09s/it][2025-02-04 04:25:09][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1558/3058 [49:58<1:14:28,  2.98s/it][2025-02-04 04:25:14][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1559/3058 [50:01<1:20:02,  3.20s/it][2025-02-04 04:25:18][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1560/3058 [50:05<1:22:53,  3.32s/it][2025-02-04 04:25:21][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1561/3058 [50:08<1:21:08,  3.25s/it][2025-02-04 04:25:24][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1562/3058 [50:11<1:18:19,  3.14s/it][2025-02-04 04:25:27][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1563/3058 [50:13<1:12:42,  2.92s/it][2025-02-04 04:25:30][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1564/3058 [50:16<1:11:42,  2.88s/it][2025-02-04 04:25:33][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1565/3058 [50:20<1:14:58,  3.01s/it][2025-02-04 04:25:36][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1566/3058 [50:21<1:06:14,  2.66s/it][2025-02-04 04:25:38][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████     | 1567/3058 [50:23<58:25,  2.35s/it]  [2025-02-04 04:25:39][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████▏    | 1568/3058 [50:26<59:50,  2.41s/it][2025-02-04 04:25:42][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████▏    | 1569/3058 [50:28<59:09,  2.38s/it][2025-02-04 04:25:44][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████▏    | 1570/3058 [50:30<57:34,  2.32s/it][2025-02-04 04:25:46][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████▏    | 1571/3058 [50:32<56:34,  2.28s/it][2025-02-04 04:25:49][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████▏    | 1572/3058 [50:36<1:07:57,  2.74s/it][2025-02-04 04:25:52][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████▏    | 1573/3058 [50:39<1:12:28,  2.93s/it][2025-02-04 04:25:56][slam_llm.models.slam_model][INFO] - modality encoder
 51%|█████▏    | 1574/3058 [50:43<1:14:45,  3.02s/it][2025-02-04 04:25:59][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1575/3058 [50:45<1:13:04,  2.96s/it][2025-02-04 04:26:02][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1576/3058 [50:47<59:04,  2.39s/it]  [2025-02-04 04:26:03][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1577/3058 [50:49<1:02:57,  2.55s/it][2025-02-04 04:26:06][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1578/3058 [50:54<1:14:13,  3.01s/it][2025-02-04 04:26:10][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1579/3058 [50:55<1:04:56,  2.63s/it][2025-02-04 04:26:11][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1580/3058 [50:58<1:02:21,  2.53s/it][2025-02-04 04:26:14][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1581/3058 [50:59<53:43,  2.18s/it]  [2025-02-04 04:26:15][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1582/3058 [51:01<53:29,  2.17s/it][2025-02-04 04:26:17][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1583/3058 [51:03<53:41,  2.18s/it][2025-02-04 04:26:19][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1584/3058 [51:05<48:46,  1.99s/it][2025-02-04 04:26:21][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1585/3058 [51:09<1:02:30,  2.55s/it][2025-02-04 04:26:25][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1586/3058 [51:11<57:29,  2.34s/it]  [2025-02-04 04:26:27][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1587/3058 [51:13<54:27,  2.22s/it][2025-02-04 04:26:29][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1588/3058 [51:17<1:07:28,  2.75s/it][2025-02-04 04:26:33][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1589/3058 [51:19<1:04:50,  2.65s/it][2025-02-04 04:26:35][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1590/3058 [51:21<1:03:26,  2.59s/it][2025-02-04 04:26:38][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1591/3058 [51:23<59:28,  2.43s/it]  [2025-02-04 04:26:40][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1592/3058 [51:28<1:11:42,  2.94s/it][2025-02-04 04:26:44][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1593/3058 [51:32<1:20:35,  3.30s/it][2025-02-04 04:26:48][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1594/3058 [51:34<1:13:03,  2.99s/it][2025-02-04 04:26:50][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1595/3058 [51:38<1:17:45,  3.19s/it][2025-02-04 04:26:54][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1596/3058 [51:40<1:12:09,  2.96s/it][2025-02-04 04:26:56][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1597/3058 [51:42<1:04:41,  2.66s/it][2025-02-04 04:26:58][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1598/3058 [51:44<56:33,  2.32s/it]  [2025-02-04 04:27:00][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1599/3058 [51:47<1:05:51,  2.71s/it][2025-02-04 04:27:03][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1600/3058 [51:50<1:04:38,  2.66s/it][2025-02-04 04:27:06][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1601/3058 [51:52<1:02:32,  2.58s/it][2025-02-04 04:27:08][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1602/3058 [51:54<58:57,  2.43s/it]  [2025-02-04 04:27:10][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1603/3058 [51:56<55:51,  2.30s/it][2025-02-04 04:27:12][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1604/3058 [51:58<53:36,  2.21s/it][2025-02-04 04:27:14][slam_llm.models.slam_model][INFO] - modality encoder
 52%|█████▏    | 1605/3058 [51:59<41:27,  1.71s/it][2025-02-04 04:27:15][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1606/3058 [51:59<32:52,  1.36s/it][2025-02-04 04:27:15][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1607/3058 [52:00<29:43,  1.23s/it][2025-02-04 04:27:16][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1608/3058 [52:01<28:19,  1.17s/it][2025-02-04 04:27:17][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1609/3058 [52:02<24:09,  1.00s/it][2025-02-04 04:27:18][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1610/3058 [52:03<25:40,  1.06s/it][2025-02-04 04:27:19][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1611/3058 [52:04<24:36,  1.02s/it][2025-02-04 04:27:20][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1612/3058 [52:06<28:38,  1.19s/it][2025-02-04 04:27:22][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1613/3058 [52:06<25:49,  1.07s/it][2025-02-04 04:27:22][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1614/3058 [52:07<25:51,  1.07s/it][2025-02-04 04:27:24][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1615/3058 [52:09<29:49,  1.24s/it][2025-02-04 04:27:25][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1616/3058 [52:10<28:01,  1.17s/it][2025-02-04 04:27:26][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1617/3058 [52:11<27:04,  1.13s/it][2025-02-04 04:27:27][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1618/3058 [52:12<25:22,  1.06s/it][2025-02-04 04:27:28][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1619/3058 [52:13<26:40,  1.11s/it][2025-02-04 04:27:29][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1620/3058 [52:14<25:23,  1.06s/it][2025-02-04 04:27:30][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1621/3058 [52:15<22:40,  1.06it/s][2025-02-04 04:27:31][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1622/3058 [52:15<20:26,  1.17it/s][2025-02-04 04:27:32][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1623/3058 [52:16<20:06,  1.19it/s][2025-02-04 04:27:32][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1624/3058 [52:17<20:43,  1.15it/s][2025-02-04 04:27:33][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1625/3058 [52:19<25:47,  1.08s/it][2025-02-04 04:27:35][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1626/3058 [52:20<28:16,  1.18s/it][2025-02-04 04:27:36][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1627/3058 [52:21<28:15,  1.18s/it][2025-02-04 04:27:37][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1628/3058 [52:22<23:30,  1.01it/s][2025-02-04 04:27:38][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1629/3058 [52:23<24:46,  1.04s/it][2025-02-04 04:27:39][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1630/3058 [52:24<22:02,  1.08it/s][2025-02-04 04:27:40][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1631/3058 [52:24<20:17,  1.17it/s][2025-02-04 04:27:41][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1632/3058 [52:26<25:04,  1.05s/it][2025-02-04 04:27:42][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1633/3058 [52:27<25:52,  1.09s/it][2025-02-04 04:27:43][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1634/3058 [52:28<26:51,  1.13s/it][2025-02-04 04:27:45][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1635/3058 [52:30<30:06,  1.27s/it][2025-02-04 04:27:46][slam_llm.models.slam_model][INFO] - modality encoder
 53%|█████▎    | 1636/3058 [52:32<32:22,  1.37s/it][2025-02-04 04:27:48][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▎    | 1637/3058 [52:33<32:00,  1.35s/it][2025-02-04 04:27:49][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▎    | 1638/3058 [52:34<29:28,  1.25s/it][2025-02-04 04:27:50][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▎    | 1639/3058 [52:35<27:25,  1.16s/it][2025-02-04 04:27:51][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▎    | 1640/3058 [52:36<28:56,  1.22s/it][2025-02-04 04:27:52][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▎    | 1641/3058 [52:37<26:37,  1.13s/it][2025-02-04 04:27:53][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▎    | 1642/3058 [52:39<29:30,  1.25s/it][2025-02-04 04:27:55][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▎    | 1643/3058 [52:40<28:53,  1.23s/it][2025-02-04 04:27:56][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1644/3058 [52:41<26:14,  1.11s/it][2025-02-04 04:27:57][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1645/3058 [52:41<23:09,  1.02it/s][2025-02-04 04:27:57][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1646/3058 [52:42<21:14,  1.11it/s][2025-02-04 04:27:58][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1647/3058 [52:43<24:35,  1.05s/it][2025-02-04 04:27:59][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1648/3058 [52:44<23:07,  1.02it/s][2025-02-04 04:28:01][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1649/3058 [52:46<28:19,  1.21s/it][2025-02-04 04:28:02][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1650/3058 [52:47<29:05,  1.24s/it][2025-02-04 04:28:03][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1651/3058 [52:48<25:48,  1.10s/it][2025-02-04 04:28:04][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1652/3058 [52:49<25:14,  1.08s/it][2025-02-04 04:28:05][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1653/3058 [52:50<25:31,  1.09s/it][2025-02-04 04:28:07][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1654/3058 [52:57<1:05:22,  2.79s/it][2025-02-04 04:28:13][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1655/3058 [52:58<52:36,  2.25s/it]  [2025-02-04 04:28:14][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1656/3058 [52:59<42:42,  1.83s/it][2025-02-04 04:28:15][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1657/3058 [53:01<42:39,  1.83s/it][2025-02-04 04:28:17][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1658/3058 [53:02<39:37,  1.70s/it][2025-02-04 04:28:18][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1659/3058 [53:03<32:39,  1.40s/it][2025-02-04 04:28:19][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1660/3058 [53:04<28:54,  1.24s/it][2025-02-04 04:28:20][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1661/3058 [53:05<30:05,  1.29s/it][2025-02-04 04:28:21][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1662/3058 [53:06<25:58,  1.12s/it][2025-02-04 04:28:22][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1663/3058 [53:07<26:35,  1.14s/it][2025-02-04 04:28:23][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1664/3058 [53:08<25:08,  1.08s/it][2025-02-04 04:28:25][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1665/3058 [53:10<29:41,  1.28s/it][2025-02-04 04:28:26][slam_llm.models.slam_model][INFO] - modality encoder
 54%|█████▍    | 1666/3058 [53:11<29:07,  1.26s/it][2025-02-04 04:28:27][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1667/3058 [53:12<30:00,  1.29s/it][2025-02-04 04:28:29][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1668/3058 [53:14<35:30,  1.53s/it][2025-02-04 04:28:30][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1669/3058 [53:16<35:33,  1.54s/it][2025-02-04 04:28:32][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1670/3058 [53:17<35:37,  1.54s/it][2025-02-04 04:28:34][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1671/3058 [53:19<37:53,  1.64s/it][2025-02-04 04:28:35][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1672/3058 [53:21<36:51,  1.60s/it][2025-02-04 04:28:37][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1673/3058 [53:23<41:21,  1.79s/it][2025-02-04 04:28:39][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1674/3058 [53:25<45:11,  1.96s/it][2025-02-04 04:28:42][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1675/3058 [53:28<50:00,  2.17s/it][2025-02-04 04:28:44][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1676/3058 [53:30<47:26,  2.06s/it][2025-02-04 04:28:46][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1677/3058 [53:33<56:12,  2.44s/it][2025-02-04 04:28:49][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1678/3058 [53:37<1:03:45,  2.77s/it][2025-02-04 04:28:53][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1679/3058 [53:38<52:51,  2.30s/it]  [2025-02-04 04:28:54][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1680/3058 [53:40<52:31,  2.29s/it][2025-02-04 04:28:56][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▍    | 1681/3058 [53:41<45:07,  1.97s/it][2025-02-04 04:28:57][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1682/3058 [53:42<36:51,  1.61s/it][2025-02-04 04:28:58][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1683/3058 [53:44<38:08,  1.66s/it][2025-02-04 04:29:00][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1684/3058 [53:45<36:23,  1.59s/it][2025-02-04 04:29:02][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1685/3058 [53:47<39:11,  1.71s/it][2025-02-04 04:29:04][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1686/3058 [53:51<53:06,  2.32s/it][2025-02-04 04:29:07][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1687/3058 [53:53<52:58,  2.32s/it][2025-02-04 04:29:10][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1688/3058 [53:55<47:20,  2.07s/it][2025-02-04 04:29:11][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1689/3058 [53:56<44:00,  1.93s/it][2025-02-04 04:29:13][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1690/3058 [53:58<41:58,  1.84s/it][2025-02-04 04:29:14][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1691/3058 [54:00<42:17,  1.86s/it][2025-02-04 04:29:16][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1692/3058 [54:01<38:45,  1.70s/it][2025-02-04 04:29:17][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1693/3058 [54:02<32:30,  1.43s/it][2025-02-04 04:29:18][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1694/3058 [54:04<33:30,  1.47s/it][2025-02-04 04:29:20][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1695/3058 [54:06<36:11,  1.59s/it][2025-02-04 04:29:22][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1696/3058 [54:07<34:19,  1.51s/it][2025-02-04 04:29:23][slam_llm.models.slam_model][INFO] - modality encoder
 55%|█████▌    | 1697/3058 [54:09<36:05,  1.59s/it][2025-02-04 04:29:25][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1698/3058 [54:10<37:13,  1.64s/it][2025-02-04 04:29:27][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1699/3058 [54:11<32:11,  1.42s/it][2025-02-04 04:29:28][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1700/3058 [54:13<30:25,  1.34s/it][2025-02-04 04:29:29][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1701/3058 [54:15<35:07,  1.55s/it][2025-02-04 04:29:31][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1702/3058 [54:16<36:10,  1.60s/it][2025-02-04 04:29:32][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1703/3058 [54:18<36:22,  1.61s/it][2025-02-04 04:29:34][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1704/3058 [54:19<34:30,  1.53s/it][2025-02-04 04:29:35][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1705/3058 [54:20<32:10,  1.43s/it][2025-02-04 04:29:37][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1706/3058 [54:22<36:21,  1.61s/it][2025-02-04 04:29:39][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1707/3058 [54:24<36:16,  1.61s/it][2025-02-04 04:29:40][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1708/3058 [54:26<36:39,  1.63s/it][2025-02-04 04:29:42][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1709/3058 [54:28<41:05,  1.83s/it][2025-02-04 04:29:44][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1710/3058 [54:30<39:20,  1.75s/it][2025-02-04 04:29:46][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1711/3058 [54:31<35:52,  1.60s/it][2025-02-04 04:29:47][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1712/3058 [54:32<32:23,  1.44s/it][2025-02-04 04:29:48][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1713/3058 [54:33<31:43,  1.42s/it][2025-02-04 04:29:50][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1714/3058 [54:35<35:48,  1.60s/it][2025-02-04 04:29:52][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1715/3058 [54:38<44:38,  1.99s/it][2025-02-04 04:29:55][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1716/3058 [54:41<49:45,  2.22s/it][2025-02-04 04:29:57][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1717/3058 [54:42<42:31,  1.90s/it][2025-02-04 04:29:58][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1718/3058 [54:44<41:44,  1.87s/it][2025-02-04 04:30:00][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1719/3058 [54:45<39:18,  1.76s/it][2025-02-04 04:30:02][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▌    | 1720/3058 [54:48<44:11,  1.98s/it][2025-02-04 04:30:04][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▋    | 1721/3058 [54:49<37:10,  1.67s/it][2025-02-04 04:30:05][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▋    | 1722/3058 [54:50<31:27,  1.41s/it][2025-02-04 04:30:06][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▋    | 1723/3058 [54:53<40:53,  1.84s/it][2025-02-04 04:30:09][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▋    | 1724/3058 [54:54<38:42,  1.74s/it][2025-02-04 04:30:11][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▋    | 1725/3058 [54:56<40:45,  1.83s/it][2025-02-04 04:30:12][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▋    | 1726/3058 [54:58<38:11,  1.72s/it][2025-02-04 04:30:14][slam_llm.models.slam_model][INFO] - modality encoder
 56%|█████▋    | 1727/3058 [54:59<37:19,  1.68s/it][2025-02-04 04:30:15][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1728/3058 [55:01<38:53,  1.75s/it][2025-02-04 04:30:17][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1729/3058 [55:02<35:15,  1.59s/it][2025-02-04 04:30:18][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1730/3058 [55:04<35:52,  1.62s/it][2025-02-04 04:30:20][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1731/3058 [55:07<42:05,  1.90s/it][2025-02-04 04:30:23][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1732/3058 [55:08<36:34,  1.66s/it][2025-02-04 04:30:24][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1733/3058 [55:09<34:12,  1.55s/it][2025-02-04 04:30:25][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1734/3058 [55:11<35:45,  1.62s/it][2025-02-04 04:30:27][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1735/3058 [55:12<33:02,  1.50s/it][2025-02-04 04:30:28][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1736/3058 [55:13<30:36,  1.39s/it][2025-02-04 04:30:29][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1737/3058 [55:14<28:39,  1.30s/it][2025-02-04 04:30:30][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1738/3058 [55:16<30:13,  1.37s/it][2025-02-04 04:30:32][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1739/3058 [55:17<29:28,  1.34s/it][2025-02-04 04:30:33][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1740/3058 [55:19<34:57,  1.59s/it][2025-02-04 04:30:36][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1741/3058 [55:23<46:38,  2.12s/it][2025-02-04 04:30:39][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1742/3058 [55:26<53:43,  2.45s/it][2025-02-04 04:30:42][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1743/3058 [55:27<47:58,  2.19s/it][2025-02-04 04:30:43][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1744/3058 [55:29<44:22,  2.03s/it][2025-02-04 04:30:45][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1745/3058 [55:31<45:15,  2.07s/it][2025-02-04 04:30:47][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1746/3058 [55:33<42:37,  1.95s/it][2025-02-04 04:30:49][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1747/3058 [55:34<36:21,  1.66s/it][2025-02-04 04:30:50][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1748/3058 [55:36<37:07,  1.70s/it][2025-02-04 04:30:52][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1749/3058 [55:37<36:40,  1.68s/it][2025-02-04 04:30:53][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1750/3058 [55:39<36:46,  1.69s/it][2025-02-04 04:30:55][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1751/3058 [55:41<38:04,  1.75s/it][2025-02-04 04:30:57][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1752/3058 [55:43<38:01,  1.75s/it][2025-02-04 04:30:59][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1753/3058 [55:45<39:58,  1.84s/it][2025-02-04 04:31:01][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1754/3058 [55:46<40:00,  1.84s/it][2025-02-04 04:31:03][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1755/3058 [55:48<37:37,  1.73s/it][2025-02-04 04:31:04][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1756/3058 [55:51<46:22,  2.14s/it][2025-02-04 04:31:07][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1757/3058 [55:54<52:25,  2.42s/it][2025-02-04 04:31:10][slam_llm.models.slam_model][INFO] - modality encoder
 57%|█████▋    | 1758/3058 [55:55<43:15,  2.00s/it][2025-02-04 04:31:11][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1759/3058 [55:57<44:02,  2.03s/it][2025-02-04 04:31:13][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1760/3058 [55:58<38:10,  1.76s/it][2025-02-04 04:31:15][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1761/3058 [56:01<45:58,  2.13s/it][2025-02-04 04:31:17][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1762/3058 [56:03<42:58,  1.99s/it][2025-02-04 04:31:19][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1763/3058 [56:04<38:47,  1.80s/it][2025-02-04 04:31:20][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1764/3058 [56:05<33:49,  1.57s/it][2025-02-04 04:31:22][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1765/3058 [56:08<37:45,  1.75s/it][2025-02-04 04:31:24][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1766/3058 [56:09<34:06,  1.58s/it][2025-02-04 04:31:25][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1767/3058 [56:11<41:28,  1.93s/it][2025-02-04 04:31:28][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1768/3058 [56:14<46:30,  2.16s/it][2025-02-04 04:31:31][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1769/3058 [56:18<54:07,  2.52s/it][2025-02-04 04:31:34][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1770/3058 [56:21<57:44,  2.69s/it][2025-02-04 04:31:37][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1771/3058 [56:24<59:29,  2.77s/it][2025-02-04 04:31:40][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1772/3058 [56:25<52:45,  2.46s/it][2025-02-04 04:31:41][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1773/3058 [56:27<45:14,  2.11s/it][2025-02-04 04:31:43][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1774/3058 [56:29<43:48,  2.05s/it][2025-02-04 04:31:45][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1775/3058 [56:32<52:43,  2.47s/it][2025-02-04 04:31:48][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1776/3058 [56:35<53:28,  2.50s/it][2025-02-04 04:31:51][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1777/3058 [56:37<51:32,  2.41s/it][2025-02-04 04:31:53][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1778/3058 [56:38<43:47,  2.05s/it][2025-02-04 04:31:54][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1779/3058 [56:40<40:52,  1.92s/it][2025-02-04 04:31:56][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1780/3058 [56:42<46:15,  2.17s/it][2025-02-04 04:31:59][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1781/3058 [56:46<55:24,  2.60s/it][2025-02-04 04:32:02][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1782/3058 [56:48<53:48,  2.53s/it][2025-02-04 04:32:04][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1783/3058 [56:50<46:20,  2.18s/it][2025-02-04 04:32:06][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1784/3058 [56:53<52:31,  2.47s/it][2025-02-04 04:32:09][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1785/3058 [56:55<51:02,  2.41s/it][2025-02-04 04:32:11][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1786/3058 [56:58<56:05,  2.65s/it][2025-02-04 04:32:15][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1787/3058 [57:02<59:56,  2.83s/it][2025-02-04 04:32:18][slam_llm.models.slam_model][INFO] - modality encoder
 58%|█████▊    | 1788/3058 [57:04<55:41,  2.63s/it][2025-02-04 04:32:20][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▊    | 1789/3058 [57:06<55:10,  2.61s/it][2025-02-04 04:32:22][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▊    | 1790/3058 [57:08<52:13,  2.47s/it][2025-02-04 04:32:25][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▊    | 1791/3058 [57:12<56:12,  2.66s/it][2025-02-04 04:32:28][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▊    | 1792/3058 [57:13<49:13,  2.33s/it][2025-02-04 04:32:29][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▊    | 1793/3058 [57:15<48:38,  2.31s/it][2025-02-04 04:32:31][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▊    | 1794/3058 [57:22<1:13:12,  3.48s/it][2025-02-04 04:32:38][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▊    | 1795/3058 [57:24<1:07:32,  3.21s/it][2025-02-04 04:32:40][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▊    | 1796/3058 [57:27<1:06:44,  3.17s/it][2025-02-04 04:32:43][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1797/3058 [57:29<58:14,  2.77s/it]  [2025-02-04 04:32:45][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1798/3058 [57:35<1:15:56,  3.62s/it][2025-02-04 04:32:51][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1799/3058 [57:38<1:14:11,  3.54s/it][2025-02-04 04:32:54][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1800/3058 [57:40<1:07:18,  3.21s/it][2025-02-04 04:32:57][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1801/3058 [57:43<1:02:17,  2.97s/it][2025-02-04 04:32:59][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1802/3058 [57:44<52:21,  2.50s/it]  [2025-02-04 04:33:01][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1803/3058 [57:47<52:35,  2.51s/it][2025-02-04 04:33:03][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1804/3058 [57:49<51:34,  2.47s/it][2025-02-04 04:33:05][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1805/3058 [57:52<52:09,  2.50s/it][2025-02-04 04:33:08][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1806/3058 [57:56<1:00:23,  2.89s/it][2025-02-04 04:33:12][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1807/3058 [57:58<55:09,  2.65s/it]  [2025-02-04 04:33:14][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1808/3058 [58:00<54:55,  2.64s/it][2025-02-04 04:33:16][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1809/3058 [58:03<57:47,  2.78s/it][2025-02-04 04:33:19][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1810/3058 [58:04<46:38,  2.24s/it][2025-02-04 04:33:20][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1811/3058 [58:06<44:55,  2.16s/it][2025-02-04 04:33:22][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1812/3058 [58:08<38:59,  1.88s/it][2025-02-04 04:33:24][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1813/3058 [58:09<39:06,  1.88s/it][2025-02-04 04:33:26][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1814/3058 [58:13<48:05,  2.32s/it][2025-02-04 04:33:29][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1815/3058 [58:16<52:17,  2.52s/it][2025-02-04 04:33:32][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1816/3058 [58:19<54:21,  2.63s/it][2025-02-04 04:33:35][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1817/3058 [58:22<58:31,  2.83s/it][2025-02-04 04:33:38][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1818/3058 [58:26<1:04:02,  3.10s/it][2025-02-04 04:33:42][slam_llm.models.slam_model][INFO] - modality encoder
 59%|█████▉    | 1819/3058 [58:29<1:03:54,  3.10s/it][2025-02-04 04:33:45][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1820/3058 [58:32<1:04:26,  3.12s/it][2025-02-04 04:33:48][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1821/3058 [58:34<1:00:48,  2.95s/it][2025-02-04 04:33:51][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1822/3058 [58:37<56:23,  2.74s/it]  [2025-02-04 04:33:53][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1823/3058 [58:39<54:23,  2.64s/it][2025-02-04 04:33:55][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1824/3058 [58:41<48:08,  2.34s/it][2025-02-04 04:33:57][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1825/3058 [58:44<53:14,  2.59s/it][2025-02-04 04:34:00][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1826/3058 [58:47<53:57,  2.63s/it][2025-02-04 04:34:03][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1827/3058 [58:52<1:07:59,  3.31s/it][2025-02-04 04:34:08][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1828/3058 [58:53<58:49,  2.87s/it]  [2025-02-04 04:34:10][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1829/3058 [58:56<57:39,  2.81s/it][2025-02-04 04:34:12][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1830/3058 [58:58<51:02,  2.49s/it][2025-02-04 04:34:14][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1831/3058 [59:00<49:21,  2.41s/it][2025-02-04 04:34:16][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1832/3058 [59:03<51:27,  2.52s/it][2025-02-04 04:34:19][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1833/3058 [59:06<54:37,  2.68s/it][2025-02-04 04:34:22][slam_llm.models.slam_model][INFO] - modality encoder
 60%|█████▉    | 1834/3058 [59:11<1:08:28,  3.36s/it][2025-02-04 04:34:27][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1835/3058 [59:12<56:44,  2.78s/it]  [2025-02-04 04:34:28][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1836/3058 [59:15<57:40,  2.83s/it][2025-02-04 04:34:31][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1837/3058 [59:17<50:36,  2.49s/it][2025-02-04 04:34:33][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1838/3058 [59:19<48:09,  2.37s/it][2025-02-04 04:34:35][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1839/3058 [59:22<51:34,  2.54s/it][2025-02-04 04:34:38][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1840/3058 [59:25<52:36,  2.59s/it][2025-02-04 04:34:41][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1841/3058 [59:26<47:01,  2.32s/it][2025-02-04 04:34:43][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1842/3058 [59:30<53:49,  2.66s/it][2025-02-04 04:34:46][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1843/3058 [59:32<53:08,  2.62s/it][2025-02-04 04:34:48][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1844/3058 [59:34<47:06,  2.33s/it][2025-02-04 04:34:50][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1845/3058 [59:36<45:08,  2.23s/it][2025-02-04 04:34:52][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1846/3058 [59:39<49:21,  2.44s/it][2025-02-04 04:34:55][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1847/3058 [59:41<46:57,  2.33s/it][2025-02-04 04:34:57][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1848/3058 [59:45<57:30,  2.85s/it][2025-02-04 04:35:01][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1849/3058 [59:49<1:02:00,  3.08s/it][2025-02-04 04:35:05][slam_llm.models.slam_model][INFO] - modality encoder
 60%|██████    | 1850/3058 [59:50<53:36,  2.66s/it]  [2025-02-04 04:35:07][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1851/3058 [59:55<1:03:05,  3.14s/it][2025-02-04 04:35:11][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1852/3058 [59:58<1:03:09,  3.14s/it][2025-02-04 04:35:14][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1853/3058 [1:00:00<56:42,  2.82s/it][2025-02-04 04:35:16][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1854/3058 [1:00:03<58:34,  2.92s/it][2025-02-04 04:35:19][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1855/3058 [1:00:06<59:18,  2.96s/it][2025-02-04 04:35:22][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1856/3058 [1:00:09<58:11,  2.90s/it][2025-02-04 04:35:25][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1857/3058 [1:00:10<50:09,  2.51s/it][2025-02-04 04:35:27][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1858/3058 [1:00:15<1:03:29,  3.17s/it][2025-02-04 04:35:31][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1859/3058 [1:00:18<1:02:14,  3.11s/it][2025-02-04 04:35:34][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1860/3058 [1:00:20<57:48,  2.90s/it]  [2025-02-04 04:35:37][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1861/3058 [1:00:23<55:08,  2.76s/it][2025-02-04 04:35:39][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1862/3058 [1:00:25<52:25,  2.63s/it][2025-02-04 04:35:41][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1863/3058 [1:00:28<54:43,  2.75s/it][2025-02-04 04:35:44][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1864/3058 [1:00:29<45:45,  2.30s/it][2025-02-04 04:35:46][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1865/3058 [1:00:31<43:38,  2.20s/it][2025-02-04 04:35:48][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1866/3058 [1:00:33<42:46,  2.15s/it][2025-02-04 04:35:50][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1867/3058 [1:00:36<42:01,  2.12s/it][2025-02-04 04:35:52][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1868/3058 [1:00:36<34:24,  1.73s/it][2025-02-04 04:35:52][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1869/3058 [1:00:38<31:40,  1.60s/it][2025-02-04 04:35:54][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1870/3058 [1:00:39<32:35,  1.65s/it][2025-02-04 04:35:55][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1871/3058 [1:00:41<30:23,  1.54s/it][2025-02-04 04:35:57][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1872/3058 [1:00:43<35:31,  1.80s/it][2025-02-04 04:35:59][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████    | 1873/3058 [1:00:45<35:40,  1.81s/it][2025-02-04 04:36:01][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████▏   | 1874/3058 [1:00:47<34:45,  1.76s/it][2025-02-04 04:36:03][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████▏   | 1875/3058 [1:00:49<36:35,  1.86s/it][2025-02-04 04:36:05][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████▏   | 1876/3058 [1:00:50<32:46,  1.66s/it][2025-02-04 04:36:06][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████▏   | 1877/3058 [1:00:52<34:55,  1.77s/it][2025-02-04 04:36:08][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████▏   | 1878/3058 [1:00:54<35:42,  1.82s/it][2025-02-04 04:36:10][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████▏   | 1879/3058 [1:00:57<45:39,  2.32s/it][2025-02-04 04:36:13][slam_llm.models.slam_model][INFO] - modality encoder
 61%|██████▏   | 1880/3058 [1:00:58<37:15,  1.90s/it][2025-02-04 04:36:14][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1881/3058 [1:01:00<39:28,  2.01s/it][2025-02-04 04:36:17][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1882/3058 [1:01:03<42:25,  2.16s/it][2025-02-04 04:36:19][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1883/3058 [1:01:06<47:42,  2.44s/it][2025-02-04 04:36:22][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1884/3058 [1:01:09<50:00,  2.56s/it][2025-02-04 04:36:25][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1885/3058 [1:01:13<59:37,  3.05s/it][2025-02-04 04:36:29][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1886/3058 [1:01:20<1:21:31,  4.17s/it][2025-02-04 04:36:36][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1887/3058 [1:01:23<1:15:03,  3.85s/it][2025-02-04 04:36:39][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1888/3058 [1:01:26<1:11:11,  3.65s/it][2025-02-04 04:36:42][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1889/3058 [1:01:29<1:08:28,  3.51s/it][2025-02-04 04:36:46][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1890/3058 [1:01:32<1:01:31,  3.16s/it][2025-02-04 04:36:48][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1891/3058 [1:01:34<56:58,  2.93s/it]  [2025-02-04 04:36:50][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1892/3058 [1:01:37<59:25,  3.06s/it][2025-02-04 04:36:54][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1893/3058 [1:01:40<58:17,  3.00s/it][2025-02-04 04:36:56][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1894/3058 [1:01:42<53:07,  2.74s/it][2025-02-04 04:36:59][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1895/3058 [1:01:44<46:27,  2.40s/it][2025-02-04 04:37:00][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1896/3058 [1:01:46<42:34,  2.20s/it][2025-02-04 04:37:02][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1897/3058 [1:01:48<41:49,  2.16s/it][2025-02-04 04:37:04][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1898/3058 [1:01:50<39:00,  2.02s/it][2025-02-04 04:37:06][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1899/3058 [1:01:52<41:14,  2.14s/it][2025-02-04 04:37:08][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1900/3058 [1:01:53<36:20,  1.88s/it][2025-02-04 04:37:09][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1901/3058 [1:02:00<1:02:30,  3.24s/it][2025-02-04 04:37:16][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1902/3058 [1:02:02<59:26,  3.08s/it]  [2025-02-04 04:37:19][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1903/3058 [1:02:04<52:38,  2.73s/it][2025-02-04 04:37:20][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1904/3058 [1:02:06<45:42,  2.38s/it][2025-02-04 04:37:22][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1905/3058 [1:02:07<38:24,  2.00s/it][2025-02-04 04:37:23][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1906/3058 [1:02:08<34:24,  1.79s/it][2025-02-04 04:37:24][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1907/3058 [1:02:09<30:00,  1.56s/it][2025-02-04 04:37:26][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1908/3058 [1:02:11<32:31,  1.70s/it][2025-02-04 04:37:27][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1909/3058 [1:02:13<31:11,  1.63s/it][2025-02-04 04:37:29][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1910/3058 [1:02:14<28:11,  1.47s/it][2025-02-04 04:37:30][slam_llm.models.slam_model][INFO] - modality encoder
 62%|██████▏   | 1911/3058 [1:02:16<31:49,  1.66s/it][2025-02-04 04:37:32][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1912/3058 [1:02:18<32:24,  1.70s/it][2025-02-04 04:37:34][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1913/3058 [1:02:20<37:37,  1.97s/it][2025-02-04 04:37:37][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1914/3058 [1:02:23<40:05,  2.10s/it][2025-02-04 04:37:39][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1915/3058 [1:02:26<48:44,  2.56s/it][2025-02-04 04:37:43][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1916/3058 [1:02:28<42:45,  2.25s/it][2025-02-04 04:37:44][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1917/3058 [1:02:29<33:06,  1.74s/it][2025-02-04 04:37:45][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1918/3058 [1:02:29<26:21,  1.39s/it][2025-02-04 04:37:45][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1919/3058 [1:02:30<23:53,  1.26s/it][2025-02-04 04:37:46][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1920/3058 [1:02:31<21:39,  1.14s/it][2025-02-04 04:37:47][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1921/3058 [1:02:32<20:17,  1.07s/it][2025-02-04 04:37:48][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1922/3058 [1:02:33<20:25,  1.08s/it][2025-02-04 04:37:49][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1923/3058 [1:02:34<21:11,  1.12s/it][2025-02-04 04:37:50][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1924/3058 [1:02:35<19:57,  1.06s/it][2025-02-04 04:37:51][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1925/3058 [1:02:36<19:42,  1.04s/it][2025-02-04 04:37:52][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1926/3058 [1:02:37<18:39,  1.01it/s][2025-02-04 04:37:53][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1927/3058 [1:02:38<20:24,  1.08s/it][2025-02-04 04:37:54][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1928/3058 [1:02:39<16:49,  1.12it/s][2025-02-04 04:37:55][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1929/3058 [1:02:40<20:02,  1.07s/it][2025-02-04 04:37:56][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1930/3058 [1:02:41<21:41,  1.15s/it][2025-02-04 04:37:58][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1931/3058 [1:02:43<22:26,  1.19s/it][2025-02-04 04:37:59][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1932/3058 [1:02:44<22:44,  1.21s/it][2025-02-04 04:38:00][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1933/3058 [1:02:45<19:57,  1.06s/it][2025-02-04 04:38:01][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1934/3058 [1:02:45<16:34,  1.13it/s][2025-02-04 04:38:01][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1935/3058 [1:02:46<17:39,  1.06it/s][2025-02-04 04:38:03][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1936/3058 [1:02:48<23:45,  1.27s/it][2025-02-04 04:38:05][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1937/3058 [1:02:50<24:40,  1.32s/it][2025-02-04 04:38:06][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1938/3058 [1:02:50<20:37,  1.11s/it][2025-02-04 04:38:06][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1939/3058 [1:02:51<18:09,  1.03it/s][2025-02-04 04:38:07][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1940/3058 [1:02:52<17:16,  1.08it/s][2025-02-04 04:38:08][slam_llm.models.slam_model][INFO] - modality encoder
 63%|██████▎   | 1941/3058 [1:02:53<19:46,  1.06s/it][2025-02-04 04:38:09][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▎   | 1942/3058 [1:02:54<19:21,  1.04s/it][2025-02-04 04:38:10][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▎   | 1943/3058 [1:02:55<18:48,  1.01s/it][2025-02-04 04:38:11][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▎   | 1944/3058 [1:02:56<17:10,  1.08it/s][2025-02-04 04:38:12][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▎   | 1945/3058 [1:02:57<16:38,  1.11it/s][2025-02-04 04:38:13][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▎   | 1946/3058 [1:02:58<18:50,  1.02s/it][2025-02-04 04:38:14][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▎   | 1947/3058 [1:02:59<20:56,  1.13s/it][2025-02-04 04:38:16][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▎   | 1948/3058 [1:03:01<24:00,  1.30s/it][2025-02-04 04:38:17][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▎   | 1949/3058 [1:03:02<20:40,  1.12s/it][2025-02-04 04:38:18][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1950/3058 [1:03:03<20:16,  1.10s/it][2025-02-04 04:38:19][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1951/3058 [1:03:04<21:33,  1.17s/it][2025-02-04 04:38:20][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1952/3058 [1:03:05<19:18,  1.05s/it][2025-02-04 04:38:21][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1953/3058 [1:03:06<21:01,  1.14s/it][2025-02-04 04:38:22][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1954/3058 [1:03:08<22:32,  1.23s/it][2025-02-04 04:38:24][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1955/3058 [1:03:10<26:26,  1.44s/it][2025-02-04 04:38:26][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1956/3058 [1:03:11<25:40,  1.40s/it][2025-02-04 04:38:27][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1957/3058 [1:03:12<22:52,  1.25s/it][2025-02-04 04:38:28][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1958/3058 [1:03:14<26:08,  1.43s/it][2025-02-04 04:38:30][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1959/3058 [1:03:15<25:52,  1.41s/it][2025-02-04 04:38:32][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1960/3058 [1:03:19<41:09,  2.25s/it][2025-02-04 04:38:35][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1961/3058 [1:03:21<39:42,  2.17s/it][2025-02-04 04:38:37][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1962/3058 [1:03:23<37:26,  2.05s/it][2025-02-04 04:38:39][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1963/3058 [1:03:24<33:57,  1.86s/it][2025-02-04 04:38:41][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1964/3058 [1:03:26<34:40,  1.90s/it][2025-02-04 04:38:43][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1965/3058 [1:03:28<30:38,  1.68s/it][2025-02-04 04:38:44][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1966/3058 [1:03:28<25:51,  1.42s/it][2025-02-04 04:38:45][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1967/3058 [1:03:29<22:31,  1.24s/it][2025-02-04 04:38:45][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1968/3058 [1:03:30<20:50,  1.15s/it][2025-02-04 04:38:46][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1969/3058 [1:03:32<22:59,  1.27s/it][2025-02-04 04:38:48][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1970/3058 [1:03:33<23:17,  1.28s/it][2025-02-04 04:38:49][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1971/3058 [1:03:35<26:29,  1.46s/it][2025-02-04 04:38:51][slam_llm.models.slam_model][INFO] - modality encoder
 64%|██████▍   | 1972/3058 [1:03:37<27:08,  1.50s/it][2025-02-04 04:38:53][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1973/3058 [1:03:38<25:01,  1.38s/it][2025-02-04 04:38:54][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1974/3058 [1:03:38<21:36,  1.20s/it][2025-02-04 04:38:55][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1975/3058 [1:03:40<25:40,  1.42s/it][2025-02-04 04:38:56][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1976/3058 [1:03:41<21:49,  1.21s/it][2025-02-04 04:38:57][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1977/3058 [1:03:43<24:52,  1.38s/it][2025-02-04 04:38:59][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1978/3058 [1:03:44<21:57,  1.22s/it][2025-02-04 04:39:00][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1979/3058 [1:03:46<27:44,  1.54s/it][2025-02-04 04:39:02][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1980/3058 [1:03:48<28:34,  1.59s/it][2025-02-04 04:39:04][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1981/3058 [1:03:50<32:43,  1.82s/it][2025-02-04 04:39:06][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1982/3058 [1:03:51<30:12,  1.68s/it][2025-02-04 04:39:08][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1983/3058 [1:03:53<27:40,  1.54s/it][2025-02-04 04:39:09][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1984/3058 [1:03:53<23:50,  1.33s/it][2025-02-04 04:39:10][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1985/3058 [1:03:55<26:04,  1.46s/it][2025-02-04 04:39:11][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1986/3058 [1:03:57<26:39,  1.49s/it][2025-02-04 04:39:13][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▍   | 1987/3058 [1:03:58<23:49,  1.34s/it][2025-02-04 04:39:14][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 1988/3058 [1:04:00<27:30,  1.54s/it][2025-02-04 04:39:16][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 1989/3058 [1:04:01<28:17,  1.59s/it][2025-02-04 04:39:18][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 1990/3058 [1:04:04<32:38,  1.83s/it][2025-02-04 04:39:20][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 1991/3058 [1:04:06<34:06,  1.92s/it][2025-02-04 04:39:23][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 1992/3058 [1:04:09<38:05,  2.14s/it][2025-02-04 04:39:25][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 1993/3058 [1:04:10<32:24,  1.83s/it][2025-02-04 04:39:26][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 1994/3058 [1:04:11<28:38,  1.62s/it][2025-02-04 04:39:27][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 1995/3058 [1:04:13<29:07,  1.64s/it][2025-02-04 04:39:29][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 1996/3058 [1:04:13<24:18,  1.37s/it][2025-02-04 04:39:29][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 1997/3058 [1:04:14<20:40,  1.17s/it][2025-02-04 04:39:30][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 1998/3058 [1:04:16<23:32,  1.33s/it][2025-02-04 04:39:32][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 1999/3058 [1:04:17<21:58,  1.24s/it][2025-02-04 04:39:33][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 2000/3058 [1:04:19<28:43,  1.63s/it][2025-02-04 04:39:36][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 2001/3058 [1:04:21<27:45,  1.58s/it][2025-02-04 04:39:37][slam_llm.models.slam_model][INFO] - modality encoder
 65%|██████▌   | 2002/3058 [1:04:23<28:58,  1.65s/it][2025-02-04 04:39:39][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2003/3058 [1:04:25<34:17,  1.95s/it][2025-02-04 04:39:41][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2004/3058 [1:04:26<28:45,  1.64s/it][2025-02-04 04:39:42][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2005/3058 [1:04:28<32:01,  1.83s/it][2025-02-04 04:39:45][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2006/3058 [1:04:30<29:35,  1.69s/it][2025-02-04 04:39:46][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2007/3058 [1:04:31<28:39,  1.64s/it][2025-02-04 04:39:48][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2008/3058 [1:04:34<33:30,  1.91s/it][2025-02-04 04:39:50][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2009/3058 [1:04:36<33:13,  1.90s/it][2025-02-04 04:39:52][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2010/3058 [1:04:38<36:19,  2.08s/it][2025-02-04 04:39:55][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2011/3058 [1:04:41<40:20,  2.31s/it][2025-02-04 04:39:57][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2012/3058 [1:04:42<35:22,  2.03s/it][2025-02-04 04:39:59][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2013/3058 [1:04:44<32:22,  1.86s/it][2025-02-04 04:40:00][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2014/3058 [1:04:45<26:18,  1.51s/it][2025-02-04 04:40:01][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2015/3058 [1:04:46<27:32,  1.58s/it][2025-02-04 04:40:02][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2016/3058 [1:04:48<26:58,  1.55s/it][2025-02-04 04:40:04][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2017/3058 [1:04:49<27:27,  1.58s/it][2025-02-04 04:40:06][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2018/3058 [1:04:52<31:28,  1.82s/it][2025-02-04 04:40:08][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2019/3058 [1:04:53<29:38,  1.71s/it][2025-02-04 04:40:09][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2020/3058 [1:04:55<27:35,  1.59s/it][2025-02-04 04:40:11][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2021/3058 [1:04:56<26:04,  1.51s/it][2025-02-04 04:40:12][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2022/3058 [1:04:58<28:10,  1.63s/it][2025-02-04 04:40:14][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2023/3058 [1:05:00<31:09,  1.81s/it][2025-02-04 04:40:16][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2024/3058 [1:05:07<57:15,  3.32s/it][2025-02-04 04:40:24][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▌   | 2025/3058 [1:05:10<56:39,  3.29s/it][2025-02-04 04:40:26][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▋   | 2026/3058 [1:05:12<50:20,  2.93s/it][2025-02-04 04:40:28][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▋   | 2027/3058 [1:05:14<46:09,  2.69s/it][2025-02-04 04:40:31][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▋   | 2028/3058 [1:05:16<40:09,  2.34s/it][2025-02-04 04:40:32][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▋   | 2029/3058 [1:05:17<36:12,  2.11s/it][2025-02-04 04:40:34][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▋   | 2030/3058 [1:05:18<29:40,  1.73s/it][2025-02-04 04:40:34][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▋   | 2031/3058 [1:05:19<23:56,  1.40s/it][2025-02-04 04:40:35][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▋   | 2032/3058 [1:05:20<21:21,  1.25s/it][2025-02-04 04:40:36][slam_llm.models.slam_model][INFO] - modality encoder
 66%|██████▋   | 2033/3058 [1:05:22<23:58,  1.40s/it][2025-02-04 04:40:38][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2034/3058 [1:05:23<23:34,  1.38s/it][2025-02-04 04:40:39][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2035/3058 [1:05:24<21:32,  1.26s/it][2025-02-04 04:40:40][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2036/3058 [1:05:25<22:26,  1.32s/it][2025-02-04 04:40:42][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2037/3058 [1:05:27<23:42,  1.39s/it][2025-02-04 04:40:43][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2038/3058 [1:05:28<23:19,  1.37s/it][2025-02-04 04:40:44][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2039/3058 [1:05:29<22:35,  1.33s/it][2025-02-04 04:40:46][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2040/3058 [1:05:30<20:59,  1.24s/it][2025-02-04 04:40:47][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2041/3058 [1:05:32<24:03,  1.42s/it][2025-02-04 04:40:49][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2042/3058 [1:05:35<29:58,  1.77s/it][2025-02-04 04:40:51][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2043/3058 [1:05:36<24:12,  1.43s/it][2025-02-04 04:40:52][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2044/3058 [1:05:37<26:01,  1.54s/it][2025-02-04 04:40:54][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2045/3058 [1:05:39<24:47,  1.47s/it][2025-02-04 04:40:55][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2046/3058 [1:05:40<26:29,  1.57s/it][2025-02-04 04:40:57][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2047/3058 [1:05:42<24:12,  1.44s/it][2025-02-04 04:40:58][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2048/3058 [1:05:43<25:22,  1.51s/it][2025-02-04 04:41:00][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2049/3058 [1:05:45<27:34,  1.64s/it][2025-02-04 04:41:02][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2050/3058 [1:05:47<27:19,  1.63s/it][2025-02-04 04:41:03][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2051/3058 [1:05:48<24:32,  1.46s/it][2025-02-04 04:41:04][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2052/3058 [1:05:51<30:33,  1.82s/it][2025-02-04 04:41:07][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2053/3058 [1:05:52<26:37,  1.59s/it][2025-02-04 04:41:08][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2054/3058 [1:05:53<25:18,  1.51s/it][2025-02-04 04:41:09][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2055/3058 [1:05:54<24:33,  1.47s/it][2025-02-04 04:41:10][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2056/3058 [1:05:55<22:45,  1.36s/it][2025-02-04 04:41:12][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2057/3058 [1:05:56<21:03,  1.26s/it][2025-02-04 04:41:13][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2058/3058 [1:05:57<18:54,  1.13s/it][2025-02-04 04:41:13][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2059/3058 [1:05:58<16:54,  1.02s/it][2025-02-04 04:41:14][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2060/3058 [1:05:59<16:22,  1.02it/s][2025-02-04 04:41:15][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2061/3058 [1:06:00<17:46,  1.07s/it][2025-02-04 04:41:16][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2062/3058 [1:06:01<18:04,  1.09s/it][2025-02-04 04:41:17][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2063/3058 [1:06:02<15:55,  1.04it/s][2025-02-04 04:41:18][slam_llm.models.slam_model][INFO] - modality encoder
 67%|██████▋   | 2064/3058 [1:06:03<13:51,  1.19it/s][2025-02-04 04:41:19][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2065/3058 [1:06:03<14:22,  1.15it/s][2025-02-04 04:41:20][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2066/3058 [1:06:04<14:45,  1.12it/s][2025-02-04 04:41:21][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2067/3058 [1:06:06<17:25,  1.05s/it][2025-02-04 04:41:22][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2068/3058 [1:06:07<16:31,  1.00s/it][2025-02-04 04:41:23][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2069/3058 [1:06:08<17:01,  1.03s/it][2025-02-04 04:41:24][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2070/3058 [1:06:09<18:40,  1.13s/it][2025-02-04 04:41:25][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2071/3058 [1:06:10<18:21,  1.12s/it][2025-02-04 04:41:26][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2072/3058 [1:06:11<18:35,  1.13s/it][2025-02-04 04:41:28][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2073/3058 [1:06:13<20:12,  1.23s/it][2025-02-04 04:41:29][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2074/3058 [1:06:14<19:10,  1.17s/it][2025-02-04 04:41:30][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2075/3058 [1:06:15<18:14,  1.11s/it][2025-02-04 04:41:31][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2076/3058 [1:06:16<17:29,  1.07s/it][2025-02-04 04:41:32][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2077/3058 [1:06:18<22:28,  1.37s/it][2025-02-04 04:41:34][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2078/3058 [1:06:19<20:56,  1.28s/it][2025-02-04 04:41:35][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2079/3058 [1:06:20<20:14,  1.24s/it][2025-02-04 04:41:36][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2080/3058 [1:06:21<20:05,  1.23s/it][2025-02-04 04:41:37][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2081/3058 [1:06:22<17:29,  1.07s/it][2025-02-04 04:41:39][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2082/3058 [1:06:29<46:23,  2.85s/it][2025-02-04 04:41:45][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2083/3058 [1:06:30<34:55,  2.15s/it][2025-02-04 04:41:46][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2084/3058 [1:06:31<30:59,  1.91s/it][2025-02-04 04:41:48][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2085/3058 [1:06:34<34:23,  2.12s/it][2025-02-04 04:41:50][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2086/3058 [1:06:34<27:24,  1.69s/it][2025-02-04 04:41:50][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2087/3058 [1:06:35<23:05,  1.43s/it][2025-02-04 04:41:51][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2088/3058 [1:06:36<20:58,  1.30s/it][2025-02-04 04:41:52][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2089/3058 [1:06:38<22:06,  1.37s/it][2025-02-04 04:41:54][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2090/3058 [1:06:39<22:22,  1.39s/it][2025-02-04 04:41:55][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2091/3058 [1:06:40<21:09,  1.31s/it][2025-02-04 04:41:56][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2092/3058 [1:06:42<22:55,  1.42s/it][2025-02-04 04:41:58][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2093/3058 [1:06:43<22:09,  1.38s/it][2025-02-04 04:41:59][slam_llm.models.slam_model][INFO] - modality encoder
 68%|██████▊   | 2094/3058 [1:06:44<21:36,  1.35s/it][2025-02-04 04:42:01][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▊   | 2095/3058 [1:06:45<19:15,  1.20s/it][2025-02-04 04:42:01][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▊   | 2096/3058 [1:06:46<16:35,  1.03s/it][2025-02-04 04:42:02][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▊   | 2097/3058 [1:06:47<14:40,  1.09it/s][2025-02-04 04:42:03][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▊   | 2098/3058 [1:06:47<13:17,  1.20it/s][2025-02-04 04:42:03][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▊   | 2099/3058 [1:06:48<13:00,  1.23it/s][2025-02-04 04:42:04][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▊   | 2100/3058 [1:06:49<12:04,  1.32it/s][2025-02-04 04:42:05][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▊   | 2101/3058 [1:06:49<12:10,  1.31it/s][2025-02-04 04:42:05][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▊   | 2102/3058 [1:06:51<13:55,  1.14it/s][2025-02-04 04:42:07][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2103/3058 [1:06:51<14:01,  1.13it/s][2025-02-04 04:42:07][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2104/3058 [1:06:52<12:46,  1.25it/s][2025-02-04 04:42:08][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2105/3058 [1:06:53<11:54,  1.33it/s][2025-02-04 04:42:09][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2106/3058 [1:06:53<10:45,  1.48it/s][2025-02-04 04:42:09][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2107/3058 [1:06:54<10:34,  1.50it/s][2025-02-04 04:42:10][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2108/3058 [1:06:54<09:53,  1.60it/s][2025-02-04 04:42:10][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2109/3058 [1:06:55<11:04,  1.43it/s][2025-02-04 04:42:11][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2110/3058 [1:06:56<11:29,  1.37it/s][2025-02-04 04:42:12][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2111/3058 [1:06:57<11:15,  1.40it/s][2025-02-04 04:42:13][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2112/3058 [1:06:57<10:54,  1.44it/s][2025-02-04 04:42:13][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2113/3058 [1:06:58<10:20,  1.52it/s][2025-02-04 04:42:14][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2114/3058 [1:06:59<11:12,  1.40it/s][2025-02-04 04:42:15][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2115/3058 [1:07:00<12:17,  1.28it/s][2025-02-04 04:42:16][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2116/3058 [1:07:01<15:03,  1.04it/s][2025-02-04 04:42:17][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2117/3058 [1:07:02<14:04,  1.11it/s][2025-02-04 04:42:18][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2118/3058 [1:07:02<12:10,  1.29it/s][2025-02-04 04:42:18][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2119/3058 [1:07:03<12:53,  1.21it/s][2025-02-04 04:42:19][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2120/3058 [1:07:04<11:32,  1.35it/s][2025-02-04 04:42:20][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2121/3058 [1:07:04<10:51,  1.44it/s][2025-02-04 04:42:20][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2122/3058 [1:07:05<12:09,  1.28it/s][2025-02-04 04:42:21][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2123/3058 [1:07:06<12:34,  1.24it/s][2025-02-04 04:42:22][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2124/3058 [1:07:07<14:46,  1.05it/s][2025-02-04 04:42:24][slam_llm.models.slam_model][INFO] - modality encoder
 69%|██████▉   | 2125/3058 [1:07:09<17:23,  1.12s/it][2025-02-04 04:42:25][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2126/3058 [1:07:10<18:16,  1.18s/it][2025-02-04 04:42:27][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2127/3058 [1:07:12<18:52,  1.22s/it][2025-02-04 04:42:28][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2128/3058 [1:07:12<16:49,  1.09s/it][2025-02-04 04:42:29][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2129/3058 [1:07:14<16:56,  1.09s/it][2025-02-04 04:42:30][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2130/3058 [1:07:15<17:15,  1.12s/it][2025-02-04 04:42:31][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2131/3058 [1:07:15<14:42,  1.05it/s][2025-02-04 04:42:31][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2132/3058 [1:07:16<14:18,  1.08it/s][2025-02-04 04:42:32][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2133/3058 [1:07:17<15:44,  1.02s/it][2025-02-04 04:42:33][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2134/3058 [1:07:18<14:50,  1.04it/s][2025-02-04 04:42:34][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2135/3058 [1:07:19<12:34,  1.22it/s][2025-02-04 04:42:35][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2136/3058 [1:07:20<13:05,  1.17it/s][2025-02-04 04:42:36][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2137/3058 [1:07:21<15:01,  1.02it/s][2025-02-04 04:42:37][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2138/3058 [1:07:22<13:47,  1.11it/s][2025-02-04 04:42:38][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2139/3058 [1:07:23<16:43,  1.09s/it][2025-02-04 04:42:39][slam_llm.models.slam_model][INFO] - modality encoder
 70%|██████▉   | 2140/3058 [1:07:24<17:44,  1.16s/it][2025-02-04 04:42:41][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2141/3058 [1:07:25<15:29,  1.01s/it][2025-02-04 04:42:41][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2142/3058 [1:07:27<17:13,  1.13s/it][2025-02-04 04:42:43][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2143/3058 [1:07:28<18:18,  1.20s/it][2025-02-04 04:42:44][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2144/3058 [1:07:29<16:18,  1.07s/it][2025-02-04 04:42:45][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2145/3058 [1:07:29<14:04,  1.08it/s][2025-02-04 04:42:45][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2146/3058 [1:07:30<12:38,  1.20it/s][2025-02-04 04:42:46][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2147/3058 [1:07:31<12:20,  1.23it/s][2025-02-04 04:42:47][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2148/3058 [1:07:32<14:29,  1.05it/s][2025-02-04 04:42:48][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2149/3058 [1:07:33<13:27,  1.13it/s][2025-02-04 04:42:49][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2150/3058 [1:07:33<11:36,  1.30it/s][2025-02-04 04:42:49][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2151/3058 [1:07:34<13:56,  1.08it/s][2025-02-04 04:42:51][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2152/3058 [1:07:35<14:13,  1.06it/s][2025-02-04 04:42:51][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2153/3058 [1:07:36<12:47,  1.18it/s][2025-02-04 04:42:52][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2154/3058 [1:07:37<14:07,  1.07it/s][2025-02-04 04:42:53][slam_llm.models.slam_model][INFO] - modality encoder
 70%|███████   | 2155/3058 [1:07:38<15:40,  1.04s/it][2025-02-04 04:42:55][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2156/3058 [1:07:40<15:45,  1.05s/it][2025-02-04 04:42:56][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2157/3058 [1:07:40<15:24,  1.03s/it][2025-02-04 04:42:57][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2158/3058 [1:07:42<18:07,  1.21s/it][2025-02-04 04:42:58][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2159/3058 [1:07:43<16:03,  1.07s/it][2025-02-04 04:42:59][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2160/3058 [1:07:43<13:13,  1.13it/s][2025-02-04 04:42:59][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2161/3058 [1:07:45<14:58,  1.00s/it][2025-02-04 04:43:01][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2162/3058 [1:07:46<14:57,  1.00s/it][2025-02-04 04:43:02][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2163/3058 [1:07:47<15:23,  1.03s/it][2025-02-04 04:43:03][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2164/3058 [1:07:47<13:51,  1.07it/s][2025-02-04 04:43:04][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2165/3058 [1:07:48<14:31,  1.02it/s][2025-02-04 04:43:05][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2166/3058 [1:07:49<13:54,  1.07it/s][2025-02-04 04:43:06][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2167/3058 [1:07:51<17:07,  1.15s/it][2025-02-04 04:43:07][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2168/3058 [1:07:52<15:38,  1.05s/it][2025-02-04 04:43:08][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2169/3058 [1:07:53<15:12,  1.03s/it][2025-02-04 04:43:09][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2170/3058 [1:07:55<18:34,  1.26s/it][2025-02-04 04:43:11][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2171/3058 [1:07:56<19:27,  1.32s/it][2025-02-04 04:43:12][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2172/3058 [1:07:57<19:04,  1.29s/it][2025-02-04 04:43:13][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2173/3058 [1:07:59<19:48,  1.34s/it][2025-02-04 04:43:15][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2174/3058 [1:08:00<20:36,  1.40s/it][2025-02-04 04:43:16][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2175/3058 [1:08:01<19:37,  1.33s/it][2025-02-04 04:43:18][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2176/3058 [1:08:03<19:18,  1.31s/it][2025-02-04 04:43:19][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2177/3058 [1:08:05<22:21,  1.52s/it][2025-02-04 04:43:21][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████   | 2178/3058 [1:08:05<18:50,  1.28s/it][2025-02-04 04:43:22][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████▏  | 2179/3058 [1:08:07<19:10,  1.31s/it][2025-02-04 04:43:23][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████▏  | 2180/3058 [1:08:08<17:14,  1.18s/it][2025-02-04 04:43:24][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████▏  | 2181/3058 [1:08:09<17:43,  1.21s/it][2025-02-04 04:43:25][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████▏  | 2182/3058 [1:08:10<17:22,  1.19s/it][2025-02-04 04:43:26][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████▏  | 2183/3058 [1:08:12<18:40,  1.28s/it][2025-02-04 04:43:28][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████▏  | 2184/3058 [1:08:13<18:15,  1.25s/it][2025-02-04 04:43:29][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████▏  | 2185/3058 [1:08:14<17:20,  1.19s/it][2025-02-04 04:43:30][slam_llm.models.slam_model][INFO] - modality encoder
 71%|███████▏  | 2186/3058 [1:08:15<17:31,  1.21s/it][2025-02-04 04:43:31][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2187/3058 [1:08:16<17:51,  1.23s/it][2025-02-04 04:43:33][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2188/3058 [1:08:17<16:39,  1.15s/it][2025-02-04 04:43:33][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2189/3058 [1:08:18<16:46,  1.16s/it][2025-02-04 04:43:35][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2190/3058 [1:08:19<15:20,  1.06s/it][2025-02-04 04:43:35][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2191/3058 [1:08:21<17:02,  1.18s/it][2025-02-04 04:43:37][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2192/3058 [1:08:22<18:05,  1.25s/it][2025-02-04 04:43:39][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2193/3058 [1:08:24<21:43,  1.51s/it][2025-02-04 04:43:41][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2194/3058 [1:08:26<23:37,  1.64s/it][2025-02-04 04:43:43][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2195/3058 [1:08:28<23:44,  1.65s/it][2025-02-04 04:43:44][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2196/3058 [1:08:30<27:00,  1.88s/it][2025-02-04 04:43:47][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2197/3058 [1:08:33<30:09,  2.10s/it][2025-02-04 04:43:49][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2198/3058 [1:08:35<28:10,  1.97s/it][2025-02-04 04:43:51][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2199/3058 [1:08:36<25:39,  1.79s/it][2025-02-04 04:43:52][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2200/3058 [1:08:38<25:56,  1.81s/it][2025-02-04 04:43:54][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2201/3058 [1:08:39<23:25,  1.64s/it][2025-02-04 04:43:56][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2202/3058 [1:08:42<28:12,  1.98s/it][2025-02-04 04:43:58][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2203/3058 [1:08:43<24:55,  1.75s/it][2025-02-04 04:43:59][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2204/3058 [1:08:45<24:03,  1.69s/it][2025-02-04 04:44:01][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2205/3058 [1:08:47<24:59,  1.76s/it][2025-02-04 04:44:03][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2206/3058 [1:08:47<20:32,  1.45s/it][2025-02-04 04:44:04][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2207/3058 [1:08:51<28:36,  2.02s/it][2025-02-04 04:44:07][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2208/3058 [1:08:52<25:24,  1.79s/it][2025-02-04 04:44:08][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2209/3058 [1:08:54<26:46,  1.89s/it][2025-02-04 04:44:10][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2210/3058 [1:08:55<24:17,  1.72s/it][2025-02-04 04:44:11][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2211/3058 [1:08:56<20:26,  1.45s/it][2025-02-04 04:44:12][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2212/3058 [1:08:57<17:20,  1.23s/it][2025-02-04 04:44:13][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2213/3058 [1:08:58<16:25,  1.17s/it][2025-02-04 04:44:14][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2214/3058 [1:08:59<16:05,  1.14s/it][2025-02-04 04:44:15][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2215/3058 [1:09:01<21:15,  1.51s/it][2025-02-04 04:44:18][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2216/3058 [1:09:02<18:34,  1.32s/it][2025-02-04 04:44:18][slam_llm.models.slam_model][INFO] - modality encoder
 72%|███████▏  | 2217/3058 [1:09:03<17:12,  1.23s/it][2025-02-04 04:44:19][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2218/3058 [1:09:04<14:31,  1.04s/it][2025-02-04 04:44:20][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2219/3058 [1:09:04<12:37,  1.11it/s][2025-02-04 04:44:21][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2220/3058 [1:09:06<14:16,  1.02s/it][2025-02-04 04:44:22][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2221/3058 [1:09:07<14:09,  1.01s/it][2025-02-04 04:44:23][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2222/3058 [1:09:08<13:14,  1.05it/s][2025-02-04 04:44:24][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2223/3058 [1:09:09<14:12,  1.02s/it][2025-02-04 04:44:25][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2224/3058 [1:09:10<13:51,  1.00it/s][2025-02-04 04:44:26][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2225/3058 [1:09:10<11:08,  1.25it/s][2025-02-04 04:44:26][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2226/3058 [1:09:10<09:21,  1.48it/s][2025-02-04 04:44:26][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2227/3058 [1:09:11<08:50,  1.57it/s][2025-02-04 04:44:27][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2228/3058 [1:09:12<08:39,  1.60it/s][2025-02-04 04:44:28][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2229/3058 [1:09:12<08:58,  1.54it/s][2025-02-04 04:44:28][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2230/3058 [1:09:13<09:56,  1.39it/s][2025-02-04 04:44:29][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2231/3058 [1:09:14<08:55,  1.54it/s][2025-02-04 04:44:30][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2232/3058 [1:09:14<08:21,  1.65it/s][2025-02-04 04:44:30][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2233/3058 [1:09:15<08:32,  1.61it/s][2025-02-04 04:44:31][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2234/3058 [1:09:16<09:44,  1.41it/s][2025-02-04 04:44:32][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2235/3058 [1:09:16<08:20,  1.65it/s][2025-02-04 04:44:32][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2236/3058 [1:09:17<08:00,  1.71it/s][2025-02-04 04:44:33][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2237/3058 [1:09:17<08:19,  1.64it/s][2025-02-04 04:44:33][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2238/3058 [1:09:18<08:46,  1.56it/s][2025-02-04 04:44:34][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2239/3058 [1:09:19<09:30,  1.43it/s][2025-02-04 04:44:35][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2240/3058 [1:09:19<08:59,  1.52it/s][2025-02-04 04:44:35][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2241/3058 [1:09:20<08:05,  1.68it/s][2025-02-04 04:44:36][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2242/3058 [1:09:21<10:35,  1.28it/s][2025-02-04 04:44:37][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2243/3058 [1:09:23<15:55,  1.17s/it][2025-02-04 04:44:39][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2244/3058 [1:09:24<14:30,  1.07s/it][2025-02-04 04:44:40][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2245/3058 [1:09:26<16:48,  1.24s/it][2025-02-04 04:44:42][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2246/3058 [1:09:27<15:43,  1.16s/it][2025-02-04 04:44:43][slam_llm.models.slam_model][INFO] - modality encoder
 73%|███████▎  | 2247/3058 [1:09:28<16:05,  1.19s/it][2025-02-04 04:44:44][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▎  | 2248/3058 [1:09:29<14:57,  1.11s/it][2025-02-04 04:44:45][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▎  | 2249/3058 [1:09:30<15:14,  1.13s/it][2025-02-04 04:44:46][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▎  | 2250/3058 [1:09:31<14:16,  1.06s/it][2025-02-04 04:44:47][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▎  | 2251/3058 [1:09:32<15:21,  1.14s/it][2025-02-04 04:44:48][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▎  | 2252/3058 [1:09:38<35:11,  2.62s/it][2025-02-04 04:44:54][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▎  | 2253/3058 [1:09:40<33:28,  2.50s/it][2025-02-04 04:44:56][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▎  | 2254/3058 [1:09:42<28:57,  2.16s/it][2025-02-04 04:44:58][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▎  | 2255/3058 [1:09:43<23:20,  1.74s/it][2025-02-04 04:44:59][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2256/3058 [1:09:45<24:54,  1.86s/it][2025-02-04 04:45:01][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2257/3058 [1:09:46<20:56,  1.57s/it][2025-02-04 04:45:02][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2258/3058 [1:09:47<19:57,  1.50s/it][2025-02-04 04:45:03][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2259/3058 [1:09:48<19:03,  1.43s/it][2025-02-04 04:45:04][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2260/3058 [1:09:50<18:36,  1.40s/it][2025-02-04 04:45:06][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2261/3058 [1:09:52<21:22,  1.61s/it][2025-02-04 04:45:08][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2262/3058 [1:09:53<21:57,  1.65s/it][2025-02-04 04:45:10][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2263/3058 [1:09:55<22:03,  1.66s/it][2025-02-04 04:45:11][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2264/3058 [1:09:56<19:35,  1.48s/it][2025-02-04 04:45:12][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2265/3058 [1:09:57<17:29,  1.32s/it][2025-02-04 04:45:13][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2266/3058 [1:09:59<18:57,  1.44s/it][2025-02-04 04:45:15][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2267/3058 [1:09:59<15:34,  1.18s/it][2025-02-04 04:45:16][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2268/3058 [1:10:01<15:49,  1.20s/it][2025-02-04 04:45:17][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2269/3058 [1:10:02<17:03,  1.30s/it][2025-02-04 04:45:18][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2270/3058 [1:10:03<14:39,  1.12s/it][2025-02-04 04:45:19][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2271/3058 [1:10:04<13:46,  1.05s/it][2025-02-04 04:45:20][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2272/3058 [1:10:05<14:53,  1.14s/it][2025-02-04 04:45:21][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2273/3058 [1:10:06<15:10,  1.16s/it][2025-02-04 04:45:23][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2274/3058 [1:10:08<18:29,  1.42s/it][2025-02-04 04:45:24][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2275/3058 [1:10:09<17:06,  1.31s/it][2025-02-04 04:45:25][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2276/3058 [1:10:10<16:19,  1.25s/it][2025-02-04 04:45:27][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2277/3058 [1:10:11<15:22,  1.18s/it][2025-02-04 04:45:28][slam_llm.models.slam_model][INFO] - modality encoder
 74%|███████▍  | 2278/3058 [1:10:12<13:31,  1.04s/it][2025-02-04 04:45:28][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2279/3058 [1:10:14<17:06,  1.32s/it][2025-02-04 04:45:30][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2280/3058 [1:10:15<15:54,  1.23s/it][2025-02-04 04:45:31][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2281/3058 [1:10:17<16:22,  1.26s/it][2025-02-04 04:45:33][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2282/3058 [1:10:17<14:29,  1.12s/it][2025-02-04 04:45:33][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2283/3058 [1:10:18<12:36,  1.03it/s][2025-02-04 04:45:34][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2284/3058 [1:10:19<13:30,  1.05s/it][2025-02-04 04:45:35][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2285/3058 [1:10:21<14:50,  1.15s/it][2025-02-04 04:45:37][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2286/3058 [1:10:21<12:45,  1.01it/s][2025-02-04 04:45:37][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2287/3058 [1:10:23<16:34,  1.29s/it][2025-02-04 04:45:39][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2288/3058 [1:10:25<18:49,  1.47s/it][2025-02-04 04:45:41][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2289/3058 [1:10:27<19:46,  1.54s/it][2025-02-04 04:45:43][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2290/3058 [1:10:29<20:54,  1.63s/it][2025-02-04 04:45:45][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2291/3058 [1:10:30<19:14,  1.50s/it][2025-02-04 04:45:46][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2292/3058 [1:10:32<21:49,  1.71s/it][2025-02-04 04:45:48][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▍  | 2293/3058 [1:10:33<20:50,  1.64s/it][2025-02-04 04:45:50][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2294/3058 [1:10:35<19:17,  1.52s/it][2025-02-04 04:45:51][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2295/3058 [1:10:38<25:12,  1.98s/it][2025-02-04 04:45:54][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2296/3058 [1:10:41<29:56,  2.36s/it][2025-02-04 04:45:57][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2297/3058 [1:10:42<26:37,  2.10s/it][2025-02-04 04:45:59][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2298/3058 [1:10:45<26:31,  2.09s/it][2025-02-04 04:46:01][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2299/3058 [1:10:45<21:02,  1.66s/it][2025-02-04 04:46:01][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2300/3058 [1:10:46<18:57,  1.50s/it][2025-02-04 04:46:03][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2301/3058 [1:10:48<17:54,  1.42s/it][2025-02-04 04:46:04][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2302/3058 [1:10:48<15:39,  1.24s/it][2025-02-04 04:46:05][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2303/3058 [1:10:49<13:47,  1.10s/it][2025-02-04 04:46:05][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2304/3058 [1:10:50<13:08,  1.05s/it][2025-02-04 04:46:06][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2305/3058 [1:10:52<14:36,  1.16s/it][2025-02-04 04:46:08][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2306/3058 [1:10:53<17:11,  1.37s/it][2025-02-04 04:46:10][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2307/3058 [1:10:55<17:19,  1.38s/it][2025-02-04 04:46:11][slam_llm.models.slam_model][INFO] - modality encoder
 75%|███████▌  | 2308/3058 [1:10:56<17:05,  1.37s/it][2025-02-04 04:46:12][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2309/3058 [1:10:57<16:40,  1.34s/it][2025-02-04 04:46:14][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2310/3058 [1:10:59<18:23,  1.48s/it][2025-02-04 04:46:15][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2311/3058 [1:11:01<18:06,  1.45s/it][2025-02-04 04:46:17][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2312/3058 [1:11:02<17:09,  1.38s/it][2025-02-04 04:46:18][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2313/3058 [1:11:04<18:28,  1.49s/it][2025-02-04 04:46:20][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2314/3058 [1:11:04<16:24,  1.32s/it][2025-02-04 04:46:21][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2315/3058 [1:11:05<14:27,  1.17s/it][2025-02-04 04:46:21][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2316/3058 [1:11:06<13:16,  1.07s/it][2025-02-04 04:46:22][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2317/3058 [1:11:07<13:21,  1.08s/it][2025-02-04 04:46:23][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2318/3058 [1:11:08<14:00,  1.14s/it][2025-02-04 04:46:25][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2319/3058 [1:11:09<13:03,  1.06s/it][2025-02-04 04:46:26][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2320/3058 [1:11:11<14:39,  1.19s/it][2025-02-04 04:46:27][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2321/3058 [1:11:12<14:37,  1.19s/it][2025-02-04 04:46:28][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2322/3058 [1:11:13<15:21,  1.25s/it][2025-02-04 04:46:30][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2323/3058 [1:11:14<13:37,  1.11s/it][2025-02-04 04:46:30][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2324/3058 [1:11:15<13:40,  1.12s/it][2025-02-04 04:46:31][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2325/3058 [1:11:17<13:53,  1.14s/it][2025-02-04 04:46:33][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2326/3058 [1:11:18<14:25,  1.18s/it][2025-02-04 04:46:34][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2327/3058 [1:11:19<13:36,  1.12s/it][2025-02-04 04:46:35][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2328/3058 [1:11:19<11:13,  1.08it/s][2025-02-04 04:46:35][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2329/3058 [1:11:21<13:57,  1.15s/it][2025-02-04 04:46:37][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2330/3058 [1:11:23<17:45,  1.46s/it][2025-02-04 04:46:39][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▌  | 2331/3058 [1:11:24<15:41,  1.29s/it][2025-02-04 04:46:40][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▋  | 2332/3058 [1:11:26<17:06,  1.41s/it][2025-02-04 04:46:42][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▋  | 2333/3058 [1:11:27<16:49,  1.39s/it][2025-02-04 04:46:43][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▋  | 2334/3058 [1:11:28<16:23,  1.36s/it][2025-02-04 04:46:45][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▋  | 2335/3058 [1:11:30<18:21,  1.52s/it][2025-02-04 04:46:46][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▋  | 2336/3058 [1:11:31<15:56,  1.32s/it][2025-02-04 04:46:47][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▋  | 2337/3058 [1:11:33<19:24,  1.62s/it][2025-02-04 04:46:50][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▋  | 2338/3058 [1:11:35<19:17,  1.61s/it][2025-02-04 04:46:51][slam_llm.models.slam_model][INFO] - modality encoder
 76%|███████▋  | 2339/3058 [1:11:37<19:23,  1.62s/it][2025-02-04 04:46:53][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2340/3058 [1:11:38<18:44,  1.57s/it][2025-02-04 04:46:54][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2341/3058 [1:11:39<16:54,  1.42s/it][2025-02-04 04:46:55][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2342/3058 [1:11:40<15:43,  1.32s/it][2025-02-04 04:46:56][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2343/3058 [1:11:41<14:47,  1.24s/it][2025-02-04 04:46:57][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2344/3058 [1:11:42<13:23,  1.13s/it][2025-02-04 04:46:58][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2345/3058 [1:11:43<12:12,  1.03s/it][2025-02-04 04:46:59][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2346/3058 [1:11:45<15:53,  1.34s/it][2025-02-04 04:47:01][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2347/3058 [1:11:46<14:27,  1.22s/it][2025-02-04 04:47:02][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2348/3058 [1:11:47<14:40,  1.24s/it][2025-02-04 04:47:03][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2349/3058 [1:11:48<14:28,  1.23s/it][2025-02-04 04:47:05][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2350/3058 [1:11:50<16:56,  1.44s/it][2025-02-04 04:47:06][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2351/3058 [1:11:51<14:24,  1.22s/it][2025-02-04 04:47:07][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2352/3058 [1:11:53<17:47,  1.51s/it][2025-02-04 04:47:09][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2353/3058 [1:11:55<16:57,  1.44s/it][2025-02-04 04:47:11][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2354/3058 [1:11:56<15:19,  1.31s/it][2025-02-04 04:47:12][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2355/3058 [1:11:57<14:42,  1.26s/it][2025-02-04 04:47:13][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2356/3058 [1:11:58<15:01,  1.28s/it][2025-02-04 04:47:14][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2357/3058 [1:11:59<14:19,  1.23s/it][2025-02-04 04:47:15][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2358/3058 [1:12:01<15:52,  1.36s/it][2025-02-04 04:47:17][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2359/3058 [1:12:02<14:03,  1.21s/it][2025-02-04 04:47:18][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2360/3058 [1:12:03<13:12,  1.14s/it][2025-02-04 04:47:19][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2361/3058 [1:12:04<13:06,  1.13s/it][2025-02-04 04:47:20][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2362/3058 [1:12:05<12:56,  1.12s/it][2025-02-04 04:47:21][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2363/3058 [1:12:06<13:08,  1.13s/it][2025-02-04 04:47:22][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2364/3058 [1:12:07<13:19,  1.15s/it][2025-02-04 04:47:23][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2365/3058 [1:12:09<16:29,  1.43s/it][2025-02-04 04:47:25][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2366/3058 [1:12:10<14:31,  1.26s/it][2025-02-04 04:47:26][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2367/3058 [1:12:11<11:40,  1.01s/it][2025-02-04 04:47:27][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2368/3058 [1:12:12<13:09,  1.14s/it][2025-02-04 04:47:28][slam_llm.models.slam_model][INFO] - modality encoder
 77%|███████▋  | 2369/3058 [1:12:13<11:33,  1.01s/it][2025-02-04 04:47:29][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2370/3058 [1:12:14<12:58,  1.13s/it][2025-02-04 04:47:30][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2371/3058 [1:12:16<16:01,  1.40s/it][2025-02-04 04:47:32][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2372/3058 [1:12:17<15:19,  1.34s/it][2025-02-04 04:47:34][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2373/3058 [1:12:19<16:11,  1.42s/it][2025-02-04 04:47:35][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2374/3058 [1:12:20<15:05,  1.32s/it][2025-02-04 04:47:36][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2375/3058 [1:12:22<16:58,  1.49s/it][2025-02-04 04:47:38][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2376/3058 [1:12:23<16:59,  1.49s/it][2025-02-04 04:47:40][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2377/3058 [1:12:25<15:49,  1.39s/it][2025-02-04 04:47:41][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2378/3058 [1:12:26<15:05,  1.33s/it][2025-02-04 04:47:42][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2379/3058 [1:12:27<13:03,  1.15s/it][2025-02-04 04:47:43][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2380/3058 [1:12:27<11:38,  1.03s/it][2025-02-04 04:47:43][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2381/3058 [1:12:28<10:43,  1.05it/s][2025-02-04 04:47:44][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2382/3058 [1:12:29<12:20,  1.10s/it][2025-02-04 04:47:46][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2383/3058 [1:12:30<11:26,  1.02s/it][2025-02-04 04:47:47][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2384/3058 [1:12:32<12:48,  1.14s/it][2025-02-04 04:47:48][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2385/3058 [1:12:32<11:25,  1.02s/it][2025-02-04 04:47:49][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2386/3058 [1:12:34<13:03,  1.17s/it][2025-02-04 04:47:50][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2387/3058 [1:12:35<12:03,  1.08s/it][2025-02-04 04:47:51][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2388/3058 [1:12:36<12:44,  1.14s/it][2025-02-04 04:47:52][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2389/3058 [1:12:37<10:47,  1.03it/s][2025-02-04 04:47:53][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2390/3058 [1:12:38<11:38,  1.05s/it][2025-02-04 04:47:54][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2391/3058 [1:12:39<12:37,  1.13s/it][2025-02-04 04:47:55][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2392/3058 [1:12:40<12:41,  1.14s/it][2025-02-04 04:47:57][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2393/3058 [1:12:42<12:36,  1.14s/it][2025-02-04 04:47:58][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2394/3058 [1:12:43<12:24,  1.12s/it][2025-02-04 04:47:59][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2395/3058 [1:12:44<11:39,  1.06s/it][2025-02-04 04:48:00][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2396/3058 [1:12:46<15:19,  1.39s/it][2025-02-04 04:48:02][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2397/3058 [1:12:47<13:35,  1.23s/it][2025-02-04 04:48:03][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2398/3058 [1:12:47<11:44,  1.07s/it][2025-02-04 04:48:04][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2399/3058 [1:12:50<15:37,  1.42s/it][2025-02-04 04:48:06][slam_llm.models.slam_model][INFO] - modality encoder
 78%|███████▊  | 2400/3058 [1:12:51<14:26,  1.32s/it][2025-02-04 04:48:07][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▊  | 2401/3058 [1:12:51<12:46,  1.17s/it][2025-02-04 04:48:07][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▊  | 2402/3058 [1:12:52<12:13,  1.12s/it][2025-02-04 04:48:09][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▊  | 2403/3058 [1:12:53<11:26,  1.05s/it][2025-02-04 04:48:10][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▊  | 2404/3058 [1:12:55<13:11,  1.21s/it][2025-02-04 04:48:11][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▊  | 2405/3058 [1:12:56<11:13,  1.03s/it][2025-02-04 04:48:12][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▊  | 2406/3058 [1:12:57<12:29,  1.15s/it][2025-02-04 04:48:13][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▊  | 2407/3058 [1:12:58<12:19,  1.14s/it][2025-02-04 04:48:14][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▊  | 2408/3058 [1:13:00<15:24,  1.42s/it][2025-02-04 04:48:16][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2409/3058 [1:13:02<15:56,  1.47s/it][2025-02-04 04:48:18][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2410/3058 [1:13:03<15:42,  1.45s/it][2025-02-04 04:48:19][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2411/3058 [1:13:04<15:13,  1.41s/it][2025-02-04 04:48:21][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2412/3058 [1:13:06<14:40,  1.36s/it][2025-02-04 04:48:22][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2413/3058 [1:13:08<18:29,  1.72s/it][2025-02-04 04:48:25][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2414/3058 [1:13:10<19:24,  1.81s/it][2025-02-04 04:48:27][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2415/3058 [1:13:12<17:37,  1.64s/it][2025-02-04 04:48:28][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2416/3058 [1:13:13<18:15,  1.71s/it][2025-02-04 04:48:30][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2417/3058 [1:13:15<16:36,  1.55s/it][2025-02-04 04:48:31][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2418/3058 [1:13:15<13:28,  1.26s/it][2025-02-04 04:48:32][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2419/3058 [1:13:17<15:37,  1.47s/it][2025-02-04 04:48:33][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2420/3058 [1:13:18<13:32,  1.27s/it][2025-02-04 04:48:34][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2421/3058 [1:13:19<12:00,  1.13s/it][2025-02-04 04:48:35][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2422/3058 [1:13:20<11:46,  1.11s/it][2025-02-04 04:48:36][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2423/3058 [1:13:21<12:52,  1.22s/it][2025-02-04 04:48:37][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2424/3058 [1:13:22<12:20,  1.17s/it][2025-02-04 04:48:38][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2425/3058 [1:13:23<12:14,  1.16s/it][2025-02-04 04:48:40][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2426/3058 [1:13:25<12:06,  1.15s/it][2025-02-04 04:48:41][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2427/3058 [1:13:25<11:18,  1.07s/it][2025-02-04 04:48:42][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2428/3058 [1:13:27<12:21,  1.18s/it][2025-02-04 04:48:43][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2429/3058 [1:13:28<12:32,  1.20s/it][2025-02-04 04:48:44][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2430/3058 [1:13:30<14:37,  1.40s/it][2025-02-04 04:48:46][slam_llm.models.slam_model][INFO] - modality encoder
 79%|███████▉  | 2431/3058 [1:13:31<14:29,  1.39s/it][2025-02-04 04:48:48][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2432/3058 [1:13:33<16:50,  1.61s/it][2025-02-04 04:48:50][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2433/3058 [1:13:34<13:52,  1.33s/it][2025-02-04 04:48:50][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2434/3058 [1:13:36<15:06,  1.45s/it][2025-02-04 04:48:52][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2435/3058 [1:13:38<16:25,  1.58s/it][2025-02-04 04:48:54][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2436/3058 [1:13:40<17:35,  1.70s/it][2025-02-04 04:48:56][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2437/3058 [1:13:41<16:24,  1.58s/it][2025-02-04 04:48:57][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2438/3058 [1:13:43<16:55,  1.64s/it][2025-02-04 04:48:59][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2439/3058 [1:13:44<15:32,  1.51s/it][2025-02-04 04:49:00][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2440/3058 [1:13:46<15:32,  1.51s/it][2025-02-04 04:49:02][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2441/3058 [1:13:47<15:47,  1.53s/it][2025-02-04 04:49:03][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2442/3058 [1:13:49<17:26,  1.70s/it][2025-02-04 04:49:05][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2443/3058 [1:13:51<16:34,  1.62s/it][2025-02-04 04:49:07][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2444/3058 [1:13:52<15:01,  1.47s/it][2025-02-04 04:49:08][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2445/3058 [1:13:53<12:44,  1.25s/it][2025-02-04 04:49:09][slam_llm.models.slam_model][INFO] - modality encoder
 80%|███████▉  | 2446/3058 [1:13:54<12:18,  1.21s/it][2025-02-04 04:49:10][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2447/3058 [1:13:55<13:25,  1.32s/it][2025-02-04 04:49:11][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2448/3058 [1:13:56<13:03,  1.28s/it][2025-02-04 04:49:13][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2449/3058 [1:13:58<14:46,  1.46s/it][2025-02-04 04:49:14][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2450/3058 [1:13:59<12:54,  1.27s/it][2025-02-04 04:49:15][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2451/3058 [1:14:00<11:22,  1.12s/it][2025-02-04 04:49:16][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2452/3058 [1:14:01<10:09,  1.01s/it][2025-02-04 04:49:17][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2453/3058 [1:14:02<10:51,  1.08s/it][2025-02-04 04:49:18][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2454/3058 [1:14:03<12:02,  1.20s/it][2025-02-04 04:49:20][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2455/3058 [1:14:05<13:11,  1.31s/it][2025-02-04 04:49:21][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2456/3058 [1:14:06<13:19,  1.33s/it][2025-02-04 04:49:23][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2457/3058 [1:14:08<15:57,  1.59s/it][2025-02-04 04:49:25][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2458/3058 [1:14:10<16:44,  1.67s/it][2025-02-04 04:49:26][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2459/3058 [1:14:11<14:42,  1.47s/it][2025-02-04 04:49:28][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2460/3058 [1:14:12<13:25,  1.35s/it][2025-02-04 04:49:29][slam_llm.models.slam_model][INFO] - modality encoder
 80%|████████  | 2461/3058 [1:14:14<13:56,  1.40s/it][2025-02-04 04:49:30][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2462/3058 [1:14:15<13:58,  1.41s/it][2025-02-04 04:49:32][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2463/3058 [1:14:17<15:45,  1.59s/it][2025-02-04 04:49:33][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2464/3058 [1:14:18<13:44,  1.39s/it][2025-02-04 04:49:34][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2465/3058 [1:14:19<11:01,  1.12s/it][2025-02-04 04:49:35][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2466/3058 [1:14:19<09:45,  1.01it/s][2025-02-04 04:49:36][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2467/3058 [1:14:20<09:36,  1.02it/s][2025-02-04 04:49:37][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2468/3058 [1:14:22<11:39,  1.19s/it][2025-02-04 04:49:38][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2469/3058 [1:14:24<13:23,  1.36s/it][2025-02-04 04:49:40][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2470/3058 [1:14:25<13:55,  1.42s/it][2025-02-04 04:49:42][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2471/3058 [1:14:26<12:25,  1.27s/it][2025-02-04 04:49:42][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2472/3058 [1:14:28<13:23,  1.37s/it][2025-02-04 04:49:44][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2473/3058 [1:14:30<14:14,  1.46s/it][2025-02-04 04:49:46][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2474/3058 [1:14:31<13:35,  1.40s/it][2025-02-04 04:49:47][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2475/3058 [1:14:32<13:33,  1.40s/it][2025-02-04 04:49:48][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2476/3058 [1:14:33<11:17,  1.16s/it][2025-02-04 04:49:49][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2477/3058 [1:14:35<12:59,  1.34s/it][2025-02-04 04:49:51][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2478/3058 [1:14:36<11:40,  1.21s/it][2025-02-04 04:49:52][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2479/3058 [1:14:36<10:55,  1.13s/it][2025-02-04 04:49:53][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2480/3058 [1:14:38<10:41,  1.11s/it][2025-02-04 04:49:54][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2481/3058 [1:14:38<09:57,  1.04s/it][2025-02-04 04:49:54][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2482/3058 [1:14:39<09:26,  1.02it/s][2025-02-04 04:49:55][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2483/3058 [1:14:41<10:09,  1.06s/it][2025-02-04 04:49:57][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████  | 2484/3058 [1:14:42<10:31,  1.10s/it][2025-02-04 04:49:58][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████▏ | 2485/3058 [1:14:42<09:19,  1.02it/s][2025-02-04 04:49:59][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████▏ | 2486/3058 [1:14:44<10:03,  1.06s/it][2025-02-04 04:50:00][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████▏ | 2487/3058 [1:14:45<09:57,  1.05s/it][2025-02-04 04:50:01][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████▏ | 2488/3058 [1:14:46<10:44,  1.13s/it][2025-02-04 04:50:02][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████▏ | 2489/3058 [1:14:47<11:04,  1.17s/it][2025-02-04 04:50:03][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████▏ | 2490/3058 [1:14:48<09:54,  1.05s/it][2025-02-04 04:50:04][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████▏ | 2491/3058 [1:14:49<09:51,  1.04s/it][2025-02-04 04:50:05][slam_llm.models.slam_model][INFO] - modality encoder
 81%|████████▏ | 2492/3058 [1:14:50<09:24,  1.00it/s][2025-02-04 04:50:06][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2493/3058 [1:14:52<11:41,  1.24s/it][2025-02-04 04:50:08][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2494/3058 [1:14:53<10:51,  1.15s/it][2025-02-04 04:50:09][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2495/3058 [1:14:54<10:13,  1.09s/it][2025-02-04 04:50:10][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2496/3058 [1:14:55<10:24,  1.11s/it][2025-02-04 04:50:11][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2497/3058 [1:14:56<10:15,  1.10s/it][2025-02-04 04:50:12][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2498/3058 [1:14:56<08:56,  1.04it/s][2025-02-04 04:50:13][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2499/3058 [1:14:57<08:39,  1.08it/s][2025-02-04 04:50:14][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2500/3058 [1:14:58<08:57,  1.04it/s][2025-02-04 04:50:15][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2501/3058 [1:15:00<09:28,  1.02s/it][2025-02-04 04:50:16][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2502/3058 [1:15:01<09:19,  1.01s/it][2025-02-04 04:50:17][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2503/3058 [1:15:02<09:25,  1.02s/it][2025-02-04 04:50:18][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2504/3058 [1:15:03<09:40,  1.05s/it][2025-02-04 04:50:19][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2505/3058 [1:15:04<10:55,  1.19s/it][2025-02-04 04:50:20][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2506/3058 [1:15:06<11:30,  1.25s/it][2025-02-04 04:50:22][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2507/3058 [1:15:07<10:40,  1.16s/it][2025-02-04 04:50:23][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2508/3058 [1:15:08<11:28,  1.25s/it][2025-02-04 04:50:24][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2509/3058 [1:15:09<11:53,  1.30s/it][2025-02-04 04:50:26][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2510/3058 [1:15:11<12:56,  1.42s/it][2025-02-04 04:50:27][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2511/3058 [1:15:12<12:30,  1.37s/it][2025-02-04 04:50:28][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2512/3058 [1:15:14<12:37,  1.39s/it][2025-02-04 04:50:30][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2513/3058 [1:15:16<14:36,  1.61s/it][2025-02-04 04:50:32][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2514/3058 [1:15:17<12:53,  1.42s/it][2025-02-04 04:50:33][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2515/3058 [1:15:18<11:23,  1.26s/it][2025-02-04 04:50:34][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2516/3058 [1:15:19<12:10,  1.35s/it][2025-02-04 04:50:35][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2517/3058 [1:15:20<11:04,  1.23s/it][2025-02-04 04:50:36][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2518/3058 [1:15:21<09:47,  1.09s/it][2025-02-04 04:50:37][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2519/3058 [1:15:22<08:34,  1.05it/s][2025-02-04 04:50:38][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2520/3058 [1:15:22<08:08,  1.10it/s][2025-02-04 04:50:39][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2521/3058 [1:15:24<09:02,  1.01s/it][2025-02-04 04:50:40][slam_llm.models.slam_model][INFO] - modality encoder
 82%|████████▏ | 2522/3058 [1:15:25<09:13,  1.03s/it][2025-02-04 04:50:41][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2523/3058 [1:15:26<08:32,  1.04it/s][2025-02-04 04:50:42][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2524/3058 [1:15:27<08:36,  1.03it/s][2025-02-04 04:50:43][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2525/3058 [1:15:29<11:55,  1.34s/it][2025-02-04 04:50:45][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2526/3058 [1:15:30<11:48,  1.33s/it][2025-02-04 04:50:46][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2527/3058 [1:15:31<10:54,  1.23s/it][2025-02-04 04:50:47][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2528/3058 [1:15:32<09:35,  1.09s/it][2025-02-04 04:50:48][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2529/3058 [1:15:33<10:22,  1.18s/it][2025-02-04 04:50:49][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2530/3058 [1:15:34<09:55,  1.13s/it][2025-02-04 04:50:50][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2531/3058 [1:15:35<08:48,  1.00s/it][2025-02-04 04:50:51][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2532/3058 [1:15:37<11:27,  1.31s/it][2025-02-04 04:50:53][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2533/3058 [1:15:39<12:39,  1.45s/it][2025-02-04 04:50:55][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2534/3058 [1:15:40<12:34,  1.44s/it][2025-02-04 04:50:56][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2535/3058 [1:15:41<11:02,  1.27s/it][2025-02-04 04:50:57][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2536/3058 [1:15:42<11:01,  1.27s/it][2025-02-04 04:50:59][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2537/3058 [1:15:45<14:07,  1.63s/it][2025-02-04 04:51:01][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2538/3058 [1:15:46<13:18,  1.53s/it][2025-02-04 04:51:02][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2539/3058 [1:15:48<13:00,  1.50s/it][2025-02-04 04:51:04][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2540/3058 [1:15:50<15:05,  1.75s/it][2025-02-04 04:51:06][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2541/3058 [1:15:51<12:41,  1.47s/it][2025-02-04 04:51:07][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2542/3058 [1:15:52<11:00,  1.28s/it][2025-02-04 04:51:08][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2543/3058 [1:15:54<12:54,  1.50s/it][2025-02-04 04:51:10][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2544/3058 [1:15:56<14:20,  1.67s/it][2025-02-04 04:51:12][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2545/3058 [1:15:57<14:02,  1.64s/it][2025-02-04 04:51:13][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2546/3058 [1:15:59<13:17,  1.56s/it][2025-02-04 04:51:15][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2547/3058 [1:16:00<13:07,  1.54s/it][2025-02-04 04:51:16][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2548/3058 [1:16:02<13:43,  1.61s/it][2025-02-04 04:51:18][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2549/3058 [1:16:03<13:24,  1.58s/it][2025-02-04 04:51:19][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2550/3058 [1:16:04<12:16,  1.45s/it][2025-02-04 04:51:21][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2551/3058 [1:16:06<11:31,  1.36s/it][2025-02-04 04:51:22][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2552/3058 [1:16:07<11:11,  1.33s/it][2025-02-04 04:51:23][slam_llm.models.slam_model][INFO] - modality encoder
 83%|████████▎ | 2553/3058 [1:16:08<10:16,  1.22s/it][2025-02-04 04:51:24][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▎ | 2554/3058 [1:16:09<09:08,  1.09s/it][2025-02-04 04:51:25][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▎ | 2555/3058 [1:16:10<10:47,  1.29s/it][2025-02-04 04:51:27][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▎ | 2556/3058 [1:16:12<10:42,  1.28s/it][2025-02-04 04:51:28][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▎ | 2557/3058 [1:16:12<09:33,  1.15s/it][2025-02-04 04:51:29][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▎ | 2558/3058 [1:16:14<11:01,  1.32s/it][2025-02-04 04:51:31][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▎ | 2559/3058 [1:16:16<11:24,  1.37s/it][2025-02-04 04:51:32][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▎ | 2560/3058 [1:16:17<10:13,  1.23s/it][2025-02-04 04:51:33][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▎ | 2561/3058 [1:16:18<09:48,  1.18s/it][2025-02-04 04:51:34][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2562/3058 [1:16:18<08:32,  1.03s/it][2025-02-04 04:51:35][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2563/3058 [1:16:21<11:31,  1.40s/it][2025-02-04 04:51:37][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2564/3058 [1:16:22<12:09,  1.48s/it][2025-02-04 04:51:39][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2565/3058 [1:16:24<12:42,  1.55s/it][2025-02-04 04:51:40][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2566/3058 [1:16:24<09:53,  1.21s/it][2025-02-04 04:51:41][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2567/3058 [1:16:26<11:48,  1.44s/it][2025-02-04 04:51:43][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2568/3058 [1:16:28<12:03,  1.48s/it][2025-02-04 04:51:44][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2569/3058 [1:16:29<11:40,  1.43s/it][2025-02-04 04:51:46][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2570/3058 [1:16:31<12:22,  1.52s/it][2025-02-04 04:51:47][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2571/3058 [1:16:33<12:59,  1.60s/it][2025-02-04 04:51:49][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2572/3058 [1:16:34<12:17,  1.52s/it][2025-02-04 04:51:50][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2573/3058 [1:16:36<13:31,  1.67s/it][2025-02-04 04:51:52][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2574/3058 [1:16:38<13:46,  1.71s/it][2025-02-04 04:51:54][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2575/3058 [1:16:39<13:15,  1.65s/it][2025-02-04 04:51:56][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2576/3058 [1:16:41<12:11,  1.52s/it][2025-02-04 04:51:57][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2577/3058 [1:16:43<13:56,  1.74s/it][2025-02-04 04:51:59][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2578/3058 [1:16:44<13:29,  1.69s/it][2025-02-04 04:52:01][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2579/3058 [1:16:46<13:37,  1.71s/it][2025-02-04 04:52:02][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2580/3058 [1:16:48<14:10,  1.78s/it][2025-02-04 04:52:04][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2581/3058 [1:16:49<12:49,  1.61s/it][2025-02-04 04:52:06][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2582/3058 [1:16:51<13:03,  1.65s/it][2025-02-04 04:52:07][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2583/3058 [1:16:53<13:44,  1.74s/it][2025-02-04 04:52:09][slam_llm.models.slam_model][INFO] - modality encoder
 84%|████████▍ | 2584/3058 [1:16:55<14:27,  1.83s/it][2025-02-04 04:52:11][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2585/3058 [1:16:56<12:31,  1.59s/it][2025-02-04 04:52:12][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2586/3058 [1:16:58<12:19,  1.57s/it][2025-02-04 04:52:14][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2587/3058 [1:16:59<11:37,  1.48s/it][2025-02-04 04:52:15][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2588/3058 [1:17:02<15:53,  2.03s/it][2025-02-04 04:52:18][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2589/3058 [1:17:04<14:37,  1.87s/it][2025-02-04 04:52:20][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2590/3058 [1:17:06<15:46,  2.02s/it][2025-02-04 04:52:22][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2591/3058 [1:17:09<18:41,  2.40s/it][2025-02-04 04:52:26][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2592/3058 [1:17:12<18:27,  2.38s/it][2025-02-04 04:52:28][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2593/3058 [1:17:14<17:37,  2.27s/it][2025-02-04 04:52:30][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2594/3058 [1:17:15<15:18,  1.98s/it][2025-02-04 04:52:31][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2595/3058 [1:17:16<12:57,  1.68s/it][2025-02-04 04:52:32][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2596/3058 [1:17:17<11:45,  1.53s/it][2025-02-04 04:52:33][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2597/3058 [1:17:18<10:55,  1.42s/it][2025-02-04 04:52:34][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2598/3058 [1:17:20<10:23,  1.35s/it][2025-02-04 04:52:36][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▍ | 2599/3058 [1:17:21<10:43,  1.40s/it][2025-02-04 04:52:37][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2600/3058 [1:17:24<13:01,  1.71s/it][2025-02-04 04:52:40][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2601/3058 [1:17:25<11:43,  1.54s/it][2025-02-04 04:52:41][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2602/3058 [1:17:26<10:45,  1.42s/it][2025-02-04 04:52:42][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2603/3058 [1:17:27<10:39,  1.40s/it][2025-02-04 04:52:43][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2604/3058 [1:17:29<11:12,  1.48s/it][2025-02-04 04:52:45][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2605/3058 [1:17:30<10:19,  1.37s/it][2025-02-04 04:52:46][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2606/3058 [1:17:31<09:50,  1.31s/it][2025-02-04 04:52:47][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2607/3058 [1:17:33<10:35,  1.41s/it][2025-02-04 04:52:49][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2608/3058 [1:17:34<09:06,  1.21s/it][2025-02-04 04:52:50][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2609/3058 [1:17:36<11:43,  1.57s/it][2025-02-04 04:52:52][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2610/3058 [1:17:37<10:01,  1.34s/it][2025-02-04 04:52:53][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2611/3058 [1:17:39<12:52,  1.73s/it][2025-02-04 04:52:55][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2612/3058 [1:17:41<11:53,  1.60s/it][2025-02-04 04:52:57][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2613/3058 [1:17:42<11:04,  1.49s/it][2025-02-04 04:52:58][slam_llm.models.slam_model][INFO] - modality encoder
 85%|████████▌ | 2614/3058 [1:17:43<09:54,  1.34s/it][2025-02-04 04:52:59][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2615/3058 [1:17:49<20:37,  2.79s/it][2025-02-04 04:53:05][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2616/3058 [1:17:51<17:49,  2.42s/it][2025-02-04 04:53:07][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2617/3058 [1:17:52<16:05,  2.19s/it][2025-02-04 04:53:08][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2618/3058 [1:17:54<14:37,  1.99s/it][2025-02-04 04:53:10][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2619/3058 [1:17:55<11:47,  1.61s/it][2025-02-04 04:53:11][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2620/3058 [1:17:57<12:44,  1.74s/it][2025-02-04 04:53:13][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2621/3058 [1:17:58<12:50,  1.76s/it][2025-02-04 04:53:14][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2622/3058 [1:17:59<11:03,  1.52s/it][2025-02-04 04:53:15][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2623/3058 [1:18:01<11:14,  1.55s/it][2025-02-04 04:53:17][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2624/3058 [1:18:02<09:56,  1.37s/it][2025-02-04 04:53:18][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2625/3058 [1:18:04<10:28,  1.45s/it][2025-02-04 04:53:20][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2626/3058 [1:18:05<09:49,  1.36s/it][2025-02-04 04:53:21][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2627/3058 [1:18:06<09:43,  1.35s/it][2025-02-04 04:53:22][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2628/3058 [1:18:07<09:49,  1.37s/it][2025-02-04 04:53:24][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2629/3058 [1:18:09<10:29,  1.47s/it][2025-02-04 04:53:25][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2630/3058 [1:18:11<11:56,  1.67s/it][2025-02-04 04:53:27][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2631/3058 [1:18:13<11:52,  1.67s/it][2025-02-04 04:53:29][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2632/3058 [1:18:14<11:20,  1.60s/it][2025-02-04 04:53:30][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2633/3058 [1:18:16<11:32,  1.63s/it][2025-02-04 04:53:32][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2634/3058 [1:18:18<13:08,  1.86s/it][2025-02-04 04:53:35][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2635/3058 [1:18:20<12:06,  1.72s/it][2025-02-04 04:53:36][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2636/3058 [1:18:22<12:45,  1.81s/it][2025-02-04 04:53:38][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▌ | 2637/3058 [1:18:24<12:23,  1.77s/it][2025-02-04 04:53:40][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▋ | 2638/3058 [1:18:25<11:29,  1.64s/it][2025-02-04 04:53:41][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▋ | 2639/3058 [1:18:27<11:50,  1.70s/it][2025-02-04 04:53:43][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▋ | 2640/3058 [1:18:29<12:00,  1.72s/it][2025-02-04 04:53:45][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▋ | 2641/3058 [1:18:31<12:32,  1.80s/it][2025-02-04 04:53:47][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▋ | 2642/3058 [1:18:32<12:12,  1.76s/it][2025-02-04 04:53:48][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▋ | 2643/3058 [1:18:34<12:24,  1.79s/it][2025-02-04 04:53:50][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▋ | 2644/3058 [1:18:35<10:46,  1.56s/it][2025-02-04 04:53:51][slam_llm.models.slam_model][INFO] - modality encoder
 86%|████████▋ | 2645/3058 [1:18:37<11:43,  1.70s/it][2025-02-04 04:53:53][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2646/3058 [1:18:38<10:53,  1.59s/it][2025-02-04 04:53:54][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2647/3058 [1:18:39<09:02,  1.32s/it][2025-02-04 04:53:55][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2648/3058 [1:18:41<10:13,  1.50s/it][2025-02-04 04:53:57][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2649/3058 [1:18:43<11:28,  1.68s/it][2025-02-04 04:53:59][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2650/3058 [1:18:46<13:01,  1.92s/it][2025-02-04 04:54:02][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2651/3058 [1:18:48<13:31,  1.99s/it][2025-02-04 04:54:04][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2652/3058 [1:18:49<11:46,  1.74s/it][2025-02-04 04:54:05][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2653/3058 [1:18:50<10:57,  1.62s/it][2025-02-04 04:54:06][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2654/3058 [1:18:51<08:53,  1.32s/it][2025-02-04 04:54:07][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2655/3058 [1:18:52<08:13,  1.22s/it][2025-02-04 04:54:08][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2656/3058 [1:18:54<10:07,  1.51s/it][2025-02-04 04:54:10][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2657/3058 [1:18:56<11:10,  1.67s/it][2025-02-04 04:54:12][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2658/3058 [1:18:57<09:47,  1.47s/it][2025-02-04 04:54:13][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2659/3058 [1:18:59<11:11,  1.68s/it][2025-02-04 04:54:15][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2660/3058 [1:19:01<10:30,  1.59s/it][2025-02-04 04:54:17][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2661/3058 [1:19:02<09:43,  1.47s/it][2025-02-04 04:54:18][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2662/3058 [1:19:04<10:49,  1.64s/it][2025-02-04 04:54:20][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2663/3058 [1:19:05<10:07,  1.54s/it][2025-02-04 04:54:21][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2664/3058 [1:19:06<09:30,  1.45s/it][2025-02-04 04:54:23][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2665/3058 [1:19:08<10:30,  1.60s/it][2025-02-04 04:54:25][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2666/3058 [1:19:10<10:51,  1.66s/it][2025-02-04 04:54:26][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2667/3058 [1:19:12<11:47,  1.81s/it][2025-02-04 04:54:28][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2668/3058 [1:19:14<12:16,  1.89s/it][2025-02-04 04:54:31][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2669/3058 [1:19:16<11:19,  1.75s/it][2025-02-04 04:54:32][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2670/3058 [1:19:18<11:11,  1.73s/it][2025-02-04 04:54:34][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2671/3058 [1:19:19<10:11,  1.58s/it][2025-02-04 04:54:35][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2672/3058 [1:19:20<10:25,  1.62s/it][2025-02-04 04:54:37][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2673/3058 [1:19:23<11:53,  1.85s/it][2025-02-04 04:54:39][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2674/3058 [1:19:25<12:48,  2.00s/it][2025-02-04 04:54:41][slam_llm.models.slam_model][INFO] - modality encoder
 87%|████████▋ | 2675/3058 [1:19:27<12:40,  1.99s/it][2025-02-04 04:54:43][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2676/3058 [1:19:28<11:21,  1.78s/it][2025-02-04 04:54:45][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2677/3058 [1:19:29<09:35,  1.51s/it][2025-02-04 04:54:45][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2678/3058 [1:19:31<08:54,  1.41s/it][2025-02-04 04:54:47][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2679/3058 [1:19:32<08:08,  1.29s/it][2025-02-04 04:54:48][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2680/3058 [1:19:33<07:55,  1.26s/it][2025-02-04 04:54:49][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2681/3058 [1:19:34<08:02,  1.28s/it][2025-02-04 04:54:50][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2682/3058 [1:19:36<08:39,  1.38s/it][2025-02-04 04:54:52][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2683/3058 [1:19:37<08:19,  1.33s/it][2025-02-04 04:54:53][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2684/3058 [1:19:39<09:19,  1.50s/it][2025-02-04 04:54:55][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2685/3058 [1:19:41<10:51,  1.75s/it][2025-02-04 04:54:57][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2686/3058 [1:19:43<10:34,  1.71s/it][2025-02-04 04:54:59][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2687/3058 [1:19:44<09:24,  1.52s/it][2025-02-04 04:55:00][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2688/3058 [1:19:47<12:07,  1.97s/it][2025-02-04 04:55:03][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2689/3058 [1:19:48<10:49,  1.76s/it][2025-02-04 04:55:04][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2690/3058 [1:19:49<09:55,  1.62s/it][2025-02-04 04:55:05][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2691/3058 [1:19:51<09:09,  1.50s/it][2025-02-04 04:55:07][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2692/3058 [1:19:53<10:16,  1.69s/it][2025-02-04 04:55:09][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2693/3058 [1:19:55<11:00,  1.81s/it][2025-02-04 04:55:11][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2694/3058 [1:19:57<11:14,  1.85s/it][2025-02-04 04:55:13][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2695/3058 [1:19:58<10:53,  1.80s/it][2025-02-04 04:55:15][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2696/3058 [1:20:01<11:37,  1.93s/it][2025-02-04 04:55:17][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2697/3058 [1:20:02<10:13,  1.70s/it][2025-02-04 04:55:18][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2698/3058 [1:20:04<10:45,  1.79s/it][2025-02-04 04:55:20][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2699/3058 [1:20:06<11:05,  1.85s/it][2025-02-04 04:55:22][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2700/3058 [1:20:07<10:42,  1.79s/it][2025-02-04 04:55:24][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2701/3058 [1:20:09<09:51,  1.66s/it][2025-02-04 04:55:25][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2702/3058 [1:20:10<08:37,  1.45s/it][2025-02-04 04:55:26][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2703/3058 [1:20:11<07:42,  1.30s/it][2025-02-04 04:55:27][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2704/3058 [1:20:13<08:55,  1.51s/it][2025-02-04 04:55:29][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2705/3058 [1:20:13<07:29,  1.27s/it][2025-02-04 04:55:30][slam_llm.models.slam_model][INFO] - modality encoder
 88%|████████▊ | 2706/3058 [1:20:16<09:08,  1.56s/it][2025-02-04 04:55:32][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▊ | 2707/3058 [1:20:17<08:19,  1.42s/it][2025-02-04 04:55:33][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▊ | 2708/3058 [1:20:18<08:16,  1.42s/it][2025-02-04 04:55:34][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▊ | 2709/3058 [1:20:20<09:32,  1.64s/it][2025-02-04 04:55:36][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▊ | 2710/3058 [1:20:23<11:13,  1.93s/it][2025-02-04 04:55:39][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▊ | 2711/3058 [1:20:25<12:08,  2.10s/it][2025-02-04 04:55:42][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▊ | 2712/3058 [1:20:27<11:29,  1.99s/it][2025-02-04 04:55:43][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▊ | 2713/3058 [1:20:28<09:45,  1.70s/it][2025-02-04 04:55:44][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2714/3058 [1:20:29<08:08,  1.42s/it][2025-02-04 04:55:45][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2715/3058 [1:20:31<08:47,  1.54s/it][2025-02-04 04:55:47][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2716/3058 [1:20:32<08:48,  1.54s/it][2025-02-04 04:55:48][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2717/3058 [1:20:34<09:17,  1.63s/it][2025-02-04 04:55:50][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2718/3058 [1:20:37<11:09,  1.97s/it][2025-02-04 04:55:53][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2719/3058 [1:20:39<12:02,  2.13s/it][2025-02-04 04:55:56][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2720/3058 [1:20:42<11:52,  2.11s/it][2025-02-04 04:55:58][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2721/3058 [1:20:44<11:39,  2.07s/it][2025-02-04 04:56:00][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2722/3058 [1:20:45<11:17,  2.02s/it][2025-02-04 04:56:01][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2723/3058 [1:20:46<09:21,  1.67s/it][2025-02-04 04:56:02][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2724/3058 [1:20:47<07:22,  1.32s/it][2025-02-04 04:56:03][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2725/3058 [1:20:48<07:27,  1.34s/it][2025-02-04 04:56:04][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2726/3058 [1:20:50<07:44,  1.40s/it][2025-02-04 04:56:06][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2727/3058 [1:20:51<07:51,  1.42s/it][2025-02-04 04:56:07][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2728/3058 [1:20:52<07:07,  1.30s/it][2025-02-04 04:56:08][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2729/3058 [1:20:54<07:25,  1.35s/it][2025-02-04 04:56:10][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2730/3058 [1:20:56<08:47,  1.61s/it][2025-02-04 04:56:12][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2731/3058 [1:20:58<09:33,  1.75s/it][2025-02-04 04:56:14][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2732/3058 [1:20:58<07:32,  1.39s/it][2025-02-04 04:56:15][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2733/3058 [1:21:00<08:03,  1.49s/it][2025-02-04 04:56:16][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2734/3058 [1:21:01<07:02,  1.30s/it][2025-02-04 04:56:17][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2735/3058 [1:21:02<06:54,  1.28s/it][2025-02-04 04:56:18][slam_llm.models.slam_model][INFO] - modality encoder
 89%|████████▉ | 2736/3058 [1:21:03<05:26,  1.01s/it][2025-02-04 04:56:19][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2737/3058 [1:21:03<04:50,  1.10it/s][2025-02-04 04:56:19][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2738/3058 [1:21:04<04:40,  1.14it/s][2025-02-04 04:56:20][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2739/3058 [1:21:05<05:03,  1.05it/s][2025-02-04 04:56:21][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2740/3058 [1:21:06<04:39,  1.14it/s][2025-02-04 04:56:22][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2741/3058 [1:21:07<04:44,  1.12it/s][2025-02-04 04:56:23][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2742/3058 [1:21:08<04:54,  1.07it/s][2025-02-04 04:56:24][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2743/3058 [1:21:08<03:59,  1.31it/s][2025-02-04 04:56:24][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2744/3058 [1:21:09<03:50,  1.36it/s][2025-02-04 04:56:25][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2745/3058 [1:21:11<05:22,  1.03s/it][2025-02-04 04:56:27][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2746/3058 [1:21:12<05:18,  1.02s/it][2025-02-04 04:56:28][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2747/3058 [1:21:13<05:00,  1.04it/s][2025-02-04 04:56:29][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2748/3058 [1:21:14<05:03,  1.02it/s][2025-02-04 04:56:30][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2749/3058 [1:21:14<04:24,  1.17it/s][2025-02-04 04:56:30][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2750/3058 [1:21:16<05:14,  1.02s/it][2025-02-04 04:56:32][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2751/3058 [1:21:17<05:42,  1.12s/it][2025-02-04 04:56:33][slam_llm.models.slam_model][INFO] - modality encoder
 90%|████████▉ | 2752/3058 [1:21:18<06:19,  1.24s/it][2025-02-04 04:56:35][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2753/3058 [1:21:19<06:04,  1.20s/it][2025-02-04 04:56:36][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2754/3058 [1:21:21<06:23,  1.26s/it][2025-02-04 04:56:37][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2755/3058 [1:21:23<07:38,  1.51s/it][2025-02-04 04:56:39][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2756/3058 [1:21:25<07:39,  1.52s/it][2025-02-04 04:56:41][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2757/3058 [1:21:25<06:36,  1.32s/it][2025-02-04 04:56:42][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2758/3058 [1:21:27<06:41,  1.34s/it][2025-02-04 04:56:43][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2759/3058 [1:21:28<06:43,  1.35s/it][2025-02-04 04:56:44][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2760/3058 [1:21:29<05:47,  1.17s/it][2025-02-04 04:56:45][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2761/3058 [1:21:30<06:03,  1.22s/it][2025-02-04 04:56:46][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2762/3058 [1:21:32<06:19,  1.28s/it][2025-02-04 04:56:48][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2763/3058 [1:21:33<06:38,  1.35s/it][2025-02-04 04:56:49][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2764/3058 [1:21:35<06:47,  1.38s/it][2025-02-04 04:56:51][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2765/3058 [1:21:36<07:10,  1.47s/it][2025-02-04 04:56:52][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2766/3058 [1:21:37<06:19,  1.30s/it][2025-02-04 04:56:54][slam_llm.models.slam_model][INFO] - modality encoder
 90%|█████████ | 2767/3058 [1:21:39<06:21,  1.31s/it][2025-02-04 04:56:55][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2768/3058 [1:21:39<05:20,  1.11s/it][2025-02-04 04:56:55][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2769/3058 [1:21:41<05:54,  1.23s/it][2025-02-04 04:56:57][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2770/3058 [1:21:42<05:49,  1.21s/it][2025-02-04 04:56:58][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2771/3058 [1:21:43<05:07,  1.07s/it][2025-02-04 04:56:59][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2772/3058 [1:21:43<04:46,  1.00s/it][2025-02-04 04:57:00][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2773/3058 [1:21:44<04:31,  1.05it/s][2025-02-04 04:57:00][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2774/3058 [1:21:45<04:03,  1.16it/s][2025-02-04 04:57:01][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2775/3058 [1:21:46<03:44,  1.26it/s][2025-02-04 04:57:02][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2776/3058 [1:21:46<03:28,  1.35it/s][2025-02-04 04:57:02][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2777/3058 [1:21:47<03:10,  1.48it/s][2025-02-04 04:57:03][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2778/3058 [1:21:47<03:18,  1.41it/s][2025-02-04 04:57:04][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2779/3058 [1:21:49<04:10,  1.12it/s][2025-02-04 04:57:05][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2780/3058 [1:21:50<04:31,  1.02it/s][2025-02-04 04:57:06][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2781/3058 [1:21:51<04:12,  1.10it/s][2025-02-04 04:57:07][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2782/3058 [1:21:51<03:42,  1.24it/s][2025-02-04 04:57:07][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2783/3058 [1:21:53<04:15,  1.08it/s][2025-02-04 04:57:09][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2784/3058 [1:21:54<04:45,  1.04s/it][2025-02-04 04:57:10][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2785/3058 [1:21:55<05:21,  1.18s/it][2025-02-04 04:57:11][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2786/3058 [1:21:56<05:01,  1.11s/it][2025-02-04 04:57:12][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2787/3058 [1:21:57<04:36,  1.02s/it][2025-02-04 04:57:13][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2788/3058 [1:21:58<04:42,  1.05s/it][2025-02-04 04:57:14][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2789/3058 [1:21:59<04:48,  1.07s/it][2025-02-04 04:57:16][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████ | 2790/3058 [1:22:01<05:43,  1.28s/it][2025-02-04 04:57:17][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████▏| 2791/3058 [1:22:02<04:57,  1.12s/it][2025-02-04 04:57:18][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████▏| 2792/3058 [1:22:03<04:40,  1.05s/it][2025-02-04 04:57:19][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████▏| 2793/3058 [1:22:03<04:03,  1.09it/s][2025-02-04 04:57:19][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████▏| 2794/3058 [1:22:04<03:40,  1.20it/s][2025-02-04 04:57:20][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████▏| 2795/3058 [1:22:05<03:55,  1.12it/s][2025-02-04 04:57:21][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████▏| 2796/3058 [1:22:06<04:22,  1.00s/it][2025-02-04 04:57:22][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████▏| 2797/3058 [1:22:07<04:19,  1.01it/s][2025-02-04 04:57:23][slam_llm.models.slam_model][INFO] - modality encoder
 91%|█████████▏| 2798/3058 [1:22:08<04:24,  1.02s/it][2025-02-04 04:57:24][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2799/3058 [1:22:09<03:57,  1.09it/s][2025-02-04 04:57:25][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2800/3058 [1:22:10<03:38,  1.18it/s][2025-02-04 04:57:26][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2801/3058 [1:22:11<03:56,  1.09it/s][2025-02-04 04:57:27][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2802/3058 [1:22:12<04:06,  1.04it/s][2025-02-04 04:57:28][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2803/3058 [1:22:13<04:40,  1.10s/it][2025-02-04 04:57:30][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2804/3058 [1:22:15<05:54,  1.39s/it][2025-02-04 04:57:31][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2805/3058 [1:22:16<05:04,  1.20s/it][2025-02-04 04:57:32][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2806/3058 [1:22:17<04:54,  1.17s/it][2025-02-04 04:57:34][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2807/3058 [1:22:18<05:01,  1.20s/it][2025-02-04 04:57:35][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2808/3058 [1:22:20<05:43,  1.37s/it][2025-02-04 04:57:36][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2809/3058 [1:22:21<05:19,  1.28s/it][2025-02-04 04:57:37][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2810/3058 [1:22:22<04:25,  1.07s/it][2025-02-04 04:57:38][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2811/3058 [1:22:23<04:12,  1.02s/it][2025-02-04 04:57:39][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2812/3058 [1:22:25<05:03,  1.23s/it][2025-02-04 04:57:41][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2813/3058 [1:22:26<05:41,  1.39s/it][2025-02-04 04:57:43][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2814/3058 [1:22:27<05:13,  1.28s/it][2025-02-04 04:57:43][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2815/3058 [1:22:28<04:12,  1.04s/it][2025-02-04 04:57:44][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2816/3058 [1:22:28<03:47,  1.07it/s][2025-02-04 04:57:45][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2817/3058 [1:22:30<04:41,  1.17s/it][2025-02-04 04:57:47][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2818/3058 [1:22:32<05:28,  1.37s/it][2025-02-04 04:57:48][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2819/3058 [1:22:33<04:56,  1.24s/it][2025-02-04 04:57:49][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2820/3058 [1:22:34<04:56,  1.25s/it][2025-02-04 04:57:51][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2821/3058 [1:22:36<05:05,  1.29s/it][2025-02-04 04:57:52][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2822/3058 [1:22:37<05:15,  1.34s/it][2025-02-04 04:57:53][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2823/3058 [1:22:39<05:32,  1.41s/it][2025-02-04 04:57:55][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2824/3058 [1:22:39<04:31,  1.16s/it][2025-02-04 04:57:55][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2825/3058 [1:22:41<04:44,  1.22s/it][2025-02-04 04:57:57][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2826/3058 [1:22:42<05:08,  1.33s/it][2025-02-04 04:57:58][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2827/3058 [1:22:43<04:51,  1.26s/it][2025-02-04 04:57:59][slam_llm.models.slam_model][INFO] - modality encoder
 92%|█████████▏| 2828/3058 [1:22:44<04:47,  1.25s/it][2025-02-04 04:58:01][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2829/3058 [1:22:46<04:40,  1.23s/it][2025-02-04 04:58:02][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2830/3058 [1:22:47<04:57,  1.31s/it][2025-02-04 04:58:03][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2831/3058 [1:22:48<04:18,  1.14s/it][2025-02-04 04:58:04][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2832/3058 [1:22:49<04:32,  1.20s/it][2025-02-04 04:58:05][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2833/3058 [1:22:50<04:06,  1.09s/it][2025-02-04 04:58:06][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2834/3058 [1:22:51<04:23,  1.18s/it][2025-02-04 04:58:08][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2835/3058 [1:22:53<04:22,  1.18s/it][2025-02-04 04:58:09][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2836/3058 [1:22:54<04:16,  1.15s/it][2025-02-04 04:58:10][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2837/3058 [1:22:56<04:57,  1.34s/it][2025-02-04 04:58:12][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2838/3058 [1:22:57<05:03,  1.38s/it][2025-02-04 04:58:13][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2839/3058 [1:22:59<05:42,  1.56s/it][2025-02-04 04:58:15][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2840/3058 [1:23:01<06:21,  1.75s/it][2025-02-04 04:58:17][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2841/3058 [1:23:03<06:11,  1.71s/it][2025-02-04 04:58:19][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2842/3058 [1:23:05<06:11,  1.72s/it][2025-02-04 04:58:21][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2843/3058 [1:23:06<05:27,  1.53s/it][2025-02-04 04:58:22][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2844/3058 [1:23:07<05:19,  1.50s/it][2025-02-04 04:58:23][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2845/3058 [1:23:09<05:58,  1.68s/it][2025-02-04 04:58:25][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2846/3058 [1:23:10<05:12,  1.48s/it][2025-02-04 04:58:26][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2847/3058 [1:23:12<05:20,  1.52s/it][2025-02-04 04:58:28][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2848/3058 [1:23:13<04:32,  1.30s/it][2025-02-04 04:58:29][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2849/3058 [1:23:14<04:14,  1.22s/it][2025-02-04 04:58:30][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2850/3058 [1:23:15<04:29,  1.29s/it][2025-02-04 04:58:31][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2851/3058 [1:23:16<03:44,  1.08s/it][2025-02-04 04:58:32][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2852/3058 [1:23:17<03:41,  1.07s/it][2025-02-04 04:58:33][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2853/3058 [1:23:19<04:39,  1.36s/it][2025-02-04 04:58:35][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2854/3058 [1:23:20<04:18,  1.27s/it][2025-02-04 04:58:36][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2855/3058 [1:23:21<04:23,  1.30s/it][2025-02-04 04:58:37][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2856/3058 [1:23:22<04:16,  1.27s/it][2025-02-04 04:58:39][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2857/3058 [1:23:24<04:16,  1.28s/it][2025-02-04 04:58:40][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2858/3058 [1:23:25<04:27,  1.34s/it][2025-02-04 04:58:41][slam_llm.models.slam_model][INFO] - modality encoder
 93%|█████████▎| 2859/3058 [1:23:27<04:55,  1.49s/it][2025-02-04 04:58:43][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▎| 2860/3058 [1:23:29<05:10,  1.57s/it][2025-02-04 04:58:45][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▎| 2861/3058 [1:23:31<05:49,  1.77s/it][2025-02-04 04:58:47][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▎| 2862/3058 [1:23:32<05:30,  1.69s/it][2025-02-04 04:58:49][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▎| 2863/3058 [1:23:34<05:37,  1.73s/it][2025-02-04 04:58:51][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▎| 2864/3058 [1:23:36<05:31,  1.71s/it][2025-02-04 04:58:52][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▎| 2865/3058 [1:23:37<05:02,  1.57s/it][2025-02-04 04:58:53][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▎| 2866/3058 [1:23:38<04:20,  1.36s/it][2025-02-04 04:58:54][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2867/3058 [1:23:40<05:03,  1.59s/it][2025-02-04 04:58:56][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2868/3058 [1:23:42<05:14,  1.65s/it][2025-02-04 04:58:58][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2869/3058 [1:23:45<06:05,  1.93s/it][2025-02-04 04:59:01][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2870/3058 [1:23:46<05:16,  1.68s/it][2025-02-04 04:59:02][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2871/3058 [1:23:47<05:02,  1.62s/it][2025-02-04 04:59:03][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2872/3058 [1:23:48<04:23,  1.42s/it][2025-02-04 04:59:05][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2873/3058 [1:23:51<06:04,  1.97s/it][2025-02-04 04:59:07][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2874/3058 [1:23:53<05:37,  1.84s/it][2025-02-04 04:59:09][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2875/3058 [1:23:55<05:48,  1.90s/it][2025-02-04 04:59:11][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2876/3058 [1:23:55<04:33,  1.50s/it][2025-02-04 04:59:12][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2877/3058 [1:23:57<04:32,  1.51s/it][2025-02-04 04:59:13][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2878/3058 [1:23:58<04:28,  1.49s/it][2025-02-04 04:59:15][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2879/3058 [1:24:00<04:13,  1.42s/it][2025-02-04 04:59:16][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2880/3058 [1:24:01<03:43,  1.25s/it][2025-02-04 04:59:17][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2881/3058 [1:24:02<03:51,  1.31s/it][2025-02-04 04:59:18][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2882/3058 [1:24:04<04:20,  1.48s/it][2025-02-04 04:59:20][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2883/3058 [1:24:05<04:05,  1.40s/it][2025-02-04 04:59:21][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2884/3058 [1:24:07<04:52,  1.68s/it][2025-02-04 04:59:24][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2885/3058 [1:24:09<04:48,  1.67s/it][2025-02-04 04:59:25][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2886/3058 [1:24:11<04:40,  1.63s/it][2025-02-04 04:59:27][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2887/3058 [1:24:13<05:32,  1.95s/it][2025-02-04 04:59:30][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2888/3058 [1:24:15<05:37,  1.98s/it][2025-02-04 04:59:32][slam_llm.models.slam_model][INFO] - modality encoder
 94%|█████████▍| 2889/3058 [1:24:17<05:28,  1.94s/it][2025-02-04 04:59:33][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2890/3058 [1:24:19<05:06,  1.82s/it][2025-02-04 04:59:35][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2891/3058 [1:24:21<05:01,  1.81s/it][2025-02-04 04:59:37][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2892/3058 [1:24:22<04:50,  1.75s/it][2025-02-04 04:59:39][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2893/3058 [1:24:25<05:56,  2.16s/it][2025-02-04 04:59:42][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2894/3058 [1:24:27<05:40,  2.08s/it][2025-02-04 04:59:43][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2895/3058 [1:24:29<05:03,  1.86s/it][2025-02-04 04:59:45][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2896/3058 [1:24:30<04:43,  1.75s/it][2025-02-04 04:59:46][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2897/3058 [1:24:31<03:53,  1.45s/it][2025-02-04 04:59:47][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2898/3058 [1:24:34<05:01,  1.88s/it][2025-02-04 04:59:50][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2899/3058 [1:24:37<06:02,  2.28s/it][2025-02-04 04:59:53][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2900/3058 [1:24:38<04:47,  1.82s/it][2025-02-04 04:59:54][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2901/3058 [1:24:39<04:23,  1.68s/it][2025-02-04 04:59:55][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2902/3058 [1:24:41<04:41,  1.80s/it][2025-02-04 04:59:57][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2903/3058 [1:24:42<04:14,  1.64s/it][2025-02-04 04:59:59][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2904/3058 [1:24:44<04:35,  1.79s/it][2025-02-04 05:00:01][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▍| 2905/3058 [1:24:45<03:34,  1.40s/it][2025-02-04 05:00:01][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2906/3058 [1:24:46<03:01,  1.19s/it][2025-02-04 05:00:02][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2907/3058 [1:24:47<03:13,  1.28s/it][2025-02-04 05:00:03][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2908/3058 [1:24:48<02:59,  1.20s/it][2025-02-04 05:00:05][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2909/3058 [1:24:50<03:26,  1.38s/it][2025-02-04 05:00:07][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2910/3058 [1:24:53<04:45,  1.93s/it][2025-02-04 05:00:10][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2911/3058 [1:24:55<04:52,  1.99s/it][2025-02-04 05:00:12][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2912/3058 [1:24:58<05:01,  2.07s/it][2025-02-04 05:00:14][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2913/3058 [1:24:59<04:25,  1.83s/it][2025-02-04 05:00:15][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2914/3058 [1:25:00<03:59,  1.66s/it][2025-02-04 05:00:16][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2915/3058 [1:25:01<03:36,  1.51s/it][2025-02-04 05:00:18][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2916/3058 [1:25:03<03:38,  1.54s/it][2025-02-04 05:00:19][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2917/3058 [1:25:05<03:43,  1.58s/it][2025-02-04 05:00:21][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2918/3058 [1:25:07<04:03,  1.74s/it][2025-02-04 05:00:23][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2919/3058 [1:25:10<04:54,  2.12s/it][2025-02-04 05:00:26][slam_llm.models.slam_model][INFO] - modality encoder
 95%|█████████▌| 2920/3058 [1:25:11<04:39,  2.02s/it][2025-02-04 05:00:28][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2921/3058 [1:25:13<04:15,  1.86s/it][2025-02-04 05:00:29][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2922/3058 [1:25:15<04:05,  1.81s/it][2025-02-04 05:00:31][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2923/3058 [1:25:16<03:46,  1.68s/it][2025-02-04 05:00:32][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2924/3058 [1:25:17<03:22,  1.51s/it][2025-02-04 05:00:33][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2925/3058 [1:25:19<03:18,  1.49s/it][2025-02-04 05:00:35][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2926/3058 [1:25:20<03:14,  1.48s/it][2025-02-04 05:00:36][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2927/3058 [1:25:21<02:53,  1.33s/it][2025-02-04 05:00:37][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2928/3058 [1:25:22<02:47,  1.29s/it][2025-02-04 05:00:38][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2929/3058 [1:25:24<03:08,  1.46s/it][2025-02-04 05:00:40][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2930/3058 [1:25:25<03:03,  1.43s/it][2025-02-04 05:00:42][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2931/3058 [1:25:27<03:05,  1.46s/it][2025-02-04 05:00:43][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2932/3058 [1:25:28<03:04,  1.46s/it][2025-02-04 05:00:45][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2933/3058 [1:25:30<02:53,  1.39s/it][2025-02-04 05:00:46][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2934/3058 [1:25:31<02:42,  1.31s/it][2025-02-04 05:00:47][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2935/3058 [1:25:32<02:42,  1.32s/it][2025-02-04 05:00:48][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2936/3058 [1:25:33<02:27,  1.21s/it][2025-02-04 05:00:49][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2937/3058 [1:25:35<02:39,  1.32s/it][2025-02-04 05:00:51][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2938/3058 [1:25:37<03:14,  1.62s/it][2025-02-04 05:00:53][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2939/3058 [1:25:40<03:47,  1.91s/it][2025-02-04 05:00:56][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2940/3058 [1:25:41<03:36,  1.84s/it][2025-02-04 05:00:57][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2941/3058 [1:25:43<03:22,  1.73s/it][2025-02-04 05:00:59][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2942/3058 [1:25:44<02:49,  1.46s/it][2025-02-04 05:01:00][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▌| 2943/3058 [1:25:45<02:46,  1.45s/it][2025-02-04 05:01:01][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▋| 2944/3058 [1:25:47<03:00,  1.58s/it][2025-02-04 05:01:03][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▋| 2945/3058 [1:25:48<03:01,  1.60s/it][2025-02-04 05:01:05][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▋| 2946/3058 [1:25:50<02:49,  1.51s/it][2025-02-04 05:01:06][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▋| 2947/3058 [1:25:52<02:55,  1.59s/it][2025-02-04 05:01:08][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▋| 2948/3058 [1:25:53<02:34,  1.41s/it][2025-02-04 05:01:09][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▋| 2949/3058 [1:25:54<02:44,  1.51s/it][2025-02-04 05:01:10][slam_llm.models.slam_model][INFO] - modality encoder
 96%|█████████▋| 2950/3058 [1:25:56<02:39,  1.47s/it][2025-02-04 05:01:12][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2951/3058 [1:25:57<02:22,  1.33s/it][2025-02-04 05:01:13][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2952/3058 [1:25:58<02:11,  1.24s/it][2025-02-04 05:01:14][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2953/3058 [1:25:59<02:15,  1.29s/it][2025-02-04 05:01:15][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2954/3058 [1:26:00<02:16,  1.31s/it][2025-02-04 05:01:17][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2955/3058 [1:26:04<03:17,  1.92s/it][2025-02-04 05:01:20][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2956/3058 [1:26:05<03:03,  1.80s/it][2025-02-04 05:01:21][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2957/3058 [1:26:08<03:23,  2.01s/it][2025-02-04 05:01:24][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2958/3058 [1:26:09<02:46,  1.66s/it][2025-02-04 05:01:25][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2959/3058 [1:26:10<02:28,  1.50s/it][2025-02-04 05:01:26][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2960/3058 [1:26:11<02:19,  1.42s/it][2025-02-04 05:01:27][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2961/3058 [1:26:13<02:22,  1.47s/it][2025-02-04 05:01:29][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2962/3058 [1:26:14<02:15,  1.41s/it][2025-02-04 05:01:30][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2963/3058 [1:26:16<02:20,  1.48s/it][2025-02-04 05:01:32][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2964/3058 [1:26:17<02:20,  1.49s/it][2025-02-04 05:01:33][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2965/3058 [1:26:18<02:15,  1.45s/it][2025-02-04 05:01:34][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2966/3058 [1:26:19<01:59,  1.30s/it][2025-02-04 05:01:36][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2967/3058 [1:26:21<02:06,  1.39s/it][2025-02-04 05:01:37][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2968/3058 [1:26:22<02:07,  1.42s/it][2025-02-04 05:01:39][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2969/3058 [1:26:25<02:43,  1.84s/it][2025-02-04 05:01:42][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2970/3058 [1:26:30<03:46,  2.57s/it][2025-02-04 05:01:46][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2971/3058 [1:26:31<03:07,  2.16s/it][2025-02-04 05:01:47][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2972/3058 [1:26:32<02:37,  1.84s/it][2025-02-04 05:01:48][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2973/3058 [1:26:34<02:47,  1.97s/it][2025-02-04 05:01:50][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2974/3058 [1:26:36<02:31,  1.81s/it][2025-02-04 05:01:52][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2975/3058 [1:26:38<02:40,  1.93s/it][2025-02-04 05:01:54][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2976/3058 [1:26:39<02:27,  1.79s/it][2025-02-04 05:01:55][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2977/3058 [1:26:41<02:23,  1.78s/it][2025-02-04 05:01:57][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2978/3058 [1:26:43<02:27,  1.84s/it][2025-02-04 05:01:59][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2979/3058 [1:26:45<02:32,  1.93s/it][2025-02-04 05:02:01][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2980/3058 [1:26:46<02:14,  1.73s/it][2025-02-04 05:02:03][slam_llm.models.slam_model][INFO] - modality encoder
 97%|█████████▋| 2981/3058 [1:26:50<02:49,  2.20s/it][2025-02-04 05:02:06][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2982/3058 [1:26:52<02:51,  2.26s/it][2025-02-04 05:02:08][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2983/3058 [1:26:56<03:38,  2.91s/it][2025-02-04 05:02:13][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2984/3058 [1:26:58<02:56,  2.39s/it][2025-02-04 05:02:14][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2985/3058 [1:27:01<03:13,  2.65s/it][2025-02-04 05:02:17][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2986/3058 [1:27:02<02:43,  2.27s/it][2025-02-04 05:02:18][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2987/3058 [1:27:03<02:11,  1.85s/it][2025-02-04 05:02:19][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2988/3058 [1:27:04<01:55,  1.65s/it][2025-02-04 05:02:20][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2989/3058 [1:27:07<02:05,  1.82s/it][2025-02-04 05:02:23][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2990/3058 [1:27:08<01:51,  1.64s/it][2025-02-04 05:02:24][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2991/3058 [1:27:10<01:56,  1.73s/it][2025-02-04 05:02:26][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2992/3058 [1:27:13<02:30,  2.28s/it][2025-02-04 05:02:29][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2993/3058 [1:27:15<02:08,  1.98s/it][2025-02-04 05:02:31][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2994/3058 [1:27:17<02:23,  2.23s/it][2025-02-04 05:02:34][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2995/3058 [1:27:20<02:23,  2.28s/it][2025-02-04 05:02:36][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2996/3058 [1:27:24<03:02,  2.94s/it][2025-02-04 05:02:40][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2997/3058 [1:27:26<02:38,  2.59s/it][2025-02-04 05:02:42][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2998/3058 [1:27:30<02:51,  2.86s/it][2025-02-04 05:02:46][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 2999/3058 [1:27:31<02:18,  2.34s/it][2025-02-04 05:02:47][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3000/3058 [1:27:32<02:00,  2.08s/it][2025-02-04 05:02:48][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3001/3058 [1:27:34<01:49,  1.91s/it][2025-02-04 05:02:50][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3002/3058 [1:27:35<01:38,  1.76s/it][2025-02-04 05:02:51][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3003/3058 [1:27:37<01:41,  1.85s/it][2025-02-04 05:02:53][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3004/3058 [1:27:38<01:25,  1.59s/it][2025-02-04 05:02:54][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3005/3058 [1:27:41<01:48,  2.04s/it][2025-02-04 05:02:57][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3006/3058 [1:27:42<01:29,  1.72s/it][2025-02-04 05:02:58][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3007/3058 [1:27:43<01:20,  1.59s/it][2025-02-04 05:03:00][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3008/3058 [1:27:45<01:12,  1.45s/it][2025-02-04 05:03:01][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3009/3058 [1:27:46<01:10,  1.43s/it][2025-02-04 05:03:02][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3010/3058 [1:27:48<01:15,  1.57s/it][2025-02-04 05:03:04][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3011/3058 [1:27:49<01:12,  1.54s/it][2025-02-04 05:03:05][slam_llm.models.slam_model][INFO] - modality encoder
 98%|█████████▊| 3012/3058 [1:27:51<01:14,  1.62s/it][2025-02-04 05:03:07][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▊| 3013/3058 [1:27:53<01:10,  1.57s/it][2025-02-04 05:03:09][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▊| 3014/3058 [1:27:55<01:18,  1.78s/it][2025-02-04 05:03:11][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▊| 3015/3058 [1:27:57<01:27,  2.04s/it][2025-02-04 05:03:14][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▊| 3016/3058 [1:27:58<01:08,  1.64s/it][2025-02-04 05:03:14][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▊| 3017/3058 [1:28:02<01:36,  2.36s/it][2025-02-04 05:03:19][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▊| 3018/3058 [1:28:06<01:53,  2.83s/it][2025-02-04 05:03:22][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▊| 3019/3058 [1:28:08<01:43,  2.65s/it][2025-02-04 05:03:25][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3020/3058 [1:28:10<01:28,  2.33s/it][2025-02-04 05:03:26][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3021/3058 [1:28:12<01:21,  2.21s/it][2025-02-04 05:03:28][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3022/3058 [1:28:13<01:11,  1.97s/it][2025-02-04 05:03:29][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3023/3058 [1:28:14<00:59,  1.71s/it][2025-02-04 05:03:30][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3024/3058 [1:28:15<00:51,  1.51s/it][2025-02-04 05:03:32][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3025/3058 [1:28:18<01:02,  1.88s/it][2025-02-04 05:03:34][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3026/3058 [1:28:21<01:06,  2.07s/it][2025-02-04 05:03:37][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3027/3058 [1:28:24<01:14,  2.39s/it][2025-02-04 05:03:40][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3028/3058 [1:28:24<00:55,  1.86s/it][2025-02-04 05:03:41][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3029/3058 [1:28:26<00:50,  1.74s/it][2025-02-04 05:03:42][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3030/3058 [1:28:27<00:45,  1.61s/it][2025-02-04 05:03:44][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3031/3058 [1:28:30<00:49,  1.83s/it][2025-02-04 05:03:46][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3032/3058 [1:28:32<00:48,  1.87s/it][2025-02-04 05:03:48][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3033/3058 [1:28:33<00:40,  1.61s/it][2025-02-04 05:03:49][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3034/3058 [1:28:34<00:35,  1.48s/it][2025-02-04 05:03:50][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3035/3058 [1:28:35<00:29,  1.28s/it][2025-02-04 05:03:51][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3036/3058 [1:28:35<00:24,  1.10s/it][2025-02-04 05:03:51][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3037/3058 [1:28:36<00:19,  1.06it/s][2025-02-04 05:03:52][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3038/3058 [1:28:36<00:17,  1.17it/s][2025-02-04 05:03:53][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3039/3058 [1:28:38<00:18,  1.02it/s][2025-02-04 05:03:54][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3040/3058 [1:28:38<00:16,  1.12it/s][2025-02-04 05:03:55][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3041/3058 [1:28:39<00:13,  1.22it/s][2025-02-04 05:03:55][slam_llm.models.slam_model][INFO] - modality encoder
 99%|█████████▉| 3042/3058 [1:28:40<00:13,  1.19it/s][2025-02-04 05:03:56][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3043/3058 [1:28:41<00:13,  1.07it/s][2025-02-04 05:03:57][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3044/3058 [1:28:42<00:12,  1.16it/s][2025-02-04 05:03:58][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3045/3058 [1:28:42<00:10,  1.29it/s][2025-02-04 05:03:58][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3046/3058 [1:28:44<00:12,  1.01s/it][2025-02-04 05:04:00][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3047/3058 [1:28:45<00:09,  1.13it/s][2025-02-04 05:04:01][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3048/3058 [1:28:46<00:11,  1.12s/it][2025-02-04 05:04:02][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3049/3058 [1:28:48<00:11,  1.29s/it][2025-02-04 05:04:04][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3050/3058 [1:28:49<00:09,  1.20s/it][2025-02-04 05:04:05][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3051/3058 [1:28:51<00:09,  1.40s/it][2025-02-04 05:04:07][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3052/3058 [1:28:53<00:10,  1.69s/it][2025-02-04 05:04:09][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3053/3058 [1:28:55<00:08,  1.63s/it][2025-02-04 05:04:11][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3054/3058 [1:28:56<00:06,  1.52s/it][2025-02-04 05:04:12][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3055/3058 [1:28:57<00:04,  1.45s/it][2025-02-04 05:04:13][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3056/3058 [1:28:58<00:02,  1.35s/it][2025-02-04 05:04:14][slam_llm.models.slam_model][INFO] - modality encoder
100%|█████████▉| 3057/3058 [1:28:59<00:01,  1.30s/it][2025-02-04 05:04:16][slam_llm.models.slam_model][INFO] - modality encoder
100%|██████████| 3058/3058 [1:29:00<00:00,  1.17s/it]100%|██████████| 3058/3058 [1:29:01<00:00,  1.75s/it]
[2025-02-04 05:04:17][root][INFO] - Predictions written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6/decode_test_beam4_pred_20250204_033515
[2025-02-04 05:04:17][root][INFO] - Ground truth written to: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6/decode_test_beam4_gt_20250204_033515
Using folder: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6
Using GT file: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6/decode_test_beam4_gt_20250204_033515
Using PRED file: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_linear_peft_ds_rate_6/decode_test_beam4_pred_20250204_033515
Combined WER: 0.26338690754177535

Filtering repeated words...

Found 16 repeated lines in total.
Repeated lines are:
- AH N D AH N D S IH NG IH NG AH N D ER EY N HH AE P IY AH F IY L IH NG AH N D K ER AY AH T AH M D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T D AA T
- AH N D AE N V AY Z ER T UW DH AH K IH NG S AH G R EY S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER S P ER
- AH N D N OW N OW N OW N OW
- DH AH DH AH DH AH DH AH DH AH
- AH S IH N D ER EH L AH S IH N D ER EH L AH Y AE Y AE Y AE Y AE
- AY HH AE D TH R IY K IH D Z AH W AY F L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V L AH V
- W AH N T UW TH R IY TH R IY HH AW ER Z G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N G AO N
- AH N D SH IY W UH D HH AE V T UW T UW T UW T UW
- AH N D N EH K S T V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY V IY
- AH N D DH AH OW L D OW L D OW L D OW L D
- TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY TH R IY
- W AH N N OW N OW N OW N OW
- AY N OW N OW N OW N OW
- R OW T R OW T R OW T R OW T R OW T R OW T R OW T R OW T R OW T
- Y UW HH AE V AH B IH T S OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW
- AY HH AE D AH R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B R OW B
Filtered Combined WER: 0.258395426589226
