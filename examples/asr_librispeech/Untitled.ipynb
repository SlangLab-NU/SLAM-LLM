{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f6c69-b94f-4b8f-b8fa-bddb5f7a2a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps -aux | grep 5678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2a6642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 10 22:33:36 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           Off | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   47C    P0              82W / 300W |   9591MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     28719      C   ...ech-nlp/jindaznb/slamenv/bin/python     9588MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcd207-6202-4ba8-96a4-e3988eba77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55526f79-be7f-486e-a8ba-407674b43cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall transformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea51d56a-795c-46ba-a696-09fc230172b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08cd79f-15c5-4c06-83b7-d820260123b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67218b55-f0ba-48a2-a096-ccfd2bdc380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show slam-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d605d-efcf-49e2-b2f8-80a9494877ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "module load anaconda3/2022.05\n",
    "module load ffmpeg/20190305 \n",
    "\n",
    "source activate /work/van-speech-nlp/jindaznb/asrenv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea94885-44a4-4df6-b39d-bba8c18f329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c33c48-af4e-4519-889c-60fa979c71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash scripts/decode_wavlm_large_linear_vicuna_7b.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3803a-fc2b-4645-a844-00fa6844e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash scripts/decode_hubert_xtralarge_linear_vicuna_7b.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac1710e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:29503 (errno: 98 - Address already in use).\n",
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to 0.0.0.0:29503 (errno: 98 - Address already in use).\n",
      "[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/run.py\", line 879, in main\n",
      "    run(args)\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/run.py\", line 870, in run\n",
      "    elastic_launch(\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 254, in launch_agent\n",
      "    result = agent.run()\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 123, in wrapper\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 733, in run\n",
      "    result = self._invoke_run(role)\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 870, in _invoke_run\n",
      "    self._initialize_workers(self._worker_group)\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 123, in wrapper\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 705, in _initialize_workers\n",
      "    self._rendezvous(worker_group)\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 123, in wrapper\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 548, in _rendezvous\n",
      "    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py\", line 55, in next_rendezvous\n",
      "    self._store = TCPStore(  # type: ignore[call-arg]\n",
      "torch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29503 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29503 (errno: 98 - Address already in use).\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/finetune_hubert_xtralarge_tiny_llama.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac50995",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/transformers/src/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "[2024-07-10 00:15:29][root][INFO] - local_rank: 0, rank: 0, world_size: 1\n",
      "[2024-07-10 00:15:29][slam_llm.utils.train_utils][INFO] - Clearing GPU cache for all ranks\n",
      "[2024-07-10 00:15:29][slam_llm.utils.train_utils][INFO] - --> Running with torch dist debug set to detail\n",
      "[2024-07-10 00:15:29][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': True, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 6, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 3, 'num_workers_dataloader': 0, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 2000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 6, 'use_peft': False, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'v_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/out/vicuna-7b-v1.5-librispeech-linear-steplrwarmupkeep1e-4-hubert-xtralarge-20240710', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True}\n",
      "[2024-07-10 00:15:29][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}\n",
      "[2024-07-10 00:15:29][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'vicuna-7b-v1.5', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/models/vicuna-7b-v1.5', 'llm_type': 'decoder_only', 'llm_dim': 4096, 'encoder_name': 'hubert', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/models/hubert_xtralarge_ll60k_finetune_ls960.pt', 'encoder_dim': 1280, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune'}\n",
      "[2024-07-10 00:15:29][root][INFO] - log_config: {'use_wandb': False, 'wandb_dir': '/root/test_wandb', 'wandb_entity_name': 'project_name', 'wandb_project_name': 'project_name', 'wandb_exp_name': 'exp_name', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/log/log_2024-07-10_00-15-28.txt', 'log_interval': 5}\n",
      "Error executing job with overrides: ['++train_config.enable_fsdp=false', '++train_config.enable_ddp=true', '++train_config.use_fp16=true', '++model_config.llm_name=vicuna-7b-v1.5', '++model_config.llm_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/models/vicuna-7b-v1.5', '++model_config.llm_dim=4096', '++model_config.encoder_name=hubert', '++model_config.normalize=true', '++dataset_config.normalize=true', '++model_config.encoder_projector_ds_rate=5', '++model_config.encoder_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/models/hubert_xtralarge_ll60k_finetune_ls960.pt', '++model_config.encoder_dim=1280', '++model_config.encoder_type=finetune', '++model_config.encoder_projector=linear', '++dataset_config.dataset=speech_dataset', '++dataset_config.train_data_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/data/M03_train.jsonl', '++dataset_config.val_data_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/data/M03_validation.jsonl', '++dataset_config.input_type=raw', '++train_config.model_name=asr', '++train_config.num_epochs=3', '++train_config.freeze_encoder=true', '++train_config.freeze_llm=true', '++train_config.batching_strategy=custom', '++train_config.warmup_steps=1000', '++train_config.total_steps=100000', '++train_config.lr=1e-4', '++train_config.validation_interval=2000', '++train_config.batch_size_training=6', '++train_config.val_batch_size=6', '++train_config.num_workers_dataloader=0', '++train_config.output_dir=/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/out/vicuna-7b-v1.5-librispeech-linear-steplrwarmupkeep1e-4-hubert-xtralarge-20240710', '++metric=acc']\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/soundfile.py\", line 164, in <module>\n",
      "[rank0]:     _snd = _ffi.dlopen(_full_path)  # OSError if file doesn't exist or can't be loaded\n",
      "[rank0]: OSError: cannot load library '/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/_soundfile_data/libsndfile_x86_64.so': libmvec.so.1: cannot open shared object file: No such file or directory\n",
      "\n",
      "[rank0]: During handling of the above exception, another exception occurred:\n",
      "\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/soundfile.py\", line 170, in <module>\n",
      "[rank0]:     raise OSError('sndfile library not found using ctypes.util.find_library')\n",
      "[rank0]: OSError: sndfile library not found using ctypes.util.find_library\n",
      "\n",
      "[rank0]: During handling of the above exception, another exception occurred:\n",
      "\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/examples/asr_librispeech/finetune_asr.py\", line 49, in <module>\n",
      "[rank0]:     main_hydra()\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/main.py\", line 94, in decorated_main\n",
      "[rank0]:     _run_hydra(\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
      "[rank0]:     _run_app(\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
      "[rank0]:     run_and_report(\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
      "[rank0]:     raise ex\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "[rank0]:     return func()\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
      "[rank0]:     lambda: hydra.run(\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 132, in run\n",
      "[rank0]:     _ = ret.return_value\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "[rank0]:     raise self._return_value\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/hydra/core/utils.py\", line 186, in run_job\n",
      "[rank0]:     ret.return_value = task_function(task_cfg)\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/examples/asr_librispeech/finetune_asr.py\", line 45, in main_hydra\n",
      "[rank0]:     train(kwargs)\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/pipeline/finetune.py\", line 154, in main\n",
      "[rank0]:     model_factory = get_custom_model_factory(model_config, logger)\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/utils/model_utils.py\", line 24, in get_custom_model_factory\n",
      "[rank0]:     module = load_module_from_py_file(module_path.as_posix())\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/utils/dataset_utils.py\", line 23, in load_module_from_py_file\n",
      "[rank0]:     loader.exec_module(module)\n",
      "[rank0]:   File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "[rank0]:   File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "[rank0]:   File \"examples/asr_librispeech/model/slam_model_asr.py\", line 4, in <module>\n",
      "[rank0]:     from slam_llm.models.slam_model import (\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_expriments/slam-llm/src/slam_llm/models/slam_model.py\", line 4, in <module>\n",
      "[rank0]:     import soundfile as sf\n",
      "[rank0]:   File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/soundfile.py\", line 192, in <module>\n",
      "[rank0]:     _snd = _ffi.dlopen(_explicit_libname)\n",
      "[rank0]: OSError: cannot load library 'libsndfile.so': libsndfile.so: cannot open shared object file: No such file or directory\n",
      "E0710 00:15:31.945000 47970513651904 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 0 (pid: 16714) of binary: /work/van-speech-nlp/jindaznb/slamenv/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/run.py\", line 879, in main\n",
      "    run(args)\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/run.py\", line 870, in run\n",
      "    elastic_launch(\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 263, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "examples/asr_librispeech/finetune_asr.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-07-10_00:15:31\n",
      "  host      : d1028.discovery.neu.edu\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 16714)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!scripts/finetune_hubert_xtralarge_linear_vicuna_7b.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d905372",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sbatch strain.bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891aa96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install setuptools==69.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd46e70c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soundfile\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
      "Collecting cffi>=1.0 (from soundfile)\n",
      "  Downloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Using cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "Downloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.9/443.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pycparser, cffi, soundfile\n",
      "  Attempting uninstall: pycparser\n",
      "    Found existing installation: pycparser 2.22\n",
      "    Uninstalling pycparser-2.22:\n",
      "      Successfully uninstalled pycparser-2.22\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.16.0\n",
      "    Uninstalling cffi-1.16.0:\n",
      "      Successfully uninstalled cffi-1.16.0\n",
      "  Attempting uninstall: soundfile\n",
      "    Found existing installation: soundfile 0.12.1\n",
      "    Uninstalling soundfile-0.12.1:\n",
      "      Successfully uninstalled soundfile-0.12.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fairseq 0.12.2 requires hydra-core<1.1,>=1.0.7, but you have hydra-core 1.3.2 which is incompatible.\n",
      "fairseq 0.12.2 requires omegaconf<2.1, but you have omegaconf 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cffi-1.16.0 pycparser-2.22 soundfile-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VERSION=118 make cuda11x_nomatmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6da603",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show slam-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d12d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
