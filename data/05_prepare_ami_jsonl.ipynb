{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/load.py:2554: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering, the number of data in each dataset split is:\n",
      "train: 108502\n",
      "validation: 13098\n",
      "test: 12643\n",
      "\n",
      "After filtering audio within a certain length, the number of data in each dataset split is:\n",
      "train: 66698\n",
      "validation: 8351\n",
      "test: 7546\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, Audio\n",
    "import logging\n",
    "\n",
    "# Enable logging for the datasets library to see detailed information\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load the AMI dataset\n",
    "dataset = load_dataset(\n",
    "    \"edinburghcstr/ami\", \"ihm\",\n",
    "    cache_dir='/work/van-speech-nlp/temp',\n",
    "    use_auth_token='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'\n",
    ")\n",
    "\n",
    "# Print the number of data points in each split before filtering\n",
    "print(\"Before filtering, the number of data in each dataset split is:\")\n",
    "for split, data in dataset.items():\n",
    "    print(f\"{split}: {len(data)}\")\n",
    "\n",
    "# Define the min and max input lengths in seconds\n",
    "min_input_length_in_sec = 1.0\n",
    "max_input_length_in_sec = 10.0\n",
    "\n",
    "# Calculate input_length as the difference between end_time and begin_time\n",
    "dataset = dataset.map(\n",
    "    lambda x: {'input_length': x['end_time'] - x['begin_time']}\n",
    ")\n",
    "\n",
    "# Filter audio samples based on the calculated input_length\n",
    "dataset = dataset.filter(\n",
    "    lambda x: min_input_length_in_sec < x['input_length'] < max_input_length_in_sec\n",
    ")\n",
    "\n",
    "# Print the number of data points in each split after filtering\n",
    "print(\"\\nAfter filtering audio within a certain length, the number of data in each dataset split is:\")\n",
    "for split, data in dataset.items():\n",
    "    print(f\"{split}: {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meeting_id': 'EN2002a',\n",
       " 'audio_id': 'AMI_EN2002a_H00_MEE073_0019663_0019800',\n",
       " 'text': 'YEAH',\n",
       " 'audio': {'path': '/work/van-speech-nlp/temp/downloads/extracted/af54b322915698bd55d07a3bc1f323ed8802dca8159367bd7188421a458688af/EN2002a/eval_ami_en2002a_h00_mee073_0019663_0019800.wav',\n",
       "  'array': array([-9.15527344e-05, -1.52587891e-04, -1.52587891e-04, ...,\n",
       "         -3.05175781e-05, -3.05175781e-05, -6.10351562e-05]),\n",
       "  'sampling_rate': 16000},\n",
       " 'begin_time': 196.6300048828125,\n",
       " 'end_time': 198.0,\n",
       " 'microphone_id': 'H00',\n",
       " 'speaker_id': 'MEE073',\n",
       " 'input_length': 1.3699951171875}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3618b2d6825a4e46914ce2c07c5436a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7546 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['meeting_id', 'audio_id', 'text', 'audio', 'begin_time', 'end_time', 'microphone_id', 'speaker_id', 'input_length'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Assuming the dataset is loaded as 'dataset'\n",
    "meeting_id_to_find = \"AMI_TS3003c_H03_MTD012ME_0183799_0183930\"\n",
    "\n",
    "# Filter the dataset to find the specific meeting_id\n",
    "filtered_data = dataset['test'].filter(lambda x: x['audio_id'] == meeting_id_to_find)\n",
    "\n",
    "# Check the result\n",
    "print(filtered_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meeting_id': 'TS3003c',\n",
       " 'audio_id': 'AMI_TS3003c_H03_MTD012ME_0183799_0183930',\n",
       " 'text': 'YEAH',\n",
       " 'audio': {'path': '/work/van-speech-nlp/temp/downloads/extracted/d613367cf787ca9a867f57a209cfd7c43eb5619b9b34597d3c24e5fd65298ddb/TS3003c/eval_ami_ts3003c_h03_mtd012me_0183799_0183930.wav',\n",
       "  'array': array([ 0.00000000e+00, -1.22070312e-04, -3.05175781e-05, ...,\n",
       "          4.88281250e-04,  2.13623047e-04,  9.15527344e-05]),\n",
       "  'sampling_rate': 16000},\n",
       " 'begin_time': 1837.989990234375,\n",
       " 'end_time': 1839.300048828125,\n",
       " 'microphone_id': 'H03',\n",
       " 'speaker_id': 'MTD012ME',\n",
       " 'input_length': 1.31005859375}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "identifier = \"ami\"\n",
    "\n",
    "def create_jsonl_file(dataset, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for split in ['train', 'validation', 'test']:\n",
    "        jsonl_path = os.path.join(output_dir, f\"{identifier}_{split}.jsonl\")\n",
    "\n",
    "        if os.path.exists(jsonl_path):\n",
    "            os.remove(jsonl_path)\n",
    "\n",
    "        with open(jsonl_path, 'w') as jsonl_file:\n",
    "            for sample in tqdm(dataset[split], desc=f\"Processing {split} split\"):\n",
    "                audio_id = sample['audio_id']\n",
    "                audio_path = sample['audio']['path']  \n",
    "                transcription = sample['text'].lower()\n",
    "\n",
    "                json_data = {\n",
    "                    \"key\": audio_id,\n",
    "                    \"source\": audio_path,\n",
    "                    \"target\": transcription\n",
    "                }\n",
    "\n",
    "                jsonl_file.write(json.dumps(json_data) + \"\\n\")\n",
    "\n",
    "        print(f\"Generated {jsonl_path}\")\n",
    "\n",
    "output_directory = \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami\"\n",
    "\n",
    "create_jsonl_file(dataset, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
