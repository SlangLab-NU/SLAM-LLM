{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97c71b015bf4706a6d14191ad243d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1fa766b75c4811946b9619e94663bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/314M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dfadccc9944519a593ada6c91be6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/30.6G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     26\u001b[0m librispeech_test_clean \u001b[39m=\u001b[39m load_dataset(\n\u001b[1;32m     27\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlibrispeech_asr\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     28\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mclean\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     trust_remote_code\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[39m# Load test-other dataset\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m librispeech_test_other \u001b[39m=\u001b[39m load_dataset(\n\u001b[1;32m     36\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mlibrispeech_asr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m     37\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mother\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m     38\u001b[0m     split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m     39\u001b[0m     cache_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/work/van-speech-nlp/temp\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m     40\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m )\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/load.py:2616\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2613\u001b[0m     \u001b[39mreturn\u001b[39;00m builder_instance\u001b[39m.\u001b[39mas_streaming_dataset(split\u001b[39m=\u001b[39msplit)\n\u001b[1;32m   2615\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 2616\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[1;32m   2617\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   2618\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   2619\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m   2620\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m   2621\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2622\u001b[0m )\n\u001b[1;32m   2624\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2625\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   2626\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   2627\u001b[0m )\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/builder.py:1029\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1028\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[0;32m-> 1029\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m   1030\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[1;32m   1031\u001b[0m         verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m   1032\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[1;32m   1033\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[1;32m   1034\u001b[0m     )\n\u001b[1;32m   1035\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/builder.py:1791\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_and_prepare\u001b[39m(\u001b[39mself\u001b[39m, dl_manager, verification_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs):\n\u001b[0;32m-> 1791\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m   1792\u001b[0m         dl_manager,\n\u001b[1;32m   1793\u001b[0m         verification_mode,\n\u001b[1;32m   1794\u001b[0m         check_duplicate_keys\u001b[39m=\u001b[39;49mverification_mode \u001b[39m==\u001b[39;49m VerificationMode\u001b[39m.\u001b[39;49mBASIC_CHECKS\n\u001b[1;32m   1795\u001b[0m         \u001b[39mor\u001b[39;49;00m verification_mode \u001b[39m==\u001b[39;49m VerificationMode\u001b[39m.\u001b[39;49mALL_CHECKS,\n\u001b[1;32m   1796\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_splits_kwargs,\n\u001b[1;32m   1797\u001b[0m     )\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/builder.py:1102\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m split_dict \u001b[39m=\u001b[39m SplitDict(dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name)\n\u001b[1;32m   1101\u001b[0m split_generators_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m-> 1102\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_generators(dl_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msplit_generators_kwargs)\n\u001b[1;32m   1104\u001b[0m \u001b[39m# Checksums verification\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m \u001b[39mif\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/librispeech_asr/2712a8f82f0d20807a56faadcd08734f9bdd24c850bb118ba21ff33ebff0432f/librispeech_asr.py:115\u001b[0m, in \u001b[0;36mLibrispeechASR._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_split_generators\u001b[39m(\u001b[39mself\u001b[39m, dl_manager):\n\u001b[0;32m--> 115\u001b[0m     archive_path \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39;49mdownload(_DL_URLS[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mname])\n\u001b[1;32m    116\u001b[0m     \u001b[39m# (Optional) In non-streaming mode, we can extract the archive locally to have actual local audio files:\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     local_extracted_archive \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39mextract(archive_path) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dl_manager\u001b[39m.\u001b[39mis_streaming \u001b[39melse\u001b[39;00m {}\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/download/download_manager.py:257\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    255\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m    256\u001b[0m \u001b[39mwith\u001b[39;00m stack_multiprocessing_download_progress_bars():\n\u001b[0;32m--> 257\u001b[0m     downloaded_path_or_paths \u001b[39m=\u001b[39m map_nested(\n\u001b[1;32m    258\u001b[0m         download_func,\n\u001b[1;32m    259\u001b[0m         url_or_urls,\n\u001b[1;32m    260\u001b[0m         map_tuple\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    261\u001b[0m         num_proc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mnum_proc,\n\u001b[1;32m    262\u001b[0m         desc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDownloading data files\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    263\u001b[0m         batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    264\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    266\u001b[0m duration \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    267\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading took \u001b[39m\u001b[39m{\u001b[39;00mduration\u001b[39m.\u001b[39mtotal_seconds()\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39m60\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m min\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/utils/py_utils.py:511\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    509\u001b[0m         batch_size \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mlen\u001b[39m(iterable) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_proc \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(iterable) \u001b[39m%\u001b[39m num_proc \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[1;32m    510\u001b[0m     iterable \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[0;32m--> 511\u001b[0m mapped \u001b[39m=\u001b[39m [\n\u001b[1;32m    512\u001b[0m     _single_map_nested((function, obj, batched, batch_size, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    513\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m hf_tqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[1;32m    514\u001b[0m ]\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m batched:\n\u001b[1;32m    516\u001b[0m     mapped \u001b[39m=\u001b[39m [mapped_item \u001b[39mfor\u001b[39;00m mapped_batch \u001b[39min\u001b[39;00m mapped \u001b[39mfor\u001b[39;00m mapped_item \u001b[39min\u001b[39;00m mapped_batch]\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/utils/py_utils.py:512\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    509\u001b[0m         batch_size \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mlen\u001b[39m(iterable) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_proc \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(iterable) \u001b[39m%\u001b[39m num_proc \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[1;32m    510\u001b[0m     iterable \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[1;32m    511\u001b[0m mapped \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 512\u001b[0m     _single_map_nested((function, obj, batched, batch_size, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m))\n\u001b[1;32m    513\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m hf_tqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[1;32m    514\u001b[0m ]\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m batched:\n\u001b[1;32m    516\u001b[0m     mapped \u001b[39m=\u001b[39m [mapped_item \u001b[39mfor\u001b[39;00m mapped_batch \u001b[39min\u001b[39;00m mapped \u001b[39mfor\u001b[39;00m mapped_item \u001b[39min\u001b[39;00m mapped_batch]\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/utils/py_utils.py:380\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    374\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    375\u001b[0m     batched\n\u001b[1;32m    376\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m)\n\u001b[1;32m    377\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types)\n\u001b[1;32m    378\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(v, (\u001b[39mdict\u001b[39m, types)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m data_struct)\n\u001b[1;32m    379\u001b[0m ):\n\u001b[0;32m--> 380\u001b[0m     \u001b[39mreturn\u001b[39;00m [mapped_item \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[39mfor\u001b[39;00m mapped_item \u001b[39min\u001b[39;00m function(batch)]\n\u001b[1;32m    382\u001b[0m \u001b[39m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m logging\u001b[39m.\u001b[39mget_verbosity() \u001b[39m<\u001b[39m logging\u001b[39m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/utils/py_utils.py:380\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    374\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    375\u001b[0m     batched\n\u001b[1;32m    376\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m)\n\u001b[1;32m    377\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types)\n\u001b[1;32m    378\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(v, (\u001b[39mdict\u001b[39m, types)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m data_struct)\n\u001b[1;32m    379\u001b[0m ):\n\u001b[0;32m--> 380\u001b[0m     \u001b[39mreturn\u001b[39;00m [mapped_item \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[39mfor\u001b[39;00m mapped_item \u001b[39min\u001b[39;00m function(batch)]\n\u001b[1;32m    382\u001b[0m \u001b[39m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m logging\u001b[39m.\u001b[39mget_verbosity() \u001b[39m<\u001b[39m logging\u001b[39m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/download/download_manager.py:313\u001b[0m, in \u001b[0;36mDownloadManager._download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    301\u001b[0m         download_func,\n\u001b[1;32m    302\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m         tqdm_class\u001b[39m=\u001b[39mtqdm,\n\u001b[1;32m    311\u001b[0m     )\n\u001b[1;32m    312\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    314\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_single(url_or_filename, download_config\u001b[39m=\u001b[39mdownload_config)\n\u001b[1;32m    315\u001b[0m         \u001b[39mfor\u001b[39;00m url_or_filename \u001b[39min\u001b[39;00m url_or_filenames\n\u001b[1;32m    316\u001b[0m     ]\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/download/download_manager.py:314\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    301\u001b[0m         download_func,\n\u001b[1;32m    302\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m         tqdm_class\u001b[39m=\u001b[39mtqdm,\n\u001b[1;32m    311\u001b[0m     )\n\u001b[1;32m    312\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m--> 314\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_single(url_or_filename, download_config\u001b[39m=\u001b[39;49mdownload_config)\n\u001b[1;32m    315\u001b[0m         \u001b[39mfor\u001b[39;00m url_or_filename \u001b[39min\u001b[39;00m url_or_filenames\n\u001b[1;32m    316\u001b[0m     ]\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/download/download_manager.py:323\u001b[0m, in \u001b[0;36mDownloadManager._download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[1;32m    321\u001b[0m     \u001b[39m# append the relative path to the base_path\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     url_or_filename \u001b[39m=\u001b[39m url_or_path_join(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_path, url_or_filename)\n\u001b[0;32m--> 323\u001b[0m out \u001b[39m=\u001b[39m cached_path(url_or_filename, download_config\u001b[39m=\u001b[39;49mdownload_config)\n\u001b[1;32m    324\u001b[0m out \u001b[39m=\u001b[39m tracked_str(out)\n\u001b[1;32m    325\u001b[0m out\u001b[39m.\u001b[39mset_origin(url_or_filename)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/utils/file_utils.py:201\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     url_or_filename \u001b[39m=\u001b[39m strip_protocol(url_or_filename)\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    200\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    202\u001b[0m         url_or_filename,\n\u001b[1;32m    203\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    204\u001b[0m         force_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mforce_download,\n\u001b[1;32m    205\u001b[0m         proxies\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    206\u001b[0m         resume_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mresume_download,\n\u001b[1;32m    207\u001b[0m         user_agent\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muser_agent,\n\u001b[1;32m    208\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mlocal_files_only,\n\u001b[1;32m    209\u001b[0m         use_etag\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_etag,\n\u001b[1;32m    210\u001b[0m         max_retries\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    211\u001b[0m         token\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mtoken,\n\u001b[1;32m    212\u001b[0m         ignore_url_params\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mignore_url_params,\n\u001b[1;32m    213\u001b[0m         storage_options\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    214\u001b[0m         download_desc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mdownload_desc,\n\u001b[1;32m    215\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mdisable_tqdm,\n\u001b[1;32m    216\u001b[0m     )\n\u001b[1;32m    217\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    218\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/utils/file_utils.py:680\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, use_auth_token, ignore_url_params, storage_options, download_desc, disable_tqdm)\u001b[0m\n\u001b[1;32m    676\u001b[0m         fsspec_get(\n\u001b[1;32m    677\u001b[0m             url, temp_file, storage_options\u001b[39m=\u001b[39mstorage_options, desc\u001b[39m=\u001b[39mdownload_desc, disable_tqdm\u001b[39m=\u001b[39mdisable_tqdm\n\u001b[1;32m    678\u001b[0m         )\n\u001b[1;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         http_get(\n\u001b[1;32m    681\u001b[0m             url,\n\u001b[1;32m    682\u001b[0m             temp_file\u001b[39m=\u001b[39;49mtemp_file,\n\u001b[1;32m    683\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    684\u001b[0m             resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[1;32m    685\u001b[0m             headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    686\u001b[0m             cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[1;32m    687\u001b[0m             max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[1;32m    688\u001b[0m             desc\u001b[39m=\u001b[39;49mdownload_desc,\n\u001b[1;32m    689\u001b[0m             disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[1;32m    690\u001b[0m         )\n\u001b[1;32m    692\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mcache_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    693\u001b[0m shutil\u001b[39m.\u001b[39mmove(temp_file\u001b[39m.\u001b[39mname, cache_path)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/datasets/utils/file_utils.py:453\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, cookies, timeout, max_retries, desc, disable_tqdm)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m    441\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    442\u001b[0m     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m     disable\u001b[39m=\u001b[39mdisable_tqdm,\n\u001b[1;32m    451\u001b[0m ) \u001b[39mas\u001b[39;00m progress:\n\u001b[1;32m    452\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[0;32m--> 453\u001b[0m         progress\u001b[39m.\u001b[39;49mupdate(\u001b[39mlen\u001b[39;49m(chunk))\n\u001b[1;32m    454\u001b[0m         temp_file\u001b[39m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/tqdm/notebook.py:262\u001b[0m, in \u001b[0;36mtqdm_notebook.update\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m(\u001b[39mself\u001b[39m, n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    261\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mupdate(n\u001b[39m=\u001b[39;49mn)\n\u001b[1;32m    263\u001b[0m     \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[39mexcept\u001b[39;00m:  \u001b[39m# NOQA\u001b[39;00m\n\u001b[1;32m    265\u001b[0m         \u001b[39m# cannot catch KeyboardInterrupt when using manual tqdm\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[39m# as the interrupt will most likely happen on another statement\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/tqdm/std.py:1242\u001b[0m, in \u001b[0;36mtqdm.update\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ema_dn(dn)\n\u001b[1;32m   1241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ema_dt(dt)\n\u001b[0;32m-> 1242\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrefresh(lock_args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlock_args)\n\u001b[1;32m   1243\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_miniters:\n\u001b[1;32m   1244\u001b[0m     \u001b[39m# If no `miniters` was specified, adjust automatically to the\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m     \u001b[39m# maximum iteration rate seen so far between two prints.\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m     \u001b[39m# e.g.: After running `tqdm.update(5)`, subsequent\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m     \u001b[39m# calls to `tqdm.update()` will only cause an update after\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m     \u001b[39m# at least 5 more iterations.\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxinterval \u001b[39mand\u001b[39;00m dt \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxinterval:\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/tqdm/std.py:1347\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39macquire()\n\u001b[0;32m-> 1347\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdisplay()\n\u001b[1;32m   1348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nolock:\n\u001b[1;32m   1349\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/tqdm/notebook.py:157\u001b[0m, in \u001b[0;36mtqdm_notebook.display\u001b[0;34m(self, msg, pos, close, bar_style, check_delay)\u001b[0m\n\u001b[1;32m    154\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_meter(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39md)\n\u001b[1;32m    156\u001b[0m ltext, pbar, rtext \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer\u001b[39m.\u001b[39mchildren\n\u001b[0;32m--> 157\u001b[0m pbar\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m msg:\n\u001b[1;32m    160\u001b[0m     msg \u001b[39m=\u001b[39m msg\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mu\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\u2007\u001b[39;00m\u001b[39m'\u001b[39m)  \u001b[39m# fix html space padding\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/traitlets/traitlets.py:716\u001b[0m, in \u001b[0;36mTraitType.__set__\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_only:\n\u001b[1;32m    715\u001b[0m     \u001b[39mraise\u001b[39;00m TraitError(\u001b[39m'\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m trait is read-only.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[0;32m--> 716\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset(obj, value)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/traitlets/traitlets.py:706\u001b[0m, in \u001b[0;36mTraitType.set\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m     silent \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[39mif\u001b[39;00m silent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39m# we explicitly compare silent to True just in case the equality\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[39m# comparison above returns something other than True/False\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m     obj\u001b[39m.\u001b[39;49m_notify_trait(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, old_value, new_value)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/traitlets/traitlets.py:1513\u001b[0m, in \u001b[0;36mHasTraits._notify_trait\u001b[0;34m(self, name, old_value, new_value)\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_notify_trait\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m, old_value: t\u001b[39m.\u001b[39mAny, new_value: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1513\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnotify_change(\n\u001b[1;32m   1514\u001b[0m         Bunch(\n\u001b[1;32m   1515\u001b[0m             name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1516\u001b[0m             old\u001b[39m=\u001b[39;49mold_value,\n\u001b[1;32m   1517\u001b[0m             new\u001b[39m=\u001b[39;49mnew_value,\n\u001b[1;32m   1518\u001b[0m             owner\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1519\u001b[0m             \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mchange\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1520\u001b[0m         )\n\u001b[1;32m   1521\u001b[0m     )\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:686\u001b[0m, in \u001b[0;36mWidget.notify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomm, \u001b[39m'\u001b[39m\u001b[39mkernel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[39m# Make sure this isn't information that the front-end just sent us.\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeys \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_send_property(name, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, name)):\n\u001b[1;32m    685\u001b[0m         \u001b[39m# Send new state to front-end\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend_state(key\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m    687\u001b[0m \u001b[39msuper\u001b[39m(Widget, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mnotify_change(change)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:555\u001b[0m, in \u001b[0;36mWidget.send_state\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    553\u001b[0m state, buffer_paths, buffers \u001b[39m=\u001b[39m _remove_buffers(state)\n\u001b[1;32m    554\u001b[0m msg \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m'\u001b[39m: state, \u001b[39m'\u001b[39m\u001b[39mbuffer_paths\u001b[39m\u001b[39m'\u001b[39m: buffer_paths}\n\u001b[0;32m--> 555\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send(msg, buffers\u001b[39m=\u001b[39;49mbuffers)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:818\u001b[0m, in \u001b[0;36mWidget._send\u001b[0;34m(self, msg, buffers)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Sends a message to the model in the front-end.\"\"\"\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomm\u001b[39m.\u001b[39mkernel \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomm, \u001b[39m\"\u001b[39m\u001b[39mkernel\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 818\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomm\u001b[39m.\u001b[39;49msend(data\u001b[39m=\u001b[39;49mmsg, buffers\u001b[39m=\u001b[39;49mbuffers)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/comm/base_comm.py:147\u001b[0m, in \u001b[0;36mBaseComm.send\u001b[0;34m(self, data, metadata, buffers)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend\u001b[39m(\n\u001b[1;32m    144\u001b[0m     \u001b[39mself\u001b[39m, data: MaybeDict \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, metadata: MaybeDict \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, buffers: BuffersType \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Send a message to the frontend-side version of this comm\"\"\"\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpublish_msg(\n\u001b[1;32m    148\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mcomm_msg\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    149\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    150\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    151\u001b[0m         buffers\u001b[39m=\u001b[39;49mbuffers,\n\u001b[1;32m    152\u001b[0m     )\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/ipykernel/comm/comm.py:37\u001b[0m, in \u001b[0;36mBaseComm.publish_msg\u001b[0;34m(self, msg_type, data, metadata, buffers, **keys)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m=\u001b[39m Kernel\u001b[39m.\u001b[39minstance()\n\u001b[1;32m     36\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39msession \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m     38\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel\u001b[39m.\u001b[39;49miopub_socket,\n\u001b[1;32m     39\u001b[0m     msg_type,\n\u001b[1;32m     40\u001b[0m     content,\n\u001b[1;32m     41\u001b[0m     metadata\u001b[39m=\u001b[39;49mjson_clean(metadata),\n\u001b[1;32m     42\u001b[0m     parent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel\u001b[39m.\u001b[39;49mget_parent(),\n\u001b[1;32m     43\u001b[0m     ident\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtopic,\n\u001b[1;32m     44\u001b[0m     buffers\u001b[39m=\u001b[39;49mbuffers,\n\u001b[1;32m     45\u001b[0m )\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/jupyter_client/session.py:852\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, stream, msg_or_type, content, parent, ident, buffers, track, header, metadata)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapt_version:\n\u001b[1;32m    851\u001b[0m     msg \u001b[39m=\u001b[39m adapt(msg, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapt_version)\n\u001b[0;32m--> 852\u001b[0m to_send \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserialize(msg, ident)\n\u001b[1;32m    853\u001b[0m to_send\u001b[39m.\u001b[39mextend(buffers)\n\u001b[1;32m    854\u001b[0m longest \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m([\u001b[39mlen\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m to_send])\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/jupyter_client/session.py:732\u001b[0m, in \u001b[0;36mSession.serialize\u001b[0;34m(self, msg, ident)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mContent incorrect type: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(content))\n\u001b[1;32m    731\u001b[0m real_message \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 732\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpack(msg[\u001b[39m\"\u001b[39;49m\u001b[39mheader\u001b[39;49m\u001b[39m\"\u001b[39;49m]),\n\u001b[1;32m    733\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpack(msg[\u001b[39m\"\u001b[39m\u001b[39mparent_header\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m    734\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpack(msg[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m    735\u001b[0m     content,\n\u001b[1;32m    736\u001b[0m ]\n\u001b[1;32m    738\u001b[0m to_send \u001b[39m=\u001b[39m []\n\u001b[1;32m    740\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ident, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    741\u001b[0m     \u001b[39m# accept list of idents\u001b[39;00m\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/jupyter_client/session.py:95\u001b[0m, in \u001b[0;36mjson_packer\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Convert a json object to a bytes.\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39;49mdumps(\n\u001b[1;32m     96\u001b[0m         obj,\n\u001b[1;32m     97\u001b[0m         default\u001b[39m=\u001b[39;49mjson_default,\n\u001b[1;32m     98\u001b[0m         ensure_ascii\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     99\u001b[0m         allow_nan\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    100\u001b[0m     )\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m\"\u001b[39m, errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msurrogateescape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    102\u001b[0m     \u001b[39m# Fallback to trying to clean the json before serializing\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     packed \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(\n\u001b[1;32m    104\u001b[0m         json_clean(obj),\n\u001b[1;32m    105\u001b[0m         default\u001b[39m=\u001b[39mjson_default,\n\u001b[1;32m    106\u001b[0m         ensure_ascii\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    107\u001b[0m         allow_nan\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    108\u001b[0m     )\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m\"\u001b[39m, errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msurrogateescape\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/json/__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n\u001b[1;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    235\u001b[0m     skipkeys\u001b[39m=\u001b[39;49mskipkeys, ensure_ascii\u001b[39m=\u001b[39;49mensure_ascii,\n\u001b[1;32m    236\u001b[0m     check_circular\u001b[39m=\u001b[39;49mcheck_circular, allow_nan\u001b[39m=\u001b[39;49mallow_nan, indent\u001b[39m=\u001b[39;49mindent,\n\u001b[1;32m    237\u001b[0m     separators\u001b[39m=\u001b[39;49mseparators, default\u001b[39m=\u001b[39;49mdefault, sort_keys\u001b[39m=\u001b[39;49msort_keys,\n\u001b[0;32m--> 238\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\u001b[39m.\u001b[39;49mencode(obj)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/work/van-speech-nlp/jindaznb/slamenv/lib/python3.10/site-packages/jupyter_client/jsonutil.py:111\u001b[0m, in \u001b[0;36mjson_default\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, datetime):\n\u001b[1;32m    110\u001b[0m     obj \u001b[39m=\u001b[39m _ensure_tzinfo(obj)\n\u001b[0;32m--> 111\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39;49misoformat()\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m+00:00\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mZ\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m b2a_base64(obj, newline\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mascii\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load train-100 dataset (100-hour subset of the clean training data)\n",
    "# librispeech_train_100 = load_dataset(\n",
    "#     \"librispeech_asr\", \n",
    "#     \"clean\", \n",
    "#     split=\"train.100\", \n",
    "#     cache_dir=\"/work/van-speech-nlp/temp\", \n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "\n",
    "\n",
    "# # Load validation (dev-360) dataset\n",
    "# librispeech_val_360 = load_dataset(\n",
    "#     \"librispeech_asr\", \n",
    "#     \"clean\", \n",
    "#     split=\"validation\", \n",
    "#     cache_dir=\"/work/van-speech-nlp/temp\", \n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "\n",
    "# Load test-clean dataset\n",
    "librispeech_test_clean = load_dataset(\n",
    "    \"librispeech_asr\", \n",
    "    \"clean\", \n",
    "    split=\"test\", \n",
    "    cache_dir=\"/work/van-speech-nlp/temp\", \n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load test-other dataset\n",
    "librispeech_test_other = load_dataset(\n",
    "    \"librispeech_asr\", \n",
    "    \"other\", \n",
    "    split=\"test\", \n",
    "    cache_dir=\"/work/van-speech-nlp/temp\", \n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train.100 split: 100%|██████████| 28539/28539 [35:18<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech_asr_phoneme/librispeech_train.100.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing validation split: 100%|██████████| 2703/2703 [01:57<00:00, 22.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech_asr_phoneme/librispeech_validation.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from g2p import make_g2p\n",
    "\n",
    "# Initialize G2P converter for English ARPAbet\n",
    "transducer = make_g2p('eng', 'eng-arpabet')\n",
    "\n",
    "# Define the identifier for the dataset\n",
    "identifier = \"librispeech\"\n",
    "\n",
    "def get_phonemes(sentence):\n",
    "    \"\"\"Convert sentence to phonemes using G2P.\"\"\"\n",
    "    phonemes_list = [transducer(word).output_string for word in re.findall(r'\\S+', sentence)]\n",
    "    phonemes = \" \".join(phonemes_list)\n",
    "    return phonemes\n",
    "\n",
    "def create_jsonl_file(dataset, split_name, output_dir):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    jsonl_path = os.path.join(output_dir, f\"{identifier}_{split_name}.jsonl\")\n",
    "\n",
    "    # If the file already exists, remove it\n",
    "    if os.path.exists(jsonl_path):\n",
    "        os.remove(jsonl_path)\n",
    "\n",
    "    # Process the dataset and write to a JSONL file\n",
    "    with open(jsonl_path, 'w') as jsonl_file:\n",
    "        # cnt = 0\n",
    "        for sample in tqdm(dataset, desc=f\"Processing {split_name} split\"):\n",
    "            # cnt += 1\n",
    "            # if cnt > 2:  # Limit to 3 samples for testing\n",
    "            #     break\n",
    "            audio_id = sample['id']\n",
    "            audio_path = sample['audio']['path']\n",
    "            transcription = sample['text'].lower()\n",
    "\n",
    "            # Generate G2P phoneme transcription\n",
    "            phonemes = get_phonemes(transcription)\n",
    "\n",
    "            json_data = {\n",
    "                \"key\": audio_id,\n",
    "                \"source\": audio_path,\n",
    "                \"target\": transcription,\n",
    "                \"phoneme\": phonemes\n",
    "            }\n",
    "\n",
    "            jsonl_file.write(json.dumps(json_data) + \"\\n\")\n",
    "\n",
    "    print(f\"Generated {jsonl_path}\")\n",
    "\n",
    "# Output directory for storing the JSONL files\n",
    "output_directory = \"/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech_asr_phoneme\"\n",
    "\n",
    "# Example dataset objects (replace with actual dataset objects)\n",
    "# librispeech_train_100 = [...] \n",
    "# librispeech_val_360 = [...]\n",
    "\n",
    "# Generate JSONL files for train and validation splits\n",
    "# create_jsonl_file(librispeech_train_100, \"train.100\", output_directory)\n",
    "# create_jsonl_file(librispeech_val_360, \"validation\", output_directory)\n",
    "create_jsonl_file(librispeech_test_clean, \"test_clean\", output_directory)\n",
    "create_jsonl_file(librispeech_test_other, \"test_other\", output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
