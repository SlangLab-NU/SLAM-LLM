model_config:
  llm_name: llama32_1b
  llm_path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct
  llm_dim: 2048
  encoder_name: wavlm
  normalize: true
  encoder_path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt
  encoder_dim: 1024
  encoder_projector: linear
  encoder_projector_ds_rate: 5
  encoder2_name: ''
  encoder2_path: ''
  identifier: ami_wavlm_llama32_1b_linear_peft_seed_42
  llm_inference_config: repetition_penalty
dataset_config:
  normalize: true
  dataset: speech_dataset
  val_data_path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/ami/test.jsonl
  inference_mode: true
  file: src/slam_llm/datasets/speech_dataset.py:get_speech_dataset
  input_type: raw
train_config:
  model_name: asr
  freeze_encoder: true
  freeze_llm: true
  batching_strategy: custom
  num_epochs: 1
  val_batch_size: 4
  num_workers_dataloader: 1
  output_dir: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_wavlm_llama32_1b_linear_peft_seed_42
  use_peft: true
  seed: 42
decode_log: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_wavlm_llama32_1b_linear_peft_seed_42/decode_test_beam4
ckpt_path: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/ami_wavlm_llama32_1b_linear_peft_seed_42/asr_epoch_2_step_20227_loss_0.6397270560264587/model.pt
log_config:
  wandb_exp_name: ami_wavlm_llama32_1b_linear_peft_seed_42
